# Saffron 3 - Formats
===================

This document describes the formats used and generated by Saffron 3. <br/>All formats are in JSON
and we will describe the properties each files has, with a link to an example (as found in the [examples](https://gitlab.insight-centre.org/saffron/saffron/blob/saffron_development/examples/) folder)

## Input formats

### Corpus  (e.g. [input_corpus.json](https://gitlab.insight-centre.org/saffron/saffron/blob/issue215/examples/input_corpus.json))
------

This file contains the description of the corpus, including all the metadata. It is a collection of documents, each element being a different dicument with its own metadata and link to the file containing the text. A corpus has the following properties:

* `documents`: A list of documents in the corpus

    Each element of the list should have *at least* one of the following four:

    * `file`: A string referring to the original version of this document on disk (absolute or relative path)
    * `id`: A unique string to identify the document
    * `url`: The URL of the file
    * `contents`: The text contents of the file
    
    In addition the following may be provided:
    * `name`: The human readable name of the document
    * `mime_type`: The MIME type of the document
    * `authors`: An array of authors of this document
            
        For each author of the document, provide:
        - Either the name of the author as a string
        - Or if more details on the author:
            * `name`: The author's name (required)
            * `id`: A unique string to identify the author (optional)
            * `name_variants`: An array of strings given other known variants of the name (optional)
            
    * `metadata`: An object containing any other properties
        Each property is in the form: 
        
            "property name":"property value", separated by commas


### Config (e.g. [config.json](https://gitlab.insight-centre.org/saffron/saffron/blob/saffron_development/examples/config.json))

This input file for the command line interface (generated automatically if using the user interface) describes all options from the different steps of Saffron.
See the [wiki](https://gitlab.insight-centre.org/saffron/saffron/wikis/saffron-approach) for the details on what each property is for and the scientific explaination of the method.

It contains each of the Saffron steps:

##### 1.   Term Extraction
Configuration for the options of the term extraction phase. All properties are included under the object:

* `termExtraction`: This element contains the following properties to set up:
    * `threshold` : Sets a minimum Saffron score for the terms retrieved

    * `maxTerms` : Sets the maximum number of terms to extract . Default to 100
    
    * `ngramMin` : Sets the shortest length of term to consider (in terms of number of words). Default to 1
    
    * `ngramMax` : Sets the longest length of term to consider  (in terms of number of words). Default to 4
    
    * `minTermFreq` : Sets the number of times a term must appear in the dataset to be retrieved. Default to 2
    
    * `maxDocs` : The maximum number of documents to consider for the analysis. Default to 2147483647
    
    * `method` : Choose between two ranking procedures: "voting" (algorithm that integrates multiple score functions) and "single" (only one score function)
    
    * `features` : List of scoring functions if choosing the "voting" method above, or will be ignored the "single" method was chosen. Default set to [ "comboBasic", "weirdness", "totalTfIdf", "cValue", "residualIdf" ])
    
        Choose between:  `comboBasic`, `weirdness`, `totalTfIdf`, `cValue`, `residualIdf`, `avgTermFreq`, `basic`, `novelTopicModel`, `postRankDC`, `relevance`
                    
    * `corpus` : #deprecated (by default set to ${saffron.home}/models/wiki-terms.json.gz) 
    
    * `baseFeature` : If `method` is set to "single", give here the unique scoring function to use.
    If `method` is set to "voting", choose the scoring function that will get more weight in the calculation of the final score. (Choose between the options given above in `features`)
    
    * `numThreads` : #deprecated (by default to 0)  
    
    * `posModel` : The path to the part-of-speech tagger's model. Only models from [OpenNLP](http://opennlp.sourceforge.net/models-1.5/) are currenlty supported. Default to "${saffron.home}/models/en-pos-maxent.bin")
    
    * `tokenizerModel` : The path to the tokenizer's model. Only models from [OpenNLP](http://opennlp.sourceforge.net/models-1.5/) are currenlty supported. Default to "null" (the configuration will automatically use the [OpenNLP SimpleTokenizer](https://www.tutorialspoint.com/opennlp/opennlp_tokenization.htm))
    
    * `lemmatizerModel` : The path to the lemmatizer's model. Only models from [OpenNLP](http://opennlp.sourceforge.net/models-1.5/) are currenlty supported.  Default to"${saffron.home}/models/en-lemmatizer.dict.txt"
    
    * `stopWords` : The path to the list of stop words (one per line) if different from the [default ones](https://gitlab.insight-centre.org/saffron/saffron/blob/saffron_development/taxonomy/src/main/resources/stopwords/README)
    
    * `preceedingTokens` : The set of tags allowed in non-final position in a noun phrase. Default to [ "NN", "JJ", "NNP", "NNS" ]
    
    * `middleTokens` : The set of tags allowed in non-final position, but not completing. Default to [ "IN" ]
    
    * `headTokens` : The set of final tags allows in a noun phrase. Default to [ "NN", "CD", "NNS" ]
    
    * `headTokenFinal` : The position of the head of a noun phrase (true=final). Default to "true"
    
    * `blacklist` : A list of terms that should never be generated. Default is an empty list
    
    * `blacklistFile` : The path to a file containing a list of terms that should never be generated (one term per line). Default to null
    
    * `oneTopicPerDoc` : If set, always output at least one topic for each input document (overrides maxTerms if necessary). Default to false.


##### 2.   Author - Term linking
The phase of linking between authors and terms (if authors are present in the metadata, ignored otherwise)

* `authorTerm`: An element which contains the following property to set up:
    * `topN` : The maximum number of total author-term pairs to extract. Default to 1000

##### 3.   Author Similarity
The phase of connecting authors with similar areas of expertise together (if authors are present in the metadata, ignored otherwise)

* `authorSim`:  An element which contains the following properties to set up:

    * `threshold` : The minimum threshold of similarity to accept. Default to 0.1
    * `topN` : The maximum number of similar authors (per author) to extract. Default to 50


##### 4.   Term Similarity
The phase of connecting similar terms

* `termSim`:  An element which contains the following properties to set up:
    * `threshold` : The minimum threshold for accepting similarity between two terms. Default to 0.1
    * `topN` : The maximum number of terms to accept. Default to 50


##### 5.   Taxonomy Extraction
The phase of supervised taxonomy extraction

* `taxonomy`:  An element which contains the following properties to set up:  
    * `negSampling` : The number of negative samples to generate when training. Default to 5.0  **not available in the interface?**  
    * `features` : The features to use. Default to null.    **not available in the interface?**  
        Choose between :  
        * inclusion : uses the inclusion feature
        * overlap : uses the overlap feature
        * lcs : uses the longest common subsequence feature
        * svdSimAve : uses the SVD Average Vector Similarity feature
        * svdSimMinMax : uses the SVD Minimum-Maximum Vector Similarity feature
        * topicDiff : uses the Topic Difference feature
        * relFreq : uses the relative frequency feature
        * wnDirect : uses direct wordnet
        * wnIndirect : uses indirect wordnet
    * `modelFile` : The model to be trained. Default to "${saffron.home}/models/default.json"
    * `maxChildren` : A limit on the number of children to be added under one node (does not work in MST mode). Default to 2147483647   **not available in the interface?**
    * `simThreshold` : Minimum threshold to accept for similarity. Default to 0.0   **not available in the interface?**

    ###### 5.1.   Taxonomy Search
    The phase of search in the taxonomy algorithm
    * `search`:  An element which contains the following properties to set up:
        * `algorithm` : The algorithm to use for finding a taxonomy. Choose between `greedy`, `beam`, `mst`. Default to greedy
        * `beamSize` :  The size of the beam to use in the beam search (only if Beam search is chosen, ignored otherwise) . Default to 20
        * `score` : The scoring function to optimize. Choose between `simple`, `transitive`, `bhattacharryaPoisson`. Default to simple
        * `baseScore` : The base metric for Bhattacharrya-Poisson (BP) (only if BP search is chosen, ignored otherwise). Default to simple
        * `aveChildren` : The average number of children (only if BP search is chosen, ignored otherwise). Default to 3.0
        * `alpha` : The weighting to give to BP (against the base algorithm) (only if BP search is chosen, ignored otherwise). Default to 0.01



## Ouput formats


### Terms ([terms.json](https://gitlab.insight-centre.org/saffron/saffron/blob/saffron_development/examples/terms.json))

Each element in this file represents a single term extracted from the corpus. The file contains the following annotations

* `term_string`: The string that names the term (must be unique)
* `occurrences`: The total number of occurrences of a term in the corpus
* `matches`: The number of documents in the corpus containing this term
* `score`: The importance of the term to this corpus (between 0 and 1)
* `status`: Whether the term was validated or not (see the [Review mode](https://gitlab.insight-centre.org/saffron/saffron/wikis/Review-mode) documentation). Default to **none**
* `mv_list`: A list of alternative (morphological variants) forms of this 
term string
   * `string`: The form of this variant



### Doc-Terms ([doc-terms.json](https://gitlab.insight-centre.org/saffron/saffron/blob/saffron_development/examples/doc-terms.json))

* `document_id`: A unique string to identify the document, made up of the document filename (preceded by _zip_filename if the dataset is submitted as a .zip file)  
* `term_string`: The string that names the term (must be unique)
* `occurrences`: The number of occurrences of the term in the single document


### Term-Sim ([term-sim.json](https://gitlab.insight-centre.org/saffron/saffron/blob/saffron_development/examples/term-sim.json))

This file gathers and compares all pair of terms extracted in the previous stage. Each element describes one edge, ie. a relation between two terms, and their similarity score (see the [pairwise scoring](https://gitlab.insight-centre.org/saffron/saffron/wikis/saffron-approach#211-pairwise-scoring) step for more explanation on how this is calculated).

* `term1_id`: The first term's term string
* `term2_id`: The second term's term string
* `similarity`: The similarity of the two terms 
* `status`: Whether the relation was validated or not during the Review mode (see the [Review mode](https://gitlab.insight-centre.org/saffron/saffron/wikis/Review-mode) documentation). Default to **none**

## Taxonomy ([taxonomy.json](https://gitlab.insight-centre.org/saffron/saffron/blob/saffron_development/examples/taxonomy.json))

This file represents the whole taxonomy. Each element describes a term and how it is related to other terms in the taxonomy. 
The file contains the following:

* `root`: The term string of this term or `HEAD_TERM` for the root of the taxonomy
* `score`: The weighting given to the root term
* `linkScore`: The likelihood of the link from this term to its root being correct
* `children`: A list of children of this node (these are also Taxonomy objects)
* `status`:
* `parent`:



If authors are present in the original corpus as metadat:
### Author-Terms

An edge linking an author to a term

* `author_id`: The ID of the author
* `term_id`: The term string of the term
* `matches`: The number of times this term is used in documents by this author
* `occurrences`: The number of occurrences of the term by this author
* `paper_count`: The number of documents from the author containing this term
* `tfirf`: The Term Frequency-Inverse Research Frequency (See "Domain adaptive 
extraction of topical hierarchies for Expertise Mining" (Georgeta Bordea (2013)) 
for evaluations of different methods)
* `score`: The score of the this linking
* `researcher_score`: The score for author's ranking for this particular term

### Author-Sim
-------------

An edge in the author-author graph

* `author1_id`: The ID of the first author
* `author2_id`: The ID of the second author
* `similarity`: The similarity score between these authors








