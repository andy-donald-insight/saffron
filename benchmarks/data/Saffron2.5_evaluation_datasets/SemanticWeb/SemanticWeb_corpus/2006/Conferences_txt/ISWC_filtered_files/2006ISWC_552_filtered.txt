Modeling Social Attitudes on the Web

Matthias Nickles

AI/Cognition Group, Department of Computer Science,

Technical University of Munich

D-85748 Garching b. M unchen, Germany

nickles@cs.tum.edu

Abstract. This paper argues that in order to allow for the representa-
tion, comparison and assessment of possibly controversial or uncertain
information on the web, the semantic web effort requires capabilities for
the social reasoning about web ontologies and other information acquired
from multiple heterogeneous sources. As an approach to this, we propose
formal means for the representation of possibly controversial opinions of
groups and individuals, and of several other social attitudes regarding
information on the web. Doing so, we integrate concepts from distributed artificial intelligence with approaches to web semantics, aiming for
a social semantics of web content.

Keywords: Semantic Web, Description Logic, Information Integration,
Agent Communication, Modal Logic.

1 Introduction

Social aspects of the web have attracted increased attention in the field of semantic web research recently. This development is certainly driven in part by
the tremendously growing interest in web-based collaboration by means of social software (e.g., for blogging, collaborative tagging, wiki creation etc.). But
the increasing interest in sociality also seems to be stemming from the general
insight, that the semantic web can never become some kind of huge distributed
knowledge base in the traditional sense. Instead, it will in our opinion become a
more and more realistic emergent image of the current non-semantic web, i.e.,
an open environment with heterogenous groups of information sources and users,
both with different and often conflicting viewpoints and interests, and with a
high amount of personal interaction. This development will likely accelerate with
new interaction-oriented developments like semantic blogging.

Approaches like emergent semantics [1], dynamic ontologies [14] and advances
in the field of information integration in general and ontology mapping and
merging specifically (e.g., [13,2]) already provide strong responses to some of the
challenges posed by open information environments. But nevertheless, to their
major part, current approaches to web semantics are concerned with the modeling of homogenous information, or the assessment and filtering of heterogenous
information in terms of trustability and suitability. What is still widely missing

I. Cruz et al. (Eds.): ISWC 2006, LNCS 4273, pp. 529543, 2006.
c Springer-Verlag Berlin Heidelberg 2006

M. Nickles

are formal means for the modeling of (knowledge-related) sociality on the web
itself, especially the simultaneous and comparative representation of heterogeneous and possibly inconsistent viewpoints of multiple information sources. Such
means would not only allow for a rich modeling of social (i.e., communication)
structures of web information (providing meta-information useful for, e.g., a
subsequent resolution of conflicts and credibility issues). They would also allow
for the social reasoning about the social meaning of information contributions
on a logical level (as opposed to semi-formal approaches like social networks
or provenance information). In this regard, the annotation of web information
with meta-information denoting their provenance already received significant
attention, but provenance modeling is to its main part strongly tailored to the
problem of trustability, and it usually provides only meta-data (i.e., identifiers
of the information sources), not an integrated logical model suitable for social
reasoning.

As a response to the described issues, the main contribution of this paper is
a general approach to a social semantics for the web by introducing a formal
framework for a social multi-modal description logic, as informally outlined in
the next section, and formally presented in Section 3 (including the semantics
and decidability results). 3.4 introduces a social semantics of web publishing acts
building on the formal framework, and Section 4 demonstrates our approach by
means of a case study. Section 5 concludes.

2 A Communication-Oriented Model of Web Semantics

The basic concept underlying our approach is that of the integration of (first-
level) information with (second-level) information about the social meaning
of the former. This can in principle be done by the assignment of appropriate
second-level meta-data to first-level information artifacts, using various techniques (e.g., higher-order logic, modal logic, or even RDFs reification). Hence-
forth, this way of reifying information is called social reification (or social higherorder modeling, if a higher-order logic shall be used). In demarcation from more
informal ways of annotating information with meta-data (and the problematic
and semantically extremely weak reification facility of RDF), we focus in this
work on the formal integration of first-level and second-level information items
which correspond (as a compound pair) to formulas and expressions of logic
languages, e.g., axioms and facts represented in description logic (DL). E.g., a
simple form of such a socially reified statement could look like Frank informs:
Sheep are pink (or Frank informs us that sheep are pink), in contrast to
the un-reified and hopefully highly controversial first-level statement Sheep are
pink.

Supposedly, it is easier for agents (including humans) to agree on a statement
which quotes the opinion of someone else, compared to the less likely agreement
with that opinion content itself (agree to disagree probably, so to say). Thus
we believe that the (selective) social reification of web statements would achieve
a great deal of increased semantic consistency of the web. In addition, social
?

?

?
reification provides in many cases a rather safe way of semantic linkage among
different information sources or documents (like different ontologies), and is thus
expected to provide a means for information integration in case there exists not
enough meta-knowledge (like trust) in order to decide about the alignment and
merging of the information into a consistent set of un-reified axioms and facts.
Although, e.g., OWL already allows for the inclusion of foreign ontologies and
class descriptions, this works on a syntactical, constraint-less level, possibly leading to inconsistencies. Information integration using social reification in contrast
allows to integrate foreign information in a relatively safe manner even if some
reified first-level information is mutually inconsistent, and later integration steps
can use the meta-information about the social meaning of the reified information
for tasks like conflict resolution or credibility assignment.

Most important, social reification enables social reasoning about web information within a logic-based knowledge representation framework itself, not needing
the help of external, non-logical approaches (although we expect that a combination of such approaches - especially that of social networks - with social
reification could be very fruitful).

So, the question is how such meta-knowledge about the social meaning of web
information should look like in detail. In this work, we claim that - independently
of technical information authorship or message-passing means - authoring information on the web is implicitly and unavoidably a communication performed
by an autonomous, self-interested source, namely an assertive or informational
speech act performed in order to express a subjective opinion (probably about
some formerly published opinion). Thereby, it is not even necessary to make
either the authorship or the propositional attitude towards the act content ex-
plicit. But we find a formal account to such second-order information highly
useful, namely to have a means for its representation using semantic web lan-
guages.

To this end, the direct inclusion of speech act locutions as with agent communication languages would not be adequate for languages like OWL or RDF
since speech acts are on a different conceptual level. Therefore, we propose a
logical means for the modeling of asserted information. Intuitively, we want to
express that, after uttering, the knowledge source (human, agent, web service...)
is committed to his assertion. To represent such states, we have chosen the approach introduced in [7,4] and the more or less equivalent approach presented in
[6,5] as a starting point for the semantics of web communication. Our approach
demarcates itself strongly both from the well-known BDI agent model and from
multiagent belief modeling (including dynamic epistemic models such as public
announcement logic, which is not concerned with opinions in our sense but with
the effects of announcements on beliefs [3]). At this, we distinguish sincere individual and group beliefs (which might be not visible on the web) from publicly
visible alleged beliefs and subjective claims (the latter also to be distinguished
from objective knowledge), and from public intentions.

Observe in this respect that it would not be sufficient to extend web knowledge
representation languages with modal operators for belief or epistemic knowledge

M. Nickles

modalities. The former denotes a mentalistic concept, which cannot be extended
to information publishing since information sources in open environments like
the web are autonomous actors with opaque beliefs and intentions. A certain
publisher might assert some statement a to audience A, assert at the same time
a to another audience B, while believing neither a nor a. In contrast, the
modality of knowing would provide epistemic introspection, but would not be
particularly useful in regard to the mentioned issues stemming from opinion
controversies and the absence of an authoritative truth in the web.

In order to model public1 attitudes of web actors towards information (and
thus assign second-order information about social meaning), we introduce the
modalities public assertion and belief and public intention as communicationlevel pendants to the mental attitudes belief and intention, and thus lift mental
attitudes to the social stage.

Examples demonstrating the high expressivity of a DL language with social

attitudes are:
 {s1,s4,s5},{a1,a7}loves. = 

(The group of web actors {s1, s4, s5} (e.g., bloggers) publicly express facing {a1, a7}
the opinion that everybody loves somebody)
 {a1,a5}AssertsFrankall(loves. = )
(Group {a1, a5} publicly believes that Frank asserts that everybody loves someone)
 P IntFrank{a1,a5}(loves. = )
(Frank publicly intends towards group {a1, a5} that everybody shall love someone)
 P IntFrank{a1}(Assertsexpr

a1all(loves. = ))

(Frank publicly intends that a1 publicly announces that everybody shall love someone (while probably privately intending the opposite))

 {Sarah}Customer = {F rank}Customer  has.M oney

(Sarahs customers are Franks customers, but only those with money. Modalities
for social attitudes are thus also attachable to concept names (and role names),
not only to axioms.)

Social attitudes will be given an intuitive but precise formal semantics which resembles the modalities of an actors belief and intention in many ways [9]. They
are nevertheless cleanly separated from mental attitudes (as in the BDI agent
model and related multiagent belief frameworks), and can thus be used together
with these without any interference. An agent might, e.g., reason simultaneously
about the real beliefs of another agent and about the information this other
agent gave to the public communicatively, which is not possible using BDI. Note
in this respect that our approach is to its main part settled on a different conceptual level than related fields like multi-agent belief revision and information
integration: Whereas these are mainly concerned with the determination of cor-
rect, consistent and useful information, the primary purpose of social attitudes
is to represent communicatory properties of and differences among semantically
heterogeneous attitudes, possibly preceding their assessment in terms of trustability and reliability.
1 We use the term public not necessarily in the sense of everyone attending, but to
refer to communicatively disclosed information within specific closed or open groups
(including the web public), as well as single persons (in form of singleton groups).
?

?

?
What mainly distinguishes an agents social attitude of public belief from her
mental attitude of belief is that the former is an ostensible belief expressed communicatively (maybe restricted to a specific audience), and triggered and revised
by social conditions (in our context namely web publishing and reception). Different groups and even subgroups of some groups can hold different public beliefs
without causing logical inconsistencies. Public assertions in addition aim at ostensibly convincing their addressees. While public assertions and beliefs might
as well reflect the true beliefs of benevolent, trustworthy information sources,
this should be considered a special case for autonomous, self-interested sources
in open environments. Also, uttering a public assertion doesnt necessarily mean
that the agent truthfully intends to make someone adopt this public assertion
as a mentalistic belief (that would be unrealistic), but as a public belief. Essentially this denotes that the release of information on the web is understood to an
important part as a request which asks the readers of the information to show
a positive attitude regarding the released information (i.e., implicit or explicit
approval).

The general provision of meaning for data found on the web in terms of
social attitudes as described in the next sections is henceforth called social web
semantics (or just social semantics).

In a nutshell, we see the main benefits of modeling social attitudes in the

provision of means for:

 Representation of and reasoning about public opinions (with sub-types such
as agreement and disagreement), as opposed to mental beliefs, and also as
opposed to (objective) knowledge. We claim that virtually any kind of
information published on the (semantic) web initially falls in the category
of opinion, since such information is initially (from an observers point of
view without any meta-knowledge such as about reliability) neither known
as sincere subjective belief of the publisher nor knowledge. But quite sur-
prisingly, to our knowledge no explicit, sufficiently powerful formal means
for the modeling of opinions existed so far (i.e., with a required expressivity
higher than BDI or other Kripke-style multi-belief frameworks).

 Representation of and reasoning about public intentions (like the intentions
behind web publishing acts, e.g., the intention to make others agree with the
respective claims)

 Modeling of different audiences. E.g., someone (using different nicknames)
might utter inconsistent information depending on the addressees of these
opinions. Such issues will likely become increasingly important with the rise
of social software and the use of semantic web technology for the representation of discourses like in web blogs or web-based negotiation platforms.

All social attitudes introduced in this paper can be restricted to specific

audiences (part-publics, so to say).

 A social semantics of web publishing acts (and some other internet-relevant

communication acts such as request) in terms of social attitudes.

M. Nickles

2.1 Related Works

Apart from the related research field of ontology integration, the storage of heterogeneous information from multiple sources also has some tradition in the fields
of data warehousing and view-generation for distributed and enterprise database
systems [15,2], whereby such approaches do not take a social or communicationoriented perspective. Contexts are also used for the integration of heterogeneous
information [12], but contexts in this sense originate from McCarthys truth con-
texts, as opposed to the essentially pragmatic social contexts implicitly used for
social reification. The assignment of provenance information is mostly based on
annotation, or makes use of the reification facility found in RDF, which also lacks
a social semantics of course. Approaches to provenance are already very useful
if it is required to specify who contributed some information artifact (which is
also done with a similar intent on the basis of social networks [11]), but they do
not provide a logic model of the meaning of being an opinion source. Precisely,
they allow to specify that someone asserts some information, but they do not
handle what asserting (requesting, denying...) actually means, in contrast to the
semantics introduced in this paper.

3 A Description Logic with Social Modalities

This section presents a description logic enhanced with modalities for the previously introduced social attitudes public assertion, public belief and public inten-
tion. The latter modality is mainly introduced for the purpose of providing a web
publishing semantics later in this work; since we omit the specification of crossmodality axioms in this paper, it could be safely removed from the language in
case one only wants to model public assertions and beliefs.
Our language is based on the standard DL ALC (Attributive concept description Language with Complements) [8], with modal extensions in the style
of [9,10]. A further extension with additional features found in SHOIN (D) (the
description logic equivalent to OWL-DL) is omitted here as being not relevant
in the context of this work, but should be completely straightforward, since they
do not affect the model-based semantics of our modalities (see below).

3.1 The Language S  ALC
Definition 1. The language S  ALC (Social ALC ) is defined as follows. The
syntax allows both to specify terminological knowledge about concepts and roles
(TBox), and assertional knowledge2 about their instances (ABox). Modalities can be attached not only to formulas, but also to roles and concepts.
Atomic concepts: C = {C0, C1, ...}
Atomic Roles: R = {R0, R1, ...}
Individuals: I = {o0, o1, ...}
2 The double meaning of assertion in this paper is unfortunate, but we wanted to

stick with the usual DL terminology.
?

?

?
Inductively, we define (compound) concepts and roles now. Let R be a role and
C and D concepts. Then iR, iR and atomic roles are roles, and
, C  D, D, R.C, iC, iC and atomic concepts are concepts (i  N).
Observe that in our framework  is not he dual of .
Formulas (in other DLs often called axioms) are either the atomic formulas
, C = D, aRb, a : C (with a, b  I), or compound formulas i, i, ,
  , with  and  being formulas.

For convenience, we also define    = (  ).
Let authors = {s1, ..., sn} be a finite set of information sources (web ac-
tors, publishers, web sites, peers...), and addressees = {a1, ..., am} the set
of recipients (possibly overlapping or identical with authors). Let actors =
authors  addressees be the set of all participants.
Then we define the following social attitudes, where  : 2authors2addressees 
N maps elements of the cartesian product of the powerset of authors and the
powerset of addressees unequivocally to a multi-modality index number (e.g.,
({s5, s7},{a1, a6})  570160), s  authors, S  authors, and A  addressees.
Possibly empty or singleton subsets of authors  addressees are called groups.
Opinion / Public weak assertion:
S,A = ((S,A)) (analogously for S,AC and S,AR).

This attitude denotes that group S holds towards group A the opinion that
 is true. Opinions need not to be honest (thus they are also called ostensible
beliefs [7]), and a certain author or a group can hold mutually inconsistent
opinions (precisely: inconsistent propositional contents of the resp. opinions)
facing different addressees.

In case S and A are identical in the definition of opinion, we use the following

abbreviation:
Ostensible group belief :
I  = I,I,
with I  actors, |I| > 1, denoting that in a group I  is the ostensibly accepted
group belief (while it is possible that a member or a subgroup of I ostensibly or
sincerely believes  - an example for such a subgroup would be some politically
dissident group which can articulate its true beliefs only in the underground).
This important special case is close to the notion of grounding [5,6].
(Analogously for I C and I R)
Public intention: P Ints,A() = (({s},A))
This modality denotes that s publicly (i.e., facing A) intends that  becomes
true. A public intention is also ostensible only, and might have nothing in common with any true (i.e., mental) intention of s. Again, public means group A
plus s.
Public assertion:
Assertss,A() = {s},A  P Ints,A(A,{s})
(analogously for classes and roles instead of .)
Thus, informally, a public assertion modality states that an actor ostensibly believes some content, and ostensibly intends other actors to adopt his viewpoint
in this regard (not necessarily explicitly)).

M. Nickles

The difference of assertion (Asserts) and weak assertion / opinion is simply that the latter attitude does by itself not include convincing the addressee
from its propositional content but the information source just expresses herself.
For a simplified notation for the expression of disagreement with some given
information cf. 3.4.

Upon these definitions, various constraints extending the well-known KD45
axioms scheme could be imposed optionally, which is omitted here for lack of
space (but see [4,7] for an - non-terminological - approach to this issue).
Private belief : Bels() = {s},{s}
(analogously for classes and roles instead of .)
Private intention: Ints() = P Ints,{s}().
Maybe surprisingly at a first glance, the ordinary mental (i.e., private) belief
Bels of a single actor can be modeled as a special case of the former public
belief, namely the ostensible belief of a singleton group. Informally, one can
imagine that actor s always expresses her honest private belief if she is within a
group consisting of herself only (talking to herself, so to say). Although we dont
encourage the use of this operator without being prefixed with another modality (denoting, e.g., that it is publicly believed that someone privately believes
something), it allows S  ALC to model multi-agent beliefs also.

Note that while the Asserts operator distinguishes information source and
addressee, this differentiation is not required for the semantics of the public belief
operator I. The latter just expresses that a certain proposition (concept, role) is
ostensibly (but not necessarily sincerely or correctly) believed by a certain group
of agents (not to be confused with the traditional concepts of multiagent group
belief and common belief, which have a different meaning - recall that ostensible
group belief does not entail that any of the group members or subgroups believes
the respective statement). E.g., Assertss3,{a1,a5}() denotes that  is asserted by
source s3, addressing recipients a1 and a5, which is equivalent to saying that i)
{s3},{a1,a5} (i.e., s3 ostensibly believes ) and ii) P Ints3,{a1,a5}({a1,a5},s3 ).
We will later describe in detail the semantics of making public assertions (i.e.,
announcing ostensible beliefs) in a speech act -sense.

3.2 Model-Based Semantics
The following provides a model-based semantics for S  ALC, with an integration of multi-modalities i and i using a multiple-world approach (a.k.a.
Kripke-style semantics) enhancing [9]. For details on modal description logics in
general please refer to [9,10].
Definition 2. A model (of S  ALC) is a pair M = (F, I) with F = (W, P I ,
 W W are a so-
P B). W is a non-empty set of worlds, i
called binary accessibility relations for public intentions and beliefs respectively,
with each element linking one world to another, i  N. Each i
P B shall be serial,
transitive and euclidian, i
P B shall exist

P I shall be serial. Moreover, for each i

 W W and i

P I

P B
?

?

?
i

i

i

, ..., CI,w

, RI,w = RI,w

j

i

 D  D, CI,w

, ..., oI,w
 D, and oI,w

one irreflexive predecessor element (thus this relation shall reflect the axioms of
a KD45 modal logic - cf. [4] for details on these axioms).
I is an interpreting function which associates with each world in W an ALC
, ...). At this, D is the domain of the
 D (i.e., the ois are objects within

model I(w) = (D, RI,w
model, RI,w
the domain).
Definition 3. The values of concepts and roles, and truth-relation (M, w) |= 
for formulas are defined as follows:
1. I,w = D, CI,w = CI,w
2. x(iR)I,wy iff v i
3. x(iR)I,wy iff v i
4. (C  D)I,w = CI,w  DI,w
5. (C)I,w = D  CI,w
P I w : x  CI,v
6. x  (iC)I,w iff v i
P B w : x  CI,v
7. x  (iC)I,w iff v i
8. x  (R.C)I,w iff y  CI,w : xRI,wy
9. (M, w) |= C = D iff CI,w = DI,w
10. (M, w) |= a : C iff aI,w  CI,w
11. (M, w) |= aRb iff aI,wRI,wbI,w
12. (M, w) |= i iff v i
13. (M, w) |= i iff v i
14. (M, w) |=    iff (M, w) |=  and (M, w) |= 
15. (M, w) |=  iff (M, w)  

P I w : (M, v) |= 
P B w : (M, v) |= 

P I w : xRI,vy
P B w : xRI,vy

for C = Ci, R = Rj

3.3 Decidability

A formula  is satisfiable w.r.t. the semantic above if there exists a pair (M, w)
such that (M, w) |= .
Theorem 1. The satisfaction problem for S  ALC formulas is decidable.
As shown in [9], the satisfaction problem (i.e, whether there exists a model and a
world such that (M, w) |= ) is decidable for ALCM , which apart from the multimodalities has an identical semantics. ALCM uses arbitrary models, as well as
such models which have two constrained accessibility relations corresponding to
the modal logics S5 and KD45, the latter commonly used to model agent belief
(as well as multi-agent belief when using multi-modalities i (KD45n). Since
our accessibility relations i
P I/P B observe S5n respectively KD45n, and we are
effectively mapping agent and group beliefs to single pseudo-agent beliefs (of
pseudo-agents representing groups and ostensible attitudes) using , S  ALC is
decidable as well.
Related to this, it can be also easily seen that in the case we would allow only
singletons for indexing the multi-modalities i, we would gain multi-agent belief
modalities (in the sense of [10]). If we would additionally do the same with i,
?

?

?
and also remove all constraints on the accessibility relation , S  ALC would
deflate to a syntactic variant of ALCM. The former is expressed with

Theorem 2. Public singleton group belief corresponds to private individual belief.
Thus, mental propositional attitudes can be written as a special case of social
attitudes.

3.4 Social Semantics of Web Publishing

The data found on web pages or any other content on the web is in general, if
taken as is, neither knowledge nor private belief. Instead, web content needs
to be interpreted as the content of communication acts. By means of such an
interpretation (which essentially unfolds the semantics in the semantic web), the
recipient can then classify the web artifact as knowledge (e.g., via trust), and,
usually in a previous step, as opinions and other social attitudes. The step from
the respective speech act of publishing (asserting, requesting, denying...) web
content to its meaning in terms of social attitudes is specified in the following.
Note that although we use an action notation, it would of course not be necessary
to rewrite web pages as speech acts, since the speech act meaning of publishing
web content is implicit. A web page claiming that sheep are pink is essentially
nothing else than the description of an assertive speech act.

But technically, the following acts could also be used more or less directly
within a document as social semantics links to external content (similar to the
import-directive of OWL).

The following provides both a semantics for typical publishing acts in terms
of their pre- and post-conditions, and at the same time an alternative (but
under-specified) operational semantics for social attitudes in terms of those acts
which are allowed to take place when certain attitudes hold. We achieve both
by using the formal style (but not the content) of mentalistic semantics of agent
communication languages, i.e., by specifying for each act its so-called feasibility
precondition (FP) and its rational effect (RE) [6]. The former denotes what
needs to hold (in terms of social attitudes in this work), the latter denotes both
guaranteed illocutionary and perlocutionary effect(s) of the respective act.
Publishing acts are denoted as
identifier1 : author.Performative(audience, |C|R|identifier2 ), with author 
authors, audience  addressees, and identifier  N.
If audience is omitted, the respective act is either not addressed at someone,
or at an unspecified group of potential recipients (as it is usually in case when
the locution is asynchronously given in form of a web site, which addresses
potentially the whole internet).

identifier optionally assigns the act an unequivocal number (or a time stamp
or an URI), or refers to another act. The helper function content maps an
identifier to the propositional or terminological content of the respective act.

The content of an act (class, role or axiom) is denoted as .
?

?

?
Note that in regard to the semantics of speech acts it is not of importance
whether the acts are technically performed asynchronously with its potential
reception (like it is the usual case on the web), or synchronously, e.g., as steps
in an interactive argumentation process.

 id : s.assert(A, ) (author s asserts  towards the recipients A )

FP: Assertss,A() and Assertss,A() and A{s}A
RE: Assertss,A()
The feasibility preconditions (FP) here express that in order to perform
an assert act, neither the information source nor the audience have already
publicly announced their alleged belief in  already (otherwise the act would
not make sense). Assertss,A() ensures that the information source does
not contradict herself communicating with A (but she might expose a public
assertion inconsistent with  towards a different audience).

The postcondition expresses that it became public that s asserts  (which
includes the public intention of s to convince A that ). In the case that
no trustability or other expectations are existing in regard to  and/or its
provenance a1, the postcondition makes the assert-act essentially a request
do adopt a public assertion, with a more or less uncertain effect on the
addressee.

 id : s.inform(A, ) (author s informs the recipients A that )

FP: {s},A() and {s},A()
RE: {s},A()
The inform act is thus a weaker form of the assert act in that the author
does not necessarily aim to convince the receivers.

Note that we can not simply define similar publishing acts for the utterance
of group belief corresponding to group (except in the case that the group is
in fact a single actor on the web, like an organization - but this is already
covered with assert and inform). Uttering such a group belief would require some
judgement aggregation procedure (like voting), and can for principle reasons not
be successful in all cases.

In order to provide convenient means for the agreement or disagreement with
certain information, the following macro acts are proposed. We suppose they
are particularly useful if the implemented language provides some sort of linkage
facility, such as OWLs owl:imports and class or property descriptions in form
of URI references. Interpreting the interlinked items (documents, class descrip-
tions, meta-data etc.) as assertions, the graph formed from such items related
by URL/URL references effectively maps to a communication process.
 id0 : s.agree(a, id1)  s.assert({a}, content(id1))
 id0 : s.deny(a, id1)  s.assert({a},content(id1))
We also propose the following intend and request acts, which (e.g.) allow to
announce that a certain proposition is intended to be true, or to ask someone
to publish a certain information. Note that our notion of intending includes as a
special case desiring that another actor makes something true (like on request):
?

?

?
M. Nickles

that )
FP: P Ints,A()
RE: P Ints,A()

 id : s.request(a, )  s.intend({a}, P Inta,{s}())
 id : s.requestEach(A, )  a  A : s.intend({a}, P Inta,{s}()) The latter
two acts express requests directed to another agent (or a group thereof) to
make some desired state come true. The act types agree and deny can be
used to utter positive or negative replies to such requests, by asserting to
intend resp. not to intend the requested act/state.

These makro acts are not unproblematic, since they request a potentially
insincere intention (P Inta,{s}). Instead, we could write P Inta,{a} to demand
a sincere intention, but this would also be problematic.

4 Case Study

In order to demonstrate the properties and one possible application of our ap-
proach, this section presents a brief case study in form of a shortened purchase
negotiation scenario (adapted from a scenario presented in [6]), which should be
quite typical for the semantic modeling of, e.g., seller/buyer platforms on the
web.

The interaction roughly follows protocols for purchase negotiation dialogue
games, but we omit some details which are not relevant for our purposes (e.g.,
specification of selling options). Although the example deals with negotiation, the
approach is expected to be usable for the modeling of other types of interaction
on the (semantic) web also (such as argumentation).
Our scenario consists of four participants {s1, s2, c1, c2}, representing potential
car sellers and customers (implemented, e.g., in form of two seller web services
and two agents of the customers). In the discourse universe exists two instances
1 and 2 of some car type  (e.g., specimen of the Alfa Romeo 159).
The interaction course is presented as a sequence of steps in the following form.
Note that the interaction course consists of multiple interlaced conversations
among different sender/receiver pairs. In particular, c2 is involved in two selling
dialogues at the same time. The different dialogues shall be visible only for the
participants (senders and receivers of the respective communication acts).
Utterance id. senderreceiver(-s): Descriptive act title
Message
Effect (optionally) gives the effect of the act in terms of social attitudes.

In contrast to Effect, Private information (PI) optionally unveils relevant
mental attitudes before or after an act has been uttered and understood by the
respective agents. The PIs are not determined by preceding communication acts,
due to agent autonomy. They are also of course usually not available to observers
on the web, and thus just given here for the readers information.
?

?

?
P Is1: Bel s1 discounts
U1 s1  {c1, c2}: Information about discount

s1.assert({c1, c2},discounts)
Effect: {s1},{c1,c2}discounts
P Ints1,{c1,c2}{c1,c2},{s1}discount
Seller s1 asserts that no discounts can be given while believing that the opposite is
true (there might be the company policy that discounts should be given, but that
might reduce the sellers individual profit).

Note that such a contradiction between private and public (communicated)
beliefs or intentions could not be modeled using BDI or known semantic web
languages, although being, as already pointed out, crucial for the semantic web as
a public opinions platform.

U2 s1  {c2}: Information about discount

Intentions can also not be modeled with any current web semantics framework
known to us, including the highly relevant ostensible public intentions (P Int...).
s1.assert({c2}, discounts)
Effect: {s1},{c2}discounts P Ints1,c2{c2},{s1}discount
While seller s1 informed group {c1, c2} that there would be no price discounts,
he informs customer c2 that this is not true (likely because s1 thinks that c2 is a
valued customer whereas c1 is not).

U3 c2  {s1}: Query if car type has high accident rate

Such different, inconsistent assertions addressed to different (even nested) groups
of addressees can not be modeled using any current web semantics language (and
also not by means of the BDI framework).
c2.request({s1}, InformIfAccidentRateHigh)
Effect: P Intc2,s1 Done(s1 : InformIfAccidentRateHigh)  ... , with
InformIfAccidentRateHigh def=
s1.inform({c2}, accidentRateHigh())  s1.inform({c2},accidentRateHigh())

P Is1 : Bel s1 accidentRateHigh()
U4 s1  {c2}: Information about accident rate

s1.assert({c2},accidentRateHigh())
Effect: {s1},{c2}accidentRateHigh()
Seller s1 asserted accidentRateHigh() while thinking the opposite. Privately,
c2 believes this information (see P Ic2 below) and publicly agrees in the next step,
but will revise her private (but not her public) belief this later.
c2.inform({s1},accidentRateHigh())
Effect: {c2},{s1}accidentRateHigh()
Since c2 has himself asked s1 to provide him the information uttered in the previous
step, he publicly believes it.

U5 c1  {s2}: Expression of belief

P Ic2 : Bel c2 accidentRateHigh()
U6 c2  {s2}: Query if car type has high accident rate

U7 s2  {c2}: Information about accident rate

c2.request({s2}, InformIfAccidentRateHigh)
To make sure, the potential buyer c2 asks s2 the same question.
s2.assert({c2}, accidentRateHigh())
Effect: c2 publicly believes the information facing s2, and even trusts it for some
reason privately more than the information given by seller s1 earlier. Nevertheless,
it remains true that he also still publicly believes the opposite towards the other
seller (i.e., that {c2},{s1}accidentRateHigh()).

M. Nickles

P Ic2 : Bel c2 accidentRateHigh()
U8 c2  {s2}: Propose to buy at a low price
c2.intend({s2}, buy(2, 4000))
U9 s2  {c2}: Accept proposal
s2.intend({c2}, sell(2, 4000))
Effect (together with the previous act):
P Intc2,s2buy(2, 4000)  P Ints2,c2sell(2, 4000) (i.e., c2 and s2 are publicly
committed to buy resp. sell 2 at the price of 4000 now).

5 Conclusion

This paper argued that in order to allow for the logical representation of possibly
controversial or uncertain web information on the web, current formal representation frameworks for web knowledge need to be enhanced for the modeling of
the social meaning of information. To this end, we proposed a socially-enhanced
description logic for the foundational modeling of socially acquired knowledge on
the web, and a social semantics of web publishing acts in terms of the dynamics
of social (i.e., communication) attitudes. Next steps will concentrate on a practical evaluation, the enhancement of other relevant languages such as SHOIN (D)
with operators for social attitudes, and a full axiomatization of the modal logic.

Acknowledgements. This work is funded by Deutsche Forschungsgemeinschaft (DFG) (research project Open Ontologies and Open Knowledge Bases,
contract BR609/13-1). I would also like to thank the anonymous reviewers for
their very valuable comments.
