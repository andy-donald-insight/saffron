Innovation Detection Based on User-Interest

Ontology of Blog Community

Makoto Nakatsuji, Yu Miyoshi, and Yoshihiro Otsuka

NTT Network Service Systems Laboratories, NTT Corporation,
9-11 Midori-Cho 3-Chome, Musashino-Shi, Tokyo 180-8585, Japan

{nakatsuji.makoto, miyoshi.yu, otsuka.yoshihiro}@lab.ntt.co.jp

Abstract. Recently, the use of blogs has been a remarkable means to
publish user interests. In order to find suitable information resources
from a large amount of blog entries which are published every day, we
need an information filtering technique to automatically transcribe user
interests to a user profile in detail. In this paper, we first classify user blog
entries into service domain ontologies and extract interest ontologies that
express a users interests semantically as a hierarchy of classes according
to interest weight by a top-down approach. Next, with a bottom-up ap-
proach, users modify their interest ontologies to update their interests in
more detail. Furthermore, we propose a similarity measurement between
ontologies considering the interest weight assigned to each class and in-
stance. Then, we detect innovative blog entries that include concepts
that the user has not thought about in the past based on the analysis of
approximated ontologies of a users interests. We present experimental
results that demonstrate the performance of our proposed methods using
a large-scale blog entries and music domain ontologies.

1 Introduction

Blogs are becoming more popular for publishing and discussing interests among
users who share interests between each other. In blog search, users can automatically pull blog entries from RDF Site Summary (RSS)1 feed by entering
keywords about their interests beforehand. Information-sharing systems of this
type have the potential to enable users to expand their interests by browsing
collected blog entries published by other users in blog communities.

However, information retrieval in current blog services relies only on keyword
searches of blogs using Google or based on simple metadata such as that of an
RSS. Moreover, there is no function to generate personalized searches easily, so
users need to consider and enter search keywords that suit their own interests
appropriately. Such a keyword search is time consuming and troublesome. More-
over, users cannot perform a keyword search if they do not understand what they
want to search for to some degree beforehand. Thus, when keywords cannot be
specified, information retrieval from blog entries often cannot be performed even
if users might become interested in a topic.
1 http://blogs.law.harvard.edu/tech/rss

I. Cruz et al. (Eds.): ISWC 2006, LNCS 4273, pp. 515528, 2006.
c Springer-Verlag Berlin Heidelberg 2006

M. Nakatsuji, Y. Miyoshi, and Y. Otsuka

To counteract the above problems, in the research on Adaptive Information
Filtering (AIF) [2], the user profile is constructed cooperatively with a user, and
recommendations based on the profile are offered. Making a user profile interactively beforehand is good for offering recommendations to users, as indicated by
the high-accuracy performance of AIF. A common complaint about AIF is the
users task of making his/her own profiles, and a user often encounters known
information many times because he/she cannot distinguish documents including
new information in the recommendation results.

For filtering these redundant documents, researchers on novelty detection [7]
define novelty as a document that includes new information that is relevant to
a user profile. They extract relevant documents from a document stream. Then,
they classify the documents as novel or not, and provide novelty documents
to users. However, detecting novelty provides documents with information that
includes concepts only in a user profile.

In this paper, we define innovation as new concepts which seem to be interesting to the user even though they are not included in a user profile. Then, we
try to expand user interests significantly by recommending innovative informa-
tion. Especially, we adopt innovation detection to blogs because they become a
popular architecture of publishing and searching information that expands user
interests.

For achieving above-mentioned purpose, we first construct user profile automatically as a user-interest ontology, which is a class hierarchy of user interests
with interest weights. Then, we propose measuring the similarity of interest ontologies considering the degree of interest agreement to each class and instance.
We apply our techniques to help users create a blog community by browsing
innovative blog entries which include information unknown to users with a high
probability of being interesting.

The specific contributions of this paper are the following.

 First, in order to analyze user interests in detail, we propose an automatic
extraction of an interest ontology with an interest weight assigned to each
class and instance. Bloggers are apt to describe their interests about topics
in several service domains freely. Thus, we use blog entries for specifying user
interests by introducing a template ontology, which is a domain ontology of
each service. We classify user entries according to a template ontology, and
remove classification mistakes by using class characteristics and continuity of
descriptions about user interests. This mechanism of improving entry classification is one of the reasons for applying the ontology technique to our
research.

 We propose measuring the similarity between interest ontologies that have
interest weight. By introducing interest ontologies, we can help users create
interest-based communities considering the width and depth of concepts of
users interests. Furthermore, we can calculate the similarity between ontologies more accurately than in previous ontology mapping techniques from
the viewpoint of the agreement of the weights of user interests. Then, we
can detect innovative blog entries for each user u by analyzing the classes
?

?

?
C of other users ontologies that have a high similarity to the ontology of
the user u though the interest ontology of user u lacks those classes C. This
new approach of recommending innovative information is another reason for
applying the ontology technique to our research.

 We describe a comprehensive set of experiments. Our experimental results
are based on a large number of blog entries (1,600,000 entries of 55,000
users) and a music template ontology (114 classes and 4,300 instances). We
confirm that our automatic ontology extraction and innovation detection
have potential for creating a user-oriented blog community according to user
interests. We also investigate the appropriate granularity of a community by
analyzing the similarity of users interests among the community extracted
by our similarity measurements.

The paper is organized as follows. Section 2 introduces related works. Section
3 describes our automatic user-interest ontology-extraction, and Section 4 describes innovative blog-entry detection by our similarity measurement. Section
5 describes our experimental study, and Section 6 concludes this paper.

2 Related Works

Many online content providers such as Amazon2, offer recommendations based
on collaborative filtering (CF) [5] which is a broad term for the process of recommending items to users based on the intuition that users within a particular
group tend to behave similarly under similar circumstances. One advantage of
previous CF techniques is that they can recommend relevant items that are different from those in a users profile. However, they cannot detect innovative blog
entries because only the similarity between user profiles based on instances such
as selling items is measured. Therefore, CF often offers items that have the same
concept to users. We want blog users to expand their interests by detecting innovative blog entries whose information is not included in the concepts (classes)
of their interest ontology.

For applying a semantic approach to retrieving information from a blog, semblog [6] tries to construct a user profile using a personal ontology which is a
manual construction of a users classification of blog entries in a category directory of the ontology according to their interests. A category directory is built
by users beforehand to construct an ontology-mapping-based search framework.
However, manual ontology creation is a time-consuming and troublesome task
for users, and applying a semantic ontology to a blog community is difficult.
We automatically extract a user-interest ontology; thus, creating and updating
ontologies is easy for users.

In researches of ontology mapping [1,3], similarity measurements considering
approximation of classes and class topologies are proposed in [3]. In addition
to class topology, we consider each users weighted interest in each class and
instance. Furthermore, in analyzing conjunctions in class topologies of ontologies
2 http://www.amazon.com

M. Nakatsuji, Y. Miyoshi, and Y. Otsuka

Select

Metadata

Title
Artist
Label
Genre
Album

(1) Designer chooses music domain for creating blog community.
(2) Choosing metadata for extracting user interests.

(3)For example, 
classifying artists by genre.

Artist

(3) Classifying artists into classes as instances.

Artist

Property: rock/pop, adult 
contemporary, light rock
Domain: music

Light 
Rock

Rock/Pop

Adult Contemporary

Property: rock/pop
Domain: music

Class

Property: rock/pop, 
adult contemporary
Domain: music

Instance

Adult Alternative

Artist

Property: rock/pop, adult 
contemporary, adult alternative
Domain: music

Fig. 1. Procedure for designing template ontology

with high similarity scores, we detect innovative instances that a user does not
have in his/her ontology, though other users have them with a high probability.

3 Interest Ontology Extraction

We first explain the template ontology design of each service domain such as
those of content delivery services of music and movies and then describe an
automatic method of extracting interest ontologies.

3.1 Design for Template Ontology

We use OWL (Web Ontology Language) [4] for describing a template ontology.
We can express a domain ontology in detail using OWL. However, the generation and spread of a detailed ontology is obstructed because users have difficulty
of designing it. Therefore, we design template ontologies as lightweight ontologies that only use a hierarchical relationship among the classes and a property
description restricts the succession condition of a class hierarchy. Then, we automatically extract an interest ontology by classifying user blog entries into
template ontologies without user intervention in Section 3.2.

As shown in Fig. 1, first, the ontology designer chooses a service domain for
extracting user interests. Then, the designer chooses metadata that reflects user
interests. In a music domain, the designer chooses metadata of genres or artists,
considering the exsisting community is generated with such metadata. Finally,
the designer chooses metadata as a restriction property of a class hierarchy
and classifies other metadata as instances of classes. For example, the designer
chooses genres as a property and classifies artists as instances of classes. In this
way, we distinguish classes from instances and define the characteristics of classes
based on the restriction properties of a class hierarchy and classified instances.
We make use of these class characteristics to improve the accuracy of interest
ontology generation in Section 3.2.

The service designers only has to construct a template ontology with the
intended domains and gradually increase the number of ontologies along with
expanding the service. Designers also should adjust granularity of the end classes
?

?

?
Entries of 
user A

All blog entries
Entries of 
user B

Entries of 
user X

(1) Creating index 
for all entries.

(2) Classifying entries 
into template ontology.

(3) Analyzing user's interest distribution 
based on user ID of classified blog entry. 

Stone Temple Pilots

Farm 

Happy Mondays 
New Order 

Alternative

Nirvana

Madchester 

Stone Roses 

Verve 

Coldplay

Number of users.

Shoegaze 

My Bloody Valentine 

Stone Temple Pilots

Alternative

Nirvana

Class

Instance

Farm  Happy Mondays 
New Order 

Madchester 

Stone Roses 

Verve 

Coldplay

Shoegaze 

My Bloody Valentine 

Stone Temple Pilots

Interest ontology 

of user A

Alternative

Farm 

Madchester 

New Order 

(4) Extracting interest 
ontology by arranging 
entries based on user ID.

New Order 

Stone Roses 

Madchester 

Interest ontology 

of user X

Nirvana

Alternative

(5) User modifies 
interest ontology.

delete

Shoegaze 
My Bloody 
Valentine 

Ride

add

Fig. 2. Procedure for generating interest ontologies

for reflecting user interests in detail. Fortunately, content directories such as goo
music3 set granularity in detail for users to browse contents according to their
interests. Therefore, we first construct template ontologies according to these
directories and evaluate the granularity through the analysis in Section 5.

3.2 Interest Ontology Generation Algorithm

We explain our interest ontology generation algorithm by analyzing the interest
distribution of users, as shown in Fig. 2.

Basic ontology generation algorithm. First, we describe the basic ontology
generation algorithm (BOGA) as follows.

(1) First, we make index files for all blog entries collected through the ping

server. Here, we assume that collected blog entries have a unique user ID.

(2) Second, we classify all collected blog entries into a template ontology. We
classify blog entry Ei into class Ci if there is a name attribute value of Ci in Ei.
We also classify blog entry Ei into instance Ii( Ci) if there is a name attribute
value of Ii in Ei. We permit the blog entries to be classified into two or more
classes. For example, consider the template ontology in Fig. 2. We classify the
blog entry into instance Happy Mondays of class Madchester when there is
a Happy Mondays character string in the description in the blog entry.

(3) Then, we measure the number of interested users in each instance of Ce,
which is one of the end classes in the template ontology. On calculating the
number of interested users, we count the number of users as one, even if the
same user is describing the same instance or class in two or more blog entries.
We calculate the number of interested users in class Ce by obtaining the number
of interested users in all instances in Ce and in class Ce. Thus, the interested
user distribution in the domain can be measured by recurrently counting the
number of users from Ce to the root class Cr.
3 http://music.goo.ne.jp/

M. Nakatsuji, Y. Miyoshi, and Y. Otsuka

(4) Next, by extracting only the classification results about a user ID from all
classification results, we can extract an interest ontology for this user ID. In Fig.
2, we can extract an interest ontology of user A when the blog entries of this
user describe instances of Stone Temple Pilots, New Order, and Farm.

(5) Finally, the user inspects and updates the interest ontology according to
their interests. Furthermore, we can develop a template ontology that is more
suitable by merging this modified information into a template ontology.

Ontology filtering algorithms. For example, BOGA classifies blog entries that
describe Farm, which means an agricultural farm, into the instance Farm
of class Madchester. For filtering these mistakes caused by words with several
meanings, we make use of the following characteristics such as class relationships
in ontologies and durability of user interests in a blog.

 Instances that belong to the same class have the same characteristics.
 Adjacent classes have similar characteristics. Instances of those classes also

 User interests that continue for a certain period and describe an interest for

have similar characteristics.

two or more days.

We propose two filtering algorithms FA1 and FA2. First, we explain FA1.

Filtering algorithm 1. We subdivide procedure (2) of BOGA for performing FA1.
(2-1) When the name attribute value n(Ii) of instance Ii( Ci) is described
in blog entry Ei, FA1 checks whether a name attribute value of an instance of
the same class (concept) Ik{(Ik  Ci)  (Ik = Ii)} or Ci is described in all
blog entries that the user accumulates. We call instances Ik and Ci classification
decision elements(CDEs).

(2-2) Entry Ei is classified as mentioning instance Ii when there is a description of CDEs, and not classified in Ii when there is no description. In Fig. 3,
when the description of Farm exists in Ei, and New Order is described
among all accumulation blog entries of a user, Ei is assumed to be a blog entry
about instance Farm of Madchester and classified.

Filtering algorithm 2. We propose filtering algorithm 2 (FA2) whose classification is stronger than FA1. In procedure (2-1) of FA1, FA2 checks whether CDEs
are described in blog entry Ei. Then, blog entry Ei is classified in Ii when there
is a description of CDEs, and not classified in Ii when there is no description.

Adjusting the range of CDEs0. We give a mechanism that adjusts the range
of CDEs by using the class hierarchy. We consider that descriptions of classes
and instances of interest often appear with instances of the neighboring classes.
We add a new adjustment parameter, hop, which defines the range of CDEs. In
Fig. 3-(a), we assume brother classes, the grandfather class, and instances that
belong to each of CDEs when there are two hops from end classes.
?

?

?
Total entries of user A

Hop 0

User A, Entry 1

Hop 1

Charlatans 

Farm 

Hop 2

nirvana

Alternative

Madchester 

Stone Roses 

New 
Order 

Rock

US Indie

Coldplay

Verve 

Shoegaze 

Ride

My Bloody Valentine 

Athens
R.E.M.

Olivia Tremor 

Elf Power

Control

Elephant 6

I like Stone Roses and 
My Bloody Valentine
recently. I love R.E.M.
in Athensmuch more.

User A, Entry 2

I think Ride and My 
Bloody Valentine are the 
best Shoegazegroups. 

User A, Entry 3

I was listening to R.E.M.
and Elf Power all day 
long today. 

The character string of italics 
indicates the class. 

Stone Roses  1/4

1/4

Madchester 

7/12

My Bloody Valentine 

3/2

Alternative

7/2

Rock

Indie

Shoegaze 
Ride 1/3

5/4

Athens

3/4

R.E.M.

1/2

Elf Power

Elephant 6

1/2

Interest weight 
for class

Interest weight 
for instance

(a) Hop counts in filtering algorithms.

(b) Applying weight to interest ontology.

Fig. 3. (a) hops in filtering algorithms, and (b) applying interest weight to ontology

3.3 Introducing Interest Weight to Ontology

In addition, we introduce the interest weight as a parameter that shows the
degree of a users interest in each class and instance of an interest ontology. By
using this parameter, we can create a community among users who have almost
the same degree of interest in the same classes or instances.

Here, we define interest weight, as shown in Fig. 3-(b). First, the interest
weight of every blog entry is one. Second, if there are N(Ei) kinds of name
attribute values of interest classes and instances that appear in blog entry Ei,
the interest weight of each class and instance in Ei becomes 1/N(Ei). Third,
when we define the set of all accumulation blog entries of a user as E, the interest
weight S(Ii) of each instance Ii is S(Ii) =
(IiEi)(1/N(Ei)), and the interest
weight S(Ci) of each class Ci is S(Ci) =
(CiEi)(1/N(Ei)) +
S(Ii).
Fourth, the interest weight of the instances is reflected in that of the class that
includes the instance. The interest weight of the classes is reflected in that of the
super class. For example, in Fig. 3-(b), we give the interest weight of instance
Elf Power as 1/2, instance R.E.M. as 1/4 + 1/2 = 3/4, class Elephant 6
as 1/2, and class Athens as 1/2 + 3/4 + 1/2 + 1/4 = 2.

|E|
|E|
?

?

?
IiCi

4 Detecting Innovative Blog Entries Using Similarity

Measurements

We propose measuring the similarity between ontologies considering interest
weight. Then, we describe innovative blog-entry detection and community creation support based on the analysis of interest ontologies with high similarity.

4.1 Interest-Weight-Based Similarity Measurement

We now explain our similarity measurement in detail by using Fig. 4.

We first define terminologies. We give interest ontology OA of user A and
OB of user B, topology T1, which is defined as the relation between a class and

M. Nakatsuji, Y. Miyoshi, and Y. Otsuka

Interest ontology of user A: OA

a1

b2

n

km

b1

c3
b

c4
g

h

a

c

Interest ontology of user B: OB

a1

b1

b2

n

b3

d

c3
a e

c

c4
p

j

c1
l

Class

Instance

Interest weight of 
instance.

Interest weight 
of class.

Topology

1T

Topology

2T

Fig. 4. Measuring similarity based on the degree of interest agreement

subclasses, and topology T2, which is defined as the relation between a class and
instances. Furthermore, we define common classes of both ontologies as Ci, and
common instances as Ii. In particular, we define common class set, C(T1), as that
which characterizes topology T1, and common class set, C(T2), as that which
characterizes topology T2. For example, in Fig. 4, C(T1) has common classes a1
and b2, and C(T2) has common classes b2, b3, and c4. We also give the degree
of interest agreement of common instance Ii as I(Ii), that of common class Ci
as I(Ci), and that of common topology created by common class Ci as It(Ci).
In [3], the authors calculate the similarity between ontologies considering the
degree of similarity between class topologies T1. In addition, we take the following
ideas from the view point of creating a user-interest-based community.

 Evaluating the degree of interest agreement between Cis and Iis as a smaller
value of interest weight. This idea is for filtering users who only enumerate
a lot of instances in an entry, and creating a community among users who
have similar or larger interest weight values from the viewpoint of each user.
 Separately treating topologies T1 and T2 because we consider that T1 reflects
the width and depth of a users interests and T2 reflects the objects in which
users are interested.

 Achieving a low computational complexity by generating the class schema of
user-interest ontologies accroding to that of template ontologies. This is important for ontology mapping to adopt large-scale dataset of blog community
such as that of our experiments in Section 5.

(1) We analyze classes common to OA and OB and extract common classes

which belong to C(T1) and C(T2).

(2) When common class Ci has common instance Ii between ontologies, we
assign the smaller value of the interest weight of common instances Ii to I(Ii).
For example, I(a) is 2.

(3) Similarly, we assign the smaller value of the interest weight of common

class Ci to I(Ci). For example, I(b1) is 3.
?

?

?
Fig. 5. Community creation service of recommending innovative blog entries

|U(Ci)|
?

?

?
CjN (Ci) I(Cj)

(4) We define product sets of subclasses of Ci, which are common to a class
set, as N(Ci), and the set union of subclasses of Ci among Ci  C(T1) as U(Ci).
For example, N(a1) = {b1, b2} and U(a1) = {b1, b2, b3}. Then, we give It(Ci)
as
. For example, It(a1) is given by (3 + 18 + 0)/3 = 7. Thus, we
obtain degree of interest agreement S(T1) of C(T1) as
CiC(T1) It(Ci). In Fig.
4, S(T1) = (3 + 18 + 0)/3 + (9 + 3)/2.
(5) We also define an instance set of Ci in ontology OA as IA(Ci), and an
instance set of Ci in ontology OB as IB(Ci) among Ci  C(T2). Then, we

give It(Ci) as
|IA(Ci)IB(Ci)| . For example, It(c3) is given by ((2 + 0 + 3 +
0)/4) = 5/4. Thus, we assign the degree of interest agreement S(T2) of C(T2) as

CiC(T2) It(Ci). In Fig. 4, S(T2) = 2/1 + 5/4 + 0.
(6) By using evaluation function f(X) corresponding to the relative degree of
importance of a topology, we finally assign the similarity score between ontologies
SO(AB) as S(T1) + f(S(T2)).

IiCi

I(Ii)

4.2 Innovative Blog-Entry Detection

We adopt our similarity measurement to innovative blog-entry detection.

(1) We calculate the similarity between the ontology of user A and ontologies
of other users in set U. By using the heuristic threshold X, we derive X users
who have a high similarity to user A as an interest-sharing community GU .

(2) Then, we analyze difference instances between the ontology of user A and
ontologies of GU . We also define a parameter, degree of innovation, which indicates how many hops we need to get from difference instances of an ontology of
GU to the class of the ontology of user A. In Fig. 5, we need 3 hops to go from
difference instance Elf Power of ontology of user B to class Rock of ontology of user A. By recommending blog entries with a high degree of innovation,
users may significantly expand their interests. Otherwise, users may receive new
concept with a low degree of innovation comparatively more acceptable.

(3) Finally, we extract innovative instances GI, which user A does not have,
even though users in GU have with a high possibility, and recommend innovative
blog entries about GI for user A with innovation degree.

M. Nakatsuji, Y. Miyoshi, and Y. Otsuka

Fig. 5 depicts an example of our community creation. We can analyze whether
a user who is interested in instance Happy Mondays of class Madchester
and so on has a possibility to become interested in instance Elf Power of class
Elephant 6. By browsing blog entries concerning these innovative instances,
users expand their interests and share interests with each other.

5 Experimental Results

We now present experimental results that show the performance of interest ontology extraction and innovative blog-entry detection.

5.1 Datasets and Methodology
We evaluated the performance of our proposed methods based on the large-scale
blog portal Doblog4, which has 1,600,000 blog entries of 55,000 users. We also
used the template ontology of the music domain, as shown in Fig. 2, which was
created referring to public information about web portals such as goo music. Our
experimental template ontology contains 114 classes as genres and 4,300 artists
as instances, and each class and instance have two or more name attribute values.
For example, the instance R.E.M. has the name attribute values of R.E.M.
and REM. Thus, we gave 7,600 name attribute values to 4,300 instances.

For evaluating accuracy, we defined correct answers as blog entries that have
descriptions of classified classes or instances and evaluated the generated interest
ontology by using precision and recall in classified results. In this paper, precision
means the proportion of correct answers in classified results and recall means
that of correct answers in all blog entries. When the recall is high, extracted interest ontologies cover user interests better. However, when the precision is lower,
created interest ontologies include classified mistakes, and innovation detection
for the user becomes unreliable. Thus, achieving high precision is indispensable.
In evaluation, we adopted filtering algorithms to instances with one word such
as police, because we considered one word has a high possibility of having
several meanings. For generating index files of blog entries, we used Namazu5.

5.2 Measuring Interest Distributions of Blog Users
Graphs of user distributions in the music domain of our experiment are depicted
in Fig. 6-(a). There are about 200 users, even in end classes. By checking the blog
entries classified in end classes, we confirmed that these blog entries frequently
have unique words, which describe the features of these classes. For example,
blog entries classified into the end class Death Metal have the phrase death
voice with a high probability. This is because the end classes in our template
ontology have an appropriate granularity to extract the feature of the blog entries
classified into these classes. The granularity of end classes is important because
it affects whether we can determine if a user is interested in the community.
4 http://www.doblog.com
5 http://www.namazu.org/
?

?

?
Number of users

Number of users in each class hierarchy

2nd hierarchy

3rd hierarchy

4th hierarchy

Rock / Pop

Alternative/Punk

Soul

R&B

Jazz

Blues

Classical

(Genre)

(a) Interest distributions of blog users in experimental template ontology.

Precision

100%

90%

80%

70%

60%

50%

40%

30%

20%

10%

FA2

FA1

0%
Funk
Rock

Glam
Rock

Metal
Rock

Folk
Rock

Hard
Rock

Adult
Contemporary

Art & Progressive

Genre/Artists

(b) Comparing  the precision of instances with one word among BOGA, FA1 and FA2.

Fig. 6. Experimental results of user distributions and ontology extraction

5.3 Measuring Performance of Extracted Interest Ontology

We evaluated the accuracy of FA2 by checking 1/4 of classified blog entries,
which were randomly selected. As shown in Table. 1-(a), the achieved precision
is higher than 90% with a high recall of 80%. Thus, our filtering algorithm is
effective for generating suitable user-interest ontologies.

5.4 Comparing Filtering Algorithms

Then, we compared BOGA and filtering algorithms by randomly checking 1/4
of the blog entries, which were classified into instances with one word.

Graphs of the precision of BOGA, FA1, and FA2 over 83 instances, which were
randomly selected among 827 instances with one word, are shown in Fig. 6-(b).
The accuracy between BOGA and filtering algorithms is compared in Table. 1-
(b). These results indicate that precision improves in the order of BOGA, FA1,
and FA2, and recall decreases significantly in FA2, even though FA1 drops only
slightly from BA. For improving recall with high precision in FA2, we will add
a method that checks for CDEs in the blog entries with a high probability of
appearing these elements such as entries near each other in a time series.

Analyzing Fig. 6-(b) in more detail, there are eight instances in which the
precision cannot be improved even with FA2, and they lower the overall precision.
Then, we extracted instances in which the number of classifications increases by
ten times or more when changing from FA2 to FA1. As a result, we extracted
28 instances and the precisions of 5 of those instances were 0. The reason is
that they do not co-occur in the same blog entry with CDEs, even though the
user was interested in them and described the name attribute value of these

M. Nakatsuji, Y. Miyoshi, and Y. Otsuka

Table 1. Experimental results of our ontology extraction and innovation detection

(a) Accuracy of extracted interest ontology (FA2, hop 2).

(b) Comparing accuracy of instances with one word.

Precision

94.9%

Recall
80.3%

Precision

FA2
70.0%
32.6%

FA1
57.9%
93.0%

18.9%
100.0%

(c) Comparing accuracy by changing hop counts.

Precision

Hop 0
89.1%

Hop 2
91.0%

Hop 4
85.6%

Recall
(d) Recall of innovation detection.

Recall

X=30
64.8%

X=60
76.7%

X=90
80.1%

(e) Comparing degree of innovation in recommendation lists.

(f) Comparing degree of innovation in our detections.

Degree of
innovation
Proportion 57.6% 15.2% 23.2% 4.0%

Degree of
innovation
Proportion 23.4% 23.1% 44.3% 9.2%

instances often. Thus, to improve the precision, deleting these instances from
template ontology is effective.

We also evaluated the accuracy of FA2 based on the change in the hop num-
ber. Hop 2 is better than hop 0 with respect to the number of correct answers
and precision, as shown in Table. 1-(c). However, hop 4 is lower than hop 2
in precision, although the number of correct answers is slightly better. That is
because our template ontology has a large number of instances in end classes,
and the relationship between end classes and super classes is closer than the relationship between super classes and grandfather classes. For example, end class
Acid Metal has the super class Metal and grandfather class Rock. In this
case, the relationship between Acid Metal and Metal is closer than the relationship between Metal and Rock. Thus, hop 2 has a better precision than
hop 0 because hop 2 has many CDEs, and hop 4 has a lower precision than hop
2 because we consider CDEs in hop 4 as instances that are far from end classes.

5.5 Measuring Performance of Innovation Detection

We evaluated innovative blog-entry detection. In the evaluation, we defined correct answers for each instance by referring to recommendation lists such as you
might like these artists in a music portal like goo music. Designers of music portals in this evaluation manually defined artists (An) that are relevant to another
artist (Ai) for recommending relevant artists (An) to users who are interested in
artist (Ai). Then, we evaluated our technique by checking the recall of 1/20 of
1503 users who were judged to be interested in the music domain of our template
ontology. In this evaluation, recall means the proportion of correct answers in
our recommended instances.

We evaluated recall in the change of X described in Section 4.2. Table. 1-(d)
indicates that recall of our recommendation was about 80%. In particular, recall
improves significantly when X = 30  60, even though X = 90 improves slightly
from X = 60. This result indicates that we can extract innovative instances by
only checking 60 high-rank interest ontologies among interest ontologies of 1503
users from the viewpoint of the user who receives the recommendation. Table. 1-
(e) and (f) compare the proportion of degree of innovation in extracted instances
?

?

?
.

p
u
o
r
g

 

h
c
a
e

 
f

o

 
s
t
s
i
t
r
a

 

n

i
 

d
e

t
s
e
r
e

t

n

i

 
 
 
 
 

e
r
a

 

o
h
w
 
s
r
e
s
u

 
f

o

 
r
e
b
m
u

.

p
u
o
r
g

 

h
c
a
e

 
f

o

 
s
t
s
i
t
r
a

 

n

i
 

d
e

t
s
e
r
e

t

n

i

 
 
 
 
 

e
r
a

 

o
h
w
 
s
r
e
s
u

 
f

o

 
r
e
b
m
u

famous group
ordinary group
not-famous group

famous group
ordinary group
not-famous group

X: Number of users in community Gu.
(a) Number of users by changing X.

X: Number of users in community Gu.

(b) Number of users with high interest weight by changing X.

Fig 7. (a) number of users obtained by changing X. (b) number of users obtained that
have high interest weight by changing X.

between recommendation lists in a music portal and our detected instances.
These results indicate that our technique detects instances with high degree of
innovation more in number than recommendation lists.

5.6 Analyzing the Suitable Granularity of User-Oriented

Community

We also investigated suitable number of users for creating a community. First, we
selected a user among all users extracted by our template ontology and analyzed
suitable granularities of GU by changing parameter X described in Section 4.2.
In this evaluation, we divided innovative instances GI into 3 instance groups in
order of the appearance rate of instances when we set X to 70: a famous group,
an ordinary group, and a not-famous group. We calculated the number of users
who are interested in the artists of each group by changing X from 10 to 70.

Graphs of the number of users who are interested in each group obtained by
changing X are shown in Fig. 7-(a). Next, we focused on users who have a high
interest weight in their interest ontologies. Graphs of the number of such users
obtained by changing X are shown in Fig. 7-(b). A famous group is recommended
to users in spite of changes in X in Fig. 7-(a). On the other hand, in Fig. 7-(b),
a not-famous group is recommended most when X is 10, and a normal group
comes to be recommended gradually as X grows. This is because users with a
high interest weight have a tendency of discussing not-famous instances, in spite
of discussing famous instances. Furthermore, the number of users of each group
increases suddenly when X is greater than 60. This is because the gap between
a users ontology and ontologies of Gu is larger when X is greater than 60, and
instances with a low possibility of being interesting come to be recommended
more often. From the results of Section 5.5 and 5.6, our innovation detection is
effective according to detailed user interests when X is smaller than 60.

6 Conclusion

We proposed an interest ontology generation method and similarity measurement
considering interest weight. Then, we adapted our technique to detect innovative

M. Nakatsuji, Y. Miyoshi, and Y. Otsuka

blog entries in a blog community. We also performed large-scale experiments
and confirmed that our techniques achieved automatic ontology extraction and
detection of innovative blog entries with high accuracy.

We offer an experimental service DoblogMusic6 for Doblog users and confirm the effectiveness of our innovative blog-entry recommendation method for
creating a blog community by analyzing user access during a period of time.

Acknowledgments

In the verification of this research we used data from blog portal Doblog of
NTT DATA Corporation. I wish to express my gratitude to the Doblog team
and Hottolink Corporation, which pleasantly cooperated in offering the data and
discussing the blog community creation service.
