The Summary Abox: Cutting Ontologies

Down to Size

Achille Fokoue1, Aaron Kershenbaum1, Li Ma2,

Edith Schonberg1, and Kavitha Srinivas1

1 IBM Watson Research Center,P.O.Box 704, Yorktown Heights, NY 10598, USA

{achille, aaronk, ediths, ksrinivs}@us.ibm.com
2 IBM China Research Lab, Beijing 100094, China

malli@cn.ibm.com

Abstract. Reasoning on OWL ontologies is known to be intractable in
the worst-case, which is a serious problem because in practice, most OWL
ontologies have large Aboxes, i.e., numerous assertions about individuals and their relations. We propose a technique that uses a summary of
the ontology (summary Abox) to reduce reasoning to a small subset of the
original Abox, and prove that our techniques are sound and complete. We
demonstrate the scalability of this technique for consistency detection in
4 ontologies, the largest of which has 6.5 million role assertions.

1 Introduction

Description Logic (DL) provides the theoretical foundation for semantic web
ontologies (OWL). A DL ontology can be divided conceptually into three com-
ponents: the Tbox, the Rbox and the Abox. The Tbox contains assertions about
concepts such as subsumption (M an  P erson) and equivalence (M an 
M aleHuman). The Rbox contains assertions about roles and role hierarchies
(hasSon  hasChild). The Abox contains role assertions between individuals
(hasChild(John, M ary)) and membership assertions (John : M an).

All common reasoning tasks in expressive DL ontologies, such as query answering [1], reduce to consistency detection. As an example, a standard approach
to testing if John is a member of the concept Man requires testing if the addition of the assertion (John : M an) makes the Abox inconsistent. A challenge
is that consistency detection in expressive DL is well known to be intractable
in the worst-case [2]. Given that the size of an Abox may be in the order of
millions of assertions, this complexity poses a serious problem for the practical use of DL ontologies, which often reside in frequently updated transactional
databases. Although highly optimized DL tableau algorithms exist, they cannot be easily adapted to Aboxes in secondary storage, especially for frequently
changing Aboxes. One approach that has been applied to reasoning on Aboxes
in secondary storage is to convert DL to disjunctive datalog, and use deductive
databases to reason over the Abox [3].

We propose an alternative technique that operates on Aboxes stored in traditional relational databases. Our technique exploits a key observation about

I. Cruz et al. (Eds.): ISWC 2006, LNCS 4273, pp. 343356, 2006.
c Springer-Verlag Berlin Heidelberg 2006

A. Fokoue et al.

real world Aboxes, namely, similar individuals are related to other individuals
in similar ways (e.g. fathers and mothers are related to their children by the
hasChild role). Specifically, our technique builds a summary Abox A of the
original Abox A, by aggregating similar individuals and assertions. The advantages of our summary Abox A are: (a) A is dramatically smaller than A; (b)
Reasoning on A isolates a small relevant portion of A needed to obtain the correct answer; (c) A can be computed efficiently using straightforward relational
database queries; (d) A can be maintained as changes occur to A, and is thus
resilient to change; (e) A only needs to be computed once, and can be reused
for answering subsequent queries.
To isolate relevant portions of A for a specific reasoning task, we introduce
efficient filtering techniques that operate on A. In this paper, we demonstrate
the utility of such filtering techniques for the task of Abox consistency detec-
tion, although the approach can be generalized to query answering. Our filtering
techniques are based on the conservative assumption that any individual in the
Abox may be inferred to be a member of any concept in the closure of the Abox.
Informally, the closure is the set of concepts used in the Abox, and their sub-
expressions. (To generalize this to query answering, the closure would include
the negated concept in the query.) The effect of filtering is to produce multiple
partitions in the summary Abox. In practice, most partitions consist of a single
individual, which can be checked with a concept satisfiability test. For partitions
of A with multiple individuals, if the partition is consistent, then the image in
A that corresponds to the partition is also consistent. If a partition is inconsis-
tent, the inconsistency could arise from either the summarization technique, or
a real inconsistency in the original Abox. In this case, we perform a consistency
check on the image in A of the inconsistent partition in A.

Our techniques proved very effective on the 4 large Aboxes that we studied:
a vast majority of partitions (95%) had just one individual. Only one of the
4 ontologies we studied required us to check the image of the partition in the
original Abox. Even in this case, our consistency check was performed in 6.3 s
on 4045 individuals and 2942 role assertions instead of the 1,106,858 individuals
and 6,494,950 role assertions in the entire Abox.
Our key contributions in this paper are as follows: (a) We present a technique
to summarize an Abox in secondary storage into a dramatically smaller A. (b)
We describe the use of filtering techniques to construct a reduced version of A.
This filtering produces many partitions, which are then exploited in scaling the
consistency check. The filtering techniques we describe works for SHIN Aboxes
(SHIN is a DL language that is described in the Background). (c) We show
the application of these techniques to 4 ontologies, where we show dramatic
reductions in space and time requirements for consistency checking.

1.1 Background

The techniques we apply in this paper assume ontologies of SHIN expressiveness.
In this section, we briefly introduce the semantics of SHIN, which is equivalent to
OWL-DL (http://www.w3.org/2001/sw/WebOnt) minus nominals and datatype
?

?

?
reasoning, as shown in Table 1 (We assume the reader is familiar with Description
Logics). In the definition of the semantics of SHIN, I= (
I) refers to an
I is a non-empty set (the domain of the interpretation),
interpretation where 
I 
and .
I, and every individual
I, every atomic role R to a binary relation R

a to a

I, the interpretation function, maps every atomic concept C to a set C
I  

I. Trans(R) in the table refers to a transitive role R.

I, .

I  

X

Table 1. SHIN Description Logic

Definitions Semantics
C  D
C  D
C
R.C
R.C
 nR
 nR
R

C I  DI
C I  DI
I\C I
{x|y. < x, y > RI, y  C I}
{x|y. < x, y > RI  y  C I}
{x| |{< x, y > RI}|  n}
{x| |{< x, y > RI}|  n}
{< x, y > | < y, x > RI}

< x, y > RI < x, y > P I

Axioms Satisfiability conditions
Trans(R) (RI)+ = RI
R  P
C  D C I  DI
a : C
aI  C I
R(a, b) < aI, bI > RI
a  =b

aI = bI

(a) Constructors

(b) Axioms

An RBox R is a finite set of transitivity axioms of the form Trans(R) and
role inclusion axioms of the form R  P where R and P are roles.  denotes
the reflexive transitive closure of the  relation on roles. A Tbox T is a set
of concept inclusion axioms of the form C  D where C and D are concept
expressions. An Abox A is a set of axioms of the form a : C, R(a, b), and a  =b.
An interpretation I is a model of an Abox A w.r.t. a Tbox T and a Rbox
R iff it satisfies all the axioms in A, R, and T (see Table 1(b)). An Abox A is
said to be consistent w.r.t. a Tbox T and a Rbox R iff there is a model of A
w.r.t. T and R. If there is no ambiguity from the context, we simply say that
A is consistent. A standard technique for checking the consistency of a SHIN
Abox is to use a tableau algorithm [4], which executes a set of non-deterministic
expansion rules to satisfy constraints in A until either no rule is applicable or
an obvious inconsistency (clash) is detected.

2 Summary Abox

Intuitively, the Abox contains many redundant assertions from the point of view of
consistency checking that can be collapsed to create a reduced summary Abox. The
summary Abox captures this redundancy by collapsing across individuals that are
members of the same concept sets as shown in Figures 1 and 2 below. As shown in
Figure 2, a single node a represents a1 and a2 because they are both members of
A, and they are not explicitly asserted to be different from each other (similarly for
b and d). Any explicit assertions that two individuals are different from each other
(c1 and c2) are maintained in the summary Abox. Reasoning over such a summary
corresponds to reasoning over the original Abox, as shown formally below.

A. Fokoue et al.

Fig. 1. Original Abox

Fig. 2. Canonical Summary Abox

I

I = C

I

I

I

, .

Definition 1. A summary Abox is an Abox A that is generated from any SHIN
Abox A using a mapping function f that satisfies the following constraints:
(1) if a : C  A then f(a) : C  A
(2) if R(a, b)  A then R(f(a), f(b))  A
(3) if a  =b  A then f(a)  =f(b)  A
Theorem 2. If the summary Abox A obtained by applying the mapping function f to A is consistent w.r.t. a Tbox T and a Rbox R, then A is consistent
w.r.t. T and R.
However, the converse of Theorem 2 does not hold.
Proof. Let us assume that A is consistent w.r.t. T and R. Therefore there is a
model I = (
) of A w.r.t. T and R. A model of A can easily be built from
I
I by interpreting an individual a in A in the same way as f(a) is interpreted
by I. Formally, let I = (
I) be the interpretation of the A w.r.t. T and R

, .
; for a role R in R,
; for a concept C  T , C
I = 
I
defined as follows: 
. I is a model of A w.r.t. T and
I = R

R as a direct consequence of the fact that I is a model of A and A satisfies

the 3 conditions stated in definition 1 (See [5] for more details).
Let L be a mapping from each individual in A to a set of concepts, such that
a : C  A iff C  L(a). We call L(a) the concept set of a. In practice, we
use a canonical function f to create a summary Abox, which maps non-distinct
individuals that have identical concept sets to the same individual in A. More
precisely, the converse of constraints (1) and (3) hold for the canonical summary,
and:
(4) If R(a, b)  A then there are a and b in A such that a = f(a), b = f(b) and
(5) If for all x  A, a  =x / A, b  =x / A, and L(a) = L(b), then f(a) = f(b).
(6) f(a)  =f(b)  A implies a is the only individual in A mapped to f(a) (same for b).
If a summary Abox A is not consistent, either there is a real inconsistency in
A or the process of summarization caused an artificial inconsistency. In section
3.4, we explain how we apply filtering to partition the summary, to provide
a scalable consistency check of the original Abox even when the summary is

; for an individual a in A, a

R(a, b)  A.

I = f(a)
?

?

?
inconsistent. Note that the summary Abox can be computed efficiently from a
relational database. Furthermore, it only needs to be computed once, and can
be maintained incrementally with changes to the Abox.

3 Abox Filtering

We perform filtering on the canonical summary Abox described in Section 2, but
for the purpose of exposition, we describe filtering techniques on the original Abox
first. Our filtering technique assumes that the Tbox T is transformed, through
splitting and absorption [6], into two disjoint sets Tu and Tg such that Tu, the
unfoldable part of T , only contains axioms of the form A  D and A  D,
where A is an atomic concept. Tg contains general concept inclusions of the form
C  D that could not be absorbed in Tu (where C is a complex concept).
We assume that for an Abox A, an Rbox R, and a Tbox T = Tu  Tg, all
concepts appearing in T and A are in the negation normal form (NNF). For a
concept expression C in NNF, clos(C,T ,R) is the smallest set X containing C,
closed under concept sub-expression, such that, for an atomic concept A, (1) if
A  X and A  D  Tu, then D  X, (2) if A  X and A  D  Tu, then
D  X, and (3) if P.C  X and there is a role R with R 
P and Trans(R),
then R.C  X. Formally, we define the closure of A w.r.t. T and R, denoted
clos(N N F (C)  D,T ,R).
clos(A,T ,R), as
When there is no ambiguity, we use clos(A) instead of clos(A,T ,R).

a:CA clos(C,T ,R) 
?

?

?
CDTg

3.1 Motivation

To provide an intuition for our criteria for filtering role assertions, we first informally describe a subset of tableau expansion rules defined in [4]. We assume
that a and b are named individuals in A, x is an unnamed individual, C is a
concept in clos(A), and R is a role. Named individuals are in A before applying
any expansion rules, while unnamed individuals are introduced as a result of
expansion rules. An individual b is defined to be an R-neighbor of a iff there is
an assertion Q(a, b) or Q
-rule: a : (R.C)  A, b is an R-neighbor of a, and b : C / A  add b : C to A.
-rule: a : ( nR)  A and, for 1  i  m, m > n, bi is an R-neighbor of a, and for two of these

(b, a) in A where Q 

R.

 =bj is not in A 

bk and bj the assertion bk
(i) Merge (identify) bj with bk (the precise rules to determine which of bj or bk is selected
(ii) add the assertions in L(bj) to L(bk)
(iii) for every role assertion with bj, replace bj with bk. In effect, this step adds new role

is detailed in [4].)

assertions to the A.

-rule: a : (R.C)  A and for R-neighbors b of a, b : C / A  add R(a, x) and x : C to A.
-rule: a : ( nR)  A and a does not have n distinct R-neighbors  add R(a, xi) to A, 1  i  n
+-rule: a : R.C  A, P 
R is transitive, b is a P -neighbor of a, and b : (P.C) / A  add

where the xi are new distinct unnamed individuals.
b : (P.C) to A.

We make the key observation that role assertions of the form R(a, b) may
affect the outcome of an execution of the tableau algorithm only if one of the
following two conditions holds:

A. Fokoue et al.

1. They can be used to trigger the application of tableau rules that alter the
original Abox. As an example of such alteration, a role assertion can be
used to add new membership assertions about named individuals (e.g., a
new concept C can be propagated to bs concept set through a role assertion
R(a, b) by the application of the  rule on a if a : (R.C)  A, and b is an
R-neighbor of a).
2. They can be involved in clash detection due to a violation of a maximum
cardinality restriction. As an example, if a : ( nR) is in the Abox and b is
one of n + 1 mutually distinct R-neighbors of a, then R(a, b) is important
for clash detection.

These conditions can only be brought about by either the application of the ,
 or +-rules or the presence of a maximum cardinality constraint. In contrast,
the -rule and -rule do not use existing role assertions R(a, b); instead, they
result in the creation of new role assertions and new unnamed individuals for
satisfying the R.C and  nR constraints.

3.2 Criteria for Filtering Role Assertions

Our filtering criteria guarantee that the absence of a role assertion will not affect the outcome of any execution of the non-deterministic tableau algorithm.
Our goal is to define criteria which are efficient to evaluate using simple queries
against relational databases, while balancing the tradeoff between filtering precision and cost. For instance, by assuming any concept in the clos(A) can reach
the concept set of any individual in the Abox during any execution of the tableau
algorithm, we avoid tableau operations which are expensive in relational data-
bases. We will say that a role R is part of a universal restriction P.C iff R 
P .
(Similarly for maximum cardinality restriction).

To filter a role assertion R(a, b), it must satisfy either 1) or both 2) and 3):

1) Absence of universal and maximum cardinality restrictions: We make
 are not part of any
the simple observation that if a role R and its inverse R
universal or maximum cardinality restrictions, then R(a, b) can never be used to
alter the original Abox or detect a clash, so it can be ignored.
2) Absence of universal rules triggering: Even if R is part of a universal
restriction, it may never trigger the application of the universal rules ( +,). We
define the conditions under which we can guarantee that the universal rules will
) is part of a universal restriction
never be triggered as follows. If R (resp. R
P.C in clos(A), then R(a, b) is irrelevant with respect to P.C if b : C  A
(resp. a : C  A) and R (resp. R
To satisfy the filtering condition, R(a, b) must be irrelevant with respect to
all universal restrictions P.C in clos(A), where R or R
3) Absence of maximum cardinality restrictions triggering: For the -
rule to be triggered, there needs to be a violation of a maximum cardinality
constraint a : nP , where the individual a has more than n P -neighbors, which
then causes a merger between individuals. We introduce a technique to conservatively estimate an upper bound on P -neighbors, such that at any step of any

) has no transitive superroles.

 is part of P.C.
?

?

?
To satisfy the filtering condition, R(a, b) must be irrelevant with respect to
 is part of

possible execution of tableau algorithm, the number of P -neighbors of a is less
) is part of a maximum carthan or equal to this upper bound. If R (resp. R
dinality restriction  nP in clos(A), then R(a, b) is irrelevant with respect to
 nP if the upper bound on the number of P -neighbors of a (resp. b) is less
than or equal to n. Note that this also guarantees that no clash can occur from
the presence of the role assertion.
all maximum cardinality restrictions  nP in clos(A), where R or R
 nP .
Upper bound on the number of P -neighbors. Unfortunately, in expressive
logics such as SHIN, computing an upper bound does not simply involve counting
the number of explicit P -neighbors of a that are present in A. Figure 3 shows
examples of the three ways that an individual a can acquire a new P -neighbor
during the execution of the tableau algorithm:

3(A) Individual a acquires a new P -neighbor x, where x is an unnamed indi-

vidual, to satisfy P.C in as concept set.
3(B) Individual a is merged with a named individual d and acquires a new P -
neighbor in order to satisfy a maximum cardinality restriction c : nQ.
3(C) Individual a is merged with an unnamed individual x and acquires a
new P -neighbor c, where c is either a named or unnamed individual.
This occurs in this example because of two conditions: (i) there is a role
 because a common super role Q is part of
 that is attracted to P

a maximum cardinality restriction and (ii) a role generator of the form
T.B or  mT is in the concept set of c, where T 

.

Fig. 3. Acquisition of P -neighbors
?

?

?
Accounting for P -neighbors acquired through situations like 3(B) and 3(C) is
not obvious. Therefore we define sufficient conditions under which these situa-
s P -neighbors can be computed
tions cannot occur, so that an upper bound of a
safely and efficiently. If any of these conditions are violated, then a merger of
a may result in an increase of its number of P -neighbors, and hence we do not
filter R(a, b):
(C1) P is safe in A.
Intuitively, the notion of safety ensures that a merger of a named individual a with an unnamed individual x that would increase the number of P -
neighbors of a, as illustrated in 3(C), cannot occur. If P is safe, then either

A. Fokoue et al.

Q, T 

condition (i) or (ii) in 3(C) must be false. More generally, for a given role
P , we say that T belongs to the set attractant(P ) iff there is a role Q such
that P 
Q, and  nQ  clos(A). A role P is safe if one of the
}
two conditions hold: (a) attractant(P )  {P} and attractant(P
 there are no Q-generators (i.e.  mQ or
(b) For all subroles Q of P or P
Q.C) in clos(A).
(C2) For any role Q, if a is a Q-neighbor of some named individual c then
(C3) For any role S, if some named individual c is a S-neighbor of a and  nS

there is no concept of the form ( nQ) in clos(A).
is in clos(A), then S is safe in A.

)  {P



, where T

Conditions (C2) and (C3) ensure that a merger of a and a named individual
as illustrated in 3(B) is impossible. (C2) by itself is not sufficient because, even
 may have an attracif Q is not part of a maximum cardinality restriction, Q
B is in the concept set of a. As described in 3(C), these
tant T
conditions can cause a merger between c and an unnamed individual x, so that
a becomes a T -neighbor of c. If T is part of a maximum cardinality restriction,
a itself may become mergable. Condition (C3) prevents mergers between c and
unnamed individuals that would make a a T -neighbor of c, thus preventing a
from becoming mergable.

If a and P satisfy (C1), (C2) and (C3), an upper bound on the number of

P -neighbors can be computed using the following formula:

|P (a)| + |Some(P, a)| +

mP M in(P,a)

m

where before the application of any tableau rules, |P (a)| denotes the number of
P -neighbors of a, Some(P, a) = {P.C  clos(A) | there is no P -neighbor d of
a such that d : C  A }, and M in(P, a) = { mP  clos(A) | there are no
individuals di such that, for 1  i  m , di is a P -neighbors of a, and if j = k,
then dk

 =dj  A }

Intuitively, the upper bound is the sum of the explicit P -neighbors of a before the application of tableau rules, plus the maximum number of unnamed
individuals that can be generated by the application of the - and - rules,
excluding any existential or minimum cardinality restrictions that are already
satisfied prior to the application of tableau rules.

3.3 Correctness of Filtering Criteria

Since some of the notions introduced in the previous section are defined in the
context of the tableau algorithm, we first briefly present some important concepts
related to this algorithm. As described in [4], the tableau algorithm operates on
completion forest F = (G,L,  =,  =) where G is graph; L is a mapping from a
node x in F to a set of concepts, L(x), in clos(A), and from an edge < x, y >
in F to a set of roles, L(< x, y >), in R;
 = is an equivalence relation on nodes
of G; and  = is the binary relation distinct from on nodes of G. To check the
consistency of A, F is initialized as follows. There is a node a in G iff there is an
individual a in A. < x, y > is an edge in G with R  L(< x, y >) iff R(x, y)  A.
?

?

?
For x and y in G, x  =y iff x  =y  A. A root node a is a node present in the initial
forest, and unnamed nodes are created by  and  rules.

Next, we show that conditions (C1), (C2) and (C3) in Section 3.2 are sufficient
to rule out mergers which can increase the number of P -neighbors as shown in
Figure 3(B) and (C). Lemma 3 below is an important step towards this goal.
Lemma 3. Let P be a role that is safe in A. At any step of any execution of the
tableau algorithm on A, the following holds: if there is an unnamed node x such
 is in the L(< parent(x), x >), then |L(< parent(x), x >)| = 1,
that P or P
where parent(x) denotes the parent node of x in the completion forest (Note
that in a SHIN completion forest, unnamed nodes are always in a tree rooted at
a root node).

Proof. Easily proven by induction on the iterations of the tableau algorithm.
See [5] for more details. A direct consequence of this lemma is that a merger
between a and an unnamed node cannot increase the number of P -neighbors of
a if P is safe (See [5] for more details).

Now, we need to prove that if (C2) and (C3) are satisfied for a named individual a, a cannot be merged with another named individual. First, we formally
define the notion of mergeability with a named individual.
Definition 4. A named individual a in A is mergeable with named individuals
in A iff there is at least one execution of the tableau algorithm on A such that,
at some step, the root node a is merged with another root node b. When there
is no ambiguity, we simply say that a is mergeable.
Theorem 5: If a named individual a in A satisfies conditions (C2) and (C3),
then a is not mergeable with named individuals in A.
Proof Sketch. By induction on the iterations of the tableau algorithm using

Lemma 3 [5].

Finally, the correctness of our filtering criteria relies on the following theorem:
Theorem 6. A role assertion R(a, b) can safely be ignored in an Abox A if it
is irrelevant with respect to universal restrictions and irrelevant with respect to
maximum cardinality restrictions, as defined in section 3.2.
Proof. Let R(a, b) be a role assertion irrelevant w.r.t. maximum cardinality
and universal restrictions in an Abox A. Let A be the Abox defined as A =
(b, a)}. If A is consistent, A is obviously consistent. We show
A  {R(a, b), R
that if A is consistent, a model of A can be constructed by applying the tableau
algorithm rules in a particular way. 1

First, for a root node c in the completion forest F , the root node (c) is
defined as follows (Informally, (c) corresponds to the node in which c has been
directly or indirectly merged): if L(c) =  then (c) = c; otherwise, (c) = d,
where d is the unique root node in F with L(d) =  and d  =c.
1 A direct model-theoretic proof cannot easily be provided here, see [5] for details.

A. Fokoue et al.

Next, we modify F to create a completion forest F

Since A is consistent, we can apply the tableau expansion rules on A without
creating a clash in such a way that: (1) -rule is never triggered to satisfy a
constraint P.C  L((a))(resp. L((b))) where  nP  clos(A), R (resp. R
)
is part of  nP , and b : C  A (resp. a : C  A); and (2) -rule is never triggered
to satisfy a constraint  nP  L((a)) (resp. L((b))) where  nP  clos(A),
) is part of  nP , and, in the Abox A, b (resp. a) is one of n
R (resp. R
P -neighbors of a (resp. P -neighbors of b) explicitly asserted to be distinct. Such
a rule application yields a clash-free completion forest F , and the only nodes on
which expansion rules may be applicable are (a) and (b) (The only applicable
rules are -rule and -rule).
 by adding to F the edge
< (a), (b) > if it was not already in F , and by adding R to L(< (a), (b) >
 is complete (i.e. no rules are
), if it was not already there. We show that F
, R  L(< (a), (b) >) ensures
applicable) and clash-free. The fact that, in F
that the  and  rules, which may have been applicable on (a) or (b) in F , are
. However, the same fact may now make
not applicable on (a) and (b) in F
the , +, , and r rules applicable on (a) or (b) in F
. We show that this
cannot be the case.
The definition of irrelevance w.r.t. universal restrictions given in section 3.2
obviously ensures that  and + rules are not applicable on (a) or (b) in F
.
, and r rules are not applicable on (a) or (b) in F
 as a direct consequence
of the following claim: Claim: if R(a, b) is irrelevant w.r.t  nP  clos(A) and R
) is part  nP , then the number of P -neighbors of a (resp. P -neighbors
(resp. R
of b) in F is less than or equal to n. Furthermore, if it is equal to n, then, in F ,
(b) is a P -neighbor of (a) (resp. (a) is a P -neighbor of (b)).

The proof of this claim is a direct consequence of Lemma 3, Theorem 5 and
the fact that the upper-bound (defined in section 3.2) of P -neighbors of a is less
than or equal to n (See [5] for more details).
The addition of R  L(< (a), (b) >) to F cannot create a clash of the form
{C,C} in F
 due to a violation

of a maximum cardinality constraint on (a) or (b) is not possible. Thus, F
is a complete clash-free completion forest such that R  L(< (a), (b) >).
Therefore, a tableau for A can be built from F
 as in [4], so A has a model. 

, and the previous claim implies that a clash in F

3.4 Summary Abox Filtering

We apply the filtering criteria described in Section 3.2 to a canonical summary
Abox A. For correctness with respect to cardinality restrictions, we need to
augment the canonical summary Abox with role assertion statistics, since role
assertions are merged by the summary Abox transformation. For each role R
that is part of a cardinality restriction, we associated with R the maximum
number of R-neighbors that any individual a has in A. With this augmentation,
it is clear that the proofs in Section 3.3 apply to the canonical summary Abox.
Typically, filtering A creates distinct partitions, and we apply the tableau
algorithm to each partition separately. If all of the partitions are consistent,
then we are done. Otherwise, we need to check A. However, even when A itself
?

?

?
More precisely, let A

is inconsistent, some of its partitions may be consistent, and we only have to
check portions of A which correspond to the filtered inconsistent partitions of A.
Thus, partitioning a summary Abox is an effective way of isolating a potential
inconsistency in A. Furthermore, filtering A is very efficient since A is relatively
small. For partitions consisting of a single individual, checking consistency is just
checking concept satisfiability.
p be a partition of individuals and assertions in A. The
image of A
p in A is defined to be the maximum subset of the individuals and
assertions in A which map to A
p via the summary Abox function f. If a role
assertion R(a, b) is irrelevant in A, then all role assertions in its image in A
are also irrelevant. By theorem 2, if a partition A
p is consistent, then its entire
image in A can be ignored. Finally, retrieving the image in A of an inconsistent
partition A
For example, suppose we filter all R-role assertions from the summary Abox
A in Figure 2. The resulting summary Abox shown in Figure 4 consists of three
partitions: X, Y, and Z. We run the consistency check on each partition. For
singleton partition Z, we just need to check concept satisfiability. Assuming only
partition X is inconsistent, we need to check only the consistency of its image
in A, shown in Figure 5, which is d1, d2 : D; b1 b6 : B; T (d1, b1) and P (d2, b4).
Checking isolated individuals b2, b3, b5 and b6, involves just concept satisfiability.

p is a simple database operation.

Fig. 4. Filtered summary Abox

Fig. 5. Filtered Abox

4 Computational Experience

We tested our approach on the four ontologies shown in Table 2(a). Their expressiveness is given in the first column (Exp) of Table 2(a) . The number of
concepts (C) and roles (R) reported in the table reflect concepts and roles actually used in the Abox. In the tables, R.A. stands for role assertions, and I for
individuals. In all the experiments reported here, the Aboxes were stored in a
relational database on a 64 bit AMD 997 Mhz dual processor 8G RAM machine.
We tested our program as a client to the database server both on a 32 bit single
1.8 Ghz processor 1.5 G RAM machine, and on the 64 bit machine described
above. Running times reported in the tables are in seconds on the 64 bit ma-
chine. On the 32 bit machine the times were 2 times slower, but the program
ran on both machines with minimal space requirements (512 M heap).

The Biopax ontology contains biological pathway data for 11 organisms publicly available from Biocyc (http://biocyc.org). LUBM [7] is a benchmark ontology

A. Fokoue et al.

that was scaled to different numbers of universities (5-30) in our experiments. We
used an OWL-DL version of LUBM [8], but with nominals removed. The NIMD
ontology expresses relationships between persons, places and events (http://
ksl.stanford.edu/projects/NIMD/Kani-dl-v1.owl). Its Abox was generated from
text analysis of unstructured documents [9]. The semantic traceability (ST) ontology specifies the relationships among software artifacts. Its Abox was generated
from a program that extracted relationships between software artifacts of a middleware application. The sizes of the last 4 Aboxes shown in Table 2(a) are beyond
the capabilities of in-memory reasoners such as Pellet and KAON2, when tested
on the 64-bit machine with a 4G heap size.

Table 2. ABoxes and Summary Aboxes prior to filtering

Ontology
Biopax
LUBM-1
LUBM-5
LUBM-10
LUBM-30
?

?

?
R.A.

Exp C R
582,655
261,149
ALCHF 31 40
214,177
42,585
SHIN 91 27
927,854
179,871
SHIN 91 27
SHIN 91 27
351,422 1,816,153
SHIN 91 27 1,106,858 6,494,950
SHIF 19 27 1,278,540 1,999,787
874,319 3,595,132

SHI 16 11

(a) Experimental Aboxes

31 40 81

Ontology C R I R.A Time

Biopax
?

?

?
LUBM-1 91 27 410 16,233
LUBM-5 91 27 598 35,375
?

?

?
LUBM-10 91 27 673 49,176

LUBM-30 91 27 765 79,845
?

?

?
(b) Summaries

19 27 19
16 11 21

Table 2(b) shows the size of the corresponding summary Aboxes prior to any
filtering, and the time to compute the summaries. As noted in earlier sections,
the summary Abox can be computed once, and maintained with changes to the
Abox.

Table 3(a) shows the effectiveness of filtering the summary ABox for the consistency detection test, and the time to perform filtering. Note that the filtering
step is dynamic, i.e., it must be computed on the summary box for each incoming
query. The filtering step can create partitions. In Table 3(a), the first number in
the first column (Sin.+Mult) indicates the number of partitions with single indi-
viduals, and the second number indicates the number of partitions with multiple
individuals. The rest of the columns show the size of the Abox that is left after
removing all partitions with single individuals.

Table 3(b) shows the size of the Abox on which we had to perform the consistency check. All times for the consistency check were measured using the Pellet
OWL reasoner. For those Aboxes where the filtered summary Abox in Table 3(a)
was consistent, the size of the ABox was simply that in Table 3(a) . For some
ontologies, however (e.g., all LUBM ontologies marked with an asterisk), the filtered Abox was inconsistent because of our summarization techniques. For these
ontologies, we had to retrieve the image of the inconsistent partition from the
original Abox. In these cases, the size shown in Table 3(b) is the image of the
partition in the original Abox. Time for consistency check is provided in seconds.
This includes the time for the concept satisfiability check for partitions with single individuals, the time for the consistency check on the filtered summary, and
?

?

?
Table 3. Filtering and consistency check

Ontology Sin.+Mult. C R I R.A. Time
1.6
Biopax
LUBM-1
1.4
2.1
LUBM-5
2.5
LUBM-10
2.8
LUBM-30
0.6
?

?

?
0.3

42+1 13 1 38

130+2 28 5 280 284
172+2 28 5 426 444
199+2 28 5 474 492
220+2 28 5 545 574

17+1 2 1

3+1 15 2 18

(a) Summary Aboxes after filtering

Ontology
?

?

?
Biopax
140 102
LUBM-1*
LUBM-5*
644 466
LUBM-10* 1283 938
LUBM-30* 4045 2942
?

?

?
-

I R.A. Time Consistent
Yes
Yes
Yes
Yes
Yes
Yes
No

0.7

1.5

3.5
0.2
0.1

-

(b) Sizes for consistency check

the time for retrieving and checking the image of the inconsistent partition on
the original Abox. As shown in Table 3(b), ST was an inconsistent ontology, but
we determined this purely based on a concept satisfiability check for partitions
with single individuals. We also deliberately injected an inconsistency for one
of the Biopax databases (agrocyc), to check if we could detect an inconsistency
that could not simply be detected by a concept satisfiability check. We were able
to detect that the Abox was inconsistent using our algorithm.

5 Related Work

There are many highly optimized reasoners such as Pellet [10], Racer [11], InstanceStore [12], and Kaon2 [3] designed for consistency checking, but only InstanceStore and Kaon2 can be extended to Aboxes in secondary storage 2. Kaon2
applies to deductive databases, whereas our techniques work with relational data-
bases. InstanceStore is limited to role-free Aboxes. In theory, Instance Store can
handle Aboxes with role assertions through a technique called precompletion
[13], but this may not be practical for large Aboxes stored in databases because it could result in an exponential number of Aboxes. Our approach can be
compared with optimization techniques such as model caching and Abox contraction [14], and partitioning techniques [15], but again, it is unclear how such
techniques can be applied to large Aboxes in databases.

6 Conclusions

We have demonstrated a technique to scale consistency detection to large Aboxes
in secondary storage by extracting a small representative Abox. Further, we have
shown that, in practice, this technique works efficiently on four large ontologies.
Our plan is to extend this approach to apply more accurate analysis techniques,
extend its applicability to more expressive languages, and to optimize these
techniques for efficient query processing.

2 RacerPro version 1.9.0 does not provide that capability, but its user guide indicates

that it will be available in a future version.

A. Fokoue et al.
