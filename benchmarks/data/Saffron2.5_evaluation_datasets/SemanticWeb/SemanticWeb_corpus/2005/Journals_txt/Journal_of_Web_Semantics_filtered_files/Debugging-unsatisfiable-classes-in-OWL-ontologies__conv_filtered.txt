Web Semantics: Science, Services and Agents

on the World Wide Web 3 (2005) 268293

Debugging unsatisfiable classes in OWL ontologies

Aditya Kalyanpur

, Bijan Parsia, Evren Sirin, James Hendler


University of Maryland, MIND Lab, 8400 Baltimore Avenue, College Park, MD 20742, USA

Received 11 September 2005; accepted 19 September 2005

Abstract

As an increasingly large number of OWL ontologies become available on the Semantic Web and the descriptions in the
ontologies become more complicated, finding the cause of errors becomes an extremely hard task even for experts. Existing
ontology development environments provide some limited support, in conjunction with a reasoner, for reporting errors in OWL
ontologies. Typically, these are restricted to the mere detection of, for example, unsatisfiable concepts. However, the diagnosis
and resolution of the bug is not supported at all. For example, no explanation is given as to why the error occurs (e.g., by
pinpointing the root clash, or axioms in the ontology responsible for the clash) or how dependencies between classes cause
the error to propagate (i.e., by distinguishing root from derived unsatisfiable classes). In the former case, information from the
internals of a description logic tableaux reasoner can be extracted and presented to the user (glass box approach); while in the
latter case, the reasoner can be used as an oracle for a certain set of questions and the asserted structure of the ontology can
be used to help isolate the source of the problems (black box approach). Based on the two approaches, we have integrated a
number of debugging cues generated from our reasoner, Pellet, in our hypertextual ontology development environment, Swoop.
A conducted usability evaluation demonstrates that these debugging cues significantly improve the OWL debugging experience,
and point the way to more general improvements in the presentation of an ontology to users.
 2005 Elsevier B.V. All rights reserved.

Keywords: OWL; Ontology debugging; Explanation; Semantic web

 This paper is an extension of the WWW05 Conference paper on
Debugging OWL Ontologies [1] and the DL05 Workshop paper
on Black Box Debugging of Unsatisfiable Concepts [2].

Corresponding author. Tel.: +1 301 314 6611;


fax: +1 301 314 9734.

E-mail addresses: aditya@cs.umd.edu (A. Kalyanpur),

bparsia@isr.umd.edu (B. Parsia), evren@cs.umd.edu (E. Sirin),
hendler@cs.umd.edu (J. Hendler).

1570-8268/$  see front matter  2005 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2005.09.005

1. Introduction

Now that OWL [3] is a W3C Recommendation, one
can expect that a much wider community of users and
developers will be exposed to the expressive description logic SHIF(D) and SHOIN(D) which are the basis
of OWL-DL. These users and developers are likely
not to have a lot of experience with knowledge representation (KR), much less logic-based KR, much
less description logic-based KR. For such people, hav-

Fig. 1. OWL version of the Tambis ontology as viewed in an ontology browser and tested using a DL reasoner.

ing excellent documentation, familiar techniques, and
helpful tools is a fundamental requirement.

A ubiquitous activity in programming is debugging,
that is, finding and fixing defects in a program. Ontologies too have defects, and a common activity is to
find and repair these defects. Unfortunately, the tool
and training support for debugging ontologies is fairly
weak.1 We have chosen to focus on debugging unsatisfiable concepts (and contradictory ABoxes) because
contradictions, in general, seem analogous to fatal
errors in programs. Debugging fatal errors in programs
can be relatively straightforward: the program crashes,
there is a stack trace or similar information, and (one
measure of) success is a running program. For ontolo-
gies, current tools (reasoners) do support indicating the
dramatic failure of an unsatisfiable class, and success is

1 While, historically, good KR modeling practices have been developed and described, often with an emphasis on description logics [4],
tool support for good modeling remains elusive, especially given
the lack of consensus on practice and the strong dependence of goodness on application and domain specifics.

similarly clear, however, the diagnosis and resolution
of the bug is not supported at all. Consider the case of
the Tambis OWL ontology2 shown in Fig. 1 in which
more than a third of the classes are unsatisfiable.

Here, the tool has detected unsatisfiable classes in
the ontology but no reason is given as to why a specific
class is unsatisfiable or what measures can be taken to
rectify it. Also, the fact that there are so many unsatisfiable classes makes the debugging task seem all the
more overwhelming.

When new modelers encounter cases of unsatisfiability such as this, they are often at a loss at what
to do. This has two negative general consequences
inhibiting adoption and effective use of OWL ontolo-
gies: either developers tend to underspecify their concepts to avoid errors or they give up on ontologies
altogether.

The above case illustrates that OWL ontology tools
have to go much further in organizing and presenting
2 http://www.cs.man.ac.uk/horrocks/OWL/Ontologies/tambis-
full.owl.

A. Kalyanpur et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3 (2005) 268293

the information supplied by the reasoner and existing
in the ontology in order to aid debugging. For exam-
ple, tools could pinpoint the problematic axioms in
the ontology responsible for an unsatisfiable class; or
detect and highlight interdependencies between unsatisfiable classes to help differentiate the root bugs from
the less critical ones (especially useful in cases such as
Tambis where there are a large number of unsatisfiable
classes). Also, readable explanations (proofs) could be
provided to help the modeler understand the cause of
the problem.

The goal of our research is to develop techniques
of the form described above to support the debugging
of OWL ontologies and to demonstrate its significance
and use in practice. In this paper, we describe some first
steps in providing debugging support for unsatisfiable
concepts in the Swoop OWL ontology browser and editor [5]. We have explored both black box and glass box
generation of debugging cues using a description logic
tableau reasoner, in this case, our OWL reasoner Pellet
[6].

A broader goal of this research is to demonstrate that
good ontology debugging support not only gives users
a sense of control over their modeling, but also encourages them to experiment more freely with expres-
sions, helping them come to understand their ontologies through the debugging process.

2. Defects in OWL

Any description logic knowledge base can have
defects (or inconsistencies), which need to be detected
and resolved in order to obtain any useful accurate
information from it. OWL ontologies are no different
and we consider some factors, which make them susceptible to errors:

(1) Difficulty in understanding modeling: As noted
earlier, OWL users and developers are not likely
to have a lot of experience with description logicbased KR, and hence, without adequate tool support for training and explanation, engineering
ontologies can be a hard task for such users.
As ontologies become larger and more complex,
highly non-local interactions in the KB combined
with other intrinsic aspects of OWL such as openworld semantics, non-unique name assumption,

etc., make modeling, and analyzing the effects of
modeling non-trivial even for domain experts.

(2) Misalignment of OWL ontologies: When related
domain ontologies created by separate parties are
merged using owl: imports, the combination
can result in modeling errors [7]. This could be due
to ontology authors either having different views of
the world, following alternate design paradigms, or
simply, using a conflicting choice of modeling con-
structs. An example is when the two upper-level
ontologies, CYC and SUMO are merged leading
to a large number of unsatisfiable concepts due to
disjointness statements present in CYC.

(3) Migration to OWL: Whenever OWL ontologies
are extracted or derived from schema/ontologies
in other languages such as XML, DAML, etc., a
faulty migration process can lead to an incorrect
specification of concepts or individuals in the resultant OWL version. For example, the OWL version
of the Tambis ontology contains 144 unsatisfiable
classes (out of 395) due to an error in the transformation script used in the conversion process.

Defects in OWL can be due to various reasons,
however, they broadly fall into three main categories:
syntactic, semantic and modeling defects. We now discuss each of these defects separately in terms of the
standard techniques for detecting these errors and for
presenting them to a user.

2.1. Syntactic defects

Syntactic issues loom large in OWL for a number of reasons including the baroque exchange syn-
tax, RDF/XML and the use of URIs (and their
abbreviations), but most of these are straightforward
to detect and rectify using XML parsers and RDF
validators (http://www.w3.org/RDF/Validator/). How-
ever, for OWL DL, there is yet another layer of syntactic
structure on top of the corresponding RDF graph, i.e.,
a number of restrictions are imposed on the form of
the graph in order for it to count as an instance of
the OWL DL species. These restrictions are quite
onerous for authors and easy to violate as, in general,
importing is not species safe: importing an OWL Lite
document into another may result in an OWL Full doc-
ument, and an OWL DL document importing either an
OWL Lite or OWL DL document may become OWL

Full. Even OWL Full, the superset of the rest, may
become OWL DL or Lite upon an import. The WebOnt
working group defined a category of OWL processor
for so-called species validation, and though there were
serious fears of the complexity and implementation of
such validation, several implementations have emerged
and appear to be reliable.

2.2. Semantic defects

Given a syntactically correct OWL ontology, semantic defects are those which can be detected by an OWL
reasoner. These include unsatisfiable classes and inconsistent ontologies. Unsatisfiable classes are those which
cannot be true of any possible individual, that is, they
are equivalent to the empty set (or, in description logic
terms, to the bottom concept, or, in OWL lingo, to
owl:Nothing). For example, class A is unsatisfiable
if it is a subclass of both, class C and C, since it
implies a direct contradiction. Unsatisfiable concepts
are usually a fundamental design error, as they cannot
be used to characterize any individual. Unsatisfiable
concepts are also quite easy for a reasoner to detect
and for a tool to display. However, determining why a
concept in an ontology is unsatisfiable can be a considerable challenge even for experts in the formalism
and in the domain, even for modestly sized ontologies.
The problem worsens significantly as the number and
complexity of axioms of the ontology grows.

Inconsistent ontologies are those which have a contradiction in the instance data, e.g., an instance of an
unsatisfiable class. They are also fairly easy for a reasoner to detect, if it can process the ontology at all.
In fact, in tableau reasoners, unsatisfiability testing is
reduced to a consistency test by positing that there is a
member of the to be tested class and doing a consistency
check on the resultant knowledge base (KB). However,
unlike with mere unsatisfiable classes, an inconsistent
ontology is, on the face of it, very difficult for a reasoner to do further work with. Since anything at all
follows from a contradiction, no other results from the
reasoner (e.g., with regard to the subsumption hierar-
chy) are useful.

2.3. Modeling/style defects

the KB or unanticipated results of modeling, which
require the modelers attention before use in a specific
domain or application scenario. Consider the following
cases:
 There may be unintended inferences (subsumption,
realization relationships, etc.) discovered by the rea-
soner. For example, it can be inferred that parents
of at least three children is a subclass of parents with at least two children, even if there is
no explicit assertion of that relationship. Though
the reasoner can detect and report subsumptions
such as this, it cannot distinguish between desirable
(non)inferences and undesired ones.
 Missing type declarations can occur in a KB, such
as if a resource is used in a particular manner that
entails it to be of a particular type, but is not explicitly
declared to be so, e.g., given the triple <John hasParent Mary>, where hasParent is known to
be an OWLObjectProperty, one can infer that John
and Mary both have to be of type OWLIndividual. In
such cases, the reasoner will infer the corresponding
entailment, but the absence of this explicit information could be considered as a defect.
 In some cases, redundancies may exist in the KB,
such as when an asserted axiom is entailed by
another set of axioms from the KB. Here, depending
on whether the redundancy is desired or not, the case
could be considered as a defect.
 There may be cases of unused atomic classes or properties with no references anywhere in the KB (i.e.,
the term is not explicitly used in any axiom in the
KB), which can be considered as extraneous data.

We will not deal with the detection and debugging of
these subtler, domain and modeler dependent defects,
focusing, in this paper, on debugging unsatisfiable con-
cepts. Since modeling defectiveness is very dependent
on the modelers intent, we believe that effective debugging requires the expression of that intent to the system.
In other words, we suspect testing and test cases are the
right modality for dealing with some of these defects.

3. Current state of the art in OWL ontology
debugging

These are defects that are not necessarily invalid,
syntactically or semantically, yet are discrepancies in

There has long been significant interest in explaining inferences to the non-sophisticated user when

A. Kalyanpur et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3 (2005) 268293

implementing reasoning services for description logic
(DL) systems. In [8] the author provides explanations
as proof fragments based on standard structural subsumption algorithms for the CLASSIC KR system. The
method has been extended for ALC reasoning in [9]
wherein the authors use a modified sequent calculus
to explain a tableaux-based proof. An implementation
of this idea can be seen in the toolOntoTrack [10],
which provides instant reasoning feedback. Addi-
tionally, the Inference Web Infrastructure [11] comprised of a web-based registry for information sources,
reasoners, etc., and a portable proof specification language for sharing explanations.

However, while the emphasis so far has been on
explaining subsumption in relatively inexpressive terminologies (ALC), there has not been much work done
in explaining and fixing errors in expressive DLs such
as SHION(D). Moreover, with OWL reaching recommendation status only recently (February 2004), the
area of debugging OWL ontologies, in particular, is a
largely unexplored field.

In [12], the authors present a tool, Chimaera, which
apart from supporting ontology merging, allows users
to run a diagnostic suite of tests across an ontol-
ogy. The tests include incompleteness tests, syntactic checks, taxonomic analysis, and semantic checks,
and the results are displayed as an interactive log,
which the users can study and explore. The focus
here is clearly on detecting modeling defects, whereas
explanation support for semantic defects is fairly
weak.

Work has been done on a Symptom Ontology [13]
for representing errors and warnings resulting from
defects in OWL ontologies, and an implementation is
provided in the consistency-checking tool, Con Visor.
The authors here do a good job of categorizing commonly occurring symptoms and motivate the significance of creating and exchanging standardized bug
reports using a symptom ontology. However, just as in
the previous case, their work does not deal with pinpointing the cause of inconsistency.
For explaining inconsistencies,

two interesting
efforts have been recently published. The first is a
tableaux based method described in [14], where nonstandard reasoning algorithms based on minimization
of axioms using Boolean methods are used to debug
the DICE terminology. The authors focus on axiom
and concept pinpointing and introduce useful relevant

terms for this purpose such as Minimal Unsatisfiability
Preserving Sub-TBoxes (MUPS). However, a drawback of their approach is that its restricted to unfoldable
ALC TBoxes.

The second piece of relevant work is a black box
heuristic approach described in [15], which is used
to detect and explain inconsistencies in OWL ontolo-
gies. The idea here is to use a pre-defined set of
rules/conditions to detect commonly occurring error
patterns in ontologies based on extensive use-case data.
However, such a rule-based heuristic is clearly incom-
plete.

4. Diagnosing unsatisfiability

When faced with a detected unsatisfiable concept,
one must perform a diagnosis, that is, come to understand the underlying causes of the unsatisfiability and
determine which are problematic. Once the diagnosis is completed, various remedies can be considered
and their costs and benefits evaluated. We distinguish
two families of reasoner-based techniques for supporting diagnosis: glass box and black box techniques.
In glass box techniques, information from the internals of the reasoner is extracted and presented to the
user (sometimes the implementation is altered in order
to improve the information returned). In black box
techniques, the reasoner is used as an oracle for a
certain set of questions, e.g., the standard description logic inferences
satisfiability,
etc.).

(subsumption,

However, before we elaborate on the glass and black
box ontology debugging techniques, it is important to
discuss basic browsing and rendering functionality that
an ontology engineering tool (coupled with a reasoner)
can provide in order to aid understanding, analysis and
debugging of the ontology. In this case, we discuss
functionality as provided in Swoop (editor), which uses
Pellet (reasoner), both of which are core components
used for debugging purposes.

Swoop has a debug mode wherein the basic rendering of entities is augmented with information obtained
from a reasoner. Different rendering styles, formats,
and icons are used to highlight key entities and relationships that that are likely to be helpful to debugging process. For example, all inferred relationships
(axioms) in a specific entity definition are italicized

and are obviously not editable directly. In the future,
we plan to extend this feature by displaying the reasoning chain for the simple, yet non-trivial inferences by
pointing to related definitions and axioms (e.g., C is an
intersection of (D,. . .) implies C is a subclass of D), but
for now, simply highlighting them separately is useful
to the ontology modeler as they can (potentially) point
to unintended assertions. On a similar note, in the case
of multiple ontologies, i.e., when one ontology imports
another, all imported axioms in a particular entity definition are italicized as well. Highlighting them helps
the modeler differentiate between explicit assertions in
a single context and the net assertions (explicit plus
implied) in a larger context (using imports), and can
also reveal unintended semantics.

All unsatisfiable named classes, and even class
expressions, are marked with red icons whenever
rendereda useful pointer for identifying dependencies between errors. In Fig. 2 (the Tambis ontology),
note how simply looking at the class definition of
gene-part makes the reason for the error apparent: it

is a subclass of the unsatisfiable class dna-part and
the unsatisfiable class expression partof.gene.
The hypertextual navigation feature of Swoop allows
the user to follow these dependencies easily, and reach
the root cause of the error, e.g., the class, which is
independently unsatisfiable in its definition (i.e., no
red icons in its definition). In this manner, the UI
guides the user in locating and understanding bugs in
the ontology by narrowing them down to their exact
source.

Also note that the class expressions themselves can
be rendered as regular classes, displaying information
such as sub/super classes of a particular expression (by
clicking on the associated CE icon, see Fig. 3). This
sort of ad hoc on-demand querying (e.g., find all
subclasses of a specific query expression) helps reveal
otherwise hidden dependencies. Consider the case of
the unsatisfiable class Koala depicted in Fig. 3, which
contains three labeled regions (the figure makes use of
the Comparator feature in Swoop, discussed in Section
7.2). Region 1 shows the definition of the Koala class

Fig. 2. The class gene-part is unsatisfiable on two counts: its defined as an intersection of an unsatisfiable class (dna-part) and an
unsatisfiable class expression (partof.gene), both highlighted using red tinted icons.

A. Kalyanpur et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3 (2005) 268293

Fig. 3. The class Koala is unsatisfiable because (1) Koala is a subclass of isHardWorking.false and Marsupials; (2)
isHardWorking.false is a subclass of Person; (3) Marsupials is a subclass of Person (disjoint). Note that the regions outlined in red are not automatically generated by the tool but are presented here for clarity.

in terms of its subclass-of axioms: note the presence
of the class expression isHardWorking.false
and the named class Marsupials mentioned here.
Now, clicking on the class expression reveals that it
is an inferred subclass of Person (Region 2),3 and
clicking on Marsupials shows that it is defined as
disjoint-with class Person (Region 3). Thus, the contradiction is foundan instance of Koala is forced to
be an instance of Person and Person at the same
time, and the bug can be fixed accordingly.

Finally, Swoop has an interesting non-standard
search feature which can be useful during ontology debugging. This feature known as Show References highlights the usage of an OWL entity (con-
cept/property/individual) by listing all references of
that entity in local or external ontological definitions.

3 A simple heuristic to manually debug an unsatisfiable class is
to inspect its asserted and inferred subclass relationships that could
potentially cause a contradiction, as is what motivates clicking the
class expression link here.

The Sweet-JPL ontology set4 presents an excellent use
case for debugging using this feature (Fig. 4). The
class OceanCrustLayer is found to be unsatisfiable
and a reason displayed for the clash is Any member
of OceanCrustLayer has more than one value for the
functional property hasDimension (Note: clash detection is explained later). Now, running a Show References search on the property hasDimension, returns
four classes GeometricObject(0. . .3)D, each of
which has a different value restriction on the functional property hasDimension. This suggests that
the unsatisfiable class is somehow related to more than
one of these four classes causing the cardinality viola-
tion. This is indeed the case since by looking at the class
hierarchy, one can note that OceanCrustLayer is a
subclass of both the classes, GeometricObject2D

4 Sweet-JPL ontologies are located at http://sweet.jpl.nasa.gov/
ontology/. The bug in the ontology was fixed on May 24, 2005
after we e-mailed the ontology authors at NASA informing them
about it. The previous faulty version can be found at http://www.
mindswap.org/ontologies/debugging/buggy-sweet-jpl.owl.

Fig. 4. The Show References feature (used along with the clash information and the resource holder) is used to hint at the source of the highly
non-local problem for the unsatisfiable class OceanCrustLayer.

and GeometricObject3D, and thus the reason for
the contradiction becomes apparent.

While browsing, rendering, and search functionality of the forms explained above can help the modeler
understand and debug the ontology, it is still primarily
a manual task and can be considerably challenging in
most cases. Thus, automated techniques are needed to
support ontology debugging and repair.

Currently, glass box techniques are used to support

two forms of debugging of unsatisfiable concepts:

(1) Present the Clash information: root cause of the

contradiction.

(2) Determine the minimal Sets of Support: the relevant axioms in the ontology that are responsible
for the clash.

4.1. Glass box techniques

4.1.1. Clashes

In glass box techniques, the internals of a description logic tableaux reasoner are modified to extract and
reveal the cause for unsatisfiability of a concept defi-
nition. An advantage of the approach is that by tightly
integrating the debugging with the reasoning proce-
dure, precise results can be obtained. On the other
hand, the reasoner needs to maintain extra data structures to track the source and its dependencies and this
introduces additional memory and computation con-
sumption.

There are many different ways for the axioms in an
ontology to cause an inconsistency. But these different
combinations boil down to some basic contradictions
in the description of an individual. Tableaux algorithms
apply transformation rules to individuals in the ontology until no more rules are applicable or an individual
has a clash. The basic set of clashes in a tableaux algorithm are:
 Atomic: An individual belongs to a class and its com-

plement.

A. Kalyanpur et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3 (2005) 268293

Fig. 5. The explanation of unsatisfiability for class Mad Cow includes the description of an anonymous individual created by the reasoner. It is
easy to see the connection between the path that identifies the individual and the existential restrictions in the Mad Cow definition.

 Cardinality: An individual has a max cardinality
restriction but is related to more distinct individu-
als.
 Datatype: A literal value violates the (global or local)

range restrictions on a datatype property.

As a minimum requirement for the clash information to be useful for diagnosis, the reasoner should
explain some details about the clash, e.g., which class
and its complement is causing the clash. However, it
is not easy to usefully present this clash information to
the user. For example, the normalization and decomposition of expressions required in reasoning can obscure
the error by getting away from the concepts actually
used by the modeler, or the clash may involve some
individuals that were not explicitly present in the ontol-
ogy, but generated by the reasoner in order to try to
adhere to some constraint. Those generated individuals may not even exist (or be relevant) in all models. For
example, if an individual has a owl:someValuesFrom
restriction on a property, the reasoner would generate
a new anonymous individual that is the value of that
property. Since these individuals (as with bnodes that
exist in the original ontology) do not have a name (URI)
associated with them, we can only use paths of prop-

erties to identify these individuals. This adds the extra
burden to the user to make the connections between the
identification path and the restrictions in the concepts
definition but this is not always a big problem as illustrated in Fig. 5 that shows an example from the Mad
Cow ontology.5

Depending on the reasoners capabilities it is possible to increase the granularity of the clash explanations.
For example, if an individual has two conflicting cardinality restrictions on a property (e.g., 2 child
and 1 child), then it is possible for the reasoner to
detect this clash without generating individuals by just
checking such obvious contradictions in cardinality
restrictions. Generating explanations specific to these
cases makes it easier for the user to see the relation
between the clash and the existing axioms in the ontol-
ogy.

4.1.1.1. Clash detection procedure. It is important to
note that tableau expansion rules may find many different clashes during a satisfiability test. Due to the
non-determinism caused by the OWL constructors such

5 The Mad Cow ontology is used in OilEd tutorials.

as owl:unionOf and owl:maxCardinality,6 some of the
clashes do not reflect an error in the ontology but simply
guide the tableau rules to the correct model. There-
fore, the question is how to identify the inconsistencyrevealing clashes from intermediary clashes. It turns
out that dependency directed backjumping technique
can be utilized to make this distinction.

Dependency directed backjumping is an optimization technique that adds an extra label to the type and
property assertions so that the branch numbers that
caused the tableau algorithm to add those assertions are
tracked. Obviously, assertions that exist in the original
ontology and the assertions that were added as a result
of only deterministic rule applications will not depend
on any branch. This means these assertions are direct
consequence of the axioms in the ontology and affect
every interpretation. If a clash found during tableau
expansion does not depend on any non-deterministic
branch, the reasoner will stop applying the rule as it
is obvious that there is no way to fix the problem by
trying different branches.

When the reasoner is known to use dependency
directed backjumping (all existing DL reasoners 
Racer, Fact, Pellet  use this technique), then looking at
the last clash to explain an unsatisfiability is generally
enough (though, one should verify this by examining
the dependency set information of the clash).

Issues in Clash Detection:

(1) The clash information may be incomplete. Consider the case in which the inconsistency is due
the different non-deterministic branches
to all
failing for different
reasons. A simple concept description that illustrates this problem is
A B C (BC). Concept A is unsatisfiable
because it is either a subclass of B or C (due
to the disjunction). However, neither is possible
since they both cause a clash with other concepts
in the conjunction. In this setting, it is not enough
to present the last clash as it will not be accurate.
This problem can be overcome when all the
clashes encountered are recorded and the depen-

6 When there is a maxCardinality restriction on a property and
more values are provided for that property, reasoner is forced to
assign equivalence between some of these values in order to satisfy
the cardinality restriction. There might be multiple different combinations to select the individuals, thus the choice is non-deterministic,
i.e., reasoner tries every different possibility.

dency set of the last clash is examined to find the
relevant set of clashes for the inconsistency. Unfor-
tunately, in this case it is harder to understand the
problem as the user is expected to look at all the
different clash reasons.

(2) The clash presented does not explain the cause of
the problem, since it fails to reveal the asserted
definitions directly responsible for
the clash.
For example, while the property path (as seen
in Fig. 5), helps establish a connection between
the unsatisfiable class in question and the root
clash, it does not indicate reasons for the property
i.e., whether the successor comes
successors,
asserted owl:minCardinality
from an
or
restriction,
or a combination of an existential with an
owl:allValuesFrom restriction. However,
computing the clash information is relatively easy
and does not introduce much overhead in terms of
speed or memory consumption for the reasoner,
as shown in the evaluation later.

owl:someValuesFrom

This problem is resolved in the next subsection

by computing the sets of support axioms.

4.1.2. Sets of support
As noted above,

the clash information does
not specify which set of axioms are causing this
inconsistencyessential information for the user trying to fix the problem. Finding the source of the problem manually may still take some reasonable effort,
especially when the descriptions in the ontology are
complex. It is possible to extend the reasoner to keep
track of the source axioms for assertions in a way similar to the dependency sets discussed earlier (see Fig. 6),
and the procedure is described below.

4.1.3. Tableaux tracing procedure

Before we explain the tracing procedure, we briefly
revisit how tableaux reasoning works: satisfiability
checking of a class involves building a model of the
class using a set of tableaux expansion (trigger) rules.
The process starts with explicit assertions in the ontology and new axioms (inferences) are added by the
reasoner depending on the triggering rule.

For example, suppose we have two assertions:
{x rdf : type C,
C rdfs : subClassOf D}

A. Kalyanpur et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3 (2005) 268293

Fig. 6. The set of axioms that support the inconsistency of Koala concept is displayed in debug mode.

The reasoner will add the additional assertion:

{x rdf : type D}

which will depend on both of the above assertions.
Also, as noted in the previous section, various internal
modifications are done by the reasoner such as normalization and absorption that combine and transform
axioms in different ways in order to optimize clash
detection.

Our goal is to track and store the original source
axioms from the ontology as they are modified and
used throughout the tableaux expansion process. For
this purpose, we extend the dependency sets used in the
clash detection procedure to keep track of the axioms.
As the reasoner continues applying the tableau rules,
the axiom set for each assertion needs to be updated
as well as the dependency set information. When an
inconsistency-revealing clash is discovered, the axiom
set is presented along with the clash information. This
ensures that only the axioms directly relevant to the

inconsistency are obtained. For example, suppose given
class A, the clash detected is atomic, i.e., A is forced
to be an instance of both: C and C. In this case, the
axiom set obtained via the dependency branches are
only those responsible for making A C and separately
making AC, and thus relevant to the contradiction.
The key elements of the current implementation are:

(1) While transforming axioms from the ontology into
the data structures used internally by the reasoner,
we precompute and store references between normalized versions of the data structures and the original axioms in an ExplanationTable (HashMap).
During tableaux expansion in the reasoner, i.e.,
type addition to an individual (unfolding), edge
addition between individual (property restriction),
etc., we refer to the ExplanationTable to obtain the
corresponding axioms responsible for the addition.
The ExplanationTable contains several tweaks to
make sure that references are maintained and
retrieved properly:

 If the data structure corresponds to a list (say an
intersection list in a subclass axiom), we store
references for each component of the list.
 Whenever equivalent-class axioms (or domain/
range/disjoint axioms) are converted to internal
representations, we store references between the
original axiom and the mapped counterparts.
 During retrieval, if an axiom is not found in the
ExplanationTable, we check if the negated version of the axiom is present.

(2) For absorption, we use the algorithm described in
[16] which is a seven-step algorithm that absorbs
GCIs (or parts of GCIs) into primitive definitions
in the KB. Tracking here entails storing axioms
responsible for introducing elements in the absorption set (steps 1, 3, 4), and then references between
the new absorbed primitive definition and these
axioms (step 2).

(3) For internalization, we track the source of the unabsorbed components (after the absorption phase),
and then store references between each component (converted to a disjunct) in the Universal
Concept (UC) and the original axiom in Explana-
tionTable. When applying the UC to each node in
the tableaux, we recover the axioms corresponding
to each disjunct and add them to the dependency
branch for each disjunction (Note: each disjunction
introduces non-deterministic branches).

(4) On a more general note: in order to prevent axiom
tracking from adversely affecting the normal operation of the reasoner, all tracking is done in a
separate completion strategy. Also, if calls are to be
made to the core methods of the reasoner, mirror
methods are created which perform the dependency tracking, and mirrors are called instead
of the original methods from this completion
strategy.

The pseudo code for the tableaux tracing is given in
Appendix A. For a detailed technical report on tableaux
tracing, see [17].

Issues in sets of support:

(1) The sets of support for a specific class (when
determined minimally) coincide with the notion
of Minimal Unsatisfiability Preserving Sub-TBox
as defined in [14], i.e., they represent the smallest sub-TBox of the ontology, which contains the
contradiction for the class. Note that there may be

more than one MUPS for a single class, since there
may be different inconsistency-causing clashes
responsible for its unsatisfiability. For example,
consider a class defined by two subclass axioms:
A (CC) and A (DD). In this case, each
axiom is a distinct MUPS of class A and in order
to resolve the bug in A, both axioms (each of the
MUPS) need to be fixed separately. In our current
solution, we determine only a single MUPS (sets
of support) since typically in reasoners, tableaux
expansion stops when the first inconsistency causing clash is found.

(2) Having found the sets of support for an unsatisfiable class, presenting the axioms in order to
facilitate understanding of the problem is a separate
challenge. For now, we have worked on a recursive
ordering strategy which arranges axioms such that
atleast one component in the RHS of the current
axiom aligns with the LHS of the next. An example
of this ordering is shown in Fig. 7 for the unsatisfiable class OceanCrustLayer in the Sweet-JPL
ontology set (discussed earlier).

We are also working on an alternate technique
to explain the contradiction by computing the
subsumption trace [18]. We intend to study both
approaches in more detail based on a thorough
evaluation.

(3) The sets of support highlight the axioms responsible for the inconsistency of a single class. However,
in an ontology with numerous unsatisfiable classes,
it is critical to find common sets of support, i.e.,
axioms that cause inconsistency for a large number of related classes since they essentially point
to the root of the problem. This is difficult to
achieve in practice using the glass box, since it
requires finding sets of support for each unsatisfiable class in the ontology, which can be extremely
time consuming for a large set of unsatisfiable
classes.

In order to resolve this problem, we explore
black box alternatives to detect structural dependencies between unsatisfiable classes and focus on
differentiating between root and derived unsatisfiable classes (see Section 4.2).

4.1.4. Related problem: explaining subsumption

As an interesting sidenote, the problem of explaining subsumption is closely related to explaining con-

A. Kalyanpur et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3 (2005) 268293

Fig. 7. The set of axioms that contain the inconsistency of OceanCrustLayer are ordered to facilitate understanding of the problem by
systematically leading the user to the source of the contradiction.

tradiction for an unsatisfiable class. This is not surprising since in tableaux reasoners subsumption-check
between a pair of classesC D is reduced to a
consistency-check of the complex class description
CD. Thus, the minimal sets of support that entail
the contradiction of CD necessarily entail the subsumption of C by D, and can be used to explain nontrivial subsumptions to users.

4.2. Black box techniques

In black box techniques, the reasoner is used as an
oracle for a certain set of questions (standard inferences such as satisfiability, subsumption, etc.) and
the asserted structure of the ontology is used to help
isolate the source of the problems. Thus, it has two
advantages over the glass box approach: reasoner inde-
pendence, i.e., you do not need a specialized, explanation generating reasoner, and avoiding the performance penalty (memory consumption) of glass box
techniques.

Currently, the black box methods focus on detecting
dependencies between unsatisfiable classes, i.e., identifying root and derived unsatisfiable classes.

4.2.1. Root/derived unsatisfiable classes

For the purpose of debugging, we categorize unsat-

isfiable classes in an ontology into two types:

(1) Root class: This is an unsatisfiable class in which
a clash or contradiction found in the class definition (axioms) does not depend on the unsatisfiability of another class in the ontology. More
specifically, the unsatisfiability bug for a root class
cannot be fixed by simply correcting the unsatisfiability bug in some other class, instead, it
requires fixing some contradiction stemming from
its own definition. Example of a root class is: Student (2)hasAdvisor (1)hasAdvisor.

(2) Derived class: This is an unsatisfiable class in
which a clash or contradiction found in a class definition either directly (via explicit assertions) or
indirectly (via inferences) depends on the unsatisfiability of another class (we refer to it as the
parent unsatisfiable class). Hence, this is a less critical bug in the sense that (in most cases) it can be
resolved by fixing the unsatisfiability of this parent
dependency. Note that there may be cases in which
fixing the dependency bug reveals yet another

unsatisfiability bug in the class, which needs to
be resolved separately (making the derived class
necessarily, but not sufficiently, dependent on the
parent). Example of a derived class is: class GraduateStudent Student, where Student is an unsatisfiable class itself, in this case, its parent.

We give formal definitions for the different types of
unsatisfiable classes in terms of MUPS of an unsatisfiable class:

Definition 1 (Root and derived). C is a derived unsatisfiable class iff it satisfies the following condition: i, j
s.t. MUPSi(C) MUPSj(D), where D is another unsatisfiable class in the ontology, in this case its parent. If C
does not satisfy this condition, it is a root unsatisfiable
class.

Intuitively, a derived unsatisfiable class C depends
on parent D if D being unsatisfiable makes C unsatis-
fiable. The converse is not guaranteed.7

4.2.2. Automating dependency detection

In this section, we present a dependency-detection
algorithm that separates the root from the derived unsatisfiable classes in an ontology as provided by a rea-
soner. The algorithm consists of two parts: asserted
dependency detection and inferred dependency detection and we describe each in detail in the following
subsections.

For each unsatisfiable class in the ontology, the algorithm returns all its parent dependency classes along
with the corresponding axioms that link this class to the
parent. More specifically, the data structure returned is
a set of tuples, where each tuple  is recursively defined
with fixed point:
 = (dep, axiom)

where dep is a set of dependency sets dep
, such

that each dep
is a set of unsatisfiable classes that
together cause the bug (could be a singleton set),
and axiom = associated axiom linking current class to
dependency set.

7 We note that in most cases that we have observed, unsatisfiable
classes have only one MUPS making the converse hold as well, i.e.,
for such cases, fixing the bug in the parent makes the derived class
satisfiable as well.

For example,

(A) = ({{D},=},{{C, E},})
implies the following:
 A has an equivalent class axiom relating it to its
parent dependency D. This means that D being unsatisfiable is sufficient to cause A to be unsatisfiable,
e.g., A = D (1p)
 A has a subclass axiom relating it to parents C and
E. This means both C and E should be unsatisfiable
to make A unsatisfiable, e.g., A (C E)

4.2.2.1. Asserted dependency detection: structural
tracing. This phase is used to detect dependencies
between unsatisfiable classes by analyzing the asserted
structure of the ontology. It is divided into three stages:
 Stage 1: Pre-processingGiven a class definition
(considering its equivalence and subclass axioms),
we obtain a set of all propertyvalue chains inherent
in these axioms, which terminate in a universal value
restriction () on an unsatisfiable class. Here, we
use the reasoner as the black box to report when the
class is unsatisfiable. For example, consider the class
definition A:
A = p.q.(B  (r.C  s.D))

If classes B, D are unsatisfiable, the following
propertyvalue chains (allPC) are obtained for A:

allPC = (p.q., B), (p.q.s., Do).
Note that:
 The class D has a subscript o to denote that a
union (or non-deterministic branch) exists in its
property chain (p.q.s), making this value restriction an optional requirement (to be handled later
in the post-processing stage).
 We also consider role hierarchy in constructing
propertyvalue chains, i.e., in the example above,
if the property p has ancestor properties p1, p2, we
expand the chains in our allPC set to:
((p/p1/p2).q., B), ((p/p1/p2).q.s., Do)
Universal value restrictions on a property must be
satisfied iff the property exists, i.e., the class definition entails a 1 cardinality restriction on the
property. In Stage 2 (dependency-tracing of a particular class), each time we discover the existence of

A. Kalyanpur et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3 (2005) 268293

a property, we check the allPC chains to ensure that
the associated universal restriction is satisfied. How-
ever, note that we need to determine the set of allPC
chains beforehand, since the non-localization of the
class definition makes it difficult to verify all universal restrictions during dependency tracing directly.
 Stage 2: Dependency-tracingThis is the core stage
in which a recursive set of methods are used to extract
all parent dependency unsatisfiable classes and the
adjoining axioms given the original class definition (for a pseudo code of the tracing see Appendix
B). The output contains a mixture of definite and
optional dependency cases. Note: In all the cases
below, we use the reasoner as the black box to check
if a class is unsatisfiable.

We present the basic cases of the tracing approach.
Unsatisfiable class A is derived if:

(1) A (set of) equivalent/subClass axioms relate
class A directly to unsatisfiable class B (B
becomes its parent).

(2) A (set

of)

equivalent/subClass

axioms
relate class A to an intersection set, any
of whose elements are unsatisfiable, e.g.,
A = (B C. . . D), and one of B, C, . . ., D
is unsatisfiable (any such unsatisfiable class
becomes its parent).

(3) A (set of) equivalent/subClass axioms relate
class A to a union set, all of whose elements
are unsatisfiable, e.g., A = (B C . . . D), and
all B, C, . . ., D are unsatisfiable (all such unsatisfiable classes become its parent).
(4) A (set of) equivalent/subClass axioms entail that
class A has an existential () property restriction
on an unsatisfiable class, e.g., A =(p, B) and B
is unsatisfiable (B becomes its parent).
(5) A (set of) equivalent/subClass axioms entail
that class A has a (1) cardinality restriction on a propertychain, and the universal ()
value restriction on that chain is not satisfied
(object/value of property chain becomes its par-
ent).
(6) A (set of) equivalent/subClass axioms entail
that class A has a (1) cardinality restriction
on a property, and the domain of the property
is unsatisfiable, e.g., A (1p), domain(p) = B,
and B is unsatisfiable, making it the parent of A
(similar domain check has to be made for every
ancestor property of p).

(7) A (set of) equivalent/subClass axioms entail that
class A has a (1) cardinality restriction on
an object property, and the range of its inverse
is unsatisfiable, e.q. A (1p), range(p

) = B,
and B is unsatisfiable, making it the parent of A
(similar range check has to be made for every

ancestor property of p

).

An interesting case of the algorithm occurs when
we find a pair of derived unsatisfiable classes such
that each one is marked as the parent of the other.
Here, its unclear which, if any, of the classes is the
actual parent. For example, if we have the equivalent
class axiom A B in the ontology and both classes,
A and B, are unsatisfiable, it is unclear whether A
depends on B for its unsatisfiability, or vice versa,
or if both classes depend on the axiom for their
unsatisfiability. In such cases, simple ontology modifications may be used to reveal the dependency. In the
above example, we remove the equivalence axiom
from the ontology and test the satisfiability of A and
B again using the reasoner. This gives us three possible outcomes:
(1) Both classes become satisfiable: This implies
that there is a strong interdependence between
the two classes, which makes each class unsatis-
fiable. Hence, we mark them both as non-derived
tentatively (to be pruned in the later stage).

(2) One class becomes satisfiable while the other
remains unsatisfiable: This implies that the former is derived from the latter (parent) class.

(3) Both classes stay unsatisfiable: We run the structural tracing algorithm on each class again to find
alternate distinct dependencies.

We now list a straightforward, yet

important

lemma related to structural tracing:

Lemma 1. Derived dependencies detected in this
stage satisfy Definition 1.

Proof 1. For each unsat, class A above, we find an
asserted axiom or a sets of axioms (say SAB) which
make it dependent (either by a subsumption relationship or a property-link) on another unsatisfiable class
B. Thus, we can form atleast one MUPS(A) which
contains any MUPS(B) plus the set SAB. Thus, A is
derived as per Definition 1. 

Note that the tracing approach described above
does not consider nominals or transitive property

relations. Hence, it can be considered as sound (i.e.,
it finds accurate dependencies between unsatisfiable
classes), but not complete (does not find all depen-
dencies).
 Stage 3: Post-processingIf the final dependency
set contains an optional unsatisfiable class Co, we
check if adjoining (siblings within the same nested
set) dependencies are definite, i.e., without an o tag.
If they are, we simply remove the optional dependency Co; else (if Co is the sole dependency) we
transform it to a C getting rid of the optional tag. We
do this recursively, until all the optional unsatisfiable
classes are either pruned out or transformed in the
final dependency set.

For example, if the final dependency set for a class

is:
dep = ({{Co, D},=},{{Eo} })
we reduce it to:
dep = ({{D},=},{{E},})

Optional classes are unsatisfiable class dependencies occurring in a disjunction (union set). Thus, they
are guaranteed to cause unsatisfiability if and only if
they are the sole reason for it, else they need to be
pruned out of the final dependency set.

For detailed examples of the structural tracing algo-

rithm, see [18].

4.2.2.2. Inferred dependency detection. The problem
with detecting hidden dependencies in a KB with
unsatisfiable classes is the masking of useful subsumption relationships in the TBox (since all unsatisfiable
classes are subsumed by everything). Hence, given a
TBox with unsatisfiable concepts, we consider a subsumption safe transformation as one, which modifies
the TBox by trying to get rid of all inconsistencies
while attempting to preserve the intended subsumption hierarchy as much as possible. Here, we present
only a heuristic approach that seems to work well in
practice.8

The heuristic consists of two steps:

8 An alternate approach to detect

inferred dependencies is
described in [2], wherein we remove a class and test the satisfiability of the related classes.

(1) For every axiom in the TBox that refers to a class of
the form C, where C could be atomic or complex,
we replace C by a new atomic class C

(2) Similarly, for every axiom in the TBox that refers
to a class of the form < n.p, where p is an OWL
property, we replace n.p by a new atomic class

There is an important aspect of the algorithm above
which attempts to preserve subsumption relations in
the underspecified KB, that is: every substitution is
stored in a cache, and each time a new one is made,
we check for subsumption (using a reasoner) between
satisfiable terms in the original KB, and if found, we
add corresponding relations between concepts in the
transformed KB. For example, consider a TBox with
the following three axioms:
(ax1) A = C  1.p
(ax2) B = D  2.p
(ax3) D  C

and D by D

Here, we substitute C by C

. Now,
because of the subsumption of D by C in the original
KB, we add the axiom C
to the transformed KB.
Similarly, after substituting 1.p by P1 and 2.p by
P2, due to the subsumption relation 1.p2.p, we
add the axiom P1  P2 to the transformed KB. This
way the subsumption relation A B is preserved in the
modified KB.

The motivation for the above approach is to remove
well-known causes for concept unsatisfiability, i.e.,
class complements and max cardinality violations on
a property as discussed in [1]. In fact, since both steps
are independent, we perform any one step first and test
subsumption before moving to the other.

Note that the above procedure is always sound since
the monotonic nature of the logic (OWL-DL) implies
that removing an axiom from the KB (or underspecifying it in the manner in which we have by reducing
expressivity) cannot add a new subsumption relation.
Though the procedure is incomplete because safety
cannot be guaranteed and the original subsumption
relation may get destroyed.

After applying the above transformation, we can use
the reasoner as the black box to classify the (relevant
part of) KB to detect hidden dependencies between

A. Kalyanpur et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3 (2005) 268293

concepts not caught in structural tracing.9 Moreover,
if the concepts turn out to be satisfiable, and hidden dependencies are revealed, we can use the transformations performed to pinpoint the axioms, which
cause incoherence in the core (parent) unsatisfiable
classes.

To elaborate, consider a simple TBox with two
unsatisfiable classes A, B, and the following axioms:
(ax1) A = D  p.D
(ax2) A  D
(ax3) B = C  p.C
(ax4) C  D
In this TBox, the unsatisfiability masks the subsumption of B by A (i.e., B A). If, however, we apply
step 1 of the transformation above and reduce the TBox
to a consistent form by modifying axiom ax2 to A D

  B A, and the hidden dependency
the new TBox T
is revealed. Moreover, we also know that axiom ax2 is
an integral part of the problem.

5. Performance evaluation

5.1. Preliminary glass box evaluation

For evaluating the runtime and memory performance of the glass box debugging techniques, we
applied them to a set of real-world and hand-crafted
ontologies that covered a wide range of unsatisfiable class cases, such as due to inverse or transitive
properties, GCIs, etc. The ontologies can be found at
http://www.mindswap.org/ontologies/debugging. We
processed each ontology using Swoop/Pellet and compared the performance of the normal reasoning mode
versus the debugging mode, which computed the clash
and sets of support. In all cases, the algorithm returned
sound and complete results, i.e., the exact sets of support axioms containing the contradiction for the unsatisfiable class were obtained.

Key results of our evaluation are summarized in the

table below:

9 Note that in general, if C, D are unsatisfiable classes in an ontol-
ogy, and a fragment of the ontology (set of axioms) entails C D,
then C is derived from D based on Definition 1 (see Lemma 1).

Ontology/
expressivity

koala.owl/
ALCON(D)

TNorm/TDebug

MExpTable

No. of classes/
unsatisfiable
classes

21/3

40/40 ms

780 kB

mad-cows.owl/

54/1

301/330 ms

1.029 MB

ALCHION(D)

sweet-

jpl.owl/
ALCHIO(D)
tambis.owl/

university.
owl/SION(D)

1391/1

16.453/16.895 s 8.84 MB

395/144

4366/4416 ms

3.65 MB

28/8

70/72 ms

786 kB

In the table, TNorm/TDebug corresponds to the time
taken for Pellet to process the entire ontology (i.e.,
check satisfiability of each class and compute the
subsumption hierarchy) in the normal/debug modes,
respectively, and MExpTable corresponds to the approximate memory consumption of the class ExplanationTable that is used to track and store the source
axioms. As these preliminary results show, dependency tracking in Pellet based on our algorithm introduces some memory overhead but only marginally
increases the running time of the normal reasoning
procedures.

5.2. Preliminary black box evaluation

For black box debugging evaluation, we decided to
use the Tambis OWL ontology since it is expressive
(SHIN), moderately sized (395 classes) and contains
a large number of unsatisfiable classes (144). Many
of the unsatisfiable classes depend in simple ways on
other unsatisfiable classes, so that a brute force going
down the list correcting each class in turn is unlikely to
produce correct results, or at best, will be pointlessly
exhausting. In one case, three changes repaired over
seventy other unsatisfiable classes. Given the highly
non-local effects of assertions in a logic like OWL, it
is not sufficient to take on defects in isolation.

We implemented the black box techniques in
Swoop, and carried out the analysis and debugging
of Tambis. Running the structural tracing algorithm
on Tambis identified 111 derived classes with at least
one parent dependency, and 33 classes with no parent
dependencies (potential root classes) in approximately
20 ms. This was a significant result, the problem space

Fig. 8. Debugging Tambis: identifying Root/Parent and derived unsatisfiable classes. Note that the time taken for the structural tracing was less
than a second.

was pruned by more than 75% enabling us to direct our
attention on a narrow set of unsatisfiabile classes, and
moreover, for each unsatisfiabile class, we obtained the
dependency relation (via axioms) leading to its corresponding parents, which were presented in the Swoop
UI.

Out of the remaining 33 potential root classes,
we applied the inferred dependency detection algorithm and uncovered equivalence between all of them
(Fig. 8).

This was both, a surprising and interesting result,
and due to the fact that all 33 classes shared the
same structure (defined equivalent to the same intersection set) out of which 3 were asserted as mutually
disjoint in the ontology thus causing the contradic-
tion; while the remaining 30 classes were inferred
to be equivalent to the above 3 classes making them
unsatisfiable as well. In this case, not only were
hidden dependencies detected, but also the disjoint
axioms causing the incoherence were obtained as well,
exposing the classes whose definition contained the

axioms (in this case, the classes metal, non-metal,
metalloid).

As a result, we now have an efficient iterative procedure to remove all the unsatisfiability bugs in the
ontology: at each point, we focus solely on fixing all the
root classes (if any), or top-level parent classes identified by the pinpointed axioms, which effectively fixes a
large set of directly derived class bugs. However, doing
so might reveal additional contradictions and a new set
of unsatisfiable classes. We then use the dependency
detecting algorithm again to obtain new potential roots
(with problematic axioms) and repeat the fixing process iteratively till no unsatisfiable classes are left in
the ontology.

6. Usability evaluation

In order to determine the practical use and efficiency of the debugging features implemented in
Swoop/Pellet, we conducted a small usability study as
follows:

A. Kalyanpur et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3 (2005) 268293

(1) We selected twelve subjects in all with at least
9 months of experience with OWL and with an
understanding of description logic reasoning that
varied greatly (novices to experts).

(2) Each subject received a 2030 min orientation that
covered:
 an overview of the semantic errors found in
OWL ontologies (using examples of unsatisfiable classes);
 a brief tutorial of Swoop, demonstrating its key
 a detailed walkthrough of the glass and black
box debugging support in Swoop using a set of
toy ontologies.

browsing, editing, and search features;

(3) The 12 subjects were randomly divided into four

groups of three subjects each:
(a) Group 1: Subjects in this group received no
debugging support at all, i.e., only a list of
unsatisfiable classes in the ontology was displayed by the reasoner.

(b) Group 2: Subjects in this group received only
glass box debugging support, i.e., the clash
information and sets of support axioms for an
unsatisfiable class were displayed.

(c) Group 3: Subjects in this group received
only black box debugging support, i.e., the
root/derived unsatisfiable classes were displayed along with the facility for classexpression highlighting and reasoning.10

(d) Group 4: Subjects in this group received both
clash/SOS and root/derived debugging sup-
port.

(4) Having formed the groups, each subject was
given three erroneous ontologiesUniver-
sity.owl, Sweet-JPL.owl and mini-
Tambis.owl (in random order), any of which the
subject had not seen before. The subject was asked
to debug the ontologies in Swoop (independently)
using only the features assigned to the group the
subject belonged to. The following guidelines were
observed during the debugging process:
 The subject was given 20 min (maximum) to
debug an ontology. He/she was free to stop the
debugging process at any time.

10 The latter can be considered as a black box debugging service
since the reasoner is used as an oracle to extract useful inferences
about specific class-expressions.

 While debugging any unsatisfiable class, the
subject was asked to write down a brief explanation of the contradiction for that class (in his/her
own words) based on the understanding of the
problem. In addition, the subject was asked to
suggest a likely fix for the problem where pos-
sible.
 The tool automatically counted the number of
entity definitions viewed, and the changes made
to the ontology during the entire debugging pro-
cess, both of which we considered as key sub-
tasks.

(5) Having obtained the times taken by a subject for
debugging each of the three ontologies, we took
the average of the times (for the group) in order to
nullify the expertise and skill factor of the subject
(note that the subjects were randomly assigned to
the groups as mentioned earlier).

(6) Finally, after working on all three ontologies, the
subject was handed a questionnaire to elicit feedback on the entire debugging experience using
Swoop.

Key properties of the ontologies used in the study

were:

Ontology

1. University.owl
2. Sweet-JPL.owl
3. miniTambis.owl

Total
classes

Unsatisfiable
classes

Root/
derived

5/3
1/
5/25

Our hypothesis was as follows:

Hypothesis 1. The clash information and sets-of-
support (SOS) axioms provided is better than no support for all the erroneous ontologies, i.e., the subject will take less time to understand and fix the
errors correctly using the clash/SOS (in this case computed using the glass box technique) than without
any debugging support. The reason for this is that
the information would help pinpoint and illustrate
the source of the contradiction for the unsatisfiable
class.

Hypothesis 2. For a relatively small no. of unsatisfiable classes (i.e., ontologies 1 and 2), the clash/SOS
information will outperform both, the root/derived
information (in this case computed using the black box
technique) and the no support, and perform not too

Fig. 9. Results of the debugging usability study.

worse than the full-debug support. The reason for this
is that the subject could potentially distinguish the root
from the derived classes by manually inspecting the
sets of support for each class, thus reducing the impact
of automatically identifying them.

Hypothesis 3. For a large no. of unsatisfiable classes
with different roots (i.e., ontology 3) the root/derived
debugging support will match the performance of
the clash/SOS information, and additionally, the fulldebug support will be clearly better than either of the
two. The reason for this is that manually discovering
the root/derived classes would often be hard and timeconsuming in such cases, and the black box automated
detection technique would help narrow down the problem space tremendously.

The results of the usability study are summarized
in the graph in Fig. 9. The graph displays the average
time taken (min) per group to debug all the errors for
each of the three ontologies given (Note: F represents
a failure to debug the error).

As seen from the graph,

the statistical results
obtained are in agreement with Hypothesis 1, i.e., a
two-tailed T-test shows that debugging with clash/SOS
is significantly better than debugging without it for
p 0.01. While the timings for the ontologies are in
agreement with Hypotheses 2 and 3, given the small
size of the study, a measure of the statistical results
was not significant for verifying those hypothesis. We
plan to conduct a more extensive evaluation to fully
justify them.

For University.owl, all subjects were able to
identify the erroneous axiom(s) for each of the unsat-

isfiable classes within the time period given, how-
ever, only 1 subject in normal/root-derived (black box)
mode was able to understand the cause of the problem,
whereas, 2/3 using the clash/SOS (glass box) and 3/3
using the full-debug mode were able to understand and
explain the problem correctly. Also, the time taken to
fix all the errors using the full-debug mode was approximately half of that taken using the normal-mode.

In the case of Sweet-JPL.owl, without support
axioms no subject was able to understand the cause of
the error due to the highly non-local interactions in the
large ontology, whereas, using the axioms, each subject
took under 5 min to understand and fix the problem
correctly.

Interestingly,

the black box support performed
nearly similar to the glass box in the case of mini-
Tambis.owl since subjects found it easier to debug
the roots identified by the black box even without the
sets of support, than to discover the roots without the
black box and with the sets of support, given the large
number of unsatisfiable classes. Also, for this ontol-
ogy, the subjects in the normal mode fixed only 2/3
roots in the time period given, i.e., they could not fully
complete the debugging.

We learnt some useful lessons based on our observations of the debugging process and the feedback given
by the subjects:
 For Group 1No-debug mode:

 3/3 subjects rated the hypertextual navigation
(with back/next history) as the most useful feature for understanding relationships and causes of
errors in the ontology.

A. Kalyanpur et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3 (2005) 268293

the most useful feature.

 2/3 subjects found ontology changes immensely
useful to identify erroneous axioms by using a
trial-and-error strategy.
 The Show References search feature was never
used by any of the subjects. Based on their com-
ments, it seemed that they were unclear about its
use and significance. Interestingly, a subject in
Group 3 found this feature very helpful, implying
that the feature either supports a different debugging style (to that of the authors in this mode) or
requires better presentation.
 For Group 2Clash/SOS mode (only glass box):
 3/3 subjects rated the sets of support axioms as
 2/3 subjects felt

that a proof-style layout of
the support axioms with intermediate inferences
shown as well would help explain the problem
better.
 Overall, six subjects were exposed to the glass
box (three from this group and three using the
full-debug mode), and they were divided on the
significance of the clash information. While half
the subjects used the clash information to pinpoint
relevant components of the support axioms, the
other half found the information poorly presented
and redundant given the support axioms, pointing
us to a definite area of improvement.
 For Group 3Root/derived mode (only black box):
 1/3 subject used the Show-References feature
extensively to aid debugging, especially for mini-
Tambis.owl, where discovering a commonly used
property restriction helped understand the source
of the contradiction for a set of unsatisfiable
classes.
 1/3 subject felt that the class-expression (CE) support needed to be made more effective by allowing
arbitrary queries on CEs.
 2/3 subjects suggested displaying the number of
derived dependencies that arise from each root to
highlight the more significant roots.

 For Group 4Full-debug mode:

 3/3 subjects felt that it was the combination of
the clash/SOS presentation and the root/derived
identification and not one specific feature that was
useful to debug all errors in the ontology.

Overall, the response of the subjects in the study
was very encouraging. Many relative newcomers to

OWL and description logic were impressed by the
fact that they were able to correctly fix all the errors
in ontologies, which they had not seen before within
the specified time period. Experts in the field who had
real-world experience in OWL ontology modeling and
manual debugging were surprised at how easy the task
of debugging was made for them.

7. Future work

7.1. Diagnosing Inconsistent KBs

As noted in Section 2, an inconsistent ontology is, on
the face of it, very difficult for a reasoner to do further
work with. Since anything at all follows from a contra-
diction, reasoner results breakdown on an inconsistent
KB. In Fig. 10, we can see how the naive application of
the reasoner to an inconsistent ontology marks all the
classes as unsatisfiable, even though, in this example,
no class is in itself unsatisfiable.

Many of the techniques discussed in the prior section
are, in fact, applicable to the diagnosis of inconsistent KBs, with a few slight twists. This should be no
surprise as unsatisfiability detection is performed by
attempting to generate an inconsistent KB. Thus, the
glass box techniques for diagnosing unsatisfiable concepts in principle work to help diagnose inconsistent
KBs.

First, we provide a categorization of the different

kind of reasons for inconsistent KBs:

(1) Inconsistency of assertions about

individuals:
There are no unsatisfiable classes in the ontology
but there are conflicting assertions about one indi-
vidual, e.g., an individual is asserted to belong to
two disjoint classes or an individual has a cardinality restriction but related to more individuals.

(2) Individuals related to unsatisfiable classes: There
is an unsatisfiable class description and one individual is asserted to belong to that class or has an
existential restriction to the unsatisfiable.

(3) Defects in class axioms involving nominals: It
might be the case that
inconsistency is not
directly caused by type or property assertions, i.e.,
ABox assertions, but caused by class axioms that
involve nominals, i.e., TBox axioms. Nominals are
simply individuals mentioned in owl:oneOf and

Fig. 10. When the ontology is inconsistent due to an assertion about an individual, all the classes end up inconsistent because reasoner can infer
anything from an inconsistent ontology.

owl:hasValue constructs. As an example, consider
the following set of axioms:

MyFavoriteColor = {Blue}
PrimaryColors = {Red, Blue, Yel-
low}
MyFavoriteColorPrimaryColors
These axioms obviously cause an inconsistency
because the enumerated MyFavoriteColor
and PrimaryColors share one element, i.e.,
individual named Blue, but they are still defined
to be disjoint. The final effect is similar as defining
an individual to belong to an unsatisfiable concept
but there is no direct type assertion in the ontology.

Depending on the type of inconsistency there are different options to be taken. For the first type of inconsis-

tency, clash information would point to the individual
that contains the problem (as already seen in Fig. 10)
and the details pane for the individual would flag the
inconsistent concept expression. For the second type of
inconsistency, removing the assertions about individuals would immediately reveal the unsatisfiable concept
because all the other classes would now be satisfiable.
Of course, there may be more than one defect in the
ontology and each of these inconsistencies need to be
solved separately in order to fix the overall problem.

The third type of inconsistency is very different in
nature because even removing all the assertions about
individuals from the reasoner would not solve the prob-
lem. It is required to get rid of the problematic class
axioms in order to make the ontology consistent. In this
case, we need to make use of the glass box techniques to

A. Kalyanpur et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3 (2005) 268293

Fig. 11. Collaborative debugging and repair using Annotea.

find the set of supporting axioms for the problem and
try to fix the problem by examining this information
along with the asserted facts.

7.2. Exploring remedies

Thus, far we have focused on bug detection and diag-
nosis, that is, the initial information gathering phase of
the debugging process. That phase is focused on helping the modeler understand the problem. Once there is
understanding, then the modeler needs to take action.
However, often there are a number of possible alternative actions (or sets of actions) that would correct
the bug, or, in spite of all the debugging information supplied by the system, the source of the problem
is unclear. At this point, a programmer will tend to
start experimenting with possible changes. Part of good
debugging support for OWL ontologies is making such
experimentation safe, easy, and effective.

Swoop has an ontology versioning feature that supports ad hoc undo/redo of changes (with logging) coupled with the ability to checkpoint and archive different

ontology versions. Such a feature can play a vital role
in ontology debugging. Consider the scenario in which
a user starts with an inconsistent ontology version, performs a set of changes in succession (undoing and
redoing as necessary), in order to reach a final consistent version. Here, the change logs give a direct
pointer to the source of inconsistency. The checkpointing allows the user to switch between versions easily
exploring different modeling alternatives.

Alternately, if the user has two different ontology
versions, one consistent and the other inconsistent,
a diff between the versions can be performed using
Swoops Concise Format Renderer in order to determine possible change paths between the versions. By
examining these change paths, and noting the common
bug-producing changes, users can find and eliminate
erroneous entity-definitions and axioms in the ontol-
ogy.

Once a series of changes has proven effective in
removing the defect and seems sensible, the modeler can use Swoops integrated Annotea [19] client
to publish the set of changes plus a commentary (see

Fig. 11). Other subscribers to the Annotea store can
see these changes and commentary in context they were
made, apply the changes to see their effect, and publish
responses. These exchanges persist, providing a repository of real cases for subsequent modelers to study.

Finally, in Swoop we have a provision to store and
compare OWL entities via the Comparator panel. Snapshots of Items can be added to this placeholder at any
time and that view will persist there until the user
decides to remove or replace them at a later stage. Upon
adding an entity, a time-stamped snapshot of it is saved
(with hyperlinks), thus providing a reference point for
future tasks. The significance of the Comparator was
amply demonstrated in Section 3 (see Fig. 3) where
we studied the unsatisfiability bug in the class Koala
by saving snapshots of related classes and expressions
in the Comparator, and browsing them to identify the
exact cause for the bug.

8. Conclusion

In this paper, we have presented a suite of features integrated into the OWL ontology browser and
editor  Swoop, and the description logic tableaux reasoner  Pellet, designed to aid modelers in debugging
inconsistency related errors in their ontologies. Key
features include the detection of clash/sets of support
axioms responsible for an unsatisfiable class, and the
identification of root/derived unsatisfiable classes. Two
orthogonal debugging techniques are used for these
featuresglass box and black box, the former optimized to compute the clash/SOS directly, while the
latter better suitted to identify dependencies in a large
number of unsatisfiable classes.

We are, in general, focused on the whole user expe-
rience, and the reactions from the user base in the
conducted usability-study has been very encouraging.
Moving around the ontology should be trivial and the
hypertextual navigation supports thisa feature unanimously welcomed by all users in the study. Also,
instead of shifting into a completely separate debugging pane, augmenting the existing display with additional cues allowed users to follow the problem using
familiar techniques. We made alterations both easy and
safe, allowing users to experiment more freely with
expressions and axioms in the ontology. Finally, users
felt that the debugging features not only helped them

understand problems in the tested ontologies, but also
gave them an insight into more generic and commonly
misunderstood outcomes of ontology modeling (such
as proper usage of equivalence versus subsumption,
intersection versus union, etc.).

We intend to continue extending and improving the
glass and black box techniques to debug all types of
semantic defects in OWL-DL ontologies, and where
possible, exploring strategies to handle modeling/style
defects. The results will be validated by conducting an
extensive evaluation on real-world ontologies, coupled
with more in-depth usability studies.

Our experience has been that the process of debugging can assist the understanding of an ontology, both
by providing motivation and by providing guidance.
For example, the Tambis ontology is large, complex,
and describes an unfamiliar domain. But each author
quickly learned quite a bit about the ontology (and
even of the domain) by trying to understand the various unsatisfiabilities. This suggests that using similar
techniques for identifying and displaying dependencies
would be effective in helping users explore and come
to understand new ontologies.

Acknowledgments

We would like to thank all the participants of the
usability study and in particular, Jennifer Golbeck, who
helped us with the setup, design and analysis of the
experiment.

This work was completed with funding from Fujitsu
Laboratories of AmericaCollege Park, Lockheed
Martin Advanced Technology Laboratory, NTT Corp.,
Kevric Corp., SAIC, National Science Foundation,
National Geospatial-Intelligence Agency, DARPA, US
Army Research Laboratory, NIST, and other DoD
sources.

Appendix A

Tableaux Reasoning Procedure with tracing

integrated:11

11 This is a simplified version of the algorithm without tracing support for inverse/transitive roles, role hierarchy etc. However, it is
possible to directly extend the principle idea behind the algorithm to
cover those cases.

A. Kalyanpur et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3 (2005) 268293

(1) Pre-processing:

(a) Normalization:

(i) for each axiom (Ax) in the OWL Ontology,

 normalize Ax and store reference between Ax
and norm(Ax) in the Explanation-Table

(b) Absorption:

(i) for each GCI C D in the OWL Ontology,

 create GCI set G = {D, C}
 obtain axiom-set Sax corresponding to G from
Explanation-Table
 if G can absorb into primitive definition A B,
then create new partial definition A G

(G
is GCI corresponding to current G) and store reference between
this definition and Sax in Explanation-Table

 if C, C G is replaced by E,

then Sax = Sax+ axioms responsible for
C/C E

 if G cannot be absorbed,

then store reference between G and Sax in
Explanation-Table
(i) for each unabsorbed GCI C D,

(c) Internalization:

Explanation-Table

 get axiom-set Sax corresponding to GCI from
 create conjunct corresponding to GCI: (DC)
 build Universal Concept
(UC) = UC {DC)
 store reference between conjunct and Sax in

Explanation-Table

(d) Dependency Maintenance Initialization:

(i) create map depends for each node x in the tableaux
(step 2 below), with (key, value) pairs:

key := label added to x
value := dependency set DS,
{branch-no|| source-axioms}
(below we refer to the axioms component directly

as DS(x, label)axioms

(ii) also create DS for each edge R(x, y) added to the

tableaux

(2) Tableaux Expansion to check Satisfiability of class C:
(a) create individual node x corresponding to C, i.e.,

L(x) = {C}

(b) while either clash found in deterministic branch or

tableaux is complete,

(i) apply unfolding rule to x, i.e. add concept label D,
 DS(x, D)axioms += axioms responsible for adding

D to L(x) (obtained from Explanation-Table)

(ii) apply someValues rule to x, i.e. add edge label R

from node x to node y,
 DS(R(x, y))axioms += axioms responsible for
adding edge x y (obtained from
Explanation-Table)

completion rules. . .)

(iii) (. . .similar tracing while applying other
(c) if atomic clash is detected, i.e. both A, A L(x)
then return sets-of-support = nodex:DS(A)axioms
 nodex:DS(A)axioms

Appendix B

Structural Tracing Pseudo-code (Stage 2):

function traceClass (C) return parent dependency dep:

(1)
(2)
(3)
(4)

if (C is satisfiable) return ;
dep = ;
if (C is atomic) dep += {C};
else (C is complex),
(a) if C is of form (C0  C1  . . .Cn),

for each unsatisfiable element Ci of the intersection,

if (Ci is atomic), dep += {Ci};
else dep += traceClass(C);
(b) if C is of form (C0  C1  . . .Cn),

= ,

dep
for each element Ci of the union,

if (Ci is satisfiable), dep

if (Ci is atomic), dep

else dep

dep += dep

+= traceClass(C);

+= {Ci};

= , break;

(c) if C is of form R.D,
propChain += {R};
if (D is unsatisfiable),

if (D is atomic) dep += {D};
else dep += traceClass(D);

(d) if (D s.t. DR


.C) and (D is unsatisfiable),

if (D is atomic) dep += {D};
else dep += traceClass (D);

(e) if C is of form 1.R, or of form R.{I}

(i) propChain += {R};
(ii) if PCchain (pre-computed) starts with propChain,

dep += terminal class (value) of PCchain;
(iii) if (R has domain E) and (E is unsatisfiable),

if (E is atomic), dep += {E};
else dep += traceClass(E);

(repeat steps (iiii) for equivalent and super-

properties of R)
(iv) if R has inverse Q,

if (Q has domain F) and (F is unsatisfiable),

if (F is atomic), dep += {F};
else dep += traceClass(F);

(repeat step for equivalent and super-properties of Q)

(5)

for each equivalent class D of C,

dep += traceClass(D);

(6)

for each superclass D of C,

dep += traceClass(D);

(7)

return dep;
