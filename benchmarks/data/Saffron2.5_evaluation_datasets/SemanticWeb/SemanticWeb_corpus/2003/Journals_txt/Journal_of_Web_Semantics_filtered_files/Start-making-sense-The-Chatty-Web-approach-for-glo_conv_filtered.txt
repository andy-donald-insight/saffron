Web Semantics: Science, Services and Agents

on the World Wide Web 1 (2003) 89114

Start making sense: The Chatty Web approach

for global semantic agreements


Karl Aberer

, Philippe Cudre-Mauroux, Manfred Hauswirth

School of Computer and Communication Sciences, Ecole Polytechnique Federale de Lausanne (EPFL), CH-1015 Lausanne, Switzerland

Received 23 June 2003; received in revised form 31 July 2003; accepted 9 September 2003

Abstract

This paper describes a novel approach for obtaining semantic interoperability in a bottomup, semi-automatic manner without
relying on pre-existing, global semantic models. We assume that large amounts of data exist that have been organized and
annotated according to local schemas. Seeing semantics as a form of agreement, our approach enables the participating data
sources to incrementally develop global agreements in an evolutionary and completely decentralized process that solely relies
on pair-wise, local interactions.
 2003 Elsevier B.V. All rights reserved.

Keywords: Semantic integration; Semantic agreements; Self-organization; P2P systems

1. Introduction

The recent success of peer-to-peer (P2P) systems
and the initiatives to create the Semantic Web have
emphasized again a key problem in information sys-
tems: the lack of semantic interoperability. Semantic
interoperability is a crucial element for making distributed information systems usable. It is prerequisite
for structured, distributed search and data exchange
and provides the foundations for higher level (web)
services and processing.

For example, the technologies that are currently in
place for P2P file sharing systems either impose a simple semantic structure a priori (e.g., Napster, Kazaa)


Corresponding author. Tel.: +41-21-693-4679;

fax: +41-21-693-8115.

E-mail address: karl.aberer@epfl.ch (K. Aberer).

and leave the burden of semantic annotation to the
user, or do not address the issue of semantics at all
(e.g., the current web, Gnutella, Freenet) but simply
support a semantically unstructured data representation and leave the burden of making sense to the
skills of the user, e.g., by providing pseudo-structured
file names such as Enterprise-2x03-Mine-Field that
encapsulate very simple semantics.

Also, classical attempts to make information resources semantically interoperable, in particular in
the domain of database integration, do not scale well
to global information systems, such as P2P systems.
Despite a large number of approaches and concepts,
such as federated databases, the mediator concept
[32], or ontology-based information integration approaches [12,24], practically engineered solutions
are still frequently hard-coded and require substantial support from human experts. A typical example

1570-8268/$  see front matter  2003 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2003.09.001

K. Aberer et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1 (2003) 89114

of such systems are domain-specific portals such as
CiteSeer (http://www.researchindex.com, publication
data), SRS (srs.ebi.ac.uk, biology) or streetprices.com
(e-commerce). They integrate data sources on the Internet and store them in a central warehouse. The data
is converted to a common schema which usually is of
simple to medium complexity. This approach adopts
a simple form of wrapper-mediator architecture and
typically requires substantial development efforts for
the automatic or semi-automatic generation of mappings from the data sources into the global schema.

In the context of the Semantic Web, a major effort
is devoted to the provision of machine processable
semantics expressed in meta-models such as RDF, OIL
[7], OWL [5], DAML+OIL [11] and TRIPLE [28] and
based on shared ontologies. Still, these approaches rely
on common ontologies, to which existing information
sources can be related by proper annotation. This is an
extremely important development, but its success will
heavily rely on the wide standardization and adoption
of common ontologies or schemas.

The advent of P2P systems, however, introduces a
different view on the problem of semantic interoperability by taking a social perspective which relies on
self-organization heavily. We argue that we can see
the emerging P2P paradigm as an opportunity to improve semantic interoperability rather than as a threat,
in particular in revealing new possibilities on how
semantic agreements can be achieved. This motivated
us to look at the problem from a different perspective
and has inspired the approach presented in this paper.
In the following, we abstract from the underlying
infrastructure such as federated databases, web sites
or P2P systems and regard these systems as graphs
of interconnected data sources. For simplicity, but
without constraining the general applicability of the
presented concepts, we denote these data sources as
peers. Each peer offers data which are organized according to some schema expressed in a data model,
e.g., relational, XML, or RDF. Among the peers, communication is supported via suitable protocols and
architectures, for example, HTTP, SOAP or JXTA.

The first issue to observe is that semantic interoperability is always based on some form of agreement.
Ontology-oriented approaches in the Semantic Web
represent this agreement explicitly through a shared
ontology. In our approach, no explicit representation
of a globally shared agreement will be required, but

agreements are implicit and result from the way our
(social) mechanism works.

We impose a modest requirement on establishing
agreements by assuming the existence of local agreements provided as partial translations between different schemas, i.e., agreements established in a P2P
manner. These agreements will have to be established
in a manual or semi-automatic way since in the near
future we do not expect to be able to fully automate the
process of establishing semantic translations even lo-
cally. However, a rich set of tools is getting available to
support this [18,23,27]. Establishing local agreements
is a less challenging task than establishing global
agreements by means of global schemas or shared
ontologies. Once such agreements exist, we establish
on-demand relationships among schemas of different
information systems that are sufficient to satisfy information processing needs such as distributed search.

We briefly highlight two of the application scenarios
that convinced us (besides the obvious applicability
for information exchange on the web) that enabling
semantic interoperability in a bottomup way driven
by the participants is valid and applicable: introduction
of meta-data support in P2P applications and support
for federating existing, loosely-coupled databases.

Imposing a global schema for describing data in
P2P systems is almost impossible, due to the decentralization properties of such systems. It would
not work unless all users conscientiously follow the
global schema. Here, our approach would fit well:
We let users introduce their own schemas which best
meet their requirements. By exchanging translations
between these schemas, the peers can incrementally
come up with an implicit consensus schema which
gradually improves the global search capabilities of
the P2P system. This approach is orthogonal to the existing P2P systems and could be introduced basically
into all of them.

The situation is somewhat similar for federating
existing loosely-coupled databases. Such large collections of data exist, for example, for biological or
genomic databases. Each database has a predefined
schema and possibly some translations may already
be defined between the schemas, for example data
import/export facilities. However, global search, i.e.,
propagation of queries among the set of databases,
is usually not provided and if this feature exists, it is
usually done in an ad hoc, non-systematic way, i.e.,

not reusable and not automated. The more complex
these database schemas get, the less likely it is that
the schemas partially overlap and the harder it gets to
increasingly generate translations automatically.

Adopting a P2P approach is (usually) motivated by
solving scalability problems. Which scalability problem are we looking at? Considering the two examples
given, we observe that in both cases we face a large
number of different schemas, where the interoperable
schemas themselves are of modest complexity. In the
case of document sharing (e.g., music files or images)
the schemas are used to annotate the media content
and are typically fairly simple. This is even true for
media annotation in more professional settings, such
as with MPEG-7 [19]. In the case of scientific data
sharing the individual schemas may be fairly com-
plex, however, the shared views typically are much
simpler as the databases are very specialized on a specific problem and the semantic intersection among
the databases is fairly small. Thus our work aims at
solutions that scale well in large numbers of schemas
and participants. We believe this is a critical and very
realistic problem in making todays web semantically
interoperable. Our work is orthogonal to efforts in ontology engineering which are devoted to the management of one or a few large and complex ontologies,
which scale well in large numbers of concepts and
rules and where social interaction occurs as part of
collaborative ontology engineering [30].

In our approach, we build on the principle of gossiping that has been successfully applied for creating
useful global behaviors in P2P systems. In any P2P
system, search requests are routed in a network of
interconnected information systems. We extend the
operation of these systems as follows: when different
schemas are involved, local mappings are used to
further distribute a search request into other semantic
domains.

For simplicity but without constraining general
applicability, we will limit the following discussions
to the processing of search requests. The quality of
search results in a gossiping-based approach depends
clearly on the quality of the local translations in the
translation graph. Our fundamental assumption is
that these translations may be incorrect. Thus, our
agreement construction mechanisms try to determine
which translations can be trusted and which not and
take this into account to guide the search process.

A main contribution of the paper is to identify
different methods that can be applied to estimate the
quality of local
translations from information obtained from the peer network. We elaborate the details
of each of these methods for a simple data model,
that is yet expressive enough to cover many practical
cases (Section 3). This model is similar to other data
models currently considered for semantic annotation
in P2P architectures [15]. The methods that will be
introduced are as follows:

1. A syntactic analysis of search queries after transformations have been applied in order to determine
the potential information-loss incurred through the
transformation. Here, we analyze to which degree
query constituents essential for obtaining useful
query results are preserved during transformation
(Section 4).

2. A semantic analysis of composite translations
along cycles in the translation graph, in order to
determine the level of agreement that peers achieve
throughout the cycle. Here, we analyze whether
cyclic translations preserve semantics. If concepts
are not preserved in a cyclic translation we assume
semantic confusion has occurred (Section 5.1).

3. A semantic analysis of search results obtained
through composite translation. We assume that
structured data is used to annotate media content
and that peers can classify their documents both
using content analysis and meta-data-based classification rules. From that peers derive to which
degree transformed meta-data annotations match
the actual content and thus how reliable the translations were (Section 5.2).

The information obtained by applying these different analyses is then used to direct searches in a
network of semantically heterogeneous information
sources (e.g., on top of a P2P network).

Finally, we give first results that take our approach
one step further. Rather than only guiding searches
by the results obtained from analyzing the transfor-
mations, we also modify the translations in an automatic manner using this information (Section 7).
Thus, we make a step towards a self-learning network
of peers automatically establishing semantic interop-
erability. We give experimental results that demonstrate how the different kinds of semantic analyses of
mappings interact with the modification of incorrect

K. Aberer et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1 (2003) 89114

translations and how this approach scales in different
parameters.

We believe that

this radically new approach to
semantic interoperability shifts the attention from
problems that are inherently difficult to solve in an automated manner at the global level (How do humans
interpret information models in terms of real world
concepts?), to a problem that leaves vast opportunities for automated processing and for increasing
the value of existing information sources, namely the
processing of existing local semantic relationships in
order to raise the level of their use from local to global
semantic interoperability. The remaining problem of
establishing semantic interoperability at a local level
seems to be much easier to tackle once an approach
such as ours is in place.

2. Overview

Before delving into the technical details, this section
provides an informal overview of our approach and of
the paper.

We assume that there exists a communication facility among the participants that enables sending and receiving of information, i.e., queries, data, and schema
information. This assumption does not constrain the
approach, but emphasizes that it is independent of
the system it is applied to. The underlying system
could be a P2P system, a federated database system,
the web, or any other system of information sources
communicating via some communication protocol.
We denote the participants as peers abstracting from
the concrete underlying system.

In the system, groups of peers may have agreed
on common semantics, i.e., a common schema. We
denote these groups as semantic neighborhoods. The
size of a neighborhood may range from a single individual peer up to any number. If two peers located in
two disjoint neighborhoods meet, they can exchange
their schemas and provide translations between them.
How peers meet and how they exchange this information depends on the underlying system but does not
concern our approach. We assume that skilled experts
supported by appropriate translation tools provide the
translations. Later, we will also devise possibilities of
how our approach might be used to automatically improve the quality of pre-existing translations by modifying them. The direction of the translation and the

p5

p1

p7

p6

p2

p3

p4

Fig. 1. Translation graph among peers.

peer providing a translation are not necessarily corre-
lated. For instance, peers p1 and p2 might both provide
a translation from schema Sp
to schema Sp2, and

they may exchange this translation upon discretion.
During the life-time of the system, each peer has the
possibility to learn about existing translations and add
new ones. This means that a directed graph of translations as shown in Fig. 1 will be built between the peers
along with the normal operation of the system (e.g.,
query processing and forwarding in a P2P system).

This translation graph has two interesting proper-
ties: (1) based on the already existing translations and
the ability to learn about existing translations, queries
can be propagated to peers for which no direct translation link exists by means of transitivity, for example
p4  p5  p2  p4  p2 and (2) the graph has
cycles, for example p4  p5  p2  p4. We call
(1) semantic gossiping. (2) gives us the possibility to
assess the degree of semantic agreement along a cy-
cle, i.e., to measure the quality of the translations and
the degree of semantic agreement in a community.

In such a system, we expect peers to perform several
tasks: (1) upon receiving a query, a peer has to decide
where to forward the query to, based on a set of criteria
that will be introduced; (2) upon receiving results or
feedback along translation cycles, it has to analyze
the quality of the results at the schema and at the
data level and adjust its criteria accordingly; and (3)
update its view of the overall semantic agreement by
modifying its query forwarding criteria or by adjusting
the translations themselves.

The criteria to assess the quality of translations
which in turn is a measure of the degree of semantic agreementcan be categorized as context-inde-
pendent and context-dependent. Context-independent
criteria, discussed in Section 4, are syntactic in nature and relate only to the transformed query and to
the required translation. We introduce the notion of

syntactic similarity to analyze the extent to which a
query is preserved after transformation.

Context-dependent criteria, which are discussed in
Section 5, relate to the degree of agreement that can
be achieved among different peers upon specific trans-
lations. Such degrees of agreement may be computed
using feedback mechanisms. We will introduce two
such feedback mechanisms, namely cycles appearing
in the translation graph and results returned by different peers. This means that a peer will locally obtain
both returned queries and data through multiple feedback cycles. In case a disagreement is detected (e.g.,
a wrong attribute mapping at the schema level or a
concept mismatch at the content level), the peer has to
suspect that at least some of the translations involved
in the cycle were incorrect, including the translation
it has used itself to propagate the query. Even if an
agreement is detected, it is not clear whether this is
not accidentally the result of compensating mapping
errors along a cycle. Thus, analyses are required that
assess which are the most probable sources of errors
along cycles, to what extent the own translation can
be trusted and therefore of how to use these translations in future routing decisions. At a global level,
we can view the problem as follows: The translations
between domains of semantic homogeneity (same
schemas) form a directed graph. Within that directed
graph we find cycles. Each cycle allows to return a
query to its originator which in turn can make the
analysis described above.

Each of these criteria is applied to the transformed
queries and results in a feature vector. The decision
whether or not to forward a query using a translation
link then is based on evaluating these feature vec-
tors. The details of the query forwarding process are
provided in Section 6.

Assuming all the peers implement this approach,
we expect the network to converge to a state where
a query is only forwarded to the peers most-likely
understanding it, where the correct translations are
increasingly reinforced by adapting the per-hop forwarding behaviors of the peers and where incorrect
translations are rectified. Implicitly, this is a state
where a best possible global agreement on the semantics of the different schemas has been reached.
To demonstrate this, we present experimental results
where semantic agreement is reached in a network of
partially erroneous translations in Section 7.

3. The model

3.1. The data model

We assume that each peer p is maintaining its
database DBp according to a schema Sp. The peers
are able to identify their schema, either by explicitly
storing it or by keeping a pseudo unique schema iden-
tifier, obtained for example by hashing. The schema
consists of a single relational table R, i.e., the data
that a peer stores consists of a set of tuples t1, . . . , tr
of the same type. The attributes have complex data
types and NULL-values are possible.

We do not consider more sophisticated data models to avoid diluting the discussion of the main ideas
through technicalities related to mastering complex
data models. Moreover, many practical applications,
in particular in P2P systems and scientific databases,
use exactly the type of simplistic data model we have
introduced, at least at the meta-data level.

We use a query language for querying and transforming databases. The query language consists of basic relational algebra operators since we do not care
about the practical encoding, e.g., in SQL or XQuery.
The relational operators that we require are as follows:
 Selection pred (a) (R), where a is a list of attribute
names A1, . . . , Ak, and pred is any predicate
on the attributes a using standard atomic predicates on the respective data types, i.e., pred =
pred(A1, . . . , Ak).
 Projection a(R), where a is a list of attribute names
A1, . . . , Ak.
 Mapping f (R), where f is a list of functions of the
form A0 := F(A1, . . . , Ak) and A1, . . . , Ak are attribute names occurring in R. The function F is specific to the data types of the attributes A1, . . . , Ak. A
special case is renaming of an attribute: A0 := A1.
We assume that queries can be evaluated against any
database irrespective of its schema. Predicates containing attributes not present in the evaluated schema
are ignored.1 Projection attributes which are not
present in the current schema return a NULL-value.

1 We do not use the same conventions as Xpath/XQuery here,
but we will make use of additional mechanisms for dropping
queries.

K. Aberer et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1 (2003) 89114

p3

N (p )

p2

p4

p1->p6

p6

p1->p7

p1

p1->p8

p7
N (p )

p8

p5

Fig. 2. The network model.

Mappings applied to non-existing attributes also return NULL-values.

3.2. The network model

Let us now consider a set of peers P. Each peer p 
P has a basic communication mechanism that allows
it to establish connection with other peers. Without
loss of generality, we assume in the following that
it is based on the Gnutella protocol [4]. Thus peers
can send ping messages and receive pong messages in
order to learn about the network structure. In extension
to the Gnutella protocol, peers also send their schema
identifier as part of the pong message.

Every peer p maintains a neighborhood N(p) selected from the peers that it identified through pong
messages. The peers in this neighborhood are distinguished into those that share the same schema, Ne(p),
and those that have a different schema, Nd(p) as shown
in Fig. 2.

A peer p1 includes another peer p2 with a different
schema into its neighborhood if it knows a transformation for queries against its own schema to queries
against the foreign schema. The query transformation
operator Tp1p2 is given as a query qT that provides a
view of schema Sp2 according to schema Sp1. In other
words, qT takes data structured according to schema
Sp2 and transforms it into data structured according to
schema Sp1.

Using qT the transformed form of a query q against
is given by

a database according to schema Sp1
Tp1p2

(q), which is defined as
) = q(qT (DBp2

(q)(DBp2

)).

Tp1p2

We assume that translations only use a mapping
operator followed by a projection on the attributes that

are preserved. Thus, qT will always be of the form

qT (DBp2

) = a(f (DBp2

)).

Furthermore, we assume that the transformation
query is normalized as follows: If an attribute A is
preserved, it also occurs in the mapping operator as
an identity mapping, i.e., A := A  f. This simplifies
our subsequent analysis.

Note that multiple transformations may be applied
to a single query q. The composition of multiple transformations T1, . . . , Tn is given by using the associative composition operator  as follows:
(T1    Tn)(q)(DB) = q(qT1
Such query transformations may be implemented
easily using various mechanisms, for example XQuery
as explained below.

 (qTn (DB))).

Queries can be issued to any peer through a query
message. A query message contains a query identifier
id, the (potentially transformed) query q, the query
message originator p, and the translation trace TT to
keep track of the translations already performed. In
the subsequent sections we will extend the contents of
the query message in order to implement a more intelligent control of query forwarding. The basic query
message format is

), (pto, Spto

query(id, q, p, TT).
The translation trace TT is a list of pairs {(pfrom,
)} keeping track of the peers having
Spfrom
sent the request through a translation link (pfrom) and
of the peers having received it after the translation link
(pto), along with their respective schema identifiers
(Spfrom and Spto). We will call pfrom the sender, and pto
the receiver. For any translation link, we have to record
both the sender and the recipient, as after a translation
a query might be forwarded without transformation to
peers sharing the same schema.

3.3. Case study

To illustrate how to apply the abstract model detailed above in a concrete setting, we will now describe one of the experiments which were conducted
in our group in order to realize Semantic Gossiping in
an XML/XQuery environment. Note that this example

title->name

title-> -

title-> - 

title-> -

p3

p1

title->title

title->title

title->name

title->acronym

p4

name->title

p5

title->title

p6

name->title

title->description/name

name->title

title->name

title->description/name

p2

name->description/name

p7

name->name

Fig. 3. A semantic graph of translations.

will also be used in the following text to illustrate the
techniques we will apply to control query propagation.
Seven people from our group were first asked to design a simple XML document containing some project
meta-data. The outcome of this deliberately imprecise
task definition was a collection of structured documents lacking common semantics though overlapping
partially for a subset of the embraced meta-data (e.g.,
name of the project or start date). Viewing these documents as seven distinct semantic domains in a decentralized setting, we then produced a graph connecting
the different domains together with series of translation links. The resulting topology is depicted in Fig. 3.
In this figure we provide also one example of how an
attribute gets transformed by the user-defined transla-
tions. All the domains have some representation for the
title of the project (usually referred to as name or title,
see Fig. 3 where the translations for the attribute title
are represented on top of the links), except p3 which
only considers a mere ID for identifying the projects.
Translations were formulated as XQuery expressions in such a way that they strictly adhere to the
principles stipulated above.

In the next step of the experiment, we asked the authors to write translations for every link departing from
their domain (for example, p1 was asked to provide
us with the translations to p2, p3 and p4). Finally, using the IPSI-XQ XQuery libraries [8] and the Xerces
[26] XML parser, we built a query translator capa-

ble of handling and forwarding the queries following
the gossiping algorithm. As an example for the out-
come, Fig. 4 presents two different documents as well
as a simple query transformation using query T12 for
translation.

4. Syntactic similarity

During translation, parts of queries may be lost
since the schema which the query is mapped to may
not have a representation for the information contained
in certain attributes of the original schema. Syntactic

Q1 =
FOR $p IN zoran_project.xml/*
WHEREJie ProjectIN p/title
RETURN
<start>$p/duration/start</start>
<zoran_project>

<title> My Project</title>
<acronym>MP</acronym>
<duration>

</duration>
<team

<start>10/1/01</start>
<end>13/10/05</end>
T12 =
FOR $p IN jie_project.xml/*
RETURN
<member>1</member>
<zoran_project>
<member>2</member>

</team

</zoran_project>

<title> $p/Name </title>
<acronym> </acronym>
<duration>

<start>$p/Begin</start>

</jie_project>

...

T12

Q2 =
FOR$pr IN
WHEREJie ProjectIN p/title
RETURN
<start>$p/duration/start</start>
<jie_project>

<Name>JieProject</Name>
<Begin>02/05/02</Begin>
<Level>Diploma</Level>
<Location>EPF</Location>
<Lab>LSIR</Lab>
<Institute>IIF</Institute>
<Faculty>I&C</Faculty>
<Length>6months</Length>
<Benefits>...</Benefits>
<Report>Yes</Report>

Fig. 4. An example of translation mechanism.

K. Aberer et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1 (2003) 89114

similarity provides a measure which is related to this
type of information loss during translation. This measure is context-independent since its evaluation relies
exclusively on the inspection of the syntactic features
of the translated queries. A high syntactic similarity
will not ensure that forwarding a query is useful, but
conversely a low syntactic similarity implies that it
might not be useful to further forward a query.

Let us suppose we have a query q, originally applied
to database DB1 with schema S1, which always has the
generic form of a selectionprojectionmapping query
q(DB1) = ap(pred(as)(fa(DB1))),
where as is a list of attributes used in the selection
predicates, ap is a list of attributes used in the projec-
tion, and fa is a list of functions applied. Without loss
of generality, we assume that the query is normalized
such that all attributes required in as and ap are computed by one of the functions in fa.

Assume a transformation T of query q is given, such
that q can be evaluated against database DB2 with
schema S2. The transformation is specified by a query
qT defining a view on DB2.
qT (DB2) = apT
The transformed query T(q) that can be evaluated

(DB2)).

(faT

against the schema S2 is of the form
T(q)(DB2) = ap(pred(as)(fa(apT (faT
This form will also be achieved after multiple trans-

(DB2))))).

formations after normalization.

It might occur that attributes used in q are no longer
available after applying transformation T to q. This
happens when an attribute from S2 required for the
derivation of an attribute from S1 by means of one of
the functions in fa and occurring in ap or as is missing,
i.e., not occurring in apT , or is not computed by one
of the functions from faT .

We now determine which attributes are needed in
order to properly evaluate the query q. For an attribute A  ap resp. A  as we define sourceT (A) as
the set of attributes required in schema S2 of database
DB2 in order to derive A by means of transformation T. If attribute A cannot be derived we will set
sourceT (A) =. For a composite transformation T1 
(A) =
T2 we have the following criterion: if sourceT1

{A1, . . . , Ak} and for all i = 1, . . . , k there exists Fi
 faT2 such that Ai = Fi(Ai
{Ai
sourceT1T2

) then
}.

, . . . , Ai
ki

, . . . , Ai
ki

(A) =

i=1,... ,k

(A) = or for some Ai no derivation of
If sourceT1
the attribute using a function Fi  faT2 is possible we
have
sourceT1T2
In order to ground the definition we assume that
source	(A) = {A} and 	  T = T for the empty sequence of transformations 	.

(A) = .

In order

to determine the effects of multiple
transformations T1, . . . , Tn we have to evaluate
sourceT1Tn (A). This allows to determine which
of the required attributes for evaluating a query containing attribute A are available after applying the
transformations T1, . . . , Tn. The definition of source
is given such that it can be evaluated locally, i.e.,
for each transformation step in an iterative manner.
Using this information we can now define the syntactic similarity between a transformed query and its
corresponding original query.

The decision on the importance of attributes is query
dependent. We have two issues to consider after applying a composite transformation T = T1    Tn:
1. Not all attributes in as are preserved. Therefore
some of the atomic predicates in p(as) will not be
correctly evaluated, i.e., the atomic predicates will
simply be dropped in this case. Depending on the
selectivity of the predicate this might be harmful
to different degrees. We capture this by calculatfor every attribute Ai  as  ap
ing a value FV 
as follows: if Ai  as and sourceT (Ai) = then

i = 0, where selAi is the se-

lectivity of an attribute Ai. The selectivity is ranging
over the interval [0, 1], with high values indicating highly selective attributes, i.e., attributes whose
predicates select a small proportion of the database.
Thus dropping highly selective and thus more critical attributes will lead to lower values of FV 
i .

i = selAi else FV 

2. Not all attributes in ap are preserved. Therefore,
some of the results may be incomplete or even
erroneous (due to the loss of key attributes, for ex-
ample). Following the method used above for the
selection, we capture this by calculating a value

for every attribute Ai  as  ap as follows: if
i = 1 else
i = 0.
i for Ai  as  ap we introduce

FV  capturing the syntactic effects for

Ai  ap and sourceT (Ai) = then FV 

Given the values FV 
feature vectors
the transformed query (T1    Tn)(q).

FV  ((T1    Tn)(q)) = (FV 
, . . . , FV 
Using this feature vector we define a syntactic

similarity measure with respect to selection includ-
W = (W1, . . . , Wk)
ing a user-defined weight vector
pondering the importance of the attributes as:

SIM (q, (T1    Tn)(q)) =


k ).

where

X| = ||

and

FV  = W1FV 

X||2 =

x2

+  + WkFV 

+  + x2
k.

This value is normalized on the interval [0, 1]. Orig-
inally, the similarity will be one, and it will decrease
proportionally to the relative weight and selectivity of
every attribute lost in the selection operator, until it
reaches 0 when all attributes are lost.
For projection using the values FV 

the analogous
feature vectors
and similarity measures SIM
are derived. Again, this similarity decreases with the
number of translations applied to the query, until it
reaches 0 when all the projection attributes are lost.


We illustrate the concepts introduced for syntactic
similarity by means of a small example. Assume a peer
p1 is connected to peers p2 and p3 through translations
as illustrated in Fig. 5.

A translation, such as Tp1p3 can be specified as a

(DB3)

(DB3) = A3:=A1,B3:=B1,C3:=A1

query, e.g.,
qTp1p3
p1 sends a query q = A1,B1,C1
(Tp1p2
peers. Peer p2 would evaluate
follows: sourceTp1p2

(B2) = sourceTp1p2

(q)(DB2)) = (1, 0, 0) and SIM(q, Tp1p2

assuming all user-defined weights
3,
1/


(DB1) to the two other
(q)) as

(A2) = {A1} and sourceTp1p2
(C2) =. Therefore
(Tp1p2
(q)) =
are


Tp1->p3

A3:=A1, B3:=B1, C3:=A1

Tp1->p2
A2:=A1

p3

p1

p2

Tp3->p1

A1:=A3, B1:=B3, C1:=C3

Tp2->p1
A1:=A2

Fig. 5. An example for syntactic similarity.


 Tp2p1

)(q)) = 1/

(C3) = {A1}. Thus,

If p2 sends q back to p1, p1 would obtain
1.
SIM(q, (Tp1p2
3, since only
attribute A1 remains intact after the two translations.
On the other hand, p3 determines sourceTp1p3
(A3) = {A1}, sourceTp1p3
(B3) = {B1}, and

(Tp1p3
sourceTp1p3

(q)) = 1.
(DB3)) = (1, 1, 1) and SIM(q, Tp1p3
If p3 sends the query back to p1, p1 would as well
(q)) = 1. The fact
obtain SIM(q, Tp1p3
that an obvious mistake occurs, i.e., that attribute C3
is wrongly mapped onto A1 in the translation, is not
detected by the syntactic similarity measure, and will
be dealt with by the semantic similarity measures
introduced in the next section.

 Tp3p1

(q)


5. Semantic similarity

The context-independent measure of syntactic similarity is based on the assumption that
the query
transformations are semantically correct, which in
general might not be the case. A better way to view
semantics is to consider it as an agreement among
peers. If two peers agree on the meaning of their
schemas, then they will generate compatible transla-
tions. From that basic observation, we will now derive
context-dependent measures of semantic similarity.
These measures will allow us to assess the quality of
attributes that are preserved in the translation.

To that end, we introduce two mechanisms for deriving the quality of a translation. One mechanism
will be based on analyzing the fidelity of translations
at the schema level, the other one will be based on
analyzing the quality of the correspondences in the
query results obtained at the data level.

K. Aberer et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1 (2003) 89114

Tp0->p1

N (p )

p1

pn

p3

p3->p5

N (p )

p1->p2

p4

p2

pn-1->pn

pn-2->pn-1

n-1p

Fig. 6. The feedback mechanism.

5.1. Cycle analysis

For the first mechanism, we exploit the protocol
property that detects cycles as soon as a query reenters a semantic domain it has already traversed (see
Section 6.1 for more details). A cycle starts with a
peer p1 transmitting a query q1 to a peer p2 through a
translation link Tp1p2 (see Fig. 6). In the example,
after a few hops, the query is finally sent to a peer pn
which, sharing the same schema as p1, detects a cycle
and informs p1. The returning query qn is of the form
qn = (Tp1p2
= T(q1).

   Tpn1pn )(q1)

 Tp3p5

p1 may now analyze what happened to the attributes
A1, . . . , Ak originally present in q1. It could attempt
to check whether the composed transformation is iden-
tity, but the approach we propose here appears more
practical. We differentiate three cases:
 Case 1: sourceT (Ai) = {Ai}, this means that Ai
has been maintained throughout the cycle. It usually
indicates that all the peers along the cycle agree on
the meaning of the attribute. Such an observation
increases the confidence in the correctness of the
translations used.
 Case 2: sourceT (Ai) =, this means that someone
along the cycle had no representation for Ai. Ai is
not part of the common semantics. This leaves the
confidence in the translations unchanged.
 Case 3: Otherwise, if none of the two previous cases
occurs, e.g., sourceT (Ai) = {Aj}, j = i this indicates some semantic confusion along the cycle.
Subcases can occur depending on what happens to
Aj. This lowers the confidence in the translations.

We now derive heuristics for p1 to assess the correctness of the translation Tp1p2 it has used, based
on the different cycle messages it received. Let us consider a translation cycle f composed of || f || translation
links. On an attribute basis, f may result in positive
feedback (case 1 above), neutral feedback (case 2, not
used for the rest of this analysis but taken into account by the syntactic similarity), or negative feedback
(case 3). We denote by 	cyc the probability of a foreign translation (i.e., Tp3p5
, . . . , Tpn1pn) along a
cycle being wrong for the attribute in question. Considering these error probabilities as being independent
and identically distributed random variables, the probability of not having a foreign translation error along
the cycle is
(1  	cyc)||f||1.
Moreover, compensating errors,

i.e., series of
independent translation errors resulting in a correct
translation, may occur along the cycle of foreign links
without being noticed by p1, which only has the final result qn at its disposal. Thus, assuming Tp1p2
correct and denoting by cyc the probability of errors
being compensated somehow, the probability of a
cycle being positive is
(1  	cyc)||f||1 + (1  (1  	cyc)||f||1)cyc
= prob

+(||f||, 	cyc, cyc)

(1)

while, under the same assumptions, the probability of
a cycle being negative is
(1  (1  	cyc)||f||1)(1  cyc)
= 1  prob
+(||f||, 	cyc, cyc).
(2)
Similarly, if we assume Tp1p2 to be incorrect, the
probability of a cycle being respectively negative and
positive are
(1  	cyc)||f||1 + (1  (1  	cyc)||f||1)(1  cyc)
= prob
(3)

(||f||, 	cyc,cyc)

and
(1  (1  	cyc)||f||1)cyc
= (1  prob
Assume a peer p1 obtains a set of positive and negative feedbacks along cycles F = {f1, . . . , fm} of

(||f||, 	cyc, cyc)).

(4)

lengths ||f1||, . . . ,||fm|| for a given attribute A. Some
of these may be positive, i.e., sourceT (A) = {A}, other
negative. We denote by F+  F the set of positive
and by F  F the set of negative feedbacks and
have F = F+  F

If p1 assumes that its own outgoing translation link
at the start of the cycle is correct, then the probability
of obtaining exactly such a combination of positive
and negative feedbacks for the set of cycles F can be
calculated as
l+

(F) =

prob

+(||f||, 	cyc,cyc)
(1  prob

+(||f||, 	cyc, cyc)).

fF+
fF

This probability is the product of all individual probabilities for positive and negative feedback cycles of
the given lengths, as the they have been previously
derived in Eqs. (1) and (2), to occur.

Similarly, if p1 assumes that its own outgoing translation link at the start of the cycle is incorrect, then the
probability of obtaining such a combination of feedbacks for the set F can be calculated as

(F) =

prob

(||f||, 	cyc, cyc)
(1  prob

(||f||, 	cyc, cyc)).

fF
fF+

Since we have no knowledge about 	cyc and cyc we
assume these probabilities to be uniformly distributed.
We integrate over 	cyc and cyc in order to obtain the
expected probability for the distribution of positive and
negative feedbacks in the observed set F to occur. We
could take into account density functions here if we
have any a priori knowledge about those two random
variables. The resulting expectation values e+
c and e

when assuming that the known translation Tp1p2 is
either correct or wrong, are then
(F) d	cyc dcyc;

e+

l+

(F) d	cycdcyc

which are used to evaluate the relative degree of
correctness cyc of the mapping Tp1p2 given the

observation set F:

cyc = e+
e+
c + e

If no relevant feedback is obtained for an attribute
relative to a translation link we set by default cyc = 1.
This analysis may be performed by any peer p1 for
every outgoing link to a peer p2 and every attribute Ai
 as  ap independently, resulting in values  p2
cyc,i indicating the likelihood of the translation Tp1p2 being
correct for the attribute Ai.

As for the preceding section, we define now a feature vector and a similarity measure to capture the
semantic losses along a sequence of translation links
T1, . . . , Tn, where Tj connects peer pj with pj+1 via
a translation link. For simplicity of presentation we
assume each peer corresponds to a different semantic
domain.
Let us suppose that peer p1 issues a query q =
ap(pred(as)(fa(DB))) to p2 through a translation link
T1 = Tp1p2. p1 computes a feature vector for q based
on the cycle messages it has received as follows:


(T1(q)) = (FV

k (T1)(q))

(T1(q)), . . . , FV

where

i (T1(q)) =  p2
cyc,i.
In the following translations these values are updated by iteratively multiplying the values obtained
for the degree of correctness for each translation link.
We consider here that if two translations Tj1 and
pj+1
Tj have degrees of correctness of 
cyc,i
for attribute Ai and are independent, the degree of
correctness of the composite translation (Tj1  Tj)
pj+1
pj
is 
cyc,i . Thus, when forwarding a transformed
cyc,i
query using a link Tj1, peer pj updates each value

i ((T1    Tj1)(q)) it has received along with

the transformed query (T1  Tj1)(q) in this way:

pj
cyc,i and 

i ((T1    Tj)(q))
= FV
The

i ((T1    Tj1)(q))
pj+1
cyc,i .
for
semantic

similarity

T1, . . . , Tn associated with the vector
SIM(q, (T1,  Tn)(q)) =


transformations
FV is then

W||

| .

K. Aberer et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1 (2003) 89114

f (c) = prob

This value starts from 1 (in the semantic domain
which the query originates from) and decreases as the
query traverses more and more semantically heterogeneous domains.
We illustrate the cycle analysis by means of the example given in Fig. 5. Assume p1 forwards query q =
(DB1) through translation links Tp1p2 and
A1,B1,C1
Tp2p1 and obtains as a result of this cycle f the posi-
(A1) = {A1} for attive feedback sourceTp1p2Tp2p1
tribute A1. It calculates l+
+(2, 	cyc, cyc) =
(1  	cyc) + 	cyccyc. After integration it obtains
= 3/4. Since no
a degree of correctness of  p2

feedback is obtained for the other attributes, p1 sets

(q)) = (3/4, 1, 1), for the attributes oc-

(q)) =
curring in q and calculates SIM(q, Tp1p2
0.957. For the translation link Tp1p3
to peer p3
peer p1 obtains feedback through translation links
Tp1p3 and Tp3p1. For A1 and B1 this feedback is
positive, whereas for C1 it is negative. Doing the cor-

responding calculations this results in a feature vector
(q)) = (3/4, 3/4, 1/4). p1 calculates

SIM(q, Tp1p3

(q)) = 0.763.

(Tp1p2

cyc,1

(Tp1p3

When deciding to forward the query, assume that
a peer requires all similarity measures (syntactic
and semantic) to be above a threshold of 0.9 (see
Section 6). Then it would not forward query q to peer
p2 for syntactic reasons (SIM is below the thresh-
old), whereas it would not forward query q to p3 for
semantic reasons (SIM is below the threshold).

A more detailed example of cycle analysis is

presented in Section 6.2.

5.2. Results analysis

The second mechanism for analyzing the semantic
quality of the translations is based on the analysis
of the results returned. In [1], we have introduced
a method using functional dependencies at the data
level in order to assess the quality of translations.
This method was based on analyzing to which extent
integrity constraints are preserved after translation.

Here, we present an alternative, more general, ap-
proach. We assume that peers annotate documents
D using meta-data expressed according to our data
model. Thus each document d  D owned by peer p
is associated with an annotation annot(d) according
to the schema Sp of the peer. Having sent a query,

peers start to receive result documents with semantically rich content, e.g., images or full text. Based on
this content they attempt to assess to which extent the
queries expressed at the meta-data level were properly
translated and thus led other peers to return the correct
result documents.

Queries in our meta-data model are thus an intensional way of expressing semantic concepts, whereas
extensionally the concepts are related to sets of doc-
uments. The problem that we address is of how to
arrive at agreed annotation schemes at the intensional
level that result in concept definitions that are compatible with the extensional notion of concepts that peers
have.

In the following, we assume that a peer has a finite
set of concepts C to classify documents. The extensional notion of a concept that each peer has is based
on methods of content analysis. Here, we do not make
any assumption about the methods (e.g., layout anal-
ysis, lexicographical analysis, contour-detection, etc.,
or even simple manual classification) used to extract
meaningful features out of the documents; we simply
treat them as high-level abstractions used to unambiguously classify any possible retrieved documents d
 D into concepts c  C using a decision rule Rcontent:
Rcontent : D  C.
In a more general setting, Rcontent could be a probabilistic rule. Using their local classification based on
content analysis, peers can thus determine for every
received document the concept it belongs to.

The intensional notion of concept each peer has
is based on classification rules applied to meta-data
annotations of documents.
Rannot : annot(D)  C.
Again, we do not make assumptions on the specific
form of the classification rules, except that they apply some predicates to the meta-data annotations and
derive from these predicates the concept to which the
document corresponds to. Examples of classification
rules are extensively discussed in the data mining liter-
ature. The document classification obtained from content analysis and by classification rules are presumed
to be consistent up to a mean classification error 	res,
i.e., we assume that with a probability 1  	res
Rcontent(d) = Rannot(annot(d)).

By analyzing its own document collection a peer

can estimate the value of 	res.

content and Rp1

Imagine now a peer p1 classifying documents according to rules Rp1
annot. Peer p1 issues a
query q against the meta-data annotation for retrieving documents. Upon reception of a document d from
a foreign peer p2  Nd(p1), p1 performs the classification operation according to its own rules Rp1
content and
Rp1
annot. Different situations may then occur:
 Rp1

annot(d): This is the result p1 was
expecting; it is an indication that the outgoing translation link used to forward q to p2 was semantically
correct for query q. We treat this as positive feedback (F

(d) = Rp1

content

 Rp1

).
(d) = Rp1

content

annot(d): p1 receives a document,
such that the content analysis does not match the
classification obtained from the meta-data annotation obtained by translation. Since the document
content is not changed during transmission of the
query result, this implies that some semantic confusion occurred in the meta-data query translation
along the path from p2 to p1. In this case, we consider this as negative feedback (F


).

If p1 and p2 are directly connected, this gives us a
clear indication about the semantic (in)correctness of
the translation link Tp1p2. Given the mean classification error probability 	res, the probability of the link
being correct or incorrect in case of positive feedback
are 1  	res and 	res respectively. In case of negative
feedback, they become 	res and 1  	res.
If two peers are separated by one or more semantic
domains, the situation is somewhat more complicated
since we have to take into account all the successive
links used to forward the query from p1 to a peer pn.
Let us suppose that a peer receives some feedback after
the query has gone through || f || different translation
links; analogous to the derivation of the probabilities
from the cycle analysis, the probability of receiving a
positive feedback assuming the link we are analyzing
is correct is
(1  	res)prob

+(||f||  1, 	cyc, cyc)

+ 	resres(1  prob

+(||f||  1, 	cyc,cyc)),

obtains positive feedback. The situation where the intermediate translations are wrong and the peer still
believes to have obtained a positive feedback is more
intricate and is covered by the second term. Receiving a wrongly annotated result a peer can still perform
a misclassification itself with probability 	res. How-
ever, only in exceptional cases with probability res
this misclassification will correct the problem, namely
when the wrong concept matches exactly the expected concept. A peer can estimate the probability
res by (|| C||  1)1, where || C || is the number of
different concepts a peer knows at a given instant of
time. The probability of receiving negative feedback
is then calculated analogously.
Performing an analysis analogous to the one given
in Section 5.1 and introducing l+
r as the probability of receiving a certain combination of responses
for a given error model under the assumption that the
outgoing translation link is correct resp. incorrect, we
obtain again two expectation values e+
r and e
r used
to estimate the degree of semantic correctness:

r and l

e+

l+

(F)d	cyc dcyc;

(F) d	cyc dcyc.

+ e

res = e+

/(e+

Defining  p2
) as the likelihood of
the translation Tp1p2 being correct for a peer p2 
Ne(p1) we obtain a scalar feature for each translation
link Tp1p2
(Tp1p2

(q)) =  p2

res

measuring the degree of correctness of the translation
link. If no value can be computed it is again set to 1 by
default. Analogous to the cycle analysis these values
are forwarded and updated iteratively by multiplying
the values obtained for each translation link, such that
a measure for the semantic similarity
SIM(q, (T1    Tn)(q)) =  p2

res   pn+1

res

where prob
is defined as in Eq. (1). The first term
covers the case where the translations are all correct
and the peer performs a proper classification, and thus

for a chain of translations is defined.

Some illustrating examples for this approach are

given in Section 7.

K. Aberer et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1 (2003) 89114

6. Gossiping algorithm

6.1. Query forwarding

At this point, we have four measures (SIM, SIM,
SIM, and SIM) for evaluating the losses due to the
translations. We will now make use of these values to
decide whether or not it is worth forwarding a specific
query to a foreign semantic domain.

First, we require the creator of a query to attach a
few user-defined or generated values to the query it
issues:
1. The weights


W pondering the importance of the

attributes in the query.

sel.

2. The respective selectivity of the selection attributes


SIMmin = (SIMmin


3. The minimal values

, SIMmin

SIMmin , SIMmin ) for the similarity measures under
which a transformed query is so deteriorated that
it can no longer be considered as equivalent to the
original query.
We extend the format of a query message to include
these values as well as the iteratively updated feature
vectors:


query(id, q, p, TT,
sel,

FV, FV).


FV ,


FV  ,


W,


SIMmin,

Now, upon reception of a query message, we require

a peer to perform a series of tasks:
1. detect any semantic cycles;
2. check whether or not this query has already been

received;

3. in case the local neighborhood has not received the

query, forward it to the local neighborhood;

4. return potential results;

and, for each of its outgoing translation links:

5. apply the translation to the query;
6. update the similarity measures for the transformed

query;

7. perform a test for each of the similarity measures
whether the current similarity of the transformed
query with the original query exceeds the required
minimal threshold given by


SIMmin;

8. forward the query using the link if all similarity

measure tests succeed.

This algorithm ensures that queries are forwarded
to a sufficiently large set of peers capable of rendering meaningful feedback without flooding the entire
network.

6.2. Case study revisiteduse of syntactic and
semantic similarities

Let us come back to the case study introduced in
Section 3.3. We assume that a single attribute query
is issued by p1 to obtain all the titles of the different
projects. This query may be written in the following
way:

Query =

FOR $project IN project A.xml/*

RETURN

<title>$project/title</title>

Let us now determine how the query will be propagated from p1. Note that the weight and selectivity
values attached to the query do not matter here, as
a single attribute is concerned. Moreover we will
not consider SIM here (SIM always evaluates to
1 because there is no selection attribute). The other
thresholds are set to 0.5.

Following the gossiping algorithm, p1 first attempts
to transmit the query to its direct neighbors, i.e., p2, p3
and p4. P2 and p4 in turn forward the query to the other
nodes, but p3 will in fact never receive the query: As p3
has no representation for the title, the only projection
attribute would be lost in the translation process from
p1 to p3, lowering SIM to 0.

Let us now examine the semantic similarity SIM.
For the topology considered, 31 semantic cycles could
be detected by p1 in the best case. As the query never
traverses p3, only 8 cycles remain (Table 1 lists those
cycles). Now we use the formulas from Section 5: For
its first outgoing link (i.e., the link going from p1 to
p2), p1 receives 5 positive cycles, raising the semantic similarity measure for this link and the attribute
considered to 0.79.2 p1 does not receive any semantically significant feedback for its second outgoing link
Tp1p3, which is anyway handled by the syntactic

2 Remember that we did not make any assumption regarding the
distribution of erroneous links. In this case, the positive feedback
received may as well come from a series of compensating errors.

Table 1
Cycles resulting in positive (+) or negative () feedback
Cycle

p1, p2, p4, p5, p1
p1, p2, p4, p5, p6, p1
p1, p2, p5, p1
p1, p2, p5, p6, p1
p1, p2, p6, p1
p1, p4, p5, p1
p1, p4, p5, p2, p6, p1
p1, p4, p5, p6, p1

Tp1p4
erroneous

Tp2p4
erroneous

analysis. Yet, it receives 3 negative cycles for its last
outgoing link Tp1p4. This link is clearly semantically
erroneous, mapping title onto acronym. This results in
p1 excluding the link for forwarding the query, since
the semantic similarity drops to 0.26 in this case.

The situation may be summarized in this way: p1
restrains from sending the query through p3 because
of the syntactic analysis (too much information is lost
in the translation process) and excludes p2 because of
the high semantic dissimilarity.

The situation somewhat changes if we correct the
erroneous link Tp1p4 and add a mistake for the link
Tp2p4. For the attribute considered, the semantic
similarity drops to 0.69 for the outgoing link Tp1p2
(two long cycles are negative, see third column in
Table 1). Even though it is not directly connected to
an erroneous link, p1 senses the semantic incompatibilities affecting some of the messages traversing p2.
It will continue to send queries through this link, as
long as it receives positive feedback at least.

7. Experimental evaluation

In the preceding section, we have evaluated The
Chatty Web approach by examining query forwarding in a small network of static translations generated
by a group of users. In contrast to this, we now use
semantic gossiping and the semantic similarity measures not only to decide on query forwarding but also
to correct existing mappings. Thus semantic gossiping is used to automatically reach semantic agreement
in large networks of computer generated and dynamic
translation links. This approach in place could for

example be used to derive basic, common ontologies
from a dynamic system with heterogeneous schemas,
or to gradually refine existing networks of translations.
The initial simulation results interpreted below provide
promising evidence that it is worth pursuing further
research along these lines and highlight some of the
issues to be addressed. In particular, they clearly indicate in which settings each of the two semantic similarity measures derived from cycle and result analysis
are more suitable.

7.1. Experimental setup

The setup we used in the experiments is as fol-
lows: We assume a network of peers representing
individual semantic domains. Peers share a finite set
of similar concepts, i.e., operate in a certain semantic
domain (for example, biological databases) inside the
network. They share annotated documents (or data)
related to those concepts, but refer to concepts using different names (they denominate the concepts
differently). From this basic setup, we attempt to
create global interoperability by applying semantic
gossiping techniques using purely pair-wise,
local
translations.

The exact description of the process is as follows:
First, we create a topology of n peers p1, . . . , pn, each
of them connected through translation links to l other
peers. The peers share ||C|| concepts c1, . . . , c||C||, but
use distinct names to refer to them. Thus we study the
problem of peers sharing the same concepts but lacking knowledge of how to refer to them by names. This
is somewhat similar to the approach taken in [29],
without aiming at universally agreed upon names.
Without loss of generality we may assume that the
same set of names n1, . . . , n||C|| is used by all peers
(this simplifies the subsequent presentation).We write
(ni p ck) if peer p uses name ni to refer to concept
ck. Thus, we can use a single attribute A to store the
name the peer associates with a concept. Also, peers
can verify whether a document belongs to a concept
or not and thus annotate documents they store with a
name using attribute A.

We then generate mappings (DB) for every translation link. The mapping function  relates names from
the first peer to names from the second peer, with every name used by the first peer mapped onto the name
used by the second peer. Thus  is a permutation of

K. Aberer et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1 (2003) 89114

the domain of names used for attribute A which we
denote as (ni) = nj to indicate that  maps name ni
to name nj. For every mapping p1p2 in every translation link Tp1p2, we say that the mapping is correct
if and only if the two names bound by the mapping
actually refer to the same concept, that is if
ck  nj p2

(ni) = nj  ni p1

p1p2

ck.

P1
n1
n2

P2
n1
n2

P3
n1
n2

P4
n1
n2

Thus, random mappings would only have a probability of 1/||C||! of being correct in this setting. In
the experiments, we generate a fraction eRate of erroneous mapping initially.

Unless specified otherwise, we use small-world
graphs [31] to interconnect peers with translation
links since small-world topologies have been extensively applied to model computer networks or social
behaviors. They are typically characterized by high
clustering coefficients (average fraction of pairs of
neighbors of a node that are also neighbors of each
other) and relatively small path length (average minimal distance between two nodes). In the following,
we generate graphs with an average clustering coefficient of 0.1 and with 10% shortcuts (i.e., links rewired
to a random peer in the network).

Starting from the original topology, we apply semantic gossiping techniques iteratively in order to
detect and rectify erroneous translations. At every
simulation step, each peer selects one of its names
randomly and issues a query about this name (i.e., the
query consists of a projection on one attribute: the
name selected). The query is propagated to the other
peers (semantic domains) in a Gnutella-like fashion
with a low time-to-live (TTL) value.

The syntactic analysis for this simplistic type of
query is straightforward: Peers forward the query
through an outgoing translation link if there exists a
translation mapping the local name used in the query
(projection attribute) into another name for the foreign peer. Now, for detecting and repairing erroneous
translation links, we slightly modify the semantic
analysis; We forward queries irrespective of the results of previous query forwarding strategy in order
to get as many evidences as possible, and use these
results to reach semantic agreements by gradually
modifying translations.

Before taking a closer look at the final results, we
will evaluate in the following sections each of the

Fig. 7. New mapping candidates.

semantic analyses (cycle and result analysis) separately to emphasize their specificities.

7.2. Cycle analysis

For every iteration step, peers randomly choose a
name, send a query for this name and analyze the cycle messages they get in return. Here, we do not only
estimate the correctness of the actual mapping as explained in Section 5.1, but also determine which of
the possible mappings is most likely correct and adopt
it as a new mapping. Therefore, peers view mappings
resulting from returned queries as new mapping can-
didates. Consider for example Fig. 7, where peer p1
systematically receives n1 mapped onto n2 in returned
queries (negative feedback). In addition to evaluating
the correctness of the current mapping, p1 considers
other mappings as well. It adopts the most probably
correct mapping candidate if its probability of being
correct is above 50%. In this example, p1 evaluates the
correctness of mapping n1 onto n2, and might consider
to modify it to a mapping n1 onto n2.

As indicated in Section 5.1, pre-existing knowledge
on the distribution of error probabilities cyc and 	cyc
may be used in the computation of semantic similarity.
cyc, the probability of a series of different errors to
compensate along a cycle, is approximated to (||C|| 
1)1, which is the probability of the last erroneous
link in the cycle to map to the original name and thus
to correct previous errors.

We estimate 	cyc with standard maximum-likelihood
techniques applied to the feedback information we
receive. From the probability of receiving a positive
cycle of length || f || knowing that the error probability
of a translation link is 	cyc,
(1  	cyc)||f|| + (1  (1  	cyc)||f||)cyc,

and from its negative counterpart, we derive the density function for the likelihood of 	cyc:
L(	cyc|F) = K
((1  	cyc)||f+||

f+F+
+ (1  (1  	cyc)||f+||)cyc)

fF

(1  (1  	cyc)||f||)(1  cyc)

where K is a normalizing constant. The local maximum of this function over [0, 1] gives a good approximation of 	cyc, supposing we have sufficient feedback
information.

What is the result of this process in the long run? It
depends of course on the initial setting but in the end,
this method attempts to obtain a mapping consensus
based on the different feedback cycles detected in the
network. Considering a high density of links and relatively few erroneous links, the method converges (i.e.,
repairs all erroneous mappings) rapidly, since peers
can base their decisions on numerous and meaningful
feedback cycles. For settings where links are scarce,
peers do not have sufficient information for making
sensible choices, and results may diverge.

Several parameters are of particular interest: The
number of peers n, the fraction of translations initially erroneous eRate, the number of concepts ||C||,
the initial time-to-live TTL of the messages and the
number of outgoing translation links l per peer. The
figures below show experimental results for topolo-

% wrong mappings

gies where n = 25, eRate = 0.1, ||C|| = 4, TTL = 5
and l = 5 and where one of those parameters varies.
All the curves are averaged over ten consecutive runs.
At every step, each peer sends a query picking a random concept for every outgoing edge and modifies
its mappings depending on the results of the analysis
explained above. Steps are represented on the x-axis.
The graph shows the evolution of the percentage of
erroneous mappings, starting at a rate eRate initially.
Clearly, the outcome depends on the density of links,
which directly impacts on the number of cycles we
have at our disposal for taking mapping decisions (see
Fig. 8). For l = 4 and the topology considered, we
get on average only one positive feedback per mapping candidate, which is obviously insufficient to take
sensible decisions. For l = 5 and 6, the value raises
to 1.8 and 2.9, respectively and most of the erroneous
mappings get corrected after ten iterations. Finally,
for l = 7, we get enough evidences (4.5 per mapping
candidate on average) for correcting all the erroneous
links, thus reaching a perfect semantic agreement, in
eight steps.

Similar results may be observed for variable TTLs.
Fig. 9 shows results using the same parameters as
before, but this time for a fixed number of outgoing
edges (l = 4) and TTLs ranging from 3 to 6. Again,
for low values, peers do not gain sufficient feedback information to correct mappings. Starting with
TTL = 4 (1.8 positive feedbacks per decision), peers
receive sufficient information to correct more than

  l = 3

  l = 4

  l = 5

  l = 6

  l = 7

# steps

Fig. 8. Sensitivity to the number of outgoing edges.

K. Aberer et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1 (2003) 89114

% wrong mappings

TTL = 3

TTL = 4

TTL = 5

TTL = 6

# steps

Fig. 9. Sensitivity to the TTL.

75% of the erroneous mappings after nine iterations.
Low-connectivity networks may thus benefit from increasing the TTL value of their queries in order to get
sufficient feedback information for the peers.

Our approach is rather insensitive to variations of
the initial error rate (see Fig. 10) until a certain thresh-
old, where too many bad links are present initially to
reach a correct consensus based on the feedback cy-
cles. Finally, it is worth mentioning that the approach
scales very well with the number of nodes. This is not
surprising, considering that the method relies solely
on local interactions (no central component or com-
putation) and that the clustering coefficient of the net-

work is relatively high. Fig. 11 shows experiments for
networks ranging from 50 to 800 peers without fundamental result variations. The small deviations are due
to the shortcuts in the small world topology which
connect two random peers in the network. The bigger
the graph, the less likely it is that these links can be
used to form cycles within a certain neighborhood.

7.3. Results analysis

Let us now consider the second part of the analysis,
in which peers analyze and categorize documents they
receive. The process is as follows: At every step, the

% wrong mappings

eRate = 0.4

eRate = 0.3

eRate = 0.2

eRate = 0.1

eRate = 0.05

# steps

Fig. 10. Sensitivity to the initial error rate.

% wrong mappings

nPeers=800

nPeers=400

nPeers=200

nPeers=100

nPeers=50

# steps

Fig. 11. Scalability.

peers first issue a couple of queries with a high TTL
for estimating the error rate as explained in the preceding section. Then, for each of their outgoing links,
the peers pick a concept randomly and issue a query
asking for documents related to that concept. In re-
turn, they receive documents they analyze following
the method described in Section 5.2. They modify the
mapping they have used to forward the query with
the most probable mapping if it has a correctness
likelihood of at least 0.5.

For the simulations, we used a fixed set of documents scattered randomly among the peers. All docu-

ments are assigned to concepts. Each document owner
has a probability (	res) of misclassifying a document
by relating it to a wrong concept. We use a fixed, low
value of 	res = 5% in the following experiments. For
our setting, res is equal to (||C||  1)1.
Unless specified otherwise, we used a network of
50 peers sharing in total 100 documents, 2 outgoing
translation links per peer, 4 concepts, a TTL of 3, an
initial error rate of 10%, and a probability of 10% of
misclassifying documents.

First, it is interesting to see that this approach is very
robust against the initial error rate, mainly because of

% wrong mappings

eRate = 0.5

eRate = 0.4

eRate = 0.3

eRate = 0.2

eRate = 0.1

# steps

Fig. 12. Sensitivity to initial error rate.

K. Aberer et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1 (2003) 89114

% wrong mappings

   res = 0.4

   res = 0.3

   res = 0.2

   res = 0.1

   res = 0.05

# steps

Fig. 13. Sensitivity to misclassification rate.

the short feedback loop (one translation link suffices
here to return documents) compared to the relatively
long cycles used previously. Fig. 12 shows the results
for a varying initial percentage of wrong mappings.

Nevertheless, the approach is rather sensitive to the
rate of misclassification of documents, as shown in
Fig. 13. This is especially true since we do not try
to evaluate this parameter but consider a mere fixed
value.

The approach taken here is completely local, and
does not take into consideration any global behav-
ior, and scales well with the number of peers (see
Fig. 14). Here, we increase the number of documents

% wrong mappings

linearly with the number of peers, to keep the average
number of documents per peer constant. This number
is essential to this analysis, since it is directly proportional to the number of evidences a peer gets for
every query. This effect is depicted in Fig. 15: Peers
start having trouble correcting the mappings as they
get less and less documents returned for their queries
(documents scarcity).

7.4. Combined results

Many possibilities exist for combining the two anal-
yses. We chose a very simple one: at each step, every

nPeers = 400

nPeers = 200

nPeers = 100

nPeers = 50

# steps

Fig. 14. Scalability.

% wrong mappings

DocPerPeer=1/4

DocPerPeer=1/2

DocPerPeer=1

DocPerPeer=2

# steps

Fig. 15. Sensitivity to number of documents.

peer first performs a result analysis step (modifying a
few mappings depending on the results returned) and
then performs a cycle analysis step (trying to reach
some local agreement on mappings based on cycle
feedback). The results for topologies with 25 peers,
4 concepts, 2 outgoing edges, TTLs of 3 (results) or
6 (cycles) and varying error rates on initial mappings
are depicted in Fig. 16.

This method takes more time to converge than the
two analyses applied separately this is because the
analyses keep interfering with each other until some

state is reached that is consistent from both a cycle
and a feedback analyses point of view. Note that the
combined method in the end outperforms the two individual methods applied separately (e.g., more than
95% of erroneous mappings corrected after 50 steps
with 50% erroneous mappings initially).

8. Implementation framework

All the tasks of the Chatty Web approach have
been mapped onto an implementation architecture

% wrong mappings

eRate = 0.5

eRate = 0.4

eRate = 0.3

eRate = 0.2

eRate = 0.1

# steps

Fig. 16. Combined results, varying initial error rate.

K. Aberer et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1 (2003) 89114

Network

Network

Semantic Processing

Data Processing

Semantic Result

Analyzer

Query Router
and Translator

Outgoing Query and

Result Handler

Neighborhood

Exploration

Semantic Cycle

Analysis

Cycle Detection

Incoming Query and

Result Handler

Legend:

Query
Result
Meta data

Meta&data Repository
(neigbboring peers,

schemas and
translations

Local Data Repository
and Query Processor

Fig. 17. Architecture for semantic gossiping.

which uses a meta-data model expressed in XML and
XQuery as the language to translate among schemas.
The framework assumes the availability of a communication infrastructure, for example, simple web
access via HTTP or a P2P infrastructure such as JXTA
[9]. However, we are not bound to any specific communication infrastructure. All we require is access
to the relevant schema data and the ability to query
information and results. This can easily be achieved
by a standard abstraction layer that maps a specific
communication infrastructures interface to the one
we require. Since this is a fairly standard software
engineering task we omit it in the following discus-
sion. Based on these assumptions, Fig. 17 shows the
standard architecture used for semantic gossiping in
the Chatty Web.

Incoming queries are registered at and handled by
the Incoming Query and Result Handler whose task
is to communicate with other peers, to forward the
query for further processing and to gather partial results which it uses to assemble the final result of a
specific query. The next step then is to detect whether
a cycle has occurred. If so, semantic analysis of the
cycle is triggered. Otherwise, the query is processed,

first by querying the local database and then by handing it over to the Query Router and Translator to collect results from other peers.

For this purpose the Query Router and Translator
inquires for possible translations, evaluates the quality of the resulting queries, and if it is above a defined
threshold, forwards the query to the respective peer in
a different semantic domain. Queries are forwarded
by the Outgoing Query and Result Handler which is
also in charge of collecting the results and forwarding
the results to the Incoming Query and Result Handler
which returns them to the original requester. Addi-
tionally, it provides input data for semantic result
analysis.

This is the main data processing flow of the archi-
tecture. In parallel, partly triggered by the ongoing
data processing, there is also semantic processing as
depicted in the left half of Fig. 17. Its main tasks
are semantic analyses of results based on the existing
knowledge of schemas and their relationships and the
semantic analyses of detected cycles. The results of
these analyses are integrated again into the systems
knowledge base and provide the basic decision criteria
for query routing.

Additionally, the knowledge base is updated and
improved by exploring the peers neighborhood
and detecting new schemas and translations. The
meta-data repository will try to infer further translations and present new ones for human analysis or apply them for actively detecting semantic agreements
in an automatic way.

9. Related work

A number of approaches for making heterogeneous information sources interoperable are based
on mappings between distributed schemas or ontologies without making the canonical assumption on the
existence of a global schema.

For example,

in OBSERVER [17] each information source maintains an ontology, expressed in
description logics, to associate semantics with the information stored and to process distributed queries. In
query processing, OBSERVER uses local measures
for the loss of information when propagating queries
and receiving results. Similarly to OBSERVER,
KRAFT [25] proposes an agent-based architecture
to manage ontological relationships in a distributed
information system. Relationships among ontologies
are expressed in a constraint language. [2] proposes
a model and architecture for managing distributed relational databases in a P2P environment. The authors
use local relational database schemas and represent
the relations between those with domain relations and
coordination formulas. These are used to propagate
queries and updates. The relationships given between
the local database schemas are always considered as
being correct. In [24], a probabilistic framework for
reasoning with assertions on schema relationships is
introduced. Thus, the approach deals with the problem of having possibly contradictory knowledge on
schema relationships. Mukherjee et al. [20] propose
an architecture for the use of XML-based annotations
in P2P systems to establish semantic interoperability.
An approach to self-organizing vocabularies is described in [29]. A set of agents communicate by randomly associating a fixed set of words to a fixed set
of meanings (which is called a vocabulary but in fact
is an ontology) and repeatedly evaluate how successful their communicative acts have been. Depending on
the success, the binding between a word and a concept

is maintained or replaced by a new random coupling.
The decision is based on sigmoid functions so that the
probability of change quickly decreases if the majority of agents uses the same coupling. This approach
is related to the method of cycle analysis we use and
simulate in Section 7. However, it does not employ
result analysis. Nevertheless [29] shows that semantic
agreements are reached rather quickly. The additional
result analysis we perform may help to speed up convergence speed and increase the scalability and robustness of the self-organization process. It is interesting
to note that [29] shows that an increased numbers of
agents, words, and meanings does not lead to combinatorial explosion but implosion. This is due to the
fact that the increasing number of words with consistent meaning narrows the selection space drastically.
This phenomenon is similar to the combinatorial implosions described by Kauffman [13] for the clustering and interconnection of autocatalytic networks.

EDUTELLA [21] is a recent approach to apply the
P2P architectural principle to build a semantically
interoperable information system for the educational
domain. The P2P principle is applied at the technical
implementation level whereas logically a commonly
shared ontology is used. The original design of
EDUTELLA which is based on Gnutella is changed
to a super-peer network approach in [22] which offers
better scalability and provides sophisticated routing and clustering strategies based on the meta-data
schemas attributes and ontologies used. This approach
includes a methodology for mediation between local
schemas at super-peers which enables super-peers
to route queries and combine results from different
semantic domains into one result. It employs transformation rules, so-called correspondences, which
have already been used in mediator-based information systems [32]. QueryResponse Assertions [16]
and Model Correspondences [3] are used to express
correspondences between heterogeneous schemas.

The Piazza system [10] defines a mapping language
to specify mappings between sets of XML or RDF
data sources that tries to take into account both domain
and document structure in the mediation process. The
transitive closure of these mappings is used to provide
a query answering algorithm over the graph of data
source defined by the mappings. Piazzas approach is
complementary to our approach since it assumes the
existence of pair-wise mappings between data sources

K. Aberer et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1 (2003) 89114

and uses these mappings for answering queries while
we try to detect the quality of mappings in terms of
an overall agreement among nodes (which can also
be seen as a form of transitive closure). However, the
mapping language of Piazza together with its query
rewriting and query answering methods could also be
used in the Chatty Web approach for more expressive
mappings and improved query routing.

Approaches for automatic schema matchingsee
[27] for an overviewwould ideally support the approach we pursue in order to generate mappings in a
semi-automated manner. In fact, we may understand
our proposal as extending approaches for matching two schemas to an approach matching multiple
schemas in a networked environment. One example
illustrating how the schema matching process could
be further automated at the local level is introduced
in GLUE [6] which employs machine learning techniques to assist in the ontology mapping process.
GLUE is based on a probabilistic model, employs
similarity measures and uses a set of learning strategies to exploit ontologies in multiple ways to improve
the resulting mappings.

Finally, we see our proposal also as an application
of principles used in Web link analysis, such as [14],
in which local relationships of information sources are
exploited to derive global assessments on their quality
(and eventually their meaning).

10. Conclusions

Semantic interoperability is a key issue on the way
to the Semantic Web which can push the usability
of the web considerably beyond its current state.
The success of the Semantic Web, however, depends
heavily on the degree of global agreement that can be
achieved, i.e., global semantics. In this paper we have
presented an approach facilitating the fulfillment of
this requirement by deriving global semantics (agree-
ments)
interactions/agreements.
This means that explicit
local mappings are used
to derive an implicit global agreement. We see our
approach as a complementary effort to the on-going
standardization in the area of semantics which may
help to improve their acceptance and application by
augmenting their top-down approach with a dual
bottomup strategy. We have developed our approach

from purely local

in a formal model that is built around a set of instruments which enable us to assess the quality of the
inferred semantics. To demonstrate its validity and
practical usability, the model is applied in a simple
yet practically relevant case study. Also, series of experimental results legitimate our claims and illustrate
our interests in pursuing research aiming at a better
understanding of network-related properties fostering
semantic interoperability.

Acknowledgements

The work presented in this paper was supported
(in part) by the National Competence Center in Research on Mobile Information and Communication
Systems (NCCRMICS), a center supported by the
Swiss National Science Foundation under grant number 5005-67322.
