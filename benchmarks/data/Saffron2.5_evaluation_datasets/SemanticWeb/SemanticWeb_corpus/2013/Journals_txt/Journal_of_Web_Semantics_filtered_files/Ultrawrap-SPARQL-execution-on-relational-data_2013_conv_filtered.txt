Web Semantics: Science, Services and Agents on the World Wide Web 22 (2013) 1939

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

journal homepage: www.elsevier.com/locate/websem

Ultrawrap: SPARQL execution on relational data
Juan F. Sequeda, Daniel P. Miranker

Department of Computer Science, University of Texas at Austin, United States

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 3 April 2012
Received in revised form
22 August 2013
Accepted 25 August 2013
Available online 2 September 2013

Keywords:
Semantic web
Relational databases
SPARQL

RDB2RDF

The Semantic Webs promise of web-wide data integration requires the inclusion of legacy relational
databases,1 i.e. the execution of SPARQL queries on RDF representation of the legacy relational data.
We explore a hypothesis: existing commercial relational databases already subsume the algorithms and
optimizations needed to support effective SPARQL execution on existing relationally stored data. The
experiment is embodied in a system, Ultrawrap, that encodes a logical representation of the database
as an RDF graph using SQL views and a simple syntactic translation of SPARQL queries to SQL queries on
those views. Thus, in the course of executing a SPARQL query, the SQL optimizer uses the SQL views that
represent a mapping of relational data to RDF, and optimizes its execution. In contrast, related research
is predicated on incorporating optimizing transforms as part of the SPARQL to SQL translation, and/or
executing some of the queries outside the underlying SQL environment.

Ultrawrap is evaluated using two existing benchmark suites that derive their RDF data from relational
data through a Relational Database to RDF (RDB2RDF) Direct Mapping and repeated for each of the three
major relational database management systems. Empirical analysis reveals two existing relational query
optimizations that, if applied to the SQL produced from a simple syntactic translations of SPARQL queries
(with bound predicate arguments) to SQL, consistently yield query execution time that is comparable
to that of SQL queries written directly for the relational representation of the data. The analysis further
reveals the two optimizations are not uniquely required to achieve a successful wrapper system. The
evidence suggests effective wrappers will be those that are designed to complement the optimizer of the
target database.

 2013 Elsevier B.V. All rights reserved.

1. Introduction

We postulate that by carefully constructing unmaterialized SQL
views2 to create a logical representation of a legacy relational
database as an RDF graph [2], the existing algorithmic machinery in
SQL optimizers is already sufficient to effectively execute SPARQL
queries [3] on native relational data [4,5]. Thereby, legacy relational database systems may be made upwardly compatible with
the Semantic Web [6], while simultaneously minimizing the complexity of the wrapping system. This is in contrast to related efforts,
detailed below, that are predicated on preprocessing and/or optimizing the SQL query before sending it to the SQL optimizer [79].
To clarify the focus of this research, consider the taxonomy
in Fig. 1. In RDF data management there are efforts that concern

 Corresponding author.

E-mail addresses: jsequeda@cs.utexas.edu (J.F. Sequeda),

miranker@cs.utexas.edu (D.P. Miranker).
1 By legacy, we mean software/data already in wide use such that an organization
is not willing to relinquish the investment.
2 Unmaterialized views are virtual tables that are defined by a query over other
tables in the database. They are not stored in the database but can be queried as if
they existed [1].

1570-8268/$  see front matter  2013 Elsevier B.V. All rights reserved.
http://dx.doi.org/10.1016/j.websem.2013.08.002

Triplestores and those that concern legacy Relational Databases.
Triplestores are database management systems whose data model
is RDF, and support at least SPARQL execution against the stored
contents. Native triplestores are those that are implemented from
scratch [1012]. RDBMS-backed Triplestores are built by adding an
application layer to an existing relational database management
system. Within that literature is a discourse concerning the best
database schema, SPARQL to SQL query translations, indexing
methods and even storage managers, (i.e. column stores vs. row
stores) [1316]. NoSQL Triplestores are also being investigated as
possible RDF storage managers [1719]. In all three cases, RDF is
the primary data model.

The research herein is concerned with the mapping of legacy
relational data with the Semantic Web, a.k.a Relational Database
to RDF (RDB2RDF). Within that, the research concerns Wrapper
Systems that present a logical RDF representation of relational data
that is physically stored in an RDBMS such that no copy of the
relational data is made. It follows that some or all of a SPARQL query
evaluation is executed by the SQL engine. An alternative is the
relational data is extracted from the relational database, translated
to RDF, and loaded (ETL) into a triplestore [20].

Since both RDBMS-backed Triplestores and RDB2RDF Wrapper
systems involve relational databases and translation from SPARQL

J.F. Sequeda, D.P. Miranker / Web Semantics: Science, Services and Agents on the World Wide Web 22 (2013) 1939

such large view definitions would be parsed by RDBMSs without
throwing an exception.

At runtime, a third compiler translates an incoming SPARQL
query to a SQL query on the Tripleview. The translation is
limited to macro-substitution of each logical SPARQL operator
with its equivalent SQL operator. This is straightforward as each
SPARQL query operator corresponds to an equivalent relational
operator [22].

Fig. 1. Taxonomy of RDF data management.

Fig. 2. Architecture of Ultrawrap.

to SQL, there is a potential for confusion. The difference is
that RDBMS-backed Triplestores translate SPARQL queries to SQL
queries that are executed on database schemas that model and
store RDF. RDB2RDF Wrapper systems translate SPARQL queries
to SQL queries that are executed on legacy database schemas that
model and store relational data.

Approximately 70% of websites have relational database backends [21]. The sheer number of websites suggests the success of the
Semantic Web is tied to maintaining compatibility and consistency
with legacy RDBMSs. Wrapper systems enable Semantic Web
applications to coexist with the legacy applications and avoid
consistency problems simply by not creating a replicated copy of
the data.

In 2008, Angles and Gutierrez showed that SPARQL is equivalent
in expressive power to relational algebra [22]. Thus, one might
expect the validity of this researchs postulate to be a foregone
conclusion. However, in 2009, two studies that evaluated three
RDB2RDF wrapper systems, D2R, Virtuoso RDF Views and Squirrel
RDF, came to the opposite conclusion; existing SPARQL to SQL
translation systems do not compete with traditional relational
databases [23,24].

A motivation for this paper is to resolve the apparent
contradiction among the aforementioned papers. Toward that end
we have built a system, Ultrawrap3 [25]. Ultrawrap is organized
as a set of four compilers with the understanding that the SQL
optimizer forms one of the four compilers (Section 3 and Fig. 2).

In a two-step, off-line process, Ultrawrap defines a SQL view
whose query component is a specification of a mapping from
the relational data to an RDF triple representation, the Tripleview.
In our experiments the Tripleview is not materialized, (i.e. the
defining queries are not executed). Thus the view forms a logical
specification of the mapping. Note that this view is extremely
large, comprising a union of select-from-where queries, at least
one query for each column in the relational database. At the onset
of the research we first conducted experiments to confirm that

3 See acknowledgments.

It follows from the SQL standard that an RDBMS must
correctly execute the translated SPARQL query. Consequently, the
target RDBMS SQL system must both use the logical mapping
represented in the Tripleview and optimize the resulting query,
forming the fourth compiler.

Ultrawrap is evaluated using the three leading RDBMS systems
and two benchmark suites, Microsoft SQL Server, IBM DB2 and
Oracle RDBMS, and the Berlin and Barton SPARQL benchmarks
(Section 5). The SPARQL benchmarks were chosen as a consequence of the fact that they derived their RDF content from a
relational source. The Berlin Benchmark provides both SPARQL
queries and SQL queries, where each query was derived independently from an English language specification. Since wrappers produce SQL from SPARQL we refer to the benchmarks SQL queries
as benchmark-provided SQL queries. For Barton, the original relational data is not available and the creator of the benchmark did not
create separate SPARQL and SQL queries. We located replacement
relational data, namely a relational data dump of DBLP and created separate SPARQL and SQL queries derived independently from
an English language specification. The benchmark-provided SQL
queries have been tuned for use specifically against each benchmark database. We have packaged the new version of Barton for
distribution [26].

By using benchmarks containing independently created SPARQL
and SQL queries, and considering the effort and maturity embodied in the leading RDBMSs SQL optimizers, we suppose that the
respective benchmark-provided SQL query execution time forms a
worthy baseline, and the specific query plans to yield insight into
methods for creating wrappers.
Our findings include:
 A mapping of relational data to a Tripleview comprising three
columns does not instigate the SQL optimizers to use indexes.
The view was refined to reflect physical schema properties
(Section 3).
 Two known query optimizations, detection of unsatisfiable
conditions and self-join elimination [27], when applied, not only
result in comparable execution times between SPARQL and the
benchmark-provided SQL queries with bound predicates, the
optimizers will often produce identical query plans (Section 4).
 In some cases, a third optimizing transform, join predicate
push down, can be as effective as the detection of unsatisfiable
conditions (Section 5).
 SPARQL queries containing variables that bind to the predicate
position remain troublesome. We relate this problem to an
already described problem concerning the use of views in the
implementation of data integration systems (Section 5).
 The impact of the self-join elimination optimization is a
function of the selectivity and the number of properties in the
SPARQL query that are co-located in a single table (Section 6).
 No system, including those that eliminated self equi-joins,
eliminated the self left outer joins. The SPARQL optional
operator is, by definition, a left outer join (Section 6).
By starting with a simple wrapper system and evaluating it with
sophisticated SQL query optimizers we are able to identify existing,
well understood optimization methods that enable wrappers. The
results provide a foundation for identifying minimal requirements
for effective wrapper systems.

2. Related work

Per the taxonomy in Fig. 1, systems that involve relational
databases are RDBMS-backed Triplestores and RDB2RDF systems.
We describe three published research efforts concerning RDBMSbacked triplestores [13,28,15]. Three RDB2RDF Wrapper systems
have been assessed in the literature: D2RQ [7], SquirrelRDF [8] and
Virtuoso RDF Views [9].

RDBMS-backed Triplestores store RDF in different database
schemas. Many RDBMS-backed Triplestores use the triple table
schema: a table with three attributes, containing one row for
each triple [14]. Another approach is the property table: a table
comprising of one column containing the subject plus one or more
columns for predicates that are defined for the subject [16]. Abadi
et al. introduced the vertical partitioned table: a table for every
unique predicate in the data [13].

Abadi et al. argue for the use of column-store based relational
systems as the basis of RDBMS-backed triplestores, as compared
to more common row-stores. The paper does not address SPARQL
to SQL translation. With respect to translation, the papers core
contribution is the mapping of RDF to a relational schema
comprising one table for each predicate value. The resulting tables
each contain two columns, the subject and object. The organization
is well suited for join processing on a column-store database.

Chebotko et al. present a translation of SPARQL to SQL, where
the RDF is modeled as a triple table. They argue that their
translation may be composed with additional mappings, enabling
their translation to be applied to any relational model of RDF. They
reported empirical results for a synthetic RDF test set of 1 million
triples. The generated SQL resembles the relational algebra rules
used to define the semantics of SPARQL, resulting in multiple
coalesce functions in one projection, null-accepting predicates,
and outer union implementations [28]. The translation is proven
to be semantics preserving. Elliot et al. improve upon Chebotko.
Chebotko et al.s methods exploit nested SQL queries. Central to
Elliot et al.s contribution are algorithms that produce flat SQL
queries. Their evaluation was also on a triple table schema with
datasets between 2 and 5 million RDF triples [15].

The authors of the three mentioned RDB2RDF wrapper systems
have not published a refereed scientific paper describing their
rewriting algorithms and optimizations. Open-source code and
forums4,5,6,7 provide evidence of their architecture. For example,
we observed that for some SPARQL queries, D2R generates multiple
SQL queries and necessarily executed a join among those results
outside of the database.

Two overlapping, refereed studies do compare the aforementioned RDB2RDF wrapper systems with native SQL execution on
the relational database [23,24]. Bizer & Schultz compared D2R and
Virtuoso RDF Views on MySQL [23]. Gray et al. compared D2R and
SquirrelRDF on MySQL [24].

The March 2009 Berlin SPARQL Benchmark on the 100 million
triple dataset reported that SPARQL queries on the evaluated
RDB2RDF systems were up to 1000 times slower that the native
SQL queries. Today, those systems are still the most used in the
Semantic Web community and no new system has been introduced
and evaluated since then. Bizer & Schultz [23], creators of the Berlin
SPARQL Benchmark, concluded that: Setting the results of the RDF
stores and the SPARQL-to-SQL rewriters in relation to the performance
of classical RDBMS unveiled an unedifying picture. Comparing the
overall performance (100 M triple, single client, all queries) of the

4 http://sourceforge.net/mailarchive/message.php?msg_id=27731620.
5 http://sourceforge.net/mailarchive/message.php?msg_id=28142066.
6 http://sourceforge.net/mailarchive/message.php?msg_id=28051074.
7 https://github.com/d2rq/d2rq/issues/94.

fastest rewriter with the fastest relational database shows an overhead
for query rewriting of 106%. This is an indicator that there is still room
for improving the rewriting algorithms.

Gray et al. [24] tested D2R and SquirrelRDF on a scientific
database. This study concluded that ...current rdb2rdf systems are
not capable of providing the query execution performance required
to implement a scientific data integration system based on the rdf
model. [...] it is likely that with more work on query translation,
suitable mechanisms for translating queries could be developed. These
mechanisms should focus on exploiting the underlying database
systems capabilities to optimize queries and process large quantities
of structured data, e.g. pushing the selection conditions to the
underlying database system.

Other RDB2RDF systems go through an ETL process of extracting
relational data, translating it to RDF and loading the results into a
triplestore [20,29]. In this case, two copies of the same data must
be maintained.

Related studies have compared native triplestores with
RDB2RDF systems and native triplestores with relational database.
In 2007, Svihla & Jelinek determined that RDB2RDF systems are
faster than the Jena and Sesame triplestores [30]. In 2009, Schmidt
et al. compared Sesame triplestore with the triple table, vertical partitioned storage scheme and the native relational scheme
on MonetDB, a column-store relational database. This study concluded that none of the RDF schemes was competitive to the native relational scheme [31]. In 2010, MahmoudiNasab and Sakr also
compared the triple table, property table and vertical partitioned
storage scheme with the native relational scheme on IBM DB2.
They also concluded that none of the storage schemes compete
with the native relational scheme [32]. In conclusion, benchmarkprovided SQL queries on relationally stored data outperform any
other approach.

Ontology-based data access systems, such MASTRO, ONDA and
Quest [3335] focus on mapping relational databases to ontologies
in order to perform reasoning during query execution. These
systems may be of interest to the reader, but do not support
SPARQL and fall outside the taxonomy.

3. Ultrawrap

The World Wide Web Consortium (W3C) is fostering RDB2RDF
systems through standardization efforts [36,37]. Ultrawrap is
compliant with the W3C RDB2RDF Direct Mapping standard which
details an RDF graph representation of the relational data. In
addition Ultrawrap also translates the relational schema and
accompany SQL constraints into an OWL ontology [3840].

Ultrawrap is comprised of four primary components as shown

in Fig. 2:
1. The translation of a SQL schema, including constraints, to an

OWL ontology: the putative ontology (PO) [3840].

2. The creation of an intensional triple table in the database by
augmenting the relational schema with one or more SQL Views:
the Tripleview.

3. Translation of SPARQL queries to equivalent SQL queries

operating on the Tripleview.

4. The native SQL query optimizer, which becomes responsible for
rewriting triple based queries and effecting their execution on
extensional relational data.
These four components can be seen as four different language
compilers. As an ensemble, the first three provide for the logical
mapping of schema, data and queries between the relational
and Semantic Web languages. The fourth component, the SQL
optimizer, is responsible for the evaluation of the data mappings
and concomitant optimization of the query.

J.F. Sequeda, D.P. Miranker / Web Semantics: Science, Services and Agents on the World Wide Web 22 (2013) 1939

Fig. 6. Pseudo-code to create the createTripleview method.

Fig. 3. Pseudo-code to create a Tripleview for types.

Fig. 4. Pseudo-code to create a Tripleview for varchar datatype properties.

Fig. 5. Pseudo-code to create a Tripleview for object properties.

3.1. Compilation

The components of Ultrawrap may also be decomposed as a
compilation phase and a runtime phase. The goal of the compilation phase is the creation of the Tripleview. The first step in
the compilation phase is the translation of the applications SQL
schema to OWL.

3.1.1. Generating the putative ontology

To define the mapping of the relational data to RDF, the system first identifies an ontological representation of the relational
schema. We implement the RDB2RDF direct mapping of Sequeda
et al. [39,40], which includes transformation rules for integrity constraints (foreign keys and primary keys). The RDF representation of
the relational data is functionally dependent that ontological map-
ping. The semantics of query execution for this mapping also have
foundation [38]. Briefly, this transformation consists of representing tables as ontological classes, foreign key attributes of a table
as object properties and all other attributes as datatype proper-
ties. Tables that represent a many-to-many relationship (a.k.a. a
join table) are translated to object properties. Each property has its
respective domain and range. Both datatype and object properties
have classes as domains. Datatype properties have a datatype as a
range while object properties have a class as its range.

We have found that when a SQL database schema has been
created using good data engineering methodology with supporting
CASE tools, the synthesized ontology can be quite good. Since

the quality of a databases data modeling is rarely of that high
quality, and the meaning of good ontology is subjective, we allay
controversy by calling the result collection of ontology declarations
a putative ontology (PO). The serialization of the putative ontology,
as an OWL file, is not needed to implement the system. However,
as both OWL and the creation of the putative ontology are formally
defined, for clarity, the exposition of the paper assumes this to be
the case.

We chose the Sequeda et al. mapping [38] over the recently
ratified W3C RDB2RDF Direct Mapping standard for many reasons.
The sufficient reason central to this paper is the semantics of
query execution and evaluation for the W3C mapping is not
yet done. Note that except for the identification of join tables,
the Sequeda et al. mapping subsumes the W3C standard. The
additional mappings do not impact the performance evaluation.

Other reasons for choosing the Sequeda et al. mapping follow.
The W3C RDB2RDF Direct Mapping standard makes no provision
for the publication of meta-data. The specification of an OWLDL description of the database enables a version of Ultrawrap
that augments the database with the RDF representation of the
ontology. This equates to linked-data publication of the databases
meta-data, including functional constraints, in a manner consistent
with native semantic data sources,
i.e. Ultrawrap provides
a completely automatic method for making legacy relational
databases upward compatible with all layers of the Semantic Web
stack. Without such provision, the developers of Semantic Web
applications must have a priori knowledge of the contents of
a data source, or develop methods capable of normalizing adhoc publication of meta-data. The W3C RDB2RDF Direct Mapping
standard does not address the inclusion of integrity constraints.
Other research shows that the inclusion of these constraints
exposes semantics that may critically improve the performance of
automatic data integration methods [41,42].

3.1.2. Creating the Tripleview

The putative ontology is the input to a second compilation step
that creates a logical definition of the relational data as RDF and
embeds it in a view definition. The pseudo-code for the algorithms
appears in Figs. 36. Per the W3C RDB2RDF Direct Mapping
standard, concatenating the table name with the primary key value
or table name with attribute name creates unique identifiers for
subject, predicate and objects. Subsequently, unique identifiers can
be appended to a base URI. The SQL Tripleview is comprised of
a union of SELECT-FROM-WHERE (SFW) statements. The WHERE
clause filters attributes with null values (IS NOT NULL), given that
null values are not expressible in RDF.

Due to its simplicity, our starting point is the triple table
approach. Even though, studies have shown that storing RDF with
the triple table approach in a relational database is easily improved
upon [13,32], this issue is not relevant to Ultrawrap because the
relational data is not being materialized in a triple table; instead
the relational data is virtually represented as a triple table through
unmaterialized views.

Even though our goal is to define a virtual triple table, we still
have to anticipate the physical characteristics of the database and
the capacity of the SQL optimizer to produce optimal physical

Fig. 7. CREATE VIEW statements defining the Tripleviews.

plans. Toward that end, we have identified two refinements to the
Tripleview.

Refinement 1: Our initial approach was to create a single
Tripleview with 3 attributes: <subject, predicate, object>. The
subject corresponds to concatenating the name of the table and
the primary key value. The predicate is a constant value that
corresponds to each attribute name of each table. There can be two
types of object values: a value from the database or a concatenation
of the name of a table with its primary key value. However, joins
were slow because the optimizer was not exploiting the indexes
on the primary keys. Therefore, the Tripleview was extended to
consist of 5 attributes: <subject, primary key of subject, predicate,
object, primary key of object>. Separating the primary key in the
Tripleview allows the query optimizer to exploit them because
the joins are done on these values. If the object is a value, then
a NULL is used as the primary key of the object. The subject and
object are still kept as the concatenation of the table name with
the primary key value because this is used to generate the final
URI, which uniquely identifies each tuple in the database. For
simplicity, composite keys were not considered in the Tripleview.
Nevertheless, it is possible to augment the number of attributes in
the Tripleview to include each separate key value.

Refinement 2: Refinement 1 represented the entire database
in a single Tripleview. This meant that all values were cast
to the same datatype (namely varchar). Even though all values
were cast to varchar, we observed throughout our experiments
that the optimizer was still able to apply operators specific
for other datatypes (i.e, >, <, etc.). However, the size of the
object field of the Tripleview is the size of the largest varchar
which led to poor query performance. Due to this issue, it was
beneficial to create a separate Tripleview for each datatype.
For varchar, this includes each length declared in the schema.
For example, datatypes with varchar(50) and varchar(200) are
considered different. Using multiple Tripleviews requires less
bookkeeping than one might anticipate. Each attribute is mapped
to its corresponding Tripleview and stored in a hashtable. Then,
given an attribute, the corresponding Tripleview can be retrieved.
Table 1 shows an example relational database and the logical
contents of the Tripleviews are shown in Tables 25. Pseudo-code
for creating the Tripleviews is shown in Figs. 36. Fig. 7 shows the
CREATE VIEW statements for the Tripleviews.

3.2. Runtime

Table 1
Example of product and producer table.

Product
Id

Label

pNum1

pNum2

prodFK

Producer
Id

Title
Foo
Bar

Location

Table 2
Logical contents of Tripleview for types.

type
type
type
type

Product1
Product2
Producer4
Producer5

S_ID

Table 3
Logical contents of Tripleview for varchar(50).

Product1
Product2
Producer4
Producer4
Producer5
Producer5

S_ID

Product#label
Product#label
Producer#title
Producer#location
Producer#title
Producer#location

Table 4
Logical contents of Tripleview for int.

Product#pNum1
Product#pNum2
Product#pNum1
Product#pNum2

Product1
Product1
Product2
Product2

S_ID

Product
Product
Producer
Producer

Foo

Bar

O_ID

O_ID

O_ID

Table 5
Logical contents of Tripleview for object properties.

Product1
Product2

S_ID

Product#producer
Product#producer

Producer4
Producer5

O_ID

3.2.1. SPARQL to SQL translation

SPARQL is a graph pattern matching query language [3] that has

the form:

Ultrawraps runtime phase encompasses the translation of
SPARQL queries to SQL queries on the Tripleviews and the maximal
use of the SQL infrastructure to do the SPARQL query rewriting and
execution.

SELECT ?var1 ? var2 ...
WHERE{triple-pattern-1.
triple-pattern-2.

...

triple-pattern-n.}

J.F. Sequeda, D.P. Miranker / Web Semantics: Science, Services and Agents on the World Wide Web 22 (2013) 1939

where each triple-pattern consists of a subject, predicate, object
and any of these can be a variable or a constant. Variables can occur
in multiple triple-patterns implying a join. Consider the following
SPARQL query as our running example:

SELECT ?label ?pnum1
WHERE{?x label ?label.
?x pnum1 ?pnum1.}

This SPARQL query binds the predicate of the first triple pattern
to the constant label and the predicate of the second triplepattern to the constant pnum1. The variable ?x indicates that
the results of triple-pattern-1 and triple-pattern-2 are to be joined
and the final result is the projection of the binding to the variable
?label and ?pnum1.

The translation of the SPARQL query to a SQL query on the
Tripleviews follows a classic compiler structure: a parser converts
the SPARQL query string to an Abstract Syntax Tree (AST). The
AST is translated into an SPARQL algebra expression tree. The
SQL translation is accomplished by traversing the expression tree
and replacing each SPARQL operator. Each internal node of the
expression tree represents a SPARQL binary algebra operator while
the leaves represent a Basic Graph Patterns (BGP), which is a set of
triple patterns. A SPARQL BGP is a set of triple patterns where each
one maps to a Tripleview. A SPARQL Join maps to a SQL Inner Join, a
SPARQL Union maps to the SQL Union, a SPARQL Optional maps to
SQL Left-Outer Join. In the previous example, there is only one BGP
with two triple patterns and a Join between the triple patterns. The
resulting SQL query is:

SELECT t1.o AS label, t2.o AS pnum1
FROM tripleview_varchar50 t1, tripleview_int t2
WHERE t1.p = label AND t2.p = pnum1 AND t1.s_id = t2.s_id

Hereafter, this is called the Ultrawrap query. Note that the
mapping mentioned in Refinement 2 (Section 2.1.2) was used
in order to know which Tripleview to use. At the initial setup
of the runtime, a hash table with the contents of the mapping
is created. Therefore given an attribute such as label (key), the
mapped Tripleview, in this case tripleview_varchar50 (value) can
be retrieved.

3.2.2. SQL engine is the query rewriter

Given the Ultrawrap query to be executed on the Tripleviews,
the query is executed and it is observed how the SQL engine oper-
ates. These results are described in the following section. A main
concern is if the SQL query can actually be parsed and executed
on the Tripleviews, given the view is a very large union of a large
amount of SFW statements. In the evaluation, BSBM consisted of 10
tables with a total of 78 attributes and Barton consisted of 20 tables
with a total of 61 attributes. It is our understanding that SQL Server
has a limit of 256 tables in a query [43]. Defining a Tripleview for
each datatype expands this limit.

4. Two important optimizations

Upon succeeding in ultrawrapping different RDBMSs and
reviewing query plans, two relational optimizations emerged as
important for effective execution of SPARQL queries: (1) detection
of unsatisfiable conditions and (2) self-join elimination. Perhaps,
not by coincidence, these two optimizations are among semantic
query optimization (SQO) methods introduced in the 1980s [27,44,
45]. In SQO, the objective is to leverage the semantics, represented
in integrity constraints, for query optimization. The basic idea is
to use integrity constraints to rewrite a query into a semantically
equivalent one. These techniques were initially designed for
deductive databases and then integrated in commercial relational
databases [44].

Fig. 8.

Initial query plan of the running example.

Fig. 8 shows the logical query plan of the Ultrawrap SQL query
from the running example. This section describes how the query
plan evolves through these optimizations. Describing a generalpurpose implementation of these optimizations is not in the scope
of this paper. We refer the reader to [27,44]. In this query plan, for
each of the triple patterns in the query, the Tripleview is accessed,
which a union of all the SFW statements.

4.1. Detection of unsatisfiable conditions

The idea of this optimization is to determine that a query
result is empty by determining, without executing the query. This
happens, for example, when a pair of predicate constants are
inconsistent [27]. The application of the following transformations
eliminates columns from the plan that are not needed to evaluate
the SPARQL query.
Elimination by contradiction: Consider a query SELECT  FROM
R WHERE A = x AND A = y such that x = y. Then the result of
that query is empty. For example, it is clear that the query
SELECT  FROM Product WHERE ProductID = 1 AND ProductID =
2 will never return results.

Unnecessary union sub-tree pruning: Given a query that includes
the UNION operator and where it has been determined that
an argument of the UNION is empty; then the corresponding
argument can be eliminated. For example:

UNION ALL ({}, S, T) = UNION ALL (S, T)
UNION ALL ({}, T) = T

In Ultrawraps Tripleview, the constant value in the predicate
position acts as the integrity constraint. Consider the following
Tripleview:
CREATE VIEW Tripleview_varchar50(s,s_id,p,o,o_id) AS
SELECT Producer+id as s, id as s_id, title as p, title as o, null as o_id FROM
Producer WHERE title IS NOT NULL
UNION ALL
SELECT Product+id as s, id as s_id, label as p, label as o, null as o_id FROM
Product WHERE label IS NOT NULL

Now consider the following query return all labels:

SELECT o FROM TripleView_varchar50 WHERE p = label

The first SFW statement from Tripleview_varchar50 defines
p =title. The query contains p =label. Both predicates cannot be
satisfied simultaneously. Given the contradiction, this particular
SFW statement of Tripleview_varchar50 can be replaced with the
empty set.

Since the Tripleviews definition includes all possible columns,
any specific SPARQL query will only need a subset of the statements
defined in the view. Application of elimination by contradiction
enables removing, the unnecessary UNION ALL conditions. Thus
the combination of the two transformations reduces the Tripleview

Fig. 9. Query plan after application of detection of unsatisfiable conditions
optimization.

to precisely the subset of referenced columns. The differences in
the query plans in Figs. 8 and 9 illustrate the impact of these
optimizations.

4.2. Augmenting Ultrawrap

The Ultrawrap architecture is readily extended to include the
detection of unsatisfiable conditions optimization. By creating
such a version, Augmented Ultrawrap, we are able to conduct
a controlled experiment (see Section 5.3.2). Instead of creating
a mapping between each attribute in the database and its
corresponding Tripleview, a mapping is created for each attribute
to its corresponding SFW statement. For example, attribute label
is mapped to the SQL query: SELECT Product+id as s, id as s_id,
label as p, label as o, null as o_id FROM Product WHERE label
IS NOT NULL. At the initial setup of the runtime, a hash table
with the contents of this mapping is generated. Therefore given an
attribute such as label (key), the mapped SFW statement (value)
can be retrieved. The view definition nested in the SQL querys
FROM clause is replaced with the SFW statement.

4.3. Self-join elimination

Join elimination is one of the several SQO techniques, where
integrity constraints are used to eliminate a literal clause in the
query. This implies that a join could also be eliminated if the table
that is being dropped does not contribute any attributes in the
results [27]. The type of join elimination that is desired is the selfjoin elimination, where a join occurs between the same tables. Two
different cases are observed: self-join elimination of projection and
self-join elimination of selections.

Self-join elimination of projection: This occurs when attributes
from the same table are projected individually and then joined
together. For example, the following unoptimized query projects
the attributes label and pnum1 from the table product where
id = 1, however each attribute projection is done separately and
then joined:

SELECT p1.label, p2.pnum1 FROM product p1, product p2 WHERE p1.id = 1
and p1.id = p2.id

Given a self-join elimination optimization, the previous query

may be rewritten as:

SELECT label, pnum1 FROM product WHERE id = 1

Self-join elimination of selection: This occurs when a selection
on attributes from the same table are done individually and then
joined together. For example, the following unoptimized query
selects on pnum1 > 100 and pnum2 < 500 separately and then
joined:

Fig. 10. Query plan after self-join elimination optimization.

SELECT p1.id FROM product p1, product p2 WHERE p1.pnum1 >100 and
p2.pnum2 < 500 and p1.id = p2.id

Given a self-join elimination optimization, the previous query

may be rewritten as:
SELECT id FROM product WHERE pnum1 > 100 and pnum2 < 500

Fig. 10 shows the final query plan after the self-joins are

removed.

5. Evaluation

The evaluation requires workloads where the SPARQL queries
anticipated that the RDF data was derived from a relational
database. Two existing benchmarks fulfill this requirement. The
Berlin SPARQL Benchmark (BSBM) [46,23] imitates the query
load of an e-commerce website. The Barton Benchmark [47]
replicates faceted search of bibliographic data. For Barton, the
readily available RDF data was derived from a dump of MITs
Barton library catalog. The original relational data is not available.
Similarly the only queries that are available are queries written
in SQL against a triple table schema. We have created a version
of Barton on par with BSBM and have organized a package so the
community may reuse it. In lieu of MITs library catalog we used a
relational form of DBLP. We deduced the original SPARQL queries
and their specification. From the query specification we wrote SQL
queries that operate directly on the relational version of DBLP.
Details of the relational schemas and queries for the BSBM and
Barton benchmark can be found in the Appendix.

The objective of this evaluation is to observe the behavior
of commercial relational databases. Therefore the evaluation
compares execution time, queries plans, and the optimizing
transforms used between the Ultrawrap SQL queries and the
benchmark-provided SQL queries on the respective RDBMS. Other
possible experiments include comparing Ultrawrap with other
RDB2RDF wrapper systems, however this is not in the scope
of this work. Nevertheless, as shown in the results, Ultrawrap
query execution time is comparable with the execution time of
benchmark-provided SQL queries. Such results have not been
accomplished by any other RDB2RDF system [23,24].

5.1. Platform

Ultrawrap was installed on Microsoft SQL Server 2008 R2
Developer Edition, IBM DB2 9.2 Express Edition and Oracle 11 g
Release 2 Enterprise Edition. Experiments were conducted on a Sun
Fire X4150 with a four core Intel Xeon X7460 2.66 GHz processor
and 16 GB of RAM running Microsoft Windows Server 2008 R2
Standard on top of VMWare ESX 4.0. SQL Server and Oracle had
access to all cores and memory, while DB2 had only access to one
core and 2 GB of RAM.

5.2. Workload

The BSBM dataset is equivalent to approximately 100 million
triples and requires approximately 11 GB of storage. For Barton,
the DBLP dataset is equivalent to approximately 45 million triples
and requires approximately 4 GB of storage. Indexes were built on

J.F. Sequeda, D.P. Miranker / Web Semantics: Science, Services and Agents on the World Wide Web 22 (2013) 1939

Table 6
Query characteristics of the BSBM and Barton queries.
Left-outer
join


Low selectivity

Inner joins

BSBM 1, 3, 10
Barton 5, 7
BSBM 4, 5, 6, 12

High selectivity

BSBM 2, 7, 8

Table 7
Optimizations implemented by existing RDBMS.

Predicate variable

BSBM 9, 11
Barton 1, 2, 3, 4, 6

DB2
SQL Server
Oracle

Detection of unsatisfiable conditions
Yes
Yes
No

Self-join elimination
Yes
No
Yes

every foreign key and on attributes that were being selected on
in the benchmark queries. The execution time was calculated by
using the elapsed time returned from SQL Servers SET STATISTICS
ON, DB2s db2batch and Oracles SET TIMING ON option.

Note that the DB2 Express Edition limits itself to 2 GB of
RAM. Otherwise, the available RAM is larger than the benchmark
databases. To control for this, both cold and warm start experiments were run. Warm start experiments were done by loading
the data, restarting the databases and executing variants of each
query twenty times. Cold start experiments were done by restarting the database after each execution of a query. The results of
the cold start experiments are not qualitatively different than the
warm start results and thus are omitted.

The benchmark queries consist of a wide variety of operators and characteristics: Basic Graph Patterns, UNION, FILTER, OP-
TIONAL, ORDER BY and unbounded predicates with high and low
selectivity. Details about the queries for both BSBM and Barton
benchmark can be found in the Appendix and on our website. Characteristics of the queries are shown in Table 6.

The initial assessment suggests observations be organized as

four cases:

Case (1) Detection of unsatisfiable conditions and self-join
elimination: if both optimizations are applied then the UNION
ALLs of the Tripleviews should not appear in the query plans and
redundant self-joins should be eliminated. The execution time and
query plans of Ultrawrap queries should be comparable to the
corresponding benchmark-provided SQL queries. This should be
the case for all queries except the special-case of predicate variable
queries, which form Case 4.

Case (2) Detection of unsatisfiable conditions without self-join
elimination: if only the first optimization is applied, then the UNION
ALLs of the Tripleviews do not appear in the query plans and the
number of subqueries is equal to the number of triple patterns
in the original SPARQL query. When the selectivity8 is high, the
execution time of Ultrawrap queries should be comparable to
benchmark-provided SQL queries because the number of tuples
that are self-joined is small. On the other hand, when selectivity
is low the number of tuples joined is larger and the overhead is
more evident. Note that the self-join elimination optimization can
only be applied after the UNIONs have been eliminated; hence the
complementary case does not occur.

Case (3) No optimizations: If no optimizations are applied then
the UNION ALLs of the Tripleviews are not eliminated. In other
words, the physical query plan is equal to the initial logical query
plan (e.g. Fig. 8). The Ultrawrap query execution time should not be
comparable to the benchmark-provided SQL queries because every
SFW statement in the Tripleviews must be executed.

Case (4) Predicate variable queries: Predicate variable queries are
queries that have a variable in the predicate position of a triple
pattern. Given an RDB2RDF direct mapping, the predicate variable
in a SPARQL query is a one-to-many mapping that ranges over all
attributes in the database. These types of queries cannot use the
mapping between the attributes and its corresponding Tripleview

8 Selectivity is the ratio between the number of unique values for the column to
the number of rows in a table [1].

because the attribute is unknown. Further, because the attribute is
unknown, detection of unsatisfiable conditions cannot be applied.
For these queries, the Tripleview described in Refinement 1 is used.
In a paper on the use of views in data integration, Krishnamurthy et al. [48] show that queries with variables ranging over
attributes and table names are of higher order logic. Relational algebra languages, such as SQL, do not support higher order logic [48,
49]. Similarly, a SPARQL query with a predicate variable does not
have a concise, semantically equivalent SQL query. By concise we
mean that the SQL query itself will avoid a union of queries over
different tables or columns.

For the SPARQL predicate variable queries, when writing the
benchmark SQL queries, a SQL developer has visibility on the
SQL schema and has related domain knowledge. In most cases
that developer will understand that only a few columns are of
interest, and write a smaller SQL query than the corresponding
SPARQL query. In other words, the SQL query will query certain
individual columns, but the SPARQL query will expand to query
all columns. This occurs for all such queries for both benchmarks.
Thus, it is arguable whether the tests comparing SPARQL queries
that contain predicate variables, with the benchmark-provided
SQL queries provides a semantically equivalent, apples-to-apples
test. Nevertheless, we execute them and include the data.

5.3. Results

Results of two experiments are reported. The first experiment,
Ultrawrap Experiment, evaluates Ultrawrap implemented as pre-
sented. The second experiment, Augmented Ultrawrap Experiment,
evaluates a version of Ultrawrap augmented with the detection of
unsatisfiable conditions optimization.

We determined that DB2 implements both optimizations.
SQL Server implements the detection of unsatisfiable conditions
optimization. Oracle implements the self-join elimination opti-
mization, but it fails to apply it if the detection of unsatisfiable conditions optimization is not applied. Neither optimization is applied
on the predicate variables queries by any RDBMS. Table 7 summarizes the optimizations implemented by each RDBMS. The results
of both experiments are presented in Figs. 1113. The Ultrawrap
execution time is normalized w.r.t the benchmark-provided SQL
query execution time for each respective RDBMS, i.e. benchmarkprovided SQL query execution time is 1.

5.3.1. Ultrawrap experiment

DB2 implements both optimizations. Therefore it is expected
that it will execute Ultrawrap queries comparable to native SQL
queries (Case 1). This is the case for 7 of the 12 SPARQL queries
with bound predicates (BSBM 2, 5, 6, 8, 10, 12 and Barton 7). For
the exceptions, BSBM 1, 3, 4 and Barton 5, the optimizer generated
a query plan typical of the benchmark-provided SQL queries, but
with a different join order. BSBM 7 has nested left-outer joins.
For that query, the DB2 optimizer did not push the respective join
predicates into the nested queries and corresponding index-based
access paths are not exploited.

SQL Server implements the detection of unsatisfiable conditions
optimizations but not self-join elimination. Thus, one would still
expect that the high selectivity queries would perform comparable
or better than the benchmark-provided SQL queries (Case 2). This is

Fig. 11. Ultrawrap experiment results on BSBM.

Fig. 13. Augmented Ultrawrap experiment results on BSBM and Barton bounded
predicate queries.

In this experiment Cases 2 and 3 are eliminated. Of the three
RDBMS only Oracle does not implement detection of unsatisfiable
conditions. Thus, despite experimenting with closed proprietary
systems, this experiment constitutes a controlled test of the value
of this optimization.

Observe that Oracle now performs comparable or better on
all bound predicate Ultrawrap queries than the comparable
benchmark-provided SQL queries. Inspection of the plans reveals
that the Oracle optimizer applies the self-join elimination optimization where it did not in the first experiment. Thus, in the
second experiment, Oracles plans include both distinguished optimizations (Case 1). For BSBM 1, 3, 4 and Barton 7, the Ultrawrap
execution is better than the benchmark-provided SQL query execution because the optimizer produced an optimal join order for the
Ultrawrap queries. To the best of our knowledge, the benchmarkprovided SQL queries were tuned for better performance. Due to
lack of Oracle DBA skills, benchmark-provided SQL queries BSBM
1, 3, 4 and Barton 7 were not tuned to the best performance
possible.

SQL Server results are largely unchanged.
The only unanticipated results were changes for DB2 for
the unsuccessful bounded predicate queries from the Ultrawrap
Experiment (BSBM 1, 3, 4, 7 and Barton 5). In all cases, performance
improved. This was the result of changes in the join order, and
choosing additional index-based access paths. But in only 1 of the 5
queries, BSBM 1, does the optimizer choose the same join-order as
the benchmark-provided SQL query. We investigated a number of
options to get better join orders and concomitant theories as to the
search behavior of the DB2 optimizer. None of these panned out.

6. Discussion

The following points deserve elaboration:
Self-join elimination: The number of self-joins and their
elimination is not, by itself, an indicator of poor performance. The
impact of the self-join elimination optimization is a function of
the selectivity and the number of properties in the SPARQL query
that are co-located in a single table. The value of optimization is
less as selectivity increases. Qualitatively, the result is predictable.
The conclusion on quantitative results follows by comparing
performance of low selectivity vs. high selectivity queries on SQL
Server as shown in Figs. 11 and 13. The number of self-joins in
the plan corresponds to the number of properties co-located in a
table. The phenomenon is reminiscent of the debate concerning
the use of row-stores vs. column stores started by Abadi et al.
[51,13,52,53,12]. Consideration of row-stores vs. column-stores is
outside the scope of this paper. Nevertheless, we note that these
measurements may help ground that debate.

Join predicate push-down: The experiments with Oracle revealed
that pushing join predicates [50] can be as effective as the detection
of unsatisfiable conditions optimization. For the case of BSBM 7 on

Fig. 12. Ultrawrap experiment results on Barton.

the case for all 7 such queries. For BSBM 4, the optimizer produced a
different join order for the two versions of the query, but this time,
the Ultrawrap query was better. For the low selectivity queries,
review of the query plans reveals the discrepancy in performance
is due precisely to the absence of the self-join elimination.

Although Oracle implements self-join elimination it does not
apply it in this experiment, and thus does not apply either
distinguished optimizations (Case 3). Nevertheless, on 7 of the
12 queries with bound predicates, the Ultrawrap execution is
comparable or better than the benchmark-provided SQL query
execution. Review of the query plans yields a third valuable
optimization: join predicate push-down [50] into each of the SFW
statements in the UNION ALL of the Tripleviews. Even though
each SFW statement is executed, most do not contribute to the
final result. By virtue of the additional predicate push-down the
execution overhead is minimal.

It is expected that neither optimization be applied for predicate
variable queries. This is the case for all three RDBMSs (Case
4). Nevertheless, there are some unanticipated results. The
benchmark-provided SQL queries and Ultrawrap queries for Barton
1 and 6 have similar query plans hence the execution times are
comparable. SQL Server outperforms the other systems on BSBM
queries 9 and 11 while Oracle outperforms the other systems
on Barton 3 and 4. For these cases, the optimizer pushed selects
down.

5.3.2. Augmented Ultrawrap experiment

Augmented Ultrawrap greedily applies the detection of unsatisfiable conditions optimization to the Ultrawrap SQL queries
prior to passing the query to the RDBMS for evaluation. Note, that
this optimization is not applicable to triple patterns with predicate variables. This should not, and did not impact the behavior of
queries with predicate variables. For clarity and space, the corresponding data is omitted. Fig. 13 contains the results for the Augmented Ultrawrap experiment.

J.F. Sequeda, D.P. Miranker / Web Semantics: Science, Services and Agents on the World Wide Web 22 (2013) 1939

Oracle, the optimizer did not push the join predicates down; hence
the poor query execution time.

Left-outer joins: We found that no commercial optimizer
eliminates self left-outer joins and OPTIONALs appear in many of
the queries where sub-optimal join orders are determined. The
experimental results are supportive of hearsay in the Semantic
Web community that the endemic use of OPTIONAL in SPARQL
queries, which compiles to a left-outer join,
is outside the
experience of the database community. We speculate that these
types of queries are not common in a relational setting, hence the
lack of support in commercial systems.

Join ordering: Join order is a major factor for poor query
execution time, both on Ultrawrap and benchmark-provided SQL
queries. Even though DB2 eliminated self-joins in the original
Ultrawrap experiment, the optimizer often generated sub-optimal
join order for the Ultrawrap queries but did so less often for the
Augmented Ultrawrap queries. A possible explanation is simply the
size of the search space. For Ultrawrap queries the optimizer has
to evaluate each query within the large union in the definition of
the Tripleviews. The Augmented Ultrawrap eliminates unneeded
UNION ALL elements, reducing the search space.

Counting NULLs: Each SFW statement of the Tripleview filters
null values. Such a filter could produce an overhead, however we
speculate that the optimizer has statistics of null values and avoids
the overhead.

7. Conclusion

RDB2RDF wrapper systems do not replicate relational database
content in order to support Semantic Web applications. Architectures that include such wrappers bypass any challenges that form
when a database is replicated. Similarly, wrappers provide a lowrisk path for existing IT organizations to develop semantic appli-
cations. The benefit is transparent in use cases where a semantic
application must operate in real-time on data that is being updated
by an existing relational database application.

To date, wrapper systems have suffered problems in performance and scalability [23,24]. Yet, enterprise class relational
database systems do not suffer so. Ultrawrap, and the experiments
in this paper move the focus to the relational systems. The primary
result being that the application of two known semantic query optimizations may yield a query plan typical of a relational query
plan, but starting from a logical plan representation of a SPARQL
query coupled with a logical plan entailing the specification of a
mapping from rows to triples. In this work, we consider SPARQL
1.0 [3].

The research commenced with a hypothesis that not only were
such optimizing transforms already known, but they are already
implemented in commercial software. To support the hypothesis, it
is not necessary to demonstrate that a single system is universally
good. Nor does the hypothesis stipulate that the optimizer will
do the right thing every time. However, where and how a system
failed to attain an excellent query plan is as critical to the analysis
as success. Although in some cases, as the target RDBMSs are
proprietary systems we can only speculate to root causes.

For SPARQL queries with bound predicate arguments the experimental results support the hypothesis. Two key optimizing
transformations do appear in commercial RDBMSs, and when applied render a SPARQL query plan comparable to the plan generated for benchmark provided SQL queries. These optimizations are
not unique. Experiments reveal a third optimization, join predicate push-down, which pushes join predicates into a view containing unions, enables useful performance improvements across the
workload, but does not rewrite the plan into one more typical of a
comparable SQL query.

Although we stipulated that tuned SQL query plans for the
benchmark provided SQL queries forms a good baseline, we cannot
rule out the existence of optimizations, perhaps not yet known in
the literature, that may provide for further improvement. The third
optimization, join predicate push-down underscores the problem
is not closed.

Even if one is satisfied with this papers existence proposition,
the empirical results still demonstrate there is work to be done.
Analysis of incongruous performance between benchmark SQL
queries and SPARQL queries revealed that relational optimizers
do not always determine optimal join orders. This is not news,
and even one of the benchmark SQL queries was not optimized
correctly. However, this issue manifest more often for the SPARQL
queries. We cannot examine the internals of these systems to
determine if the complexity of the Ultrawrap queries is challenging
the optimizers cost function, the search strategy or both. Recall
Ultrawrap transforms a SPARQL query to a SQL query by naively
substituting SPARQL operators in the SPARQL query plan with
relational operators. Independent of the reason for the optimizers
failing to determine optimal join orders, the mere fact that they are
failing suggests there is opportunity for improvement by means of
less naive translations.

Even though Ultrawrap was not compared to other RDB2RDF
wrapper systems, the results of the experiments show that SPARQL
queries with bound predicates on Ultrawrap execute at nearly the
same speed as semantically equivalent benchmark-provided SQL
queries. These results have not been accomplished by any other
RDB2RDF systems [23,24].

The only point of controversy may be our distinction of SPARQL
queries with predicate variables. In these queries, an RDB2RDF
mapping stipulates that the variable may be bound to the name
of any column in the database. With these semantics, none of
the commercial RDBMSs are able to eliminate any elements of
the Tripleview union. However, developers familiar with the SQL
schema of the RDBMS application are able to choose particular
columns from specific tables.

Queries with predicate variables should not be dismissed
as a special case. Queries of this form are intrinsic to faceted
search, an increasingly common use case. Even so, two arguments
that maintain support for our hypothesis include; one, per
Krishnamurthy et al. [48], predicate variables are a syntactic
construct of higher-order logic, therefore the simple SQL queries
expressed in the benchmark as equivalent to the SPARQL queries,
produce the same answers on the test data, (they are operationally
equivalent), but their formal semantics is not the same, and
thus should not be used as a basis of comparison. The formally
equivalent queries will contain a union [54] and bear comparable
performance penalty. A second, more constructive argument
is before writing the benchmark-provided SQL query, the SQL
developers determined, a priori, which attributes were relevant
to the query and which were inconsistent, and they themselves
detected unsatisfiable conditions and simply did not code them.
In any case, queries with unbound predicate variables remain an
open problem.

Acknowledgments

We thank Conor Cunningham for his advice on SQL Server and
Diego Funes for the implementation of the SPARQL to SQL query
translator. The name of our system, Ultrawrap, was adopted, in
part, to pay homage to the late Jack Schwartz who developed the
Ultracomputer, an early parallel computer.

This work was supported by the National Science Foundation
under grant 1018554. Juan Sequeda was supported by a NSF
Graduate Research Fellowship.

Appendix

A.1. Berlin SPARQL Benchmark BSBM

More information about the Berlin SPARQL Benchmark can be found: http://www4.wiwiss.fu-berlin.de/bizer/berlinsparqlbenchmark/.
The BSBM data generator can be downloaded from http://sourceforge.net/projects/bsbmtools/.

Query 1 (BSBM1). Find products of a certain type that have two different product features and have a minimum numeric property. This
query touches large amount of data and returns a small set of results. It consists of one BGP with 5 triple patterns and the Filter operator.

SPARQL:
PREFIX product: http://www.example.com/bsbm/product#
SELECT DISTINCT ?product ?label
WHERE {
?product product:label ?label.
?product product:producttype %ProductType%.
?product product:productfeature %ProductFeature1%.
?product product:productfeature %ProductFeature2%.
?product product:productPropertyNumeric1 ?value1.
FILTER (?value1 >%x%)

ORDER BY ?label

SQL:
SELECT distinct nr, label
FROM product p, producttypeproduct ptp
WHERE p.nr = ptp.product AND ptp.productType=@ProductType@
AND propertyNum1 >@x@
AND p.nr IN (SELECT distinct product FROM productfeatureproduct WHERE productFeature=@ProductFeature1@)
AND p.nr IN (SELECT distinct product FROM productfeatureproduct WHERE productFeature=@ProductFeature2@)
ORDER BY label

Query 2 (BSBM2). Find basic information about a product found in the previous query. This query touches on a small amount of data. It
consists of 4 BGPs with 11 triple patterns in the first BGP, 1 triple pattern in each of the other 3 BGPs and 3 OPTIONALs.

SPARQL:
PREFIX product: http://www.example.com/bsbm/product#
PREFIX producer: http://www.example.com/bsbm/producer#
PREFIX pf: http://www.example.com/bsbm/productfeature#
SELECT ?label ?comment ?producer ?productFeature ?propertyTextual1 ?propertyTextual2 ?propertyTextual3 ?propertyNumeric1

?propertyNumeric2 ?propertyTextual4 ?propertyTextual5 ?propertyNumeric4

WHERE {
FILTER(?x = %ProductXYZ%)
?x product:label ?label.
?x product:comment ?comment.
?x product:ref-producerID ?p.
?p producer:label ?producer.
?x product:productfeature ?f.
?f pf:label ?productFeature.
?x product:propertyTex1 ?propertyTextual1.
?x product:propertyTex2 ?propertyTextual2.
?x product:propertyTex3 ?propertyTextual3.
?x product:propertyNum1 ?propertyNumeric1.
?x product:propertyNum2 ?propertyNumeric2.
OPTIONAL {?x product:propertyTex4 ?propertyTextual4 }
OPTIONAL {?x product:propertyTex5 ?propertyTextual5 }
OPTIONAL {?x product:propertyNum4 ?propertyNumeric4 }

SQL:
SELECT pt.label, pt.comment, pt.producer, productFeature, propertyTex1, propertyTex2, propertyTex3, propertyNum1, propertyNum2,

propertyTex4, propertyTex5, propertyNum4

FROM product pt, producer pr, productfeatureproduct pfp

J.F. Sequeda, D.P. Miranker / Web Semantics: Science, Services and Agents on the World Wide Web 22 (2013) 1939

WHERE pt.nr=@ProductXYZ@ AND pt.nr=pfp.product AND pt.producer=pr.nr

Query 3 (BSBM3). Find products having several features but not having a specific other feature. This query touches large amounts of data
and includes negation as failure (optional with not bound). It consists of 2 BGPs with 5 triple patterns in the first BGP, 2 triple patterns for
the second BGP, 3 Filter operators and 1 Optional.

SPARQL:
PREFIX product: http://www.example.com/bsbm/product#
SELECT ?product ?label
WHERE {
?product product:label ?label.
?product product:producttype %ProductType%.
?product product:productfeature %ProductFeature1%.
?product product:propertyNum1 ?p1.
FILTER (?p1 >%x%)
?product product:propertyNum3 ?p3.
FILTER (?p3 < %y%)
OPTIONAL {

?product product:productfeature %ProductFeature2%.
?product product:label ?testVar }
FILTER (!bound(?testVar))

ORDER BY ?label

SQL:
SELECT p.nr, p.label
FROM product p, producttypeproduct ptp
WHERE p.nr=ptp.product AND productType=@ProductType@ AND propertyNum1>@x@
AND propertyNum3<@y@
AND @ProductFeature1@ IN (SELECT productFeature FROM productfeatureproduct WHERE product=p.nr)
AND @ProductFeature2@ NOT IN (SELECT productFeature FROM productfeatureproduct WHERE product=p.nr)
ORDER BY p.label

Query 4 (BSBM4). Find product that has two different sets of features. This query touches a large amount of data. It consists of 2 BGPs with
6 triple patterns in each BGP, a Filter operator in each BGP and a UNION operator that joins both BGPs.

SPARQL:
PREFIX product: http://www.example.com/bsbm/product#
SELECT DISTINCT ?product ?label ?propertyTextual
WHERE {

?product product:label ?label.
?product product:producttype %ProductType%.
?product bsbm:productfeature %ProductFeature1%.
?product bsbm:productfeature %ProductFeature2%.
?product bsbm:propertyTex1 ?propertyTextual.
?product bsbm:propertyNum1 ?p1.
FILTER (?p1 > %x%)
} UNION {
?product product:label ?label.
?product product:producttype %ProductType%.
?product product:productfeature %ProductFeature1%.
?product product:productfeature %ProductFeature3%.
?product product:propertyTex1 ?propertyTextual.
?product product:propertyNum2 ?p2.
FILTER (?p2 > %y%)

ORDER BY ?label

SQL:
SELECT distinct p.nr, p.label, p.propertyTex1
FROM product p, producttypeproduct ptp
WHERE p.nr=ptp.product AND ptp.productType=@ProductType@
AND p.nr IN (SELECT distinct product FROM productfeatureproduct WHERE productFeature=@ProductFeature1@)

AND ((propertyNum1>@x@ AND p.nr IN (SELECT distinct product FROM productfeatureproduct WHERE productFeature=
@ProductFeature2@)) OR (propertyNum2>@y@ AND p.nr IN (SELECT distinct product FROM productfeatureproduct WHERE
productFeature=@ProductFeature3@)))

ORDER BY label

Query 5 (BSBM5). Find products that are similar to a different product. This query touches a large amount of data with complex filters. It
consists of one BGP with 7 triple patterns and 3 filter operators.

SPARQL:
PREFIX product: http://www.example.com/bsbm/product#
SELECT DISTINCT ?product ?productLabel
WHERE {
FILTER (%ProductXYZ% != ?product)

?product product:label ?productLabel.

%ProductXYZ% product:productfeature ?prodFeature.
?product product:productfeature ?prodFeature.
%ProductXYZ% product:propertyNume1 ?origProperty1.
?product product:propertyNum1 ?simProperty1.
FILTER (?simProperty1 < (?origProperty1 + 120) && ?simProperty1 > (?origProperty1  120))
%ProductXYZ% product:propertyNum2 ?origProperty2.
?product bsbm:propertyNum2 ?simProperty2.
FILTER (?simProperty2 < (?origProperty2 + 170) && ?simProperty2 > (?origProperty2  170))

ORDER BY ?productLabel

SQL:
SELECT distinct p.nr, p.label
FROM product p, product po,
(Select distinct pfp1.product FROM productfeatureproduct pfp1, (SELECT productFeature FROM productfeatureproduct WHERE
product=@ProductXYZ@) pfp2 WHERE pfp2.productFeature=pfp1.productFeature) pfp WHERE p.nr=pfp.product AND po.nr=
@ProductXYZ@ AND p.nr!=po.nr

AND p.propertyNum1<(po.propertyNum1+120) AND p.propertyNum1>(po.propertyNum1-120)
AND p.propertyNum2<(po.propertyNum2+170) AND p.propertyNum2>(po.propertyNum2-170)
ORDER BY label

Query 6 (BSBM6). Find products having a label that contains a specific string. This query only touches the Product table. It consists of one
BGP with 2 triple patterns and a Filter for full text search.

SPARQL:
PREFIX product: http://www.example.com/bsbm/product#
SELECT ?product ?label
WHERE {

?product product:label ?label.
FILTER regex(?label, %word1%)

SQL:
SELECT nr, label
FROM product
WHERE label like %@word1@%

Query 7 (BSBM7). Find in-depth information about a product including offers and reviews. This query touches a large amount of data. It
consists of 5 BGPs with a total of 14 triple patterns within 4 different OPTIONAL clauses and a Filter for date. There are two OPTIONAL
clauses nested inside of another OPTIONAL clause.

SPARQL:
PREFIX product: http://www.example.com/bsbm/product#
PREFIX rev: http://www.example.com/bsbm/review#
PREFIX per: http://www.example.com/bsbm/person#
PREFIX offer: http://www.example.com/bsbm/offer#
PREFIX vendor: http://www.example.com/bsbm/vendor#
SELECT ?productLabel ?offer ?price ?vendor ?vendorTitle ?review ?revTitle ?reviewer ?revName ?rating1 ?rating2
WHERE {
%ProductXYZ% product:label ?productLabel.
OPTIONAL {

?offer offer:ref-productID %ProductXYZ%.
?offer offer:price ?price.
?offer offer:ref-vendorID ?vendor.

J.F. Sequeda, D.P. Miranker / Web Semantics: Science, Services and Agents on the World Wide Web 22 (2013) 1939

?vendor vendor:label ?vendorTitle.
?vendor vendor:country DE.
?offer offer:validTo ?date.
FILTER (?date > %currentDate%)

OPTIONAL {

?review rev:ref-productID %ProductXYZ%.
?review rev:ref-personID ?reviewer.
?reviewer per:name ?revName.
?review rev:title ?revTitle.
OPTIONAL {?review rev:rating1 ?rating1. }
OPTIONAL {?review rev:rating2 ?rating2. }

SQL:
SELECT *
FROM (select label from product where nr=@ProductXYZ@) p left join
((select o.nr as onr, o.price, v.nr as vnr, v.label from offer o, vendor v where @ProductXYZ@=o.product AND
o.vendor=v.nr AND v.country=DE AND o.validTo>@currentDate@) ov right join
(select r.nr as rnr, r.title, pn.nr as pnnr, pn.name, r.rating1, r.rating2 from review r, person pn where
r.product=@ProductXYZ@ AND r.person=pn.nr) rpn on (1=1)) on (1=1)

Query 8 (BSBM8). Find English reviews of a specific product. It consists of 5 BGPs with a total of 11 triple patterns and four separate
OPTIONAL clauses. Each OPTIONAL clause has one triple pattern

SPARQL:
PREFIX rev: http://www.example.com/bsbm/review#
PREFIX per: http://www.example.com/bsbm/person#
SELECT ?title ?text ?reviewDate ?reviewer ?reviewerName ?rating1 ?rating2 ?rating3 ?rating4
WHERE {

?review rev:ref-productID %ProductXYZ%.
?review rev:title ?title.
?review rev:text ?text.
?review rev:language EN.
?review rev:reviewDate ?reviewDate.
?review rev:ref-personID ?reviewer.
?reviewer per:name ?reviewerName.
OPTIONAL {?review rev:rating1 ?rating1. }
OPTIONAL {?review rev:rating2 ?rating2. }
OPTIONAL {?review rev:rating3 ?rating3. }
OPTIONAL {?review rev:rating4 ?rating4. }

ORDER BY DESC(?reviewDate)

SQL:
SELECT r.title, r.text, r.reviewDate, p.nr, p.name, r.rating1, r.rating2, r.rating3, r.rating4
FROM review r, person p
WHERE r.product=@ProductXYZ@ AND r.person=p.nr AND r.language=en
ORDER BY r.reviewDate desc

Query 9 (BSBM9). This query uses the SPARQL DESCRIBE operator, which is not defined in relational algebra. This query is translated as a
single triple pattern where the subject is bound while the predicate and object are unbounded. The benchmark-provided SQL query is a
select-project-join query which projects the attributes that are previously known to return the correct results.

SPARQL:
PREFIX rev: http://www.example.com/bsbm/review#
SELECT ?p ?o
WHERE {

%ReviewXYZ% rev:ref-personID ?x.
?x ?p ?o.

SQL:
SELECT p.nr, p.name, p.mbox_sha1sum, p.country, r2.nr, r2.product, r2.title
FROM review r, person p, review r2

WHERE r.nr=@ReviewXYZ@ AND r.person=p.nr AND r2.person=p.nr

Query 10 (BSBM10). Find offers for a given product that satisfy specific requirements. It consists of a single BGP with 7 triple patterns and
filters on a numeric and date value.

SPARQL:
PREFIX offer: http://www.example.com/bsbm/offer#
PREFIX vendor: http://www.example.com/bsbm/vendor#
SELECT DISTINCT ?offer ?price
WHERE {

?offer offer:ref-productID %ProductXYZ%.
?offer offer:ref-vendorID ?vendor.
?vendor vendor:country US.
?offer offer:deliveryDays ?deliveryDays.
FILTER (?deliveryDays <= 3)
?offer offer:price ?price.
?offer offer:validTo ?date.
FILTER (?date > %currentDate%)

ORDER BY xsd:double(str(?price))
SQL:
SELECT distinct o.nr, o.price
FROM offer o, vendor v
WHERE o.product=@ProductXYZ@ AND o.deliveryDays<=3 AND v.country=US
AND o.validTo>@currentDate@ AND o.vendor=v.nr
ORDER BY o.price

Query 11 (BSBM11). Find all the information about an offer. It consists of two BGP and each with one triple pattern. The first triple pattern
has a bound subject and unbounded predicate and object while the second triple pattern has a bound object and unbounded subject and
predicate. Both BGPs are joined with the UNION operator. The benchmark-provided SQL query is a select-project query which projects of
10 attributes.

SPARQL:
SELECT ?property ?hasValue ?isValueOf
WHERE {
{%OfferXYZ% ?property ?hasValue }

{?isValueOf ?property %OfferXYZ% }

SQL:
Select product, producer, vendor, price, validFrom, validTo, deliveryDays, offerWebpage, publisher, publishDate
from offer where nr=@OfferXYZ@.

Query 12 (BSBM12). Return specific information about a specific offer. This query touches large amount of data from the database.

SPARQL:
PREFIX offer: http://www.example.com/bsbm/offer#
PREFIX product: http://www.example.com/bsbm/product#
PREFIX vendor: http://www.example.com/bsbm/vendor#
SELECT ?productURI ?productlabel ?vendorname ?vendorhomepage ?offerURL ?price ?deliveryDays ?validTo
WHERE {
FILTER(?x = %OfferXYZ%)
?x offer:ref-productID ?productURI.
?productURI product:label ?productlabel.
?x offer:ref-vendorID ?vendorURI.
?vendorURI vendor:label ?vendorname.
?vendorURI vendor:homepage ?vendorhomepage.
?x offer:offerWebpage ?offerURL.
?x offer:price ?price.
?x offer:deliveryDays ?deliveryDays.
?x offer:validTo ?validTo

SQL:
Select p.nr As productNr, p.label As productlabel, v.label As vendorname, v.homepage As vendorhomepage, o.offerWebpage As offerURL,

o.price As price, o.deliveryDays As deliveryDays, o.validTo As validTo

J.F. Sequeda, D.P. Miranker / Web Semantics: Science, Services and Agents on the World Wide Web 22 (2013) 1939

From offer o, product p, vendor v
Where o.nr=@OfferXYZ@ AND o.product=p.nr AND o.vendor=v.nr

A.2. Barton Benchmark on DBLP schema

We create a relational version of DBLP by translating the DBLP XML dump to SQL.9 The DBLP XML dump and DTD can be downloaded

from: http://dblp.uni-trier.de/xml/

The DBLP XML to SQL software can be downloaded from: http://ribs.csres.utexas.edu/ultrawrap/dblpxml2sql.zip.

Query 1 (B1). This query has to calculate the counts of each different type of data in the database. It involves scanning the Tripleview for
types and a count of each object value.

SPARQL:
PREFIX rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns#
SELECT DISTINCT ?o (COUNT(?o) as ?counter)
WHERE {
?x rdf:type ?o

GROUP BY ?o

SQL query on Tripleview:
SELECT DISTINCT t1.o, COUNT(*)
FROM tripleview t1
WHERE t1.p = rdf:type
GROUP BY t1.o

SQL query on native relational schema:
select distinct DBLP_AUTHOR as p, count(*) from DBLP_AUTHOR union
select distinct DBLP_EDITOR as p, count(*) from DBLP_EDITOR union
select distinct DBLP_ENTITY as p, count(*) from DBLP_ENTITY union
select distinct DBLP_ENTITY_ARTICLE as p, count(*) from DBLP_ENTITY_ARTICLE union
select distinct DBLP_ENTITY_BOOK as p, count(*) from DBLP_ENTITY_BOOK union
select distinct DBLP_ENTITY_CDROM as p, count(*) from DBLP_ENTITY_CDROM union
select distinct DBLP_ENTITY_CITATION as p, count(*) from DBLP_ENTITY_CITATION union
select distinct DBLP_ENTITY_EE as p, count(*) from DBLP_ENTITY_EE union
select distinct DBLP_ENTITY_INCOLLECTION as p, count(*) from DBLP_ENTITY_INCOLLECTION union
select distinct DBLP_ENTITY_INPROCEEDINGS as p, count(*) from DBLP_ENTITY_INPROCEEDINGS union
select distinct DBLP_ENTITY_ISBN as p, count(*) from DBLP_ENTITY_ISBN union
select distinct DBLP_ENTITY_MSTHESIS as p, count(*) from DBLP_ENTITY_MSTHESIS union
select distinct DBLP_ENTITY_NOTE as p, count(*) from DBLP_ENTITY_NOTE union
select distinct DBLP_ENTITY_PHDTHESIS as p, count(*) from DBLP_ENTITY_PHDTHESIS union
select distinct DBLP_ENTITY_PROCEEDINGS as p, count(*) from DBLP_ENTITY_PROCEEDINGS union
select distinct DBLP_ENTITY_URL as p, count(*) from DBLP_ENTITY_URL union
select distinct DBLP_PUBLISHER as p, count(*) from DBLP_PUBLISHER

Query 2 (B2). The user selects In Proceedings from the previous panel. The faceted browser must present the user with a list of other
de?ned properties for resources of In Proceedings It must also calculate the frequency of these properties.

SPARQL:
PREFIX rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns#
SELECT DISTINCT ?p (COUNT(?p) as ?counter)
WHERE {
?s rdf:type <DBLP_ENTITY_ INPROCEEDINGS>.
?s ?p ?o

GROUP BY ?p

SQL query on Tripleview:
SELECT t2.p AS p, COUNT(*)

tripleview t1,
tripleview t2

9 We use a software program developed by Demian Lessa (demian@lessa.org).

t1.p = rdf:type AND
t1.o = DBLP_ENTITY_INPROCEEDINGS AND
t1.spk = t2.spk AND
t1.s = t2.s
GROUP BY t2.p

SQL query on native relational schema:
select distinct crossref as p, count(crossref) from DBLP_ ENTITY_INPROCEEDINGS union
select distinct year as p, count(year) from DBLP_ ENTITY_INPROCEEDINGS union
select distinct entityid as p, count(entityid) from DBLP_ ENTITY_INPROCEEDINGS union
select distinct rdf:type as p, count(*) from DBLP_ ENTITY_INPROCEEDINGS union
select distinct booktitle as p, count(booktitle) from DBLP_ ENTITY_INPROCEEDINGS union
select distinct pages as p, count(pages) from DBLP_ ENTITY_INPROCEEDINGS

Query 3 (B3). For each property defined on items of In Proceedings, populate the property panel with the counts of popular object values
for that property (where popular means that an object value appears more than once).

SPARQL:
PREFIX rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns#
SELECT DISTINCT ?p (COUNT(?p) as ?counter)
WHERE {
?s rdf:type <DBLP_ENTITY_ INPROCEEDINGS>.
?s ?p ?o

GROUP BY ?p ?o
HAVING (COUNT(?p) >1)

SQL query on Tripleview:
SELECT t2.p AS p, t2.o, COUNT(*)
FROM tripleview t1, tripleview t2

t1.p = rdf:type AND
t1.o = DBLP_ENTITY_INPROCEEDINGS AND
t1.spk = t2.spk AND
t1.s = t2.s
GROUP BY t2.p, t2.o
HAVING count(*) >1

SQL query on native relational schema:
select crossref as p, cast(crossref as varchar) as o, count(crossref) from DBLP_ENTITY_INPROCEEDINGS
GROUP BY crossref HAVING count(*) >1 union
select year as p, cast(year as varchar) as o, count(year) from DBLP_ENTITY_INPROCEEDINGS
GROUP BY year HAVING count(*) >1 union
select entityid as p, cast(entityid as varchar) as o, count(entityid) from DBLP_ENTITY_INPROCEEDINGS
GROUP BY entityid HAVING count(*) >1 union
select booktitle as p, cast(booktitle as varchar) as o, count(booktitle) from DBLP_ENTITY_INPROCEEDINGS
GROUP BY booktitle HAVING count(*) >1 union
select pages as p, cast(pages as varchar) as o, count(pages) from DBLP_ENTITY_INPROCEEDINGS
GROUP BY pages HAVING count(*) >1

Query 4 (B4). This query recalculates all of the property-object counts from Q3 if the user clicks on the 2000 value in the Year property
panel. Essentially this is narrowing the working set of subjects to those whose Type is In Proceedings and Year is 2000. This query has a
much higher-selectivity than Q3.

SPARQL:
PREFIX rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns#
SELECT DISTINCT ?p (COUNT(?p) as ?counter)
WHERE {
?s rdf:type <DBLP_ENTITY_ INPROCEEDINGS>.
?s <DBLP_ENTITY_ INPROCEEDINGS#year>2000.
?s ?p ?o

GROUP BY ?p ?o
HAVING (COUNT(?p) >1)

J.F. Sequeda, D.P. Miranker / Web Semantics: Science, Services and Agents on the World Wide Web 22 (2013) 1939

SQL query on Tripleview:
SELECT t2.p AS p, t2.o, COUNT(*)
FROM tripleview t1, tripleview t2, tripleview t3

t1.p = rdf:type AND
t1.o = DBLP_ENTITY_INPROCEEDINGS AND
t1.spk = t2.spk AND
t1.s = t2.s AND
t3.p = DBLP_ENTITY_INPROCEEDINGS#year AND
t3.o = 2000 AND
t1.spk = t3.spk AND
t1.s = t3.s
GROUP BY t2.p, t2.o
HAVING count(*) >1

SQL query on native relational schema:
select crossref as p, cast(crossref as varchar) as o, count(crossref) from DBLP_ENTITY_INPROCEEDINGS
WHERE year = 2000 GROUP BY crossref HAVING count(*) >1 union
select year as p, cast(year as varchar) as o, count(year) from DBLP_ENTITY_INPROCEEDINGS
WHERE year = 2000 GROUP BY year HAVING count(*) >1 union
select entityid as p, cast(entityid as varchar) as o, count(entityid) from DBLP_ENTITY_INPROCEEDINGS
WHERE year = 2000 GROUP BY entityid HAVING count(*) >1 union
select booktitle as p, cast(booktitle as varchar) as o, count(booktitle) from DBLP_ENTITY_INPROCEEDINGS
WHERE year = 2000 GROUP BY booktitle HAVING count(*) >1 union
select pages as p, cast(pages as varchar) as o, count(pages) from DBLP_ENTITY_INPROCEEDINGS
WHERE year = 2000 GROUP BY pages HAVING count(*) >1

Query 5 (B5). This is type of an inference query. If there are triples of the form (X was published by Y) and (Y has publisher name Z), then
we can say that X is a type Z publication. For example, if Paper1 was published by Publisher2 and Publisher2 has name Elsevier, then we
know that Paper1 is a type of Elsevier Publication. For this query, we want to find all the entities that have been edited by Editor 1, and
which have not been published by ACM.

SPARQL:
SELECT ?x ?y ?z
WHERE {
<DBLP_EDITOR/editorId=1><DBLP_EDITOR#DBLP_ENTITY>?x.
?x <DBLP_ENTITY#DBLP_ PUBLISHER>?y.
?y <DBLP_PUBLISHER#publisher>?z.
FILTER (?z != ACM)

SQL query on Tripleview:
SELECT t2.s as a_s, t3.s as b_o, t3.o as c_o
FROM tripleview t1, tripleview t2, tripleview t3

t1.s = DBLP_EDITOR/editorId=1 AND t1.spk = 1 AND

t1.p = DBLP_EDITOR#DBLP_ENTITY AND
t2.s = t1.o AND t2.spk = t1.opk AND
t2.p = DBLP_ENTITY#DBLP_PUBLISHER AND
t3.s = t2.o AND t3.spk = t2.opk AND
t3.p = DBLP_PUBLISHER#publisher AND
t3.o != ACM

SQL query on native relational schema:
select ep.entityId, p.publisherId, p.publisher
from DBLP_EDITOR e, DBLP_ENTITY_ EDITOR ee, DBLP_ENTITY_PUBLISHER ep, DBLP_PUBLISHER p where e.editorID= 1 AND ee.editorId

= e.editorId AND ee.entityId = ep.entityId and ep.publisherId = p.publisherId and p.publisher != ACM
Query 6 (B6). This query extracts information in aggregate form about all resources that are known to be of type Entity or inferred to be.

SPARQL:
PREFIX rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns#
SELECT DISTINCT ?p (COUNT(?p) as ?counter)
WHERE{
?s ?p ?o

?s rdf:type <DBLP_ENTITY>

?s <DBLP_EDITOR#DBLP_ ENTITY>?x.
?y rdf:type <DBLP_ENTITY>

GROUP BY ?p

SQL query on Tripleview:
SELECT t1.p, count(*) FROM tripleview AS t1,

(SELECT t2.s, t2.spk FROM tripleview t2 WHERE t2.p = rdf:type AND t2.o = DBLP_ENTITY)

(SELECT t3.s, t3.spk FROM tripleview t3, tripleview t4
WHERE t3.p = DBLP_EDITOR#DBLP_ENTITY AND t3.o = t4.s AND t3.opk = t4.spk
AND t4.p = rdf:type AND t4.o = DBLP_ENTITY)
) AS uniontable
WHERE t1.s = uniontable.s AND t1.spk = uniontable.spk GROUP BY t1.p
SQL query on native relational schema:
select DBLP_EDITOR#DBLP_ENTITY, count(*) from DBLP_ENTITY_EDITOR AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#DBLP_ENTITY_CDROM, count(*) from DBLP_ ENTITY_CDROM AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#DBLP_ENTITY_EE, count(*) from DBLP_ ENTITY_EE AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#DBLP_ENTITY_ISBN, count(*) from DBLP_ ENTITY_ISBN AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#DBLP_ENTITY_NOTE, count(*) from DBLP_ ENTITY_NOTE AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#DBLP_ENTITY_PHDTHESIS, count(*) from DBLP_ ENTITY_PHDTHESIS AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#key, count(key_) from DBLP_ENTITY AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#DBLP_EDITOR, count(*) from DBLP_ENTITY_EDITOR AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

select DBLP_ENTITY#DBLP_BOOK, count(*) from DBLP_ENTITY_BOOK AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#DBLP_ ENTITY_INCOLLECTION, count(*) from DBLP_ ENTITY_INCOLLECTION AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#title, count(title) from DBLP_ENTITY AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

uniontable.entityId

select DBLP_ENTITY#type, count(type) from DBLP_ENTITY AS t1,

J.F. Sequeda, D.P. Miranker / Web Semantics: Science, Services and Agents on the World Wide Web 22 (2013) 1939

((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#DBLP_ ENTITY_CITATION, count(*) from DBLP_ ENTITY_CITATION AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#DBLP_ ENTITY_PROCEEDINGS, count(*) from DBLP_ ENTITY_PROCEEDINGS AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

uniontable.entityId

select DBLP_ENTITY#DBLP_ ENTITY_URL, count(*) from DBLP_ ENTITY_URL AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#mdate, count(mdate) from DBLP_ENTITY AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select rdf:type, count(*) from DBLP_ENTITY AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#DBLP_ ENTITY_AUTHOR, count(*) from DBLP_ ENTITY_AUTHOR AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#DBLP_ ENTITY_ARTICLE, count(*) from DBLP_ ENTITY_ARTICLE AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#DBLP_ ENTITY_INPROCEEDINGS, count(*) from DBLP_ ENTITY_INPROCEEDINGS AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_ENTITY#DBLP_ ENTITY_PUBLISHER, count(*) from DBLP_ ENTITY_PUBLISHER AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.entityId =

select DBLP_EDITOR#editor, count(*) from DBLP_EDITOR AS t1,
((select entityId from DBLP_ENTITY) UNION (select entityId from DBLP_ENTITY_EDITOR)) AS uniontable where t1.editorId =

Query 7 (B7). This query returns all the In-Proceedings, their book title and cross-reference that were published in 2010. This is a simple
query that consists of a single BGP with 3 triple patterns.

SPARQL:
SELECT ?x ?y ?z
WHERE {
?x <DBLP_ENTITY_ INPROCEEDINGS#year>2010.
?x <DBLP_ENTITY_ INPROCEEDINGS#booktitle>?y.
?x <DBLP_ENTITY_ INPROCEEDINGS#crossref>?z.

SQL query on Tripleview:
SELECT t1.s as a_s, t2.o as b_o, t3.o as c_o
FROM tripleview t1, tripleview t2, tripleview t3

t1.p = DBLP_ENTITY_INPROCEEDINGS#year AND
t1.o = 2010 AND
t2.s = t1.s AND t2.spk = t1.spk AND
t2.p = DBLP_ENTITY_ INPROCEEDINGS#booktitle AND
t3.s = t2.s AND t3.spk = t2.spk AND
t3.p = DBLP_ENTITY_ INPROCEEDINGS#crossref
SQL query on native relational schema:
