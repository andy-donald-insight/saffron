Towards Evaluation and Comparison of Tools for Ontology

Population from Spreadsheet Data

Christian Doppler Laboratory for Software Engineering Integration for Flexible Automation Systems

Olga Kovalenko, Estefania Serral and Stefan Biffl

Favoritenstrasse 9-11/E188, A-1040 Vienna

Vienna University of Technology
name.surname@tuwien.ac.at

ABSTRACT
Semantic Web technologies and ontologies increasingly provide mission-critical capabilities for a variety of applications,
not only in the Web, but also in industry projects to facilitate semantic integration and interoperability between heterogeneous systems. Due to this proliferation in the use
of ontologies, technologies and tools have been developed
to facilitate the ontology engineering process and ontology
population, as a part of this process. As spreadsheets are
widely used to store and exchange data, academia and industry have developed a range of tools and mapping techniques
to support the (semi-)automated translation of spreadsheet
data into OWL/RDF. Existing tools vary in many aspects,
therefore it can be difficult to select tool that fits best for
a specific usage context. In this paper we analyzed several
types of end users, which could be interested to apply such
tools in their workflow, and their specific needs. Based on
this analysis we propose an evaluation framework that could
facilitate tools comparison; and c) search for an appropriate
tool for a specific task/problem.
In order to validate the
proposed evaluation framework, a qualitative analysis of a
set of six tools for ontology population has been performed.

Categories and Subject Descriptors
H.4.1 [Information Systems]: Office AutomationSpreadPermission to make digital or hard copies of all or part

of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for
profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for
components of this work owned by others than the author(s)
must be honored. Abstracting with credit is permitted. To
copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from Permissions@acm.org.
ISEM 13, September 04 - 06 2013, Graz, Austria
Copyright is held by the owner/author(s). Publication rights
licensed to ACM.
ACM 978-1-4503-1972-0/13/09. . . $15.00
http://dx.doi.org/10.1145/2506182.2506190

sheets; H.2.5 [Information Systems]: Heterogeneous Databases
Data translation

General Terms
Measurement

Keywords
Ontology engineering, ontology population, knowledge ex-
traction, data transformation, spreadsheet data

INTRODUCTION

1.
Semantic Web technologies and ontologies support semantic integration and semantic interoperability in a variety of
mission-critical applications, from online services to enterprise systems. Due to the proliferation in the use of on-
tologies, a variety of tools have been developed to support
the ontology engineering starting from all-round development environments, aiming at embracing all aspects of the
ontology engineering process, to narrowly focused tools that
support one specific task within the whole process, e.g., mappings definition or ontology alignment.

Ontology engineering is inevitably an iterative process [11].
According to Gazevic et al it includes the following activi-
ties: design, implementation, evaluation, validation, main-
tenance, deployment, mapping,
integration, sharing, and
reuse [4]. Focusing particularly on the implementation and
speaking from the practical point of view Noy et al had
distinguished following steps to implement an ontology: a)
definition of classes; b) arranging classes into a taxonomy;
c) defining properties and allowable values for them; d) creating the instances [11]. The first three steps concern specification of the vocabulary to describe a given domain; and
last one (instances creation) refers to ontology population,
which is an important final step in order to obtain data for
further analysis. As it is unlikely that all necessary data
already is represented in other ontologies or using Semantic
Web-related technologies, ontology population for the realworld applications requires data extraction and data elicitation from the legacy systems and existing proprietary data.
Considering the amount of data that must be managed in
real-world systems, ontology population undoubtedly must
be tool-supported and automated, as performing it manually
will be extremely time-consuming and error-prone task.

Most proprietary data that serves as a source for ontology population is stored as (semi-)structured data, e.g. using spreadsheets, XML-files, or databases. The problem of

                                               57data transformation from relational databases (RDB) into
OWL and RDF formats has been addressed by many au-
thors. Some important papers in this area are [2, 3, 8];
plenty of work on this topic is covered within the W3C
RDB2RDF Working Group1 with the R2RML2, a language
to define customized mappings from relational databases to
RDF datasets, as one of the main deliveries. In contrary, the
problem of data extraction from spreadsheet data is surprisingly less addressed from the scientific community, although
spreadsheets still remain as a popular way to share, store,
and exchange data. Spreadsheets are easy to understand
and do not require sophisticated skills from users; they provide intuitive interfaces to capture the similarity of data;
and have representational power and expressiveness that are
sufficient for many common purposes. At the same time,
such simplicity and flexibility in the data representation often leads to a situation when the creation of spreadsheets
does not follow the best practices of data representation.
Also, the data schema in this case is implicit, which makes
it more difficult to process data automatically, correctly and
efficiently.

The wide use of spreadsheets in companies, organizations,
and research institutions has motivated both academia and
industry to develop a range of tools and mapping techniques
for (semi-)automated transformation of spreadsheets content into Semantic Web formats, i.e., OWL or RDF, without writing ad hoc extraction programs. The available tools
vary in many aspects, e.g., input and output formats sup-
ported, the complexity of spreadsheets they can deal with,
and the required level of user expertise. Therefore, it may be
a challenge to find the best fitting tool for a usage context.

To the best of our knowledge there is no up to date work
done that would provide a comprehensive view on the problem of (semi-)automated ontology population from spreadsheet data as well as there is no reports on attempts to
classify or categorize existing approaches and tools for this
problem. Villaz on-Terrazas et al. presented a brief survey
of methods and tools to convert a content of non-ontological
resources into ontologies [14]. The authors distinguished between 4 types of non-ontological resources: flat files, spread-
sheets, XML files and relational databases. However, most
of the tools considered in the paper can extract the schema
(classes and properties) from the non-ontological resource,
but not instances. In addition, they did not consider any
specific tools or methods that can transform the content of
spreadsheet into ontologies. Due to the lack of comprehensive and credible information on the ontology population
from spreadsheet data, it would be complicated to choose a
proper tool: a user would need either to independently analyze presented work in this area or just to choose randomly
a certain tool that can be not optimal for his requirements.
The goal of this paper is to fill this gap by a) analyzing
the typical users, which can be interested in transforming
spreadsheet data into ontology, and their needs; b) introducing an evaluation framework that can be used to perform
tools classification and comparison, and facilitate search for
an appropriate tool for a specific task; and c) evaluating
a representative set of tools for ontology population from

1http://www.w3.org/2001/sw/rdb2rdf/
2http://www.w3.org/TR/r2rml/

spreadsheet data and giving the recommendation on what
tools could better fit for a certain user type. The main aim
is to bring an insight on state-of-the-art in this area and
alleviate search of an appropriate tool for a specific task.

The rest of the paper is organized as follows:
in Section 2
we derived criteria for our framework based on analysis of a)
relevant types of end users and their needs; and b) analysis
of a related work on ontology population and data transformation from spreadsheets into Semantic Web formats.
In
Section 3 we discuss existing tools for ontology population
and designate several categories of such tools; the motivation behind the selection of tools that will be included into
following tools analysis is also explained.
In Section 4 a
qualitative analysis of a set of seven different tools is performed using proposed evaluation framework. In Section 5
an example of the tool selection for a specific user context
based on the proposed evaluation framework is considered.
Section 6 concludes the paper and summarises the results of
tools analysis.

2. EVALUATION FRAMEWORK FOR TOOLS

COMPARISON

In this section we have analyzed different types of end users
of tools for ontology population from spreadsheet data and
their specific needs in order to derive the evaluation crite-
ria. Additionally, we have reviewed existing related work on
ontology population and data transformation from spreadsheets into RDF/OWL in order to identify further criteria
that can be important for tool comparison and tool evalua-
tion. The resulting set of evaluation criteria is presented in
the end of the section.

2.1 Analysis of the End Users of Tools for Ontology Population from Spreadsheet Data
Since the main goal of our framework is to facilitate selection of a suitable tool in a given user context, we have followed the guidelines of recommender systems area stating
that proper evaluation requires understanding of goals and
tasks of the end user [5]. For this purpose we analyze the
relevant types of end users that can be interested in populating ontologies from spreadsheets data during their workflow.
According to Kobsa when modeling user stereotype it is important to identify user subgroup and its key characteristics
with particular focus on the assessment of the users backgroung knowledge [7]. In order to distinguish types of the
end users and to better understand their needs we addressed
the following questions: a) what is the users background,
i.e. what technologies and tools are users already familiar
with?; b) why does a user need to transform spreadsheet
data into ontologies?; c) what are the size and complexity
of a typical data set?; and d) what does a user need to learn
to accomplish the ontology population task effectively and
efficiently? and e) are there any features of a user workflow that must be taken into consideration when choosing
an ontology population tool?.

2.1.1 End User Types
Semantic Web Experts
This type of end users can be characterized as experts in
Semantic Web field. They have a deep knowledge about

                                               58ontology languages and data representation using OWL or
RDF formats. However, they typically have only limited
knowledge in the domain field where the data comes from.
For instance, if the spreadsheets include data for a certain
financial report, it could be difficult for this type of users to
realize all relations and interdependencies of corresponding
data, i.e. the meaning of data, even if they have a good
command of managing spreadsheets in general.

There are two typical use cases in which a Semantic Web
expert could need to populate ontologies from spreadsheet
data: a) he needs to analyse or compare some ontologyrelated tools (e.g., ontology development, ontology matching
or ontology querying tools) and therefore wants to put data,
which he already has in spreadsheets, into ontologies; b) he
aims to analyse the data itself using the advantages provided
by Semantic Web technology, e.g.
such as reasoning and
inference.

The size of the data sets the Semantic Web experts work
with is usually relatively not big, comparing with data size
in real world applications. Speaking in terms of ontologies it
can be thousands of instances, in contrast to millions of instances in case of real-world applications. The reason is that
often it is enough to provide a prototype implementation to
validate applied ideas and/or methods.

An important feature of the Semantic Web experts work-
flow, which must be considered when choosing a suitable
tool for ontology population from spreadsheet data, is that
they usually already have a habitual set of tools, which they
use to work with Semantic Web data, e.g. Prot eg e3 ontology
editor is very widespread among researchers. In this case it
would be better if the user could stick to his tools, e.g. by using some external plug-in, instead of being required to learn
and configure a tool that he was not familiar before. Also
the tool license can be an important issue as in some cases
usage of the open-source or free software may be required.

Domain Experts
Unlike the Semantic Web experts, domain experts typically
have deep knowledge of the domain, where the spreadsheet
data originates from, and thus, very good comprehension of
the meaning of data, but very limited, if any, knowledge
in Semantic Web technologies.

A typical use case would be that the domain expert needs
to use advanced applications and tools, which take data in
OWL or RDF format as input, and therefore he needs to
convert his proprietary spreadsheet data into these formats.
Examples of such advanced applications could be consistency checking or executing of comprehensive queries over
the heterogeneous data.

The size of data that domain experts work with can be characterized as huge. When transformed into ontologies it can
be millions of instances or TBs of original proprietary data.
Also, the complexity of spreadsheet data itself can be rather
high. For an instance, in the financial domain it is often
that data is spread over many sheets within the file, each
sheet contains several spreadsheets or the data is irregularly

3http://protege.stanford.edu/

structured within the sheet. Moreover, the sheets are not
independent from each other, instead there are complex interrelations and dependencies between the data comprised
in different sheets.

As domain experts work with real world data the reliability
and accuracy of a given tool become extremely important
issues. The preference may be given to mature tools that
already have a long history of application and therefore the
probability of bugs or malfunctions is lesser comparing to
the tools that are still on a prototype phase. Taking into
account typically very limited knowledge of domain experts
in the Semantic Web technologies it also may be reasonable
to pay more for a reliable commercial tool with a strong
user-support service provided. Another important issue is
whether additional possibilities for data analysis are provided by a given tool, e.g. querying of data, so that the
domain expert can use the same tool for the purposes of his
use case.

Software Developers
The software developers are experts in software engineer-
ing, but lack knowledge in the Semantic Web field, i.e. it is
very unlikely that they have worked with ontologies before.
Regarding the domain knowledge, software developers typically have limited understanding of the domain, only to an
extent that is needed to perform their specific task within
the software engineering process.

A typical use case for software developers could be that a
client company decided to switch to a new technology and
apply Semantic Web technologies and ontologies in order to,
e.g., obtain data integration and data interoperability across
their projects. In these circumstances software developers
could need to populate ontology with test data that was
previously stored in spreadsheets.

Regarding the size of data, for the software developers it is
the same as for the domain experts, because they also work
with real-world scale data.

Similar to domain experts, reliability and accuracy of a given
tool are important issues for software developers use cases.
However, a vast experience in configuring, debugging and
learning of new software, which the software developers usually have, will facilitate adjusting of an ontology population
tool for their specific use cases. Thus, the tools that do not
provide extensive user support or user-friendly interactive
interfaces, wont introduce serious obstacle for this type of
end users

2.1.2 Criteria from End User Analysis
Based on the needs of these three main types of end users
we derived following criteria for our evaluation framework.

General Information contains useful information that describes what kind of a tool it is in general. It is further refined into Maturity, e.g., prototype, beta version or release;
License, e.g., free or commercial; and Type, e.g., plug-in,
stand-alone tool or web service.
Expressiveness determines the complexity of data that can
be managed by a given tool, e.g., whether it can process only
rather simple spreadsheets, which conform to entity-per-

                                               59row assumption or it can deal also with more sophisticated
data, e.g., process multiple spreadsheets/sheets or unconventionally structured data; manage formulas and macros;
and resolve blank nodes;
Multi-user support originates from the need to manage
big volumes of data. Being able to share the work and proceed in parallel would facilitate the ontology population and
reduce the time needed to accomplish this task;
Usability describes how convenient and easy to use is a
given tool if consider from the user point of view. This
criterion is further divided into 2 sub criteria: GUI and Required User Knowledge. GUI shows whether the graphical
user interface is available to facilitate mappings definition
and next data transformation. Required User Knowledge
reflects what knowledge is required from the user to be able
to work with a given tool, e.g., it can be enough to only be
familiar with spreadsheets technology; or user will need to
manage also Semantic Web technology or have a good command of RDF;
Required software provides information about software
required by tool to operate.
It can be e.g., Prot eg e environment for its plug-ins or MS Excel for the tools that are
integrated in this environment.
Additional features describes additional possibilities provided by a given tool, e.g., an ability to execute SPARQL
queries.

2.2 Literature Analysis on Tools for Ontology

Population from Spreadsheet Data

In order to identify further criteria, relevant for tool evaluation and comparison, we have studied the most important
related work [1, 6, 9, 10, 12, 13] on ontology population and
data transformation from spreadsheets into Semantic Web
formats. Our main goal was to investigate the motivation for
the development of a specific tool and also the requirements
that were imposed to the functionality and operation of a
particular tool. From this analysis we derived the following
additional criteria, which are more technical comparing to
those, that were derived from the end user analysis:

Input format characterizes what types of files can be processed by a given tool. It can be for an instance Excel spread-
sheets, .CSV, files or Open Office spreadsheets.
Output format determines what types of output can be
generated by a given tool.
It can be either RDF (RDF
Schema) or OWL; or both of them.
Mappings describes how the process of mappings definition between the spreadsheet and output file is managed in
a given tool. This criterion is subdivided into following sub
criteria: Internal Representation, External Representation
and Storage. Internal Representation determines the internal structure of mapping, i.e., how they are presented inside
the tool. External Representation determines how mappings
are presented to the user. It can be done, for example, using graph-based approach or a textual representation. The
last sub criterion Storage determines how the mappings are
stored, e.g., in an external file or directly in the spreadsheet.

2.3 Evaluation Framework Criteria
In the following we summarize all criteria that have been
inferred as a result of before mentioned end user and liter-

ature analysis. Note that the order, in which the criteria
are presented, does not mean any ranking according to their
significance.

(C1) General Information with Maturity, License and
Type as sub criteria;
(C2) Usability with GUI and Required User Knowledge
as sub criteria;
(C3) Input format;
(C4) Output format;
(C5) Mappings with Internal Representation, External Representation and Storage as sub criteria;
(C6) Expressiveness;
(C7) Multi-user support;
(C8) Required software;
(C9) Additional features.

The presented criteria can be used to perform several tasks:
a) classification of tools; b) comparison of existing tools; and
c) search for an appropriate tool for a specific task/problem.

3. TOOLS OVERVIEW AND CATEGORIZA-

There is a variety of tools, which aim to facilitate the process
of ontology population from spreadsheets. For our analysis
we consider also tools that support data translation from
spreadsheets to RDF graphs, because as soon as data is presented in a form of RDF triples it can be further processed in
order to obtain OWL ontology, using for an instance OWL
Syntax Converter4. In general, all tools that support ontology population from spreadsheet data can be divided into
four main categories.

The first category includes tools that produce an RDF graph
as an output. Usually they provide a graphical template,
using which user specifies how a specific part of a spreadsheet will be converted into an RDF document. During the
translation, an intermediate RDF graph is created for every part of the spreadsheet according to the rules defined
by the user. Resulting RDF graph then is generated by
merging all of the intermediate graphs, removing duplicated
resources and triples if needed. Although such tools usually
provide some graphical representation for the user, which facilitates dealing with RDF graphs, the language that is used
to define mappings (expressions that will be used to calculate values/labels of vertexes in final RDF graph) is rather
complex and requires good understanding of both RDF and
principles of data representation in spreadsheets.

Second category comprises tools that support converting of
the content of spreadsheets into OWL ontologies. Most of
these tools proceed in the following way: they take a spreadsheet as an input and then allow user to define the rules, according to which data transformation will be performed. To
define the rules either special mapping language is used or a
tool provides an interactive GUI that leads the user during
the rules definition.

Another important category includes tools that are not specifically targeted to transform spreadsheet data into RDF or
OWL, but instead represent multipurpose Semantic Web de-

4http://owl.cs.manchester.ac.uk/converter/

                                               60velopment environments aiming to cover the whole ontology
engineering process. Such tools provide the ability to transform spreadsheet data into RDF graph or ontology instances
as an additional feature, together with many others extra
features that they have, e.g. ability to execute SPARQL5
queries or define SWRL6 rules. Although such tools usually put big focus on providing user-friendly and interactive
interfaces and support services for their users, it can be challenging for the user, which is interested only in using one of
provided features to transform his spreadsheet data, to learn
the whole complex environment before he will learn how to
use this specific feature. Also, tools from this category are
usually commercial and high-priced.

Last category includes tools that do not provide exact possibility of converting data from spreadsheets to RDF or OWL,
but instead aim to simplify the process of ontology population by hiding the Semantic Web technology behind simple
and easily understandable spreadsheets-like user interface.
It helps to bring domain experts and other users that are
not familiar with Semantic Web technologies for participating in knowledge collecting, thus, supporting the ontology
population process.

Due to space constraints this paper does not aim to provide
a comprehensive analysis of available tools for data transformation from spreadsheets into RDF and OWL, but instead
we would like to bring an insight on what types of tools are
available for this task and what are the main differences between them. Therefore, we decided to choose several best
known tool from each of the described above categories to
analyze them using the introduced evaluation framework.
For this purpose we have chosen seven tools: RDF123 7,
XLWrap [9], and Google Refine8 as the representatives of
the first category. The latter one is intended as a workbench to work with a messy data, but supports export to
RDF through the external extension RDF Refine9. Also, we
have chosen Anzo suite 10 from Cambridge Semantics and
Mapping Master [13] from the second category; TopBraid
Composer 11 as a sample of multipurpose ontology development environment; and Populous [6] as a representative of
the fourth category.

4. QUALITATIVE ANALYSIS AND COMPAR-

ISON OF TOOLS

In this section we use the proposed evaluation framework
to perform qualitative analysis and comparison of the seven
chosen tools, which aim to support data transformation from
spreadsheets into Semantic Web formats. The results of tool
analysis show that they strongly vary by provided capabilities and features. Table 1 below summarizes the results of
the performed tools comparison.

5http://www.w3.org/TR/rdf-sparql-query/
6http://www.w3.org/Submission/SWRL/
7RDF123 Web site: http://rdf123.umbc.edu/
8http://code.google.com/p/google-refine/
9http://refine.deri.ie/rdfExportDocs
10Anzo express: http://www.cambridgesemantics.com/en/
products/anzoexpress
11Topquadrant: http://www.topquadrant.com/products/TB
Composer.html

The considered tools strongly vary by their maturity level
and type. Most of the tools are presented as a research
prototypes or beta-versions. Only 3 tools: two commercial -
Anzo for Excel and TopBraid Composer ; and Google Refine
- are distributed as a release. Also, most of the tools are
stand alone applications, one (Mapping Master ) is a plugin for Prot eg e development environment and one (Anzo for
Excel ) is a plug-in to work with MS Excel.

Regarding the usability issue, most tools, except for the
XLWrap, provide at least user interface to facilitate mapping process. For an instance Mapping Master as a plug-in
provides user interface via special tab in Prot eg e. To employ this tool user must be able to work with Prot eg e, which
means that he must know and understand the Semantic Web
technology at relatively high level. Also, the domain specific
language that is used to define mappings in Mapping Master
is rather sophisticated and requires good understanding of
how the rows and columns indexes are managed in spreadsheets combined with the knowledge of RDF and OWL data
types and data representation mechanisms. RDF123 and
XLWRap require good command of RDF technology, and
only one of these tools - RDF123 - provides a GUI to facilitate mappings definition process. Populous can be treated
as quite user-friendly tool, as it provides simple GUI to populate ontology in a form of spreadsheet. However, to make
a final transformation of filled spreadsheet into OWL ontology user should be able to write OPPL scripts or he will
need an assistance of a software engineer. Anzo for Excel is integrated into the MS Excel environment and GUI
is thereby provided by MS Excel. TopBraid Composer has
basically well elaborated and user-friendly GUI, but as a development environment for Semantic Web application it has
a plenty of additional features and capabilities, which influence also the complexity of the user interface. Thus, besides
for willingness to pay for the licence, a good understanding
of Semantic Web technology will be required from the user
to work with it. Google Refine provides rich data analysis
and refinement possibilities, however one will need to use its
own expression language - GREL for this purpose. RDF Refine provides user-friendly GUI to define how current project
will be transformed into RDF, but the good understanding
of RDF technology is still required from the user.

Speaking of input format, most tools can deal with Excel spreadsheets and .CSV files; few can process also Open
Office spreadsheets. Populous needs additionally an OWL
ontology as input to use it as a schema model. Google Refine
has also an extension that allows importing Google spreadsheets into the project.

Concerning output format, RDF123 and XLWrap can
produce only RDF graphs; Top Braid Composer generates
output in form of RDF schema; Google Refine generates
RDF/XML or RDF Turtle as an output; Populous and Mapping Master both allow output only in form of OWL ontology and only one tool - Anzo for Excel, which is commercial
tool from Cambridge Semantics, can generate both OWL
and RDF as output.

Another aspect to consider is the technology used to map
the content of a spreadsheet to an OWL ontology or RDF.
Unfortunately, there is no information regarding this aspect

                                               61E








 e

 e


fi


fi


fi


fi


fi


fi


fi


 e

 e


 e

 e


fi


fi


fi


fi


                                               62available for the commercial tools, so we had to restrict
our analysis here only to open source tools. For Google
Refine the only information available is the external representation of mappings. Basically user designs the desired
RDF graph using a graphical skeleton that describes what
resources and literals must be incuded in the resulting RDF
graph. RDF123 and XLWrap encode mapping information
in a form of a RDF graph and store it as an external file, so
it can be reused later or different map files can be applied
to the source spreadsheet in order to obtain different RDF
representations of the same spreadsheet. Mapping Master
uses domain specific language to define a set of mapping
expressions that describe how the content of a spreadsheet
should be transformed into the target OWL ontology. Populous use OPPL language as a basis for its mappings that
then are used to transform the data from spreadsheet representation into the OWL ontology.

Speaking of expressiveness of a certain tool, RDF123 allows processing of rather complex spreadsheet data, including managing of formulas and macros and resolving of blank
nodes, but only within one sheet. XLWrap goes further and
allows additionally processing multiple sheets and files and
arbitrarily structured data within one sheet. Mapping Master can process rather complex spreadsheets but only within
one sheet and file.
It allows defining cell filters that will
identify the set of cells to be transformed according to specific mapping rule. Populous presents data following simple
entity-per-row assumption, when each row corresponds to
a set of related entities and each column represents the type
of relationship. It does not allow definition of sophisticated
filters or complex mapping expressions, but is useful when a
repeating design pattern appears through the ontology that
makes it reasonable to populate it in bulk. Anzo for Excel can process spreadsheet data across multiple sheets in
MS Excel and can work with more complex layouts, than
just on plain, tabular spreadsheets, and also with formulas and macros. Regarding the expressiveness of Top Braid
Composer there is a lack of detailed information, except for
rather advertising-like features description, therefore we refrain from stating anything regarding this aspect of the tool.
Google Refine provides various operations to refine tabular
data, but the definition of the transformation into RDF is
rather straight forward: users define what resources and literals from the current project will be included in the resulting RDF graph, what relations to set between them, and
what URIs to use for resources [10].

Concerning the possibility of multi-user support, this feature is provided only by commercial tools Anzo for Excel and
TopBraid Composer.

Speaking of required software to use a given tool, using of
MS Office will be needed to work with Anzo for Excel as it
is integrated with in MS Excel environment. Also, usage of
Prot eg e will be required to work with Mapping Master plug-
in. Google Refine requires the installation of its external
extension - RDF Refine, to export the data as RDF. Rest
of tools do not have any special requirements for additional
software.

The majority of tools are intended to facilitate only data
transformation from spreadsheets into Semantic Web for-

mats and it is their main or single application. To this
category belong all considered tools, except for TopBraid
Composer and Google Refine. The first one is a comprehensive development environment that has a lot of capabilities,
besides the ontology population from spreadsheets. Google
Refine is intended to clean and reconcile the messy data
and its main functionalities focus in various operations to
manipulate with data in a bulk; RDF export is provided as
an additional feature through the external extension - RDF
Refine. Additionally, XLWrap and Anzo for Excel provide
possibility to execute SPARQL queries.

Summarizing, there are no better or worse tools in general.
Existing tools for ontology population from spreadsheet data
strongly vary in many aspects. In order to understand what
tool will fit better in a specific use case context and for a specific end user, it is important to analyze all possible options
over a set of well-founded evaluation criteria. Depending
of the use case some criteria could become more important
than other and therefore will have a stronger impact on final
tool selection.

5. EXAMPLE OF TOOL SELECTION US-

ING EVALUATION FRAMEWORK

In this section we consider an example of a specific usage
context and recommend what tool couls fit better based on
specific user requirements and information obtained from
the tool analysis in previous section.

Consider a reseacher that is an expert in Semantic Web technologies and would like to perform the consistency checking
of his data obtained from the industry partners. He wants to
use reasoning and inference provided by Semantic Web tech-
nologies, in particular SPARQL queries to work with data.
Original data is presended in the single Excel file within one
sheet, the spreadsheet contains about 20 columns and 1000
rows, but is unconventionally structured. Therefore, the reseacher wants to transform the data from the spreadsheet
into OWL ontology. Also, the researcher is familiar with
Prot eg e ontology editor, uses it in his habitual workflow and
would prefer tools, which operate based on Prot eg e.

Possible preferences and requirements of the researcher regarding the tool for ontology population in such use case are
summarized in Table 2. The values in Importance column
show the significance of a certain criterion for the researcher,
e.g., in this particular use case the Required software and
the Output format have high priority and such criteria as
Multi-user support and Additional features have low
priority.

Based on the information obtained from the tool comparison in section 4 the best fitting tool for the researcher in
this use case will be the Mapping Master tool, which is
a plug-in for Prot eg e, open source and produces an OWL
ontology as output. Thus, it meets the best the researchers
requirements comparing to other tools.

6. CONCLUSION
We introduced an evaluation framework for tools that support ontology population from spreadsheet data. In order
to derive the evaluation criteria for our framework we have

                                               63Evaluation criterion

User requirements

General Information
Usability
Input format
Output format
Mappings
Expressiveness
Multi-user support
Required software
Additional features

Mature and free tools are preferable
GUI and interactive mapping process are desirable
Excel sheet
OWL ontology
No special requirements
Support for unconventionaly structured data within one sheet
Not required
Prot eg e compatible tools are preferable
Support for SPARQL queries

Table 2: User Requirements for the Tool Selection

Importance (1 - low; 2
- medium; 3 - high)


analyzed several types of end users that can be interested in
applying such tools in their workflow and also have studied
the existing related work in this field. The obtained evaluation criteria can help guide practitioners and researchers in
classifying available tools and selecting the most appropriate
tool for a given problem.

In order to prove the usefulness of proposed framework we
have performed a qualitative analysis and comparison of a
representative set of seven tools that support data transformation from spreadsheets to Semantic Web formats. The
analysis shows that the tools strongly vary by provided capabilities and features. Most tools can translate data either
to RDF or OWL format, but not to the both formats. Also,
the tools vary on the complexity of spreadsheets they can
deal with. Some of them can process only rather simple
plain spreadsheets, where each row corresponds to a specific entity and each column describes a specific property of
this entity, while others provide flexible mapping techniques,
which can help to convert data distributed through several
sheets or even workbooks; and to process also formulas and
macros. Although almost all tools provide GUI to facilitate
mappings definition and final conversion, the general trend
is: the more sophisticated layout and processing, the higher
demands are for the user knowledge.

We see the direction for further development of ontology
population tools in the first place in improving the communication with user, i.e. developing user interfaces that will
hide the complexity of Semantic Web technologies from the
user. It would facilitate the participation of domain experts
in the knowledge gathering.

7. ACKNOWLEDGMENTS
This work has been supported by the Christian Doppler
Forschungsgesellschaft and by the Erasmus Mundus Action
2 Programme of the European Union.
