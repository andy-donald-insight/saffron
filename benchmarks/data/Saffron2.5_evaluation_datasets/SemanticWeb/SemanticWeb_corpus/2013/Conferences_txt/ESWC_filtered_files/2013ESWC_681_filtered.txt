Automatic Argumentation Extraction

Alan Sergeant

SAP UK Ltd, The Concourse, Queens Road, Belfast, BT3 9DT

Abstract. This extended abstract outlines the area of automatic argumentation extraction. The state of the art is discussed, and how it
has influenced the proposed direction of this work. This research aims
to provide decision support by automatically extracting argumentation
from natural language, enabling a decision maker to follow more closely
the reasoning process, to examine premises and counter-arguments, and
to reach better informed decisions.

Keywords: Argumentation, Argument
Extraction.

Extraction,

Information

1 Problem Overview

Automatic Argumentation Extraction (AAE) is a relatively new research area[1],
and work carried out to date is still regarded as experimental[2]. Argumentation can be defined as the process by which arguments are constructed and
handled[3], with four main tasks undertaken: identification, analysis, evaluation and invention[4]. Identification is the task of determining the conclusion,
premises and scheme of an argument from natural discourse, and is the task
with which this work is concerned with automating.

Motivation for this work comes from the question Was the right decision
made? Was it well founded? For every decision made, one might be asked to
justify, explain or defend how it was arrived at[5]. An antagonist can probe
the reasoning process which led to the conclusion by asking for clarification or
justification. Therefore, it can be said that arguments are constructed to express
the reasoning process taken to reach a conclusion, with a view to persuading
hearers that the conclusion is valid and the reasoning behind it well grounded[6].
What is an argument? The building blocks of every argument are propositions:
a statement or assertion that expresses a judgement or opinion[7]. An argument
consists of two or more propositions[3,8], one proposition functions as the claim
(also known as the conclusion), and a set of one or more propositions serve as
supports (also known as premises). The relationship between the propositions
(premises and conclusions) is important. An argument is not simply a collection
of propositions, it has a structure, which plays a key role in determining the
presence or absence of an argument[7].

One useful approach to viewing arguments and their structure is that of argument diagramming. Argument diagramming enables the conclusions and related
premises to be identified, and the relationships between them expressed in a tree

P. Cimiano et al. (Eds.): ESWC 2013, LNCS 7882, pp. 656660, 2013.
 Springer-Verlag Berlin Heidelberg 2013
?

?

?
structure[9]. It provides an overview of how well supported or attacked a conclusion or premise is. This overview can be used to inform argument-based decision
making. The argument diagram is a representation of the reasoning process, and
serves as a basis for reflection on how the conclusion was reached. It also enables an antagonist to target certain areas in the reasoning process for further
examination. If a conclusion is well supported, or even if it has been attacked
and successfully defended, it provides good ground on which to make a decision,
as the reasoning process by which it was reached is demonstrated to be valid.

Automatic argumentation extraction incorporates the understanding of con-
struction, handling, and visual representation of arguments and aims to support
decision making. Given the new ways in which we communicate (newspapers,
Facebook, Twitter, review sites etc.), often statements or assertions are made
without explicit justification for the opinion, belief or conclusion. Without this,
how can a reader reasonably decide to agree with a post or meaningfully assess
whether a product is suitable for purchase?

This research will begin by finding means of automatically identifying argumentative propositions (premises or conclusions). However at this first stage no
attention to type (whether a proposition is premise or conclusion) is considered.
It has been shown that by filtering out propositions that have no role to play
in an argument, a more accurate classification of type can be achieved[1]. Fi-
nally, once the propositions have been classified by their type, work will move
towards identifying the relationship (support or attack) between the premises
and conclusions, forming an argument diagram.

2 Related Work

While so far there has been little work in the area of AAE[1,2], several related
areas have been the focus of research: text zoning[10], RST (rhetorical structure
theory)[11], argumentation schemes, and argument diagramming[9]. Research
which has been carried out in AAE has largely focused on the legal domain[1,12],
with more recent work moving to online reviews[13], and online debates[14].

State of the Art. The state of the art encompasses two main approaches to
automatic argumentation identification: statistical classification and rule-based
parsing. In both cases, the goal is to identify and extract the parts of an argument
(premises and conclusions), as well as their relationships. The work in [1] begins
with experimentation on the Araucaria corpus [9], but quickly shifts focus to
the annotation of a new corpus consisting of fifty-seven ECHR (European Court
of Human Rights) cases. This was due to an interest in the full argumentation
structure, i.e the relations between arguments, which Araucaria does not provide.
The results of this work have been outlined in Table 1. However issues with the
statistical classification approach taken were also given. This approach cannot
detect the delimiters of each argument or their relations. Therefore, it is known
which information forms the argumentation but not how this information is
split into the different arguments.[1]. This eventually caused the research to
shift towards rule-based parsing. These results are also shown in Table 1.

A. Sergeant

Table 1. State of the art automatic argumentation identification results (F1 Measure)

Statistical Classification Rule-base Parser

Premise
Conclusion
Structure

68.12%
74.07%

N/A

64.3%
67.4%
60.0%

3 Contributions

Firstly, this research will begin by providing a much needed argumentation cor-
pus, as well as tools to enable easier production of argumentation corpora. This
corpus will be annotated with tags suitable for analysis by many of the available Apache UIMA1 Tools and components[15]. Annotation is underway and a
need for clear definitions has already become evident. As in previous work [12],
we will attempt to establish an appropriate definition of the elementary units
of argumentation. There is broad consensus that arguments are the elementary
units of argumentation, but what are the elements of an argument? Initial efforts in annotating a selection of car reviews, (our Car Review Corpus - CRC)
highlight the fact that sentences are not appropriate (as compared to the state
of the art[1]) as the fundamental elements of an argument (i.e. a complete, conventionally punctuated sentence often cannot simply be labeled as being a single
conclusion or a single premise). Take for example the sentence Other weight
saving measures means it is 80kg lighter overall and Audi claims it is the lightest
car in the class. This sentence, taken from an AA Car Review for an Audi A3,
contains the conclusion, Audi claims it is the lightest car in the class. However it also contains a premise: Other weight saving measures means it is 80kg
lighter overall which adds support to the claim. Therefore we can say that this
sentence contains both a conclusion and premise. This is a comparatively simple
case - a complex sentence comprising two independent clauses joined by a coordinator - and can be easily annotated. However, devising a means of identifying
propositions and their role in more complex syntactic constructions will require
greater effort. This research regards the proposition, classified as a conclusion or
premise, as the smallest element of an argument.

Our research addresses potential issues in moving from the more structured
natural language found in legal cases (state of the art), to the less structured and
therefore more computationally complex domain of journalistic argumentation
and consumer comment, exemplified in this case by car reviews. Our work will
explore which features achieve higher accuracies given various machine learning (ML) algorithms. It will begin by using Support Vector Machines (SVMs),
evaluating results against other ML algorithms such as Maximum Entropy(ME).
ML has been chosen because of the positive results achieved in [1], where it was
shown to obtain higher F1 measures in identifying both premises and conclusions
compared to rule-based parsing.

http://uima.apache.org/
?

?

?
Statistical classification, whether SVN or ME, typically encounters difficulty
when faced with the challenge of identifying individual argument parts and then
associating them with over-arching argumentation structures. Our research will
tackle this segmentation problem by use of semantic analysis. Whilst this was
explored briefly in [1], results were unfavorable. However it was stated that,
A different type of document or a more complex clustering model could achieve
better results, however it was decided to leave this research line for future work.

4 Evaluations

The evaluation of our systems effectiveness in identifying basic units of argument
will be standardised with the state of the art to enable direct comparison. The
state of the art uses well known evaluation metrics to count the number of
correctly classified sentences. In our work we will be counting the number of
correctly classified propositions instead of sentences. Therefore, in the context
of classification tasks (cf. classification between two class labels: C1 and C2) the
following four terms are used to compare the given labels with the label the
items actually belong to:

 True Positive (Tp) : number of propositions correctly classified as C1
 True Negative (Tn) : number of propositions correctly classified as C2
 False Positive (Fp) : number of propositions incorrectly classified as C1
 False Negative (Fn) : number of propositions incorrectly classified as C2

Precision(P), recall(R) and F1 measure are defined as follows:

P =

Tp

Tp + Fp

R =

Tp

Tp + Fn

F1 = 2  P  R

P + R

(1)

Accuracy is computed as the number of correctly classified propositions divided
by the total number of propositions:

Accuracy =

Ncorr
Ntotal

5 Work Plan

Ncorr = Tp + Tn

Ntotal = Tp + Tn + Fp + Fn

(2)

The initial effort has been on the creation of tools to help annotate a new argumentative corpus, the Car Reviews Corpus (CRC). These tools, based upon
UIMA [15], can be used to annotate text. The annotations created are then
capable of being utilised by any new or existing UIMA components.

The next stage of work is the annotation of propositions within the car review
texts by several human annotators, followed by a study of annotator agreement.
This will lead to the task of training a classifier to automatically identify propositions in unseen text in the same domain.

A. Sergeant

Upon successful completion, attention will shift back to fully annotating the
CRC with argumentative annotations, describing the argument parts and struc-
ture. Once again, an evaluation of annotator agreement will be carried out before proceeding to the task of classifying argumentative propositions from non-
argumentative, followed by classification of conclusions and premises.

The final stage of this work will be the investigation into a complex semantic
clustering model to enable the automatic construction of an argument tree from
an unseen text in a domain similar to that of the training corpus.

Acknowledgements. This work is supported by SAP AG and the Invest NI
Collaborative Grant for R&D - RD1208002.

Supervisors - Ian ONeill & Jun Hong (School of Electronics, Electrical Engineering and Computer Science, Queens University Belfast, Belfast, BT7 1NN)
