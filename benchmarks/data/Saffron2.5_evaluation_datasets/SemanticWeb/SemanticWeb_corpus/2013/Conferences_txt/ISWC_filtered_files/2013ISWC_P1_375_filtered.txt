Semantic Rule Filtering for Web-Scale

Relation Extraction

Andrea Moro1, Hong Li2, Sebastian Krause2,

Feiyu Xu2, Roberto Navigli1, and Hans Uszkoreit2

1 Dipartimento di Informatica, Sapienza Universita di Roma

Viale Regina Elena 295, 00161 Roma, Italy
{moro,navigli}@di.uniroma1.it

2 Language Technology Lab, DFKI, Alt-Moabit 91c, Berlin, Germany

{lihong,skrause,feiyu,uszkoreit}@dfki.de

Abstract. Web-scale relation extraction is a means for building and extending
large repositories of formalized knowledge. This type of automated knowledge
building requires a decent level of precision, which is hard to achieve with automatically acquired rule sets learned from unlabeled data by means of distant
or minimal supervision. This paper shows how precision of relation extraction
can be considerably improved by employing a wide-coverage, general-purpose
lexical semantic network, i.e., BabelNet, for effective semantic rule filtering. We
apply Word Sense Disambiguation to the content words of the automatically extracted rules. As a result a set of relation-specific relevant concepts is obtained,
and each of these concepts is then used to represent the structured semantics of
the corresponding relation. The resulting relation-specific subgraphs of BabelNet
are used as semantic filters for estimating the adequacy of the extracted rules. For
the seven semantic relations tested here, the semantic filter consistently yields a
higher precision at any relative recall value in the high-recall range.

Keywords: Relation Extraction, Semantics, WSD, Rule Filtering, Web-scale,
Semantic relations.

1 Introduction

Information Extraction (IE) automatically finds relevant entities or relations (including
facts and events) in natural language texts. The task of Relation Extraction (RE) is
to recognize and extract instances of semantic relations between entities or concepts
mentioned in these texts. Usually the relations are given, but they may also be induced
from the data, as in Open IE [3] where tuples of potential relations are extracted without
role labeling. In this paper, we address Web-scale domain-adaptive RE with semantic
labeling for given relations of varying arity.

Precision and recall are two important performance measurements. In the past, re-
call, scalability, domain adaptability and efficiency were regarded as much greater challenges than achieving high precision, because research employed learning data limited
in size, types and domains that did not give rise to the noise levels encountered when
using the Web as learning corpus. Much research also concentrated on intelligence ap-
plications, where recall is much more important than precision. But the limited learning

H. Alani et al. (Eds.): ISWC 2013, Part I, LNCS 8218, pp. 347362, 2013.
c Springer-Verlag Berlin Heidelberg 2013

A. Moro et al.

data were not sufficient to overcome the recall barriers, because of the long tail in the
skewed frequency distribution of relevant linguistic patterns. Today, the availability of
(i) large open-source knowledge databases such as Freebase [6], (ii) nearly unlimited
textual resources on the Web and (iii) efficient NLP systems such as dependency parsers
(e.g., [2,46]) enables the creation of large-scale distantly (or minimally) supervised RE
systems for many relations with acceptable efficiency [22,25,36,38,59]. These systems
can achieve much better recall without the need for larger volumes of labeled data.
Their drawback is their lack of precision, resulting from the large number of candidate patterns which are selected but not sufficiently constrained by the seed knowledge.
Filtering by lexical features (e.g., part-of-speech information, word sequences, etc.),
syntactic features such as dependency relations, or simple manually-defined heuristics
[1,4,8,22,25] does not suffice. A major open challenge is the exploitation of semantic
information in the text and in existing semantic resources beyond the seed data. Several
recent approaches add secondary semantic features to their systems which, however,
have been shown to offer only slight improvements in RE precision [19,60].

In this paper, we propose a new method that automatically learns relation-specific
lexical semantic resources from a general-purpose knowledge base without any taskspecific manual annotation. The input of this unsupervised learning method is a large
collection of noisy RE patterns (40K rules per relation on average) acquired by the
RE system Web-DARE [22], together with their sentence mentions from 20M Web
pages retrieved by searching for the named-entity tuples of the seed facts. The patterns are dependency structures extracted from the parse trees of the sentence mentions.
The learning system acquires relation-relevant word senses by applying Word Sense
Disambiguation [30] to the words in the patterns and then extracts the corresponding
relation-specific lexical semantic subgraphs from a large-scale general purpose lexical
semantic network, i.e., BabelNet [31]. These relation-specific subgraphs are utilized as
semantic knowledge for filtering out bad rules. In contrast to frequency-based filters,
our semantic rule filter, on the one hand, deletes those high-frequency rules which do
not contain any relation-relevant words, but at the same time, on the other hand, it also
preserves any low-frequency rules which are semantically relevant (owing to their low
frequency such rules would previously have been, erroneously, filtered out). It thereby
increases both precision and recall.

The main contributions of this paper are to:

 introduce a novel unsupervised, scalable learning method for automatically building relation-specific lexical semantic graphs representing the semantics of the considered relation. Moreover, we show the usefulness of these graphs for filtering
semantically irrelevant rules and improving the precision of large-scale RE;

 report on a first comparison of WordNet and BabelNet with respect to improving
RE: BabelNet achieves better recall and F-score than WordNet both in rule filtering
and in RE;

 demonstrate that relation-specific lexical semantic resources can improve RE per-
formance: For seven semantic relations tested, the semantic filter consistently yields
a higher precision at any relative recall value in the high-recall range.
?

?

?
2 Related Work

In recent years several approaches to RE have tried to circumvent the costly, and still
not satisfactory, corpus annotation needed for supervised learning. Minimally or weakly
supervised methods start with limited initial knowledge and unlabeled data. By a bootstrapping process partial labeling of data and system training are performed in several
iterations (e.g., [1,7,8,39,55]). However, these systems often have to cope with low recall and precision, the latter partially due to semantic drift.

A newer class of approaches, sometimes referred to as distant supervision, utilizes
extensive volumes of preexisting knowledge for partially labeling large volumes of data.
[25] train a linear-regression classifier on Freebase relation instances occurring in a
large Wikipedia corpus. In order to achieve high precision (without much consideration
for recall), lexical features, syntactic dependency information and negative examples
are employed. The resulting precision is 67.6% for 10,000 sampled instances of 102
relations.

Open IE systems such as TextRunner and its successors [3,4,13,56], together with
subsequent developments [48,27,28], detect instance candidates of any unknown rela-
tion. The Open IE task, however, is faced with even higher levels of noise. Shallow
linguistic analysis and numerous heuristics based on lexical features and frequencies
are utilized to filter out noisy or irrelevant information for both learning and extraction.
However, all these RE methods are faced with the problem of estimating the confidence of automatically labeled information and learned rules. Some approaches use
the confidence value of the extracted instances or the seed examples as feedback for
estimating the confidence of rules [1,7,55]. In most cases, however, the confidence
values rely on redundancy. Many approaches utilize negative examples for filtering
[25,51,54]. As mentioned above, lexical features such as word sequences or part-of-
speech information are often utilized for further filtering [3,4,25,56]. Some approaches
employ domain-relevant terms for filtering rules [35,52]. Web-DARE [22] filters rules
by their absolute frequency and their relative frequency in comparison to other related
relations (overlap). In order to improve precision, NELL  a large-scale RE system designed to learn factual knowledge from the Web in a never-ending manner [8]  employs
the coupled learning of a collection of classifiers for several relations. By exploiting
this method it is possible to filter out noisy relation instances recognized by mutually
exclusive classifiers. However, even if some of these approaches reach the goal of high
precision, this is obtained at the cost of recall.

To obtain high precision while at the same time preserving recall, the use of semantic
approaches can be highly beneficial. One of the first attempts was presented in [24]
where the authors proposed a method for adding semantic features to the labeled data
used for training a syntactic parser. However, even if the authors obtained promising
results, the major drawback of this approach is the need for huge volumes of annotated
data, which, even today, is hard to obtain. Other approaches add semantic features to
feature-based RE systems that learn relation-specific extractors [20,60]. However, none
of these approaches has taken full advantage of syntactic and semantic analysis, and thus
they have achieved only small improvements [19]. A recent trend in this research strand
is the utilization of tree kernel-based approaches, which can efficiently represent highdimensional feature spaces [36,59]. However, supervision is stil required and semantic

A. Moro et al.

analysis is only marginally employed. In contrast, in this paper we draw only upon
semantic knowledge to obtain significant improvements over non-semantic systems.

To integrate and make the most of semantics in RE systems we need a lexical representation of knowledge that can be exploited to obtain a semantic description of the
relations. In contrast to many state-of-the-art resources [15,18,29], BabelNet [31] integrates encyclopedic (i.e., from Wikipedia) and lexicographic knowledge (i.e., from
WordNet) to obtain a rich multilingual encyclopedic dictionary.

3 Web-DARE and NELL

Our goal is to leverage semantic knowledge to improve the quality of the RE rules
learned by two Web-scale RE systems,
introduced
hereafter.

i.e., Web-DARE and NELL,

3.1 Web-DARE

The Web-DARE system [22] learns RE rules for n-ary relations in a distant-supervision
manner [25]. For 39 relations, 200k instances, i.e. seeds, were collected from the freelyavailable knowledge base Freebase. Utilizing these relation instances as Web-search
queries, a total of 20M Web pages were retrieved and processed, extracting from them
3M sentences mentioning the arguments (entities) of a seed instance. After analyzing
these sentences by additional NER and parsing, 1.5M RE rules were extracted from the
dependency parses. The following example rule contains four arguments, two married
persons plus the wedding location and the starting date of the marriage:

(1)

person

nsubj

pobj

location

in

marry

prep

prep

dobj

person

on

pobj /

/ date

FO-Filter. The reported recall for Web-DARE is rather high. To overcome the extremely low precision, a rule filter (called FO-Filter) is introduced based on the rule
frequency and mutual exclusiveness of relations with similar entity-type signatures.
Whenever a particular rule has been learned for more than one relation, it will be added
to one relation if its relative frequency in this relation is the highest in comparison to
other relations. Rule frequency is the number of the sentence mentions from which a
rule has been learned. Relative frequency of a rule in a relation is calculated on the basis
of the frequency of this rule in this relation compared to the total frequency of all rules
in this relation. Furthermore, a frequency threshold has been applied to exclude rules
with low frequency.

3.2 NELL
NELL [8] is a system designed to learn factual knowledge from an immense corpus
over a long period. NELLs background ontology contains several hundred entity types
(categories) and binary relations, which are related in that certain pairs of categories
or relations are marked as being sub- or supersets of each other, or as being mutually

o
o
/
/
x
x
&
&
o
o
?

?

?
exclusive. This coupling of relations is beneficial when estimating the correctness of
newly extracted facts. Earlier versions of NELL, described by [5] and [9], were based
mainly on a learner of lexico-syntactic rules. The architecture was extended with an
extractor working on semi-structured parts of Web pages, i.e., HTML lists and tables,
by [10]. Afterwards, a classifier for categorizing noun phrases into entity types based
on morphological features as well as an inference-rule learning component was added
to NELL [8,23]. NELLs rules are binary and surface-level oriented, as illustrated by
the following example:
(1)
While in the NELL system these patterns are only a single piece in a bigger learning and
extraction pipeline, we employ them here on their own for RE. The NELL rules serve
mainly as an additional testing ground for our semantic filter. This implies that the RE
results presented in Section 6 are not representative of the performance of NELL itself.

person and husband person.

4 WordNet and BabelNet

In this section we give a brief overview of the knowledge bases that we use to obtain a semantic description of the considered relations. The first is WordNet [15] which
is a manually-created lexical network of the English language, initiated by George A.
Miller in the mid-1980s. The two main components of this resource are the synsets and
the semantic relations between them. A synset is a set of synonyms representing the
same concept. Each synset is connected to other synsets through lexical and semantic
relations. There are roughly 20 relations, among which are hyponymy, meronymy and
entailment.

The second resource that we draw upon is BabelNet1 [31], a large-scale multilingual
semantic network which, in contrast to WordNet, was built automatically through the
algorithmic integration of Wikipedia and WordNet. Its core components are the Babel
synsets, which are sets of multilingual synonyms. Each Babel synset is related to other
Babel synsets by semantic relations such as hypernymy, meronymy and semantic relat-
edness, obtained from WordNet and Wikipedia. Moreover, since BabelNet is the result
of the integration of a lexical resource and an encyclopedic resource, it is perfectly in
line with the multilingual linguistic Linked Open Data project [12]. This project consists of a vision of the Semantic Web in which a wealth of linguistic resources are linked
to each other so as to obtain a bigger and optimal representation of knowledge [32].

One major difference between these two resources is in respect of their considerably
different sizes, both in terms of number of concepts and semantic relation instances. On
the one hand, WordNet provides roughly 100K synsets, 150K lexicalizations and 300K
relation instances. On the other hand, BabelNet contains roughly 5.5M synsets, 15M
lexicalizations and 140M relation instances. Moreover, given the multilingual nature of
BabelNet (the current version 1.1.1 considers six different languages: Catalan, English,
French, German, Italian and Spanish), this resource can exploit multilinguality to perform state-of-the-art knowledge-based Word Sense Disambiguation [33] (in contrast to
WordNet which encodes only English lexicalizations), thereby enabling new methods
for the automatic understanding of the multilingual (Semantic) Web.

1 http://babelnet.org

A. Moro et al.

5 Rule Filtering with Relation-Specific Semantic Graphs

Current statistical approaches to the rule filtering problem do not take into account the
semantic information available within the rules. As a consequence they are not able
to identify bad rules, which, from the point of view of the extracted arguments, look
correct. For instance, the rule PERSON met PERSON, extracted for the relation mar-
ried, is not specific to the considered semantic relation even if it extracts several good
relation instances. We tackle this issue by introducing a novel approach to explicitly
represent the semantics of each rule and relation. To do this, we apply Word Sense Disambiguation (WSD) to the automatically extracted rules and then build relation-specific
semantic graphs which represent the semantics of the considered relation. For instance,
our semantic representation of the relation married contains concepts that are semantically distant from the concepts usually associated with the term met. As a result, our
approach is able to correctly filter out the aforementioned rule.

5.1 Building Semantic Graphs
Given a semantic relation , we consider the set of rules R automatically extracted by
the Web-DARE system, together with the set S of sentences from which these rules were
extracted. Our goal is to build a semantic representation for the relation . In Algorithm
1 we show the pseudocode of our semantic graph construction approach, described in
the following.

WSD (lines 413 of Algorithm 1). In this first part of the algorithm we compute a frequency distribution over the synsets of the considered knowledge base for the semantic
relation . Given the set S of sentences used by the Web-DARE system and a rule
r  R, we define the subset Sr  S as the set of sentences from which the rule r was extracted (see line 6). For instance, we add the sentence It was here that the beautiful Etta
Place first met Harry Longabaugh to the set SPERSON_met_PERSON. Then, for each sentence s in Sr, we perform WSD on each content word of the rule r using the remaining
content words of s as context (see line 9). For instance, using the previous sentence and
given the word met, we use as context the following words: was, here, beautiful, Etta,
Place, first, Harry, Longabaugh obtaining the synset2 meet1
v. We use an off-the-shelf
API for knowledge-based WSD3 which exploits a knowledge base and graph connectivity measures to disambiguate words [34]. For each synset selected by the WSD API,
we increment its count (see line 10 in Algorithm 1). As a result of this step, we obtain
, a synset frequency distribution representing the unstructured semantics of the given
relation  (see lines 410 in Algorithm 1). Then, to avoid data sparsity, we discard all
the synsets that occur only once (lines 1113). For example, given the semantic relation
 = marriage, the most frequent synsets returned by the WSD API are: marry1
v, wife1
n
and husband1
n.

2 For ease of readability, in what follows we use senses to denote the corresponding synsets. We

follow [30] and denote with wi

p the i-th sense of w with part of speech p.

3 We did not use supervised approaches as they would have required a separated training phase

for each considered domain.
?

?

?
Algorithm 1. Building the relation-specific semantic graph
1: input: S, the set of sentences from which the rules where extracted;

R, the set of rules automatically extracted for the the relation ;
Ekb, the edges, i.e. the semantic relation instances, of the knowledge base;
k, our free parameter.

for each word  contentWords(r) do
synset := W SD(word, sentence)
[synset]++ // we increase by one the integer associated with the synset

 := Map<Synset, Integer>
for each r  R do
Sr := {s  S : s matches r}
for each sentence  Sr do

2: output: G, the semantic graph for .
3: function SEMANTICGRAPH(S, R,Ekb, k)
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:

if [synset] = 1 then
.remove(synset)

for each synset  keys() do

 := {synset}

if  synset

$  Top(, k) s.t. (synset, synset

$

)  Ekb then

 := Top(, k) // we initialize the core synsets with the top-k most frequent synsets
for each synset  keys() do

return G := (,{(synset1, synset2)  Ekb : synset1, synset2  })

wife1
n

husband1
n

marriage1
n

marry1
v

divorce2
v

divorce1
n

Fig. 1. An excerpt of the semantic graph associated with the relation marriage with k = 2

v,wife1
n

Core Synsets (lines 1418 of Algorithm 1). In the second part of Algorithm 1 we build
a subset    of core synsets, i.e., the most semantically representative concepts
for a semantic relation . We initialize  with the top-k most frequent synsets in 
(line 14). For instance, with k = 2 and the relation  = marriage, we have marriage :=
}. We then look at each synset s in  and we check if there exists a
{marry1
semantic relation in the knowledge base that connects the synset s to any of the top-k
frequent synsets. If this is the case, we augment  with s, i.e., we extend our initial set
of core synsets with additional semantically related synsets (lines 1517). For example,
with k = 2 and the relation = marriage, we add husband1
v to
marriage, among others (see Figure 1). Finally, the algorithm returns the subgraph G

n and divorce2

n, marriage1

A. Moro et al.

Algorithm 2. Classifying the rules of a semantic relation
1: input: G, the semantic graph associated with the relation ;

R, the set of rules associated with the relation ;

2: output: GR, the good rules
3: function FILTER(G, R)
GR := /0
4:
for each rule  R do
5:
6:

if  word  contentWords(rule), synset  V (G) such that
word  lexicalizations(synset) then
GR := GR{rule};

7:
8:

return GR;

of the given knowledge base induced by the set of core synsets  (see line 18), which
will be used to filter out bad rules as described in Section 5.2. An excerpt of the kind of
graphs that we obtain is shown in Figure 1.

5.2 Filtering Out Bad Rules

We now describe our semantic filter, whose pseudocode is shown in Algorithm 2, which
filters out bad rules by exploiting the semantic graph G previously described. For each
rule r  R associated with a semantic relation , we check if any of its content words
matches one lexicalization of the concepts contained in the semantic graph G (see line
6). If this is the case we mark r as a good rule, otherwise we filter out r. For instance,
our filter recognizes the rule PERSON married PERSON as a good rule, while filtering
out PERSON met PERSON because none of the senses of meetv matches any of the core
synsets automatically associated with the relation married.

6 Experiments and Evaluations

6.1 Experimental Setup

Overview. We carried out two different experiments to assess the quality of our semantic filtering algorithm: an intrinsic evaluation (i.e., evaluating the quality of the filtered
rules against a gold-standard rule set without taking into account the extraction perfor-
mance) and an extrinsic evaluation (i.e., determining its effect on recall and precision of
real RE). In both evaluations, we experiment with different values of k for Algorithm 1,
ranging from 1 to 15.

Our evaluation aims at obtaining insights concerning the following aspects:

 rule-frequency driven FO Filter vs. filtering based on lexical semantics: We test
our semantic rule filter against the previous FO-Filter to compare the performance
difference.

 impact of the selection among lexical semantic resources: We evaluate the effects
of training our filtering algorithm with two different knowledge bases: manually
generated WordNet vs. BabelNet, a massive extension of WordNet automatically
created from Wikipedia information (cf. Section 4).
?

?

?
Table 1. Statistics about (a) the input data for the rule filters, (b) the gold standard for intrinsic
evaluation, (c) the baseline (pre-filtering) performance for the extrinsic evaluation. Values are
shown for both Web-DARE (WD) and NELL (N) systems. Freebase Mentions refers to the
number of correctly identified Freebase mentions in a sample of the evaluation corpus.

# Rules

26,986
88,350
22,377
31,559
45,093
47,689
26,250
?

?

?
288,304 4,036
41,186

INTRINSIC
(SEC. 6.2)

# Gold-Set

Rules

WD (+|-)
52|48
47|53
50|50
50|50
22|78
51|49
12|88
284|416
41|59

Relation

acquisition
marriage
person birth
person death
person parent
place lived
sibling relationship

sum
average

EXTRINSIC (SEC. 6.3)

# Extracted
Mentions

Baseline
Precision

# Freebase
Mentions

N WD N WD  N

17,913
92,780
63,819
84,739
93,800
84,389
59,465

496,905
70,986

296 14.20% 28.04% 93 1
2,586 11.60% 8.50% 161 9
2,607 36.50% 5.60% 77 0
17 18.00% 100.00% 300 0
358 13.20% 66.20% 91 5
3,155 47.90% 92.00% 68 38
211 5.60% 51.18% 48 2

9,230
838 55
1,319 21.00% 50.22% 120 20




?

?

?
 generality of the semantic filtering method: We also apply our filtering to the NELL
rule set to check whether the filtering is general enough to apply beyond DARE
rules.

Table 1 lists our target relations in column Relation while in column INPUT we

show the respective number of rules given by the Web-DARE and NELL4 systems.

6.2 Intrinsic Evaluation

Dataset. For the intrinsic evaluation, we manually validate a set of 700 Web-DARE
rules to create a balanced gold standard of correct rules (+) and incorrect ones (-) from
all target relations. Column INTRINSIC of Table 1 presents the number of manually
validated rules per relation.

Results. In this section we describe the intrinsic evaluation of our filtering algorithm.
To evaluate the filtered rules, we compute their precision, recall and F-score against
the manually built gold standard rule set. We do this without considering the relation
extraction performance of the filtered rules, i.e., how many good relation instances are
effectively extracted by these rules, as this is the focus of the extrinsic evaluation.

Figure 2 displays precision, recall and F-score values for the total set of seven semantic relations using WordNet and BabelNet as knowledge bases and varying the parameter k from 1 to 15 (see Algorithm 1 in Section 5). As Figure 2 shows, we obtain a
considerable increase in recall by using BabelNet instead of WordNet (with a maximum
value of roughly 90% for BabelNet and 70% for WordNet). Despite the gain in recall

4 NELL rules were taken from iteration 680,

http://rtw.ml.cmu.edu/resources/results/08m/

A. Moro et al.

 0.9

 0.8

 0.7

 0.6

 0.5

 0.4

 0.3

 0.9

 0.8

 0.7

 0.6

 0.5

 0.4

bn-precision
bn-recall
wn-precision
wn-recall

bn-f-score
wn-f-score

 0.3

Fig. 2. Precision, Recall and F-score considering all the 7 semantic relations, using WordNet
(dotted) and BabelNet (solid), varying the value k from 1 to 15

for the BabelNet filter, precision stays roughly the same as for the WordNet filter (for
each value of k), which yields an F-score boost of roughly 10%.

The main reason for the observed improvement can be found in the rich set of semantic relation instances of BabelNet, i.e. when using BabelNet as our knowledge base, the
filtering method is able to discover semantic connections between concepts that are not
provided by WordNet. For instance, WordNet does not contain a semantic connection
between the concepts of marriage and divorce, whereas BabelNet does.

6.3 Extrinsic Evaluation

Dataset. In the extrinsic evaluation, we use the Los Angeles Times/Washington Post
(henceforth LTW) portion of the English Gigaword v5 corpus [37] for RE. LTW is
comprised of 400K newswire documents from the period 19942009. We match all
Web-DARE and NELL rules against the LTW corpus, resulting in more than 500K
detected relation mentions, shown in column EXTRINSIC of Table 1. To estimate
the precision of RE, we manually check a random sample of 1K extracted mentions
per relation and system, giving us the pre-filtering performance depicted in column
Baseline Precision. To estimate the RE coverage of the rules, we investigate how
many mentions of Freebase facts the systems find on LTW. The values are listed in the
last three columns of Table 1, labeled Freebase Mentions. Only actual mentions are
taken into account, i.e., sentences containing the entities of a Freebase fact and actually
referring to the corresponding target relation. Relative recall values stated in this section
are to be understood as recall with respect to the set of Freebase-fact mentions found
by at least one of the two rule sets (Web-DARE/NELL), i.e., relative to the very last
column of Table 1.

Semantic Filter for Web-DARE Rules. Figure 3 presents the precision vs. relative
recall results of RE when performed with the baseline Web-DARE rules, the statistical
approach (FO-Filter) and our semantic filtering algorithm (S-Filter) using BabelNet and
WordNet. The FO-filter is able to increase the precision from the baseline of 20% up
to close to 100%, since by varying the frequency threshold, any value between 40%
and 98% can be reached. But this filtering sacrifices a large portion of the initial recall.
?

?

?
Baseline 
FO-Filter 

S-Filter (WordNet) 
S-Filter (BabelNet) 

100% 

90% 

80% 

70% 

60% 

50% 

40% 

30% 

 

n
o
i
s
i
c
e
r

s
e
v
r
u
c
?

?

?
o
s

90% 

80% 

70% 

60% 

50% 

40% 

20% 

20%  30%  40%  50%  60%  70%  80%  90%  100% 

Recall 

Fig. 3. RE performance of Web-DARE rules with different applied filters. Dashed curves in gray
depict points with equal F1 score. For the semantic filter (S-Filter), the curves resulted from
varying k from 1 to 15. FO-Filter is described in [22]. Results are averaged over seven relations.

Table 2. Impact of WordNet (WN) vs. BabelNet (BN) utilization on Web-DARE rule filtering.
Results are averaged over seven relations, all values are in %.

k (Alg. 1)

Precision

Recall

F1

WN BN WN BN WN BN

(Basel.)

21.00

93.83

34.32
?

?

?
33.24 38.50 68.87 84.37 44.84 52.87
38.89 46.16 68.01 82.20 49.48 59.12
49.07 52.99 67.40 80.04 56.79 63.76
65.57 65.76 49.93 78.69 56.69 71.64
74.43 68.79 49.84 76.61 59.70 72.49
59.43 74.66 27.84 60.73 37.92 66.98

In contrast, the semantic filter trained with BabelNet does not permit precision levels
above 75% for the average of the relations targeted in this paper, but it has at the same
time a more reasonable precision-recall trade-off, e.g., by retaining about 15 percentage
points recall above the FO-Filter at a precision level of around 70%. In the recall range
covered by the BabelNet filter, its precision is consistently higher.

As illustrated by the chart, training the S-Filter with WordNet instead of BabelNet
leads to inferior performance. Table 2 shows the Web-DARE RE performance for different parameter values of Algorithm 1. The use of BabelNet consistently leads to a
higher F-score compared to WordNet. For example at k = 2, the F-score is roughly
thirteen percentage points higher.

A. Moro et al.

Baseline 

S-Filter (WordNet) 

S-Filter (BabelNet) 

80% 

75% 

70% 

65% 

60% 

55% 

50% 

45% 

 

n
o
s

i

i

c
e
r

40% 

0% 

1% 

2% 

3% 

4% 

5% 

6% 

7% 

8% 

Recall 

Fig. 4. RE performance of NELL rules, both with and without semantic filter (S-Filter). k varies
from 1 to 15. Results are averaged over seven relations.

Semantic Filter for NELL Rules. Figure 4 shows the precision versus relative recall
results of the baseline and our semantic filtering algorithms when applied to NELLs
patterns. Again, the RE precision increases. The relative recall values on our test data
do not permit any conclusions to be drawn for the NELL system. Due to the low number
of mentions found in the NELL recall baseline (see Table 1), the filter application has
a high impact on the depicted recall values and thus the curves show a non-monotonic
growth. Nevertheless, as the chart indicates, the proposed filter can also be applied to
pattern sets of different RE rule formalisms. Similarly to Figure 3, Figure 4 demonstrates that training the filter on BabelNet leads to superior RE performance compared
to the filter variant trained on WordNet.

6.4 Result Analysis and Insights

Generality. Both Figures 3 & 4, as well as Table 2, show significant performance
improvements after the application of the semantic filter, regardless of the underlying
pattern formalism, i.e., dependency-analysis-based or surface-level-based. This means
that our algorithm could be applied in a large variety of application scenarios, as long as
the patterns or rules contain content words to which the semantic filter can be applied.

BabelNet vs. WordNet. The semantically-enhanced RE performance values of WebDARE and NELL as given in Sections 6.2 & 6.3 fully support our initial expectation
that BabelNet, with its richer inventory of lexical semantic relations, is better suited for
effective rule filtering.
?

?

?
Consider the following example from the marriage relation:

(3)

person

appos /

/ widow

prep

/ of

pob j /

/ person

This rule draws on the concept of deceased spouses, i.e. widow, for detecting the
target relation. Since the semantic graph created with BabelNet contains this concept,
the rule is identified as being useful for RE and hence it is not filtered out, in contrast to
the filter from WordNet, which erroneously excludes it.

Individual Relations. The performance of the filter varies across relations. Due to
space limitations we cannot show detailed per-relation results here. The filter works
particularly well for relations like acquisition and person birth/death, whereas the results are rather discouraging for place lived. Investigating the sampled mentions of the
latter relation, we found that this can be attributed to the larger lexical diversity of this
relation. Often the semantic information is carried by constructions such as Belfast
writer J. Adams, where the lexical anchor writer is semantically insignificant to the
relation. To get high coverage on such mentions extraction rules would have to match
a certain set of semantically diverse nouns here, without matching all nouns (Belfast
visitor Cameron). The relation seems to require much background knowledge, which
may have to include entailment and other inferences. For example, a mention of a person being a senator for some (US) state could, depending on legal requirements, indeed
be a mention for place lived.

Semantic Filter vs. FO-Filter. Finally, we investigated the causes of the superior performance of our new semantic filter compared to the pre-existing FO-Filter. In addition
to the problem of always finding mutually exclusive relations with compatible entity
signatures, the FO-Filter also has the disadvantage of not excluding erroneous rules
which belong neither to the particular target relation nor to any of the compatible rela-
tions. In contrast, the new semantic filter works independently for each relation.

The following low-precision Web-DARE rules illustrate this point, all learned for the

marriage relation:
(4)

(5)

(6)

person

nsub j

prep

lose

nsub j

nsub j

person

person

date

meet

to
dob j /

dob j /

pob j /

/ person

person

person

These rules, as they express typical relations for married couples, get strong statistical
support for the marriage relation against the other relations. Therefore, the FO-Filter is
not able to correctly identify them as wrong. In contrast, the semantic filter correctly
disposes of them.

Another shortcoming of the FO-Filter is the recurring exclusion of high-quality patterns for which there is only limited support in the training data. When taking only the
frequency of a pattern into account, these patterns cannot be distinguished from erroneously learned ones. Our use of an additional lexical-semantic resource, such as Word-
Net/BabelNet, provides a filtering mechanism that correctly identifies the appropriate
meaning of the target relation. Consider the following example rule, which, as it has

/
/
/
o
o
/
o
o
/
o
o

A. Moro et al.

a low frequency, gets filtered out by the FO-Filter, whereas, as it expresses a relevant
word sense for the considered relation, gets classified as correct by our semantic filter:

(7)

person

poss

appos

widower

person

7 Conclusion and Outlook

After the successful utilization of parsing for large-scale RE, the time seems ripe for
injecting more semantics into this most challenging task within IE. This paper demonstrates that exploiting advanced comprehensive semantic knowledge resources can significantly improve extraction performance.

This is just the beginning, opening the way for new lines of research. The semantic
classifier should now be extended for rule classification with respect to relations, building a bridge between traditional IE and open IE. The synonyms provided by semantic
resources could also be applied to extend the rule set for increased coverage, in addition
to filtering it. As a side result of the comparison between the FO-Filter and the new semantic filter, we observed that the two methods exhibit different shortcomings, giving
rise to the hope that a combination may further improve RE performance.

Acknowledgements. This research was partially supported by the European Research
Council through the MultiJEDI Starting Grant No. 259234, by the German Federal
Ministry of Education and Research (BMBF) through the projects Deependance (con-
tract 01IW11003) and Software Campus (contract 01IS12050, sub-project Intellektix)
and by Google through a Faculty Research Award granted in July 2012.
