Controlled Query Evaluation
over OWL 2 RL Ontologies

Bernardo Cuenca Grau1, Evgeny Kharlamov1, Egor V. Kostylev2,

and Dmitriy Zheleznyakov1

1 Department of Computer Science, University of Oxford

2 School of Informatics, University of Edinburgh

Abstract. We study confidentiality enforcement in ontology-based information systems where ontologies are expressed in OWL 2 RL, a profile
of OWL 2 that is becoming increasingly popular in Semantic Web ap-
plications. We formalise a natural adaptation of the Controlled Query
Evaluation (CQE) framework to ontologies. Our goal is to provide CQE
algorithms that (i) ensure confidentiality of sensitive information; (ii)
are efficiently implementable by means of RDF triple store technologies;
and (iii) ensure maximality of the answers returned by the system to
user queries (thus restricting access to information as little as possible).
We formally show that these requirements are in conflict and cannot be
satisfied without imposing restrictions on ontologies. We propose a fragment of OWL 2 RL for which all three requirements can be satisfied.
For the identified fragment, we design a CQE algorithm that has the
same computational complexity as standard query answering and can be
implemented by relying on state-of-the-art triple stores.

Introduction

Preserving confidentiality of information (i.e., ensuring that sensitive data is
only accessible to authorised users) is a critical requirement for the design of
information systems. In recent years, Semantic Web technologies have become
widespread in many application domains. There is consequently a pressing need
for suitable confidentiality enforcement infrastructure in ontology-based information systems which rely on RDF as a data model, SPARQL as a query language,
and OWL 2 as a language for describing background knowledge.

In traditional database management systems, confidentiality is enforced by
means of mandatory and discretionary access control mechanisms, where access
to data items such as tuples, entire relational tables, or database views is granted
only to certain (groups of) users. Such access control mechanisms are, however,
problematic for ontology-based information systems: explicitly represented RDF

 This work was partially supported by the EU project Optique (FP7-IP-318338), EPSRC project Score!, ERC FP7 grant Webdam (n. 226513), and UK EPSRC project
SOCIAM (grant EP/J017728/1). Bernardo Cuenca Grau is also supported by a
Royal Society University Research Fellowship.

H. Alani et al. (Eds.): ISWC 2013, Part I, LNCS 8218, pp. 4965, 2013.
c Springer-Verlag Berlin Heidelberg 2013

B. Cuenca Grau et al.

data is assumed to be incomplete and hence new, implicit, data can be derived
from the axioms in the ontology via logical reasoning. By granting access to a
certain set of RDF triples, system administrators are de facto disclosing a much
larger set of implicit triples, some of which a user might not be allowed to know.
In contrast, traditional databases are complete, and hence system data is always
explicit; as a result, managing access rights is conceptually a simpler problem.
Controlled Query Evaluation (CQE). [1,2,3,4,5,6] is an approach to confidentiality enforcement where system administrators specify in a declarative way the
information that cannot be disclosed to users (neither directly nor indirectly via
results of previous queries) by means of a confidentiality policy. When given a user
query, a censor checks whether returning the answer would lead to a violation of
the corresponding policy and thus to a disclosure of confidential information to
unauthorised users; in that case, the censor returns a distorted answer.

CQE in databases is a long standing research area [1,2,4,6,3]; existing work,
however, focuses mostly on complete relational databases. CQE for incomplete
databases, which are more closely related to ontologies, remains relatively unexplored and research has so far been limited to foundational aspects [5].

In this paper, we are interested in ensuring confidentiality in ontology-based
information systems where the relevant ontologies are expressed in the OWL 2
RL profile [7]a fragment of OWL 2 for which query answering is known to
be theoretically tractable in the size of both ontology and data, and efficiently
implementable by means of rule-based triple store technologies. OWL 2 RL has
become increasingly popular, and state-of-the-art RL reasoners such as OWLim
[8] and Oracles RDF Semantic Graph [9] provide robust and scalable support
for SPARQL queries over OWL 2 RL ontologies and RDF data.

Motivated by the CQE paradigm, we study confidentiality enforcement in the
scenario described next. We assume that the information in the system consists
of background knowledge formalised as an OWL 2 RL ontology, and dataset
formalised as a set of unary and binary facts. The ontology is assumed to be
fully known to all users (a worst-case situation for confidentiality enforcement),
whereas data is assumed to be hidden. Interaction with the system is restricted to
a query interface, which allows users to formulate arbitrary conjunctive queries
(which constitute the core of SPARQL). A confidentiality policy is represented
as a set of facts logically entailed by the ontology and dataset. Given a user
query, the system returns a subset of the certain answers to this query over the
ontology and dataset determined by the censor. Thus, we adopt the basic case
of the CQE paradigm where the censor only filters out problematic answers.

In this scenario, there is a tradeoff between confidentiality and accessibility of
information: a censor that returns the empty answer for each query makes the
system secure, but also equally useless. Thus, we are interested in optimal cen-
sors, i.e., those that return maximal sets of answers to queries which still preserve
the required confidentiality. Also, CQE can be computationally expensive and to
the best of our knowledge practicable algorithms are yet to be developed. We are
consequently interested in censors that can be efficiently implemented, ideally by
relying on the same technology used for query answering in OWL 2 RL.
?

?

?
person

person

knows

person

John

fOf

Bob

fOf

Mary

John

fOf

Bob

knows
fOf

person

Mary

(a)
Fig. 1. Dataset Dex (a), and the same dataset extended with implicit information (b)

knows

(b)

knows

The contributions of this paper are as follows. In Section 3 we take existing
work on CQE for incomplete databases as a starting point, and present a CQE
framework that takes into account the specific features of standard ontology
and query languages. In Section 4 we propose the class of view-definable cen-
sors, which can be implemented by delegating the censors main computational
workload to an OWL 2 RL query answering engine. Roughly speaking, the behaviour of such a censor is determined by what we call a view : a dataset that
encodes the information in the system relevant to the censors output for any
user query. We next explore in Section 5 the formal limitations of our approach
and show that censors that are both optimal and view-definable may not ex-
ist; furthermore, even if such a censor exists, the corresponding view might be
exponentially larger than the systems dataset, thus making efficient implementations difficult. In Section 6, we identify a fragment of OWL 2 RL for which
these limitations can be circumvented. Our fragment is able to capture nontrivial extensions of RDF-Schema and is thus relevant for many Semantic Web
applications. We consequently provide a practical CQE evaluation algorithm
that guarantees both optimality and efficiency if the systems ontology belongs
to our fragment. Finally, in Section 7 we observe that there are cases where different optimal view-definable censors exist, and where there is no good reason
for choosing one over the others; hence, we study how to deal with such cases.

2 Preliminaries

We assume that all our definitions are parameterised by a first-order signature
 consisting only of constants, unary predicates, and binary predicates. We also
assume first-order logic with equality over , and denote with  the special
binary equality predicate and  the special nullary false predicate. A dataset is
a finite set of ground (equality-free) atoms over .

Example 1. Consider the following dataset Dex , where the predicate fOf repre-

sents the friend of relation:

person(Bob),
fOf(John, Bob),
A graphical representation of Dex is given in Figure 1(a).

knows(Mary, John),

fOf(Bob, Mary).

Definition 2 (Rule, ontology). A rule r is a first-order sentence of the form
xz. (x, z)  (x), where x and z are tuples of variables, (x, z) is a

B. Cuenca Grau et al.

conjunction of atoms not mentioning  or , and (x) is a single atom. The
conjunction (x, z) is the body of r and the atom (x) is the head of r; quantifiers are often omitted for simplicity. An ontology is a finite set of rules.

We assume first-order semantics of formulae such as rules, and use |= in the

standard way as the logical consequence relation.

Example 3. Consider the ontology Oex consisting of the following rules:
knows(x, y)  person(x); knows(x, y)  person(y); fOf(x, y)  knows(x, y).
Intuitively, Oex says that only people can participate in the relation knows, and if
two people are friends (i.e., they participate in the fOf relation), then they know
each other. In Figure 1(b), we depict the dataset Dex from Example 1 extended
with ground atoms that are logically entailed by Oex Dex . For example, Oex 
Dex |= person(John) and Oex  Dex |= knows(John, Bob).

OWL 2 RL was designed as a syntactic subset of OWL 2 which is amenable to
implementation using rule-based technologies [7]. In particular, each OWL 2 RL
knowledge base can be normalised as a set of rules. We make two simplifying
assumptions w.r.t. the normative specification of OWL 2 RL. First, we ignore
datatypes for simplicity; second, we assume that no constants occur in rules.
The latter assumption ensures a clean separation between schema knowledge
and data. The following definition characterises a class of rules that is sufficient
to capture normative OWL 2 RL under our basic assumptions.
Definition 4 (RL ontology). An ontology O is an RL ontology if it can be
partitioned as O = O  O
1. Each rule r from O

is constant-free; furthermore, the variables in r consist

such that the following properties hold.

of a single root variable x and a set of branch variables y such that:
(a) each binary atom in the body of r must mention x once and only once;
(b) each branch variable y occurs in exactly one binary atom in the body;
(c) if the head atom is binary then it is of the form y  y
?

?

?
2. Each rule in O

from y, and the binary atoms in the body, mentioning y and y
on the same position.
same predicate symbol and have y and y
(c) R(x, y)  S(y, x); or
(d) R(x, y)  S(x, y)  .

(a) R(x, y)  S(x, y); or
(b) R(x, y)  S(y, z)  T (x, z); or

is of one of the following forms:
?

?

?
, for some y, y
, use the
?

?

?
The OWL 2 RL specification requires certain global restrictions to hold in
order to ensure that OWL 2 RL is a syntactic fragment of OWL 2 DL (e.g., transitive properties cannot occur in cardinality constraints) [7,10]. Such restrictions
are not reflected in Definition 4 since they are immaterial to our results.

Example 5. The ontology Oex is an RL ontology. Moreover, for Oex , O
of the first two rules, while O

ex consists of the last rule only.

ex consists
?

?

?
Definition 6 (Conjunctive query). A conjunctive query Q(x) is a first-order
formula of the form y. (x, y), where x and y are tuples of variables and
(x, y) is a conjunction of atoms.

We will write Q instead of Q(x) when x is irrelevant or clear from the context.
Definition 7 (Query answering). Let O be an ontology, D be a dataset, and
let Q(x) be a conjunctive query. A tuple t of constants is a certain answer to
Q(x) w.r.t. O and D if O  D |= Q(t). The set of all certain answers to a
conjunctive query Q(x) w.r.t. O and D is denoted by cert(Q,O,D).

Example 8. Consider the following queries:

Q1(x) = person(x);

Q2(x) = y, z. fOf(x, y)  fOf(y, z)  knows(z, x).

Clearly, cert(Q1,Oex ,Dex ) = {John, Bob, Mary} since all constants in Dex are
entailed to be persons (c.f., Figure 1(b)). Also, cert(Q2,Oex ,Dex ) = {John}
since John is a friend of Bob, Bob is a friend of Mary, and Mary knows John.

3 Controlled Query Evaluation for Ontologies

Our approach to confidentiality enforcement in ontology-based information systems was inspired by the CQE paradigm for incomplete databases first proposed
by Biskup and Weibert [5], which we briefly describe next.

A CQE system in [5] stores a database and a policy, which are both defined
as sets of propositional sentences. The policy is under the control of the system
administrators, and its goal is to declaratively specify the information that is to
be kept secret. Both database and policy are hidden from users, and interaction
with the system is limited to a query interface. Given a (propositional) user
query the system does not directly return the correct answer; instead, a censor
decides whether the answer needs to be modified according to the policy.

Let q1, . . . , qn be any finite sequence of such user queries, let v1, . . . , vn be the
answers (truth values) to these queries returned by the censor for the systems
database D, and let  be an arbitrary sentence in the policy. The confidentiality
of  is compromised if the truth values v1, . . . , vn fully determine the truth value
of  over D. In other words, to preserve confidentiality of  there must exist

some other database D
such that the censor evaluates the queries q1, . . . , qn to

the same values v1, . . . , vn over D
. This means that

D and D
are indistinguishable w.r.t. the user queries and hence the user cannot
decide whether  holds or not. Hereby, the censor must preserve confidentiality
of all the sensitive data in the policythat is, it should make sure that users
cannot derive any sentence in the policy by posing any finite set of queries.
?

?

?
, but  does not hold in D

Our framework focuses on ontology-based information systems and hence deviates from [5] in order to better reflect the specific features of standard ontology
and query languages. In the remainder of this section, we formally describe the
elements of our approach.

B. Cuenca Grau et al.

3.1 Policies and CQE-Instances

We start with some assumptions made in our framework. Following [5], we assume that both dataset and policy are hidden and that users can pose arbitrary
(conjunctive) queries to a query interface. We will assume, however, that the sys-
tems ontology is fully known to all users. The rationale behind this assumption
is twofold. On the one hand, information represented in ontologies is typically
common knowledge, and it is dangerous to enforce confidentiality by relying on
users unawareness of rather straightforward constraints; on the other hand, public availability of the systems background knowledge is key to improving access
to information: familiarity with the rules in the ontology can be invaluable for
users to formulate accurate queries. Furthermore, in our setting, information is
under the control of system developers and domain experts; thus, inconsistencies have been resolved before the query interface is made available to users. We
consequently assume that query answering is always performed over a satisfiable
ontology and dataset. This assumption makes query results meaningful to users.
Finally, we assume that a policy is represented by a set of ground atoms that
are logically entailed by the ontology and dataset in the system.

To sum up, the relevant content of the CQE system for the purpose of confi-

dentiality enforcement is formalised in the following definition.
Definition 9 (Policy, CQE-instance). Let O be an ontology and let D be a
dataset such that O  D is satisfiable. A policy P for O and D is a dataset such
that O  D |= P, and a CQE-instance is the triple I = (O,D,P).
Example 10. The dataset Pex = {knows(Mary, John)} is a policy for our running
example ontology Oex and dataset Dex since Oex Dex |= Pex . The triple Iex =
(Oex ,Dex ,Pex ) thus constitutes a CQE-instance.

3.2 Censors and Confidentiality Preservation

In [5], Biskup and Weibert consider censors that can distort query answers in
various ways. We adopt a pragmatic approach where censors are required to
return a sound, but possibly incomplete set of certain answers. Thus, the goal
of such a censor is limited to filtering out answers which may compromise the
policy. In contrast to [5], our censors never return unsound answers, or reject
queries.
Definition 11 (Censor). A censor cens for a CQE-instance I = (O,D,P) is
a function which maps each conjunctive query Q to a subset of cert(Q,O,D).

To align with the semantics of OWL 2, we adopt a notion of confidentiality
preservation that is formulated directly in terms of first-order models and en-
tailment. Specifically, with a censor cens for a CQE-instance I = (O,D,P), we
associate the following (possibly infinite) set of first-order sentences:
F (cens) = {Q(t) | t  cens(Q), Q(x) is a conjunctive query}.
?

?

?
The set F (cens) intuitively represents all the information that a user can potentially gain by interacting with the query interface. Since a user can ask only
a finite (yet unbounded) number of arbitrary queries, the information that the
user can gather from the system can be captured by a finite subset of F (cens).
Confidentiality preservation then amounts to ensuring that no finite subset of
F (cens) can logically entail an atom in the policy when coupled with O.
Definition 12 (Confidentiality preservation). Let I = (O,D,P) be a CQE-
instance. A censor cens for I is confidentiality preserving if for each ground atom
 in the policy P and each finite subset F of F (cens) it holds that O  F |= .
Definition 12 is consistent with the notion of confidentiality preservation in [5].
Indeed, if a censor cens is confidentiality preserving for I, then a user cannot entail
any confidential information from P regardless of what queries they pose. Thus,
for each atom  in the policy P and each finite subset F of F (cens) there is a model
of O  F in which  does not hold. Moreover, since O is an OWL 2 RL ontology
and F is a finite set of positive existential first-order sentences, there always exists
a finite model M , which can be seen as a database instance in the sense of Biskup
and Weibert. Since M |= F , the model M cannot be distinguished from D using
the query answers returned by the censor. In contrast, D and M differ w.r.t. the
atom  in the policy, which implies that the user cannot decide whether  holds
or not in D based on returned query answers alone.

3.3 Information Access vs. Confidentiality Tradeoff

There is a tradeoff between confidentiality preservation and accessibility of in-
formation. On the one hand, a censor for a CQE-instance that returns the empty
set of answers for each query is clearly confidentiality preserving, but it also does
not provide any useful information; on the other hand, a censor that returns all
the certain answers to each query maximises information accessibility, but may
not be confidentiality preserving. Hence, we are interested in optimal censors,
which distort the answer only if necessary for enforcing confidentiality.

Definition 13 (Optimality). Let I be a CQE-instance, and let cens be a confidentiality preserving censor for I. The censor cens is optimal if no other censor
cens
is confidentiality preserving; and (ii)
cens(Q)  cens

 = cens for I exists such that (i) cens
?

?

?
(Q) holds for each conjunctive query Q.

As we will discuss later on, there can be several optimal censors for a given
CQE-instance. In general, however, there is no good reason for choosing one over
the others, so we will design an algorithm which constructs all of them; however,
we will also study situations were a unique optimal censor is guaranteed to exist.
We conclude this section with a useful characterisation of the optimality of
cens in terms of its associated theory F (cens).
Proposition 14. Let cens be a confidentiality preserving censor for a CQEinstance I = (O,D,P). Then, cens is optimal iff for each conjunctive query
Q(x) and each tuple t  cert(Q,O,D) the fact that O  F (cens)  {Q(t)} |= 
holds for each   P implies that O  F (cens) |= Q(t).

B. Cuenca Grau et al.

4 View-Based Controlled Query Evaluation

As already discussed, the main task of the censor in a typical CQE system is
to receive answers to user queries as computed by the query answering engine,
and to decide, according to the policy, which answers are safe to return to the
user and which ones must be distorted. Such a censor is usually conceived as a
separate component, which is implemented on top of the query answering engine.
Unsurprisingly, implementing the censor of a CQE system becomes a major
challenge. The censors task can be computationally very expensive, and the
cost of the censors evaluation adds to the cost of query answering. Furthermore,
implementing the censor may require dedicated algorithms, and, in particular,
the highly optimised infrastructure available for query answering might not be
reusable. Hence, performance of a CQE system can be significantly affected by
the confidentiality enforcement component, and, as a result, the system might
not be practically feasible in performance-critical situations.

To address these challenges, we develop a novel approach that deviates from
the mainstream separation of query answering engine and censor as different
components of a CQE system. More specifically, we propose to exploit the available OWL 2 RL triple store infrastructure as much as possible, by delegating
the censors main computational workload to the query answering engine.
Our key idea is to associate to each CQE-instance I = (O,D,P) a new dataset,
which we call a view. Such a view V determines a censor censV in the sense
that, for each input user query Q, the censors output censV (Q) is uniquely and
trivially extractable from the set cert(Q,O,V) of all certain answers to Q w.r.t.
the ontology O and the view V. Since the view V is associated only with I and is
query-indenpendent, it also does not need to be recomputed until the underlying
dataset D is updated. In this way, the main workload of the censor in a typical
user session boils down to the computation of certain answers, which can be fully
delegated to the query answering engine.
Obviously, if we want the censor censV to enjoy the properties we are after,
the view V must be constructed with care. In order for censV to be indeed a
censor, V must not lead to spurious query answers. Furthermore, in order for
censV to be confidentiality preserving, V and O should not entail any atom in P.
Finally, in order for censV to be optimal, V must encode as much information
from D as possible. We next illustrate these ideas with an example.
Example 15. We construct a view Vex for our example CQE-instance Iex =
(Oex ,Dex ,Pex ). Since the policy Pex contains the atom  = knows(Mary, John),
we cannot include  in Vex . An obvious possibility would be to define Vex as
Dex \{}, and then censVex as the function that returns cert(Q,Oex ,Vex ) for each
conjunctive query Q. Clearly, censVex is a censor for Iex , since cert(Q,Oex ,Vex ) 
cert(Q,Oex ,Dex ), i.e., censVex returns only sound answers. Furthermore, censVex
is confidentiality preserving: since Oex  Vex |=  and Oex  Vex |= F (censVex ),
it is clear that Oex  F (censVex ) |= , as required by Definition 12. The censor censVex
is, however, not optimal. To see this, consider the query Q(x) =
y, z. fOf(x, y)  knows(y, z) asking for everyone who is a friend of someone
?

?

?
knows

person

knows

person

John

fOf

Bob

fOf

Mary

John

fOf

Bob

fOf

Mary

fOf

fOf

fOf

fOf

fOf

anm

anj

fOf

anb

fOf

anm

person

b)

knows

harmless in the
(c.f. Proposition 14).

sense

knows

that Oex  F(censVex )  {Q(Bob)}

a)
Fig. 2. View Vex (a), and view defining an optimal censor for Iex = (Oex ,Dex ,Pex ) (b);
dashed arrows represent binary atoms that do not occur in Dex
who in turn knows somebody else. We have cert(Q,Oex ,Dex ) = {John, Bob},
but cert(Q,Oex ,Vex ) = {John}; nevertheless, answering this query correctly is
|= 
Clearly, we cannot add  back into Vex without compromising the polVex by some other means. A possibility is to extend the domain of Vex
with an anonymised copy anm of Mary, and extend Vex with the atoms
fOf(Bob, anm) and knows(anm, John) (see Figure 2(a)). As a result, we obtain cert(Q,Oex ,Vex ) = {John, Bob} and Oex  Vex
|=  as we wanted.
There is, however, an undesired effect to this modification: for queries such as
(x) = y. knows(x, y) we would obtain the fresh constant anm as a spurious
?

?

?
answer. The obvious fix is to filter out such answers syntactically, and only return those answers in cert(Q,Oex ,Vex ) that mention only constants from the
domain of Dex . Although such extended view is still not optimal, we can reiter-

icy, and hence our only choice is to encode the missing information in

ate this procedure until we achieve optimality. As we will see, the view depicted
in Figure 2(b) defines an optimal censor for Iex .

We are ready to define the notion of a view V and its corresponding censor.
Definition 16 (View). Let I = (O,D,P) be a CQE-instance. A view for I is
a dataset V which satisfies the following properties:
(i) O  V |=  for each   P; and
(ii) t  cert(Q,O,V) implies t  cert(Q,O,D) for each conjunctive query Q
Definition 17 (View-based censor). Let I = (O,D,P) be a CQE-instance
and let V be a view for I. The censor based on V (or view-based censor when V
is clear) is the function censV mapping a conjunctive query Q to the set of tuples

and each tuple t of constants from D.

{t | t  cert(Q,O,V), t has constants only from D}.

By Property (ii) in Definition 16, each view-based censor is indeed a censor.
Proposition 18 establishes that view-based censors are confidentiality preserving.
Proposition 18. Let I be a CQE-instance and let V be a view for I. Then censV
is a confidentiality preserving censor for I.

B. Cuenca Grau et al.

5 Limitations of View-Based Censors

Before investigating the design of efficient view-based CQE algorithms, we first
explore the theoretical limitations of our approach. In this section we answer the
following important questions about an arbitrary CQE-instance I.

1. Is an optimal view-based censor for I guaranteed to exist?
2. How large can be the smallest view defining an optimal censor for I?

We answer the first question negatively: the presence of equality in the ontology
can preclude the existence of an optimal view-based censor, in the sense that the
view corresponding to such a censor would be necessarily infinite. As a result,
there are CQE-instances for which all view-based censors are not optimal.

Concerning the second question, we show that even if the ontology does not
contain equalities, the smallest view associated to an optimal censor can be at
least exponentially larger than the given instance. This is a crucial limitation
in practice, since such a censor would need to compute certain answers over an
exponentially large dataset, with the obvious negative effect on performance.

In Section 6 we will restrict the form of ontology rules to guarantee the exis-

tence of optimal censors based on small views.

5.1 Non-existence of Optimal View-Based Censors

We say that a censor cens for a CQE-instance I is view-definable if there exists a
view V for I such that cens = censV . The following theorem establishes that for
some CQE-instances view-definability and optimality of a censor are in conflict.
Theorem 19. There exists a CQE-instance I = (O,D,P) with an RL ontology
O, for which no censor exists that is both view-definable and optimal.

The intuition behind the proof is given by means of the following example.
Example 20. Consider the CQE-instance I = (O,D,P), where P = {emp(John)},
D = {manages(John, John)}, and O is defined as follows:
O = {manages(x1, y)  manages(x2, y)  x1  x2; manages(x, y)  emp(y)}.
The rules in O say that a person can only be managed by a single manager
and that everyone who is managed is an employee. Consider also the following
(infinite) sequence of conjunctive queries (for k  1):

Qk(x) = x1, . . . , xk. manages(x, x1)  . . .  manages(xk1, xk).

Clearly, John is the only certain answer to each Qk w.r.t. O and D. Furthermore,

answering each of these queries correctly is harmless for the confidentiality
of the policy, and hence each optimal censor for I must answer these queries
correctly. Imagine that such an optimal censor is based on some view V; in order
for John to be returned as an answer to a given Qk, V must contain atoms
?

?

?
manages(John, a1), . . . , manages(ak1, ak). Since k is unbounded and the view
must be finite, some of the individuals ai must be equal; but then, the fact
that manages is axiomatised in O as inverse-functional causes the management
chain in V to collapse into a cycle involving John. This compromises the
policy since O  V implies that John is managed by someone, and hence is an
employee.

5.2 Exponential Size of Views Defining Optimal Censors

Consider now the situation where an optimal view-based censor exists for a given
instance. The following theorem says that the smallest view associated to any
such optimal censor might necessarily be of size at least exponential in the size
of the given instance. In what follows, |O| and |D| denote the number of atoms
in the rules of the ontology O and in the dataset D, respectively.
Theorem 21. There exists a sequence of CQE-instances In = (On,Dn,P) for
n  1 such that On is an equality-free RL ontology, |On|  O(n), |Dn|  O(n),
and each view V for In with censV optimal is such that |V|  (2n).

Again, we explain the main ideas of the proof by means of an example.

Example 22. Next we give the second element I2 = (O2,D2,P) of the sequence
In of CQE-instances. Let P = {executive(John)} and

1(x)  Ai

O2 = {Ai
D2 = {managedBy(Bob, John)}  {Ai

2(x)  managedBy(x, y)  executive(y) | 1  i  2},

j(Bob) | 1  i, j  2}.

The ontology O2 has two rules with four atoms in each, and the dataset D2 has
2  2 + 1 atoms. Consider the following four queries, which ask for those people
who manage someone satisfying a given subset of requirements:

Qj1,j2 (y) = x. A1

j1 (x)  A2

j2 (x)  managedBy(x, y);

1  j1, j2  2.

Clearly, John is the only certain answer to each of these queries w.r.t. O2 and
D2. Answering these queries correctly does not compromise the policy, because
none of the pairs of Ai
j from the queries occur together in the body of any rule
in O2.
So, in order to be optimal, a censor censV must answer all these queries correctly and, for this, the view V must contain four witnessing constants aj1,j2 for
each 1  j1, j2  2, such that A1
j2 (aj1,j2 ), and managedBy(aj1,j2 , John)
are in V. Furthermore, any pair of these constants cannot be identified into a
single one, since otherwise the user would be able to derive the policy atom.
Similarly, for any other n  1, the domain of the view has to contain 2n

j1 (aj1,j2 ), A2

different constants aj1,...,jn (each witnessing a different query Qj1,...,jn ).

This example exploits that RL ontologies allow rules in which unary atoms
refer to branch variables. Alternatively, a similar example can be constructed by
using rules of the form 2(b) in Definition 4 (also known as role chain rules).

B. Cuenca Grau et al.

6 Efficient View-Based Controlled Query Evaluation

Theorems 19 and 21 show that ensuring optimality comes at the expense of
practicality. The proofs of these theorems, however, rely on very specific OWL
2 RL constructs: Theorem 19 critically depends on equality, whereas Theorem
21 requires a rule that mentions a unary atom involving a branch variable (or,
alternatively, a rule of the form 2(b) in Definition 4).

We next present a fragment RL

of OWL 2 RL for which the limitations from
Section 5 can be circumvented. We show that for any CQE-instance involving
ontology it is possible to construct an optimal view in polynomial time
an RL
(in the size of I). We start with the definition of RL





.







ontology is an RL ontology O =

is equality-free. Furthermore, each unary atom in r (both

ontology). An RL

satisfying the following restrictions.

Definition 23 (RL
O  O
1. Each rule r in O
in the head and body) mentions only the root variable of r.
2. There is no rule of the form 2(b) from Definition 4 in O
.

In particular, this definition ensures that positive rules in O
Sk(yk, x)  B(x).

Rj(x, yj) 

Ai(x) 
?

?

?
i

j

k

are of the form

The ontologies in Examples 20 and 22 are not RL


ontologies. Nevertheless,

is powerful enough to capture the rules corresponding to RDFS, including subclass and subproperty axioms (i.e., rules of the form A(x)  B(x) and
R(x, y)  S(x, y)) as well as property domain and range axioms (i.e., rules
R(x, y)  A(x) and R(x, y)  A(y)). Additionally, RL
goes well beyond RDFS
and can capture other useful kinds of OWL 2 RL rules.





Example 24. Our example ontology Oex is expressible as RDFS rules and hence

also in RL

. The following rules are RL

, but with no correspondence in RDFS:





fOf(x, y)  fOf(y, x);

emp(x)  manages(x, y)  manager(x);

student(x)  onpayroll(x)  PHDStudent(x).

(1)

(2)
(3)

Rule (1) axiomatises fOf as symmetric. Rule (2) says that employees managing
others are managers. Rule (3) says that paid students must be doing a PhD.

We next present an algorithm ComputeView (c.f. Algorithm 1) that takes as
input a CQE-instance I = (O,D,P) such that O is an RL
ontology and returns
a view V for I such that censV is guaranteed to be an optimal censor. This
algorithm works in polynomial time and, hence, computes V of polynomial size.
The algorithm ComputeView starts by creating an anonymised copy of each
constant occurring in D (Line 2), and replicates in Dan all atoms (unary and
binary) of D on these new constants (Lines 3-4). Moreover, if R(a, b) is in D,


?

?

?
Algorithm 1. ComputeView
INPUT : A CQE-instance I = (O,D, P) with an RL
OUTPUT: A view V for I



ontology O

1 Dan := ;
2 foreach constant a occurring in D do create a fresh constant an a;
3 foreach A(a)  D do Dan := Dan  {A(an a)};
4 foreach R(a, b)  D do Dan := Dan  {R(an a, an b), R(a, an b), R(an a, b)};
5 Dsat := D  Dan;
6 foreach atom  s.t. O  D  Dan |=  do Dsat := Dsat  {};
7 V := ;
8 repeat

Choose   Dsat such that O  V  {} |=  for each   P;
V := V  {}

11 until no such   Dsat can be chosen;
12 return V.

then the algorithm also relates by R in Dan the constant a to the anonymised copy
anb of b, and the anonymised copy ana of a to b (Line 4). Then, the algorithm
saturates the resulting dataset Dsat = D Dan with all facts entailed by O Dsat
(Line 6). Finally, it enforces the policy P by computing a maximal subset V of
the saturated dataset that respects P (Lines 8-11), which is finally returned as
the output. Note, that different choices in Line 9 might lead to different outputs,
i.e., algorithm ComputeView is non-deterministic. Indeed, for a given instance I,
there may be several view-based censors that are optimal, and each run of the
algorithm ComputeView computes one of them; however, as we will see later on,
any view leading to an optimal censor is computed by some run of the algorithm.

Example 25. When receiving our running example CQE-instance Iex as input,
the algorithm ComputeView computes the view given in Figure 2(b). In this case,
the algorithms output is independent from the choices made in Line 9, i.e., all
possible runs of the algorithm lead to the same result.
To see how different runs of the algorithm might lead to different outputs,
consider a CQE-instance I = (O,D,P) where O = {A(x)  B(x)  C(x)},
D = {A(a), B(a)}, and P = {C(a)}. There are two possible runs of ComputeView
on I, which lead to two different views {A(a), A(an a), B(an a), C(ana)} and
{B(a), A(an a), B(an a), C(ana)}, respectively.

The following theorem establishes correctness and complexity of the algorithm.
Theorem 26. Let I = (O,D,P) be a valid input of the algorithm ComputeView.
(i) If V is the result of a run of ComputeView on I then censV is an optimal

censor for I.

B. Cuenca Grau et al.

I that computes V such that cens = censV .

(ii) For each optimal censor cens for I, there exists a run of ComputeView on
(iii) The algorithm can be implemented to run in time polynomial in |D| + |O|.

There is a couple of remarks about the proof of Theorem 26 that are worth
to be made here. Polynomial complexity is a direct consequence of two facts:

first, the size of Dsat is polynomial in the size of D and O; second, checking

whether a ground atom can be entailed from an OWL 2 RL ontology and a
dataset can be done in polynomial time in both the size of the ontology and
dataset [7]. Optimality of censV relies on the fact that Dsat captures all the
possible matchings of an input query Q over the least Herbrand model of OD;
for this to be the case, the restrictions on rules imposed by RL

are the key.



7 Uniqueness of Optimal View-Based Censors

The fact that the output of ComputeView is not uniquely determined can be
problematic. For example, a CQE system that relies on this algorithm needs to
ensure that the same view is used in different user sessions, as well as for different
users for which equivalent policies apply. One could, of course, determinise the
output of the algorithm using application-dependent heuristics; however, there
may not be a good reason for choosing one possible view over the others.

Our first proposal is to impose further restrictions to the ontology language.
Example 25 suggests that existence of multiple views is related to the presence
of conjunction in the bodies of rules, which suggests the restriction given next.
ontology O is linear if every

ontology). An RL
Definition 27 (Linear RL
rule in O contains exactly one atom in the body.
Each RDFS ontology, such as Oex in our running example, is also a linear RL











ontology; hence, linearity might not be too strict a restriction for many Semantic
Web applications. Note also that linear RL
is a fragment of OWL 2 QL, in the
sense that every linear RL
rule can be transformed into an equivalent OWL 2
is not captured by OWL 2 QL since it
QL axiom. In contrast, non-linear RL
allows for conjunction in the body of rules. The following theorem shows that
restricting ourselves to linear ontologies has the desired effect.
Theorem 28. If I = (O,D,P) is a CQE-instance with O a linear RL
ogy; then, each run of ComputeView on I yields the same result.

ontol-





Corollary 29. Let I = (O,D,P) be a CQE-instance with O a linear RL
on-
tology and let V be the result of a run of ComputeView on I; then, censV is the
only optimal censor for I.



For applications where linearity is too strict, we can give up optimality in

favour of uniqueness by taking the intersection of all optimal views.
?

?

?
Definition 30. Let I = (O,D,P) be a CQE-instance with O an RL
The WIDTIO-view1 for I is the view defined as the following set of atoms:
{ground atom  | O  V |=  for each view V for I with censV optimal}.



ontology.

The (non-optimal) censor based on the WIDTIO-view implements a cau-
tious approach to confidentiality enforcement since it disregards all atoms that
could possibly participate in the disclosure of an atom in P. The following theorem shows, however, that this solution might be computationally expensive.

Theorem 31. Deciding whether a ground atom  belongs to the WIDTIO-view
for a CQE-instance I = (O,D,P) with O an RL

ontology is coNP-complete.



8 Related Work

The CQE paradigm was first proposed by Sichermann et al. [6], and was later
extended by Biskup, Bonatti, Kraus and Subrahmanian [3,2,4,1]. CQE in the
context of incomplete databases was studied by Biskup and Weibert [5]. These
foundational works on CQE assume that both the information in the system and
user queries are represented in propositional logic. Recently, Biskup and Bonatti
studied CQE in relational databases where queries contain answer variables [12].
The formal study of data privacy and information hiding has received significant attention within the database community. Miklau and Suciu introduced
perfect privacy in data exchange [13]. Rizvi et al. studied view-based authorisation mechanisms [14,15], and Deutsch et al. analysed the logical implications to
privacy derived from publishing views of a database [16]. Formal data privacy
frameworks have been proposed by Kifer et al. [17] and Evfimievski et. al. [18].
Privacy and information hiding in the context of ontologies has been investigated only recently. Information hiding at the schema level has been studied in
[19,20]. Data privacy was studied for EL ontologies by Tao et al. [21]. Bao et al.
introduced the notion of a privacy-preserving reasoner [22] and Stouppa et al.
proposed a framework for data privacy in the context of ALC ontologies [23]. Fi-
nally, Calvanese et al. [24] proposed techniques for ontology access authorisation
based on Zhang and Mendelzons database authorisation views paradigm [15].

9 Conclusion and Future Work

We have proposed novel techniques for enforcing confidentiality in information
systems that rely on RDF, SPARQL, and OWL 2 RL for representing data,
queries, and ontologies, respectively. Our techniques ensure an optimal tradeoff
between confidentiality and accessibility of information; furthermore, they can
be efficiently implemented by relying on existing highly optimised OWL 2 RL
triple stores. Our next step is to implement and test our algorithms, and we are

1 This solution is related to the well-known When In Doubt Through It Out

(WIDTIO) approach [11] to knowledge base update.

B. Cuenca Grau et al.

also planning to consider the problem of view maintenance for applications that
require very frequent changes to the data, such as data streaming applications.
Finally, we will study how our results could be extended to the case where the
ontology is expressed in either the QL, or the EL profile of OWL 2.
