Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : h t t p : / / w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

Robust and scalable Linked Data reasoning incorporating provenance
and trust annotations
Piero A. Bonatti a, Aidan Hogan b,

, Axel Polleres b, Luigi Sauro a

a Universita di Napoli Federico II, Complesso Universitario di Monte S. Angelo, Via Cinthia, I-80126 Napoli, Italy
b Digital Enterprise Research Institute, National University of Ireland, Galway, Ireland

a r t i c l e

i n f o

a b s t r a c t

Article history:
Available online 17 June 2011

Keywords:
Annotated programs
Linked Data
OWL 2 RL
Scalable reasoning
PageRank
Provenance

In this paper, we leverage annotated logic programs for tracking indicators of provenance and trust during reasoning, specifically focussing on the use-case of applying a scalable subset of OWL 2 RL/RDF rules
over static corpora of arbitrary Linked Data (Web data). Our annotations encode three facets of informa-
tion: (i) blacklist: a (possibly manually generated) boolean annotation which indicates that the referent
data are known to be harmful and should be ignored during reasoning; (ii) ranking: a numeric value
derived by a PageRank-inspired techniqueadapted for Linked Datawhich determines the centrality
of certain data artefacts (such as RDF documents and statements); (iii) authority: a boolean value which
uses Linked Data principles to conservatively determine whether or not some terminological information
can be trusted. We formalise a logical framework which annotates inferences with the strength of derivation along these dimensions of trust and provenance; we formally demonstrate some desirable properties of the deployment of annotated logic programming in our setting, which guarantees (i) a unique
minimal model (least fixpoint); (ii) monotonicity; (iii) finitariness; and (iv) finally decidability. In so
doing, we also give some formal results which reveal strategies for scalable and efficient implementation
of various reasoning tasks one might consider. Thereafter, we discuss scalable and distributed implementation strategies for applying our ranking and reasoning methods over a cluster of commodity hardware;
throughout, we provide evaluation of our methods over 1 billion Linked Data quadruples crawled from
approximately 4 million individual Web documents, empirically demonstrating the scalability of our
approach, and how our annotation values help ensure a more robust form of reasoning. We finally sketch,
discuss and evaluate a use-case for a simple repair of inconsistencies detectable within OWL 2 RL/RDF
constraint rules using ranking annotations to detect and defeat the marginal view, and in so doing, infer
an empirical consistency threshold for the Web of Data in our setting.

O 2011 Elsevier B.V. All rights reserved.

1. Introduction

The Semantic Web is no longer purely academic: in particular,
the Linking Open Data project has fostered a rich lode of openly
available structured data on the Web, commonly dubbed the
Web of Data [53]. Based on the Resource Description Framework
(RDF), Linked Data emphasises four simple principles: (i) use URIs
as names for things (and not just documents); (ii) make those URIs
dereferenceable via HTTP; (iii) return useful and relevant RDF content upon lookup of those URIs; (iv) include links to other datasets.
Since its inception four years ago, the Linked Data community has
overseen exports from corporate bodies (e.g., the BBC, New York
Times, Freebase, Linked Clinical Trials [linkedct.org], Thompson
Reuters [opencalais.com] etc.), governmental bodies (e.g., UK

 Corresponding author.

E-mail addresses: bonatti@na.infn.it (P.A. Bonatti), aidan.hogan@deri.org (A.

Hogan), axel.polleres@deri.org (A. Polleres), sauro@na.infn.it (L. Sauro).

1570-8268/$ - see front matter O 2011 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2011.06.003

Government [data.gov.uk], US Government [data.gov], US National Science Foundation, etc.), community driven efforts (e.g.,
Wikipedia-based exports [dbpedia.org], GeoNames, etc.), socialnetworking sites (e.g., MySpace [dbtune.org], flickr, Twitter
[semantictweet.com], etc.) and scientific communities (e.g.,
DBLP, PubMed, UniProt), amongst others.1

Interspersed with these voluminous exports of assertional (or
instance) data are lightweight schemata/ontologies defined in
RDFS/OWLwhich we will collectively call vocabulariescomprising the terminological data which describe classes and properties
and provide a formalisation of the domain of discourse. The assertional data describe things by assigning datatype (string) values for
named attributes (datatype properties), named relations to other

1 See http://richard.cyganiak.de/2007/10/lod/ for a comprehensive graph
of such datasets and their inter-linkage; howeverand as the Linked Open Numbers
project (see [64] Fig. 1]) has aptly evinced, and indeed as we will see ourselves in later
evaluationnot all of this current Web of Data is entirely compelling.

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

things (object properties), and named classifications (classes). The
terminological data describe these classes and properties, with
RDFS and OWL providing the formal mechanisms to render the
semantics of these termsin particular, their inter-relation and
prescribed intended usage. Importantly, best-practices encourage:
(i) re-use of class and property terms by independent and remote
data publishers; (ii) inter-vocabulary extension of classes and
properties;
(iii) dereferenceability of classes and properties,
returning a formal RDFS/OWL description thereupon.

Applications are slowly emerging which leverage this rich vein
of structured Web data; however, thus far (with of course a few
exceptions) applications have been slow to leverage the underlying
terminological data for reasoning. Loosely speaking, reasoning utilises the formal underlying semantics of the terms in the data to
enable the derivation of new knowledge. With respect to Linked
Data, sometimes there is only sparse re-use of (terminological
and/or assertional) terms between sources, and so reasoning can
be used to better integrate the data in a merged corpus as follows:
(i) infer and support the semantics of ground equality (owl:sam-
eAs relations between individuals) to unite knowledge fractured
by insufficient URI re-use across the Web; (ii) leverage terminological knowledge to infer new assertional knowledge, possibly across
vocabularies and even assertional documents; (iii) detect inconsistencies whereby one or more parties may provide conflicting
dataherein, we focus on the latter two reasoning tasks.

However, reasoning over (even subsets) of the Web of Data
poses two major challenges, with serious implications for reason-
ing: (i) scalability, where one can expect Linked Data corpora containing in the order of billions or tens of billions of statements (for
the moment); (ii) tolerance to noise and inconsistency, whereby data
published on the Web are afflicted with naive errors and disagree-
ment, arbitrary redefinitions of classes/properties, etc. Traditional
reasoning approaches are not well positioned to tackle such chal-
lenges, where the main body of literature in the area is focussed
on considerations such as expressiveness, soundness, completeness and polynomial-time tractability2, and makes some basic
assumptions about the underlying data quality; for example, tab-
leaux-based algorithms struggle with large bodies of assertional
knowledge, and are tied by the principle of ex falso quodlibetfrom
contradiction follows anythingand thus struggle when reasoning
over possibly inconsistent data.3

In previous works, we presented our Scalable Authoritative
OWL Reasoner (SAOR) which applies a subset of OWL 2 RL/RDF
rules over arbitrary Linked Data crawls: in particular, we abandon
completeness in favour of conducting sensible inferencing which
we argue to be suitable for the Linked Data use-case [36,38].4 We
have previously demonstrated distributed reasoning over 1 b
Linked Data triples [38], and have also presented some preliminary
formalisations of what we call authoritative reasoning, which considers the source of terminological data during reasoning [36]. The
SAOR system is actively used for materialising inferences in the
Semantic Web Search Engine (SWSE) [37] which offers search and
browsing over Linked Data.5

In this paper, we look to reformalise how the SAOR engine
incorporates the notions of provenance and trust which form an
integral part of its tolerance to noise, where we see the use of
annotated logic programs [42] as a natural fit. We thus derive a for-

2 In our scenario with assertional data from the Web in the order of billions of

statements, even quadratic complexity is prohibitively expensive.

3 There is ongoing research devoted to paraconsistent logics which tackle this
issuee.g., see a recent proposal for OWL 2 [51]but the efficiency of such approaches
is still an open question.

4 For a high-level discussion on the general

infeasibility of completeness for

scenarios such as ours, see [31].

5 http://swse.deri.org/

mal logical framework for annotated reasoning in our setting,
which encodes three indicators of provenance and trust and which
thus allows us to apply robust materialisation over large, static,
Linked Data corpora.

Further, in previous work we noted that many inconsistencies
arise on the Web as the result of incompatible naming of resources,
or naive publishing errors [35]: herein, we look at a secondary usecase for our annotations which leverages OWL 2 RL/RDF constraint
rules to detect inconsistencies, where subsequently we perform a
simple repair of the Web knowledge-base using our annotationsparticularly ranksto identify and defeat the marginal
view present in the inconsistency. More specifically, we:

 introduce some necessary preliminaries (Section 2);
 discuss our proposed annotation values to represent provenance and trustblacklisting, authority, and rankinggiving concrete instantiations for each (Section 3);

 describe a formal framework for annotated programs which
incorporate the above three dimensions of provenance and
trust, including formal discussion of constraint rules (Section 4);
 describe our experimental setup and our 1 billion triple Linked

Data corpus (Section 5);

 describe our distributed (i) implementation and evaluation of
links-based ranking (Section 6), (ii) annotated reasoning for a
subset of OWL 2 RL/RDF rules (Section 7), and (iii) our inconsistency detection and repair use-case (Section 8);

 discuss issues relating to scalability and expressiveness (Section
9), render related work in the field (Section 10), and conclude
(Section 11).

2. Preliminaries

In this section, we provide some necessary preliminaries relating to (i) RDF (Section 2.1); (ii) Linked Data principles and data
sources (Section 2.2); (iii) rules and atoms (Section 2.3); (iv) generalised annotated programs (Section 2.4) (v) terminological data given by RDFS/OWL (Section 2.5); and (vi) OWL 2 RL/RDF rules
(Section 2.6). We attempt to preserve notation and terminology
as prevalent in the literature.

2.1. RDF

We briefly give some necessary notation relating to RDF con-

stants and RDF triples; cf. [30].

2.1.1. RDF constant

Given the set of URI references U, the set of blank nodes B,6 and
the set of literals L, the set of RDF constants is denoted by C:= U [ B [
L. We also define the set of variables V which range over C.

Herein, we use CURIEs [5] to denote URIs. Following Turtle syntax [2], use a as a convenient shortcut for rdf:type. We denote
variables with a ? prefix.

2.1.2. RDF triple

A triple t: = (s,p,o) 2 (U [ B) 
 U 
 C is called an RDF triple,
where s is called subject, p predicate, and o object. A triple
t: = (s,p,o) 2 G,G: = C 
 C 
 C is called a generalised triple [25],
which allows any RDF constant in any triple position: henceforth,
we assume generalised triples unless explicitly stated otherwise.
We call a finite set of triples G  G a graph.

6 We interpret blank-nodes as skolem constants, as opposed to existential
variables. Also, we rewrite blank-node labels to ensure uniqueness per document,
as prescribed in [30].

2.2. Linked Data principles, data sources and quadruples

In order to cope with the unique challenges of handling diverse
and unverified Web data, many of our components and algorithms
require inclusion of a notion of provenance: consideration of the
source of RDF data found on the Web. Tightly related to such notions are the best practices of Linked Data [3], which give clear
guidelines for publishing RDF on the Web. We briefly discuss
Linked Data principles and notions relating to provenance.7

2.2.1. Linked Data principles

The four best practices of Linked Data are as follows [3]:

 (LDP1) use URIs to name things;
 (LDP2) use HTTP URIs so that those names can be looked up;
 (LDP3) provide useful structured information when a look-up

on a URI is made  loosely, called dereferencing;

 (LDP4) include links using external URIs.

2.2.2. Data source

We define the http-download function get :U ? 2G as the mapping from a URI to an RDF graph (set of facts) it may provide by
means of a given HTTP lookup [21] which directly returns status
code 200 OK and data in a suitable RDF format; this function also
performs a rewriting of blank-node labels (based on the input
URI) to ensure uniqueness when merging RDF graphs [30]. We define the set of data sources S  U as
the set of URIs
S: = {s 2 Ujget(s)  ;}.

2.2.3. RDF triple in context/RDF quadruple

An ordered pair (t, c) with a triple t = (s, p, o),c 2 S and t 2 get(c)
is called a triple in context c. We may also refer to (s, p, o, c) as an
RDF quadruple or quad q with context c.

2.2.4. HTTP redirects/dereferencing

A URI may provide a HTTP redirect to another URI using a 30x
response code [21]; we denote this function as redir : U? U which
may map a URI to itself in the case of failure (e.g., where no redirect
exists)note that we do not need to distinguish between the different 30x redirection schemes, and that this function would implicitly involve, e.g., stripping the fragment identifier of a URI [4].
We denote the fixpoint of redir as redirs, denoting traversal of a
number of redirects (a limit may be set on this traversal to avoid
cycles and artificially long redirect paths). We define dereferencing
as the function deref : get  redirs which maps a URI to an RDF graph
retrieved with status code 200 OK after following redirects, or
which maps a URI to the empty set in the case of failure.

2.3. Atoms and rules

In this section, we briefly introduce some notation as familiar
from the field of Logic Programming [48], which acts as a generalisation of the aforementioned RDF notation.

2.3.1. Atom

Atoms are of the form p(e1, . . . ,en) where e1,

. . . ,en are terms
(like Datalog, function symbols are disallowed) and where p is a
predicate of arity nwe denote the set of all such atoms by Atoms.
This is a generalisation of RDF triples, for which we employ a ternary predicate T where our atoms are of the form T(s,p, o)for brev-
ity, we commonly omit the ternary predicate and simply write
(s,p, o). An RDF atom of this form is synonymous with a generalised

triple pattern where variables of the set V are allowed in any posi-
tion). A ground atomor simply a factis one which does not contain variables (e.g., a generalised triple); we denote the set of all
facts by Factsa generalisation of G. A (Herbrand) interpretation I
is a finite subset of Factsa generalisation of a graph.

Letting A and B be two atoms, we say that A subsumes Bdenoted A.Bif there exists a substitution h of variables such that
Ah = B (applying h to the variables of A yields B); we may also say
that B is an instance of A; if B is ground, we say that it is a ground
instance. Similarly, if we have a substitution h such that Ah = Bh,
we say that h is a unifier of A and B; we denote by mgu(A,B) the
most general unifier of A and B which provides the minimal variable substitution (up to variable renaming) required to unify A and
B.

2.3.2. Rule

A rule R is given as follows:

H   B1; . . . ; Bnn P 0
where H,B1, . . . ,Bn are atoms, H is called the head (conclusion/conse-
quent) and B1, . . . ,Bn the body (premise/antecedent). We use Head(R)
to denote the head H of R and Body(R) to denote the body B1, . . . , Bn
of R. Our rules are range restricted  or safe [60]: like Datalog, the
variables appearing in the head of each rule must also appear in
the body.

The set of all rules that can be defined over atoms using an
(arbitrary but fixed) infinite supply of variables will be denoted
by Rules. A rule with an empty body is considered a fact; a rule
with a non-empty body is called a proper-rule. We call a finite set
of such rules a program P.

Like before, a ground rule is one without variables. We denote
with Ground(R) the set of ground instantiations of a rule R and with
Ground(P) the ground instantiations of all rules occurring in a program P.

Immediate Consequence Operator We give the (classical) immediate consequence operator CP of a program P under interpretation
I as:
CP : 2Facts ! 2Facts

I # HeadRhjR 2 P and
9= I0

# I s:t: h 14 mguBodyR; I0

Intuitively, the immediate consequence operator maps from a set of
facts I to the set of facts it directly entails with respect to the program Pnote that CPI will retain the facts in P since facts are rules
with empty bodies and thus unify with any interpretation, and note
that for our purposes CP is monotonicthe addition of facts and
rules to a program can only lead to a superset of consequences.

Since our rules are a syntactic subset of Datalog, CP has a least
fixpointdenoted lfpCPwhereby further application of CP will
not yield any changes, and which can be calculated in a bottomup fashion, starting from the empty interpretation D and applying
iteratively CP [66] (here, convention assumes that P contains the
set of input facts as well as proper rules). Define the iterations of
CP as follows: CP " 0 :14 D;
for all ordinals a, CP " a  1 :14
CPCP " a; since our rules are Datalog, there exists an a such that
lfpCP 14 CP " a for a < x, where x denotes the least infinite ordi-
nali.e., the immediate consequence operator will reach a fixpoint
in countable steps [61], thereby giving all ground consequences of
the program. We call lfpCP the least model, which is given the
more succinct notation lm(P).

2.4. Generalised annotated programs

7 Note that in a practical sense, all HTTP-level functions {get, redir, redirs, deref} are

set at the time of the crawl, and are bounded by the knowledge of our crawl.

In generalised annotated programs [42] the set of truth values is
that may

generalised to an arbitrary upper semilattice T ,

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

representsayfuzzy values,
(i.e., time), or a confidence value, to name but a few.

inconsistencies, validity intervals

(Generalised) Annotated rules Annotated rules are expressions

like
H : q   B1 : l1; . . . ; Bn : ln
where each li can be either an element of T or a variable ranging
over T ; q can be a function f(l1, . . . ,ln) over T . Programs, Ground(R)
and Ground(P) are defined analogously to non-annotated programs.

Example 1. Consider the following simple example of a (general-
ised) annotated rule where T corresponds to a set of confidence
values in the interval [0,1] of real numbers:

Father?x : 0:5 
 l   Parent?x : l:
This rule intuitively states that something is a Father with (at least)
half of the confidence for which it is a Parent.8 h

2.4.1. Restricted interpretations

So-called restricted interpretations map each ground atom to a
member of T . A restricted interpretation I satisfies A:l (in symbols,
I  A:l) iff IAPT l, where PT is T s ordering. Now I satisfies a rule
like the above iff either I satisfies the head or I does not satisfy
some of the annotated atoms in the body.

Example 2. Take the annotated rule from Eq. 1, and let us say that
we have a restricted interpretation I which satisfies Parent(-
sam):0.6. Now, for I to satisfy the given rule, it must also satisfy
Father(sam):0.3 such that I(Father(sam)) P 0.3. h

2.4.2. Restricted immediate consequences

In the generalised annotation framework, the restricted immediate consequence operator of an annotated program P is defined as follows, where r ranges over substitutions:
RPIA :14 lub qjA : q   B1 : l1; . . . ; Bn : lnr 2 GroundP and

I  Bi : lir for 1 6 i 6 n

Example 3. Take a program P which comprises of the annotated
rule shown in Eq. 1 and the annotated fact Parent(sam):0.6. Then,
RPIFathersam 14 0:3. Instead, let us say that P also contains
Father(sam):0.5. Then RPIFathersam 14 lubf0:5; 0:3g 14 0:5. h

Importantly, various properties of RP have been formally demonstrated for generalised annotated programs in [42], where
we will reuse these results later for our own (more specialised) annotation framework in Section 4; for example, RP has been shown
to be monotonic, but not always continuous [42].

2.5. Terminological data: RDFS/OWL

As previously described, RDFS/OWL allow for providing terminological data which constitute definitions of classes and properties used in the data. A detailed discussion of RDFS/OWL is out of
scope, but the distinction of terminological and assertional data
which we now describeis important for our purposes. First, we
require some preliminaries.9

2.5.1. Meta-class

We consider a meta-class as a class specifically of classes or prop-
erties; i.e., the members of a meta-class are themselves either
classes or properties. Herein, we restrict our notion of meta-classes
to the set defined in RDF(S) and OWL specifications, where examples
include rdf:Property, rdfs:Class, owl: Class, owl: Restric-
tion, owl: Datatype Property, owl: Functional Property,
etc. Note that rdfs:Resource, rdfs:Literal, e.g., are not meta-
classes, since their members need not be classes or properties.

Meta-property A meta-property is one which has a meta-class as
its domain. Again, we restrict our notion of meta-properties to the set
defined in RDF(S) and OWL specifications, where examples include
rdfs: domain, rdfs: sub Class Of, owl:has Key, owl:inverse
Of, owl:one Of, owl:on Property, owl:union Of, etc. Note that
rdf: type, owl:sameAs, rdfs: label, e.g., do not have a metaclass as domain, and are not considered meta-properties.

Terminological data We define the set of terminological triples as

the union of the following sets of triples:

(i) triples with rdf:type as predicate and a meta-class as

object;

(ii) triples with a meta-property as predicate;
(iii) triples forming a valid RDF list whose head is the object of a
meta-property (e.g., a list used for owl: union Of, owl:
intersection Of, etc.);

(iv) triples which contribute to an all-disjoint-classes or all-dis-

joint-properties axiom.10

Note that the last category of terminological data is only required
for special consistency-checking rules called constraints: i.e., rules
which check for logical contradictions in the data. For brevity, we
leave this last category of terminological data implicit in the rest
of the paper, where owl: All Disjoint Classes and owl: All
Disjoint Properties can be thought of as honorary meta-clas-
ses included in category 1, owl: members can be thought of as an
honorary meta-property included in category 2, and the respective RDF lists included in category 3.

Finally, we do not consider triples involving user-defined
meta-classes or meta-properties as contributing to the terminol-
ogy, where in the following example, the first triple is considered
terminological, but the second triple is not.11

(ex:inSubFamily, rdfs:subPropertyOf, rdfs:subClassOf)
(ex:Bos, ex:inSubFamily, ex:Bovinae)

2.5.2. T-split rule

A T-split rule R is given as follows:
H   A1; . . . ; An; T1; . . . ; Tm n; m P 0

where the Ti, 0 6 i 6 m atoms in the body (T-atoms) are all those
that can only have terminological ground instances, whereas the
Ai, 1 6 i 6 n atoms (A-atoms), can have arbitrary ground instances.
We use TBody(R) and ABody(R) to, respectively, denote the set of
T-atoms and the set of A-atoms in the body of R. Herein, we presume that the T-atoms and A-atoms of our rules can be distinguished and referenced as defined above.

Example 4. Let REX denote the following rule

8 This example can be trivially converted to RDF by instead considering the ternary

atoms (?x, a, ex:Parent) and (?x, a, ex:Father).

9 As we are dealing with Web data, we refer to the OWL 2 Full language and the
OWL 2 RDF-based semantics [18] unless explicitly stated otherwise. Note that a clean
and intuitive definition of terminological data is somewhat difficult for RDFS and
particularly OWL Full. We instead rely on a shibboleth approach which identifies
markers for what we consider to be RDFS/OWL terminological data.

10 That is, triples with rdf:type as predicate and owl: All Disjoint Classes or
owl:All Disjoint Properties as object, triples whose predicate is owl: members
and whose subject unifies with the previous category of triples, and triples forming a
valid RDF list whose head unifies with the object of such an owl: members triple.
11 In particular, we require a data-independent method for distinguishing terminological data from purely assertional data, such that we only allow those meta-
classes/-properties which are known a-priori.

(?x, a, ?c2)   (?c1, rdfs:sub Class Of, ?c2), (?x, a, ?c1)
When writing T-split rules, we denote TBody(REX) by underlining:
the underlined T-atom can only be bound by a triple with the
meta-property rdfs: subClass Of as RDF predicate, and thus can
only be bound by a terminological triple. The second atom in the
body can be bound by assertional or terminological triples, and so
is considered an A-atom. h

T-ground rule A T-ground rule is a set of rule instances for the T-
split rule R given by grounding TBody(R). We denote the set of such
rules for a program P and a set of facts I as GroundT(P,I), defined as:
GroundTP; I :14 HeadRh   ABodyRhjR 2 P
and 9= I0
The result is a set of rules whose T-atoms are grounded by the terminological data in I.

# I s:t: h 14 mguTBodyR; I0

Example 5. Consider the T-split rule REX from the previous
example. Now let IEX: = {(foaf:Person, rdfs:subClassOf, foa-
f:Agent), (foaf:Agent, rdfs:subClassOf, dc:Agent)}. Here,
GroundT({REX},IEX) = {(?x, a, foaf:Agent)   (?x, a, ?foaf:Per-
son); (?x, a, dc:Agent)   (?x, a, ?foaf:Agent)}. h

T-split program and least fixpoint Herein, we give an overview of
the computation of the T-split least fixpoint for a program P, which
is broken up into two parts: (i) the terminological least fixpoint,
and (ii) the assertional least fixpoint. Let PF: = {R 2 PjBody(R) = ;}
be the set of facts in P,12 let PT;: = {R 2 PjTBody(R)  ;,ABody(R) = ;},
let P;A: = {R 2 PjTBody(R) = ;,ABody(R)  ;}, and let PTA: = {R 2 Pj
TBody(R)  ;,ABody(R)  ;}. Clearly, P = PF [ PT; [ P;A [ PTA. Now, let
TP: = PF [ PT denote the initial (terminological) program containing
ground facts and T-atom only rules, and let lm(TP) denote the least
model for the terminological program. Now, let AP: = lm(TP) [ P;A
[ GroundT(PTA, lm(TP)) denote the second (assertional) program containing all available facts and rules with empty or grounded T-atoms.
Now, we can give the least model of the T-split program P as lm(AP) for
AP derived from P as abovewe more generally denote this by lmT(P).
In [38], we showed that the T-split least fixpoint is complete
wrt. the standard variant (given that our rules are monotonic)
and that the T-split least fixpoint is complete with respect to the
standard fixpoint if rules requiring assertional knowledge do not
infer unique terminological knowledge required by the T-split program (i.e., the assertional program AP does not generate new terminological facts not available to the initial program TP).

2.6. OWL 2 RL/RDF rules

OWL 2 RL/RDF [25] rules are a partial axiomatisation of the
OWL 2 RDF-Based Semantics which is applicable for arbitrary
RDF graphs, and thus is compatible with RDF Semantics [30]. The
atoms of these rules comprise primarily of ternary predicates
encoding generalised RDF triples; some rules have a special head
denoted false which indicate that an instance of the body is
inconsistent. All such rules can be considered T-split where we
use the aforementioned criteria for characterising terminological
data and subsequently T-atoms.

As we will further discuss in Section 7, full materialisation wrt.
the entire set of OWL 2 RL/RDF is infeasible in our use-case; in par-
ticular, given a large A-Box of arbitrary content, we wish to select a
subset of the OWL 2 RL/RDF profile which is linear with respect to
that A-Box; thus, we select a subset O2R of OWL 2 RL/RDF rules
where jABody(R)j 6 1 for all R 2 O2R [36]we provide the full
ruleset in Appendix A. Besides ensuring that the growth of assertional inferences is linear wrt. the A-Boxand as we will see in la-

12 Of course, PF can refer to axiomatic facts and/or the initial facts given by an input
knowledge-base.

ter sectionsour linear profile allows for near-trivial distribution
of reasoning, as well as various other optimisation techniques
(see [38,32]).

With respect to OWL 2 RL/RDF, in [32] we showed that the T-
split least fixpoint is complete assuming (i) no non-standard usage,
whereby rdf:type, rdf:first, rdf:rest and the RDFS/OWL
meta-properties do not appear other than as a predicate in the
data, and RDFS/OWL meta-classes do not appear in a position other
than as the value for rdf:type; and (ii) that owl:sameAs does not
affect constants in the terminology.13

3. Annotation values

Naively conducting materialisation wrt. non-arbitrary rules
over arbitrary, non-verified data merged from millions of sources
crawled from the Web broaches many obvious dangers. In this sec-
tion, we discuss the annotation values we have chosen to represent
the various dimensions of provenance and trust we use for reasoning over Linked Data, which have been informed by our past experiences in reasoning over arbitrary Linked Data.

3.1. Blacklisting

Despite our efforts to create algorithms which automatically detect and mitigate noise in the input data, it may often be desirable
to blacklist input data based on some criteria: for example, data
from a certain domain may be considered likely to be spam, or certain triple patterns may constitute common publishing errors
which hinder the reasoning process. We currently do not require
the blacklisting function, and thus consider all triples to be not
blacklisted. However, such an annotation has obvious uses for
bypassing noise which cannot otherwise be automatically
detected.

One particular use-case we have in mind for including the
blacklisting annotation relates to the publication of void values
for inverse-functional properties: the Friend Of A Friend (FOAF)14
vocabulary offers classes and properties for describing information
about people, organisations, documents, and so forth: it is currently one of the most widely instantiated vocabularies in Linked
Data [[37] Appendix A]. FOAF includes a number of inverse-func-
tional-properties which allow for identifying (esp.) people in the
absence of agreement upon URIs, e.g.,: foaf:homepage, foaf:m-
box, foaf:mbox_sha1sum. However, FOAF exporters on the Web
commonly do not respect the inverse-functional semantics of
these properties; one particularly pathogenic case we encountered
was exporters producing empty strings or values such as mail-
to: for foaf:mbox when users omitted specifying their email.
Similarly, we encountered many corresponding erroneous values
for the foaf:mbox_sha1sum propertyrepresenting a SHA1 encoded email valuereferring to the SHA1 hashes of
mailto:
and the empty string [34]. These valuescaused by naive publishing errorslead to quadratic spurious inferences equating all users
who omitted an email to each other. Although for reasons of efficiency we currently do not support the relevant OWL 2 RL/RDF
rules which support the semantics of inverse-functional properties,
the blacklisting annotation could be used to negate the effects of
such pathogenic valuesessentially, it serves as a pragmatic last
resort.

 rules can cause incompleteness by condition
13 Note that the OWL 2 RL/RDF eq-rep-
(ii), but herein, we do not support these rules. Further, note that in other profiles
(such as RDFS and pD) axiomatic triples may be considered non-standardhowever,
none of the OWL 2 RL/RDF axiomatic triples (see Table A.1) are non-standard.
14 http://xmlns.com/foaf/0.1/

3.2. Authoritative analysis

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

In our initial works on SAOR [36]a pragmatic reasoner for
Linked Datawe encountered a puzzling deluge of inferences which
we did not initially expect. We found that remote documents sometimes cross-define terms resident in popular vocabularies, changing
the inferences authoritatively mandated for those terms. For exam-
ple, we found one document15 which defines owl:Thing to be a
member of 55 union classesthus, materialisation wrt. OWL 2 RL/
RDF rule cls-uni [[25] Table 6] over any member of owl:Thing would
infer 55 additional memberships for these obsolete and obscure union
classes. We found another document16which defines nine properties as
the domain of rdf:typeagain, anything defined to be a member of
any class would be inferred to be a member of these nine properties.
Even aside from cross-defining core terms, popular vocabularies
such as FOAF were also affected [36]such practice lead to the materialisation of an impractical bulk of arguably irrelevant data (which
would subsequently burden the consumer application).

To counter-act remote contributions about the semantics of
terms, we introduced a more conservative form of reasoning called
authoritative reasoning [36] which critically examines the source of
terminological knowledge. We now re-introduce the concept of
authoritative reasoning from [36], herein providing more detailed
formalisms and updated discussion.

Our authoritative reasoning methods are based on the intuition
that a publisher instantiating a vocabularys term (class/property)
thereby accepts the inferencing mandated by that vocabulary
and recursively referenced vocabularies for that term. Thus, once
a publisher instantiates a class or property from a vocabulary, only
that vocabulary and its references should influence what inferences are possible through that instantiation.

First, we must define the relationship between a class/property
term and a vocabulary, and give the notion of term-level authority.
We view a term as an RDF constant, and a vocabulary as a Web
document. From Section 2.2, we recall the get mapping from a
URI (a Web location) to an RDF graph it may provide by means
of a given HTTP lookup and the redirs mapping for following the
HTTP redirects of a URI. Also, let bnodes(G) denote the set of blank
nodes appearing in the RDF graph G. Now, we denote a mapping
from a source URI to the set of terms it speaks authoritatively for
as follows:17

auth :

S ! 2C
s # fc 2 Ujredirsc 14 sg [ bnodesgets

where a Web source is authoritative for URIs which dereference to
it and the blank nodes it contains; e.g., the FOAF vocabulary is
authoritative for terms in its namespace since it follows best-prac-
tices and makes its class/property URIs dereference to an RDF/XML
document defining the terms. Note that no document is authoritative for literals.

To negate the effects of non-authoritative terminological axioms on reasoning over Web data (as exemplified above), we add
an extra condition to the T-grounding of a rule: in particular, we
only require amendment to rules where both TBody(R)  ; and
ABody(R)  ;.

Authoritative T-ground rule Let varsTA(R)  V denote the set of
variables appearing in both TBody(R) and ABody(R). Now, we define
the set of authoritative rule instances for a program P, RDF graph G,
and source s as:18

15 http://lsdis.cs.uga.edu/oldham/ontology/wsag/wsag.owl
16 http://www.eiao.net/rdf/1.0
17 Even pre-dating Linked Data, dereferenceable vocabulary terms were encour-
aged; cf. http://www.w3.org/TR/2006/WD-swbp-vocab-pub-20060314/
18 Here we favour RDF graph notation as authority applies only in the context of
Linked Data (but could be trivially generalised through the auth function).

GroundTP; G; s :14 fHeadRh   ABodyRhj

R 2 P
and 9= G0

# Gs:t:h 14 mguTBodyR; G0

and if TBodyR; ^ ABodyR;

then 9= v 2 varsTAR s:t: hv 2 authsg

where authoritative rule instances are synonymous with authoritatively T-ground rules and where the notion of authoritative rule instances for a program follows naturally. The additional condition
for authoritativeness states that if a rule contains both T-atoms
and A-atoms in the body (ABody(R)  ; ^ TBody(R)  ;), then the
unifier must substitute at least one variable appearing in both
ABody(R) and TBody(R) (a variable from the set varsTA(R)) for an
authoritative term from source s (a constant from the set auth(s))
for the resulting T-ground rule to be authoritative. This implies that
the source s must speak authoritatively for at least one term that
will appear in the body of each proper T-ground rule which its terminology generates, and so cannot create new assertional rules
which could apply over arbitrary assertional data not mentioning
any of its terms. We illustrate this with an example.

Example 6. Take the T-split rule REX as before where varsTA(REX) =
{?c1} representing the set of variables in both TBody(REX) and
ABody(REX). Let IEX be the graph from source s, where now for each
substitution h, there must exist v 2 varsTA(REX) such that s speaks
authoritatively for h(v). In this case,

 s must speak authoritatively for the URI foaf:Personfor
which ?c1 is substitutedfor the T-ground rule (?x, a, foaf:A-
gent)   (?x, a, ?foaf:Person) to be authoritative,

 analogously, s must speak authoritatively for the URI foaf:A-
gentagain for which ?c1 is substitutedfor the T-ground rule
(?x, a, dc:Agent)   (?x, a, foaf:Agent) to be authoritative.

In other words, the source s serving the T-facts in IEX must be the
FOAF vocabulary for the above rules to authoritative. h

For reference, we highlight variables in varsTA(R) with boldface

in Table A.4.

(It is worth noting that for rules where ABody(R) and TBody(R)
are both non-empty, authoritative instantiation of the rule will
only consider unifiers for TBody(R) which come from one source:
however, in practice for OWL 2 RL/RDF this is not so restrictive:
although TBody(R) may contain multiple atoms, in such rules TBo-
dy(R) usually refers to an atomic axiom which requires multiple triples to representindeed, the OWL 2 Structural Specification19
enforces usage of blank-nodes and cardinalities on such constructs
to ensure that the constituent triples of the multi-triple axiom appear in one source. To take an example, for the T-atoms (?x,
owl:hasValue, ?y), (?x, owl:onProperty, ?p), we would expect
?x to be ground by a blank-node skolem and thus expect the instance to come from one graph.)

3.3. Links-based ranking

There is a long history of links-based analysis over Web data
and in particular over hypertext documentswhere links are seen
as a positive vote for the relevance or importance of a given docu-
ment. Seminal works exploiting the link structure of the Web for
ranking documents include HITS [44] and PageRank [8]. Various
approaches (e.g., [1,16,33,23,15,?]) look at incorporating linksbased analysis techniques for ranking RDF data, with various

19 http://www.w3.org/TR/2009/REC-owl2-syntax-20091027/

end-goals in mind, most commonly, prioritisation of informational
artefacts in user result-views; however, such analyses have been
applied to other use-cases, including work by Gueret et al. [28]
which uses betweenness centrality measures to identify potentially weak points in the Web of Data in terms of maintaining connectedness integrity.

Herein, we employ links-based analysis with the underlying
premise that higher ranked sources contribute more trustworthy
data: in our case, we would expect a correlation between the
(Eigenvector) centrality of a source in the graph, and the quality
of data that it provides. Inspired in particular by the work of Harth
et al. [29] on applying PageRank to RDF, we implement a two-step
process: (i) we create the graph of links between sources, and apply a standard PageRank calculation over said graph to derive
source ranks; (ii) we propagate source ranks to the triples they
contain using a simple summation aggregation. We now discuss
these two steps in more detail.

3.3.1. Creating and ranking the source graph

Creating the graph of interlinking Linked Data sources is non-
trivial, in that the notion of a hyperlink does not directly exist.
Thus, we must extract a graph sympathetic to Linked Data principles and current publishing patterns.

Recalling the Linked Data principles enumerated in Section 2.2,
according to LDP4, links should be specified simply by using external URI names in the data. These URI names should dereference to
an RDF description of themselves according to LDP2 and LDP3,
respectively. Let D: = (V, E) represent a simple directed graph
where V  S is a set of sources (vertices), and E  S 
 S is a set of
pairs of vertices (edges). Letting si,sj 2 V be two vertices, then (si,
sj) 2 E iff si
 sj and there exists some u 2 U such that redirs(u) = sj
and u appears in some triple t 2 get(si): i.e., an edge extends from
si to sj iff the RDF graph returned by si mentions a URI which redirects to sj.

Now, let E(s) denote the set of direct successors of s (outlinks),
let E; denote the set of vertices with no outlinks (dangling nodes),
and let Es denote the set of direct predecessors of s (inlinks). The
PageRank of a vertex si in the directed graph D: = (V,E) is then given
as follows [8]:

rsi :14 1  d
Vj

j  d

rs;
Vj

j  d

s;2E;

sj2Esi

rsj
Esj

where d is a damping constant (usually set to 0.85) which helps ensure convergence in the following iterative calculation, and where
the middle component splits the ranks of dangling nodes evenly
across all other nodes. Note also that the first and second components are independent of i, and constitute the minimum possible
rank of all nodes (ensures that ranks do not need to be normalised
during iterative calculation).

Now let w :14 1d

jVj represent the weight of a universal (weak link)
given by all non-dangling nodes to all other nodesdangling nodes
split their vote evenly and thus do not require a weak link; we can
use a weighted adjacency matrix M as follows to encode the graph
D: = (V,E):

8>><
>>:

mi;j :14

j  w;

Esj

jVj ;
w;

if sj; si 2 E
if sj 2 E;
otherwise

where this stochastic matrix can be thought of as a Markov chain
(dubbed the random-surfer model). The ranks of all sources can
be expressed algebraically as the principal eigenvector of M, which
in turn can be estimated using the power iteration method up until
some termination criteria (fixed number of iterations, convergence

measures, etc.) is reached. We refer the interested reader to [8] for
more detail.

3.3.2. Calculating triple ranks

Based on the rank values for the data sources, we now calculate
the ranks for individual triples. We use a simple model for ranking
triples, based on the intuition that triples appearing in highly
ranked sources should benefit from that rank, and that each additional source stating a triple should increase the rank of the tri-
ple.20 Thus, for calculating the rank of a triple t, we use the
summation of the ranks of the sources it appears in as follows:
rt :14

rst

st2fs2Sjt2getsg

4. The logical framework

In this section, we look at incorporating the above three dimensions of trust and provenancewhich we will herein refer to as
annotation propertiesinto an annotated logic programming
framework which tracks this information during reasoning, and
determines the annotations of inferences based on the annotations
of the rule and the relevant instances, where the resultant values of
the annotation properties can be viewed as denoting the strength
of a derivation. We propose and formalise a general annotation
framework, introduce some high-level tasks it enables, and discuss
issues relating to scalability in our scenario.

We begin in Section 4.1 by formalising annotation functions
which abstract the mechanisms used for annotating facts and
rules. In Section 4.2, we propose an annotated program framework
and associated semantics based on the previous work of Kifer et al.
[42] (introduced previously in Section 2.4). In Section 4.3, we introduce some high-level reasoning tasks that this framework enables;
in Section 4.4 we look at how each task scales in the general case,
and in Section 4.5 we focus on the scalability of the task required
for our use-case over our selected annotation properties. In Section
4.6, we briefly discuss some alternative semantics that one might
consider for our framework. We wrap up in Section 4.7 by introducing annotated constraint rules which allow for detecting and
labelling inconsistencies in our use-case.

4.1. Abstracting annotation functions

The first step towards a formal semantics of annotated logic
programs consists in generalising the annotations (such as black-
listing, authoritativeness, and ranking) recalled in the previous sec-
tions. The annotation domains are abstracted by an arbitrary finite
set of ordered domains D1, . . . ,Dz:

Definition 1. An annotation domain is a Cartesian product
D :14 
z
i141Di where each Di is totally ordered by a relation 6i. Each
Di has a 6i-maximal element >i. Define a partial order 6on D as the
direct product of the orderings 6i, that is h d1, . . . ,dzi 6 hd0
1, . . . ,d0
zi
if for all 1 6 i 6 z, di 6 id0
1, . . . ,d0
zi we say
that h d0

i. When hd1, . . . ,dz i < hd0

zi dominates hd1, . . . ,dz i.

1, . . . ,d0

We denote with lub(D0) and glb(D0), respectively, the least

upper bound and the greatest lower bound of a subset D0 # D.

In the examples
introduced so far, based on blacklisting,
authoritativeness, and ranking, z = 3 and D1 = {b,nb} (b=blacklisted,

20 Note that one could imagine a spamming scheme where a large number of
spurious low-ranked documents repeatedly make the same assertions to create a set
of highly-ranked triples. In future, we may revise this algorithm to take into account
some limiting function derived from PLD-level analysis.

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

nb=non-blacklisted), D2 = {na,a} (a=authoritative, na=non-authori-
tative), D3 14 R. Moreover, b 6 1 nb, na 6 2a, and x 6 3y iff x 6 y.

Now there are several kinds of annotations for the facts and

rules mentioned so far:

(i) Somelike blacklistingdepend on structural properties of
facts (e.g., e-mail addresses set to empty strings). Such
annotations can be modelled as functions f:Facts ? Di, for
some i.

(ii) Some depend only on the source context, like page ranking;
all of the facts in get(s) inherit the ranking assigned to the
source s. Such annotations can be modelled as functions
f:S ? Di, for some i.21

(iii) Somelike authoritativenessapply to profile rules, that are
sound (meta)axiomatisations of OWL 2/RDF-based seman-
tics. In this case, the quality and reliability of the rules as
such is not questioned. In fact, the ranking applies (indi-
rectly) to the T-atoms unified with the body and their
semantic consequences (i.e., to specific rule applications).
Accordingly, different rule instances are given different
rankings based on the provenance of the facts unified with
the rule body and the corresponding values of the variables.
Roughly speaking, such annotations can be modelled as
f:Rules 
 S ? Di where Rules typically corresponds to the
O2R ruleset as discussed in Section 2.6.

The first two kinds of annotation functions can be generalised by
abstract annotation functions
ai : Facts 
 S ! Di:
We assume that ai(F,s) is defined for all F 2 get(s). Furthermore we
assume without loss of generality that for some index z0 (0 6 z0 6 z),
D1; . . . ; D0

z are associated to annotation functions of this type.

Annotations of type 3 can be formalised as

ai : Rules 
 S ! 2Facts ! Di:
We assume that such ai are defined over O2R 
 get. Moreover, we
assume (without loss of generality) that Dz01; . . . ; Dz are associated to
annotation functions of this type.

Now given the annotation functions a1, . . . ,az, the correspond-

fR : hd1; . . . ; dzijR 2 GroundTO2R; get;
di :14 >i
di :14 aiR; get
The formal semantics of AnnPO2R; get will be specified in the
next section.

1 6 i 6 z0
z0 < i 6 zg :

4.2. Annotated program semantics

According to the nature of AnnPO2R; get, we define our

annotated programs as follows:

Definition 2 (Programs). A program P is a finite set of annotated
rules

21 Strictly speaking, ranking also depends also on the interlinkage occurring
between sources; these details are left implicit in our framework.

s2S

ing annotated program is:
AnnPO2R; get :14
di :14 aiF; s
di :14 >i

1 6 i 6 z0
z0 < i 6 z;g

F : hd1; . . . ; dzijF 2 gets;

H   B1; . . . ; Bm : d

m P 0

where H,B1, . . . ,Bm are logical atoms and d 2 D. When m = 0, a rule is
called a fact and denoted by H:d (omitting the arrow).

In the above definition, we abstract away the details of rule distribution across multiple sources; provenance is only reflected in rule
annotations. In this section, we need no a-priori restriction on the
set of predicates (although we may use the RDF ternary predicate
in examples).

Note that our notion of an annotated program is a specialisation
of the generalised annotated programs introduced in Section 2.4,
where our notion of an annotated rule (or fact) comprises of a classical rule (or fact) and a ground annotation value.

Now we can define the models of our programs. Following
the examples introduced in the previous sections, the semantics
of an atom A is a set of annotations, covering the possible ways
of deriving A. Roughly speaking, the annotations of A include the
minimum rankings of the facts and rule used to derive A.

Definition 3 (Interpretations). Let BP be the Herbrand base of a
program P. An interpretation is a mapping I : BP ! 2D that associates each fact F 2 BP with a set of possible annotations.
Given a ground rule R: = F   B1, . . . ,Bm:dan interpretation I
satisfies R if for all di 2 I(Bi) (1 6 i 6 m), glb({d1, . . . ,dm,d}) 2 I(F).
More generally, I satisfies a (possibly non-ground) rule R (in
symbols, I  R) iff I satisfies all of the ground rules in Ground(R).
Accordingly, I is a model of a program P (I  P) iff for all R 2 P, I  R.
Finally, we say that the fact F:d is a logical consequence of P iff for
all interpretation I, I  P implies I  F:d.

Example 7. Consider the following program, where annotations
come from our use-case domain:

A   B; C

: hb; a;0:4i
: hnb; a;0:7i
: hnb; a;0:6i
: hnb; na;1i

The atom A can be derived directly by the fact A:hb,a,0.4i or using
the rule A   B,C:hnb,na,1i and the facts B:hnb,a,0.7i and
C:hnb,a,0.6i. In each derivation, the annotation assigned to A gatherscomponent by componentthe minimal values used during
the derivation. In particular, during the second derivation, no blacklisted information is used, a non-authoritative rule is applied, and
the rank value never falls below 0.6. It is easy to see that, according
to Definition 3, both A:hb,a,0.4i and A:hnb,na,0.6i are logical consequences of P. h

The semantics in Definition 3 enjoys the same good properties as standard logic programming semantics.
In particular,
every given program P has one minimal model which contains
exactly the logical consequences of P, and can be characterised
as the least fixed point of an immediate consequence operator
TP. To see this, we need a suitable ordering over interpretations:
I  I0 iff for all F 2 BP; IF # I0F :

The partial order  induces a complete lattice in the set of all inter-

pretations. Given a set of interpretations I the least upper bound tI
and the greatest lower bound uI satisfy tIF 14
I2I IF and
uIF 14
I2I IF, for all F 2 BP. The bottom interpretation D maps
each F 2 BP to ;.
pretations such that for all facts F 2 BP:

The immediate consequence operator is a mapping over inter-

TPIF :14

F B1;...;Bm:d2GroundP

fglbfd1; . . . ; dm; dgj 8
16i6m

di 2 IBig

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

Theorem 1. For all programs P and interpretations I,

(i) I is a model of P iff TPI  I;
(ii) TP is monotone, i.e., I  I 0 implies TPI  TPI0.

Proof. (Sketch) Our framework can be regarded as a special case of
the general theory of annotated programs developed in [42]. In
that framework, our rules can be reformulated as
H : fX1; . . . ; Xm; d   B1 : X1; . . . ; Bm : Xm
where each Xi is a variable ranging over 2D and
fX1; . . . ; Xm; d :14 fglbfd1; . . . ; dm; dgjdi 2 Xi 1 6 i 6 mg :

The upper semilattice of truth values T [[42] Section 2] can be set to
the complete lattice h2D, # , [ , \ i. Then our semantics corresponds to the restricted semantics defined in [42] and our operator
TP corresponds to the operator RP which has been proven to satisfy
the two statements. h

Corollary 2. For all programs P,

(i) P has one minimal model that equals the least fixed point of TP,
(ii) for all F 2 BP, d 2 lfpTPF iff P  F:d.

lfpTP;

Another standard consequence of Theorem 1 is that lfpTP can be calculated in a bottom-up fashion, starting from the empty interpretation D and applying iteratively TP. Define the iterations of TP in the
usual way: TP " 0 :14 D; for all ordinals a, TP " a  1 :14 TPTP " a;
if a is a limit ordinal, let TP " a :14 tb<aTP " b. Now, it follows from
Theorem 1 that there exists an a such that lfpTP 14 TP " a. To ensure
that the logical consequences of P can be effectively computed, it
should also be proven that a 6 x, which is usually proven by showing
that TP is continuous. In [[42] Ex. 3], it is shown that these properties
do not hold for general annotated programseven if the program is
Datalog (i.e., terms can only be constants)because it is possible to
infer infinite sequences F:d1,F:d2, . . . ,F:di,. . . such that the sequence
of labels d1,d2,. . . converges to a limit d1, but F : d1 R RP " x. We
demonstrate this now by adapting Example 3 from [42].

Example 8. Consider a simple generalised annotated program P,
with truth values T in the interval [0,1] of real numbers, and three
rules as follows:
A : 0  
2   A : a
A : 1a
B : 1   A : 1

By the restricted semantics of generalised annotated programs,
A : 1 2 RP " x. However, since the third rule is discontinuous,
B : 1 R RP " x and so we see that RP " xlfpRP; note that
B : 1 2 RP " x  1. h

Then, in order to prove that our TP is continuous, we have to

rely on the specific properties of the function f(.) defined in (3).

Lemma 3. Let D be a z-dimensional annotation domain, P a program
and F a fact. The number of possible annotations d such that P  F:d is
bounded by j Pjz, where jPj is the cardinality of P.

i , for 1 6 i 6 z, be the set of all values occurring as
Proof. Let DP
the i-th component in some annotation in P and DP :14 
z
i141DP
i .
Clearly, for all i = 1, . . . ,z, j DP
i j6j P j, therefore the cardinality of
DP is at most jPjz. We are only left to show that the annotations
occurring in TP " a are all members of DP. Note that
if
{d1, . . . ,dm,d} # DP, then also glb{d1, . . . ,dm,d} 2 DP. Then, by a
straightforward induction on a,
if
F : d 2 TP " a, then d 2 DP. h

it follows that for all a,

In other words, since the glb function cannot introduce new
elements from the component sets of the annotation domain,
the application of TP can only create labels from the set of tuples which are combinations of existing domain elements in P;
thus the set of all labels is bounded by jPjz.

Next, in order to demonstrate that TP is continuous we must
introduce the notion of a chain of interpretations: a sequence {Ib}b6a
such that for all b < c, Ib  Ic.

Theorem 4. For all programs P, TP is continuous: that is, for all chains
I :14 fIbgb6a, TPtI 14 tfTPIjI 2 Ig.
Proof. The  inclusion is trivial. For the # inclusion, assume that
d 2 TPtIF. By definition, there exists a rule F   B1, . . . ,Bm:d0 in
Ground(P) and some d1, . . . ,dm such that d = glb(d0,d1, . . . ,dm) and
for all 1 6 j 6 m, dj 2 tIF. Therefore, for all 1 6 j 6 m there exists
a bj 6 a such that dj 2 Ibj. Let b be the maximum value of d1, . . . ,dm;
since I is a chain, dj 2 Ib(F), for all 1 6 j 6 m. Therefore, d is in
TPIbF and hence in tfTPIjI 2 IgF. h

Corollary 5. The interpretation TP " x is the least fixed point of TP,
lfpTP, and hence it is the minimal model of P.
The logical consequences of our programs satisfy another important
property.

Lemma 6. A fact F:d is a ground logical consequence of P iff for some
(finite) i < x, d 2 TP " iF.

Proof. Due to corollaries 2 and 5, P  F:d iff d 2 TP " xF. By def-
inition, TP " xF 14
i<xTP " iF, therefore P  F:d iff for some
finite i < x, d 2 TP " iF. h

In the jargon of classical logic, this means that our framework is
finitary. As an immediate consequence of this lemma, the logical
consequences of P are semidecidable. Note that for generalised
annotated programs, even if RP is continuous, it may not be
finitary.

Example 9. Consider the previous example (as borrowed from
[[42] Ex. 3]), but drop the last (discontinuous) rule:

A : 0  
A : 1a

2   A : a

This program is continuous with respect to the restricted semantics
of general annotated programs, therefore RP " x 14 lfpRP. How-
ever, although A : 1 2 RP " x, it is not finitary because for all i < x,
A : 1 R RP " i. h

Moreover, if P is Datalog, then the least fixed point of TP is

reached after a finite number of iterations:

Lemma 7.
lfpTP 14 TP " i.

If P is Datalog,

then there exists i < x such that

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

Proof. Due to corollary 2 and Lemma 3, for each F 2 BP, the set
lfpTPF is finite. Moreover, when P is Datalog, the Herbrand base
BP is finite as well. Thus, the thesis immediately follows from the
monotonicity of TP. h

It follows that the least model of Pdenoted lm(P)can be finitely represented, and that the logical consequences of P are
decidable.

4.3. Annotated reasoning tasks

Once the semantics of annotated programs has been defined, it
is possible to consider several types of high-level reasoning tasks
which, roughly speaking, refine the set of ground logical consequences according to optimality and threshold conditions.

Plain: Returns all of the ground logical consequences of P.
Formally:

plainP :14 fF : djF 2 BPand P  F : dg:

Optimal: Only the non-dominated elements of plain(P) are
returned. Intuitively, an answersay, F:h nb,nb,0.5ican be
ignored if a stronger evidence can be derived; for example
F:hnb,a, 0.6i. Formally, for all sets S of annotated rules and facts,
let:

maxS : 14 fR : d 2 SjforallR : d0 2 S; d  d0g

and define opt(P): = max(plain(P)).

Above threshold (optimal): Refines opt(P) by selecting the consequences that are above a given threshold. Formally, given a
threshold vector t 2 D, for all sets S of annotated rules and facts
let

SPt :14 fR : d 2 Sjt 6 dg
and define optt(P): = opt(P)Pt.

Above threshold (classical): Returns the ground atoms that have
some annotation above a given threshold t. Annotations are not
included in the answer. Formally, define:

abovetP :14 fF 2 BPj9d P ts:t: P  F : dg:

All tasks except plain, make it possible to optimise the input program by dropping some rules that do not contribute to the
answers. For example, opt(P) does not depend on the dominated
elements of P, which can thus be discarded:

Theorem 8. opt(P) = opt(max(P)).

Proof. Clearly, max(P) # P and both max and plain are monotonic
wrt. set inclusion. Therefore, plain(max(P)) is contained in plain(P)
and max(plain(max(P)))
i.e.,
opt(max(P)) # opt(P).

contained in max(plain(P)),

is

The assertion is vacuously true for

For the opposite inclusion, we first prove by induction on natural numbers that for all i P 0 and F 2 BP, if d 2 TP " iF, then there
exists an annotation d0 P d such that d0 2 TmaxP " iF.
d 2 TP " i  1F, with i P 0, we have that
F   B1; . . . ; Bm : d in Ground(P) and some d1, . . . ,dm:
d 14 glbfd1; . . . ; dm; dg

and for all 1 6 j 6 m, dj 2 TP " iBj. By definition of max(P), there
exists a F   B1; . . . ; Bm :
d P d. Moreover,
by induction hypothesis, for all 1 6 j 6 m, there exists a d0
j P dj
such that d0
:14 glbfd0
1; . . . ;
d0
m;

j 2 TmaxP " iBj. Thus if we set d0
dg, we have d0 P d and d0 2 TmaxP " i  1F.

i = 0. Assume that
for some rule

d in Ground(max(P)) with

Now assume that F:d 2 opt(P). In particular F:d is a logical consequence of P: therefore, by Lemma 6 and the previous statement,
we have that there exists an annotation F:d0 2 plain(max(P)) with
d 6 d0. However, since opt(max(P)) # opt(P), plain(max(P)) cannot
contain
that
and
F:d 2 opt(max(P)). h

therefore

improve

d0 = d

facts

F:d,

Similarly, if a minimal threshold is specified, then the program
can be filtered by dropping all of the rules that are not above
threshold:

Theorem 9. optt(P) = opt(PPt).

Proof. Since by definition we know that optt(P) = max(plain(P))Pt
and max(plain(P))Pt = max(plain(P)Pt),
it suffices to show that
plain(P)Pt = plain(PPt). By Lemma 6, F:d 2 plain(P)Pt implies that
for some i, d 2 TP " iF and d P t. Analogously to Theorem 8, it
can be proven by induction on natural numbers that for all i P 0
and F 2 BP, if d 2 TP " iF and d P t, then d 2 TPPt " iF. Therefore,
d 2 TPPt " iF and hence F:d 2 plain(PPt).
Again it is easy to prove by induction that if F:d 2 plain(PPt),
then d P t. Thus, since plain is monotone wrt. set inclusion and
PPt # P, plain(PPt) # plain(P). But plain(PPt) contains only annotations that dominate t, hence plain(PPt) # plain(P)Pt. h

4.4. Scalability issues: general case

We see that some of the reasoning tasks outlined above are
amenable to straightforward optimisations which allow for
pruning dominated facts and rules. However,
in our application domain programs contain typically v109 facts coming
from millions of RDF sources [36,38]. With programs of this size,
it is necessary to carefully take into account the number of facts
a task has to manipulate. In general a polynomial bound with
respect to the cardinality of P is not a sufficient evidence of
feasibility; even a quadratic exponent may be too high.
Accordinglyand as discussed in Section 2the OWL 2 RL/RDF
ruleset has been restricted to the O2R fragment where the
number of logical consequences of a program grows linearly
with the number of assertional facts [32]. In order to achieve
the same bound for our reasoning tasks over the same fragment
of OWL 2, for each F 2 BP, the number of derived consequences
F:d should be constant wrt. the cardinality of P (equivalently, the
number of different annotations associated to each proper rule
or fact should be constant wrt. jPj). In this section, we now give
a detailed assessment of the four reasoning tasks with respect to
this requirement.

From Lemma 3, we know that the cardinality of plain(P) is
bounded by jPjz; we now use an example to demonstrate that this
bound is tight.

Example 10. Consider a z-dimensional D where each component i
may assume an integer value from 1 to n. Let P be the following
propositional program consisting of all rules of the following form:

A1

Ai   Ai1

. . .

: hm1; n; . . . ; ni
: hn; . . . ; mi; . . . ; ni

1 6 m1 6 n
1 6 mi 6 n
2 6 i 6 z

where, intuitively, mi assigns all possible values to each component
i. Now, there are n facts which have every possible value for the first
annotation component and the value n for all other components.
Thereafter, for each of the remaining z  1 annotation components,
there are n annotated rules which have every possible value for the
given annotation component, and the value n for all other compo-

nents. Altogether, the cardinality of P is nz. The set of annotations
that can be derived for Az is exactly D, therefore its cardinality is
nz which grows as H(jPjz). When z P 2, the number of labels associated to Az alone exceeds
the desired linear bound on
materialisations.

To illustrate this, let us instantiate P for n = 2 and z = 3:

Here, all nine facts are considered optimal (again, we do not assume
a lexicographical order).

In the above example, the annotations associated to each atom
grow linearly with jPj. We can generalise this result and prove that
the annotations of a given atom may grow as jPjz
2 by slightly modifying the example for plain materialisation.

A1 : h1; 2; 2i; A1 : h2; 2; 2i;

A2   A1 : h2; 1; 2i; A2   A1 : h2; 2; 2i;
A3   A2 : h2; 2; 1i; A3   A2 : h2; 2; 2i:
Here, jPj = 23 = 6. By plain(P), we will get:

A1 : h1; 2; 2i; A1 : h2; 2; 2i;

A2 : h1; 1; 2i; A2 : h1; 2; 2i; A2 : h2; 1; 2i; A2 : h2; 2; 2i;
A3 : h1; 1; 1i; A3 : h1; 1; 2i; A3 : h1; 2; 1i; A3 : h1; 2; 2i;
A3 : h2; 1; 1i; A3 : h2; 1; 2i; A3 : h2; 2; 1i; A3 : h2; 2; 2i:
where A3 is associated with 23 = 8 annotations. h

Such examples naturally preclude the reasoning task plain(.) for
our scenario, making opt(.) a potentially appealing alternative.
Unfortunately, even if Theorem 8 enables some optimisation, in
general opt(P) is itself not linear wrt. jPj. This can be seen with a
simple example which uses RDF rules and two rational-valued
annotation properties:

Example 11. Consider a program containing all facts and rules of
the form:

ex : Foo; ex : spam; ex : Bar : k;

. . .

?x; rdf : k; ?y   ?y; ex : spam; ?x : hn; ni

. . .

such that n is a (constant) positive integer and 1 6 k 6 n. By increasing n, P grows as H(2n), whereas (as per the previous example)
jplain(P)j grows as H(n2), with n facts of the form (ex:Foo, ex:-
spam_k, ex:Bar) being associated with n annotations of the form
hk; 1
kithus, jplain(P)j grows quadratically with jPj. Now, for all such
ji, if h < j,
consequences relative to the same fact F : hh; 1
then 1
h and vice versa. This implies that all of the derived consequences are optimalthat is, plain(P) = opt(P). Consequently, jopt(P)j
grows quadratically with jPj, too.

hi and F : hj; 1

j < 1

To illustrate this, let us instantiate P for n = 3:

ex : Foo; ex : spam; ex : Bar : h1; 1i;

ex : Foo; ex : spam; ex : Bar : 2;

ex : Foo; ex : spam; ex : Bar : 3;

?x; rdf : 1 ; ?y   ?y; ex : spam; ?x : h3; 3i;
?x; rdf : 2 ; ?y   ?y; ex : spam; ?x : h3; 3i;
?x; rdf : 3 ; ?y   ?y; ex : spam; ?x : h3; 3i

Here, jPj = 23 = 6. Now, opt(P)or, equivalently, plain(P)will give

32 = 9 annotated facts of the form:
ex : Bar; rdf : k; ex : Foo : h1; 1i;

ex : Bar; rdf : k; ex : Foo : 2;

ex : Bar; rdf : k; ex : Foo : 3;


1 6 k 6 3


; n . . . ; ni

; n; . . . ; ni

Example 12. Assume that the dimension z is even, and that a
component may assume any value from the set of rationals in the
interval [0,n]; now, consider the program P containing all such
facts and rules:
A1 : hr1; 1
r1
Ai   Ai1 : hn; . . . ; n; r2i1; 1
r2i1
. . .
where r2i1 assigns the (2i  1)th (odd) component all possible values between 1 and n inclusive, and 1
assigns the 2ith (even) com-
r2i1
ponent all possible values between 1 and 1
n inclusive. Note that the
cardinality of P is nz
2 proper rules. Now,
given two consequences A:d1,A:d2 2 plain(P) sharing the same atom
A, there exist two distinct integers j,k 6 n, j  k and a pair of contig-
j ; . . .i and
uous components
d2 14 h. . . ; k; 1
k ; . . .i. Therefore, all of the facts in plain(P) are optimal,
and the number of annotations for Az

1 6 r1 6 n
1 6 r2i1 6 n
2 6 i 6 z

2 , containing n facts and nz2

such that d1 14 h. . . ; j; 1

To illustrate this, let us instantiate P for n = 2 and z = 6:

A1 : h1; 1; 2; 2; 2; 2i; A1 : 2; 1

A2   A1 : h2; 2; 1; 1; 2; 2i; A2   A1 : 2; 2; 2; 1
2 ; 2; 2
A3   A2 : h2; 2; 2; 2; 1; 1i; A3   A2 : 2; 2; 2; 2; 2; 1

2 ; 2; 2; 2; 2

i,i + 1 6 z

is nz
2.

2 ; 2;

A2 : h2;

A2 : h1; 1; 1; 1; 2; 2i; A2 : 1; 1; 2;

A3 : h1; 1; 1; 1; 1; 1i; A3 : 1; 1; 1; 1; 2;

2 14 6. By opt(P)or, equivalently, by plain(P)we will

2 ; 2; 2; 2; 2

2 ; 2; 2

2 ; 2; 2

2 ; 2;

2 ; 1; 1; 2;

2 ; 2;
2 ; 2;

Here, jPj 14 2
6
get:

A1 : h1; 1; 2; 2; 2; 2i; A1 : 2;

2 ; 1; 1; 2; 2i; A2 : 2;

2 ; 1; 1; 1; 1i; A3 : 2;

2 ; 1; 1i; A3 : 2;
2 ; 2;
Here, A3 is associated with 26
It is not hard to adapt this example to odd z and prove that for
all z 2 N, the number of annotations associated to an atom is in
HjPjbz
2c. Therefore, if the number of distinct atoms occurring in
the answer can grow linearly (as in the aforementioned fragment
2c1 and hence not linear for z > 1. h
O2R), then jopt(P)j is in HjPjbz

2 ; 1; 1i; A3 : 1; 1; 2;

2 14 8 optimal annotations.

A3 : h1; 1; 2;

A3 : h2;

A3 : h2;

If we further restrict our computations to the consequences
above a given threshold (i.e., optt(.)), then some improvements
may be possible (cf. Theorem 9). However it is clear that the worst
case complexity of optt(.) and opt(.) is the same (it suffices to set t
to the least element of D). Thus, neither optt(.) nor opt(.) are suitable for our use-case scenario in the general case.

The last reasoning task, abovet(P), returns atoms without anno-
tations, and hence it is less informative than the other tasks. How-
ever, it does not suffer from the performance drawbacks of the
other tasks: abovet
increase the complexity of

(.) does not

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

annotation-free reasoning because it only needs to drop the rules
whose annotation is not above t and reason classically with the
remaining rules, as formalised by the following proposition:

Theorem 10. Let lm(Pt) denote the least Herbrand model of the
(classical) program Pt. Then abovet(P) = lm(PPt).

Proof. Let C be the classical immediate consequence operator as
per Section 2.3 and define CPPt " a by analogy with TPPt " a. It is
straightforward to see by induction on natural numbers that for
all i P 0, TPPt " iF; iff F 2 CPPt " i. This means that F 2 lm(PPt)
iff TPPt " xF;, or equivalently, iff for some d, F:d 2 plain(PPt).
Moreover, as already shown in the proof of Theorem 9,
plain(PPt) = plain(P)Pt, therefore F:d 2 plain(P)Pt (for some d) iff
F 2 abovet(P). h

4.5. Scalability issues: opt and optt for our use-case

The analysis carried out so far apparently suggests that abovet is
the only practically feasible inference among the four tasks. How-
ever, the output facts are not associated with annotations in this
scheme, which may be required for many use-cases scenarios
(including our use-case for repairing inconsistencies investigated
later).

Although we have shown that opt and optt are polynomial in
the general case, our chosen Linked Data annotation domain
comprising of blacklisting, triple-rank and authoritativeness
enjoys certain properties that can be exploited to efficiently
implement both opt and optt. Such properties bound the number
of maximal labels with an expression that is constant with respect
to P and depends only on the annotation domains: the most
important property is that all Dis but one are finite (blacklisting
and authoritativeness are boolean; only triple-ranks range over
an infinite set of values). Thus, the number of maximal elements
of any finite set of annotations is bounded by a linear function
of D.

Example 13. Here we see an example of a fact with four nondominated annotations from our use-case domain.

(ex:Foo, ex:precedes, ex:Bar) :hb,na,0.4i,
(ex:Foo, ex:precedes, ex:Bar) :hb,a,0.3i,
(ex:Foo, ex:precedes, ex:Bar) :hnb,na,0.3i,
(ex:Foo, ex:precedes, ex:Bar) :hnb,a,0.2i.

Any additional annotation for this fact would either dominate or be
dominated by a current annotationin either case, the set of maximal annotations would maintain a cardinality of four. h

First, with a little abuse of notation, given D0

We now formalise and demonstrate this intuitive result. For
simplicity, we assume without further loss of generality that the finite
domains are D1, . . . ,Dz1; we make no assumption on Dz.22
# D, max(D0) is
the set the of maximal values of D0, i.e., {d; 2 D0"d0 2 D0,d  d0}.
If D1, . . .,Dz1 are finite, then for all finite D0 # D,
jDij:

Theorem 11.
jmaxD0j 6 Pz1

22 Note that for convenience, this indexing of the (in)finite domains replaces the
former indexing presented in Section 4.2 relating to how annotations are labelled
the two should be considered independent.

Proof. Clearly, there exist at most Pz1
jDij combinations of the
first z  1 components. Therefore, if jmaxD0j was greater than
jDij, there would be two annotations d1 and d2 in max(D0) that
Pz1
differ only in the last component. But in this case either d1 > d2 or
d1 < d2, and hence they cannot be both in max(D0) (a contradic-
tion). h

As a consequence,
in our reference scenario (where z = 3 and
jD1j = jD2j = 2) each atom can be associated with at most 4 different
annotations. Therefore, if the rules of P belong to a linear fragment
of OWL 2, then opt(P) grows linearly with the size of P.However, a
linear bound on the output of reasoning tasks does not imply the
same bound on the intermediate steps (e.g., the alternative framework introduced in the next subsection needs to compute also
non-maximal labels for a correct answer). Fortunately, a bottomup computation that considers only maximal annotations is possible in this framework. Let Tmax
IF :14 maxTPIF
Tmax
and define its powers Tmax

I be such that for all F 2 BP:

Lemma 12. For all ordinals a, Tmax

" a by analogy with TP " a.
" a 14 maxTP " a.

Proof. First we prove the following claim:
maxTPmaxI 14 maxTPI:
The inclusion # is trivial. For the other inclusion, assume that for
some F 2 BP, d 2 maxTPIF, this means that d 2 TPIF and
for all d0 2 TPIF, d  d0. As d 2 TPIF, there exists a rule
F   B1; . . . ; Bm : d and some annotations d1, . . . ,dm such that (i)
d 14 glbfd1; dm; dg and (ii) for all 1 6 j 6 m, dj 2 I(Bj).
2 maxI such
By definition, for all 1 6 j 6 m, there exists a dmax
that dj 6 dmax
dmax 14 glbfdmax
d 6 dmax and dmax 2 TPmaxI. However, since d is maximal wrt.

and
d 2 maxTPmaxI. This proves the claim.

. Clearly, given
m ; dg;

and TPmaxIF # TPIF,

d 6 dmax

; . . . ; dmax

then

Now the lemma follows by an easy induction based on the

claim. h
It follows from Lemma 12 that Tmax
reaches a fixpoint, although
Tmax
is not monotonic (because annotations may be only temporarily optimal and be replaced at later steps). When P is Datalog this
fixpoint is reached in a finite number of steps:

Theorem 13. If P is Datalog, then there exists i < x such that

(i) Tmax
(ii) Tmax
(iii) F:d 2 opt(P) iff d 2 Tmax

" i is a fixpoint of Tmax
" j is not a fixpoint of Tmax
" iF.

, for all 0 6 j < i;

Tmax

" k is a fixpoint as well. By definition

Proof. If P is Datalog, by Lemma 7, for some k < x, TP " k 14 lfpTP,
we will show that Tmax
Tmax
by Lemma 12, Tmax
Tmax

" k 14 maxTP " k, so we have

" k 14 maxTPmaxTP " k:

" k 14 maxTPTmax

" k;

Tmax

Tmax

However, as already shown in the proof of Lemma 12, for any I,
maxTPmaxI 14 maxTPI. Therefore,
Tmax
Finally, since TP " k is a fixpoint and reusing Lemma 12
Tmax

" k 14 maxTP " k 14 Tmax

" k 14 maxTPTP " k:

Tmax

" k:

Thus, Tmax
ists an 0 6 i 6 k such that Tmax
Tmax

" j is not a fixpoint.
Clearly, Tmax

" k 14 Tmax
(Lemma 12), we finally have

" k is a fixpoint and hence, by finite regression, there ex-
" i is a fixpoint and for all 0 6 j < i,

" i.

Since Tmax

" k 14 maxTP " k

The experiments reported in the rest of the paper belong to this
case: formally, the threshold t is hnb,a,0i = h>1,>2,?3i. Accord-
ingly, the implementation maintains a single annotation for each
derived atom, where rules and facts below the threshold can be
pruned as part of a straightforward pre-processing step.

Tmax

" i 14 maxlfpTP:

4.6. Alternative approaches

Therefore, d 2 Tmax

" i iff F:d 2 max(plain(P)) = opt(P). h

Theorem 11 ensures that at every step j, Tmax

" j associates each
derived atom to a number of annotations that is constant with respect to jPj. By Theorem 9, the bottom-up construction based on
Tmax
can be used also to compute optt(P) = opt(PPt). Informally
speaking, this means that if D1, . . . ,Dz1 are finite, then both
opt(.) and optt(.) are feasible.

Another useful property of our reference scenarios is that the
focus is on non-blacklisted and authoritative consequencesthat
is, the threshold t in optt(.) has z  1 components set to their maximum possible value. In this case, it turns out that each atom can
be associated to one optimal annotation.

Example 14. Given our threshold t: = hnb,a,0 i and the following
triples:

(ex:Foo, ex:precedes, ex:Bar) :h b,na,0.4i,
(ex:Foo, ex:precedes, ex:Bar) :h b,a,0.3i,
(ex:Foo, ex:precedes, ex:Bar) :hnb,na,0.3i,
(ex:Foo, ex:precedes, ex:Bar) :h nb,a,0.2i,
(ex:Foo, ex:precedes, ex:Bar) :h nb,a,0.6i,

we see that only the latter two triples are above the threshold, and
only the last is optimal. Similarly, any additional annotation for
this triple will either (i) be below the threshold, (ii) be optimal,
or (iii) be dominated. In any case, a maximum of one annotation
is maintained, which is non-blacklisted, authoritative, and contains
the optimal rank value. h

We now briefly formalise this result. For the sake of simplicity,
we assume without loss of generality that the threshold elements set
to the maximum value are the first z  1.

Theorem 14. Let t: = ht1, . . . ,tzi. If ti = >i for 1 6 i < z, then for all
D0 # D, jmaxD0

Ptj 6 1.

Proof. If not empty, all of the annotations in D0
Pt are of type
h>1, . . . >z1,dzi, thus max selects the one with the maximal value
of dz. h

As a consequence, each atom occurring in optt(P) is associated to
one annotation, and the same holds for the intermediate steps
PPt " j of the iterative construction of optt(P):
Tmax

Theorem 15. Assume that P is Datalog and the assumption of
PPt " i is a
Theorem 14 holds. Let i be the least index such that Tmax
fixpoint of Tmax

PPt . Then

(i) if {F:d1,F:d2} # optt(P), then d1 = d2;
(ii) if fd1; d2g # Tmax

PPt " jF (0 6 j 6 i), then d1 = d2.

j = 0,

PPt " jF (0 6 j 6 i), then d1 = d2.

Proof. We prove both the assertions by showing that for all j P 0
if fd1; d2g # Tmax
For
j > 0,
PPt " jF 14 maxTPPtTmax
PPt " j  1F, therefore both d1 and
Tmax
d2 are maximal (d1  d2 and d1  d2). But d1 and d2 differ only for
the last component z, and since 6z is a total order, then d1 = d2. h

vacuously true.

assertion is

the

For

As a side note, the discussion above shows that scalability problems may arise in the general case from the existence of a polynomial number of maximal annotations for the same atom. Then it
may be tempting to force a total order on annotations and keep
for each atom only its (unique) best annotation, in the attempt to
obtain a complexity similar to above-threshold reasoning. In our
reference scenario, for example, it might make sense to order
annotation triples lexicographically,
thereby giving maximal
importance to blacklisting (i.e. information correctness), medium
importance to authoritativeness, and minimal importance to page
ranking, so thatfor examplehnb,na,0.9i 6 hnb,a,0.8i. Then interpretations could be restricted by forcing I(F) to be always a single-
ton, containing the unique maximal annotation for F according to
the lexicographic ordering.

Unfortunately, this idea does not work well together with the
standard notion of rule satisfaction introduced before. In general,
in order to infer the correct maximal annotation associated to an
atom A it may be necessary to keep some non-maximal annota-
tion, too (therefore the analogue of Lemma 12 does not hold in
this setting). We illustrate the problem with a simple example.

Example 15. Consider for example the program:
H   B : hnb; na; 1:0i
B : hnb; na; 0:9i
B : hnb; a; 0:8i:
The best proof of H makes use of the first two rules/facts of the pro-
gram, and gives H the annotation hnb,na,0.9i, as none of these rules/
facts are blacklisted or authoritative, and the least page rank is 0.9.
However, if we could associate each atom to its best annotation
only, then B would be associated to hnb,a,0.8i, and the corresponding label for H would only be forced to be h nb,na,0.8i by the definition of rule satisfaction; therefore this semantics (in conjunction
with lexicographic orderings) does not faithfully reflect the properties of the best proof of H. h

One may consider a further alternative semantics whereby each
dimension of the annotation domain is tracked independently of
each other. However, with these semantics, if, for example, we find
an inference which is associated with the ranks 0.2 and 0.8, and the
blacklisted values nb and b, we cannot distinguish whether the
high rank was given by the derivation involving blacklisted knowl-
edge, or non-blacklisted knowledgein the general case, this
would also prescribe a more
for our
thresholding.23

semantics

liberal

Currently we do not know whether any other alternative, reasonable semantics can solve these problems, and we leave this issue as an open questionin any case, we note that this discussion
does not affect our intended use-case of deriving optt(P) for our
threshold since, as per Theorem 15, we need only consider the total
ordering given by the single dimension of triple ranks.

23 Given that we do not consider a lexicographical order, we could support these
semantics by flattening the set of annotation triples associated with each rule/fact
into a triple of sets of values, where to support the various reasoning tasks outlined
(other than plain), we would have to make straightforward amendments to our max,
opt, optt and abovet functions.

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

4.7. Constraints

In this paper, our referential use-case for annotated reasoning is
a non-trivial repair of inconsistencies in Linked Data based on the
strength of derivation for individual facts (as encoded by the annotations with which they are associated). Given that we apply rulebased reasoning, inconsistencies are axiomatised by constraints,
which are expressed as rules without heads:
  A1; . . . ; An; T1; . . . ; Tm n; m P 0

where T1, . . . ,Tm are T-atoms and A1, . . . ,An are A-atoms. As before,
let Body(R): = {A1, . . . ,An ,T1, . . . ,Tm} and let TBody(R): = {T1, . . . ,Tm}.
Example 16. Take the OWL 2 RL/RDF (meta-)constraint cax-dw:  
(?c1, owl:disjointWith, ?c2), (?x, a, ?c1), (?x, a, ?c2)

where TBody(cax  dw) is again underlined (T1). Any grounding

of this rule denotes an inconsistency. h

Classical semantics prescribes that a Herbrand model I satisfies
a constraint C iff I satisfies no instance of Body(C). Consequently, if
P is a logic program with constraints, either the least model of Ps
rules satisfies all constraints in P or P is inconsistent (in this case,
no reasoning can be carried out with P).

Annotations create an opportunity for a more flexible and reasonable use of constraints. Threshold-based reasoning tasks can
be used to ignore the consequences of constraint violations based
on low-quality or otherwise unreliable proofs. In the following,
let P: = Pr [ Pc, where Pr is a set of rules and Pc a set of constraints.

Definition 4. Let t 2 D. P is t-consistent iff abovet(Pr) satisfies all of
the constraints of Pc.
For example, if t: = hnb,a,0i and P is t-consistent, then for all constraints C 2 Pc all of the proofs of Body(C) use either blacklisted facts
or non-authoritative rules. In other words, all inconsistencies are
the consequence of ill-formed knowledge and/or ontology hijack-
ing. For exampleand as we will see in more detail in our empirical
analysis (Section 8)we find that our Web corpus is consistent for
the threshold hnb,a,0.001616 i.

This form of consistency can be equivalently characterised in
terms of the other threshold-dependent reasoning task (optt). For
all sets of annotated rules and facts S, let [S]: = {RjR:d 2 S}. Then
we have:

Proposition 16. P is t-consistent iff [optt(Pr)] satisfies all of the
constraints in Pc.

More generally, the following definitions can be adopted for measuring the strength of constraint violations:

Definition 5 (Answers). Let G: = {A1, . . . ,An} be a set of atoms and
let P: = Pr [ Pc. An answer for G (from P) is a pair hh,d i where h is a
grounding substitution and

(i) there exist d1, . . . ,dn 2 D such that Pr  Aih:di,
(ii) d = glb{d1, . . . ,dn}. The set of all answers of G from P is

denoted by AnsP(G).

Definition 6 (Annotated constraints, violation degree). Annotated
constraints are expressions C:d where C is a constraint and
d 2 D.
violation degree of C:d wrt. program P is
max{glb(d,d0jhh, d0i2 AnsP(Body(C))}.

24 The

24 Constraint annotations are produced by abstract annotation functions of type 3
(ai:Rules 
 (S ? 2Facts) ? Di), that apply to constraints with no modification to their
signature (assuming that the set Rules comprises of constraints as well).

Intuitively, violation degrees provide a way of assessing the severity
of inconsistencies by associating each constraint with the rankings
of their strongest violations.

Example 17. As per the previous example, take the OWL 2 RL/RDF
(meta-)constraint caxdw:h>1, >2, >3i, and consider the following
set of annotated facts:

(foaf:Organization, owl:disjointWith, foaf:Person):
hnb,a,0.6i,

(ex:W3C, a, foaf:Organization): hnb,a,0.4i,

(ex:W3C, a, foaf:Person): h nb,na,0.3i,

(ex:TimBL, a, foaf:Organization): hb,na,0.5i,
(ex:TimBL, a, foaf:Person): h nb,a,0.7i,

There are four answers to the constraint, given by the above

facts; viz.:


f?x=ex : W:; ?c 1=foaf : P:; ?c 2=foaf : O:g;hnb; na; 0:3i

f?x=ex : W:; ?c 1=foaf : O:; ?c 2=foaf : P:g;hnb; na; 0:3i

f?x=ex : T:; ?c 1=foaf : P:; ?c 2=foaf : O:g;hb; na; 0:5i

f?x=ex : T:; ?c 1=foaf : O:; ?c 2=foaf : P:g;hb; na; 0:5i

here abbreviating the respective CURIEs. Note that the first two
and last two answers are given by the same sets of facts. Again,
the annotations of the answers are derived from the glb function
over the respective facts.

The violation degree of cax-dw is then {hnb,na,0.3i,hb,na,0.5i}

since neither annotation dominates the other. h

The computation of violation degrees can be reduced to opt by
means of a simple program transformation. Suppose that
Pc: = {C1:d1, . . . ,Cm:dm}. Introduce a fresh propositional symbol fi
for each Ci and let
P0

:14 Pr [ ffi   BodyCi : diji 14 1; . . . ; mg:

Proposition 17. An annotation d belongs to the violation degree of
Ci:di iff fi:d 2 opt(P0).

Of course, violation degrees and thresholds can be combined by
picking up only those annotations that are above threshold. This
can be done by selecting all d such that fi:d 2 optt(P0)as such, in
our use-case we will again only be looking for violations above
our threshold t: = h>1,>2,?3i.

Another possible use of annotations in relation to constraints is
knowledge base repair. If Ci:di is violated, then the members of
Body(Ci) with the weakest proof are good candidates for deletion.
These ideas will be further elaborated in Section 8, where we
sketch a scalable method for knowledge base repair.

5. Implementation and experimental setup

Having looked in detail at the formal aspects of the annotated
program frameworkin particular aspects relating to the scalability of the different reasoning taskswe now move towards detailing our scalable implementation and empirical results. In the
following sections, we look at the design, implementation and
evaluation of (i) ranking (Section 6); (ii) annotated reasoning
(Section 7); (iii) inconsistency detection and repair using constraint rules (Section 8). Before we continue, in this section we
describe the distributed framework (see [37]) which forms the
substrate of our experiments, and then describe our experimental
Linked Data corpus.

5.1. Distribution architecture

Our methods are implemented on a shared-nothing distributed
architecture [58] over a cluster of commodity hardware. In partic-
ular, we leverage the nature of our algorithms to attempt to perform the most expensive tasks in an embarrassingly parallel
fashion, whereby there is little or no co-ordination required between machines.

The distributed framework consists of one master machine
which orchestrates the given tasks, and several slave machines
which perform parts of the task in parallel.

The master machine can instigate the following distributed

operations:

 Scatter: partition on-disk data into logical chunks given some
local split function, and send the chunks to individual slave
machines for subsequent processing;

 Run: request the parallel execution of a task by the slave
machinessuch a task either involves processing of some local
data (usually involving embarrassingly parallel execution), or
execution of the coordinate method by the slave swarm;

 Gather: gathers chunks of output data from the slave swarm and
performs some local merge function over the datathis is usually performed to create a single output file for a task, or more
usually to gather global knowledge required by all slave
machines for a future task;

 Flood: broadcast global knowledge required by all slave

machines for a future task.
The master machine is intended to disseminate input data to the
slave swarm, to provide the control logic required by the distributed task (commencing tasks, coordinating timing, ending
tasks), to gather and locally perform tasks on global knowledge
which the slave machines would otherwise have to replicate in
parallel, and to transmit globally required knowledge.
The slave machines, as well as performing tasks in parallel, can
perform the following distributed operation (on the behest of
the master machine):

 Coordinate: local data on each slave machine are partitioned
according to some split function, with the chunks sent to individual machines in parallel; each slave machine also gathers
the incoming chunks in parallel using some merge function.

The above operation allows slave machines to partition and disseminate intermediary data directly to other slave machines; the coordinate operation could be replaced by a pair of gather/scatter
operations performed by the master machine, but we wish to avoid
the channelling of all such intermediary data through one machine.
Note that herein, we assume that the input corpus is evenly distributed and split across the slave machines, and that the slave machines have roughly even specifications: i.e., we do not consider
any special form of load balancing, but instead aim to have uniform
machines processing comparable data-chunks.

5.2. Experimental setup

Table 1
Average quadruples per machine for the four different sizes of corpora and four
different distribution setups.

Corpus

1sm (total)

2sm

4sm

8sm

1,117,567,842
558,783,923
279,391,964
139,695,985

558,783,921
279,391,962
139,695,982
69,847,992

280,159,613
140,079,807
70,039,904
34,923,996

139,859,503
69,929,752
34,964,876
17,461,998

machines have roughly equal specifications in order to ensure that
tasks finish in roughly the same time, assuming even data distribution.

5.3. Experimental corpus

Later in this paper, we discuss the performance and fecundity of
applying our methods over a corpus of 1.118 b quadruples (triples
with an additional context element encoding source) derived from
an RDF/XML crawl of 3.985 m Web documents in mid-May 2010.
Of the 1.118 b quads, 1.106 b are unique, and 947 m are unique tri-
ples. The data contain 23 k unique predicates and 105 k unique class
terms (terms in the object position of an rdf:type triple). Please
see ([37] Appendix A) for further statistics relating to this corpus.

Quadruples are stored as GZip compressed flat files of
N-Quads.26 Also, all machines have a local copy of a sorted list of
redirects encountered during the crawl: i.e., ordered pairs of the
form h f,t i where redir( f) = t. The input data are unsorted, not uni-
qued, and pre-distributed over eight slave machines according to a
hash function of context; this is the direct result of our distributed
crawl, details of which are available in [37].

To evaluate our methods for varying corpus sizes, we also create
subsets of the corpus, containing one half, one quarter and one
eighth of the quadruples: to do so, we extract the appropriate subset from the head of the full corpusnote that our raw data are
naturally ordered according to when they were crawled, so smaller
subsets taken from the head emulate a smaller crawl. Also, in order
to evaluate our methods for a varying number of slave machines,
we additionally merge each of the four sizes of corpora onto one,
two and four machines by hashing on context. Thus, we have the
one eighth, one quarter, one half and all of the corpus, respectively,
split over one, two, four and eight machines; the average counts of
quadruples per machine for each configuration are listed in Table
1. Note that henceforth, we use c; c
8 to denote the full, half,
quarter and eighth corpus, respectively, and use 1sm, 2sm, 4sm and
8sm to denote one, two, four and eight slave machines (and one
master machine), respectively.

4 and c

2 ; c

Looking at how evenly the corpora are split across the ma-
chines, the average absolute deviation of quadruplesas a percentage of the meanwas 0.9%, 0.55% and 0.14% for eight, four and two
slaves, respectively, representing near-even data distribution given
by hashing on context (these figures are independent of the size of
the corpus).

Note that for our implementation, we use compressed files of
N-Triple/N-Quad type syntax for serialising arbitrary-length linedelimited tuples of RDF terms.

We instantiate the distributed architecture described in Section
5.1 using the standard Java Remote Method Invocation libraries as
a convenient means of development given our Java code-base.

All of our evaluation is based on nine machines connected by
Gigabit ethernet,25 each with uniform specifications; viz.: 2.2 GHz
Opteron x86-64, 4 GB main memory, 160 GB SATA hard-disks, running Java 1.6.0_12 on Debian 5.0.4. Again please note that much of
the performance evaluation presented herein assumes that the slave

6. Links-based analysis: implementation and evaluation

In this section, we describe and evaluate our distributed methods for applying a PageRank-inspired analysis of the data to derive
rank annotations for facts in the corpus. We begin by discussing
the high-level approach (Section 6.1), then by discussing the
distributed implementation (Section 6.2), and finally we present
evaluation for our corpus (Section 6.3).

25 We observe, e.g., a max FTP transfer rate of 38 MB/s between machines.

26 http://sw.deri.org/2008/07/n-quads/

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

6.1. High-level ranking approach

Again, our links-based analysis is inspired by the approach
presented in [29], in which the authors present and compare two
levels of granularity for deriving source-level ranks: (i) docu-
ment-level granularity analysing inter-linkage between Web
documents; and (ii) pay-level-domain (PLD) granularity analysing
inter-linkage between domains (e.g., dbpedia.org, data.gov.uk).
Document-level analysis is more expensivein particular, it generates a larger graph for analysisbut allows for more fine-grained
ranking of elements resident in different documents. PLD-level
analysis is cheaperit generates a smaller graphbut ranks are
more coarse-grained, and many elements can share identical ranks
grouped by the PLDs they appear in.

In previous work [37], we employed in-memory techniques for
applying a PageRank analysis of the PLD-granularity source graph:
we demonstrated this to be efficiently computable in our distributed setup due to the small size of the graph extracted (in partic-
ular, the PageRank calculation took <1 min in memory applying
10 iterations), and argued that PLD-level granularity was sufficient
for that particular use-case (ranking entity importance, which
combined with TF-IDF keyword search relevance forms the basis
of prioritising entity-search results). However, in this paper we
opt to apply the more expensive document-level analysis which
provides more granular results useful for repairing inconsistent
data in Section 8. Since we will deal with larger graphs, we opt
for on-disk batch-processing techniquesmainly sorts, scans, and
sort-merge joins of on-disk fileswhich are not hard-bound by
in-memory capacity, but which are significantly slower than inmemory analysis.

6.2. Distributed ranking implementation

Individual tasks are computed using parallel sorts, scans and
merge-joins over the slave machines in our cluster. For reference,
we provide the detailed description of the ranking sub-algorithms
in Appendix B, where our high-level distributed approach can be
summarised as follows:

(i) Run/gather/flood: each slave machine sorts its segment of the
data by context, with a list of sorted contexts generated on
each machine; the master machine gathers the list of con-
texts, merge-sorting a global list of contexts which is subsequently flooded to the slave machines;

(ii) Run: the slave machines extract the source-level graph in
parallel from their segment of the data (Algorithm 2),
rewrite the vertices in the sub-graph using redirects (Algo-
rithm 3), prune links in the sub-graph such that it only contains vertices in the global list of contexts (Algorithm 4), and
finally sorts the sub-graph according to inlinks and
outlinks;

(iii) Gather/flood: the master machine gathers the sub-graphs
(for both inlink and outlink order) from the slave machines
and merge-sorts to create the global source-level graph;
the master machine then performs the power iteration algorithm to derive PageRank scores for individual contexts
using on-disk sorts and scans (Algorithms 5 and 6); ranks
are subsequently flooded to each machine;

(iv) Run/coordinate: each slave machine propagates ranks of contexts to individual quadruples (merge-join over ranks and
data sorted by context); the ranked data are subsequently
sorted by subject; each slave machine splits its segment of
sorted ranked data by a hash-function (modulo slavemachine count) on the subject position, with split fragments
sent to a target slave machine; each slave machine concurrently receives and stores split fragments from its peers;

 1e+009

 1e+008

 1e+007

 1e+006

 100000

number of edges

 100000

 1e+006

Fig. 1. Distribution of quadruples per subject.

(v) Run: each slave machine merge-sorts the subject-hashed
fragments it received from its peers, summating the ranks
for triples which appear in multiple contexts while streaming the data.

The results of this process are: (a) data sorted and hashed by context on the slave machines; (b) ranks for contexts on all machines;
(c) data sorted and hashed by subject on the slave machines, with
aggregated ranks for triples. For (c), the result is simply a flat file
of sorted quintuples of the form hs,p,o,c,ri, where c denotes context
and r rank, and where ri = rj if h si,pi,oii = hsj,pj,oji.

Note that, with respect to (b), we could select a data-partition-
ing strategy which hashes on any arbitrary (but consistent) element (or combination of elements) of each triple. We hash on
the subject position since data-skew becomes a problem for other
positions [47]; in our input data we observe that:

(i) hashing on predicates would lead to poor load-balancing,
where, e.g., we observe that rdf:type appears as the predicate for 206.8 m input quadruples (18.5% of the corpus);

(ii) hashing on objects would also lead to poor load-balancing,
for

where, e.g., foaf:Person appears as the object
163.7 m input quadruples (14.6% of the corpus).

Conversely, in Fig. 1, we present the distribution of subjects with respect to the number of quadruples they appear in: although there is
an apparent power-law, we note that the most frequently occurring
subject term appeared in 252 k quadruples (0.02% of the corpus).27
Subsequent to partitioning the full corpus by hashing on subject
across the eight slave machines, we found an average absolute
deviation of 166.3 k triples from the mean (0.012% of the mean),
representing near-optimal load balancing.

We note that in [47]which argues against single-element
hashing for partitioning RDF dataalthough the authors observe
a high-frequency for common terms in a large corpus also acquired
from the Web (14% of all triples had the literal object "0"), they do
not give a positional analysis, and in our experience, none of the
highlighted problematic terms commonly appear in the subject po-
sition. If the number of machines was to increase greatly, or the
morphology of the input data meant that hashing on subject would
lead to load-balancing problems, one could consider hashing on

27 There are some irregular peaks apparent the distribution, where we encounter
unusually large numbers of subjects just above milestone counts of quadruples due
to fixed limits in exporters: for example, the hi5.com exporter only allows users to
have 2,000 values for foaf:knowse.g., see: http://api.hi5.com/rest/profile/
foaf/100614697.

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

all data
1/2 data
1/4 data
1/8 data

Table 2
On the left, we present the factors by which the ranking total runtimes changed when
doubling the data. On the right, we present the factors by which the runtimes
changed when doubling the number of slave machines.

Doubling data

Doubling slaves

sm

1sm
2sm
4sm
8sm

Mean

c= c

2 = c

4 = c

2.71 Mean

2sm/1sm

4sm/2sm

8sm/4sm

slave machines

Fig. 2. Total time taken for ranking on 1/2/4/8 slave machines for varying corpus
sizes.

the entire triple, which would almost surely offer excellent load-
balancing. Otherwise, we believe that hashing on subject is preferable given that (i) the low-level operation is cheaper, with less
string-characters to hash; and (ii) less global duplicates will be
produced by the distributed reasoning process (Section 7) during
which machines operate independently.28

6.3. Ranking evaluation

Applying distributed ranking over the full 1.118 b statement
corpus using eight slave machines and one master machine took
just under 36 h, with the bulk of time consumed as follows: (i) parallel sorting of data by context took 2.2 h; (ii) parallel extraction
and preparation of the source-level graph took 1.9 h; (iii) ranking
the source-level graph on the master machine took 26.1 h (apply-
ing ten power iterations); (iv) propagating source ranks to triples
and hashing/coordinating and sorting the data by subject took
3 h; (v) merge-sorting the data segments and aggregating the
ranks for triples took 1.2 h.

We present the high-level results of applying the ranking for
varying machines and corpus sizes (as per Table 1) in Fig. 2.29 For
the purposes of comparison, when running experiments on one slave
machine, we also include the coordinate stepsplitting and merging
the datawhich would not be necessary if running the task locally.
For reference, in Table 2 we present the factors by which the runtimes changed when doubling the size of the corpus and when doubling the number of slave machines. We note that:

(i) ranking with respect to c

than ranking over c
roughly equates to a doubling of runtime;

4 takes, on average, 2.71
 longer
8otherwise, doubling the corpus size

(ii) when doubling the number of slave machines, runtimes do
not halve: in particular, moving from four slaves to eight
slaves reduces runtime by an average of 17%, and only 7%
for the full corpus.

With respect to the first observation, we note that the PageRank calculations on the master machine took 3.8
 longer for c
4 than c
8:
although the data and the number of sources roughly double from
8 to c
4, the number of links between sources in the corpus quadru-

28 For example, using the LRU duplicate removal strategy mentioned in Section 7,
we would expect little or no duplicates to be given by rule prp-dom when applied over
a corpus hashed and sorted by subject.
29 Note that all such figures in this paper are presented log/log with base 2, such that
each major tick on the x-axis represents a doubling of slave machines, and each major
tick on the y axis represents a doubling of time.

8, 40.3 m links for c

4, 80.7 m links

pledwe observed 11.3 m links for c
for c

2, and 183 m links for c.
With respect to the second observation, we note that the local
PageRank computation on the master machine causes an increasingly severe bottleneck as the number of slave machines increases:
again, taking the full corpus, we note that this task takes 26.1 h,
irrespective of the number of slave machines available. In Fig. 3,
we depict the relative runtimes for each of the ranking tasks over
the full corpus and varying number of machines. In particular,
we see that the PageRank computation stays relatively static whilst
the runtimes of the other tasks decrease steadily: at four slave ma-
chines, the total time spent in parallel execution is already less
than the total time spent locally performing the PageRank. Otherwiseand with the exception of extracting the graph from c
4 and c

for reasons outlined abovewe see that the total runtimes for the
other (parallel) tasks roughly halve as the number of slave machines doubles.

With respect to redressing this local bottleneck, significant
improvements could already be made by distributing the underlying sorts and scans required by the PageRank analysis. Further, we
note that parallelising PageRank has been the subject of significant
research, where we could look to leverage works as presented, e.g.,
in [24,45]. We leave this issue open, subject to investigation in another scope.

Focussing on the results for the full corpus, the source-level
graph consisted of 3.985 m vertices (sources) and 183 m unique
non-reflexive links. In Table 3, we provide the top 10 ranked doc-
uments. The top result refers to the RDF namespace, followed by
the RDFS namespace, the DC namespace and the OWL namespace
(the latter three are referenced by the RDF namespace, and
amongst themselves). Subsequently, the fifth result contains some
links to multi-lingual translations of labels for RDFS terms, and is
linked to by the RDFS document; the sixth result refers to an older
version of DC (extended by result 3); the seventh result is the SKOS

(i) sort by context (slaves)
(ii) create source-level graph (slaves)
(iii) pagerank (master)
(iv) rank, sort, hash and coordinate triples (slaves)
(v) merge-sort / summate ranks (slaves)
total (slaves)
total (master)
total

slave machines

Fig. 3. Breakdown of relative ranking task times for 1/2/4/8 slave machines and full
corpus.

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

Table 3
Top 10 ranked documents.

Document

http://www.w3.org/1999/02/22-rdf-syntax-ns
http://www.w3.org/2000/01/rdf-schema
http://dublincore.org/2008/01/14/dcelements.rdf
http://www.w3.org/2002/07/owl
http://www.w3.org/2000/01/rdf-schema-more
http://dublincore.org/2008/01/14/dcterms.rdf
http://www.w3.org/2009/08/skos-reference/skos.rdf
http://www.w3.org/2003/g/data-view
http://xmlns.com/foaf/spec/
http://www.w3.org/2000/01/combined-ns-
translation.rdf.fr

Rank

vocabulary; the eighth result provides data and terms relating to
the GRDDL W3C standard; the ninth result refers to the FOAF
vocabulary; the tenth is a French translation of RDFS terms. Within
the top ten, all of the documents are primarily concerned with terminological data (e.g., are ontologies or vocabularies, or describe
classes or properties): the most wide-spread re-use of terms across
the Web of Data is on a terminological level, representing a higher
in-degree and subsequent rank for terminological documents. The
average rank annotation for the triples in the corpus was
1.39 
 105.

7. Reasoning with annotationsimplementation and
evaluation

In order to provide a scalable and distributed implementation
for annotated reasoning, we extend the SAOR system described in
[38] to support annotations. Herein, we summarise the distributed
reasoning steps, where we refer the interested reader to [38] for
more information about the (non-annotated) algorithms. We begin
by discussing the high-level approach (Section 7.1), then discuss
the distributed approach (Section 7.2), the extension to support
annotations (Section 7.3), and present evaluation (Section 7.4).

7.1. High-level reasoning approach

Given our explicit requirement for scale, in [38] we presented a
generalisation of existing scalable rule-based reasoning systems
which rely on a separation of T-Box from A-Box [36,65,63,62]:
we call this generalisation the partial-indexing approach, which
may only require indexing small subsets of the corpus, depending
on the program/ruleset. The core idea follows the discussion of the
T-split least fixpoint in Section 2.5 where our reasoning is broken
into two distinct phases: (i) T-Box level reasoning over terminological data and rules where the result is a set of T-Box inferences and
a set of T-ground rules; (ii) A-Box reasoning with respect to the set
of proper T-ground rules.

With respect to RDF(S)/OWL(2) reasoning, we assume that we
can distinguish terminological data (as presented in Section 2.5)
and that the program consists of T-split rules, with known terminological patterns. Based on the assumption that the terminological
segment of a corpus is relatively small, and that it is static with respect to reasoning over non-terminological data, we can perform
some pre-compilation with respect to the terminological data
and the given program before accessing the main corpus of assertional data.30

30 If the former assumption does not hold, then our approach is likely to be less
efficient than standard (e.g., semi-naive) approaches. If the latter assumption does not
hold (e.g., due to extension of RDF(S)/OWL terms), then our approach will be
incomplete [38].

The high-level (local) procedure is as follows:

(i) identify and separate out the terminological data (T-Box)

from the main corpus;

(ii) recursively

rules

apply

axiomatic

(Table A.1)

and
rules which do not require assertional knowledge (Table
A.2) over the T-Boxthe results are included in the
A-Box and if terminological, may be recursively included
in the T-Box, where the T-Box will thereafter remain
static;

(iii) for rules containing both T-atoms and A-atoms, ground the
T-atoms wrt. the T-Box facts, applying the (respective)
most general unifier over the remainder of the rulethe
result is the assertional program where all T-atoms are
ground;

(iv) recursively apply the T-ground program over the assertional

data.

The application of rules in Step (ii) and the grounding of T-
atoms in Step (iii) are performed by standard semi-naive evaluation over the indexed T-Box. However, in Step (iv), instead of
bulk-indexing the A-Box, we apply the rules by means of a scan.
This process is summarised in Algorithm 1.

Algorithm 1. Reason over the A-Box

for all t 2 A

 Gi1

iftd R LRU

/ fixed-size, LRU cache /

/ {t0 . . . tm} /
/triple index /

G0: = {},G1: = {t},i: = 1
while Gi
for all td 2 Gin Gi1

Require: ABOX: A
Require: ASSERTIONAL PROGRAM: AP /{R0 . . . Rn},TBody(Ri) = ; /
1. Index: = {}
2. LRU: = {}
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.

card: = jIndexj
Index: = Index [ {td}
if card  j Indexj

if $h s.t. {td} = Body(R)h
Gi+1: = Gi+1 [ Head(R)h

add td to LRU
output(td)
for all R 2 AP

if $hs.t. td 2 Body(R)h

/ remove eldest/

if jBody(R)j=1

end if

else

for all h s.t.Body(Rh) # Index ^
td 2 Body(Rh)

Gi+1: = Gi+1 [ Head(Rh)

end for

end if

end if

end if
end for

end if
end for
i++
Gi+1: = copy(Gi)

end while

21.
22.
23.
24.
25.
26.
27.
28.
29.
30.
31.
32. end for
33.

/ avoids cycles /

return output

/ on-disk inferences /

First note that duplicate inference steps may be applied for
rules with only one atom in the body (Lines 1114): one of the
main optimisations of our approach is that it minimises the
amount of data that we need to index, where we only wish to
store triples which may be necessary for later inference, and
where triples only grounding single atom rule bodies need not
be indexed. To provide partial duplicate removal, we instead
use a Least-Recently-Used (LRU) cache over a sliding window of
recently encountered triples (Lines 7 and 8)outside of this win-
dow, we may not know whether a triple has been encountered
before or not, and may repeat inferencing steps. In [38], we found
that 84% of non-filtered inferences were unique using a fixed
LRU-cache with a capacity of 50 k over data grouped by
context.31

Thus, in this partial-indexing approach, we need only index triples which are matched by a rule with a multi-atom body (Lines
1525). For indexed triples, aside from the LRU cache, we can
additionally check to see if that triple has been indexed before
(Line 19) and we can apply a semi-naive check to ensure that
we only materialise inferences which involve the current triple
(Line 20). We note that as the assertional index is required to
store more data, the two-scan approach becomes more inefficient
than the full-indexing approach; in particular, a rule with a
body atom containing all variable terms will require indexing
of all data, negating the benefits of the approach; e.g., if the rule
OWL 2 RL/RDF rule eq-rep-s:
?s0; ?p; ?o   ?s; owl : sameAs; ?s0;?s; ?p; ?o

is included in the assertional program, the entire corpus of assertional data must be indexed (in this case according to subject)
because of the latter open atom. We emphasise that our partialindexing performs well if the assertional index remains small and
performs best if every proper rule in the assertional program has
only one A-atom in the bodyin the latter case, no assertional
indexing is required.

If the original program does not contain rules with multiple A-
atoms in the bodysuch as is the case for our subset O2R of OWL
2 RL/RDF rulesno indexing of the A-Box is required (Lines 1115)
other than for the LRU cache.32

Note that, depending on the nature of the T-Box and the original
program, Step (ii) may result in a very large assertional program
containing many T-ground rules where Algorithm 1 can be seen
as a brute-force method for applying all rules to all statements.
In [38], we derived 301 k raw T-ground rules from the Web, and
estimated that brute force application of all rules to all 1 b triples
would take >19 years. We thus proposed a number of optimisations for the partial-indexing approach; we refer the interested
reader to [38] for details, but the main optimisation was to use a
linked-rule index. Rules are indexed according to their atom patterns such that, given a triple, the index can retrieve all rules containing an atom for which that triple is a ground instantiationi.e.,
the index maps triples to relevant rules. Also, the rules are linked
according to their dependencies, whereby the grounding of a head
in one rule may lead to the application of anotherin such cases,
explicit links are materialised to reduce the amount of rule-index
lookups required.

31 Note that without the cache, cycles are detected by maintaining a set of
inferences for a given input triple (cf. Algorithm 1; Line 30)the cache is to avoid
duplication, not to ensure termination.
32 In previous works we have discussed and implemented techniques for scalable
processing of rules with multiple A-atoms; however, these techniques were specific
to a given ruleset [36]as are related techniques presented in the literature [62]and
again break the linear bound on materialisation wrt. the A-Box.

7.2. Distributed reasoning

Assuming that our rules only contain zero/one A-atoms, and
that the T-Box is relatively small, distribution of the procedure is
straight-forward [38]. We summarise the approach as follows:

(i) Run/gather: identify and separate out the T-Box from the
main corpus in parallel on the slave machines, and subsequently merge the T-Box on the master machine;

(ii) Run: apply axiomatic and T-Box only rules on the master
machine, ground the T-atoms in rules with non-empty T-
body/A-body, and build the linked rule index;

(iii) Flood/run: send the linked rule index to all slave machines,
and reason over the main corpus in parallel on each
machine.

The results of this operation are: (a) data inferred through T-Box
only reasoning resident on the master machine; (b) data inferred
through A-Box level reasoning resident on the slave machines.

7.3. Extending with annotations

We now discuss extension of the classical reasoning engine
(described above) to support the annotated reasoning task optt(P)
for our annotation domain which we have shown to be theoretically scalable in Section 4. As mentioned at the end of Section 4.3,
t: = hnb,a,0i =
for our experiments we assume a threshold:
h>1,>2,?3i. Thus, our reasoning task becomes optt(P). By Theorem 8, we can filter dominated facts/rules; by Theorem 9, we
can immediately filter any facts/rules which are blacklisted/
non-authoritative. Thus, in practice, once blacklisted and nonauthoritative facts/rules have been removed from the program,
we need only maintain ranking annotations.

Again, currently, we do not use the blacklisting annotation. In
any case, assuming a threshold for non-blacklisted annotations,
blacklisted rules/facts in the program could simply be filtered in
a pre-processing step.

For the purposes of the authoritativeness annotation, the
authority of individual terms in ground T-atoms are computed during the T-Box extraction phase by the slave machines using redirects information from the crawl. This intermediary term-level
authority is then used by the master machine to annotate T-ground
rules with the final authoritative annotation. Recall that all initial
ground facts and proper rules O2R are annotated as authoritative,
and that only T-ground rules with non-empty ABody can be annotated as na, and subsequently that ground atoms can only be annotated with na if produced by such a non-authoritative rule; thus,
wrt. our threshold t, we can filter any T-ground rules annotated
na when first created on the master machinethereafter, only a
annotations can be encountered.

Thus, we are left to consider rank annotations. In fact, following
the discussion of Section 4.3 and the aforementioned thresholding,
the extension is fairly straightforward. All axiomatic triples (man-
dated by OWL 2 RL/RDF), and all initial (meta-)rules are annotated
with > (the value 1). All other ground facts in the corpus are preassigned a rank annotation by the links-based ranking procedure.
The first step involves extracting and reasoning over the rankannotated T-Box. Terminological data are extracted in parallel on
the slave machines from the ranked corpus. These data are gathered onto the master machine. Ranked axiomatic and terminological facts are used for annotated T-Box level reasoning: internally,
we store annotations using a map (alongside the triple store itself),
and the semi-naive evaluation only considers unique or non-dom-
inated annotated facts in the delta. Inferred annotations are computed using the glb function as described in Definition 3.

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

Next, rules with non-empty ABody are T-ground. If TBody is not
empty, the T-ground rule annotation is again given by the glb
aggregation of the T-ground instance annotations; otherwise, the
annotation remains >. These annotated rules are flooded by the
master machine to all slave machines, who then begin the A-Box
reasoning procedure.

Since our T-ground rules now only contain a single A-atom, during A-Box reasoning, the glb function takes the annotation of the
instance of the A-atom and the annotation of the T-ground rule
to produce the inferred annotation. For the purposes of duplicate
removal, our LRU cache again considers facts with dominated
annotations as duplicate.

Finally, since our A-Box reasoning procedure is not semi-naive
and can only perform partial duplicate detection, we may have
duplicates or dominated facts in the output. To ensure optimal outputand thus achieve optt(P)we must finally:

(iv) Coordinate inferred data on the slave machines by sorting
and hashing on subject; also include the T-Box reasoning
results resident on the master machine;

(v) Run an on-disk merge-sort of ranked input and inferred segments on all slave machines, filtering dominated data and
streaming the final output.

7.4. Reasoning evaluation

In total, applying the distributed reasoning procedure with
eight slave machines and one master machine over the full
1.118 b quadruple corpusincluding aggregation of the final resultstook 14.6 h. The bulk of time was consumed as follows: (i)
extracting the T-Box in parallel and gathering the data onto the
master machine took 53 min; (ii) locally reasoning over the T-
Box and grounding the T-atoms of the rules with non-empty ABody
took 16 min; (iii) parallel reasoning over the A-Box took 6 h; (iv)
sorting and coordinating the inferred data by subject over the slave
machines took 4.6 h; (v) merge-sorting the inferred and input data
and aggregating the rank annotations for all triples to produce the
final optimal output (above the given threshold) took 2.7 h. Just
over half the total time is spent in the final aggregation of the
optimal reasoning output. In Fig. 4, we overlay the input/output
performance of each slave machine during the A-Box reasoning
scannotably, the profile of each machine is very similar.

In Fig. 5, we present the high-level results of applying distributed reasoning for varying corpus sizes and number of slave

input
output (raw)

 3e+008

 2.5e+008

 2e+008

 1.5e+008

 1e+008

 5e+007

time elapsed in minutes

Fig. 4. Input/output throughput during distributed A-Box reasoning overlaid for
each slave machine.

all data
1/2 data
1/4 data
1/8 data

slave machines

Fig. 5. Total time taken for reasoning on 1/2/4/8 slave machines for varying corpus
sizes.

machines (as per Table 1). For reference, in Table 4 we present
the factors by which the runtimes changed when doubling the size
of the corpus and when doubling the number of slave machines.
We note that:

 although doubling the amount of data from c

runtimes to (on average) roughly double, moving from c
2 to c cause runtimes to increase by (on average) 2.2
;
and c

 when doubling the number of slave machines from 1sm to 2sm,
runtimes only decrease by (on average) a factor of 0.6
; for to
2sm and 2sm to 1sm, the factor falls to 0.55
 and stays steady.

8 to c

4 causes the
4 to c

2, c

4 and c

With respect to the first observation, we note that as the size of the
corpus increases, so too does the amount of terminological data,
leading to an increasingly large assertional program. We found
2.04, 1.93, 1.71 and 1.533 m T-Box statements in the c, c
8 cor-
pora, respectively, creating 291, 274, 230 and 199 k assertional
rules, respectively. Here, we note that the rate of growth of the terminological data slows down as the corpus sizes gets larger (i.e., the
crawl gets further), perhaps since vocabularies on the Web of Data
are well interlinked (cf. Table 3) and will be discovered earlier in the
crawl. Furtherand perhaps relatedlywe note that the total
amount of inferences and the final aggregated output of the annotated reasoning process grows at a rate of between 2.14
 and
2.22
 when the corpus is doubled in size: we observed 1889,
857, 385 and 180 m aggregated (optimal) output facts for the c,

2 ; c

4 and c
With respect to the second observation, in Fig. 6, we give the
breakdown of the runtimes for the individual tasks when applied
over the full corpus using one, two, four and eight slave machines.
We note that the percentage of total runtime spent on the master

8 corpora, respectively.

Table 4
On the left, we present the factors by which the annotated reasoning total runtimes
changed when doubling the data. On the right, we present the factors by which the
runtimes changed when doubling the number of slave machines.

Doubling data

Doubling slaves

sm

1sm
2sm
4sm
8sm

Mean

c= c

2 = c

4 = c

Mean

2sm/1sm

4sm/2sm

8sm/4sm

(i) extract T-Box (slaves)
(ii) T-Box reasoning (master)
(iii) A-Box reasoning (slaves)
(iv) hash/sort/coordinate (slaves)
(v) merge-sort/filter dominated (slaves)
total (slaves)
total (master)
total

slave machines

Fig. 6. Breakdown of relative reasoning task times for 1/2/4/8 slave machines and
full corpus.

machine is between 0.5% for 1sm and 3.4% for 8sm (19.2 min); we
observe that for our full corpus, the number of machines can be
doubled approximately a further five times (256 machines) before the processing on the master machine takes >50% of the run-
time. Although the time taken for extracting the T-Box roughly
halves every time the number of slaves doubles, we note that the
runtimes for inferencing, sorting, hashing and merging do not: in
particular, when moving from 1sm to 2sm, we note that A-Box reasoning takes 37% less time; hashing, sorting and scattering the
inferences takes 26% less time; and merge-sorting and removing
dominated facts takes 43% less time. We attribute this to the additional duplicates created when inferencing over more machines:
reasoning over the A-Box of the full corpus generates 1.349,
1.901, 2.179 and 2.323 b raw inferences for 1sm, 2sm, 4sm and
8sm, respectively. Note that we use a fixed-size LRU cache of 50 k
for removing duplicate/dominated facts, and since our data are
sorted by subject, we would not only expect duplicate inferences
for each common subject group, but also for data grouped together
under the same namespace, where having all of the data on fewer
machines increases the potential for avoiding duplicates. Thus,
when increasing the number of machines, there are more data to
post-process (although the results of that post-processing are the
same), but we would expect this effect to converge as the number
of machines continues to increase (as perhaps evidenced by Fig. 6
where runtimes almost halve for doubling from 2sm to 4sm and
from 4sm to 8sm).

For the full corpus, a total of 1.1 m (0.1%) input T-Box triples
were extracted, where T-Box level reasoning produced an additional 2.579 m statements. The average rank annotation of the input T-facts was 9.94 
 104, whereas the average rank annotation
of the reasoned T-facts was 3.67 
 105. Next, 291 k T-ground rules
were produced for subsequent application over the A-Box, within
which, 1.655 m dependency links were materialised.

Next, in order to demonstrate the effects of authoritative reasoning wrt. our rules and corpus, we applied reasoning over the
top ten asserted classes and properties.33 For each class c, we performed reasoningwrt. the T-ground program and the authoritatively T-ground programover a single assertion of the form
(x, rdf: type, c) where x is an arbitrary unique name; for each
property P, we performed the same over a single assertion of the
form (x1, p, x2). Subsequently, we only count inferences mentioning

Table 5
Breakdown of non-authoritative and authoritative inferences for foaf:Person, with
number of appearances as a value for rdf:type in the raw data.

Class

Authoritative
foaf:Agent
wgs84:SpatialThing
contact:Person
dct:Agent
contact:SocialEntity

Non-Authoritative (additional)
po:Person
wn:Person
aifb:Kategorie-3AAIFB
b2r2008:Controlled_vocabularies
foaf:Friend_of_a_friend
frbr:Person
frbr:ResponsibleEntity
pres:Person
po:Category
sc:Agent_Generic
sc:Person
wn:Agent-3

(Raw) Count

8,165,989

an individual name xe.g., we would not count (foaf: Person,
owl: same As, foaf:Person). Table 6 gives the results (cf. older results in [36]). Notably, the non-authoritative inference sizes are on
average 55.46
 larger than the authoritative equivalent. Much of
this is attributable to noise in and around core RDF(S)/OWL terms;34
thus, in the table we also provide results for the core top-level concepts (rdfs:Resource and owl:Thing) and rdf:type, and provide
equivalent counts for inferences not relating to these conceptsstill,
for these popular terms, non-authoritative inferencing creates
12.74
 more inferences than the authoritative equivalent.

We now compare authoritative and non-authoritative inferencing in more depth for the most popular class in our input data:
foaf:Person. Excluding the top-level concepts rdfs:Resource
and owl:Thing, and the inferences possible therefrom, each
rdf:type triple with foaf:Person as value leads to five authoritative inferences and twenty-six additional non-authoritative inferences (all class memberships). Of the latter 26, 14 are anonymous
classes. Table 5 enumerates the five authoritatively-inferred class
memberships and the remaining twelve non-authoritatively inferred named class memberships; also given are the occurrences
of the class as a value for rdf:type in the raw data. Although
we cannot claim that all of the additional classes inferred nonauthoritatively are noisealthough classes such as b2r2008:Con-
trolled_vocabularies appear to bewe can see that they are
infrequently used and arguably obscure. Although some of the
inferences we omit may of course be serendipitouse.g., perhaps
po:Personagain we currently cannot distinguish such cases
from noise or blatant spam.

owl:sameAs,

Overall, performing A-Box reasoning over the full corpus using
all eight slave machines produced 2.323 b raw (authoritative)
inferences, which were immediately filtered down to 1.879 b inferences (80.9%) by removing non-RDF and tautological triples (reflex-
ive
rdf:type
rdfs:Resource statements which hold for every ground term in
the graph which are not useful in our use-case SWSE). Of the
1.879 b inferences, 1.866 b (99.34%) inherited their annotation
from an assertional fact (as opposed to a T-ground rule), seemingly
since terminological facts are generally more highly ranked by our

rdf:type

owl:Thing,

33 We performed a count of the occurrences of each term as a value for rdf:type
(class membership) or predicate position (property membership) in the quadruples of
our input corpus.

34 We note that much of the noise is attributate to the opencalais.com domain; cf.
http://d.opencalais.com/1/type/em/r/PersonAttributes.rdf and http://
groups.google.com/group/pedantic-web/browse_thread/thread/
5e5bd42a9226a419

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

approach than assertional facts. Notably, the LRU cache detected
and filtered a total of 12.036 b duplicate/dominated statements.

After hashing on subject, for each slave machine, the average
absolute deviation from the mean was 203.9 k triples (0.08% of
the mean) representing near-optimal data distribution. In the final
aggregation of rank annotations, from a total of 2.987 b raw state-
ments, 1.889 b (63.2%) unique and optimal triples were extracted;
of the filtered, 1.008 b (33.7%) were duplicates with the same
annotation,35 89 m were (properly) dominated reasoned triples
(2.9%), and 1.5 m (0.05%) were (properly) dominated asserted triples.
The final average rank annotation for the aggregated triples was
5.29 
 107.

8. Use-case: Repairing inconsistenciesapproach,
implementation and evaluation

In this section, we discuss our approach and implementation for
handling inconsistencies in the annotated corpus (including asserted and reasoned data). We begin by formally sketching the repair process applied (Section 8.1). Thereafter, we describe our
distributed implementation for detecting and extracting sets of
annotated facts which together constitute an inconsistency
(Section 8.2) and present the results of applying this process over
our Linked Data evaulation corpus (Section 8.3). We then present
our distributed implementation of the inconsistency repair process
(Section 8.4) and the results for our corpus (Section 8.5).

8.1. Repairing inconsistencies: formal approach

Given a (potentially large) set of annotated constraint viola-
tions, herein we sketch an approach for repairing the corpus from
which they were derived, such that the result of the repair is a consistent corpus as defined in Section 4.7.36 In particular, we re-use
notions from the seminal work of Reiter [55] on diagnosing faulty
systems.

For the momentand unlike loosely related works on debugging unsatisfiable concepts in OWL terminologieswe only consider repair of assertional data: all of our constraints involve
some assertional data, and for the moment, we consider terminological data as correct. Although this entails the possibility of
removing atoms above the degree of a particular violation to repair
that violation, in Section 7.4 we showed that for our corpus, 99.34%
of inferred annotations are derived from an assertional fact.37 Thus,
as an approximation, we can reduce our repair to being wrt. the T-
ground program P: = Pc [ Pr, where Pc is the set of (proper) T-ground
constraint rules, and Pr is the set of proper T-ground positive rules
derived in Section 7. Again, given that each of our constraints requires assertional knowledgei.e., that the T-ground program P only
contains proper constraint rulesP is necessarily consistent.

Moving forward, we introduce some necessary definitions

adapted from [55] for our scenario. First, we give:

The Principle of Parsimony: A diagnosis is a conjecture that

some minimal set of components are faulty [55].

This captures our aim to find a non-trivial (minimal) set of
assertional facts which diagnose the inconsistency of our model.
Next, we define a conflict set which denotes a set of inconsistent

facts, and give a minimal conflict set which denotes the least set
of facts which preserves an inconsistency wrt. a given program P:

Definition 7 (Conflict set). A conflict set is a Herbrand interpretation C: = {F1, . . . , Fn} such that P [ C is inconsistent.

Definition 8 (Minimal conflict set). A minimal conflict set is a Herbrand interpretation C: = {F1, . . . ,Fn} such that P [ C is inconsistent,
and for every C0  C, P [ C0 is consistent.
Next, we define the notions of a hitting set and a minimal hitting set
as follows:

Definition 9 (Hitting set). Let I :14 fI1; . . . ; Ing be a set of Herbrand
interpretations, and H: = {F1, . . . ,Fn} be a single Herbrand interpre-
tation. Then, H is a hitting set for I iff for every Ij 2 I, H \ Ij

 ;.

Definition 10 (Minimal hitting set). A minimal hitting set for I is a
hitting set H for I such that for every H0  H, H0 is not a hitting set
for I.

Given a set of minimal conflict sets C, the set of corresponding minimal hitting sets H represents a set of diagnoses thereof [55]; selecting one such minimal hitting set and removing all of its members
from each set in C would resolve the inconsistency for each conflict
set C 2 C [55].

This leaves three open questions: (i) how to compute the minimal conflict sets for our reasoned corpus; (ii) how to compute and
select an appropriate hitting set as the diagnosis of our inconsistent corpus; (iii) how to repair our corpus wrt. the selected
diagnosis.

8.1.1. Computing the (extended) minimal conflict sets

In order to compute the set of minimal conflict sets, we leverage the fact that the program Pr does not contain rules with multiple A-atoms in the body. We leave extension of the repair process
for programs with multiple A-atoms in the body for another
scope.

First, we must consider the fact that our corpus C already represents the least model of C [ Pr and define an extended minimal
conflict set as follows:

Definition 11 (Extended minimal conflict set). Let C be a Herbrand
model such that C: = lm(C [ Pr), and let C: = {F1, . . . ,Fn},C # C
denote a minimal conflict set for C. Let
EF :14 fF0 2 CjF 2 lmPr [ fF0gg
be the set of all facts in C from which some F can be derived
wrt. the linear program Pr (note F 2 E(F)). We define the extended
minimal conflict set (EMCS) for C wrt. C and Pr as E :14 fEFjF 2 Cg.
Thus, given a minimal conflict set, the extended minimal conflict set
encodes choices of sets of facts that must be removed from the corpus C to repair the violation, such that the original seed fact cannot
subsequently be re-derived by running the program Pr over the reduced corpus. The concept of a (minimal) hitting set for a collection
of EMCSs follows naturally and similarly represents a diagnosis for
the corpus C.

35 Note that this would include the 171 million duplicate asserted triples from the
input.
36 Note that a more detailed treatment of repairing inconsistencies on the Web is
currently out of scope, and would deserve a more dedicated analysis in future work.
Herein, our aim is to sketch one particular approach feasible in our scenario.
37 Note also that since our T-Box is also part of our A-Box, we may defeat facts which
are terminological, but only based on inferences possible through their assertional
interpretation.

8.1.2. Preferential strategies for annotated diagnoses

Before we continue, we discuss two competing models for
deciding an appropriate diagnosis for subsequent reparation of
the annotated corpus. Consider a set of violations that could be
solved by means of removing one strong facte.g., a single fact
associated with a highly-ranked documentor removing many
weak factse.g., a set of
facts derived from a number of

Table 6
Summary of authoritative inferences vs. non-authoritative inferences for core properties, classes, and top-ten most frequently asserted classes and properties: given are the
number of asserted memberships of the term n, the number of unique inferences (which mention an individual name) possible for an arbitrary membership assertion of that
term wrt. the authoritative T-ground program (a), the product of the number of assertions for the term and authoritative inferences possible for a single assertion (n  a),
respectively, the same statistics excluding inferences involving top-level concepts (a/na), statistics for non-authoritative inferencing (na/nna) and also non-authoritative
inferences minus inferences through a top-level concept (na/nna).

n a

a

n a

na

n  na

na

nna

Term
Core classes (top-level concepts)
rdfs:Resource
owl:Thing

Core property
rdf:type

Top ten asserted classes
foaf:Person
foaf:Agent
skos:Concept
mo:MusicArtist
foaf:PersonalProfileDocument
foaf:OnlineAccount
foaf:Image
opiumfield:Neighbour
geonames:Feature
foaf:Document

206,799,100

163,699,161
8,165,989
4,402,201
4,050,837
2,029,533
1,985,390
1,951,773
1,920,992

206,799,100

982,194,966
16,331,978
22,011,005
4,050,837
4,059,066
3,970,780
1,951,773
1,920,992
1,967,600

2,359,169,596

59,641,540
50,960,935
80,488,024
76,183,296

3,873,126,401

1,307,556
74,067,680

22,541,101,900

818,495,805
8,165,989
13,206,603

2,029,533
1,985,390

2,022,145,368

11,928,308
20,384,374
50,305,015
47,614,560

22,917,882,540
1,004,416,647
506,253,115
534,710,484
231,366,762
218,392,900
214,695,030
209,388,128
109,201,800
84,229,409

43,590,784,704
48,025,952,490

3,256,659,094
2,636,156,068
2,609,199,872
3,118,910,930
4,047,237,600

5,074,673,991
114,323,846
26,413,206
93,169,251
10,147,665
1,985,390
1,951,773

1,967,600
2,981,572

11,290,311,638

44,208,042
35,784,924
387,303,106
925,612,276
1,971,242,784

2,997,244,745

155,931,914,709

19,982,077,064

Top ten asserted properties (after rdf:type)
rdfs:seeAlso
foaf:knows
foaf:nick
bio2rdf:linkedToFrom
lld:pubmed
rdfs:label
owl:sameAs
foaf:name
foaf:weblog
foaf:homepage

199,957,728
168,512,114
163,318,560
31,100,922
18,776,328
14,736,014
11,928,308
10,192,187
10,061,003
9,522,912

Total

1,035,531,872

low-ranked documents: should one remove the strong fact or the
set of weak facts? Given that the answer is non-trivial, we
identify two particular means of deciding a suitable diagnosis:
i.e., the characteristics of an appropriate minimal hitting set
wrt. to our annotations. Given any such strategy, selecting the
most appropriate diagnosis
then becomes an optimisation
problem.

Strategy 1: we prefer a diagnosis which minimises the number
of facts to be removed in the repair. This can be applied independently of the annotation framework. However, this diagnosis strategy will often lead to trivial decisions between elements of a
minimal conflicting set with the same cardinality; also, we deem
this strategy to be vulnerable to spamming such that a malicious
low-ranked document may publish a number of facts which conflict and defeat a fact in a high-ranked document. Besides spam-
ming,
it may also trivially favour, e.g.,
memberships of classes which are part of a deep class hierarchy
(the memberships of the super-classes would also need to be
removed).

in our repair process,

Strategy 2: we prefer a diagnosis which minimises the strongest annotation to be removed in the repair. This has the benefit
of exploiting the information in the annotations, and being computable with the glb/lub functions defined in our annotation
framework; however, for general annotations in the domain D
only a partial-ordering is defined, and so there may not be an
unambiguous strongest/weakest annotationin our case, with
our pre-defined threshold removing blacklisted and non-authori-
tative inferences from the corpus, we need only consider rank
annotations for which a total-ordering is present. Also, this diagnosis strategy may often lead to trivial decisions between
elements of a minimal conflicting set with identical annotationsmost likely facts from the same document which we have

seen to be a common occurrence in our constraint violations
(54.1% of the total raw cax-dw violations we empirically observe).
Strategy 3: we prefer a diagnosis which minimises the total sum
of the rank annotation involved in the diagnosis. This, of course, is
domain-specific and also falls outside of the general annotation
framework, but will likely lead to less trivial decisions between
equally strong diagnoses. In the naive case, this strategy is also
vulnerable to spamming techniques, where one weak document
can make a large set of weak assertions which culminate to defeat
a strong fact in a more trustworthy source.

In practice, we favour Strategy 2 as exploiting the additional
information of the annotations and being less vulnerable to spam-
ming; when Strategy 2 is inconclusive, we resort to Strategy 3 as a
more granular method of preference, and thereafter if necessary to
Strategy 1. If all preference orderings are inconclusive, we then select an arbitrary syntactic ordering.

Going forward, we formalise a total ordering 6I over a pair of
(annotated) Herbrand interpretations which denotes some ordering of preference of diagnoses based on the strength of a set of
factsa stronger set of facts denotes a higher order. The particular
instantiation of this ordering depends on the repair strategy cho-
sen, which may in turn depend on the specific domain of
annotation.

Towards giving our notion of 6I, let I1 and I2 be two Herbrand
interpretations with annotations from the domain D, and let 6D
denote the partial-ordering defined for D. Starting with Strategy
2slightly abusing notationif lub{I1} < Dlub{I1}, then I1 < r I2; if lu-
b{I1} > Dlub{I2}, then I1 > II2; otherwise (if lub{I1} = D lub{I2} or 6D is
undefined for I1,I2), we resort to Strategy 3 to order I1 and I2: we apply a domain-specific summation of annotations (ranks) denoted
RD and define the order of I1, I2 such that if RD{I1} < DRD{I2}, then I1
< II2, and so forth. If still equals (or uncomparable), we use the

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

cardinality of the sets, and thereafter consider an arbitrary syntactic order. Thus, sets are given in ascending order of their single
strongest fact, followed by the order of their rank summation, followed by their cardinality (Strategy 1), followed by an arbitrary
syntactic ordering. Given <I, the functions maxI and minI follow
naturally.

8.1.3. Computing and selecting an appropriate diagnosis

Given that in our Linked Data scenario, we may encounter many
non-trivial (extended) conflict setsi.e., conflict sets with cardinality greater than onewe would wisely wish to avoid materialising
an exponential number of all possible hitting sets. Similarly, we
wish to avoid expensive optimisation techniques [59] for deriving
the minimal diagnosis w.r.t 6 I. Instead, we use a heuristic to
materialise one hitting set which gives us an appropriate, but possibly sub-optimal diagnosis. Our diagnosis is again a flat set of
facts, which we denote by D.

First, to our diagnosis we immediately add the union of all
members of singleton (trivial) EMCSs, where these are necessarily
part of any diagnosis. This would include, for example, all facts
which must be removed from the corpus to ensure that no violation of dt-not-type can remain or be re-derived in the corpus.

For the non-trivial EMCSs, we first define an ordering of conflict
sets based on the annotations of its members, and then cumulatively derive a diagnosis by means of a descending iteration of
the ordered sets For the ordered iteration of the EMCS collection,
we must define a total ordering 6E over E which directly corresponds to minI(E1) 6 IminI(E2)a comparison of the weakest set
in both.

We can then apply the following diagnosis strategy: iterate over

E in descending order wrt. 6E, such that for each E:
if 9= I 2 E such that I # D then D :14 D [ minIE
where after completing the iteration, the resulting D represents our
diagnosis. Note of course that D may not be optimal according to
our strategy, but we leave further optimisation techniques to future
work.

8.1.4. Repairing the corpus

Removing the diagnosis D from the corpus C will lead to consistency in P [ (CnD). However, we also wish to remove the facts that
are inferable through D with respect to P, which we denote as D+.
We also want to identify facts in D+ which have alternative derivations from the non-diagnosed input data (CrawnD), and include
them in the repaired output, possibly with a weaker annotation:
we denote this set of re-derived facts as D. Again, we sketch a
scan-based approach which is contingent on P only containing proper
rules with one atom in the body, as is the case for any assertional program derived from O2R.

First, we determine the set of statements inferable from the

diagnosis, given as:
:14 lmP [ D n D:

Second, we scan the raw input corpus Craw as follows. First, let
D: = {}. Let
Craw :14 fF : d 2 Crawj9= d0F : d0 2 Dg
denote the set of annotated facts in the raw input corpus not
appearing in the diagnosis. Then, scanning the raw input (ranked)
data, for each Fi 2 Craw, let
d

: d0 2 lmP [ fFi : digj9dxF0

: dx 2 D; 9= dy P d0F0

: dy

:14 fF0
2 Dg

:14 maxD

D
tions. After scanning all raw input facts, the final result is D:

i , maintaining the dominant set of rederiva-

i1 [ d

D 14 maxfF : d 2 lmP [ Crawj9= d0F : d0 2 Dg

the dominant rederivations of facts in D+ from the non-diagnosed
facts of the input corpus.

Finally, we scan the entire corpus C and buffer any facts not in
D [ D+nD to the final output, and if necessary, weaken the annotations of facts to align with D.

We note that if there are terminological facts in D, the T-Box
inferences possible through these facts may remain in the final
corpus, even though the corpus is consistent. However, such
cases are rare in practice. For a T-Box statement to be defeated
in our repair,
it would have to cause an inconsistency in a
punned A-Box sense: that is to say, a core RDFS or OWL
meta-class or property would have to be involved in an ax-
iome.g., a disjointness constraintwhich could lead to inconsis-
tency. However, such constraints are not authoritatively specified
for core RDFS or OWL terms, and so cannot be encountered in
our approach. One possible case which can occur is a T-Box
statement containing an ill-typed literal, but we did not encounter such a case for our corpus and selected ruleset. If required,
removal of all such T-Box inferences would instead require
rerunning the entire reasoning process over CrawnDthe repaired
raw corpus.38

8.2. Inconsistency detection: implementation

We now begin discussing our implementation and evaluation
of
this repair process, beginning in this section with the
distributed implementation of inconsistency detection for our
scenario.

In Table A.6, we provide the list of OWL 2 RL/RDF constraint
rules which we use to detect inconsistencies. The observant reader
will note that these rules require A-Box joins (have multiple A-
atoms) which we have thus far avoided in our approach. However,
up to a point, we can leverage a similar algorithm to that presented
in Section 7.1 for reasoning.

First, we note that the rules are by their nature not recursive
(have empty heads). Second, we postulate that many of the ungrounded atoms will have a high selectivity (have a low number
of ground instances in the knowledge-base)in particular, for the
moment we partially assume that only one atom in each constraint rule has a low selectivity. When this assumption holds,
the rules are amenable to computation using the partial-indexing
approach: any atoms with high selectivity are ground in-memory
to create a set of (partially) grounded rules, which are subsequently flooded across all machines. Since the initial rules are
not recursive, the set of (partially) grounded rules remains static.
Assuming that at most one pattern has low selectivity, we can
efficiently apply our single-atom rules in a distributed scan as
per the previous section.

However, the second assumption may not always hold: a constraint rule may contain more than one low-selectivity atom. In
this case, we manually apply a distributed on-disk merge-join
operation to ground the remaining atoms of such rules.

Note that during the T-Box extraction in the previous section,
we additionally extract the T-atoms for the constraint rules, and
apply authoritative analysis analogouslywe briefly give an
example.

denote the intersection of facts derivable from both Fi and D+ which
are not dominated by a previous
rederivation; we apply

38 We note that other heuristics would be feasible, such as pre-validating the T-
Box for the possibility of inconsistency, but leave such techniques as an open question.

Example 18. Again take cax-dw as follows: (?c1, owl:disjoint
With, ?c1), (?x, a, ?c1), (?x, a, ?c2)

Here, varsTA(caxdw) = {?c1,?c2}. Further assume that we have
the triple (foaf: Person, owl:disjointWith, geoont: TimeZ-
one) given by a source s. For the respective T-ground rule: (?x,
a, foaf: Person), (?x, a, geoont:TimeZone)

to be authoritative, s must correspond to either deref(foaf:
Person) or deref(geoont:TimeZone)it must be authoritative
for at least one T-substitution of {?c1 ,?c2}.39 h

Then, the process of extracting constraint violations is as

follows:

(i) Local: apply an authoritative T-grounding of the constraint
rules in Table A.6 from the T-Box resident on the master
machine;

(ii) Flood/run: flood the non-ground A-atoms in the T-ground
constraints to all slave machines, which extract the selectivity (number of ground instances) of each pattern for their
segment of the corpus, and locally buffer the instances to a
separate corpus;

(iii) Gather: gather and aggregate the selectivity information
from the slave machines, and for each T-ground constraint,
identify A-atoms with a selectivity below a given threshold
(in-memory capacity);

(iv) Reason: for rules with zero or one low-selectivity A-atoms,
run the distributed reasoning process described in Section
7.2, where the highly-selective A-atoms can be considered
T-atoms;

(v) Run(/coordinate): for any constraints with more than one
low-selectivity A-atoms, apply a manual on-disk merge-join
operation to complete the process.

The end result of this process is sets of annotated atoms constituting constraint violations distributed across the slave machines.

8.3. Inconsistency detection: evaluation

Distributed extraction of the inconsistencies from the aggregated annotated data took, in total, 2.9 h. Of this: (i) 2.6 min were
spent building the authoritative T-ground constraint rules from the
local T-Box on the master machine; (ii) 26.4 min were spent
extractingin parallel on the slave machinesthe cardinalities of
the A-atoms of the T-ground constraint bodies from the aggregated
corpus; (iii) 23.3 min were spent extracting ground instances of
the high-selectivity A-atoms from the slave machines; (iv) 2 h
were spent applying the partially-ground constraint rules in parallel on the slave machines.

In Fig. 7, we present the high-level results of applying inconsistency detection for varying corpus sizes and number of slave machines (as per Table 1). For reference, in Table 7 we present the
factors by which the runtimes changed when doubling the size
of the corpus and when doubling the number of slave machines.
We note that:

 doubling the amount of input data increases the runtime (on

average) by a factor of between 2.06 and 2.26, respectively;

 when doubling the number of slave machines from 1sm to 2sm,

runtimes approximately halve each time. 10

With respect to the first observation, this is to be expected given
that the outputs of the reasoning process in Section 7.4which

39 It corresponds to the latter:http://geoontology.altervista.org/
schema.owl#Timezone.

serve as the inputs for this evaluationare between 2.14
 and
2.22
 larger for 2
 the raw data.

With respect to the second observation, we note that in partic-
ular, for the smallest corpus, and doubling the number of machines
from four to eight, the runtime does not quite halve: in this case,
the master machine takes up 17% of the total runtime with local
processing. However, this becomes increasingly less observable
for larger corpora where the percentage of terminological data decreases (cf. Secton 7.4): when processing the full corpus, note that
the amount of time spent on the master machine was between
0.2% for 1sm and 1.7% for 8sm (2.5 min). Further, in Fig. 8 we present the breakdown of the individual inconsistency detection tasks
for the full corpus using one, two, four and eight slave machines;
we observe that for our full corpus, the number of machines can
be doubled approximately a further six times (512 machines) before the processing on the master machine takes > 50% of the
runtime.

Focussing again on the results for the full corpus, a total of
301 k constraint violations were found; in Table 8, we give a
breakdown showing the number of T-ground rules generated,
the number of
total ground instances (constraint violations
found), and the total number of unique violations found (a constraint may fire more than once over the same data, where for
example in rule cax-dw, ?c1 and ?c2 can be ground interchange-
ably). Notably, the table is very sparse: we highlight the constraints requiring new OWL 2 constructs in italics, where we
posit that OWL 2 has not had enough time to gain traction on
the Web. In fact, all of the T-ground prp-irp and prp-asyp rules
come from one document40, and all cax-adc T-ground rules come
from one directory of documents41. The only two constraint rules
with violations in our Linked Data corpus were dt-not-type
(97.6%) and cax-dw (2.4%).

Overall, the average violation rank degree was 1.19 
 107 (vs.
an average rank-per-fact of 5.29 
 107 in the aggregated corpus).
The single strongest violation degree is shown in Listing 1 and was
given by dt-not-type where the term True"^^ xsd:integer is
invalid. In fact, the document serving this triple is ranked 23rd
overall out of our 3.985 m sourcesindeed, it seems that even
highly ranked documents are prone to publishing errors and incon-
sistencies. Similar inconsistencies were also found with similar
strengths in other documents within that FreeBase domain.42 Thus,
only a minute fraction (0.0006%) of our corpus is above the consistency threshold.

Listing 1
Strongest constraint violation.

# ABox Source - http://rdf.freebase.com/rdf/type/

key/namespace

# Annotation - <nb,a,0.001616>
(fb:type.key.namespace, fb:type.property.unique,

True^^xsd:integer)

With respect to cax-dw, we give the top 10 pairs of disjoint
classes in Table 9. The single strongest violation degree for caxdw is given in Listing 2 where we see that the inconsistency is
given by one document, and may be attributable to use of properties without verifying their defined domain; arguably, the entity kingdoms:Aa is unintentionally a member of both the

40 h t t p : / / m o d e l s . o k k a m . o r g / E N S - c o r e - v o c a b u l a r y #
country_of_residence
41 http://ontologydesignpatterns.org/cp/owl/fsdas/
42 Between our crawl and time of writing, these errors have been fixed.

slave machines

Fig. 7. Total time taken for inconsistency detection on 1/2/4/8 slave machines for
varying corpus sizes.

Table 7
On the left, we present the factors by which the inconsistency detection total
runtimes changed when doubling the data. On the right, we present the factors by
which the runtimes changed when doubling the number of slave machines.

Doubling data

Doubling slaves

sm

1sm
2sm
4sm
8sm

Mean

c= c

2 = c

4 = c

2.06 Mean

2sm/1sm

4sm/2sm

8sm/4sm

(i) load T-Box (master)
(ii) get selectivities (slaves)
(iii) get low-sel. data (slaves)
(iv) find inconsistencies (slaves)
total (slaves)
total (master)
total

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

all data
1/2 data
1/4 data
1/8 data

Listing 2
Strongest disjoint-class violation.

# TBox Source - foaf: (amongst others)
# Annotations - <nb,a,0.024901>
(foaf:primaryTopic, rdfs:domain, foaf:Document)
(foaf:Document, owl:disjointWith, foaf:Agent)
# TBox Source - geospecies:
# Annotation - <nb,a,0.000052>
(geospecies:hasWikipediaArticle, rdfs:domain, foaf:Person)
# ABox Source - kingdoms:Aa?format=rdf
# Annotations - <nb,a,0.000038>
(kingdoms:Aa, foaf:PrimaryTopic, kingdoms:Aa)
(kingdoms:Aa , geospecies:hasWikipediaArticle,

enwiki:Animal)

# Violation
# Annotations - <nb,a,0.000038>
(kingdoms:Aa, rdf:type, foaf:Document) # Inferred
(kingdoms:Aa, rdf:type, foaf:Person) # Inferred

Listing 3
Disjoint-class violation involving strongest fact.

# TBox Source - foaf: (amongst others)
# Annotations - <nb,a,0.024901>
(foaf:knows, rdfs:domain, foaf:Person)
(foaf:Organization, owl:disjointWith, foaf:Person)
# Comment - dav:this refers to the company OpenLink

Software

# ABox Source - 5,549 documents including dav:
# Annotation - <nb,a,0.000391>
(dav:this, rdf:type, foaf:Organization)
# ABox Source - dav: (alone)
# Annotation - <nb,a,0.000020>
(dav:this, foaf:knows,

vperson:kidehen@openlinksw.com#this)

# Violation
# Annotation - <nb,a,0.000391>
(dav:this, rdf:type, foaf:Organization)
# Annotation - <nb,a,0.000020>
(dav:this, rdf:type, foaf:Person) # Inferred

Of the cax-dw constraint violations, 3848 (54.1%) involved A-
atoms with the same annotation (such as in the former cax-dw
examplelikely stemming from the same A-Box document). All
of the constraint violations were given by A-atoms (i.e., an A-atom
represented the weakest element of each violation).

slave machines

8.4. Inconsistency repair: implementation

Fig. 8. Breakdown of distributed inconsistency-detection task times for 1/2/4/8
slave machines and full corpus.

FOAF disjoint classes, where the entity is explicitly a member of
geospecies:KingdomConcept. Taking a slightly different exam-
ple, the cax-dw violation involving the strongest A-atom annotation is given in Listing 3 where we see a conflict between a
statement asserted in thousands of documents, and a statement
inferable from a single document.

Given the set of inconsistencies extracted from the corpus in the
previous section, and the methodology of repair sketched in Section 8.1, we now briefly describe the distributed implementation
of the repair process.

To derive the complete collection of EMCSs from our corpus, we
apply the following process. First, for each constraint violation extracted in the previous steps, we create and load an initial (mini-
mal) conflict set into memory. From this, we create an extended
version representing each member of the original conflict set (seed
fact) by a singleton in the extended set. (Internally, we use a map
structure to map from facts to the extended set(s) that contain it,

or or course, null if no such conflict set exists.) We then reapply Pr
over the corpus in parallel, such thathere using notation which
corresponds to Algorithm 1for each input triple t being reasoned
over, for each member td of the subsequently inferred set Gn, if td is
a member of an EMCS, we add t to that EMCS.

Consequently, we populate the collection of EMCS, where
removing all of the facts in one member of each EMCS constitutes
a repair (a diagnosis). With respect to distributed computation of
the EMCSs, we can run the procedure in parallel on the slave ma-
chines, and subsequently merge the results on the master machine
to derive the global collection of EMCSs. We can then apply the
diagnosis procedure and compute D, D+ and D needed for the repair of the closed corpus.

We now give the overall distributed steps; note that Steps (i),
(iii) and (v) involve aggregating and diagnosing inconsistencies
and are performed locally on the master machine, whereas Steps
(ii), (iv) and (vi) involve analysis of the input and inferred data
on the slave machines and are run in parallel:

(i) Gather:

the set of conflict sets (constraint violations)
detected in the previous stages of the process (Sections 8.2
and 8.3) are gathered onto the master machine;

(ii) Flood/run: the slave machines receive the conflict sets from
the master machine and reapply the (positive) T-ground
program over the closed corpus; any triple involved in the
inference of a member of a conflict set is added to an
extended conflict set;

(iii) Gather: the respective extended conflict sets are merged on
the master machine, and the sets are ordered by 6E and iterated overthe initial diagnosis D is thus generated; the master machine applies reasoning over D to derive D+ and floods
this set to the slave machines;

(iv) Flood/run: the slave machines re-run the reasoning over the
input corpus to try to find alternate (non-diagnosed) derivations for facts in D;

(v) gather: the set of alternate derivations are gathered and aggregated on the master machine, which prepares the final D set
(maintaining only dominant rederivations in the merge);

(vi) flood/run: the slave machines accept the final diagnosis and
scan the closed corpus, buffering a repaired (consistent)
corpus.

8.5. Inconsistency repair: evaluation

The total time taken for applying the distributed diagnosis and repair of the full corpus using eight slave machines was 2.82 h; the
bulk of the time was taken for (i) extracting the extended conflict sets
from the closed corpus on the slave machines which took 24.5 min;
(ii) deriving the alternate derivations D over the input corpus
which took 18.8 min; (iii) repairing the corpus which took 1.94 h.43
In Fig. 9, we present the high-level results of applying the diagnosis and repair for varying sizes of input corpora and number of
slave machines (as per Table 1). For reference, in Table 7 we present the factors by which the runtimes changed when doubling the
size of the corpus and when doubling the number of slave ma-
chines. We note that: (see Fig. 10, 11)

 doubling the amount of input data increases the runtime (on

average) by a factor of between 1.96 and 2.16, respectively;

 when doubling the number of slave machines from 1sm to 2sm,

runtimes approximately halve each time.

43 Note that for the first two steps, we use an optimisation technique to skip
reasoning over triples whose Herbrand universe (set of RDF constants) does not
intersect with that of D/D+ resp.

Table 8
Number of T-ground rules, violations, and unique violations found for each OWL 2 RL/
RDF constraint rulerules involving new OWL 2 constructs are italicised.

Rule

eq-diff1
eq-diff2
eq-diff3
eq-irp
prp-irp
prp-asyp
prp-pdw
prp-adp
prp-npa1
prp-npa2
cls-nothing
cls-com
cls-maxc1
cls-maxqc1
cls-maxqc2
cax-dw
cax-adc
dt-not-type

T-ground

Violations

Table 9
Top 10 disjoint-class pairs.

Class 1

Class 2

Violations

foaf:Agent
foaf:Document
sioc:Container
foaf:Person
ecs:Group
skos:Concept
foaf:Document
foaf:Organization
sioc:Community
ecs:Fax

foaf:Document
foaf:Person
sioc:Item
foaf:Project
ecs:Individual
skos:Collection
foaf:Project
foaf:Person
sioc:Item
ecs:Telephone

With respect to the first observationand as per Section 8.3this is
again to be expected given that when the raw corpus increases by
2
, the union of the inferred and raw input data increases by between 2.14
 and 2.22
. Thus, the tasks which extend the conflict
sets and repair the final corpus must deal with more than double
the input data.

With respect to the second observation, as per Section 8.3 we
again note that in particular, for the smallest corpus and doubling
the number of machines from four to eight, the runtime does not
quite halve: this time, the master machine takes up 25.2% of the total runtime with local processing. However, (and again, as per Section 8.3) this becomes increasingly less observable for larger
corpora where the percentage of terminological data decreases:
when processing the full corpus, note that the amount of time
spent on the master machine was between 0.7% for 1sm and 4.2%
for 8sm (9.6 min). Further, in Fig. 8 we present the breakdown
of the individual repair tasks for the full corpus using one, two, four
and eight slave machines; we observe that for our full corpus, the
number of machines can be doubled approximately a further four
times (128 machines) before the processing on the master machine
takes > 50% of the runtime.

With respect to the results of repairing the full corpus, the initial diagnosis over the extended conflict set contained 316,884 en-
tries, and included 16,733 triples added in the extension of the
conflict set (triples which inferred a member of the original conflict
set). 413,744 facts were inferable for this initial diagnosis, but
alternate derivations were found for all but 101,018 (24.4%) of
these; additionally, 123 weaker derivations were found for triples
in the initial diagnosis. Thus, the entire repair involved removing

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

all data
1/2 data
1/4 data
1/8 data

slave machines

all data
1/2 data
1/4 data
1/8 data

slave machines

Fig. 9. Total time taken for diagnosis/repair on 1/2/4/8 slave machines for varying
corpus sizes.

(i) load T-Box/gather inconsistencies (master)
(ii) extend conflict sets (slaves)
(iii) diagnose (master)
(iv) find alternate derivations (slaves)
(v) gather alt. der./final diagnosis (master)
(vi) repair corpus (slaves)
total (slaves)
total (master)
total

slave machines

Fig. 10. Breakdown of distributed diagnosis/repair task times for 1/2/4/8 slave
machines and full corpus.

417,912 facts and weakening 123 annotations, touching upon
0.02% of the closed corpus.

9. Discussion

In this section, we wrap up the contributions of this paper by (i)
giving a summary of the performance of all distributed tasks
(Section 9.1); (ii) detail potential problems with respect to scaling
further (Section 9.2); (iii) discuss extending our approach to support a larger subset of OWL 2 RL/RDF rules (Section 9.3).

9.1. Summary of performance/scalability

Herein, we briefly give an overall summary of all distributed

tasks presented in Sections 68.

Along these lines, in Fig. 9, we summarise the total runtimes
for all high-level tasks for varying corpus size and number of ma-
chines; as before, we give the breakdown of factors by which the
runtimes changed in Table 11. Again, we note that for doubling
the size of the corpus, the runtimes more than double; for doubling the number of slave machines, the runtimes do not quite
halve. In Fig. 12, we present the relative runtimes for each of
the high-level tasks; we note that the most expensive tasks are
the ranking and annotated reasoning, followed by the inconsistency detection and repair processes. Quite tellingly, the total

Fig. 11. Total time taken for all tasks on 1/2/4/8 slave machines for varying corpus
sizes.

execution time spent on the master machine is dominated by
the time taken for the PageRank computation (also shown in
Fig. 12 for reference). Similarly, for eight slave machines, the total
time spent computing the PageRank of the source-level graph locally on the master machine roughly equates to the total time
spent in distributed execution for all other tasks: as the number
of machines increases, this would become a more severe bottleneck relative to the runtimes of the distributed tasksagain, distributing PageRank is a mature topic in itself, and subject to
investigation in another scope. Besides the ranking, we see that
the other high-level tasks behave relatively well when doubling
the number of slave machines.

9.2. Scaling further

Aside from the aforementioned ranking bottleneck, other local
aggregation taskse.g., processing of terminological knowledge
may become a more significant factor for a greatly increased number of machines, especially when the size of the corpus remains
low. Similarly, the amount of duplicates and/or dominated inferences produced during reasoning increase along with the number
of machines: however, as discussed in Section 7.4, the total amount
of duplicates should converge and become less of an issue for higher numbers of machines.

With respect to reasoning in general, our scalability is predicated on the segment of terminological data being relatively small
and efficient to process and access; note that for our corpus, we
found that 0.1% of our corpus was what we considered to be ter-
minological. Since all machines currently must have access to all of
the terminologyin one form or another, be it the raw triples or
partially evaluated rulesincreasing the number of machines in
our setup does not increase the amount of terminology the system
can handle efficiently. Similarly, the terminology is very frequently
accessed, and thus the system must be able to service lookups

Table 10
On the left, we present the factors by which the inconsistency detection total
runtimes changed when doubling the data. On the right, we present the factors by
which the runtimes changed when doubling the number of slave machines.

Doubling data

Doubling slaves

sm

1sm
2sm
4sm
8sm

Mean

c= c

2 = c

4 = c

1sm
2sm
4sm
8sm

1.96 Mean

2sm/1sm 4sm/2sm 8sm/4sm

against it in a very efficient manner; currently, we store the termi-
nology/partially-evaluated rules in memory, and with this ap-
proach, the scalability of our system is a function of how much
terminology can be fit on the machine with the smallest mainmemory in the cluster. However, in situations where there is insufficient main memory to compute the task in this manner, we believe that given the apparent power-law distribution for class
and property memberships (see [37, Figs. A.2 and A.3]), a cached
on-disk index would work sufficiently well, enjoying a high-cache
hit rate and thus a low average lookup time.

Also, although we know that the size of the materialised data is
linear with respect to the assertional data (cf. [32]), another limiting factor for scalability is how much materialisation the terminology mandatesor, put another way, how deep the taxonomic
hierarchies are under popularly instantiated classes and properties.
For the moment, with some careful pruning, the volume of materialised data roughly mirrors the volume of input data; however,
if, for example, the FOAF vocabulary today added ten subclasses
of foaf:Person, the volume of authoritatively materialised data
would dramatically increase.

Some of our algorithms require hashing on specific triple elements to align the data required for joins on specific machines;
depending on the distribution of the input identifiers, hash-based
partitioning of data across machines may lead to load balancing is-
sues. In order to avoid such issues, we do not hash on the predicate
position or object position of triples: otherwise, for example, the
slave machine that receives triples with the predicate rdf:type
or object foaf:Person would likely have significantly more data
to process than its peers (cf. [37, Fig. A.1 and A.2]). Instead, we only
hash on subject or context, arguing throughout the paper that
hashing on these elements does not cause notable data skew for
out current corpuseven still, this may become an issue if, for
example, the number of machines is significantly increased, in
which case, one may consider alternate data distribution strate-
gies, such as hashing over the entire triple, etc.

Finally, many of our methods also rely on external merge-sorts,
which have the linearithmic complexity O(nlog(n)); moving towards true Web(-of-Data)-scale, the log(n) factor can become conspicuous with respect to performance. Although log(n) grows
rather slowly, from a more immediate perspective, performance
can also depreciate as the number of on-disk sorted batches required for external merge-sorts increases, which in turn increases
the movement of the mechanical disk arm from batch to batchat
some point, a multi-pass merge-sort may become more effective,
although we have yet to investigate low-level optimisations of this
type. Similarly, many operations on a micro-levelfor example,
operations on individual resources (subject groups) or batches of
triples satisfying a joinare of higher complexity; typically, these
batches are processed in memory, which may not be possible given
a different morphology of data to that of our current corpus.

In any case, we believe that we have provided a sound basis for
scalable, distributed implementation of our methods, given a nontrivial demonstration of scale and feasibility for an input corpus in

Table 11
On the left, we present the factors by which the overall runtimes changed when
doubling the data. On the right, we present the factors by which the runtimes
changed when doubling the number of slave machines.

Doubling data

Doubling slaves

sm

1sm
2sm
4sm
8sm

Mean

c= c

2 = c

4 = c

1sm
2sm
4sm
8sm

2.36 Mean

2sm/1sm 4sm/2sm 8sm/4sm

ranking sources and triples
annotated reasoning
extract inconsistencies
diagnosis and repair
[local ranking (master)]
total (slaves)
total (master)
total

slave machines

Fig. 12. Breakdown of distributed ranking, reasoning, inconsistency detection, and
repair task-times for 1/2/4/8 slave machines and full corpus.

the order of a billion triples of arbitrary Linked Data, and provided
extensive discussion on possible obstacles that may be encountered when considering further levels of scale.

9.3. Extending OWL 2 RL/RDF support

Our current subset of OWL 2 RL/RDF rules is chosen since it (i)
allows for reasoning via a triple-by-triple scan, (ii) guarantees linear materialisation with respect to the bulk of purely assertional
data, and (iii) allows for distributed assertional reasoning without
any need for coordination between machines (until aggregation of
the output).

First, we note that the logical framework presented in Section
4 can also be usedwithout modificationfor rulesets containing
multiple A-atoms in the body (A-Box join rules). However, the
distributed implementation for reasoning presented in Section
7, and the methods and implementation for repairing the corpus
presented in Section 8, are based on the premise that the original
program only contains rules with zero or one A-atoms in the
body.

With respect to annotated reasoning, we note that our local
assertional reasoning algorithm (as per Algorithm 1) can support
A-Box join rules; this is discussed in Section 7.1. However, in the
worst case when supporting such rules (and as given by the eq-
rep- OWL 2 RL/RDF rules), we may have to index the entire corpus
of assertional and inferred data, which would greatly increase the
expense of the current reasoning process.

Further, the growth in materialised data may become quadratic
when considering OWL 2 RL/RDF A-Box join rulessuch as prp-trp
which supports transitivity. In fact, the worst case for materialisation with respect to OWL 2 RL/RDF rules is cubic, which can be
demonstrated with a simple example involving two triples:

(owl: same As, owl: same As, rdf: type)
(owl: same As, rdfs: domain, ex: BadHub)

Adding these two triples to any arbitrary RDF graph will lead to the
inference of all possible (generalised) triples by the OWL 2 RL/RDF
rules: i.e., the inference of C 
 C 
 C (a.k.a. the Herbrand base),
where C  C is the set of RDF constants mentioned in the OWL 2
RL/RDF ruleset and the graph (a.k.a. the Herbrand universe).44 Note
however that not all multiple A-atom rules can produce quadratic
(or cubic) inferencing with respect to assertional data: some rules

44 The rules required are the prp-dom rule for supporting rdfs:domain and the eqrules for supporting the semantics of owl:sameAs.

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

(such as cls-int1, cls-svf1) are what we call A-guarded, whereby
(loosely) the head of the rule contains only one variable not ground
by partial evaluation with respect to the terminology, and thus the
number of materialised triples that can be generated for such a rule
is linear with respect to the assertional data.

Despite this, such A-guarded rules would not fit neatly into our
partial-indexing approach, and may require indexing of a significant portion of the assertional data (and possibly all such data).
Also, A-Box join rules would not fit into our current distributed
implementation, where assertional data must then be coordinated
between machines to ensure correct computation of joins (e.g., as
presented in [62]).

Assuming a setting whereby A-Box join rules could be supported for classical (non-annotated) materialisation, annotated
reasoning would additionally require each rule and fact to be associated with a set of annotation tuples. As per the formal results of
Section 4.3, for deriving only optimal annotations with respect to
the presented annotation domain, each rule or fact need only be
associated with a maximum of four annotation tuples; assuming
our threshold, each rule or fact need only be associated with a single (optimal) rank annotationboth of these annotation settings
should have a relatively small performance/scalability impact for
a reasoner supporting the classical inferences of a larger subset
of OWL 2 RL/RDF.

Finally, we note that our repair process currently does not support A-Box join rules. Assuming that the original program does not
contain such rules allows for the simplified scan-based procedure
sketched in Section 8.1; although we believe that certain aspects of
our approach may be re-used for supporting a fuller profile of OWL
2 RL/RDF, we leave the nature of this extension as an open question.

10. Related work

In this section, we introduce related works in the various fields
touched upon in this paper. We begin in Section 10.1 by discussing
related works in the field of annotated programs and annotated
reasoning; we discuss scalable and distributed RDF(S) and OWL
reasoning in Section 10.2, followed by Web-reasoning literature
in Section 10.3, and finally inconsistency repair in 10.4.

10.1. Annotated programs

With respect to databases, [26] proposed semiring structures for
propagating annotations through queries and views in a generic
way, particularly for provenance annotations, but also applying
this approach for instance to probabilistic annotations, or annotations modelling tuple cardinality (i.e., bag semantics). For such
forms of annotations, [26] gives an algorithm that can decide query
answers for annotated Datalog45materialisation in their general
case, though, can be infinite. In contrast, our work focuses exactly
on efficient and scalable materialisation, however (i) in a very specialised setting of Datalog rules, (ii) for a less flexible annotation
structure, such that we can guarantee finiteness and scalability.

Cheney et al. [10] present a broad survey of provenance techniques deployed in database approaches, where they categorise
provenance into (i) why-provenanceannotations that model the
raw tuples from which answers/inferences were obtained, (ii)
how provenanceannotations that model the combinations of raw
tuples by which answers/inferences were obtained, and (iii) where
provenanceannotations that model the combinations of source
tuples from which answers/inferences were obtained. In this cate-
gorisation, the above mentioned provenance semirings of Green
et al. [26] fall into the so-called how-provenance approaches. We

note, however, that our annotations are orthogonal to all of these
provenance notations of [10]: although our annotations for authoritativeness and ranking are informed by data provenance, our
annotations do not directly model or track raw provenance,
although we consider a scalable extension of our approach in this
manner an interesting direction for future research.46

Perhaps of more immediate interest to us, in [41] the authors of
[26] extend their work with various annotations related to prove-
nance, such as confidence, rank, relationships between triples
(where, remarkably, they also discusssomewhat orthogonal to
our respective notionauthoritativeness). All of these are again
modelled using semirings, and an implementation is provided by
means of translation to SQL.

In [7] the Datalog language has been extended with weights
that can represent metainformation relevant to Trust Management
systems, such as costs, preferences and trust levels associated to
policies or credentials. Weights are taken from a c-semiring where
the two operations 
 and + are used, respectively, to compose the
weights associated to statements, and select the best derivation
chain. Some example of c-semirings are provided where weights
assume the meaning of costs, probabilities and fuzzy values. In
all of these examples the operator 
 is idempotent, so that the c-
semiring induces a complete lattice where + is thelub and 
 is
the glb. In these cases, by using our reasoning task opt(P), the proposed framework can be naturally translated into our annotated
programs. The complexity of Weighted Datalog is just sketched
only decidability is proven. Scalability issues are not tackled and
no experimental results are provided.

More specifically with respect to RDF, in [22] the provenance of
inferred RDF data is tackled by augmenting triples with a fourth
component named colour representing the collection of the different data sources used to derive a triple. A binary operation + over
colours forms a semigroup; the provenance of derived triples is the
sum of the provenance of the supporting triples. Clearly, also this
framework can be simulated by our annotated programs by adopting a flat lattice where all of the elements (representing different
provenances) are mutually incomparable. Then, for each derived
atom, plain(P) collects all of the provenances employed according
to [22]. Although the complexity analysis yields an almost linear
upper bound, no experimental results are provided.

Dividino et al. [17] introduce RDF+: a language which allows for
expressing meta-knowledge about the core set of facts expressed
as RDF. Meta knowledge can, for example, encode provenance
information such as the URL of an originating document, a time-
stamp, a certainty score, etc.; different properties of meta knowledge are expressible in the framework as appropriate for different
applications. The approach is based on named graphs and internal
statement identifiers; meta statements are given as RDF triples
where a statement identifier appears as the subject. Semantics
are given for RDF+ through standard interpretations and interpretations for each individual property of meta knowledge; mappings
between RDF and RDF+ are defined. Unlike us, Dividino et al. focus
on extending SPARQL query processing to incorporate such meta
knowledge: they do not consider, e.g., OWL semantics for reasoning
over such meta knowledge. Later results by Schenk et al. [56] look at
reasoning and debugging meta-knowledge using the Pellet (OWL
DL) reasoner, but only demonstrate evaluation over ontologies in
the order of thousands of axioms.

Lopes et al. [49] define a general annotation framework for
RDFS, together with AnQL: a query language inspired by SPARQL
which includes querying over annotations. Annotations are
formalised in terms of residuated bounded lattices, which can be

45 Here, only the ground data rather than the proper rules are annotated.

46 Further, in our case we consider provenance as representing a container of
informationa Web documentrather than a method of derivation.

specialised to represent different types of meta-information (tem-
poral constraints, fuzzy values, provenance etc.). A general deductive systembased on abstract algebraic structureshas been
provided and proven to be in PTIME as far as the operations defined
in the structure can be computed in polynomial time. The Annotated RDFS framework enables the representation of a large spectrum of different meta-information. Some of themin particular
those where an unbounded number of different values can be assigned to an inferred tripledo not fit our framework. On the other
hand, the framework of [49] is strictly anchored to RDFS, while our
annotated programs are founded on OWL 2 RL/RDF and hence are
transversable with respect to the underlying ontology language.
Moreover, our results place more emphasis on scalability. Along
similar lines, work presented in [9] also focuses on the definition
of a general algebra for annotated RDFS, rather than on computational aspects which we are concerned about here.

10.2. Scalable/distributed reasoning

From the perspective of scalable RDF(S)/OWL reasoning, one of
the earliest engines to demonstrate reasoning over datasets in the
order of a billion triples was the commercial system BigOWLIM [6],
which is based on a scalable and custom-built database management system over which a rule-based materialisation layer is
implemented, supporting fragments such as RDFS and pD, and
more recently OWL 2 RL/RDF. Most recent results claim to be able
to load 12 b statements of the LUBM synthetic benchmark, and
20.5 b statements statements inferrable by pD rules on a machine
with 2
 Xeon 5430 (2.5 GHz, quad-core), and 64 GB (FB-DDR2) of
RAM.47 We note that this system has been employed for relatively
high-profile applications, including use as the content management
system for a live BBC World Cup site.48 BigOWLIM features distribu-
tion, but only as a replication strategy for fault-tolerance and supporting higher query load.

The Virtuoso SPARQL engine [19] features support for inference
rules; details of implementation are sketchy, but the rdfs: sub
Class Of, rdfs: sub Property Of, owl: equivalent Class,
owl: equivalent Property and owl: same As primitives are
partially supported by a form of internal backward-chaining, and
other user-defined rulesencoded in SPARQL syntaxcan also be
passed to the engine.49

A number of other systems employ a similar strategy to ours for
distributed RDFS/OWL reasoning: i.e., separating out terminological data, flooding these data to all machines, and applying parallel
reasoning over remote segments of the assertional data.

One of the earliest such distributed reasoning approaches is
DORS [20], which uses DHT-based partitioning to split the input
corpus over a number of nodes. Data segments are stored in remote databases, where a tableaux-based reasoner is used to perform reasoning over the T-Box, and where a rule-based reasoner
is used to perform materialisation. Since they apply the DLP ruleset
[27]which contains rules with multiple A-atomsthe nodes in
their distributed system must coordinate to perform the required
assertional joins, which again is performed using DHT-based parti-
tioning. However, they hash assertional data based on the predicate and the value of rdf:type which would cause significant
data-skew for Linked Data corpora (cf. [37, Figs. A.2 and A.3]). Their
evaluation is with respect to 2 m triples of synthetically generated data on up to 32 nodes.

Weaver and Hendler [65] discuss a similar approach for distributed materialisation with respect to RDFSthey also describe a

47 http://www.ontotext.com/owlim/benchmarking/lubm.html
48 http://www.readwriteweb.com/archives/bbc_world_cup_website_
semantic_technology.php
49 http://docs.openlinksw.com/virtuoso/rdfsparqlrule.html

separation of terminological (what they call ontological) data from
assertional data. Thereafter, they identify that all RDFS rules have
only one assertional atom and, like us, use this as the basis for a
scalable distribution strategy: they flood the terminological data
and split the assertional data over their machines. Inferencing is
done over an in-memory RDF store. They evaluate their approach
over a LUBM-generated synthetic corpus of 345.5 m triples using
a maximum of 128 machines (each with two dual-core 2.6 GHz
AMD Opteron processors and 16 GB memory); with this setup, reasoning in memory takes just under 5 min, producing 650 m triples.
Urbani et al. [63] use MapReduce [13] for distributed RDFS materialisation over 850 m Linked Data triples. They also consider a separation of terminological (what they call schema) data from
assertional data as a core optimisation of their approach, andlikewise with [65]identify that RDFS rules only contain one assertional atom. As a pre-processing step, they sort their data by
subject to reduce duplication of inferences. Based on inspection of
the rules, they also identify an ordering (stratification) of RDFS rules
which (again assuming standard usage of the RDFS meta-vocabu-
lary) allows for completeness of results without full recursionunlike us, they do reasoning on a per-rule basis as opposed to our
per-triple basis. Unlike us, they also use a 8-byte dictionary encoding of terms. Using 32 machines (each with 4 cores and 4 GB of
memory) they infer 30 b triples from 865 m triples in less than
1 h; however, they do not materialise or decode the outputa
potentially expensive process. Note that they do not include any
notion of authority (although they mention that in future, they
may include such analysis): they attempted to apply pD on 35 m
Web triples and stopped after creating 3.8 b inferences in 12 h,
lending strength to our arguments for authoritative reasoning.
In more recent work [62], (approximately) the same authors revisit the topic of materialisation with respect to pD. They again use a
separation of terminological data from assertional data as the basis
for scalable distributed reasoning, but since pD contains rules with
multiple A-atoms, they define bespoke MapReduce procedures to
handle each such rule, some of which are similar in principle to those
presented in [36] (and later on) such as canonicalisation of terms related by owl:sameAs. They demonstrate their methods over three
datasets; (i) 1.51 b triples of UniProt data, generating 2.03 b inferences in 6.1 h using 32 machines; (ii) 0.9 b triples of LDSR data (dis-
cussed later), generating 0.94 b inferences in 3.52 h using 32
machines; (iii) 102.5 b triples of synthetic LUBM data, generating
47.6 b inferences in 45.7 h using 64 machines. The latter experiment
is two orders of magnitude above our current experiments, and features rules which require A-Box joins; however, the authors do not
look at open Web data, stating that reasoning over arbitrary triples
retrieved from the Web would result in useless and unrealistic derivations [62]. They do, however, mention the possibility of including our authoritative reasoning algorithm in their approach, in
order to prevent such adverse affects.

In very recent work [46], Kolovski et al. have presented an (Ora-
cle) RDBMS-based OWL 2 RL/RDF materialisation approach. They
again use some similar optimisations to the scalable reasoning lit-
erature, including parallelisation, canonicalisation of owl:sameAs
inferences, and also partial evaluation of rules based on highly
selective patternsfrom discussion in the paper, these selective
patterns seem to correlate with the terminological patterns of
the rule. They also discuss many low-level engineering optimisations and Oracle tweaks to boost performance. Unlike the approaches mentioned thus far, Kolovski et al. tackle the issue of
updates, proposing variants of semi-naive evaluation to avoid
rederivations. The authors evaluate their work for a number of different datasets and hardware configurations; the largest scale
experiment they present consists of applying OWL 2 RL/RDF materialisation over 13 billion triples of LUBM using eight nodes (Intel
Xeon 2.53 GHz CPU, 72 GB memory each) in just under 2 h.

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

10.3. Web reasoning

As previously mentioned, in [63], the authors discuss reasoning
over 850 m Linked Data tripleshowever, they only do so over
RDFS and do not consider any issues relating to provenance.

In [43], the authors apply reasoning over 0.9 b Linked Data triples using the aforementioned BigOWLIM reasoner; however, this
dataset is manually selected as a merge of a number of smaller,
known datasets as opposed to an arbitrary corpusthey do not
consider any general notions of provenance or Web tolerance.
(As aforementioned, the WebPie system [62] has also been applied
over the LDSR dataset.)

In a similar approach to our authoritative analysis, Cheng et al.
[12] introduced restrictions for accepting sub-class and equivalentclass axioms from third-party sources; they follow similar arguments to that made in this paper. However, their notion of what
we call authoritativeness is based on hostnames and does not consider redirects; we argue that both simplifications are not compatible with the common use of PURL services50: (i) all documents
using the same service (and having the same namespace hostname)
would be authoritative for each other, (ii) the document cannot be
served directly by the namespace location, but only through a redi-
rect. Indeed, further work presented in [11] better refined the notion
of an authoritative description to one based on redirectsand one
which aligns very much with our notion of authority. They use their
notion of authority to do reasoning over class hierarchies, but only
include custom support of rdfs:subClassOf and owl:equiva-
lentClass, as opposed to our general framework for authoritative
reasoning over arbitrary T-split rules.

A viable alternative approach to authorityand which also
looks more generally at provenance for Web reasoningis that of
quarantined reasoning, described in [14]. The core intuition is
to consider applying reasoning on a per-document basis, taking
each Web document and its recursive (implicit and explicit) imports and applying reasoning over the union of these documents.
The reasoned corpus is then generated as the merge of these perdocument closures. In contrast to our approach where we construct one authoritative terminological model for all Web data,
their approach uses a bespoke trusted model for each document;
thus, they would infer statements within the local context which
we would consider to be non-authoritative, but our model is more
flexible for performing inference over the merge of documents.51
As such, they also consider a separation of terminological and assertional data; in this case ontology documents and data documents.
Their evaluation was performed in parallel using three machines
(quad-core 2.33 GHz CPU with 8 GB memory each); they reported
loading, on average, 40 documents per second.

10.4. Inconsistency repair

Most legacy works in this area (e.g., see DION and MUPSTER [57]
and a repair tool for unsatisfiable concepts in Swoop [40]) focus
on debugging singular OWL ontologies within a Description Logics
formalism, in particular focussing on fixing terminologies (T-Boxes)
which include unsatisfiable conceptsnot of themselves an incon-
sistency, but usually indicative of a modelling error (termed inco-
herence) in the ontology. Such approaches usually rely on the
extraction and analysis of MUPs (Minimal Unsatisfiability Preserving Sub-terminologies) and MIPs (Minimal Incoherence Preserving
Sub-terminologies), usually to give feedback to the ontology editor
during the modelling process. However, these approaches again focus on debugging terminologies, and have been shown in theory

and in practice to be expensive to computeplease see [59] for a
survey (and indeed critique) of such approaches.

using multi-valued,

There are a variety of other approaches for handling inconsistencies in OWL ontologies, including works on paraconsistent rea-
soning
possibilistic
appraoches, by, e.g., Ma et al. [52], Zhang et al. [67], Huang et al.
[39], Qi et al. [54], etc.52 However, all such approaches are again
based on Description Logics formalisms, and only demonstrate evaluation over one (or few) ontologies containing in the order of thou-
sands, tens of thousands, up to hundreds of thousands of axioms.

probabalistic,

or

11. Conclusion

In this paper, we have given a comprehensive discussion on
methods for incorporating notions of provenance during Linked
Data reasoning. In particular, we identified three dimensions of
trust-/provenance-related annotations for data: viz. (i) blacklisting,
where a particular source or type of information is distrusted and
should not be considered during reasoning or be included in the final corpus; (ii) authoritativeness which analyses the source of terminological facts to determine whether assertional
inferences
they mandate can be trusted; (iii) ranking which leverages the
well-known PageRank algorithm for links-based analysis of the
source-level graph, where ranking values are subsequently propagated to facts in the corpus.

We continued by discussing a formal framework based on
annotated logic programs for tracking these dimensions of trust
and provenance during the reasoning procedure. We gave various
formal properties of the programsome specific to our domain of
annotation, some notwhich demonstrated desirable properties
relating to termination, growth of the program, and efficient
implementation. Later, we provided a use-case for our annotations
involving detection and repair of inconsistencies.

We introduced our distribution framework for implementing
and running our algorithms over a cluster of commodity hardware,
subsequently detailing non-trivial implementations for deriving
rank annotations, for applying reasoning wrt. the defined logic pro-
gram, for detecting inconsistencies in the corpus, and for leveraging the annotations in repairing inconsistencies. All of our
methods were individually justified by evaluation over a 1.118 b
quadruple Linked Data corpus, with a consistent unbroken thread
of evaluation throughout. In so doing, we have looked at non-triv-
ial application and analysis of Linked Data principles, links-based
analysis, annotated logic programs, OWL 2 RL/RDF rules (including
the oft overlooked constraint rules), and inconsistency repair tech-
niques, incorporating them into a coherent system for scalable and
tolerant Web reasoning.

As the Web of Data expands and diversifies, the need for reasoning will grow more and more apparent, as will the implied need for
methods of handling and incorporating notions of trust and provenance which scale to large corpora, and which are tolerant to
spamming and other malicious activity. We hope that this paper
represents a significant step forward with respect to research into
scalable Web-tolerant reasoning techniques which incorporate
provenance and trust.

Acknowledgements

We thank Antoine Zimmermann for providing feedback on earlier drafts of this paper. We also thank the anonymous reviewers
and the editors for their time and comments. The work presented
in this paper has been funded in part by Science Foundation Irelan-

50 http://purl.org/
51 Although it should be noted that without considering rules with assertional joins,
our ability to make inferences across documents is somewhat restricted.

52 For a survey of the use of multi-valued, probabilistic and possibilistic approaches
for uncertainty in Descrption Logics, see [50].

dunder Grant No. SFI/08/CE/I1380 (Lion-2), and by an IRCSET postgraduate scholarship.

Appendix A. Rule tables

Table A.1
Rules with empty body (axiomatic triples) we strike out the datatype rules which we
currently do not support.

Body(R) = ;
OWL2RL
prp-ap

Consequent
?p a owl: AnnotationProperty

Notes
For each built-in

Herein, we list the subset of OWL 2 RL/RDF rules we apply in
our scenario categorised by the assertional and terminological arity
of the rule bodies, including rules with no antecedent (Table A.1),
rules with only T-atoms in the body (Table A.2), rules with only a
single A-atom in the body (Table A.3), and rules with some T-atoms
and a single A-atom in the body (Table A.4). Also, in Table A.5, we

cls-thing
cls-nothing
dt-type1

owl:Thing a owl:Class
owl:Nothing a owl:Class
?dt a rdfs:Datatype

annotation property

For each built-in datatype

Table A.3
Rules containing no T-atoms, but one A-atom in the body; we strike out the rule
supporting the reflexivity of equality which we choose not to support since it adds a
large bulk of trivial inferences to the set of materialised facts.

Table A.2
Rules containing only T-atoms in the body.

TBody(R)  ;,ABody(R) = ;
OWL2RL Antecedent

Terminological

cls-00
scm-cls

?c owl:oneOf (?x1 . . . ?xn)
?c a owl:Class

scm-sco

scm-eqc1

scm-eqc2

scm-op

?c1 rdfs:subClassOf ?c2
?c2 rdfs: subClassOf ?c3
?c1 owl: equivalentClass ?c2

?c1 rdfs:subClassOf ?c2
?c2 rdfs:subClassOf ?c1
?p a owl:ObjectProperty

scm-dp

?p a owl:DatatypeProperty

Consequent

?x1. . .?xn a ?c
?c rdfs: subClassOf ?c ;
rdfs:subClassOf owl: Thing ;
owl:equivalentClass ?c
owl:Nothing rdfs:subClassOf ?c
?c1 rdfs: subClassOf ?c3

?c1 rdfs: subClassOf ?c2
?c2 rdfs:subClassOf ?c1
?c1 owl:equivalentClass ?c2

?p rdfs:subPropertyOf ?p
?p owl:equivalentProperty ?p
?p rdfs:subPropertyOf ?p
?p owl:equivalentProperty ?p
?p1 rdfs:subPropertyOf ?p3

scm-spo

scm-eqp1

scm-eqp2

?p1 rdfs:subPropertyOf ?p2
?p2 rdfs:subPropertyOf ?p3
?p1 owl:equivalentProperty ?p2 . ?p1 rdfs:subPropertyOf ?p2
?p2 rdfs:subPropertyOf ?p1
?p1 owl:equivalentProperty ?p2

?p1 rdfs:subPropertyOf ?p2
?p2 rdfs:subPropertyOf ?p1

scm-dom1 ?p rdfs:domain ?c1 .

?c1 rdfs:subClassOf ?c2

scm-dom2 ?p2 rdfs:domain ?c .

?p rdfs:domain ?c2

?p1 rdfs:domain ?c

scm-rng1

scm-rng2

scm-hv

scm-svf1

scm-svf2

scm-avf1

scm-avf2

scm-int
scm-uni

?c1 rdfs:subClassOf ?c2

?p rdfs:range ?c2

?p1 rdfs:range ?c

?c1 rdfs:subClassOf ?c2

?p1 rdfs:subPropertyOf ?p2
?p rdfs:range ?c1
?c1 rdfs:subClassOf ?c2
?p2 rdfs:range ?c .
?p1 rdfs:subPropertyOf ?p2
?c1 owl:hasValue ?i ;
owl:onProperty ?p1
?c2 owl:hasValue ?i ;
owl:onProperty ?p2
?p1 rdfs:subPropertyOf ?p2
?c1 owl:someValuesFrom ?y1 ;
owl:onProperty ?p
?c2 owl:someValuesFrom ?y2 ;
owl:onProperty ?p
?y1 rdfs:subClassOf ?y2
?c1 owl:someValuesFrom ?y ;
owl:onProperty ?p1
?c2 owl:someValuesFrom ?y ;
owl:onProperty ?p2
?p1 rdfs:subPropertyOf ?p2
?c1 owl:allValuesFrom ?y1 ;
owl:onProperty ?p
?c2 owl:allValuesFrom ?y2 ;
owl:onProperty ?p
?y1 rdfs:subClassOf ?y2
?c1 owl:allValuesFrom ?y ;
owl:onProperty ?p1
?c2 owl:allValuesFrom ?y ;
owl:onProperty ?p2
?p1 rdfs:subPropertyOf ?p2
?c owl:intersectionOf (?c1. . . ?cn) ?c rdfs:subClassOf ?c1. . . ?cn
?c1. . . ?cn rdfs:subClassOf ?c
?c owl:unionOf (?c1. . . ?cn)

?c1 rdfs:subClassOf ?c2

?c1 rdfs:subClassOf ?c2

?c1 rdfs:subClassOf ?c2

ABody(R)  ;,TBody(R) = ;
OWL2RL

Antecedent
Assertional

Consequent

eq-sym

?x owl::sameAs ?y

?y owl::sameAs ?x

Table A.4
Rules containing some T-atoms and precisely one A-atom in the body with
authoritative variable positions in bold.

TBody(R)  ; and jABody(R)j = 1
OWL2RL Antecedent

Terminological

Assertional

prp-dom ?p rdfs:domain ?c
prp-rng
prp-symp
prp-spo1
prp-eqp1
prp-eqp2
prp-inv1
prp-inv2
cls-int2
cls-uni
cls-svf2

?p rdfs:range ?c
?p a owl:SymmetricProperty
?p1 rdfs:subPropertyOf ?p2
?p1 owl:equivalentProperty ?p2
?p1 owl:equivalentProperty ?p2
?p1 owl:inverseOf ?p2
?p1 owl:inverseOf ?p2
?c owl:intersectionOf (?c1. . . ?cn)
?c owl:unionOf (?c1. . . ?ci. . . ?cn)
?x owl:someValuesFrom owl:Thing ;
owl:onProperty ?p
?x owl:hasValue ?y ;
owl:onProperty ?p
?x owl:hasValue ?y ;
owl:onProperty ?p
?c1 rdfs:subClassOf ?c2
?c1 owl:equivalentClass ?c2
?c1 owl:equivalentClass ?c2

cls-hv1

cls-hv2

cax-sco
cax-eqc1
cax-eqc2

Consequent

?x a ?c
?y a ?c
?y ?p ?x
?x ?p2 ?y
?x ?p2 ?y
?x ?p1 ?y
?y ?p2 ?x
?y ?p1 ?x
?x a ?c1. . . ?cn
?x a ?c
?u a ?x

?x ?p ?y
?x ?p ?y
?x ?p ?y
?x ?p1 ?y
?x ?p1 ?y
?x ?p2 ?y
?x ?p1 ?y
?x ?p2 ?y
?x a ?c
?x a ?ci
?u ?p ?v

?u a ?x

?u ?p ?y

?u ?p ?y

?u a ?x

?x a ?c1
?x a ?c1
?x a ?c2

?x a ?c2
?x a ?c2
?x a ?c1

Table A.5
Informal indication of the coverage in case of the omission of rules in Table A.2 wrt.
inferencing over assertional knowledge by recursive application of rules in Table A.4:
underlined rules are not supported, and thus we would encounter incompleteness
wrt. assertional inference (would not affect a full OWL 2 RL/RDF reasoner which
includes the underlined rules).

OWL2RL
scm-cls

scm-sco
scm-eqc1
scm-eqc2
scm-op
scm-dp
scm-spo
scm-eqp1
scm-eqp2
scm-dom1
scm-dom2
scm-rng1
scm-rng2
scm-hv
scm-svf1

scm-svf2

scm-avf1

scm-avf2

scm-int
scm-uni

Partially covered by recursive rule(s)
incomplete for owl:Thing membership inferences

cax-sco
cax-eqc1, cax-eqc2
cax-sco
no unique assertional inferences
no unique assertional inferences
prp-spo1
prp-eqp1, prp-eqp2
prp-spo1
prp-dom, cax-sco
prp-dom, prp-spo1
prp-rng, cax-sco
prp-rng, prp-spo1
prp-rng, prp-spo1
incomplete: cls-svf1, cax-sco
incomplete: cls-svf1, prp-spo1
incomplete: cls-avf, cax-sco
incomplete: cls-avf, prp-spo1
cls-int2
cls-uni

P.A. Bonatti et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 165201

The algorithms are heavily based on on-disk operations: in the
algorithms, we use typewriter font to denote on-disk operations and files. In particular, the algorithms are all based around
sorting/scanning and merge-joins: a merge-join requires two or
more lists of tuples to be sorted by a common join element, where
the tuples can be iterated over in sorted order with the iterators
kept aligned on the join element; we mark use of merge-joins
in the algorithms using m-join in the comments.

Algorithm 2. Extract raw sub-graph

/ hs,p,o,ci0. . .n sorted by c /

links := {}, L := {}
for allhs,p,o,cii 2 Q

write(links,L)
links := {}

if ci

 ci1

Require: QUADS: Q
1.
2.
3.
4.
5.
6.
7.
8.
end for
9.
10. end for
11. write(links,L)
12.

return L

end if
for all u 2 Uju 2 {si,pi,oi} ^ u  ci

links: = links [ {hci,ui}

/ unsorted on-disk outlinks /

Table A.6
Constraint rules with authoritative variables in bold.

Head(R) = ?
OWL2RL

Antecedent
Terminological

eq-diff1

eq-diff2

eq-diff3

eq-irpa
prp-irp
prp-asyp
prp-pdw
prp-adp

prp-npa1


?p a IrreflexiveProperty
?p a AsymmetricProperty
?p1 propertyDisjointWith ?p2
?x a AllDisjointProperties
?x members (. . . ?pi. . . ?pj. . . )


prp-npa2


cls-nothing2
cls-com
cls-maxc1

cls-maxqc1

cls-maxqc2

cax-dw
cax-adc
dt-not-type


?c1 complementOf ?c2
?x maxCardinality 0
?x onProperty ?p
?x maxQualifiedCardinality 0
?x onProperty ?p
?x onClass ?c
?x maxQualifiedCardinality 0
?x onProperty ?p
?x onClass owl:Thing
?c1 disjointWith ?c2
?x a AllDisjointClasses
?x members (. . . ?ci. . . ?cj. . . )


Assertional

?x sameAs ?y
?x differentFrom ?y
?x a AllDifferent ;
members (?z1. . . ?zn)
?zi sameAs ?zj (i  j)
?x a AllDifferent ;
distinctMembers ?z1. . . ?zn)
?zi sameAs ?zj (i  j)
?x owl:differentFrom ?x
?x ?p ?x
?x ?p ?y . ?y ?p ?x
?x ?p1 ?y ; ?p2 ?y
?u ?pi ?y ; ?pj ?y (i  j)

?x sourceIndividual ?i1
?x assertionProperty ?p
?x targetIndividual ?i2
?i1 ?p ?i2
?x sourceIndividual ?i
?x assertionProperty ?p
?x targetValue ?lt
?i ?p ?lt
?x a Nothing
?x a ?c1 , ?c2
?u a ?x ; ?p ?y

?u a ?x ; ?p ?y . ?y a ?c

?x a ?c1 , ?c2
?z a ?ci , ?cj (i  j)

?s ?p ?ltb

a This is a non-standard rule we support since we do not materialise the reflexive

sameAs statements required by eq-diff1.

b Where ?lt is an ill-typed literal: this is a non-standard version of dt-not-type
which captures approximately the same inconsistencies, but without requiring rule
dt-type2.

give an indication as to how recursive application of rules in Table
A.4 can be complete, even if the inferences from rules in Table A.2
are omitted. Finally, in Table A.6, we give the OWL 2 RL/RDF rules
used for consistency checking.

Appendix B. Ranking algorithms

Herein, we provide the detailed algorithms used for extracting,
preparing and ranking the source level graph. In particular, we provide the algorithms for parallel extraction and preparation of the
sub-graphs on the slave machines: (i) extracting the source-level
graph (Algorithm 2); (ii) rewriting the graph with respect to redirect information (Algorithm 3); (iii) pruning the graph with respect
to the list of valid contexts (Algorithm 4). Subsequently, the subgraphs are merge-sorted onto the master machine, which calculates the PageRank scores for the vertices (sources) in the graph
as follows: (i) count the vertices and derive a list of dangling-nodes
(Algorithm 5); (ii) perform the power iteration algorithm to calculate the ranks (Algorithm 6).

?u a ?x ; ?p ?y

Algorithm 3. Rewrite graph wrt. redirects

/ hu,vi0. . .m unsorted /

/ hf,ti0. . .n sorted by unique f /

/ typ.I:=5 /
/sort by v /

tmp :14 fg

/ m-join /

d :14 G

if j = 0 _ vj

; ^ i < I do
k :14 0; G
:14 fg; G
for all hu; vij 2 G

Require: RAW LINKS: L
Require: REDIRECTS: R
Require: MAX. ITERATIONS: I
1: R:= sortUnique(L)
2: i:= 0;G
3: while G
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
end if
16:
end for
17:
i++; G
18:
19: end while
20: G

21: return G

rewrite:=tk

d :14 G

tmp;

 vj1 then

rewrite:= ?
if 9=hf,tik 2 Rjfk = vj then

end if
end if
if rewrite=? then
writehu; vij; G

else ifrewrite uj then
writehuj; rewritei; G

tmp

:14 mergeSortUniquefG

0 ; . . . ; G

i1 g

r /on-disk, rewritten, sorted inlinks /

Algorithm 4. Prune graph by contexts

Require: NEW LINKS: G

Require: CONTEXTS: C
p :14 fg

1: G

/ hu,vi0. . .m sorted by v /
/ hc1, . . . ,cni sorted /

/ m-join/

write:=true
end if

write:=false

if i = 0 _ ci
ifcj 2 C

2: for all hu; vii 2 G

 ci1
3:
4:
5:
6:
7:
8:
9:
10:
11:
12: end for
13: return G

if write then

end if

sorted inlinks /

write hu; vii; G

end if

/ on-disk, pruned, rewritten,

Algorithm 5. Analyse graph

 ui1

/ vertex count /

/hu,v i0. . .n sorted by u /
/ hw,xi0. . .n sorted by x /

V++
for allhw,xij 2 Gjui1 < xj < ui / m-join /
V++;write(xj,DANGLE)

Require: OUT LINKS: G
Require: IN LINKS: G
1: V:=0
2: u1: = ?
3: for all hu,vii 2 G
if i = 0 _ ui
4:
5:
6:
7:
8:
9:
10: end for
11: for all hw,xij 2 Gjxj
> un / m-join /
12:
13: end for
14: return DANGLE / sorted list of dangling vertices /
15: return V

/ number of unique vertices /

V++; write(xj,DANGLE)

end for

end if

Algorithm 6. Rank graph

/hu,vi0. . .m sorted by u /
/ hy0, . . . yni sorted /
/ typ. I:=10 /
/ typ. D:=0.85 /

/ GENERATE UNSORTED VERTEX/RANK PAIRS /

; PR tmp :14 fg;

V; min :14 1D

mini :14 min  dangle
for all zj 2 DANGLE do

Require: OUT LINKS: G
Require: DANGLING: DANGLE
Require: MAX. ITERATIONS: I
Require: DAMPING FACTOR: D
Require: VERTEX COUNT: V
1:i:=0;initial:=1
2: dangle:= D  initial  jDANGLEj
3:
4:while i < 1 do
5:
6:
7:
8:
9:
10:
11:
12:
13:
14;
15:
16:
17:

write (hzj,minii,PRtmp)

 uj1 then

write huj1; minii; PR tmp
if i  0 then

rank:getRank (uj1,PRi)
end if
for all vk 2 out do
write hvk; rank

ji; PR tmp

out

18:

end for

end for
outj: = {}; rank := initial
for all hu,vij 2 G do / strong links /
if j  0 ^ uj

end if
outj: = outj [ {vj}

end for
do lines 1218 for last uj1: = um

/ SORT/AGGREGATE VERTEX/RANK PAIRS /

/ m-join /

 zj1

if j  0 ^ zj

PRi+1: = {}; dangle:=0
for all hz,rij 2 sort(PRtmp)
ifzj1 2 DANGLE then
dangle:=dangle+rank
end if
write (hzj1,rank i,PRi+1)

end if
rank:= rank+rj

end for
do lines 2730 for last zj1: = zl
/ iterate /
i++

19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
35:
36: end while
37: return PRI
rank pairs/

/ on-disk, sorted vertex/

Appendix C. Prefixes

In Table C.1, we provide the prefixes used throughout the paper.

Table C.1
CURIE prefixes used in this paper.

Prefix

Vocabulary prefixes
aifb:
b2r2008:
bio2rdf:
contact:
dct:
ecs:
fb:
foaf:
frbr:
geonames:
geospecies:
lld:
mo:
opiumfield:
owl:
po:
pres:
rdf:
rdfs:
sc:
sioc:
skos:
wgs84:
wn:
Instance-data prefixes
dav:
enwiki:
kingdoms:
vperson:

http://www.aifb.kit.edu/id/
http://bio2rdf.org/bio2rdf-2008.owl#
http://bio2rdf.org/bio2rdf_resource:
http://www.w3.org/2000/10/swap/pim/contact#
http://purl.org/dc/terms/
http://rdf.ecs.soton.ac.uk/ontology/ecs#
http://rdf.freebase.com/ns/
http://xmlns.com/foaf/0.1/
http://purl.org/vocab/frbr/core#
http://www.geonames.org/ontology#
http://rdf.geospecies.org/ont/geospecies#
http://linkedlifedata.com/resource/entrezgene/
http://purl.org/ontology/mo/
http://rdf.opiumfield.com/lastfm/spec#
http://www.w3.org/2002/07/owl#
http://purl.org/ontology/po/
http://www.w3.org/2004/08/Presentations.owl#
http://www.w3.org/1999/02/22-rdf-syntax-ns#
http://www.w3.org/2000/01/rdf-schema#
http://umbel.org/umbel/sc/
http://rdfs.org/sioc/ns#
http://www.w3.org/2004/02/skos/core#
http://www.w3.org/2003/01/geo/wgs84_pos#
http://xmlns.com/wordnet/1.6/

http://www.openlinksw.com/dataspace/org. . ./dav#
http://en.wikipedia.org/wiki/
http://lod.geospecies.org/kingdoms/
http://virtuoso.openlinksw.com/dataspace/
person/
