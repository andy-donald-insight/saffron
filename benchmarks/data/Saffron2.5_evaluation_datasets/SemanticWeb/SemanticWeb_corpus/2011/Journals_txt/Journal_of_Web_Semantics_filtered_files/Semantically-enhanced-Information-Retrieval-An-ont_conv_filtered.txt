Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 434452

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : h t t p : / / w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

Semantically enhanced Information Retrieval: An ontology-based approach
Miriam Fernandez a,

, Ivan Cantador b, Vanesa Lopez a, David Vallet b, Pablo Castells b, Enrico Motta a

a Knowledge Media Institute, The Open University, Milton Keynes MK7 6AA, United Kingdom
b Departamento de Ingenieria Informatica, Universidad Autonoma de Madrid, Madrid, Spain

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 20 January 2010
Received in revised form 26 October 2010
Accepted 30 November 2010
Available online 23 December 2010

Keywords:
Semantic Web
Information Retrieval
Semantic search

Currently, techniques for content description and query processing in Information Retrieval (IR) are based
on keywords, and therefore provide limited capabilities to capture the conceptualizations associated with
user needs and contents. Aiming to solve the limitations of keyword-based models, the idea of conceptual
search, understood as searching by meanings rather than literal strings, has been the focus of a wide body
of research in the IR field. More recently, it has been used as a prototypical scenario (or even envisioned
as a potential killer app) in the Semantic Web (SW) vision, since its emergence in the late nineties.
However, current approaches to semantic search developed in the SW area have not yet taken full advantage of the acquired knowledge, accumulated experience, and technological sophistication achieved
through several decades of work in the IR field. Starting from this position, this work investigates the definition of an ontology-based IR model, oriented to the exploitation of domain Knowledge Bases to support
semantic search capabilities in large document repositories, stressing on the one hand the use of fully
fledged ontologies in the semantic-based perspective, and on the other hand the consideration of
unstructured content as the target search space. The major contribution of this work is an innovative,
comprehensive semantic search model, which extends the classic IR model, addresses the challenges
of the massive and heterogeneous Web environment, and integrates the benefits of both keyword and
semantic-based search. Additional contributions include: an innovative rank fusion technique that minimizes the undesired effects of knowledge sparseness on the yet juvenile SW, and the creation of a largescale evaluation benchmark, based on TREC IR evaluation standards, which allows a rigorous comparison
between IR and SW approaches. Conducted experiments show that our semantic search model obtained
comparable and better performance results (in terms of MAP and P@10 values) than the best TREC automatic system.

O 2010 Elsevier B.V. All rights reserved.

1. Introduction

1.1. Motivation

With the continued growth of online information, the processes
of searching and managing massive scale content have become
increasingly challenging, bringing along the upsurge of huge new
markets. Major search engines, like Google,1 Yahoo!2 or Bing,3 are
constantly introducing new features to improve users search expe-
rience, including the introduction of novel mechanisms to handle
multimedia content4; the categorization of information sources such

 Corresponding author. Tel.: +44 1908 659400.

E-mail address: m.fernandez@open.ac.uk (M. Fernandez).

1 Google search engine, http://www.google.com/.
2 Yahoo! search engine, http://www.yahoo.com/.
3 Microsoft Bing search engine, http://www.bing.com/.
4 Google images, http://images.google.com/, Yahoo! images, http://images.search.
yahoo.com/, YouTube, http://www.youtube.com/, Yahoo! videos, http://video.yahoo.
com/.

1570-8268/$ - see front matter O 2010 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2010.11.003

as news, blogs, forums or books5; the introduction of metadata by
publishers to enhance the visualization of results6; or the use of personal and contextual information, such as social networks and loca-
tion, to particularize results according to users tastes, interests and
situations.7

Even though search engine technology has experienced impressive enhancements in the last decade, the content description and
query processing techniques Information Retrieval (IR) technology
currently builds upon are still mostly based on keywords, and
therefore provide limited capabilities to capture and exploit the
conceptualizations involved in user needs and content meanings.
For instance, limitations include the inability to account for relations between search terms (e.g., hurricanes originated in Mexico
vs.
hurricanes that have affected Mexico and books about
recommender systems vs. systems that recommend books), to

5 http://googleblog.blogspot.com/2009/10/refine-your-search-results-with-

new.html.

6 http://developer.yahoo.com/searchmonkey/.
7 http://www.google.com/ig/.

handle searches that involve a secondary sense of a term (e.g., Victor Valdes, the goal keeper vs. Victor Valdes, the video processing researcher) or to integrate information distributed over several
Web resources (e.g., searches regarding products or services).

Aiming to solve the limitations of keyword-based models, the
idea of semantic search, understood as searching by meanings
rather than literal strings, has been the focus of a wide body of research in the Information Retrieval (IR) and the Semantic Web
(SW) communities. However, these two fields have had a different
understanding of the problem.

Semantic search has been present in the IR field since the early
eighties [1], if not earlier [2]. Some of these approaches are based
on statistical methods that study the co-occurrence of terms
[3,4], and therefore they capture and exploit rough and fuzzy con-
ceptualizations. Other IR approaches apply linguistic algorithms
[5], modelled on human language processing structures and mech-
anisms, but rely on thesauri and taxonomies, where the level of
conceptualization is often shallow and sparse, especially at the level of relations, which are commonly at the core of expressing user
needs and finding the answers.

On the other hand, semantic search can be said to have become
one of the philosophers stones in the SW community since its
emergence in the late nineties. The SW vision was brought about
with the aim of helping automate tasks that require a certain level
of conceptual understanding of the objects involved (e.g., information objects) or the task itself, and enabling software programs to
automatically find and combine information and resources in consistent ways. At the core of these new technologies, ontologies [6]
were envisioned as key elements to represent knowledge that
could be understood, used and shared among distributed applications and agents. Their potential to overcome the limitations of
keyword-based search in the IR context was soon envisaged, and
was explored by several researchers in the SW area [79]. How-
ever, these approaches exhibit certain limitations like: (a) the still
sparseness of the available SW content [10], leading to knowledge
incompleteness when applying search to heterogeneous sources of
information, (b) the poor usability of the systems, specially at the
level of query, requiring users to manage complex languages or
interfaces to express their information needs, and (c) the lack of
ranking algorithms to cope with large-scale information sources,
etc. (see Section 2.3). One may say that the undertakings in information search and retrieval from the SW community have not yet
taken full advantage of the acquired knowledge, accumulated
experience, and theoretical and technical achievements developed
through several decades of work in the IR field tradition.

Starting from this position, and aiming to bridge the gap between these two communities, this work investigates the definition of an ontology-based IR model, oriented to the exploitation
of domain Knowledge Bases (KBs) to support semantic search
capabilities in large document repositories, stressing on the one
hand the use of fully fledged ontologies in the semantic-based per-
spective, and on the other the consideration of unstructured content as the target search space.
In other words, this work
explores the use of semantic information to support more expressive queries and more accurate results, while the retrieval problem
is formulated in a way that is consistent with the IR field, thus
drawing benefit from the state of the art in this area, and enabling
more realistic and applicable approaches.

1.2. Contributions

between both perspectives. Despite the large amount of work
on conceptual search in the IR field, semantic search has been
addressed as a refinement or smooth extension of traditional
IR techniques rather than as a radical new paradigm, until the
emergence of the SW. We study the strengths and weaknesses
of the proposals towards the semantic search paradigm from
both fields.

 Definition and realization of a novel semantic retrieval model. In
order to address the shortcomings in prior semantic search
approaches, this work proposes the exploitation of fine-grained
domain ontologies and KBs to improve semantic retrieval in
large repositories of unstructured information, extending the
general ontology-based search capabilities towards more
widely applicable IR-oriented search capabilities.

 Investigation of the feasibility of semantic retrieval in the Web
environment. As a step towards a proof of concept of the feasibility of semantic retrieval within large-scale and heterogeneous
environments, the proposed model is modified to address scala-
bility, heterogeneity and usability challenges.

 Creation of semantic retrieval evaluation benchmarks. The standardization of experimental practice in keyword-based IR has
come a long way. In contrast, there is not an equivalent body
of methodologies and datasets for the evaluation of semantic
retrieval models. This work aims to take a step forward, starting
from traditional IR evaluation measures and datasets to provide
evaluation
retrieval
technologies.

ontology-based

benchmarks

for

1.3. Structure of the paper

The rest of the paper is organized as follows. Section 2 describes
related work in both the IR and SW areas, and addresses a common
understanding of what semantic search is, and where we are
standing in the progress towards semantic Information Retrieval.
Section 3 presents a semantic search approach that combines, under a common model, the main achievements in semantic search
from the IR and SW perspectives. Section 4 presents the research
done to scale the above model to an open, massive and heterogeneous environment such as the Web. The evaluation of the
Web extended model is reported in Section 5. Conclusions and
future work are presented in Section 6.

2. Related work

Any IR system is based on a logic representation of user information needs, and the information supplied by the information objects in the search space, in such a way that the comparison
between queries and potential answers takes place in the ideal
model. The various logic representations proposed in the area
[11] respond, on the one hand, to the requirement of being efficiently processable by an IR system, and necessarily entail some
information loss. This is clear, for instance, in the representation
of information needs by a simple list of keywords, as is the case
in currently dominant paradigms in both research and industry.

An important aspect of semantic search approaches is that practically all of them use conceptual representations of content beyond plain keywords, and many of them also attempt to provide
conceptual representations of user needs, as a way to enhance
mainstream IR technologies.

Our contributions fall into four major categories:

2.1. Semantic search: an IR perspective

 Better understanding of the semantic search problem, the potential
of semantic enhancements in IR technology, the current achievements from the IR and SW fields, and the fundamental differences

The elaboration of conceptual frameworks and their introduction in IR models have wide precedents. For instance, Croft [1] proposed a representation where domain knowledge is modelled by a

M. Fernandez et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 434452

thesaurus of concepts, each one having a name, some relations to
other concepts, and a list of more or less ad-hoc rules (defined
on a per-case basis) to recognize the concepts in a textual passage.
The considered relations between concepts included synonymy,
hyponymy and instantiation, meronymy and similarity. These concepts and relations are used to expand both queries and document
indexing entries. Aware of the cost of producing domain knowl-
edge, Croft suggested using such knowledge as an enabler of incremental improvement over purely statistical methods, in such a
way that the performance of the latter is retained in the absence
or incompleteness of the former.

Crofts work is representative of a trend which, during the same
period, attempted to enhance the performance of IR systems by
strengthening content representation through the use of conceptual abstractions. In this line, and possibly under the influence of
knowledge based systems in the Artificial Intelligence area, several
approaches in the eighties investigated the use of semantic networks to enrich the representation of the indexing terms [12,13].
The idea of augmenting the semantic representation of a document beyond a set of plain words is in fact present in earlier works
to those decades, such as Karen Sparck Jones PhD thesis [14]. In it,
the author reflects on the flexible, non univocal correspondence
between words and meanings, and the role of relations between
words (synonymy, antonymy, hyponymy, entailment, and others)
in the description of meanings. Her work considers the notion of
predefined semantic primitives, consisting in essence of (domain-
specific or generic) concepts taken from a thesaurus (the Rogets
[15]), which are automatically extended with emergent semantic
entities, observable in the analysis of a text corpus.

Considerable research followed in which several authors have
kept progressing on conceptual approaches to IR based on domain
knowledge. One of the pursued lines in this direction is the one
based on linguistic approaches, among which the use of resources
like WordNet8 is particularly representative of the use of explicit
conceptual descriptions [16,17].

Beyond WordNet, or complementarily to its use, many works
have explored the use of thesauri with a lower or higher specialization level to introduce enhancements in search effectiveness
[18,19]. One of the most common uses of thesauri in this context
is the expansion of query terms, based on the mapping of query
words to thesauri elements, and the extension of the latter through
their relations to other terms in the thesauri.

From a very different starting point, the idea of raising IR techniques to a higher conceptual level is also present in Latent Semantic Analysis (LSA) techniques, widely studied and applied in diverse
domains [3]. As distinct from thesauri-oriented techniques, concepts emerge in LSA by means of algebraic methods, based on
the frequency of words in the documents of a corpus.

2.2. Semantic search: a SW perspective

The introduction of ontologies to move beyond the capabilities
of current search technologies has been an often portrayed scenario in the area of semantic-based technologies since the late
nineties [20]. Compared to what is usual in thesauri, the emphasis
on formalization is much higher in ontologies, which seek to describe the world (or at least a domain) on the basis of a descriptive
logic that axiomatizes the ontology classes, their relations, and the
properties of both (symmetry, transitivity, equivalences, etc.) in
suitable terms to be formally reasoned upon.

In contrast with the standard IR model, a number of systems referred to as semantic search systems in the SW area, provide
search mechanisms over a single KB rather than documents. Hence

8 http://wordnet.princeton.edu/.

here the emphasis is on developing mechanisms that are able to
capture user queries and convert them to a formal query represen-
tation, e.g., SPARQL. In general, this vision makes sense when the
whole information corpus can be fully represented as a formal
KB. But there are limits to the extent to which knowledge can be
formalized in this way. The so-called semantic portals [7,21] and
ontology-based Question Answering systems [22,23] are examples
of this approach.

There are nonetheless approaches in this context that explicitly
consider keeping, along with the domain ontologies and KBs, the
original documents in the retrieval model, where the relations between ontologies and documents are established by annotation
relations. In this line, KIM [9,24], TAP [8] and more recently, Ha-
kia,9 are examples of wide-ranging achievements on the construction of high-quality KBs, and the automatic annotation of
documents on a large scale.

While these approaches are focused on knowledge extraction
from text, recent solutions like Powerset10 aim to exploit existing
and publicly available metadata, like the one generated as part of
the Linked Open Data (LOD) initiative,11 and provide this knowledge
in combination with textual documents. In the particular case of
Powerset, FreeBase12 and Wikipedia13 are integrated as the main
metadata and textual information sources respectively.

Finally, an interesting trend of semantic search in recent years is
the use of explicit metadata provided by publishers. These metadata are embedded in Web pages using RDFa,14 or Microformats15 and
exploited by commercial search engines, like Yahoo! Search Mon-
key,16 or Google Rich Snippets,17 to enhance the visualization of
results.

2.3. Classification and limitations of semantic search approaches

The classification of semantic search approaches is complex, not
just because of their diversity, in the sense of how differently this
problem has been approached in the literature, but also because of
the large number of dimensions involved in the information search
task. This section proposes a set of general criteria under which SW
and IR approaches can be classified and compared, identifying their
key advantages and limitations.

The classification criteria are summarized in Table 1 and

comprise:

Semantic knowledge representation: three main trends can be
distinguished in the literature based on the type and use of semantic knowledge representation: (a) statistical approaches, like LSA [3],
use statistical models to identify groups of words that commonly
appear together, and therefore may jointly describe a particular
reality; (b) linguistic conceptualization approaches [5,17,25] are
based on light conceptualizations, usually considering few types
of relations between concepts, and low information specificity lev-
els; and (c) ontology-based proposals [8,24] consider a much more
detailed and densely populated conceptual space in the form of
ontology-based KBs.

Scope: semantic search has been applied in different environments such as the Web [26,27], controlled repositories [24], or even
the desktop [28]. Obtaining conceptualizations to cover the
meanings involved in all Web content as well as the automatic

9 http://www.hakia.com/.
10 http://www.powerset.com/.
11 http://linkeddata.org/.
12 http://www.freebase.com/.
13 http://www.wikipedia.org/.
14 http://http://www.w3.org/TR/xhtml-rdfa-primer/.
15 http://microformats.org/.
16 http://developer.yahoo.com/searchmonkey/.
17 http://googlewebmastercentral.blogspot.com/2009/05/introducing-rich-
snippets.html.

Table 1
Semantic search systems classification.

Criterion

Approaches

Semantic knowledge

representation

Scope

Query

Statistical
Linguistic conceptualization
Ontology-based

Web search
Limited domain repositories
Desktop search

Keyword query
Natural language query
Controlled natural language query
Structured query based on ontology query languages

Content retrieved

Content ranking

Data retrieval
Information Retrieval

No ranking
Keyword-based ranking
Semantic-based ranking

annotation of these conceptualizations with some degree of completeness is still an open challenge. Restricting themselves to more
reduced environments, many systems have been developed and
tested over controlled repositories, where the available information is enclosed in one or few domains of knowledge. In a third
degree of complexity, the desktop environment provides easier
ways to extract the semantic information from semi-structured
contents such as e-mails, folders, etc. Some works do not explicitly
state their potential or limitations in scope and scale, but the
considerable computational complexity involved in their methods
(see, e.g., [25]) leaves scalability (in particular, Web scalability) as a
non addressed issue.

Query: another relevant aspect that characterizes semantic
search models is the way the user expresses his information
needs. Four different approaches can be identified in the state
of the art, according to a gradual increase of their level of formality and usage complexity. At a first level, queries are expressed by
means of keywords [8]. This is the most traditional way of consul-
tation, but also the least expressive one, since the information
need is represented as a set of terms without any explicit relation
between them. A second level involves a natural language representation of the information need [29]. This kind of query provides more information than the keyword-based approach since
a linguistic analysis can be performed to extract syntactic infor-
mation, such as subject, predicate, object and other details of
the sentence. A third level in formality is portrayed by controlled
language systems [22,25,30], where the query may be
natural

Table 2
Limitations of semantic search approaches.a

Criterion

Limitation

expressed by adding tags that represent properties, values or objects within the consultation or by more sophisticated methods
like [25], which builds a logic-based approach on top of WordNet
synsets. These types of queries can be more easily processed and
mapped to the corresponding classes, properties and values of a
schema or ontology describing the search space, thus facilitating
the acquisition of semantically related information. Finally, the
most formal ontology-based search systems use ontology-query
languages such as RDQL [31] and SPARQL [32]. The full expressive
power of this kind of query allows the system to automatically
retrieve in a highly precise way the information that satisfies
the users need. These systems, which demand a high formalization of queries, tend to be impractical from a usability point of
view. On the other hand, it can be argued that increasing the
expressivity of queries helps to improve the quality of results,
since the returned results must strictly hold all the conditions
of the formal query and therefore, they are assumed to be 100%
precise. A trade-off between usability and query expressivity
should be achieved, bringing an inherent degree of fuzziness
during the data search process.

Content retrieved: semantic retrieval approaches can be characterized by whether they aim at data or Information Retrieval.
While the majority of IR approaches return documents as response
to user requests, and therefore should be classified as information
retrieval models, a large amount of ontology-based approaches return ontology instances rather than documents, and therefore
may be classified as data retrieval models. A data retrieval model
makes sense when the whole information corpus can be fully represented as a KB. However, converting the huge amount of information available worldwide, in the form of unstructured text and
media documents, into formally characterized knowledge at an
affordable cost is currently an unsolved problem.

Content ranking: While IR approaches have traditionally addressed the ranking of documents, most ontology-based approaches do not consider ranking query results in general, or
base their ranking functionality on traditional keyword-based approaches [8]. A few approaches take advantage of semantic information to generate query result rankings, but generally KB
instances rather than documents are ranked [33]. These methodologies are not yet adapted to large and heterogeneous environments
(e.g., the Web) where the majority of content is still unstruc-
tured.The set of limitations associated to each of the previously
mentioned classification criteria is summarized in Table 2.

As shown in Table 2, out of the selected criteria, two additional
major open issues in ontology-based search approaches can be
pointed out.

Semantic knowledge representation

Scope

Goal

Query

Content retrieved

Content ranking

Coverage

No exploitation of the full potential of an ontological language,
beyond those that could be reduced to conventional classification schemes

No scalability to large and heterogeneous repositories of documents

Boolean retrieval models where the Information
Retrieval problem is reduced to a data retrieval task

Limited usability

Focus on textual content: no management of different
formats (multimedia)
Lack of semantic ranking criterion. The ranking
(if provided) relies on keyword-based approaches

Additional Limitations

Knowledge incompleteness

(Partially)

(Partially)

Semantic

(Partially)

(Partially)

Evaluation
a The last two columns of this table identify if the limitation refers to IR or semantic-based knowledge technologies approaches. Note that the notation (
, partially) has

Lack of standard evaluation frameworks

been used for simplification purposes. An 
 does not refer to all the approaches, but to the majority of the studied systems.

M. Fernandez et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 434452

 The problem of knowledge incompleteness: the difficulties and
cost of building and maintaining rich semantic resources is a
well-known fundamental hurdle, already identified by the earliest works in the field [1]. A fundamental issue here is to discern what level of detail (depth) and coverage (breadth) is
appropriate, and how well we may cope with the remaining
incompleteness beyond that point. A potential way to satisfy
the latter is by means of a graceful degradation to a classic IR
system which gets by without semantics when there is insufficient domain knowledge.

 The problem of evaluating semantic search models: while IR systems traditionally compete against each other under formal
evaluation frameworks, e.g., at the annual TREC conference,18
or using published datasets, there are no standard evaluation
measures or benchmarks for ontology-based retrieval and, fur-
thermore, there is not a well established evaluation methodology.
To the best of our knowledge, none of the ontology-based retrieval approaches reported in the literature have been validated in
such rigorous ways. A partial exception is recent work by Giunchiglia et al. [25], although the work is focused on WordNet, thus
leaving the integration of domain ontologies with TREC as an
open problem, and does not report improvements with respect
to the performance of the best TREC systems.

3. An ontology-based IR model

Our approach builds upon principles from Castells et al. [34],
where a general framework to leverage ontologies in the frame of
a traditional vector space IR model is developed. In our present work,
we address the further challenges involved in making the approach
feasible on large and heterogeneous information repositories, as
required to target practical and realistic settings such as the Web.
Furthermore, we seek to devise a methodological approach supporting a formal evaluation of the ontology-based search approach in the
spirit and standards of conventional IR practice.

The proposed extensions over an ontology-based IR model and
the complete evaluation of the model are presented in Sections 4
and 5 respectively. In this section, we provide a brief overview of
the original base model, which provides the ground foundation
for the research presented herein. For specific details about this
model and its evaluation, see Ref. [34].

The core semantic search model is based on an adaptation of the
classic keyword-based IR model [35]. It spans the four main processes of an IR system: indexing, querying, searching and ranking
(Fig. 1). However, as opposed to traditional keyword-based IR mod-
els, in our approach, the query is expressed in terms of an ontologybased query language (SPARQL), and the external resources used
for indexing and query processing consist of an ontology and its
corresponding KB. The indexing process is equivalent to a semantic
annotation process. Instead of creating an inverted index where the
keywords are associated with the documents where they appear, in
the case of our ontology-based IR model, the inverted index contains semantic entities (meanings) associate to the documents
where they appear. The relation or association between a semantic
entity and a document is what we call annotation.

The overall retrieval process consists of the following steps:

1. The system takes as input a formal SPARQL query.
2. The SPARQL query is executed against a KB, returning a list of
semantic entities that satisfy the query. This process is purely
Boolean (i.e., based on an exact match), so that the returned
instances must strictly hold all the conditions of the formal
query.

18 Text REtrieval Conference (TREC), http://trec.nist.gov/.

Fig. 1. Graphical representation of the proposed semantic retrieval framework.

3. The documents that are annotated (indexed) with the above
instances are retrieved, ranked, and presented to the user. In
contrast to the previous phase, the document retrieval phase
is based on an approximate match, since the relation between
a document and the concepts that annotate it has an inherent
degree of fuzziness.

The steps listed above are described in more detail in the following subsections, from indexing to query processing, document
retrieval and ranking.

3.1. Semantic indexing

In our view of semantic IR, it is assumed that a KB has been
built and associated to the information sources (the document
base), by using one or several domain ontologies that describe
concepts appearing in a document
text. The concepts and
instances in the KB are linked to the documents by means of ex-
plicit, non-embedded annotations of the documents. Since we do
not address the problem of knowledge extraction from text
[9,21,24,36,37], we provide a vocabulary and some simple mechanisms to aid in the semi-automatic annotation of documents,
once ontology instances have been created (manually or auto-
matically).

These annotations are later used during the retrieval and
ranking processes. As we shall describe in the next subsection,
the ranking algorithm is based on an adaptation of the classic
IR vector space model [38]. In this model, keywords appearing
in a document are assigned weights reflecting the fact that some
words are better at discriminating between documents than
others. Similarly, in our system, annotations are assigned weights

that reflect the discriminative power of instances with respect to
the documents. Weights are computed automatically by an
adaptation of the TF-IDF algorithm [38], based on the frequency
of occurrence of the instances in each document. More specifi-
cally, the weight dx of an instance x for a document d is
computed as:

dx 14 freqx;d

maxyfreqy;d

	 log;

jDj
nx

where freqx,d is the number of occurrences in d of the keywords attached to x, maxyfreqy,d is the frequency of the most repeated instance in d, nx is the number of documents annotated with x, and
D is the set of all documents in the search space.

3.2. Querying, searching and ranking

The query execution returns a set of tuples that satisfy the
SPARQL query. We then extract the semantic entities from those
tuples and access the semantic index to collect all the documents in the repository that are annotated with these semantic
entities. Once the list of documents is formed, the search engine
computes a semantic similarity value between the query and
each document, using an adaptation of the classic vector space
IR model.

As shown in Fig. 2, each document in the search space is represented as a document vector where each element corresponds to a
semantic entity. The value of an element is the weight of the annotation between the document and the semantic entity, if such
annotation exists, and zero otherwise. The query vector is generated weighting the variables in the SELECT clause of the SPARQL
query. For testing purposes, the weight of each variable of the
query was set to 1, but in the original model, users are allowed
to manually set this weight according to their interest. Once the
vectors are constructed, the similarity measure between a document d and the query q is computed as:

simd; q 14 d 
 q
jdj 	 jqj

3.3. Dealing with the problem of knowledge incompleteness: rank
fusion

If the knowledge in the KB is incomplete (e.g., there are documents about travel offers in the knowledge source, but the corresponding instances are missing in the KB), the semantic ranking
algorithm performs very poorly: SPARQL queries will return less
results than expected, and the relevant documents will not be re-
trieved, or will get a much lower similarity value than they should.
As limited as might be, keyword-based search will likely perform
better in these cases. To cope with this, our ranking function combines the semantic similarity measure with the similarity measure
of a keyword-based algorithm.

Combining the output of several search engines has been a
widely addressed research topic in the IR field [39,40]. After testing
several approaches, we selected the so-called CombSUM strategy
[41], which has been found to be among the most simple and effective in prior works, and consists of computing the combined ranking score by a linear combination of the inputs. That is, in our case
the final score is k 	 sim(d,q) + (1  k) 	 ksim(d,q), where ksim is
computed by a keyword-based algorithm, and k 2 [0,1]. We set
k = 0.5, which seemed to perform well in our experiments. Obvi-
ously, for the combination of scores to make sense, the scores have
to be first made comparable, which involves a normalization step.
For this purpose, we use our own optimized normalization method
[42], which not only scales the scores to the same range (the [0,1]
range) as other standard approaches proposed in the literature do
[40], but also undoes potential biases in the distribution of the
scores.

4. Semantic retrieval on the Web

The semantic search model detailed in Section 3, as well as
other semantic approaches that have proved to work well in specific domains [9,28], still have to undertake further steps towards
an effective deployment of semantic search on a decentralized,
heterogeneous, dynamic and massive repository of content such
as the Web. Accomplishing this objective involves tackling several
problems such as:

Fig. 2. Adaptation of the classic vector-space model.

M. Fernandez et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 434452

across complex forms to formulate their queries. To address this
problem we propose the integration of a new query module that
allows users to express their requirements using natural
language.

Fig. 3 shows the extensions performed over the previous framework in order to address the above mentioned challenges. Three
main changes can be perceived in the architecture:

 The queries are not expressed using ontology-based query lan-
guages. Instead, queries are expressed in natural language as a
compromise between expressivity and usability.

 The external resources for indexing and query processing are
not a single ontology and KB, but online available SW
information.

 In order to manage large amounts of semantic information during the query and annotation processes, a SW gateway is incorporated with the aims of gathering, storing and accessing the
online distributed semantic information.

The overall retrieval process is illustrated in Fig. 3, and consists

of the following steps:

1. The system takes as input a users natural language (NL) query.
This query is processed by the query processing module, which
has been replaced by an ontology-based Question Answering
(QA) system, PowerAqua [29]. This component operates in a
multi-ontology scenario where it translates the user terminology into the ontologies terminology. The integration of this
QA system into our framework brings two clear benefits to
our approach. First, the user interaction is eased by allowing
natural language queries, improving the usability of the system.
Second, the response is obtained from a large set of ontologies
covering a potential unrestricted set of domains, therefore dealing with the heterogeneity limitation.

2. Once the pieces of relevant ontological knowledge have been
returned as an answer to the users query, the system performs
a second step to retrieve and rank the documents containing
this information. To do so, the document collection is automatically indexed in terms of the ontology concepts prior to the use
of the system. The indexing module has been changed to integrate scalable and flexible annotation algorithms. These new
indexing algorithms are able to deal with large document collections and large amounts of ontologies and KBs. Exploiting
large amounts of metadata brings the advantage of retrieving
Web documents without any potential domain restriction,
therefore addressing the heterogeneity limitation.

3. The final output of the system consists of a set of ontology elements that answer the users question and a complementary list
of semantically ranked relevant documents.

The details of how the main functionalities of our approach
(document indexing, query processing, searching and ranking)
have been adapted to exploit the information spaces defined by
the SW and the (non-semantic) WWW are explained in the following subsections.

4.1. Indexing

In the proposed view of semantic search, it is assumed that the
information available in standard Web pages (the document base)
is indexed using the semantic knowledge found in the SW. A key
step in achieving this aim lies on linking the semantic space to
the unstructured content space by means of the explicit annotation
of documents with semantic data. In such a dynamic and changing
environment, annotation must be done in a flexible and scalable

Fig. 3. Semantic search framework extensions.

 Heterogeneity. The experiments described in Ref. [34] are based
on the KIM KB. This ontology provides a reasonably good coverage of knowledge areas of general importance (geographical
locations, organizations, etc.). Nonetheless, the contents available on the Web range over a potentially unlimited number of
domains. Therefore, substantially better means to procure
proper knowledge coverage levels are required. To address this
problem we propose: (a) the generation of a SW gateway that
provides access to large amounts of online available semantic
metadata (Section 4.4) covering a significant number of
domains and (b) the adaptation of the previous model to exploit
the semantic information provided by the SW gateway. This
information is used at indexing time (Section 4.1) and at query
time (Section 4.2), to improve the domain coverage.

 Scalability. Scalability issues are still a pervading open problem
in ontology-based technologies. A popular example of this is
Powerset,19 whose coverage is limited to Wikipedia. Scaling our
model to the Web environment implies, on the one hand, to
exploit all the increasing available semantic metadata in order
to provide a good coverage of topics and, on the other hand, to
manage huge amounts of information in the form of unstructured
content. To address this problem we propose the creation of scalable and flexible annotation processes that associate Web contents with semantic metadata, while still keeping the two
spaces (content and metadata) decoupled (Section 4.1).

 Usability. Another important requirement in order to extend our
ontology-based retrieval model to the Web environment is to
provide users with an easy to use query user interface (Sec-
tion 4.2). This means not to require users to have previous
knowledge of ontology-based query languages, or to navigate

19 http://www.powerset.com/.

way. As we explain in the following sections, the solutions explored in this work do not require hardwiring the links between
Web pages and semantic markup. On the contrary, these are created dynamically in such a way that the two information sources
may remain decoupled.

Similarly to traditional IR techniques, which base their ranking
algorithms on keyword weighting, our approach relies on measuring the relevance of each individual association between semantic
concepts and Web documents. In this case, not just the retrieval
process, but also the ranking of query answers can take advantage
from the available semantic information.

Two different annotation methodologies are studied. The fist
one uses Information Extraction methodologies in order to identify
in the documents words or groups of words that can potentially
represent semantic entities (classes, properties, instances or liter-
als). The second one uses a more scalable approach based on statistical occurrences of semantic entities and their contextual
semantic information. Both annotation procedures have been designed considering a set of common requirements:

 The semantic annotator identifies ontology entities (classes,
properties, instances or literals) within the text documents,
and generates the corresponding annotations. This is equivalent to a traditional IR indexing process where the indexing
units are ontology entities (word senses) instead of plain
keywords.

 The annotation processes carried out do not aim to populate
ontologies, but to identify already available semantic knowledge within the documents. In this way, the semantic information and the documents remain decoupled.

 Differently to other large scale annotation frameworks, our system has been designed to support annotation in open domain
environments. Any document can be associated or linked to
any ontology without any predefined restriction. The exploitation of massive amounts of metadata and documents introduces
scalability limitations. To address them, we propose the use of
ontology indices, document
indices, and non-embedded
annotations:
 Generation of ontology indices: We envision a scenario
where the annotation module may need to interact with
thousands of KBs structured in hundreds of ontologies. To
successfully manage such amount of information on real
time, the ontologies and KBs are analyzed and stored into
one or more inverted indices using Lucene.20 This index
structures are part of the SW gateway module explained in
Section 4.4.1.

 Generation of document indices. A massive amount of
unstructured content is currently available on the Web. To
successfully manage such amount of information on real
time, Web documents are pre-processed and stored in one
or more inverted indices using Lucene.

 Construction of the annotation database. In contrast to systems where annotations are embedded in the ontologies or
documents, the proposed mechanism generates non-embed-
ded annotations. These annotations are stored in a relational
database, increasing the efficiency of the retrieval phase. For
each annotation, an entry is generated in the database. This
entry contains the identifiers of the corresponding semantic
entity (word sense) and document, as well as a weight indicating the degree of relevance of the semantic entity within
the document. Weights are automatically computed using
different techniques for the two proposed annotation processes (see below).

In the following sections, we present the two implemented
annotation processes. The first one analyzes textual documents
using Natural Language Processing (NLP) techniques, extracts
information from those documents, and maps it with the semantic
information stored in the ontologies and KBs. The second one
works in the opposite direction. It analyzes the semantic information stored in ontologies and KBs and, considering each ontology
entity and its semantic context, attempts to identify the semantic
entities within the textual documents to generate new annotations.

4.1.1. Annotation by NLP

Using Wraetlic NLP tools [43], the annotation module analyzes
the textual documents, removes stop words, and extracts relevant
(simple and compound) terms, categorized according to their Part
of Speech (PoS): nouns, verbs, adjectives, adverbs, pronouns, prep-
ositions, etc. Then, terms are morphologically compared with the
names of the semantic entities of the domain ontologies. The comparisons are done by using an ontology index created with Lucene
(Section 4.4.1), and according to fuzzy metrics based on the
Levenshtein distance [44]. For each term, if similarities above a certain threshold are found, the most similar semantic concepts are
chosen and added as annotations of the document. After all annotations are created, a TF-IDF technique computes and assigns
weights to them. Fig. 4 shows a more detailed view of the annotation mechanism, which takes as input the HTML document to
annotate, and the ontology indices, and returns as output new entries for the annotation database. The steps followed are:

1. The textual Web documents are parsed to erase meaningless (in

terms of essential content to be conveyed) HTML tags.

2. The remaining text is analyzed by the Wraetlic tools to extract

the PoS and the stem of each term.

3. The information provided by the linguistic analysis is used to
filter the less meaningful terms or stop words (determinants,
prepositions, etc.), and to identify those sets of terms that can
operate as individual information units.

4. The filtered terms are searched in the ontology indices, obtain-

ing the subset of semantic entities to annotate.

5. The annotations are weighted according to the semantic entity
frequencies within individual documents and the whole
collection.

6. The annotations are added to a relational database.

4.1.1.1. Enhancing the accuracy of annotations. The use of a potentially unlimited number of domain ontologies ad KBs increases
the uncertainty of the annotations, since more morphological similar concepts (with divergent meanings) can be found. To address
this limitation, we propose to exploit the PoS information provided
by Wraetlic NLP tools in order to identify and discard those words
that typically do not provide significant semantic information.
Moreover, the approach attempts to group sets of words that can
operate as individual semantic information units. The empirically
identified patterns are the following:

 Noun + noun, e.g., tea cup.
 Proper noun + proper noun, e.g., San Francisco.
 Proper noun + proper noun + proper noun, e.g., Federico Garcia

Lorca.

 Abbreviation + proper noun + proper noun, e.g.,

F. Garcia

Lorca.

 Abbreviation + abbreviation + proper noun, e.g., F. G. Lorca.
 Participle + preposition, e.g., located in, stored in.
 Modal verb + participle + preposition, e.g., is composed by, is

20 http://lucene.apache.org/java/docs/index.html.

generated with.

M. Fernandez et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 434452

Fig. 4. Document annotation by NLP.

4.1.1.2. Weighting annotations. As in the base model (Section 3.1),
annotation weights are computed automatically by an adaptation
of the TF-IDF algorithm, based on the frequency of the occurrences
of each semantic entity within the document. The number of
occurrences of a semantic entity in a document is primarily defined
as the number of times any of its associate keywords appears in the
document text. In our first experiments, we observed that quite a
number of occurrences were missed in practice, since the algorithm was not considering pronouns as semantic entity occur-
rences. To mitigate this
the
algorithm has been introduced to count pronoun occurrences in
the scope of a sentence if a noun-based semantic entity has been
previously identified.

limitation, a modification of

The Wraetlic tools use the PoS tags of the Penn Treebank cor-
pus.21 These PoS classification distinguishes between four different
types of nouns (NN Noun singular or mass, NNS Noun plural, NNP
Proper noun singular and NNPS Proper noun plural) and four different types of pronouns (PRP Personal pronoun, PRP$ Possessive pro-
noun, WP Wh-pronoun and WP$ Possessive Wh-pronoun). Whpronouns are not used for counting additional occurrences. In the
rest of the cases, the following simple rules are followed:

 A PRP$ refers to the previous NNP or NNPS if it exists and their

numbers (singular, plural) agree.

 A PRP refers to the previous NNP or NNPS if it exists and their
numbers (singular, plural) agree, except in the case of the pronoun it (it always refers to the previous NN).

Note that these rules do not cover all the cases and, therefore,
not all pronoun occurrences are taken into account. However, we

21 The Penn Treebank Project, http://www.cis.upenn.edu/treebank/.

observed that, following these simple rules, most of the identified
pronoun occurrences were correctly associated with their corresponding semantic entity. As future research work, we plan to exploit current state of the art techniques in coreference resolution
[45] to detect not only pronouns (he), but also nominal (president)
and proper (Barak Obama) mention types. While this modification
in the weighting algorithm does not help to increase the correctness of the annotations, or to obtain new ones, it enhances the
accuracy of the annotation weights that will be later used in the
ranking process.

4.1.2. Annotation based on contextual semantic information

In the NLP based annotation mechanism, the documents are
analyzed to filter the terms that have to be searched in the semantic entity index. Here, instead, the semantic entities are those analyzed and searched in the document index, a standard keywordbased index generated prior to the annotation process. Inverting
the direction of the annotation process from semantic entities to
documents, provides two important advantages: on the one hand,
the semantic information stored in the ontologies and KBs can be
used as background knowledge to improve the accuracy of the
annotations; on the other hand, the computational cost decreases
because the textual documents have been indexed in advance. This
new annotation schema constitutes a more scalable and widely
applicable approach because it can potentially use any keywordbased document index. The overall annotation process is shown
in Fig. 5, and consists of the following steps to be performed for
every semantic entity in every ontology:

1. Load the information of a semantic entity, that is, extracting the
textual representation of the selected entity. Each entity may
have one or more textual representations in the ontology. For

Fig. 5. Document annotation based on contextual semantic information.

instance, the individual entity describing the football player
Maradona can be named as Maradona, Diego Armando Mar-
adona, Pelusa, etc. Here, we assume that such lexical variants
are present in the ontology as multiple values of the local name
or rdfs:label property of the entity.

2. Find the set of potential documents to annotate. The textual
representations of the entity are then searched in the document
index using standard searching and ranking techniques. The
retrieved documents simply contain the textual representation
of the entity, which does not necessarily imply that they contain its meaning. The disambiguation process is performed in
the subsequent steps by exploiting the context of the entity in
the ontology.

3. Extract the semantic context of the entity. The meaning of an
entity is determined by the set of concepts it is related to in
the domain ontology. To ensure that the entity annotates the
appropriate set of documents, the ontological relations are
exploited to extract its semantic context, that is, the set of entities directly linked in the ontology by explicit relations. Following the example described in Fig. 5, the semantic context of the
entity Maradona in the ontology is formed by the entities football player and Argentina.

4. Find the set of contextualized documents. The textual representations of entities belonging to the semantic context are then
searched in the document index to extract the set of contextualized documents. In the example, the textual representations
Argentina and football player are used to extract the set
of contextualized documents.

5. Select the final list of documents to annotate. We compute the
intersection between the set of documents containing any textual representation of the entity (extracted in step 2), and the
set of documents containing any textual representation of its

semantic context (extracted in step 4). Documents in this intersection are not just likely to contain the corresponding entity,
but also the contextual meaning of the entity in the ontology.
In our example, this documents do not contain only any of
the textual representations of the concept Maradona, but also
at least one of the textual representations of its semantic context (football player, Argentina).

6. Create the annotations. A new entry or annotation is created for
each document in the previous intersection. The annotation is
assigned a weight indicating the degree of relevance of the
entity within the document. The algorithm to calculate this
annotation weight is explained below.

4.1.2.1. Enhancing the accuracy of annotations. As described previ-
ously, to reduce the ambiguity of annotations, the context of the
semantic entities is taken as background information. The context
of a semantic entity is defined as the set of entities directly linked
to it in the ontologies by explicit relations. Using this context, we
are able to annotate entities with documents that contain the ontological meaning of the semantic entity. We have empirically observed that this technique brings a considerable precision gain,
but at the expense of losing an important number of annotations.
A potential cause of this problem is the low density of relations
supported in the SW ontologies [46,47]. There are cases where
the ontologies do not have enough contextual information to identify the meaning of the entity in the document, and, therefore, the
annotation is not created. This trade-off between the quality and
the quantity of annotations is further investigated in Section 5.3.2.

4.1.2.2. Weighting annotations. In both the base model and the NLPbased annotation schemas, annotations weights are computed

M. Fernandez et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 434452

automatically by an adaptation of the TF-IDF algorithm based on
the frequency of the occurrences of each semantic entity within
the document [34]. In the contextual annotation approach, the
annotation weights are computed as follows:

 A fusion technique, described in Ref. [58], is applied to the
ranked lists of documents obtained from steps 2 and 4 to produce a ranked list S of documents, candidates to be annotated,
and a ranked list C of contextualized documents for semantically related entities.

 A document d appearing in both lists S and C is selected for
annotation
a weight
k 	 Sd + (1  k) 	 Cd, where k is a constant used control the influence of the semantic contextualization, Sd is the score of document d in the ranked list S, and Cd is the score of document d in
the ranked list C. A value of k = 0.6 was empirically found to
work well in our experiments.

assigned

step

by

5,

and

is

This annotation weighting approach is less sensitive to potential changes in the ontologies and KBs. When a new semantic entity is added or modified, it is only necessary to recompute its
annotations, and the annotations of the semantic entities directly
linked to it in the ontologies and KBs. However, it presents one
main trade-off: the use of document ranking scores to compute
the annotation weights introduces a loss of accuracy with respect
to our previous weighting techniques.

4.2. Query processing

As already mentioned, most semantic search systems suffer
from one of two following limitations when attempting to enhance
the conceptual representation of user needs beyond plain key-
words: (a) usability limitations, where users are expected to use
formal query languages to express their requirements and (b) heterogeneity limitations, where a predefined (usually small) set of
ontologies is used as the target data set.

Aiming to overcome these limitations, we use an ontologybased QA system, PowerAqua [29], as the query processing mod-
ule. PowerAqua is able to answer queries by locating and integrating information, which can be massively distributed across
heterogeneous semantic resources. To do so, PowerAqua initially
uses syntactic techniques to identify those semantic resources
which may be relevant to the user query. In many cases this initial
syntactic match will generate several possible candidates (i.e.,
semantic entities), which may provide potential alternative interpretations for a query term. Hence, to address this problem, PowerAqua builds on techniques developed in the Word Sense
Disambiguation community, to disambiguate between different
possible interpretations of the same query term within an ontology
or across several ones. In particular, PowerAqua makes use of the
context of the user query, the context surrounding candidate entities in their ontologies, and the background knowledge provided
by WordNet to determine the most likely interpretation or a user
query as whole and the individual terms in the query.

For instance, lets consider the query Rock musicians in Britain.
Firstly, PowerAqua parses the query and translates it into a set of
linguistic triples: hrock, ?, musiciansi, hmusicians, ?, Britaini. In a second step, PowerAqua then searches for approximate syntactic
matches of these linguistic triples in the ontologies, using not just
the terms in the triples, but also lexically related words obtained
from WordNet (synonyms, hypernyms and hyponyms). In this
case, the term rock belongs to different WordNet synsets, and is
therefore associated to different meanings, stone and music genre.
However, by matching the linguistic triples to candidate answer
triples in the relevant ontologies, and by determining the most
likely WordNet senses for the potentially ambiguous entities in

the ontologies, in this example, PowerAqua will quickly find that
no ontologies relate musicians to rock interpreted as stone, while
many ontologies relate musicians to rock, interpreted as a music
genre. Hence, PowerAqua can discard the sense of rock as a stone.
In those cases, where it is not possible to quickly determine the
correct sense for a query term, i.e., alternative interpretations are
covered by one or multiple ontologies, then PowerAqua will produce a ranking of the different interpretations according to their
popularity  i.e., how many ontologies in the result set contain each
particular interpretation.

This approach has been evaluated empirically and has been
shown to perform well with our evaluation datasets. More details
on both the algorithm and the evaluation studies can be found in
Refs. [59,48].

4.3. Searching and ranking

The semantic document retrieval and ranking approach presented here is the same as the one in our initial design (Section 3.2),
except for the way in which the query vector is constructed. As explained earlier, the document retrieval and ranking algorithm is
based on an adaptation of the traditional vector space IR model,
where documents and queries are represented as weighted vec-
tors. The query vector components represent the importance of
each semantic entity in the information need expressed by the
user, while the document vector components represent the relevance of each semantic entity within the document.

The construction of the document vector remains from our previous model, but the construction of the query vector has been
adapted to manage the degree of uncertainty of the answers retrieved by PowerAqua. Note that, in the base model, the input
was a formal SPARQL query. This query was executed against the
KB returning as answer a list of instance tuples in a purely Boolean
step (i.e., based on an exact matching). Using PowerAqua as query
processing module introduces a degree of uncertainty in the retrieved answers: firstly, because it searches for approximate syntactic matches in order to find the ontologies that can potentially
answer the users query; secondly, because it has to disambiguate
the sense of the identified entities using as background knowledge
the available semantic information; and finally, because it constructs one or more generic patterns to match the tuples from different ontologies.

To compute the degree of uncertainty of the retrieved answers
and, as a simple approach to weight the elements of the query vec-
tor, a query weighting measure has been introduced into the query
module. This measure is based on the number of semantic entities
retrieved for each detected query condition. For example, if the
user asks for symptoms and treatments of Parkinson disease,
PowerAqua is able to retrieve as answer a set of individual symptoms and a set of individual treatments. Considering that SEci is
the set of semantic entities retrieved for the query condition i,
the weight of each retrieved semantic entity in the query vector
is computed as 1/|SEci|. The intuition behind this measure is that
those query variables for which fewer ontology entities have been
retrieved are more likely to be representative of the users information needs, and therefore they should be considered more
important.

4.4. Providing fast access to SW information: a SW gateway

This section focuses on the work carried out towards the generation of a SW gateway that collects, analyzes and gives access to
online available semantic content, enabling the experimentation
of the proposed retrieval algorithms on large amounts of semantic
content. A SW gateway should accomplish three main goals:

 Collect the available semantic content from the Web.
 Implement efficient storage facilities to access the data.
 Implement ontology evaluation and selection algorithms to
retrieve the most appropriate semantic information considering
the user or application needs.

One of the most popular SW gateways currently available is Swoogle [49]. This system claims to have indexed around ten thousand
ontologies, which is a significant coverage of the SW data. However,
the selection algorithms that this tool provides to users and applications are based on traditional IR methodologies, like the well known
Page-Rank algorithm [50]. Thus, the ontology selection algorithms
do not take into account semantic data quality measures such as
lexical vocabulary, relations, consistency, correctness, etc.

Another very popular SW Gateway is Watson22 [46,47]. It combines the capabilities of Swoogle to crawl and search SW data with
novel techniques to analyze the quality of content.

For the purpose of having control over our experimental envi-
ronment, and making our evaluation reproducible, we developed
our own SW gateway, WebCORE [42,51], focusing our attention in
the last two requirements and avoiding the cost of constructing a
SW crawler. The collection of semantic content has been done
manually from several public ontology repositories, and contains
around 2 GB of metadata. The designed structures to store and access the semantic content are explained below. These structures
are used by the annotation modules (Section 4.1), and by the introduced natural language query processing module, PowerAqua. Its
algorithms for ontology selection and evaluation are described in
Refs. [42,51], but are not used as part of this work.

4.4.1. Ontology indexing module

To efficiently access large amounts of SW content, WebCORE
pre-processes and stores the gathered information in several inverted indices. Two kinds of indices are created, the lexical ontology
index, which associates each semantic entity (class, property, instance or literal) with a set of terms or lexical representations,
and, the taxonomical ontology index, which associates each semantic entity with its direct subclasses and superclasses.

The lexical ontology-index generation is achieved by a conceptkeyword extraction mechanism over the semantic entities. The
keywords associated to each concept are extracted from the entity
local name (which is part of its URI), the standard ontology meta
property rdfs:label, and optionally,
from any other ontology
property.

An example of the generated inverted index is shown in Table 3,
where each keyword is associated to one or several semantic entities from different ontologies. The semantic entities are uniquely
identified within the system by the identifier of the ontology they
belong to, their URIs, their type (class, property, individual or lit-
eral), and their set of associated terms obtained after the con-
cept-keyword extraction phase.

These indices are useful to identify, in a first step, the set of potential semantic entities (over the whole gathered SW content)
that can be associated to a set of pre-defined terms describing a
user query, a document, or any other application need.

To search the set of semantic entities associated to a specific
term in the indices, we make use of the search capabilities of Lu-
cene, and the term relations obtained with WordNet. Lucene allows performing three different kinds of searches within the
lexical ontology index:

 Exact search: the index must contain the exact searched term to

retrieve an answer.

Table 3
Lexical ontology index.

Keyword

Lorca
Writer
Animal

Ontology entities

E2, E11, E120, . . .
E57, E62, E34, . . .
E43, . . .

Table 4
Taxonomical ontology index.

Ontology entity

Direct subclasses

Direct superclasses

E1
E2
E3

E11, E120

E1, E2, . . .

E3, E14, E22
E3, E23 E41


 Fuzzy search: the keywords stored in the index must be similar to the searched term. The similarity is computed using
the Levenshtein distance [44], and considering an established
prefix that represents the number of letters that must be equal
at the beginning of both words.

 Spell search: the searched term might contain some spelling
mistakes. In this case, Lucene provides some suggestions of
additional terms. For these cases, the system uses the first suggestion in order to perform a new search within the index.

WordNet allows extending the searched terms with three main
types of relationships: synonyms, hypernyms and hyponyms.
Searching for related terms increases the chances of finding a
matching within the index.

A second index level is generated to store taxonomical informa-
tion. In this way, the ontology entities are also associated with its
main superclasses and subclasses. An example of this indexing
structure can be shown in Table 4.

The lexical and taxonomical indices increase the mapping speed
of semantic entities, allowing the management in real time of the
distributed semantic information. For those cases in which the system requires more information than the one stored in the indices,
the SW gateway provides a multi-ontology accessing module that
allows managing several ontologies at a time within the
application.

4.4.2. Multi-ontology access module

Providing universal access to multiple ontologies from different
applications presents two main difficulties: accessing the semantic
content in a common way for all the applications, and generating
appropriate multi-ontology management modules to administer
several ontologies at a time. Three main problems should be addressed in order to access the semantic content in a common
way for all the applications:

 Ontologies are expressed in different languages (RDF, OWL,

DAML, etc.).

 Ontologies can be stored in different types of repositories

(databases, text files, URLs, etc.).

 Ontology frameworks implement different APIs to access

ontologies (Sesame,23 Jena,24 etc.).

To address the first problem, we have developed a common API
to access all the distributed semantic content. Fig. 6 shows the

22 http://watson.kmi.open.ac.uk/WatsonWUI/.

23 OpenRDF, http://www.openrdf.org/.
24 Jena Semantic Web Framework, http://jena.sourceforge.net/.

M. Fernandez et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 434452

Fig. 6. Common access to Semantic Web content. Ontology image extracted from:
http://accuracyandaesthetics.com/wp-content/uploads/2006/12/ontology.jpg.

architectural design and the set of layers involved in the semantic
content accessing process.

At a first level, an OntologyPlugin API defines a common set of
functionalities to query ontologies and KBs independently of their
language, type of storage, and location. In a second layer, two
implementations of the above API are provided for two of the most
popular SW frameworks: Sesame and Jena. Different extensions of
the implementations are done for these frameworks to encapsulate
the different ontology languages, and types of storage. These
implementations are done using the APIs and the query languages
available for the different SW frameworks, which are the ones that
directly access to the SW graph of information.

Ontologies are added to WebCore by providing the following
information: the ontology identifier, its language, its corresponding framework, and its location. An example of such information
is shown in Fig. 7. The SW gateway manages this information for
the ontologies that have been previously gathered from the SW.
However, any external application can provide information about
a new ontology, so that the SW gateway can analyze, and store
or access it at run time.

To manage several ontologies at a time in the application, the
SW gateway provides an additional API to encapsulate a cache
based memory of ontologyPlugins. Internally, this cache structure
is managed as a Hash table of OntologyPlugins, where each ontologyPlugin is associated to the ontology identifier. A graphical view
of the MultiOntologyPlugin structure is shown in Fig. 8.

With the described architecture, the SW gateway provides
large-scale storage and accessing capabilities. It provides the necessary structures to manage multiple ontologies and KBs at the

Fig. 8. Architectural design of the MultiOntologyPlugin module.

same time, and provides a common API to access the semantic content independently of the ontology language, storage type, and
location.

5. Evaluation

In contrast to the IR community, where evaluation using standardized techniques, such as those used for the annual TREC com-
petitions, has been common for decades, the SW community is still
a long way from defining standard evaluation benchmarks to judge
the quality of semantic search methods. Current approaches for
SW technology evaluation are based on user-centred methods
[5254], and therefore tend to be high-cost, non-scalable and difficult to repeat, especially at Web scale.

A systematic and rigorous evaluation thus involves addressing a
benchmark building task. We require a text collection, a set of queries and the corresponding document judgments, ontologies covering the query topics, and KBs populating such ontologies,
preferably using an independent source, which is independent
from the text collection.

5.1. Evaluation benchmark

The constructed benchmark is composed by: (a) the TREC
WT10G document collection [55], (b) 20 queries selected and
adapted from the TREC9 and TREC2001 competitions,25 with
their corresponding judgments, (c) 40 public ontologies covering
a subset of TREC domains (these comprises 370 files, and
around 400 MB of RDF, OWL and DAML), plus 100 additional
repositories (2 GB of RDF and OWL) stored,
indexed and accessed towards the SW gateway integrated into the system,
and (d) the public available KBs associated with these ontolo-
gies, plus some metadata generated from a external data source,
Wikipedia. The detailed motivation, principles, and steps for the
construction of this evaluation benchmark, as a step forward in
the standardization of a semantic search evaluation methodol-
ogy, are given in Ref. [56].

Fig. 7. Information needed to create a new OntologyPlugin.

25 http://technologies.kmi.open.ac.uk/poweraqua/trec-evaluation.html.

5.2. Experimental set up

Table 6
Quality of results by P@10.

The proposed experimental setup involves the comparison of
four different systems: three traditional keyword-based systems
(Lucene, the best TREC automatic, and the best TREC manual, both
of them from TREC9 and TREC2001 competitions), and our semantic search engine. The difference between the best TREC automatic
(short runs) and manual (notshort runs) is based on how they process the query [57]. While automatic search approaches take the
query as it comes from user logs, TREC manual approaches modify
the query with additional information before processing it. Note
that the results by TREC manual are reported but are not included
as part of the discussion because, as mentioned in Ref. [57], only
short runs are representative or real Web search. Non-short runs
increase the number of known relevant documents and give an
idea of what level of performance may be possible on each task.

5.3. Results

Tables 5 and 6 show the results of the evaluation using the 20
TREC topics and two standard IR evaluation metrics: Mean Average
Precision (MAP) and Precision at 10 (P@10) for each of the evaluated search approaches. The first metric captures the overall performance of the system in terms of precision, recall and ranking.
The second one relates to the accuracy of the top-10 results, which
are generally the ones most often explored by search users.

Values in bold correspond to the best results for the corresponding topic and metric, excluding the Best TREC manual ap-
proach, which outperforms the others significantly by both
metrics, likely because of manual modifications to the query. Note
that, for this experiment, the semantic retrieval approach uses the
annotation process based on contextual semantic information described in Section 4.1.2.

As shown in Table 6, by P@10, the semantic retrieval outperforms
the other two approaches, providing the highest quality for 55% of
the queries, and being only outperformed by both Lucene and TREC
semantic for one query (511). Semantic retrieval provides better
results than Lucene for 60% of the queries, and equal results for another 20%. Compared to the best TREC automatic engine, our approach performs better for 65% of the queries, and produces
comparable results for 5%. Indeed, the highest average value for
this metric is obtained by semantic search.

Table 5
Quality of results by MAP.

Topic

Semantic

Lucene

TREC automatic

TREC manual

Mean

Topic

Semantic

Lucene

TREC automatic

TREC manual

Mean

The results by MAP, in Table 5, show that there is no clear win-
ner. While the average rating for Best TREC automatic is higher
than that for semantic search, the latter outperforms TREC automatic in 50% of the queries, and Lucene in 75% of the cases.

We hypothesize that the quality of the results retrieved by
semantic retrieval, and its measurement with MAP may be disadvantaged by the following two factors:

 More than half of the documents retrieved by the semantic
retrieval approach lack relevance judgments in the TREC collec-
tion. Therefore, the used metrics marked them as irrelevant,
when, in fact, some of them can be considered relevant. In Section 5.3.1, we study the impact of this effect by manually evaluating some results to analyze how the semantic retrieval
approach would perform if all
the documents had been
evaluated.

 The annotation process used for the semantic retrieval approach
is very restrictive (see Section 4.1.2). In order to increase the
annotation accuracy, an annotation is generated when a document contains not just a concept, but also its semantic context.
If the concept appears in the document with a semantic context
not covered by its ontology, the annotation is not generated.
Thus, the process discards potentially correct annotations. The
impact of this effect is studied in Section 5.3.2, which compares
the performance of the context-based annotation model with
the NLP based annotation model (see Section 4.1.1).

The aforementioned sections also explain why these factors afthe MAP measurements much more than the P@10

fect
measurements.

Three additional relevant conclusions can be drawn from the

evaluation:

 For some queries for which the keyword search (Lucene) approach
finds no relevant documents, the semantic search does. This is the
case of queries 457 (Chevrolet trucks), 523 (facts about the five
main clouds) and 524 (how to erase scar?). When the same reality is expressed in document and queries using a different ter-
minology,
as opposed to
traditional keyword-based models, are able to detect it and provide valuable answers.

search approaches,

semantic

 The queries in which the semantic retrieval did not outperform
the keyword baseline seem to be those where the semantic

M. Fernandez et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 434452

information obtained by the query processing module was
scarce. One of such queries would be 467 (Show me all information about dachshund dog breeders). However, the keywordbased baseline only rarely provides significantly better results than
semantic search. In addition, it is important to highlight that,
when there is a lack of semantic information to answer the
users request, the system gracefully degrades to a keyword
based system and as a result its performance is still comparable
to traditional keyword based approaches.

 As already pointed out, the effect of complex queries (in terms
of relationships) was not evaluated, because TREC search evaluation topics are written for keyword-based search engines, and
do not consider this type of query expressivity. Based on prior
experiments outside TREC [34] it is fair to assume that for more
complex queries, involving several related information needs or
potentially ambiguous meanings, the performance of semantic
search is likely to improve significantly relative to the baselines.

5.3.1. Studying the impact of retrieved non-evaluated documents

Given a TREC topic and a document, there is one of three

possibilities:

 The document is judged as a relevant result.
 The document is judged as an irrelevant result.
 The document has not been judged in the TREC collection. If

semantic search retrieves it, our metrics take it as irrelevant.

As shown in Table 7, only 44% of the results returned by semantic
retrieval had been previously evaluated in the TREC collection. The
non judged documents, 66% of the whole set, are therefore considered irrelevant beforehand, although some of these results may be
relevant. Therefore, the performance of semantic retrieval may be
better than reported.

Fig. 9 shows the probability of a result returned by the semantic
retrieval approach to be evaluated as function of its position. Results in the first positions have a very high probability. In other
words, the first results returned by the semantic retrieval approach
are very likely to have been returned by at least one of the TREC
search engines as well. This explains why unevaluated results are
a significant issue for MAP but not for P@10.

We now focus on how the lack of evaluations for documents
retrieved by semantic search does affect the results by the MAP
metrics. A legitimate question is whether the unevaluated results
are actually relevant. Indeed, a result is no evaluated if it was
not returned by any of the search engines in TREC, which one
may expect to imply that it has a low probability of being
relevant.

To provide a partial answer to this question we performed a
small evaluation of the first 10 non evaluated results returned for
every query: a total number of 200 documents. 89% of these results
occur in the first 100 positions for their respective queries. The first
10 were picked because these are the most likely to be seen by the
user, and also because, occurring first on the query, have a larger
impact on the MAP measurements. Note that these additional

Table 7
Documents retrieved by semantic retrieval that are evaluated.

Topic

Evaluated Topic Evaluated Topic Evaluated Topic Evaluated

44.6%
31.3%
49.4%
54.6%
38.5%

Mean

38.0%
50.6%
13.4%
51.6%
47.2%

57.3%
32.8%
62.8%
61.3%
39.8%

54.5%
47.5%
20.3%
47.6%
44.6%

44.4%

Fig. 9. Probability of a document being evaluated by position.

judgments had not been used to conduct the global evaluation,
shown in Tables 5 and 6, but just as a posteriori study of the fact
that semantic search is finding additional documents that none
of the TREC participants had retrieved. Note also that the assessor
performing this evaluation is a different person than the original
TREC assessor. This may lead to an inter-assessor consistency problem in which the new assessor may be interpreting relevance in a
stricter or a looser way than the original one.

The results of the evaluation are given in Table 8. For each
query, we show the percentage of documents judged as relevant
that were not evaluated in TREC, and the average, minimum and
maximum ranking positions of those documents.

A significant portion, 31.5%, of the additional judged documents
turned out to be relevant. Clearly, this cannot be generalized to all
the non evaluated results returned by the semantic search ap-
proach: as one moves towards the bottom, the probability of a result being relevant decreases, as shown in Fig. 10. This figure is
based only on the TREC evaluations, treating non evaluated (by
TREC) results as irrelevant, so the actual probability is slightly
higher. The figure shows that the probability of being relevant
drops around the first 100 results, and then varies very little.
Although this percentage cannot be generalized, it supports our
hypothesis that the MAP value of the semantic search approach
puts this at a disadvantage with respect to the MAP value obtained
by TREC approaches.

We analyzed the queries for which at least 50% of the top-10
documents retrieved and not evaluated by TREC were considered
relevant in our evaluation. The analysis shows that, in most of
these cases, semantic search was obtaining new relevant documents when the query involved a class-instance relationship in
the ontologies. Examples of such queries are: symptoms and treatments of Parkinson disease or movies or TV programs where Jenifer
Anniston appears. This effect indicates that, semantic search obtains better recall when querying for class instances.

Most of the results evaluated and listed in Table 8, even those
considered as irrelevant, contain information related to the query.
For example, for topic 451, What is a Bengals cat, although documents about Bengal cats were not retrieved, most of the results
were about other types of cats. For topic 457, the results focused
on specifications of Chevrolet cars instead of Chevrolet trucks. This
potential
recommendation characteristic of semantic search
could even have a positive impact on the users satisfaction, but
this should be studied more carefully before definitive conclusions
can be drawn.

Table 8
Analysis of top-10 documents retrieved by semantic retrieval, which were not evaluated by TREC. 0% means none of the non-evaluated documents where considered as
relevant. Position means the semantic retrieval position of a document.

Percentage of non
evaluated relevant
documents

Average position of
non evaluated relevant
documents

Minimum position of a
non evaluated relevant
document

Maximum position of a
non evaluated relevant
document

Topic

0%
0%
90%
0%
50%
50%
50%
0%
30%
0%
40%
60%
50%
70%
30%
40%
10%
30%
30%
0%

31.5%


41.8 (19.0)


20.2 (7.4)
12.8 (6.1)
14.4 (8.4)

58.0 (40.7)

110.5 (27.6)
6.2 (3.5)
31.2 (12.5)
39.7 (18.2)
55.3 (24.4)
127.0 (35.5)
91.0 (0.0)
32.0 (7.8)
13.3 (10.8)

indices, and could thus take advantage of the structures used by
large commercial search engines, such as Google or Yahoo!

With the aim to compare the effect of the two different annotation processes, four topics were selected based on the total percentage of retrieved non evaluated documents: 484 (13%), 452
(31.3%), 465 (38.5%), and 476 (50.6%).

The results of the analysis are shown in Tables 9 and 10. For

each query, these tables include:

 The old value of the metric for the semantic search approach.
 The new value of the metric for the semantic search approach.
 The value of the metric for the Best TREC approach.

As shown in the tables, the quality of results increases significantly with the new annotation model. On average, by the MAP
metric, the new model performs 1.76 times better than with the
previous annotation method. What is more, the quality of the first
results, measured by P@10, did not diminish: in fact, it went up

Table 9
Quality of results by MAP using an NLP-based annotation model.

Topic

Average

Old

New

Table 10
Quality of results by P@10 using an NLP-based annotation model.

Topic

Average

Old

New

Fig. 10. Probability of a document being relevant by position.

5.3.2. Annotation quality vs. quantity tradeoffs

As Table 8 shows, many relevant documents retrieved by the
TREC search engines were not retrieved by the semantic search
approach.

We hypothesize that the restrictions in the annotation process
may have some influence here. Note that annotations are only generated if the ontological context of the entity is found within the
documents (see Section 4.1.2). This loss of potential correct annotations is a price to be paid for the increase in accuracy.

We decided to run a small-scale test with a variation of the
annotation process based on NLP methodologies (this annotation
method is described in Section 4.1.1). Although this new annotation method is less restrictive, given the fact that it relaxes the conditions to generate a new annotation, and its weighting algorithm
generates more accurate weights (it is based on an adaptation of
TF-IDF over semantic entity frequencies), it is important to stress
that this annotation model is considerably less scalable. Note that,
even though the annotation is an off-line process, the contextbased annotation model is based on traditional keyword document

M. Fernandez et al. / Web Semantics: Science, Services and Agents on the World Wide Web 9 (2011) 434452

Table 11
Query time performance.

Topic

Time

Topic

Time

Topic

Time

Topic

Time

(albeit marginally). This is due to the highest accuracy of the
weighting annotation algorithm used for this annotation model,
which is based on TF-IDF algorithms.

Besides the selected algorithms, two important factors also affect the quality and quantity of annotations, and therefore, the
effectiveness of the semantic retrieval: (a) the volume and domain
coverage of the publicly available semantic information and (b)
how this information is associated or annotated with the current
World Wide Web content.

Regarding the first factor, major advances have been made in
the last few years, creating rich semantic resources, such as DBPedia26 and Freebase, and opening up large datasets previously hidden
under backend databases, like the ones released by the data.gov27
initiative.

Regarding the second factor, initiatives like Google Rich Snippets and Yahoo! Search Monkey are encouraging publishers to
annotate their own Web content. In a recent publication,28 Google
declared that currently 5% of the Web pages have some semantic
markup, but they expect to raise soon this number up to 50%. Addi-
tionally, for the cases in which publishers do not introduce this
information, current state of the art techniques [60] have shown
the feasibility of performing rapid analysis of Web content to generate large-scale annotation.

Considering all these advances seems reasonable to assume that
an important percentage of Web content will be soon annotated
with semantic information with an acceptable coverage. In addi-
tion, for those cases in which the annotations are scarce, our
semantic retrieval model is combined with a traditional key-
word-based retrieval technique to maintain an appropriated level
of recall.

5.3.3. Run time performance evaluation

Table 11 shows the performance of the semantic search system
in terms of query response time, showing a maximum time of
18.32 s for query 523, facts about the five main clouds?, a minimum time of 1.63 s for query 491 Japanese Wave and an average
of 5.37 s per query.

The experiments have been conducted on a server with the following characteristics: 3 GHz Intel Pentium Dual Core, 8 GB RAM
and 150 GB hard disk.

As described by the results, the query time, even though reason-
able, is still too high. Most of this execution time corresponds to
the query processing phase (Section 4.2). Although PowerAqua
uses the generated ontology indices (Section 4.4.1) and multiontology access module (Section 4.4.2) to filter the ontologies that
may partially cover the users request, extracting the answer from
these ontologies may require the execution of several ontologybased queries over the corresponding triple stores where the ontologies are saved. To conduct these experiments, Sesame 1.x29 has

26 DBPedia: http://dbpedia.org.
27 http://data.gov.uk/.
28 Google Semantic Technologies invited talk, San Francisco, 2010: http://
www.readwriteweb.com/archives/google_semantic_web_push_rich_snippets_usage_
grow.php.
29 http://www.openrdf.org/documentation.jsp.

been used as the main triple store. However, current initiatives to
evaluate and compare the performance of triple store systems at a
large scale30 have shown that, while Sesame is faster for smaller
repositories, Virtuoso31 outperforms it in query time for large metadata volumes. Thus, our main strategy to improve the performance is
to replace Sesame 1.x by Virtuoso as the main triple store. Parallel
computing, and more specifically Hadoop,32 has been also considered to reduce the total query processing time, dividing the tasks
carried out by PowerAqua, and minimizing its response time to the
performance of the slowest ontology-based query executed over
the selected triple store.

6. Conclusions and future work

The main goal of this work is to attempt to bridge the gap between the IR and the SW communities in the understanding and
realization of semantic search. In order to leverage the best features towards semantic search from both fields, and with the ultimate goal of improving the retrieval performance of traditional
keyword-based search, this work proposes the generation of a novel semantic search model that integrates and exploits highly formalized semantic knowledge in the form of ontologies and KBs
within traditional IR ranking models.

As a further extension of this research line, we have investigated the practical feasibility of applying semantic search models
to the Web environment. Several problems, among which we
may highlight the size and heterogeneity of the content or the need
for simple ways of interaction with users, keep this line of research
open to further improvements. Our contributions here are based
on providing potential solutions to the above mentioned problems,
taking a step towards the advancements of semantic search models
within large scale and heterogeneous environments, such as the
Web. This goal has been achieved by:

 The integration of an external NL query processing module,
PowerAqua [29]. This integration aims to solve the problem of
usability, allowing the user to express her requirements in natural language, and the problem of heterogeneity, exploiting
PowerAquas ability to answer queries using large amounts of
heterogeneous semantic content.

 The implementation of flexible and scalable annotation algorithms that generate annotations between large amounts of
documents and semantic metadata, while maintaining both
information sources decoupled.

 The use of a SW gateway that provides fast access for applica-

tions to SW content.

The evaluation of this model has been done using a large-scale
evaluation benchmark based on an adaptation of the evaluation
benchmarks used for the TREC Web track competition [56]. The

30 http://www4.wiwiss.fu-berlin.de/bizer/BerlinSPARQLBenchmark/results/
index.html.
31 http://virtuoso.openlinksw.com/dataspace/dav/wiki/Main/.
32 http://hadoop.apache.org/.

generated benchmark allows the comparison between semantic
search systems and traditional keyword-based search approaches.
As a side effect of an ontology-based approach, we also investigate the problem of knowledge incompleteness. This problem refers to the need of retrieving accurate results when the semantic
information is not available or incomplete. To address this problem
we propose the combination of rankings coming from ontologybased and keyword-based search results. This combination is
based on a score normalization algorithm [58] that undoes potential biases in the distribution of the scores.

As general conclusions of this work we would like to highlight

that:

 Semantic retrieval approaches can integrate and take advantage
of SW and IR models and technologies to provide better search
capabilities, thus achieving a qualitative improvement over
keyword-based retrieval by means of the introduction and
exploitation of fine-grained domain ontologies.

 The application of semantic retrieval models to the Web, and
more specifically the integration of ontologies as key-enablers
to improve search in this environment, remains an open prob-
lem. Challenges and limitations such as the size and heterogeneity of the Web, the scarceness of the semantic knowledge, the
usability constraints, or the lack of formal evaluation bench-
marks, can be pointed out as some of the main reasons for the
slow application of the semantic retrieval paradigm at Web scale.

As reflected in this work, the topic of semantic search is very
broad, and involves many different aspects that can be addressed
as future research lines including unsolved limitations, possible
courses of action to address them, and potential future research
challenges. Among the most relevant future lines of work we
would like to highlight:

 The exploitation of richer, in terms of amount of semantic infor-

mation, SW gateways, e.g., Watson [46,47].

 The analysis of subsets of queries for which semantic search
algorithms generally perform better than traditional keywordbased approaches (like those ones involving potential different
meanings or complex information needs).

 The analysis of the effect of semantic coverage, i.e., the comparison of results obtained with rich custom-made generated
ontologies and KBs against the results obtained reusing public
online available ontologies.

 The study and development of novel evaluation benchmarks,
which consider not just basic IR performance measures, such
as precision and recall, but which also measure the new features
associated with semantic search paradigms (different ways of
interaction, richer user interfaces, structured answers, etc.).

To conclude, in this paper we have presented a comprehensive
semantic search model which, extends the classic IR model, addresses the challenges of the massive and heterogeneous Web
environment, and integrates the benefits of both keyword and
semantic-based search. The evaluation results have shown that
the semantic search model outperforms the best TREC automatic
(short run) system, thus demonstrating the value of the approach.
Future research lines will focus on exploiting the richer amounts
of semantic information, like the ones emerged under the LOD ini-
tiative, with the final aim to provide better levels of information
coverage when answering users information needs.
