Applications 

Pedro Lopes, Jose Luis Oliveira 
DETI/IEETA, University of Aveiro 
Campus Universitario de Santiago 

3810  193 Aveiro, Portugal 

Towards Knowledge Federation in Biomedical 

+351 234 370 500 

[pedrolopes,jlo]@ua.pt 

ABSTRACT 
Knowledge federation is a particular matter of concern in the life 
sciences  domain.  The  magnitude  of  data  generated  by 
biomedical software and hardware since the initial discovery of 
the  human  genome  is  tremendous  in  quantity  and  diversity. 
Consequently,  state-of-the-art  software  solutions  have  always 
lagged behind researchers demands, even more so with recent 
developments  in  high-throughput  sequencing  technology  and 
open access to digital disease records. 
The maturity of Semantic Web technologies brought with it new 
strategies  to  tackle  life  sciences  challenges.  In  spite  of  the 
increased  awareness  regarding  these  technologies  advantages, 
its  adoption  has  been  slow  paced.  With  a  steep  learning  curve 
and  lacking  turnkey  solutions,  bioinformatics  developers  are 
faced with many roadblocks, resulting in a low number of purely 
semantic solutions. 
Our research springs new life to knowledge federation in the life 
sciences with a new application deployment framework, which 
includes  a  native  federation  layer  connecting  and  federating 
deployed  instances  by  default.  This  feature  is  integrated  in  a 
complete  software  stack  for  creating  new  applications,  easing 
the  troubled  development  cycle  associated  with  Semantic  Web 
tools.  As  a  result,  the  door  is  opened  for  harnessing  more 
insightful  knowledge 
the  aggregated  network  of 
relationships amongst biological data. 

Categories and Subject Descriptors 
D.2.13  [Software]:  Reusable  Software    Reusable  libraries; 
[Database  Management]:  Systems    Distributed 
H.2.4 
Databases;  H.3.5  [Information  Storage  and  Retrieval]:  Online Information Services  Data Sharing, Web-based services 

General Terms 
Design, Management, Standardization 

Keywords 
Semantic  Web,  Knowledge 
Management, Biomedicine, Bioinformatics. 

Federation,  Knowledge 

from 

Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not  made  or  distributed  for  profit  or  commercial  advantage  and  that 
copies  bear  this  notice  and  the  full  citation  on  the  first  page.  To  copy 
otherwise,  to  republish,  to  post  on  servers  or  to  redistribute  to  lists, 
requires prior specific permission and/or a fee. 
I-SEMANTICS  2011,  7th  Int.  Conf.  on  Semantic  Systems,  Sept.  7-9, 
2011, Graz, Austria 
Copyright 2011 ACM 978-1-4503-0621-8 ...$10.00. 

1.  INTRODUCTION 
The  biomedical  research  domain  is  a  perfect  benchmark  for 
computer science innovation. In the last three decades we have 
witnessed  the  rapid  evolution  of  both  hardware  and  software 
biological  technologies.  Sequencing  hardware  mapping  human 
genetic  sequences  to  digital  data  has  grown  exponentially, 
generating  now  enormous  amounts  of  data  in  each  read.  To 
make  sense  of  these  data,  huge  in  quantity  and  diversity, 
advanced  software  tools  are  constantly  appearing,  financed  by 
European or worldwide research projects. The Human Genome 
Project [1], the Human Variome Project [2] or the GEN2PHEN 
Project  [3]  were  created  to  foster  a  quicker  progression  in 
biomedical  technologies,  and  to  provide  us  with  insightful 
meanings  regarding  our  genetic  sequence.  A  predictable 
consequence of this interest in our genetic heritage is a vicious 
development  cycle,  where  life  sciences'  demands  are  always 
one-step ahead of existing computer science solutions. 

Data acquired at biological labs are transformed throughout 
many  stages  until  there  is  biological  information  from  where 
biomedical  knowledge  can  be  inferred.  In  spite  of  recent 
advances in this field, most available data is dispersed through 
independent systems, fragmented through closed data silos and 
unreachable to the most noteworthy software analysis methods. 
Most biologists still rely on primitive software and publish data 
online  through  flat-files  or  relational  databases  in  ad-hoc 
unstructured  fashion.  From  a  computer  science  point  of  view, 
Semantic Web technologies' arrival resulted in new capabilities 
to  match 
innate 
heterogeneity, diversity and distribution are a logical contender 
for  Semantic  Web  developments.  Although  Semantic  Web 
awareness has increased over the last couple of years, it is still 
largely  unknown  and  not  considered  as  a  viable  solution  for 
biomedical  applications  development.  Nevertheless,  recent 
efforts,  Bio2RDF  [4],  SADI  [5]  or  Biocatalogue  [6],  have 
proven  the  benefits  of  applying  meaningful  semantics  to 
biology. 

life  sciences'  demands.  Life  sciences 

transition 

that  ease 

To  harness  Semantic  Webs  true  potential  in  biomedical 
applications  we  need  to  provide  developers  with  new  software 
tools 
from  existing  monolithic 
applications  to  improved  semantic  information  systems.  There 
are  already  tools  providing  semantic  views  over  relational 
databases,  but  there  is  a  clear  lack  in  fully  semantic  software 
frameworks,  where 
the  deployment  of  new  applications, 
integrating diverse data semantically, is enhanced. Additionally, 
modern applications cannot repeat errors committed in the past. 
Whereas traditional applications are usually targeted at solving a 
single  problem  in  a  specific  niche  field,  modern  applications 
must  be  designed  from  scratch  for  future  participations  in  an 
open  knowledge  network.  It  is  no  longer  desirable  to  build 
standalone  applications  without  any  kind  of  connection  to 
external resources. For this matter, a new software framework, 

the 

87where  knowledge  integration  and  federation  are  underlying 
development vectors, is required. 

The  life  sciences  domain  is  also  where  the  most  intense 
combinations  of  data  structures  are  mandatory.  Biomedical 
applications  data  models  are  complex  and  very  difficult  to 
integrate or map to external systems. For this matter, Semantic 
Web  modeling  and  schema  technologies,  RDFS  and  OWL, 
appear  as  modern  standards  for  improving  existing  models. 
Modeling  a  system  using  any  subset  of  OWL  rules,  equips  it 
with a common, widely used, language for data organization. In 
the Semantic Web, all systems can be described and annotated 
using 
this  syntax,  easing  model  mapping  and  software 
interoperability  methods.  It  is  vital  that  new  biomedical 
applications  take  into  account  previously  develop<ped  work 
regarding 
target  area,  and  re-use  existing  models, 
expanding and enriching them. 

their 

Research work discussed in this article proposes a software 
deployment framework addressing these challenges, namely the 
setup  enabling  long-term  bridges  to  other  resources,  the 
federation  of  knowledge,  the  migration  from  relational  to 
semantic applications, and the usage of well-known data models. 
As a proof-of-concept, two existing biomedical applications are 
being modernized with the proposed framework. WAVe [7] and 
DiseaseCard  [8]  are  focused  on  genetic  variation  information 
and rare diseases, respectively. Both applications integrate data 
from several heterogeneous and distributed resources and can be 
greatly 
to  Semantic  Web 
technologies,  especially  through  the  addition  of  connections 
between  them,  improving  research  quality  at  both  ends.  With 
these two applications using this framework, we are able to start 
our  own  genotype-to-phenotype  software  ecosystem,  sustained 
by a rich knowledge federation architecture. 
2.  MOTIVATION 
Integration  and  federation  in  the  life  sciences  domain  have 
reached  a  breaking  point  where  traditional  solutions  no  longer 
scale to overcome current problems. Slater [9] and Kozhenkov 

improved  with 

transition 

the 

[10] research underlines drawbacks intrinsic to current strategies 
and recognize the need for novel approaches, based on distinct 
skills and ideals. For this, Semantic Web methodologies arise as 
the  desired  resolution  in  spite  of  their  projected  slow  adoption 
[11]. Next, a discussion on the various challenges for this slower 
adoption  is  detailed.  In  this  discussion,  knowledge  federation 
solutions  are  stressed,  along  with  motivations  for  a  smoother 
transition  to  the  Semantic  Web,  and  an  overview  of  existing 
modeling solutions. 
2.1  Knowledge Federation 
Combining biomedical software engineering with Semantic Web 
ideals,  we  can  pinpoint  two  broad  and  distinct  approaches  for 
enriching existing datasets with integrated connections amongst 
resources  [12].  On  the  one  hand,  there  are  strategies  based  on 
data  warehousing 
from 
resources.  On  the  other  hand,  there  are  solutions  involving 
integrated access to distributed data sources, federating available 
content. Both approaches are shown in Figure 1. 

techniques,  centralizing  content 

Warehousing  deals  with  the  integration  of  data  in  central 
systems,  often  supporting  decision-making  analysis.  These 
scenarios involve the convergence of custom data models into a 
unified  universal  data  mapping  and  the  loading  of  data  into  a 
single  repository.  Clearly,  this  approach  has  the  advantage  of 
gathering  the  required  data  in  a  single  location,  where  it  is 
promptly  available  for  processing  and  querying.  Nonetheless, 
this great advantage also hinders developments for this solution. 
Drawbacks  of 
include  complex  ontology 
mappings,  long  data  loading  times  and  a  non-trivial  update 
process.  These  obstruct  warehouses'  scalability,  flexibility  and 
long-term  sustainability.  However,  warehouse  strategies  are 
perfect  for  scenarios  where  the  wish  is  to  control  all  data  in  a 
single model, disregarding any future fragmentation or the field 
dynamics. Older solutions, like UniProt or NCBI, accommodate 
a huge amount of data collected from several smaller tools and 
only make it available for public usage. Modern examples, like 
Bio2RDF  or  DBPedia  [13],  perform 
transformations  and 
reasoning  over  the  immense  amount  of  loaded  data,  forming 

this  approach 

A - Warehouse Integration

B - SPARQL-based Federation

Data
Source

Data
Source

Data
Source

Data
Source

Data
Source

Data
Source

Data
Source

Data
Source

Warehouse

    Knowledge

SPARQL

SPARQL

SPARQL

SPARQL

Federation Layer

     Knowledge

Figure 1: A  Warehouse integration strategy, multiple resources are replicated in a central warehouse for prompt access to 

knowledge; B  Federation strategy based on SPARQL endpoints providing direct access to each resource 

88new connections in the initially disjoint graph. 

Strategies  opposed 

to  warehousing  acknowledge 

the 
distinct setup of each specialized instance and take advantage of 
it. The integration of distributed resources requires some kind of 
middleware, a federation layer, to connect data available in each 
federated  instance.  Once  this  layer  is  deployed,  data  access 
becomes  transparent.  Even  though  performance  may  be poorer 
than  in  warehousing  solutions,  federation  strategies  can  easily 
scale  to  accommodate  distinct  ontologies,  regular  data  updates 
in  each 
improvements. 
Federation is hidden from end-users as they can access data in 
the same way as with warehousing repositories. The federation 
layer  handles  query  distribution  and  deals  directly  with  each 
repository native API. 

independent  node  and 

long-term 

is 
innate 
transported 

to  Semantic  Web 
Furthermore,  federation 
technologies  and  may  be 
to 
the  biomedical 
applications  domain  [14].  The  SPARQL  specification  was 
designed  from  scratch  to  ease  this  process.  Publishing  data 
through  SPARQL  endpoint  enables  access  to  data  in  more 
advanced ways than traditional SQL. Not only does this permit 
development of general federation tools, but also promotes the 
creation  of  more  complex  software  frameworks,  sustained  by 
native  Semantic  Web  federation,  such  as  the  one  proposed  in 
this document. 
2.2  Evolving to Semantic Web 
Emerging  Semantic  Web  technologies  realize  the  premise  of 
transparent relationships amongst distributed data. The Semantic 
Web  itself  can  be  viewed  as  a  truly  intelligent  federated 
network, where rich data connections provide insightful access 
to  available  knowledge.  However,  despite  these  immense 
possibilities  surrounding  Semantic  Web 
its 
adoption  has  been  slower  than  expected.  Whilst  researchers 
from  all  domains  acknowledge  the  benefits  of  having  a  fully 
semantic  information  system,  the  difficult  transition  from 
traditional  flat-file  or  relational  database  supported  systems  to 
the Semantic Web is definitely the main roadblock. 

technologies, 

Considering  the  long-term  benefits  of  having  a  Semantic 
Web  application  and  the  well-known  difficulties  in  deploying 
such  a  system,  there  is  a  true  need  for  software  tools  that  can 
help in handling this migration more smoothly.  

Projects 

as  D2R 

(http://www4.wiwiss.fu-
berlin.de/bizer/d2r-server/),  S3DB  [15]  or  OWLIM  [16],  have 
managed  to  speed  up  this  transition  process.  D2R  enables  the 
publication  of  data  stored  in  relational  databases  through 
SPARQL endpoints and Linked Data interfaces. This is aimed at 
any  kind  of  relational  database  and  fosters  a  quick  migration 
to  a  semantic  data  model.  DrugBank 
from  a  relational 
(http://www4.wiwiss.fu-berlin.de/drugbank/) 
[17],  DailyMed 
(http://www4.wiwiss.fu-berlin.de/dailymed/)  [18]  or  Diseasome 
(http://www4.wiwiss.fu-berlin.de/diseasome/)  [19]  are  already 
public  SPARQL  endpoints  and  can  be  integrated  in  any  new 
Semantic Web application. Despite the Semantic Web interface, 
it  is  still  supported  by  a  relational  backend.  Hence,  available 
data  relationships  are  not  very  rich.  S3DB  proposes  a  new 
management  model  for  integrating  biomedical  knowledge. 
Created tools can be downloaded and used freely. This enables 
developers with an initial architecture to build their own ad-hoc 
Semantic  Web  applications  instead  of  starting  everything  from 
scratch.  The  OWLIM  project  includes  a  family  of  tools  for 
building  semantic  repositories.  OWLIM  includes  customized 
rules and optimizations for data handling, improving the overall 
repository  performance.  There  are  several  other  projects 

such 

is  of 

surrounding Semantic Web migration and data triplification that 
have only had mild success. 

the  utmost 

Moving  existing  applications  into  the  Semantic  Web 
ecosystem 
importance.  This  can  be 
accomplished,  at  some  level,  with  existing  tools.  However,  by 
deploying new systems as independent solutions, we would be 
making the same mistakes committed in the past. The easy path 
of converting existing applications to Semantic Web models will 
still  result  in  a  fragmented  ecosystem.  This  means  that 
integration and interoperability issues will still be a problem for 
knowledge federation. Thus, the need for software tools capable 
of  streamlining  this  transition  to  the  Semantic  Web  is  clearly 
identifiable.  This  software  must  be  easily  configurable  and 
include  the  adequate  set  of  tools  for  publishing  semantic  data 
and  for  deploying  state-of-the-art  applications  with  these  data. 
Moreover,  such  a  system  should  be  designed  with  knowledge 
federation in mind. The development of standalone, independent 
and closed solution is no longer suitable. New software should 
be designed for future integration in a Semantic Web ecosystem, 
and  this  interoperability  layer  must  be  part  of  any  new 
application.  
2.3  Modeling 
Connecting  knowledge  from  distributed  applications,  sustained 
by  relational  databases  and  models,  has  been  the  subject  of  a 
multitude  of  research  projects  over  the  last  couple  of  decades. 
Exchanging  data  between  non-interoperable  software  and 
analyzing  heterogeneous  data  are  cumbersome  tasks  requiring 
excessive software engineering efforts. Most of this complexity 
is  due  to  difficult  data  model  mappings.  There  are  not  any 
universal  data  models  in  any  area,  and  trying  to  converge 
existing  solutions  to  a  single  common  format  is  a  work 
constantly  in  progress.  Despite  Semantic  Webs  intertwined 
graph structure, this is also a problem for modern software. 

Whilst  it  is  not  imperative  that  integrated  ontologies 
converge  to  a  single  unified  and  universal  ontology,  it  is 
important that semantic mappings are made between ontologies. 
These mappings take advantage of Semantic Webs expression 
to connect data. RDFS and OWL properties and annotations are 
used  to  extrapolate  new  relationships  amongst  subjects  from 
distinct datasets. Likewise, applying curated ontology mappings 
to Semantic Web data does not remove existing relationships: it 
will  only  enrich  the  datasets  with  novel  connections  to  other 
entities.  Automated  ontology  mapping  software,  like  RiMOM 
[20]  or  Lily  [21],  performs  large  scale  ontology  alignments 
based  on  pattern  matching;  concept,  property  and  individual 
matrices;  and  various  similarity  measures.  Original  ontology 
annotations  also  contribute 
text-mining  process, 
improving the mapping accuracy. In the end, mappings must be 
validated through both manual curation and reasoning. 

As with any software tool, the data model is always a key 
component  of  the  system.  Semantic  Web  standards,  namely 
OWL  and  RDFS,  enable  the  description  of  these  models  in  a 
standardized  syntax.  It  is  only  logical  that  newly  developed 
software adopts these standards internally, as it will ease future 
integration  with  external  entities.  The  framework  proposed  in 
this  document  relies  on  this  assumption  to  define  a  common 
meta-model shared by all framework instances. That is, there is 
a  framework  ontology  that  each  standalone  instance  adopts, 
which  enables  it  to  be  a  part  of  a  larger  knowledge  federation 
infrastructure. 

this 

to 

89in 

in 

3.  A KNOWLEDGE FEDERATION 
FRAMEWORK 
Developing  a  framework  that  is  able  to  cope  with  identified 
challenges 
the  biomedical  applications  domain,  while 
conforming to Semantic Web guidelines, is an essential stride to 
ensure  evolution 
the  field.  Summarily,  a  knowledge 
management and federation framework, with a simple setup, and 
including a complete backend for the rapid deployment of new 
information systems is being produced. The outcome is not just 
an application framework, but software capable of empowering 
developers  with  tools  to  create  their  own  Semantic  Web 
federation ecosystem. 
3.1  Architecture 
Semantic  Web  application  development  has  been,  since  its 
origins,  associated  with  new  data  storage,  manipulation  and 
access  solutions.  One  of  this  framework's  goals  was  to  reduce 
these multiple decisions in the information system development 
process.  Hence,  the  proposed  framework  was  designed  paying 
special  attention  to  flexibility.  Despite  being  geared  towards 
federation  by  design,  it  is  possible  to  deploy  and  manage  a 
single  application  instance.  For  simplicitys  sake,  a  gardening 
metaphor is used to describe the frameworks key sections. 

Figure  2  displays  a  single  information  system  instance 
created  using  the  proposed  framework.  This  single  entity  is 
entitled  Knowledge  Seed,  or  simply  seed  from  this  point 
forward.  Figure  3  shows  the  integration  of  various  deployed 
seeds,  resulting  in  a  federated  Semantic  Web  environment,  the 

SPARQL

SEED ENGINE

Semantic
Data Store

this  framework 

Knowledge  Garden.  Using 
to  deploy  a 
standalone  system,  a  seed,  developers  are  provided  with  a 
complete software stack. The stack includes integrated semantic 
data  store  access,  the  framework  engine  and  the  applicationprogramming interface (API). 

The semantic data store is a seed's main storage unit. Data 
is  converted  by  the  seed  engine  from  legacy  formats  to  RDF 
statements, triples, and the framework includes an access layer 
to deal with miscellaneous semantic storage back ends, such as 
in-memory data, files or relational databases. The chosen storage 
type  is  hidden  from  the  framework  engine  and  API.  Hence, 
access  to  data  is  transparent  and  available  methods  are 
abstracted from the low-level data store communication. 

The seed engine acts as the main application controller. In a 
sense, it is the brain behind the framework. This component is 
responsible for managing the systems configuration and startup, 
the  data  loading  operation  and  the  various  modules.  Seed 
configuration  is  based  on  two  files:  a  JSON  setup  file,  with 
ontology  information  and  application-specific  information  like 
naming, description or file locations; and a RDF file, containing 
the  seed  ontology  based  on  the  framework  meta-model.  The 
latter  is  described  in  the  next  section.  With  the  loaded 
configuration, 
the 
biomedical application. 

the  API  and  serves 

the  engine  starts 

Whereas the engine is seen as the seed brain, the API is its 
nervous  system.  The  API  is  a  custom  middleware  solution, 
connecting the semantic data store to the application engine. All 
queries, whether to get data in or out, are executed against the 
API, and it is responsible for managing received requests with 
the adequate method execution. The API operates at two distinct 
levels, internally and externally. For the former, the API is as a 
collection  of  Java  methods  for  getting  data  in  and  out  of  the 
semantic  database.  Operations 
like  adding  statements  or 
selecting data are executed through their respective methods, in 
an API instance, or through REST and SOAP web services. As 
for  the  external  view,  the  API  is  composed  of  a  modified 
SPARQL endpoint, vital for the federation solution. It must be 
highlighted  that  it  is  not  a  simple  SPARQL  endpoint  due  to 
possible  stored  data  characteristics.  Queries  performed  against 
this endpoint are processed for forbidden operations or content 
request. This query processing follows a set of custom-defined 


Seed

Seed

Seed

SPARQL

Seed

SPARQL

Seed

SPARQL

SPARQL

SPARQL

SPARQL

Biomedical
Application

Carrier

12:00 
PMPage Title
http://
www.domain.
com

Figure 2: Knowledge Seed, a software stack for Semantic 
Web information systems including diverse data loading 
connectors, integrated semantic data storage, and API for 
submitting and extracting data through both internal usage 
(with REST, SOAP or inner methods) and external usage 

(with the SPARQL endpoint). 

Federation Layer

     Knowledge

Figure 3: Knowledge Garden, a federated collection of seeds 

where each seeds external API (a modified SPARQL 

endpoint) supports the establishment of connections between 
multiple seeds and thus achieves true knowledge federation 

90for 

rules and, in an extreme scenario, may block all requests. This is 
required  in  scenarios  where  seeds  contain  sensitive  data  or 
where developers want to restrain publicly available data. 

Deploying a Knowledge Garden requires the creation of at 
least  two  seeds.  As  mentioned,  knowledge  federation  involves 
the  establishment  of  intelligent  software  connections  between 
distributed systems. In this framework, knowledge federation is 
obtained by connecting multiple seeds in the same Knowledge 
Garden,  and  reasoning  or  inferring  knowledge  over  a  wider 
array of data.  

With this framework, federation is enabled through access 
to  a  seeds  API:  its  external  operation  level,  with  a  modified 
SPARQL  endpoint,  permits  accessing  data  directly.  Once 
multiple  seeds  are  deployed,  the  framework  relies  on  the 
extended  ARQ  SPARQL  specification,  which  includes  the 
"SERVICE"  keyword 
endpoint  definition 
(http://jena.sourceforge.net/ARQ/service.html).  Exploiting  this 
feature,  queries  can  be  created  targeting  distinct  SPARQL 
endpoints,  and  crossing  data  available  at  each  data  source. 
Comparing  SPARQL  to  SQL  syntax,  this  can  be  seen  as  an 
improved and extended inner join operation, where data comes 
from distinct data stores instead of distinct tables. The following 
SPARQL request connects data from two distinct seeds based on 
associations with the connector resource. 

custom 

?contentA to:connects ?connector } 

?connector to:connects ?contentA } 

SELECT ?contentA ?contentB ?connector  
WHERE { { 
   SERVICE<http://www.seed-a.org/sparql> {  
} {  
   SERVICE <http://www.seed-b.org/sparql> {  


With  this  framework,  biomedical  application  developers 
are  provided  with  the  tools  to  deploy  their  own  seeds  and 
connect  them  in  Knowledge  Gardens.  However,  not  only  this 
naive approach is allowed. By depleting Linked Data guidelines 
and  Semantic  Web  ideals,  each  seed  may  belong  to  a 
Knowledge  Garden,  and  each  Knowledge  Garden  will  be 
connected  to  the  intelligent  knowledge  network  that  is  the 
Semantic Web. 
3.2  Meta Model 
Using  currently  available  technologies,  data  models  in  most 
research domains can be improved through the definition of new 
semantic  web  models,  and  harnessing  the  new  modeling 
capabilities brought about by RDFS and OWL specifications.  

The main outcome of these new data modeling strategies is 
greater  promiscuity  between  data  models.  Taking  into  account 
the richness attached to new ontologies, the levels of expression 
we  can  now  denote  and  the  fact  that  there  is  a  common 
specification  language  for  all  data  models,  current  software 
solutions  are  empowered  with  new  tools  for  better  and  easier 
data  exchanges.  That  is,  not  knowing  the  specifics  of  a  given 
model is no longer an obstacle to data integration and federation: 
it is possible to integrate data and extrapolate its meaning from 
existing relationships. 

Consequently, 

the  proposed  approach 

to  knowledge 
federation is abstracted from the knowledge itself. Since there is 
ground  for  a  common  underlying  data  model,  knowledge 
bridges  can  be  established  without  the  need  for  custom 
mappings, middleware or software constraints. There is a model, 
an ontology, for deploying new instances with this framework. 

Furthermore,  each  seed  may  have  its  custom  model,  based  on 
the framework meta-model and specific to its domain.  

A Knowledge Garden can connect seeds adopting the same 
model or seeds with distinct models. Connecting multiple seeds 
with the same model has the advantage of knowing what data is 
collected at each seed. With knowledge federation, a combined 
view  of  data  in  all  seeds  is  made  available  for  querying  and 
analysis.  In  Knowledge  Gardens  where  seeds  have  distinct 
models,  we  can  abstract  a  transitive  relation  between  seeds, 
resulting in relationships from data in seed A to seed C, if there 
is a connection from seed A to seed B and from seed B to seed 
C.  This  is  a  perfect  setup  for  biomedical  applications  where 
heterogeneous data models with slim connections amongst them 
are commonplace. 

3.3  Deployment Workflow 
Aiming at a smoother transition to a Semantic Web application 
scenario,  the  workflow  for  deploying  new  seeds  was  lightened 
up  and  reduced  to  three  stages:  configuration,  booting  and 
publishing. 

The first stage revolves around writing both configuration 
files.  A  seed  configuration,  in  JavaScript,  is  similar  to  the 
following JSON object: 

"config": { 
        "name": "Diseasecard4", 
        "description": "DiseaseCard v4.0a", 
        "keyprefix":"coeus", 
        "version": "4.0a", 
        "ontology": "..//diseasecard.owl", 
        "setup": ..//dc4_setup.rdf", 
        "sdb..//dc4_sdb.ttl", 
        "predicates..//dc4_predicates.csv", 
        "built": true, 
        "debug": true 

While this might be a straightforward process for the seed 
configuration,  that  is  not  the  case  for  the  seed  ontology.  The 
following  Turtle  block  configures  loading  information  for  data 
in CSV from HGNCs website: 

:resource_HGNC rdf:type :Resource ,   

owl:NamedIndividual ;   
rdfs:label "resource_hgnc"^^xsd:string ; 
dc:date "2011-04-08"^^xsd:dateTime ;   
:order 3 ; 
owl:versionInfo "4.0a"^^xsd:string ; 
dc:title "HGNC"^^xsd:string ; 
     :method "complete"^^xsd:string ; 
dc:publisher "csv"^^xsd:string ; 
:endpoint  "http://www.genenames.org/cgi-
bin/hgnc_downloads.cgi?title=HGNC+output+data
&col=gd_hgnc_id&col=gd_app_sym&col=gd_app_nam
e&col=gd_pub_chrom_map&status=Approved&status
_opt=1&level=pri&where=gd_app_sym+like+%27#re
place#%27&order_by=gd_app_sym_sort&limit=&for
mat=text&submit=submit&.cgifields=&.cgifields
=level&.cgifields=chr&.cgifields=status&.cgif
ields=hgnc_dbtag"^^xsd:string ; 

:extends :concept_HGNC ; 
:isResourceOf :concept_HGNC ; 
:hasKey :csv_HGNC_id ; 
:loadsFrom :csv_HGNC_id ,:csv_HGNC_name . 

 Relying on Protege is advisable to ease the configuration 
process.  In  this  widely  used  ontology  modeling  tool,  the  seed 
ontology can be visually organized. Also, Protege enables direct 

91and indirect imports of external ontologies, which can result in a 
single  seed  ontology  file  with  explicit  connections  to  one  or 
more  models.  These  are  the  files  loaded  by  the  framework 
engine to fill in the preliminary seed configuration. 

initial  dataset.  By  default, 

In the second stage, the application is booted. Booting tasks 
involve  launching  and  populating  the  semantic  data  store  with 
the 
the  framework  provides 
configurable  connectors  for  transforming  data  in  CSV,  XML, 
SQL  or  SPARQL  into  triples,  and  adding  them  to  the  seeds 
semantic data store. Besides these data loaders, there is support 
for  implementing  custom  extensions  through  the  addition  of 
plugins. Plugins can take advantage of internal API methods to 
add or modify data in the semantic data store. The booting stage 
is  finished  once  there  is  a  comprehensive  initial  dataset  in  the 
seed. The framework flexibility permits that in some seeds this 
may  be  a  large  dataset  collected  from  multiple  sources  and  in 
others  it  might  just  be  a  simple  semantic  version  of  the 
application  configuration.  The  silver  lining  is  that  this  is 
adjustable to each seeds individual needs. 

The  last  stage  is  making  the  seed  public.  With  the  seed 
running and the initial dataset loaded in the semantic data store, 
the seed can be opened to public usage. At this point, the API 
assumes  control.  Using  internal  API  methods,  developers  are 
now  able  to  create  any  kind  of  web  applications  that  takes 
advantage  of  collected  data  or  that  adds  new  data  to  the  seed. 
The framework is designed to permit the quick creation of webbased  biomedical  applications,  but  available  REST  and  SOAP 
services  also  allow  desktop-  or  mobile-based  access  to  data. 
Additionally, more than one application can take advantage of a 
seeds  content  and  API.  Each  deployed  instance  scales  to 
accommodate a large number of requests. The HTTP nature of 
published  REST/SOAP  services  and  the  SPARQL  endpoint 
makes  every  seed  available  for  connections  with  any  kind  of 
new or existing application.  
4.  DISCUSSION 
For a real-world assessment of the frameworks adequacy to the 
biomedical applications scenario, we are updating two existing 
software tools, developed at our research unit and without any 
Semantic Web feature in place. 

WAVe  is  a  centralized  portal  for  curated  human  variome 
information.  It  provides  a  streamlined  solution,  sustained  by  a 
holistic  and  lightweight  integration  approach,  for  accessing  a 
wide  and  rich  array  of  genetic  variation  datasets.  WAVe, 
publicly  available  online  at  http://bioinformatics.ua.pt/WAVe/, 
is at the edge of notable developments being made in the human 
variome research field and evolution in this area will occur at an 
increasingly  faster  pace.  Hence,  exponential  data  growth,  new 
standards,  modern  systems  and  many  other  novelties  are 
expected to be unveiled in the next few years. Being aware of 
the  field  dynamics,  WAVe  must  evolve  to  comply  with  these 
ordinary advances. 
DiseaseCard, 

at 
http://bioinformatics.ua.pt/diseasecard/,  is  a  web  portal  for  the 
integration  of  real-time  knowledge  regarding  rare-diseases. 
Information  is  gathered  from  distributed  and  heterogeneous 
medical  and  genomic  databases,  and  is  displayed  in  a  familiar 
visual  paradigm.  Like  WAVe,  DiseaseCard  is  also  prone  to 
biomedical field dynamics, and updates to its internal engine are 
mandatory. 

available 

publicly 

These two existing applications fit in the wide biomedical 
domain  of  genotype-to-phenotype  research.  Ongoing  research 
envisages  the  discovery  and  understanding  of  associations 
between  changes  in  the  human  genetic  sequence  and  their 

online 


Figure 4: Proof-of-concept implementation for the proposed 
framework where WAVe and DiseaseCard will be replaced 
by seeds with similar content, enabling their evolution to 

Semantic Web biomedical applications and their connection 
to future seeds and/or external Semantic Web applications. 
effects  on  human  health.  Genetic  sequence  mutations  are  what 
makes each human being unique and are occurring at all times in 
our  organism.  Although  mutations  define  an  individuals  hair 
color  or  height,  they  also  control  certain  disease  proneness  or 
reactions  to  drug  treatments.  With  the  panacea  of  personalized 
medicine  being  postponed  daily,  it  is  vital  to  understand  what 
causes these changes and their immediate or long-term effects in 
the  human  body.  In  practice,  clinicians  must  be  able  to  work 
with biologists to improve patient health care and custom drug 
design. 

is  developed 

from  diverse 

The  genotype-to-phenotype  research  field  requires  the 
scientific  areas. 
involvement  of  experts 
Consequently,  biomedical  software 
towards 
specific user niches. Regarding the information systems required 
to support such endeavor, it is clear that a single solution cannot 
fit  the  requirements  arising  in  this  field.  Starting  with  detailed 
applications, DiseaseCard is targeted at clinicians while WAVe 
was designed with geneticists and gene curators in mind. More 
applications  can  be  added  to  this  scenario.  Pharmacology 
software  explicitly  demands  drug  design  and  analysis  features. 
Proteomics tools are based around amino-acid combinations and 
protein interaction networks. However, the whole is greater than 
the sum of its parts. There has to be a holistic view connecting 
knowledge  in  each  individual  application  so  that  deeper  and 
more precise relationships can be recognized. This diversity in 
requirements,  features,  data  and  models  is  indeed  a  perfect 
match  for  ongoing  general  Semantic  Web  advances  and,  in 
particular, for this framework proposal.  

 This Knowledge Garden (Figure 4), with multiple focused 
seeds,  will  be  a  federated  genotype-to-phenotype  knowledge 
ecosystem, where applications are developed independently, but 
their content is grasped as an ensemble. Upon the deployment of 
new  seeds,  old  applications  will  be  replaced  with  modern 

92 

The first seed will replace DiseaseCard entirely. This 
information  system  is  targeted  at  clinicians  and  will 
provide  an  integrative  view  of  information  on  rare 
diseases.  The  inclusion  of  disease  features,  genes, 
drugs,  symptoms  or  associated  literature  is  required 
for  the  establishment  of  rich  connections  to  other 
seeds. 

Semantic Web systems, and new applications will be semantic 
from  scratch.  The  ongoing  procedure  for  deploying  this 
frameworks  proof-of-concept  Knowledge  Garden  is  detailed 
next and comprises multiple information systems, each with its 
own specific data model, features and target users. 

  Next, the second seed will replace WAVes core data 
engine.  User  interface  and  features  will  remain  the 
same,  but  data  will  be  semantically  richer  and  with 
new relations to DiseaseCards seed content. 
Further  seeds  will  be  deployed  according  to  need.  A 
drug-based seed engaging pharmacologists may be the 
most suitable candidate.  

 

seed; 

Despite  the  obvious  distinctions  in  the  underlying  data 
model for each seed, all will use our framework, with its lowlevel meta model. Therefore, this sample scenario results in rich 
and independent databases, whose knowledge is harvested using 
the  framework's  efficient  federation  API.  Figure  4  also 
highlights 
the  knowledge  bridge  between  WAVe  and 
DiseaseCard,  centered  in  gene  symbol  identifiers.  WAVes 
genetic  data  revolves  around  genes  and  DiseaseCards  rare 
disease  information  includes  the  list  of  genes  associated  with 
each disease. Since both seeds include the same concept, we can 
explore  this  transitive  connection.  Consequently,  WAVes 
genetic variation datasets is expanded with disease-related data 
from  DiseaseCards 
and  DiseaseCards  disease 
information is enriched with genetic variation information from 
WAVes seed.  

Additional  comprehensive  analysis  software  will  be  built 
on  top  of  this  federated  knowledge,  enabling  new  curated 
connections from genotype to phenotype data, which would not 
be possible otherwise and which extract the true value from each 
federated seed.  
5.  CONCLUSION 
Biomedical  software  engineering  is  profuse  in  challenges  for 
computer  scientists.  The  magnitude  of  currently  generated 
biological  data,  combined  with  the  fields  great  dynamics, 
establishes  the  need  for  constantly  evolving  software  tools 
capable  of  coping  with  a  defying  array  of  life  science 
requirements.  Though  there  are  some  notable  exceptions,  most 
presently used biomedical information systems were developed 
with  primitive  strategies,  relying  on  relational  databases  and 
monolithic  application  setups.  The  Semantic  Web  has  reached 
its  maturity,  providing  developers  with  modern  tools  for  the 
creation  of  applications  that  can  be  integrated  in  a  global  data 
network. 

latency 

So  far, 

there  has  been 

in  Semantic  Web 
technologies  adoption  in  the  life  sciences  domain.  Though 
bioinformatics  are  aware  of  clear  benefits  inherent  to  this 
change,  the  steep  learning  curve  and  the  lack  of  a  strong 
Semantic  Web  application  framework  have  delayed 
the 
anticipated  migration  of  existing  tools  and  the  usage  of  these 
techniques  in  new  ones.  The  presented  framework  intends  to 
address  four  key  roadblocks 
the  current  biomedical 
application scenario.  

First, connections amongst data from distinct peers must be 
encouraged.  Ad-hoc  solutions  and  standalone  systems  are 

in 

primitive  solutions.  Hence,  it  is  vital  that  modern  applications 
are  connected  to  or  prepared  for  the  establishment  of  future 
connections  to  external  resources.  Developers  can  no  longer 
ignore  the  improved  richness  generated  by  connecting  content. 
Social  networks  connecting  people  have  gained  popularity. 
Likewise,  biomedical  applications  must  be  empowered  by 
default  with  advanced  connectivity  features.  The  proposed 
framework  accomplishes  this  with  its  intrinsic  Semantic  Web 
technologies and open federation layer. 

Life  sciences  nature  results  in  complex  data  models  and 
this  matter  is  overly  explored  by  an  abundance  of  published 
research  work.  Until  recently,  unified  model  mappings  and 
convergence have been simply out of reach. With Semantic Web 
standards,  integrating  distinct  models  is  less  cumbersome. 
Reusing  ontologies  is  highly  encouraged  and,  by  taking 
advantage  of  rich  modeling  semantics,  it  is  easier  to  ensure 
interoperability  with  annotated  models  and  more  expressive 
object or data properties. On top of Semantic Webs modeling 
productivity,  seeds  deployed  using  the  proposed  framework 
respect  a  standardized  meta-model,  based  on  W3C  RDFS  and 
OWL  standards.  This  flexible  approach  guarantees  common 
ground  between  each  seed  custom  data  model  and  external 
seeds'  schemas.  Seeds  will  never  be  detached  from  each  other 
since they share features in terms of structure and software.  

Furthermore,  developers  must  adapt  their  applications  to 
Semantic Web technologies sooner rather than later. The longer 
it  takes  for  new  applications  to  fit  this  new  deployment 
methodology,  the  more  fragmented  the  resulting  environment 
will  be.  Henceforth,  this  framework  empowers  biomedical 
application  developers  with  a  streamlined  Semantic  Web 
deployment  tool.  This  aims  at  a  smoother  transition  from 
monolithic applications with relational or flat-file back ends to 
an  information  system  sustained  by  a  fully  semantic  software 
stack. The frameworks out-of-the-box approach is based on a 
reduced deployment workflow, where a couple of configuration 
files  and  an  application  server  are 
the  only  mandatory 
requirements for launching a new seed. 

envisages 

framework 

the  practical 
implementation of expected Semantic Web real-world scenarios, 
enhancing  knowledge  federation  in  biomedical  applications. 
Knowledge  federation  will  kick-off  a  new  resource  integration 
area,  fostering  the  creation  of  novel  knowledge  management 
software  by  removing  all  concerns  relating  the  underlying 
integration methods. Each seeds deploys an API encompassing a 
SPARQL endpoint and a collection of web services. This allows 
the integration of a single seeds knowledge base within a much 
wider  scope.  Knowledge  Seeds  will  become  part  of  a  larger 
software 
and  will 
subsequently  be  contained  within  a  worldwide  intelligent 
knowledge network, the Semantic Web.  
6.  ACKNOWLEDGMENTS 
The research leading to these results has received funding from 
the  European  Communitys  Seventh  Framework  Programme 
(FP7/2007-2013)  under  grant  agreement  no.  200754  -  the 
