Representing and Reasoning on Typicality 

in Formal Ontologies
Marcello Frixione, Antonio Lieto

University of Salerno
Via Ponte Don Melillo
Tel +39 089 962221

84084 Fisciano (SA), Italy

mfrixione, alieto@unisa.it

ABSTRACT
The problem of concept representation is relevant for many
subfields of cognitive research, including psychology, philosophy
and artificial intelligence. In particular, in recent years, it received
great attention within knowledge representation, because of its
relevance for knowledge engineering and for ontology-based
technologies. However, the notion of concept itself turns out to be
highly disputed and problematic. In our opinion, one of the causes
of this state of affairs is that the notion of concept is in some sense
heterogeneous, and encompasses different cognitive phenomena.
This results in a strain between conflicting requirements, such as,
for example, compositionality on the one side and the need of
representing prototypical information on the other. AI research in
some way shows traces of this situation. In this paper we propose
an analysis of this state of affairs and sketch some proposal for
concept representation in formal ontologies, which takes into
account suggestions coming from psychological research. Our
basic assumption is that knowledge representation technologies
designed considering evidences coming from experimental
psychology (and, therefore, more similar to the humans way of
reasoning and organizing information) can have better results in
real life applications (e.g. in the field of Semantic Web).
Categories and Subject Descriptors
D.3.1 [Programming Languages]: Formal Definitions and
Theory  Semantics. 

General Terms
Design, Languages, Human Factors.
Keywords: ontologies, knowledge representation, reasoning,
knowledge engineering.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy other-
wise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee.
I-SEMANTICS 2011, 7th Int. Conf. on Semantic Systems, Sept. 79,
2011, Graz, Austria.
Copyright 2011 ACM 978-1-4503-0621-8 ...$10.00.

the technology of

1.   Introduction
Computational representation of concepts is a central problem for
the development of ontologies and for knowledge engineering.
Concept representation is a multidisciplinary topic of research that
Intelligence,
involves such different disciplines as Artificial
Philosophy, Cognitive Psychology and, more
in general,
Cognitive Science. However, the notion of concept itself results to
be highly disputed and problematic. In our opinion, one of the
causes of this state of affairs is that the notion itself of concept is
in some sense heterogeneous, and encompasses different cognitive
phenomena. This has several consequences for the practice of
knowledge engineering and for
formal
ontologies. 
In this paper we propose an analysis of this situation. The paper is
organized as follows. In section 2. we point out some differences
between the way concepts are conceived in philosophy and in
psychology. In section 3. we argue that AI research in some way
shows traces of the contradictions individuated in sect. 2. In
particular,
style
semantics conflicts with the need of representing concepts in the
terms of typical traits that allow for exceptions. In section 4 we
review some attempts to resolve this conflict in the field of
knowledge representation, with particular attention to description
logics. It is our opinion that a mature methodology to approach
knowledge representation and knowledge engineering should take
advantage from both the empirical results of cognitive psychology
that concern human abilities and from philosophical analyses. In
this spirit, in section 5 we individuate some possible suggestions
coming from different aspects of cognitive research:
the
distinction between two different types of reasoning processes,
developed within the context of the so-called dual process
accounts of reasoning; the proposal to keep prototypical effects
separate from compositional
the
possibility to develop hybrid, prototype and exemplar-based
representations of concepts. In section 6 we give some tentative
suggestion to implement the above mentioned proposals within
the context of semantic web languages, in the framework of the
linked data perspective. Finally, in section 7, we discuss some
expected results of our proposal. 

the requirement of compositional,

representation of concepts;

logical

119as

categorisation,

2. Compositionality vs. Prototypes 
Within the field of cognitive science, the notion of concept is
highly disputed and problematic. Artificial intelligence (from now
on AI) and, more in general,
the computational approach to
cognition reflect this state of affairs. Conceptual representation
seems to be constrained by conflicting requirements, such as, for
example, compositionality on the one side and the need of
representing prototypical information on  the other.
A first problem (or, better, a first symptom that some problem
exists) consists in the fact that the use of the term concept in the
philosophical tradition is not homogeneous with the use of the
same term in empirical psychology [see 1-3]. Briefly, we could
say that in cognitive psychology a concept is essentially intended
as the mental representations of a category, and the emphasis is on
such processes
induction and learning.
According to philosophers, concepts are above all the components
of thoughts. Even if we leave aside the problem of specifying
what thoughts exactly are, this requires a more demanding notion
of concept. In other words, some phenomena that are classified as
conceptual by psychologists turn out to be nonconceptual for
philosophers. There are, thus, mental representations of categories
that philosophers would not consider genuine concepts. 
that philosophers consider concepts mainly as the
The fact
components
on
compositionality, and on related features, such as productivity and
systematicity, that are often ignored by psychological treatments
of concepts. On the other hand,
is well known that
compositionality is at odds with prototypicality effects, which are
crucial
in most psychological characterisations of concepts.
Prototypical effects are a well established empirical phenomenon.
However, the characterisation of concepts in prototypical terms is
difficult to reconcile with the requirement of compositionality.
According to a well known argument by Jerry Fodor
[4],
prototypes are not compositional (and, since concepts in Fodor's
opinion must be compositional, concepts cannot be prototypes). In
synthesis, Fodor's argument runs as follows: consider a concept
like PET FISH. It results from the composition of the concept
PET and of the concept FISH. But the prototype of PET FISH
cannot result from the composition of the prototypes of PET and
of FISH. For example, a typical PET is furry and warm, a typical
FISH is greyish, but a typical PET FISH is not furry and warm
neither greyish. 

emphasis

thoughts

brought

great

of

it

3. Concept Representation in AI
The situation sketched in the section above is in some sense
reflected by the state of the art in AI and, more in general, in the
field of computational modelling of cognition. This research area
seems often to hesitate between different (and hardly compatible)
points of view. In AI the representation of concepts is faced
mainly within the field of knowledge representation (KR).
Symbolic KR systems (KRs) are formalisms whose structure is, in
a wide sense, language-like. This usually involves that KRs are
assumed to be compositional.
In a first phase of their development (historically corresponding to
the end of the 60s and to the 70s) many KRs oriented to
conceptual representations tried to keep into account suggestions
coming from psychological research. Examples are early semantic
networks and frame systems. Frame and semantic networks were
originally proposed as alternatives to the use of logic in KR. The

to

and

reconcile

compositionality

notion of frame was developed by Marvin Minsky [5] as a
solution to the problem of representing structured knowledge in
AI systems . Both frames and most semantic networks allowed the
possibility to characterise concepts in terms of prototypical
information. 
However, such early KRs where usually characterised in a rather
rough and imprecise way. They lacked a clear formal definition,
and the study of their meta-theoretical properties was almost
impossible. When AI practitioners tried to provide a stronger
formal foundation to concept oriented KRs, it turned out to be
difficult
prototypical
representations. As a consequence, they often choose to sacrifice
the latter. 
In particular, this is the solution adopted in a class of conceptoriented KRs which had (and still have) wide diffusion within AI,
namely the class of formalisms that stem from the so-called
structured inheritance networks and from the KL-ONE system [6-
7]. Such systems were subsequently called terminological logics,
and today are usually known as description logics (DLs) [8]. 
A standard inference mechanism for this kind of networks is
inheritance. Representation of prototypical
information in
semantic networks usually takes the form of allowing exceptions
to inheritance. Networks in this tradition do not admit exceptions
to inheritance, and therefore do not allow the representation of
prototypical information. Indeed, representation of exceptions can
be hardly accommodated with other types of inference defined on
these formalisms, concept classification in the first place [9].
Since the representation of prototypical
information is not
allowed, inferential mechanisms defined on these networks (e.g.
inheritance) can be traced back to classical logical inferences.
In more recent years, representation systems in this tradition have
formalisms (the above
been directly formulated as logical
mentioned
[8]),
in which Tarskian,
compositional semantics is straightly associated to the syntax of
the language. Logical formalisms are paradigmatic examples of
compositional representation systems. As a consequence, this kind
of systems fully satisfy the requirement of compositionality. This
has been achieved at
the cost of not allowing exceptions to
inheritance. By doing this we gave up the possibility of
representing concepts in prototypical terms. From this point of
view, such formalisms can be seen as a revival of the classical
theory of concepts (stating that concepts can be defined in terms
of necessary and sufficient conditions), in spite of its empirical
inadequacy in dealing with most common-sense concepts.
Nowadays, DLs are widely adopted within many application
fields,
in particular within the field of the representation of
ontologies. For example, the OWL (Web Ontology Language)
system is a formalism in this tradition that has been endorsed by
the World Wide Web Consortium for the development of the
semantic web. 

description

logics

3.1 The Advantage of a Cognitive Approach on
Typicality in Artificial Systems  
Prototypical effects in categorisation and, in general, category
representation are not only crucial for the empirical study of
human cognition. They are also of the greatest importance in
representing concepts in artificial systems. Let us first consider
human cognition. Under what conditions should we say that
somebody knows the concept DOG (or, in other terms, that she

120a

concept, but

possesses an adequate mental representation of it)? It is not easy
to say. However, if a person does not know that, for example, dogs
usually bark, that they typically have four legs and that their body
is covered with fur, that in most cases they have a tail and that
they wag it when they are happy,
then we probably should
conclude that
this person does not grasp the concept DOG.
Nevertheless, all these pieces of information are neither necessary
nor sufficient conditions for being a dog. In fact, they are traits
that characterise dogs in typical (or prototypical) cases. The
problem is exactly the same if we want to represent knowledge in
an artificial system. Let us suppose that we want to provide a
computer program with a satisfactory representation of DOG.
Then we probably also want to represent the kind of information
mentioned above: for many applications, a representation of DOG
that does not include the information that dogs usually bark is a
bad representation also from a technological point of view.
Therefore, if a system does not allow to represent information in
typical/prototypical terms (as is the case of standard description
logics), then it is not adequate in this respect. With standard DLs,
the only way to face this problem should be the recourse to tricks
or ad hoc solutions (as often happens in many applications).
The concept DOG is not exceptional from this point of view. The
majority of everyday concepts behave in this way. For most
concepts, a classical definition in terms of necessary and sufficient
conditions is not available (or, even if it is available, it is unknown
to the agent). On the other hand, it can happens that we know the
classical definition of
typical/prototypical
knowledge still plays a central role in many cognitive tasks.
Consider the following example: nowadays most people know
necessary and sufficient conditions for being WATER: water is
exactly the chemical substance whose formula is H2O, i.e., the
substance whose molecules are formed by one atom of oxygen
and two atoms of hydrogen. However, in most cases, when we in
everyday life categorise a sample of stuff as WATER, we do not
take advantage of
this piece of knowledge. We use such
prototypical traits such as the fact that (liquid) water is usually a
colourless, odourless and tasteless fluid. As a further example,
consider the concept GRANDMOTHER. Everybody knows a
classical definition for it: x is the grandmother of y if and only if
x is the mother of a parent of y. However, in many cases we do not
use this definition to categorise somebody as a grandmother. We
resort to typical traits: grandmothers are old women who take care
of children, who are tender and polite with them, and so on. Once
more, the problem is not different in the case of artificial systems:
generally a system that has to categorise some stuff as WATER
cannot perform chemical analyses, and it must trust prototypical
evidence. 
Therefore, the use of prototypical knowledge in cognitive tasks
such as categorisation is not a fault of the human mind, as it
could be the fact that people are prone to fallacies and reasoning
errors (leaving aside the problem of establishing whether recurrent
errors in reasoning could have a deeper rationality within the
general economy of cognition). It has to do with the constraints
that concern every finite agent that has a limited access to the
relevant knowledge for a given task and that try to adopt a
heuristic approach to problem solving. This is the case of both
natural and artificial cognitive systems.

4. Non-classical Concepts in Ontologies
Of course, within symbolic,
rigorous
logic oriented KR,
approaches exist, that allow to represent exceptions, and that

therefore would be, at least in principle, suitable for representing
non-classical concepts. Examples are fuzzy logics and nonmonotonic formalisms. Therefore, the adoption of logic oriented
semantics is not necessarily incompatible with prototypical
effects. But such approaches pose various theoretical and practical
difficulties, and many unsolved problems remain. 
In this section we overview some recent proposal of extending
concept-oriented KRs, and in particular DLs, in order to represent
non-classical concepts. 
Recently different methods and techniques have been adopted to
represent non-classical concepts within computational ontologies.
They are based on extensions of DLs and of standard ontology
languages such as OWL. The different proposals that have been
fuzzy
advanced can be grouped in three main classes: a)
approaches, b) probabilistic
c)
approaches based on non-monotonic formalisms.

and Bayesan approaches,

a) For the integration of fuzzy logics in DLs and in ontology
oriented formalisms, see for example [10-11], Stoilos et al. [12]
propose a fuzzy extension of OWL, f-OWL, able to capture
imprecise and vague knowledge, and a fuzzy reasoning engine
that lets f-OWL reason about such knowledge. In [13] a fuzzy
representing vague
extension of OWL 2 is proposed,
information in semantic web languages. However,
is well
known [14] that approaches to prototypical effects based on fuzzy
logic encounter some difficulty with compositionality.

for

it

also

offers

several

b) The

literature

probabilistic
generalizations of web ontology languages. Many of
these
approaches, as pointed out in [15], focus on combining the OWL
language with probabilistic formalisms based on Bayesian
networks. In particular, in [16] a probabilistic generalization of
OWL is
called PR-OWL, whose probabilistic
semantics is based on multi-entity Bayesian networks (MEBNs);
in [17] a probabilistic generalization of OWL is proposed, called
Bayes-OWL, which is based on standard Bayesian networks.
Bayes-OWL provides a set of rules and procedures for the direct
translation of an OWL ontology into a Bayesian network. 

suggested,

c) The role of non-monotonic reasoning in the context of
formalisms for the ontologies
is actually a debated problem.
According to many KR researches, non-monotonic logics are
expected to play an important role for the improvement of the
reasoning capabilities of ontologies and of the Semantic Web
applications. In the field of non-monotonic extensions of DLs,
Baader and Hollunder [18] propose an extension of the ALCF
system, based on Reiters default
logic. The same authors,
however, point out both the semantic and computational
difficulties of this integration and, for this reason, propose a
restricted semantics for open default theories, in which default
rules are only applied to individuals explicitly represented in the
knowledge base. Since Reiters default logic does not provide a
direct way of modeling inheritance with exceptions, Straccia [19]
proposes an extension of DL H-logics (Hybrid KL-ONE style
logics) able to perform default inheritance reasoning (a kind of
default
on
taxonomies). This proposal is based on the definition of a priority
order between default rules. In [20-21] an extension of DL with
two non-monotonic epistemic operators
is proposed. This
extension allows to encode Reiters default logic and to express
epistemic concepts and procedural rules. However, this extension
presents a rather complicated semantics, so that the integration
with the existing systems requires significant changes to the
standard semantics of DLs. Bonatti et al.
[22] propose an

specifically

reasoning

reasoning

oriented

to

121extension of DLs with circumscription. This extension is
motivated by the need to express prototypical properties with
exceptions. This is done by introducing abnormality predicates,
whose extension is minimized. In [23] an approach to defeasible
inheritance is proposed, based on the introduction in the ALC DL
of a typicality operator T, which allows to reason about
prototypical properties and inheritance with exceptions. This
approach, given the non-monotonic character of the T operator,
has some difficulties in individuating what information is relevant
for reasoning. For a development of this proposal, which deals
with the problems of irrelevance and inheritance, see [24, 25]. In
[26], it is argued that ALCK, a non monotonic DL extended with
the epistemic operator K (that can be applied to concepts or roles)
could represent a model for a similar non monotonic extension of
OWL. In fact, according to the authors, it would be possible to
create local closed-world assumption conditions, in order the
reap the benefits of non-monotonicity without giving up OWLs
open-world semantics in general.
A different approach is based on the use of the OWL 2 annotation
properties (APs) in order to represent vague or prototypical,
information [27]. The limit of this approach is that APs are not
taken into account by the reasoners, and therefore have no effect
on the inferential behaviour of the system [13]. 

logics

and, more

in general, non-classical

5. Some Suggestions from Cognitive Science
Though the presence of a relevant field of research, there is not, in
the scientific community, a common view about the use of non-
monotonic
in
ontologies. For practical applications, systems that are based on
classical Tarskian semantics and that do not allow for exceptions
(as it is the case of traditional DLs), are usually still preferred.
Some researchers, such as, for example, Pat Hayes [28], argue that
the non monotonic logics (and, therefore, the non monotonic
machine reasoning for Semantic Web) can be maybe adopted
for local uses only or for specific applications because it
is
unsafe on the web. Anyway, the question about which logics
must be used in the Semantic Web (or, at least, until which degree,
and in which cases, certain logics could be useful) is still open. 
The empirical results from cognitive psychology show that most
common-sense concepts cannot be characterized in terms of
necessary/sufficient conditions. Classical, monotonic DLs seem to
capture the compositional aspects of conceptual knowledge, but
are inadequate to represent prototypical knowledge. But a non
classical alternative, a general DL able to represent concepts in
prototypical terms does not still emerge.
As a possible way out, we sketch a tentative proposal that is based
on some suggestions coming from cognitive science. Some recent
trends of psychological
the hypothesis that
reasoning is not an unitary cognitive phenomenon. At the same
time, empirical data on concepts seem to suggest that prototypical
effects could stem from different representation mechanisms. In
this spirit, we individuate some hints that, in our opinion, could be
useful for the development of artificial representation systems,
namely:
types of
reasoning processes, which has been developed within the context
of the so-called dual process accounts of reasoning (sect. 5.1
below); (ii) the proposal to keep prototypical effects separate from
compositional representation of concepts (sect. 5.2); and (iii) the
possibility to develop hybrid, prototype and exemplar-based
representations of concepts (sect. 5.3).

the distinction between two different

research favour

(i)

reasons

to believe that,

5.1 A Dual Process Approach
Cognitive research about concepts seems to suggest that concept
representation does not constitute an unitary phenomenon from
the cognitive point of view. In this perspective, a possible solution
should be inspired by the experimental results of empirical
psychology, in particular by the so-called dual process theories of
reasoning and rationality [29-30]. In such theories, the existence
types of cognitive systems is assumed. The
of two different
systems of the first
type (type 1) are phylogenetically older,
unconscious, automatic, associative, parallel and fast. The systems
of the type 2 are more recent, conscious, sequential and slow, and
are based on explicit rule following. In our opinion, there are good
prima facie
in human subjects,
classification, a monotonic form of reasoning which is defined on
semantic networks, and which is typical of DL systems, is a task
of the type 2 (it is a difficult, slow, sequential task). On the
contrary, exceptions play an important role in processes such as
categorization and inheritance, which are more likely to be tasks
of the type 1: they are fast, automatic, usually do not require
particular conscious effort, and so on. 
Therefore, a reasonable hypothesis is that a concept representation
system should include different modules: a monotonic module
of type 2, involved in classification and in similar difficult
tasks, and a non-monotonic module involved in the management
of exceptions. This last module should be a "weak" non
monotonic system, able to perform only some simple forms of
non monotonic inferences (mainly related to categorization and to
exceptions inheritance). This solution goes in the direction of a
dual representation of concepts within the ontologies, and the
realization of hybrid reasoning systems (monotonic and non
monotonic) on semantic network knowledge bases. 

since

representations,

concepts must

5.2 A Pseudo-Fodorian Proposal
As seen before (section 2), according to Fodor, concepts cannot be
prototypical
be
compositional, and prototypes do not compose. On the other hand,
in virtue of the criticisms to classical theory, concepts cannot be
definitions. Therefore, Fodor argues that (most) concepts are
atoms, i.e., are symbols with no internal structure. Their content is
determined by their relation to the world, and not by their internal
structure and/or by their relations with other concepts [31-32]. Of
course, Fodor acknowledges the existence of prototypical effects.
However, he claims that prototypical representations are not part
of concepts. Prototypical representations allow to individuate the
reference of concepts, but
they must not be identified with
concepts. Consider for example the concept DOG. Of course, in
our minds there is some prototypical representation associated to
DOG (e.g., that dogs usually have fur, that they typically bark, and
so on). But this representation does not the coincide with the
concept DOG: DOG is an atomic, unstructured symbol. 
We borrow from Fodor
that compositional
representations and prototypical effects are demanded to different
components of the representational architecture. We assume that
there is a compositional component of representations, which
admits no exceptions and exhibits no prototypical effects, and
which can be represented, for example, in the terms of some
classical DL knowledge base.
In addition, a prototypical
representation of categories is responsible for such processes as
categorisation, but it does not affect the inferential behaviour of
the compositional component. 

the hypothesis

122It must be noted that our present proposal is not entirely

Fodorian, at least in the following three senses:

i. We leave aside the problem of the nature of semantic
content of conceptual representations. Fodor endorses a causal,
informational theory of meaning, according to which the content
of concepts is constituted by some nomic mind-world relation. We
are in no way committed with such an account of semantic
content. (In any case, the philosophical problem of the nature of
the intentional content of representations is largely irrelevant to
our present purposes). 

ii. Fodor claims that concepts are compositional, and that
prototypical representations, in being not compositional, cannot
be concepts. We do not take position on which part of the system
we propose must be considered as truly conceptual. Rather, in
our opinion the notion of concept is spurious from the cognitive
point of view. Both the compositional and the prototypical
components contribute to the conceptual behaviour of the
system (i.e., they have some role in those abilities that we usually
describe in terms of possession of concepts).

iii. According to Fodor, the majority of concepts are atomic.
In particular, he claims that almost all concepts that correspond to
lexical entries have no structure. We maintain that many lexical
concepts, even though not definable in the terms classical theory,
should exhibit some form of structure, and that such structure can
be represented, for example, by means of a DL taxonomy.

for

(some

of)

effects

aspects

prototypical

5.3 Prototypes and Exemplars
Within the field of psychology, different positions and theories on
the nature of concepts are available. Usually, they are grouped in
three main classes, namely prototype views, exemplar views and
theory-theories (see e.g. [33-34]). All of them are assumed to
account
in
conceptualisation. 
According to the prototype view, knowledge about categories is
stored in terms of prototypes, i.e. in terms of some representation
of the best instances of the category. For example, the concept
CAT should coincide with a representation of a prototypical cat. In
the simpler versions of this approach, prototypes are represented
as (possibly weighted) lists of features. 
According to the exemplar view, a given category is mentally
represented as set of specific exemplars explicitly stored within
memory: the mental representation of the concept CAT is the set
of the representations of (some of) the cats we encountered during
our lifetime. 
Theory-theories approaches adopt some form of holistic point of
view about concepts. According to some versions of the theory-
theories, concepts are analogous to theoretical terms in a scientific
theory. For example, the concept CAT is individuated by the role
it plays in our mental theory of zoology. In other version of the
approach, concepts themselves are identified with micro-theories
of some sort. For example, the concept CAT should be identified
with a mentally represented micro-theory about cats. 
These approaches turned out to be not mutually exclusive. Rather,
they seem to succeed in explaining different classes of cognitive
phenomena, and many researchers hold that all of them are
needed to explain psychological data. In this perspective, we
propose
computational
representations of concepts. More precisely, we try to combine a

them in

integrate

some

of

to

prototypical and an exemplar based representation in order to
account for category representation and prototypical effects (for a
similar, hybrid prototypical and exemplar based proposal, see
take into consideration the theory-theory
[35]). We do not
approach, since it
is in some sense more vaguely defined if
compared the other two points of view. As a consequence, its
computational treatment seems at present to be less feasible.

6. Some Suggestion for the Implementation
In the field of web ontology languages,
the developments
sketched above appear nowadays,
technologically possible.
Within the Semantic Web research community, in fact, the Linked
Data perspective is assuming a prominent position [36].
According to this view, in recent years, one of the main objectives
of the Semantic Web community regards the integration of
different data representations (often stored in different data
sources) within unique, semantically linked,
representational
frameworks. The main technical
result coming from this
integration is represented by the possibility of enlarging the
answer-space of a query through the realization of semantic
bridges between different pieces of data (and, often, data
sources). Such integration is made possible through constructs
provided by Semantic Web languages, such as OWL, SKOS etc. 
Consider for example the opposition between exemplar and
prototype theories (see sect. 5.3 above). Both theories can be
implemented in a representation system using the Linked Data
perspective. 
Let us consider first
the case of prototype theory. A dual
representation of concepts and reasoning mechanisms appears to
be possible trough the following approach: a concept
is
represented both in a formal ontology (based on a classical,
compositional DL system),
a prototypical
representation,
implemented using the Open Knowledge-Base
Connectivity (OKBC) protocol. The knowledge model of the
OKBC protocol is supported and implemented in Protege Frames,
an ontology editor that supports the building of the so called
Frame Ontologies. Since it is possible to export (without losing
information) the Frame Ontologies in OWL
the prototypical
language,
the
connection
of
representation can be done using the standard formalisms
provided by the Semantic Web community within the linked data
perspective
linking
constructs1). 
In a similar way, an exemplar based representation of a given
concept can be expressed in a Linked Data format, and connected
to a DL ontological representation. 
types of
In this way, according to our hypothesis, different
reasoning processes (e.g., classification and categorization) can
follow different paths. For example, classification could involve
only the DL ontology, while the non monotonic categorization
process could involve exemplars and prototypical information. A
possible solution to perform non monotonic categorization of
instances could be based on the PEL-C algorithm, PrototypeExemplar Learning Classifier
[37]. The PEL-C is a hybrid
machine learning algorithm able to account for typicality in the
categorization process, using both prototype and exemplar based

(e.g. using the owl:sameAs or other

and in terms

between

types

these

two

1 At the current state of art, the connection between OWL classes
and Frame Ontology classes through owl:sameAs is possible
only in OWL-Full.

123representations. The application of this algorithm requires the
choice of a metric of semantic similarity between concepts within
the prototype and exemplar based component of the architecture. 

that, using the prototypical

7. Expected Results 
It is our intention to evaluate our proposal by comparing its
performance with that of a traditional ontology representing the
same domain. The evaluation tasks could consist mainly in two
types of controls: property checking and instance checking
running SPARQL query on the different knowledge bases. 
Instance checking aims to answer at such questions as is a
particular instance member of a given concept?. In this case we
expect
and exemplar based
representations, would provide a different answer if compared to a
traditional DL ontology. For example:
it could result that an
instance A is not a member of the Class A* in the DL component
while it
is an instance of the Class A** in the prototypical
representation of the same concept. This result does not cause
inconsistencies or create any problem to the system because of the
separation of representation and reasoning process. 
The second evaluation task is based on property checking. It
consists answering such questions as does the class A have the
property b?. We expect that the query-answering mechanism
should take advantage from the integration of different types of
information provided for the same concept. A simple example can
be useful. Let us suppose that an user runs an informational query
[38] on a dual knowledge base representing information
concerning fruit in order to know which kind of citrus is yellow
(that is an indirect formula to ask: does any citrus have the
property of being yellow?). The expected answer that fits the
informational needs of the user is lemon. However, does not
exist
in the knowledge base any kind of citrus that has the
property of being yellow as a defining condition. Being yellow is
not a necessary condition for being a lemon and, therefore, this
property is not represented into the class lemon of a DL ontology.
However the property to be yellow is relevant from a cognitive
point of view to characterize the concept lemon, and, according
to our hybrid approach, can be represented into the prototypical
component of the class lemon. In this way is possible to retrieve
the desired information from the prototypical and/or exemplar part
of the representation. So, given a SPARQL query such as, for
example:

 SELECT? citrus
    WHERE {?citrus :has colour : YELLOW  .

the result returned from the DL representation should be null,
while the correct answer (correct with respect to the intention of
the user) will be generated from the prototypical component of the
representation. 
