A Model for Human-Computer Interaction in the Semantic

Web

Philipp Heim

Visualization and Interactive

Systems Group

University of Stuttgart,

Germany

philipp.heim@vis.uni-

stuttgart.de

Thomas Schlegel

Software Engineering and

Ubiquitous Systems
University of Dresden,

Germany

thomas.schlegel@tu-

dresden.de

Thomas Ertl

Visualization and Interactive

Systems Group

University of Stuttgart,

Germany

thomas.ertl@vis.uni-

stuttgart.de

ABSTRACT
For the general public, the breakthrough of the Semantic
Web as an important addition and further development of
the WWW has not yet taken place. This is primarily due to
its yet not obvious and largely still not existing benefits for
the average Web user. To address this problem, we advocate a greater focus on the topic of human-computer interaction in the Semantic Web. Since to date, however, there
are only fragmentary considerations on this subject, in this
paper we present the first time a general model specifically
designed for the human-computer interaction in the Semantic Web and propose it as a basis for work in this area.
The model builds on the concept of interactive alignment,
which is known from human-to-human communication. In
this concept, human and computer inform each other iteratively and in short intervals in what way they understood
each others in order to be able to identify misunderstandings quickly and thus correct them early on. The model
provides a comprehensive description and thus a better understanding of the processes, dependencies and ways of cooperation involved within human-computer interaction in the
Semantic Web which is the key to new ideas and innovations
in this area. Once the mechanism of human-computer interaction in the Semantic Web is understood, new applications
can be designed and new business opportunities can be discovered more easily so that the benefits of the Semantic Web
can be made available also for the wider public.

Categories and Subject Descriptors
H.1.2 [Models and Principles]: User/Machine Systems
human information processing; H.5.2 [Information Interfaces and Presentation]: User Interfacesgraphical user
interfaces (GUI), interaction styles

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
I-SEMANTICS 2011, 7th Int. Conf. on Semantic Systems, Sept. 7-9, 2011,
Graz, Austria
Copyright 2011 ACM 978-1-4503-0621-8 ...$10.00.

General Terms
Design, Human Factors, Theory

Keywords
Human-computer interaction, Semantic Web, interactive align-
ment, interaction model, mental model, semantic represen-
tation

1.

INTRODUCTION

In the early days of the Semantic Web the subject of
human-computer interaction (HCI) has played virtually no
role and only gradually receives the necessary attention. In
the beginning it was even discussed whether it would be
necessary to consider the specific issue of human-computer
interaction in the Semantic Web at all, or whether a separate consideration of both areas would be sufficient. The
first version of the Semantic Web Stack, as it was introduced
by Tim Berners-Lee at the international WWW conference
2005,1 therefore didnt yet contain an interaction layer at
all. This changed, however, in the second version, when
the new layer User Interface and Applications was introduced [2] so as to accommodate the increased importance of
human-computer interaction in the Semantic Web. This increase in importance was even more obvious by the growing
number of workshops on interaction in the Semantic Web,
as e.g.
the workshop series Semantic Web User Interaction (SWUI) or Visual Interfaces to the Social and Semantic Web (VISSW), and by the widespread introduction of
so-called in Use Tracks at Semantic Web conferences, as
e.g. at the ISWC and the ESWC, focusing on the presentation of new and mostly interactive approaches. Already
in 2005, Naeve asked in his article The Human Semantic
Web Shifting from Knowledge Push to Knowledge Pull [13]
for a combination of user semantics, represented in UML
diagrams, and computer semantics, represented in RDF, in
order to enable more user-friendly forms of interaction.

A key reason for this increased interest in the topic of
interaction is the gradually gained insight that the Semantic Web can be beneficial for average users only under the
precondition of a functioning human-computer interaction.
This benefit of the Semantic Web for the average users can
be divided into:

1http://www.w3.org/2005/Talks/0511-keynote-tbl/

150 Incorrect interpretation of the query: The computer is

not able to interpret the user query correctly.

 Missing or incorrect semantic data to answer the query:
The requested information is not or only incorrectly
represented in the Semantic Web (e.g. due to problems in automatically creating semantic data).

 False or misleading representation of the found results:

The computer displays information incorrectly.

 Incorrect interpretation of the representation: The user
is not able to interpret the displayed information cor-
rectly.

The use of artificial query languages like SPARQL (Fig.
1, C) and artificial output languages like RDF/XML or N3
(Fig. 1, F) can help to avoid these problems, but also requires tremendous expertise and is therefore more suitable
for experts. Apart from the distinction between creation
and access, we thus also distinguish between manual and
automatic methods to use the Semantic Web.

In this paper the term manual methods describes all
approaches to create and access semantic data where users
must make most of the practical and cognitive work; including the manual formulation of queries in artificial languages
such as SPARQL (Fig. 1, C) and the consumption of results
in languages such as RDF/XML (Fig. 1, F).

The term automatic method in contrast describes all approaches where the computer must make most of the practical and cognitive work, as e.g.
in the form of automatic
interpretation. This includes the automatic interpretation
of natural language queries (Fig. 1, B) and the transfer of
semantic data into natural language output (Fig. 1, D).

In our view are neither purely automatic nor purely manual methods suitable to enable the successful use of the Semantic Web. What is rather needed is an interactive approach which can compensate to varying degrees, lack of
automated methods by involving the user. Many such interactive approaches have already been presented in litera-
ture. A good overview of existing approaches until 2006 is
given e.g.
in the book Visualizing the Semantic Web [6].
Unfortunately, there is no state of the art report regarding
interaction in the Semantic Web from 2007 to the present to
our best knowledge. However, many papers exist that describe interesting individual approaches for the interactive
creation [8, 18] and access [9, 3] of semantic data.

The existing approaches, however, are usually either limited to very specific tasks or are optimized for specific data
sets or user groups. For the demonstration of the broad applicability and also flexibility of the Semantic Web, however,
a more general description of human-computer interaction
in the Semantic Web is needed. The involved processes and
components need to be explained at an abstract level and
thus detached from concrete implementations, so as to generate a broader understanding of the benefits of interaction
in the Semantic Web. A better understanding of the benefits and potential of interaction can help to recognize more
easily new application possibilities and to open up new domains and business fields. Unfortunately, at the moment
such a general description does not yet exist.

Due to the reasons described, in this paper we define a
first model for human-computer interaction in the Semantic
Web.
In order to deal with the mentioned problems regarding the interpretation of information on both, the user

Figure 1: The Semantic Web allows to store knowledge by creating semantic data (A, B and C) and to
use knowledge by accessing semantic data (D, E and
F).

 storing knowledge by creating semantic data (Fig. 1,

A, B and C)

 and using knowledge by accessing semantic data (Fig.

1, D, E and F).

Creating semantic data enables existing knowledge to be
represented in a semantically unambiguous manner and accessing semantic data makes it possible to quickly obtain
knowledge that is relevant for a particular situation.

Few users, however, will store knowledge in the form of artificial languages like RDF or OWL (Fig. 1, C), since it does
assume some expertise and time. They will rather prefer to
store knowledge primarily in the form of natural language
text (cf. Fig. 1, A) just as they are used to. Though the automatic interpretation of natural language text (Fig. 1, B)
in order to be able to store the implicitly contained knowledge explicitly as semantic data can be difficult because of
the following reasons (cf. [10]):

 The required ontological structure is not present: In order to automatically interpret information on a specific
topic, at least the corresponding abstract structures
(classes and relationships) need to be present.

 The quality of the automatic interpretation is not suf-
ficient: Computers are often not able to interpret natural language in sufficient quality.

 The existing semantic data is inconsistent and incom-
plete: The integration of newly extracted knowledge
into the Semantic Web is difficult because of the low
quality of the existing semantic data (many duplicates
as well as false and missing entries).

Just as in creating semantic data, people also prefer natural to artificial languages when accessing semantic data.
Both the formulation of queries (Fig. 1, A) and the representation of the results (Fig. 1, E) is to take place in
familiar ways. However, both the automatic interpretation
of requests (Fig. 1, B) as well as the automatic transfer of
semantic data, such as the results of a request, into information with implicit meaning, e.g. in a natural language text,
(Fig. 1, D) may be hampered by the following factors:

 Imprecise formulation of the need for information: The
user is not able to express his information need in a
computer understandable way.

151and the computer sides, we use a strategy called interactive
alignment that is well-known from human-to-human communication [16]. This strategy ensures that user and computer exchange information regularly and in short intervals
on how they have understood each other in order to quickly
recognize false interpretations and thus be able to correct
them as early as possible. In the following we describe our
new model for interaction in the Semantic Web with all its
components and functions in detail, both on an abstract
level and with concrete examples, and discuss its value and
potential for the future development of the Semantic Web.

2. A NEW INTERACTION MODEL

The most important reason why existing models, as e.g.
introduced by Norman [15] or by Ziegler and F ahnrich [19],
are not sufficient for describing the human-computer interaction in the Semantic Web, is the fact that in the Semantic
Web, also on the side of the computer, a semantic representation is present and thus also on the side of the computer
information is interpreted on the basis of existing semantic structures. We thus adapt the existing models to the
specific situation in the Semantic Web and extend them by
the concept of interactive alignment from human-to-human
communication.

Communication between two people can be conceived as
a game [11]. As with most other games, also the communication can be won or lost. The special is that you can win in
a communication only if both participants understand each
other. Once one of the two or both do not understand the
communication, both lose the game. Consequently, there
are either two winners or no winners. Cooperation is the
most successful strategy in a communication.

According to Pickering and Garrod [16] understanding
takes place in a communication on the alignment of the multidimensional models in the heads of the two people involved.
This is called mental models [14]. It contains representations
of different situational dimensions in a dialog where the main
ones are: space, time, causality, intention, and references to
important people and things. Here, the global alignment of
mental models is the result of many local alignment at the
semantic and syntactic-lexical level of representation. For
example, if on the basis of a statement of the dialogue partner certain parts of the own mental model are activated,
it increases the likelihood that these parts will determine
the own utterances semantically, syntactically and lexically.
This mechanism of interactive alignment, according to Pickering and Garrod, functions automatically and without additional expense [16].
2.1 Interactive Alignment in the Semantic Web
The concept of interactive alignment in human-to-human
communication provides for various reasons a good starting
point for developing a model of human-computer interaction
in the Semantic Web. Since the Semantic Web also contains an additional level with semantic representations, the
concept of interactive alignment, at least in part, can provide important evidence on how interaction can take place
across these multiple levels. Thus, interesting points of intersection between the concept of interactive alignment and
human-computer interaction in the Semantic Web are:

 Information representation on different levels: Dialogue participants, both in human-to-human commu-

nication as well as in human-computer interaction in
the Semantic Web represent information on syntacticlexical and semantic levels.

 Alignment necessary: Both in human-to-human communication as well as in human-computer interaction
in the Semantic Web a common understanding on the
semantics of the used syntactic-lexical expressions is
necessary. Otherwise, a successful dialogue is difficult.
 Automatic activation between different levels: As in
peoples minds, there are links between different levels also in the Semantic Web, with the result that the
alignment on one level leads to the automatic alignment at other levels.
In addition to a strong network within each level, many basal semantic representations e.g. are also connected to certain words
on the syntactic-lexical level (e.g. via the property
rdfs:label).

 Underlying mental models: As with the semantic representations in peoples minds, the semantic representations also in the Semantic Web are based on mental
models. These are, however, not located in the Semantic Web itself, but in the minds of the people who
created the semantic representations in the Semantic
Web. The alignment of mental models in the Semantic Web will therefore, in contrast to the alignment
in human-to-human communication, take place rather
indirectly (a more detailed description can be found in
section 2.3).

The fact that in the Semantic Web also the computer
can rely on semantic representations means that the humancomputer interaction in the Semantic Web is more like a
dialogue, as it occurs between two people, as the actuation
of levers and buttons to control a machine. Accordingly the
model for human-computer interaction in the Semantic Web
as it is shown in Fig. 2 has a level semantic representation
on both sides.

The interaction in this model is as follows: Based on a
specific intention and in comparison with his mental model
the user first checks to what extent this intention can be
reached; taking into account the prevailing situation and
the importance of achieving it. Based on the semantic representation of both the intention and all relevant aspects of
his mental model, the user plans his actions, creates appropriate syntactic-lexical requests and transmits their physical
representation to the Semantic Web (Fig. 2, left).

On the side of the Semantic Web, the transmitted physical representation is converted to a syntactic-lexical representation and then interpreted to a certain semantic repre-
sentation. According to the interpretation of the request, a
response is generated in syntactic-lexical form and its physical representation is finally sent back to the user (Fig. 2,
right).

After the response is perceived by the user, first the syntax
gets interpreted and converted into a semantic representa-
tion. Second, according to the semantic representation of the
transmission, the mental model gets adapted and its semantic representation gets updated. Then it will be determined
if, and to what degree, the intention has been achieved al-
ready. As long as the intention has not yet been reached and
there is no other interruption of the process, the next steps
are executed until the intended objective has been achieved.

152Figure 2: A model for human-computer interaction in the Semantic Web with a level of semantic representations also on the part of the computer (Semantic Web) and interactive alignment on syntactic-lexical,
semantic and mental level.

2.2 Syntactic-Lexical and Semantic Alignment
The great advantage of syntactic-lexical and semantic align-

ment is that the production and understanding processes are
coupled on both sides (Fig. 2). The interpretation of the
transmitted data is no longer isolated from each other, but
in agreement and therefore co-operative. This facilitates a
better communication between users and computers in the
Semantic Web and thus enables a faster and more successful
exchange of information.

Fig. 3 shows schematically and step by step how the interactive alignment process between user and Semantic Web
could take place. In the following we will use an example
to make this process more understandable.
In this exam-
ple, a user wants to obtain information about a commercial
bank in the city of Clinton. Therefore, he uses an interactive application that implements the introduced model of
interactive alignment in the Semantic Web.

The interactive alignment process starts with the intention
of the user to get information about the commercial bank in
Clinton (Fig. 3, A). The user has a clear and unambiguous
semantic representation of this bank in his mind, which he
tries to translate into a syntactic-lexical form, e.g.
in the
words bank and Clinton. After he has entered the words
into the application, the words are physically transmitted
to the computer where corresponding references (Resources)
are found in the Semantic Web. If the interpretation of a
word is not unique, e.g. the word bank could refer to both
a financial institute and a sloping land, there are several
possible semantic representations for selection (Fig. 3, B).
At this point a purely automated interpretation may have
limitations, e.g. because there are no or only inadequate
selection criteria available, and the advantage of the inter-

active alignment comes into play.

Thus, in the interactive alignment process all possible semantic representations of the word bank together with
their URIs (id in Fig. 3), their syntactic-lexical repre-
sentations, e.g.
in the form of labels (rdfs:label), and
first context information (Fig. 3, C), such as assigned ontological classes, are gathered and transferred back to the
user. On the other side the user tries to translate the transmitted syntactic-lexical representations (as e.g. the labels),
into unique semantic representations so to understand their
meaning (Fig. 3, D). If the syntactic-lexical representations
are insufficient for a clear and accurate translation, it is also
possible to consider the additional context information to
support the interpretation (good candidates are e.g.
the
ontological classes). If the provided context is still not suf-
ficient, further context can be obtained through exploration
along the semantic structures (see Fig. 4).

Once the context information is sufficient and the interpretation of the transmitted syntactic-lexical representation
can be achieved, it is now possible to evaluate the semantic representations with respect to the users initial intention (Fig. 3, E). After the right semantic representation
has been found, the corresponding syntactic-lexical representation is transmitted back to the computer where it can
be interpreted unambiguously due to its URI (Fig. 3, G).
Thus, both parties have agreed and the semantic alignment
is completed. From this point, the interpretation of the word
bank is clear on both sides and will therefore not lead
to misunderstandings within this particular dialogue any-
more.2 This will only work as long as words whose mean-

2It is important to note that every alignment has a time limited validity (it lasts usually only for a particular dialogue).

153Figure 3: The interactive alignment process between user (left) and Semantic Web (right).

Figure 4: Further context information can be obtained by explorations along the semantic structures.

ings have been already agreed are exclusively used with this
particular meaning and not in other context. Since such behavior would cause misunderstandings also in a human-to-
human dialogue, the users are intuitively familiar with this
problem. On the side of the computer, the problem can be
prevented by either transmitting such words always together
with their corresponding URI or creating a temporary table
of alignments (word-meaning).

An example of a concrete implementation of the process
described in Fig. 3 is the tool RelFinder 3 [7]. The RelFinder
extracts and visualizes relationships between given objects
in semantic datasets and makes these relationships interactively explorable.
In order to support the definition of
starting objects for the relationship search, the RelFinder
implements the interactive alignment process between user
and computer (Fig. 5). Once the user has entered the first
few letters, possibly matching objects are displayed below
the input field using an auto-completion feature (A). If the
correct object is not shown, a more extensive list may be obtained (B), and additional context in the form of abstracts

3The RelFinder can be accessed online at:
relfinder.visualdataweb.org.

http://

extracted from Wikipedia articles can be displayed (C) (c.f.
the process described in Fig. 4).

The described ambiguity of the words Clinton together
with the resulting need for an agreement about its correct
interpretation is just a very simple example of syntacticlexical and semantic alignment in the Semantic Web. The
new model allows for the interactive alignment of much more
complex situations and intentions through the combination
and repetition of the processes described in Fig. 3 and 4.
Even if the intention is not precisely known in advance or if
the user changes or extends his intentions due to e.g. new
findings made while interacting with the Semantic Web, the
model serves as the prerequisite to understand the processes
and to implement appropriate interaction tools.

2.3 Alignment of the Mental Models

Most of us will agree with the statement that a computer
might simulate a mind but never actually have a mind and
thus is not able to understand or think in the literal, nonmetaphorical sense. Searle [17] explains this with the fact
that the computer is not alive and therefore does not have its

154Figure 5: The RelFinder supports the interactive alignment process by auto completion (A), detailed lists
of possible interpretations (B) and additional context information in the form of abstracts extracted from
Wikipedia articles (C).

of this meaning, which up to this point was only implicitly
present for that specific man, can be made explicit. Due to
the unique assignment of a symbol to a thing via a certain
semantic representation, the interpretation of this symbol
can explicitly be defined in advance.

A good example is again the word Clinton. Although
many more different meanings are possible, we want to focus on the two most obvious classes: cities and persons. In
the U.S. alone, there are more than 20 cities and far more
than 20 popular persons with this name.
In the Semantic Web, there are corresponding semantic representations
for both classes, city and person, as well as for many of
the actual cities and persons with the name Clinton.
In
contrast to the ambiguity of the word Clinton, the meanings of these semantic representations, however, are unambiguous because of the existence of unique URIs.
In addition to these URIs, there are also many other properties in the Semantic Web that can help to distinguish the
different objects from each other. One important property is e.g. rdf:type that expresses an object-class relation and thus allows e.g.
to distinguish between objects
that are cities and objects that are persons. Within cities
with the name Clinton, important properties for differentiation are e.g.
dbpprop:state that indicates the citys
state or dbpedia-owl:populationTotal that indicates the
citys population. Within persons with the name Clinton,
important properties are e.g. dbpedia-owl:birthDate or
dbpedia-owl:birthPlace. Good sources of information are
also textual summaries, as e.g. available via the properties
dbpedia-owl:abstract or rdfs:comment. What connects
all the semantic representations of cities and persons, how-
ever, is the fact that their syntactic-lexical representations
are the word Clinton (that is defined via the property
rdfs:label) or at least contain this word, as e.g. the label Bill Clinton.

As described in the model of interactive alignment in the
Semantic Web, such semantic representations are the keys
to achieve a common understanding of terms that are used
in a dialogue between human and computer (see Figure 3).
Representations, however, can also be used e.g. to annotate

Figure 6: The classic semiotic triangle supplemented
by an additional node Representation in the Semantic Web as well as appropriate links to existing
nodes.

own perspective from which it perceives things 4. In contrast,
living beings 5 have their own perspective from which they
perceive things and from which these things have a meaning.
Having their own perspectives thus allows people to follow
their own targets and to gain their own advantages (which
can be advantageous under a specific perspective only).

In order to exchange the meanings of things between peo-
ple, symbols, as e.g. words or images, are required. The
relationships between symbol, thing, and meaning can be
illustrated by means of the semiotic triangle 6 (c.f. Fig. 6).
In addition to the known structure of the semiotic triangle,
Fig. 6 contains an extra node in the middle, which illustrates the function of semantic representation in this con-
text. The outer triangle stands for the basic statement: that
a symbol is not directly connected to a thing, but only indirectly by the meaning that the symbol has for a man. The
newly added inner node Representation in the Semantic
Web shows how the existence of a semantic representation

4In this context, the term thing refers to items, objects or
events in the real world.
5At this point, living beings refers to man.
6The semiotic triangle is a model of how linguistic symbols
are related to the things they represent. The idea of separation between symbol, thing and meaning is already found
in Plato and Aristotle.

155words in a text in order to uniquely define their meaning.
Ultimately, it should be understood that the different semantic representations in the Semantic Web only represent
what symbols in certain contexts mean to certain people, or
in other words, how symbols are interpreted by certain peo-
ple. The mental models of semantic representation in the
Semantic Web are therefore in the minds of the people who
create these representations (denoted as Community in Fig.
2) and not in the Semantic Web itself.

The creator of a semantic representation can thus be understood as a kind of dialogue partner that is using the
computer interface to sent information to the users [4]. An
alignment of mental models between creators (community)
and users of the Semantic Web is important because the
mental models differ not only from user to user, but also
from user to creator [14]. The users of the Semantic Web,
however, normally interact with the semantic representations stored in the Semantic Web and not directly with the
community (the creators). Therefore, a direct alignment of
mental models (see Fig. 2, model alignment), as is happening in human-to-human dialogue, is in the Semantic Web
only partly possible, if at all.

In the Semantic Web, the alignment of mental models
can be accomplished only indirectly, that is offset in time
or space. An example of a concrete implementation of the
indirect alignment of mental models in the Semantic Web is
the Softwiki tool [12]. The Softwiki tool is a Semantic Wiki
and thus allows a simple collaboration of many people in
the preparation of semantic data. The possibilities for com-
menting, discussing and rating enable an indirect exchange
between consumer and creator of semantic data and thus
an indirect alignment of their mental models. This requires,
however, that the creators of semantic data are also made
aware of appropriate feedback from consumer side; e.g. via
email.

3. POTENTIALS AND LIMITATIONS

In this section we are trying to provide a general assessment of the potentials and also the limitations of the general
model of interactive alignment in the Semantic Web.
3.1 Potentials

The greatest potential of our model is to provide a better understanding of the human-computer interaction, especially in the Semantic Web. The model describes all the
processes and components that are relevant for the interaction in the Semantic Web as well as their relationships at an
abstract and universal level. Through the clear separation
into a syntactic-lexical, a semantic and a model level, the
special significance of a semantic representation for the interaction on the computers side becomes obvious. At the same
time, the problems to exchange information between these
levels become more apparent, however, also the approach to
solve these problems by interactive alignment in the Semantic Web can be better understood. An understanding of the
problems, but also of their solutions are ultimately important prerequisites for successful use or implementation of the
model of interactive alignment in the Semantic Web.

Generally there are two ways to implement the model:
On the one hand, applications can be developed to specifically support only either the creation of semantic data, or
the access to them. On the other hand, applications can be
implemented with the objective to combine both activities

more closely. In the second case, blurring the boundaries between creation and access allows to better approximate the
general idea of interactive alignment in the Semantic Web.
Both, the computer and the user, should interactively adjust
to each other as it is the case with the dialogue between two
people.

The combination of both activities has the following ad-

vantages:

 Natural transmission of information: Contrary to a
strict separation between the creation of semantic data,
which is mostly done by experts, and the access to semantic data, offers a combination of both activities a
much more natural form of transfer of information.

 More recent information: If semantic data can be customized and supplemented by every user, then the latest information is in circulation much faster than if
only a small group of authorized experts is allowed to
change something.

 Fewer errors: With many people helping with the re-
views, it would be possible to notice and correct errors,
inconsistencies and incorrect information more quickly
(collective intelligence).

 More detailed information: If many people participate
in the creation, more detailed information can be converted into semantic data.

 Broader acceptance: A more democratic process increases the confidence in and the acceptance of the
semantic data (c.f. Wikipedia).

Through the advantages described above, a positive spiral can set in motion, which continuously increases both the
quantity and quality of semantic data as well as the number
of applications and thus the number of users of this data.
The more semantic data is available in high quality, the more
sense also makes the development of new interactive applications for the use of this data and thus leads to an increase
in the number of users of these applications. An increasing
number of users, in turn, increases the scope, quality and
timeliness of the data and thus further enhances the positive spiral.

DBpedia [1] and GeoNames 7, for example, already provide
semantic data in higher quality, but their scope is limited
to very specific and clearly defined domains. Through the
implementation of our model of interactive alignment in the
Semantic Web, more and more such islands of high quality
data could occur and gradually merge into larger units, as
it is also the goal of the LOD project 8.

In the medium and long term, an increased automation
of services in the course of a broad implementation of the
model of interactive alignment in the Semantic Web would
fundamentally change the way in which people interact with
computers. In contrast to an interaction that is more focused
on the operation and control of computers, human-computer
interaction would approach more and more a dialogue, similar to that between two people. However, there are also
hybrids possible, where as soon as the automated service

7http://www.geonames.org/
8http://www.w3.org/wiki/SweoIG/TaskForces/
CommunityProjects/LinkingOpenData

156is no longer sufficient, a real person is engaged in the dialogue that can solve particularly complex or rare problems.
Because of the very similar dialog behavior, people would
possibly not even be able to notice the difference between a
dialogue with a human and a dialogue with a computer (c.f.
Turing Test 9).
3.2 Limitations

Besides the large potential of the presented model of interactive alignment in the Semantic Web, it also has clear
limitations. According to this model, in most dialogs between humans and computers an approximation takes place
on both, the humans and the computers sides. As a result,
the semantic data is subject to a constant change process,
which, in addition to many positive effects, also can pose
consistency problems. In order to get these problems under
control, new approaches need to be developed and imple-
mented. For example, a mechanism is needed that can resolve or prevent inconsistencies, which may occur when data
is changed simultaneously by several parallel processes. One
possible solution would be to always block data that is being
processed for other dialogues. This would, however, hinder
many dialogues and thus limit the potential of available semantic data massively. Thus, a better solution would be
to create local copies for those parts of the semantic data
that are currently processed and re-integrate them in the
Semantic Web after the dialogue is completed. Although
many approaches exist for the automatic integration of semantic data [5], not all conflicts can be resolved automat-
ically. These conflicts, however, are often too complicated,
as they could be resolved by average users; quite apart from
the question whether solving these conflicts can be expected
by average users at all. For example, if a certain object has
been deleted in a local copy, a useful re-integration is often possible only by experts. However, being dependent on
experts limits the benefits of the model of interactive alignment in the Semantic Web significantly and should therefore
be avoided as much as possible.

A meaningful integration of changes is also difficult because the alignment on the mental level is only indirectly
possible in our model (see Fig. 2). The semantic data only
represents the meaning that things and events have for certain people. The real knowledge exists thus always only in
the minds of the people who have created the semantic representations (the experts), and not in the Semantic Web itself.
In fact, only these people can judge complex changes in the
semantic representations correctly and cause the appropriate actions to conserve their meaning. Because these ex-
perts, however, are only indirectly accessible (if any), there
is always a time gap between a change of a certain semantic
representation and its meaningful integration into the total stock of semantic data. But what happens in the time
until an expert is available to monitor the integration? Is
such monitoring by experts even possible or affordable? And
since the entire model of interactive alignment in the Semantic Web heavily relies on feedback cycles between machines
and humans in order to resolve ambiguities: Are users generally willing to accept the additional overhead that is caused
by such cycles?

Ultimately, also in the Semantic Web the computer will
remain just a placeholder, a representative for a real person

9http://www.loebner.net/Prizef/loebner-prize.html.

and a true human-to-human communication. The Semantic Web serves as a buffer in the transmission of knowledge
and information between people. The buffer can replace the
direct transmission by an indirect transmission, in order to
achieve a greater time, financial and social independence.
The passing of information from person to person, however,
remains the key driver for the further development of the
Semantic Web.

4. CONCLUSION AND FUTURE WORK

In this paper, we establish for the first time a general
model of interaction between humans and computers in the
Semantic Web. The motivation for such a model is derived
from the problems that are currently observed in the use
of the Semantic Web. As a reason for these problems, the
difficulties are identified, which predominate in the interpretation of information with implicit meaning, particularly on
the computers side. As a solution, we propose a specially
for the Semantic Web adjusted interaction between humans
and computers that allows to quickly detect errors in the
interpretation and to resolve them immediately.

As a basis for the new model of human-computer interaction in the Semantic Web, we use the concept of interactive
alignment that is known from the human-to-human commu-
nication. As people have internalized this concept already,
there are fewer problems in applying this strategy to communicate with the computer. The interactive alignment on
the syntactic-lexical as well as on the semantic level allows
to gradually achieve agreements on both the use and the
combination of symbols as well as the associated semantics.
Simultaneously, the gradual alignment also allows an immediate intervention and correction when misunderstandings
arise between human and computer. However, alignments
at the mental level can only be made indirectly, since only
the representations of the meanings are available in the Semantic Web; the underlying mental models, however, exist
only in the minds of the people who created these represen-
tations.

In future work, we plan to proof the applicability and potentials of the introduced new model of interactive alignment
in the Semantic Web by further concrete implementations
of it and interactive tools. The goal is to make the Semantic Web visually more experienceable, also for average Web
users with little to no knowledge about the underlying tech-
nologies. We thus understand our work described in this
paper as a basis to generate new ideas, methods, and tools
that help making the Semantic Web easier accessible, more
visible, and thus more attractive.
