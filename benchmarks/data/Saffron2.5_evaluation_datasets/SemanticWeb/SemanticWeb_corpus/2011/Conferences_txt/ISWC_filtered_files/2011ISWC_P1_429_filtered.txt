Large Scale Fuzzy pD

Reasoning Using

MapReduce

Chang Liu1, Guilin Qi2, Haofen Wang1, and Yong Yu1

1 Shanghai Jiaotong University, China

{liuchang,whfcarter,yyu}@apex.sjtu.edu.cn

2 Southeast University, China

gqi@seu.edu.cn

Abstract. The MapReduce framework has proved to be very efficient
for data-intensive tasks. Earlier work has tried to use MapReduce for
large scale reasoning for pD
semantics and has shown promising results.
In this paper, we move a step forward to consider scalable reasoning on
top of semantic data under fuzzy pD
semantics (i.e., an extension of
OWL pD
semantics with fuzzy vagueness). To the best of our knowl-
edge, this is the first work to investigate how MapReduce can help to
solve the scalability issue of fuzzy OWL reasoning. While most of the
optimizations used by the existing MapReduce framework for pD
se-
mantics are also applicable for fuzzy pD
semantics, unique challenges
arise when we handle the fuzzy information. We identify these key chal-
lenges, and propose a solution for tackling each of them. Furthermore,
we implement a prototype system for the evaluation purpose. The experimental results show that the running time of our system is comparable
with that of WebPIE, the state-of-the-art inference engine for scalable
reasoning in pD

semantics.

1 Introduction

The Resource Description Framework (RDF) is one of the major representation
standards for the Semantic Web. RDF Schema (RDFS) is used to describe vocabularies used in RDF descriptions. However, RDF and RDFS only provide a very
limited expressiveness. In [3], a subset of Ontology Web Language (OWL) vocabulary (e.g., owl:sameAs) was introduced, which extends the RDFS semantics
 fragment of OWL. Unlike the standard OWL (DL or Full) semantics
to the pD
 fragment follows
which provides the full if and only if semantics, the OWL pD
 fragment provides a complete set
RDF(S)s if semantics. That is, the OWL pD
of entailment rules, which guarantees that the entailment relationship can be
determined within polynomial time under a non-trivial condition (if the target
graph is ground). It has become a very promising ontology language for the Semantic Web as it trades off the high computational complexity of OWL Full and
the limited expressiveness of RDFS.

Recently, there is an increasing interest in extending RDF to represent vague
information on Web. Fuzzy RDF allows us to state to a certain degree, a triple

L. Aroyo et al. (Eds.): ISWC 2011, Part I, LNCS 7031, pp. 405420, 2011.
c Springer-Verlag Berlin Heidelberg 2011

C. Liu et al.

is true. For example, (T om, eat, pizza) is true with degree at least 0.8. How-
ever, Fuzzy RDF (or fuzzy RDFS) has limited expressive power to represent
information in some real life applications of ontologies, such as biomedicine and
 fragment with fuzzy semantics to
multimedia. In [4], we extended the OWL pD
provide more expressive power than fuzzy RDF(S). In that work, we focused on
some theoretical problems, such as the complexity issues, without providing an
 semantics
efficient reasoning algorithm for the new semantics. Since fuzzy pD
is targeted to handle large scale semantic data, it is critical to provide a scalable
reasoning algorithm for it.

Earlier works (e.g.

[12]) have proved that MapReduce is a very efficient
framework to handle the computation of the closure containing up to 100 billion
 semantics. One may wonder if it is helpful to scalable reatriples under pD
 semantics. It turns out that this is a non-trivial problem
soning in fuzzy pD
 semantics requires the comas the computation of the closure under fuzzy pD
putation of the Best Degree Bound (BDB) of each triple. The BDB of a triple
is the greatest lower bound of the fuzzy degrees of this triple. Although most
 semantics are also
of the optimizations for reasoning with MapReduce in pD
 semantics, unique challenges arise when we handle
applicable for the fuzzy pD
the fuzzy information.

In this paper, we first identify some challenges to apply the MapReduce frame-
 semantics. We then propose an algowork to deal with reasoning in fuzzy pD
rithm for fuzzy pD reasoning by separately considering fuzzy D rules and fuzzy
p rules. After that, we propose the map function and the reduce function for
 rules that may cause difficulties. Finally, we implement a proseveral fuzzy pD
totype system to evaluate these optimizations. The experimental results show
that the running time of our system is comparable with that of WebPIE [12]
which is the state-of-the-art inference engine for OWL pD

 fragment.

2 Background Knowledge

In this section, we first introduce the fuzzy pD
then explain the MapReduce framework for reasoning in OWL pD
Section 2.2.

 entailment rule set in Section 2.1,
 fragment in

Fuzzy pD

2.1 Fuzzy RDF and Fuzzy pD Reasoning
A fuzzy RDF graph is a set of fuzzy triples which are in form of t[n]. Here t is
a triple, and n  (0, 1] is the fuzzy degree of t.
 semantics with fuzzy semantics
 semantics, given in [4], extends pD

so that there is a complete and sound entailment rule set in fuzzy OWL pD
fragment. We list part of them in Table 1 by excluding some naive rules. The
notion of a (partial) closure can be easily extended to the fuzzy case.
 semantics is called the Best Degree Bound (BDB)
of a triple. The BDB n of an arbitrary triple t from a fuzzy RDF graph G is
defined to be the largest fuzzy degree n such that t[n] can be derived from G by
-entailment rules, or 0 if no such fuzzy triple can be derived.
applying fuzzy pD

The key notion in fuzzy pD
?

?

?
Reasoning Using MapReduce

Table 1. Difficult part of fuzzy pD

-entailment rules

Condition Conclusion
f-rdfs2
f-rdfs3
f-rdfs5
f-rdfs7x
f-rdfs9
f-rdfs11
f-rdfs12
f-rdfs13
f-rdfp1
f-rdfp2

(v, type, u)[n  m]
(p, domain, u)[n] (v, p, w)[m]
(v, type, w)[n  m]
(p, range, w)[n] (v, p, w)[m]
(v, subPropertyOf, u)[n  m]
(v, subPropertyOf, w)[n] (w, subPropertyOf, u)[m]
(v, q, w)[n  m]
(p, subPropertyOf, q)[n] (v, p, w)[m]
(u, type, w)[n  m]
(v, subClassOf, w)[n] (u, type, v)[m]
(v, subClassOf, u)[n  m]
(v, subClassOf, w)[n] (w, subClassOf, u)[m]
(v, type, ContainerMembershipProperty)[n]
(v, subPropertyOf, member)[n]
(v, type, Datatype)[n]
(v, subClassOf, Literal)[1]
(p, type, FunctionalProperty)[n] (u, p, v)[m] (u, p, w)[l] (v, sameAs, w)[l  m  n]
(p, type, InverseFunctionalProperty)[n]
(u, sameA, v)[l  m  n]
(u, p, w)[m] (v, p, w)[l]
(w, p, v)[n  m]
(p, type, SymmetricProperty)[n] (v, p, w)[m]
(u, p, w)[n  m  l]
(p, type, TransitiveProperty)[n] (u, p, v)[m] (v, p, w)[l]
(v, sameAs, v)[1], (w, sameAs, w)[1]
(v, p, w)[n]
(v, sameAs, w)[n]
(w, sameAs, v)[n]
(u, sameAs, w)[n  m]
(u, sameAs, v)[n] (v, sameAs, w)[m]
(w, q, v)[n  m]
(p, inverseOf, q)[n] (v, p, w)[m]
(w, p, v)[n  m]
(p, inverseOf, q)[n] (v, q, w)[m]
(v, subClassOf, w)[m]
(v, type, Class)[n] (v, sameAs, w)[m]
(p, subPropertyOf, q)[m]
(p, type, Property)[1] (p, sameAs, q)[m]
)[n  m  l]
?

?

?
(u
(u, p, v)[n] (u, sameAs, u

f-rdfp3
f-rdfp4
f-rdfp5(ab)
f-rdfp6
f-rdfp7
f-rdfp8ax
f-rdfp8bx
f-rdfp9
f-rdfp10
f-rdfp11
f-rdfp12(ab) (v, equivalentClass, w)[n]  (v, subClassOf, w)[n],(w, subClassOf, w)[n]
f-rdfp12c
f-rdfp13(ab) (v, equivalentProperty, w)[n]  (v, subPropertyOf, w)[n], (w, subPropertyOf, w)[n]
f-rdfp13c
f-rdfp14a
f-rdfp14bx
f-rdfp15

(v, subClassOf, w)[n] (w, subClassOf, v)[m]

(v, subPropertyOf, w)[n] (w, subPropertyOf, v)[m]
(v, hasValueOf, w)[n] (v, onProperty, p)[m] (u, p, w)[l]
(v, hasValueOf, w)[n] (v, onProperty, p)[m] (u, type, v)[l] (u, p, w)[n  m  l]
(v, someValueFrom, w)[n] (v, onProperty, p)[m]
(u, p, x)[l] (x, type, w)[k]
(v, allValuesfrom, w)[m] (v, onProperty, p)[n]
(u, type, v)[l] (u, p, x)[k]

(u, type, v)[n  m  l  k]
(x, type, w)[n  m  l  k]

(v, equivalentClass, w)[min(n, m)]
(u, type, v)[n  m  l]

(v, equivalentClass, w)[min(n, m)]

)[m] (v, sameAs, v

)[l]

f-rdfp16
?

?

?
, p, v

2.2 MapReduce Algorithm for pD Reasoning
MapReduce is a programming model introduced by Google for large scale data
processing [1]. A MapReduce program is composed of two user-specified func-
tions, map and reduce. When the input data is appointed, the map function scans
the input data and generates intermediate key/value pairs. Then all pairs of key
and value are partitioned according to the key and each partition is processed
by a reduce function.

We use an example to illustrate how to use a MapReduce program to apply

a rule. Here, we consider Rule rdfs2 which reads:

(p, domain, u), (v, p, w)  (v, type, u)

The map function scans the data set, and checks every triple if it has the form
(p, domain, u) or (v, p, w). If a triple has the form (p, domain, u), then the map
function generates an output (key=p, value={flag=L, u}). While a triple in
the form of (v, p, w) is scanned, the map function generates an output (key=p,
value={flag=R, v}). The reduce function gets all outputs of the map function
that share the same key together. Then it enumerates all values with flag L to
get all u and enumerates all values with flag R to get all v. For each pair of u
and v, the reduce function generates a new triple (v, type, u) as output.

There are several key factors to make a MapReduce program efficient. Firstly,
since the map function operates on single pieces of data without dependencies,

C. Liu et al.

partitions can be created arbitrarily and can be scheduled in parallel across many
nodes. Secondly, the reduce function operates on an iterator of values since the
set of values is typically too large to fit in memory. So the reducer should treat
the values as a stream instead of a set. Finally, all the outputs of mappers
sharing the same key will be processed by the same reduce function. Therefore,
the reducer that processes one popular key will run very slowly. The mappers
output keys should be carefully designed to ensure that the sizes of all partitions
should be balanced.

Due to these reasons, the naive implementations of rules may be very inef-
ficient. In [12] and [13], several optimizations are proposed that improve the
 fragment significantly. We list them as
performance of inference in OWL pD
follows.

 Loading schema triples in memory. Since the set of schema triples is
generally small enough to fit in memory, when performing a join over schema
triples, we can load them into memory. Then, the join can be performed
directly between the loaded data and the in-memory schema triples.

 Data grouping to avoid duplicates. Some RDFS rules may generate
duplicates. However, using carefully designed algorithms, such duplicates
can be avoided.

 Ordering the RDFS rule applications. Arbitrarily applying the rules
will result in a fixpoint iteration. For RDFS rules, such a fixpoint iteration
can be avoided by applying rules in a specific order.

 Transitive algorithm. An efficient algorithm to calculate the transitive
closure is designed, which will produce a minimal amount of duplicates and
minimize the number of iterations.
 fragment, [12] uses the canonical repre-
 Sameas algorithm. For OWL pD
sentation to deal with the sameas rules. This method greatly reduces both
the computation time and the space required.

 someValuesFrom and allValuesFrom algorithm. In both rules involve
someValuesFrom and allValuesFrom, three joins among four triples are
needed. However, two of the four triples are schema triples so that they
can be loaded into memory. Furthermore by choosing the output key, the
map function will generate balanced partitions for the reduce function.

3 MapReduce Algorithm for Fuzzy pD

Reasoning

In this section, we first illustrate how to use a MapReduce program to apply a
 reasoning
fuzzy rule. Then, we give an overview of the challenges in fuzzy pD
when applying the MapReduce framework. Finally, we present our solutions to
handle these challenges.

3.1 Naive MapReduce Algorithm for Fuzzy Rules

We consider rule f-rdfs2 to illustrate our naive MapReduce algorithms:
?

?

?
Reasoning Using MapReduce

Algorithm 1. map function for rule f-rdfs2
Input: key, triple
1: if triple.predicate == domain then
emit({p=triple.subject}, {flag=L, u=triple.object, n=triple.degree};
2:
3: end if
4: emit({p=triple.predicate}, {flag=R, v=triple.subject, m=triple.degree};

Algorithm 2. reduce function for rule f-rdfs2
Input: key, iterator values
1: unSet.clear();
2: vmSet.clear();
3: for value  values do
4:
5:
6:
7:
end if
8:
9: end for
10: for i  unSet do
11:
12:
13:
14: end for

emit(null, triple(i.u, type, j.v, i.nj.m));

for j  vmSet do

vmSet.update(value.v, value.m);

if value.flag == L then

unSet.update(value.u, value.n);

else

end for

(p, domain, u)[n], (v, p, w)[m]  (v, type, u)[n  m]

In this rule, we should find all fuzzy triples that are either in the form of
(p, domain, u)[n] or in the form of (v, p, w)[m]. A join should be performed
over the variable p. The map and reduce functions are given in Algorithms 1
and 2 respectively. In the map function, when a fuzzy triple is in the form of
(p, domain, u)[n] (or (v, p, w)[m]), the mapper emits p as the key and u (or v)
along with the degree n (or m) as the value. The reducer can use the flag in
the mappers output value to identify the content of the value. If the flag is
L (or R), the content of the value is the pair (u, n) (or the pair (v, m)). The
reducer uses two sets to collect all the u, n pairs and the v, m pairs. After all
pairs are collected, the reducer enumerates pairs (u, n) and (v, m) to generate
(u, type, v)[n  m] as output.
3.2 Challenges in Fuzzy pD Reasoning
 rules,
Even though the fuzzy pD
several difficulties arise when we calculate the BDB for each triple by applying
the MapReduce framework. We summarize these challenges as follows:

 entailment rules are quite similar to the pD

 semantics, the reasoner might
Ordering the rule applications. In fuzzy pD
produce the duplicated triple with different fuzzy degrees before the fuzzy BDB

C. Liu et al.

triple is derived. For example, suppose the data set contains a fuzzy triple t[m],
when we derive a fuzzy triple t[n] with n > m, a duplicate is generated. When
duplicates are generated, we should employ a duplicate deleting program to
reproduce the data set to ensure that only the fuzzy triples with maximal degrees are in the data set. Different rule applications order will result in different
number of such duplicates. To achieve the best performance, we should choose
a proper order to reduce the number of duplicates. For instance, the subproperty rule (f-rdfs7x) should be applied before the domain rule (f-rdfs2); and the
equivalent class rule (f-rdfp12(abc)) should be considered together with the subclass rule (f-rdfs9, f-rdfs10). The solution for this problem will be discussed in
Section 3.3.

 fragment, the three rules, rdfs5
Shortest path calculation. In OWL pD
(subproperty), rdfs11 (subclass) and rdfp4 (transitive property) are essentially
used to calculate the transitive closure over a subgraph of the RDF graph. In
, when we treat each fuzzy triple as a weighted edge in the RDF
fuzzy OWL pD
graph, then calculating the closure by applying these three rules is essentially a
variation of the all-pairs shortest path calculation problem. We have to find out
efficient algorithms for this problem. In Section 3.4, we will discuss the solutions
for rules f-rdfs5 and f-rdfs11, while discuss rule f-rdfp4 in Section 3.5.

 fragment, the traditional technique to handle the
Sameas rule. For OWL pD
semantics of sameas is called canonical representation. Rules rdfp6 and rdfp7 enforce that sameas is a symmetric and transitive property, thus the sameas closure
obtained by applying these two rules is composed of several complete subgraphs.
The instances in the same subgraph are all synonyms, so we can assign a unique
key, which we call the canonical representation, to all of them. Replacing all the
instances with its unique key results in a more compact representation of the
RDF graph without loss of completeness for inference.
 semantics, we cannot choose such a canonical
representation as illustrated by the following example. Suppose we use the min
as the t-norm function. Given a fuzzy RDF graph G containing seven triples:

However, in the fuzzy pD

(u, b, v)[0.9]

(a, sameas, b)[0.8] (b, sameas, c)[0.1] (c, sameas, d)[0.8]
(a, range, r)[0.9]
From this graph, we can derive (v, type, r)[0.8]. Indeed, we can derive (b,
range, r)[0.8] by applying rule f-rdfp11 over (a, sameas, b)[0.8], (a, range, r)[0.9]
and (r, sameas, r)[1.0]. Then we can apply rule f-rdfs3 over (b, range, r)[0.8]
and (u, b, v)[0.9] to derive (v, type, r)[0.8].

(c, domaine)[1]

)[0.9]

, d, v

In this graph, four instances, a, b, c and d are considered as synonyms in the
 semantics. Suppose we choose c as the canonical representation,
 containing

classical pD
then the fuzzy RDF graph is converted into the following graph G
four fuzzy triples:

(c, range, r)[0.1] (u, c, v)[0.1] (c, domaine)[1] (u
From this graph, we can derive the fuzzy triple (v, type, r)[0.1], and this is
, which means we cannot derive the fuzzy triple,
a fuzzy BDB triple from G
(v, type, r)[0.8]. The reason is that after replacing a and b with c, the fuzzy

, c, v

)[0.8]
?

?

?
(u
?

?

?
Reasoning Using MapReduce

information between a and b, e.g. the fuzzy triple (a, sameas, b)[0.8], is missing.
Furthermore, no matter how we choose the canonical representation, some information will inevitably get lost during the replacement. We will discuss the
solution for this problem in Section 3.6.

3.3 Overview of the Reasoning Algorithm

Our main reasoning algorithm is Algorithm 3, which can be separated into two
phases: the first phase (line 3) applies the fuzzy D rules (from f-rdfs1 to f-rdfs13),
and the second phase (lines 7 to line 9) applies the fuzzy p rules (from rdfp1
to rdfp16). However, since some fuzzy p rules may generate some fuzzy triples
having effect on fuzzy D rules, we execute these two phases iteratively (line 2 to
line 11) until a fix point is reached (line 4 to line 6).

In the first phase, we consider the following order of rule applications such
that we can avoid a fix point iteration. Firstly, we apply the property inheritance
rules (f-rdfs5 and f-rdfs7), so that domain rule (f-rdfs2) and range rule (f-rdfs3)
can be applied consecutively without loosing any important fuzzy triples. Then
the class inheritance rules (f-rdfs9 and f-rdfs11) along with the rest rules are
applied together. Similar techniques have been used in [13] for RDFS. Compared
with [13], our algorithm relies on the computation of rules f-rdfs5, f-rdfs7, f-rdfs9
and f-rdfs11. We will discuss this point in the next section.

For the fuzzy p rules, there is no way to avoid a fixpoint iteration. So we employ
an iterative algorithm to calculate the p closure. In each iteration, the program
can be separated into five steps. In the first step, all non-iterative rules (rules
f-rdfp1, 2, 3, 8) are applied. The second step processes the transitive property
(rule f-rdfp4) while the sameas rules (rule f-rdfp6, 7, 10, 11) are applied in the
third step. The rules related to equivalentClass, equivalentProperty and
hasValue are treated in the fourth step, because we can use the optimizations for
 fragment to compute the closure of these rules in a nonreasoning in OWL pD
iterative manner. The someValuesFrom and allValuesFrom rules are applied in
the fifth step which needs a fixpoint iteration. The first step and the last two
steps can employ the same optimization discussed in [12]. We will discuss the
solution to deal with transitive property in Section 3.5. Finally the solution to
tackle sameas rules will be discussed in Section 3.6.

3.4 Calculating subClassOf and subPropertyOf Closure

Rules f-rdfs5, 6, 7, f-rdfp13(abc) process the semantics of subPropertyOf property while rules f-rdfs9, 10, 11 and f-rdfp12(abc) mainly concern the semantics
of subClassOf property. Since they can be disposed similarly, we only discuss
the rules that are relevant to subClassOf. Since f-rdfs10 only derives a triple
(v, subClassOf, v)[1] which will have no affect on other rules, we only consider
rules f-rdfs5, 7 and f-rdfp12(abc).

We call the triples in the form of (u, subClassOf, v)[n] to be subClassOf
triples. The key task is to calculate the closure of subClassOf triples by applying
rule f-rdfs11. Since the set of subClassOf triples is relatively small, we can
?

?

?
derived = apply fD rules();
if derived == 0 and not first time then

C. Liu et al.

Algorithm 3. Fuzzy pD
1: first time = true;
2: while true do
3:
4:
5:
6:
7:
8:
9:
10:
11: end while

until derived == 0;
first time = false;

end if ;
repeat

break;

derived = apply fp rules();

for i  I and w(i, k) > 0 do

for j  I and w(k, j) > 0 do

Algorithm 4. Calculate the subClassOf closure
1: for k  I do
2:
3:
4:
5:
6:
7:
8:
9: end for

if w(i, k)  w(k, j) > w(i, j) then

w(i, j) = w(i, k)  w(k, j);

end if
end for

end for

load them into memory. We can see that calculating the subClassOf closure
by applying rule f-rdfs11 is indeed a variation of the all-pairs shortest path
calculation problem, according to the following property:

Property 1. For any fuzzy triple in the form of (u, subClassOf, v)[n] that
can be derived from the original fuzzy RDF graph by only applying rule f-rdfs11,
there must be a chain of classes w0 = u, w1, ..., wk = v and a list of fuzzy
degrees d1, ..., dk where for every i = 1, 2, ..., k, (wi1, subClassOf, wi)[dk] is in
the original fuzzy graph and n = d1  d2  ...  dk.

So we can use the FloydCWarshall style algorithm given in Algorithm 4 to
calculate the closure. In the algorithm, I is the set of all the classes, and w(i, j)
is the fuzzy degree of triple (i, subClassOf, j). The algorithm iteratively update
the matrix w. When it stops, the subgraph represented by the matrix w(i, j) is
indeed the subClassOf closure.
The worst-case running complexity of the algorithm is O(|I|3), and the algorithm uses O(|I|2) space to store the matrix w. When |I| goes large, this is unac-
ceptable. However, we can use nested hash map instead of 2-dimension arrays to
only store the positive matrix items. Furthermore, since 0n = n0 = 0, in line
2 and line 3, we only enumerate those i and j where w(k, i) > 0 and w(k, j) > 0.
In this case, the running time of the algorithm will be greatly reduced.

After the subClassOf closure is computed, rules f-rdfs9 and f-rdfs11 can be
applied only once to derive all fuzzy triples: for rule f-rdfs9 (or f-rdfs11), when
?

?

?
Reasoning Using MapReduce

Algorithm 5. map function for rule f-rdfp4
Input: length, triple=(subject, predicate, object)[degree], n

if getTransitiveDegree(predicate) == 0 then

return;

end if
if length ==2n2 or length == 2n1 then

emit({predicate, object}, {flag=L, length, subject, degree};

end if
if length > 2n2 and length  2n1 then

emit({predicate, subject}, {flag=R, length, object, degree};

end if

we find a fuzzy triple (i, type, v)[n] (or (i, subClassOf, v)[n]), we enumerate all
classes j so that w(v, j) > 0 and output a fuzzy triple (i, type, j)[n w(v, j)] (or
(i, subClassOf, j)[n  w(v, j)]).

For rule f-rdfp12(abc), since equivalentClass triples are also schema triples,
we load them into memory and combine them into the subClassOf graph.
Specifically, when we load a triple (i, equivalentClass, j)[n] into memory, if
n > w(i, j) (or n > w(j, i)), we update w(i, j) (or w(j, i)) to be n . After the closure is calculated, two fuzzy triples (i, equivalentClass, j)[n] and
(j, equivalentClass, i)[n] are output for each pair of classes i, j  I, if n =
min(w(i, j), w(j, i)) > 0.

3.5 Transitive Closure for TransitiveProperty

The computation of the transitive closure by applying rule f-rdfp4 is essentially
calculating the all-pairs shortest path on the instance graph. To see this point,
we consider the following property:

Property 2. Suppose there is a fuzzy triple (p, Type, TransitiveProperty)[n]
in the fuzzy RDF graph G, and (a, p, b)[m] is a fuzzy triple that can be derived
from G using only rule f-rdfp4. Then there must be a chain of instances u0 =
a, u1, ..., uk = b and a list of fuzzy degree d1, ..., dk such that m = d1  n  d2 
...  n  dk, and for every i = 1, 2, ..., k, (ui1, p, up)[di] is in the original fuzzy
RDF graph. Furthermore, in one of such chains, ui = uj, if i = j and i, j  1.
We use an iterative algorithm to calculate this transitive closure. In each itera-
tion, we execute a MapReduce program using Algorithm 5 as the map function
and Algorithm 6 as the reduce function.

We use getTransitiveDegree(p) function to get the maximal n such that
(p, type, TransitiveProperty)[n] is in the graph. Since these triples are schema
triples, we can load them into memory before the mappers and reducers are exe-
cuted. In the map function, n is the number of iterations that the transitive closure calculation algorithm already executes. Since for any fuzzy triple (a, p, b)[m],
there is at least one chain u0 = a, u1, ..., uk = b according to Property 2, we use
variable length to indicate the length of the shortest chain of (a, p, b)[m]. At the

C. Liu et al.

Algorithm 6. reduce function for rule f-rdfp4
Input: key, iterator values

left.clear();
right.clear();
for value  values do

if value.flag == L then

left.update(value.subject, {value.degree, value.length});
right.update(value.object, {value.degree, value.length});

else

end if
end for
for i  left do

for j  right do

newLength = i.length + j.length;
emit(newLength, triple(i.subject, key.predicate, j.object,

i.degree  j.degree getTransitiveDegree(key.predicate)));

end for

end for

beginning of the algorithm, for every triple (a, p, b)[n] in the fuzzy RDF graph,
length is assigned to be one.

If (a, p, b)[m] has a chain u0, u1, ..., uk with length k, and it can be derived from
(a, p, t)[m1] and (t, p, b)[m2] in the n-th iteration, then we have m1 + m2 = m,
m1 = 2n2 or 2n1, and 2n2 < m2  2n1. We can prove the integer equation
m1 + m2 = m has a unique solution satisfying m1 = 2n2 or m1 = 2n1, and
2n2 < m2  2n1. Thus for such a chain, the triple (a, p, b)[m] will be generated
only once. As a consequence, a fuzzy triple will be generated at most as many
times as the number of chains it has. In most circumstances, every fuzzy triple
will be generated only once.
Furthermore, based on the above discussion, if a fuzzy triple (a, p, b)[m] has
a chain with length 2n1 < l  2n, it will be derived within n iterations. As
a consequence, the algorithm will terminate within log N iterations where N is
the number of all instances in the graph.

3.6 Handling SameAs Closure

The rules related to sameas are f-rdfp5(ab), 6, 7, 9, 10 and 11. Rules f-rdfp5(ab)
are naive rules which can be implemented directly. The conclusion of Rule f-
rdfp9 can be derived by applying rules f-rdfs10 and f-rdfp11. Rule f-rdfp10 allows
replacing the predicate with its synonyms. Thus we only consider the rules f-
rdfp6 and f-rdfp7, and the following variation of rule f-rdfp11, called f-rdfp11x:

(u, p, v)[n], (u, sameas, u

)[m], (v, sameas, v

)[l], (p, sameas, p
?

?

?
)[k]
?

?

?
 (u
?

?

?
, p

, v
?

?

?
)[n  m  l  k]
?

?

?
Reasoning Using MapReduce

The first two rules only affect the computation of sameas closure, and the

rule f-rdfp11x influences the other rules computation.

For convenience, we call a fuzzy triple in the form of (i, sameas, j)[n] a sameas
triple. We further call the sameas triples with fuzzy degree 1 the certain sameas
triples, and the others with fuzzy degree less than 1 the vague sameas triples.
The sameas problem is caused by those vague sameas triples. Thus for certain
sameas triples, the canonical representation technique is still applicable. In real
applications, such as Linking Open Data project, most of the sameas triples
are certain in order to link different URIs across different datasets. Thus the
traditional technique will be helpful to solve the problem.
 semantics allows using sameas triples to represent the
similarity information. For these triples, we must store all of them and calculate
the sameas closure using rules f-rdfp6 and f-rdfp7 to ensure the inference to be
complete.

However, the fuzzy pD

Materializing the result by applying the rule f-rdfp11x will greatly expand the
dataset which may cause fatal efficiency problems. To accelerate the computa-
tion, we do not apply rule f-rdfp11x directly. Instead, we modify the algorithms
for other rules to consider the effect of rule f-rdfp11x.

In the following, we use rule f-rdfs2 mentioned in 3.1 as an example to illustrate
the modification. In rule f-rdfs2, two fuzzy triples join on p. Considering rule f-
)[n], then we can
rdfp11x, if the dataset contains a fuzzy triple (p, sameas, p
make the following inference by applying f-rdfp11x and f-rdfs2:
?

?

?
)[n]  (v, type, u)[n  m  k]

, w)[k], (p, sameas, p

(p, domain, u)[m], (v, p
We use Algorithm 7 to replace Algorithm 1 as the map function. The difference
is that Algorithm 7 uses a loop between line 2 and line 5 instead of line 2 in
Algorithm 1. In practice, vague sameas triples are relatively few. Thus we can
load them into memory and compute the sameas closure before the mappers are
launched. When the mapper scans a triple in the form of (p, domain, u)[m], the
mapper looks up the sameas closure to find the set of fuzzy triples in the form
 along
, n), the mapper outputs a key p
of (p, sameas, p
with a value {flag=L, u=triple.object, m  n}. While processing key p
, the
reducer will receive all the values of u and m  n. Furthermore, the reducer
will receive all values of v and k outputted by the mapper in line 7. Thus the
reducer will generate fuzzy triples in the form of (v, type, u)[nmk] as desired.
Similarly we can modify the algorithms for other rules to consider the effect of
rule f-rdfp11x.

)[n]. For each pair (p

Finally, we discuss the sameas problem while processing the rules f-rdfp1 and
f-rdfp2, since they generate sameas triples. We only discuss the rule f-rdfp1 since
the other is similar. Consider a fuzzy graph G containing the following n + 1
fuzzy triples:

(a, p, b1)[m1] (a, p, b2)[m2] ... (a, p, bn)[mn]
(p, type, FunctionalProperty)[k]
By applying the rule f-rdfp1, we can derive n(n  1)/2 fuzzy triples in the
form of (bi, sameas, bj)[k  mi  mj].

C. Liu et al.

for (subject, sameas, p

)[n] is in the sameas closure do

Algorithm 7. map function for rules f-rdfs2 and f-rdfp11
Input: key, triple
1: if triple.predicate == domain then
2:
3:
4:
5:
6: end if
7: emit({p=triple.predicate}, {flag=R, v=triple.subject, k=triple.degree};

m = triple.degree;
emit({p=p}, {flag=L, u=triple.object, m  n};

end for

4 Experiment

Since there is no system supporting fuzzy pD

We implemented a prototype system based on the Hadoop framework1, which is
an open-source Java implementation of MapReduce. Hadoop uses a distributed
file system, called HDFS2 to manage executions details such as data transfer,
job scheduling, and error management.
 reasoning, we run our system
over the standard LUBM data, and validate it against the WebPIE reasoner
which supports inference of Horst fragment to check the correctness of our algo-
rithms. Our system can produce the same results as WebPIE. Furthermore, we
 ontologies, and a naive inference system for validabuild some small fuzzy pD
tion purpose. Our system can produce the same results on all these ontologies.
The experiment was conducted in a Hadoop cluster containing 25 nodes. Each
node is a PC machine with a 4-core, 2.66GHz, Q8400 CPU, 8GB main-memory,
3TB hard disk. In the cluster, each node is assigned three processes to run map
tasks, and three process to run reduce tasks. So the cluster allows running at
most 75 mappers or 75 reducers simultaneously. Each mapper and each reducer
can use at most 2GB main-memory.

4.1 Datasets

Since there is no real fuzzy RDF data available, we generate synthesis fuzzy
ontology, called fpdLUBM3, for experimental purpose. Our system is based on a
fuzzy extension of LUBM [2], called fLUBM, which is used for testing querying
ability under fuzzy DL-Lite semantics in [7]. The fLUBM dataset adds two fuzzy
classes, called Busy and Famous. The fuzzy degrees of how an individual belongs
to these classes are generated according to the number of courses taught or taken
by the individual, and the publications of the individual respectively.

However, since there is no hierarchy among these fuzzy classes, we cannot use
fLUBM to test our reasoning algorithm. To tackle this problem, we further added
six fuzzy classes, VeryBusy, NormalBusy, LessBusy, VeryFamous, NormalFamous
and LessFamous. Given an individual i, suppose its membership degree w.r.t.
1 http://hadoop.apache.org/
2 http://hadoop.apache.org/hdfs/
3 Available at http://apex.sjtu.edu.cn/apex_wiki/fuzzypd
?

?

?
Reasoning Using MapReduce

class Busy (the fuzzy degree how i belongs to class Busy) is bi. If bi < 0.5,
we add a fuzzy triple (i, type, LessBusy)[bi/0.5] into the dataset; if 0.5 
bi < 0.7, we generated a fuzzy triple (i, type, NormalBusy)[bi/0.7]; other-
wise, we generate a fuzzy triple (i, type, VeryBusy)[b]. We added two fuzzy
triples, (LessBusy, subClassOf, Busy)[0.5] and (VeryBusy, subClassOf,
Busy)[1.0] to the TBox. Similarly, we can generate the fuzzy triples related
to Famous.

We further added a transitive property call youngerThan to test calculation of
the transitive closure. In each university ontology, we assigned a randomly generated age to each student. Then we generated n youngerThan triples. For each
triple, we randomly chose two different students i and j satisfying agei < agej,
and added a fuzzy triple (i, youngerThan, j)[agei/agej] into the data set.

Finally, we added a TBox triple to assert that emailAddress is an inverse
functional property. In fact, e-mail is usually used for identifying a person online.
Furthermore, for each faculty f, since we know the university from which he got
his bachelor degree, we picked one email address e belonging to an undergraduate
student in that university, and added a triple (f , emailAddress, e)[d] into
the data set. Here we assigned the fuzzy degrees d to be either 1.0 or 0.9. Then
sameas triples were derived using the semantics of inverseFunctionalProperty.
We set the probability when d = 0.9 to be 1%, so that a small set of vague sameas
triples can be generated. Similarly, we can generate other emailAddress triples
according to the master and doctoral information similarly.

4.2 Experimental Results

Comparison with WebPIE. We compared the performance of our system
with that of the baseline system WebPIE4. We run both systems over the same
dataset fpdLUBM8000. The results are shown in Table 2. Notice that the dataset
is a fuzzy dataset, for WebPIE, we simply omit the fuzzy degree, and submit
all crisp triples to the system. So our system (FuzzyPD) output a little more
triples than WebPIE, because our system also updates the fuzzy degrees. The
running time difference between our system and WebPIE is from -5 to 20 min-
utes. However, since a Hadoop jobs execution time is affected by the statuses of
the machines in the cluster, several minutes difference between the two systems
is within a rational range. Thus we conclude that our system is comparable with
the state-of-the-art inference system.

Scalability. To test the scalability of our algorithms, we run two experiments. In
the first experiment, we tested the inference time of our system over datasets with
different sizes to see the relation between the data volume and the throughput.
In the second experiment, we run our system over fpdLUBM1000 dataset with
different number of units (mappers and reducers) to see the relation between the
processing units and the throughput. Furthermore, in the second experiment, we
set the number of mappers to be the same as the number of reducers. Thus a
total number of 128 units means launching 64 mappers and 64 reducers.

4 We fix some bugs in the source code which will cause performance problem.

C. Liu et al.

Table 2. Experimental results of
our system and WebPIE

Table 3. Scalability over number of mappers

Number of Time of Time of
Universities FuzzyPD WebPIE
41.32
74.57
130.87
210.01

38.8
66.97
110.40
215.48
?

?

?
Time Speedup

Number
of units (minutes)
38.80
53.15
91.58
155.47
?

?

?
4.01
2.93
1.70
1.00

Table 4. Scalability over data volume

Input

Output

Time

Number of
Throughput
universities (MTriples) (MTriples) (minutes) (KTriples/second)
39.52
46.28
57.37
61.29

155.51
310.71
621.46
1243.20

38.8
66.97
110.40
215.50

92.01
185.97
380.06
792.54
?

?

?
The results for the first experiment can be found in table 4. From the table, we
can see that the throughput increases significantly while the volume increases.
The throughput while processing fpdLUBM8000 dataset is 50% higher than the
throughput while processing dataset containing 1000 universities. We attribute
this performance gain to the platform startup overhead which is amortized over
a larger processing time for large datasets. The platform overhead is also responsible for the non-linear speedup in Table 3 which contains the results of the
second test. Figure 1 gives a direct illustration of the overhead effect. In Figure 1,
if we subtract a constant from the time dimension of each data point, then the
time is inversely proportional to the number of units. Since the running time
should be inversely proportional to the speed, after eliminating the effect of the
platform overhead, the systems performance speeds up linearly to the increase
of number of units.

5 Related Work

[10] is the first work to extend RDFS with fuzzy vagueness. In [4], we further
 semantics which allows some useful OWL vocabularies,
propose the fuzzy pD
such as TransitiveProperty and SameAs. In [11] and [6], a more general framework called annotated RDF to represent annotation for RDF data and a query
language called AnQL were proposed.

As far as we know, this is the first work on applying the MapReduce framework to tackle large scale reasoning in fuzzy OWL. Pan et al. in [7] propose a
framework of fuzzy query languages for fuzzy ontologies. However, they mainly
concerns the query answering algorithms for these query languages over fuzzy
DL-Lite ontologies. Our work concerns the inference problem over large scale
fuzzy pD

 ontologies.
?

?

?
Reasoning Using MapReduce

)
s
e
t
u
n
m

i

(
 
e
m

i

1/128 1/64

1/32

1/16

Inverse of the number of units

Fig. 1. Time versus inverse of number of mappers

We briefly discuss some related work on scalable reasoning in OWL and RDF.

None of them takes into account of fuzzy information.

Schlicht and Stuckenschmidt [8] show peer-to-peer reasoning for the expressive ALC logic but focusing on distribution rather than performance. Soma and
Prasanna [9] present a technique for parallel OWL inferencing through data
partitioning. Experimental results show good speedup but only on very small
datasets (1M triples) and runtime is not reported.

In Weaver and Hendler [14], straightforward parallel RDFS reasoning on a
cluster is presented. But this approach splits the input to independent parti-
tions. Thus this approach is only applicable for simple logics, e.g. RDFS without
extending the RDFS schema, where the input is independent.

Newman et al. [5] decompose and merge RDF molecules using MapReduce
and Hadoop. They perform SPARQL queries on the data but performance is
reported over a dataset of limited size (70,000 triples).

Urbani et al. [13] develop the MapReduce algorithms for materializing RDFS
inference results. In [12], they further extend their methods to handle OWL
 fragment, and conduct experiment over a dataset containing 100 billion
pD
triples.

6 Conclusion

In this paper, we proposed MapReduce algorithms to process forward infer-
 semantics (i.e. an extension of OWL
ence over large scale data using fuzzy pD
Horst semantics with fuzzy vagueness). We first identified the major challenges
to handle the fuzzy information using the MapReduce framework, and proposed
a solution for tackling each of them. Furthermore, we implemented a prototype
system for the evaluation purpose. The experimental results show that the running time of our system is comparable with that of WebPIE, the state-of-the-art
 fragment. As a future
inference engine for large scale OWL ontologies in pD
work, we will apply our system to some applications, such as Genomics and
multimedia data management.

C. Liu et al.

Acknowledgement. Guilin Qi is partially supported by NSFC (61003157),
Jiangsu Science Foundation (BK2010412), and the Key Laboratory of Computer
Network and Information Integration (Southeast University).
