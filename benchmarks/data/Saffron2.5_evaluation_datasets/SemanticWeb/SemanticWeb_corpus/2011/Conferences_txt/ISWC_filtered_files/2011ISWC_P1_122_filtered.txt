An Empirical Study of Vocabulary Relatedness
and Its Application to Recommender Systems

Gong Cheng, Saisai Gong, and Yuzhong Qu

State Key Laboratory for Novel Software Technology, Nanjing University,

{gcheng,yzqu}@nju.edu.cn, saisaigong@gmail.com

Nanjing 210093, China

Abstract. When thousands of vocabularies having been published on
the Semantic Web by various authorities, a question arises as to how they
are related to each other. Existing work has mainly analyzed their sim-
ilarity. In this paper, we inspect the more general notion of relatedness,
and characterize it from four angles: well-defined semantic relatedness,
lexical similarity in contents, closeness in expressivity and distributional
relatedness. We present an empirical study of these measures on a large,
real data set containing 2,996 vocabularies, and 15 million RDF documents that use them. Then, we propose to apply vocabulary relatedness
to the problem of post-selection vocabulary recommendation. We implement such a recommender service as part of a vocabulary search engine,
and test its effectiveness against a handcrafted gold standard.

Keywords: Ontology, recommendation, relatedness, vocabulary.

1 Introduction

The Semantic Web enriches data with machine-readable, unambiguous meaning
by advising different applications to use common vocabularies (a.k.a. ontologies),
and to adhere strictly to the term descriptions provided. It would enable an even
wider range of applications that operate on integrated data when vocabularies
from different communities are interconnected, e.g. aligned. A large body of
work has been devoted to this problem of matching [9], which aims at finding
terms (i.e. classes or properties) in different vocabularies that have the same
intensional meaning. Accordingly, approaches thus far mainly follow a paradigm
that measures the similarity between terms [9] or between vocabularies [17,5]. In
fact, similarity is just a specific kind of relatedness. As other forms of relatedness,
one vocabulary may extend another by defining more specific subclasses, and
two vocabularies may describe closely related domains so that they are often
used together, etc. However, this more general notion of relatedness has been
addressed by only few work [19,23,11], and none of these approaches has been
evaluated on a representative sample of real-world vocabularies. In this regard,
whereas our previous work [4] has analyzed only explicit relations between terms,
in this paper, we will characterize several different aspects of relatedness between
vocabularies via an empirical study of many real-world, diverse vocabularies.

L. Aroyo et al. (Eds.): ISWC 2011, Part I, LNCS 7031, pp. 98113, 2011.
c Springer-Verlag Berlin Heidelberg 2011
?

?

?
Vocabulary relatedness can find many applications. For example, it could be
employed to rank and find central vocabularies [7]. Here we conceive another application called post-selection vocabulary recommendation. Assume that a user
has shown an interest in a vocabulary, or in other words, she has selected a
vocabulary. Such selection widely exists in many scenarios, e.g. having selected
a vocabulary for further exploration when interacting with a vocabulary search
engine, or having selected a vocabulary for use when developing an application.
Then, a recommender system will automatically suggest several other vocabularies that the user might also be interested in, e.g. one as an alternative or
complementary to the selected one for a particular use. Naturally, such recommendation mainly relies on the features of the selected vocabulary, and thus we
call it post-selection recommendation. We will discuss how this specific task can
be supported by the study of vocabulary relatedness.

To summarize, the contribution of this paper is threefold:

 Rather than similarity, we study the more general notion of relatedness between vocabularies on the Semantic Web. We discuss four kinds of relat-
edness: (a) semantic relatedness defined by vocabulary (meta-)descriptions,
(b) content similarity which exploits lexical features, (c) expressivity closeness according to the language constructs adopted, and (d) distributional
relatedness derived from vocabulary usage.

 We apply six proposed relatedness measures to a real-world data set crawled
by a Semantic Web search engine, which contains 2,996 vocabularies instantiated by other 15 million RDF documents (collectively containing 4 billion
RDF triples). We analyze and compare the effects of our measures, and report many statistical findings that help characterize real-world vocabularies.
 We consider the problem of post-selection vocabulary recommendation, and
propose to solve it by using relatedness measures. We also examine the popularity of vocabularies for recommendation. We evaluate our approach based
on a handcrafted gold standard, and also develop such a recommender system and incorporate it into a vocabulary search engine.

In the remainder of this paper, Sect. 2 characterizes our data set, in particular
the vocabularies identified from it. Section 3 describes and compares several relatedness measures. Section 4 introduces and evaluates a solution to the problem
of post-selection vocabulary recommendation. Finally, Sect. 5 compares related
work, and Sect. 6 concludes the paper.

2 Vocabularies in the Real World

2.1 Data Set

The data set investigated in this work is the one  at the time of writing
 used by the Falcons search engine.1 As summarized in Table 1, it comprises

http://ws.nju.edu.cn/falcons/

G. Cheng, S. Gong, and Y. Qu

15 million RDF (including RDF/XML and RDFa) documents, which collectively
contain 4 billion RDF triples, crawled from 5 thousand pay-level domains2 between February 2010 and May 2011.

Table 1. Data set statistics

Number of RDF documents
Number of pay-level domains hosting RDF documents
Aggregate number of RDF triples

15,947,721
5,805
4,099,414,887

Number of vocabularies
Number of pay-level domains hosting vocabularies
Aggregate number of classes
Aggregate number of properties

2,996

396,023
59,868

To characterize the data set, Figure 1 presents the distribution of the number
of pay-level domains over the number of RDF documents hosted on a log-log
scale. The distribution approximates a power law, but having a long tail to the
right which corresponds to several large data sources including hi5.com, l3s.de,
geonames.org, dbpedia.org, etc. This power law phenomenon has also been
observed on other data sets such as the one crawled by Swoogle [8].

s
n

i
a
m
o
d

 
l
e
v
e
l
-
y
a
p
 
f
o

 
r
e
b
m
u

Number of RDF documents

s
e
i
r
a
l

u
b
a
c
o
v
 
f
o
 
r
e
b
m
u

org

edu

com eu

uk

fr

net

de others

Top-level domains

Fig. 1. Distribution of the number of
pay-level domains over the number of
RDF documents hosted

Fig. 2. Distribution of the number of vocabularies hosted over top-level domains,
where others represents an aggregate
of all the ones not presented

2.2 Identifying Vocabularies

We study only the vocabularies that are published by applying best practice.3
Accordingly, since a vocabulary description may be distributed among multiple
2 A pay-level domain is a domain that requires payment at a (country-code) top-level
domain [14]. For instance, the URI http://ws.nju.edu.cn/falcons/ belongs to the
pay-level domain nju.edu.cn. We use the Apache Nutch package (nutch.apache.
org) to identify the pay-level domain of a URI.
http://www.w3.org/TR/swbp-vocab-pub/
?

?

?
documents, we employ a bottom-up strategy to identify vocabularies from the
data set. That is, firstly we identify a term as a dereferenceable URI that refers to
a class or a property in the RDF document retrieved via dereferencing the URI.
Then, terms sharing a common namespace URI are grouped into a vocabulary,
using this namespace URI as its identification. In this way, we may miss some
old-fashioned vocabularies that are not dereferenceable, and may also fail to find
all the terms for some vocabulary, but we believe that the results obtained would
accurately reflect real-world conditions at our best.

As summarized in Table 1, we have identified 396,023 classes and 59,868 prop-
erties, which are grouped into 2,996 vocabularies. They come from 261 pay-level
domains or 33 top-level domains. That is, among 5,805 pay-level domains in our
data set that serve RDF documents, only a small portion (4.50%) publish their
own vocabularies. Figure 2 depicts the distribution of the number of vocabularies hosted over top-level domains, in which org and edu dominate with 44.53%
and 31.58%, respectively, followed by com and several country-code ones. This
distribution is also close to the one for Swoogle [8].

These vocabularies vary considerably in size and composition. The largest
ones, in terms of the number of terms, are some versions of YAGO and Cyc
which comprise tens of thousands of terms, whereas most of the others (72.30%)
contain not more than 25. Even among large vocabularies, some (e.g. YAGO)
mainly provide classes when some others (e.g. SUMO) are rich in both classes
and properties.

3 Characterizing Relatedness between Vocabularies

In this section, we discuss, from different points of view, four kinds of relatedness
between vocabularies, and formalize them as numerical measures. In particular,
we assume that relatedness measures are symmetric. We perform an empirical
analysis of these measures, and finally make a comparison.

3.1 Semantic Relatedness

Vocabularies on the Semantic Web are described in a structured way. When one
vocabulary is connected to another via a typed link, it naturally indicates certain
kind of relatedness having well-defined semantics, and this leads to our first kind
of relatedness measure.

Explicit Relation. Major vocabulary languages such as OWL provide mechanisms for describing information about a vocabulary itself. For instance, owl:
imports references another vocabulary whose meaning will be included in the
present one. Since such relation between vocabularies is directly given in the
meta-description of a vocabulary, we call it explicit relation. Further, when there
are explicit relations between vocabulary v1 and v2, and between v2 and v3, we
observe some kind of relation between v1 and v3, which looks longer and thus
is probably weaker than the two original relations.

G. Cheng, S. Gong, and Y. Qu

These observations could be represented as an edge-weighted graph GE, where
nodes correspond to vocabularies, and every pair of explicitly related vocabularies vi and vj are connected by an undirected edge, associated with a weight w
indicating how weak the relation is:
?

?

?
w(vi, vj) =
?

?

?
if vi references vj or vj references vi,
if vi references vj and vj references vi.

(1)

S ) between two vocabularies is defined as
Then, the relatedness (denoted by RE
the multiplicative inverse of the weight of a shortest path between their corresponding nodes in GE, which is thus inside (0,1], or 0 when unreachable. Note
that we actually ignore the specific types of relations, as we will see later that
most relations observed in practice are quite homogeneous.

Implicit Relation. In a vocabulary, the description of a term may refer to terms
in other vocabularies, e.g. via rdfs:subClassOf or complex OWL constructs,
which suggests a kind of implicit relation between vocabularies, in the sense that
they are revealed by term-level descriptions but might not be mentioned in the
meta-description of vocabulary. Analogous to GE, here we devise another edgeweighted graph GI to convey such relations, which differs from GE in only one
respect that: implicit but not explicit relation is considered. Then, a relatedness
measure, denoted by RI

S, is defined based on GI analogously.

Hybrid Relation. When we take both explicit and implicit relations into con-
sideration, we obtain a kind of hybrid relation between vocabularies. Analo-
gously, it could be characterized as an edge-weighted graph GE+I, based on
which a relatedness measure, denoted by RE+I

, is defined.

Empirical Analysis. Among 2,996 vocabularies in the data set, explicit, implicit and hybrid relations are observed between 2,968, 2,845 and 4,691 pairs
of vocabularies, respectively. According to Table 2 which summarizes several
statistical properties of GE, GI and GE+I, whereas GE and GI are similar in
terms of the number of edges, GE seems more fragmented, suggested by the percentages of isolated nodes and the metrics below for characterizing reachability.
On the other hand, there are far more edges in GE+I than in GE, indicating
that many implicit relations between vocabularies are not captured by the metadescriptions thereof.

In particular, only 17 types of explicit relations are observed in our data set,
and only 6 occur in the meta-descriptions of more than one vocabulary. As shown
in Table 3, when owl:imports dominates largely, most others are negligible.

3.2 Content Similarity

In a vocabulary description, terms are not only interconnected but also usually
associated with human-readable contents, e.g. labels. Given two vocabularies
?

?

?
Table 2. Statistical properties of GE, GI and GE+I

Number of nodes
Number of edges

Average degree
Maximum degree
Percentage of isolated nodes

Number of connected components
Percentage of nodes in the largest connected component
Percentage of pairs of connected nodes

GI GE+I

2,996
2,968

2,996
2,845

2,996
4,691

1.98

3.13

56.88% 36.72% 32.31%

1.90

1,763

1,143

1,007
32.78% 57.44% 62.18%
5.40% 16.50% 19.33%

Table 3. Relations used in the highest percentages of vocabulary meta-descriptions

http://www.w3.org/2002/07/owl#imports
http://www.daml.org/2001/03/daml+oil#imports
http://www.w3.org/2000/01/rdf-schema#seeAlso
http://www.w3.org/2002/07/owl#priorVersion
http://purl.org/dc/terms/requires
http://www.openlinksw.com/schema/attribution#isDescribedUsing

36.58%
1.60%
0.30%
0.10%
0.07%
0.07%

modeling the same or related domains, their textual descriptions often overlap.
By detecting this aspect, we present our second kind of relatedness measure.

Specifically, the relatedness (denoted by RC) between two vocabularies vi and
vj combines the content similarity between their classes (denoted by Ci and Cj)
and the one between their properties (denoted by Pi and Pj):

RC(vi, vj) =

SetSim(Ci,Cj)+SetSim(Pi,Pj )

SetSim(Ci, Cj)
SetSim(Pi, Pj)

if Ci  Cj =  and Pi  Pj = ,
if Ci  Cj =  and Pi  Pj = ,
if Ci  Cj =  and Pi  Pj = ,
if Ci  Cj =  and Pi  Pj = ,

(2)
where SetSim is a similarity measure for term sets that determines the extent
to which the lexical features of both sets are covered by each other:


?

?

?
tiTi
?

?

?
tjTj

SetSim(Ti, Tj) = HMean(

|Ti|

max
tjTj

LS(ti, tj),

|Tj|

max
tiTi

LS (ti, tj)) ,

(3)
where HMean returns the harmonic mean of the two parameters, and LS(ti, tj)
gives the lexical similarity between terms. As one implementation of LS, we apply
a string metric [24] to all pairs of the respective labels of the two terms, normalize
each result to be inside the interval [0,1], and finally take the maximum.

G. Cheng, S. Gong, and Y. Qu

Empirical Analysis. In our data set, to exploit term descriptions for labels,
we retrieve property values from rdfs:label, dc:title and their subproperties
(e.g. skos:prefLabel) that are defined via or can be inferred from the rdfs:
subPropertyOf relation, which collectively amount to 86 types of properties. In
this way, at least one label can be found for 63.67% of all the terms, which are
distributed among 36.21% of all the vocabularies. Since the absence of label is
still commonly observed, the local name of each term URI is also employed.

Another thing we would like to point out is: computing content similarity
is the most expensive task performed in our experiments, which costs a multithreading program running on a multi-core server several weeks. This is not
surprising because all pairs of 2,996 vocabularies are compared, and for each
pair, every class (resp. property) in one vocabulary is compared with every class
(resp. property) in another, which is again time-consuming in particular for large
vocabularies, as illustrated in Sect. 2.2.

3.3 Expressivity Closeness

Vocabularies vary from lightweight taxonomies to heavyweight ones with complex constraints. In this regard, two vocabularies are close when they are similar
in expressivity. Accordingly, we develop our third kind of relatedness between
vocabularies based on their expressivity closeness.

The expressivity of a vocabulary is mainly (though not fully) captured by
the language constructs (e.g. rdfs:subClassOf vs. owl:complementOf) adopted
for describing terms. Besides, other meta-level terms may also be employed for
description, e.g. Dublin Core metadata terms and those for meta-modeling.
Therefore, we propose to characterize the expressivity of a vocabulary v by
MetaTerms(v)  the set of all meta-level terms that are instantiated in vs de-
scription. Then, given two vocabularies vi and vj, we define their relatedness
(denoted by RE) as follows:

RE(vi, vj) = J(MetaTerms(vi), MetaTerms(vj)) ,

(4)

where J returns the Jaccard similarity coefficient of the two sets.

Empirical Analysis. We observe 4,978 meta-level terms that are instantiated
in at least one vocabularys description, 469 (9.42%) of which are used in at
least two, showing a wide variety. In particular, the meta-level terms instantiated in the highest percentages of vocabulary descriptions are all language
constructs, led by rdf:type, rdfs:domain and rdfs:range. Excluding these,
Table 4 presents the top-ranked ones remaining, which are all not widely used.
On the other hand, describing a vocabulary needs to instantiate an average
of 10.13 types of meta-level terms. In fact, 92.96% of all the vocabularies in our
data set use not more than 20 types. However, we still recognize hundreds of
types of meta-level terms in some complex vocabularies such as Cyc.
?

?

?
Table 4. Meta-level terms (excluding those in RDF, RDFS, OWL or DAML) instantiated in the highest percentages of vocabulary descriptions

http://purl.org/dc/elements/1.1/description
http://purl.uniprot.org/core/encodedIn
http://www.w3.org/2004/02/skos/core#definition
http://purl.org/dc/terms/modified
http://www.swop-project.eu/ontologies/pmo/product.owl#unit
http://purl.org/dc/terms/issued
http://www.w3.org/2003/06/sw-vocab-status/ns#term_status

1.50%
0.90%
0.73%
0.67%
0.67%
0.63%
0.63%

3.4 Distributional Relatedness

Whereas all the previous notions of relatedness rely on the intensional descriptions of vocabularies, our fourth kind of measure looks at the extensional side,
i.e. to investigate vocabulary usage in practice.

Recall that on the fruitful topic of relatedness in the field of computational
linguistics, among others, distributional relatedness [20] defines close words as
those that are used in similar contexts, e.g. having many co-occurring words in
common. Accordingly, a distributional profile is created for each word, which
characterizes the strength of association between the word and every other word
that co-occurs with it, commonly by using conditional probability. Then, the
similarity (e.g. cosine) between distributional profiles is calculated, as a proxy
for relatedness between words.

Inspired by this line of research, we study vocabulary co-occurrence in
use, which in the context of the Semantic Web amounts to vocabulary co-
instantiation. We conceive an RDF document as the context from which coinstantiation is observed, and let IV(d) be the set of all vocabularies instantiated
in RDF document d. Then, given the set of all vocabularies V and v  V , the
distributional profile of v is represented by a |V |-dimensional vector, denoted by
DP(v), where:

DPi (v) =

|{d  D| v, vi  IV(d)}|
|{d  D| v  IV(d)}|

,

(5)

where D is the set of all RDF documents under investigation. In particular,
DP(v) is defined as 0 when no instantiation of v can be observed in any d  D.
Finally, the relatedness between vocabulary vi and vj, denoted by RD(vi, vj), is
given by the cosine similarity between DP(vi) and DP(vj).

This straightforward implementation is improved in two ways. Firstly,
language-level vocabularies (e.g. RDF) are trivially and widely instantiated,
which function as stop words in computational linguistics. Hence they are filtered
out prior to processing. Otherwise, they may undesirably, even largely, increase
the relatedness between many pairs of vocabularies. Secondly, as discussed in
Sect. 2.1, considering the distribution of the number of pay-level domains over
the number of RDF documents hosted, a large data source in the long tail of the

G. Cheng, S. Gong, and Y. Qu

distribution may unfairly affect the computation of relatedness. To avoid this,
we limit the effects that could be caused by a single pay-level domain. Specifi-
cally, we define PLD(D) as a partition of D such that each element of PLD(D)
corresponds to all the RDF documents in D that are hosted by one particular
pay-level domain. Then, we rewrite (5) as follows:

DPi (v) =

|{S  PLD(D)|d  S, v, vi  IV(d)}|
|{S  PLD(D)|d  S, v  IV(d)}|

.

(6)

In our data set,

instantiation is observed for 1,874
Empirical Analysis.
(62.55%) vocabularies. Table 5 shows the most widely instantiated ones, led
by Dublin Core metadata vocabularies and FOAF. Further, among 9,763 pairs
of vocabularies that have co-instantiation, Table 6 presents the most frequent
ones.

Table 5. Vocabularies (excluding RDF, RDFS, OWL and DAML) instantiated in RDF
documents hosted by the highest percentages of pay-level domains

http://purl.org/dc/elements/1.1/
http://xmlns.com/foaf/0.1/
http://purl.org/dc/terms/
http://www.icra.org/rdfs/vocabularyv03#
http://www.w3.org/2003/01/geo/wgs84_pos#
http://purl.org/vocab/bio/0.1/
http://www.w3.org/2000/10/swap/pim/contact#
http://rdfs.org/sioc/ns#
http://usefulinc.com/ns/doap#
http://purl.org/vocab/relationship/

37.45%
22.79%
15.90%
10.65%
5.22%
2.76%
2.76%
2.20%
1.67%
1.38%

Table 6. Pairs of vocabularies (excluding those involving RDF, RDFS, OWL or
DAML) co-instantiated in RDF documents hosted by the highest percentages of paylevel domains

http://purl.org/dc/elements/1.1/
http://purl.org/dc/terms/

http://purl.org/dc/elements/1.1/
http://www.icra.org/rdfs/vocabularyv03#

http://purl.org/dc/terms/
http://www.icra.org/rdfs/vocabularyv03#

http://xmlns.com/foaf/0.1/
http://purl.org/dc/elements/1.1/

http://www.w3.org/2003/01/geo/wgs84_pos#
http://xmlns.com/foaf/0.1/

14.42%

10.65%

10.61%

9.42%

5.05%
?

?

?
3.5 Comparison
Now we study the levels of agreement between different relatedness measures.
We apply, to all pairs of 2,996 vocabularies in our data set, each of our six
, RC, RE and RD. Each measure will
relatedness measures, namely RE
induce a ranking of these pairs, and we leverage the Spearmans rank correlation
coefficient, denoted by , to measure the correspondence between these rankings
and assess its significance.  is inside the interval [-1,1], and an increasing value
implies increasing agreement.

S, RE+I

S , RI

The results are summarized in Fig. 3. All the values are positive, i.e., all
these measures are positively correlated. Larger values are found between RI

S and RE+I
and RE+I
(0.53), which are not surprising
since RE+I
S. In particular, the second largest value (0.66)
S and RD, indicating that explicitly related vocabularies
is observed between RE
are also most likely to be instantiated together, and vice versa.

(0.88), and between RE
comprises RE

S and RI

S RE+I

RC RE RD

S 0.39 0.53 0.21 0.19 0.66

0.88 0.26 0.38 0.35

0.30 0.26 0.43
0.32 0.23
0.24

RE+I
?

?

?
-
-
-
-

-
-
-

-
-

-
?

?

?
SR 
?

?

?
Fig. 3. Levels of agreement between individual relatedness measures

Fig. 4. Dendrogram showing the singlelink hierarchical clustering of individual
relatedness measures based on their levels of agreement

Further, based on  values, we employ the single-link hierarchical clustering
technique to depict the relationships between measures. As shown in Fig. 4, RC
is relatively far from the other measures. One reason might be that for describing
the same domain, different authorities may publish their own vocabularies, which
vary considerably in expressivity and are rarely connected to each other.

4 Post-selection Vocabulary Recommendation

In this section, we describe an application that can be enriched by the study of
vocabulary relatedness. Recall that when we browse online book stores or movie
databases, some of these applications will provide recommendations to avoid
overloading users with information. For instance, when we look at the introduction of a book, several related items are also presented, e.g. books written by
the same author. Analogously, when interacting with a vocabulary repository,
e.g. a vocabulary search engine, after a vocabulary has been selected for examining details, the system is expected to recommend several related vocabularies. In
the next, we address this problem of post-selection vocabulary recommendation.
We describe an approach as well as an extension, and present evaluation results.

G. Cheng, S. Gong, and Y. Qu

4.1 Relatedness-Based Ranking

S , RI

S, RE+I

In Sect. 3, we have introduced six measures of relatedness between vocabularies,
namely R = {RE
, RC , RE, RD}, all returning values inside the interval [0,1]. For a selected vocabulary v0, we argue that a vocabulary vi is more
likely to be recommended if it is more related to v0, in terms of some Rj  R.
That is, we rank recommendation candidates by Rj(vi, v0). Here, which Rj to
use is specified by users according to their specific needs. R can also be extended
to include other metrics developed in the future.

When users intend to receive recommendations featuring several different
characteristics, it requires employing multiple measures. Further, users may attach different degrees of importance to different measures. To this end, we allow
ranking recommendation candidates by a linear combination of all the measures
in R, i.e.

RjR jRj(vi, v0), where j  [0, 1] is a group of weightings.
?

?

?
We implement such a recommender service in Falcons Ontology Search.4
When exploring a retrieved vocabulary, users could enquire about related ones
after specifying a weighting for each relatedness measure.

4.2 Popularity-Based Re-ranking

Besides relatedness, another factor we would like to consider in vocabulary recommendation is popularity. Recall that the Semantic Web could facilitate data
integration on the semantic level exactly because different Semantic Web applications produce and consume data adhering to common vocabularies. Hence,
we argue that a recommender service should return more popular vocabular-
ies, i.e. those having been used by more applications. To incorporate popularity
into the criteria for ranking, given Pop(v)  the number of pay-level domains
hosting RDF documents that instantiate v, we extend our approach to rank
recommendation candidates by the following metric:
?

?

?
RjR

jRj(vi, v0)  (1 + logb (1 + Pop(vi))) ,

(7)

where b is a parameter that tunes the degree of influence of popularity on rec-
ommendation. When decreasing b from + to a small value (e.g. 2), the degree
of influence increases. But apparently, popularity is achieved at the relative cost
of relatedness. A trade-off needs to be studied for specific applications.

4.3 Evaluation
Firstly, without considering popularity, we examine which Rj  R is more useful for recommendation. To achieve this, we compare generated rankings thereof
to the gold standard given by human experts. We identify 1,302 vocabularies
from our data set for this experiment, each containing 525 terms, being neither

http://ws.nju.edu.cn/falcons/ontologysearch/
?

?

?
too small to be significant nor too large for manual investigation. We choose 20
from them at random as selections for testing post-selection recommendation.
For each selection, we can hardly ask experts to give a ranking of all the other
1,301 vocabularies, but rather, we apply the depth-10 pooling technique, which is
widely adopted for evaluating information retrieval (IR) systems. To be specific,
we apply each Rj  R to score all the other 1,301 vocabularies, retain only those
having positive relatedness values, and collect the top-10 ones. For all Rj  R,
these top-ranked vocabularies collectively form a pool to be used in the exper-
iment. The pool is randomly divided up and assigned to two experts. For each
assignment, the expert is asked to assess the relatedness between the assigned
vocabulary and the selection, and report (a) closely related, (b) somewhat
related, or (c) unrelated, corresponding to ratings 2, 1 and 0, respectively. In
particular, 5 vocabularies in each pool are assigned to both experts.

We receive 739 assessments in total, of which 81.60% are unrelated, 10.55%
somewhat related and 7.85% closely related. Unrelated vocabularies take the
largest proportion, which in fact is quite common under pooling methods. Be-
sides, among 100 (20  5) vocabularies assessed by both experts, agreement is
reached on 80%. If we consider only binary ratings by taking closely and somewhat related as related, agreement is reached on 91%, suggesting a high quality
of the assessments. Finally, to form one single gold standard, when two experts
give different assessments on a vocabulary, we take the higher rating.

k
@
?

?

?
0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1
?

?

?
E+I

b=2(cid:117)100

b=2(cid:117)101

s
n

i
a
m
o
d

 
l
e
v
e
l
-
y
a
p
 
f
o
 
r
e
b
m
u

b=2(cid:117)102

b=2(cid:117)103

b=2(cid:117)104

k
?

?

?
0.1

0.2

0.3

0.4

0.5

b=2(cid:117)105
0.7

0.6

Fig. 5. NDCG of individual measures

Fig. 6. Relationship between relatedness
and popularity under different b values

For each selection, we evaluate each Rj  R by calculating its normalized
discounted cumulative gain (NDCG)  a widely used metric for IR evaluation.
NDCG@k, inside the interval [0,1], measures the quality of the k top-ranked vocabularies against their gold-standard ratings. Figure 5 summarizes the results
averaged over all the 20 selections, under different settings of k. RC noticeably
outperforms the others, showing that our experts assess relatedness between vocabularies mainly based on the overlap between their contents. On the other
S and RD to the fact that, as
hand, we attribute the bad performances of RE

G. Cheng, S. Gong, and Y. Qu

presented in Sect. 3, 56.88% of vocabularies in our data set are not explicitly related to any other ones, and that 37.45% have no instantiation. Thereby, RE
S and
RD fail to find any related vocabularies for 13 and 11 selections, respectively. In
these cases, NDCG is defined as 0, which largely hurt their overall performances.
Secondly, we look at combinations of measures. Since RC performs the best
in the first experiment, we combine it with every other measure in R to see
whether better results can be achieved. Figure 7 illustrates the evaluation results
of several combinations. Actually, for each kind of combination, we show only
one group of weightings with which the best result is obtained. We find that
under different settings of k, better or equal results are consistently observed
when RC is combined with RE
seem only
helpful when k = 1, i.e. in generating the top-ranked vocabulary. However, the
reader is reminded that these results only reflect the bias of our experts, whereas
our flexible approach indeed allows task-oriented combination.

S , RE or RD, whereas RI

S and RE+I

0.9

0.8

0.7

0.6

0.5

k
@
?

?

?
RC+0.7RS

RC+0.5RS

E+I
RC+0.4RS

RC+0.2RE

RC+0.3RD

k

Fig. 7. NDCG of several combinations of measures

Finally, we illustrate, with RC, the relationship between relatedness and pop-
ularity. Under different b values in (7), we evaluate relatedness by NDCG@1
and evaluate popularity by the number of pay-level domains hosting RDF documents that instantiate the top-ranked vocabulary. As shown in Fig. 6, when
NDCG decreases from 0.60 to 0.45 (averaged over all the 20 selections), the number of pay-level domains increases linearly. A much higher popularity can also be
achieved, which however loses relatedness considerably. It reveals that looking
for a good trade-off is not an easy task, but has to rely on specific applications.

5 Related Work

5.1 Relatedness

In computational linguistics, a substantial amount of research has been conducted on the measurement of relatedness between words (or senses) [3]. Most
existing methods exploit semantic networks such as WordNet, and operate on
shortest paths or information theory. These ideas have also been transplanted
to the Semantic Web for measuring relatedness between terms in a vocabulary [19,23,11], by treating a vocabulary description as a semantic network.
?

?

?
Complementary to this, another line of research studies the co-occurrence of
words to measure their distributional relatedness [20].

Differently, we look at relatedness on the vocabulary but not the term level.
In an earlier work [4], we derive a vocabulary dependence graph from the relations between terms, and perform a complex network analysis, which reveals its
scale-free nature. In [7], several types of relations between terms and between
vocabularies are identified, to characterize a random surfers behavior for rank-
ing. In [25], vocabularies are clustered based on their use of language constructs.
Whereas each of these studies investigates very few kinds of relatedness, the
work in this paper characterizes it in four aspects and compares six measures.
As a special kind of relatedness, similarity between terms [9] and between
vocabularies [17,5] have attracted extensive research. Further, the similarities
among a collection of vocabularies can be represented as a graph, on which
statistical analysis [10,21] and complex network analysis [12] have been carried
out. Besides, more sophisticated measures of similarity have been established
based on such graph [6]. In our work, we also implement content-based similarity
as one aspect, when we deal with the more general notion of relatedness.

5.2 Recommendation
Recommender systems have become an important research area [1]. In partic-
ular, collaborative approaches have been applied to vocabulary recommendation [22,15], which are grounded on user-generated ratings. A closely related
problem is vocabulary search, which usually takes a keyword query as input
and in fact performs query-biased recommendation [2,13,18]; these approaches
mainly investigate how well a vocabulary is relevant to a keyword query. Inspired by [16], the problem of post-selection recommendation addressed in our
work is in a different context that takes a selected vocabulary as input and demands selection-biased recommendations, to which relatedness measurement is
the natural solution.

6 Conclusions and Future Work

In this paper, we have discussed vocabulary-level relatedness from four aspects.
Our empirical analysis on a large, real data set compares six developed measures,
and also, reports many statistical findings, which help characterize vocabularies
on the real Semantic Web. In particular, we observe that many cross-vocabulary
relations between terms are not embodied in their vocabulary meta-descriptions,
and vocabularies having explicit relations tend to be instantiated together. After
that, we have proposed to apply relatedness measures to the problem of postselection vocabulary recommendation. The evaluation results demonstrate the
effectiveness of our measures in recommendation, particularly when they are
combined appropriately. We have enriched our Falcons Ontology Search system
with such a flexible recommender service.

In fact, our relatedness measures have not fully exploited vocabularies. As
future work, textual descriptions and provenance information in vocabulary

G. Cheng, S. Gong, and Y. Qu

meta-description still need investigation. About vocabulary recommendation, it
would be interesting to combine our relatedness measures with collaborative
methods and ontology evaluation techniques.

Acknowledgments. This work was supported in part by the NSFC under
Grant 60973024 and 61021062, and in part by ZTE Corp. (R&Dcon1105160003).
We thank Min Liu for his time and effort in the experiments.
