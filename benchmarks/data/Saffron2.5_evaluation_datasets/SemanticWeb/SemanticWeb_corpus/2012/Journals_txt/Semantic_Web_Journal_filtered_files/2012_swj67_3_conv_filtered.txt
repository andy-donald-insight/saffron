Undefined 0 (0) 1
IOS Press

Injecting semantic annotations into
(geospatial) Web service descriptions

Editor(s): Thomas Lukasiewicz, University of Oxford, UK
Solicited review(s): Jacek Kopecky, The Open University, UK; Tudor Groza, The University of Queensland, Australia;
Marinos Kavouras, National Technical University of Athens, Greece

Patrick Maue a Henry Michels a and Marcell Roth a
a Institute for Geoinformatics (ifgi)
University of Munster, Germany
Weseler Str. 253
48151 Munster
Germany e-mail: firstname.lastname@uni-muenster.de

Abstract. Geospatial Web services comply with wellestablished standards to support seamless integration
into applications ranging from commercial Geographic
Information Systems (GIS) to open source web mapping clients. Descriptions of service capabilities contain information about the provided data. Updates to
the underlying database result in changing descrip-
tions. To ensure compatibility with existing solutions,
semantic enablement of Geospatial Web services has
to reflect both, standards and changing metadata. Semantic annotations link between legacy non-semantic
Web service descriptions and their semantic counter-
parts. The open source Semantic Annotations Proxy
(SAPR) is a light-weight RESTful API deployed as
free service which injects semantic annotations into
existing Web service descriptions without breaking the
standards. This approach decouples the annotations
from the original metadata, which ensures the separation of concerns between data providers and end users
with different and sometimes conflicting views on an-
notations. In addition, the service is robust regarding
changes of the service descriptions. The presented approach is focusing on W3C- and OGC-compliant Web
services, but can be theoretically applied on any kind
of information source with structured metadata.
Keywords: Semantic Annotation, Semantic Web,
Tools, Geospatial Semantic Web, Semantic Web Ser-
vices

1. Introduction

Efficient discovery relies on search engines with
sophisticated indexing and scoring techniques.
These techniques can not be simply applied on
structured data without textual content such as
geospatial data, or any kind of binary data, including pictures or videos. Finding such content
relies on annotations which associate descriptive
metadata with the resource [1]. The metadata is
then again used for common indexing and scoring techniques. Semantic annotations link to formally specified vocabularies capturing the contents meaning. Besides the traditional information retrieval techniques based on indexing and
string matching, semantic annotations linking to
ontologies support logic-based reasoning. In the
case of finding information, reasoning engines such
as Pellet [27] can then precisely match the semantic queries to the semantically annotated content,
and ensure better precision of search results [15].
We understand semantic annotation as a reference which establishes a Link Annotation [1]
between the application-specific metadata and a
shared external vocabulary. They enable reasoning
on the linked ontologies and support non-domain
experts to better understand what the data rep-
resents. In this paper we focus on annotations for
Web services which describe their interfaces with
standardized metadata. The latter is semantically

0000-0000/0-1900/$00.00 c 0  IOS Press and the authors. All rights reserved

Injecting Semantic Annotations

annotated to integrate the Web services into semantically enabled applications.

Research on semantic annotations for Web documents [16,11], multimedia [29,3], geospatial data
[15,12,19], and Web services [30,28,17] has been
around for years. The description of Semantic Web
Services (SWS) eventually led to the standard Semantic Annotations for Web Service Description
Language (SAWSDL) [14]. It specifies extension
points for W3C-compliant Web service metadata
encoded with the Web Service Description Language (WSDL). Although the W3C standards are
widespread and well-established, domain-specific
standardization organizations have come up with
their own solutions. Geospatial Data Services, for
example, comply to the standards of the Open
Geospatial Consortium (OGC)1. These standards
define their own approach for XML-based meta-
data. Depending on the type of the spatial resource
(i.e. features for vector-based data, coverages for
raster based data, and geoprocessing methods),
different OGC Web service types exist.

In this paper we present the implementation
of the Semantic Annotations Proxy (SAPR)2. It
builds on (and is part of) the Sapience API3,
which comprises libraries used to extract, store,
and inject semantic annotations within Web service metadata without breaking the underlying
standards. SAPR exposes the Sapience functionality following a Software-as-a-Service approach.
It is a conceptually simple proxy-based [11] solution for injecting semantic annotations. Similar to
traditional HTTP proxies (e.g. for Web browsing),
SAPR acts on behalf of the proxied Web service
and either redirects client requests to the original Web service or updates the returned meta-
data. End users are not aware of its existence: the
proxy takes the identity of the proxied service.
The injection-procedure refers to the semantic
enrichment of XML-based documents by writing
Link Annotations directly into the data stream.
We explain how the proxy-based solution for the
semantic enablement of existing Web service de-

1The reason why OGC has not (yet) adapted W3C standards is simple: the OGC standards have been developed
years before SOAP/WSDL emerged.

2SAPR is a free

service, available at: http://

semantic-proxy.appspot.com

3See http://purl.org/net/sapience/docs for the access to the source code, issue tracking, and documentation.

scriptions ensures a clear Separation of Concern
(SoC). The proposed solution for loosely-coupled
metadata (separating between client-specific annotations and the provider-specific metadata) supports multiple annotations for one service descrip-
tion. This makes different application scenarios
feasible, without relying on the service provider for
specifying the annotations. The introduced implementation reflecting the standards and changing
metadata, as well as the discussion of SoC for Web
service annotations should be considered as main
contribution of this paper.

The following section 2 introduces two application scenarios which illustrate the benefit of injecting annotations. A more in depth discussion about
the need for injecting references is following in section 3. The implementation of SAPR is introduced
in section 4, followed by an evaluation in section 5.
Section 6 lists related work about Semantic Web
Services. The paper concludes with an outlook and
a summary in section 7.

2. Application Scenarios

Annotations support better interpretation and
evaluation of the referenced data. Using a proxy
ensures that different sets of annotations for applications deployed in different scenarios can be re-
quested. In the following two sections we illustrate
one typical application scenario for semantic annotations (linking to vocabularies describing the
datas relation to reality) and one for data quality annotations (linking to vocabularies describing
aspects such as trust or uncertainty).

2.1. Annotations for capturing data semantics

The most prevalent application of annotations
is semantic enrichment: the individual entities in
a data model are linked to concepts in shared
vocabularies to explain what the data represents
in reality. Semantic annotations combined with
semantic-enabled applications can be useful for a
varying field of applications such as Web service
discovery, automatic integration into existing business or scientific workflows, logic data integrity
tests, semantic validation of Web service composi-
tions, or inferring data visualization strategies. A
more in depth discussion of these applications can
be found in [20].

The linked vocabularies can be commonly accepted thesauri of one particular domain, shared
domain ontologies developed for particular use
cases, or local application-specific ontologies. The
domain ontologies should be understood as formal specifications of reality, in particular of our
geographic environment. A Web Feature Service
(WFS) [31] could,
for example, provide XML
schema describing the data model of the feature type GEOL50KType with the two attributes
CODE and FORMATION (see Figure 1). These attribute labels are unfortunately cryptic, its meaning remains hidden to non-experts (or experts
from different information communities). Requesting the actual data returns 2 for CODE and PlioPleistocene for FORMATION, which does not reveal any meaning as well. This example4 is taken
from one of the scenarios of the European research
project ENVISION. It adequately reflects the current situation: todays use of (geospatial) Web services is significantly impaired by the lack of meaningful metadata [23].

GIS users directly load and visualize feature
data from such a WFS. In this sense, the data
is useable, but far from being useful. Client applications can be semantically enabled (i.e. supporting logic inference and visualization of the
referenced knowledge). But without semantic an-
notations, these clients have no means to identify and retrieve the shared vocabularies to infer
what these attributes represent. And without a
precise knowledge about the underlying data mod-
els, the data itself can be hardly used for critical geospatial tasks like decision making or risk
modelling. In Figure 1, the attributes have an additional attribute sawsdl:modelReference="..".
This model reference is the link annotation which
is not part of the original schema, but has been
injected afterwards. Semantic-enabled clients follow these links pointing to classes in RDF-based
ontologies. On this level, descriptive metadata and
meaningful (and multilingual) labels exist which
are needed for the interpretation of the data mod-
els. More importantly, reasoning with common engines such as Pellet for OWL-DL[27] ease integra-
tion. They help to select appropriate visualization
strategies (e.g. features representing water bodies
are commonly coloured blue) or detect (and poten-

tially avoid) semantic conflicts in geospatial work-
flows.

Semantic annotations linking to local application ontologies have been proven useful to capture the sometimes complex functional dependencies within data models [19]. In the given exam-
ple, CODE identifies the geological formation (i.e.,
all features representing geological layers formed
in the pleistocene era have the code 2). Built-in
ontology constructs such as constraints on properties in OWL help to re-model this inner relationships of the data. To make these local ontologies
useful, they have to be aligned to globally shared
ontologies. The FORMATION could then, for exam-
ple, be linked to a domain concept GeologicEra.

2.2. Annotations for describing data quality

Communicating quality aspects of data is crucial for evaluating its usefulness for the intended
application. Typical data quality metadata covered in the following are data provenance and un-
certainty.

Geospatial data is the result of a measurement
procedure (or sensor observation), and each measurement comes with some sort of error. The original input for the data representing geologic layers,
for example, derives from core samples. A threedimensional interpolation algorithm estimates the
distribution of the layers according to these sam-
ples. This deviation from truth is commonly called
the Uncertainty of geographic information. Applications in need for high accuracy of certain prop-
erties, e.g. urban planning, should be aware of imprecise data. Otherwise, the error is hidden in the
result (and high precision is simulated), leading
eventually to wrong calculations or more serious
issues. UncertML [32] has been developed as extension for geospatial data models to formalize the
uncertainty. The Link Annotations then point to
the appropriate definitions in the UncertML dic-
tionary5. Such information might not be necessary for some applications (i.e. simple navigation
tasks). Their clients wont be able to process the
updated uncertainty information. With the help
of the proxy, this information about the uncertainty can simply injected during runtime, and

4The service can be found at: http://envision.

brgm-rec.fr/Data_Geology.aspx

5Examples and the dictionary are available at: http://

dictionary.uncertml.org/

Injecting Semantic Annotations

<element type="GEOL50KType" substitutionGroup="gml:_Feature"/>
<complexType name="GEOL50KType">
<complexContent>
<sequence>
<element name="CODE" type="string"

sawsdl:modelReference="http://.../local/2zhe2#CODE"/>

<element name="FORMATION" type="string"

sawsdl:modelReference="http://.../Geology-Ontology#GeologicEra"/>

</sequence>
</complexContent>
</complexType>

Fig. 1. Semantic Annotations for XML (GML) schema

only (technically) compatible clients can request
this data if needed.

Specifying provenance of (geospatial) data helps
to build confidence (or trust) into the data. Such
metadata includes, amongst others, detailed information about the publishing organization and a
description of the data lineage. The former could
be as simple as a link to a publicly shared FOAF
profile. Clients might want to learn about the
data providers reputation to infer its usefulness
for critical applications. Data lineage refers to the
actual process for creating the data. Here, Link
Annotations point to external (but application-
specific) documents containing detailed information about the creation process. Which links to
either FOAF profiles or Data Provenance documents are required has to be decided by the
client application. The presented approach separates between original provider-specific metadata
and application-specific annotations, making it
possible to support semantically-enabled applications and uncertainty-aware applications simulta-
neously.

3. Separation of Concerns for Semantic

Annotations

Legal directives such as INSPIRE (Infrastruc-
ture for Spatial Information in Europe)and the
U.S. NSDI (National Spatial Data Infrastructure)
call for a Web-based provision of spatial data from
the public sector. In the last decade, large-scale
spatial data infrastructures (SDI) have been deployed by public mapping agencies. But the migration from local installations to Web-enabled infrastructures has been (and still is) a tedious and cost-

intensive task. That service providers will update
and re-deploy existing Web services to include aspects such as semantic annotations cannot be ex-
pected. The proxy-based solution of SAPR has initially been a pragmatic approach to integrate these
legacy Web services into semantic-enabled appli-
cations. SAPR enables client application developers in need for semantically enriched Web services
to simply annotate Web service in question and
register it to the proxy. The original Web service is
not modified and the outcome remains standards-
compliant. The only modification from a clients
perspective is the change of the URL representing
the Web service location.

Selecting an appropriate strategy to benefit
from annotations requires that applications understand the annotations intended purpose. Bechhofer et al. [1] state that we must be explicit
about the assumptions that we make and the
context within such annotations should be in-
terpreted. They distinguish between Decoration,
Linking, Instance Identification and Instance Ref-
erence, Aboutness and Pertinence as typical annotation types. Marshall
[16] draws a line between formal/informal and explicit/tacit anno-
tations. The presented approach is restricted to
Link Annotations pointing to formal (and explicit)
metadata.

The limitation on Link Annotations for the injection is based on the two following assumptions:
(1) Link Annotations support loose coupling of
the data models and the domain-specific meta-
data. This enables separation of concerns and del-
egation. (2) Annotations are pointing to explicit
specifications, either captured in ontologies or in
shared vocabularies encoded in a well-known for-

mat (e.g. in the Resource Description Framework
RDF).

3.1. Decoupling metadata

Separation of Concerns (SoC) refers to the idea
of separating distinct features in software appli-
cations. Typical concerns are concurrency, persis-
tence, or failure recovery [9]. In the case of meta-
data, the already mentioned information about
data semantics, uncertainty, and trust could represent the different concerns. Link Annotations
loosely couple implementation-specific data models with application-specific (or domain-specific)
metadata. The client application has to specify
which annotations are to be injected. The presented proxy generates a unique identifier for each
set of annotations, and expects this identifier as
parameter to allocate the according annotations in
the repository.

SoC supports delegation of the annotation from
the data provider to the domain experts. Library
Research has always faced the problem of the information gap between potential readers and indexing catalogers due to differing backgrounds [8].
It is the librarian who is responsible for indexing
a book for a library. She knows best how potential
readers might be looking for it, and what search
terms they might be using. The books author,
on the other hand, might have had a very specific reader in mind; hence his description of book
would be semantically narrow. Creating metadata
for Web services is facing the similar issue: the
data provider is an expert in data acquisition and
authoring, but she might lack skills in identifying appropriate ontologies for semantic annotations or the correct equations to describe the uncertainty inherent in the data6. Furthermore, data
providers usually have very a specific end user in
mind when creating the metadata. It requires domain experts to close the information gap between
the data providers and the potential users. It is the
domain expert who, on behalf of the data provider,
identifies the appropriate shared vocabularies and
creates the semantic annotations.

The ad-hoc injection procedure allows for decoupling semantic annotations from the original

6This discussion is focusing on the separation between
the two roles of the data provider and the domain expert.
One person (or organization) can still play both roles.

service metadata. Depending on the client request,
different sets of annotations may be added to the
metadata. Experts coming from different information communities are able to define their annota-
tions, without risking conflicts with other anno-
tations. The presented implementation does not
support the domain expert in the actual semantic
annotation; this is expected to happen before the
service is registered to SAPR.

Clients for OGC Web services dont separate
between the location of the Web service and its
description. Descriptions are typically generated
on the fly, since updates to underlying data sets
are common. Each OGC Web service implements
the GetCapabilities-operation providing the service metadata. Supported operations and servicespecific information like feature types are listed
in this document. W3C-compliant Web services,
on the other hand, support separation of descriptions from services. Best practice may imply that
WSDL descriptions are provided by the services
(by concatenating the ?wsdl to the URL). But
this is not part of the standard; SoC is thus inherently supported by W3C Web services. How-
ever, updating such service would require to locate and update all WSDL descriptions linking to
it. Hence, services typically have implementation
and description at the same location, which again
raises the issue of SoC (and makes the presented
proxy useful for semantic annotations).

3.2. Semantics of Link Annotations

The categorization of books in libraries is following a well define scheme which has been adopted
by the popular Dublin Core standard for resources
on the Web. Capturing the semantics of data, and
describing the inner relationships of data entities,
is considerably more complex. The Link Annotation has been proposed as means to connect the
individual elements in the data schema to the appropriate ontology concepts in shared vocabular-
ies. But the link itself does not indicate the nature
of the linked resource, or how the client application
has to process the annotations. The resource may
be just a different representation of the annotated
item (the Instance Identification according to [1]).
Or it provides information about it, e.g. how to use
it (the Aboutness). The SAWSDL standard proposes the ModelReference to add semantic annotations into XML schema or WSDL elements [14].

Injecting Semantic Annotations

Its main purpose is the separation between two different encodings of the same entity (even though
the standard itself is intentionally unconstrained).
The standard also recommends to complement the
reference with pointers to scripts which translate
between the different encodings. In [20], we discuss
theDomainReference as extension to the ModelReference to align local implementation-specific
data models with globally shared domain models.
Another option to let the client know about
the nature of the referenced resource is to link
only to well-defined instances in a vocabulary. A
link pointing to a resource modelled as instance
of a Person from the FOAF vocabulary [5] can be
used to infer trust information (if it is injected in
the appropriate location). Links to SKOS concepts
may be used to enhance discovery (e.g. browsing through categories). A similar approach can
be taken for place names by pointing to entities
served by gazetteers. Having all these different options could potentially result in a plethora of different kinds of Link Annotations with different
identifiers. Avoiding this either requires an ontology of Link Annotations or committing to one
commonly used method. In the case of the lat-
ter, only the ModelReference from the SAWSDL
standard may be used. The referenced resource
then has to be encoded in a way to let common
reasoning engines infer its type. For example, instead of introducing a new reference for places
(e.g. the http://.../PlaceReference), the ModelReference points to the OWL instance Paris,
which is modelled as instance of the class City
(which itself is a sub-class of Place).

4. The Semantic Annotations Proxy (SAPR)

The concept of a network proxy has been around
for decades [26]. A proxy acts on behalf of the service it encapsulates by taking its identity. Clients
can access the original service only through the
proxy; the proxied service stays hidden behind the
proxy. Clients are not aware of the existence of the
proxy. Even though the service location changes
(including the query part with the parameters),
the client interacts with the proxy as with the
original service . This approach is similar to Web
browsers accessing the Web through a proxy. The
semantic annotations proxy only acts on a requests
for metadata which has been registered to the

proxy. All other requests - if supported by the selected HTTP method - are redirected to the proxied service. The client then directly interacts with
the original service to, for example, request the actual data. In all other cases (including invocation
requests using HTTP Post, which doesnt support
redirects) the proxy forwards the request to the
services, and streams the result back.

The introduced proxy-based solution for injecting annotations into Web service descriptions
has been implemented as a Web service itself.
The first URL in Figure 2 represents a typical request for the capabilities description of an
OGC Web service. Once registered to the proxy
service, the semantically annotated description
can be retrieved using the second URL by using
the original request parameter (in this case re-
quest=GetCapabilities) and the service id 7. A
list of registered Web services and a list of all references for one Web service could then be requested
using the URLs (3) and (4).

4.1. Extracting the annotations

The following scenario assumes that the document with the annotations listed in Figure 1
is uploaded to the proxy using the manual upload form (URL (5) in Figure 2). The XML
stream is forwarded to the reference extractor,
which first identifies the service type by scanning
the XML header. Each service type is configured
through an identification pattern (a regular ex-
pression) and the patterns for the reference locations as specified in the according metadata stan-
dard. These locations are path expressions based
on the XPath [2] syntax. In this example, the
metadata is provided by an OGC WFS (version
1.1.0). The according pattern for the header is
listed as (1) in Figure 3. Each of the three given
patterns (e.g. .*Capabilities.*) has to be part
of the documents root element. For the WFS
1.1.0, the path expressions (2) and (3) in Figure 3 are configured. The first describes the location of a modelReference (as defined in the
SAWSDL standard) as attribute of a simpleTypeElement in XML schema. The second specifies the
MetadataURL in the FeatureType element as valid

7These are examples; the service identifiers change continuously and the repository is purged often. Use URL (3)
for a list of valid services.

(1) http://www.example.com/wfs?request=GetCapabilities&...
(2) http://semantic-proxy.appspot.com/api/get?request=GetCapabilities&...&sid=ae34aa09
(3) http://semantic-proxy.appspot.com/api/list/services
(4) http://semantic-proxy.appspot.com/api/list/references?sid=ae34aa09
(5) http://semantic-proxy.appspot.com/html/upload.html

Fig. 2. Example URLs to access the Semantic Proxy

destination. The nature of the reference is con-
catenated, and used to identify the location in the
original metadata document: child indicates that
the location of the discovered annotation should
point to the parent element, i.e., the annotation
should later be injected as child of the given loca-
tion. In the case of attribute or sibling the full location is stored; the metadata is then either injected
as attribute into the element located by the path
expression, or directly after it as new element.

The extraction and injection procedures make
use of the Streaming API for XML (STAX)8. The
extractor computes the path, implemented as a
stack of XML elements, for every element in the
XML stream and computes the match with the
configured patterns (also represented in stacks).
The elements in the stacks are recursively com-
pared. Namespaces of the individual elements are
ignored. In the case of a match, the location is extracted and persistently stored together with the
reference. In Figure 3, Pattern (4) represents such
a location. In consists of the path expression describing the location within the XML tree and
the location indicator (sibling, attribute, or child).
This example states that the associated reference
is injected after the element Name (since it is configured as sibling) with the text Geol50k. The
result of the extraction procedure is the service
identifier, which is required to retrieve the annota-
tions. Each registration results in a new service id.
One document (with different sets of annotations)
can therefore be uploaded multiple times without
risking conflicts.

4.2. Injecting the annotations

The injection procedure is illustrated in Figure
4. The client software requests annotated metadata using the proxy, a service identifier, and an

8We use Woodstox, a high-performance validating
namespace-aware StAX-compliant (JSR-173) Open Source
XML-processor, see http://woodstox.codehaus.org/.

open set of parameters. The second URL in Figure 2 is an example how to request a WSDL-based
description of a Web service. The proxy first extracts the service identifier from the request and
retrieves the annotations as well as the original
service request from the cache (which is built initially from the data store on startup). If the service id is not registered, an exception is returned
to the client. In the next step, the other request
parameters (e.g. the request-parameter of an OGC
service) are extracted and compared to the parameter in the original service request. If they dont
match, the client receives a redirection response
(HTTP Code 302) with the original location in the
HTTP header. If they match, the service metadata is retrieved from its original source and forwarded to the injection engine. The XML stream
from the source is read element by element (us-
ing again StAX). Similar to the extraction proce-
dure, a path expression is generated and matched
against the registered annotations. In the case of a
match, the reference itself (which could be either
attribute or a new XML element) is written into
the output stream. The resulting stream is directly
forwarded to the client.

Any errors during this procedure, e.g. due to
missing parameters or parsing problems, cause appropriate HTTP status errors. It is the clients responsibility to communicate the error to the end
user. Requests to the service which do not serve
metadata (e.g. requesting the feature data from an
OGC Web service) are redirected.

4.3. Reflecting change

Changes in the original metadata (e.g. new feature types have been added) dont affect the injection procedure as long as the stored reference
locations (the XPath statements) are still valid.
The injection procedure works on the stream, and
only stops if the XPath Stack at the current position in the stream matches a XPath expression
stored with the annotations. New feature types, or

Injecting Semantic Annotations

(1) ".*Capabilities.*",".*xmlns.*http://www.opengis.net/wfs.*",".*version=\"1.1.0\".*"
(2) //xsd:simpleType[@sawsdl:modelReference]/attribute()
(3) //wfs:FeatureTypeList/wfs:FeatureType/wfs:MetadataURL/sibling()
(4) //Capabilities/FeatureTypeList/FeatureType/Name/text()=\Geol50k\/sibling()

Fig. 3. Patterns for the extraction of annotations.

new operations in a WSDL file, are ignored; previously existing metadata will still be annotated.
If, however, the location of the stored XPath element changes (e.g., if the feature type which is
annotated is renamed, and the name attribute is
in the path), the annotation has to be updated
accordingly.

Fig. 4. The injection procedure

The current implementation supports semantic
annotations for common Web services compliant
to the W3C standards and described using the
WSDL standard. In addition, the OGC standards
for Web Processing Services (WPS), Sensor Observation Services (SOS), and Web Feature Services (WFS) have been configured. Support for
new service types (or new extension points for semantic annotations) is added through XML-based
configuration files. Annotations are usually simple
attributes which are added to existing elements.

But annotating, for example, a process description
coming from a WPS requires the injection of multiple lines of XML.

SAPR additionally comes with a RESTful API
to interact (e.g. uploading, searching) with the registered services. The URLs (3), (4), and (5) in Figure 2 are examples. (3) can be used to list all services currently registered with SAPR. (4) lists extracted semantic annotations for one service. The
response, encoded in JSON, is a set of bindings
between a location (the XPath-Expression) and a
reference which has to be injected at this location
(either an attribute or a whole chunk of XML).
To register an annotated document, the file can
be uploaded via the upload form available at (5).
Clients are also able to directly register annotated
metadata through the API.

5. Evaluation of the injection approach

The focus on the implementation is the dynamic
injection of semantic annotations into structured
metadata. It does neither contain an automatism
how to create the annotations, nor do we add any
functionality which makes use of them (e.g. include reasoning on the semantic annotations). In
the research project SWING [25], a visual interface has been implemented which supports the
user in semantically annotating OGC Web Feature Services [6]. The semantic annotations have
been used in SWING for the semantic discovery.
In the GDI-Grid project [21], we implemented an
Eclipse-based plugin for the semantic validation
of service compositions. The WSDL documents of
the Web services in the workflow were semantically
annotated using the SAWSDL standard. SAPR
has been initially developed in GDI-Grid to support the semantic validation. In the ENVISION
project [18], SAPR is one core component for
building a semantically enabled infrastructure for
designing and publishing environmental models as
Web services. The originally desktop-based semantic annotation interface implemented in SWING

is currently migrated to the Web. It directly integrates with SAPR, making it possible for even
non-ICT experts to semantically annotate Web
service metadata. Being a standard component for
the semantic enablement of existing service infrastructures is the long-term vision for the Semantic
Annotations Proxy.

SAPR has been deployed as a Software-as-a-
Service (SaaS) using the Google App Engine9.
This approach comes with some limitations on the
consumed resources, which have only a theoretical impact in the case of SAPR. The requirements for bandwidth, processing time, or storage
are negligible for injecting references into metadata streams. The benefits of cloud infrastructures
such as scalability, availability, and performance
[4] outbalance the drawbacks caused by flexibility
constraints. Google App Engine manages load balancing by dynamically adding instances covering
increased load. To further improve performance,
the internal caching service of the App Engine is
used for the retrieval of the annotations. SAPR is
a free Web service. In addition, it is free software
and can be deployed in other locations as well.

Fig. 5. Impact of the proxy on the response time.

9Available at http://code.google.com/appengine

Working directly on the streams ensures very
fast responses. The time difference between accessing the meta-data from the original source or
the annotated document from SAPR is negligi-
ble, external factors, such as network latency or
server response time, have a larger impact on re-
sponsiveness. Figure 5 depicts the average (50 runs
each) response times (vertical axis) for requesting the original metadata or the injected metadata from the proxy (which includes the former).
In particular the third (very slow) service illustrates that other factors have a greater impact on
the response then the proxy. In the fourth case
(requesting one file from the SAWSDL-Testsuite),
the proxy request was consistently faster then the
original. This is probably due to a more efficient
implementation of HTTP request handling within
the Google App Engine SDK (since the tests ran
on a local setup, any benefits from the proxy running on the Google infrastructure are not reflected
in this chart).

The required support of different service metadata standards has been thouroughly tested with
module tests using appropriate test suites from
the various standards (e.g. the already mentioned
SAWSDL Test Suite). But the strict dependence
on standards is also a problem: Web services with
invalid service descriptions are common, and far
too often we experienced unexpected errors during
the XML parsing. In addition, the slow response
times can be a limiting factor within the Google
App Engine. The API cuts off requests exceeding
ten seconds response time, which is not uncommon
for Web services running not within large-scale in-
frastructures. SAPR has been implemented to be
robust in respect to changes of the source meta-
data. Changing the metadata does not affect the
injection procedure, as long as no elements are removed which are used within the extracted XPath
expressions.

6. Related Work

Early work on semantic annotations was focused
on the manual semantic annotation of Web content
[11]. Semantic annotations for Web services, and
the concept of Semantic Web Services (SWS), have
been introduced by [22] and [28]. This work was
primarily concerned about the semantically enabling W3C-compliant Web services, which even-

Injecting Semantic Annotations

tually led to the development of the W3C recommendation for Semantic Annotations for WSDL
(SAWSDL) [14]. Enriching Geospatial Web services with ontologies has been investigated by [15]
and [12].

The long-term vision of SWS is the automatic,
reasoner-supported integration of Web services.
Reasoning engines depend on specifications expressed in a logic-based language, e.g. the Web
Ontology Language (OWL). Enabling semantics is
therefore the task of either directly creating Web
service descriptions in such a language, or by linking existing XML-based descriptions to these on-
tologies. The OWL-S Ontology (OWL for Services,
[17] helps to (re-)model W3C-compliant Web ser-
vices. The Web Service Modelling Ontology [24]
(WSMO), and its recent descendant WSMO-Lite
[13] are similar (but more sophisticated) solutions
following the same approach. In this case, the
capabilities of a Web services, as well as its information model, are completely covered by the
ontologies. In the long run, semantically enabled
Web services will directly deliver these ontologies (aligned to shared domain ontologies). XMLbased metadata may then only be used to sustain
backwards-compatibility.

Coupling Semantic Web technologies with often
heterogeneous Spatial Data Infrastructures (SDI)
has been subject of various research [19,7,12,23,
15,25]. In [10], a semantic-enablement layer (SEL)
is proposed to complement existing SDI components with Web services for ontology access and
reasoning. SAPR can be considered as one important step towards SEL, since it provides the link
between existing spatial data services and the SEL
components.

7. Conclusion

The vision of the Semantic Web relies on content which is either directly semantically represented (i.e., data encoded in an ontology language)
or has been semantically annotated. Legacy infrastructures comply to well-established (and often
domain-specific) standards. Here, semantic representations of the data would require updates to
the standards and accordingly the running infras-
tructures. Injecting the semantic annotations with
SAPR is a non-intrusive solution to bring the benefits of semantics to these systems. And by re-

maining compliant to the standards, existing nonsemantic clients wont be locked out. The proxy
itself is not semantically enabled: it does neither
enable users to create semantic annotations, nor
does it perform reasoning on the semantic annota-
tions. The API supports registration of annotated
documents and simple operations such as deleting or listing annotations. It does not support the
discovery, since we assume that existing semantically enabled catalogues and service registries already perform this task. Registering a Web service
semantically annotated with SAPR to such catalogues then enables the semantic discovery of the
annotations.

Merging different annotations is not supported.
During the registration of annotated metadata,
SAPR assigns a unique identifier (the SID). It is
later required to retrieve the annotated document,
which could then, for example, be registered to
a concept-based search engine. A document registered multiple times with different annotations
results in different SIDs, and consequently new
service metadata URLs. An URL pointing to the
same document (but having a different SID) with
data quality references would accordingly be used
in trust-aware IR systems. SAPR is only providing
means to inject annotations into legacy metadata.
It is in the responsibility of the client application
to propagate the resulting new service metadata
links to appropriate applications like search en-
gines.

The presented approach targets XML-based
metadata of Web service descriptions. We have
neither addressed the actual XML data nor other
content types not encoded in XML. The former is
simply an issue of configuring the proxy accord-
ingly. The mentioned example of injecting details
of data quality into the actual data is one target
application of SAPR. Injecting annotations into
non-XML based data was not covered, but is also
required to integrate information hidden in raw
data (e.g. sensor streams, satellite images, audio
files). Here, the annotations could be injected as
additional fields into existing metadata (e.g. the
EXIF metadata for image files).

Dynamic injection relies on a reproducible way
to identify the annotations location. Injecting annotations into unstructured data (i.e. data without a structure compliant to a schema) is difficult

to achieve. Microformats and RDFa 10 are proposed markup formats for XHTML, and therefore
means to annotate websites. The benefits of separating the annotations from the source data may
also apply here, but are not realized in SAPR.

SAPR is currently used in the ENVISION
project11. In ENVISION we aim to semantically
enrich and chain environmental Web services, with
the long-term goal to migrate existing environmental models into the Web. We have also released an API12 which supports the translation
of existing Web services into RDF-based service
models. Ontology alignment tools allow for linking
these service models to shared domain vocabular-
ies. References to these service models are then
added to the service metadata and uploaded to
SAPR. The resulting new locations are registered
to a search engine supporting concept-based and
spatial query processing. In addition, we are currently investigating the semantic annotation of binary data formats such as NetCDF13, which are
common for environmental services. Future work
will investigate how these formats can be supported in SAPR.

In this paper an implementation for a decoupled solution for semantic annotations of existing Web services has been presented. The proxybased approach enables semantically aware clients
to benefit from the injected semantic annotations
into legacy metadata without touching the original
services. The proxy acts on behalf of the hidden
Web service; the client does not have to manage
the two separate sources. Requests are mediated
and result either in updated metadata or redirects
to the original source. SAPR is used for the semantic annotation of W3C- and OGC compliant
Web services. The implementation was conceptually designed to be non-intrusive, making it possible to stay compliant to the underlying standards
for Web service descriptions. Finally, the streambased injection approach and the deployment in
the cloud ensured a very responsive system useful

10RDAa is a W3C recommendation for annotating web-
sites. More information can be found here: http://www.w3.
org/TR/rdfa-in-html/

11See http://www.envision-project.eu
12See http://kenai.com/projects/envision for

the

source code

13A description of this format is available at http://www.

unidata.ucar.edu/software/netcdf/

also for applications with high demands for per-
formance.

8. Acknowledgements

The presented research has been funded by the
BMBF project GDI-Grid (BMBF 01IG07012, see
http://www.gdi-grid.de) and the European research project ENVISION (FP7-249170, see http:
//www.envision-project.eu). Contributions by
Carsten Kessler, Simon Scheider, and Mohammed
Bishr have been of great help.
