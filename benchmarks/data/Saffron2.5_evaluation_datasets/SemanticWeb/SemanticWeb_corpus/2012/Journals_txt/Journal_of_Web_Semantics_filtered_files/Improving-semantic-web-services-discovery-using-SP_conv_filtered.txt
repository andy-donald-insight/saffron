Web Semantics: Science, Services and Agents on the World Wide Web 17 (2012) 1224

Contents lists available at SciVerse ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

journal homepage: www.elsevier.com/locate/websem

Improving semantic web services discovery using SPARQL-based
repository filtering
Jose Maria Garcia, David Ruiz, Antonio Ruiz-Cortes

University of Seville, ETSI Informatica, Av. Reina Mercedes, s/n, 41012 Sevilla, Spain

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 28 August 2010
Received in revised form
19 May 2012
Accepted 9 July 2012
Available online 24 July 2012

Keywords:
Semantic web services
Service discovery
Scalability
Service repositories
Semantic web query languages

Semantic Web Services discovery is commonly a heavyweight task, which has scalability issues when
the number of services or the ontology complexity increase, because most approaches are based on
Description Logic reasoning. As a higher number of services becomes available, there is a need for
solutions that improve discovery performance. Our proposal tackles this scalability problem by adding
a preprocessing stage based on two SPARQL queries that filter service repositories, discarding service
descriptions that do not refer to any functionality or non-functional aspect requested by the user before
the actual discovery takes place. This approach fairly reduces the search space for discovery mechanisms,
consequently improving the overall performance of this task. Furthermore, this particular solution does
not provide yet another discovery mechanism, but it is easily applicable to any of the existing ones, as
our prototype evaluation shows. Moreover, proposed queries are automatically generated from service
requests, transparently to the user. In order to validate our proposal, this article showcases an application
to the OWL-S ontology, in addition to a comprehensive performance analysis that we carried out in
order to test and compare the results obtained from proposed filters and current discovery approaches,
discussing the benefits of our proposal.

 2012 Elsevier B.V. All rights reserved.

1. Introduction

Current Semantic Web Services (SWS) discovery solutions
often suffer from scalability issues, so large and complex service
repositories cannot be properly handled by them. Although the
research community is putting efforts into improving discovery
mechanisms, the underlying reasoning facilities do not scale well
in general [1]. The approach taken in this paper does not consist
of yet another discovery mechanism, but on the inclusion of a
preprocessing stage that filters service repositories using two
different queries, so that the search space for discovery processes is
reduced in our experiments, on average, from 12.5% of the original
repository size up to 1.1%, depending on the concrete query used
and the nature of the repository and user request. Consequently,
service discovery execution time is greatly improved, performing
the whole process, when using our proposed filters, at least 9.1
times faster and up to 44.7 times faster, with a contained penalty
on precision, depending on each corresponding query and the
underlying discovery mechanism chosen.

 Corresponding author. Tel.: +34 9545 59814; fax: +34 9545 57139.

E-mail addresses: josemgarcia@us.es (J.M. Garcia), druiz@us.es (D. Ruiz),

aruiz@us.es (A. Ruiz-Cortes).

URL: http://www.isa.us.es/josemaria.garcia (J.M. Garcia).

1570-8268/$  see front matter  2012 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2012.07.002

The number of currently available services in public repositories1 is expected to explode in the future, so that billions of services will be able to be consumed on the Web [2]. Furthermore,
currently available semantic descriptions, in terms of SWS classical
ontologies such as OWL-S or WSMO, present a high complexity for
defining and processing them. Both issues lead to a scenario where
discovery mechanisms based on different logic formalisms have
scalability issues. Consequently, current research efforts focus on
providing improvements and optimizations of those mechanisms,
using lightweight semantic technologies, in order to enhance the
usability of SWS [3,4].

In order to alleviate the scalability problem on semantic discovery mechanisms, there are some proposals that provide different techniques to improve the discovery performance, such as
indexing or caching descriptions [5], using several matchmaking
stages [6], and hybrid approaches that include non-semantic techniques [7]. Our proposal takes a novel approach of reducing the input for discovery mechanisms, so that the resulting process is more
streamlined, only reasoning about services which actually matter
with respect to the user request. Thus, our solution filters services
that can be discarded a priori, because they are not related at all

1 At the moment of writing, seekda! service crawler has indexed 28,606 services,
ProgrammableWeb has registered 3,287 web APIs, and iServe repository contains
2,193 SWS descriptions.

with requirements and preferences stated by the user, considerably reducing the search space before actual discovery.

For example, consider the following scenario: a semantic service repository contains thousands of services from several travelrelated domains, such as hotel bookings, plane tickets, car rentals,
and travel insurances. If a user looks for a service that returns hotels
given a particular city and a country, it is not necessary to process
the whole repository to discover candidate services for the user re-
quest, but only consider the portion of services that are specifically
related to the hotel lookup domain concepts that appear on the re-
quest, in this case. Thus, using lightweight technologies to preprocess the repository, the search space can be reduced in order to save
computational resources and improve discovery performance.

For the proposed preprocessing, our proposal analyzes the user
request in order to extract the concepts that are being used in its
semantic definition (in the above example, some of them could be
City, Country or Hotel, for instance). Then, the repository is filtered
so that only services that use those concepts or related ones are
selected to become the input for the subsequent discovery process
(e.g. services whose definitions refer to City, Country and/or Hotel
concepts, in the latter case).

Two different SPARQL [8] queries perform the filtering in our
approach, namely Qall and Qsome. The former returns only those
services whose definitions contain all the concepts referred by a
user request, assuming that services have to fulfill every term of the
request in order to be useful for the user. In turn, the latter query
selects service definitions that refer to some (at least one) of the
concepts referred by a user request, assuming that those services
may satisfy its requirements and/or preferences to some extent,
despite the missing information.

Our solution does not pretend to provide yet another discovery
mechanism, but to introduce a preprocessing filtering stage, based
on an accepted standard, that yields a notable improvement on
heavyweight semantic processes, such as matchmaking of services.
Furthermore, our proposed filtering does not add a noticeable
amount of execution time with respect to matchmaking, because
SPARQL queries used present a linear complexity on the size of the
dataset and graph patterns included [9].

To the best of our knowledge, there are no proposals on filtering
semantically-enhanced service repositories, but it is acknowledged
that some sort of preprocessing can alleviate discovery and ranking
tasks performed on those repositories [6]. To sum up, the main
contributions of the proposal presented in this article are the
following:
1. We propose a technique to improve semantic service discovery
performance, based on a preprocessing stage that filters repositories in order to reduce the search space of subsequent discovery processes.

2. Our proposal is applicable to any discovery mechanism because
it is performed before actual discovery occurs, and it allows interoperability with existing service repositories. In this work,
we use the OWLS-MX hybrid matchmaker [7] to illustrate this
point, though our proposal has also been applied to other discovery mechanisms [10].

3. Filtering is performed automatically from user requests, analyzing them and obtaining standard SPARQL queries without user
interaction. Two different queries are presented, enabling two
filtering levels, depending on the user needs and the characteristics of service repositories. We analyze and thoroughly discuss
each query throughout the article.

4. In order to assess the actual impact of our proposal, we carried out a comprehensive, experimental study. Using a widelyused test collection (OWLS-TC), we applied our proposed filters
to several discovery mechanisms, evaluating and discussing
performance improvements using the Semantic Web Service
Matchmaker Evaluation Environment (SME2).

The rest of the article is structured as follows. Firstly, Section 2
presents some background information to contextualize and motivate the proposal. In Section 3 we show how to use SPARQL-based
filtering within a discovery scenario, presenting both restrictive
and relaxed filters that can be applied in different cases. Section 4
discuss the integration and implementation of our proposal applied to SWS frameworks, specifically OWL-S. Then, in Section 5
the performed experimental study is explained, analyzing the results and discussing the advantages of our proposal. Section 6 outlines the related work on this field. Finally, in Section 7 we discuss
the conclusions.

2. Background

Using a Semantic Web query language is a natural fit for
performing SWS discovery and ranking processes in terms of user
requests, because, essentially, these processes search for elements
in some sort of persistent storage using selection and ordering
criteria. However, current query languages present shortcomings
with respect to the level of inference and computation needed
for SWS discovery and ranking. In the following we introduce the
background elements of our proposal in order to contextualize and
further motivate our work.

2.1. Querying the Semantic Web

There are three main approaches for Semantic Web query
languages: graph-based, rule-based, and DL-based query languages [1113]. Firstly, graph-based query languages allow us
to fetch RDF [14] triples based on matching triple patterns with
RDF graphs. Secondly, rule-based query languages propose logic
rules to define queries, supporting RDF reasoning systems. Finally,
DL-based query languages allow us to query Description Logic (DL)
ontologies described in OWL-DL [15], being able to search for con-
cepts, properties, and individuals. In general, rule- and DL-based
query languages provide more reasoning mechanisms than graphbased ones, though it depends on the entailment regime applied
to the concrete triple store and querying system. However, the
former are not mature enough and they are in early stages of
development [11], so the latter are more widely used, especially
SPARQL [8], which is the current W3C Recommendation.

There are several graph-based query languages with different
features [11], but SPARQL is the only language that is a W3C
Recommendation [8]. In fact, it is fully supported in several
implementations.2 As a consequence, SPARQL (and its extensions)
is the most widely used query language for the Semantic Web.
There are several SPARQL implementations, such as Virtuoso,
Sesame and ARQ,3 which is included in the Jena Semantic Web
Framework for Java. The latter is the chosen one for our evaluation
tests presented in Section 5.

SPARQL, as a graph-based query language, explicitly accounts
for the definition of labeled directed graphs by RDF triples, which
conforms the very foundations of a Semantic Web ontology. Its
main approach to query semantic repositories is to define graph
patterns involving triple patterns, matching RDF triples, which are
usually denoted (s, p, o), where s is the subject, p the predicate, and
o the object. In order to work with said repositories, SPARQL has
four different types of queries: SELECT, CONSTRUCT, DESCRIBE
and ASK. Each type serves for a different purpose: SELECT queries
return variables and their bindings with respect to the stored
RDF triples; CONSTRUCT queries build an RDF graph based on

2 http://www.w3.org/2001/sw/DataAccess/tests/implementations.
3 Virtuoso: http://www.openlinksw.com/virtuoso/ ;
Sesame: http://www.openrdf.org/ ; ARQ: http://jena.sourceforge.net/ARQ/.

J.M. Garcia et al. / Web Semantics: Science, Services and Agents on the World Wide Web 17 (2012) 1224

a template defined in the query; ASK queries test whether a
pattern has any solution or not; and DESCRIBE queries return
a graph made up of triples relating to a nominated resource,
in some preconfigured way, according to the querying system
implementation.

Essentially, each SPARQL query is defined by a graph pattern
expression, based on Turtle notation [16], that is matched against
an RDF dataset in order to bind the variables used in triple patterns
involved in that expression. Variables may substitute the subject,
predicate, and/or object of any triple pattern, that ranges over
matching RDF triples, binding variables accordingly. A basic graph
pattern containing a set of triple patterns can be filtered using
built-in conditions that restrict variable bindings, or combined
with other patterns that may be matched optionally (not rejecting
solutions if variables included in an optional graph pattern cannot
be bound) or alternatively (one or more of several alternative graph
patterns may match). Finally, a list of modifiers can be applied to
SPARQL queries solutions, so that they can be returned ordered by
a defined criteria, ensuring that solutions are unique, or limiting
the number of them, for instance.

Current SPARQL recommendation offers a very simple entailment that does not support proper reasoning. For instance, if a
graph pattern looks for an RDF resource of a given class A, it does
not match with resources whose classes are subclasses of A, though
intuitively they should match. To solve this issue, SPARQL querying systems implement various entailment regimes, some of them
being formalized by W3C for the next version of the SPARQL rec-
ommendation.4 However, if simple entailment, as defined in [8],
is the only available regime in the SPARQL implementation being
used, two approaches can be taken: (1) the implicit knowledge,
such as subclassing, can be made explicit by adding corresponding RDF triples to the dataset prior to SPARQL query execution; or
(2) subclasses can be made explicit directly in the graph patterns of
the query. The latter solution is chosen for our proposal evaluation
as discussed in Section 4.3.

Currently, the SPARQL recommendation is being revised to
apply some other extensions already identified, such as insert/
update/delete queries, access to collection members, or aggregate
functions (COUNT, SUM, GROUP BY, etc.). Furthermore, different
authors propose extensions to further improve reasoning features [17], expressiveness of queries [18], or even approaches that
add DL-based languages features [13]. However, in this work we
stick to SPARQL 1.0 (the recommendation at the time of writing) to
improve discovery processes, though some of the extensions discussed can be also applied (see Section 6).

2.2. Semantic Web Services

SWS are often defined using specific semantic frameworks,
which add extensions to non-semantic service descriptions as
in SAWSDL [19], or provide ontologies, such as OWL-S [20],
WSMO [21], or WSMO-Lite [22], that serve as the foundations
for tools to discover and rank services in terms of user requests
described using their provided facilities. Furthermore, these
ontologies can be extended to improve those tasks using other
ontologies [2325], so that service descriptions may include
information about quality-of-service and preferences, for instance.
Essentially, a service description, whether it is defined using
OWL-S, WSMO, SAWSDL, or WSMO-Lite, is composed of several
statements or terms that define service features, which can
describe functionality (such as input and output parameters)
or non-functional aspects. These terms refer to several related

4 http://www.w3.org/TR/sparql11-entailment/.

Listing 1: OWL-Sservice profile example.

@prefix p r o f i l e :

@prefix process :

<http : / /www. daml . org / services / owls / 1 . 1 / P r o f i l e . owl#>.
<http : / /www. daml . org / services / owls / 1 . 1 / Process . owl#>.

@prefix portal :

@prefix travel :

<http : / / purl . org / iserve / ontology / owlstc / portal . owl#>.

<http : / / purl . org / iserve / ontology / owlstc / travel . owl#>.

: CityCountryHotelProfile a p r o f i l e : P r o f i l e ;

p r o f i l e : hasInput
p r o f i l e : hasInput
p r o f i l e : hasOutput

: CityInput ;
: CountryInput ;
: HotelOutput .

: CityInput a process : Input ;

process : parameterType portal : City .

: CountryInput a process : Input ;

process : parameterType portal : Country .

: HotelOutput a process : Output ;

process : parameterType travel : Hotel .

domain concepts. Similarly, user requests are composed of a
number of terms that describe the requirements the requested
service has to meet. Each requirement is also related to one or more
particular concepts.

For instance, OWL-S service descriptions feature the service
functionality within service profiles, where different types of terms
describe inputs, outputs, preconditions and results, correspond-
ingly. In turn, WSMO service descriptions are defined by a capability and interfaces, that contains a number of terms describing
preconditions, assumptions, postconditions, effects; and inputs,
outputs and transition rules, respectively.

In order to develop an abstract and interoperable solution,
decoupled from concrete SWS ontologies, our filters are defined
in Section 3 using an abstract vocabulary of terms and their referred domain concepts. Concrete applications to existing SWS
frameworks can be consequently developed by identifying correspondences between this vocabulary and the corresponding SWS
ontology so that proposed filters can be implemented using
SPARQL queries over SWS ontologies (see Section 4).

Consequently, we assume that service descriptions and user
requests are defined in terms of concepts from some domain
ontologies, which depend on the concrete scenario. As an example,
consider the scenario described in Section 1, where a repository
contains several services related to travel domains. Service
descriptions may feature several statements or terms defining
their provided functionality and non-functional properties using
concepts from travel domain ontologies. Thus, a hotel lookup
service description (showcased as an OWL-S profile in Listing 1,
using Turtle notation) will contain terms that refer to concepts like
City, Country or Hotel, for instance.

2.3. Discovering and ranking

The common use case for discovery and ranking of SWS is
depicted in Fig. 1: Starting from a service repository (S) containing
definitions either using OWL-S, WSMO, SAWSDL, or WSMO-
Lite, for instance, that conforms the search space, the discovery
process searches for these available service definitions, which
are described in terms of domain ontologies (O), that match
with a user request (U). This matchmaking is usually performed
using logic reasoning techniques, such as DL reasoners [2628],
logic programming [25,29], or hybrid approaches [7,30,31]. The
resulting discovered services are a subset of the initial repository,
where each instance of this subset is considered to be compliant
with the user request, to some extent.

Fig. 1. Semantic discovery and ranking processes.

Fig. 2. Service procurement architecture including a SPARQL filtering stage.

Concerning user requests for SWS discovery and ranking, there
are several approaches on how to define them. Thus, in standard
WSMO they are described as goals, where the functionality
requested by a user is defined by means of capabilities and
interfaces. They can be used to match corresponding services
in the discovery stage taking into account preconditions, effects,
inputs, and outputs, among other description elements pertaining
to capabilities and interfaces.

Furthermore, some authors extend WSMO goals to refine
non-functional property descriptions, so that they can be used
to rank previously discovered services [25,31]. Therefore, using
both discovered services and preferences described in the user
request [23], the ranking process returns an ordered list of those
services in terms of stated preferences. Although user requests
used in our evaluation only contain information about inputs and
outputs, more complex user requests can also take benefit of our
proposal [10].

SWS discovery techniques particularly suffer from performance
and scalability issues in this context. The underlying logic formalisms are not sufficiently scalable for the current Web [1], so
there is a need for lightweight approaches to SWS discovery or
optimizations over currently available solutions. The main motivation of this work is to come out with a solution that effectively improves discovery and ranking, turning them into more lightweight
processes, while making the most of currently available match-
makers.

3. Preprocessing service repositories using SPARQL

As discussed before, current SWS discovery and ranking tend to
be complex, heavyweight processes. In the following we present
our abstract filtering proposal and how it can be implemented
using standard, automatically generated SPARQL 1.0 queries.

3.1. Filtering a service repository

Fig. 2 showcases our proposed architecture as an alternative to
the one described in Fig. 1. Our solution adds a new preprocessing
stage, previous to the discovery process, that filters the service
repository, using SPARQL queries as described in Section 3.2. The
 services from the original
aim of the filtering stage is to obtain S
repository S that may be possibly matched with the user request
U in the discovery process, discarding those ones that cannot fulfill
that request at all.

In a general scenario, our proposed filtering stage discriminates
service descriptions depending on whether concepts referenced
within their terms are present in the user request or not. To
this extent, two different filters can be applied, offering different
filtering levels. On the one hand, one of the filters (Qall) only returns
service descriptions that refer to the whole set of related concepts
described in the user request. On the other hand, a more relaxed
filter (Qsome) returns those service descriptions that refer to some
(at least one) of the concepts that are also referred by the user
request. In turn, both filters discard services whose terms do not
refer to any of the related concepts referred in the requirements of
the user request, because in that case it can be inferred that they
are not related to the service the user is searching for.

Considering that a service description is defined using a series
of terms that refer to several domain concepts, we can describe
our generic proposal as follows. Let D = (O, S, U) be a 3-tuple
that represent a discovery scenario as outlined in Fig. 2, where each
element of the tuple is defined in the following.
Domain ontologies (O). Let Oi be a certain domain ontology
whose concepts can be referred by the user request and service
descriptions from a certain discovery scenario D. The set of domain
ontologies O is defined as the set of ontologies that can be used

J.M. Garcia et al. / Web Semantics: Science, Services and Agents on the World Wide Web 17 (2012) 1224

to define the rest of the elements from that scenario, i.e. the user
request and service descriptions.
O = O1    On.
Service repository (S). Let OSi be a subset of O. A service repository S
is a set of service descriptions Si that are defined by several terms
tij. Each term refer to a set of concepts Cij defined in the ontology
OSi. Therefore, each Si is represented as a set of tuples that relate
terms with their corresponding set of referred concepts:
Si = {(ti1, Ci1), . . . , c, (tin, Cin): Ci1    Cin  OSi}.
User request (U). Similarly, a user request U contains requirements
in the form of terms that refer to some subset of concepts from a
domain ontology OU  O:
U = {(t1, C1), . . . , c, (tn, Cn): C1    Cn  OU}.

In order to better illustrate previous definitions, consider an
scenario where a user is searching for a hotel lookup service like the
described in Listing 1. The corresponding user request U is defined
as follows:
U = {(inputTermu1,{portal:City}),
(inputTermu2,{portal:Country}),
(outputTermu1,{travel:Hotel})}.

This user is going to search for services described in a repository
S that contains three services related to travel domains, such that:
S1 = {(inputTerm11,{portal:City}),
(outputTerm11,{travel:LuxuryHotel})}
S2 = {(inputTerm21,{portal:City}),
(inputTerm22,{portal:Country}),
(outputTerm21,{travel:Hotel})}
S3 = {(inputTerm31,{travel:Surfing}),
(outputTerm31,{travel:Beach})}.

Finally, the global domain ontology in this example could be
simply considered as the set of concepts involved in previous de-
scriptions: O = {portal:City, portal:Country, travel:LuxuryHotel,
travel:Beach, travel:Hotel, travel:Surfing}.
Once the elements that conform to the discovery scenario D =
(O, S, U) are properly defined, the two previously introduced
  S so that
filters can be used alternatively to obtain an S
 = (O, S
, U)
the subsequent discovery process defined by D
performs better.

In order to simplify both filter definitions, we denote with CSi
the subset of concepts from OSi that are actually referred in the
terms featured in Si. Equivalently, CU is the subset of referred
concepts in U.
CSi = {c  OSi:(tij, Cij)  Si|c  Cij}
CU = {c  OU:(tj, Cj)  U|c  Cj}.

Consequently, in the example described before, the corresponding concepts subsets of O for the service descriptions in S and the
user request U are the following:
CS1 = {portal:City, travel:LuxuryHotel}
CS2 = {portal:City, portal:Country, travel:Hotel}
CS3 = {travel:Surfing, travel:Beach}
CU = {portal:City, portal:Country, travel:Hotel}.

The application of both filters to a service repository S return a
 depending on the corresponding filter applied. In the case
subset S
 = Qall(S, U), the application of the filter returns a subset of
that S
S only containing services whose referred concepts are a superset

= }.

In turn, if we identify S

of those referred by a user request U, i.e. all concepts referred by
the user request are referred by returned service descriptions.
Qall(S, U) = {Si  S: CU  CSi}.
 = Qsome(S, U), the filter selects
those services from S that share at least one referred concept with
the user request U, so the intersection of corresponding referred
concepts sets cannot be empty.
Qsome(S, U) = {Si  S: CU  CSi
Results of applying both filters to the described example are, in
the first proposed filter case: Qall(S, U) = {S2}, and in the second
case: Qsome(S, U) = {S1, S2}.
Although Qall effectively reduces the discovery search space
(Qall(S, U)  S) and, consequently, processing time, it may
excessively restrict the candidate services to be considered for the
subsequent discovery process, whose resultant precision and/or
recall may be affected, as we corroborate in our experiments in
Section 5. Thus, the proposed Qsome filter relaxes the former one
by considering each concept referenced in the user request as a
matching alternative within the set of concepts referred by service
description terms. In this case, service descriptions that do not
refer to any concept used in the user request are discarded for the
following discovery stage. In general, Qall(S, U)  Qsome(S, U) 
S, so filtering repositories using Qsome, the amount of services that
are considered for discovery (and ranking) is reduced less than in
the Qall scenario. However, the overall performance improvement
is also high, while it slightly affects the process precision/recall
relation, as analyzed in Section 5.

3.2. A SPARQL implementation for filters

The abstract description of our proposed filters Qall and
Qsome introduced previously can be implemented in any existing
SWS discovery scenario using SPARQL SELECT queries. Given a
concrete user request defined using an existing SWS framework,
both filters can be instantiated as SPARQL queries that select
corresponding services from an RDF-based repository, which
contains descriptions based on the same SWS framework. In
this case, generated queries have to be also based on graph
patterns ranging over that SWS framework RDF representation.
Nevertheless, to better account for interoperability some proposals
that integrate SWS framework definitions [3234] can also apply
our proposed filters (see Section 6).

Queries need to be instantiated for each user request U,
because they depend on the structure of that request. In order
to compose Qall and Qsome filters, the implementation has to
analyze which concrete concepts referred by the user request
are going to be included in the corresponding SPARQL query.
Specifically, query generation depends not only on the structure
of the ontology our proposal is being applied to, but also on the
concrete instance U of the user request itself, especially on the
concepts referred by its terms (CU). As a consequence, queries have
to be tailored depending on the corresponding instances managed
by each discovery process. However, the generation of Qall and
Qsome SPARQL queries can be done automatically, maintaining the
transparency for the user of our proposed filtering stage within the
discovery process.

On the one hand, the Qall filter is implemented as a query
that searches for services whose featured terms refer to every
concept referred in the user request. Thus, for each term and
its corresponding concepts, the Qall query contains a triple
pattern that matches service definition triples that contains those
concepts, depending on the structure of the underlying SWS
ontology. On the other hand, the Qsome query is generated similarly,
but each triple pattern matching a user request referred concept is
grouped with the rest as alternative patterns, i.e. using the UNION
keyword, because Qsome searches for services whose terms refer
to at least one concept referred by the user request. The following
section presents an application of both queries to OWL-S.

Listing 2: Qall SPARQL query applied to OWL-S.

SELECT DISTINCT ? service

2 WHERE {

? service a service : Service ;

service : presents ? p r o f i l e .

l e a s t two inputs and an output . . .

# ? p r o f i l e has at
? p r o f i l e p r o f i l e : hasInput ?inputTerm1 .
? p r o f i l e p r o f i l e : hasInput ?inputTerm2 .
? p r o f i l e p r o f i l e : hasOutput ?outputTerm1 .
# . . . and referred input concepts are City . . .
{?inputTerm1 process : parameterType portal : City }
# . . . Country . . .
{?inputTerm2 process : parameterType portal : Country }
# . . . and the output concept
{?outputTerm1 process : parameterType travel : Hotel }

i s Hotel

4. Application to existing SWS frameworks

Our proposed preprocessing stage can be easily adapted to
any SWS framework, such as WSMO, OWL-S, SAWSDL or WSMO-
Lite, so that it can be virtually included within any discovery
process. Application to these frameworks can be performed by
identifying correspondences between elements from the filter
definition discussed in Section 3.1 and the facilities that each
framework provides to describe user requests, service terms and
their referred concepts. Therefore, the SPARQL implementation
of both filters contains triple patterns, using the target SWS
framework ontology, that refer to services (S), requests (U), terms
and domain concepts (CSi and CU). In the following, we present
a concrete OWL-S implementation of filters, but another early
implementation to WSMO services can be found in [10], further
proving our proposal applicability.

4.1. An OWL-S implementation

In order to implement an application of our proposed filtering
stage that relies on OWL-S descriptions, they have to be published
in a triple store and queries have to be defined in terms of OWL-
S constructs. Basically, both service descriptions (S) and user
requests (U) are modeled as Service Profiles. A service
profile may contain several terms that further define features
of an OWL-S service functionality, such as Inputs, Outputs,
Preconditions, and Results. Already presented Listing 1
shows an OWL-S service profile RDF description that is used as an
example user request in the following.

That service profile example has been taken from the OWLSTC test collection used to evaluate our proposal in Section 5. In
this collection, service descriptions merely contain information
about inputs and outputs, and their parameter types, but no
preconditions and results. Although both inputs and outputs can
be related to the corresponding service profile by using the
abstract hasParameter OWL-S property, in OWLS-TC profiles
are explicitly related to inputs and outputs with hasInput and
hasOutput properties. In consequence, our filters are refined to
take into account the stated difference between inputs and outputs
terms in OWL-S descriptions, so that they can obtain more accurate
results.

Listings 2 and 3 presents our proposed Qall and Qsome filter
queries, respectively.5 The identified correspondences between
the elements of our abstract filtering proposal and OWL-S

5 Prefixes are omitted for the sake of clarity, but they correspond to those shown
in Listing 1, in addition to service that refers to http://www.daml.org/services/
owl-s/1.1/Service.owl.

constructs are introduced for both SPARQL queries, as described
in Section 3.2, so that they can be directly used to filter an OWL-
S repository. In this example, both queries have been generated
from the sample user request U defined in Section 3.1, whose
referred concepts to be matched against service descriptions are
CU = {portal:City, portal:Country, travel:Hotel}.
Note that the presented OWL-S application refines the filters
proposed in Section 3, taking into account that each type of term in
U should be matched with the corresponding terms from service
descriptions Si. In consequence, CU and CSi sets of concepts are
split in two subsets each, depending on the type of term (input or
output), and compared with the corresponding one to obtain both
filters results.

Listing 3: Qsome SPARQL query applied to OWL-S.

SELECT DISTINCT ? service

2 WHERE {

? service a service : Service ;

service : presents ? p r o f i l e .

the p r o f i l e . . .

inputs and outputs of

# match a l l
? p r o f i l e p r o f i l e : hasInput ?inputTerms .
? p r o f i l e p r o f i l e : hasOutput ?outputTerms .
# . . . that
{? inputTerms process : parameterType portal : City }
UNION {? inputTerms process : parameterType portal : Country }
UNION {?outputTerms process : parameterType travel : Hotel }

refer to some concepts of

the user request

In principle, if the RDF(S) entailment regime were applied to
the RDF dataset of the service repository, making the inferred
knowledge explicit, Qsome could have been written using a more
concise and general approach that does not need to process the
user request instance in order to explicitly reflect its referred
concepts. Thus,
lines 911 in Listing 3 could be substituted
by the following excerpt, with : reqProfile being the concrete
ServiceProfile instance that is used to look for requested
services. However,
if we have to account for inference as
considered in Section 4.3 because a basic entailment is the only
available in our querying system, then Qsome as defined in Listing 3
is more convenient.

?inputTerms process : parameterType ?inputConcepts .
?outputTerms process : parameterType ?outputConcepts .
: reqProfile rdf : type service : Service .
: reqProfile p r o f i l e : hasInput ?reqInputTerms .
: reqProfile p r o f i l e : hasOutput ?reqOutputTerms .
?reqInputTerms process : parameterType ?inputConcepts .
?reqOutputTerms process : parameterType ?outputConcepts .

4.2. Automatic generation of filter queries

Right before the filtering is executed, corresponding SPARQL
queries have to be generated using OWL-S user requests. Conse-
quently, generation algorithms need to be applied to the OWL-S
ontology, as discussed in Section 3.2. Essentially, the user request
U (defined as a service profile as in Listing 1) has to be analyzed
to obtain the concepts that are referred by each description term
(CU). The automatic generation of queries can also differentiate
terms in order to get better results with basic entailment regimes.
For the evaluation discussed in Section 5, our filtering queries
generated from OWLS-TC user requests only take inputs and
outputs into account, though service profiles may contain more
information terms that could be also analyzed to obtain more
referred concepts from the corresponding domain ontology [10].
Therefore, for each OWLS-TC user request, its service profile is
traversed identifying each input and output, and adding a triple
pattern to the corresponding query to match services with the
same referred parameter types.

J.M. Garcia et al. / Web Semantics: Science, Services and Agents on the World Wide Web 17 (2012) 1224

4.3. Dealing with SPARQL entailment

If the RDF dataset does not contain subclassing knowledge as
explicit triples, there are two different approaches to deal with the
SPARQL basic entailment regime issues as described in Section 2.1.
On the one hand, the implicit knowledge concerning subclasses
can be retrieved using a DL reasoner [35,36], so that corresponding
RDF triples can be added to the RDF dataset, providing RDFS
entailment. As this inferencing process is time-consuming, it may
be executed periodically on the whole repository to properly
update the dataset, in order to minimize its impact on query
execution. However, this approach does not account for the fact
that, at the moment a query is executed, the RDF dataset may not
contain all the corresponding inferred triples.

On the other hand, queries can be rewritten, explicitly including
subclasses of the concepts referenced in user requests. Thus, a DL
reasoner is executed when generating SPARQL queries for both Qall
and Qsome filters to obtain the related subclasses for each concept
referred in the user request. As a consequence, service descriptions
whose referred concepts are subclasses of user request concepts
can also be returned by our filtering stage, improving the accuracy
of the results.

For instance, the chosen reasoner (Pellet [36] in our experi-
ments) may infer that LuxuryHotel instances are also Hotel
instances, because there is a subclass relationship between these
classes. Then both of them can be considered as valid alternatives
for a referred concept in a service description, if the user is looking for a service that features a Hotel concept as its input. Thus,
an additional pattern alternative where ?inputTerms refers to a
LuxuryHotel concept have to be included in line 11 of Listing 3.
Similarly, Qall queries can also be modified to take concept subclasses into account. In this case, line 14 of Listing 2 have to be
modified to the same patterns used in the Qsome case for Hotel
concept, i.e.:

{?outputTerms process : parameterType travel : Hotel }

{?outputTerms process : parameterType travel : LuxuryHotel } .

5. Analysis and evaluation

Our proposed filters have to be thoroughly analyzed, using
experimental results, in order to corroborate their soundness
and expected benefits. Each filter has been tested in different
situations, measuring several indicators to determine the actual
improvements of our proposed preprocessing stage. In this section
we describe the performed experimental evaluation, along with an
interpretation and discussion of the results for that experimental
study, which validates our proposal.

5.1. Experimental scenario

In order to experimentally test the suitability and performance
of our proposal, a proper test collection has to be used. There are
some publicly available collections to evaluate service discovery
algorithms for OWL-S and SAWSDL services. Particularly, we
evaluate our proposal with respect to the OWL-S Services Retrieval
Test Collection (OWLS-TC v36). This collection contains 1007 OWL-
S service descriptions from different domains, in addition to 29
user requests (referred as queries) and their corresponding sets of
relevant services, so that, for each OWL-S query, the performance
and effectiveness of matchmakers can be evaluated by checking

whether returned services are relevant to the corresponding query
or not.

In our experimental prototype, SPARQL query execution was
implemented in Java using the Jena Semantic Web Framework.
Therefore, our implementation reads OWL-S service descriptions
from OWLS-TC, which are parsed and processed by Jena, enabling
the execution of SPARQL queries over them. Then, the results
from the query execution are used to filter the list of services
that take part in the subsequent discovery process, improving its
performance.

Nevertheless, our proposal cannot be evaluated on its own, because it does not perform service discovery, but includes a preprocessing stage to filter repositories before service matchmaking.
Thus, in order to evaluate the actual impact of proposed filters using OWLS-TC, they have to be tested on top of an OWL-S service
matchmaker, so that the differences between using filters or directly performing the discovery process can be analyzed.

The actual evaluation of our prefiltering proposal has been
done using the Semantic Web Service Matchmaker Evaluation
Environment (SME2 v2.17). SME2 is an open source tool that can
be used to test and compare several SWS matchmakers using the
same test collection (OWLS-TC v3 in our case) as the input for
each matchmaker. The variables measured by SME2 that we use
to compare matchmakers are the following:
 Precision. The proportion of returned services that are actually
relevant for the corresponding query. The more precision a
query execution presents, the more accurate the answer is.
 Recall. The proportion of the relevance set that is returned by a
query. The more recall a query answer has, the more relevant
services are returned by the corresponding query.
 Fallout. The proportion of non-relevant services retrieved by
a query. In other words, it measures the amount of false
positives returned by the corresponding query with respect to
the complete answer set.
 Query response time. For each query, it measures the time a
concrete matchmaker spends on evaluating that query and
returning the corresponding results, without the initialization
time needed for registering service descriptions.
 Memory usage. Measured samples of the amount of memory a
matchmaker uses during its whole execution time.
Precision, recall and fallout are standard, well-known measures
for evaluating information retrieval techniques [37]. Particularly,
SME2 computes precision and fallout using a macro-averaged
approach that sums up the results from all query executions. Thus,
for each query, SME2 measures precision and fallout at equidistant
standard recall values, and then it obtains the mean value for these
measures at each recall level. Nevertheless, SME2 also computes
the well-known average precision measure for each single query,
enabling performance evaluation regardless of the number of
services returned by the matchmaker. Section 5.2 discusses the
mean average precision, along with the others measures.

Our prototype implements the IMatchmakerPlugin interface so that it can be plugged into SME2. However, it has to be associated with another matchmaker that is called using the same
interface to actually perform SWS discovery after prefiltering the
input. For evaluation purposes we have chosen some variants of
OWLS-MX, which is a hybrid SWS matchmaker that combines both
logic-based approaches and information retrieval techniques for a
high performance discovery [7]. Each chosen variant is firstly executed as is, and then with Qall and Qsome filters on top of it. Thus,
the different combinations of a OWLS-MX variant and (possibly) a

6 http://projects.semwebcentral.org/projects/owls-tc/.

7 http://projects.semwebcentral.org/projects/sme2/.

Table 1
Average query response times and precision.

Matchmaker

Filter

OWLS-M0

OWLS-MX3 (M3)

Qall
Qsome
None
Qall
Qsome
None

Avg query response
time (ms)
(57)

(3,023)

(1,592)

(61)

(2,810)

(214)

Avg query
precision (%)

(6.20)
(7.49)
(6.70)
(6.15)
(6.28)
(4.50)

corresponding filter are compared against each other in order to
evaluate the performance of our proposal in different situations.

For the sake of brevity, in the following we only compare the
performance results of two different OWLS-MX variants, namely
OWLS-M0 and OWLS-MX3 (M3), because the other variants present
similar results to the latter. OWLS-M0 is a simple, logic-based
matchmaker that only uses reasoning techniques, while OWLSMX3 (M3) adds text similarity matchings to avoid false positives
and improve the precision of the results. Evaluation results of the
rest of the variants are available upon request from the authors.

5.2. Analyzing tests results

Firstly, we analyze the performance improvement obtained
by using our proposed filters before service discovery. Table 1
presents a summary of the evaluation performed where both
OWLS-M0 and OWLS-MX3 (M3) variants are compared in terms
of their average execution time and mean average precision for
all OWL-S queries of the test collection, along with confidence
intervals calculated using a confidence level of 95%. Most query
response times are highly improved when using any of the filters,
though Qsome filter impact is lower because it returns more results
as shown in Fig. 3. Noteworthy, actual filtering time does not affect
the overall OWL-S query response time, because our proposed
SPARQL queries can be executed in polynomial time by SPARQL
implementations [9].

Experimental results show that, on average, response time of
OWLS-M0 is 44.7 times faster if applying the Qall filter, and about
9 times faster if the Qsome filter is the applied one. OWLS-MX3 (M3)
performance is similarly improved (44.3 times faster with Qall and
10.6 times faster with Qsome). Even though the confidence interval
in Qsome cases is large, in the worst case scenario, the execution is
at least 6.1 times faster when using OWLS-M0 matchmaker, and 7
times faster for OWLS-MX3 (M3).

Despite its high time performance, Qall filtering shows worse
performance in terms of average precision than the rest of the
evaluated alternatives, providing an average value of about 31%. In
turn, Qsome shows a better average precision on all the evaluation
tests than Qall. Thus, for logic-based OWLS-M0 variant, Qsome
filtering presents an improvement of about 19% on precision with
respect to the execution of OWLS-M0 with no preprocessing. For
the OWLS-MX3 hybrid variant, average precision only drops by
11%, though response time is considerably faster. Note that average
precision measures have a strong dependency on the concrete
query and services registered in the repository.

Response time improvements are correlated to the degree of
filtering each filter is able to provide. Fig. 3 presents a logari-
thmically-scaled box plot that analyzes the proportion of services
returned for the 29 queries from OWLS-TC with respect to the initial repository of 1007 services. In general, Qall filter returns a very
low number of services (most queries returning between 0.4% and
1.29% of the original repository), greatly improving query response
time as discussed before. On the other hand, Qsome filter results vary
between a bigger range, with a median value of 7.05% of the original repository, so the corresponding query response time for each

Fig. 3. Returned results with respect to the original repository size.

Fig. 4. Memory consumption statistics when filtering OWLS-MX3 (M3).

matchmaker is slightly slower when using a Qsome filter than when
using Qall. In particular, some OWLS-TC queries present a lower filtering degree when using Qsome, causing a noticeable variation on
the response time that explains the larger Qsome confidence interval shown in Table 1. Additionally, the discovery process presents
less initialization time because the number of services to be loaded
by matchmakers is significantly low, especially when the Qall filter
is applied.

Furthermore, Fig. 4 presents the performance gain in terms
of memory consumption, only showcasing samples from the
execution of OWLS-MX3 (M3) variant for the sake of clarity.
Results show that filtering the repository leads to a lower memory
usage, because the matchmaker needs to access less resources.
On average, OWLS-MX3 (M3) needs 1.5 times less memory if
Qsome filter is applied, and 2.8 times less if filtering with Qall. In
conclusion, the use of our proposed filters substantially improves
the overall performance of OWLS-MX matchmaker hybrid variants,
both in terms of response time and memory consumption, though
the impact on precision, recall and fallout has to be evaluated.

In order to analyze the penalty on precision and recall, Fig. 5
compares the macro-averaged precision of the two discussed
OWLS-MX variants when different filters are applied (i.e. using Qall,
Qsome, or no filter, respectively). It shows that when prefiltering
the repository using Qall, both OWLS-MX variants behave similarly.
Precision in this case drops at a high pace as the recall level in-
creases, performing much worse than the rest of the combinations,
though at the highest recall levels Qall filtering slightly improves
precision over OWLS-M0 (Fig. 5(a)) without filtering. The low number of results obtained when filtering repositories using Qall query
is the cause for this low precision.

However, Qsome filtering performs reasonably well, with a loss
in precision of at most 29% with respect to the precision obtained
with OWLS-MX3 (M3) variant at high recall levels, as shown
in Fig. 5(b). Interestingly, the evaluation shows that applying
Qsome filtering to OWLS-M0 variant improves the precision of

J.M. Garcia et al. / Web Semantics: Science, Services and Agents on the World Wide Web 17 (2012) 1224

Fig. 5. Recall-Precision effect when filtering OWLS-MX variants.

Fig. 6. RecallFallout effect when filtering OWLS-MX variants.

the answered set (up to 38% of difference), especially with recall
levels over 50%. Thus, the more accurate results obtained by Qsome
filtering help purely logic-based formalisms to find more relevant
services, while avoiding more false positives.

In turn, Fig. 6 represents false positives returned by each
compared variant as their fallout. Qsome filtering applied to OWLSM0 again improves the results when compared to the results of
OWLS-M0 without applying any filter, as shown in Fig. 6(a). In
the case of OWLS-MX3 (M3) (Fig. 6(b)) fallout difference when
applying Qsome filtering turns higher as recall level increases,
especially from 70% on. As with precision, prefiltering repositories
using the Qall query leads to much higher fallout levels, no matter
which OWLS-MX variant is used.

Obtained fallout performance results are a consequence of
the prototype implementation used to evaluate our proposal
performance using SME2, that requires each query result to be a
ranked list of all the services that were registered in the system.
Thus, our prototype also includes those services that do not pass
the corresponding filter at the end of the ranked list. Analyzing
filtering results of both queries, if only filtered services are taken
into account when evaluating the fallout for each case, fallout will
drop to less than 7% for Qsome, and 0.02% for the Qall filter. Thus, the
amount of false positives in a generic discovery scenario is reduced
by using our prefiltering proposal, in general.

5.3. Discussion

As a general conclusion from the performed evaluation, though
the more restrictive Qall filter may be better suited to filter because
it reduces the size of the service repository to a greater extent,
the Qsome filter turns to be more suitable in general because
the precision penalty is negligible while execution time is fairly
improved, outperforming service matchmaking without applying
any filter. In turn, the Qall filter scales well in every situation,
though the greater loss of precision has to be considered, so it may
only be applied in scenarios with really large repositories.

Both filters clearly improve the subsequent discovery stage by
reducing the search space for matchmaking algorithms. However,
there is a trade-off between precision, recall, and execution time
that should be evaluated, depending on the concrete scenario,
in order to choose the filter to use. Actually, the current trend
in the literature and real-world applications is to achieve better
performance and usability, by sacrificing precision, recall, or
both [4], so our proposal provides a feasible and efficient solution
in this direction.

The main feature of using our proposed filters is that not only
total execution time is very low, but actual filtering is efficiently
executed, providing a high scalability. Furthermore, our solution
also reduces the time needed for registering services for the

(a) OWLS-M0.(b) OWLS-MX3 (M3).(a) OWLS-M0.(b) OWLS-MX3 (M3).J.M. Garcia et al. / Web Semantics: Science, Services and Agents on the World Wide Web 17 (2012) 1224

matchmaking process, because the filter execution minimizes the
number of candidate services. Consequently, a hybrid architecture
can be applied, where the Qall filter is executed in the first
place. If after performing service matchmaking, the obtained
results did not present sufficient quality, the Qsome filter could
be used in place, executing again the matchmaking process. Note
that even in the worst case, i.e. applying both filters and the
corresponding matchmaking for each filtered repository, the total
query execution time is 7.5 times faster than the OWLS-M0
matchmaking process for the whole service repository, and 8.6
times faster than OWLS-MX3 (M3). This approach is similar to the
Best-Matches-Only solution proposed in [38], where if the most
accurate results are found (i.e. Qall returns good enough results),
they are used, but in other case fairly appropriate results (i.e.
results from Qsome) may also be useful.

Additionally, another mixed approach may be taken, where
both filters are jointly used before discovery and ranking processes
take part. Thus, Qall may be used to filter services that refer to
concepts from the hard requirements of the user request, i.e. terms
that have to be fulfilled in order to consider the corresponding
service as a candidate. Then, the Qsome filter can be applied to obtain
services that refer to some of the concepts used in the preferences,
i.e. terms that state how candidate services should be ranked after
discovery. Consequently, both filters can be integrated into one
that take into consideration the differences between requirements
and preferences [23].

Concerning the user requests applied in our evaluation, OWLSTC v3 only provides information about inputs and outputs. How-
ever, an OWL-S user request may also contain preconditions,
results, functional classification, and non-functional properties, in
general. Our proposal can be seamlessly applied to these different
terms of an OWL-S profile description, or in general to any SWS
user request, because they also refer to concepts from domain on-
tologies. For instance, conditional expressions can be simply analyzed in order to obtain which concepts appear inside them. An
early prototype on filtering WSMO services described in [10] is able
to obtain those referred concepts from conditions and rules described within a WSMO capability. The evaluation of that approach
presents similar results as the ones presented in this article, with
respect to precision and improved performance of discovery when
applying our proposed filters.

Finally, although the evaluation of our proposal has been
carried out using OWLS-MX variants as the underlying service
matchmaker, the prototype implementation can be easily adapted
to any matchmaker that implements SME2 interfaces. In the 4th
International Semantic Service Selection (S3) Contest in 2010 we
presented an evolution of the prototype implementation that
allows to change the underlying service matchmaker.8 EMMA
 an Enhanced MatchMaking Add-on  was implemented as a
configurable OWL-S matchmaking plugin compatible with SME2
2.1.1. Although EMMA offers a similar precision as the prototype
evaluated in this article, average query response time is worse
than the prototype, because of the way SME2 plugins register the
available services. This issue is identified in the S3 Contest 2010
report, so the next version of the SME2 application will allow the
use of pre-filtering techniques, such as our proposed solution.

6. Related work

In the following, we discuss proposals related with our
work, analyzing their relationship with our solution. Firstly, we
describe approaches that use Semantic Web query languages

8 http://www-ags.dfki.uni-sb.de/~klusch/s3/s3c-2010-summary-report-v2.pdf.

Table 2
Related work analysis.

Proposal
Lamparter et al. [39]
Iqbal et al. [40]
Sbodio et al. [41]
Siberski et al. [42]
Pedrinaci et al. [32]
Chabeb et al. [33]
Norton et al. [34]
Agarwal et al. [6]
Stollberg et al. [5]
Klusch et al. [7]
Kiefer et al. [43]
Carenini et al. [44]
Our proposal

Automation


Applicability


Integrability


to perform discovery and ranking. Then, we discuss some SWS
ontology integration proposals that our proposal can be applied to,
providing a higher interoperability. Finally, we analyze proposals
that offer solutions to improve discovery processes.

We have focused our analysis on three key aspects to compare
related work with our proposed filtering solution, namely: (1) if
discovery can be automatically optimized by using the analyzed
approach, (2) if it can be applied to any SWS framework, and (3) to
what extent each proposal can be integrated with other discovery
approaches in order to further optimize their performance. Table 2
sums up our comparison results, showing wether the discussed
proposals provide full (), partial (), or no () support to the
analyzed aspects.

There exist several proposals that use a Semantic Web query
language to perform discovery and ranking of services [45], though
they do not use queries explicitly to filter repositories. They choose
SPARQL as their base language, enabling their applicability to any
SWS framework, though they add some extensions in order to fully
support these tasks. The analyzed proposals provide some optimizations to their algorithms, though they are not fully automa-
tized. Additionally, their optimized discovery approaches cannot
be integrated with other solutions. Thus, Lamparter et al. [39] provide an ontology to represent service offers and requests that conforms the foundations for a discovery and selection process, which
is performed using rules in SWRL [46] and SPARQL queries. These
queries include predicates that have to be evaluated at run-time,
so they include an extension to SPARQL that is implemented using different proposed algorithms. Thus, a query for a user request
is provided, though this query depends on rules that change the
matchmaking policy, allowing some ad hoc optimizations.

Another discovery approach that uses SPARQL to actually perform semantic service discovery is proposed by Iqbal et al. in [40].
In this case, authors embed semantic information about services
using SAWSDL. Thus, they define pre- and post-conditions of services using SPARQL CONSTRUCT queries so that depending on
each service functionality, they add corresponding RDF tuples representing that functionality to the knowledge base. Then, their
discovery algorithm use an ASK query to check whether a service
fulfills a user request or not, returning the results. In this case, authors use standard-only SPARQL queries to perform discovery, and
their service discovery algorithm can progressively relax the conditions from the user request in case no results are returned in the
first place, as in our hybrid approach discussed in Section 5.3.

Sbodio et al. also introduce SPARQL queries to describe OWL-S
service pre and post-conditions, and user requests, providing
a matchmaker implementation based on agents called SPARQLent [41]. They discuss a complete discovery solution that uses
SPARQL queries to modify and ask the agents knowledge base,
evaluating their proposal against OWLS-MX using SME2, as in our

J.M. Garcia et al. / Web Semantics: Science, Services and Agents on the World Wide Web 17 (2012) 1224

work. Although they provide some optimizations to their discovery
algorithm, our proposal could be also applied to further improve
their agent performance, by preventing it to load the complete set
of available services on the repository.

Finally, there is another approach, more related to ranking,
presented in [42], where Siberski et al. propose an extension
to SPARQL so that preferences are described directly using the
query language, without basing on existing preferences and nonfunctional properties ontologies, as in other semantic ranking
approaches [23,25,31]. They provide a PREFERRING clause that
states preferences among values of variables, similar to FILTER
expressions. However, this approach does not have the flexibility
and reasoning facilities that provides a solution based on an
external ontology, and it uses non-standard SPARQL extensions
without providing an implementation.

Klusch et al. take a different approach in OWLS-MX [7], where
they present a hybrid matchmaker that combines information
retrieval techniques, such as syntactic similarity, with classical
DL-based discovery, in order to improve OWL-S service match-
making. Their comprehensive evaluation proves that hybrid approaches present a better performance than classical ones. Our
proposal has been applied to their proposed OWLS-MX variants,
further improving performance results, especially on logic-based
ones as discussed in Section 5. Moreover, similar solutions have
been also proposed by the authors for WSMO [50] and SAWSDL
[51] service matchmaking.

Kiefer et al. present in [43] another hybrid matchmaker called
iMatcher, which uses information retrieval techniques to improve
the discovery process. In this proposal, authors use a SPARQL
extension (iSPARQL [17]) that enables the introduction of similarity operators into query elements. Thus, different similarity
strategies are combined with logic-based discovery in order to improve precision and recall of the matchmaking process. Addition-
ally, machine-learning can also be applied to automatically choose
the most appropriate strategy to be included in the hybrid match-
making, for each case.

Finally, Carenini et al. propose a customizable hybrid architecture for SWS discovery and ranking named GLUE2 [44]. GLUE2 offers a set of specialized discovery components, such as functional
discovery, dynamic discovery, non-functional discovery, and rank-
ing, among other additional components [52]. Based on WSMO,
GLUE2 enables the configuration of the discovery workflow on a
case by case basis. Thus, as with other hybrid approaches such
as [30], our proposed filtering stage can be integrated with GLUE2
as an additional component so that it can be included in any hybrid
discovery workflow.

Note that most proposed discovery optimization proposals are
coupled with a concrete SWS framework and a corresponding
discovery mechanism, as shown in Table 2. However, we designed
our filtering proposal to allow its application to any SWS definition
framework and available discovery mechanisms, so it can even
be applied on top of any of the discussed proposals that already
improve service discovery process, as our experimental evaluation
shows in Section 5.

7. Conclusions

Although Semantic Web query languages are not widely used
for SWS discovery and ranking, they can certainly play a role in
these scenarios. As discussed in this paper, some authors extend
the SPARQL query language to directly support these stages, but
our proposal sticks to the recommendation at the time of writing
(1.0), providing two different filter queries that may be used before
actual discovery process in order to reduce the set of available
services from the initial repository. Consequently, the reduced
search space further improves scalability and performance in
discovery and ranking stages, decreasing the total execution time
and memory consumption of these processes, with a contained
penalty on precision, recall and fallout.

In this work, we have run comprehensive evaluation tests, analyzing the actual improvement. The conclusions obtained are
mainly that our proposal effectively reduces the search space,
while it conforms a generic solution, adaptable to any SWS framework that a potential user may want to use. Particularly, we discuss
an application to OWL-S-based services in order to test the implemented prototype using the OWLS-TC test collection, though we
also introduce additional applications to other frameworks.

Our proposal of including a (possibly multiple) filtering stage
before the discovery and ranking processes has several additional
benefits, summarized in the following:
 Proposed filters are generic, so they can be used no matter what
kind of user request and service descriptions are defined for

Concerning the integration of SWS frameworks, there are a
number of proposals in the literature that address this issue
to tackle applicability and integrability of different discovery
solutions. However, they do not provide facilities to automatically
optimize discovery mechanisms. Pedrinaci et al. present a service
repository called iServe that exposes service descriptions as linked
data in terms of a Minimal Service Model (MSM) [32]. This
model serves the purpose of an ontology of integration that
simplifies SWS frameworks, integrating not only OWL-S, WSMO,
SAWSDL and WSMO-Lite services, but also MicroWSMO [47] or
SA-REST [48] descriptions of Web APIs. Our proposal can be also
applied to MSM so that our filters can be applied to services
registered in iServe, that provides a SPARQL endpoint that can be
used to retrieve descriptions for a subsequent discovery.

Chabeb et al. describe another ontology of integration in [33].
They discuss a systematic approach to generate mappings between
OWL-S, WSMO and plain WSDL services, matching concepts from
the different SWS ontologies using similarity techniques that
validate the inferred correspondences. Their resulting ontology
merges concepts from different SWS frameworks, as opposed to
MSM, that only captures part of those SWS ontologies, offering a
more concise approach. Our proposed filters can also be applied
to this merged ontology, providing a global-as-view approach to
query OWL-S, WSMO and WSDL services [49].

Norton et al. present a similar proposal in [34], where the authors also take a union approach to integrate OWL-S, WSMO,
and WSMO-Lite descriptions. They present several SPARQL CONSTRUCT queries that transform SWS descriptions to and from the
Semantic SOA Reference Ontology, a standard proposed by OASIS.
Applicability of our proposal can be also achieved by implementing
our filters using this reference ontology, and then using the Norton
et al. approach to project SWS descriptions into the model, allowing our proposed queries to be applied to them.

Concerning the need for an improved discovery process which
tackles scalability issues, Agarwal et al. discuss a hybrid approach
that use different discovery mechanisms together, in order to
improve discovery performance [6]. They also propose a simple
filtering stage based on an efficient classification-based discovery.
However, this filter rely on a less expressive user request. Our
proposal may also be applied to the authors hybrid approach in
order to further improve discovery but using a more expressive
model to describe user requests [23].

In order to improve discovery engines, Stollberg et al. provides
a caching mechanism that reduces the search space and minimizes
matchmaking operations [5]. The proposed cache uses a graph that
stores relationships between user requests described as WSMO
goal templates, and their related services. Thus, goal instances are
compared with cached templates in terms of semantic similarity,
and if there is a match, only the related services stored in the
graph are used for the subsequent discovery. This proposal can be
complemented by using our filters when creating the cache graph.

[12] M. Sintek, S. Decker, Triplea query, inference, and transformation language for the Semantic Web, in: I. Horrocks, J. Hendler (Eds.), The Semantic
WebISWC 2002, in: LNCS, vol. 2342, Springer, 2002, pp. 364378.

[13] E. Sirin, B. Parsia, SPARQL-DL: SPARQL query for OWL-DL, in: C. Golbreich, A.
Kalyanpur, B. Parsia (Eds.), OWLED, vol. 258, CEUR Workshop Proceedings,
2007.

[14] F. Manola, E. Miller, RDF primer, Recommendation, W3C, 2004.
[15] D.L. McGuinness, F. van Harmelen, OWL web ontology language overview,

Recommendation, W3C, Feb. 2004.

[16] D. Beckett, T. Berners-Lee, Turtleterse rdf triple language, Team submission,

each concrete scenario. Corresponding SPARQL queries can be
generated automatically from a given user request.
 Our proposal does not distinguish between types of concepts,
i.e. both functional and non-functional concepts can be used to
filter the repository. In consequence, concepts being used for
both discovery and ranking stages can be considered.
 Filters can be applied to any SWS framework because they are
based only on domain concepts referred by service descriptions
and user requests.
 Our filtering stage can be applied to improve any currently
available matchmaking implementation. The actual improvement on the overall discovery performance depends on the
nature of the matchmaker, providing a high impact on performance with DL-based matchmakers, and a relative impact on
hybrid approaches.
 Our solution is based on the current standard query language for
the Semantic Web, i.e. SPARQL 1.0. Nevertheless, our proposed
queries do not use any extension to the standard, so they are
compatible with most SPARQL implementations.
In conclusion, our proposal follows the current research trend
on developing lightweight, scalable applications and extensions
that effectively enable the adoption of Semantic Web technologies,
by improving current discovery mechanisms in terms of scalability
and performance, while offering a contained penalty on precision
with respect to classical, heavyweight approaches to SWS match-
making.

Acknowledgments

This work has been partially supported by the European
Commission (FEDER) and Spanish Government under CICYT
project SETI (TIN2009-07366), by the Andalusian Government
under projects ISABEL (TIC-2533) and THEOS (TIC-5906), by the
EU FP7 IST project 27867 SOA4All, and by the EC FP7 Network of
Excellence 215483 S-CUBE.

The authors would like to thank the reviewers for their invaluable opinions and recommendations that improved this work
substantially; Carlos Pedrinaci and Marco Luca Sbodio for their
insightful comments and suggestions on early versions; the S3
Contest organization for their evaluation tools and support; and
Adela del-Rio-Ortega and Carlos Rivero for their useful technical
support and reviews.
