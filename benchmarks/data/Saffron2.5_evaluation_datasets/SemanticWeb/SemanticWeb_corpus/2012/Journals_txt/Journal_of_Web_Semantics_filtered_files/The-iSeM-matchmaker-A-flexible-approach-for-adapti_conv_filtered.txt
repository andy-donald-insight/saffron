Web Semantics: Science, Services and Agents on the World Wide Web 15 (2012) 114

Contents lists available at SciVerse ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

journal homepage: www.elsevier.com/locate/websem

The iSeM matchmaker: A flexible approach for adaptive hybrid semantic service
selection
Matthias Klusch, Patrick Kapahnke

German Research Center for Artificial Intelligence (DFKI), Saarbruecken, Stuhlsatzenhausweg 3, Germany

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 27 June 2011
Received in revised form
20 June 2012
Accepted 9 July 2012
Available online 24 July 2012

Keywords:
Semantic Web
Semantic service selection
Adaptive matchmaking

We present iSeM (intelligent Service Matchmaker), a precise hybrid and adaptive matchmaker for
semantic Web services, which exploits functional service descriptions in terms of logical signature
annotations as well as specifications of preconditions and effects. In particular, besides well-known
strict logical matching filters and non-logic-based textual and structural signature matching, it adopts
approximated reasoning based on logical concept abduction and contraction for the description logic
subset SH with information-theoretic valuation for matching inputs and outputs. In addition,
it
uses a stateless logical specification matching approach, which applies the incomplete but decidable
-subsumption algorithm for preconditions and effects. The optimal aggregation strategy of all those
aspects is learned off-line by means of a binary SVM-based service relevance classifier in combination
with evidential coherence-based pruning to improve ranking precision with respect to false classification
of any such variant on its own. We demonstrate the additional benefit of the presented approximation and
the adaptive hybrid combination by example and by presenting an experimental performance analysis.
 2012 Elsevier B.V. All rights reserved.

1. Introduction

Semantic service selection is commonly considered key to the
discovery of relevant services in the semantic Web, and there
are already quite a few matchmakers available for this purpose
as highlighted for example in the summary given in [1] or the
annual international Semantic Service Selection (S3) contest.1 In this
paper, we present the first adaptive semantic service IOPE (inputs,
outputs, preconditions and effects) matchmaker.2 In essence,
its innovative features are (a) approximated logical signature
(IO) matching based on non-monotonic concept abduction and
contraction in the description logic subset SH3 together with
information-theoretic similarity and evidential coherence-based
valuation of the result to avoid strict logical false negatives, (b)
stateless strict logical specification (PE) plug-in matching to avoid
failures of signature matching only, and (c) SVM (support vector
machine)-based semantic relevance learning adopted from [3] but
extended to full functional service profile (IOPE) matching and use
of approximated IO matching results to prune the feature space for
precision. Performance evaluation results particularly indicate that

 Corresponding author. Tel.: +49 681 85775 5011; fax: +49 681 857 75 2235.

E-mail addresses: klusch@dfki.de (M. Klusch), patrick.kapahnke@dfki.de

(P. Kapahnke).
1 http://www-ags.dfki.uni-sb.de/~klusch/s3/.
2 This article is a revised and extended version of [2].
3 http://www.cs.man.ac.uk/~ezolin/dl/.

1570-8268/$  see front matter  2012 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2012.07.003

this kind of approximated logical matching performs close to its
logical and non-logical counterparts (text and structural matching)
and significantly improves ranking precision in adaptive hybrid
combination with those.

The remainder of the article is structured as follows. We
motivate our matchmaker iSeM in Section 2 and give an overview
of our approach in Section 3. A detailed description of its signature
matching filters with focus on approximated logical matching
is given in Section 3.1, while Section 3.2 discusses its stateless,
logical specification matching filter. Section 3.3 describes the SVMbased service relevance learning for selection, which is followed
by implementation details including an introduction to the S2M2
framework for semantic matchmaker development in Section 4.
Performance evaluation and result discussion are provided in
Section 5, after which we comment on related work in Section 6.
Finally, we conclude in Section 7.

2. Motivation

The specific problems of semantic service selection the
matchmaker iSeM has been particularly designed to cope with
are motivated by the following service example, which is used
throughout the paper.

Example 1. Consider the semantic profiles of service request R and
offer S in Fig. 1, taken from the standard test collection OWLS-TC4
according to which S is relevant to R.

M. Klusch, P. Kapahnke / Web Semantics: Science, Services and Agents on the World Wide Web 15 (2012) 114

Fig. 1. Service request (book purchasing) and relevant service offer (article purchasing).

The desired service R is supposed to purchase a book for a
given person by debiting his own debit account, shipping the book
to him and eventually acknowledging the completed deal. The
e-shopping service S, like amazon.com, offers arbitrary articles
including books that are requested by some customer whose own
credit card account gets respectively charged while sending an
invoice for and pricing information about the deal. Both semantic
service descriptions are written in OWL-S with semantic signature
concept definitions in description logic OWL-DL and their logical
preconditions and effects in SWRL. In the following, we assume
the matchmaker to have an appropriate shared ontology and a
service registry available over which semantic service selection is
performed.

False negatives of strict logical signature matching. The majority of
semantic service matchmakers perform logical signature matching
(see [1] and S3). One prominent set of strict logical matching
filters for this purpose is provided below [4,5]. Each of these
filters requires (a) each service input concept to be more
generic than or equal to those provided in the request and
(b) the complete requested output to be covered by that of
the service in terms of different types of logical subsumption
relations.

Definition 1 (Strict Logical Signature Matching). Let S, R be the
semantic service offer and request and Sin, Sout , Rin, Rout
the
multisets of input and output concepts of the semantic signatures
of S and R defined in a shared OWL ontology O. The logical filter
definitions used in iSeM are inspired by OWLS-MX3 [3] but are
more strict with respect to the mapping of matching request and
offer parameters. While each element of Rin (Sout) could have more
than one matching part in Sin (Rout) in OWLS-MX3, iSeM requires
strictly injective concept assignments for logical matching filters.
This refinement was based on previous observations regarding
cases of false positives in OWLS-MX3 due to this characteristic.
To accomplish this, BPG( C,  D) is defined as the set of concept
assignments (C, D) with C   C and D   D that form an injective
mapping as a valid solution of bipartite graph matching on a graph
with  C and  D as nodes and weighted edges between them. The
weights v between concepts C and D indicate whether C  D
holds: v = 1 iff C  D else v = 0. That is, BPG( C,  D) is

(Rout , Sout ) =   (IS , IR)  BPG1

the mapping that maximizes the sum of binary weights v for the
given logical relation type. For the definition of filters analogous
to OWLS-MX3, BPGX ( C,  D) with X  {,1,1} are introduced,
with 1 denoting direct parent/child relations in a subsumption
graph. Moreover, if no assignment is possible, i.e.| D| < | C|, it holds
that BPGX ( C,  D) = . The degree MatchIOLogic (R, S) of strict logical
signature matching is then finally defined as follows:
MatchIOLogic (R, S){Exact, Plug-in, Subsumes, Subsumed-by, LFail}
with
Exact: BPG(Sin, Rin) =   (IS , IR)  BPG(Sin, Rin) : IS  IR
BPG(Rout , Sout ) =   (OR, OS )  BPG(Rout , Sout ) : OR  OS.
Plug-in: BPG(Sin, Rin) =   (IS , IR)  BPG(Sin, Rin) : IS  IR
BPG1
(Rout , Sout ) : OR 1 OS.
Subsumes: BPG(Sin, Rin) =   (IS , IR)  BPG(Sin, Rin) : IS  IR
BPG(Rout , Sout ) =   (IS , IR)  BPG(Rout , Sout ) : OR  OS.
=   (IS , IR)  BPG(Sin,
Subsumed-by: BPG(Sin, Rin)
Rin) : IS  IR
(Rout , Sout ) : OR 1 OS.
BPG1
LFail: None of the above logical filter constraints are satisfied. 
Fig. 2 shows two examples of the application of BPG: on the
left hand side, the algorithm is able to find an assignment for each
parameter in Rout for which the required subsumption relation
holds; the assignment on the right is (one of) the best possible
solutions but does not satisfy the requirement OR,2  OS,1 (i.e. v =
0), which causes the filter to fail.
Applying these strict logical matching filters to the running example introduced above produces a logical fail (LFail), hence a false
negative. The reasons are that (a) the inputs book and article are not
strictly logically disjoint siblings in the ontology, that is (Book 
Article ), and (b) the inputs debit accountand credit card are
strictly logically disjoint, that is (DebitAccount  CreditCard  ).
Such cases of logical signature mismatches may appear quite
often, in fact, applying the above filters to the de facto standard
collection OWLS-TC4 yields a relatively high number of strict
logical false negatives for each request in the order of 45% of the
size of its relevance set in average. As shown, for example, in [3,5,6]
and the contest S3, some hybrid combination of strict logical with

(Rout , Sout ) =   (IS , IR)  BPG1

Fig. 2. BPG for output part of Subsumes filter, positive and (partially) negative example.

non-logic-based approximated signature matching methods may
avoid failures of strict logical signature matching filters defined
above in practice.4 But how can logical matching itself be improved
by what kind of complementary approximation (cf. Section 3.1),
and how well does this perform compared to and in combination
with its non-logic-based counterparts in practice (cf. Section 5.1)?
Failures of signature matching only. It is well known that matching
of semantic signatures only may fail in many cases, since they
do not capture the functional behavior commonly encoded in
logical service preconditions and effects (PE). There are different
approaches to logical PE-matching [1]but which one can most
effectively be used in a third-party matchmaker that usually has
no access to concept instances describing the states of service
providers and requesters (cf. Section 3.2)?
Best combination of semantic matching filters. How to best combine
different kinds of semantic service matching filters in terms of
precision? One option proposed, for example, in [7,3,6] is to let the
matchmaker learn the optimal aggregation of different matching
results for its semantic relevance decisionrather than to put the
burden of finding and hard-coding the solution by hand on the
developer. Though this turned out to be quite successful in the S3
contest restricted to semantic signatures, how can approximated
logical matching be used to improve the learning for better
precision of service selection (cf. Section 3.3)?

3. iSeM matchmaker: overview

Before delving into the technical details of the matchmaker

iSeM, we shall first provide an overview of its functionality.
Matchmaking algorithm in brief. For any given service request R
and service offers S  SR described in OWL-S or SAWSDL, with
SR being the service registry of iSeM, the matchmaker returns a
ranked set of relevant services as its answer set to the user. For
this purpose, it first learns the weighted aggregation of different
kinds of service IOPE matching results off line over a given training
set of positive and negative samples by means of SVM-based
binary relevance classification with ranking. These different kinds
of matching approaches include strict and approximated logical,
text similarity-based and structural semantic matching of service
signatures (IO) in SH,5 as well as stateless, logical plug-in matching
of service preconditions and effects (PE) in SWRL, if they exist. Once
learning has been done, the same filters are used by the learned
relevance classifier for selecting relevant services for previously
unknown requests. iSeM may be classified as an adaptive, hybrid
semantic service IOPE matchmaker [1].
Hybrid signature (IO) matching. Logical signature matching of iSeM
comes in two complementary flavors: Strict logical matching

4 Avoidance and higher (lower) ranking of false negatives (positives) increases
average precision of ranked result lists.
5 Restriction to annotation in SH is due to respective limitation of the adopted
concept abduction reasoner [8]; its extension to SHOIN is ongoing.

and approximated logical matching. For every service pair (R, S)
for which strict logical signature matching MatchIOLogic(R, S) as
defined above (Section 2, Definition 1) fails, iSeM computes the
approximated logical matching degree MatchIOALogic(R, S) based
on approximated subsumption relations (C AC D) between I/O
concepts C, D via contraction and structured abduction together
with their information-theoretic valuation. This leads to two
hypotheses of approximated logical signature matching, that are
approximated logical plug-in (H1) and subsumed-by (H2), both
of which weighted by their averaged informative quality v 
[1, 1]. Eventually, the degree MatchIOALogic (R, S) = (H, v) of
approximated logical service signature matching is determined as
the hypothesis H with maximal valuation v. The approximated
logical matching results are used in the learning process over a
given training set of service pairs to prune the respective feature
space restricted to logic-based matching to compensate for strict
logical false negatives. In addition, iSeM performs non-logic-based
approximated matching, that are text and structural semantic
similarity-based signature matching for which purpose it applies
the respective filters of OWLS-MX3 [3] (cf. Section 3.1).
Logical specification (PE) matching. To cope with failures of signature matching only and to allow for third-party matchmaking
without having access to service concept instances, iSeM performs
stateless, logical plug-in matching MatchPE(S, R) of service preconditions and effects by means of approximated theorem proving,
that is theta-subsumption, of required logical PE-implications as
in LARKS [4] (cf. Section 3.2).
Learning of full service profile (IOPE) selection. To combine the results
of its different IOPE matching filters for optimal precise service
selection, iSeM performs binary SVM-based semantic relevance
learning off line over a given training set of positive and negative
samples (S, R) each of which is represented as a vector x in the 10dimensional feature space of different matching filters. This space
gets particularly pruned by exploiting the approximated logical
signature matching results to compensate for strict logical false
negatives. Once that has been done, the learned binary classifier
d with ranking r is applied by iSeM to any service pair (S, R) with
unknown request R to return the final result: MatchIOPE(S, R) =
(d, r) (cf. Sections 3.3 and 5.1).

3.1. Hybrid semantic signature matching

Semantic signature matching in iSeM is performed by means
of both logic-based and non-logic-based matching. While the
first type basically relies on strict logical (cf. Definition 1) and
approximated logical concept subsumptions (cf. Section 3.1.1),
the second exploits text and structural similarities of signature
concepts (cf. Section 3.1.2). Both kinds of approximated logical
and non-logic-based matching are performed by iSeM in particular to compensate for strict logical signature matching failures in due course of its relevance classification learning (cf.
Section 3.3).

M. Klusch, P. Kapahnke / Web Semantics: Science, Services and Agents on the World Wide Web 15 (2012) 114

3.1.1. Approximated logical matching

Inspired by Di Noia et al. [8], Colucci et al. [9] and Lin [10],
approximated logical signature matching of a given service
pair (S, R) relies on the combined use of logical contraction
and abduction of signature concepts for approximated concept
subsumption (cf. Definition 2) which is valuated in terms of
the information gain and loss induced by its construction (cf.
Definition 3). Eventually, we extend both means of approximation
and valuation on the concept level to its application on the
signature level (cf. Definition 4).

Definition 2 (Logical Concept Contraction and Abduction). Let
C, D be concepts of an ontology O in SH. The contraction of C
with respect to D is CCP(C, D) = (G, K ) with C  G  K and
K  D .6 The abducible concept K h is derived from concept K
through rewriting operations [8]:
K h = h0  rew(K ), rew(A) = A, rew(A) = A, rew(C1  C2) =
rew(C1)rew(C2), rew(RC) = R(hirew(C)) and rew(RC) =
R  (hi  rew(C)); where i is incremented per application of rew,
A is a primitive component (in the logical unfolding of K in O),
Ci are concepts in SH, and  H = (h0, . . . , hn) denotes variables
in the resulting concept structure, where additional definitions
are added for approximation. The Structural abduction of concept
K with respect to D is SAP(K , D) = H = (H0, . . . , Hn) with
[ H, H](K h)  D and [ H, H](K h) . The approximated concept
C := [ H, H](K h) of C with respect to D is constructed by applying
[ H, H] = {h0  H0, . . . , hn  Hn} to the abducible concept K h.
The approximated logical concept subsumption C AC D is defined
as follows: C AC D  C  D with (G, K ) = CCP(C, D), H =
SAP(K , D) and C = [ H, H](K h).

To avoid strict logical false negatives leading to lower average
precision,
iSeM assumes the user to be willing to give up
those parts of logical signature concept definitions that cause
strict
logical subsumption failures and keep the remaining
parts instead. The latter are used to compute approximated
concept subsumption relations and the respectively approximated
signature matching. A tableau algorithm for computing nearoptimal solutions to the problem is given by Di Noia et al. in [8].
Fig. 3 provides a schematical overview of the approximation
process: given the incompatible concept definitions C and D, the
contraction is computed to establish compatibility in terms of a
less specific definition K based on C (step 1). Based on this result,
structural abduction is applied to construct the approximation C,
for which concept subsumption C  D holds (step 2).
Example 2. Consider Example 1. The approximated logical subsumption between strict logically disjoint siblings DebitAccount,
CreditCard is computed as follows:
(G, K ) = CCP(DA, CC) = (allows  CreditP , MOE  issuedBy 
BankP ), i.e. the restriction of not allowing credit of the debit
account is given up, which establishes compatibility with the
CreditCard definition.
K h = h0ObjectPhasValue(h1ValueP )issuedBy(h2BankP ).
The abducible concept K h determines the positions for concept
refinement in the structure of the remaining concept definition K.
 H = (h0, h1, h2), H = SAP(DA, CC) = (allows  CreditP ,
, CompanyP ) then is the solution computed according to [8].
The approximated concept DebitAccount is then constructed using
the following mapping function: [ H, H] = {h0  allows 
CreditP , h1  , h2  CompanyP},

DA = [ H, H](K h) = allows Credit  MOE issuedBy (Bank
Company).
DA, CC and MOF are abbreviations for concept names DebitAccount,
CreditCard and MediumOfExchange respectively.
It holds that
DebitAccount  CreditCard, hence DebitAccount AC CreditCard.

It is worth mentioning that for the special case, where C 
D initially holds, the algorithm presented in [8] that is used
by iSeM yields a trivial solution, which later on causes the
overall approximate logic-based matching filter to be redundant
to strict logic-based matching in terms of (true or false) positive
classification, i.e. it can only be used to remedy strict logical
matching failures. This fact is formalized by the following lemma
and will be used in subsequent analysis of this behavior:

Lemma 1 (Trivial Approximated Concept Subsumption). Given two
concepts C and D in NNF and satisfiable in SH with C  D and a T-box
T  SH. The application of the tableaux-algorithm for approximated
concept subsumption given in [8] to the problem SAP(C, D) always
yields the trivial solution H = H0, . . . , Hn = , . . . ,.
Proof. SAP is applicable per Definition 2, since C  D implies
C  D . H = , . . . , is a solution for SAP(C, D), since
[ H, H](C h) = C for C in NNF. Thus, because of the original
assumption C  D, it holds that [ H, H](C h)  D and
[ H, H](C h) . A tableau  for the proposition T |= C  D is
already closed per definition. Algorithm 1 given in [8] then yields
the following substitution because of the conditional given in line
4:  = {h0  , . . . , hn  }. 

In order to rank the computed approximations, we valuate them
by means of their informative quality. Roughly, the informative
quality of approximated logical subsumption between signature
concepts C, D is the difference between the information gain
and loss induced by its construction. That is, the utility of the
respectively approximated concept C is the trade-off between its
information-theoretic similarity [10] with the original concept C
and the targeted one D. The similarity is based on the probabilistic
information content of concepts with respect to the frequency of
their occurrence in semantic service signatures.

Definition 3 (Informative Quality of Approximated Subsumption).
Let SR be the set of service offers registered at the matchmaker
(service registry), Sin, Sout the multi-sets of concepts used for
signature parameter annotation of service S, SAC(SR) the set of
all concepts used for annotating services in SR. We define the
informative quality v of approximated concept subsumption C AC D
(cf. Definition 2) as:
v(C, D) = siminf (C, D)  (1  siminf (C, C))
with the information-theoretic similarity of concepts C and D
proposed by Lin [10]:
siminf (C, D) = 2  IC(max dcs(C, D))/(IC(C) + IC(D)),
where max dcs(C, D) = argmaxcdcs(C,D){IC(c)} is the direct
common subsumer (dcs) of C and D in ontology O with maximum
information content IC(c). The information content of concept C 
SAC(SR) is IC(C) =  log P(C), else IC(C) := maxDSAC(SR){IC(D)}.
We define the probability of concept C being used for semantic
service annotation as the frequency of its occurrence in semantic
signatures of services in service registry SR:
|{D  Sin  Sout : D  C}|,
P(C) = 1

|IOSR| 

6 K (keep) denotes the compatible part of C with respect to D, while G (give
up) denotes the respectively incompatible part.

where IOSR is the multiset of all parameters used in SR. Please note
that we adapted the original notion introduced by Resnik [11] for

Fig. 3. Approximated logical concept subsumption. Arrows denote subsumption relations, dashed lines concept (in-)compatibility.

our approach based on description logics to account for implicit
subsumption relationships. The frequencies can be computed in
linear time given a fixed domain ontology, thus the information
content can be updated reasonably fast at runtime for non-static
sets of service offers SR. This also holds for the case of extended
domain ontologies (i.e. services that reference new concept
definitions are added to SR), since the inferred subsumption
relationships have to be computed anyway to perform logic-based
filtering operations. However, we assume a static SR for the rest of
the article since the provided experiments in Section 5.1 are based
on a static test collection. 

Example 3. For the running example introduced in Fig. 1, the
measured probabilities P(C) for each concept are annotated in
the subsumption hierarchy graph. These values are the basis for
computing the informative quality of DebitAccount AC CreditCard
from Example 2 in the following:
IC(DA) =  log P(DA) =  log 0.045  1.348 is the information
content of the original concept DebitAccount and IC(CC) =
 log P(CC) =  log 0.075  1.125 the information content
of target concept CreditCard accordingly. For the approximated
concept DebitAccount, it holds that IC(DA) =  log 0.035 
1.456+1.125 

1.456, since DA
0.872 is the information gain from using the approximated concept
1.456+1.348 
instead of the original one and siminf (DA, DA) = 21.348
0.962 the information loss of the approximation. The valuation
then is computed as follows: v(DA, CC) = 0.872  (1  0.962) =
0.834. 

 SAC(SR). siminf (DA, CC) =

For each service pair, depending on the computed type of their
approximated signature concept subsumption relations, one can
determine two hypotheses of approximated logical service signature matching: approximated logical plug-in and approximated
logical subsumed-by. For both, the maximal informative quality is
computed using bipartite concept graph matching.

Definition 4 (Approximated Logical Signature Match). Let S, R be
semantic service offer and request, Sin, Sout , Rin, Rout multisets of
( C,  D) the concept assignment
their signature concepts and BPGAC
via bipartite graph matching as in Definition 1 but with approximated subsumption AC and informative quality of edge weights
v(C, D) for C   C, D   D; BPGAC
( C,  D) analogously with edge
weights v(D, C).
Approximated logical plug-in matching hypothesis H1(R, S) holds

iff:
IS  Sin : IR  Rin : (IS , IR)  BPGAC
(Sin, Rin)
OR  Rout : OS  Sout : (OS , OR)  BPGAC
Approximated logical subsumed-by matching hypothesis H2(R, S)
holds iff:
IS  Sin : IR  Rin : (IS , IR)  BPGAC
(Sin, Rin)
OR  Rout : OS  Sout : (OS , OR)  BPGAC

(Sin, Rin).

(Sin, Rin).

2  |Sin| 

: {H1, H2}  [1, 1] of an approxiInformative quality val(S,R)
mated signature matching hypothesis is the average of informative

qualities of its respective approximated concept subsumptions:
val(S,R)(H1) = 1
2  |Rout| 
val(S,R)(H2) = 1
2  |Rout| 

(OS ,OR)BPGAC (Sout ,Rout )
2  |Sin| 

(IR,IS )BPGAC (Rin,Sin)

(IR,IS )BPGAC (Rin,Sin)


v(OS , OR).

v(IR, IS )

v(IR, IS )

(OS ,OR)BPGAC (Sout ,Rout )

v(OS , OR).

The approximated logical signature matching degree is the approximation hypothesis with maximum informative quality:
MatchIOALogic (S, R) := (H, v) with H = argmaxx{H1,H2}val(x)
and v = val(S,R)(H). Semantic relevance ranking of services S is
based on MatchIOALogic (S, R)[2]  [1, 1]. Binary relevance classification by approximated logical matching: MatchIOALogic (S, R) = 1
iff MatchIOALogic (S, R)[2]  0, else MatchIOALogic (R, S) = 0.

Example 4. Consider Examples 13. The approximated logical
signature match of S, R is computed as follows:
(Rin, Sin) = {(Book, Article), (DA, CC), (Person, Customer)}

is
the assignment based on concept approximation and
information-theoretic valuation for inputs and BPGAC
(Sout , Rout )
= {(Invoice, Ack)} the assignment for outputs accordingly, both
assuming approximated signature matching hypothesis H1. The informative quality valuation for H1 is val(S,R)(H1) = 1
23  (0.829 +
21  0.895 = 0.879. In this example, the same
0.834 + 0.927) + 1
valuation holds for H2, which can be easily seen considering the
fact that computation of valS,R(H1) and valS,R(H2) only differ regarding the outputs, for which only one assignment is possible
and concepts already subsume. The overall matching result then
is MatchIOALogic (S, R) := (H1, 0.851). 

Obviously,

the approximated logical matching relation
MatchIOALogic (R, S) always exists, and we will show in the follow-
ing, that its binary decision variant MatchIOALogic (R, S) is redundant to its logical counterpart MatchIOLogic (R, S) with respect to
positive service classification. That is, their true and false positives
are the same, but not vice versa. This can be easily seen by considering that strict logical positives already provide parameter assignments based on subsumption relations and approximation is
trivial in those cases (cf. Lemma 1).

Theorem 1 (Redundancy of Strict and Approximated Logical Signature Matching Positives). Given a service offer S and service request R
described in terms of sets of satisfiable input and output concepts Sin,

M. Klusch, P. Kapahnke / Web Semantics: Science, Services and Agents on the World Wide Web 15 (2012) 114

with
simstruct (A, B) = 1
|A|

simcsim(C, D) =

aA


el  eh  eh

eh + eh

1,

C = D
C = D,

Sout, Rin, Rout, it holds that:
MatchIOLogic (S, R) = LFail  MatchIOALogic (S, R) = 1.
In particular, it holds that all strict logical true positives are also
approximated logical true positives and all strict logical false positives
are also approximated logical false positives.
Proof. LM(R, S) holds iff one of the following four cases applies:
MatchIOLogic (R, S)  {Exact, Plug-in, Subsumes Subsumed-by}.
For the Subsumes case the following holds: There exists a solution
BPG(Sin, Rin) for which for every contained pair (IR, IS ) it holds
that IR  IS. CCP(IR, IS ) = , IR (since IR  IS ), SAP(IR, IS ) =
, . . . , (Lemma 1). Hence, for each pair (IR, IS ), the concept
R = [ H, H](K h) =
constructed for approximation is as follows: I
[ H,, . . . ,](Ih
R, IR) = 2  IC(IR) =
R ) = IR. Moreover, siminf (I
/(IC(IR)+IC(IR)) = 1. From this, one can clearly see that v(IR, IS ) 
0 for each such pair. The analogous series of explanations can be
applied for all output pairs (OS , OR). Therefore, val(S,R)(H1)  0
(every summand is 0), which implies MatchIOALogic (S, R) =
1 per last paragraph of Definition 4 (valuation for hypothesis
H = argmaxx{H1,H2}val(x) must be 0 because at least H1 
0). Cases MatchIOLogic (R, S) = Exact and MatchIOLogic (R, S) =
Plug-in are special cases (with more restricted operators  and
1 respectively) of what has just been shown and the applied
arguments also hold. For MatchIOLogic (R, S) = Subsumed-by,
argumentation is equivalent w.r.t. to inputs, for outputs it can
be easily shown analogously with approximation hypothesis H2
instead of H1. 

This fact is used in iSeM to restrict its computation of
approximated logical signature matches in the learning phase to
cases of strict logical false negatives only and use the evidential
coherence of the matching results to heuristically prune the feature
space for precision (cf. Section 3.3.2).

3.1.2. Text and structural signature matching

Non-logic-based approximated signature matching can be performed by means of text and structural similarity measurement.
For iSeM, we adopted those of the matchmaker OWLS-MX3, since
they have been experimentally shown to be most effective for this
purpose [3]. For text matching of signature concepts in the classical vector space model, their unfoldings in the shared ontology are
represented as weighted keyword vectors for token-based similarity measurement. Structural semantic similarity of concepts relies
on their relative positioning in the subsumption graph, in particular on the shortest path via their direct common subsumer and its
depth in the taxonomy [12].


Sin,

Definition 5 (Approximated Non-Logic-Based Signature Matching).

Let SR be the service registry of the matchmaker, I the text index


Sout,
of service signature concepts, O the shared ontology and
Rin,
Rout the TFIDF weighted keyword vector of the conjunction of
unfolded input or output concepts of S and R respectively. Text
similarity-based signature matching is the average of the respective
signature concept similarities:
MatchIOText (S, R) = 1
 (simtext (


with Tanimoto coefficient (alternatively Cosine similarity) simtext
C,

Structural semantic signature matching is the averaged maximal
structural similarity of their signature concepts:
MatchIOStruct (S, R) = 1
 (simstruct (Sin, Rin)

+ simstruct (Sout , Rout ))


Rin) + simtext (


D )  [0, 1].


Rout ))


Sout ,


Sin ,

max{simcsim(a, b) : b  B}  [0, 1],

and structural concept similarity adopted from [12]:

with l the shortest path via direct common subsumer between
given concepts and h its depth in O,  = 0.2 and  = 0.6 weighting
parameters manually adjusted to structural features of ontology O
based on results of [12].

Example 5. Applied to Example 1, we obtain a high score for
text-based signature matching MatchIOtext (S, R) = 0.71 which
correctly accounts for semantic relevance of S to R, and hence
avoids the strict logical false negative. The same holds for the
structural semantic matching MatchIOstruct (S, R) = 0.69. For
example, text and structural similarities of the strict logically
disjoint input concept siblings DebitAccount and CreditCard are
high (simtext (DA, CC) = 0.94, simcsim(DA, CC) = 0.63) which
indicates their semantic proximity. Please note, that we do not
apply a threshold value to determine relevance but perform
semantic relevance learning (cf. Section 3.3). However, matching
pairs tend to get higher results for MatchIOtext and MatchIOstruct
than irrelevant pairs.

While text matching of signatures may avoid strict logical
matching failures, structural semantic matching may also compensate for text matching failures, in particular when mere is-a ontologies with inclusion axioms only are used for semantic annotation
of service signatures. For reasons of space limitation, we refer to [3]
for more details and examples.

3.2. Stateless logical specification matching

As mentioned above, semantic signatures of services do not
cover functional service semantics usually encoded in terms
of
logical service preconditions and effects. This may cause
signature matching only to fail, for example if signatures are
equivalent for a book selling service offer and a book borrowing
request. Though semantic service descriptions rarely contain such
specifications in practice [13], we equipped the implemented
iSeM matchmaker with the most prominent PE-matching filter
adopted from software retrieval: logical specification plug-in
matching.

iff

|= (PR  PS )  (ES  ER).

Definition 6 (Stateless, Logical Specification Plug-in Matching). Let
(S, R) be services with preconditions (PR, PS) and effects (ER, ES)
defined in SWRL. Service S logically specification-plugin matches R:
MatchPE(S, R)
Stateless checking of MatchPE(S, R) in iSeM 1.0 is adopted from
LARKS [4]: Preconditions and effects specified as SWRL rules are
translated into PROLOG as in [14] and then used to compute the
required logical implications by means of -subsumption checking
stateless, that is without any instances (ABox), as given in [15]:
(pS  PS : pR  PR : pR  pS )  (PR  PS )
(eR  ER : eS  ES : eS  eR)  (ES  ER).
A clause C -subsumes D, written C  D,
iff there exists a
substitution  such that C  D holds; -subsumption is an
incomplete, decidable consequence relation [16].

Example 6. If applied to Example 1, this PE-matching filter
succeeds, and hence avoids the respective false negative of strict
logical signature matching only. Further, consider a service pair
(S, R) having the identical or strict logically equivalent semantic
signatures as (S, R) given in Example 1but with the requested
effect of R to only register a book at a given local index such
that service S is irrelevant to R: The false positive S of (strict or
approximated) logical signature matching only can be avoided by
an additional specification plug-in matching filter, which, in this
case, would correctly fail. 

3.3. Off-line service relevance learning

In order to find the best combination of its different matching
filters for most precise service selection, iSeM learns their optimal
weighted aggregation by using a support vector machine (SVM)
approach. To improve the overall ranking precision, the underlying
feature space is pruned by weighting the results of approximated
and strict logical signature matching based on evidential coherence
computations over the given training set.

3.3.1. Overview: learning and selection

The training set TS is a subset (5%) drawn uniformly at
random from the service test collection OWLS-TC4. It contains
user-rated service pairs (S, R) each of which is equipped with
a 10-dimensional matching feature vector xi for positive and/or
negative service relevance samples (xi, yi)  X  {1,1} in the
possibly non-linearly separable7 feature space X = {0, 1}5 
[1, 1]2  [0, 1]  [0, 1]  {0, 1}. The different matching results
for (S, R) are encoded as follows: x[1] x[5]  {0, 1}5 for
MatchIOLogic(R, S) in decreasing order; x[6] = val(S,R)(H1) and
x[7] = val(S,R)(H2)  [1, 1] for MatchIOALogic(R, S); x[8] 
[0, 1] for MatchIOText (R, S); x[9]  [0, 1] for MatchIOStruct (R, S);
and x[10]  {0, 1} for MatchPE(R, S). For example: x =
(0, 0, 0, 0, 1, 0.85, 0, 0.4, 0.6, 1) encodes a strict logical fail but
approximated logical plugin with informative quality of 0.85, text
(structural) match of 0.4 (0.6) and plugin specification match.

The SVM-based classification learning problem of iSeM then is
to find a separating hyperplane h in X such that for all samples
(x, y)  TS for (S, R) with minimal distances (these particular
samples are also called support vectors) to h these distances are
maximal. It is defined as follows:
wT w + C
minimize in w, b,  : 1

subject to 1  i  N : yi(wT (xi) + b)  1  i,
where w and b define the optimally separating hyperplane as the
set of points satisfying wT (x) + b = 0. Furthermore, w is the
origin of the feature space X. The error term CN
normal vector which specifies the orientation of the plane, b is
called bias and indicates the offset of the hyperplane from the
i=1 i is introduced
to allow for outliers in a non-linear separable training set, where
the error penalty parameter C must be specified beforehand.
The predefined function  maps features into a higher, possibly
infinitely dimensional space in which the SVM finds a hyperplane
that allows a classification of non-linear separable data (more
precise with respect to the original dimension of X).8

i  0,

i=1

i=1 yii(xi) is a linear combination of training
sample feature vectors the dual formulation of the SVM classifica-

Since w = N

7 E.g. the feature space for OWLS-TC4 is non-linearly separable.
8 The fraction 1
the classification result.

2 is introduced for computational reasons only, and does not affect

i=1

i=1

i,j=1

yiyjijK (xi, xj)  N

tion problem that is actually solved by OWLS-MX3 is as follows:
maximize in  : 1

yii = 0, 1  i  N : 0  i  C.

subject to
The kernel function K (xi, xj) = (xi)T (xj) implicitly defines  in
the scalar product, while the problem is solved by finding a set
of Lagrange multipliers i representing the hyperplane for which
= 0 are called support vectors (of the
training samples xi with i
hyperplane). As kernel, the RBF (Radial Basis Function) K (xi, xj) =
exixj2 is used as suggested in [17]. Unlike polynomial kernels,
it only introduces a single parameter  which keeps the complexity of model selection low. Besides, for specific parameter settings
it can behave like a linear or sigmoid kernel.


d(x) = N

The searching for an optimal SVM parameter setting (C,  )
with respect to average classification accuracy has been achieved
by means of grid search and sixfold cross-validation. Binary
classification of samples x
X for service pair (S, R)
with the above mentioned parameters is defined as follows:
i=1 yiiK (xi, x) + b with bias b satisfying the
KarushKuhnTucker condition (KKT) [18], such that S is classified
as relevant iff d(x) > 0. Please note, that w is not a direct output
of the dual optimization but computed using the objective value

i,j=1 yiyjijK (xi, xj) = 2  (o + N
o of the dual optimization and the coefficients i based on the
relation between the primary and dual problem: w2 = wT w =
i=1 i). Since we are not
only interested in binary classification but also want to compute
a service ranking, the distance of the sample to the hyperplane is
also computed: dist(x) = d(x)
|w| . The matching function then returns
a tuple of classification result and distance using the following
definition: MatchIOPE(S, R) = (d(x) > 0, dist(x)).

3.3.2. Evidential coherence-based feature space pruning

To improve the performance of the binary SVM-based relevance
classifier to be learned by iSeM, iSeM exploits information available from the given training set TS to prune the feature space X
based on the classification results of strict vs. approximated logical signature matching. Due to redundancy of both logical matching types for (true and false) positive classification (cf. Theorem 1),
it restricts the pruning of feature vectors x  X to cases of strict
logical matching failures (MatchIOALogic (R, S) = LFail). The respective set Ev = {(x, y) : x[5] = 1} of classification events is
partitioned with respect to binary classification results of approximated logical matching (MatchIOALogic (R, S)) for these cases as
follows:
E1 = {(x, y)  Ev : y = 1  (x[6] > 0  x[7] > 0)},
E2 = {(x, y)  Ev : y = 1  x[6]  0  x[7]  0},
E3 = {(x, y)  Ev : y = 1  x[6]  0  x[7]  0},
E4 = {(x, y)  Ev : y = 1  (x[6] > 0  x[7] > 0)}.
For example, E1 denotes all relevant samples (x, y)  Ev classified
correctly as (true) positives by MatchIOALogic while E2 contains
all irrelevant samples (x, y)  Ev classified correctly as (true)
negatives by MatchIOALogic. The set E3 contains wrong negative
classifications of approximated matching, hence is redundant to its
strict logical counterpart and deleted from the respectively pruned
feature space for learning. In contrast, E4 contains those cases,
where approximated logic-based matching itself classifies as false
positives contrary to strict logic-based matching.

M. Klusch, P. Kapahnke / Web Semantics: Science, Services and Agents on the World Wide Web 15 (2012) 114

x[6] := w1  x[6],
x[6] := 0,

Inspired by the work of Glass [19], the feature space X is pruned
further by modification of logical matching results of feature
vectors x  X of samples in E1, E2 or E4 based on evidential
coherence-based weighting of approximated matching results as
follows:
E1, x[6]  x[7]  x[5] := 0,
x[7] := 0,
E1, x[6] < x[7]  x[5] := 0,
x[7] := w2  x[7],
E2, x[6]  x[7]  x[6] := w3  x[6],
E2, x[6] < x[7]  x[6] := 0,
E4, x[6]  x[7]  x[6] := (1  w1)  x[6],
E4, x[6] < x[7]  x[6] := 0,
In the case of true positive approximated logical matching, the
encoded strict logical misclassification in x  X is displaced
(x[5] = 0); in any case, the better approximation (H1 or H2) is
weighted with the evidential coherence value (one of w1  w4) of
one of the following hypotheses (A1, A2) of relevance explanation:
(A1) MatchIOALogic is a correct explanation of semantic relevance
(avoids logical false negatives), and (A2) MatchIOALogic is a correct
explanation for semantic irrelevance (avoids introduction of false
positives). For events in E4, the coherence for the contrary of hypothesis A1 (MatchIOALogic is not a correct explanation of semantic
relevance) is used for weighting corresponding features to alleviate
support for false positives of approximate logic-based matching in
the aggregation strategy learning step.

x[7] := 0,
x[7] := w4  x[7],
x[7] := 0,
x[7] := (1  w2)  x[7].

1 , E+), w2 = Co(H+

1 , E) and w4 = Co(H

Which of both hypotheses of semantic relevance explanation
is best with respect to a given test collection? Following [19],
iSeM determines the quality of an explanation by measuring the
impact of evidence E on the probability of explanation H (with
coherence or confirmation measures) rather than measuring its
posterior probability with Bayes. In other words, it determines
the most plausible explanation H instead of the most probable
measured in terms of its coherence with evidence E over given
training set. While hypothesis A1 (A2) is represented by special
case set H+
(H
i ), the set E+ (E) provides cases of observed
evidence for relevance (irrelevance) in the test collection. The
coherence overlap measure Co(H, E) = P(HE)
P(HE) performed best
in practice [19], and is used by iSeM to compute the weights
of approximated logical signature matching results for respective
feature space pruning: w1 = Co(H+
2 , E+),
w3 = Co(H
2 , E).
Example 7. Consider training set TS with |Ev| = 20, |E1| = 10
and |E4| = 1. E1 contains eight events (cases) of approximated
plug-in matching (x[6]  x[7]), the only event in E4 is also
an approximated plug-in match. Required posterior probabilities
for w1 = Co(H+
1 ) =
1 |E+) =
|{xE1E4:x[6]x[7]}|

= 8
|{xE1:x[6]x[7]}|
. The resulting evidential coherence-based
1 , E+) =
weight of approximated logical matching is: Co(H+
 0.5333. That is, the coherence value of
P(E+)+P(H+
the hypothesis of approximation H1 (represented by feature x[6])
being a correct explanation for semantic relevance (A1) is w1 =
0.5333. Analogously, to compute the weights w2, w3 and w4, the
following posterior probabilities can be computed by observing
1 ) = |{xE2E3:x[6]x[7]}|
the set of all relevant events Ev: P(H

|Ev|
, P(E) =
P(H+

1 , E+) are computed as follows: P(H+
= 9

|Ev|
|E1E3|
P(E+)P(H+

, P(E+) = |E1E3|

2 ) = |{xE2E3:x[6]<x[7]}|

2 ) = |{xE1E4:x[6]<x[7]}|

|Ev| = 14

1 |E+)
1 )P(H+

, P(H+

, P(H

1 E+)

|Ev|

|Ev|

|E2E4|

, P(H+

1 |E) = |{xE2:x[6]x[7]}|

2 |E+) = |{xE1:x[6]<x[7]}|
|E2E4|
, P(H

|Ev|
|E2E4|
2 |E) = |{xE2:x[6]<x[7]}|
P(H
. To compute the remaining coherence
values, the probabilities have to be inserted into the following
P(E+)P(H+
2 |E+)
2 E+) , w3 =
formulas: w2 =
1 E) ,
2 )P(H+
w4 =
2 E) . 
P(E)+P(H

P(E+)+P(H+
2 |E)
2 )P(H

1 |E)
1 )P(H

P(E)+P(H

P(E)P(H

P(E)P(H

|E1E3|

4. Implementation

In the following, details regarding the implementation of the
current version 1.1 of iSeM are given. Selected algorithms are
presented and an architectural overview based on the Semantic
Service MatchMaker (S2M2) framework is provided, followed by
details on the flexible model-driven approach used to define
matching filters. iSeM 1.1 is implemented in Java and publicly
available at http://www.semwebcentral.org/projects/isem/.

4.1. Algorithms

Algorithm 1 (please note that all algorithms described here
are located in the Appendix to not disrupt the text flow) shows
the training phase of iSeM as described formally in the previous
sections. After the feature vectors have been computed for each
request/candidate pair (R, S) with relevance y of training set TS
(lines 25), the event sets as described in Section 3.3.2 are filtered
(lines 1013). After that, the adaptation of feature vectors based
on coherence computations for the previously described cases is
performed (lines 1531) and the SVM is trained.

Algorithm 2 technically describes the approximate service
matching procedure in detail, which is used during the training
phase.9 At first, the explanations including local valuation at
concept level for all relevant concept combinations are computed
(lines 218), which then serve as the basis for possible approximate
matching variants H1 and H2. The next lines (1921) then
describe the use of bipartite graph matching, which finds the best
assignment for the signature components. After that, the local
valuations of both variants at service level are computed (lines
2223). Finally, the two approximation results are returned with
their valuation. Please note, that the result tuple of this function
may be used to compute MatchIOALogic*; however, this is not
required for the training and matching process using the SVMbased result aggregation.

Approximation at concept level is described in Algorithm 3
and follows the formal definitions given in Section 3.1.1. Given
a concept C and target concept D, the contraction problem is
solved first to establish compatibility (K  D ), followed by
structural concept abduction to create a (near-)optimal (w.r.t.
minimization of applied changes) subsumed concept definition.
Both results are taken into account for the constructed concept
C, which is then returned together with its information-theoretic
valuation v.

4.2. S2M2 framework

The S2M2 (Semantic Service MatchMaker)

framework is
designed to support various aspects of development of a semantic
matchmaker while being independent of specific formalisms for
service description and semantic annotation as well as inference
mechanisms. To accomplish this, adequate interfaces for extraction

9 It is also used for matching, which is not covered here, because it is quite similar
to training in terms of feature computation and only differs in using the SVM for
prediction instead of training.

Fig. 4. S2M2 architecture overview.

of relevant service information, matching of service candidates
with a given request and creation of rankings based on results of
the matching process are provided.

Fig. 4 provides a broad overview of the S2M2 framework.
Given a set of service offer candidates stored in a service registry
and a request, service information is parsed and mapped to
an internal representation as preparation step of the matching
process inside the Service Information Extractor core component.
A parser interface offers capabilities for extension to other formats
not provided by default. The step of mapping functional or nonfunctional properties enables the implementation of matchmakers
independent of the used formalism to describe services. For
example, a matchmaker developer may intend to map OWL-
S input parameters and SAWSDL model references of input
message parts to a unified view on service inputs in the internal
representation.

Each service offer/request pair is then matched inside the
Matching Expression Evaluator according to a set of matching feature expressions (filter definitions). For this, a very flexible approach based on the Eclipse Modeling Framework (EMF) has been
adopted, which describes filter expressions in terms of a metamodel based on a generic expression interface definition. This allows us (a) to easily extend the set of expressions provided with
S2M2 by creating new packages extending existing features or
the generic interface as has been done for example in iSeM 1.1,
(b) to automatically generate code for a graphical editor to create and edit filter definition instances for S2M2 core functionality as well as additional packages and (c) to make use of the
persistence functionality provided by EMF in terms of the XMI
(XML Metadata Interchange) format, which is interpreted by the
generic matching engine implementation of S2M2 and thus allows for straightforward integration of own filter definitions in the
matchmaker. Fig. 5 shows the generated stand-alone tree-editor
application based on RCP (Rich Client Platform), which is contained
in the iSeM distribution. Based on EMF, other editors can be im-
plemented, such as for example a syntax-highlighting text editor
with auto-completion using XText. The set of matching expressions provided with S2M2 range from logical connectors like and,
or to more complex numerical operations and specific similarity

computations at concept or textual level. Besides the core pack-
age, S2M2 provides a package for inference mechanisms, which
is further sub-divided into description-logic-based operations and
reasoners and theorem-proving, as well as a text-similarity package providing sample implementations for VSM-based (vector
space model) similarity computations. Some of them are directly
used for implementing iSeM 1.1 as presented in previous sec-
tions, while some functionality has been added in terms of a
new package, which provides specification and implementation
of approximate matching and SVM-based feature aggregation
among others. An exhaustive listing of supported expressions of
S2M2 and the iSeM extension can be found in the Appendix in
Table B.1.

After evaluation of matching expressions, the result ranking
is prepared by the Ranking Processor. The ordering is given by
a ranking strategy specification that incorporates the results of
the previously performed evaluation. Currently, different ranking
production strategies have to be implemented in Java directly
given a set of interfaces. Moreover, the generic matching engine
factory implementation of S2M2 is currently hard-coded to
allow for decreasing ranking in multiple feature dimensions with
decreasing priority only. However, for a first stand-alone version of
S2M2, it is planned to enable complete matchmaker configurations
using EMF as described for filter definitions, which includes
ranking strategies and service information extraction.

5. Performance analysis

The performance evaluation of iSeM (namely iSeM 1.1) has
been conducted using the service retrieval test collection OWLS-
TC4,10 which consists of 1083 service offers in OWL-S 1.1 and
42 queries including binary and graded relevance assignments
from nine different application domains. Since version 4, it also
includes definitions of preconditions and effects for a subset of
services (180 offers, 18 queries) which enables us to apply the fullfledged iSeM including specification matching as presented above.

10 Publicly available at http://www.semwebcentral.org/projects/owls-tc.

M. Klusch, P. Kapahnke / Web Semantics: Science, Services and Agents on the World Wide Web 15 (2012) 114

Fig. 5. EMF-based S2M2 filter editor.

However, since only a subset of definitions actually contain PE
and therefore the used -subsumption algorithm trivially yields
MatchPE(S, R) (because   ) for a larger portion of the test
collection, we added another binary dimension to feature space X
of our learning algorithm that allows iSeM to identify those cases:
x[11]  {0, 1} with x[11] = 1 iff request R contains a nontrivial precondition or effect (PR =   ER = ). Moreover,
service parameter annotations in OWLS-TC4 are not restricted to
the DL subset SH, which is a requirement for the current version
of the approximated logic-based signature matching algorithm
used in iSeM 1.0. To overcome this, we implemented a trivial
and non-optimal approximation for cases where the algorithm
is not applicable: given concepts C and D with one of them
not in SH, the result of concept contraction is CCP(C, D) =
C, and concept abduction yields C = SAP(C, D) = D,
i.e. every aspect of the original definition of C is neglected to
derive the most obvious solution such that C  D. However, even
considering this weak approximation for those cases, we observed
a significant improvement with respect to ranking precision as
we will show in the following. For evaluation, we used the public
tool SME2 v2.111 on a WinXP SP3 32 bit machine with Intel
Core2Duo T9600 (2, 8 GHz) processor and 3 GB RAM. We measured
macro-averaged precision at 20 equidistant recall levels (MARP
graph), averaged average precision and average query response
time.

5.1. Evaluation results

In summary, the evaluation results shown in Fig. 6 reveal that
(a) approximated logical matching via abduction and informative
quality performs similarly to its strict logical counterpart with

11 http://projects.semwebcentral.org/projects/sme2/.

respect to average precision, but differs to a large extent at fixed
recall levels, (b) this kind of matching performs close to but still
worse than its non-logic-based approximated counterparts (text
and structural matching), and (c) adaptive hybrid combination
outperforms all other variants in terms of precision.

As expected, due to the redundancy of strict and approximated
logical signature matching positives (cf. Theorem 1), approximated
logic-based matching alone was not able to outperform its non-
logic-based counterparts but performed close to strict logical
matching. As already hinted in statement (a) before, the rankings
of approximated logic-based and strict logic-based matching vary
to a large extent, which provides evidence that both variants
are mutually independent to a satisfactory degree. This fact
has been validated using a Friedman test conducted on average
precisions per query, which revealed that there is no significant
difference at 5% level (p  0.088), i.e. neither was able to
outperform the other for a majority of queries. As has already
been shown in the context of OWLS-MX3 (cf. [3]), this also
holds for the other basic matching variants leading to the
conclusion that each of the basic signature matching filters of iSeM
contributes to an overall increase of performance for some cases
of strict logical false classification, i.e. none of the tested variants
outperformed the others for almost all service requests in the test
collection.

The adaptive hybrid aggregation of all matching filters as
done by iSeM (cf. Section 3.3) significantly increases the retrieval
performance compared to that of its individual matching filters.
While the combination of strict logic-based, text similarity and
structure matching already yields good results as expected
from previous observations with OWLS-MX3, the additional
consideration of approximated logical matching and stateless
logical specification matching (in the learning process) performs
best. Moreover, the comparative performance analysis conducted

Fig. 6. Macro-averaged recall/precision (MARP), average precision (AvgP) and average query response time (AvgQRT) of basic and adaptive signature matching by iSeM 1.0.

for the annual S3 contest in 201012 resulted in iSeM being among
the top contestants regarding precision-based measures. In fact,
it won the OWL-S track with the best average precision (0.92)
ever measured in this contest so far. For our specific use case, the
proposed feature space pruning for relevance learning performed
best, but arguably not in general [20].

Regarding query response times, the adaptive hybrid aggregated variants performed significantly slower than the basic
matching filters (cf. Fig. 6), which is not surprising considering
the fact that each of the presented filters has to be evaluated per
offer/query pair in case of hybrid matching. For the basic vari-
ants, it is worth mentioning that the approximated logic-based
matching performs significantly slower than strict logic-based
matching, but performance is still reasonable looking at the benefit with respect to ranking precision of the full-fledged iSeM
system.

5.2. Discussion

As the evaluation results show, hybrid matchmakers may
benefit from integration of the presented approximated logicbased matching approach and thus increase ranking precision
significantly. As motivated in Section 2, the reason for this is the
improved avoidance of strict logical false negatives by additionally
considering approximated logic-based matching, which shows
sufficient mutual independence of all other approaches presented
here.

The proposed feature space model as a basis for the applied machine-leaning approach allows for easy integration of arbitrary matching filters and similarity functions and facilitates
straightforward matchmaker tool configuration without manually setting up weights for a fixed result aggregation. This approach implicitly solves the question of how to find the best
combination of semantic matching filters to achieve high precision on average. Moreover, the application of SVM using the RBFkernel nicely fits the non-linear separable nature of the feature
space in the context of semantic service retrieval on the Web
as presented in this section. For example, in OWLS-TC4 it is not
possible to strictly perform linearly weighted separation based

12 S3 2010 summary report is available at
http://www-ags.dfki.uni-sb.de/~klusch/s3/html/2010.html.

on the various features into matching true positives and true
negatives.

Failure of signature matching only has been minimized satisfactorily using the presented stateless specification matching step
whenever preconditions or effects were available. Besides the increased overall average precision achieved by the fully fledged
iSeM matchmaker, this has also been shown exemplarily in the S3
2010 summary report. However, as already stated before, OWLSTC4 only consists of a few services and request documents with
full IOPE profile. A majority of examples does not provide preconditions and effects yet, which alleviates the overall benefit
in precision for the experimental performance analysis to some
degree.

On the other hand, as shown above, the presented approach
results in a linear increase of query response times, because
every filtering and similarity computation is performed for each
service request and offer pair, even in cases where the adapted
aggregation strategy gives very low weights on some features for
certain circumstances. Moreover, the adaption is done such that
precision is optimized on average for the whole training set and
thus is rather coarse grained. Even though this turned out not
to be a problem for OWLS-TC4, there may be cases where some
basic approaches (features) are better than others given certain
contexts and vice versa. For example, the presented approximated
logic-based matching may perform better in domains described in
terms of rich-detailed ontologies like medical domains, where it
may prove inferior for coarse-grained domain descriptions. Finally,
the presented adaption strategy is strictly off-line with a distinct
training and exploitation phase. Adapting iSeM over time, for
example while collecting more and more user feedback, would
require us to drop the current aggregation function and train a
new one from scratch after some period. This could be controlled
by a threshold value for the resulting precision based on the
retrieved user feedback, but training the SVM itself is a costly
process.

6. Related work

There exists a large body of work in the area of semantic service matchmaking, and the field has been surveyed extensively for example in [1]. Moreover, the annual S3 contest
provides a platform for SWS matchmaker developers to present
their state-of-the-art implementations and to participate in a
comparative performance analysis. Details on this can be found

M. Klusch, P. Kapahnke / Web Semantics: Science, Services and Agents on the World Wide Web 15 (2012) 114

Domain

Range

Table B.1
S2M2 and iSeM filter expressions.

Expression
Basic
And
Or
Negation
Inverse
True
Greater equals
Average
Maximum
Fixed value()
Boolean as float
Conditional

Semantic annotations

Literals

Specification
Forall exists

Bipartite graph matching
Concat
Inference
Equivalence
Subsumption
Least generic concept
Implication
Text similarity
Loss of information
Cosine
iSeM
Approximated subsumption
Direct common subsumers
Structural similarity
Svm

Any
Any
Any
Any
Any
Any
Any
Any
Any
Any
Any

Service

Service

Service
Collection

Collection
String coll.

Concept
Concept
Concept
Spec.

String
String

Concept
Concept
Concept
Any

# of sub-expr.
2 n
2 n

2 n
2 n

Description

Conjunction
Disjunction
Negates sub-expression
Switches request and candidate parameter
Always returns true
Checks if first sub-expression is greater or equal than second
Computes average value
Computes maximum value
Always returns 
Converts boolean subexpression result to one of {0, 1}
Checks first subexpression and executes second or third based on result
(if-then-else)
Extracts collection of concepts (inputs or outputs) and applies subexpression
to it
Extracts collection of string values (descriptions, unfolded I/O) and applies
subexpression to it
Extracts specification (P/E) and applies subexpression to it
Checks if there exists a candidate value for each request value, where
subexpression holds (surjection)
Applies bipartite graph matching and returns average valuation (injection)
Concatenates strings and evaluates subexpression on result
Concept equivalence 
Concept subsumption 
Checks for 1
Checks if logical expressions imply 

Computes loss of information
Computes VSM-based cosine measure

Boolean
Boolean
Boolean
Any
Boolean
Boolean
Float
Float
Float
Float
Any

Any

Any

Any
Boolean

Float
Any

Boolean
Boolean
Boolean
Boolean

Float
Float

Float
Concept coll.
Float
Float


2 n

Computes valuation of approximated logical matching v(C, D)
Computes direct common subsumers
Computes structural similarity simcsim(C, D)
Aggregates sub-expressions using SVM

in [21]. However, to the best of our knowledge, iSeM is the
first fully fledged adaptive, hybrid semantic service IOPE match-
maker. Therefore, we will focus on the adaptivity aspect of hybrid matching and approximative logic-based filtering in the
following.

The strict logical and the non-logic-based semantic signature
matching filters as well as the SVM-based learning process of
iSeM are adopted from the adaptive signature matchmaker OWLSMX3 [3]. However, unlike iSeM, OWLS-MX3 neither performs
approximated logical signature matching, nor PE-matching, nor
is its adaptive process applicable to IOPE matching results and
the feature space is not evidentially pruned. The same holds for
the adaptive hybrid semantic signature matchmaker SAWSDLMX2 [6]. Besides, SAWSDL-MX2 performs structural matching
on the WSDL grounding level only which significantly differs
from the semantic structural matching performed by iSeM. The
use of abduction for approximated logical signature matching
is inspired by DiNoia et al. [8] and Colucci et al. [9]. How-
ever, their non-adaptive matchmaker MaMaS performs abduction for approximated matching of monolithic service concept
descriptions in SH, while iSeM exploits it for significantly different approximated structured signature matching and its use
for learning. Besides, MaMaS has not been evaluated yet. OWL-
S iMatcher [7] performs hybrid Semantic Web service matchmaking based on a flexible approach for user-defined matching
strategies named iSPARQL. It also adopts a wide range of machinelearning aggregation strategies and presented evaluation results
were promising. In contrast to iSeM, it does not consider approximated logic-based matching and specification matching in any
way.

7. Conclusion

We presented the first adaptive, hybrid and full semantic service profile (IOPE) matchmaker iSeM. As a continuation
of our previous work on semantic service selection, we particularly focused on the use of approximated logical reasoning and evidential coherence-based pruning of the learning
space to improve the average precision. We have shown typical pitfalls of semantic service matching by a running example
which caused false classifications and demonstrated how these
are addressed by the exploitation of different kinds of semantic service matching which are performed and aggregated by
iSeM.

The experimental evaluation results for iSeM over the widely
adopted semantic service test collection OWLS-TC revealed, among
others, that all of its hybrid combinations of logic-based, text
similarity-based and structural matching filters improves on each
of them individually. Moreover, iSeM has been among the top
contestants regarding precision-based measures, in particular it
won the OWL-S track of the 2010 edition of the annual S3 contest
with an average precision of 0.92.

From the architectural point of view, we also provided insight
on our model-driven S2M2 framework which served as a basis
for the development of the iSeM matchmaker presented and
evaluated in this paper. S2M2 provides the user with easy-to-
use interfaces for handling every aspect of the service matching
process, in particular the definition and configuration of different
semantic service signature, specification and concept matching
filters.

The approach for adaptive combination of matching variants
based on a feature space representation provides a flexible basis

Input: Request/offer pair (R, S), weighting parameter 
Output: Approximation explanation and valuation (H, v)
// compute approximation for all parameter
combinations
1 Min  
2 foreach IS  Sin do

Min  Min  {(IS , IR)  approximate(IR, IS)}

for detailed experiments with different machine-learning ap-
proaches. Besides well-known off-line algorithms, we intend to
also implement on-line approaches to add flexibility at runtime
as described above. Moreover, the approximated logical matching results of iSeM can also be exploited for explanation-based
interaction with the user during the selection process. Though in
its initially implemented version iSeM is non-obtrusive in this re-
spect, such interaction together with extending the abductive approximated reasoning to OWL2-DL annotations is subject to future
work. In this regard, we are also investigating new approaches to
the valuation of elements considered by iSeM during the structural concept abduction process such that the overall selection
may benefit from a more fine-grained information-theoretic val-
uation. In particular, the individual learning of graded valuations
of terms to give up or to keep in logically abduced signature concepts can be exploited for a more user-centered precise service
selection.

Appendix A. Algorithms

Appendix B. S2M2/iSeM filter expressions

See Table B.1.

foreach IR  Rin do
end

6 end
7 Mout,  
8 foreach OR  Rout do

foreach OS  Sout do

end

12 end
13 Mout,  
14 foreach OR  Rout do

foreach OS  Sout do

Mout,  Mout,  {(OR, OS ) 
approximate(OS , OR)}

Mout,  Mout,  {(OR, OS ) 
approximate(OR, OS)}

end

// bipartite graph matching for approximation

// compute valuation for both overall

18 end
19 HI  BPG(Min)
20 HO,  (HI , BPG(Mout,))
21 HO,  (HI , BPG(Mout,))

explanations
22 val(S,R)(H1)  1

23 val(S,R)(H2)  1
24 return {(H1 = (HI , HO,), val(S,R)(H1)), (H2 =

(IS ,IR)HI Min(IS , IR) + 1
(IS ,IR)HI Min(IS , IR) + 1

2|Sin| 
2|Sin| 

(OR,OS )HO, Mout,(OR, OS )

(OR,OS )HO, Mout,(OR, OS )

2|Rout| 
2|Rout| 

// return approximations and their valuation
(HI , HO,), val(S,R)(H2))}

Algorithm 2: Approximate Logic-based Matching

Input: Original concept C and target concept D
Output: Approximation explanation and valuation
(H(C, D), v)
1 (G, K )  CCP(C, D);
// concept contraction
2 H  SAP(K , D);
// concept abduction
3 C  [ H, H](K h);
// approximated concept
4 H(C, D)  (G, H, C);
// explanation
5 v  siminf (C, D)  (1  siminf (C, C)); // valuation
6 return (H(C, D), v)

Algorithm 3: Concept approximation
