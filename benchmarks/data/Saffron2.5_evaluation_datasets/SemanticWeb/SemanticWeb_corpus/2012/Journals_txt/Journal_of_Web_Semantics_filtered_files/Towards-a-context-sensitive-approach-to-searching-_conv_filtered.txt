Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 4152

Contents lists available at SciVerse ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : h t t p : / / w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

Towards a context sensitive approach to searching information
based on domain specific knowledge sources

Duy Dinh


, Lynda Tamine

IRIT Laboratory, University of Toulouse, 31062 Toulouse, France

a r t i c l e

i n f o

a b s t r a c t

Article history:
Available online 10 December 2011

Keywords:
Context sensitive information retrieval
Document expansion
Query expansion
Biomedical information retrieval

In the context of document retrieval in the biomedical domain, this paper introduces a novel approach to
searching for biomedical information using contextual semantic information. More specifically, we propose to combine the contextual semantic information in documents and user queries in an attempt to
improve the performance of biomedical information retrieval (IR) systems. Contextual information provides knowledge about a domain in a global context or statistical properties of a sub collection of documents related to a given query in a local context. In our context sensitive IR approach, terms denoting
concepts are extracted from each document using several biomedical terminologies. Preferred terms
denoting concepts are used to enrich the semantics of the document content via document expansion.
The user query is expanded using terms extracted from the top-ranked expanded documents via a blind
feedback query expansion approach. In addition, we aim to evaluate the utility of incorporating several
terminologies within the proposed context sensitive approach. The experiments carried out on the TREC
Genomics 2004 and 2005 test sets show that our context-sensitive IR approach significantly outperforms
state-of-the-art baseline approaches.

O 2011 Elsevier B.V. All rights reserved.

1. Introduction

Biologists search for literature on a daily basis using commercial
literature search engines such as PubMed, or Google Scholar. For
example, their information needs may involve published articles
describing the specifics of how genes contribute to disease in
organisms. However, none of those search tools provide explicit
support for genomic-focused queries.

Information retrieval (IR) is a scientific research field concerned
with the design of models and techniques for selecting relevant
information in response to user queries within a collection (cor-
pus) of documents. Two main steps characterizing an IR process
are document indexing and documentquery matching. The objective of the indexing stage is to assign to each document in the collection the set of words, terms or concepts expressing the topic(s)
or subject matter(s) addressed in the document. The matching
stage aims at identifying the most valuable documents that better
fit the query. Several and different issues arise from both indexing
and matching in IR [4]. In this paper, we are interested particularly
in biomedical IR where collections entail medical knowledge and
queries cover the information needs of physicians, researchers in
the biomedical domain or more generally users of biomedical
search tools.
 Corresponding author. Tel.: +33 561556300.

E-mail addresses: dinh@irit.fr (D. Dinh), tamine@irit.fr (L. Tamine).

1570-8268/$ - see front matter O 2011 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2011.11.009

Within the context of the biomedical sciences, there is actually
a real need to develop efficient and effective IR systems for helping
scientists to find desired information from biomedical literature.
Indeed, in recent years, the Genomic IR has attracted a lot of
talented IR researchers. Several IR approaches have been proposed
to improve the biomedical IR effectiveness using a classical vs. a
semantic IR approach.

Classical or traditional IR approaches rely on the word-based
representations of query and documents in the collection. The documentquery matching between keywords from the users query
and documents is realized under the basic term independence
assumption [29]. The specification of the user information need
is completely based on words figuring in the original query in order
to retrieve documents containing those words. Such approaches
have been limited due to the absence of relevant keywords as well
as the term variation in documents and users query (e.g.,
acronyms, homonyms, synonyms, etc.). These issues have been
addressed in semantic IR approaches which take into account the
meaning of terms and semantic relatedness between senses in ter-
mino-ontological resources for enhancing the document/query
representations.

Semantic IR approaches are an attempt to go beyond simple
term matching by relaxing the strong assumption of term independence and also to cope with term variation in documents/queries
[14,22,5,37,9,34]. The centerpiece of semantic IR models is how
to identify terms denoting domain concepts in documents/queries

D. Dinh, L. Tamine / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 4152

in a given context (lexical chains, ontologies, semantic networks, or
in an entire collection or a sub-collection) in order to highlight the
semantics of the document/query. However, research work along
these lines have reported mixed results. The reason could be due
to the nature of the user tasks (e.g., writing a report, making a deci-
sion, etc.), the knowledge about the domain (e.g., users background knowledge or expertise),
the
problem structure (e.g., cognitive structure of expert information
seekers, computational artifacts), or also the choice of the conceptual representation, i.e., the context where concepts are extracted
for a particular document/query and how the conceptual model
is used to represent the document/query, etc. For the last reason,
conceptual IR systems are involved with several parameters: the
vocabulary or terminology employed, the concept extraction
method or also the strategy in which extracted concepts are used
to represent the semantics of the document/query.

the knowledge about

In this paper, we present a novel context sensitive IR approach
to searching for information based on domain knowledge sources
and statistical properties of the sub-collection. More specifically,
we propose to combine the documents global context (domain
knowledge sources) and the querys local context (top-ranked doc-
uments) in an attempt to increase the term overlap between the
users query and documents in the collection through document
expansion (DE) and query expansion (QE).

 For DE, documents are expanded with concepts extracted from
several
terminologies. We propose to combine concepts
extracted from multiple terminologies using data fusion techniques to extract the most important concepts for each docu-
ment. The terminologies, where terms denoting concepts are
extracted, are referred to as the global context of the document.
 For QE, queries are expanded with terms extracted from the
top-ranked expanded documents obtained in the first retrieval
stage using statistical measures to compute the most related
terms of each query. The top-ranked expanded documents,
where related terms of the query are examined, are referred
to as the local context.

The remainder of the paper is structured as follows: Section 2
provides an overview of related work in biomedical IR dealing with
terminological resources. Section 3 presents our concept-based IR
approach taking into account the semantic context of the docu-
ment/query for improving biomedical IR effectiveness. Section 4
describes our experimental methodology and results. We then discuss several aspects of our IR approach in Section 5, prior to conclude the paper and outline directions for future work.

2. Background and related work

This section describes relevant background knowledge about
terminologies used in the biomedical IR domain and relevant
works related to our interests. We first present some terminologies
currently used in literature, viewed a global context where medical
concepts as well as the relationships between them are defined.
Afterwards, we present some data smoothing techniques (e.g.,
document expansion, query expansion) which can be categorized
into two main approaches: local context analysis vs. global context
analysis. By global context, we mean that concepts or related terms
are extracted using a knowledge source or a whole collection
independently from the input text (document or query). By local
context, related terms or concepts are extracted for a given
text (document or query) using statistical properties of the subcollection (top-ranked documents, k nearest concepts, etc.) related
to the corresponding text. Finally, we summarize some related
works dealing with search context for enhancing document/query

representations using either a local context (e.g., a sub-collection,
top-ranked documents) or global context (e.g., a whole collection,
a single terminology or several terminologies).

2.1. Biomedical terminologies as a global context

Several biomedical terminologies have been used by different
groups of research in IR, especially in the context of TREC Genom-
ics. The motivation of TREC Genomics was to support research and
development in biomedical IR to drive new experimental research
in the area of drug discovery for diseases. Since the commencement of TREC Genomics in 2003, several participants have tried
to improve the performance of classical IR approaches by incorporating domain knowledge sources into a conceptual IR model. Generally speaking, conceptual IR model can be viewed a contextsensitive model because conceptual
information are extracted
within a particular context, e.g., thesaurus, ontology, or related
documents, etc. We review in what follows the most terminoontological resources that have been widely used for indexing biomedical documents: MeSH, ICD-10, SNOMED and GO.

2.1.1. Medical Subject Headings

The Medical Subject Headings (MeSH) thesaurus is the standardized vocabulary developed by the National Library of Medicine
for indexing, cataloging, and searching biomedical literature. Cur-
rently, it contains more than 25,000 terms (called descriptors or
main headings) that describe biomedical concepts used in biomedical citations in a bibliographic database, e.g. MEDLINE. MeSH
descriptors are organized into 16 categories, each of which is divided into more specific subcategories. Within each category,
descriptors are organized in a hierarchical structure of up to eleven
levels. In addition, MeSH uses Entry Term and See also references to indicate semantic relations such as synonyms, near-syn-
onyms, and related concepts of a particular term.

Although MeSH is comprehensive and well maintained, it has
several drawbacks. First, the synonymous relationship is not
clearly listed and not differentiated from the related term relation
in MeSH. Second, many descriptors do not have corresponding Entry vocabularies listed, which means that synonyms cannot be
found for many terms in MeSH. Third, the design of MeSH does
not follow the ANSI thesaurus standard, which results in problems
of interoperability and reusability.

2.1.2. International Statistical Classification of Diseases

The International Statistical Classification of Diseases, 10th revision (ICD-10) is a medical classification list for the coding of dis-
eases, signs and symptoms, abnormal findings, complaints, social
circumstances and external causes of injury or diseases, as maintained by the World Health Organization (WHO). The ICD is the
international standard diagnostic classification for all general epi-
demiological, many health management purposes and clinical
use. These include the analysis of the general health situation of
population groups and monitoring of the incidence and prevalence
of diseases and other health problems in relation to other variables
such as the characteristics and circumstances of the individuals
affected,
and
guidelines.

allocation, quality

reimbursement,

resource

It is used to classify diseases and other health problems
recorded on many types of health and vital records including death
certificates and health records. In addition to enabling the storage
and retrieval of diagnostic information for clinical, epidemiological
and quality purposes, these records also provide the basis for the
compilation of national mortality and morbidity statistics by
WHO Member States.

2.1.3. Systematized Nomenclature of Medicine

The Systematized Nomenclature of Medicine (SNOMED) is a
multi-axial coded nomenclature developed and supported by the
College of American Pathologists. Different from a classification
system, SNOMED is a multi-axial coded medical nomenclature,
which allows the recording of all disease entities regardless of
prevalence, as well as all observations related to any particular
case. SNOMED covers all fields of medicine as well as human dentistry and veterinary medicine. More details about the description
of each axis can be found in [7].

2.1.4. Gene Ontology

The Gene Ontology (GO) project provides an ontology of defined
terms representing gene product properties. The ontology covers
three domains: cellular component, the parts of a cell or its extracellular environment; molecular function, the elemental activities
of a gene product at the molecular level, such as binding or catal-
ysis; and biological process, operations or sets of molecular events
with a defined beginning and end, pertinent to the functioning of
integrated living units: cells, tissues, organs, and organisms.

2.2. Data smoothing techniques in context: query expansion vs.
document expansion

In order to close the semantic gap between the users query and
documents in the collection, several research works have been focused on applying data smoothing techniques such as document
expansion and query expansion on the original document/query.
Theoretically, such techniques allow to enhance the semantics of
the document/query by bringing the query closer to the relevant
documents in the collection. As stated earlier, semantic information can be detected in a global context (usually from a domain
knowledge source or an entire collection) or a local context (usu-
ally from a sub collection of related top-ranked documents).

The principle goal of QE is to increase the search performance
by increasing the likelihood of term overlap between a given query
and documents that are likely to be relevant to the user query. Current approaches of QE can be subdivided into two main categories:
global analysis [30,35,20,15,32,21] and local analysis [27,31,2,1].
Global techniques aim to discover word relationships in a large collection (global context) such as Web documents [30] or external
knowledge sources like Wordnet [35], MeSH [15,21] or UMLS
[37,20] or multiple terminological resources [32]. Local techniques
emphasize the analysis of the top-ranked documents (local con-
text) retrieved for a given query in the previous retrieval stage
[31,1].

Similar to QE approaches, DE can help to enhance the semantics
of the document by expanding the document with the most informative terms. This technique has been used recently in the context
of textual document IR [6,33] as well as in the context of biomedical IR [20,15]. There are two principle ways of document expan-
sion: local context vs. global context. In a local context (e.g., k
nearest related documents) of a given document, similar terms
are extracted to highlight related subject matters in the document.
In a global context, terms are extracted from a whole collection
(usually a set of concepts, or a whole set of documents). The difference between DE and QE is basically the timing of the expansion
step. In DE, terms are expanded during the indexing phase for each
individual document while in QE only query terms are expanded at
the retrieval stage.

2.3. Related Work

Biomedical IR has attracted a lot of talented IR researchers over
the last two decades and is getting more and more attention from
the IR community. In the area of Genomics, users queries tend to

focus on genes and their corresponding proteins. More specifically,
geneticists are interested in the role of genes and proteins in biological processes in the body through their interactions with other
genes and their products. The main goal of the Genomics task is to
provide support for knowledge discovery of new methods for disease prevention and treatment. One of the most challenges
encountered by any IR system is to deal with term variation in natural language. Many research works have focused on the use of
knowledge sources or terminologies for indexing and retrieving
biomedical documents [3,28,1,15,18,10]. The idea is to bring the
document representation to a conceptual representation level by
means of concepts, which can be extracted manually or automatically from documents/queries. Manual concept extraction is
undertaken by human experts with many years of experience.
Automatic concept extraction is less likely to be expensive in terms
of costs and time and thus could be an alternative for helping the
manual task. Several works have been extensively studied in
literature
from documents/queries
[19,3,28,38,13,18].

concepts

to

extract

2.3.1. Mono-terminology approaches to semantic IR in the biomedical
domain

In the biomedical domain, several works have been undertaken
in an attempt to enhance the semantics of document and/or the
users query using several semantic data smoothing techniques
including QE [36,1,21,32] and/or DE techniques [20,15]. The work
in [1] adapted the local analysis QE approach for evaluating the
IR performance on searching MEDLINE documents. Their approach
relies on a blind feedback by selecting the best terms from the topranked documents in a local context of the query. Candidate terms
for QE are weighted using the linear combination of the withinquery term frequency and the inverse document frequency according to whether the term appears in the query and/or the document.
Furthermore, they compared the performance of MeSH-based
manual DE to the classical IR approach. They reported that MeSH
based DE outperforms the baseline. Using a global approach, the
work in [21] investigated QE using MeSH to expand terms that
are automatically mapped to the user query via the Pubmeds
Automatic Term Mapping (ATM) service, which basically maps untagged terms from the user query to lists of pre-indexed terms in
Pubmeds translation tables (MeSH, journal and author). [15] combined both QE and DE using the MeSH thesaurus to retrieve medical records in the ImageCLEF 2008 collection. More concretely,
they combined an IR-based approach of QE and DE for a conceptual
indexing and retrieval purpose. For each MeSH concept, its synonyms and description are indexed as a single document in an index structure. A piece of text, the query to the retrieval system, is
classified with the best ranked MeSH concepts. Finally, identified
terms denoting MeSH concepts are used to expand both the document and the query.

2.3.2. Multi-terminology approaches to semantic IR in the biomedical
domain

In order to enhance the semantics of documents indexed in a
health portal, Pereira et al. [25] proposed a multi-terminology concept extraction approach based on the bag-of-words representation of concepts in ontologies and documents in the collection. In
their approach, each sentence in the document is represented as
multiple bags of words independently to the word order correlation between words in the sentence and the ones in concepts.
According to their evaluation using a set of five different terminologies (MeSH, ICD10, SNOMED, CCAM and TUV) on a small collection of 18,814 documents indexed manually by four professional
experts, they concluded that the multi-terminology approach outperforms the concept extraction relying on a single terminology in
terms of recall. Similarly, Darmoni et al. [8] presented a multi-ter-

D. Dinh, L. Tamine / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 4152

Fig. 1. The multi-terminology based indexing and retrieval process.

minology approach for assigning biomedical concepts issued from
more terminologies (MeSH, ICD10, SNOMED, CCAM, TUV, ATC, INN,
Orphanet thesaurus, MeSH Supplementary concepts) to documents
in the CISMeF portal but the concept extraction between free text
and terminologies
is based on the simple bag-of-words
representation.

In the context TREC Genomics evaluation, Stokes et al. [32]
exploited several medical knowledge sources such MeSH, Entrez
gene, SNOMED, UMLS, etc. for expanding the query with syn-
onyms, abbreviations and hierarchically related terms identified
using the PubMeds automatic term mapping service. Furthermore,
they also defined several rules for filtering the candidate terms
according to each knowledge source. Zhou et al. [36] proposed a
knowledge-intensive conceptual retrieval by combining both the
global context (i.e., concepts in several termino-ontological resources such as MeSH, Entrez Gene, ADAM). MeSH terms are identified using the Pubmed ATM service, Entrez Gene is used for
identifying gene names and symbols while abbreviations are recognized using the abbreviation database namely ADAM. They combined the knowledge sources (global context) and the local context
(top-ranked documents) of the query in a query expansion setting
and reported an improvement of 23% over the baseline.

Biomedical concept extraction whether based on the use of terminologies or not, is a key component of semantic IR approaches.
Indeed, concepts extracted from documents allow to represent
the subject matters of each document via MeSH terms (main headings or subject headings) [25,8,23]. Concepts extracted from the
user query allows to enrich the semantics of the query via query
expansion [37,36,15]. However, to the best of our knowledge,
works dealing with biomedical terminologies typically focused
on the evaluation of the indexing performance in the context of
an information extraction task or typically focused on the evaluation of the query expansion performance in the context of an IR
task. There is so far no work investigating the evaluation of the
multi-terminology indexing for biomedical IR, i.e. the utility of
indexing biomedical documents using multiple terminologies for
biomedical information retrieval.

Our contributions in this paper are essentially to evaluate the
impact of using terminological resources for detecting contextual
information in the document content and the users query for
improving biomedical
IR effectiveness. Compared to previous
work, our major contributions are three-fold:

 First, we use an approximate concept extraction method to
identify concepts in each document using a mono terminology.
Candidate concepts are weighted to measure their relevance to
the document.

 Second, we apply the concept extraction process on several terminologies and combine several concept lists using voting tech-
niques. We see each concept identified from each document
using multiple terminologies as an implicit vote for the docu-
ment. Therefore, the multi-terminology based concept extraction can be modeled as a voting problem. The final concept
list is considered to be revealing the documents subject mat-
ter(s) and could be used for DE/QE.

 Third, unlike previous works [36,15,32,21], which only focus on
QE/DE using the global context (UMLS, MeSH, etc.) or only QE/
DE using the local context (corpus-based) [6,33] or even only
QE using both the local and global context [36], we aim to point
out that the combination of the documents global context
(knowledge sources) and the querys local context (top-ranked
documents) could be a source evidence to improve the biomedical IR effectiveness.

3. Our context-sensitive IR approach

Our context sensitive IR approach relies on two main steps detailed below: (1) Conceptual Document Indexing and (2) Context Sensitive Document Retrieval. We integrate them into a biomedical IR
process as the combination of the global and local semantic contexts for improving the biomedical IR effectiveness. The contextual
semantic information is detected using domain knowledge sources
and statistical information in a sub-collection. The former is referred to as global context while the latter is referred to as local
context. Therefore, the contextual semantic information of a given
query is revealed by concepts extracted from the global context
during document expansion and related terms from a local context
during query expansion. Fig. 1 depicts the two main stages of our
biomedical IR approach.

During the indexing stage, each document in the collection is
analyzed to extract the most significant concepts using several ter-
minologies. Our assumption behind multi-terminology based concept extraction is that the more concepts are found in several
terminologies, the more they are important in the description of
the document since they are well recognized in several sub domains of medicine. For concept extraction, we adopt MaxMatcher,
which is an approximate lookup based on dictionary matching
[38]. Given a document, MaxMatcher will extract a set of terms
or phrases denoting domain concepts as well as their corresponding concept unique identifiers (CUIs). However, MaxMatcher does
not measure the importance of each concept for describing the
semantics of the document. To achieve this, we use the BM25 term
weighting model [26] to measure the degree of description of each
concept to the semantics of the document. Formally:

Table 1
Description of the voting techniques used for a multi-terminology based concept extraction.

Category

Rank-based

Score-based

Technique

CombRank
CombRCP

CombSUM
CombMIN
CombMAX
CombMED
CombANZ
CombMNZ

scorecj; D

i141kRD; Tik  rD
ji

i1411=rD
ji

i141wD
ji
minfwD
maxfwD

medianfwD

i141wD

i141wD

ji ; i 14 1::ng
ji ; i 14 1::ng

ji ; i 14 1::ng

ji  kfcj 2 RD; Tgk
ji 
 kfcj 2 RD; Tgk

Description

Sum of concept ranks
Sum of inverse concept ranks

Sum of concept scores
Minimum concept sores
Maximum concept scores
Median of concept scores
CombSUM  kfcj 2 RD; Tgk
CombSUM 
 kfcj 2 RD; Tgk

ji 14 1= 
wD


k141

tftk 

log

k1  1  b  b 

N  nk  0:5

nk  0:5
dl

avg dl

  tftk

where tk is the constituent1 k of concept cj; tftk is the number of
occurrences of term tk in document D; N is the total number of documents in the collection; nk is the number of documents containing
word tk; dl is the document length; avg dl is the average document
length; k1, and b are parameters;  is the number of words comprising concept cj.
Let CD be the set of concepts extracted from document D and
CTi be the set of concepts defined in terminology Ti. For each docthe list of candidate concepts, denoted RD; Ti 14
ument D,
fcjj8cj 2 CD ^ cj 2 CTig, is extracted using terminology T i. We
need to find the final set RD; T containing the most relevant

concepts for document D among the ones identified from several
terminologies: RD; T 14
i141RD; Ti, where T 14 fT1; T2; . . . ; Tng; n
is the number of terminologies used for indexing.

During the retrieval stage, the top k terms from the h top-ranked
expanded documents retrieved from the first retrieval stage are
used to expand the original users query. We then detail our con-
text-sensitive IR approach via the two main steps: (1) Conceptual
Document Indexing and (2) Context Sensitive Information Retrieval.

3.1. Conceptual document indexing: How to extract key concepts from
multiple terminologies?

Given a collection of documents and n terminologies used for
indexing, we first extract concepts from each document D using
a particular terminology Ti, i.e., we will obtain n lists of concepts
for document D. We need to fuse n concept lists to obtain a final
list of unique concepts representing various subjects matters of
document D. Our fusion method for concept extraction is typically
based on well known data fusion techniques (e.g., CombMAX,
CombMIN, CombSUM, CombMNZ, etc.) that have been used to
combine data from different information sources [12]. Our purpose
here is to select the best concepts issued from several terminologies by means of voting scores assigned to candidate concepts.
For this purpose, we propose to combine rankings of the extracted
concepts from each document using their matching scores and/or
their ranks. Intuitively speaking, the concept fusion can be seen
as the voting problem described as follows.

We compute the combined score of the candidate concept cj
voting for document D, given its score wD
ji when using
terminology Ti, as the aggregation of votes of all identified con-
cepts. We consider two sources of evidence when aggregating
the votes to each candidate concept: (E1) Scores of the identified
concept voting for each document; (E2) Ranks of the identified
concept voting for each document.

ji and rank rD

1 In this paper, a constituent is a term forming a part of a concept. For example,

breast and neoplasms are two constituents of concept breast neoplasms.

We evaluate 8 voting techniques based on known data fusion
methods [12], which aggregate the votes from several rankings of
concepts into a single ranking, using both the ranks and/or scores
of candidate concepts. The lists of extracted concepts from each
document using several terminologies are merged together to obtain a final single concept list representing the documents subject
matter(s). The optimal number of extracted concepts is retained for
expanding the document content, in an attempt to enhance its
semantics. Such a technique is also known as DE or concept tagging
for document smoothing in the context of a specific domain.

Table 1 depicts all the voting techniques that we use and evaluate in this work. They are grouped into two categories according
to the source of evidence used. The k:k operator indicates the number of concepts having non-zero score in the described set; rD
ji is the
rank of concept cj defined in terminology Ti and extracted from
document D; and wD
ji is the score of concept cj, defined in Ti and extracted from document D, computed using the probabilistic BM25
scheme [26].

3.2. Context sensitive document retrieval

The document retrieval aims at matching the users query to
documents in order to retrieve a list of results that may satisfy
the user information need. In our work, we use well established
probabilistic BM25 term weighting model [26] to rank documents,
which are expanded with extracted concepts using multiple termi-
nologies, w.r.t a user query, where the relevance score of a document D for a query Q is:
scoreD; Q 14

k1  1  tfn

 w1

 k3  1  qtf
k3  qtf

K  tfn

t2Q

where

 tfn is the normalized within-document term frequency given

by:
tfn 14

tf

1  b  b  dl
avg dl

where tf is the within-document term frequency, dl and avg dl
are respectively the document length and average document
length,
 k1; k3 and b are tuning parameters,
 K is k1  1  b  b  dl=avg dl,
 qtf is the within-query term frequency,
 w1 is the idf (inverse document frequency) factor computed

as:
w1 14 log2

N  Nt  0:5

Nt  0:5

where N is the total number of documents in the collection and
Nt is the number of documents containing term t (document
frequency).

D. Dinh, L. Tamine / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 4152

Fig. 2. Variation of document length in TREC Genomics collections.

In order to improve the IR performance, we aim to expand the
users query with related terms extracted from the top-ranked
expanded documents returned by the BM25 function. Our QE approach is based on statistical properties of a sub-collection, which
is referred to as local context QE. More specifically, the local context
QE applies a blind-feedback technique to select the best terms
from the top-ranked expanded documents in the first retrieval
stage. In this expansion process, terms in the top-returned documents are weighted using a particular Divergence From Randomness (DFR) term weighting model [2]. In our work, the BoseEinstein statistics [2] is used to weight terms in the expanded
query qe derived from the original query q. Formally:
weightt 2 qe 14 tfqn  b  InfoBo1
MaxInfo
where

maxt2qtfq: the normalized term frequency in the original

 tfqn 14 tfq
query,
 MaxInfo 14 arg maxt2qe max InfoBo1,
 InfoBo1 is the normalized term frequency in the expanded query

induced by using the Bose-Einstein statistics, that is:

InfoBo1 14  log2ProbFreqtjKjFreqtjC
 FreqtjK  log2

14  log2

1  k

1  k

where Prob is the probability of obtaining a given frequency of the
observed term t within the topmost retrieved documents, namely K;
C is the set of documents in the collection; k 14 FreqtjC
, with N is the
number of documents in the collection, b 14 0:4. The number of topranked documents and the number of terms expanded to the original query are tuning parameters.

4. Experimental evaluation

The objectives of the experimental evaluation were:

expansion and query expansion, which we believe to be a
relevant source of evidence for resolving the term mismatch
problem in biomedical IR;

2. To demonstrate the advantages to integrate several biomedical

terminologies into a biomedical IR process; and

3. To compare the IR performance of the multi-terminology index-

ing to state-of-the-art IR approaches.

We describe in what follows the datasets, the experimental setup,

the evaluation measures and then present and discuss the results.

4.1. Datasets

4.1.1. Test collections

We validate our concept-based IR approach using two collec-
tions: TREC Genomics 2004 [16] and TREC Genomics 2005 [17],
which are the subset of about 4.6 millions MEDLINE citations2 from
1994 to 2003, under the Terrier IR platform [24]. TREC Genomics test
collections have been created since 2003. The 20042005 TREC
Genomics collections aim at evaluating the performance of ad hoc retrieval at the level of document. The latest TREC Genomics collection
was released in 2006 and has been reused in 2007 but the objective
has been changed: unlike the objective of the 20042005 collections,
this collection aims at providing a benchmark for evaluating the performance of retrieval of exact answer passages in response to natural
language questions (question answering-style task). Our prototype
IR system deals with biomedical information retrieval at the level
of document. Therefore, the 20042005 datasets are the most appropriate for evaluation of our IR approach.

Human relevance judgments were merely made to a relative
small pool, which were built from the top-precedence run from
each of the participants. Our prototype IR system only indexes
and searches all human relevance judged documents, i.e. the union
of 50 single pools containing 48,753 citations in TREC Genomics
2004 and 41,018 ones in TREC Genomics 2005. We only applied

1. To determine the utility of the combination of the global
context (knowledge sources) of the document and the local
context (top-ranked documents) of the query via document

2 A MEDLINE citation is a reference to an original journal article which has been
selected for indexing in MEDLINE. Each one contains several fields including an
identifier, a title, an abstract, several authors, etc. It is provided with a dozen of MeSH
terms manually assigned by librarians.

Table 2
Descriptive statistics of terminologies.

Number of concepts

Number of entries

MeSH
SNOMED
ICD-10

our conceptual indexing and retrieval method on titles and abstracts of MEDLINE citations. Fig. 2 depicts the variation of document length of both TREC Genomics 2004 and TREC Genomics
2005 documents. The average document length of TREC Genomics
2004 is 122 terms and the one of TREC Genomics 2005 is 134
terms.

There are 50 queries in the TREC Genomics 2004 with an average query length of 17 informative terms3 and 49 queries in TREC
Genomics 2005 with an average query length of 9 informative terms.

4.1.2. Biomedical terminologies

In our experiments described later, we primarily used four biomedical knowledge sources namely MeSH, SNOMED, ICD-10 and
GO released in 2010 as controlled terminologies for indexing biomedical documents. Table 2 depicts some characteristics of each
terminology where the total number of unique concepts as well
as the total number of their entries are reported. Each entry, which
can be a synonym, a lexical variant or an acronym, corresponds to a
term that refers to a particular concept. Each concept can have
more than one entry term.

4.2. Evaluation measures

In general, the IR performance must guarantee two measures:
effectiveness and efficiency. Specifically, the first one reveals the
capacity of the IR system retrieving the most relevant information
w.r.t the users information need, while the second one reveals the
capacity of the IR system providing fast and ordered access to large
amounts of information. In the context of TREC experiments, we
are only interested in the effectiveness. For measuring the IR effec-
tiveness, we used the MAP metrics representing the Mean Average
Precision calculated over all the queries. The average precision of a
query is computed by averaging the precision values computed for
each relevant retrieved document of rank x 2 1; . . . ; K, where
K 14 1000 is the number of retrieved documents. Our MAP results
are generated by the trec eval standard tool4 used by the TREC community for evaluating ad hoc retrieval runs.

4.3. Experimental setup

In order to evaluate the utility of our context sensitive IR approach based on the use of domain knowledge sources and statistical properties in the sub-collection, we carried out three series of
experiments:

 The first one (our strong baseline) is based on classical indexing
of title and abstract based articles using the well-established
probabilistic model BM25 [26].

 The second one concerns our mono-terminology IR approach

and consists of three sub-scenarios:

1. The first one concerns document expansion using MeSH
[38], denoted

identified by MaxMatcher

concepts
DEautomatic or simply DE.

3 An informative term or also keyword descriptor is a term that is useful for

describing the semantics of the document.

4 http://trec.nist.gov/trec_eval/

2. The second one concerns the query expansion using a
blind feedback technique on original documents (title+ab-
stract) without DE (see formula 5), denoted QE,

3. The last one concerns our method which relies on the
combination of both QE and the automatic DE strategy
as described above, denoted QE  DE.

 the third one concerns our multi-terminology IR approach
where four terminologies MeSH, SNOMED, ICD-10 and GO are
built into four dictionaries employed by MaxMatcher, which
generates four concept lists for each document. First, concepts
are extracted using each terminology separately to evaluate
the influence of using different single terminologies for biomedical IR. Afterwards, we applied several voting techniques for
merging the final list of identified concepts as described in Section 3.1.

Table 3 illustrates a MEDLINE citation that is expanded with
terms denoting MeSH concepts extracted using MaxMatcher and
terms denoting concepts extracted from the document content
using several terminologies. Fields such as TITLE and ABSTRACT represent the document content and KERNEL MESH; KERNEL CombMNZ
represent the concepts extracted from documents.

4.4. Experimental results

Due to the lack of training dataset in the TREC Genomics 2004
and 2005 collections, we consider using the TREC Genomics 2004
collection as the training dataset for testing our IR approach on
the 2005 collection, and vice versa. Therefore, the training dataset
is different from the testing dataset in our experiments.

4.4.1. Tuning parameter results

There are three important tuning parameters in the BM25
model, namely k1; k3 and b (see formula 2). In order to optimize
the IR performance, these parameters must be tuned appropriately
to obtain the best configuration. In our work, we suppose that the
hyper parameter b is the most important parameter reflecting the
impact of the document length and average document length in
the collection on the IR performance, we only optimize the IR performance by tuning b from a set of typical values, which are
f0:25; 0:50; 0:75; 1:00; 1:25; 1:50; 1:75; 2:00g and k1 and k3 are set
to be 1.2 and 8.0, respectively [2]. For automatic QE, according to
our previous work [11], we extract the 20 most informative terms
from 20 top-ranked documents in the first retrieval stage. First of
all, we aim to estimate the number of concepts, namely Nc, which
can be used to expand the document content. On the two collec-
tions, we tune parameter Nc along with parameter b to find out
the optimal values of each parameter.

Tables 4 and 5 show the MAP results of the automatic DE method using MeSH concepts extracted by MaxMatcher. We tuned the
number of extracted concepts, namely Nc, which will be expanded
to each document from 5 to 50 for TREC Genomics 2004 with a step
of 5 and the term frequency hyper parameter b from 0.25 to 1.50
with a step of 0.25. We did the same procedure on the TREC
Genomics 2005 collection with the exception that parameter Nc
is tuned from 2 to 10 with a step is 2 and when Nc is greater than
10, this step is 5. This allows us to determine the optimal number
Nc of candidate concepts expanded to each document as well as the
optimal value of parameter b. When Nc gets over 30, the IR performance becomes saturated. This could be explained by the fact that
a maximum number of 30 concepts in average are extracted from
each MEDLINE document.

It is noticeable that the retrieval performance of the BM25 baseline scheme and the automatic DE method differs between the
TREC Genomics 2004 and TREC Genomics 2005 tasks: the best

D. Dinh, L. Tamine / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 4152

Table 3
Example of a MEDLINE citation that is expanded with concepts extracted by MaxMatcher using a single terminology (MeSH) and multiple terminologies (MeSH, SNOMED, ICD-10
and GO). Extracted concepts are ranked according to their weight in a descending order.

<DOC>
<DOCNO>10605437</DOCNO>
<TITLE>
Structural conformation of ciliary dynein arms and the generation of sliding forces in Tetra-hymena cilia.
</TITLE>
<ABSTRACT>
The sliding tubule model of ciliary motion requires that active sliding of microtubules occur by cyclic cross-bridging of the dynein arms. When isolated,

demembranated Tetrahymena cilia are allowed to spontaneously disintegrate in the presence of ATP, the structural conformation of the dynein arms can be clearly
resolved by negative contrast electron microscopy. . . . Because the base-directed polarity of the bridged arms is opposite to the direction required for force
generation in these cilia and because the bridges occur in the presence of ATP, it is suggested that the bridged conformation may represent the initial attachment
phase of the dynein cross-bridge cycle. The force-generating phase of the cycle would then require a tip-directed deflection of the arm subunit attached to the B
subfiber.

</ABSTRACT>
<KERNEL_MESH>
tetrahymena (C0039679; 8,3433)  ; dynein (C0013352; 8,2212); arm (C0446516; 6,4393); motion (C0026597; 5,4157); displacement (C0012725; 5,1163);
</KERNEL_MESH>
<KERNEL_CombMNZ>
dynein (C0013352; 49,3272); motion (C0026597; 32,4942); atp (C0001480; 25,4916); electron microscopy (C0026019; 21,2070); tetrahymena (C0039679; 16,6866);
</KERNEL_CombMNZ>
</DOC>

  (A;B): A corresponds to a Concept Unique Identifier (CUI) and B the score of the extracted concept.

Table 4
MAP results for MeSH-based DE on TREC Genomics 2004.

Nc

Table 5
MAP results for MeSH-based DE on TREC Genomics 2005.

Nc

MAP obtained by BM25 is 0.4146 on TREC Genomics 2004 and
0.2476 on TREC Genomics 2005 while our automatic DE method
achieves the best MAP of 0.4243 on the former and 0.2504 on
the latter. The difference in terms of MAP could be due to the nature of the task of each year. In 2004, the topics are more descriptive
with title and description as well as search context indicating the
background information to place information need in context
while in 2005 the topics are given with a set of limited terms, most

of which are gene and protein names with abbreviations along
with their long forms. For the next experiments, we retain
Nc 14 30 (resp. Nc 14 6) for DE on the TREC Genomics 2004 (resp.
TREC Genomics 2005) and parameter b is set to 0.75 on the former
and 1.00 on the latter for retrieval.

Fig. 3 depicts the IR performance in terms of MAP of our automatic DE on TREC Genomics of each year when compared to the
baseline BM25 weighting scheme. The improvement rates in terms

Fig. 3. MAP results obtained by tuning parameter b of the BM25 model and the MeSH based DE.

Table 6
MAP results of the baseline BM25, DE and/or QE.

TREC Genomics 2004

TREC Genomics 2005

BM25

QE  DE

0:4507 

D (%)

2:34
7:99
8:77

Recall

D (%)

+01.35
+03.82
+03.38

0:2639 

D (%)

1:13
0:97
6:58

Recall

D (%)

-03.12
+01.64
+03.90

Paired sample t-test:
  Significant (p < 0:05).

of MAP of our DE method range from +2.13% to +10.51% on the
TREC Genomics 2004 collection and from +0.04% to +39.30% on
the TREC Genomics 2005 collection. When b is from 0 to 1, the
MAP obtained by the BM25 model tends to be stable, but when b
is greater than 1, the MAP decreases dramatically. By smoothing
the document content with extracted terms denoting concepts,
our DE method outperforms the BM25 scheme whatever the value
of b is. This clearly proves the interest to smooth the document
content using concepts extracted from domain knowledge source
to solve the problem of term mismatch, especially in the biomedical domain.

4.4.2. Effectiveness of MeSH based indexing

At this level, we aim to demonstrate the utility of the combination of DE and QE for improving biomedical IR performance. Table
6 shows the MAP results of the classical and the MeSH-based IR approaches (cf. Section 4.3). According to the results, we see that DE
gives slight improvement rates compared to the baseline BM25 on
both test collections: +2.34% for TREC Genomics 2004 and +1.13%
for TREC Genomics 2005. QE outperforms the BM25 by yielding
an improvement rate of +7.99% on the TREC Genomics 2004 but
a slight improvement of +0.97% on the TREC Genomics 2005. The
combination of DE and QE is effective on both test collections
and gives an improvement of +8.77% in terms of MAP on the TREC
Genomics 2004 collection and +6.58% on the TREC Genomics 2005
collection.

In terms of recall, we observe that DE alone only yields a small
improvement rate of +1.35% on TREC Genomics 2004 but does not
help to improve the recall on TREC Genomics 2005. QE alone yields

an improvement of +3.82% on the former, but only +1.64% on the
latter. The combination of QE and DE is more stable and shows a
consistent improvement on both TREC Genomics 2004 and 2005
collections (+3.38% and +3.90%). This proves clearly the effect of
document expansion in combination with query expansion on
the biomedical IR performance.

As shown in Table 6, the paired-sample T-tests computed between MAP rankings of the combination of document and query
semantic contexts, namely QE  DE, and the baseline in each TREC
year (e.g., in TREC Genomics 2004: M 14 0:0532; t 14 2:0756; df 14
49; p 14 0:0432 and in TREC Genomics 2005: M 14 0:1363; t 14
2:1940; df 14 48; p 14 0:0331) show that our context sensitive IR
approach is statistically significant compared to the baseline.

4.4.3. Effectiveness of multi-terminology indexing

Table 7 shows the IR performance of both mono- and multi-ter-
minology IR on the TREC Genomics 2004 and 2005 collections. We
compared the results obtained by the mono- and multi-termino-
logical indexing to the median run of all participants of each TREC
year. According to the results, we see that most of the IR scenarios
based on terminological indexing either mono or multi-termino-
logical indexing outperform the median run of each TREC year.

Within a mono-terminological setting, MeSH-based indexing
yields better results than using each of other terminologies. This
is straightforward because MEDLINE documents are currently
indexed using MeSH terms, each of which represents a subject
matter of the document. In particular, we observe that for TREC
Genomics 2004, the MAP results of MeSH-based indexing and
GO-based indexing are very competitive (0.4412 vs. 0.4408). For

D. Dinh, L. Tamine / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 4152

Table 7
Retrieval effectiveness of MaxMatcher and the 8 voting techniques on the TREC Genomics 2004 and TREC Genomics 2005 collections. Submitted runs in TREC are ranked by MAP.

Run

TREC Genomics 2004

TREC Genomics 2005

Median
Mono-terminology indexing and retrieval
MeSH
SNOMED
ICD-10

Multi-terminology indexing and retrieval
CombANZ
CombMAX
CombMED
CombMIN
CombMNZ
CombRank
CombRCP
CombSUM
a Significant changes at p 6 0:05; 0:01 and 0.001.

0:4412a
0:4222a
0:4138a
0:4408a

0:4435a
0:4387a
0:4459a
0:4440a
0.4529a
0:4407a
0:4371a
0:4470a

D (%)

(+112.73)
(+103.57)
(+99.52)
(+112.54)

(+113.84)
(+111.52)
(+115.00)
(+114.08)
(+118.37)
(+112.49)
(+110.75)
(+115.53)

0.2684a
0.2683a
0.2685a

D (%)

(+21.45)
(+21.03)
(+19.28)
(+16.71)

(+20.89)
(+23.52)
(+23.47)
(+23.56)
(+19.33)
(+19.37)
(+19.70)
(+19.70)

TREC Genomics 2005, MeSH-based indexing gives the similar results as SNOMED-based indexing (0.2639 vs. 0.2630). On both TREC
Genomics 2004 and 2005 collections, MeSH-based indexing yield
the best MAP results. For this reason, we choose MeSH-based
indexing as the reference to compare to the results obtained by
several voting techniques.

Within a multi-terminological setting, we see that most of the
voting techniques lead to a consistent improvement over median
runs. For instance, applying the CombMNZ fusion technique on
the TREC Genomics 2004 collection results in an increase up to
+118.37% in terms of MAP over the median run. The improvement
rate is better than using a mono terminology (+112.73% vs.
+118.37%). The CombMNZ technique takes into account the score
of the extracted concept as well as the number of terminologies
where the concept is defined. Therefore, we think that highly
weighted concepts that are defined in several terminologies tend
to give the most important vote for the document and so to represent better the semantics of the document. For the TREC Genomics
2005 collection, the improvement rates of the voting techniques
(ranging from +19.33% to +23.56%) are smaller but always result
in a statistically significant increase in terms of MAP. The best
MAP values are obtained using different voting techniques such
as CombMIN; CombMAX or CombMED since the MAP results
obtained by those techniques are very competitive.

As shown in Table 7, the paired-sample T-tests computed
between MAP rankings of the median run in TREC Genomics
2004 and each of our run (e.g., CombMNZ : M 14 0:2455; t 14
6:8517; df 14 49; p 14 0:001) shows that our multi-terminology
based IR approach is statistically significant compared to the base-
line. For TREC Genomics 2005, our indexing approach yields smaller MAP improvements but that are always statistical significant
compared to the TREC Genomics 2005 median run (e.g.,
CombMIN : M 14 0:0513; t 14 2:1407; df 14 48; p 14 0:0374).

We summarize the utility of our multi-terminology indexing
and retrieval based on different voting techniques as follows: in
general, the indexing based on combining several terminologies
using different voting technique allows a better IR performance
in terms of MAP compared to the median run. The improvement
rate compared to the baseline varies according to the voting technique used. In a mono-terminology setting, the use of concepts extracted from documents can be a relevant source of evidence to
improve the IR performance. Indeed, extracted concepts are used
to expand the document content in order to highlight the most
important subject matters in each document (MEDLINE citation
in our study). By expanding preferred terms denoting concepts in
the document, we can normalize the document content so to

enhance the semantics of the document. In a multi-terminological
setting, we aim to highlight the most important concepts which
are defined in several terminologies using their mappings between
each pair of terminologies (defined in UMLS). The improvement
rate of each voting technique depends on the characteristics of
each collection and requires extensive training experiments.
According to the results obtained on two collections, we see that
the three voting techniques namely CombANZ, CombMED and
CombMIN are stable because the IR performance in terms of MAP
obtained by those methods allow a consistent and statistical
improvement over the median run and the mono-terminology
based IR.

4.5. Comparative Evaluation

We further compare the results obtained by our context sensitive IR approach to the results obtained by participants in both
TREC Genomics 2004 and 2005 tracks. Table 8 depicts the comparative results of our best run with official runs of participants in the
TREC 2004 Genomics track. The results show that our multiterminology based indexing and retrieval method (CombMNZ)
outperforms the best run submitted to TREC Genomics 2004
(MAP=0.4075) with a gain of +11.14%. Our best results on the TREC
Genomics 2005 collection are found in the top four of automatic
best runs in TREC Genomics 2005 (MAP of the fourth-best run is
0.2580) given that the MAP results of the top three best runs are
very competitive (see Table 9). Most runs in the TREC Genomics
2004 and 2005 tracks extensively apply various query expansion
and pseudo-relevance feedback techniques to their IR models
while our IR approach tries to maximize the likelihood of observing
query terms in documents by expanding documents content with
key concepts extracted from either a single terminology or multiple terminologies.

Table 8
The comparison of our best run with official runs
participated in TREC 2004 Genomics Track.

Run

pllsgen4a2 (the best)
uwmtDg04tn (the second)
pllsgen4a1 (the third)
THUIRgen01 (the fourth)
PDTNsmp4 (median)
edinauto5 (the worst)
CombMNZ (our best run)

Table 9
The comparison of our best run with official runs
participated in TREC 2005 Genomics Track.

Run

york05ga1 (the best)
ibmadz05us (the second)
ibmadz05bs (the third)
uwmtEg05 (the fourth)
NTUgah1 (median)
edinauto5 (the worst)
CombMIN (our best run)

5. Discussion

To cope with the term mismatch problem in the biomedical do-
main, IR systems must bring the users vocabulary closer to the
authors vocabulary. One of the appropriate solutions is to use terminologies as means of normalizing query/document vocabulary.
For instance, document contents are smoothed or expanded with
preferred terms denoting concepts could help to improve the IR
effectiveness. Indeed, many research works have repeatedly demonstrated the added value of using MeSH terms which are manually or semi-automatically expanded to the MEDLINE citation
[31,3,1]. In a completely automatic setting, we demonstrate that
automatic concept extraction whether based on a mono-terminol-
ogy or multiple terminologies could be an effective way to improve
the IR performance. As shown in Table 6, within a mono-terminol-
ogy indexing schema, the combination of the global context DE and
local context QE consistently and significantly improves the BM25
baseline system. Furthermore, several terminologies can be combined together by using data fusion techniques to produce a coherent concept list representing the documents subject matter(s). The
final concept list containing concepts extracted from several terminologies could be regarded as the documents semantic kernel
which is finally used for document expansion. The query expansion
aims at retrieving more relevant documents by expanding the original query with relevant terms extracted either from original documents or from those expanded with extracted concepts.

Several research works in the general domain have demonstrated that the local context QE techniques are quite effective.
However, within the biomedical IR domain, such techniques may
give no improvement in terms of MAP probably because they do
not deal with term variation in natural language. For example, as
shown in Table 6, although the local context QE gives a better
improvement in terms of MAP on the TREC Genomics 2004 collection (+7.99%), it gives a very small improvement in terms of MAP
on the TREC Genomics 2005 collection (+0.97%) compared to the
baseline. In this case, the global context DE combined with the local context QE allows picking up more relevant terms from the expanded documents in order to better improve the IR effectiveness.
Furthermore, our context-sensitive IR method based on the combination of DE and QE shows stable IR performance with a significant
improvement rate of +8.77% on the former and +6.58% on the latter
collection.

In a multi-terminology setting, our MAP results consistently
and statistically outperform the results obtained by the median
of all participants in each TREC year. Since the added value of the
multi-terminology IR approach is modest compared to the monoterminology (MeSH-based) IR approach (the improvement of the
best results obtained by the CombMNZ (resp. CombMIN) method
compared to QE  DE is +0.49% (resp. +1.74%) on TREC Genomics
2004 (resp. TREC Genomics 2005)), in future work, we aim to study
the importance of each terminology where concepts are extracted.
For example, GO concepts may be better scored than those coming
from SNOMED.

6. Conclusion

In this paper, we have proposed a novel IR method for combining the global context DE and the local context QE. The results
demonstrate that our IR approach shows a significant improvement over the classical IR. The best results of our conceptual IR approach are significantly superior to the median of official runs in
TREC 2004 & 2005 Genomic Tracks and are comparable to the best
runs. In addition, we have also proposed a novel multi-terminology
approach to biomedical IR. We argued that concept extraction
using multiple terminologies can be regarded as a voting problem
taking into account the rank and score of identified concepts. The
extracted concepts are used for DE and QE in an attempt to close
the semantic gap between the users query and documents in the
collection. The results demonstrate that our multi-terminology IR
approach shows a significant improvement over the median runs
submitted in TREC Genomics 2004 and 2005 tracks.

Our future work aims at incorporating our multi-terminology IR
into a semantic model taking into account the concept centrality
and specificity, which we believe to be able to overcome the limits
of the bag-of-words based models. We also plan to combine several dictionary-based and statistical concept extraction methods
by leveraging the advantages of each method. We believe that concepts extracted from several methods would enhance the concept
extraction accuracy. Finally, it is also interested to integrate other
biomedical ontologies such as EFO (Experimental Factor Ontology)
and OBI (Ontology for Biomedical Investigations) into our context
sensitive IR approach to annotate various semantic information
in biomedical literature.
