Web Semantics: Science, Services and Agents on the World Wide Web 16 (2012) 1731

Contents lists available at SciVerse ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

journal homepage: www.elsevier.com/locate/websem

Georeferencing Flickr photos using language models at different levels of
granularity: An evidence based approach
Olivier Van Laere a,, Steven Schockaert b, Bart Dhoedt a

a Department of Information Technology, Ghent University, IBBT, Belgium
b School of Computer Science & Informatics, Cardiff University, United Kingdom

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 6 April 2011
Received in revised form
27 April 2012
Accepted 2 May 2012
Available online 2 July 2012

Keywords:
DempsterShafer evidence theory
Language models
Georeferencing
Web 2.0
Geographic information retrieval

1. Introduction

The topic of automatically assigning geographic coordinates to Web 2.0 resources based on their tags
has recently gained considerable attention. However, the coordinates that are produced by automated
techniques are necessarily variable, since not all resources are described by tags that are sufficiently
descriptive. Thus there is a need for adaptive techniques that assign locations to photos at the right level of
granularity, or, in some cases, even refrain from making any estimations regarding location at all. To this
end, we consider the idea of training language models at different levels of granularity, and combining
the evidence provided by these language models using Dempster and Shafers theory of evidence. We
provide experimental results which clearly confirm that the increased spatial awareness that is thus
gained allows us to make better informed decisions, and moreover increases the overall accuracy of the
individual language models.

 2012 Elsevier B.V. All rights reserved.

In addition to topical relevance, the geographic scope of a web
resource is often paramount for assessing its relevance. Inspired
by this observation, geographic information retrieval (GIR) systems
attempt to identify spatial constraints in queries, and to determine
which web resources satisfy them [1,2]. This requires appropriate,
structured geographic background information, which is available
in the form of gazetteers. However, as gazetteers are often
restricted to administrative places or are otherwise incomplete,
many of the names people use to refer to places (i.e. vernacular
place names) are not recognized. Moreover, in determining the
geographic scope of a web resource, other terms than toponyms
may play a key role (e.g. the names of local events). As a result,
there has been a recent interest in the automated acquisition of
geographic knowledge from online resources which are already
georeferenced, e.g. utilizing information provided by users in
tagging-based systems such as Flickr [36], other types of social
websites [7,8], or even local business directories such as Yahoo!
local [9]. What is common to these approaches is that they rely
on resources containing both geographic coordinates and textual
descriptions (typically in the form of tags) to find correlations

 Corresponding author. Tel.: +32 93314940.

E-mail addresses: olivier.vanlaere@intec.ugent.be (O. Van Laere),

S.Schockaert@cs.cardiff.ac.uk (S. Schockaert), bart.dhoedt@intec.ugent.be
(B. Dhoedt).

1570-8268/$  see front matter  2012 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2012.05.005

between locations and linguistic descriptions. These correlations
are then used to obtain geographic information in the sense of
[1012], i.e. tuples of the form x, y, z, t, U where U represents
a thing which was present at location (x, y, z) at time t. Note that
in the aforementioned works, U is referred to by some web object;
e.g. a Flickr photo or Twitter post refers to the presence of a user at
a particular location.

Given this importance of large-scale repositories of georeferenced resources, it is of interest to increase the number of resources for which appropriate geo-annotations exist. In the case
of Flickr, for instance, coordinates are only available for a small
fraction.1 A number of recent research efforts have been directed
towards automatically finding (approximate) coordinates of Flickr
photos [13,2,14]. The importance of this task is twofold. On one
hand, it shows how we may directly georeference online resources,
without the intermediate construction of a gazetteer or other
forms of explicit spatial semantics of toponyms. On the other hand,
it allows to make a larger number of georeferenced Flickr photos
available, which is interesting per se (e.g. to allow spatial browsing
by displaying them on a map). Note that the idea of using Flickr tags
to derive geo-annotations, as a form of semantic information about
a photo, fits within a broader trend to use Web 2.0 data sources to

1 http://www.flickr.com/map/ shows that around 168 M photos are geotagged
of over 6.46 billion photos (http://www.flickr.com/explore) on Flickr. Accessed on
December 6th, 2011.

O. Van Laere et al. / Web Semantics: Science, Services and Agents on the World Wide Web 16 (2012) 1731

bootstrap the semantic web. For example [15] suggests building
collective knowledge systems by integrating user-contributed content from the Social Web and machine-gathered (semantic) data.
Taking this idea one step further, the DBPedia Mobile client proposed in [16] allows a user to browse location related information
and semantically interlinked data sources, but at the same time
also to contribute to the overall geospatial semantic web by publishing content that is linked with nearby DBPedia resources.

Existing work indicates that language models are particularly
suitable for the task of assigning coordinates to Flickr photos
[13,17]. The geographic space is then discretized into a set of
disjoint areas. After training a language model for each of these
areas, we may determine which one is most likely to contain the
true location of a given photo. A drawback of this approach is that
it must be decided a priori what is the most suitable granularity
at which the location of each photo should be determined. Clearly,
such a view is at odds with the observation that the tags of some
photos are more indicative of a specific place (e.g. Central Park, New
York) than others (e.g. picnic).

The solution we propose in this paper is to train language
models at different levels of granularity, and subsequently decide
the most appropriate granularity level for each individual photo.
Although we then still need to choose a specific number of
clusters for each granularity level, this avoids having to fix
the overall scale at which each photo should be georeferenced.
In this decision, there is a trade-off between accuracy and
informativeness. Essentially, we choose the finest granularity at
which the most likely area is sufficiently probable. In contrast to
standard language modeling approaches, the actual probabilities
that come out of the language models thus become important,
rather than only the ranking that is imposed by them. Since such
probabilities are known to be poorly calibrated, in this paper, we
study the effect of two forms of post-processing that are applied
to these probabilities. First, we consider a standard approach
for calibrating classifier probabilities, based on the well-known
PAV (pair-adjacent violators) algorithm. The second form of postprocessing relies on the spatial dimension of the problem setting.
In particular, we propose an approach based on Dempster and
Shafers theory of evidence [18,19], which allows us to deal with
probabilistic information at different levels of granularity in a
natural way. Moreover, the theory dictates how evidence coming
from different sources  in this case the language models of areas
at different granularity levels  can be combined.

The paper is structured as follows. First, in Section 2 we
explain how our training and test data was selected, what relevant
meta-data is available for Flickr photos, and which preprocessing
we have performed. Next, Section 3 recalls the basic approach
to georeferencing Flickr photos based on language models, and
it explains how the resulting probabilities can be calibrated.
The core of our approach is presented in Section 4, where
we show how the probabilities produced by language models
may be encoded as belief functions in the sense of Shafer,
and how these belief functions may be combined with each
other to arrive at a single belief function capturing all available
evidence. Section 5 then explains how we may use belief functions
in practice. Subsequently, Section 6 presents our experimental
findings. Finally, we provide an overview of related work and
conclude.

This paper is a substantially revised and extended version
of [20]; the main extensions are as follows. First, the belief functions are now built from calibrated language model probabilities,
whereas we used the raw probabilities in [20]. Second, we now
consider more combination operators, and a different decision rule
based on pignistic probability. Furthermore, to have a better mapping among different granularity levels, we now use one hierarchical clustering, rather an independent flat clustering for each level.
Finally, the experimental results have been significantly extended,
using a more representative data set.

Table 1
Size of the considered data sets.

Training set
Calibration set
Test set
Total

2 176 719 photos
1 038 612 photos
50 000 photos
3 265 331 photos

Table 2
Mean and standard deviation for the number of tags per photo in each data set.
Standard deviation

Data set
Training set
Calibration set
Test set

Mean

2. Data acquisition and preprocessing

For each photo that is uploaded to its website, Flickr maintains
several types of meta-data, which can be obtained via its publicly
available API. In this paper, two types of meta-data will be relevant:
descriptive tags that have been provided by the photo owners, and
for some photos, information about where they were taken. The
location information includes a geographical coordinate (latitude
and longitude), and information about the accuracy of the location,
encoded as a number between 1 (world-level) and 16 (street-level).
The data set we have used consists of two parts. The first part
contains the 3 185 343 photos that were provided to the participants of the 2010 MediaEval Placing Task,2 a recent benchmarking
initiative on the topic of automatically georeferencing Flick videos.
In July 2010, we crawled Flickr in order to expand this initial data
set. The query used for this additional crawl constrained the resulting photos to those with an accuracy of at least 12, to ensure that
all coordinates were meaningful w.r.t. within-city location. Once
retrieved, photos that did not contain any tags or whose coordinates were not valid were removed from the collection. As a result,
we obtained an additional data set containing the 5 500 368 most
recently georeferenced images (at that time). Combining these two
sets resulted in a data set consisting of 8 685 711 georeferenced
photos covering more or less the entire world.

In a preprocessing phase, we removed duplicates, i.e. photos
of the same user that have an identical tag set (to reduce the impact of bulk uploads [13]). Once filtered, the remaining data set of
3 265 331 photos was divided into a training set of 2 176 719 photos (2/3rd), a separate training set of 1 038 612 photos (1/3rd
50 K) that will be used for calibration of the probabilities, and a test
set of 50 000 photos. When separating training data from calibration and test data, we ensured that all photos from the same user
were either in the training set, or in the calibration and test sets
(to avoid an unfair exploitation of user-specific tags [21]). Tables 1
and 2 provide some characteristics of the different data sets. A plot
of the coordinates of the photos from the training set is shown in
Fig. 1.

The task of estimating the location where a photo was taken
can be seen as a classification problem: for each unseen photo
t from the test set, we then determine which area a from a
given set of areas A is most likely to contain this location. To
create this set of areas A, a k-medoids clustering algorithm (PAM
Partitioning Around Medoids) with geodesic distance was used to
cluster the locations of the photos in the training set into 2000
disjoint areas. Note that the k-medoids algorithm was preferred
over k-means as it handles the occurrence of outliers better. Among
all coordinates, the initial k medoids are randomly chosen. In a
subsequent step, initial clusters are obtained by associating the

2 http://www.multimediaeval.org/mediaeval2010/placing/index.html.

Fig. 1. Plot of the training set.

Table 3
Mean and standard deviation of the size of the clusters in terms of kilometers.

Fig. 2. Coarse clustering of Europe (|A| = 250).

Granularity

Mean (km)

Standard deviation (km)

d(c, c)

remaining coordinates to the closest medoid (in terms of geodesic

distance). Next, for each cluster C, the new medoid is chosen as the
element c  C minimizing

cC
where the cluster C is identified with its set of coordinates, and d
refers to geodesic distance. New clusters can then be obtained from
these medoids by again assigning each coordinate to the closest
medoid. This process is repeated until the cluster configuration
does not change anymore.
In this paper, we will consider
different levels of granularity, with 2000 areas being the finest
level. To obtain coarser granularity levels, we subsequently used
agglomerative hierarchical clustering on this initial clustering,
leading to clusterings into 1000, 500, 250 and 50 areas. This step of
agglomerative clustering was accomplished by repeatedly merging
those two clusters whose medoids were closest to each other
w.r.t. geodesic distance. Note that each cluster at one of the coarser
granularity levels then exactly corresponds to the union of one or
more of the areas of the finest clustering. Note that alternative
clustering algorithms, such as a grid based approach [22], mean
shift clustering [13] or even a classification based on administrative
boundaries can be used for this task; all we require is that each
cluster from a coarser granularity level can be seen as the union
of one or more clusters from the finest clustering. Examples of our
clusterings are shown in Figs. 2 and 3, showing only the clusters
located in Europe for clarity. To illustrate the characteristics of
the different granularity levels, Table 3 provides the mean and
standard deviation of the size of the clusters, where the size of a
cluster C is taken to be the maximal distance between the medoid
and any other member of the cluster.

Next, a vocabulary V consisting of interesting tags is compiled,
which are tags that are likely to be indicative of geographic
location. We used  2 feature selection to determine for each area in
A the m most important tags.3 The vocabulary V was then obtained
by taking for each area a, the m tags with highest  2 value. The m

Fig. 3. Fine clustering of Europe (|A| = 2000).

values which we have used are 62 500 for the coarsest clustering,
12 500, 2500, 500 for the intermediate resolutions and 100 for
the finest clustering level. This choice of features ensures that the
language models, introduced next, require approximately the same
amount of memory space for each clustering level.4

3. Calibrated language models for estimating location

3.1. Language models

Let A be a set of (disjoint) areas, obtained by clustering the
locations of the photos in our training set. For ease of presentation,
we identify an area a  A with the corresponding set of photos
that were taken in it. Given a previously unseen photo x, we try
to determine in which area x was most likely taken by comparing
its tags with those of the images in the training set. Previous
work [13,17,2] has revealed that probabilistic (unigram) language
models [23] are particularly useful to this end. The probability
p(a|x) that image x was taken in area a is then taken to be
proportional to

p(t|a)

(1)

p(a|x)  p(a) 

tx

3 Initial experiments have shown  2 feature selection to perform slightly better
than mutual information on this task.

4 Space requirements increase quadratically with the number of clusters.

O. Van Laere et al. / Web Semantics: Science, Services and Agents on the World Wide Web 16 (2012) 1731

which corresponds to using a multinomial Naive Bayes classifier to
assign areas to photos. The prior probability p(a) of area a can be
estimated using the maximum likelihood method:

p(a) = |Xa|

To avoid a zero probability when x contains a tag that does not
occur in area a, some form of smoothing is needed when estimating
p(t|a). Let Da(t) be the occurrence count of tag t in area a. The total
tag occurrence count Da of area a is then defined as follows:

|Da| =

tV

Da(t)

where V is the vocabulary that was obtained after feature selection,
as explained in Section 2. One possible smoothing method is
Bayesian smoothing with Dirichlet priors, in which case we have
( > 0):

p(t|a) = Da(t) +  p(t|C)
in which the probabilistic model of the collection p(t|C) is defined
using maximum likelihood:

|Da| + 


Da (t)
Da (t)

aA

aA

tV

p(t|C) =

Another possibility is to use JelinekMercer smoothing, in which
case we have (  [0, 1]):
p(t|a) = 

|Da| + (1  ) p(t|C).

Da(t)

We have experimentally found these two smoothing techniques
to yield comparable results (for optimal values of the parameters
 = 1750 and  = 0.80), although Bayesian smoothing was found
to be more robust w.r.t. the choice of the parameter. These findings
conform to experimental results in other areas of information
retrieval [24,25], and to earlier work on georeferencing Flickr
photos [13].

As we focus on the effect of different granularity levels in
this paper, we restrict ourselves to a rather standard language
modeling approach. Note, however, that the model presented in
this section can be refined in different ways, using additional
information about the owner, information from visual features, etc.
For example, [26,27] use the home location of the user, while [28]
uses information about her social network. As another form of
refinement, in [13] a location-aware from of smoothing is used.

3.2. Calibration

In principle, an estimation of the actual value of p(a|x), for
all a  A, is found from (1) after normalization. However, it is
well-known that Naive Bayes does not produce well-calibrated
probability estimates [29]. As our approach will strongly depend
on the actual values of the probability estimates, we need to
apply some form of calibration. In [30], an approach called binning
is shown to produce such well-calibrated probabilities. In [31],
an extension of this method based on the PAV (pair-adjacent
violators [32]) algorithm is proposed, which we have adopted
in our experiments. In particular, let us write n(a|x) for the
normalized Naive Bayes output, i.e.:
n(a|x) = score(a|x)
score(a|x)
where score(a|x) denotes the estimation of the right-hand side
of (1).


aA

(2)

Some care needs to be taken to avoid underflow or a significant
loss of precision, as the values score(a|x) tend to be very small. As
usual, these values can be calculated in log-space, i.e.

log p(t|a).

The normalization cannot be carried out in log-space, so we rewrite
the denominator in Eq. (2) in the following way:

tx

score(a|x)

log score(a|x) = log p(a) +
log


  score(a|x)

log
log
log

aA

aA

aA

aA

 log 


exp log(  score(a|x))

 log 

exp(log( ) + log(score(a|x)))

(3)

(4)

(5)

(6)

 log  .

abs(log(score(a|x))).

By choosing  sufficiently high, problems of reduced precision can
be avoided; we have used
log  = max
aA
In this way, exp(log( ) + log(score(a|x))) in Eq. (6) becomes
exp(0) = 1 for the most plausible areas a, which avoids both
underflow and overflow for the probability of those areas. Note
that if underflow occurs for the probability of less plausible areas,
this is then because their probability is extremely small compared
to the most plausible area, in which case we can safely ignore them.
The PAV algorithm is now used to map the scores n(a|xi) to
accurate probability estimates, as follows [33,34]:
 Assume that the photos x1, . . . , xm from the training set are
ranked such that n(a|xi)  n(a|xi+1) for all i.
 At each stage of the algorithm, a list of bins is maintained. Let us
write B(i, j) for the bin that contains the images xi, xi+1, . . . , xj.
Initially the list L contains one bin for each photo, i.e. L =
{B(i, i)|1  i  m}. For a given bin B1 = B(i, j), we write
avg(B1) for the percentage of photos in bin B1 that actually
belong to the area a.
 Let L = (B1, . . . , Bp). Until it holds that avg(Bi)  avg(Bi+1) for
all i, repeat the following
1. Find all maximal subsequences of bins Bi, . . . , Bj in the list
such that avg(Br )  avg(Br+1) for all r  {i, i+ 1, . . . , j 1}.
2. Replace these subsequences in the list L by the single bin
B = Bi  Bi+1    Bj.

To ensure that meaningful probability estimates are obtained, as an
additional step, we also merge each bin containing fewer than 100
items with the bin succeeding it. This is especially important for the
first bin, which we otherwise found to provide an unrealistically
optimistic estimation. For instance, if the highest ranked photo
were correctly georeferenced, the highest bin would always be
associated with a probability of 1.
Let L = (B1, . . . , Bp) be the final list of bins that is obtained
from this procedure. Each bin B naturally corresponds to an
interval bounds(B) = [n, n] where n = minxB n(a|x) and
n = maxxB n(a|x). For a given photo x from the test set, we
then determine the bin B for which bounds(B) contains n(a|X ), or
is then given by avg(B). Note that
whose bounds are closest to n(a|x). A probability estimate p(a|x)
a p(a|x) may be different from
1. However, we refrain from normalizing these estimates at this
stage, as initial experiments have shown that this may largely
nullify the effect of the calibration process.

4. Combining language models of different granularity levels

The language modeling approach that was outlined in Section 3
is not spatially aware in the sense that e.g. neighboring areas are
treated in the same way as areas that are located in different
parts of the world. To see why this difference might be important,
assume that the probability p(|x) takes a high value for two
different areas a and b. If a and b are adjacent or close to each other,
it makes sense to estimate the location of x at a coarser level of
granularity, using an area c as result which encompasses both a
and b. Indeed, the fact that all areas that are considered plausible
are spatially close suggests that our estimation will be near the
actual location of x, while the available information is not sufficient
to distinguish reliably between a and b. In contrast, when a and b
are not close, the choice between a and b is likely to be a problem
of disambiguation. In such as case, it makes more sense to first
determine the most likely area c at a coarser granularity level, and
take a to be the result if c contains a (but not b), and b if c contains
b (but not a).

Our solution uses DempsterShafer evidence theory [18,19]
to combine the probability distributions obtained from language
models that operate at different resolutions. Based on the agreement between fine-grained models and coarse-grained models, we
may then try to find the most plausible region in which a photo was
taken, at the most appropriate resolution given the available infor-
mation. Essentially, our approach then finds the smallest region for
which all models agree (to a sufficient degree) to contain the true
location with high probability.

4.1. Belief functions

Let {A1, . . . , Ak} be different clusterings of the locations in
the training set such that |A1| > |A2| >  > |Ak|,
i.e. A1 corresponds to the finest clustering and Ak corresponds
to the coarsest clustering. For each clustering, a language model
is obtained which (after calibration) results in a probability
distribution pi(|x) in the universe Ai for each image x. A key
observation is that the spatial extension of each area a in Ai
corresponds to the union of the spatial extensions of a set of
areas from the finest level A1, as the different clusterings have
been obtained in a hierarchical fashion. Let us write areas(a) for
this set of areas from A1 that are included in a. Then, if a is
the area maximizing p(|x), we can take this as evidence that the
correct area, at the finest level, is among those of the set areas(a).
In other words, the probability distributions p2, . . . , pk naturally
correspond to probability distributions on the power set of A1,
i.e. to belief functions on A1.

2U  [0, 1] mapping m satisfying

Recall that a belief function [19] on a finite universe U is any
XU m(X ) = 1 and m() = 0;
belief functions are also called mass assignments. Intuitively, m(X )
represents the amount of evidence that the correct value of some
variable is among those in X. Subsets X such that m(X ) > 0
are called focal elements. Starting from a belief function m, two
measures of uncertainty are usually considered:

Bel(X ) =

m(Y )

Pl(X ) = 

m(Y )

YX=

for any X  U. The degree of belief Bel(X ) can be interpreted as a
lower bound on the probability that X contains the correct value,
while the degree of plausibility Pl(X ) is an upper bound for this
probability.

Probability distributions essentially model variability, i.e. the
phenomenon that the outcome of a given experiment may not
always be the same, but they lack the capability of genuinely
modeling epistemic uncertainty, i.e. the uncertainty resulting from
a lack of information. For example, suppose that we know with

perfect certainty that the outcome of rolling a die was among the
values {1, 2, 3}. In probability theory, we are left with assigning
an equal probability to each of these values, i.e. p(1) = p(2) =
p(3) = 1
3 . However, this probability distribution is not a faithful
representation of the beliefs that we hold: why should we be able
to infer that it is twice as likely that the outcome was odd than that
the outcome was even, if all we started off with was the knowledge
that the outcome was in {1, 2, 3}. Using belief functions, on the
other hand, we can distinguish between the mass assignment m1
defined by m1({1, 2, 3}) = 1, and the mass assignment m2 defined
by m2({1}) = m2({2}) = m2({3}) = 1
3 . In other words, belief
functions are capable of modeling both variability and epistemic
uncertainty.

Note that in the special case where all focal elements are
singletons, belief
functions simply correspond to probability
distributions. Specifically, if we define p(x) = m({x}), it holds
that P(X ) = Bel(X ) = Pl(X ) for every X  U, where P is the
probability measure associated with p, and Bel and Pl are the belief
and plausibility measures associated with m.

Nonetheless, when it comes to making decisions based on our
available beliefs, the choice between m1 and m2 may actually
not matter. When deciding whether or not to accept a bet, for
instance, all we can do is assume an equal probability for each
outcome, i.e. apply the maximum entropy principle. The point of
using belief functions, however, is to apply this maximum entropy
principle after all the available evidence is combined. In other
words, a difference is made between the credal level, which is
concerned with modeling the beliefs of an agent, and the decision
or pignistic level (from the Latin word pignus for bet). Specifically,
when it comes to decision making based on belief functions, a
mass assignment m is often converted into the associated pignistic
probability distribution p defined by Smets [35]

p(x) = 

XU,xX

m(X )
|X|

after which decisions may be made using standard approaches
(e.g. based on maximizing expected utility).

4.2. Obtaining mass assignments

In the context of this paper, the universe U will always be
the set of areas (clusters) of the most fine-grained clustering
A1. For a given photo x, the different granularity levels lead to
mass assignments m1, . . . , mk defined as follows. First, at each
granularity level i, a set Si containing the most likely areas from Ai
is determined. In principle, we could take Ai = Si, but in practice,
areas in decreasing order of likelihood until
a smaller set Si is desirable to keep the approach time- and space-
efficient. In our experiments, the set Si was obtained by adding
aSi pi(a|x)   for
some fixed parameter i (e.g. i = 0.95). Recall that the probability
estimates pi(a|x) are not necessarily normalized, i.e. they do not

necessarily sum to 1. However, in all but a few cases we have that
aSi pi(a|x) < 1. Then we define:

pi(a|x)

i (X ) =
mx
outside Si, i.e.

aSi

pi(a|x)

if X = areas(a) for a  Si
if X = A1
otherwise.

(7)

Note that the probability pi(a|x) is translated to the mass mx
i (a)
for areas a in Si. The remaining mass corresponding to the areas
a(Ai\Si) pi(a) is assigned to the entire universe A1.
This mass will be approximately equal to 1  i and reflects the
probability that we are ignorant about the location of x. Choosing
a lower value of i will thus lead to a more cautious and less
informative mass assignment.

Finally, in the rare cases where s = 
probability estimates are first normalized as
i (a|x) = pi(a|x)


and the mass assignment is defined as in (7), but based on the
normalized estimates p

aSi pi(a|x)  1, the

i (a|x) instead of pi(a|x).

4.3. Combining evidence

Different belief functions may encode the evidence provided
by different sources, in which case a combination operator may
be used to obtain a single, combined belief function. In particular,
given two belief functions m and m in a universe U, Dempster [18]
proposes to model the combined evidence using the mass
assignment m  m defined as
(m  m)() = 0
(m  m)(X ) =

for any subset   X  U, and provided that


m(Y )m(Z )

YZ=X
YZ= m(Y )m(Z )

(8)

(9)

m(Y )  m(Z ) < 1.

YZ=
The denominator in (9) is a normalization factor, which corresponds to the mass that would normally be assigned to the empty
set, i.e. it is a measure of the amount of conflict between m and m.
It can be shown that this combination rule is associative.

By treating the different granularity levels as independent
sources, the overall evidence about the location of a photo x may
thus be described by the belief function mx:
mx = mx

2    mx
k.

1  mx

(10)

1(A1)  mx

2(A1)
2(A1)

1(A1)  mx
1(A1)  mx
2(A1)

1({a}) mx
1({b}) mx

2(areas(u)) + mx
2(areas(u)) + mx
2(areas(u))
2(areas(v))

Example 1. Let us go back to the scenario outlined in the beginning
of Section 4.
In particular, assume that there are only two
granularity levels, and S1 = {a, b} and S2 = {u, v}. At the finest
level, we are thus faced with the choice of a or b as the location of a
given photo x. First assume that areas(u) contains both a and b. In
this case, the focal elements of mx are {a},{b}, areas(u), areas(v),
and A1; we obtain
mx({a}) = K  mx
mx({b}) = K  mx
mx(areas(u)) = K  mx
mx(areas(v)) = K  mx
mx(A1) = K  mx
where K is the normalization constant. Assuming that mx
mx
2(A1) are sufficiently small, we have
mx(areas(u))  mx(areas(v))  mx(A1)  0
and thus K  mx({a}) + mx({b}); we obtain
Bel({a}) 

Bel({b}) 

1({a})  mx
mx
p1(a|x)
p1(a|x) + p1(b|x)
1({b})  mx
mx
1({a})  mx
2(areas(u)) + mx
mx
p1(b|x)
p1(a|x) + p1(b|x)

1({a})  mx
mx
2(areas(u)) + mx

2(areas(u))
1({b})  mx

2(areas(u))
1({b})  mx

2(areas(u))

2(areas(u))

1(A1) and

Bel(areas(u))  1.

2(A1)

2(areas(v)) + mx

1({b}) mx

Note that because v does not overlap with any area of S1, most of
the mass mx
2(areas(v)) disappears in the normalization constant K.
If u is a clear winner at the second level, i.e. p2(u|x)  p2(v|x),
without a clear winner at the first level, we thus obtain strong
evidence that the correct location is in u, but much weaker
evidence for a or b individually.
Now consider a second scenario in which a  areas(u) while
b  areas(v). We then get
mx({b}) = K  mx
and mx({a}), mx(areas(u)), mx(areas(v)) and mx(A1) as before.
Again assuming that mx
2(A1) are sufficiently small, we
have
Bel({a}) 
Bel({b}) 
If we moreover again make the assumption that p2(u|x)  p2(v|x),
we get
Bel({a})  Bel(areas(u))  1
Bel({b})  Bel(areas(v))  0.
Hence in this case, we do obtain strong evidence for a. Note that in
the latter scenario the evidence from the second granularity level
has allowed us to make a decision between a and b, while in the
former scenario it has rather provided a more cautious alternative,
avoiding a somewhat arbitrary choice between a and b.

1(A1) and mx
1({a})  mx
mx
2(areas(u)) + mx
1({b})  mx
mx
2(areas(u)) + mx

2(areas(u))
1({b})  mx
2(areas(u))
1({b})  mx

1({a})  mx
mx
1({a})  mx
mx

2(areas(v))

2(areas(v))

perspective, when the degree of conflict

The combination rule (8)(9) is the first and most widely known
combination rule, already proposed by Dempster in the 1960s. It
has been argued by several authors that it constitutes the only
principled way to combine independent and reliable sources in a
conjunctive way [36,37]. On the other hand, from an application
YZ= m(Y )  m(Z ) is
close to 1, it is reputed to provide counterintuitive results [38].
Moreover, when the degree of conflict is equal to 1, the result
of the combination is not even defined. To cope with this, when
using Dempsters rule, we first apply some form of discounting,
i.e. each mass assignment m is replaced by the mass assignment
m, defined by
m(A) =   m(A)
if A is different from the universe U, and
m(U) =   m(U) + (1  ).
In our experiments, we use  = 0.99. Note that this indeed guarantees that the degree of conflict is strictly smaller than 1.

Another solution, which is adopted in the transferable belief
model (TBM) of Smets [39], is to simply allow a non-zero mass for
the empty set. We thus obtain the following combination operator:

m1(B)  m2(C).

(11)

(m1  m2)(A) = 

BC=A

After the final mass assignment has been determined, the mass
of the empty set is than added to the mass of the universe.
The resulting combination operator is sometimes called Yagers
rule [40] (  A  U):
(m1   mk)(A) = (m1    mk)(A)
(m1   mk)(U) = (m1    mk)(U)
+ (m1    mk)()
(m1   mk)() = 0.

(13)
(14)

(12)

Note that unlike  and , the operator  underlying Yagers
combination rule is not associative. Dubois and Prade have
proposed the following alternative way of distributing the mass of
the empty set [41]:
(m1  m2)(A) = (m1  m2)(A)

BC=A,BC=

m1(B)  m2(C).

(15)

The underlying intuition here is that in the presence of conflicts,
we should take the point of view that one of the sources is correct,
which leads to a disjunctive combination of conflicting evidence
and the requirement that B  C = A in the right-hand side of (15).

5. Using belief functions in geographic information retrieval

1, . . . , mx

By combining mx

k using either of the combination
operators, we obtain a single mass assignment mx summarizing
the available evidence about the location of x. In many cases,
some post-processing of this mass assignment will be needed
to obtain usable approximations of the location of x, e.g. in the
form of a precise point, a precise region (i.e a polygon), or a
fuzzy region (i.e. a nested set of polygons). Indeed, unlike simple
representations such as points and polygons, mass assignments
cannot readily be spatially indexed, which is a prerequisite
if we are to use georeferencing of photos to support online
location-based querying [1]. Moreover, mass assignments, unlike
probability distributions and fuzzy regions, cannot be visualized in
a way which is sufficiently intuitive for end users. How exactly xs
location should be represented in the result depends on the precise
requirements of the application context:
Supporting location-based queries Consider a user indicating an
interest in photos that were taken in Manhattan. In such
a case, we could simply use the mass assignment mx of
each photo x to calculate the belief or plausibility that
x was taken in Manhattan, the latter being represented
as a union of elements from A1. Similarly, if a user is
interested in photos that were taken in the vicinity of
a particular point-of-interest, we could determine the
belief or plausibility that each photo in the collection was
taken within a given radius of that point. When the mass
assignments have been converted to points (the most
likely location of x) or polygons (a confidence region for x)
that have been spatially indexed a priori, location-based
querying becomes computationally feasible.

Helping users georeference their photos When users upload a
photo to Flickr, they have the option to indicate on a
map where it was taken. When the user has already
provided a number of tags for the photo, it makes sense
to analyze these tags, and already zoom in on this
map at where the photo was likely taken. In this way,
less effort is required by the user, which may lead to
more users georeferencing their photos, with a higher
accuracy level. This application not only requires the
system to determine where to center the map, but also
to determine at which zoom level it should be shown.
This boils down, conceptually, to finding the smallest area
containing the true location of x with a given confidence
level, i.e. a confidence region for x.

Visualizing plausible locations In some applications, we may
simply provide the user with a visual summary of where
a photo was likely taken. One of the most obvious ways
to do this is by presenting a heat map, which may
conceptually be seen as a mapping from locations to
the unit interval [0,1], i.e. a possibility distribution [42]
of locations. This requires to determine an appropriate
approximation of mx.

It seems that from an application point of view, mass assignments are mainly useful (i) to find the most likely area, at a given
granularity level, in which the photo was taken, (ii) to find the most
fine-grained area that contains the true location of the photo at a
given confidence level, and (iii) to obtain a visual summary of the
plausible locations. These three uses are discussed below.

5.1. Finding the most plausible area

The probability distribution pi(|x) obtained by calibrating the
language models of the areas in Ai naturally allows us to determine
the most plausible area from Ai, viz. the area a maximizing pi(a|x).
The mass assignment mx has been obtained by combining pi with
other pieces of evidence (i.e. the probability distributions over the
other levels of granularity), and may thus allow us to determine the
most plausible location of Ai in a better-informed way. In general,
one could also think of combining pi with belief functions encoding
information from other sources of evidence such as gazetteers or
visual feature information to obtain mx. Obvious decision rules are
choosing the area a maximizing the belief measure and choosing
the area maximizing the plausibility measure:
chooseBel(Ai, mx) = arg max
aAi
choosePl(Ai, mx) = arg max
aAi

Bel(areas(a))

Pl(areas(a)).

(16)

(17)

A third decision rule uses the pignistic probability measure Px
induced by m:
chooseP (Ai, mx) = arg max
aAi

Px(areas(a))

(18)

5.2. Determining confidence regions

restrict ourselves to the areas in
view. Moreover, as the areas in

Rather than first fixing the granularity level and then determining the most plausible area, it often makes sense to look for the
smallest area that contains a given photo x with some predefined
confidence level, where confidence may be measured in terms of
belief, plausibility or pignistic probability. An important question
is which areas are to be considered for the result. Either we may
i Ai, or we may allow arbitrary
subsets of A1, possibly with the restriction that the chosen subset constitutes a connected (or even convex) region. The solution
which we have adopted in the experiments is based on the former
choice, which is considerably easier from a computational point of
i Ai have all been obtained from
clustering the training data, they likely correspond to meaningful
geographic entities. For instance, if all of the most plausible areas
from A1 are in Manhattan, it often makes more sense to use the entire region of Manhattan as result, rather than the disjoint union of
these specific areas within Manhattan. The situation where available information is ambiguous forms an exception to this view: if
all we know is that a photo was taken in Washington, it makes
sense to represent the result e.g. as the union of Washington DC
and Washington state.

The procedure to determine a confidence region then becomes
the following. First, we check whether our confidence in the most
likely area a from A1  determined e.g. using chooseP , chooseBel
or choosePl  is sufficiently high. This confidence could again be
measured in terms of pignistic probability, belief or plausibility.
If this is the case, region a is taken as the result. Otherwise, we
check whether our confidence in the most likely area from A2 is
sufficiently high, etc. If even our confidence in the most likely area
from Ak is too low, it seems reasonable to acknowledge that no
reliable location could be determined for the corresponding photo.

O. Van Laere et al. / Web Semantics: Science, Services and Agents on the World Wide Web 16 (2012) 1731

5.3. Approximation of mass assignments

Mass assignments have the disadvantage that they are difficult
to visualize, and they may require considerable amounts of storage
space (which may become problematic at the scale of billions of
Flickr images). Therefore, there is an interest in approximating
the mass assignments mx in a way that alleviates these issues,
without losing too much relevant information. Ideally, we want an
approximation of the mass assignment as a mapping from A1 to
[0, 1] (or some other scale), as such mappings are easy to visualize,
e.g. as a heat map. An obvious candidate would be to use the
pignistic probability. However, this still has the disadvantage that
a value must be stored for each element from A1. Here we present
an alternative solution, which uses possibility theory [42].
The main idea is to determine a nested family of areas B1 
B2    Bl  A1, such that B1, . . . , Bl correspond to
increasingly more cautious approximations of the location of the
photo x. They can be obtained by applying the procedure from
Section 5.2, using a (fixed) set of different thresholds on the
required confidence. In this way, all we have to store are the
l regions and the corresponding confidence values. To visualize
the mass assignment, we can then simply plot these areas, using
gray-scale values that depend on the confidence levels. Moreover,
the use of a small number of confidence regions also means
that standard spatial indexing methods can be used, e.g. when
implementing a system that needs to be able to retrieve all photos
that are located in a given area with a predefined confidence.
Note that the nested family B1    Bl can be seen as a
mapping  from A1 to [0, 1]:
 (a) = lmax

i=1

Bl+1i(a),


min

(19)

where we identify the sets Bi with their characteristic mapping
for the ease of presentation, i.e. we have Bi(a) = 1 iff a  Bi
and Bi(a) = 0 otherwise. The mapping  is called a possibility
distribution [42], and  (a) the degree of possibility that the correct
area is a. Where probability distribtutions can model variability
but not epistemic uncertainty, possibility distributions can model
epistemic uncertainty but not variability. A situation of complete
ignorance can be modeled as  (a) = 1 for all a  A1, whereas in
a completely informed situation we have  (a) = 1 for exactly one
a  A1 and  (a) = 0 for all other areas. In general, the degree
 (a) is interpreted as the degree to which one would be surprised
to learn that a is the real value of the considered variable, an
interpretation which at least goes back to the work of Shackle [43].
Like probability distributions, possibility distributions also
correspond to a special case of belief functions. To clarify this link,
first note that with each possibility distribution , two uncertainty
measures  and N can be associated, defined (in a universe U) by
 (X ) = sup
uU
N(X ) = 1   (U \ X ).
Intuitively,  (X ) corresponds to the degree to which it is
consistent with our beliefs to assume that the correct value is
among those in X, whereas N(X ) corresponds to the degree to
which this is implied by our beliefs. Now, let m be a mass
assignment whose focal elements constitute a nested family of
sets:   X1  X2    Xl  U. With the mass assignment m

we can associate the possibility distribution  defined by  (x) =
xXi m(Xi) = Pl({x}) [44]. Then we have that for any X  U, it
holds that Bel(X ) = N(X ) and Pl(X ) =  (X ). In general, a mass
assignment m can be approximated by a possibility distribution in
different ways. One approach is to still define  (x) = Pl({x}), in
which case  is called the contour function of m. A second approach
is to use a predefined family of nested sets, as we did in (19).

 (u)

Possibility distributions are not only useful for visualization.
Their graded nature makes them suitable representations for
modeling the boundaries of vague vernacular geographic regions
[9,7,45]. Such flexible boundaries could be obtained by georeferencing a virtual photo whose tags are the name of the region, and
the city and country in which it occurs. In fact, similar ideas have
already been proposed, but without making the links with possibility theory explicit. For instance, [46] proposes a method in which
spatial terms occurring on a web page are converted into polygons
and the overall relevance of that web page w.r.t. a given location
is calculated based on the number of polygons in which that location appears. However, seeing these polygons as the focal elements
of a mass assignment, this corresponds exactly to determining the
degree of plausibility of the considered location.

6. Evaluation

As the baseline of our experiments, we will consider the raw
probabilities that are produced by the language models (i.e. the
right-hand side of (1)). This baseline technique has been the
basis of a system with which we participated in the 2010 and
2011 editions of the MediaEval Placing Task competition, where
it was shown to compare favorably against other georeferencing
techniques [14,27]. This result confirms and strengthens earlier
support for using language models in this task [13].

The techniques that we propose in this paper aim at improving
the baseline in two different ways. First, by combining evidence
from different granularity levels, we can hope that better informed
decisions can be made about which is the most likely area at a given
granularity level (as was illustrated in Example 1). This means that
the DempsterShafer based techniques should allow us to obtain
a higher overall accuracy. Second, by calibrating the probabilities
and by combining evidence from different granularity levels, we
can also hope that more reliable confidence estimates are obtained.
Here, we are not interested in improving the overall accuracy, but
in determining which of the photos we can georeference in an
accurate way. This is important from an application point of view,
as clearly not all photos have sufficiently descriptive tags to allow
meaningful coordinates to be found. What we need then, is a way
of selecting a maximal set of photos such that at least, say 95% of
these photos is correctly georeferenced. Both goals are more or
less independent, in the sense that techniques which succeed in
improving the overall accuracy may not necessarily be best suited
to determine photos that are likely to be georeferenced correctly.
In the following, we analyze both goals.

6.1. Overall accuracy

Considering the first goal, Table 4 summarizes the overall
accuracies that are obtained at each of the 5 considered granularity
levels, for each of the considered methods. The line Probability
Raw contains the results that are obtained when using the
raw probabilities provided by the language models, and the
line ProbabilityCalibrated contains the results of using the
PAV algorithm to calibrate these probabilities as explained in
Section 3.2. As can be seen from the table, calibration leads to a
minor (but consistent) improvement in accuracy. This is somewhat
surprising, as the aim of calibration was not to obtain better
predictions but to obtain better confidence scores (in relation to
the second goal). It should be emphasized here that we used a
separate set for calibrating the probabilities, which did neither
overlap with the test set nor with the training set that was used
for training the language models. As such, in applying the PAV
algorithm, we may implicitly take the observation into account
that the probabilities for some areas are systematically too large

Table 4
Accuracy of the predictions at each of the five considered granularity levels.

ProbabilityRaw
ProbabilityCalibrated
BeliefDempster
PlausibilityDempster
Pign. prob.Dempster
BeliefYager
PlausibilityYager
Pign. prob.Yager
BeliefDuboisPrade
PlausibilityDuboisPrade
Pign. prob.DuboisPrade

Accuracy

or too small, and thus influence which area is considered to be the
most plausible one for a given photo.

Nonetheless, the improvement in accuracy that is witnessed
by applying the PAV algorithm is rather small. One of the main
reasons for applying this technique was that accurate probability
estimates were needed by the DempsterShafer method, to
compare the probabilities from language models at different
granularity levels. Table 4 shows the results that were obtained
using three different combination rules (Dempster (8)(9), Yager
(12)(14), and DuboisPrade (15)), each time considering three
different decision rules (based on belief (16), plausibility (17) and
pignistic probability (18)). For each of these 9 configurations, a
clear improvement is found over the results of the (calibrated)
language model probabilities. The difference is most pronounced
at the intermediate granularity levels. It appears that the language
models results for the coarsest granularity level are difficult
to improve, as (i) most of the incorrectly georeferenced photos
are simply not tagged in a sufficiently descriptive way (i.e. the
language model probabilities are nearly optimal), and (ii) there
is little evidence to be found at the finer granularity levels to
help make a decision at the coarsest level. Note that, at the
coarsest level, there are only 50 clusters for the entire world, hence
classification here basically amounts to finding the right country
for a photo. Conversely, the results for the finest granularity level
are also difficult to improve, which may be due to the same
two reasons. While many photos contain tags that allow us to
pinpoint the right city, finer predictions can often not be made.
Moreover, evidence from the coarser granularity levels is usually
not sufficiently specific to help make this decision. For the three
intermediate granularity levels, larger improvements are obtained.

Comparing the three combination rules in Table 4, we notice
that Dempster and Yager produce identical results when either
belief or plausibility is used as the decision rule. This was to be
expected, since Dempsters and Yagers rules only differ in how the
mass of the empty set is redistributed. As a result, the ranking of
areas according to their degree of belief or degree of plausibility
is unaltered. When using pignistic probability, however, some
changes may occur. Similarly, when using Dubois and Prades
combination rule, additional focal elements are introduced, which
may affect which area is considered to be the most plausible one
at a given granularity level. While Dubois and Prades rule leads
to similar results as Dempsters and Yagers, results of the latter
combination rules are slightly better. Concerning the decision rule,
pignistic probability was found to be slightly better when using
Dempsters rule, while belief was slightly better in combination
with Dubois and Prades rule. In most cases, using belief was also
the best choice in combination with Yagers rule.

Tables 5 and 6 provide an overview of these results in terms
of error distance between the estimated location for a photo and
its true location. These tables confirm the main conclusion from
Table 4: the use of DempsterShafer theory leads to a moderate,
but consistent improvement over the baseline, with larger gains
to be found at the intermediate levels. Tables 7 and 8 provide
an overview of the results for the same two methods in terms of
accuracy at a city level, local administrative unit (LAU) level and
country level. The ground truth information for this evaluation was
obtained by feeding the real coordinates to the Google Geocoding
API [47]. The Admin category in the tables corresponds to
the administrative_area_level_1 information provided by Google
(i.e. the first-level administrative divisions in a country, such as
provinces or states). As the administrative information could not
be determined for several photos in the test set and the medoids
of several clusters, for the evaluation in Tables 7 and 8, we have
excluded all photos from the test set for which we could not
determine the relevant information, as well as all photos which
were assigned to a cluster, by any of the methods at any of the
granularity levels, with a medoid for which we could not determine
the relevant information. This has led to a reduced test set of 32 748
test items (65.49% of the original test set). The results in Tables 7
and 8 are thus mainly meaningful relative to each other.

To gain a better insight into why the use of DempsterShafer
theory leads to improved results, we discuss two concrete
examples of photos in the test set, where it was needed to look at
evidence from other granularity levels to find the correct location.
Consider the upper example in Table 9. All the tags mentioned
in the example were retained at the coarsest granularity level
(50 areas). Using the raw probability, this photo was estimated to

Table 5
Percentage of photos for which the found location was within 1, 5, 10, 50, 100 and 1000 km of the true location, and the median distance on the error (in kilometers), when
using the raw probabilities (full test set).

Gran.

Median

Table 6
Percentage of photos for which the found location was within 1, 5, 10, 50, 100 and 1000 km of the true location, and the median distance on the error (in kilometers), when
using pignistic probabilities obtained from Dempsters combination rule (full test set).

Gran.

Median

O. Van Laere et al. / Web Semantics: Science, Services and Agents on the World Wide Web 16 (2012) 1731

Table 7
Percentage of photos for which the found location was within the correct city,
administrative region and country, when using the raw probabilities (restricted test
set).

Granularity

City

Admin

Country

Table 8
Percentage of photos for which the found location was within the correct city,
administrative region and country, when using pignistic probabilities obtained from
Dempsters combination rule (restricted test set).

Granularity

City

Admin

Country

Table 9
Example assignments of test photos by using ProbabilityRaw and Pign. prob.
Dempster.

Animal zoo wildlife straw colchester mandrill forage foraging

True location

Estimated location
(50 areas)

ProbabilityRaw
Pign. prob.Dempster
Sandals korea toji

True location

ProbabilityRaw
Pign. prob.Dempster

Estimated location
(2000 areas)
30.0665 51.2359

be in a cluster that represents the Northeast of the US, whereas
using the pignistic probability correctly assigned it to a cluster in
Western Europe. To find the location of this photos, mainly the
tags Colchester and zoo are important, as they clearly suggest that
the photo was taken in Colchester zoo in the UK. However, at the
coarse granularity level of 50 areas, the tag zoo will have very little
discriminative power, as most of the 50 clusters will contain the
location of several zoos. The term Colchester, however, will help to
find the right cluster, although it leads to an ambiguity: the area
containing the UK will definitely contain several occurrences of
this tag, but this is also true for the cluster containing the Northeast
of the US (which contains places called Colchester in VT, CT, NY and
IL). Without any further help to make the decision, the baseline
system incorrectly assigned the photo to the US. When looking at
the granularity level of 2000 levels, on the other hand, the location
becomes obvious: there is only one cluster with a substantial
number of occurrences of both zoo and Colchester (none of the
places called Colchester in the Northeast of the US has a zoo). The
DempsterShafer based methods are able to use this evidence from
the 2000 area level to find the correct cluster at the 50 area level.
The lower example in Table 9 is an illustration of the opposite
case, where coarser levels can help us to correctly assign a photo
to a cluster at the finer-grained levels. The example concerns
a photo taken in South Korea, which was mistakenly estimated
to be in Southern Brazil by the baseline, despite the occurrence
of the toponym tag korea and the apparent lack of ambiguity.
After inspecting the training data, we found that the error was
due to one cluster (at the 2000 area level) in Brazil with a
disproportionate number of occurrences of the tag toji, caused by
a large number of photos of one users cat named toji. This tag

turned out to be more discriminative than the term korea (which
occurs in several clusters within Korea), leading to an incorrect
decision. At the coarser levels, however, the tag korea becomes very
discriminative while the tag toji loses its importance. In this way,
the DempsterShafer based methods can using the evidence from
the coarser levels to avoid making the mistake at the finest level.

6.2. Confidence score reliability

We now turn to the second goal of trying to identify those
photos for which the predicted area is most likely to be correct.
Being able to identify the easy cases from the hard cases
assists an application in determining the action to be taken:
if the application has high confidence in its estimation, it will
georeference the photo at hand. Else, when confidence is low, the
application does not suggest the location of the photo. Preferably,
we want to have a system that is highly accurate in recognizing
the easy cases. Another way of viewing this task is that we
should determine for each photo individually, at which granularity
level it is best classified (cfr. the use cases that were outlined in
Sections 5.2 and 5.3). To illustrate this idea, consider the following
examples: In the case of a photo tagged with water wales boats
bay cardiff cardiffbay barrage, the tags unambiguously identify a
specific location at a fine granularity level, hence the system should
be quite confident in georeferencing such a photo. Secondly, a
photo tagged with france will not yield likely locations at the
finest granularity level, but at a coarser level of granularity (say,
a level at the scale of the European countries), it should become
very confident that the photo was taken in the area covering
France. Lastly, a photo tagged only with birthday abby clearly is a
hard case, which is impossible to georeference even for a human
assessor. To determine about which photos predictions we are
confident enough, we can put some threshold on the considered
confidence scores. These confidence scores may be probabilities
(raw or calibrated), degrees of belief, degrees of plausibility, and
pignistic probabilities. In the last three cases, the confidence scores
may be evaluated w.r.t. the combined mass assignments resulting
from either of the three considered combination rules. The choice
of the threshold value allows us to tune the trade-off between
having a higher accuracy and having more photos georeferenced.
To assess which method provides the most useful confidence
scores,
in Tables 1013 we show how many photos can be
georeferenced when a given level of accuracy is imposed.
Comparing the performance of the raw and calibrated probabilities
in Table 10, we can see that the calibrated probabilities perform
consistently better, with the improvement being largest for the
finest granularity levels and the highest accuracy thresholds. For
instance, at the finest granularity level (2000 clusters), 24% of
the photos can be georeferenced with 95% accuracy using the
calibrated probabilities, as opposed to only 14% when using the
raw probabilities. This means that e.g. if we allow the pignistic
probability method to choose 24% of the photos, which it thinks are
easiest to georeference, and only require it to georeference these
24%, it will assign a correct cluster to 95% of them. To interpret the
meaning of these results, consider an application which suggests a
location to users uploading and tagging photos on Flickr, as a way
to encourage more people to reveal location-based information,
e.g. by showing a map of where the system think the photo was
taken. As users will be annoyed if the system is wrong too often,
we may need to get it right in, say, 95% in the cases. As this is
not possible, by any method, in general (due to there being too
many photos with tags that do not reveal any location at all),
we can only accomplish this by only making a suggestion to the
user when we are confident enough that it is correct. So, given
the results in Table 10, and assuming that we want 95% of the
suggestions we make to be correct, we can only suggest a location

Table 13
Percentage of photos that can be classified at each level of granularity when a fixed
accuracy level is imposed (using Dubois and Prades rule of combination to combine
evidence from different granularity levels).
Acc. (%)

Percentage of photos

Table 10
Percentage of photos that can be classified at each level of granularity when a fixed
accuracy level is imposed (using the probabilities from the language models).

ProbabilityRaw

ProbabilityCalibrated

Acc. (%)

Percentage of photos

PlausibilityDuboisPrade

BeliefDuboisPrade

Table 11
Percentage of photos that can be classified at each level of granularity when a
fixed accuracy level is imposed (using Dempsters rule of combination to combine
evidence from different granularity levels).

Pign. prob.DuboisPrade

PlausibilityDempster

BeliefDempster

Pign. prob.Dempster

Acc. (%)

Percentage of photos

Table 12
Percentage of photos that can be classified at each level of granularity when a fixed
accuracy level is imposed (using Yagers rule of combination to combine evidence
from different granularity levels).
Acc. (%)

PlausibilityYager

BeliefYager

Pign. prob.Yager

Percentage of photos

in 14% of the cases when using raw probabilities, while we can do
it in 24% of the cases using calibrated probabilities. Note that this
improvement is mainly due to the better capabilities of the latter
method of distinguishing easy cases from hard cases, rather than
being (much) better at the actual task of georeferencing.

In Table 11, the results of using Dempsters combination rule are
presented. A marked improvement over the results from Table 10
can be seen, which is largest at the intermediary granularity levels
and the higher accuracy thresholds. For instance, at the third

Fig. 4. Comparing the trade-off between number of georeferenced photos and
accuracy for different combination rules, using pignistic probability and 50 clusters.

granularity level (500 clusters), using Dempsters combination rule
and the pignistic probability decision rule, 56% of the photos can be
georeferenced with 95% accuracy, as opposed to only 36% for the
calibrated probabilities and 34% for the raw probabilities. The best
results are found when using pignistic probabilities, although the
results for degrees of belief are almost identical and the results for
degrees of plausibility are similar in most of the cases. Tables 12
and 13 show the results for respectively Yagers rule and Dubois
and Prades rule. Overall, we may conclude that Dempsters rule
provides the best results, followed by Dubois and Prades rule, and
then Yagers rule.

A graphical view on the relation between the number of photos
that can be georeferenced and the resulting level of accuracy
is provided in Figs. 413. These figures provide a clear view
of the trade-off in applications between georeferencing a larger
percentage of all photos and maintaining a higher accuracy. All the
photos in the test set are ranked according to their confidence score
(i.e. pignistic probability, belief, or plausibility). As mentioned in
the introduction of Section 6.2, all the photos whose confidence
scores are above a certain threshold would be considered as the
easy cases. Specifically, for each number of photos n on the
X-axis, the accuracy of the n photos with the highest values
for this confidence score is reported. First, Figs. 48 compare
the performance of the three combination rules (using pignistic
probabilities), each time also displaying the results for raw and
calibrated probabilities. What is particularly noticeable is that

O. Van Laere et al. / Web Semantics: Science, Services and Agents on the World Wide Web 16 (2012) 1731

Fig. 5. Comparing the trade-off between number of georeferenced photos
and accuracy for different combination rules, using pignistic probability and
250 clusters.

Fig. 8. Comparing the trade-off between number of georeferenced photos
and accuracy for different combination rules, using pignistic probability and
2000 clusters.

Fig. 6. Comparing the trade-off between number of georeferenced photos
and accuracy for different combination rules, using pignistic probability and
500 clusters.

Fig. 9. Comparing the trade-off between number of georeferenced photos and
accuracy for different decision rules, using Dempsters combination rule and
50 clusters.

Fig. 7. Comparing the trade-off between number of georeferenced photos
and accuracy for different combination rules, using pignistic probability and
1000 clusters.

Fig. 10. Comparing the trade-off between number of georeferenced photos and
accuracy for different decision rules, using Dempsters combination rule and
250 clusters.

the use of calibrated probabilities does not improve the raw
probabilities at all for the coarser granularity levels, while at the
finest granularity level (Fig. 8), the calibrated probabilities are
essentially as good as the outcome of the DempsterShafer based
approaches. Overall, we can also see that the combination operator

being used does not affect the performance in a crucial way. Figs. 9
13 compare the performance of the three decision rules (using
Dempsters rule of combination). Here we can clearly see that
using degrees of belief or using pignistic probabilities does not
substantially change the result. Regarding degrees of plausibility,

be found. Indeed, plausibility degrees reflect the compatibility of a
given element with available evidence, rather than an amount of
support.

7. Related work

7.1. Finding locations of resources

Fig. 11. Comparing the trade-off between number of georeferenced photos and
accuracy for different decision rules, using Dempsters combination rule and
500 clusters.

Fig. 12. Comparing the trade-off between number of georeferenced photos and
accuracy for different decision rules, using Dempsters combination rule and
1000 clusters.

Fig. 13. Comparing the trade-off between number of georeferenced photos and
accuracy for different decision rules, using Dempsters combination rule and
2000 clusters.

the results are somewhat mixed. At the finer granularity levels and
the left-most part of the graphs, plausibility degrees perform even
worse than the baseline. In some sense, this is not surprising, as
the idea of plausibility degrees is somewhat at odds with the task
of finding those photos for which sufficient location evidence can

The task of deriving geographic coordinates for photos has
recently gained popularity (see e.g. [14]). However, to the best
of our knowledge, the idea of combining evidence from different
granularity levels and the related problem of finding the most
appropriate granularity level for a given photo have not been
previously considered. In the context of geographic information
systems, on the other hand, it is well known that different scales
may yield different effects on the spatial and thematic resolution
of geographic data [11] (e.g. monitoring the earths surface using
satellites with different resolutions).

Most existing approaches are based on clustering, in one way
or another, to convert the task into a classification problem. For
instance, in [22] target locations are determined using mean shift
clustering, a non-parametric clustering technique from the field of
image segmentation. The advantage of this clustering method is
that an optimal number of clusters is determined automatically,
requiring only an estimate of the scale of interest. Specifically,
to find good locations, the difference is calculated between the
density of photos at a given location and a weighted mean of
the densities in the area surrounding that location. To assign
locations to new images, both visual (keypoints) and textual (tags)
features were used. Experiments were carried out on a sample
of over 30 million images, using both Bayesian classifiers and
linear support vector machines, with slightly better results for the
latter. Two different resolutions were considered corresponding
to approximately 100 km (finding the correct metropolitan area)
and 100 m (finding the correct landmark). It was found that
visual features, when combined with textual features, substantially
improve accuracy in the case of landmarks. In [48], an approach is
presented which is based purely on visual features. For each new
photo, the 120 most similar photos with known coordinates are
determined. This weighted set of 120 locations is then interpreted
as an estimate of a probability distribution, whose mode is
determined using mean-shift clustering. The resulting value is used
as prediction of the images location.

The idea that when georeferencing images, the spatial distribution of the classes (areas) could be utilized to improve accuracy has
already been suggested in [13]. Their starting point is that typically
not only the correct area will receive a high probability, but also the
areas surrounding the correct area. Indeed, the expected distribution of tags in these areas will typically be quite similar. Hence, if
some area a receives a high score, and all of the areas surrounding
a also receive a relatively high score, we can be more confident in a
being approximately correct than when all the areas surrounding
a receive a low score. Motivated by this intuition, [13] proposes to
smooth P(a|x) as follows (using a uniform prior):
P(x|b)

P(a|x)  P(x|a) + (1  )  

(2d + 1)2  1

bneighd(a)

where d > 0 and neighd(a) is the set of all areas that are within
distance d of a.

Some Flickr tags are intuitively more important than others
in determining the location of a photo. Toponyms in particular
are by definition indicative of geographic location. One way
of recognizing toponyms is by looking for so-called comma-
groups. These are groups of words that are comma-separated,
e.g. San Francisco, California, USA. In this example, there is a

O. Van Laere et al. / Web Semantics: Science, Services and Agents on the World Wide Web 16 (2012) 1731

clear relationship between the comma-separated values, as San
Francisco is a city, located in the state of California, which is in turn
one of the states of the USA. As a result, resolution of the toponyms
represented by this group reveals an unambiguous geographical
reference. Resolution of such comma-groups has been studied by
Lieberman in [49].

In addition to georeferencing Flickr photos, several authors
have recently focused on finding the location of other web
resources such as Twitter posts or Wikipedia pages. For instance,
in [50], a probabilistic framework based on maximum likelihood
estimation was used to estimate the location of users based on
the content of their tweets. In particular, a generative probabilistic
model proposed in [51] is used to determine words with a
geographic scope within a tweet, and a form of neighborhood
smoothing is employed to refine the estimations. For 51% of
the users, a location was obtained that is within a 100 mile
radius of their true location. Next, [52] looked into georeferencing
Wikipedia articles as well as Twitter posts. After laying out a grid
over the earths surface (in a way similar to [1]), for each grid cell
a generative language model is estimated. To assign a test item
to a grid cell, its KullbackLeibler divergence with the language
models of each of the cells is calculated. In [53], it was shown how
Wikipedia pages can be georeferenced using language models that
are trained from Flickr, taking the view that the relative sparsity
of georeferenced Wikipedia pages does not allow for sufficiently
accurate language models to be trained, especially at finer levels of
granularity.

Interestingly, some recent language modeling approaches have
combined the idea of topic models with location-dependent language models. For instance, [28] proposes geographic topic models with the aim of simultaneously capturing linguistic variation
across different regions and different topics.

7.2. Using locations of resources

When available, the coordinates of a photo may be used in
various ways. In [54], for instance, coordinates of tagged photos
are used to find representative textual descriptions of different
areas of the world. These descriptions are then put on a map to
assist users in finding images that were taken in a given location
of interest. Their approach is based on spatially clustering a set of
geotagged Flickr images, using k-means, and then relying on (an
adaptation of) tf-idf weighting to find the most prominent tags
of a given area. Similarly, [55] looks at the problem of suggesting
useful tags, based on available coordinates. The relevance of a given
tag is measured in terms of the number of users that have used it
to describe photos located within a certain radius of the current
photos coordinates. A refinement of this method only looks at tags
that occur with visually similar photos, which is shown to improve
the quality of the proposed tags. Some authors have looked at
using geographic information to help diversify image retrieval
results [56,57]. Finally, in [58] GeoSR is presented as a way of
measuring the semantic relatedness of Wikipedia articles based on
their geographic context, allowing users to explore information in
Wikipedia that is relevant to a particular location.

Geotagged photos are also useful from a geographic perspec-
tive, to better understand how people refer to places, and overcome the limitations and/or costs of existing mapping techniques
[59]. For instance, by analyzing the tags of georeferenced pho-
tos, Hollenstein [60] found that the city toponym was by far the
most essential reference type for specific locations. Moreover, [60]
provides evidence suggesting that the average user has a rather
distinct idea of specific places, their location and extent. Despite
this tagging behavior, Hollenstein concluded that the data available in the Flickr database meets the requirements to generate spatial footprints at a sub-city level. Finding such footprints

for non-administrative regions (i.e. regions without officially defined boundaries) using georeferenced resources has also been addressed in [9,6]. Another problem of interest is the automated
discovery of which names (or tags) correspond to places. Especially for vernacular place names, which typically do not appear
in gazetteers, collaborative tagging-based systems may be a rich
source of information. In [61], methods based on burst-analysis are
proposed for extracting place names from Flickr. Finally, note that
to some extent, even without geographic coordinates, ontologies,
and in particular ontologies of places may be derived from Flickr
tags [62].

7.3. Evidence theory

Various authors have investigated the use of DempsterShafer
theory for combining the results of different classifiers [6366].
However, the aim of using DempsterShafer theory in this context
is quite different from our aim in this paper. Specifically, these
methods mainly use DempsterShafer theory for its ability to
represent partial ignorance. For instance, if a given classifier
m(C) = 1 
assigns a probability pi to each class ci, a belief function may be
constructed by choosing m({ci}) = fi for some fi < pi, and
The value 1 
i fi, for C = {c1, . . . , cn} the set of all classes.
i fi can then intuitively be interpreted in terms
of confidence in the associated classifier. Note also that all focal
elements are then either singletons or the universe, which makes
DempsterShafer theory sufficiently scalable to deal with large
numbers of classes, although sometimes focal elements of the form
C \ {ci} are also used.
DempsterShafer theory has also been widely considered for
dealing with the imperfection of real-world geographic informa-
tion; [67] provides a survey on works using DempsterShafer theory in a GIS setting. More generally, we refer to [68] for an overview
of different frameworks for handling uncertainty, applied to spatial
information.

8. Conclusions

We have proposed an approach to georeferencing Flickr photos which combines the evidence provided by different language
models using DempsterShafer evidence theory. As these language
models were trained at different granularity levels, they provide
complementary views on the georeferencing process, and implicitly add a spatial dimension to the language models.

The core idea of our approach is to see a probability distribution over coarse areas as a probability distribution over sets of
fine-grained areas. Noting that this latter probability distribution corresponds to the notion of a mass assignment from DempsterShafer theory, we can connect to the vast amount of work that
has already been done on combining evidence. In particular, we
have experimented with three well-known combination rules, due
to Dempster, Yager, and Dubois and Prade respectively.

After the evidence from the language models has been com-
bined, we end up with a mass assignment that summarizes all
available evidence about the location of a given photo. This mass
assignment may then be used in different ways: we may use it
to select the most likely area at a given granularity level, we may
determine the smallest area that contains the true location of the
photo with a predefined certainty, or we may simply visualize the
evidence after approximating the mass assignment to a possibility
distribution. In our experiments, we have focused on the first two
of these tasks, as the quality of visual representations is difficult
to quantify. In both cases, we have found that our evidence-based
approach considerably improves the performance of individual
