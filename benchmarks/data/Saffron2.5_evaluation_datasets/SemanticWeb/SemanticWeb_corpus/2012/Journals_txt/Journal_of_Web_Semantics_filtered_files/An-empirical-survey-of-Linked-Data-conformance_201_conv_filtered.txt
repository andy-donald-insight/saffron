Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

Contents lists available at SciVerse ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

journal homepage: www.elsevier.com/locate/websem

An empirical survey of Linked Data conformance
Aidan Hogan a,, Jurgen Umbrich a, Andreas Harth b, Richard Cyganiak a, Axel Polleres c, Stefan Decker a

a Digital Enterprise Research Institute, National University of Ireland, Galway, Ireland
b AIFB, Karlsruhe Institute of Technology, Germany
c Siemens AG Osterreich, Siemensstrasse 90, 1210 Vienna, Austria

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 8 March 2011
Received in revised form
3 September 2011
Accepted 27 February 2012
Available online 2 April 2012

Keywords:
Linked Data
Web of data
Semantic web
Rdf
Web

1. Introduction

There has been a recent, tangible growth in RDF published on the Web in accordance with the Linked
Data principles and best practices, the result of which has been dubbed the Web of Data. Linked Data
guidelines are designed to facilitate ad hoc re-use and integration of conformant structured data  across
the Web  by consumer applications; however, thus far, systems have yet to emerge that convincingly
demonstrate the potential applications for consuming currently available Linked Data. Herein, we compile
a list of fourteen concrete guidelines as given in the How to Publish Linked Data on the Web tutorial.
Thereafter, we evaluate conformance of current RDF data providers with respect to these guidelines. Our
evaluation is based on quantitative empirical analyses of a crawl of 4 million RDF/XML documents
constituting over 1 billion quadruples, where we also look at the stability of hosted documents for a
corpus consisting of nine monthly snapshots from a sample of 151 thousand documents. Backed by our
empirical survey, we provide insights into the current level of conformance with respect to various Linked
Data guidelines, enumerating lists of the most (non-)conformant data providers. We show that certain
guidelines are broadly adhered to (esp. use HTTP URIs, keep URIs stable), whilst others are commonly
overlooked (esp. provide licencing and human-readable meta-data). We also compare PageRank scores for
the data-providers and their conformance to Linked Data guidelines, showing that both factors negatively
correlate for guidelines restricting the use of RDF features, while positively correlating for guidelines
encouraging external linkage and vocabulary re-use. Finally, we present a summary of conformance for
the different guidelines, and present the top-ranked data providers in terms of a combined PageRank and
Linked Data conformance score.

 2012 Elsevier B.V. All rights reserved.

As a means of promoting grass-roots adoption of Semantic Web
standards, the Linked Data community [1] has advocated a set
of best principles for collaboratively publishing and interlinking
structured data over the Web, as follows (here paraphrasing [2]):
(i) use URIs as names for things;
(ii) use HTTP URIs so those names can be looked up (aka.

dereferencing);

(iii) return useful information upon lookup of those URIs (esp. RDF);
(iv) include links by using URIs that dereference to remote

documents.
As such, the Linked Data community encourage those who
wish to disseminate structured data on the Web to do so in an

 Corresponding author.

E-mail addresses: aidan.hogan@deri.org (A. Hogan), juergen.umbrich@deri.org

(J. Umbrich), harth@kit.edu (A. Harth), richard.cyganiak@deri.org (R. Cyganiak),
axel.polleres@siemens.com (A. Polleres), stefan.decker@deri.org (S. Decker).

1570-8268/$  see front matter  2012 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2012.02.001

interoperable manner using the Semantic Web standards. Thus,
Linked Data can be seen as a bottom-up approach to Semantic Web
adoptionin particular, this bottom-up philosophy is epitomised
by the five-star Linked Data scheme for Web publishing (here
paraphrasing [2]):

Publish under an open licence
Publish structured data
Use non-proprietary formats
Use URIs to identify things
Link your data to other data.

By promoting an accessible message to the wider Web
community, Linked Data has enjoyed increasing adoption over
the past four years. In 2007, the W3C Linking Open Data
project began publishing legacy Web corpora under Linked Data
principles. This resulted in rich datasets, most prominently the
DBpedia [3] corpus extracted from semi-structured WikipediA
articles. Thereafter, Linked Data adoption spread to various

corporate entities, with, e.g., the BBC [4],1 Thompson Reuters,2 and
the New York Times3 joining the effort and exposing information
as Linked Data. More recently, various governmental agencies [5]
have begun disseminating various public corpora as Linked
Data, beginning with commitments from the US [6]4 and UK
governments [7],5 and spreading to various other governmental
bodies.

Taken together, these (varyingly) interlinked RDF corpora have
resulted in a burgeoning, heterogeneous Web of Data built
using Semantic Web standards and augmented with Linked Data
principles. Thereafter, various claims have been made about the
potential for new applications that can operate over this global
data space; Bizer et al. envisage the following scenario(s):

This Web of Data enables new types of applications. There are
generic Linked Data browsers which allow users to start browsing
in one data source and then navigate along links into related
data sources. There are Linked Data search engines that crawl
the Web of Data by following links between data sources and
provide expressive query capabilities over aggregated data, similar
to how a local database is queried today. [...] Unlike Web 2.0
mashups which work against a fixed set of data sources, Linked
Data applications operate on top of an unbound, global data space.
This enables them to deliver more complete answers as new data
sources appear on the Web.[1, Section 1]

However, although (i) a number of generic web-based browsers
have emerged for Linked Data (e.g., Disco6, Marbles7, Tabulator [8],
Zitgist8, etc.) and (ii) various warehouses have been proposed
to operate over Linked Data from arbitrary domains (e.g., FactForge [9], Falcons [10], Sindice [11], Sig.ma [12], Swoogle [13],
SWSE [14], Watson [15], etc.), the above stated vision has yet to
be entirely realised.

From our experience on the SWSE project [14]  and also in the
Pedantic Web group [16]9  we have found that (unsurprisingly)
RDF data on the Web is of varying quality. Aside from concrete
issues of noise [16], oftentimes data are modelled in a manner that
is not facilitative to generic consumption: for example, common
properties for labels are not re-used, properties and classes are
invented and not defined, insufficient links are given to enable data
discovery, etc. Such issues are something which, according to the
above quote, the Linked Data guidelines aim to address.

In general, we currently see a lack of work addressing the issue
of quality for Linked Data on the Web. Although a quantitative,
objective, consumer-agnostic and universal measure of quality for
Linked Data is probably unachievable, in this paper, we focus on
the conformance of data providers with respect to Linked Data
guidelines.

Along these lines, we extract and present a list of fourteen
concrete recommendations from the How to Publish Linked
Data on the Web [17] tutorial, prominently featured on the
central linkeddata.org site. We discuss the importance of
these recommendations, particularly in the light of consumer
applications that intend to operate over the data. In particular, we
currently focus on recommendations (i) that are targeted at the

1 http://www.bbc.co.uk/blogs/bbcinternet/2010/02/case_study_use_of_
semantic_web.html ; retr. 2011/02/21.
2 http://www.opencalais.com/; retr. 2011/02/21.
3 http://data.nytimes.com/; retr. 2011/02/21.
4 http://www.data.gov/; retr. 2011/09/01.
5 http://data.gov.uk/; retr. 2011/09/01.
6 http://www4.wiwiss.fu-berlin.de/bizer/ng4j/disco/; retr. 2011/09/01.
7 http://marbles.sourceforge.net/; retr. 2011/09/01.
8 http://dataviewer.zitgist.com/; retr. 2011/09/01.
9 http://pedantic-web.org/; retr. 2011/09/01.

provision and maintenance of instance data as opposed to the
provision and maintenance of vocabularies, and (ii) for which we
can design straightforward, quantitative analyses.

In terms of experimentation and analysis, we propose a set of
measures that can be used to quantify conformance with respect
to each guideline highlighted. We then take a large corpus of
RDF Web data, consisting of 1.1 billion facts collected from 4
million RDF/XML documents by means of a breadth-first, opendomain crawl conducted in May 2010, and apply our measures
to the data providers involved. We also contrast and compare the
PageRank scores of data providers and their conformance with
respect to different guidelines. Finally, we compare results for
different guidelines, and look at aggregate scores that give insights
into the overall landscape of Linked Data (non-)conformance.

The rest of the paper is structured as follows:

(i) we discuss related literature in the area of analyses of RDF

Web data (Section 2);

(ii) we present core preliminaries and notation (Section 3);
(iii) we describe the corpora used for our study (Section 4);
(iv) we enumerate fourteen Linked Data guidelines (Section 5),

where for each we present:
(a) description of the guideline,
(b) motivation for the guideline,
(c) analysis of conformance in our corpora, and
(d) critical discussion of the analysis;

(v) we present analysis of the PageRank scores of providers, and

contrast with conformance (Section 6);

(vi) we summarise, aggregate and discuss our empirical analyses

for all issues (Section 7);

(vii) we discuss our results and conclude (Sections 89).

2. Background and related work

Empirical surveys of RDF Web data are important to generate
feedback on current developments and to guide future developments for the Semantic Web and Linked Data. This papers contribution to the area centres around analysis of conformance with
respect to Linked Data publishing guidelines. However, in this sec-
tion, we provide a comprehensive survey of the research literature
concerning empirical analyses of RDF Web data that goes beyond
our specific focus and covers the broader background, including:
(i) analyses that generally characterise the Semantic Web/Linked

(ii) works that focus on the link structure inherent in published

Data (Section 2.1);

RDF (Section 2.2);

(iii) works that analyse the semantics of such data (Section 2.3);
(iv) miscellaneous/specialised studies (Section 2.4);
(v) studies of coverage and use (Section 2.5); and
(vi) analyses focused on concrete issues of RDF data quality

(Section 2.6).

2.1. General analyses

Various authors have tried to broadly characterise the Semantic
Web down through the years. These analyses now constitute
chronological snapshots of the nature of RDF data on the Web at
different times.

In 2005, Ding et al. [18] presented one of the earliest analyses
of RDF data published on the Web. They collected over 1.5
million RDF/XML documents from the Web and reported about the
prevalence of use of various namespaces and properties therein,
where the bulk of data were described in the Friend of a Friend
(FOAF) and Dublin Core (DC) vocabularies. As opposed to lowvolume auto-biographical FOAF profiles, they found that the most
prevalent source of RDF data on the Web at that time was

A. Hogan et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

given by FOAF social networks, such as livejournal.com,
deadjournal.com, ecademy.com, etc. Further experiments
included calculating connected components in the FOAF social
network and detecting groups on a subset of 7 thousand FOAF
files. They detected various forms of Zipf distributions, such as the
number of persons described in each Web document, the number
of aliases found per person (found through sharing key values for
foaf:mbox_sha1sum property), etc.

Roughly a year later, Ding and Finin [19] again looked to
characterise the amount of Semantic Web data on the Web.
Using search results sizes reported by Google, they estimated the
number of RDF documents on the Web at that time to be in the
range of 107109. Analysing a dataset of 1.4 million RDF sources
from 2006  again mostly consisting of FOAF with some RSS 1.0
feeds  they presented various statistics relating to the largest
providers, document sizes, last-modified dates, etc. Furthermore,
they identified that, e.g., a large fraction of defined classes (>97%)
had no instances in their data, and that the majority (more than
>70%) of properties are never used. In many cases, the derived
statistics follow power law distributions. Towards the end of the
paper, they provide some prescient discussion about whether or
not the traditional monolithic ontology makes sense for the Web,
noting:

Recent work [...] argues against large, monolithic ontologies in
favour of having many interconnected components. We might even
eliminate namespaces as boundaries. For example, the Dublin Core
Element ontology has been widely used together with terms from
many other semantic web ontologies.

As we will see later, the emerging trends they remark upon (inter-
connected, lightweight vocabularies and mixing namespaces) are
now central aspects of Linked Data. They also note issues relating
to identity and accessibility, which are currently core themes in
Linked Data.

Skipping forward to 2008, when Linked Data was gaining a
strong foothold on the Web, Hausenblas et al. [20] attempted
to empirically gauge the size of
the Semantic Web. They
differentiate data into schema level data, and instance level
data, where the latter is further split into single-point-of-access
datasets (e.g., high-volume publishers) and distributed datasets
(e.g., decentralised FOAF files, SIOC descriptions [21], etc.). For
the single-point-of-access datasets, they report on the number of
triples made available, the level of external linkage, and build a
(directed, labelled, weighted) graph of interconnections between
the different data providers. They also crawled documents from
the decentralised datasets, showing that, e.g., FOAF data was well
interlinked within itself, but poorly linked to external datasets.
Although no definitive results are given on the effective size of
the Semantic Web at that time (informally, a lower bound of
two billion triples was established, which we believe to be very
conservative), the main conclusion was that more emphasis should
be placed on interlinking the datasets.

Various authors have presented unpublished works analysing
different Billion Triple Challenge (BTC) corpora down through
the years. Most recently, Grimnes [22] provided a detailed
analysis of the BTC-201010 dataset. The dataset consists of 3.172
billion statements, representing 1.441 billion unique triples,
collected from 8.1 million sources. Grimnes presents a variety
of statistics, including triple distributions for subject, predicate
and object terms, documents, class memberships, etc. Analysing
namespaces, he found that FOAF-related data still contributed
the bulk of the corpus, but where new Linked Data domains
(particularly data.gov related initiatives), and new vocabularies
(e.g., GoodRelations data [23]) were also contributing heavily.

10 http://km.aifb.kit.edu/projects/btc-2010/; retr. 2011/08/21.

2.2. Link-structure analyses

As per the previous remarks of Hausenblas et al., an important
aspect of the Semantic Web  and of the Web in general  is the
interlinkage of content, and the graph structure embodied by those
links.

The work of Ge et al. [24] reports experimental results on
analysing the complex network structure of the object link graphs
(i.e., the RDF data graph) constructed from two large datasets:
11.7 million RDF documents crawled in 2008 and 21.6 million
RDF documents crawled in 2009. Both datasets are crawled by the
Falcon-S search engine. Their statistics contain the distribution
of the number of hosts versus number of documents, and graph
invariants such as degree distribution and connectivity. For the
2009 dataset, excluding single non-linked vertices, they find 813
thousand strongly connected components in the graph, where
88.1% of resources are contained in the largest thereof. They
estimated the effective diameter of the graph to be 11.5,
indicating the longest (shortest) path between two vertices:
i.e., 11.5 is roughly the maximum length walk needed to get
from one node to another, taking the shortest route. Comparison
between the 2008 and 2009 datasets shows that interlinkage
improves slightly.

Josyln et al. look again at the BTC-2010 corpus [25]. Although
their work focuses on scalable processing of data using a
Cray XMT supercomputing platform, they derive and present
an array of useful statistics from the corpus that include:
top subjects, predicates and objects; top edge types and node
types they connect; top link types; link type bi-grams and trigrams (i.e., predicate paths of length two and three), as well
as connected components and typed paths. They found 208.3
thousand connected components in the RDF graph constituted by
the corpus, with the largest component containing 99.8% of the
total number of vertices; the discrepancy with Ge et al.s result
is probably due to different sampling techniques for the empirical
corpora.

Gueret et al. [26] also look at BTC-2010, but instead measure
what they call
robustness via infrastructure analysis and
semantic network analysis, and propose measures for improving
the Web of Data; their notion of robustness relates to the
reachability of macro-components on the Semantic Web in the
case of domains going offline. They derive a hostname graph
and a namespace graph from the BTC corpus, and calculate
several network measures over those graphs, such as degree
distribution and betweenness centrality (which they see as a proxy
for robustness). They devise methods to improve the robustness of
the Web of Data that aim to minimise the graphs centrality index
with the fewest links possible; for this, they propose using a Jaccard
distance measure based on vocabulary overlap as a cost function.
A qualitative analysis revealed that as much as 80% of the triples
do not link to external URIs but refer to either site-internal links,
blank nodes or literals. The analysed networks show an extreme
distribution and have a brittle structure; much of the connectivity
is provided via three central domains (xmlns.com, dbpedia.org
and purl.org).

2.3. Semantic analyses

Another important aspect of the Semantic Web is, of course,
semantics. Various empirical studies down through the years have
looked at the use of the RDFS and OWL standards in RDF Web data.
On an instance-level, some studies have specifically investigated
the use of the owl:sameAs relation on the Web, which is used
to relate two coreferent resources that talk about the same realworld thing (also known as URI aliases [17,27]). On a schema-level,
other studies have looked at how RDFS and OWL are used to define

the semantics of classes and properties appearing in various Web
vocabularies and ontologies.

Recent works by Ding et al. [28] discuss the use of owl:sameAs
for linking URI aliases and retrieving additional data during
crawling. They also discuss quality issues arising when using
owl:sameAs statements from the Web indiscriminately; in
particular, they raise concerns about the symmetric semantics of
owl:sameAs links across domains, and about the relaxed use
of owl:sameAs. In another 2010 paper, Ding et al. [29] return
to this issue, providing quantitative analysis of the owl:sameAs
graph extracted from the BTC-2010 dataset. They found that URIs
with at least one alias had an average of 2.4 aliases (i.e., the
average does not include URIs not in the owl:sameAs graph). The
average path length was 1.07, indicating that few transitive aliases
are given. They also summarise owl:sameAs linkage between
different publishers of Linked Data.

In a similar vein, Halpin and Hayes [30] and Halpin et al. [31]
investigate the incorrect use of owl:sameAs. Taking an initial
set of 58 million owl:sameAs triples extracted from 1202 Linked
Data domains, they present the top providers of such links, and a
distribution of links-per-domain. They then employ four human
judges to manually inspect 500 links sampled (using logarithmic
weights for each domain) from the full corpus. Their experiments
found that approximately 51% (21%) of owl:sameAs relations
were deemed correct: the level of disagreement observed amongst
the human judges indicates that coreference between URI aliases
is inherently subjective [31]; the authors also note that the RDF
descriptions of the aliases were deemed insufficient to make a
meaningful judgement in 27% (19%) of cases.

In a recent paper, we looked more generally at the issue of
equality for Linked Data, analysing not only owl:sameAs, but also
use of OWL features that allow for inference thereof [32], including
inverse-functional properties, functional properties, etc. Surveying
the (closure of explicit) owl:sameAs relations in the same corpus
used herein, we found that URIs with at least one alias had an
average of 2.65 aliases, with the largest set containing over eight
thousand aliases (due to incorrect owl:sameAs linkage of online
drugs data). We also found that 57% of alias groups contained URIs
from more than one domain. Based on our manual evaluation of
a sample of one thousand alias pairs, we estimated the accuracy
to be 97.2% (much more encouraging than the results of Halpin
et al. [31], although many of our results were deemed trivially
correct if there was not enough information to suggest otherwise).
We also investigated implicit owl:sameAs relations, where most
were found through reasoning over inverse-functional properties,
but where the vast bulk of additional aliases involved blank nodes
within the same domain (accuracy remained stable at 97.7%).

A recent paper by Mallea at al. [33] discusses the semantics of
blank nodes and presents an empirical study of their use in RDF
Web data. Although some high-volume publishers export huge
amounts of blank nodes in absolute terms, the average use of
blank nodes (vs. unique literal or URI terms) across domains was
measured as 7.5%, which decreased to 6.1% when only considering
domains appearing in the LOD Cloud diagram.11 Further empirical
analysis of the graph-structures formed by blank nodes (where two
blank nodes are linked by appearing in the subject and object of the
same triple) indicates that 98% of the time, such graphs form trees:
the implication is that simple entailment [34] over blank nodes is
often tractable in practice despite being NP-complete in theory.

On a schema-level, various works have looked at the expressivity of ontologies on the Web [3537]; these results are somewhat
tangential to the focus of this paper, but show that restrictions laid
out in the OWL standard (specifically for the OWL Lite and OWL DL

11 http://lod-cloud.net/; retr. 2012/01/11.

dialects) are not well-followed by Web ontologies, but that such
ontologies are typically relatively inexpressive. In previous works,
we analysed the use of RDFS and OWL in top-ranked vocabularies extracted from an RDF Web crawl (the same as used later); we
found that RDFS features were the most prominently used, with
OWL (1) features not requiring blank nodes to serialise in RDF also
finding use in prominent vocabularies [38].

More recently, Cheng et al. [39] performed a study of 2996 Web
vocabularies, spanning 261 pay-level-domains, finding 396023
classes and 59868 properties. Approximately 72% of vocabularies
were found to contain no more than 25 terms. Taking a
further 15 million instance documents, the authors investigate
indicators of relatedness between vocabularies, measured with
respect to how terms are defined, textual content of vocabularies,
explicit interlinkage, and co-occurrence in instance documents.
Some resulting high-level conclusions note that various related
vocabularies are not interlinked, but that interlinked vocabularies
often tend to be co-instantiated in the same documents.

2.4. Miscellaneous analyses

Motivated by certain observations or use-cases, a number of
specialised analyses of the Semantic Web (esp. Linked Data) have
been presented in the literature.

Hartig [40] discusses various issues relating to notions of provenance and the provision of document meta-data. In particular,
he provides discussion on current provenance-related properties appearing in popular Linked Data vocabularies. Thereafter
 and based on information extracted from Ping-the-Semantic-
Web and Sindice  he presents a survey of the approximate number of documents using each of the provenance-related proper-
ties, where, of the vocabularies and properties surveyed, DC (esp.
dcterms:created indicating the date of creation) and FOAF
terms (esp. foaf:maker indicating an author of the document)
were the most prevalently encountered.

Umbrich et al. [41] studied the changes in content of a total of
550 thousand RDF/XML documents crawled from the Web over
a period of 24 weeks in 2008. They showed that the Etag and
Last-modified HTTP header fields  which typically indicate
the date the document being served was last updated  were
not provided in 67.95% of the documents. Thereafter, surveying
the content of the documents, they ascertained that 62% of
documents remained static over the 24 weeks, whereas 69% of
entity descriptions also remained static. Of the documents that did
change, 59% were estimated to change at a rate of 1224 weeks,
23% at a rate of 412 weeks, 9% at a rate of 14 weeks, and 9% at
a rate of <1 week. However, the authors admit that the empirical
corpus used was insufficient to derive any concrete, fine-grained
conclusions on the dynamicity of RDF Web data, but instead could
only offer insights into the approximate level of change.

2.5. Usage-based analyses

We have seen that  starting from at least 2004/05 with
FOAF, RSS 1.0 and DC data  there has long been a large base of
interlinked RDF documents on the Web. Early use-cases for search
over Semantic Web data typically centred around domain-specific
ontologies created by academia, and/or hand-crafted FOAF files
created by hobbyists, and/or bespoke RDF converted from dumps
of legacy structured data [13,15,14,42]. In more recent years, the
diversity and volume of RDF Web data has expanded significantly
under the banner of Linked Data publishing. Given all of this
openly available, interlinked, semantic RDF content, the pertinent
question is then: what can it be used for?

The overall goal of a 2009 study by Halpin [43,44] was to
determine if content on the Semantic Web is potentially of

A. Hogan et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

interest to the average Web user, and what the coverage of
general-interest topics is like; he identifies two categories, first
generation content characterised by FOAF social networks, RSS
1.0, etc., and second generation content characterised by Linked
Data publishing. Halpin acquired a set of 15 million (6.6 million
unique) real-world keyword queries from the Microsoft Live search
engine, from which, 7.8 thousand unique entity queries (e.g., entity
names) and 5.3 thousand unique concept queries (e.g., class names)
with more than ten occurrences were extracted. These keyword
queries were run against the Falcon-S search engine [10]  which
indexes large crawls of RDF Web data  where the results showed
that searches either returned a great many results, or none at
all. Interestingly, he found that there was no correlation between
results sizes and the popularity of the input keyword query,
suggesting that a mismatch between the transient nature of Web
search and the static nature of RDF data was a possible cause. Many
results came from the (second generation) DBpedia domain [3].
Analysis suggested that the spread of results over the different
domains ostensibly followed a power-law, but the distribution
was ultimately found to have an insignificant fit, possibly because
the amount of RDF data published by very large domains greatly
outweighs smaller, bespoke publishing. Similar observations of
poorly-fitting power laws in the analysis suggest (to us) that RDF
data on the Web is still not mature enough to exhibit true powerlaw distributions. Other results presented in the paper looked at
the RDF(S) and OWL features, also discussing the issue of identity
where concern were raised about the lack of owl:sameAs links to
model URI aliases.

In another 2009 paper, Mika et al. [45] tackle a similar issue
that they call the Semantic Gap, viz., the divide between the
supply of data on the Semantic Web and the demand of typical
Web users. However, given that their study is centred around
the Yahoo! search engine index (which does not index RDF/XML),
they focus on analysing structured data embedded in *HTML
documents, such as RDFa, eRDF and Microformats. Although they
show that RDFa is growing in popularity, the overall percentage of
indexed documents containing RDFa was 0.6%, much less than the
equivalent percentage for various forms of Microformats (e.g., tag
was in 2.6% of indexed documents). They also looked at the
ratio of top-ten results pages with embedded meta-data for 7.6
thousand unique, real-world keyword queries. Their results found
that 59% of queries had at least one result with embedded meta-
data, but where the equivalent figure considering only RDFa
was 2.5%. Although coverage was poor, one conclusion was that
Semantic Web technologies could play a more significant role for
mainstream web-search if it was adopted by particular sites, or
better targeted particular categories of queries.

Looking at the issue of Linked Data usage from another
perspective, in 2010, Moller et al. [46] analysed the server access
logs of four prominent Linked Data hosts, viz., Semantic Web Dog
Food [47], DBpedia [3], DBTune [48] and RKBExplorer [49]. The
available logs covered periods from one month (RKBExplorer) to
two years (Dog Food), all falling somewhere between 20082010.
They distinguish semantic agents accessing the servers as those
issuing SPARQL queries [50] or requesting RDF-specific content-
types. Their findings indicate that for the different domains,
semantic traffic represented 919% of the total traffic observed.
They then look at whether real-world events affected demand
for resources from the different sites (e.g., monitoring access
to dbpedia:Michael_Jackson around the time of his death),
where some topical resources did encounter peaks in demand.

Aside from issues relating to coverage, interlinkage, semantic ex-
pressivity, dynamicity, use-cases, and so on, one possible reason for
the (arguably) slow emergence of applications operating over the
Semantic Web and Linked Data is that the data being published on
the Web is simply not of high-enough quality. Publishing problems
with respect to accessibility, syntax, semantics, etc., may greatly
diminish the potential for applications over the data and/or introduce increased overhead for adoption. More opaque or subjective
notions of quality  relating to resource identity, conceptual mod-
elling, competency, etc.  may be more difficult to formalise and
quantify. Such matters are further complicated by the inherent decoupling of publishing and modelling from applications, where,
aside from coverage, data might be considered of excellent quality
for one use-case and of poor quality for another due to, e.g., specific
modelling choices.

Indeed, the notion of quality (in this context and in general)
is quite a nebulous one. In his dissertation, Vrandecic [51] asks
how to assess the quality of an ontology for the Web?. He refers
to an ontology as a formal, explicit specification of a shared
conceptualisation that may include classes, properties but also
instances. Based on previous proposals, he discusses various
criteria that a good Web ontology should meet, and then proposes
concrete measures relating to accuracy, adaptability, clarity,
completeness, computational efficiency, conciseness, consistency
and organisational fitness. His conclusion is that a single measure
to assess the overall quality of an ontology is elusive, and deriving
concrete measures to identify shortcomings in ontologies is a more
useful approach; he also states:

[...] instead of aiming for evaluation methods that tell us if
an ontology is good, we settled for the goal of finding ontology
evaluation methods that tell us if an ontology is bad, and if so, in
which way.

Along these lines he analyses issues relating to naming conventions
(i.e., checking if the local part of a URI coincides with a label given to
that entity), erroneously introduced punning, superfluous blank
nodes (i.e., blank nodes that are not used for encoding RDF
collections and OWL constructs), to name but a few checks.

In previous works [16], we listed and discussed common
errors made by RDF publishers on the Web based on experiments
conducted on a dataset acquired from 150k URIs mentioned in
a previous RDF dataset. We classified errors into the following
four categories: (i) accessibility and dereferenceability, (ii) syntax
errors, (iii) reasoning: noise and inconsistency and (iv) nonauthoritative contributions. Most URIs returned without error,
but less than half returned RDF/XML. We found that 8.1% of
triples in the resulting dataset used undeclared class URIs, and
14.3% used undeclared property URIs. With respect to noise,
the most prevalent issues related to reasoning, where we found
many invalid values for inverse-functional properties, and various
forms of
inconsistency, particularly memberships of disjoint
classes. We also identified the issue of ontology hijacking,
where third-parties redefine the meaning of popular vocabulary
terms. We argued against application-side workarounds for certain
frequently observed problems and buggy datasets, as those would
have to be replicated across all applications that use the data,
entailing a large barrier-to-entry for potential consumers. Rather,
we provided a prototypical validator12 and initiated an online
community  the Pedantic Web Group13  which aims to educate
publishers on issues of data-quality and contacts publishers with
bug-reports.

2.6. Data-quality analyses

The previous literature gives a somewhat luke-warm impression of the use and usefulness of RDF data published on the Web.

12 http://swse.deri.org/RDFAlerts/; retr. 2011/08/21;
also http://inspector.sindice.com/; retr. 2011/08/21.
13 http://pedantic-web.org/ ; retr. 2011/08/21.

As discussed in the introduction, Linked Data guidelines are
designed to enable new types of applications over data published
in a conformant manner. With respect to empirical studies of
Linked Data conformance, although there is some overlap between
some of the more generic guidelines and some results previously
discussed, we are not aware of any published work focusing
specifically on this topic. At the time of writing, Bizer et al. [52]
are currently draughting an online document (currently version
0.3) which  similarly to our contribution  enumerates nine
Linked Data guidelines and characterises the conformance of
publishers thereto. However, their study of conformance is based
on self-reported statistics provided by the publishers themselves in
CKAN.14 We view our work herein as complementary, effectively
constituting an empirical, consumer-side study of the issue of
Linked Data conformance.

3. Preliminaries

We now move towards presenting our primary contribution,
but first we cover some necessary preliminaries relating to RDF
and Linked Data principles. We also very briefly discuss the
implementation and methods used to conduct our experiments
and extract our results.

3.1. RDF

We briefly give some necessary notation relating to RDF

constants and RDF triples; cf. [34].

3.1.1. RDF constants

Given the set of URI references U, the set of blank nodes B,15
and the set of literals L, the set of RDF constants is denoted by
C := U  B  L.
Herein, we use CURIEs [53] to denote URIs: we refer the reader
to the service at http://prefix.cc/ (retr. 2011/09/01), where the
namespace prefixes used in this paper can be looked up. Following
Turtle syntax [54], we may use a as a convenient shortcut for
rdf:type.

3.1.2. RDF triples
The set of all RDF triples is given as G := (UB)U(UBL).
A triple t := (s, p, o)  G is called an RDF triple, where s is called
subject, p predicate, and o object. We call a finite set of triples
G  G an RDF graph.

3.1.3. Data-level position

We define two data-level positions in a triple:

(i) the subject of a triple; and
(ii) the object of a triple iff the predicate is not rdf:type.
Given an RDF graph G, we use the function dlc(G) to denote the set
of RDF constants appearing in the data-level position of some triple
in that graph. In particular, we distinguish the data-level positions
of a triple from those that are typically occupied by schema terms
such as properties appearing in the predicate position or classes
appearing as the value of rdf:type. (Many of the guidelines we
will look at focus on data-level terms and do not naturally apply
to these latter schema-level terms, where we would not expect,
for example, all members of a class to be given in its dereferenced
document, and so forth.)

3.2. Linked Data principles and data sources

Linked Data principles [2] and associated best practices [17]
offer clear guidelines for publishing RDF on the Web. We
briefly discuss Linked Data principles and notions relating to
provenance.16

3.2.1. Linked Data principles

Throughout the rest of this paper, we denote the four best

practices of Linked Data as follows [2]:
LDP1
LDP2
LDP3

use URIs to name things;
use HTTP URIs so that those names can be looked up;
provide useful structured information when a look-up on
a URI is made, called dereferencing;
include links using external URIs.

LDP4

3.2.2. Data source

We define the http-download function get : U  2G as the
mapping from a URI to an RDF graph (set of facts) it may provide
by means of a given HTTP lookup [55] that directly returns status
code 200 OK and data in a suitable RDF format; this function also
performs a rewriting of blank-node labels (based on the input URI)
to ensure uniqueness when merging RDF graphs [34]. We define
the set of (RDF) data sources (S  U) as the set S := {s  U :
get(s) = }. In this paper, sources refer to individual RDF/XML
documents retrievable over the Web from location s.

3.2.3. RDF triple in context/RDF quadruple
An ordered pair (t, c) with a triple t = (s, p, o), c  S and
t  get(c) is called a triple in context c. We may also refer to (s, p,
o, c) as an RDF quadruple or quad q with context c.

3.2.4. HTTP redirects/dereferencing
A URI may provide a HTTP redirect to another URI using a 30x
response code [55]; we denote this function as redir : U  U that
may map a URI to itself in the case of failure (e.g., where no redirect
exists)this function would implicitly involve, e.g., stripping the
fragment identifier of a URI [56]. We denote the fixpoint of redir as
redirs, denoting traversal of a number of redirects (a limit may be
set on this traversal to avoid [very rare, possibly malicious] redirect
cycles and artificially long redirect paths). We define dereferencing
as the function deref := get  redirs that maps a URI to an RDF
graph retrieved with status code 200 OK after following redirects,
or that maps a URI to the empty set in the case of failure.

3.2.5. Pay-level domains/data providers

Herein, we use pay-level domains (PLDs) [57,29] to distinguish
individual data providers. A pay-level domain is a direct subdomain of a top-level domain (TLD) or a reserved second-level
country domain (ccSLD); examples of PLDs include dbpedia.org
and bbc.co.uk.

We do not consider general fully-qualified domain names
(FQDNs) as indicating different data providers since PLDs such as
livejournal.com publish data under many FQDNs, assigning
a third-level domain to each user (e.g., danbri.livejournal.
com). Also, we acknowledge that multiple datasets may intuitively operate within a given PLD, but note that a pay-level
domain is typically under the control of a single person or organi-
sation, which we herein consider to be the granularity of our data

14 http://ckan.net/group/lodcloud; retr. 2011/08/21.
15 We interpret blank nodes as skolem constants, as opposed to existential
variables. Also, we rewrite blank-node labels to ensure uniqueness per document,
as prescribed in [34].

16 In a practical sense, all HTTP-level functions {get, redir, redirs, deref} are set at
the time of the crawl, and are bounded by the knowledge of our crawl.

A. Hogan et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

providers. We may interchangeably use the terms data provider,
PLD or domain to refer to such sites that host a set of data
sources (in our case, a set of RDF/XML documents).
For convenience, herein we represent PLDs as a set of HTTP
URIs  e.g.: http://dbpedia.org/  given by the set P  U. We
define the function pld : U  P that maps a HTTP URI to its
PLD. Letting sources(p) := {s  S : pld(s) = p} denote the
sources under the (direct) control of PLD p, we use the function
data : P  2G to denote the RDF merge of the set of triples
given the set of sources in that PLD (sources(p)); more specifically
ssources(p) get(s). We also define the function local :
pld  B  U that maps a PLD p to the union of
(i) the set of blank nodes appearing in a triple of data(p);
(ii) URIs appearing in a triple of data(p) such that pld(redirs(u))

data(p) := 

= p.

Intuitively, local(p) refers to the locally minted non-literal terms
under the control of the PLD p [58].

3.3. Extraction of statistics

In this paper, we are more interested in the results of the
empirical analysis rather than the implementation thereof, where
we consider issues relating to performance, etc., as out of scope.
However, we now briefly give an insight into the batch-processing
techniques used to extract the statistics.

We assume that the dataset to be analysed is given as a flat file
of N-Quads, optionally compressed with GZip; further, we assume
that knowledge of the crawl is given in a structured input file,
including information about response codes, content-types and
redirect locations.

In preparation for the analysis, the dataset is sorted according
to subjectpredicateobjectcontext order and objectpredicate
subjectcontext order in two separate files: the sorts are performed using standard on-disk external merge-sorts. Thereafter,
we perform a merge-join over the two files, joining on the sorted
subject/object position, effectively producing batches corresponding to all of the inlinks and outlinks for each resource in the
data. Statistics about the various data-providers are accumulated
in memory during the scan of resources.

Our implementation is Java based, where we use the Java Statistical Classes library17 to compute Kendalls  measure (introduced
later for comparing PageRank and conformance). Further, we use a
simple RMI infrastructure to perform distributed sorts and scans
details of the infrastructure are available in [14,38]. Analyses are
performed using nine machines with 2.2 GHz Opteron x86-64 CPU,
4 GB main memory, 160GB SATA hard-disks, running Java 1.6.0_12
on Debian 5.0.4.

4. Empirical corpora

In this section, we give pertinent descriptions of the two
corpora we acquired for the purposes of our empirical analysis. Our
primary corpus (Section 4.1) comprises of 1.1 billion quadruples
crawled from just under 4 million RDF/XML documents in May
2010, spanning content hosted by 778 data providers (PLDs). We
also briefly describe our secondary corpus (Section 4.2), which we
use to analyse the stability of documents hosted by individual data
providers, and which consists of nine monthly snapshots, accessing
a static set of 155 thousand RDF/XML documents and covering the
period of March 2010 to November 2010.

17 http://www.jsc.nildram.co.uk/; retr. 2011/09/01.

4.1. Billion quadruple crawl

To provide insights into current conformance with respect
to Linked Data best-practices, the first corpus over which we
apply our analyses consists of 1.118 billion quadruples, crawled in
mid-May 2010 from 3.985 million RDF/XML documents spanning
778 pay-level domains (data providers). Of the 1.118 billion raw
quadruples parsed, 1.106 billion (98.9%) are unique, and 947
million (84.7%) are unique triples.

4.1.1. Corpus acquisition

We conducted the crawl in a breadth-first manner over a cluster
of nine machines. The crawl was seeded with 42.5 thousand URIs
extracted from an older Linked Data crawl conducted in 2009: URIs
were randomly sampled from all positions of the RDF triples. To
ensure a broad sample of data-providers during the crawl (and to
ensure polite crawling), we assign each pay-level domain (PLD)
an individual priority queue. The PLD queues are sampled in a
round-robin fashion during the crawl, with the highest linked
URIs for each domain being returned first. (For more details on the
implementation of our distributed crawler, we refer the interested
reader to [38].)

Furthermore, we only access RDF/XML documents using an
accept-header application/rdf+xml and do not consider
documents in other syntaxes, such as RDFa, N-Triples or Turtle.
Linked Data guidelines have traditionally suggested that RDF/XML
data should be provided as a minimum:

There are various ways to serialise RDF descriptions. Your data
source should at least provide RDF descriptions as RDF/XML which
is the only official syntax for RDF.[17, Section 5]

However, more recent Linked Data guidelines [27] and trends
suggest that other RDF syntaxes can be used as an alternative to
RDF/XML, where in particular, RDFa has been standardised [59]
and is growing in popularity.

Along these lines, our empirical corpus is only a sample of
Linked Data, and like any non-trivial sample of open Web data
(where the nature of the entire population cannot be feasibly
known), it has inherent biases that may affect our analysis and
results [43]. We identify the following known biases for our
corpus:
 given that our crawl was run in May 2010, our corpus does not

reflect newer publishers or published data;

 our crawl only samples RDF/XML and does not cover data in

other syntaxes;

 given that our crawl does not follow all possible URIs, our
corpus is particularly incomplete for domains that host a large
amount of documentstowards the end of the crawl, there
were still 50 PLDs whose RDF/XML content was (almost
surely) known not to be exhausted;

 given that the crawl is breadth-first and that URIs with higher
inlinks are prioritised, our corpus is biased towards containing
the most well-linked documents in each domain.

To help counter-act the effects of sampling bias, we focus on
presenting conformance measures on a per-PLD basis. Considering
the RDF/XML data provided by each PLD as an independent
population, we have a varying degree of coverage for each
sampling frame. Our results will generally be more accurate for
smaller PLDs (for which we have a higher relative coverage), and
less accurate for larger PLDs (for which we have a lower relative
coverage). Where possible, we present ratio-based conformance
measures and other forms of measures that we argue are less
sensitive to the level of coverage in the sample for a given PLD.
Where pertinent, we later discuss possible biases given by our
sampling for specific conformance measures.

A more difficult question relates to how the statistics for individual data-providers should be aggregated into an overall conformance score for each guideline. One option is to take the average (i.e., arithmetic mean) of conformance scores for all providers;
however, this would assign equal weight to the conformance of,
e.g., the high-volume and highly-prominent dbpedia.org do-
main, and the low-volume, obscure phoenixproductions.org.
uk domain, which publishes a single triple.18 There is perhaps no
single ideal aggregation. For the purposes of Section 5, we only
present statistics relating to those 188 data-providers (24.2%) contributing more than 1000 quadruples to our sample, which is the
same cut-off used for datasets to be included in the LOD cloud.19
When presenting aggregate scores, we use the arithmetic mean
and population standard deviation of conformance across only
these 188 providers. Later in Section 7, we present and compare
other methods of aggregating the per-PLD conformance scores into
an overall score for each guideline.

Again, our corpus constitutes a large collection of documents
sampled from a wide variety of Linked Data publishers, and so
should yield interesting insights into conformance; it is the base
dataset indexed by the SWSE system at the time of writing [14].
We now present statistics that further characterise the particular
contents of our corpus.

4.1.2. Corpus summary

In Table 1, we present the top twenty-five data providers
contributing to our corpus, with respect to the number of
quadruples and documentswe extracted the PLDs from the
source documents (contexts) and summated occurrences. We
see that a large portion of the data is sourced from social
networking sites  such as hi5.com and livejournal.com
 that host FOAF exports for millions of users. Notably, the
hi5.com domain provides 595 million (53.2%) of all quadruples
in the data: although the number of documents crawled from this
domain was comparable with other high yield domains, the high
ratio of triples per document meant that in terms of quadruples,
hi5.com provides the majority of data. Other providers in the topfive include the opiumfield.com domain, which offers LastFM
exports; as well as linkedlifedata.com and bio2rdf.org,
which publish data from the life-science domain.

With respect to the nature of the data that these providers
contribute to our corpus, we now look at usage of properties and
classes in the data. The dominance of foaf:* terms for raw triple
counts is attributable (in large part) to the high-percentage of data
from the hi5.com domain.

For properties, we analysed the frequency of occurrence of
terms in the predicate position, and for classes, we analysed the
occurrences of terms in the object position of rdf:type quads.
We found 23,155 unique predicates, translating into an average
48,367 quads per predicate; Table 2 gives the listing of the top
25 predicates, where (unsurprisingly) rdf:type heads the list
(18.5% of all quads), and where foaf:* properties also feature
prominently.

Analogously, we found 104,596 unique values for rdf:type,
translating into an average of 1977 rdf:type quadruples per
class term; Table 2 gives the listing of the top twenty-five classes,
where again FOAF  and in particular foaf:Person (79.2% of all
rdf:type quads)  features prominently.

In order to get an insight into the most instantiated vocabu-
laries, we extracted the namespace from predicates and URIvalues for rdf:type: we simply strip the URI upto the last hash

Table 1
Top twenty-five PLDs and number of quads and documents they provide.

hi5.com
livejournal.com
opiumfield.com
linkedlifedata.com
bio2rdf.org
rdfize.com
appspot.com
identi.ca
freebase.com
rdfabout.com
ontologycentral.com
opera.com
dbpedia.org
qdos.com
l3s.de
dbtropes.org
uniprot.org
dbtune.org
vox.com
bbc.co.uk
geonames.org
ontologyportal.org
ordnancesurvey.co.uk
loc.gov
fu-berlin.de

Quads (m)

Docs (k)

Quads/doc

or slash. Table 2 also gives the top twenty-five occurring namespaces for a cumulative count, where FOAF, RDFS, and RDF domi-
nate; in contrast, Table 2 also gives the top twenty-five namespaces
for unique URIs appearing as predicate or value of rdf:type,
where in particular namespaces relating to DBPedia, Yago and
Freebase offer a diverse set of instantiated terms; note that (i) the
terms need not be defined in that namespace (e.g., foaf:tagLine
used by LiveJournal) or may be misspelt versions of defined terms
(e.g., foaf:image used by LiveJournal instead of foaf:img [16]),
and (ii) 460 of the 489 terms in the rdf: namespace are predicates
of the form rdf:_ n.

4.2. Nine monthly snapshots

We now briefly discuss the nature of our nine monthly
snapshots, which we later analyse in order to determine the
stability with which the individual data-providers host their
documents; in particular, we focus on the parameters of the crawl
and the crawler.

Each month, we accessed a static set of the URIs of 155 thousand
RDF/XML documentsthese URIs were randomly sampled from a
large crawl conducted in January 2010, and so contain a similar
sample bias to that of the larger crawl. The nine monthly snapshots
contain an average of 51 million quadruples each. The accessed
documents are served by 850 data providers (PLDs). Of these, 457
data providers coincide with our larger crawl.

Given that we will present the stability with which different
providers host data, it is perhaps important to note the specific
times for crawling and the timeouts used. Each snapshot was
crawled starting at 00:01 a.m. GMT on the first Sunday of each
month. We carried out the crawl with the LDSpider framework.20
The crawler uses a 128 s socket timeout, and a 64 s timeout
for establishing a connection. Further, we (i) enabled Nagles
algorithm,21 which tries to conserve bandwidth by minimising
the number of segments that are sent; and (ii) enabled GZip
compression (as available).

18 http://www.phoenixproductions.org.uk/newsbomb/index.rdf; displays hacked
notice, 2011/08/15.
19 http://lod-cloud.net/ ; retr. 2011/09/01.

20 http://code.google.com/p/ldspider/; retr. 2011/09/01.
21 See RFC 896: http://tools.ietf.org/html/rfc896; retr. 2011/09/01.

A. Hogan et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

Predicate

Class

Namespace

Table 2
Top twenty-five (i) predicates by number of triples they appear in; (ii) values for rdf:type by number of triples they appear in; (iii) namespaces by number of triples the
contained predicates or values for rdf:type appear in; (iv) namespaces by unique predicates or values for rdf:type that they contain.
Triples
615,110,022 yagor:
219,205,911 yago:
213,652,227 dbtropes:
43,182,736 fb:
27,944,794 dbp:
22,228,436 own16:
19,870,999 semwebid:
17,500,405 opencyc:
13,140,895 estoc:
11,594,699 dbo:
11,322,417 sumo:
9238,140 rdf:
9175,574 wn:
6400,202 b2r:/b2rr:
5839,771 movie:
5411,725 uniprot:
4057,450 aifb:
3985,276 factbook:
3466,560 foaf:
3299,442 geospecies:
2964,084 b2rns:
2630,198 ludopinions:
2603,123 oplweb:
2519,543 esns:
2371,396 drugbank:

Triples
206,799,100 foaf:Person
199,957,728 foaf:Agent
168,512,114 skos:Concept
163,318,560 mo:MusicArtist
31,100,922 foaf:PersonalProfileDocument
18,776,328 foaf:OnlineAccount
14,736,014 foaf:Image
11,928,308 opiumfield:Neighbour
10,192,187 geonames:Feature
10,061,003 foaf:Document
9522,912 owl:Thing
8910,937 estoc:cphi_m
8780,863 gr:ProductOrServiceModel
8780,817 mo:Performance
8475,063 fb:film.performance
8383,510 fb:tv.tv_guest_role
7457,837 fb:common.webpage
6917,754 dcmit:Text
6163,769 estoc:irt_h_euryld_d
5560,144 owl:Class
5346,271 opwn:WordSense
4923,026 bill:LegislativeAction
4510,169 fb:common.topic
4158,905 rdf:Statement
4140,048 mu:Venue

rdf:type
rdfs:seeAlso
foaf:knows
foaf:nick
b2rr:linkedToFrom
lldegene:pubmed
rdfs:label
owl:sameAs
foaf:name
foaf:weblog
foaf:homepage
lldpubmed:chemical
foaf:member_name
foaf:tagLine
foaf:depiction
foaf:image
foaf:maker
lldpubmed:journal
foaf:topic
lldpubmed:keyword
dc:title
foaf:page
b2r:linkedToFrom
skos:subject
skos:prefLabel

Namespace

Triples
163,699,161 foaf:
8165,989 rdfs:
4402,201 rdf:
4050,837 b2r:/b2rr:
2029,533 lldpubmed:
1985,390 lldegene:
1951,773 skos:
1920,992 fb:
983,800 owl:
745,393 opiumfield:
679,520 mo:
421,193 dc:
407,327 estoc:
392,416 dct:
300,608 b2rns:
290,246 sioc:
288,537 vote:
262,517 geonames:
243,074 skipinions:
217,334 dbo:
206,941 uniprot:
193,202 estoc:
190,434 lldlifeskim:
169,376 ptime:
166,374 dbp:

Terms

5. Best practices for data providers

Linked Data principles and publishing guidelines are designed
to make structured data more amenable to ad hoc consumption
on the Web. However, it is currently unclear how closely RDF
publishers follow these best-practices.

From [17]  up until recently, the definitive guide to publishing
Linked Data on the Web as prominently promoted on the
http://linkeddata.org/ (retr. 2011/09/01) site  we derive a list of
fourteen concrete guidelines, and empirically evaluate their uptake
with respect to our corpora. Going through this list, we first quote
the advice from [17] verbatim, and discuss the rationale, feasibility
and repercussions thereof. We design and briefly formalise some
(typically) straightforward metrics that aim to quantify the level
of conformance with respect to the given guidelines, and then
present the results of some empirical analyses over our corpora
that indicate how closely data-providers follow the given best
practice.

We aim to have a good coverage of the broad-range of
recommendations and topics covered in [17]. However, we note
that we omit a couple of issues for which we found it difficult
to design some quantitative experiments; for example, we do not
look at the use of unique keys in URIs, or at the dereferenceability of
information vs. non-information resources. Also, again we focus on
issues relating to data providers, and not to vocabulary providers.
Otherwise, we believe that our guidelines have good competency
with respect to the discussion in [17].

Importantly, we also acknowledge that many of the bestpractices we outline may not be applicable to all scenarios, and that
reasonable exceptions may often applyfor example, although
best-practices discourage the use of blank nodes, they may be
useful for representing highly-transient resources, or perhaps
for n-ary predicate constructs.22 However, we believe that the
presented recommendations apply in the general casesince we
look at a significant spectrum of issues, we necessarily need to
apply straightforward, objective, quantitative analysis.

22 See http://richard.cyganiak.de/blog/2011/03/blank-nodes-considered-harmful/
(retr. 2011/09/01.) for some informal discussion.

We also present lists of the top five and bottom five most/least
conformant domains for each guideline; full versions of all
tables are available online at http://aidanhogan.com/ldstudy/;
retr. 2012/01/12. When presenting statistics about specific data
providers (to avoid connotations of pointing the finger) we mark
data providers with which at least one of the authors is directly
involved (D) or with which at least one of the authors is directly
affiliated (E). We (humbly) note that these domains often appear
towards the bottom of our conformance rankings.

Moving forward, we organise issues into categories, presenting

them together in the following subsections:
(i) naming resources (Section 5.1);
(ii) linking to external data providers (Section 5.2);
(iii) describing resources (Section 5.3);
(iv) dereferenced representations (Section 5.4).

5.1. Naming

In this section, we look at best-practices relating to the naming

of resources as discussed in [17,60].
Issue I: Avoid blank nodes

We discourage use of blank nodes. It is impossible to set external
RDF links to a blank node, and merging data from different sources
becomes much more difficult when blank nodes are used.[17,
Section 2.2]

What? Blank-node identifiers are local to a given document,
and thus cannot be externally referenced. The above quote
recommends minimal usage of blank nodes in Linked Data
publishing.
Why? Primarily, Linked Data best-practices emphasise the importance of interlinking and re-using names across domains, whereby
use of blank nodes would pose obvious problems.

Further, classical RDF semantics mandates an existential
interpretation of blank nodes [34] not well-supported by Linked
Data tools (or arguably even understood by adopters), where, for
example, the current RDF semantics of blank nodes does not align
well with SPARQL, which interprets them as names [33].

Table 3
Top five PLDs and bottom five PLDs ordered by percentage use of URIs vs. blank
nodes (ties ordered by number of quads in sample).

...
...
...
...

linkedlifedata.com
appspot.com
dbpedia.orgE
l3s.de
dbtropes.org
okkam.org
opencalais.com
hi5.com
ontologycentral.comD
prefix.ccD

bn [%]

In addition, when merging documents, local blank-node labels

must be mapped to globally unique labels.23
Conformance? We see minimal (or no) use of blank nodes as a
general indicator of Linked Data conformance. Along these lines,
we use the following metric to determine conformance for a
PLD p, where a higher percentage is interpreted as having higher
conformance (here recalling notation from Section 3):
bn(p) :=

|dlc(p)  U|

|dlc(p)  (U  B)|

where dlc(p) is a shortcut denoting the set of data-level constants
appearing in the data hosted by the PLD p. Here, bn(p) (not blank
node) gives the ratio (expressed as a quotient) of the set of unique
data-level URIs vs. the set of unique data-level URIs and blank
nodes in data hosted by the PLD phere we exclude literals.
In Table 3, we present the top-five and bottom-five data
providers with respect to bn (expressed as a percentage). We
found that 64 data-providers (34% of 188 offering more than 1000
quads) did not use any blank nodes, where Table 3 only enumerates
the five largest such providers with respect to the total quads in
our sample. Further, 86 providers (45.7%) used less than <1% blank
nodes. The average score for bn across the 188 data-providers
included was 84.3% (24.2 pp).24
Bias? Regarding the above results, the high-level sampling biases
discussed in Section 4.1.1 again apply (e.g., not considering
RDFa data, etc.). Regarding sampling biases specific to the above
measures, we note that documents that contain a high percentage
of blank nodes may be less likely to be crawled since they contain
less dereferenceable URIs (and thus, less opportunities to be
linked). Perhaps more importantly, given that local URIs can be reused across documents whereas blank nodes cannot, the ratio of
blank nodes vs. local URIs may increase when more documents
are available for analysis; for example, if a domain publishes a
single consistent local URI and a single unique blank-node in each
document it hosts, the ratio of blank nodes will increase linearly
as the number of documents considered increases. Thus, for the
very large domains that we only partially sample, the ratio of blank
nodes may be under-represented assuming significant re-use of
local URIs across documents.
Conclusion? Given the high standard deviation (24.2 pp), we
can still see that conformance to this guideline varies widely
across domains. However, although a number of high-volume
publishers still make heavy use of blank nodes  thus ensuring their
prevalence in absolute terms  we have seen that most domains
make relatively sparse (or no) use of blank nodes.

23 This is not necessarily an expensive process: in our case, we use an escaped
concatenation of context and the local blank-node label to generate a global ID.
24 We use  to indicate population standard deviation. pp indicates percentage
point units.

There are various possible valid reasons for using blank nodes,
including use for transient items that only exist at request time,
or for resources that should not be externally referenced, or as
shortcuts for representing n-ary predicates in RDF, or use for
serialising certain OWL axioms, etc. However, in the general case,
avoiding blank nodes makes RDF Web data better subject to
interlinking and re-use. Traditionally, blank nodes were heavily
used to identify non-information resources, particularly by highvolume publishers of FOAF data [61], where we can still see the
effects of this practice in RDF published today (e.g., hi5.com).

In fact, the recently reconvened RDF W3C Working Group
has been discussing the possibility of specifying an informative,
agreed-upon mechanism for converting (aka. Skolemising) blank
nodes into unique URIs [33].25 This would allow for legacy
blank nodes to be converted, serialised and consumed as URIs
by software agents. Current proposals centre around the use of
.well-known URIs with a reserved path prefix [62].
Issue II: Use HTTP URIs

In the context of Linked Data, we restrict ourselves to using HTTP
URIs.[17, Section 2.1]

What? The above quote recommends only using URIs with the
http:// or https:// schemes, and thus avoiding other URI
schemes, such as ftp:, file:, mailto:, urn:, info:, etc.
Why? Unlike blank nodes, URIs give a direct mechanism for globally
identifying a given resource. In addition, HTTP URIs are compatible
with the identification of resources with respect to Web Architecture principles [63], such that (related) representations of the referent can be returned by means of a HTTP lookup [55]. (We will see
more in the next issue.)
Conformance? We see a high percentage use of HTTP URIs as a
general indicator of Linked Data conformance, where we use the
following metric to quantify this conformance:

hu(p) := |dlc(p)  {u  U : sch(u)  {http, https}}|

|dlc(p)  U|

where sch(u) denotes the URI scheme of u, and where hu(p) (HTTP
URIs) represents the ratio of unique URIs appearing in a datalevel position of a triple in data(p) that have the http or https
scheme. Note that we do not count blank nodes here since they are
accounted for by the previous metric.

In Table 4, we present the top-five and bottom-five data
providers with respect to hu (represented as a percentage). We
found that 112 data-providers (60% of 188 providers hosting more
than 1000 quads) did not use any non-HTTP URIs, where Table 4
only enumerates the five largest such providers (with respect
to total quads hosted). Further, we note that 162 data-providers
(86.2%) used >99% HTTP URIs. The average percentage use of HTTP
URIs was 98.8% (4.8 pp).
Bias? Aside from the high-level biases already discussed  and as
per the use of blank nodes in the previous guideline  documents
with high percentages of non-HTTP URIs are perhaps less likely to
be crawled due to a lack of dereferenceable names.
Conclusion? We have seen that most domains surveyed are highlyconformant with this guideline. The most significant counterexample to this trend is the loc.gov domain, which assigns each
locally minted URI an alias with the info: scheme; in fact, this
case is not problematic given that a http: alias is available for all
resources.

Despite the guideline, there are valid reasons to use non-HTTP
URIs, esp. for identifying legacy resources, where schemes like

25 cf. http://www.w3.org/2011/rdf-wg/track/issues/40; retr. 2011/08/10.

A. Hogan et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

Table 4
Top five PLDs and bottom five PLDs ordered by percentage use of HTTP URIs (when
tied, ordered by number of quads).

Table 5
Top five PLDs and bottom five PLDs ordered by percentage of locally used URIs that
were not found to be non-dereferenceable (when tied, ordered by number of quads).

...
...
...
...

hi5.com
linkedlifedata.com
rdfize.com
identi.ca
freebase.com
code4lib.org
gregheartsfield.com
fluffyandmervin.com
smhowell.net
loc.gov

hu [%]

...
...
...
...

ontologycentral.comD
zitgist.com
zbw.eu
ebusiness-unibw.org
174.129.12.140 (open-biomed.org.uk)
br3nda.com
ajft.org
smhowell.net
snell-pym.org.uk
typepad.com

du [%]

mailto: and tel: can be used to directly indicate email and
telephone numbers respectively, and where many information
resources are identified/accessible through an ftp: scheme URI.
Instead, the guideline is implicitly encouraging new identifiers
to be minted with the http: scheme (as opposed to, e.g., using
URN schemes), which, in particular, enables information about the
resource to be dereferenced, as per the next guideline.
Issue III: Mint dereferenceable URIs

Define your URIs in an HTTP namespace under your control, where
you actually can make them dereferenceable.[17, Section 3]
When publishing Linked Data on the Web, we represent
information about resources using the Resource Description
Framework (RDF).[17, Section 2.2]
Your data source should at least provide RDF descriptions
as RDF/XML which is the only official syntax for RDF.[17,
Section 5]

What? As alluded to by the previous guideline, HTTP URIs can be
dereferenced by means of a HTTP lookup. In the context of Linked
Data, we would expect some RDF representation to be returned
as discussed in the second quote above. Given the third quote, we
would also expect data to be returned in RDF/XML format (and then
optionally in Turtle or TriX, etc. [17, Section 5]).
Why? When a URI identifying some resource is looked up, a
consumer should reasonably respect a (related) representation
thereof to be returned. Given that applications are consuming
Linked Data in an ad hoc manner, such applications require
structured data to be provided in a known, standardised fashion.
Again, in the context of Linked Data, RDF provides the core,
interoperable data-model. RDF/XML is traditionally the most
widely supported RDF syntax, although we again acknowledge that
RDFa has enjoyed recent growth in adoption.

We note that many Linked Data systems rely on dereferenceable URIs being used in the data. First, use of dereferenceable URIs
is important for locating information about resources, useful for
processing SPARQL queries over a priori unknown data sources
(e.g., see [64]), for Linked Data browsers, which allow for navigating the Web of Data through dereferenceable URIs (e.g., see [8]),
etc.26 Similarly, dereferenceability establishes an important relationship between resources and their authoritative representa-
tions, often used as an indicator of provenance or trustworthiness
of the information in a specific source with respect to a specific
resources, used in applications such as ranking (e.g., see [58]) or
reasoning (e.g., see [65,66]). Finally, performing HTTP lookups on
non-dereferenceable URIs can cause significant wasted computa-
tion-time for agents, especially Web crawlers used in warehousing approaches, which may perform many millions of lookups, and

26 In the context of Linked Data browsers, a non-dereferenceable URI equates to a
dead-link on the traditional HTML Web.

live-querying and browsing systems, which must retrieve sources
at query-time.
Conformance? We consider providers that mint a high ratio of
local URIs that dereference to RDF/XML content (using Accept:
application/rdf+xml) as highly conformant. Note however
that our crawl is incomplete, where we do not perform lookups
on all URIs in the corpus. Thus, herein we restrict our analyses
to look at the percentage of URIs that were confirmed not to
be dereferenceable, where we would expect conformant data
providers to mint fewer non-dereferenceable URIs; more formally,
for a PLD p, we measure:

|ldlc(p)  U|

du(p) := 1  |ldlc(p)  {u  U : deref(u) = }|
where U  U is the set of HTTP URIs looked up during the crawl
of our corpus, and ldlc(p) := dlc(p)  local(p) denotes the set of
local, data-level constants in the data hosted by p. For a PLD p,
a lower ratio of confirmed non-dereferenceable URIs results in a
higher value for du(p) indicating better conformance.
We found three domains that did not mint any local URIs
(ldlc(p)  U = ) : hopcroft.name, lehigh.edu, and unitn.
it. We exclude these three domains from tables that have local
URIs as a denominator, and consider them as having a score of zero
when calculating averages or orderings.

Along these lines, Table 5 presents the top five and bottom
five data-providers with respect to du conformance (represented
as a percentage). We note that no non-dereferenceable URIs were
found for 14 providers (7.4%); in total, 36 PLDs (19.1%) have less
than 1% of their local URIs confirmed as non-dereferenceable. The
average score for du was 70.3% (26.8 pp) across the 188 data-
providers.

However, we note that this metric and these results do not
consider the amount of data returned about the given URI in the
dereferenceable document; hence, we also look at another metric,
as follows:

|{t  deref(u) : u  dlc({t})}|


uDUp

dt(p) :=

|DUp|

where
DUp := {u  U : deref(u) =   u  ldlc(p)}
denotes the set of URIs for a PLD p that (i) are mentioned in the data
of p and (ii) were looked up and found to dereference to RDF/XML
data during our crawl. Thus, for each PLD p, the dt metric takes the
average across all u  DUp, of the number of triples mentioning u
(in a data-level position) in the dereferenced document of u.
In Table 6, we give the top five and bottom five PLDs for the
dt measure. We note that the prefix.cc domain only had two
dereferenceable (information resource) URIs, denoting the two
documents found on that domain, where each document had a

Table 6
Top five and bottom five PLDs ordered by average number of triples mentioning
dereferenceable URI in resp. dereferenced documents.

prefix.ccD
bio2rdf.org
linkedlifedata.com
br3nda.com
dbpedia.orgE
bestbuy.com
lingvoj.org
livejournal.com
opiumfield.com
hi5.com

dt [triple]

Table 7
Top five PLDs and bottom five PLDs ordered by average length of local URIs.

gromgull.net
4july.me
urmf.net
chirup.com
waka.me
idehen.name
rkbexplorer.com
daviding.com
uniba.it
nuigalway.ieE

ul [char.]

large set of foaf:topic outlinks.27 Documents in the bottom
half of the table typically only had dereferenceable information
resources (the documents themselves). For example, the hi5.com
domain only hosts dereference document URIs, where every
document has links to external RDF/XML documents, but has no
mention of itself. Similarly, each document on livejournal.com
only speaks about itself in two triples.28
The average value for dt across all documents was 17.5 (40.3)
triples: the high standard deviation tells us that the outliers at the
top of the table have a strong effect on the average.

Note that we further analyse the information dereferenced by

different domains later in Section 5.4.
Bias? Besides the high-level sampling biases already discussed, it
is important to note that we would consider URIs that dereference
(only) to RDFa as non-dereferenceable: we do not detect RDF
embedded in HTML documents. Further still, since we only
partially crawl the local URIs of large data-providers, the ratio of
confirmed non-dereferenceable URIs would be under-represented
for these domains. It is also worth noting that documents with few
or no dereferenceable URIs are less likely to be well-linked and
thus, again, less likely to be crawled.
Conclusions? We have seen that although many publishers largely
abide by the dereferenceable-URIs guideline (average of 70.3%),
there is still some notable variability in conformance (standard
deviation of 26.8 pp).

Again, legacy information resources on the Web are most
naturally identified using their native URL. For certain local
resources referenced in RDF data  e.g., online spreadsheets,
images, etc.  it is often infeasible to make their URIs dereference
to a valid RDF description; similarly, embedding RDFa into certain
HTML documents may not be feasible or currently cost-effective.
Thus, despite the guideline, it is often infeasible to make all (local)
URIs dereference to RDF. Indeed, the prohibitive cost involved
in, e.g., embedding RDFa metadata into the legacy HTML content
of established web-sites, or maintaining content-negotiation and
redirect schemes, etc., might discourage potential adopters if
the guideline were enforced more rigorously.
In addition to
overhead, prior to Linked Data principles, making RDF URIs
dereferenceable was not a priority. The earliest recommendations
relating to dereferenceability were specific to class and property
terms published by vocabularies [67], where older RDF Web data
may still feature sparse use of dereferenceable URIs.
Issue IV: Keep URIs short

27 cf. http://prefix.cc/popular/all.file.vann and http://prefix.cc/rdf,owl,foaf,dc.file.
vann ; retr. 2010/08/22.
28 This has since changed; LiveJournal FOAF files now do not host any
information about themselves, although they offer links to external documents; cf.
http://danbri.livejournal.com/data/foaf; retr. 2011/08/23.

Keep implementation cruft out of your URIs. Short, mnemonic
names are better.[17, Section 3]

What? The above recommendation recommends avoiding, for
example, URIs that contain query parameters, or that are very long,
instead preferring short, human readable URIs. Many Web server
solutions offer URI rewriting engines that enable mapping from
longer, low-level implementational URIs to short, mnemonic URIs.
Why? On the Web, humans must often deal directly with URLs,
keying them into browser address bars, memorising the locations
of commonly accessed pages, advertising the web-site of a
company, etc. Thus, URLs are not solely designed to be computerprocessable addresses, but are also purposefully designed to be
human-cognisablefor example, mnemonic domain names are
used to represent numerical IP addresses. Following the same
rationale, the use of mnemonic URIs in Linked Data is explicitly
encouraged in [17].

Further, the prevalent use of shorter URI strings offers some
obvious benefits for large-scale and/or frequent processing of
RDF data; for example, short URIs allow for (i) smaller on-disk
indexes, allowing for shorter disk reads; (ii) storing more data in
main memory, translating into larger caches (e.g., see [68]) and
more scalable in-memory applications; (iii) efficient compression
techniques for further reducing memory-footprint (e.g., see [69,
70]); (iv) faster serialisation of RDF data, requiring less bandwidth
and reducing latency; etc.
Conformance? We deem data providers that locally mint (on
average) shorter URIs as being generally more compliant with
Linked Data best practices. Along these lines, we use the following
measure to quantify conformance:


len(u)
uldlc(p)U
|ldlc(p)  U|

ul(p) :=

where len(u) is the character length of the URI u; i.e., ul(p) gives
the average length of URIs local to a PLD p.

Table 7 presents the top five and bottom five data-providers
with respect to ul as observed in our large corpus (excluding
the three that did not define any local URIs). The mean averagelength of local URIs across the 185 PLDs surveyed was 52.4 (16.4)
characters.
Conclusions? The average length of
local URIs varies by a
notable factor of 4 in the sample of data-providers analysed
(i.e., between nuigalway.ie and gromgull.net).

Although shorter URIs do enable more efficient indexing and
serialisation, longer URIs composed of recognisable patterns or
words  e.g., a well-structured directory scheme or a full resource
label  may often be mnemonically preferable, or better indicate
the resource they identify, than shorter URIse.g., an authority
followed by a trailing nine-digit number as commonly produced
by URL shorteners. Of course, the guideline is more concerned

A. Hogan et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

with avoiding excessive URI length29 than making URIs as short as
possible.
Issue V: Host stable URIs

Table 8
Top five and bottom five PLDs ordered by average percentage availability of
documents for our nine monthly snapshots (ordered thereafter by number of
quads).

Try to keep your URIs stable and persistent. Changing your URIs
later will break any already-established links, so it is advisable
to devote some extra thought to them at an early stage. [17,
Section 3]

What? The above quote advises against the use of transiently/
intermittently dereferenceable URIs. Once dereferenceable URIs
are minted, they should be kept dereferenceable over time (even
if the underlying redirects and/or RDF content are dynamic).
Why? As per the importance of dereferenceability, URIs should
also be stable over time: URIs that are only temporarily or
intermittently dereferenceable  or that identify different noninformation resources over time  damage previous efforts at
external linking and mapping. As such, unstable URIs can seriously
harm the performance of agents and applications [71] and the
reliability of query answers from search engines or live query
processors. Similarly, the connectivity of the Web of Data (and
the reachability of its various subsets) is heavily dependent on the
stability of resources with a high (betweenness) centrality [26].
Conformance? We deem data providers that maintain a higher
percentage of stable URIs (minted locally) as generally being more
conformant to Linked Data best practices. Along these lines, we use
the following metric of conformance for stability of documents:

st(p, S) := |{(s, i) : s  Si  S  pld(s) = p}|
|S|  |{s  S  S : pld(s) = p}|
where S  2S denotes a collection of sets of sources from which
RDF graphs were successfully retrievedas such, S represents
our monthly snapshots of documents. Intuitively, st represents
the average number of appearances of local sources for p in the
snapshots (i.e., sources that appeared at least once in one of the
snapshots).30

Along these lines, Table 8 presents the top five and bottom five
data-providers with respect to the st measure for the respective
domain for our nine-month crawl (when tied, ordered thereafter
by number of quads hosted). We only consider documents that
appeared at least once in the snapshot. Note again that we only
have monthly information available for 141 (75%) of the 188
providers hosting more than 1000 quads. We found that 65 of
these providers (46%) had an average availability of 100%, and that
75 (53%) had an average availability in excess of 99%. The lowest
data provider hosted one document in one snapshot. The mean
availability of documents was 88.8% (19.4 pp) across all data-
providers.
Bias? Besides the high-level bias, one possible concern with this
analysis is the low number of observations available for each
document (i.e., nine) and the large interval between observations
(i.e., per month). For example, a domain could regularly experience
capacity problems one whole day each month (96% uptime),
which we would have only a 9
30 probability of encountering in one
of our monthly snapshots. The presented figures thus serve as an
informative indicator of medium-term stability.
Conclusions? The average stability of documents being hosted
across the nine snapshots was relatively high, at 88.8%. One may
note however that a more granular analysis with more frequent

29 As exemplified by the following document on our home university server:
http://rss.library.nuigalway.ie/rdf/Medicine-new-books.rdf; retr. 2011/08/16.
30 Note again that the list of URIs we attempt to retrieve in each snapshot is static.

...
...
...
...

ontologyportal.org
ordnancesurvey.co.uk
fao.org
kit.eduE
nytimes.com
4july.me
reshouts.com
deri.ieE
kaufkauf.net
ourcoffs.org.au

st [%]

snapshots may yield different results (we plan on gathering such a
corpus as future work).

There are few if any good reasons to host unstable URIs.
However, in reality there are currently few (if any) revenue streams
available through Linked Data publishing, leading to less server
resources and inevitably less emphasis on quality-of-service. In
addition, Linked Data consumers are sometimes naive/impolite
with respect to their demands on data providers, where prominent
publishers such as dbpedia.org (with a stability of 86% in
our analysis) receive high levels of traffic, and must carefully
implement triple-limits for SPARQL queries and dereferenced
documents to keep services running. Conversely, many Linked
Data sites are hosted on stable, high-bandwidth, university servers.
instable URIs are to be expected in Linked
Data, especially as it expands and diversifies. Link monitoring
and maintenance frameworks such as DSNotify [71] should help
attenuate the problem of URI instability by monitoring when
remote resources are created, removed, changed, updated or
moved, and revising links to these resources accordingly.

In any case,

5.2. Linking

Herein, we now discuss conformance with respect to how data
providers provide external links to other data providers (note that
we do not examine internal interlinkage). Again, we continue to
follow best practices extracted from [17].
Issue VI: Use external URIs

[...] the most valuable RDF links are those that connect a resource
to external data published by other data sources, because they
link up different islands of data into a Web. Technically, such an
external RDF link is a RDF triple which has a subject URI from one
data source and an object URI from another data source.[17,
Section 2.2]

What? Data providers are encouraged to provide a diverse set of
URIs that dereference to external Linked Data domains, effectively
providing links to remote data.
Why? Defining RDF links to external providers allows data
consumers to serendipitously discover related information on
the Web, be it in a (semi-)automated manner as performed by
crawlers, or in a direct manner as performed by users of Linked
Data browsers.

In fact, the principle aesthetic of Linked Data  as its name
suggests  is the importance of well-interlinked data. Not only do
links connect together islands of information, but self-organising
phenomena  such as preferential attachment [72]  bring an
inherent structure to the resulting network, where the most
in-demand nodes become the most heavily connected, etc. The
resulting structure is then amenable to various analyses  such

Table 9
Top five PLDs and bottom five PLDs ordered according to the number of external
PLDs they link to.

...
...
...
...

identi.ca
status.net
soton.ac.uk
semanticweb.org
appspot.com
semantic-web-grundlagen.de
prefix.ccD
opiumfield.com
hi5.com
fgiasson.com

el [PLD]

as those discussed in Section 6  that allow for identifying the
importance of various nodes in the graph.
Conformance? We deem data providers that offer a higher
outdegree of RDF links to external (RDF) data providers as being,
in general, more conformant with respect to Linked Data best-
practices. We count the number of external links as follows:
el(p) := |P  plds(dlc(p)  U) \ {p}|
where P is the set of 778 PLDs providing RDF to our corpus. In other
words, for a PLD p, el(p) counts the number of unique external
PLDs linked from a data-level position in the data hosted by p; only
links to PLDs found to host RDF are counted. We see a higher value
of el as denoting better conformance with respect to the stated
guideline.

In Table 9, we present the top five and bottom five PLDs with
respect to el; again, we only consider links to providers that were
confirmed to host RDF in our crawl. In total, in our corpus, we
found five PLDs that did not provide links to any external PLD. The
188 data-providers analysed linked to an average of 20.4 (38.2)
external PLDs.
Bias? Since this measure is not based on a ratio or other form of
quotient  but instead an absolute count  our results would underrepresent the level of external links for domains that are only
partially sampled, particularly those with very diverse link-sets.
In other words, the more documents analysed, the more external
links are likely to be found. However, by counting links on the
level of RDF domains, we believe that the absolute count would
plateau more quickly than counting, e.g., the number of external
documents linked. Also, since we omit links to PLDs for which we
did not find RDF/XML data, we may under-represent the level of
links to external domains providing RDFa.
Conclusions? Although the absolute figures here are difficult to
interpret (how many externally linked domains are enough?),
we can see that there is very high variability in terms of the level
of external linking on different domains, highlighted by a standard
deviation (38.2 PLDs) which is greater than the average (20.4 PLDs).
Those domains featuring diverse links to external RDF domains
are typically collaborative platforms (e.g., semanticweb.org
hosts a Semantic MediaWiki platform [73]) or offer some form
of centralised service (e.g., identi.ca and status.net act as
central hubs for an open-source micro-blogging platform, linking
to installations on other sites).

High-quality links between remote data providers are crucial to
realising the Linked Data vision. However, in the general case,
creating high-quality links to external RDF providers is often a
challenging task for publishers. Along these links, link-generation
frameworks and tools are important to see conformance to this
guideline realised in practice. One such proposal is SILK [74], which
allows publishers to specify declarative criteria by which two
datasets should be linked; once the criteria have been defined,
they can be re-executed intermittently to refresh the interlinkage
between the two providers.
Issue VII: Provide owl:sameAs links

It is common practice to use the owl:sameAs property for stating
that another data source also provides information about a
specific non-information resource. An owl:sameAs link indicates
that two URI references actually refer to the same thing. Therefore,
owl:sameAs is used to map between different URI aliases [...].
[17, Section 6]

What? The owl:sameAs property is used to directly relate two
URIs aliases: i.e., URIs that are coreferent. As such, owl:sameAs
denotes a form of equality between resources, and has a corresponding transitive, symmetric, and reflexive semantics [75].
Linked Data best-practices encourage publishers to specify
owl:sameAs relations between local resources and known URI
aliases, particularly to URIs minted in another domain.
Why? Linked Data principles mandate use of dereferenceable URIs
to identify resources (Issue III); now, if two different data providers
wish to contribute information about the same resource, they must
mint separate URIs to ensure this dereferenceability. Thereafter,
owl:sameAs links can be used between the two URIs to specify
that they denote the same resource. From another perspective (and
assuming correct usage) an owl:sameAs link states that an agent
can find more information about the given resource under the
given URI alias by dereferencing that URI alias.

These relations can be used by live Linked Data browsers to
(possibly semi-automatically) pull in additional remote information about a given resource. Additionally, various warehousing systems use (and/or generate) owl:sameAs relations to consolidate
or smush local data [7678,49,79,38,32], unifying the information
about a given resource  specified by different data providers under
different URI aliases  under a canonical identifier, thus effectively
integrating the different data contributions about that resource.
Conformance? We deem data providers that offer a higher
outdegree of owl:sameAs links to external providers as being
more conformant to Linked Data principles. Along these lines, we
use a similar metric as for the previous issue, but restricted to
owl:sameAs links:
el=(p) := |P  plds(dlc(sa(p))  U) \ {p}|
where sa(p) is the set of triples with the predicate owl:sameAs
hosted by p. This is equivalent to the previous measure, but
restricted to the set of owl:sameAs links (external URIs in the
subject and object of such triples are counted).

Thereafter, Table 10 enumerates the top five and bottom five
providers in terms of hosting owl:sameAs links to external
providers. Firstly, of the 188 PLDs analysed, 56 PLDs (29.8%) had
an owl:sameAs link to some external PLD also contributing RDF
data to our corpus.31 Each provider offered owl:sameAs links
to an average of 1.79 (5.19) external PLDs (the high population
standard deviation indicates that a small number of PLDs dominate
the average).
Bias? As per the previous guideline, the el=(p) measure is not a
quotient, but an absolute count. Thus again, our results may underrepresent the level of external links for domains that are only
partially sampled and that offer diverse owl:sameAs links.
Conclusions? The level of owl:sameAs interlinkage across domains is seemingly quite low, with 29.8% of the domains considered offering such links to an external RDF domain appearing in
our corpus.

Compared to the previous guideline recommending the provision of generic (RDF) links, generating owl:sameAs links to
remote domains is even more challenging given the definitive

31 Notably, uriburner.com had owl:sameAs links to a rather impressive 1274
external providers, but only 39 were to RDF PLDs contributing to our corpus.

A. Hogan et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

Table 10
Top five PLDs and bottom five PLDs ordered according to the number of external
PLDs they link to using owl:sameAs (and thereafter, by number of quads).

Table 11
Top five PLDs and bottom five PLDs ordered according to the total percentage
of triples that do not relate to RDF reification, containers or collections (ordered
thereafter by number of quads).

57...
...
...
...
...

harth.orgD
uriburner.com
revyu.com
deri.orgE
semanticweb.org
appspot.com
linkedlifedata.com
opiumfield.com
livejournal.com
hi5.com

el= [PLD]

...
...
...
...

hi5.com
livejournal.com
opiumfield.com
linkedlifedata.com
rdfize.com
nuigalway.ieE
sourceforge.net
ivan-herman.net
okkam.org
uniprot.org

rcc [%]

semantics of the owl:sameAs relation. Again, tools such as
SILK [74] can be used to generate owl:sameAs links to remote do-
mains; various works have explored domain-specific techniques
for interlinking the URI aliases of RDF datasets (e.g., see [48,80]);
other authors present best-effort mechanisms for mining URI
aliases from large RDF corpora in a generic and automatic manner
(e.g., see [81,32]).

Conversely, herein we have not looked at the accuracy of such
owl:sameAs links, which is difficult to determine by automatic
means. (We refer the reader to the works already mentioned in
Section 2.3 for more detail on this topic.)

5.3. Describing resources

In this section, we look at Linked Data best practices that discuss

how the local resources of interest should be described.
Issue VIII: Avoid prolix RDF features

We discourage the use of RDF reification as the semantics
of reification are unclear and as reified statements are rather
cumbersome to query with the SPARQL query language. [...] You
should think twice before using RDF collections or RDF containers
as they do not work well together with SPARQL. [...] can the
information also be expressed using multiple triples having the
same predicate?[17, Section 2.2]

What? Various RDF primitives are discouraged in Linked Data
publishing, including those that relate to (i) RDF reification, viz., the
properties rdf:subject, rdf:predicate, rdf:object and
the class rdf:Statement; (ii) RDF containers, viz., properties of
the form rdf:_n (n  N), the property rdfs:member and the
classes rdf:Alt, rdf:Bag, rdf:Seq and rdfs:Container;
and (iii) RDF collections, viz., the properties rdf:first, rdf:
rest, and the class rdf:List.
Why? With respect to RDF reification  speaking about triples
themselves within the RDF data-model  few systems support or
use this feature, and it is widely considered as cumbersome where
requests have been made for its deprecation [82,83].

Similarly, RDF containers have enjoyed little uptake in the
wild, with sparse support from tools. For example, the lightweight
semantics of RDF containers encoded in RDFS mandates an infinite
number of axiomatic triples of the form (n  N):
rdf:_n a rdfs:ContainerMembershipProperty ;

rdfs:domain rdfs:Resource ;
rdfs:range rdfs:Resource .

Finally, collections are perhaps the most widely adopted of the
three discouraged abovemost notably, various OWL axioms rely
on RDF collections [75], which, importantly, can be terminated
to indicate that the given set of elements is closed.32 However,
collections require a nested structure containing linked sublists,
which is cumbersome to represent in triples, and can be expensive
to support in performance- or data-intensive environments.

Further, as noted in the above quote, no explicit support for
any of the three features have been provided in SPARQL (other
than Turtle shortcuts for RDF collections)for example, there is no
support for returning the members of arbitrary length collections,
etc.33

Finally, we note that such primitives are typically expressed
using blank nodes  which are generated from RDF/XML and Turtle
shortcuts thereof  where, as per Issue I, blank nodes are expressly
discouraged in Linked Data best practices.
Conformance? We deem data providers that avoid use of RDF
reification, containers and collections to be more conformant to
Linked Data best practices. Along these lines, we use the following
metric to measure conformance with respect to this best practice:

rcc(p) := |data(p) \ RCC|
|data(p)|

where RCC denotes the set of all RDF triples relating to reification,
containers and collections as discussed at the outset, with:
(i) a predicate from the set {rdf:subject, rdf:predicate,
rdf:object, rdfs:member, rdf:first, rdf:rest} or of
the form rdf:_ n (n  N); or
from the set
{rdf:Statement, rdf:Alt, rdf:Bag, rdf:Seq, rdfs:
Container, rdf:List}.
Thereafter, rcc represents the ratio of triples hosted by p (in our
corpus) that are not of this form.

(ii) the predicate rdf:type and an object

Table 11 enumerates the top five and bottom five providers in
terms of not using the discouraged RDF primitives (presented in
ascending order of rcc, and thereafter by quadruple count). Of
the 188 PLDs analysed, we note that 148 PLDs (78.7%) had no use
of reification/containers/collections, whereas 167 PLDs (88.8%) had
less than 1% use thereof. Each provider hosted 99.1% (4.7 pp) of
non-RCC triples.
Conclusions? Most publishers (78.7%) do not use the features of RDF
discouraged by the guidelines; many of those that do only make
sparse use of such features.

where scalable RDFS materialisation engines are typically forced to
omit such inferences [8486] (for discussion, see [87]). Similarly,
three classes of containers have been defined in RDF  rdf:Bag,
rdf:Seq and rdf:Alt  but the semantics thereof have not been
adequately specified. Again, tool support is sparse, and calls have
been made for deprecation [82,83].

32 However, Linked Data best practices implicitly discourage use of the OWL
constructs that require collections [17].
33 We note that support for such queries are indirectly covered by SPARQL 1.1
proposals pertaining to property paths [88].

However, the guideline may be considered somewhat simplis-
tic. In particular, collections offer a standardised means of specifying ordered, closed lists of items in RDF, and as such, form an
important part of serialising certain OWL axioms in RDF, including
union classes, intersection classes, enumerations, property chains,
compound keys, pair-wise disjoint sets, etc. Although most of these
OWL features are rarely used in prominent Linked Data vocabularies [27, Section 4.4.3], [38], union classes and intersection classes
are used in the formal definition of, e.g., the SKOS vocabulary and
the Music Ontology [89], amongst others.
Issue IX: Re-use existing terms

In order to make it as easy as possible for client applications
to process your data, you should reuse terms from well-known
vocabularies wherever possible.[17, Section 3]

What? Another important aspect of Linked Data is the (re-)use
of declarative, extensible, shared vocabularies across the Web.
The above best-practice encourages re-use of existing class and
property terms  used prominently by other data-providers  as
defined in de-facto agreed-upon vocabularies.
Why? Re-using well-known terms to describe resources in a
uniform manner increases the interoperability of data published
in this manner. Indeed, the re-use of well-known vocabularies
supports not only data integration and management tasks, but is
also important for Linked Data consumer applications that have
tailored support for the most common vocabularies (e.g., [12]),
as well as for applications that offer domain agnostic userinterfaces for browsing and querying the data (e.g., [13,14,10,
11,15,9]). Otherwise, given complete disagreement on the use
of vocabularies between different data-providers, consumers are
faced with the crippling problem of heterogeneity with respect to
how the data can be interpreted, queried and displayed [90].
Conformance? We deem data-providers that exhibit a higheroverlap (with respect to external providers) in the vocabularies
used to describe their data as being more compliant with Linked
Data best practices. Along these lines, we first quantify the level of
overlap of class-membership terms for the local data of a provider
p as:

|{p  P \ {p} : x  cmem(p)}|

olc(p) := 

xcmem(p)

where P denotes the known set of PLDs, cmem(p) denotes the set
of terms appearing in the object of a triple t  data(p), where
 B and t.pred = rdf : type (class membership terms).
t.obj
Intuitively, olc denotes the sum of the number of external PLDs
also using the local class membership term, for each such term.
Analogously, we quantify the level of the overlap of local predicateterms with external providers as follows:

|{p  P \ {p} : x  pred(p)}|

olp(p) := 

xpred(p)

where pred(p) denotes the set of terms appearing in the
predicate of some triple t  data(p), but where we exclude
rdf:type (which was used by 187/188 PLDs, the exception being
lehigh.edu). Finally, to aggregate these two values, we use a
simple summation:
olt(p) := olc(p) + olp(p)
denoting the total overlap of vocabulary terms used to describe
local data, with respect to external providers.

In Table 12, we present the top five and bottom five dataproviders with respect to olt. The 188 data-providers analysed had
an average overlap of 6607 (3667) shared uses of a term.
Bias? As per the previous measures relating to linking, the given
olt metric is not based on a quotient, but on an absolute count.

Table 12
Top five PLDs and bottom five PLDs ordered according to total overlap of all classes
and properties with respect to use by external data providers.

w3.org
mit.edu
qdos.com
kanzaki.com
kasei.us
unitn.it
rkbexplorer.com
prefix.ccD
freebase.com
lehigh.edu

olt (PLD  term)

Thus, again, the smaller the relative sample of data we have for
a PLD, the more likely its score is to be under-represented. This
would be particularly true of domains with very heterogeneous
documents: i.e., with high variability in the class and property
terms used across individual local documents.
Conclusions? Although it is difficult to determine an optimal figure
for overlap, we do see that there are non-trivial levels of reuse across different data-providers. Some exceptions do exist,
however. For example, freebase.com is a prominent publisher
of RDF, providing general-interest resource descriptions on a broad
range of topics, but was found to have relatively low overlap
with other domains; most of the class and property terms are
minted in a local namespace, with few external properties used
(viz. owl:sameAs, cc:attributionURL and RDFS terms).

To improve the amount of vocabulary overlap between different
domains, it seems that two things are required: (i) the continuous
proposal and promotion of new vocabularies to expand coverage;
(ii) tools and search engines that enable publishers to find the
correct, most widely-adopted terms for their needs. With respect
to (i), web-based vocabulary editors such as Neologism [91] are an
important development, promoting vocabulary development and
maintenance as a community-driven process. With respect to (ii),
initiatives such as Linked Open Vocabularies34 that study and
promote legacy vocabularies are of vital importance.
Issue X: Cherry-pick vocabularies

It is common practice to mix terms from different vocabularies.
[17, Section 4]

What? Related to the previous issue, in re-using class and property
terms from legacy vocabularies (which are themselves likely to be
re-used by external datasets), data providers may often have to
cherry pick appropriate terms defined in different vocabularies
and namespaces: mixing terms from different vocabularies is
endorsed by Linked Data best practices.
Why? For example, many data providers need to describe
information about people, where FOAF is the vocabulary of choice.
Similarly, many providers may wish to describe information about
online presence or users, where SIOC is the de facto agreedupon vocabulary. For describing metadata about documents, terms
from the DC vocabulary are often used. Taxonomies and tagging
schemes are often represented in SKOS, etc.

Following the same rationale as for the previous issue  where
Linked Data best practices encourage data providers to use the
same terms to specify similar information about resources in
an agreed-upon manner  publishers are herein encouraged to
re-use terms wherever available. In other words, publishers are
(implicitly) discouraged from unnecessarily remodelling insular
vocabularies from scratch in their own namespace.

34 http://labs.mondeca.com/dataset/lov/index.html ; retr. 2011/08/17.

A. Hogan et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

Table 13
Top five PLDs and bottom five PLDs ordered according to number of unique
namespaces for class and property terms (and thereafter, by number of quads).
nss (URIs)

w3.org
uriburner.com
openlinksw.com
b4mad.net
wasab.dk
hi5.com
appspot.com
ontologyportal.org
unitn.it
lehigh.edu

...

159...

...
...

Table 14
Top five PLDs and bottom five PLDs ordered according to the percentage coverage
of labels and depictions defined for local dereferenceable resources (and thereafter,
by number of quads).

109...
...
...
...
...

rdfize.com
kit.eduE
ebusiness-unibw.org
l3s.de
ontologydesignpatterns.org
freebase.com
identi.ca
opiumfield.com
livejournal.com
hi5.com

hr (%)

Conformance? We deem the use of a larger number of vocabularies
 for class and property terms  by a given data provider to be
an indicator of conformance with respect to Linked Data best
practices. Along these lines, we use the following simple metric to
quantify conformance:
nss(p) := |{ns(u) : u  pred(p)  cmem(p)}|
where ns(u) denotes the namespace of a URI, which we compute
as the set of characters up until the last hash or slash. Note that we
only consider the namespaces of HTTP URIs and that we only count
namespaces that appear for at least one other PLD. Intuitively, nss
denotes the number of unique namespaces given by the vocabulary
terms used to describe the local data of p.

Along these lines, in Table 13 we present the top five and bottom
five data-providers in terms of the number of unique namespaces
used in their respective contributions to our corpus. Each of the 188
providers used predicates/classes from an average of 8.6 (7.1)
namespaces.
Bias? Again, the nss metric is based on an absolute count. Domains
for which we have smaller samples, and that have high variability
in the class and property namespaces used across documents, may
thus be under-represented by the measures score.
Conclusions? We see that it is indeed common practice to mix
vocabularies and select class and property terms from different
namespaces when describing Linked Data, with an average of 8.6
namespaces used per domain. As per the previous guideline, this
indicates that Linked Data publishers (often) partially self-organise
by selecting numerous legacy vocabularies as opposed to defining
(each time) a novel, insular, local vocabulary. Such agreement
helps reduce the heterogeneity of datasets merged from different
providers, making them easier to consume.

Interestingly, prominent Linked Data vocabularies often provide mappings to other vocabularies, formalised using the RDF and
OWL standards [38]. Thus, even if two publishers choose different
(but mapped) vocabularies, the data they provide can oftentimes
be semantically integrated using reasoning techniques. We note
however, that reasoning over Linked Data is a relatively new and
challenging topic [38], where efforts to avoid or minimise the need
for reasoning in the first place (i.e., by fostering agreement on vocabulary use as discussed for the previous issue) obviously have
immediate practical benefits.

5.4. Dereferencing resources

Herein, we look at those Linked Data best practices  as
introduced in [17]  that discuss what information about a resource
should be returned when its respective URI is dereferenced.
Issue XI: Give human-readable meta-data

We especially recommend the use of rdfs:label and foaf:depiction
properties whenever possible as these terms are well-supported by
client applications.[17, Section 4]

What? Publishers are encouraged to assign human-consumable
information to their resources in a standard way; in particular,
use of the property rdfs:label (used for attaching human
readable labels or names to resources) and the property
foaf:depiction (used for attaching digital images to resources)
are explicitly encouraged.
Why? Although RDF focuses on the provision of computerreadable resource descriptions, end-user applications often need
to render a human-consumable description of the resources.
Indeed, with respect to non-information resources, computers
have no knowledge of the referents (the entities) being described
 no way of mapping from a URI to the actual thing it identifies 
and thus human-consumable meta-information is a fundamental
requirement for applications to directly and effectively convey to
users what is being talked about. The usability of such applications
is thus dependent on the provision of some core information for a
high percentage of resources in the corpus: in particular, a label or
title for the resource being described, and/or an image depicting
the resource.
Conformance? We deem data-providers that provide a high
percentage of their dereferenceable resources with some value for
the rdfs:label and/or foaf:depiction properties to be more
conformant with respect to Linked Data best practices. Along these
lines, for each PLD, we check the percentage of such resources
(appearing in a data-level position of a triple) that are provided a
value for rdfs:label:

hrl(p) := |{u  DUp : lab(u)  data(p) = }|
where lab(u) denotes the (infinite) set of triples given by {u} 
{rdfs : label}  L and recalling that DUp denotes the set of
URIs from PLD p that were looked up and found to dereference
to RDF/XML content during our crawl. We also compute the
analogous measure hrp, but for pic(u), given similarly as the set
of triples {u}  {foaf : depiction}  U. Finally, we compute an
average of the hrl and hrp to give our final measure of conformance:
hr(p) := hrl(p) + hrp(p)

|DUp|

In Table 14, we present the top five PLDs with respect to this hr
measure. Notably, of the 188 PLDs, 71 (37.8%) did not have a value
for either property for any locally dereferenceable resources. Each
PLD provided a label/depiction (hr) for, on average, 10.2% (16.0)
of locally dereferenceable resources; taking just labels (hrl), the
analogous figure was 19.1% (31.1 pp); taking depictions (hrp), the
analogous figure was 1.2% (5.2 pp) respectively.

Given the prolific use of sub-properties of rdfs:label on
the Web of Data  properties such as foaf:name, doap:name
or the various SKOS label properties  we checked to see
whether reasoning would be able to automatically find more

Table 15
Top five PLDs and bottom five PLDs ordered according to the percentage coverage of
possibly implicit labels and depictions defined for local dereferenceable resources
(and thereafter, by number of quads).

168...
...
...
...
...

rdfize.com
dbtune.org
kit.eduE
advogato.org
robots.net
vox.com
freebase.com
opiumfield.com
livejournal.com
hi5.com

hr+ (%)

human-readable meta-information for the above two properties.
For rdfs:label, we found 24 (possibly indirect) sub-properties
in our corpus. For foaf:depiction, we found a sub-property
within FOAF itself (foaf:img), an inverse-property also in
FOAF (foaf:depicts), and four further sub-properties in remote vocabularies (sioc:avatar, ov:houseColor, mo:image,
swid:Property-3AFoaf-3Aimg). We then extend the previous
measures to include these additional human-readable properties
that can be found through reasoning (hrl+, hrp+, and their average:
hr+)we also include the original properties (thus, e.g., hr+  hr).
Thereafter, Table 15 gives analogous results, but for hr+. This
time, of the 188 PLDs, 20 (10.6%) still did not provide a (possibly
implicit) value for either property for any dereferenceable
resources (a reduction of 27.2 pp over hr). The average coverage of
possibly implicit labels and depictions (i.e., hr+) was 20.2% (16.5
pp), an overall increase of 10 pp with reasoning. Considering just
labels (hrl+), the analogous figures were 32.8% (30.4 pp) average,
an increase of 13.7 pp with reasoning. Considering just depiction
(hrp+), the figures were 7.5% (10.8 pp) average, a 6.3 pp increase
with reasoning.
Conclusions? Publishers frequently do not conform to this guide-
line, particularly for providing images. After reasoning, the average coverage of dereferenceable resources with at least one
rdfs:label value roughly doubles, and the number of resources
with a foaf:depiction value increases by a factor of roughly
6, albeit still remaining low at 7.5%.

There are a number of possible factors for this. Firstly,
the prominent use of alternative naming properties that are
not formally mapped to rdfs:label  such as foaf:nick,
dc:title, rss:title, and dct:title (cf. Table 2)  leads to
a lack of agreement on how human readable labels should be
assigned to resources, which cannot be resolved automatically
by reasoning. Consumers typically must hard-code the most
popular labelling alternatives into their applications. Secondly,
information resources and other auxiliary resources, such as
those used to represent n-ary predicates, may not have natural
human-readable labels, or may not have any suitable images
available, etc. Another possible explanation is that publishers
do not appreciate the importance of making human-consumable
metadata available due to a lack of tangible applications using their
data.

Providing human-consumable meta-information for resources
is important for allowing users to visualise, browse, and understand RDF data, where providing labels and depictions establishes
a baseline. Further textual information about the resource, preferably given as a value for rdfs:comment, can also be valuable.
Extending the concept further, different vocabularies may have different combinations of properties whose values are interesting to
human users; work like Fresnel [92], which allows for specifying
how data from different vocabularies should be rendered, go in this

Table 16
Top five PLDs and bottom five PLDs ordered according to percentage of local outlinks
given in the dereferenced document (and thereafter by number of quads).

...
...
...
...

livejournal.com
opiumfield.com
ontologycentral.comD
vox.com
ontologyportal.org
twoozer.com
xmlns.com
nickshanks.com
gregheartsfield.com
hi5.com

do (%)

direction, with the potential to extend human-readability beyond
just labels and images.
Issue XII: Dereference forward-links

The description: The representation should include all triples from
your dataset that have the resources URI as the subject. This is the
immediate description of the resource.[17, Section 5]

What? As discussed in Issue III, the URIs assigned to resources
should dereference to (related) representations thereof. This
representation should contain all locally available triples where
the given URI of the resource is in the subject position.
Why? Many Linked Data applications rely on the assumption that
content relevant to the resource will be returned, in RDF, as a
response to a HTTP lookup on its URI.35 Intuitively, the above
recommendation encourages data providers to return as complete
an immediate description of a given local resource as possible
to those requesting agents, allowing applications to achieve a
higher recall with respect to query answering, or to render a more
complete description of the resource of interest to the user.
Conformance? We deem data-providers that return a high percentage of triples with locally minted subject URIs  triples that appear
in a local document  to also be given in the dereferenced document of that subject; for brevity, we call such triples local out-
links. Along these lines, we give the following quantification of
conformance:

do(p) := |{t  deref(t.sub) : t.sub  ldlc(p)  U}|
|{t  data(p) : t.sub  ldlc(p)  U}|

where we only include URIs (t.sub) that were looked up during
our crawl (the set U). Intuitively, for each PLD p, do denotes the
average number of outlinks of local URIs found in the respectively
dereferenced documents.

In Table 16, we present the top and bottom five PLDs with
respect to the given do measure. Of the 188 PLDs  where again,
three did not mint any local URIs (Issue III)  36 PLDs (19.1%) gave
all known local outlinks in all known dereferenced documents;
60 PLDs (31.9%) provided more than 99% of
local outlinks
in the respectively dereferenced documents. We encountered
no local outlinks for any URI local to the hi5.com: for this
domain, all such local URIs are documents that are only given
rdfs:seeAlso inlinks. Across the 188 data providers surveyed,
the average percentage of local outlinks returned in the respective
dereferenceable documents was 83.6% (20.1 pp).
Bias? Again, we do not consider the case where URIs dereference to
RDFa embedded in HTML documents. Also, documents that contain

35 We have previously made proposals for a priori checks that determine a degree
of likelihood as to whether dereferencing a URI is likely to contain relevant content
for a certain mime-type [93].

A. Hogan et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

very few (or no) dereferenceable URIs are less likely to be picked
up by our crawler. Finally, for data providers with partial samples,
we may underestimate the number of local outlinks, which may
cause the do measure to be over-represented. (It is worth noting
that this analysis does not consider blank nodes  covered already
by Issue I  which are naturally not dereferenceable.)
Conclusions? This guideline is core to the Linked Data principles
themselves, allowing consumers to follow their nose when
looking for information about a resource of interest. As previously
discussed, the dereferenceability of data is a key assumption for
many Linked Data applications (cf. [64,8]).

Indeed, it seems that there is relatively high conformance to this
guideline, where the domains surveyed provide, on average, 83.6%
of local outlinks in the dereferenced document for the given subject
URI. Thus, a Linked Data consumer can expect a high yield of triples
where a resource appears in the subject position by dereferencing
its URI. However, as we will see for the next issue, this yield does
not hold to the same extent for triples where the resource appears
in other positions.
Issue XIII: Dereference back-links

Backlinks: The representation should also include all triples from
your dataset that have the resources URI as the object [allowing]
browsers and crawlers to traverse links in either direction. [17,
Section 5]

local

What? Closely related to the previous issue, Linked Data best
practices recommend the provision of all
inlinks or
backlinks  locally available triples in which the resource URI
appears as an object  in the dereferenced document returned for
the given resource.
Why? Arguably the distinction between inlinks and outlinks in
terms of descriptiveness is a trivial one for RDF, where a resource
appearing in an object position is equally being described. For
example, consider:

ex:page foaf:maker ex:Joan.
ex:Joan foaf:made ex:page.

Both triples describe the resources ex:page and ex:Joan in
an equivalent manner, irrespective of the positioning thereof.
Similarly, let us say that we only know the second triple above,
and that ex:page is dereferenced: by only returning outlinks,
the consuming agent will not know of any relation between
ex:page and ex:Joan, and, taking the example of a live Linked
Data browser, users will not be able to navigate between these
nodes. In other words, inlinks can themselves implicitly represent
outlinks,36 and inlinks allow for navigating from a given resource
to those resources that are related to it.
Conformance? For locally minted and dereferenceable URIs, we
deem data-providers that return a high percentage of local triples
with the dereferenced term as object (local inlinks), in the
respectively dereferenced document, to be highly conformant. We
give a similar quantification of conformance as for local outlinks:

di(p) := |{t  deref(t.obj) : t.obj  ldlc(p)  U}|
|{t  data(p) : t.obj  ldlc(p)  U}|

Note that by the definition of ldlc(p), as a special case, we do
not count objects of rdf:type triples in the analysis, where,
e.g., it would be unrealistic (and probably undesirable) to expect

Table 17
Top five PLDs and bottom five PLDs ordered according to percentage of local inlinks
given in the dereferenced document (and thereafter, by number of quads).

...
...
...
...
177...
...
...
...
...

ontologyportal.org
ebusiness-unibw.org
174.129.12.140 (open-biomed.org.uk)
skipforward.net
semantic-web-grundlagen.de
umbel.org
lexvo.org
loc.gov
geonames.org
hi5.com

di (%)

FOAF to provide a list of all foaf:Person members in the FOAF
vocabulary dereferenced by that class term.

In Table 17, we present the top and bottom five PLDs with
respect to the given di measure. Of the 188 PLDs, 14 PLDs
(7.4%) gave all known local inlinks in all known dereferenced
documents; 20 PLDs (10.6%) provided more than 99% of local
inlinks in the respectively dereferenced documents. Conversely, 11
PLDs (5.9%) offered no dereferenceable outlinks, with 17 domains
(9%) providing less than 1% of locally available inlinks through
dereferencing. We also encountered two domains  unitn.it
and prefix.cc  that had no local inlinks for any local URI (we
consider these scores as zero). Across the 188 data-providers, the
average percentage of local outlinks returned in the respectively
dereferenced documents was 55.2% (32.9 pp).
Bias? Similar biases exist as per the previous issue.
Conclusions? Compared to dereferencing outlinks, publishers are
much less conformant when it comes to dereferencing inlinks:
compared with an average 83.6% of outlinks being dereferenced
across the domains surveyed, the analogous figure for inlinks was
55.2%. Similarly, a relatively high standard deviation of 32.9 pp
indicates significant variability in conformance across publishers.
Some of the domains not providing any dereferenceable inlinks
are quite prominent in the Linked Data community, where in
particular, the dereferenceable RDF hosted by geonames.org
consists only of the local outlinks of the geographical resource in
question, and meta-data about the document.37

Many of the local URIs appearing in the object position are
information resources, often HTML pages. These are associated
with a given subject resource with typed links, e.g., foaf:page,
foaf:weblog, gn:locationMap, etc. Such information resources are typically assigned no further meta-data other than
the aforementioned inlink(s), and do not dereference to RDF (al-
beit, we do not check for RDFa). Further still, certain resources
may feature a high indegree, which makes the inclusion of all inlinks in the dereferenced document somewhat impractical. For ex-
ample, the URI http://identi.ca had 1.66 million inlinks through
the foaf:accountServiceHomepage property in our corpus,
many of which were local; making all of these inlinks dereferenceable  e.g., by embedding RDFa into the main identi.ca webpage
 would obviously be impractical.
Issue XIV: Describe & licence documents

Metadata: The representation should contain any metadata you
want to attach to your published data, such as a URI identifying
the author and licencing information. These should be recorded
as RDF descriptions of the information resource that describes a
non-information resource; that is, the subject of the RDF triples

36 Such implicit knowledge can be formally represented using an owl:
inverseOf relation.

37 See, e.g., http://sws.geonames.org/2964179/about.rdf ; retr. 2011/08/18.

Table 18
Top five PLDs and bottom five PLDs ordered according to percentage of local
documents with some embedded meta-information (ordered thereafter by number
of quads).

...
...
...
...
168...
...
...
...
...

identi.ca
dbtropes.org
vox.com
ontologyportal.org
twatter.com
uniprot.org
ontologycentral.comD
rdfabout.com
freebase.com
hi5.com

dmr (%)

should be the URI of the information resource. [...] In order to
enable information consumers to use your data under clear legal
terms, each RDF document should contain a licence under which
the content can be used.[17, Section 5]

What? The information resources (possibly) returned through
dereferencing non-information resources are, of course, themselves dereferenceable resources. Thus, by implication, the previous two premises of Linked Data best practices again apply:
locally known inlinks and outlinks relating to the information resource should be returned in the dereferenced document. Emphasis is placed on returning licencing information.
Why? Returning meta-information about documents follows the
same rationale as before: descriptions of information resources
can similarly contain any form of meta-data the provider deems
relevant. However, the above stated best practice emphasises that
licencing information should be attached, such that consumers are
made aware of the legal rights and permissiveness under which the
pertinent data are made available.
Conformance? Since this issue is partially covered by the previous
two, herein we focus on conformance with respect
to (i)
providing meta-information about documents and (ii) licencing
information. Thus, we deem data providers that return (i) a high
percentage of resource descriptions for their documents, and (ii)
a high percentage of licencing information for these resource
descriptions, as being better conformant to Linked Data best
practices. With respect to (i), we quantify conformance as follows:

dmr(p) := |{s  S : pld(s) = p  s  dlc(get(s))}|

|{s  S : pld(s) = p}|

where S denotes the set of known sources. Here, dmr denotes the
percentage of source URIs local to p that themselves appear as a
data-level constant in the RDF graph they return.

Along these lines, in Table 18 we provide the top five and bottom five data-providers with respect dmr. We found 20 providers
(10.6%) that gave no meta-data for any of their documents, where
in Table 18, we show the five largest. Conversely, 77 PLDs (41%)
offered some meta-data for all documents, where again we only
show the five largest. On average, the 188 data providers offered
some meta-data in 75.7% (36.6 pp) of the documents.

With respect to licencing, we note that the guidelines do not
mention a specific property to relate a document to its licence.
From the set of property terms appearing in the predicate position
of a triple in our corpus, we performed a search for the string
licen to determine a set of candidates that publishers might be
using. After filtering out some obviously irrelevant properties (such
as fb:common.licensed_object.provenance), we present
the top ten such properties in Table 19 according to the number

Table 19
Top ten licencing properties according to use in our corpus.

Property

xhtml:license
dc:licence
cc:license
dc:rights
sz:license_text
dbo:license
dct:licence
dbp:licence
wrcc:license
doap:license
dct:rights

Quads

Table 20
Top five PLDs and bottom five PLDs ordered according to percentage of local
documents with embedded licencing meta-information (ordered thereafter by
number of quads).

28...
...
...
...
...

fluffyandmervin.com
l3s.de
geospecies.org
smhowell.net
mfd-consult.dk
rdfize.com
linkedlifedata.com
opiumfield.com
livejournal.com
hi5.com

dmrl (%)

of times they were used as a predicate. As suggested by Bizer et al.,
we also include the properties dc:rights and dct:rights [52].
We note that some of these properties may not be intended for
usage on documents, where we note that the value of the property
doap:license should give licencing information with respect
to a software project. In any case, we believe that Linked Data
guidelines should more explicitly recommend a chosen licencing
property for RDF documents published on the Web.

With respect to conformance, we re-use the dmr(p) metric,
but where in the numerator, we only consider descriptions of
documents that included a value for a property containing the
string licen or for the properties dc:rights or dct:rights;
we denote this value as dmrl(p). The top-five and bottom-five
providers resulting from this analysis are presented in Table 20,
where we found that only 27 PLDs (14.4%) returned some licencing
information for some local document. We found that, on average,
providers gave licencing information for 3.4% (15.4 pp) of local
documents.
Conclusions? Few documents provide licencing information directly as part of the document meta-data. Further still, there is a
palpable need for (i) an agreed-upon licencing property, and (ii)
an agreed set of common licence URIs; to avoid consumers again
having to hard-code support for all alternatives used by publish-
ers. The most complete proposal along these lines is provided by
the Creative Commons vocabulary.38

We note that there may be other licencing practices not
checked by our analysis. For example, publishers may choose
to make licencing meta-data available for an entire dataset  a
logical grouping of documents  in a single VoiD description [94].
However, others have also observed a worrying lack of licencing
information for RDF documents published on the Web, where,

38 http://creativecommons.org/ns; retr. 2011/08/28.

A. Hogan et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

e.g., Bizer et al. put the figure at 15% of Linked Data publishers
offering document-level licencing [52].39

6.1. PLD-level graph

6. PageRank of domains

Having analysed various issues relating to Linked Data con-
formance, we now briefly look at measures that use links-based
analysis to rank the different domains hosting RDF in our corpus.
In particular, we are interested in whether or not there is a correlation between the PageRank scores of the different domains
and their conformance to the guidelines measured in the previous
section. Later, we will also use the PageRank scores to present a
weighted aggregation of conformance measures (as opposed to the
arithmetic-mean aggregation introduced thus far).

There is a long history of links-based analysis over Web data
 and in particular over hypertext documents  where links are
seen as a vote for the relevance or importance of a given document.
Seminal works exploiting the link structure of the Web for ranking
documents include HITS [95] and PageRank [96].

Whilst link-based analysis, such as PageRank, are an established
technique when considering the Web of Documents, there are
some fundamental differences between the notion of a (hyper)link
on the traditional Web of Documents, and the notion of a (RDF)
link on the Web of Data. On the Web of Documents, a hyperlink
is typically interpretable as a pointer to the content of the target
page; when considering PageRank, hyperlinks are often intuited as
votes from source pages to target pages. On the Web of Data, links
can have arbitrary labels (i.e., predicates), can be of various forms,
and may serve a variety of purposes, including (but not limited to):

(i) the target domain hosts a description of a class or property

used on the host domain (schema links);

(ii) the target domain was involved in the generation of the source
data, or provides a centralised service upon which the source
domain relies;

(iii) the target domain describes legacy resources that refer to the
same real-world entities as the source domain (owl:sameAs
links);

(iv) the source domain does not wish to describe a particular
resource, but instead out-sources the description to the target
domain with a link.

Along these lines, there are many possible ways one might consider
applying PageRank over Linked Data.

More recent works (e.g., [97,98,58]) have presented various
attempts at incorporating links-based analysis techniques for
ranking RDF data, with various end-goals in mind: most com-
monly, prioritisation of informational artefacts in user result-
views. Detailed discussion of the different approaches is out of
the current scope, where for our purposes, we choose a straightforward approach inspired by the work of Harth et al. [58], who
propose (amongst other approaches) a PLD-level ranking of Linked
Data. (A similar proposal has been put forward by Delbru et al. [98],
who also look at performing ranking on a dataset-level, the results of which are then propagated to ranks of intra-dataset enti-
ties.)

The first step towards ranking PLDs is to construct a directed
graph representing the link structure between the different PLDs,
which we now discuss.

Recalling the Linked Data principles enumerated in Section 3.2,
according to LDP4, links should be specified simply by using
external URI names in the data. These URI names should
dereference to an RDF description of themselves according to LDP2
and LDP3 respectively.
Following these principles, we define our PLD-level graph as
follows. Let D := (V , E) represent a simple directed graph where
V  P is a set of PLDs (vertices), and E  V  V is a set of pairs of
vertices (edges). Letting pi, pj  V be two vertices, then (pi, pj)  E
= pj and there exists some u  U such that u appears in
iff pi
data(pi), and pld(u) = pj. In other words, an edge extends from
pi to pj if pi hosts a triple that contains a URI under the authority
of pj and/or that redirects to pj. Notably, the link is forwarded
through any redirect such that, e.g., if the URI mentioned in pi has
the authority purl.org but redirects to xmlns.com (as would
be the case for a FOAF URI), the link is given to the latter domain
(pj = xmlns.com), not the former redirection domain.40

6.2. PageRank algorithm

pr(p)

pjE(pi)

|V| + d 

pV

|V| + d 

We now introduce the PageRank algorithm [96], which we
apply to the PLD-level graph.
Taking D := (V , E), let E(p) denote the set of direct successors
(outlinks) of vertex (PLD) p, let E(p) denote the set of direct
predecessors (inlinks) of p, and let
V := {p  V : E(p) = }
denote the set of vertices with no outlinks (aka. dangling vertices).
The PageRank of a vertex pi in the directed graph D := (V , E) is
then given as follows [96]:
pr(pi) := 1  d
where d is a damping constant (typically d := 0.85 [96]), which
helps ensure convergence in the following iterative calculation,
and where the middle component splits the ranks of dangling
nodes evenly across all other nodes.
Now let w := 1d|V| represent the weight of a universal (weak
link) given by all non-dangling nodes to all other nodesdangling
nodes split their vote evenly and thus do not require a weak link;
we can use a weighted adjacency matrix M as follows to encode
the graph D := (V , E):
|E(pj)| + w,

|V| ,

pr(pj)
|E(pj)|

mi,j :=

if (pj, pi)  E
if pj  E
otherwise


w,

where this stochastic matrix can be thought of as a Markov chain
(dubbed the random-surfer model). The ranks of all PLDs can be
expressed algebraically as the principal eigenvector of M, which in
turn can be estimated using the power iteration method up until
some termination criteria (fixed number of iterations, convergence
measures, etc.) is reached. We refer the interested reader to [96]
for more detail on PageRank, and to [14] for our distributed
implementation thereof.

39 Dodds has also raised similar concerns; cf. http://www.flickr.com/photos/
ldodds/4043803502/ ; retr. 2011/08/12.

40 In fact, purl.org does not appear as a PLD in our analysis at all since it always
redirects to an external domain.

6.3. PLD PageRank results

From our billion-quadruple corpus, we extracted the PLDlevel graph, which contained 778 vertices and 7647 edges, giving
an average degree of 9.83 edges per vertex. Four vertexes had
no inlinks,41 whereas every vertex had at least one outlink. In
Table 21, we present the top-25 scoring PLDs after applying the
PageRank analysis over this graph. Note that we italicise domains
that contributed less than 1000 quads to our corpus. We will now
discuss the top ten results.

Unsurprisingly, the w3.org domain  which hosts the rdf:,
rdfs:, owl: and skos: namespace documents, amongst others
 tops the table.42

Otherwise, the top half of the table is dominated by domains
that host popular vocabularies: (2) dublincore.org hosts the
dc: and dct: namespaces; (3) xmlns.com hosts the foaf: and
wot: namespaces; (5) rdfs.org hosts the sioc: and related
namespaces; (6) resource.org hosts the rss: namespace,
as well as an older cc: namespace; (8) vocab.org hosts a
variety of namespaces, including bio:, frbr:, ov:, rel:, vann:,
whisky:; and (6) usefulinc.com hosts the doap: namespace.
Further down the table, we find domains not necessarily
associated with popular vocabularies. Notably, (4) loc.gov and
(9) vu.nl rank highly despite having a much smaller in-degree
than many PLDs below them: loc.gov was one of two domains
linked by dublincore.org, from which it gained a significant
boost in rank, where, in turn, vu.nl was one of three domains
linked from loc.gov, which accounted for most of its rank. This is
an example of highly-ranked domains with low out-degree passing
on high rank scores to their neighbours. Wrapping up the top ten
 and as already mentioned  (10) the dbpedia.org domain is a
prominently-linked publisher of RDF on the Web.

Thus, we see that top-ranked domains attract inlinks (and thus
higher PageRank) for very different reasons. In fact, we believe its
unclear whether Linked Data is mature enough, and well-linked
enough, to allow for meaningful links-based analysis, particularly
on the level of domains: many of the cross-provider links are
being generated in automated ways, or are being generated in
large batches by a few data providers (to few data providers). We
believe that there is little in the way of ad hoc, manual interlinkage
being performed by humans on the current Web of Datausing
the analogy of links being interpreted as votes on the Web, there
are relatively few human voters (or, currently, incentives to vote).
However, as the Web of Data diversifies, so too will the benefits of
PageRank-esque measures over the burgeoning graph. For now, we
are interested to see how the presented PageRank scores correlate
with the conformance scores for the data providers in our corpus.

7. Synopsis of analysis

Herein, we present overall summaries and aggregations for
conformance with respect to the different guidelines, also looking
at correlation with the PageRank scores of the different domains
(Section 7.2). We then look at aggregating conformance scores
across the different guidelines and PageRank scores into one
overall measure (Section 7.3).

41 This implies that the links to these domains must only have appeared in the
seed list of URIs for the crawl.
42 Only the globalnames.org, sig.ma and unitn.it domains did not link to
w3.org in our data.

Table 21
Top twenty-five ranked PLDs and number of inlinks and outlinks from/to external
PLDs; domains with less than 1000 quads are italicised.

w3.org
dublincore.org
xmlns.com
loc.gov
rdfs.org
resource.org
ldodds.com
vocab.org
vu.nl
dbpedia.orgE
usefulinc.com
identi.ca
semanticweb.org
rdfweb.org
creativecommons.org
mit.edu
isi.edu
geonames.org
danbri.org
wordpress.com
daml.org
stanford.edu
sourceforge.net
umd.edu
mindswap.org

Rank
0.175582
0.092568
0.068402
0.043293
0.017477
0.017409
0.016112
0.014381
0.013240
0.010859
0.010494
0.009672
0.009231
0.007931
0.006679
0.006079
0.006066
0.005914
0.005886
0.005859
0.005656
0.005403
0.005315
0.005080
0.004688

In-degree

Out-degree

7.1. Kendalls  coefficient

First, we introduce Kendalls  coefficient [99], which we use
to compare the orderings given by conformance scores of each
domain and its respective PageRank score. Given that our data may
contain outliers and follow non-normal distributions, we favour
the non-parametric (rank-based) Kendalls  over the parametric
(value-based) Pearsons coefficient: although some information is
lost by compressing absolute values into ranks, non-parametric
tests are more robust in the face of outliers, which are to be
expected in data such as ours. We also favour Kendalls  over
Spearmans  (a non-parametric version of Pearsons) since 
is based on simple distances, whereas  is based on squared
differences, implying that outliers in ordering  i.e., fewer, longer
distances  are punished more by  than  when compared with
many, shorter distances. Additionally, we are also grateful for the
fact that Kendalls  measure is simpler to present and explain [99],
vs. the Spearmans  intuition of characterising the monotonicity
for a function mapping one ordering to the other. (Informally, we
also ran Spearmans  measures and found that they correspond
closely with Kendalls  where we choose to only present the latter
for brevity.)
Towards defining Kendalls  , let 1 and 2 denote two total
orderings defined for a set S (where |S|  2), intuitively, Kendalls
 quantifies the amount of agreement between the ordered pairs
given by the two orderings. In particular, it measures the ratio
of (dis)agreement across all possible pairs for the two orderings,
represented in an interval [1, 1].
Agree(1,2, S) := S  S  <1  <2
denote the set of ordered pairs (si, sj) from S  S for which si <1 sj
and si <2 sji.e, Agree is the set of unique unequal and non-tied
pairs such that both orderings agree. Also, let
Disagree(1,2, S) := S  S  <1  >2
similarly denote the unique set of unequal and non-tied pairs such
that the orderings disagree. Now, for 1, 2, and S (omitting the
arguments for brevity):
 := (|Agree|  |Disagree|)

First let

n(n1)

A. Hogan et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

where n = |S  S| denotes the cardinality of the set of all ordered
pairs that can be constructed from S, and where n(n1)
denotes
the cardinality of the set of all unordered, unequal pairs. Thus,
Kendalls  measures the difference between the total number of
all pairs for which both orderings agree and those for which they
disagree, normalised by the total number of independent nontrivial pairs to compare. Thus,  is a rational number in the interval
[1, 1], where a value of 0 indicates no correlation (agreement)
between the orderings, 1 indicates perfect correlation (agreement)
between the orderings, and 1 indicates perfect disagreement
between the orderings (i.e., <1 = >2).
However, ties may often occur in our scenario, where si =1 sj
or si =2 sj (or both). For Kendalls  , tied pairs are simply excluded
from the analysis, with the denominator modified to only count
non-tied pairs.

Finally, we also present the statistical significance (p-value) of
the  measure, which denotes the probability of the given observations occurring under the null hypothesis: i.e., the probability of
finding the given (or weaker) correlation if the two orderings were
completely independent. As per tradition [100], we interpret a
p-value of less than 0.05 to be a significant result.

7.2. Aggregating results for issues

In Table 22, we summarise all of the results for all of the
issues/measures encountered thus far. Note that Issue IV (referring
to URI length) is the only exception to the rule that a higher
value corresponds to higher conformance. We present a number
of aggregate scores for each measure. We first present the average
and population standard deviation for each guideline across the
188 data providers contributing more than 1000 quads to our
corpus. We then present the analogous figures for all 778 data
providers in our corpus. Given that the latter averages are mostly
influenced by low-volume publishers, we also present weighted
averages based on the size (quad count) of providers, and their
PageRank.

First, let posw(p) denote a straightforward (non-parametric)
ranking of PLDs prescribed by some orderingin this case, we use
size and PageRank, denoted poss and pospr respectively. For size,
we count the number of documents, where for example poss(p) =
3 indicates that PLD p contributed the third-most documents to
our corpus (possibly tied with another PLD). Similarly, pospr (p) =
1 would indicate that p was the highest ranked PLD in our
PageRank scores (i.e., p = w3.org; cf. Table 21). We then use
these weights (denoted generically by posw(.)) for averaging the
conformance scores for an issue x as follows:


pP

wcsx :=

(|P| + 1  posw(p))  csx(p)


|P| + 1  posw(p)

pP

where P is the set of all PLDs in our corpus. Again, w stands for
a generic weight, which we instantiate by s | pr such that scsx
denotes the size-weighted average for issue x and pr csx denotes
the PageRank-weighted average for issue x. We also present the
accompanying biased weighted standard deviation (such that
distances from the mean are also weighted). Where w is omitted
(csx), we denote a non-weighted arithmetic mean.

Finally, we also present Kendalls  correlation between
PageRank and conformance scores, where again, a positive value
indicates positive correlation between the two orderings they
prescribe for the PLDs.

On a high level, with respect to conformance, we see that
providers current abide by guidelines regarding the use of HTTP
URIs (Issue II), hosting stable URIs (Issue V), avoiding use of

verbose RDF features (Issue VIII), and making local outlinks
dereferenceable (Issue XII). On the other hand, other guidelines
are not well abided by, particularly the provision of humanreadable metadata (Issue XI), providing licencing information for
documents (Issue XIVb), and dereferencing inlinks (Issue XIII).
Thus, applications relying on these features of Linked Data 
for example, for allowing users to navigating through inlinks,
rendering domain-agnostic display of resources, or determining
whether the consumers intended use of the data is legal  are
inherently affected.

Regarding the differences between considering only the 188
PLDs with >1000 quads and all PLDs, we see that many of the
average conformance scores remain relatively stable. However, by
including the lower-volume publishers, we (unsurprisingly) see a
marked drop in those scores given in absolute terms, such as the
level of external linkage, the number of triples dereferenced, and
the variety of vocabularies and vocabulary terms used.

When looking at the size-weighted averages, the conformance
figures quite often float between the scores considering only the
PLDs with >1000 quads and all PLDs; we see a slight increase again
in the level of external linkage, dereferenced triples, and in the
variety of vocabulary usage.

When looking at the PageRank-weighted averages, we see a
slight drop in some conformance scores, particularly those that
restrict use of RDF features such as blank nodes, non-HTTP URIs
and reification/containers/collections. We note that there may be
valid exceptions to these guidelines, particular when modelling
vocabularies in OWL; recalling that many of the highest-ranked
domains host vocabularies, this may explain these observations.
Further, looking at the significant results given by Kendalls 
for correlation between conformance and PageRank, we see some
similar results. Highly-ranked domains tend not to follow the
aforementioned guidelines restricting use of RDF features and
non-HTTP URIs. In addition, highly-ranked PLDs are less likely
to provide all inlinks in the locally dereferenced document, or
to provide metadata for the document itself. Conversely, highlyranked PLDs tend to provide more dereferenceable data, to contain
a higher level of external linkage, to use more vocabularies, and
to provide more human-readable meta-data (again, vocabularies
commonly provide rdfs:label scores directly for class and
property terms).

7.3. Aggregating results for PLDs

In the previous section, we looked at aggregating scores for
each guideline by taking various forms of mean across the PLDs
surveyed. In this section, we conversely look at aggregating scores
for each PLD across the guidelines presented. As such, we formulate
a high-level conformance metric that aggregates scores across
Issue IXIV, as follows:
(i) each individual issue is given an equal weight with respect to

the overall conformance measure;

(ii) wherever possible, each PLD should gain/lose conformance
score in a manner appropriate with their absolute conformance to each issue.

With respect to Item ii above, we considered using a purely nonparametric (position-based) aggregation of overall conformance,
but found this to often be unrepresentative and overly simplistic
for example, ordnancesurvey.co.uk uses one blank node and
371 thousand URIs, but would be in position 65/188 for the bn
metric.

Along these lines, for each issue we score each data-provider
on a scale from [0100], where 100 denotes the highest level of
conformance. Metrics that are in the interval [01] are directly

A. Hogan et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

|P|

converted to percentages. For metrics that are not percentage- or
ratio-based  viz., those discussed for Issue IV, VI, VII, IX, X  we
resort to a positional based ranking that we then linearly bin into
the [0100] interval using:

csx(p) := (|P| + 1  posx(p))  100
where x denotes an issue in {IV, VI, VII, IX, X}, |P| is the number of
data-providers under analysis, and posx(p) is the position assigned
to that data-provider by the associated metric of conformance.
Thus, for example, all providers tied for first (most conformant)
for issue x will be assigned csx(p) = 100; all tied for third will
be assigned csx(p) = (188+13)100
Next, for Issue III, XI, & XIV where we presented two measures
each, we first take the local average of these measures as the final
score for csIII, csXI and csXIV: for example, csXI is given the average
score for providing human-readable meta-information with and
without reasoning enabled.

= 98.9, etc.

Finally, we take the overall per-PLD aggregated score as the

average of the scores for the individual issues:


csx(p)
x{I...XIV}
|{I . . . XIV}|

cs(p) =

giving us our final overall conformance measure for provider p. We
exclude the conformance measure csV(p) from the average for the
47 providers for which we had no information about the stability
of URIs from our nine snapshots.

Thereafter, for reference, we present the results for the 188
PLDs with >1000 quads in Table A (at the end of the paper),
along with their individual score for each issue presented. We do
not claim that lower ranked providers definitively host data of less
quality or worth, but rather, we instead claim that they host
data in a manner that is less conformant to Linked Data guidelines.
The average score for the providers was 64.7% (8.0 pp).43 In the
Table, we also present the ranking position of each provider in
the rightmost column (under pr). Looking for correlation between
the orderings given by a higher cs score and a higher PageRank
score, we computed Kendalls  = 0.17 with p = 0.00005, denoting a significant, weak-to-moderate correlation between the
two orderings. The largest distance between the two orderings was
given by loc.gov, which was ranked 9th in terms of PageRank,
but ranked 172nd in terms of overall conformance (recall from
Section 6.3 that this PLD received much of its PageRank through
a single link from dublincore.org). Along these lines, Table 23
enumerates the remaining top ten, where all results bar Z 8 & Z
10 had high PageRank and low conformance scores.

Conversely, Table 24 presents the top ten data providers with
respect to the highest average position in terms of conformance
and PageRank. We note that these providers rank highly for our
two distinct quality measures, and thus we would consider them
 in a generic sense  to be the highest scoring providers resulting
from our analysis, providing highly-conformant data, and being
heavily linked from other highly-ranked providers.

8. Discussion and outlook

We have seen that the conformance of data providers varies
significantly for the different Linked Data guidelines highlighted,
which in turn may have implications for ad hoc consumers
operating over the Web of Data. Although publishers may

43 We acknowledge that with the inclusion of the position-based scores, the
absolute values of cs have little by way of direct meaning.

Table 23
Top ten PLDs with the greatest (absolute) difference in position in terms of PageRank
(pr) and conformance (cs).

loc.gov
unitn.it
geonames.org
vu.nl
okkam.org
typepad.com
livejournal.com
chirub.com
xmlns.com
jobsonica.com

|pospr  poscs|

poscs

pospr

Table 24
Top ten PLDs with the highest average positions for PageRank (pr) and conformance
(cs).

dbpedia.orgE
mit.edu
identi.ca
w3.org
rdfweb.org
qdos.com
l3s.de
sourceforge.net
bblfish.net
fu-berlin.de

poscs+pospr

poscs

pospr

(reasonably) decide to (partially) forego compliance with respect
to individual guidelines  and as we have discussed in this paper
 each such guideline has, in the general case, a clear rationale. By
aggregating a conformance score for a wide range of guidelines, we
believe that the result offers a good indication as to the inherent
consumability of the resulting data by generic, domain-agnostic,
applicationsbe it live Linked Data browsers, or warehousing
engines, or systems operating on similar principles. Along these
lines, we presented a comprehensive summary of results for all
providers of a non-trivial amount of data found in our empirical
corpus, giving a breakdown of their conformance score for fourteen
individual guidelines, as well as their aggregated conformance
score and independent PageRank scorewe hope that this will
serve as a useful reference list for publishers as well as developers
of consumer applications.

Non-conformance could be explained by a number of factors.
First, certain data accessed during our crawl may be old, and
possibly pre-date Linked Data publishing. Second, as we have
discussed, while all guidelines are well-motivated in the general
case, some guidelines are not necessarily definitive or universal
where there may be valid reasons for occasional non-conformance.
Third, following certain guidelines may be impractical for certain
domains, where for example providing images for all entities is
often not practical or useful (esp., if the entities described are
more conceptual, such as time periods or sensor measurements,
etc.). Fourth, we believe that many patterns emerging in Linked
Data publishing are down to precedent, where newer publishers
follow the example set out by more established publishers; this
may explain, for example, the endemic lack of per-document
licencing. That said, we note that guidelines that are core
to the original Linked Data principles (use HTTP URIs, make
them dereferenceable, etc.) are typically well adhered to, with
the possible exception of making inlinks dereferenceable (a
specialisation of LDP4).

However, aggregated conformance alone is itself insufficient to
characterise the quality of a data-provider: for example, we could
 with fairly minimal effort  create a new data-provider that
would earn the highest possible aggregated conformance score in
our analysis (without necessarily having any meaningful content).
Indeed, we have seen (e.g., in Table A) that many times, lowvolume publishers are the most compliant with the guidelines.
Thus, we see PageRank and other links-based analysis measures as
complimenting our conformance scores: our intuition here is that
the conformance scores give insights as to the structural quality
of the data providers contribution, whereas the PageRank scores
give insights into the importance of their contribution. We saw
that highly-ranked providers tended to be non-conformant with
respect to certain guidelines, particular those discouraging use of
particular RDF features; we argue that these guidelines are more
exceptional in nature. Conversely, highly-ranked providers tended
to be more conformant for guidelines pertaining to interlinkage.

Returning to the more general topic of Linked Data quality, we
have very much followed Vrandecics intuition [51] of looking at
specific, quantifiable issues, which often tell more about what data
providers are doing wrong, as opposed to what they are doing
right. Indeed, one of the most useful indicators of data quality is
competency with respect to a given task: are the data sufficient to
enable a particular application? Linked Data guidelines represent
a basic, structural
form of competence for applications to
locate, parse, retrieve, discover, and consume content. However,
other than some specific recommendations with respect to
providing human-readable meta-data and licencing information,
the presented guidelines are quite vague on the topic of how
content should be modelled and presented, what granularity
of modelling maximises data utility in the general case, how
data should be versioned, how authorship provenance should be
specified, how the semantics of the data can be effectively used to
increase interoperability, how the coverage and scope of the data
should be advertised, etc. Such issues are inherently difficult to
study, but also inherently important to study.

With respect to future work, we would next like to do a
more specialised empirical study for vocabularies in Linked Data,
particularly their use of the RDFS and OWL standards, how they are
interlinked and mapped, how they are externally redefined, what
kinds of reasoning the defined semantics enables, what modelling
patterns exist, what are the prevalent issues, etc. We have already
compiled some initial results on the most commonly used features
of RDFS and OWL in Linked Data vocabularies [38, Table 5.2], which
we would like to expand into a more comprehensive study of
the Linked Vocabulary ecosystem. Furthermore, we hope to repeat
the experiments presented in this paper for a future, sufficiently
different sample of the Web of Data; we would be particular
interested in studying data published as RDFa or other embedded
formats, how trends change over time, conformance for new
guidelines that emerge (e.g., as per [27]), etc. We would also like
to investigate a more granular means of identifying individual
data-providers than the current rather catch-all notion of PLDs
used herein. Finally, we are currently setting up some monitoring
experiments that will take snapshots of Linked Data from different
publishers at regular intervals, and that when studied, we hope will
yield insights into the dynamicity and evolution of such datasets
over time.

9. Conclusion

particular quantifiable aspects relating to Linked Data quality
for individual data providers: their conformance with respect to
Linked Data guidelines and their PageRank score.

We have offered insights into the current level of conformance
with respect to the current wisdom on how to publish Linked
Data, where we see, for example, that few providers attach humanreadable meta-data to their resources (particularly images), or
licencing information to their documents.44 Similarly, providers
often do not provide locally-known inlinks in the dereferenced
document of a given resource. Thereafter, lack of such conformance
has a varying knock-on effect with respect to consumer applica-
tions, which must be taken into account by developers.

We also looked at the PageRank scores of data providers as a
complimentary analysis to our conformance measures. We found
that highly-ranked data providers are more likely to use RDF
features discouraged by Linked Data guidelines, but are also more
likely to offer a diverse set of links to external domains.

We then proposed a straightforward aggregated conformance
measure for data-providers, presenting results for 188 domains in
our sample of data; we considered the qdos.com domain to be
the most compliant across all guidelines, where many personal
domains also featured highly. For our proposed aggregated
conformance, we found a significant, moderate correlation with
PageRank; however, we also found highly-ranked providers that
had very low conformance with respect to the stated guidelines. In
particular, the loc.gov domain, which was highly ranked on the
basis of a single link from dublincore.org, was found to have
a low conformance score. A similar result was given for the more
established geonames.org and livejournal.com domains,
etc.; loosely speaking, the data provided by these domains were
found to be rather uniform (e.g., not using diverse vocabulary) and
insular (e.g., linking to few external domains). Conversely, the two
most conformant and highly ranked providers were the prominent
dbpedia.org and mit.edu domains.

To conclude, empirical analyses of Linked Data adoption are
imperative to understand what is working and what is not and
to inform future directions for the Semantic Web standards and
Linked Data guidelines. Herein, we presented our own contribution
to the area, which focuses on Linked Data conformance. We hope
to see many more such empirical analyses  particularly those that
go beyond raw dataset sizes, and those that focus on Linked Data
quality and usage patterns  emerge in the next few years.

Acknowledgements

We would like to thank the anonymous reviewers and the
editors for their helpful feedback and comments. We would also
like to thank those involved in the Pedantic Web Group. The work
presented herein has been funded in part by Science Foundation
Ireland under Grant No. SFI/08/CE/I1380 (Lion-2), and by an IRCSET
postgraduate scholarship.

Appendix

See Table A.

With respect to Linked Data  where the provision of data
is only loosely coupled with the modus-operandi of consumer
applications  universal notions of quality are inherently difficult
to pinpoint and measure. Herein, we have focused on two

44 A result echoed by Dodds; see http://www.ldodds.com/tmp/iswc-legal-
frameworks-overview.pdf (retr. 2011/09/01) for discussion regarding licencing on
the Web of Data.

A. Hogan et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

Table A
Quality metrics for all domains providing more than 1000 quadruples.

pld
qdos.com
harth.orgD
wikier.org
iandavis.com
l3s.de
dbpedia.orgE
tommorris.org
bblfish.net
gromgull.net
mit.edu
deri.orgE
kanzaki.com
brainbird.net
identi.ca
rdfweb.org
openlinksw.com
jobsonica.com
sourceforge.net
geospecies.org
fu-berlin.de
urmf.net
dbtune.org
status.net
w3.org
ivan-herman.net
iberliner.de
ontologi.es
walsh.name
b4mad.net
bleeper.de
bio2rdf.org
budez.com
linkedmdb.org
rdfize.com
soton.ac.uk
floss.pro
deri.ieE
3kbo.com
semanticweb.org
nickshanks.com
chirup.com
plasr.com
0nl1ne.at
android-pt.net
tomheath.com
kit.eduE
br3nda.com
androidpt.com
myxavier.com
microblogs.org
kjernsmo.net
mkbergman.com
tweet.ie
recit.org
opera.com
nuigalway.ieE
uriburner.com
advogato.org
9001700.com
twitterpile.com
kasei.us
dagoneye.it
milaro.net
mindswap.org
naijapulse.com
bbc.co.uk
pipian.com
taxonconcept.org
4july.me
sodetailed.org
tuitui.info
torrez.us
nytimes.com
mulestable.net
mfd-consult.dk

cs

ii

iii

iv

vi

vii

viii

ix

xi

xii

xiii

xiv

pr

Table A (continued)

pld
lingvoj.org
bentio.com
semantic-web.at
revyu.com
snell-pym.org.uk
tflearning.com
twit.tv
plik.com.br
larkc.eu
petstatus.com
heppnetz.de
idehen.name
smhowell.net
leuksman.com
tllts.org
robots.net
googlecode.com
twatter.com
linkedct.org
ldodds.com
ordnancesurvey.co.uk
squeak.im
metafora.it
waka.me
haktweet.com
us.es
ajft.org
ontologyd.p..org
scoffoni.net
eye48.com
linkedlifedata.com
dublincore.org
dowhatimean.netD
appspot.com
titticimmino.com
ebusiness-unibw.org
hii.co.il
umbel.org
shef.ac.uk
alandix.com
svenbilt.com
semanticschool.com
bluereek.com
miggi.fi
talis.com
ontologyportal.org
data.gov.uk
wasab.dk
secondintegral.com
dbtropes.org
uniprot.org
dataincubator.org
yeebok.com
bestbuy.com
thesecretlair.com
diving-robot.de
uniba.it
daml.org
vocab.org
ourcoffs.org.au
tdwg.org
xmlns.com
gregheartsfield.com
zbw.eu
fluffyandmervin.com
spip.org
wingerz.com
dajobe.org
freebase.com
twoozer.com
sebastiankruk.com
feebleforce.com
pbj.ca
vu.nl
fancygonzo.net

cs

ii

iii

iv

vi

vii

viii

ix

xi

xii

xiii

xiv

pr

(continued on next page)

A. Hogan et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 1444

Table A (continued)

pld
daviding.com
vaenl1.com
aregar.it
rkbexplorer.com
livejournal.com
designmills.com
zitgist.com
telegraphis.net
s.-w.-grundlagen.de
korrekt.org
rdfabout.com
geonames.org
fgiasson.com
eswc2006.org
europa.eu
vox.com
174.129.12.140
code4lib.org
outestoi.com
skipforward.net
fffff.at
todaysmama.com
ahvoice.com
lexvo.org
opiumfield.com
opencalais.com
fao.org
reshouts.com
typepad.com
kaufkauf.net
okkam.org
loc.gov
prefix.ccD
ontologycentral.comD
hi5.com
lehigh.edu
hopcroft.name
unitn.it

cs

ii

iii

iv

vi

vii

viii

ix

xi

xii

xiii

xiv

