Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 5783

Contents lists available at SciVerse ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

journal homepage: www.elsevier.com/locate/websem

A general Datalog-based framework for tractable query answering
over ontologies
Andrea Cali a,b, Georg Gottlob c,b, Thomas Lukasiewicz c,

a Department of Computer Science and Information Systems, Birkbeck, University of London, UK
b Oxford-Man Institute of Quantitative Finance, University of Oxford, UK
c Department of Computer Science, University of Oxford, UK

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 12 November 2010
Received in revised form
6 March 2012
Accepted 6 March 2012
Available online 5 April 2012

Keywords:
Datalog
Ontologies
DL-Lite
Conjunctive queries
Chase
Constraints

1. Introduction

Ontologies and rules play a central role in the development of the Semantic Web. Recent research in
this context focuses especially on highly scalable formalisms for the Web of Data, which may highly
benefit from exploiting database technologies. In this paper, as a first step towards closing the gap
between the Semantic Web and databases, we introduce a family of expressive extensions of Datalog,
called Datalog, as a new paradigm for query answering over ontologies. The Datalog family admits
existentially quantified variables in rule heads, and has suitable restrictions to ensure highly efficient
ontology querying. We show in particular that Datalog encompasses and generalizes the tractable
description logic E L and the DL-Lite family of tractable description logics, which are the most common
tractable ontology languages in the context of the Semantic Web and databases. We also show how
stratified negation can be added to Datalog while keeping ontology querying tractable. Furthermore,
the Datalog family is of interest in its own right, and can, moreover, be used in various contexts such as
data integration and data exchange. It paves the way for applying results from databases to the context
of the Semantic Web.

 2012 Elsevier B.V. All rights reserved.

Ontology languages, rule-based systems, and their integrations
play a central role in the development of the Semantic Web. Although there are a plethora of approaches to tight and loose (or
hybrid) integrations of ontology languages and rule-based systems,
and to generalizations of ontology languages by the ability to express rules, there is literally no previous work on how to generalize
database rules and dependencies so that they can express ontological axioms. This is surprising, especially also because there are recently strong interests in the Semantic Web community on highly
scalable formalisms for the Web of Data, which would benefit very
much from applying technologies and results from databases.

In this paper, we try to fill this gap. We propose and study variants of Datalog that are suited for efficient ontological reasoning,
and, in particular, for tractable ontology-based query answering.

 This paper is a significantly extended and revised version of a paper that
appeared in: Proceedings of the 28th ACM Symposium on Principles of Database
 Corresponding author.
Systems (PODS 2009), pp. 7786, ACM Press, 2009 [35].

E-mail addresses: andrea@dcs.bbk.ac.uk (A. Cali), georg.gottlob@cs.ox.ac.uk

(G. Gottlob), thomas.lukasiewicz@cs.ox.ac.uk (T. Lukasiewicz).

1570-8268/$  see front matter  2012 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2012.03.001

We introduce the Datalog family of Datalog variants, which extend plain Datalog by the possibility of existential quantification
in rule heads, and by a number of other features, and, at the same
time, restrict the rule syntax in order to achieve tractability. The
goal of this paper is threefold:
 First, we aim at bridging an apparent gap in expressive power
between database query languages and description logics (DLs)
as ontology languages, extending the well-known Datalog
language in order to embed DLs.
 Second, we aim at transferring important concepts and proof
techniques from database theory to DLs. For example, it was
so far not clear how to enrich tractable DLs by the feature of
nonmonotonic negation. By the results of the present paper, we
are now able to enrich DLs by stratified negation via mappings
from DLs to Datalog with stratified negation.
 Last but not least, we have a genuine interest in studying new
fascinating tractable query languages. We are convinced that
these languages are of independent relevance and interest,
even without reference to ontological reasoning. Moreover, we
have reasons to believe that the languages that we discuss
may be useful for data exchange [1], and constraint satisfaction
for automatic configuration, where value invention techniques
are used [2,3]. For lack of space, we do not discuss these
applications in detail here.

A. Cali et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 5783

In addition to playing a key role in the development of the
Semantic Web, ontologies are also becoming more and more
important in the database area, for example, in data modeling and
information integration [4]. While much of the research on DLs
of the last decade was centered around decidability issues, there
is a current trend towards highly scalable procedures for query
answering over ontologies. A family of well-known DLs fulfilling
these criteria is, e.g., the DL-Lite family [5,6] (which has recently
been further extended in [7,8]). The following example briefly
illustrates how queries can be posed and answered in DL-Lite.

Example 1. A DL knowledge base consists of a TBox and an
ABox. For example, the knowledge that every conference paper
is an article and that every scientist is the author of at least
one paper can be expressed by the axioms ConferencePaper 
Article and Scientist  isAuthorOf
in the TBox, respectively,
while the knowledge that John is a scientist can be expressed
by the axiom Scientist(john) in the ABox. A simple Boolean
conjunctive query (BCQ) asking whether John authors a paper is
X isAuthorOf (john, X ).

An ABox can be identified with an extensional database, while
a TBox can be regarded as a set of integrity constraints involving,
among others, functional dependencies and (possibly recursive)
inclusion dependencies [9,10]. An important result of [5,6] is that
the DL-Lite description logics, in particular, DL-LiteF , DL-LiteR, and
DL-LiteA, are not only decidable, but that answering (unions of)
conjunctive queries for them is in logspace, and actually in AC0,
in the data complexity, and query answering in DL-Lite is FOrewritable (see below) [5].

In the context of DLs, data complexity is the complexity of query
answering over input ABoxes, when both the TBox and the query
are fixed. This scenario is very similar to query answering with
well-known rule-based languages, such as Datalog. It is easy to see
that plain Datalog can neither directly express DL-Lite disjointness
constraints (e.g., ConferencePaper  JournalPaper), nor the functional constraints used in DL-LiteF (e.g., (funct hasFirstAuthor)).
Moreover, as observed in [11], the lack of value creation makes
plain Datalog not very well suited for ontological reasoning with
inclusion axioms either (e.g., Scientist  isAuthorOf ). It is thus
natural to ask whether Datalog can be suitably modified to nicely
accommodate ontological axioms and constraints such as those expressible in the DL-Lite family. In particular, we have addressed the
following two questions:
Question 1. What are the main modifications of Datalog that are
required for ontological knowledge representation and
query-answering?

Question 2. Are there versions of Datalog that encompass the
DL-Lite family of description logics, and that share the
favorable data complexity bounds for query-answering
with DL-Lite? If so, how do they look like?

As an answer to Question 1, we identified the possibility of
having existentially quantified variables in rule heads as the main
Datalog extension enabling ontological knowledge representation
and reasoning. Datalog rules extended this way are known as
tuple generating dependencies (TGDs), see [12]. Given that fact
inference (let alone conjunctive query answering) under TGDs is
undecidable [13,14], we must somehow restrict the rule syntax
for achieving decidability. We thus require that the rule bodies of
TGDs are guarded. This means that in each rule body of a TGD there
must exist an atom, called guard, in which all non-existentially
quantified variables of the rule occur as arguments. An example
of a guarded TGD is P(X )  R(X , Y )  Q (Y )  Z R(Y , Z ).
Guarded TGDs form the first Datalog formalism that we
consider. Note that this formalization was briefly mentioned
in [15]. We embark in Section 3 in a detailed analysis of the data

complexity of this formalism. To this aim, we study the behavior
of the (oblivious) chase algorithm [16,12], a well-known algorithm
for constructing a (usually infinite) universal model chase(D, ) of
a given extensional database D and a set of guarded TGDs .

As a key lemma, we prove that for each set of guarded TGDs ,
there exists a constant  such that for every extensional database
D, whenever a ground atom a is generated while chasing D with
, then the ground atom a and a whole derivation of a from D
and  must be generated at depth at most  . Using this lemma,
we can show that whenever a Boolean conjunctive query (BCQ)
Q maps homomorphically into chase(D, ), then it maps into the
initial fragment of constant depth k|Q| of chase(D, ). This result
is a nontrivial generalization of a classical result by Johnson and
Klug [17] on inclusion dependencies, which are a restricted class of
guarded TGDs. For the complexity of fact inference and answering
BCQs, we then get the following result:

Theorem: Given a database D and a fixed set of guarded TGDs
, deciding whether D   |	 a for facts a is ptimecomplete and can be done in linear time. Moreover,
deciding whether D   |	 Q is not harder than BCQ
evaluation over extensional databases (without guarded
TGDs).

Guarded TGDs are sufficiently expressive to model the tractable
description logic E L [18,19] (as well as the more expressive
E LIf [20]; see Section 9.2), but are still more expressive than
actually necessary for modeling DL-Lite. Therefore, in Section 4, we
consider the further restricted class of linear TGDs. These consist
of TGDs whose bodies contain only single atoms (and so are
trivially guarded, or TGDs whose bodies contain only guards, called
multi-linear TGDs). Note that this class generalizes the class of
inclusion dependencies. A detailed analysis of chase properties of
linear TGDs yields the following results.

Theorem: Given a database D, a fixed set of linear TGDs , and
a fixed BCQ Q , deciding whether D   |	 Q is in AC0.
In particular, this problem is FO-rewritable, i.e., Q and 
can be compiled into a first-order formula  such that for
each database D, it holds that D   |	 Q iff D |	 .

In order to capture DL-Lite, we further enrich guarded Datalog
by two additional other features: negative constraints and keys. A
negative constraint is a Horn clause whose body is not necessarily
guarded and whose head is the truth constant false which we
denote by . For example, the requirement that a person ID
cannot simultaneously appear in the employee(ID, Name) and in
the retired(ID, Name) relation can be expressed by:
employee(X , Y )  retired(X , Z )  .
While negative constraints do add expressive power to Datalog,
they are actually very easy to handle, and we show that the
addition of negative constraints does not increase the complexity
of query answering. We also allow a limited form of equalitygenerating dependencies, namely, keys, to be specified, but we
require that these keys be  in a precise sense  not conflicting
with the existential rules of the Datalog program. We lift a result
from [21] about non-key-conflicting inclusion dependencies to the
setting of arbitrary TGDs to prove that the keys that we consider do
not increase the complexity. With these additions we have a quite
expressive and still extremely efficient version of Datalog.
Theorem: Query answering with Datalog based on guarded
TGDs (resp.,
linear TGDs), negative constraints, and
keys that do not conflict with the TGDs is possible
in polynomial time in the data complexity (resp., FO-
rewritable).

with guarded Datalog and the special case of linear Datalog,
respectively. In Section 5, we show how negative constraints
can be added. In Section 6, we discuss the addition of keys.
Sections 79 deal with the translation of the DL-Lite family
to Datalog, while Section 10 defines stratified Datalog. In
Section 11, we discuss related work. Section 12 summarizes the
main results and gives an outlook on future research. Note that
detailed proofs of all results are given in Appendices AG.

Fig. 1. Relationships between Datalog

0 , Datalog

1 , DL-Lite, and E L.

Let us refer to the above basic version of Datalog (linear TGDs,
negative constraints, and non-conflicting keys) as Datalog
0 , and to
the guarded version with negative constraints and non-conflicting
keys as Datalog
1 . We are finally able to show in Sections 79
that all description logics of the well-known DL-Lite family
of description logics [5] smoothly translate into Datalog
0 . The
relationships between Datalog
1 , DL-Lite, and E L are
summarized in Fig. 1.
Theorem: The description logics DL-LiteX of the DL-Lite family and
their extensions with n-ary relations DLR-LiteX can all
be reduced to Datalog
0 .

0 , Datalog

Example 2. The axioms of the TBox of Example 1 are translated to
the TGDs ConferencePaper(X )  Article(X ) and Scientist(X )  Z
isAuthorOf (X , Z ), while the axiom of the ABox is translated to the
database atom Scientist(john).

The translation from the DL-Lite family into Datalog

0 is so
smooth and natural, that Datalog
0 can rightly be called a DL.
Note that Datalog
0 is strictly more expressive than any of the
description logics of the DL-Lite family. Interestingly, we prove that
(at most binary) linear TGDs alone can express useful ontological
relationships such as, e.g., manager(X )  manages(X , X ) that are
not expressible in any of the description logics of the DL-Lite family.
In the DL community, there is currently a need for enhancing
tractable DLs by some nonmonotonic negation (where negative
information is derived from the absence of positive one). It was
asked whether there is some stratified negation for DLs. Given our
translation from DL-Lite to Datalog, this amounts to ask whether
there is a satisfactory stratified negation for Datalog, and, in
particular:
Question 3. Can we extend the concept of safe stratified negation

to guarded TGDs?

In classical Datalog with stratified negation [22], each stratum
is finite, and the stratum i + 1 can be evaluated as soon as all
facts in stratum i have been derived. With guarded TGDs, this is
not so. Given that usually an infinite number of facts is generated
by the chase, each stratum, including the lowest may be infinite,
which means that single strata may at no time be fully computed.
The difficulty is then, how long to wait before deciding that a
negative atom in a rule body is satisfied. We solve this problem
by making use of the above-mentioned constant-depth bounds
for atom derivations. We define a new version of the chase that
uses a constant-depth bound for establishing whether a negative
atom whose arguments all appear in those of a (positive) rule
guard is satisfied. We show that this semantics is stratification-
independent, corresponds to a perfect model semantics, and that
query answering can be done in polynomial time for guarded TGDs
and is FO-rewritable for linear TGDs.

The rest of this paper is organized as follows. In Section 2, we
give some preliminaries and basic definitions. Sections 3 and 4 deal

2. Preliminaries

In this section, we briefly recall some basics on relational
databases, conjunctive queries (CQs), Boolean conjunctive queries
(BCQs), tuple-generating dependencies (TGDs), and the chase
procedure relative to such dependencies.

2.1. Databases and queries

As for the elementary ingredients, we assume constants, nulls,
and variables as follows; they serve as arguments in atomic formulas in databases, queries, and dependencies. We assume (i) an
infinite universe of (data) constants  (which constitute the normal domain of a database), (ii) an infinite set of (labeled) nulls N
(used as fresh Skolem terms, which are placeholders for unknown values, and can thus be seen as variables), and (iii) an
infinite set of variables X (used in queries and dependencies).
Different constants represent different values (unique name as-
sumption), while different nulls may represent the same value. We
assume a lexicographic order on  N, with every symbol in N
following all symbols in . We denote by X sequences of variables
X1, . . . , Xk with k  0.

We next define atomic formulas, which occur in databases,
queries, and dependencies, and which are constructed from
relation names and terms, as usual. We assume a relational schema
R, which is a finite set of relation names (or predicate symbols,
or simply predicates) along with the names of the attributes of
each relation. A position P[i] identifies the i-th argument of a
predicate P. A term t is a constant, null, or variable. An atomic
formula (or atom) a has the form P(t1, . . . , tn), where P is an
n-ary predicate, and t1, . . . , tn are terms. We denote by pred(a) and
dom(a) its predicate and the set of all its arguments, respectively.
The latter two notations are naturally extended to sets of atoms and
conjunctions of atoms. A conjunction of atoms is often identified
with the set of all its atoms.

We are now ready to define the notion of a database relative
to a relational schema, as well as the syntax and the semantics
of conjunctive and Boolean conjunctive queries to databases. A
database (instance) D for a relational schema R is a (possibly
infinite) set of atoms with predicates from R and arguments from
. A conjunctive query (CQ) over R has the form Q (X) = Y (X,
Y), where (X, Y) is a conjunction of atoms with the variables
X and Y, and eventually constants, but without nulls. Note that
(X, Y) may also contain equalities but no inequalities. A Boolean
CQ (BCQ) over R is a CQ of the form Q (). We often write a BCQ as the
set of all its atoms, having constants and variables as arguments,
and omitting the quantifiers. Answers to CQs and BCQs are defined
via homomorphisms, which are mappings :   N  X 
  N  X such that (i) c   implies (c) = c, (ii) c  N
implies (c)    N, and (iii)  is naturally extended to atoms,
sets of atoms, and conjunctions of atoms. The set of all answers to
a CQ Q (X) = Y (X, Y) over a database D, denoted Q (D), is the
set of all tuples t over  for which there exists a homomorphism
: X  Y    N such that ((X, Y))  D and (X) = t.
The answer to a BCQ Q () = Y (Y) over a database D is Yes,
denoted D |	 Q , iff Q (D) = , i.e., there exists a homomorphism
: Y    N such that ((Y))  D.

A. Cali et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 5783

Example 3. Consider an employee database, which stores information about managers, employees, and departments, where
managers may supervise employees and direct departments, and
employees may work in a department. The relational schema R
consists of the unary predicates manager and employee as well as
the binary predicates directs, supervises, and works_in with obvious
semantics. A database D for R is given as follows:
D = {employee(jo), manager(jo), directs(jo, finance),

supervises(jo, ada), employee(ada), works_in(ada, finance)}.
It encodes that Jo is an employee and a manager directing the
finance department and supervising Ada, who is an employee
working in the finance department. A CQ is given by Q (X ) =
manager(X )  directs(X , finance), which asks for all managers
directing the finance department, while a BCQ is given by Q () =
X (manager(X )  directs(X , finance)), often simply abbreviated
as the set of atoms {manager(X ), directs(X, finance)}, which asks
whether there exists a manager directing the finance department.
The set of all answers to the former over D is given by Q (D) = {jo},
while the answer to the latter is Yes.

2.2. Tuple-generating dependencies (TGDs)

Tuple-generating dependencies (TGDs) describe constraints
on databases in the form of generalized Datalog rules with
existentially quantified conjunctions of atoms in rule heads; their
syntax and semantics are as follows. Given a relational schema R, a
tuple-generating dependency (TGD)  is a first-order formula of the
form XY (X, Y)  Z  (X, Z), where (X, Y) and  (X, Z)
are conjunctions of atoms over R (without nulls), called the body
and the head of  , denoted body( ) and head( ), respectively. We
usually omit the universal quantifiers in TGDs. Such  is satisfied
in a database D for R iff, whenever there exists a homomorphism
h that maps the atoms of (X, Y) to atoms of D, there exists an
extension h of h that maps the atoms of  (X, Z) to atoms of D. All
sets of TGDs are finite here.

Example 4. Consider again the employee database D of Example 3.
Some constraints on D along with their encoding as TGDs (where
we use , to denote the Boolean conjunction ) are as follows:
 every manager is an employee:
manager(M)  employee(M);
 every manager directs at least one department:
manager(M)  P directs(M, P);
 every employee who directs a department is a manager, and
supervises at least another employee who works in the same
department:
employee(E), directs(E, P)  E manager(E),

supervises(E, E), works_in(E, P);

 every employee supervising a manager is a manager:
employee(E), supervises(E, E), manager(E)
 manager(E).

It is not difficult to verify that all the above TGDs are satisfied in

D. Consider next the database D defined as follows:
D = D  {manager(ada)}.
Then, the first, the third, and the last TGD listed above are all
satisfied in D, while the second TGD is not satisfied in D.

Query answering under TGDs, i.e., the evaluation of CQs and
BCQs on databases under a set of TGDs is defined as follows. For
a database D for R, and a set of TGDs  on R, the set of models of
D and , denoted mods(D, ), is the set of all (possibly infinite)
databases B such that (i) D  B and (ii) every    is satisfied in
B. The set of answers for a CQ Q to D and , denoted ans(Q , D, ),
is the set of all tuples a such that a  Q (B) for all B  mods(D, ).
The answer for a BCQ Q to D and  is Yes, denoted D  |	 Q , iff
ans(Q , D, ) = , i.e., B |	 Q for every B  mods(D, ). Note
that query answering under general TGDs is undecidable [13], even
when the schema and TGDs are fixed [15].
Example 5. Consider again the employee databases D and D of
Examples 3 and 4, respectively, and the set of TGDs  of Example 4.
Then, D is a model of D and , i.e., D  mods(D, ), while D is not
 mods(D, ), since the second and
a model of D and , i.e., D
the third TGD of Example 4 are not satisfied in D. Trivially, every
model of D and  is a superset of D. In particular, the following
databases B1, B2, and B3 are models of D and :
B1 = D  {directs(ada, finance), supervises(ada, ada)},
B2 = D  {directs(ada, finance), supervises(ada, bill),
B3 = D  {directs(ada, toy), supervises(ada, bill),

works_in(bill, finance)},
works_in(bill, toy)}.

On the contrary, the following database B4 is not a model of D and
, since the third TGD of Example 4 is not satisfied in B4:
B4 = D  {directs(ada, toy), supervises(ada, tom)}.
Notice that the atom employee(jo) is true in all models of D and
; therefore, the BCQ {employee(jo)} evaluates to true over D and
. This also holds for the BCQ {directs(ada, X )}, while the BCQ
{directs(ada, finance)} evaluates to false over D and , since it is
false in the database B3.

We recall that the two problems of CQ and BCQ evaluation
under TGDs are logspace-equivalent [23,17,1,24]. Moreover, it
is easy to see that the query output tuple (QOT) problem (as a
decision version of CQ evaluation) and BCQ evaluation are AC0reducible to each other. Henceforth, we thus focus only on the
BCQ evaluation problem. All complexity results carry over to the
other problems. We also recall that query answering under TGDs
is equivalent to query answering under TGDs with only singleton
atoms in their heads. In the sequel, we thus always assume
w.l.o.g. that every TGD has a singleton atom in its head.

2.3. The TGD chase

The chase was introduced to enable checking implication of
dependencies [16], and later also for checking query containment [17]. It is a procedure for repairing a database relative to a set
of dependencies, so that the result of the chase satisfies the depen-
dencies. By chase, we refer both to the chase procedure and to its
output. The TGD chase works on a database through so-called TGD
chase rules (for an extended chase with also equality-generating
dependencies (EGDs), see Section 6). The TGD chase rule comes in
two flavors: restricted and oblivious, where the restricted one applies TGDs only when they are not satisfied (to repair them), while
the oblivious one always applies TGDs (if they produce a new re-
sult). We focus on the oblivious one, since it makes proofs technically simpler. The (oblivious) TGD chase rule defined below is the
building block of the chase.
TGD Chase Rule. Consider a database D for a relational schema
R, and a TGD  on R of the form (X, Y)  Z  (X, Z). Then,
 is applicable to D if there exists a homomorphism h that maps

the atoms of (X, Y) to atoms of D. Let  be applicable to D, and
h1 be a homomorphism that extends h as follows: for each Xi  X,
h1(Xi) = h(Xi); for each Zj  Z, h1(Zj) = zj, where zj is a fresh
null, i.e., zj  N, zj does not occur in D, and zj lexicographically
follows all other nulls already introduced. The application of  on
D adds to D the atom h1( (X, Z)) if not already in D (which is
possible when Z is empty). 

The chase algorithm for a database D and a set of TGDs 
consists of an exhaustive application of the TGD chase rule in a
breadth-first (level-saturating) fashion, which leads as result to a
(possibly infinite) chase for D and . Formally, the chase of level
up to 0 of D relative to , denoted chase0(D, ), is defined as D,
assigning to every atom in D the (derivation) level 0. For every k  1,
the chase of level up to k of D relative to , denoted chasek(D, ),
is constructed as follows: let I1, . . . , In be all possible images of
bodies of TGDs in  relative to some homomorphism such that
(i) I1, . . . , In  chasek1(D, ) and (ii) the highest level of an
atom in every Ii is k  1; then, perform every corresponding
TGD application on chasek1(D, ), choosing the applied TGDs
and homomorphisms following a deterministic execution strategy
(e.g., using a (fixed) linear and lexicographic order for the TGDs
and homomorphisms, respectively), and assigning to every new
atom the (derivation) level k. The chase of D relative to , denoted
chase(D, ), is then defined as the limit of chasek(D, ) for
k  .
The (possibly infinite) chase relative to TGDs is a universal
model, i.e., there exists a homomorphism from chase(D, ) onto
every B  mods(D, ) [24,15]. This result implies that BCQs Q
over D and  can be evaluated on the chase for D and , i.e., D 
 |	 Q is equivalent to chase(D, ) |	 Q .
Example 6. Consider again the employee database D of Example 3
and the set of TGDs  of Example 4. Then, in the construction
of chase(D, ), we apply first the second TGD of Example 4 to
manager(jo) (resp., manager(ada)), adding directs(jo, z1) (resp.,
directs(ada, z2)), where z1 and z2 are fresh nulls, and then the
third TGD to employee(jo) and directs(jo, z1) (resp., employee(ada)
and directs(ada, z2)), adding supervises(jo, z3) and works_in(z3, z1)
(resp., supervises(ada, z4) and works_in(z4, z2)), where z3 and z4
are fresh nulls. Hence, the construction yields a finite chase
chase(D, ), given as follows:
chase(D, ) = D  {directs(jo, z1), directs(ada, z2),
supervises(jo, z3), works_in(z3, z1),
supervises(ada, z4), works_in(z4, z2)}.

Here, every atom in D is of level 0, the two atoms directs(jo, z1)
and directs(ada, z2) are of level 1, and the other four atoms are of
level 2.
3. Guarded Datalog

We now introduce guarded Datalog as a class of special TGDs
that exhibit computational tractability in the data, while being
at the same time expressive enough to model ontologies. BCQs
relative to such TGDs can be evaluated on a finite part of the
chase, which is of constant size when the query and the TGDs are
fixed. Based on this result, the data complexity of evaluating BCQs
relative to guarded TGDs turns out to be polynomial in general and
linear for atomic queries.

A TGD  is guarded iff it contains an atom in its body that
contains all universally quantified variables of  . The leftmost such
atom is the guard atom (or guard) of  . The non-guard atoms in
the body of  are the side atoms of  . For ease of presentation,
we assume that guarded TGDs contain no constants (but all the
results of this paper can be extended to guarded TGDs without this
restriction).

Example 7. The TGD r(X , Y ), s(Y , X , Z )  W s(Z , X, W ) is
guarded (where s(Y , X , Z ) is the guard, and r(X , Y ) is a side atom),
while the TGD r(X , Y ), r(Y , Z )  r(X , Z ) is not guarded, since
it has no guard, i.e., no body atom contains all the (universally
quantified) variables in the body. Furthermore, it is easy to verify
that every TGD in Example 4 is guarded.

Note that sets of guarded TGDs (with single-atom heads) are
theories in the guarded fragment of first-order logic [25]. Note also
that guardedness is a truly fundamental class ensuring decidability.
As shown in [15], adding a single unguarded Datalog rule to a
guarded Datalog program may destroy decidability.

In the sequel, let R be a relational schema, D be a database
for R, and  be a set of guarded TGDs on R. We first give some
preliminary definitions as follows. The chase graph for D and  is
the directed graph consisting of chase(D, ) as the set of nodes and
having an arrow from a to b iff b is obtained from a and possibly
other atoms by a one-step application of a TGD   . Here, we
mark a as guard iff a is the guard of  . The guarded chase forest for
D and  contains (i) for every atom a  D, one node labeled with
a, and (ii) for every node labeled with a  chase(D, ) and for
every atom b  chase(D, ) that is obtained from a and possibly
other atoms by a one-step application of a TGD    with a
as guard, one node labeled with b along with an arrow from the
node labeled with a. The subtree of a node v labeled with an atom
a (also simply called subtree of a) in this forest, denoted subtree(a),
is the restriction of the forest to all descendants of v. The type of
an atom a, denoted type(a), is the set of all atoms b in chase(D, )
that have only constants and nulls from a as arguments. Note that
the subtree of (a node labeled with) an atom a in the guarded chase
forest depends only on the set of all atoms in the type of a (and no
others).
Example 8. Consider the database D = {r(a, b), s(b)} and the set
of TGDs  consisting of the following two TGDs 1 and 2:
1: r(X , Y ), s(Y )  Z r(Z , X ),
2: r(X , Y )  s(X ).
The first part of the (infinite) chase graph (resp., guarded chase
forest) for D and  is shown in Fig. 2, left (resp., right) side, where
the arrows have the applied TGDs as labels (formally not a part of
the graph (resp., forest)). The number on the upper right side of
every atom indicates the derivation level of the atom. The subtree
of (the node labeled with) r(z1, a) in the guarded chase forest is
also shown in Fig. 2, right side. The type of r(z1, a) consists of the
atoms r(z1, a), s(a), and s(z1).
Given a finite set S    N, two sets of atoms A1 and A2
are S-isomorphic (or isomorphic if S = ) iff a bijection : A1 
dom(A1)  A2  dom(A2) exists such that (i)  and 1 are
homomorphisms, and (ii) (c) = c = 1(c) for all c  S. Note
that  is already fully determined by its restriction to dom(A1).
Two atoms a1 and a2 are S-isomorphic (or isomorphic if S = )
iff {a1} and {a2} are S-isomorphic. The notion of S-isomorphism
(or isomorphism if S = ) is naturally extended to more complex
structures, such as pairs of two subtrees (V1, E1) and (V2, E2) of the
guarded chase forest, and two pairs (b1, S1) and (b2, S2), where b1
and b2 are atoms, and S1 and S2 are sets of atoms.
Example 9. The two sets of atoms {a1: r(a, z1, z2), a2: s(b, z2),
a3: t(z3, z4)} and {b1: r(a, z1, z5), b2: s(b, z5), b3: t(z6, z7)}, where
a, b   and z1, . . . , z7  N, are {a, z1}-isomorphic via the
bijection  defined by (ai) = bi, i  {1, 2, 3}, (z2) = z5,
(z3) = z6, (z4) = z7, and (c) = c for all other c    N.
Furthermore, let a = r(a, b, z1), where a, b   and z1  N.
Then, s(b, z3) and s(b, z4) are dom(a)-isomorphic, while s(b, z3)
and s(b, z1) are not (with z3, z4  N).

A. Cali et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 5783

Fig. 2. Chase graph (left side) and guarded chase forest (right side) for Example 8.

The following lemma shows that if two atoms in the guarded
chase forest for D and  along with their types are S-isomorphic,
then their subtrees are also S-isomorphic, which can be proved by
induction on the number of applications of the TGD chase rule to
generate the subtrees of the two atoms.

Lemma 1. Let R be a relational schema, D be a database for R, and
 be a set of guarded TGDs on R. Let S be a finite subset of   N,
and let a1 and a2 be atoms from chase(D, ) such that (a1, type(a1))
and (a2, type(a2)) are S-isomorphic. Then, the subtree of a1 is
S-isomorphic to the subtree of a2.
The next lemma provides, given an atom a  chase(D, ), an
upper bound for the number of all non-dom(a)-isomorphic pairs
consisting of an atom and a type with arguments from a and new
nulls. The result follows from a simple combinatorial analysis of
the number of all possible such pairs.

Lemma 2. Let R be a relational schema, D be a database for R, and
 be a set of guarded TGDs on R. Let w be the maximal arity of a
predicate in R,  = |R|  (2w)w  2|R|(2w)w , and a  chase(D, ).
Let P be a set of pairs (b, S), each consisting of an atom b and its type
S of atoms c with arguments from a and new nulls. If |P| > , then P
contains at least two dom(a)-isomorphic pairs.

We next define the guarded depth of atoms in the guarded chase
forest as follows. The guarded depth of an atom a in the guarded
chase forest for D and , denoted depth(a), is the smallest length
of a path from (a node labeled with) some d  D to (a node labeled
with) a in the forest. Note that this is in general different from the
derivation level in the chase (see Example 10). The guarded chase
of level up to k  0 for D and , denoted g-chasek(D, ), is the set
of all atoms in the guarded chase forest of depth at most k.
Example 10. Consider the database D = {r1(a, b)} and the set of
TGDs  consisting of the following three TGDs 1, 2, and 3:
1: r3(X , Y )  r2(X ),
2: r1(X , Y )  Z r3(Y , Z ),
3: r1(X , Y ), r2(Y )  r1(Y , X ).
The chase graph for D and  is shown in Fig. 3. It nearly coincides
with the guarded chase forest for D and , where only the dashed
arrow is removed. Every atom is also labeled with its guarded
depth and its derivation level.

The next lemma shows that BCQs in the form of single ground
atoms a can be evaluated using only a finite, initial portion of the
guarded chase forest, whose size depends only on the relational
schema R. In fact, the lemma even shows the stronger result that

also a whole proof of a is contained in such a portion of the forest.
Here, a proof of an atom a from D and  is a subgraph  of the chase
graph such that  contains the atom a as a vertex, and whenever
 contains b as a vertex, where b  D, then  also contains a
set of parent atoms b1, . . . , br for b such that there exists a TGD
in  that applied to b1, . . . , br yields b. The proof of Lemma 3
in Appendix A is done by induction on the derivation level of a.
There, it is also stated how  is bounded in terms of the size of the
relational schema R, namely double-exponentially in the general
case, and single-exponentially in case of a fixed arity. Of course, for
a fixed relational schema R,  is a constant.

Lemma 3. Let R be a relational schema, D be a database for R,
and  be a set of guarded TGDs on R. Then, there is a constant
 , depending only on R, such that for each ground atom a 
chase(D, ), there is a proof of a from D and , whose atoms all
belong to g-chase (D, ).

The following lemma shows that BCQs Q can be evaluated using
only a finite, initial portion of the guarded chase forest, whose size
depends only on the query Q and the relational schema R. The
result is proved by showing that every path from D to (the image of)
a query atom in the guarded chase forest, whose length exceeds a
certain value (depending on Q and R), has two atoms with dom(a)-
isomorphic subtrees (since two atoms and their types are dom(a)-
isomorphic), and thus Q can also be evaluated closer to D.

Lemma 4. Let R be a relational schema, D be a database for R,  be
a set of guarded TGDs on R, and Q be a BCQ over R. If there exists a
homomorphism  that maps Q into chase(D, ), then there exists a
homomorphism  that maps Q into g-chasek(D, ), where k depends
only on Q and R.

Intuitively, the chase of a database relative to a set of guarded
TGDs has a periodicity of atoms and their types, as illustrated by
the following example.

Example 11. Every derivation level k  2 of the chase graph for
Example 8 in Fig. 2 is given by two atoms r(zk, zk1) and s(zk1),
where the type of the former is given by the three atoms r(zk, zk1),
s(zk1), and s(zk). This pattern repeats indefinitely in the chase,
as easily seen. For example, a BCQ Q = {r(X , Y ), r(Z , X ), r(W , Z )}
will necessarily map onto three atoms that form a path in the
guarded chase forest: however deep these atoms are in the chase,
Q can anyway also be mapped onto the first levels, e.g., onto
{r(z2, z1), r(z3, z2), r(z4, z3)}.

expressive enough for representing ontologies, as we will show in
Sections 7 and 8 for ontologies encoded in the description logics of
the DL-Lite family (DL-LiteF , DL-LiteR, and DL-LiteA [5,6]).
A guarded TGD is linear iff it contains only a singleton body atom
(i.e., the TGD is of the form XY (X, Y)  Z  (X, Z), where
(X, Y) is an atom).

Example 12. Consider again the TGDs of Example 4. As easily
verified, the first two are linear, while the last two are not. Another
linear TGD is directs(E, P)  employee(E), restricting the first
argument of the directs relation to employees.

Observe that linear Datalog generalizes the well-known class
of inclusion dependencies, and that this generalization is strict, for
example, the linear TGD supervises(X , X )  manager(X ), which
asserts that all people supervising themselves are managers, is not
expressible with inclusion dependencies.

We next define the bounded derivation-depth property for sets
of TGDs, which is strictly stronger than the bounded guard-depth
property (see Definition 1), since the former implies the latter, but
not vice versa. Informally, the bounded derivation-depth property
says that whenever (homomorphic images of) the query atoms are
contained in the chase, then they (along with their derivations) are
also contained in a finite, initial portion of the chase graph (rather
than the guarded chase forest), whose size depends only on the
query and the schema.

Definition 2. Let R be a relational schema, and  be a set of
TGDs on R. Then, we say that  has the bounded derivation-depth
property (BDDP) iff, for every database D for R and for every BCQ
Q over R, whenever D   |	 Q , then chased (D, ) |	 Q , where
d depends only on Q and R.
Clearly, in the case of linear TGDs, for every a  chase(D, ),
the subtree of a is now determined only by a itself, while in
the case of guarded TGDs it depends on type(a). Therefore, for a
single atom, its depth coincides with the number of applications
of the TGD chase rule that are necessary to generate it. That is,
the guarded chase forest coincides with the chase graph. Thus,
by Theorem 5, we immediately obtain that linear TGDs have the
bounded derivation-depth property.

Corollary 8. Linear TGDs enjoy the BDDP.

We next recall the notion of first-order rewritability for classes
of TGDs. A class of TGDs C is first-order rewritable (or FO-rewritable)
iff for every set of TGDs  in C and for every BCQ Q , there exists a
first-order query Q such that, for every database D, it holds that
D   |	 Q iff D |	 Q. Since answering first-order queries is
in ac 0 in the data complexity [26], also BCQ answering under FOrewritable TGDs is in ac 0 in the data complexity.

The following result shows that BCQs Q relative to TGDs 
with the bounded derivation-depth property are FO-rewritable.
The main ideas behind its proof are informally summarized as
follows. Since the derivation depth and the number of body atoms
in TGDs in  are bounded, the number of all database ancestors of
query atoms is also bounded. So, the number of all non-isomorphic
sets of potential database ancestors with variables as arguments
is also bounded. Take the existentially quantified conjunction of
every such ancestor set where Q is answered positively. Then, the
FO-rewriting of Q is the disjunction of all these formulas.

Theorem 9. Let R be a relational schema,  be a set of TGDs on R,
and Q be a BCQ over R. If  enjoys the BDDP, then Q is FO-rewritable.
As an immediate consequence of Corollary 8 and Theorem 9, we

obtain that BCQs are FO-rewritable in the linear case.

Fig. 3. Guarded depth/derivation level of atoms in the chase graph.

The above lemma informally says that whenever (homomor-
phic images of) the query atoms are contained in the chase, then
they are also contained in a finite, initial portion of the guarded
chase forest, whose size is determined only by the query and the
schema. However, it does not yet ensure that also a whole proof of
the query atoms is contained in such a portion of the forest. This
slightly stronger property is captured by the following definition.

Definition 1. Let R be a relational schema, and  be a set of TGDs
on R. Then,  has the bounded guard-depth property (BGDP) iff, for
every database D for R and for every BCQ Q , whenever there exists
a homomorphism  that maps Q into chase(D, ), then there exists
a homomorphism  of this kind such that a proof of every a  (Q )
from D and  is contained in g-chaseg (D, ), where g depends
only on Q and R.

The next theorem shows that, in fact, guarded TGDs have also
this stronger bounded guard-depth property. The proof of this
result is based on the above Lemmas 3 and 4, where the former
now also assures that all side atoms that are necessary in a proof
of the query atoms are contained in a finite, initial portion of the
guarded chase forest, whose size is determined only by Q and R
(which is slightly larger than the one for the query atoms only).

Theorem 5. Guarded TGDs enjoy the BGDP.

By this theorem, deciding BCQs in the guarded case is in P in the
data complexity (where all but the database is fixed) [15]. It is also
hard for P, as can be proved by reduction from propositional logic
programming.

Theorem 6. Let R be a relational schema, D be a database for R, 
be a set of guarded TGDs on R, and Q be a BCQ over R. Then, deciding
D   |	 Q is P-complete in the data complexity.

Deciding Boolean atomic queries in the guarded case can even
be done in linear time in the data complexity, as the following
theorem shows, which holds by a reduction to propositional logic
programming. Note that since general BCQs are not necessarily
guarded, they are in general not reducible to atomic queries.

Theorem 7. Let R be a relational schema, D be a database for R, 
be a set of guarded TGDs on R, and Q be a Boolean atomic query over
R. Then, deciding D   |	 Q can be done in linear time in the data
complexity.
4. Linear Datalog

We now introduce linear Datalog as a variant of guarded
Datalog, where query answering is even FO-rewritable in the data
complexity. Nonetheless, (an extension of) linear Datalog is still

A. Cali et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 5783

Corollary 10. Let R be a relational schema,  be a set of linear TGDs
on R, and Q be a BCQ over R. Then, Q is FO-rewritable.

Observe that all the above results also apply to multi-linear
TGDs, which are TGDs with only guards in their bodies, since here
the guarded chase forest can be chosen in such a way that the depth
of all its atoms coincides with their derivation depth. Formally, a
TGD  is multi-linear iff all its body atoms have the same variables
(i.e.,  has the form XY (X, Y)  Z  (X, Z), where (X, Y)
is a conjunction of atoms pi(X, Y), each containing each variable of
X and Y).

5. Adding (negative) constraints

In this section, we extend Datalog by (negative) constraints,
which are an important ingredient, in particular, for representing
ontologies.
A negative constraint (or simply constraint) is a first-order formula of the form X (X)  , where (X) is a (not necessarily
guarded) conjunction of atoms (without nulls). It is often also written as X (X)  p(X), where (X) is obtained from (X) by
removing the atom p(X). We usually omit the universal quantifiers,
and we implicitly assume that all sets of constraints are finite here.
Example 13. If the two unary predicates c and c represent two
classes (also called concepts in DLs), we may use the constraint
c(X ), c(X )   (or alternatively c(X )  c(X )) to assert that
the two classes have no common instances. Similarly, if additionally the binary predicate r represents a relationship (also called a
role in DLs), we may use c(X ), r(X, Y )   to enforce that no
member of the class c participates to the relationship r. Further-
more, if the two binary predicates r and r represent two relation-
ships, we may use the constraint r(X , Y ), r(X , Y )   to express
that the two relationships are disjoint.

Query answering on a database D under a set of TGDs T (as
well as a set of EGDs E as introduced in the next section) and a set
of constraints C can be done effortless by additionally checking
that every constraint  = (X)    C is satisfied in D
and T , each of which can be done by checking that the BCQ
Q = (X) evaluates to false on D and T . We write D T |	 C
iff every Q with   C evaluates to false in D and T . We thus
obtain immediately the following result. Here, a BCQ Q is true in D
and T and C, denoted D  T  C |	 Q , iff (i) D  T |	 Q
or (ii) D  T |	 C (as usual in DLs).
Theorem 11. Let R be a relational schema, D be a database for R,
T and C be sets of TGDs and constraints on R, respectively, and Q
be a BCQ on R. Then, D  T  C |	 Q iff (i) D  T |	 Q or
(ii) D  T |	 Q for some   C.

As an immediate consequence, we obtain that constraints do
not increase the data complexity of answering BCQs in the guarded
(resp., linear) case.
Corollary 12. Answering BCQs on databases under guarded (resp.,
linear) TGDs and constraints has the same data complexity as
answering BCQs on databases under guarded (resp., linear) TGDs
alone.

6. Adding equality-generating dependencies (EGDs) and keys

In this section, we add equality-generating dependencies
(EGDs) to guarded (and linear) Datalog, which are also important when representing ontologies. Note that EGDs generalize functional dependencies (FDs) and, in particular, key dependencies (or
keys) [10]. In DL-Lite (see Sections 7 and 8), general EGDs cannot be formulated, but only keys. Therefore, we mainly focus on
keys here. We transfer a result by Cali et al. [21] about non-key-
conflicting (NKC) inclusion dependencies to the more general setting of guarded Datalog.

However, while adding negative constraints is effortless from
a computational perspective, adding EGDs is more problematic:
The interaction of TGDs and EGDs leads to undecidability of
query answering even in simple cases, such that of functional and
inclusion dependencies [27], or keys and inclusion dependencies
(see, e.g., [21], where the proof of undecidability is done in the style
of Vardi as in [17]). It can even be seen that a fixed set of EGDs and
guarded TGDs can simulate a universal Turing machine, and thus
query answering and even propositional ground atom inference is
undecidable for such dependencies. For this reason, we consider a
restricted class of EGDs, namely, non-conflicting key dependencies
(or NC keys), which show a controlled interaction with TGDs
(and negative constraints), such that they do not increase the
complexity of answering BCQs. Nonetheless, this class is sufficient
for modeling ontologies (e.g., in DL-LiteF , DL-LiteR, and DL-LiteA;
see Lemmas 16 and 20).
An equality-generating dependency (or EGD)  is a first-order
formula of the form X (X)  Xi = Xj, where (X), called
the body of  , denoted body( ), is a (not necessarily guarded)
conjunction of atoms (without nulls), and Xi and Xj are variables
from X. We call Xi = Xj the head of  , denoted head( ). Such 
is satisfied in a database D for R iff, whenever there exists a
homomorphism h such that h((X))  D, it holds that h(Xi) =
h(Xj). We usually omit the universal quantifiers in EGDs, and all
sets of EGDs are finite here.

Example 14. The following formula  is an equality-generating
dependency:
r1(X , Y ), r2(Y , Z )  Y = Z .
The database D = {r1(a, b), r2(b, b)} satisfies  , because every
homomorphism h mapping the body of  to D is such that h(Y ) =
h(Z ). On the contrary, the database D = {r1(a, b), r2(b, c)} does
not satisfy  .
An EGD  on R of the form (X)  Xi = Xj is applicable to a
database D for R iff there exists a homomorphism : (X)  D
such that (Xi) and (Xj) are different and not both constants.
If (Xi) and (Xj) are different constants in , then there is a
hard violation of  , and the chase fails. Otherwise, the result of
the application of  to D is the database h(D) obtained from D
by replacing every occurrence of a non-constant element e 
{(Xi), (Xj)} in D by the other element e (if e and e are both
nulls, then e precedes e in the lexicographic order). Note that h
is a homomorphism, but not necessarily an endomorphism of D,
since h(D) is not necessarily a subset of D. But for the special class
of TGDs and EGDs that we define in this section, h is actually an
endomorphism of D.
The chase of a database D, in the presence of two sets T
and E of TGDs and EGDs, respectively, denoted chase(D, T 
E ), is computed by iteratively applying (1) a single TGD once,
according to the standard order and (2) the EGDs, as long as they
are applicable (i.e., until a fixpoint is reached).
Example 15. Consider the following set of TGDs and EGDs  =
{1, 2, 3}:
1 : r(X , Y )  Z s(X , Y , Z ),
2 : s(X , Y , Z )  Y = Z ,
3 : r(X , Y ), s(Z , Y , Y )  X = Y .
Let D be the database {r(a, b)}. In the computation of chase(D, ),
we first apply 1 and add the fact s(a, b, z1), where z1 is a null.
Then, the application of 2 on s(a, b, z1) yields z1 = b, thus turning
s(a, b, z1) into s(a, b, b). Now, we apply 3 on r(a, b) and s(a, b, b),
and by equating a = b, the chase fails; this is a hard violation, since
both a and b are constants in .

6.1. Separability

The following definition generalizes the notion of separability
originally introduced in [21] to Datalog. Intuitively, the semantic
notion of separability for EGDs formulates a controlled interaction
of EGDs and TGDs / (negative) constraints, so that the EGDs do not
increase the complexity of answering BCQs.

Definition 3. Let R be a relational schema, and T and E be sets
of TGDs and EGDs on R, respectively. Then, E is separable from
T iff for every database D for R, the following conditions (i) and
(ii) are both satisfied:
(i) If there is a hard violation of an EGD of E in chase(D, T E ),
(ii) If there is no chase failure, then for every BCQ Q , it holds that

then there is also a hard violation of some EGD of E in D.
chase(D, T  E ) |	 Q iff chase(D, T ) |	 Q .
Note that (ii) is equivalent to: (ii) if there is no chase failure,
it holds that ans(Q , D, T  E ) =
then for every CQ Q ,
ans(Q , D, T ). Here, (ii) implies (ii), since (ii) is a special case of
(ii), and the converse holds, since a tuple t over  is an answer for
a CQ Q to D and  iff the BCQ Qt to D and  evaluates to true,
where Qt is obtained from Q by replacing each free variable by
the corresponding constant in t. The following result shows that
adding separable EGDs to TGDs and constraints does not increase
the data complexity of answering BCQs in the guarded and linear
case. It follows immediately from the fact that the separability of
EGDs implies that chase failure can be directly evaluated on D.
Here, for disjunctions of BCQs Q, D   |	 Q iff D   |	 Q
for some BCQ Q in Q.

Theorem 13. Let R be a relational schema, T and E be fixed sets
of TGDs and EGDs on R, respectively, where E is separable from T ,
and C be a fixed set of constraints on R. Let QC be the disjunction of
all Q with   C. Then:
(a) If deciding D  T |	 Q  QC is feasible in polynomial time for
each fixed query Q , then so is deciding D  T  E |	 Q  QC.
(b) If deciding DT |	 Q QC is FO-rewritable for each fixed query
Q , then so is deciding D  T  E |	 Q  QC.

6.2. Non-conflicting keys

We next provide a sufficient syntactic condition for the
separability of EGDs. We assume that the reader is familiar with the
notions of a functional dependency (FD) (which informally encodes
that certain attributes of a relation functionally depend on others)
and a key (dependency) (which is informally a tuple-identifying
set of attributes of a relation) [10]. Clearly, FDs are special types
of EGDs. A key  of a relation r can be written as a set of FDs that
specify that  determines each other attribute of r. Thus, keys can
be identified with sets of EGDs. It will be clear from the context
when we regard a key as a set of attribute positions, and when
we regard it as a set of EGDs. The following definition generalizes
the notion of non-key-conflicting dependency relative to a set of
keys, introduced in [21], to the context of arbitrary TGDs.
Definition 4. Let  be a key, and  be a TGD of the form (X, Y) 
Z r(X, Z). Then,  is non-conflicting (NC) with  iff either (i) the
relational predicate on which  is defined is different from r, or (ii)
the positions of  in r are not a proper subset of the X-positions in
r in the head of  , and every variable in Z appears only once in the
head of  . We say  is non-conflicting (NC) with a set of TGDs T iff
 is NC with every   T . A set of keys K is non-conflicting (NC)
with T iff every   K is NC with T .

Example 16. Consider the four keys 1, 2, 3, and 4 defined by
the key attribute sets K1 = {r[1], r[2]}, K2 = {r[1], r[3]}, K3 =
{r[3]}, and K4 = {r[1]}, respectively, and the TGD  = p(X , Y ) 
Z r(X , Y , Z ). Then, the head predicate of  is r, and the set
of positions in r with universally quantified variables is H =
{r[1], r[2]}. Observe that all keys but 4 are NC with  , since only
K4  H. Roughly, every atom added in a chase by applying 
would have a fresh null in some position in K1, K2, and K3, thus
never firing 1, 2, and 3, respectively.

The following theorem shows that the property of being NC
between keys and TGDs implies their separability. This generalizes
a useful result of [21] on inclusion dependencies to the much larger
class of all TGDs. The main idea behind the proof can be roughly
described as follows. The NC condition between a key  and a
TGD  assures that either (a) the application of  in the chase
generates an atom with a fresh null in a position of , and so the
fact does not violate  (see also Example 16), or (b) the X-positions
in the predicate r in the head of  coincide with the key positions
of  in r, and thus any newly generated atom must have fresh
distinct nulls in all but the key position, and may eventually be
eliminated without violation. It then follows that the full chase
does not fail. Since the new nulls are all distinct, it also contains
a homomorphic image of the TGD chase. Therefore, the full chase
is in fact homomorphically equivalent to the TGD chase.

Theorem 14. Let R be a relational schema, T and K be sets of
TGDs and keys on R, respectively, such that K is NC with T . Then,
K is separable from T .

We conclude this section by stating that in the NC case, keys
do not increase the data complexity of answering BCQs under
guarded (resp., linear) TGDs and constraints. This result follows
immediately from Theorems 13 and 14.

Corollary 15. Let R be a relational schema, T and K be fixed sets
of TGDs and keys on R, respectively, where K is NC with T , and C
be a fixed set of constraints on R. Let QC be the disjunction of all Q
such that   C. Then:
(a) If T are guarded TGDs, then deciding D  T  K |	 Q  QC
(b) If T are linear TGDs, then deciding D  T  K |	 Q  QC is

is feasible in polynomial time.

FO-rewritable.

7. Ontology querying in DL-LiteF and DL-LiteR

In this section, we show that the description logics DL-LiteF and
DL-LiteR of the DL-Lite family [5] can both be reduced to linear (or
multi-linear) Datalog with (negative) constraints and NC keys,
called Datalog
0 , and that the former are strictly less expressive
than the latter. More specifically, we show how Datalog
0 can be
used for answering BCQs in DL-LiteF and DL-LiteR ontologies. We
first recall the syntax and the semantics of DL-LiteF and DL-LiteR.
We then define the translation and provide the representation and
expressivity results.

Note that DL-LiteR is able to fully capture the (DL fragment of)
RDF Schema [28], the vocabulary description language for RDF;
see [29] for a translation. Hence, Datalog
0 is also able to fully
capture (the DL fragment of) RDF Schema.
The other description logics of the DL-Lite family [5] can be
similarly translated into Datalog
0 : the translation of DL-LiteA into
Datalog
0 is given in Section 8, and the translations for the other
DLs are sketched in Section 9. Note that it is mainly for didactic
reasons that we start with the simpler DL-LiteF and DL-LiteR, and
we continue with the slightly more complex DL-LiteA.

Intuitively, DLs model a domain of

interest in terms of
concepts and roles, which represent classes of individuals and

A. Cali et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 5783

binary relations on classes of individuals, respectively. A DL
knowledge base (or ontology) encodes in particular subset
relationships between concepts, subset relationships between
roles, the membership of individuals to concepts, the membership
of pairs of individuals to roles, and functional dependencies on
roles.

7.1. Syntax of DL-LiteF and DL-LiteR

We now recall the syntax of DL-LiteF (also simply called
DL-Lite). As for the elementary ingredients, we assume pairwise
disjoint sets of atomic concepts, abstract roles, and individuals A, RA,
and I, respectively.

These elementary ingredients are used to construct roles and
concepts, which are defined as follows: A basic role Q is either an
atomic role P  RA or its inverse P. A (general) role R is either a
basic role Q or the negation of a basic role Q . A basic concept B
is either an atomic concept A  A or an existential restriction on
a basic role Q , denoted Q . A (general) concept C is either a basic
concept B or the negation of a basic concept B.
Statements about roles and concepts are expressed via axioms,
where an axiom is either (1) a concept inclusion axiom B  C, where
B is a basic concept, and C is a concept, or (2) a functionality axiom
(funct Q ), where Q is a basic role, or (3) a concept membership
axiom A(a), where A  A and a  I, or (4) a role membership axiom
P(a, c), where P  RA and a, c  I. A TBox is a finite set of concept
inclusion and functionality axioms. An ABox is a finite set of concept
and role membership axioms. A knowledge base KB = (T , A)
consists of a TBox T and an ABox A. CQs and BCQs are defined as
usual, with concept and role membership axioms as atoms (over
variables and individuals as arguments).
The description logic DL-LiteR allows for (5) role inclusion
axioms Q  R, rather than functionality axioms, where Q is a basic
role, and R is a role.
Example 17. Consider the sets of atomic concepts, abstract roles,
and individuals A, RA, and I, respectively, given as follows:
A = {Scientist, Article, ConferencePaper, JournalPaper},
RA = {hasAuthor, hasFirstAuthor, isAuthorOf},
I = {i1, i2}.
The following concept inclusion axioms express that (i) conference
and journal papers are articles,
(ii) conference papers are
not journal papers, (iii) every scientist has a publication, and
(iv) isAuthorOf relates scientists and articles:
(i) ConferencePaper  Article, JournalPaper  Article,
(ii) ConferencePaper  JournalPaper, Scientist  isAuthorOf ,
(iii)isAuthorOf  Scientist,isAuthorOf   Article.
Some role inclusion and functionality axioms are as follows;
they express that (v) isAuthorOf is the inverse of hasAuthor, and
(vi) hasFirstAuthor is functional:
(v) isAuthorOf   hasAuthor, hasAuthor  isAuthorOf ,
(vi) (funct hasFirstAuthor).
The following are some concept and role memberships, which
express that the individual i1 is a scientist who authors the
article i2:
Scientist(i1), isAuthorOf (i1, i2), Article(i2).

7.2. Semantics of DL-LiteF and DL-LiteR

The semantics is defined via standard first-order interpreta-
tions. An interpretation I = (I,I) consists of a nonempty (ab-
stract) domain I and a mapping I that assigns to each atomic
concept C  A a subset of I, to each abstract role R  RA a subset of I  I, and to each individual a  I an element of I.

Here, different individuals are associated with different elements
of I (unique name assumption). The mapping I is extended to all
concepts and roles by:
 (P)I = {(a, b) | (b, a)  P I};
 (Q )I = I  I  Q I;
 (Q )I = {x  I | y: (x, y)  Q I};
 (B)I = I \ BI.
The satisfaction of an axiom F in the interpretation I = (I,I),
denoted I |	 F, is defined as follows: (1) I |	 B  C iff BI  C I;
(2) I |	 (funct Q ) iff (o, o)  Q I and (o, o)  Q I implies o = o;
(3) I |	 A(a) iff aI  AI; (4) I |	 P(a, b) iff (aI, bI)  P I; and (5)
I |	 Q  R iff Q I  RI. The interpretation I satisfies the axiom
F, or I is a model of F, iff I |	 F. The interpretation I satisfies
a knowledge base KB = (T , A), or I is a model of KB, denoted
I |	 KB, iff I |	 F for all F  T  A. We say that KB is satisfiable
(resp., unsatisfiable) iff KB has a (resp., no) model. The semantics of
CQs and BCQs is as usual in first-order logic.
7.3. Translation of DL-LiteF and DL-LiteR into Datalog

0 is defined as follows:

The translation  from the elementary ingredients and axioms
of DL-LiteF and DL-LiteR into Datalog
(1) Every atomic concept A  A is associated with a unary
predicate  (A) = pA  R, every abstract role P  RA is
associated with a binary predicate  (P) = pP  R, and every
individual i  I is associated with a constant  (i) = ci  .
(2) Every concept inclusion axiom B  C is translated to the TGD
or constraint  (B  C) = (B)  (C), where
(i) (B) is defined as pA(X ), pP (X , Y ), and pP (Y , X ), if B is of
the form A,P, and P, respectively, and
(ii) (C) is defined as pA(X ),Z pP (X , Z ),Z pP (Z , X ),pA(X ),
pP (X , Y), and pP (Y, X ), if C is of form A,P,P,A,
P, and P, respectively.
(3) The functionality axioms (funct P) and (funct P) are under 
translated to the EGDs pP (X , Y )  pP (X , Y)  Y = Y and
pP (X , Y )  pP (X, Y )  X = X, respectively.
(4) Every concept membership axiom A(a) is under  translated to
the database atom pA(ca), and every role membership axiom
P(a, b) to the database atom pP (ca, cb).
(5) Every role inclusion axiom Q  R is translated to the TGD or
constraint  (Q  R) = (Q )  (R), where
(i) (Q ) is defined as pP (X , Y ) and pP (Y , X ), if Q is of the form
(ii) (R) is defined as pP (X , Y ), pP (Y , X ),pP (X , Y ), and
if R is of the form P, P,P, and P,

P and P, respectively, and
pP (Y , X ),
respectively.

Example 18. The concept inclusion axioms of Example 17 are
translated to the following TGDs and constraints (where we
identify atomic concepts and roles with their predicates):
ConferencePaper(X )  Article(X ),
JournalPaper(X )  Article(X ),
ConferencePaper(X )  JournalPaper(X ),
Scientist(X )  Z isAuthorOf (X , Z ),
isAuthorOf (X , Y )  Scientist(X ),
isAuthorOf (Y , X )  Article(X ).
The role inclusion and functionality axioms of Example 17 are
translated to the following TGDs and EGDs:
isAuthorOf (Y , X )  hasAuthor(X , Y ),
hasAuthor(Y , X )  isAuthorOf (X , Y ),
hasFirstAuthor(X , Y ), hasFirstAuthor(X , Y)  Y = Y.

dD Vd.

of atomic concepts, atomic roles, atomic attributes, and individuals,

respectively, and let V =
Roles, concepts, attributes, and datatypes are defined as
follows:
 A basic role Q is either an atomic role P  RA or its inverse P. A
(general) role R is either a basic role Q or the negation of a basic
role Q .
 A basic concept B is either an atomic concept A  A, or an
existential restriction on a basic role Q , denoted Q , or the
domain of an atomic attribute U  RD, denoted (U). A (general)
concept C is either the universal concept C, or a basic concept
B, or the negation of a basic concept B, or an existential
restriction on a basic role Q of form Q .C, where C is a concept.
 A (general) attribute V is either an atomic attribute U  RD or
the negation of an atomic attribute U.
 A basic datatype E is the range of an atomic attribute U  RD,
denoted (U). A (general) datatype F is either the universal
datatype D or an atomic datatype d  D.
An axiom has one of the following forms: (1) B  C (concept
inclusion axiom), where B is a basic concept, and C is a concept;
(2) Q  R (role inclusion axiom), where Q is a basic role, and
R is a role; (3) U  V (attribute inclusion axiom), where U is
an atomic attribute, and V is an attribute; (4) E  F (datatype
inclusion axiom), where E is a basic datatype, and F is a datatype;
(5) (funct Q ) (role functionality axiom), where Q is a basic role;
(6) (funct U) (attribute functionality axiom), where U is an atomic
attribute; (7) A(a) (concept membership axiom), where A is an
atomic concept and a  I; (8) P(a, b) (role membership axiom),
where P is an atomic role and a, b  I; and (9) U(a, v) (attribute
membership axiom), where U is an atomic attribute, a  I, and
v  V.

We next define knowledge bases, which consist of a restricted
finite set of inclusion and functionality axioms, called TBox, and a
finite set of membership axioms, called ABox. We first define the
restriction on inclusion and functionality axioms. A basic role P
or P (resp., an atomic attribute U) is an identifying property in a
set of axioms S iff S contains a functionality axiom (funct P) or
(funct P) (resp., (funct U)). Given an inclusion axiom  of the form
X  Y (resp., X  Y ), a basic role (resp., atomic attribute) Y
appears positively (resp., negatively) in its right-hand side of . A
basic role (resp., atomic attribute) is primitive in S iff it does not
appear positively in the right-hand side of an inclusion axiom in
S and it does not appear in an expression Q .C in S. We can now
define knowledge bases. A TBox is a finite set T of inclusion and
functionality axioms such that every identifying property in T is
primitive. Intuitively, identifying properties cannot be specialized
in T , i.e., they cannot appear positively in the right-hand side of
inclusion axioms in T . An ABox A is a finite set of membership
axioms. A knowledge base KB = (T , A) consists of a TBox T and an
ABox A. As usual, CQs and BCQs use concept and role membership
axioms as atoms (over variables and individuals).

The concept and role membership axioms of Example 17 are
translated to the following database atoms (where we also identify
individuals with their constants):
Scientist(i1), isAuthorOf (i1, i2), Article(i2).

Every knowledge base KB in DL-LiteS, S  {F , R}, is then
translated into a database DKB, set of TGDs KB, and disjunction
of queries QKB as follows: (i) the database DKB is the set of all
 () such that  is a concept or role membership axiom in KB,
(ii) the set of TGDs KB is the set of all TGDs resulting from  ()
such that  is a concept or role inclusion axiom in KB, and (iii)
QKB is the disjunction of all queries resulting from constraints and
EGDs  () such that  is a concept inclusion, or role inclusion, or
functionality axiom in KB (satisfying any query Q occurring in QKB
means violating a constraint or EGD).

The following lemma shows that the TGDs generated from a
DL-LiteR knowledge base are in fact linear TGDs, and that the
TGDs and EGDs generated from a DL-LiteF knowledge base are
in fact linear TGDs and NC keys, respectively. Here, the fact that
the generated TGDs and EGDs are linear and keys, respectively,
is immediate by the above translation. Proving the NC property
for the generated keys boils down to showing that keys resulting
from functionality axioms (funct P) are NC with TGDs from concept
inclusion axioms B  P and B  P.
Lemma 16. Let KB be a knowledge base in DL-LiteS, S  {F , R}.
Then, (a) every TGD in KB is linear. If KB is in DL-LiteF , and K is
the set of all EGDs encoded in QKB, then (b) every EGD in K is a key,
and (c) K is NC with KB.

The next result shows that BCQs addressed to knowledge
bases in DL-LiteF and DL-LiteR can be reduced to BCQs in linear
Datalog
0 . This important result follows from the above Lemma 16
and Theorem 14 (stating that the NC property for keys implies
their separability relative to a set of TGDs). Here, recall that for
disjunctions of BCQs Q, D   |	 Q iff D   |	 Q for some
BCQ Q in Q.
Theorem 17. Let KB be a knowledge base in DL-LiteS, S  {F , R},
and let Q be a BCQ for KB. Then, Q is satisfied in KB iff DKB  KB |	
Q  QKB.
As an immediate consequence, the satisfiability of knowledge
bases in DL-LiteF and DL-LiteR can be reduced to BCQs in Datalog
0 .
Intuitively, the theorem follows from the observation that the
unsatisfiability of KB is equivalent to the truth of  in KB, which
is in turn equivalent to DKB  KB |	 QKB.
Theorem 18. Let KB be a knowledge base in DL-LiteS, S  {F , R}.
Then, KB is unsatisfiable iff DKB  KB |	 QKB.

The next important result shows that Datalog

0 is strictly more
expressive than both DL-LiteF and DL-LiteR. The main idea behind
its proof is to show that neither DL-LiteF nor DL-LiteR can express
the TGD p(X )  q(X , X ).
Theorem 19. Datalog
DL-LiteR.

0 is strictly more expressive than DL-LiteF and

8. Ontology Querying in DL-LiteA

We now generalize the results of Section 7 to the description
logic DL-LiteA of the DL-Lite family [6]. We first recall the syntax
and the semantics of DL-LiteA. We then define the translation and
the representation and expressivity results.

8.1. Syntax of DL-LiteA

As for the elementary ingredients of DL-LiteA, let D be a finite set
of atomic datatypes d, which are associated with pairwise disjoint
sets of data values Vd. Let A, RA, RD, and I be pairwise disjoint sets

8.2. Semantics of DL-LiteA

O, I

d, where the I

The semantics of DL-LiteA is defined in terms of standard typed
first-order interpretations. An interpretation I = (I,I) consists
of (i) a nonempty domain I = (I

V ), which is the disjoint
V =
union of the domain of objects I
ds are pairwise disjoint domains of values
dD I
for the datatypes d  D, and (ii) a mapping I that assigns to each
d, to each data value v  Vd
datatype d  D its domain of values I
d (such that v = w implies vI = wI), to each
an element of I
O, to each atomic role P  RA
atomic concept A  A a subset of I
O, to each atomic attribute P  RD a subset of
a subset of I

O and the domain of values I

O  I

A. Cali et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 5783

O | (o, o)  P I};

V , to each individual a  I an element of I

O  I
O (such that
a = b implies aI = bI). Note that different data values (resp.,
individuals) are associated with different elements of I
V (resp.,
O) (unique name assumption). The extension of I to all concepts,

roles, attributes, and datatypes, and the satisfaction of an axiom 
in I = (I,I), denoted I |	 , are defined by:
V and (C )I = I
 (D)I = I
O;
 (U)I = (I
O  I
V )  U I;
O  I
O)  Q I;
 (Q )I = (I
 ((U))I = {v  I
V | o: (o, v)  U I};
O | v: (o, v)  U I};
 ((U))I = {o  I
O  I
 (P)I = {(o, o)  I
 (Q )I = {o  I
O | o: (o, o)  Q I};
 (Q .C)I = {o  I
O | o: (o, o)  Q I, o  C I};
O \ BI.
 (B)I = I
The satisfaction of an axiom  in the interpretation I = (I,I),
denoted I |	 , is defined as follows: (1) I |	 B  C iff BI  C I,
(2) I |	 Q  R iff Q I  RI, (3) I |	 E  F iff EI  F I, (4)
I |	 U  V iff U I  V I, (5) I |	 (funct Q ) iff (o, q), (o, q)  Q I
implies q = q, (6) I |	 (funct U) iff (o, v), (o, v)  U I implies
v = v, (7) I |	 A(a) iff aI  AI, (8) I |	 P(a, b) iff (aI, bI)  P I,
(9) I |	 U(a, v) iff (aI, vI)  U I. The interpretation I satisfies
the axiom , or I is a model of , iff I |	 . We say I satisfies
a knowledge base KB = (T , A), or I is a model of KB, denoted
I |	 KB, iff I |	  for all   T  A. We say KB is satisfiable (resp.,
unsatisfiable) iff KB has a (resp., no) model. The semantics of CQs
and BCQs is as usual in first-order logic.
8.3. Translation of DL-LiteA into Datalog

dD  (Vd).

0 is defined as follows:

constant  (i) = ci   

The translation  from the elementary ingredients and axioms
of DL-LiteA into Datalog
(1) Every data value v has a constant  (v) = cv   such that
the  (Vd)s for all datatypes d  D are pairwise disjoint. Every
datatype d  D has under  a predicate  (d) = pd along with
the constraint pd(X )  pd (X )   for all pairwise distinct
d, d  D. Every atomic concept A  A has a unary predicate
 (A) = pA  R, every abstract role P  RA has a binary
predicate  (P) = pP  R, every attribute U  RD has a binary
predicate  (U) = pU  R, and every individual i  I has a
(2) Every concept inclusion axiom B  C is translated to the TGD
or constraint  (B  C) = (B)  (C), where
(i) (B) is defined as pA(X ), pP (X , Y ), pP (Y , X ), and pU (X , Y ),
if B is of the form A,P,P, and (U), respectively, and
(ii) (C) is defined as pA(X ), Z pP (X, Z ), Z pP (Z, X ), Z
pU (X , Z ), pA(X ), pP (X , Y), pP (Y, X ), pU (X , Y),
Z pP (X , Z )  pA(Z ), and Z pP (Z, X )  pA(Z ), if C is of
form A, P, P, (U), A, P, P, (U), P.A, and
P.A, respectively.
Note that concept inclusion axioms B  C can be safely
ignored, and concept inclusion axioms B  Q .C can be
expressed by the two concept inclusion axioms B  Q .A and
A  C, where A is a fresh atomic concept. Note also that the
TGDs with two atoms in their heads abbreviate their equivalent
sets of TGDs with singleton atoms in the heads.
(3) The functionality axioms (funct P) and (funct P) are under 
translated to the EGDs pP (X , Y )  pP (X , Y)  Y = Y and
pP (X , Y )pP (X, Y )  X = X, respectively. The functionality
axiom (funct U) is under  translated to the EGD pU (X , Y ) 
pU (X , Y)  Y = Y.

P and P, respectively, and
pP (Y , X ),
respectively.

(4) Every concept membership axiom A(a) is under  translated
to the database atom pA(ca). Every role membership axiom
P(a, b) is under  translated to the database atom pP (ca, cb).
Every attribute membership axiom U(a, v) is under  translated to the database atom pU (ca, cv).
(5) Every role inclusion axiom Q  R is translated to the TGD or
constraint  (Q  R) = (Q )  (R), where
(i) (Q ) is defined as pP (X , Y ) and pP (Y , X ), if Q is of the form
(ii) (R) is defined as pP (X , Y ), pP (Y , X ), pP (X , Y ), and
if R is of the form P, P, P, and P,
(6) Attribute inclusion axioms U  U and U  U are under 
translated to the TGD pU (X , Y )  pU (X , Y ) and the constraint
pU (X , Y )  pU (X , Y ), respectively.
(7) Every datatype inclusion axiom (U)  d is under  translated
to the TGD pU (Y , X )  pd(X ). Note that datatype inclusion
axioms (U)  D can be safely ignored.
Every knowledge base KB in DL-LiteA is then translated into a
database DKB, set of TGDs KB, and disjunction of queries QKB as
follows: (i) DKB is the set of all  () such that  is a membership
axiom in KB along with type declarations pd(v) for all their data
values; (ii) KB is the set of all TGDs resulting from  () such that
 is an inclusion axiom in KB; and (iii) QKB is the disjunction of all
queries resulting from datatype constraints and from constraints
and EGDs  () such that  is an inclusion or functionality axiom
in KB.

The following result shows that Lemma 16 carries over to
DL-LiteA. That is, the TGDs and EGDs generated from a DL-LiteA
knowledge base are in fact linear TGDs and NC keys, respectively.
This follows from the observation that the new TGDs for DL-LiteA
are also linear or equivalent to collections of linear TGDs, and that
the keys are also NC with the new TGDs, due to the restricting
assumption that all identifying properties in DL-LiteA knowledge
bases are primitive.

Lemma 20. Let KB be a knowledge base in DL-LiteA, and let K be
the set of all EGDs encoded in QKB. Then, (a) every TGD in KB is linear,
(b) every EGD in K is a key, and (c) K is NC with KB.

Consequently, also Theorem 17 carries over to DL-LiteA. That is,
BCQs addressed to knowledge bases in DL-LiteA can be reduced to
BCQs in Datalog
0 . Note that here and in the theorem below, we
assume that every datatype has an infinite number of data values
that do not occur in KB. Here, recall that for disjunctions of BCQs Q,
D   |	 Q iff D   |	 Q for some BCQ Q in Q.
Theorem 21. Let KB be a knowledge base in DL-LiteA, and let Q be a
BCQ for KB. Then, Q is satisfied in KB iff DKB  KB |	 Q  QKB.
Similarly, the satisfiability of knowledge bases in DL-LiteA can
be reduced to BCQs in Datalog
0 . This result is formally expressed
by the following theorem, which is an extension of Theorem 18 to
DL-LiteA.
Theorem 22. Let KB be a knowledge base in DL-LiteA. Then, KB is
unsatisfiable iff DKB  KB |	 QKB.

Finally, Datalog

0 is also strictly more expressive than DL-LiteA,
which is formulated by the next theorem, extending Theorem 19
to DL-LiteA.
Theorem 23. Datalog

0 is strictly more expressive than DL-LiteA.

9. Ontology querying in other description logics

In this section, we show that also the other tractable description
logics of the DL-Lite family can be reduced to Datalog
0 . We also
recall that F-Logic Lite is a special case of weakly-guarded Datalog.

EGD pUR

0 is then extended to the remaining axioms by:

atomic role attributes UR, and (10) extending the notion of identifying property to also include all atomic role attributes in functionality axioms. Note that all axioms with concepts Q .C and with
concepts and roles containing the operator F can be reduced to
other axioms without them [31]. The translation  of DL-LiteA into
Datalog
(1) for concept inclusion axioms B  C, we additionally define
(Y , X , Y), if B is of the
(i) (B) as pUR
form (UR) and (UR), respectively, and (ii) (C) as
Z , Z pUR
(X , Z , Z), and
(Z , X , Z) if C is of the form(UR),(UR),(UR), and
pUR
(UR), respectively;
(X , Y , Z )  pUR

(2) functionality axioms (funct UR) are under  translated to the

(X , Z , Z), Z , Z pUR

(X , Y , Z)  Z = Z;

(X , Y , Y) and pUR

(Z , X , Z), pUR

(X , Y , Z )  pU

(X , Y , Z ), Z pUR

(5) role attribute inclusion axioms UR  U
(X , Y , Z )  pU

(3) role attribute membership axioms UR(a, b, c) are under 
(ca, cb, cc );
translated to the database atom pUR
(4) for role inclusion axioms Q  R, we additionally define
(Y , X , Y) if Q is of the
(X, Y , Y) and pUR
(i) (Q ) as pUR
form (UR) and (UR), respectively, and (ii) (R) as
Z pUR
(Y , X , Z ), pUR
(X , Y , Z ), and pUR
(Y ,
X , Z ) if R is of the form (UR), (UR),(UR), and (UR),
respectively;
R and UR  U

are under  translated to the TGD pUR
(X , Y , Z )
and the constraint pUR
(X , Y , Z ), respec-
tively; and
(6) datatype inclusion axioms E  F are under  translated
to (E)  (F ), where (i) (E) is defined as pd(X ) and
(Y , Y, X ), if E is of form d and (UR), respectively, and
pUR
(Z , Z, X ),pd(X ), andpUR
(ii) (F ) as pd(X ), pUR
(Z , Z, X ), if
F is of form d, (UR),d, and (UR), respectively.
An identification axiom [32] is of the form (id B I1, . . . , In), with
n  1, where B is a basic concept, and each Ij, j  {1, . . . , n},
is either an atomic attribute or a basic role. Such an axiom
encodes that the combination of properties I1, . . . , In identifies the
instances of the basic concept B. The notion of identifying property
is then extended to also include all atomic attributes and basic roles
that occur in identification axioms. The translation  of DL-LiteA
into Datalog
0 is extended by mapping each such axiom under 
to the EGD (which is a slight extension of Datalog
0 to also include
I1, . . . , In as a key of a virtual relation R(B, I1, . . . , In)):

B(X )  n

Ii

(X , Yi)  B(X)  n

(X, Yi)  X = X,

Ii

i=1

i=1
where (i) B(X ) is defined as pA(X ), pP (X , Y ), pP (Y , X ), pUR
(X ,
(Y , X , Y), and pU (X , Y ), if B is of form A,P,P,
Y , Y), pUR
(UR), (UR), and (U), respectively, and (ii) I (X , Y ) is
(X , Y , Y), and pUR
(Y , X , Y), if I is
pU (X , Y ), pP (X , Y ), pP (Y , X ), pUR
of form U, P, P, (UR), and (UR), respectively.
The following result shows that Theorems 21 and 22 carry over
to DL-Lite+
A, i.e., both BCQs addressed to knowledge bases KB in
DL-Lite+
A as well as the satisfiability of such KB can be reduced to
BCQs in Datalog
0 . Here and in the following, the database DKB, the
set of TGDs KB, and the disjunction of queries QKB are defined as
in Sections 7 and 8, except that we now use the corresponding
extended translation  , rather than those of Sections 7 and 8,
respectively.
Theorem 24. Let KB be a knowledge base in DL-Lite+
A, and let Q be a
BCQ for KB. Then, (a) Q is satisfied in KB iff DKB  KB |	 Q  QKB,
and (b) KB is unsatisfiable iff DKB  KB |	 QKB.

Fig. 4. The DL-Lite family of description logics.

Furthermore, we show that the tractable description logics E L
and E LIf can be reduced to guarded Datalog and to guarded
Datalog with non-conflicting keys, respectively.

9.1. Ontology querying in the DL-Lite family

A complete picture of the DL-Lite family of description logics
(with binary roles) [5] is given in Fig. 4; note that the arrows
with filled lines represent proper generalizations, while the ones
with dashed lines encode generalizations along with syntactical
restrictions. In addition to DL-LiteF , DL-LiteR, and DL-LiteA, the
DL-Lite family consists of further description logics, namely,
(i) DL-Litecore, which is the intersection of DL-LiteF and DL-LiteR,
(ii) DL-Lite+
A, which is obtained from DL-LiteA by adding role
attributes and identification constraints, and (iii) DL-LiteF ,,
DL-LiteR,, and DL-Lite+
A,, which are obtained from DL-LiteF ,
DL-LiteR, and DL-Lite+
A, respectively, by additionally allowing
conjunctions in the left-hand sides of inclusion axioms (without
increase of complexity, which is related to the addition of Boolean
role constructors in some popular description logics, as explored
in [30]). Furthermore, each above description logic (with binary
roles) DL-LiteX has a variant, denoted DLR-LiteX, which additionally
allows for n-ary relations, along with suitable constructs to deal
with them.
Clearly, since DL-Litecore is a restriction of DL-LiteF , it can also be
reduced to Datalog
0 . In the following, we show that all the other
description logics of the DL-Lite family can similarly be reduced to
Datalog
0 .

A role attribute UR [31] denotes a binary relation between objects and values. Role attributes come along with: (1) introducing
a set of atomic role attributes, (2) extending (general) concepts
by expressions of the form F (U),F (UR), and F (UR), denoting the set of all objects, object pairs, and inverses of object pairs,
respectively, that an atomic (concept) attribute U or an atomic
role attribute UR relates to values of a (general) datatype F, (3) extending basic datatypes by atomic datatypes d and the expression
(UR), denoting the range of the atomic role attribute UR, (4) extending (general) datatypes by basic datatypes E and their negations E, (5) adding (general) role attributes VR, which are either
atomic role attributes UR or their negations UR, (6) extending basic roles by the expressions (UR) and (UR), denoting the set of
all object pairs and inverses of object pairs, respectively, that an
atomic role attribute UR relates to values, (7) extending (general)
roles by the expressions F (UR) and F (UR), denoting the set of
all object pairs and inverses of object pairs, respectively, that an
atomic role attribute UR relates to values of a general datatype F,
(8) adding role attribute inclusion axioms UR  VR and functionality axioms (funct UR), where UR (resp., VR) is an atomic (resp., a gen-
eral) role attribute, (9) adding membership axioms UR(a, b, c) for

A. Cali et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 5783
Finally, observe also that Datalog

A into Datalog

The three description logics DL-LiteF ,, DL-LiteR,, and DL-
Lite+
A, are obtained from DL-LiteF , DL-LiteR, and DL-Lite+
A, re-
spectively, by additionally allowing conjunctions in the left-hand
sides of inclusion axioms. These DLs can be encoded by Datalog

with multi-linear TGDs. To this end, the translation  of DL-LiteF ,
DL-LiteR, and DL-Lite+
0 is extended by first mapping
the left-hand sides of inclusion axioms to the conjunctions of their
previous mappings under  . Every body atom p(X, Y) in a TGD 
with variables Y that do not occur in the head of  is then replaced
by a new body atom p(X), where p is a fresh predicate, along with
adding the TGD p(X, Y)  p(X).
The next result shows that Theorems 17, 18 and 24 carry over
to DL-LiteF ,, DL-LiteR,, and DL-Lite+
A,, i.e., both BCQs addressed
to knowledge bases KB in these DLs and the satisfiability of such KB
are reducible to BCQs in Datalog
0 .

Theorem 25. Let KB be a knowledge base in DL-LiteF ,, DL-LiteR,,
or DL-Lite+
A,, and let Q be a BCQ for KB. Then, (a) Q is satisfied in KB iff
DKBKB |	 QQKB, and (b) KB is unsatisfiable iff DKBKB |	 QKB.
For each of the above description logics (with binary roles)
DL-LiteX, the description logic DLR-LiteX is obtained from DL-LiteX
by additionally allowing for n-ary relations, along with suitable
constructs to deal with them. More concretely, (1) the constructP
in basic concepts is generalized to the constructi : R, where R is an
n-ary relation and i  {1, . . . , n}, which denotes the projection of R
on its i-th component; (2) the constructQ .C in (general) concepts
is generalized to the construct i : R.C1  Cn, where R is an n-
ary relation, the Cis are (general) concepts, and i  {1, . . . , n},
which denotes those objects that participate as i-th component to
tuples of R where the j-th component is an instance of Cj, for all
j  {1, . . . , n}; (3) one additionally allows for functionality axioms
: R), stating the functionality of the i-th component of
(funct I
R; and (4) one additionally allows for inclusion axioms between
projections of relations R1[i1, . . . , ik]  R2[j1, . . . , jk], where R1 is
an n-ary relation, i1, . . . , ik  {1, . . . , n}, ip = iq if p = q, R2 is an m-
ary relation, j1, . . . , jk  {1, . . . , m}, and jp = jq if p = q. Since the
construct i : R.C1  Cn can be removed in a similar way as Q .C
in the binary case [31], it only remains to define the translation 
into Datalog
(1) for concept inclusion axioms B  C, we additionally define
(i) (B) as pR(Y1, . . . , Yi1, X , Yi+1, . . . , Yn), if B = i
: R,
and (ii) (C) as Z1, . . . , Zi1, Zi+1, . . . , Zn pR(Z1, . . . , Zi1, X,
Zi+1, . . . , Zn) and pR(Y
i1, X , Y
n), if B is of
the form i : R and i : R, respectively;
(2) every functionality axiom (funct i : R) is under  mapped to the
set of all EGDs pR(Y1, . . . , Yi1, X , Yi+1, . . . , Yn)  pR(Y
1, . . . ,
j such that j  {1, . . . , n} and
i1, X , Y

j = i; and
(3) every inclusion axiom R1[i1, . . . , ik]  R2[j1, . . . , jk] is under
= Xil for
j with

 mapped to the TGD pR1
all l  {1, . . . , k}, and Z is the vector of all variables Z
j  {1, . . . , m}  {j1, . . . , jk}.
The next theorem finally shows that Theorem 25 carries over
to DLR-LiteF ,, DLR-LiteR,, and DLR-Lite+
A, (and so also to all less
expressive n-ary description logics of the DL-Lite family), i.e., both
BCQs addressed to knowledge bases KB in these DLs and the
satisfiability of such KB are reducible to BCQs in Datalog
0 .

0 for the following cases:

n)  Yj = Y

(Z), where Z
jl

(X)  Z pR2

i+1, . . . , Y

1, . . . , Y

i+1, . . . , Y

Theorem 26. Let KB be a knowledge base in DLR-LiteF ,, DLR-
LiteR,, or DLR-Lite+
A,, and let Q be a BCQ for KB. Then, (a) Q is
satisfied in KB iff DKB  KB |	 Q  QKB, and (b) KB is unsatisfiable
iff DKB  KB |	 QKB.

0 is strictly more expressive
than every description logic of the DL-Lite family and its extension
with n-ary relations, which follows from the next theorem,
generalizing Theorems 19 and 23.
Theorem 27. Datalog
DL-LiteR,, DL-Lite+

A,, DLR-LiteF ,, DLR-LiteR,, and DLR-Lite+
A,.

0 is strictly more expressive than DL-LiteF ,,

9.2. Ontology querying in F-Logic Lite, E L, and E LIf

Other ontology languages that are reducible to Datalog include
F-Logic Lite [33], which is a special case of weakly-guarded
Datalog [15]. F-Logic Lite is a limited version of F-Logic [34], which
is a well-known object-oriented formalism; an F-Logic Lite schema
can be represented as a fixed set of TGDs using meta-predicates
and a set of ground facts. In the rest of this section, we show
that the tractable description logics E L [19] and E LIf (which is
the extension of E L by inverse and functional roles) [20] can be
reduced to guarded Datalog and to guarded Datalog with nonconflicting keys, respectively.

The description logic E L has the following ingredients. We
assume pairwise disjoint sets of atomic concepts, abstract roles, and
individuals A, RA, and I, respectively. A concept is either the top
concept , an atomic concept A, an existential role restrictionR.C,
or a conjunction C  D, where R is an abstract role, and C and D are
concepts. A TBox is a finite set of concept inclusion axioms C  D,
where C and D are concepts, while an ABox is a finite set of concept
and role membership axioms A(c) and R(c, d), respectively, where
A is an atomic concept, R is an abstract role, and c and d are
individuals. A knowledge base KB = (T , A) consists of a TBox T
and an ABox A.
We define a translation  from E L to Datalog with guarded
TGDs as follows. Atomic concepts, abstract roles, and individuals
are translated under  in the same way as for DL-Lite. The same
applies to concept and role membership axioms, which produce
the database DKB for a given knowledge base KB in E L. As for
concept inclusion axioms C  D, we can w.l.o.g. assume that C
contains at most one existential role restriction R.E, since any
other existential role restriction can be replaced by a fresh atomic
concept B along with the concept inclusion axiom R.E  B. We
then inductively define X, where X is a variable, for all concepts
by X () =  (i.e., logical truth), X (A) = pA(X ), X (R.C) =
Z (pR(X , Z ) Z (C)), and X (CD) = X (C) (X (D)), where 
is a renaming of existentially quantified variables such that X (C)
and (X (D)) have no such variables in common anymore. We
finally define the translation  for all concept inclusion axioms
by  (C  D) = 
X (D)) is
obtained from X (C) (resp., X (D)) by a renaming of existentially
quantified variables to eliminate common ones and by removing
(resp., moving out) all existential quantifiers. We denote by KB
the resulting set of rules for KB. It is not difficult to verify that KB
is in fact a finite set of guarded TGDs.
The following immediate result finally shows that the tractable
description logic E L can be reduced to guarded Datalog, i.e., BCQs
addressed to knowledge bases in E L can be reduced to BCQs in
Datalog with guarded TGDs.

X (D), where 

X (C) (resp., 

X (C)  

Theorem 28. Let KB be a knowledge base in E L, and let Q be a BCQ
for KB. Then, Q is satisfied in KB iff DKB  KB |	 Q .

As for the description logic E LIf , rather than only abstract
roles in concepts, we may have abstract roles and inverses of
abstract roles, and we may additionally state that abstract roles and
inverses of abstract roles are functional. The above translation 
from E L to guarded Datalog can be easily extended to also allow
for inverses of abstract roles by defining additionally X (R.C) =

Z (pR(Z , X ) Z (C)), while the functionality of abstract roles and
of inverses of abstract roles can be encoded as EGDs that are unary
keys and NC with the TGDs. To verify the NC property, observe that
we can w.l.o.g. assume that each concept D in concept inclusion
axioms C  D is either an atomic concept A or of the form S.B,
where S is an abstract role or the inverse of an abstract role, and
B is an atomic concept, since conjunctions in D can be removed
by encoding C  D1  D2 as C  D1 and C  D2, and since
existential role restrictions S.C with non-atomic concepts C in D
can be replaced by existential role restrictions S.B along with the
concept inclusion axiom B  C, where B is a fresh atomic concept.
Note that guarded Datalog and guarded Datalog with nonconflicting keys are also strictly more expressive than E L and
E LIf , respectively, since they allow for predicates of arbitrary
arity in rules (provided that guardedness holds).

10. Stratified negation

In this section, we extend Datalog by stratified negation. We
first define the syntax of TGDs with negations in their bodies
(called normal TGDs) and of BCQs with negations (called normal
BCQs), and we introduce a canonical model semantics via iterative
chases. We then show that answering safe normal BCQs from
databases under stratified sets of guarded normal TGDs can be
done on finite portions of these chases; as a consequence, it is datatractable (resp., FO-rewritable) in the guarded (resp., linear) case.
We finally define a perfect model semantics, and we show that it
coincides with the canonical model semantics (which also implies
that the canonical model semantics is independent of a concrete
stratification), and that it is an isomorphic image of the perfect
model semantics of a corresponding normal logic program with
function symbols.

The fact that the canonical model semantics coincides with a
perfect model semantics, the independence of the canonical model
semantics of a concrete stratification, and the fact that the perfect
model semantics is an isomorphic image of the perfect model semantics of a corresponding normal logic program show that we
provide a natural stratified negation for query answering over on-
tologies, which has been an open problem in the DL community to
date, since it is in general based on several strata of infinite models.
By the results of Sections 5 and 6 (which can easily be extended to
stratified sets of normal TGDs), and of Sections 79, this also provides a natural stratified negation for the DL-Lite family.

10.1. Normal TGDs and BCQs

We first introduce the syntax of normal TGDs, which are
informally TGDs that may also contain negated atoms in their
bodies. Given a relational schema R, a normal TGD (NTGD) has the
formXY (X, Y)  Z  (X, Z), where (X, Y) is a conjunction
of atoms and negated atoms over R, and  (X, Z) is a conjunction
of atoms over R (all atoms without nulls). It is also abbreviated as
(X, Y)  Z  (X, Z). As in the case of standard TGDs, we can
assume that  (X, Z) is a singleton atom. We denote by head( )
the atom in the head of  , and by body+( ) and body( ) the
sets of all positive and negative (-free) atoms in the body of
 , respectively. We say that  is guarded iff it contains a positive
atom in its body that contains all universally quantified variables of
 . For ease of presentation, guarded NTGDs contain no constants.
We say that  is linear iff  is guarded and has exactly one positive
atom in its body.

As for the semantics of normal TGDs  , we say that  is satisfied
in a database D for R iff, whenever there exists a homomorphism
h for all the variables and data constants in the body of  that maps
(i) all atoms of body+( ) to atoms of D and (ii) no atom of body( )
to atoms of D, then there exists an extension h of h that maps all
atoms of head( ) to atoms of D.

We next add negation to BCQs as follows. A normal Boolean
conjunctive query (NBCQ) Q is an existentially closed conjunction
of atoms and negated atoms (without nulls) of the form
X p1(X)    pm(X)  pm+1(X)    pm+n(X),
where m  1, n  0, and the variables of the pis are among X.
We denote by Q + (resp., Q ) the set of all positive (resp., negative
(-free)) atoms of Q . We say Q is safe iff every variable in a
negative atom in Q also occurs in a positive atom in Q .

Example 19. Consider the following set of guarded normal TGDs
, expressing that (1) if a driver has a non-valid license and drives,
then he violates a traffic law, and (2) a license that is not suspended
is valid:
 : hasLic(D, L), drives(D),valid(L)  I viol(D, I);
  : hasLic(D, L),susp(L)  valid(L).
Then, asking whether John commits a traffic violation and whether
there exist traffic violations without driving can be expressed by
the two safe normal BCQs Q1 = X viol(john, X ) and Q2 =
D, I viol(D, I)  drives(D), respectively.

10.2. Canonical model semantics

We now define the concept of a stratification for normal TGDs
as well as the canonical model semantics of databases under
stratified sets of guarded normal TGDs via iterative chases along
a stratification. We then provide several semantic results around
canonical models, and we finally define the semantics of safe
normal BCQs via such canonical models.

We define the notion of stratification for normal TGDs by
generalizing the classical notion of stratification for Datalog with
negation but without existentially quantified variables [22] as
follows. A stratification of a set of normal TGDs  is a mapping
: R  {0, 1, . . . , k} such that for each normal TGD   :
(i) (pred(head( )))  (pred(a)) for all a  body+( );
(ii) (pred(head( ))) > (pred(a)) for all a  body( ).
We call k  0 the length of . For every i  {0, . . . , k}, we then
define Di = {a  D | (pred(a)) = i} and D
i = {a  D |
(pred(a))  i}, as well as i = {   | (pred(head( ))) = i}
i = {   | (pred(head( )))  i}. We say that  is
and  
stratified iff it has a stratification  of some length k  0.

Example 20. Consider again the set of guarded normal TGDs  of
Example 19. It is then not difficult to verify that the mapping 
where (susp) = (hasLic) = (drives) = 0, (valid) = 1,
and (viol) = 2 is a stratification of  of length 2. Hence,  is
stratified, and we obtain 0 = , 1 = { }, and 2 = {}.

We next define the notion of indefinite grounding, which
extends the standard grounding (where rules are replaced by
all their possible instances over constants) towards existentially
quantified variables. A subset of the set of nulls N is partitioned
into infinite sets of nulls  ,Z (which can be seen as Skolem terms
by which Z can be replaced), one for every    (where  is
a set of guarded normal TGDs) and every existentially quantified
variable Z in  . An indefinite instance of a normal TGD  is obtained
from  by replacing every universally quantified variable by an
element from  N and every existentially quantified variable Z
by an element from  ,Z. The indefinite grounding of , denoted
ground(), is the set of all its indefinite instances. We denote
by HB the set of all atoms built from predicates from  and
arguments from   N. We naturally extend the oblivious chase
of D and  to databases D with nulls, which are treated as new data
constants; similarly, normal TGDs are naturally extended by nulls.

A. Cali et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 5783

We are now ready to define canonical models of databases
under stratified sets of guarded normal TGDs via iterative chases
as follows. Note that this is slightly different from [35], where
we define the canonical model semantics as iterative universal
models. The main reason why we use the slightly stronger
definition here is that it makes canonical models isomorphic to
canonical models of a corresponding normal logic program with
function symbols (cf. Corollary 38).

Definition 5. Let R be a relational schema. Given a database D for
R under a stratified set of guarded normal TGDs  on R, we define
the sets Si along a stratification : R  {0, 1, . . . , k} of  as
follows:
(i) S0 = chase(D, 0);
(ii) if i > 0, then Si = chase(Si1,  Si1

), where the set of TGDs
 Si1
is obtained from ground(i) by (i) deleting all  such that
body( ) Si1 =  and (ii) removing the negative body from
the remaining  s.

Then, Sk is a canonical model of D and .

Example 21. Consider again the set of guarded normal TGDs 
of Example 19 and the database D = {susp(l), drives(john, c),
hasLic(john, l)}. Since 0 = , 1 = { }, and 2 = {} (see
Example 20), we obtain S0 = S1 = D, and S2 is isomorphic to
D  {viol(john, i)}, where i is a null.

Observe that, given a database D and a set of guarded TGDs ,
the oblivious chase of D and  minimizes equality between newly
introduced nulls, but every TGD  = (X, Y)  Z  (X, Z)
generates exactly one new null for every indefinite ground instance
of the body of  satisfied in the oblivious chase. The following
theorem shows that this policy is actually closely related to the
least Herbrand model semantics of positive logic programs with
function symbols: there exists an isomorphism from the oblivious
chase of D and  to the least Herbrand model of a corresponding
positive logic programs with function symbols. This provides a
strong justification for using the oblivious chase in the above
canonical model semantics of databases under stratified sets of
guarded normal TGDs.

Given a set of guarded TGDs , the functional transformation
of , denoted  f , is obtained from  by replacing each TGD
 = (X, Y)  Z  (X, Z) in  by the generalized TGD  f
= (X, Y)   (X, f (X, Y)), where f is a vector of function
symbols f ,Z for  , one for every variable Z in Z. Observe that
 f now contains function symbols, but no existential quantifiers
anymore. Furthermore, for every database D, it holds that D 
 f is a positive logic program with function symbols, which has
a canonical semantics via unique least Herbrand models. The
notions of databases, queries, and models are naturally extended
by such function symbols. An additional restriction on the notion
of isomorphism is that nulls c   ,Z are associated with terms of
the form f ,Z (x, y).

Theorem 29. Let R be a relational schema, D be a database for
R, and  be a set of guarded TGDs on R. Then, there exists an
isomorphism from chase(D, ) to the least Herbrand model M of D
and  f .

The following result shows that canonical models of databases
D under stratified sets of guarded normal TGDs  are in fact also
models of D and , which is a minimal property expected from
the notion of canonical model. The proof is done by induction
along a stratification of , showing that every Si is a model of D and
i , using the chase construction of every Si. Thus, in particular, the

canonical model Sk of D and  is a model of D and  

k = .

Proposition 30. Let R be a relational schema, D be a database for
R, and  be a stratified set of guarded normal TGDs on R. Let S be a
canonical model of D and . Then, S is also a model of D and .

In general, there are several canonical models of databases D
under stratified sets of guarded normal TGDs . The next result
shows that they are all isomorphic. It is proved by induction along
a stratification of , showing that for any two constructions of
canonical models S0, . . . , Sk and T0, . . . , Tk, it holds that every Si
is isomorphic to Ti, using the chase construction of every Si and Ti.
Thus, in particular, the two canonical models Sk and Tk of D and 
are isomorphic.

Proposition 31. Let R be a relational schema, D be a database for
R, and  be a stratified set of guarded normal TGDs on R. Let U and
V be two canonical models of D and . Then, U is isomorphic to V .

We finally define the semantics of safe normal BCQs addressed
to databases D under stratified sets of guarded normal TGDs  via
their canonical models as follows. A BCQ Q evaluates to true in D
and , denoted D   |	strat Q , iff there exists a homomorphism
that maps Q to a canonical model Sk of D and . A safe normal
BCQ Q evaluates to true in D and , denoted D   |	strat Q , iff
there exists a homomorphism from Q + to a canonical model of D
and , which cannot be extended to a homomorphism from some
Q +  {a}, where a  Q , to the canonical model of D and . Note
that the fact that every canonical model of D and  is isomorphic to
all other canonical models of D and  (cf. Proposition 31) assures
that the above definition of the semantics of safe normal BCQs
does not depend on the chosen canonical model and is thus well-
defined.

Example 22. Consider again the set of guarded normal TGDs 
and the two normal BCQs Q1 and Q2 of Example 19. Let the database
D be given as in Example 21. Then, by the canonical model S2 shown
in Example 21, Q1 and Q2 are answered positively and negatively,
respectively.

10.3. Query answering

As we have seen in the previous section, a canonical model
of a database and a stratified set of guarded normal TGDs can be
determined via iterative chases, where every chase may be infinite.
We next show that for answering safe normal BCQs, it is sufficient
to consider only finite parts of these chases. Based on this result,
we then show that answering safe normal BCQs in guarded (resp.,
linear) Datalog with stratified negation is data-tractable (resp.,
FO-rewritable).

We first give some preliminary definitions as follows. Given a
set of atoms S, a database D, and a set of guarded normal TGDs
, we denote by chaseS (D, ) a slightly modified oblivious chase
where the TGD chase rule is applicable on a guarded normal TGD 
iff the homomorphism h maps every atom in body( ) to an atom
not from S, and in that case, the TGD chase rule is applied on the
TGD obtained from  by removing the negative body of  . Then,
g-chasel,S (D, ) denotes the set of all atoms of depth at most l in
the guarded chase forest.

The next result shows that safe normal BCQs Q can be
evaluated on finite parts of iterative guarded chase forests of
depths depending only on Q and R. Its proof is similar to the proof
of Lemma 4. The main difference is that the atoms of Q may now
belong to different levels of a stratification, and one also has to
check that the negative atoms do not match with any atom in a
canonical model.
Theorem 32. Let R be a relational schema, D be a database for R,
 be a stratified set of guarded normal TGDs on R, and Q be a safe
normal BCQ over R. Then, there exists some l  0, which depends only

on Q and R, such that D   |	strat Q iff Q evaluates to true on Sk,
where the sets Si, i  {0, . . . , k}, are defined as follows:
(i) S0 = g-chasel(D, 0);
(ii) if i > 0, then Si = g-chasel,Si1 (Si1, i).
The following result shows that answering safe normal BCQs in
guarded Datalog with stratified negation is data-tractable. Like
in the negation-free case, not only homomorphic images of the
query atoms are contained in finite portions of iterative guarded
chase forests, but also the whole derivations of these images. That
is, the theorem is proved similarly as Theorems 5 and 6; the
main difference is that the finite portion of the guarded chase
forest is now computed for each level of a stratification, and that
we now also have to check that the negative atoms cannot be
homomorphically mapped to a canonical model.
Theorem 33. Let R be a relational schema, D be a database for R,
 be a stratified set of guarded normal TGDs on R, and Q be a safe
normal BCQ over R. Then, D   |	strat Q is decidable in polynomial
time in the data complexity.
The next result shows that answering safe normal BCQs in
linear Datalog with stratified negation is FO-rewritable. Its proof
extends the line of argumentation in Theorem 9 and Corollary 10
by stratified negation and safe normal BCQs.
Theorem 34. Let R be a relational schema,  be a stratified set of
linear normal TGDs on R, and Q be a safe normal BCQ over R. Then,
Q is FO-rewritable.

10.4. Perfect model semantics and independence from stratification

We now introduce the perfect model semantics of guarded
Datalog with stratified negation, and prove that it coincides with
the canonical model semantics (thus also being independent of
a concrete stratification), and that it is an isomorphic image of
the perfect model semantics of the corresponding normal logic
program with function symbols [36]. This gives strong evidence
that the canonical model semantics of guarded Datalog is quite
natural.
The perfect model semantics of databases D and a stratified set
of guarded normal TGDs  is defined via a preference relation 
on the models of D and  that are isomorphic images of models
of D and  f . We first define the strict and reflexive relations 
and  on ground atoms (having terms with function symbols as
arguments). Given a set of guarded normal TGDs , the relations
 and  on the set of all ground atoms are the smallest relations
that satisfy (i)(iv):
(i) (head( ))  (a) for every   ground( f ) and every
a  body+( ),
(ii) (head( ))  (a) for every   ground( f ) and every
a  body( ),
(iii)  and  are transitively closed, and
(iv)  is a subset of .

We are now ready to define the preference relation  on
isomorphic images of models of D and  f , as well as the perfect
model semantics of D and  as a collection of isomorphic such
images that are preferred to all others.
Definition 6. Let R be a relational schema, D be a database for
R, and  be a set of guarded normal TGDs on R. For isomorphic
images M, N  HB of two models Mf and Nf of D and  f ,
respectively, we say that M is preferable to N, denoted M  N,
iff (i) M is not isomorphic to N and (ii) for every a  Mf  Nf , there
exists some b  Nf  Mf such that a  b (which is also denoted
Mf  Nf ). Given an isomorphic image M  HB of a model of D
and  f , we say that M is a perfect model of D and  iff M  N for
all isomorphic images N  HB of models of D and  f such that
N is not isomorphic to M.

The following lemma shows that the preference relation  is

well-defined.

Lemma 35. Let R be a relational schema, D be a database for R, and
1, and Nf
 be a set of guarded normal TGDs on R. Let Mf
2 be
models of D and  f , let M  HB (resp., N  HB) be an isomorphic
2  Nf
image of Mf
2.
The following result shows that in the negation-free case,
perfect models of D and  are isomorphic to the least model of
D and  f . Hence, by Theorem 29, they are also isomorphic to the
oblivious chase of D and .

1, Mf
2, Nf
1  Nf

2). Then, Mf

1 and Mf

2 (resp., Nf

1 and Nf

1 iff Mf

Proposition 36. Let R be a relational schema, D be a database for
R, and  be a set of guarded TGDs on R. Then, M is a perfect model
of D and  iff M is an isomorphic image of the least model of D
and  f .
The next result shows how perfect models of D and  can
be iteratively constructed. Here, given a stratification : R 
{0, 1, . . . , k} of , we define HBi (resp., HB
i ) as the set of all a 
HB with (pred(a)) = i (resp., (pred(a))  i).
Proposition 37. Let R be a relational schema, D be a database for
R, and  be a set of guarded normal TGDs on R with stratification
: R  {0, 1, . . . , k}. Let S  HB
i+1 such that
S  HB
i = S. Then, for all i  {0, 1, . . . , k  1}, S is a perfect
model of D
i and  
i , and
i )f , and (ii) S is
S is an isomorphic image of a model Sf of D
an isomorphic image of the least model of Sf  Di+1 and ( f
i+1)Sf .
Observe that the perfect model of the normal logic program D
 f is given by Mk, where M0 is the least model of D0 f
0, and every
Mi+1, i  {0, 1, . . . , k1}, is the least model of MiDi+1( f
i+1)Mi.
Hence, as an immediate corollary of Propositions 36 and 37, we
obtain that the perfect model of D and  is an isomorphic image
of the perfect model of D and  f .

i and S  HB
i+1 iff (i) S is a perfect model of D

i+1 and  

i and ( 

Corollary 38. Let R be a relational schema, D be a database for R,
and  be a stratified set of guarded normal TGDs on R. Then, M is a
perfect model of D and  iff M is an isomorphic image of the perfect
model of D and  f .

The following theorem shows that the perfect model semantics
coincides with the canonical model semantics. It is proved using
Theorem 29 and Propositions 36 and 37. Since perfect models are
independent of a concrete stratification, the theorem also implies
that the same holds for the canonical model semantics.

Theorem 39. Let R be a relational schema, D be a database for R,
and  be a stratified set of guarded normal TGDs on R. Then, M is a
canonical model of D and  iff M is a perfect model of D and .

11. Related work

In this section, we give a brief overview of several related
approaches in the literature. The main motivation behind our
research is the Semantic Web. We recall that the vision of the
Semantic Web has led in the recent years to a new way of
conceiving information systems, deeply integrated into the Web
and its semantics, where Web information is annotated, so as
to be machine-readable; in this way, such information can be
integrated and especially queried in information systems, and not
merely searched by keywords. This requires a precise sharing of
terms by means of an ontology, so that the semantics of terms
across different sources is clear. Moreover, by using ontologies,
it is possible to perform automated reasoning tasks in order

A. Cali et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 5783

to infer new knowledge from the raw information residing on
the Web. Underneath the ontology, a data layer represents the
raw data present on the Web, in an inherently heterogeneous
way. The World Wide Web Consortium (W3C) defines several
standards, including the Resource Description Framework (RDF)
for the data layer, the Web Ontology Language (OWL) (based on
description logics (DLs)) for the ontology layer, and the currently
being standardized Rule Interchange Format (RIF) for the rule layer.
As for the latter, rather than providing a common semantics, RIF
aims at offering a common exchange format for rules, given that
numerous languages already exist.

We start by discussing the features of DLs employed in Semantic
Web reasoning. We then review a few works in database theory
that are deeply related to Semantic Web reasoning, highlighting
the role of the chase. Datalog is a well-known language for
knowledge bases, and we briefly describe some of its extensions
beyond the languages presented in this paper, which can also
play a prominent role in ontological querying. We also discuss
different rewriting techniques that have been the subject of
several relevant research activities on ontology querying. We then
describe different approaches to integrate rules and ontologies.
After reviewing some ontology reasoning systems, we close by
discussing the issue of whether to consider infinite models for the
theories constituted by the ontologies.

11.1. Description logics

In the Semantic Web, the ontology layer is highly important,
and has led to a vast corpus of literature. DLs have been playing a
central role in ontology reasoning; they are decidable fragments
of first-order logic, based on concepts (classes of objects) and
roles (binary relations on concepts); several variants of them have
been thoroughly investigated, and a central issue is the tradeoff between expressive power and computational complexity
of the reasoning services. In DL reasoning, a knowledge base
usually consists of a TBox (terminological component, i.e., ontology
statements on concepts and roles) and an ABox (assertional
component, i.e., ontology statements on instances of concepts and
roles); the latter corresponds to a data set. The description logic
SROIQ [37] is one of the most expressive DLs, which is underlying
OWL 2 [38], a new version of OWL [39]. Reasoning in SROIQ is
computationally expensive, and several more tractable languages
have been proposed in the Semantic Web community. Among such
++ [19],
languages, we now discuss the DL-Lite family [5,6], E L
and DLP [40], which are underlying the OWL 2 profiles QL, EL, and
RL [41], respectively, as well as ELP [42], SROE L() [43], and
SROE LV3(,) [44].
The DL-Lite family of description logics [5,6] focuses on
conjunctive query answering under a database and a set of axioms
that constitute the ontology; query answering is in ac0 in the data
complexity, due to FO-rewritability of all languages in the DL-Lite
family (note that query answering in the extended DL-Lite family
introduced in [7,8] may also be more complex (P and co-NP)). The
description logic DL-LiteR of the DL-Lite family provides the logical
underpinning for the OWL 2 QL profile [41]. Note here that the
unique name assumption can be given up in DL-LiteR and OWL 2
QL, as it has no impact on the semantic consequences of a DL-LiteR
and an OWL 2 QL ontology. In addition to being strictly more
expressive than DL-Lite, linear Datalog (with negative constraints
and non-conflicting keys) is also strictly more expressive than OWL
2 QL.
++ [19] is an extension of E L
[18,19] by the bottom element , nominals, concrete domains,
and role inclusions (between concatenations of abstract roles and
++ is ptime-complete,
atomic abstract roles); reasoning in E L
++ is undecidable.
while conjunctive query answering in E L

The description logic E L

Since guarded Datalog can express E L, guarded Datalog (with
negative constraints) can also express all the above extensions of
E L except for role inclusions with a concatenation of abstract roles
on the left-hand side, which require non-guarded rules. The OWL
++; reasoning and conjunctive
2 EL profile [41] is based on E L
query answering in OWL 2 EL are both ptime-complete in the
data complexity. As OWL 2 EL allows for stating the transitivity of
atomic roles, it is also not expressible in guarded Datalog. Note
++ and OWL 2 EL, differently from guarded Datalog,
that both E L
also do not make the unique name assumption; however, guarded
Datalog (with negative constraints and non-conflicting keys)
can easily be extended (without increase of complexity) in this
direction by abstracting from constants to equivalence classes
of constants denoting the same objects (this then requires to
compute the reflexive-symmetric-transitive closure of the same
as relation, which can be done in polynomial time). Interestingly,
differently from OWL 2 QL, OWL 2 EL also allows to express
TGDs of the form p(X )  q(X , X ) (via axioms SubClassOf (:
p, ObjectHasSelf (: q))).

DLP [40] is a Horn fragment of OWL, i.e., a set of existential-free
rules and negative constraints, without unique name assumption.
Since these rules may be non-guarded, DLP is not expressible in
guarded Datalog (with negative constraints and non-conflicting
keys). The OWL 2 RL profile [41] is an (existential-free) extension
of DLP, which aims at offering tractable reasoning services while
keeping a good expressive power, enough to enhance RDF Schema
with some extra expressiveness from OWL 2. Compared to DLP,
OWL 2 RL can in particular additionally encode role transitivity,
which is also not expressible in guarded Datalog. Conversely,
due to the missing existential quantifiers in rule heads, guarded
Datalog is clearly neither expressible in DLP nor in OWL 2 RL.

In particular,

it extends E L

A closely related extension of E L

The rule-based tractable language ELP [42] generalizes both
++ and DLP.
++ with local
E L
reflexivity, concept products, universal roles, conjunctions of
simple roles, and limited range restrictions. Here, concept products
are another source of non-guardedness, in addition to the sources
++ and DLP. Thus, ELP is not expressible
already inherited from E L
in guarded Datalog.
++ is the DL SROE L() [43],
which provides efficient rule-based inferencing for OWL 2 EL,
and which is in turn extended by the DL SROE LV3(,) [44].
The latter introduces so-called nominal schemas, which allow
for variable nominals, which are expressions that may appear in
more than one conjunct in a concept expression, and such that
all occurrences of the same variable nominal bind to the same
individual. This way, to represent a SROE LV3(,) assertion
with a TGD, we need in general arbitrary joins, which are also
beyond the expressiveness of guarded Datalog. Observe that,
conversely, guarded Datalog allows for predicate symbols of
arbitrary arity n  0, while SROE LV3(,) in its original
version in [44] (and also SROE L(), ELP, OWL 2 EL, and E L
++)
only allows for predicate symbols of arity n  2 (but can be
extended to predicate symbols of arbitrary arity n  0). Another
important difference between SROE LV3(,) and guarded
Datalog is that SROE LV3(,) covers (restricted versions) of
the profiles OWL 2 EL and OWL 2 RL, but does not cover the profile
OWL 2 QL, while guarded Datalog strictly covers OWL 2 QL, but
does not cover OWL 2 EL and OWL 2 RL.

11.2. Database schemata, ontologies, and chase

Classical database constraints, as well as more involved ones,
can be employed in modeling complex schemata and ontologies.
Interestingly, the well-known inclusion dependencies [10], common
constraints in relational databases, are quite useful in expressing
ontologies; linear TGDs are in fact an extension of inclusion

dependencies. In [45,46], inclusion dependencies are employed
together with key dependencies to represent an extension of
entityrelationship schemata; FO-rewritable subclasses of such
schemata are defined by means of graph-based conditions.
The chase [16,17,21] of a database against a set of inclusion
dependencies is crucial in ontological query answering; it has been
extended to TGDs in [1,24]. In most practical cases in ontological
reasoning, the chase does not terminate; the first work to tackle
the problem of a non-terminating chase was [17]. In data exchange,
the chase is necessarily finite; weakly-acyclic sets of TGDs are the
main class of sets of TGDs that guarantees chase termination [1],
later extended by Deutsch et al. [24] and Marnette [47]. However,
this is not appropriate for ontological databases.

11.3. Datalog extensions

Datalog [10] is a powerful language, but it has some inherent
limitations in modeling ontologies, as clearly discussed in [11].
To overcome such limitations, existential quantification was
introduced in Datalog (Horn) rules in the form of value invention
[3,48]. Datalog rules with value invention are in fact TGDs. Guarded
TGDs in guarded Datalog are extended by weakly-guarded TGDs
in weakly-guarded Datalog [15]. The restrictions on the bodies of
guarded and weakly-guarded TGDs, respectively, however, cannot
express, e.g., the concept product [4951]; they also cannot capture
assertions having compositions of roles in their body, which are
inherently non-guarded. A recent paradigm called stickiness, on
which sticky Datalog and its variants are based, allows for such
rules. Sticky sets of TGDs [52,53] are defined via a condition
based on variable marking. Like DL-Lite, some of the variants of
sticky Datalog are FO-rewritable, and therefore tractable. Sticky
Datalog also properly extends DL-Lite.

Recent works focus on general semantic characterizations of
sets of TGDs for ensuring decidability of query answering. One
such characterization is the notion of finite unification set (FUS),
which is strictly connected to that of rewriting. Given a set of TGDs
 and a BCQ Q , a backward chaining mechanism is a procedure
that constructs a rewriting Q of Q relative to , also called
-rewriting of Q , such that for every database D, D   |	
Q iff D |	 Q. The key operation in backward chaining is the
unification between the set of atoms in the body of Q and the
head of some TGD in ; for the precise definitions, see [54,55].
Finite unification sets (FUSs) ensure that the constructed rewriting
is finite. Thus, query answering under FUSs is decidable, as we just
have to build the (finite) rewriting, and then evaluate it over the
given database. Interestingly, linearity and stickiness are sufficient
syntactic properties which ensure that the TGDs are FUSs [52].

Another such characterization is the notion of bounded
treewidth set (BTS). A set of TGDs  is called bounded treewidth set
(BTS) iff for every database D, the chase graph of chase(D, ) has
bounded treewidth. Intuitively, this means that the chase graph
is a tree-like graph. Decidability of query answering under BTSs
was established in [15]. A FUS is not necessarily a BTS (e.g., sticky
TGDs). Every set of linear, guarded, and weakly guarded TGDs
is a BTS [15]. Two other classes of sets of TGDs that are BTSs
are sets of frontier-guarded and of weakly-frontier-guarded TGDs,
where the latter generalize both sets of guarded and of frontierguarded TGDs [54,55]. Intuitively, the frontier of a TGD is the set
of variables that are shared between the body and the head, and a
TGD is frontier-guarded iff an atom in its body guards the frontier.
Frontier-guardedness also allows tractable query answering in the
data complexity [56].

Under certain conditions [54], a FUS can be combined with a BTS
while retaining decidability of query answering. A class of sets of
TGDs that are neither FUSs nor BTSs, but still ensure decidable (and

even data-tractable) query answering, are sets of weakly-sticky
TGDs [53], which generalize sets of sticky TGDs.

Less closely related, Eiter and Simkus [57] present a class of
logic programs with function symbols, disjunction, constraints,
and negation under the answer set semantics; consistency
checking and brave/cautious reasoning are shown to be exptimecomplete in this setting, and some lower-complexity fragments are
presented.

11.4. Query rewriting

Ontological queries are often answered through some form
of query reformulation (or rewriting) that (partially) embeds
the constraint of the TBox into the query itself to avoid the
explicit generation of the universal model. The rewriting algorithm
for the FO-rewritable languages of the DL-Lite family is based
on backward resolution, as others developed for dealing with
entityrelationship schemata [58], inclusion dependencies [59],
and linear TGDs [60]. Such rewriting algorithms produce a
first-order rewriting in form of a union of conjunctive queries
(UCQs). The work in [61] instead goes beyond FO-rewritability
by proposing a Datalog rewriting algorithm for the expressive DL
, which comprises a limited form of concept and role
E LHIO
negation, role inclusion, inverse roles, and nominals, i.e., concepts
that are interpreted as singletons; conjunctive query answering in
 is ptime-complete in the data complexity. The proposed
E LHIO
algorithm is based on resolution and produces an optimal
rewriting relative to the language adopted to define the TBox
constraints. In particular, in the case of DL-Lite, it produces a UCQs
FO-rewriting instead of a Datalog rewriting.

Other rewriting techniques for ptime-complete languages (in
the data complexity) have been proposed for E L [62,20,63,64].
Another approach to rewriting is a combination of rewriting
according to the ontology and to the data; this was proposed
in [65,66] for DL-Lite. As already noticed in [61,65], rewritings
in the form of a UCQs may have a size that is exponential in
the size of the TBox and of the input query. To overcome this
problem, several techniques have recently been proposed. The
work in [65,66] adopts a combined approach that first extends the
input database with additional facts that witness the existential
constants of the TBox and then rewrites the input query into a firstorder query that retrieves only the sound answers. This technique
is best suited in those cases where the rewriting according to
the TBox alone is very large; however, it intrinsically depends
on the data and is therefore not a purely intensional first-order
rewriting. In [67], the problem of the exponential size of the UCQs
rewriting techniques for DL-Lite is addressed by targeting a nonrecursive Datalog program as a form of the rewriting. The size of
the rewriting remains polynomial in the size of the TBox, but still
exponential in the size of the input query. In [68], the ideas at the
basis of [61] are refined to obtain a predicate-bounded Datalog
rewriting for ontologies expressed with linear TGDs. Also in this
case, the worst-case size of the rewriting is exponential in the
size of the input query, but polynomial in the size of the TBox.
Recently, [69] proposed a rewriting technique that produces a nonrecursive Datalog (and therefore first-order) rewriting that is of
polynomial size relative to the size of the input query and the TBox.
This algorithm applies to classes of TGDs that enjoy the polynomialwitness property Gottlob and Schwentick [69] among which there
are linear TGDs and, therefore, DL-Lite. An up-to-date survey of
rewriting approaches for ontological query answering can be found
in [70].

11.5. Integration of rules and ontologies

The integration of rules with ontologies has recently raised
significant interest in the research community, as it allows for
combining the high expressive power of rule languages with

A. Cali et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 5783

the interoperability provided by ontologies. This is different
from the approach of this paper, where we concentrate on the
ontology alone (expressed as rules), aiming at attaining the highest
expressive power with the least computational cost. Essentially,
we can classify the approaches to this integration into two
categories: loose coupling (or strict semantic separation) and tight
coupling (or strict semantic integration).
Loose coupling. In loose coupling, the rules layer consists of a
(usually) nonmonotonic language, while the ontology layer is expressed in OWL/RDF flavor. The two layers do not have particular
restrictions, as their interaction is forced to happen through a safe
interface: rule bodies contain calls to DL predicates, allowing for
a mix of closed- and open-world semantics. An example of this approach are dl-programs, together with several extensions [7177],
including probabilistic dl-programs, fuzzy dl-programs, and HEX-
programs. More precisely, probabilistic and fuzzy dl-programs [75]
extend dl-programs by probabilistic uncertainty and fuzzy vague-
ness, respectively, while HEX-programs [71,72] extend the framework of dl-programs so that they can integrate several different
external sources of knowledge, possibly under different semantics.
A framework for aligning ontologies is added on top of dl-programs
in [77]. The work in [78] extends dl-programs to handle priorities.
Defeasible reasoning is combined with DLs in [79]; in this work,
like in the above cited ones, the DL layer serves merely as an input
for the default reasoning system; a similar approach is followed in
the TRIPLE rules engine [80].
Tight coupling. In tight coupling, the existing semantics of rule
languages is adapted directly in the ontology layer. The above
cited DLP [40] is an example of this, as well as the undecidable
SWRL [81]; a mutual reduction between inference in a fragment
of the DL SHOIQ and a subset of Horn programs is shown
in [40]. Between DLP and SWRL, several other works extend
the expressiveness while retaining decidability, dealing with this
trade-off in different ways. Among hybrid approaches, in which
DL knowledge bases act as input sources, we find the works
[8285]. The paper [82] combines plain Datalog (without negation
or disjunction) with the DL ALC, obtaining a language called
AL-log. In AL-log, concepts in an ALC knowledge base (the
structural component) enforce constraints in rule bodies of a
Datalog program (the relational component). Levy and Rousset
in [83] present the carin framework, which combines the DL
ALCN R with logic programs in a similar fashion, allowing also
roles to enforce constraints on rules (unlike [82] which allows
only concepts to impose constraints). Such interaction leads to
undecidability easily, but in [83] two decidable fragments are
singled out. Another work along the same lines is [86]. Rosatis
r-hybrid knowledge bases [84,85] combine disjunctive Datalog
(with classical and default negation) with ALC based on
a generalized answer set semantics; besides the satisfiability
problem, also that of answering ground atomic queries is
discussed. This formalism is the basis for a later one, building
upon it, called DL + log [87]. Another approach is found in [88],
in the framework of hybrid MKNF knowledge bases, based on
the first-order variant of Lifschitzs logic MKNF [89]. Other recent
approaches to combine rules and ontologies through uniform firstorder nonmonotonic formalisms are found in [90,91].

11.6. Systems

Several systems perform reasoning services on ontologies in
+, i.e., E L
various flavors. The CEL system [92] is based on E L
extended by role inclusions; CEL can perform subsumption in
polynomial time, thus aiming at tractable reasoning on large
knowledge bases. Snomed [93] is also based on E L, restricted to
having acyclic TBoxes only. Snorocket [94] is based on EL++, and

achieves good scalability without the restrictions of Snomed. The
research on DL-Lite has also given raise to systems, in particular,
QuOnto [95], Mastro [5], and Requiem [61]; they rewrite queries
into SQL according to a DL-Lite TBox, thus taking advantage of
the optimizations of an underlying relational DBMS. In particular,
Requiem accepts as input more expressive languages such as
. The linear, guarded, and sticky-join languages of
E LHIO
Datalog are supported by the Nyaya knowledge management
system [96]. Apart from these research prototypes, there are also
commercial systems that deal with more expressive languages.
Owlim [97], IBM IODT [98], and Oracle 11 g [99] allow to store,
reason over, and query large OWL-DL ontologies. The Pellet and
Racer-pro reasoners [100,101] also partially support conjunctive
query answering for OWL-DL ontologies.

11.7. Finite controllability

Finally, we have considered in this paper entailment under
arbitrary (finite or infinite) models; when this coincides with
finite
entailment under finite models only,
controllability [17,102,103] holds.

is said that

it

12. Conclusion

We have introduced a family of expressive extensions of
Datalog, called Datalog, as a new paradigm for query answering
and reasoning over ontologies. The Datalog family admits
existentially quantified variables in rule heads, and has suitable
restrictions to ensure highly efficient ontology querying. These
languages are rather attractive, as they are simple, easy to
understand and analyze, decidable, and they have good complexity
properties. Furthermore, for ontological query answering and
reasoning, they turn out to be extremely versatile and expressive:
in fact, guarded Datalog can express the tractable description
logic E L, and languages as simple as linear Datalog with negative
constraints and NC keys (both simple first-order features) can
express the whole DL-Lite family of tractable description logics
(including their generalizations with n-ary relations), which are
the most popular tractable ontology languages in the context
of the Semantic Web and databases. We have also shown how
nonmonotonic stratified negation (a desirable expressive feature
that DLs are currently lacking) can be added to Datalog, while
keeping ontology querying and reasoning tractable.
Datalog is the first approach to a generalization of database
rules and dependencies so that they can express ontological
axioms, and it is thus a first step towards closing the gap between
the Semantic Web and databases. Datalog paves the way for
applying decades of research in databases, e.g., on data integration
and data exchange, to the context of the Semantic Web, where
there is recently a strong interest on highly scalable formalisms for
the Web of Data.
The Datalog family is of interest in its own right; it is still
a young research topic, and there are many challenging research
problems to be tackled. One interesting topic is to explore how
Datalog can be made even more expressive. For example, many
DLs allow for restricted forms of transitive closure or constraints.
Transitive closure is easily expressible in Datalog, but only through
non-guarded rules, whose addition to decidable sets of rules may
easily lead to undecidability. Hence, it would be interesting to
study under which conditions, closure can be safely added to
various versions of Datalog. Moreover, for those logics where
query answering is FO-rewritable, the resulting FO-query is usually
very large. A topic for future work is to study from a theoretical
and a practical point of view how such FO-rewritings can be
optimized. Furthermore, it would also be interesting to explore
how more general forms of nonmonotonic negation, such as

negation under the well-founded and under the answer set
semantics, can be added to Datalog, which could, e.g., also
be applied when combining/merging two ontologies, where the
underlying stratifications cannot always be maintained. Finally,
SPARQL [104] has the same expressive power as non-recursive
Datalog with negation; capturing the integration of SPARQL and
DL-Lite seems feasible with extensions of Datalog, which will be
another subject of future investigation.

Acknowledgments

This work was supported by the European Research Council
under the EUs 7th Framework Programme (FP7/2007-2013)/ERC
grant 246858DIADEM, by the German Research Foundation
(DFG) under the Heisenberg Programme, and by a Yahoo! Research
Fellowship. Georg Gottlob is a James Martin Senior Fellow, and also
gratefully acknowledges a Royal Society Wolfson Research Merit
Award. The work was carried out in the context of the James Martin
Institute for the Future of Computing.
We are grateful to Giorgio Orsi

for his contributions to
Section 11. We are also grateful to Marco Manna, Andre Hernich,
Clemens Kupke, and Andreas Pieris for their useful comments on
an earlier version of this article. Many thanks also to the reviewers
of this paper and of its PODS-2009 abstract for their useful and
constructive comments, which have helped to improve this work.

Appendix A. Proofs for Section 3

Proof of Lemma 1. We give a proof by induction on the number
of applications of the TGD chase rule to generate subtree(a1) and
subtree(a2).
Basis: We apply the TGD chase rule to generate a child of the nodes
labeled with a1 and a2 in the subtrees. The side atoms in such
applications are contained in type(a1) and type(a2), respectively.
Suppose that we are adding a node labeled with an atom b1 as a
child of the node labeled with a1, applying a TGD   , and
using as side atoms S1  type(a1). Then, there is another set
S2  type(a2) that is S-isomorphic to S1. Hence, we can apply 
to a2 using S2 as side atoms, and we obtain a node labeled with
an atom b2 as a child of the node labeled with a2, which is S-
isomorphic to b1. Thus, we can extend the S-isomorphism between
type(a1) and type(a2) to an S-isomorphism between type(a1){b1}
and type(a2)  {b2} by assigning to every fresh null in b1 the
corresponding fresh null in b2.
type(a1)  P1 and
Induction: By the induction hypothesis,
type(a2)  P2 are S-isomorphic, where every Pi, i  {1, 2}, is the
set of atoms introduced in subtree(ai) during the first k applications
of the TGD chase rule. The proof is now analogous to the one of
the basis, replacing every type(ai), i  {1, 2}, by type(ai)  Pi, and
considering the (k + 1)-th application of the TGD chase rule. 
Proof of Lemma 2. As for the atoms b, at most w arguments from
a and at most w nulls in the two extreme cases may be used as
arguments in b. We thus obtain 2w possible symbols, which can
be placed into at most w argument positions of |R| predicates.
Hence, the number of all non-dom(a)-isomorphic atoms b is given
by |R|  (2w)w. As for the types S, we thus obtain 2|R|(2w)w as
the number of all subsets of this set of atoms. In summary, the
number of all pairs as stated in the theorem is bounded by  =
|R|  (2w)w  2|R|(2w)w .

For the proof of Lemma 3, we need some preliminary definitions
and results as follows. Each proof  of a ground atom a from a
database D and a set of guarded TGDs  gives rise to a guarded
proof forest GPF  , which is the smallest subforest of the guarded
chase forest for D and  containing (i) a vertex labeled with b for

each atom b of D that is also a vertex of , and (ii) for all sets of
vertices {b1, . . . , br , b} of  such that there is a TGD    that
applied to b1, . . . , br produces b, where bi unifies with the guard
of  , a vertex labeled with bi, a vertex labeled with b, and an arc
between the former and the latter. The -depth of an atom b in
, denoted -depth(b), is its smallest depth in GPF  . Note that for
each atom b occurring in , it holds that depth(b)  -depth(b).
For a relational schema R and set of terms (constants or
variables) T, the atom base of T, denoted ABR(T ), is the set of all
atoms that can be built from predicate symbols in R and terms in
T. For a ground atom a over R, the Herbrand base of a, denoted
HBR(a), is defined by HBR(a) = ABR(dom(a)).
Let R be a relational schema,  be a set of TGDs on R, d be a
ground atom over R, and S be a set of ground atoms over R. Then,
a (d, S, )-proof of a ground atom e is defined as a proof  of e
from {d}  S and , where elements of S are used as side atoms
only, and whose associated guarded proof forest GPF  is a thus a
single tree whose root is labeled d.

Lemma 40. Let R be a relational schema, and  be a set of guarded
TGDs on R. Let d and e be ground atoms over R such that e 
HBR(d), and S be a set of ground atoms over R such that S 
HBR(d). Let (R, , S, d, e) be defined by:
 (R, , S, d, e) = 0, if there is no (d, S, )-proof of e;
 (R, , S, d, e) = k, where k is the smallest integer i such that
there is a (d, S, )-proof  whose atoms are all in g-chasei({d}
S, ), otherwise.
Then, there exists an upper bound  on (R, , S, d, e) that
depends only on R, where  is double-exponentially (resp., single-
exponentially) bounded in R in the general case (resp., in the case of
a fixed arity).
Proof. Let  be the maximum predicate arity of R. Let C =
{c1, . . . , c} be a set of arbitrary distinct data constants. Note that
the choice of C is completely irrelevant, and we could as well use
symbolic dummy constants. A trivial upper bound (R, ) for
(R, , S, d, e) that depends only on R and  is defined by:
(R, ) = max
dHB(C)
SHB(d)
eHB(d)

(R, , S, d, e).

Observe now that, unlike for general TGDs, for each given
schema R, there is (up to isomorphism) only a finite set  (R) of
guarded TGDs over R, and this set depends solely on R. In fact,
each guarded TGD has a guard, and there is a clearly determined
finite choice of guard predicates in R. After having chosen a
guard predicate P of arity r, there are no more than rr  
possibilities of populating its arguments with variables from X =
{x1, x2, . . . , xr}. Let V  X be the set of variables used in the guard.
Then, the set of side atoms can only consist of a subset of ABR(V ),
which is clearly a finite set. In a similar way, the set of possible
choices for the head of a guarded TGD is finite and determined
by the guard. In summary,  (R) is (up to isomorphic variable
renaming) unique, finite, and determined by R. It follows that
there are (up to isomorphism) only finitely many sets of guarded
TGDs  over R, and their totality is determined by R. In fact,
these possible sets of guarded TGDs are the subsets of  (R). Note
that the number of all (non-isomorphic) guarded TGDs formed
according to R is at most double-exponential in the size of R.
Each    (R) is thus at most double-exponential in the size
of R. The above allows us to obtain an upper bound  (R) for
(R, , S, d, e) that depends only on R:
 (R) = max
 (R)

(R, ).

The above line of argumentation does not give us a concrete
bound of  (R) in terms of the size of R. It does not even show that

A. Cali et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 5783

Fig. 5. Construction in the proof of Lemma 3.

 (R) is computable from R. To understand how  (R) depends on
R, we may, however, analyze a suitably restricted version of the
(alternating) Acheck algorithm presented in the extended version
of [15]. The analysis shows that  (R) is double-exponentially
bounded in the size of R in the general case and exponentially in
case of bounded arities. A rough sketch of such an analysis goes
as follows. We may concentrate on the setting where a database
atom d is given and a set of ground atoms S has already been
shown to be derivable at the required depth. The Acheck algorithm,
when adapted to our setting, generates on input {d}  S and 
a guarded chase tree rooted in d, and checks whether a belongs
to it. Each (macro-)configuration of Acheck actually corresponds
to a vertex of this guarded chase tree. Given that the size of each
configuration of Acheck is at most exponential in the size of R, in
case the atom a is at all contained in the guarded chase tree, it must
be derivable within a double-exponential number of chase steps. In
the case of bounded arities, the Acheck configurations are each of
size polynomial in the size of R, and thus there exists a derivation
of a in exponentially many chase steps.
Proof of Lemma 3. Assume that a is a ground atom such that a 
chase(D, ). We use induction on the derivation level l(a) of a in
chase(D, ) to show that a has a proof from D and  that lies
entirely in g-chase (D, ), where  =  (R) as defined in the
proof of Lemma 40.
Basis: For l(a) = 0, it holds that a belongs to D, and thus there is a
proof of a from D and  of depth 0.
Induction: Assume now that for all ground atoms b of derivation
level l(b) < n, there is a proof of b lying entirely in g-chase (D, ),
and assume that l(a) = n. Note that the guarded chase forest F for
a may contain several vertices labeled a, corresponding to different
possible derivations of a. Among those, we choose one vertex v that
was generated according to a derivation of a of minimum level.
Let Ta be the tree in the guarded chase forest containing vertex
v. Then, Ta is rooted in some vertex v0 labeled with some ground
atom d  D. Note that, due to guardedness, it must hold that
a  type(d). In fact, no constant that was not already present in the
root can enter Ta. Consider now a minimal set S of all side atoms
a of atoms in Ta that contribute to the generation of vertex v, that
are of derivation level l(a) < l(a), and that are not generated
within Ta at derivation level l(a). These are the side atoms used to
generate node v labeled a in Ta that come from trees different from
Ta in the forest F. Due to the guardedness of , these side atoms
are all ground and belong to type(d). By the induction hypothesis,
having a lower derivation level than a, each atom a  S has a
proof a that lies entirely in g-chase (D, ). Observe that v in Ta
is generated by a chase derivation from {d}  S and , whose
guarded chase forest is rooted in d. Moreover, a  type(d) 
HBR(d) and S  type(d)  HBR(d). Hence, the precondition of
Lemma 40 applies, and thus there exists a (d, S, )-proof of a of
depth  =  (R). This proof, jointly with all proofs a of atoms
a  S, constitutes a complete proof of a from D and  that lies
entirely in g-chase (D, ) (see Fig. 5). 

Fig. 6. Construction in the proof of Lemma 4.

depth() = 

Proof of Lemma 4. Let k = n  , where n = |Q|,  = |R| 
(2w)w  2|R|(2w)w , and w is the maximal arity of a predicate
in R. Suppose there exists a homomorphism that maps Q into
chase(D, ). Let  be a homomorphism of this kind such that
qQ depth((q)) is minimal. We now show that
(Q ) is contained in g-chasek(D, ). Towards a contradiction,
suppose the contrary. Consider the tree consisting of all nodes
labeled with atoms in (Q ) and their ancestors in the guarded
chase forest for  and D. Since (Q ) is not contained in
g-chasek(D, ), this tree must contain a path P of length greater
than  of which the labels (= atoms) of all inner nodes (i.e., without
start and end node) do not belong to (Q ) and have no branches
(i.e., have exactly one outgoing edge). Let the atom a be the
label of the start node of P. By Lemma 2, there are two dom(a)-
isomorphic atoms h and h on P with dom(a)-isomorphic types.
By Lemma 1, subtree(h) is dom(a)-isomorphic to subtree(h). Thus,
we can remove the node labeled with h and the path to h,
obtaining a path that is at least one edge shorter. Let  be the
homomorphism mapping subtree(h) to subtree(h), and let  =
  . Then,  is a homomorphism that maps Q into chase(D, )
such that depth() < depth(), which contradicts  being a
homomorphism of this kind such that depth() is minimal. This
shows that (Q ) is contained in g-chasek(D, ) (see Fig. 6). 
Proof of Theorem 5. Consider the following fact ():
() For each atom a  g-chasei(D, ), where i  0, there is a proof
of a from D and  that is contained in g-chase(+1)i(D, ),
where  is as in Lemma 3.

Clearly, () immediately implies the BGDP, because in Lemma 4
we have shown that the entire query Q maps homomorphically
to h(Q )  g-chasek(D, ), for some constant k, which thus
implies that every a  h(Q ) has a proof that is contained in
g-chase(+1)k(D, ). We now prove () by induction on i  0.
Basis: For i = 0, we have that a  D, and thus () obviously holds.
Induction: Assume that () holds for some i  0. We now show
that () also holds for i + 1. Let a  g-chasei+1(D, ). If
a  g-chasei(D, ), then by the induction hypothesis, there
exists a proof of a that is contained in g-chase(+1)i(D, ) 
g-chase(+1)(i+1)(D, ). Otherwise, there is a TGD  , and atoms
a1, a2, . . . , as matching the body of  , producing in one step a.
Here, a1 corresponds w.l.o.g. to the guard in  . Thus, a1  g-
chasei(D, ). By the induction hypothesis, there exists a proof of
a1 that is contained in g-chase(+1)i(D, ).
Let us now temporarily freeze g-chase(+1)i(D, ) and consider
it as a database D. Observe that D contains D and a complete
proof of a1. Now, given that a1 was obtained via a guard, a2, . . . , as
are instances of side atoms, and thus, for j  {2, . . . , s}, we have

that dom(aj)  dom(a1). Since a1 belongs to the frozen database
D, all of its arguments are constants relative to D. Thus, relative
to D, the atoms a2, . . . , as are ground, and Lemma 3 applies,
and all of a2, . . . , as (and trivially also a1 itself) have a proof in
g-chase (D, ). But this means that all of a1, a2, . . . , as have a
full proof in g-chase+(+1)i(D, ), and thus the atom a, which
is obtained in one step from a1, a2, . . . , as has a full proof in g-
chase+(+1)i+1(D, ) = g-chase(+1)(i+1)(D, ). 
Proof of Theorem 6. As for membership in P, by the proof
of Theorem 5, we obtain the following polynomial decision
algorithm. We first construct g-chase(n+1)(D, ), where n = |Q|,
 = |R|(2w)w2|R|(2w)w , and w is the maximal arity of a predicate
in R, and we then evaluate Q on g-chase(n+1)(D, ).
To prove hardness for P, we give a logspace reduction from
the P-complete problem of deciding whether a propositional
logic program with at most two body atoms in its rules logically
implies a propositional atom [105]. Let L be a propositional logic
program with at most two body atoms in its rules, and let p be a
propositional atom. So, L is a finite set of rules of the form h 
b1  b2, where h is a propositional atom, and each bi is either the
propositional constant true, denoted , or a propositional atom ai.
Then, we define R, D, , and Q as follows:
R = {program, query, holds};
D = {program(h, b1, b2) | h  b1  b2  L}
{query(p)}  {holds()};
 = {program(X , Y , Z )  holds(Y )  holds(Z )  holds(X );
query(X )  holds(X )  q};
Q = q.
Observe that only D depends on L and p, while R, , and Q are
all fixed. Observe also that D can be computed in logspace from L
and p. It is then not difficult to verify that L logically implies p iff
D   |	 Q . 
Proof of Theorem 7. By the proof of Theorem 5, we can evaluate Q
on g-chase(n+1)(D, ), where n = |Q|,  = |R|(2w)w2|R|(2w)w ,
and w is the maximal arity of a predicate in R, which can be done as
follows. For every atom a  D, we construct the tree of all potential
descendants in the guarded chase forest of depth up to (n + 1)  .
Since || is constant, every node in this tree has only a constant
number of children. Thus, the tree can be constructed in constant
time, and the number of applied instances of TGDs in it is constant.
Hence, the union S of all applied instances of TGDs in the trees of
descendants of all a  D can also be constructed in linear time.
Observe now that S is a propositional logic program, and the nodes
of the guarded chase forest of depth up to (n + 1)   are all atoms
that are logically implied by D  S. Let S be obtained from S by
adding all rules a  q such that (i) a is an atom and the label
of a potential node in the guarded chase forest and (ii) Q can be
homomorphically mapped to a. Clearly, S can also be constructed
in linear time. Then, D   |	 Q iff D  S
|	 q, where the
latter can be decided in linear time [105]. In summary, this shows
that deciding D   |	 Q can be done in linear time in the data
complexity.

Appendix B. Proofs for Section 4

Proof of Theorem 9. Let d (which depends only on Q and R) be
the depth of the derivation of Q . Let  be the maximum number of
body atoms in a TGD in . Then, every atom in the chase is generated by at most  atoms, of which 1 are side atoms. The derivation of a is therefore contained in all its ancestors; among those,
there are at most  d at level 0. If we consider the whole query Q
(with |Q| = n), the number of level 0-ancestors of its atoms is at

most n   d. An FO-rewriting for Q is thus constructed as follows.
Take all possible sets of n   d atoms using predicates in R and
having constants from Q and (at most n   d  w, where w is
the maximal arity of a predicate in R) nulls as arguments. Then,
considering them as a database B, compute chased (B, ). Finally,
whenever Q can be homomorphically mapped to chased (B, ),
take all atoms in B, transform the nulls into distinct variables, and
make the logical conjunction  out of the resulting atoms. The existential closure of the logical disjunction of all such conjunctions 
is the rewriting of Q relative to , denoted Q. Observe now that,
for every database D for R, it holds that D |	 Q iff D   |	 Q
(i.e., chase(D, ) |	 Q ): this is because every conjunction in Q
corresponds to some derivation of n atoms (soundness), and every
derivation of n atoms in the levels of the chase up to d (i.e., all
those sufficient to check whether chase(D, ) |	 Q ) corresponds
to a conjunction in Q (completeness). 

Appendix C. Proofs for Section 6

Proof of Theorem 13. (a) Immediate by the definition of separa-
bility.
(b) Assume that Q , T , and QC can be rewritten into the first-order
formula  such that for each database D, it holds that D  T |	
QQC iff D |	 . Now, let  be the disjunction of all negated EGDs
 with   E. Then, D T  E |	 Q  QC iff D |	   . 
Proof of Theorem 14. The proof in [21, Lemma 3.8] uses the
restricted chase (where a TGD does not fire whenever it is
satisfied). We construct a somewhat different proof for the
oblivious chase, which is used in the present paper. We do this
for self-containedness, and also because it is quite instructive
to see how the oblivious chase works for TGDs and NC keys.
Note that, alternatively, one can just exploit the result shown
in [21, Lemma 3.8] stating that when D satisfies K , then the
restricted chase of D relative to T  K is equal to the restricted
chase of D relative to T alone. We observe that the latter is
homomorphically equivalent to the oblivious chase chase(D, T ).
Hence, chase(D, T  K ) does not fail, and chase(D, T ) is a
universal model of D  T  K .
We use the standard chase order adopted in this paper:
whenever the chase has generated a new atom by some TGD, it
applies all applicable keys (EGDs). We show that the oblivious
chase converges with such an order. Let R be a relational schema,
T be a set of TGDs on R, K be a set of NC keys on R, and D be
a database for R. Assume D satisfies K . By Definition 3, it suffices
to show that
(1) when chasing the TGDs in T over D using the oblivious chase,
(2) for every database D and BCQ Q , it holds that chase(D, T ) |	

the keys in K never lead to a hard violation, and
Q iff chase(D, T  K ) |	 Q .
Suppose that, in the process of constructing the oblivious chase,
a TGD  = (X, Y)  Z r(X, Z) fires. Take any key   K
for r, where K is the corresponding set of positions of relation
r. Then, since the set H of positions in head( ) occupied by
universally quantified variables is not a proper superset of the
set K, there are only two possible cases: (i) K = H : in this
case,  is actually the only key that can fire! By our particular
chase order, this key is immediately applied and just eliminates
the new atom a generated by  , because a has fresh nulls in all
positions but those of K. (ii) At least one position in K is occupied
by an existentially quantified variable in head( ): then, the new
fact a generated by the application of  contains a fresh null in a
position in K, and therefore it cannot violate the key . It follows
that the oblivious chase only eliminates some facts generated by
some TGDs, and converges to a possibly infinite fixpoint  without

A. Cali et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 5783

ever producing a hard violation. By results of [24], the resulting
chase(D, T  K ) is a universal model for D  T  K . It is
also an endomorphic image of chase(D, T ) via the endomorphism
: chase(D, T )  chase(D, T  K ), where  is defined by the
union of all substitutions performed by those keys that are applied.
Hence, chase(D, T ) and chase(D, T  K ) are homomorphically
equivalent, and thus satisfy the same BCQs.

Appendix D. Proofs for Section 7

Proof of Lemma 16. Clearly, every TGD generated from KB is
linear, which already shows (a). Furthermore, every EGD generated
from functionality axioms in KB is obviously a key, which then
shows (b). It thus only remains to prove (c). Since every key in K
is defined on a role, the only TGDs that are potentially interacting
with K are those derived from concept inclusion axioms in KB
of the form B  P and B  P, when a functionality axiom
(funct P) is in KB. In such cases, we have a TGD whose head is
of the form Z pP (X , Z ) or Z pP (Z , X ), and a key of the form
P(Y3, Y1), P(Y3, Y2)  Y1 = Y2. In both cases, (1) the set of key
positions {pP[1]} is not a proper subset of the set of X-
positions{pP[1]} and{pP[2]}, respectively, and (2) the existentially
quantified variable Z appears only once in the head of the TGD. That
is, the key is non-conflicting with the two TGDs. In summary, K
is non-conflicting with KB. 
Proof of Theorem 17. By Lemma 16, the set K of all EGDs
encoded in QKB is a set of keys that is non-conflicting with KB.
By Theorem 14, K is separable from KB. Obviously, Q is satisfied
in KB iff DKB  KB  K  C |	 Q , where C is the set of all
constraints encoded in QKB. As argued in Section 5, the latter is
equivalent to DKBKBK |	 QQC, where QC is the disjunction
of all queries resulting from C. By the definition of separability (cf.
Definition 3), the latter is equivalent to DKB  KB |	 Q  QKB. 
Proof of Theorem 18. Observe that KB is unsatisfiable iff the BCQ
Q = X A(X ) is satisfied in KB = KB  {A  B, A  B}, where
A and B are fresh atomic concepts. By Theorem 17, the latter is
equivalent to DKB  KB |	 Q  QKB. This is in turn equivalent
to DKB  KB |	 QKB, that is, DKB  KB |	 QKB. 
Proof of Theorem 19. The TGD p(X )  q(X , X ) can neither be
expressed in DL-LiteF nor in DL-LiteR, since the TGDs of concept
and role inclusion axioms can only project away arguments,
introduce new nulls as arguments, and change the order of
arguments in the predicates for atomic concepts and abstract roles,
and the EGDs for functionality axioms can only produce an atom
q(c, c) from q(n, c) and/or q(c, n), where n is a null, if q(c, c) was
already there before. 

Proof of Theorem 21. The proof is verbally nearly identical to the
proof of Theorem 17; it only differs in using Lemma 20 instead of
Lemma 16. 
Proof of Theorem 22. The proof is verbally nearly identical to the
proof of Theorem 18; it only differs in using Theorem 21 instead of
Theorem 17. 
Proof of Theorem 23. The proof is verbally nearly identical to
the proof of Theorem 19, referring only to DL-LiteA instead of
DL-LiteF . 

Appendix F. Proofs for Section 9

Proof of Theorem 24. We extend the proofs of Theorems 21
and 22 to DL-Lite+
A. Observe first that, as for role attributes,
the extended translation  produces linear TGDs and keys.
Furthermore, the keys also have the NC property, since (a) by
the assumed restriction on DL-Lite+
A, all the atomic role attributes
in functionality axioms (funct UR) do not occur positively in the
right-hand sides of role attribute inclusion axioms, and (b) the key
positions resulting from (funct UR) are not a proper subset of the X-
positions in the TGD heads generated from (UR), (UR), (UR),
(UR), and (UR). The extended translation  for identification
axioms (id B I1, . . . , In) lies slightly outside Datalog
0 , since the
produced EGD is not really a key, but it can intuitively be
considered as a key of the virtual relation R(B, I1, . . . , In). It also
has the NC property, since by the assumed restriction on DL-Lite+
A,
all the atomic attributes and basic roles in identification axioms
do not occur positively in the right-hand sides of inclusion axioms.

Proof of Theorem 25. Immediate by Theorems 17, 18 and 24,
respectively, as the only difference is that we now have multilinear TGDs instead of linear ones.
Proof of Theorem 26. Immediate by Theorem 25, since also the
extended translation  produces only linear TGDs and NC keys.
In particular, the NC property of keys follows from the restriction
of DLR-LiteF ,, DLR-LiteR,, and DLR-Lite+
A,, respectively, that all
n-ary relations R in functionality axioms (funct i: R) do not appear
positively in the right-hand sides of concept inclusion axioms and
of the newly introduced inclusion axioms between projections of
relations. 
Proof of Theorem 27. Following the same line of argumentation
as in the proof of Theorem 19, it can be shown that the TGD
p(X )  q(X , X ) cannot be expressed in any of the DLs stated in
the theorem. 

Appendix E. Proofs for Section 8

Appendix G. Proofs for Section 10

Proof of Lemma 20. Obviously, every TGD generated from KB is
linear or equivalent to a collection of linear TGDs, and every EGD
generated from functionality axioms in KB is a key, which already
proves (a) and (b). As for (c), we extend the proof of Lemma 16
from DL-LiteF to DL-LiteA. As for the TGDs that are potentially
interacting with the keys, DL-LiteA newly produces TGDs for role
and attribute inclusion axioms Q  R and U  V , respectively, as
well as for concept inclusion axioms B  C, where C may contain
general concepts of the form Q .D with basic roles Q and general
concepts D. However, by the assumption that all role and attribute
functionality axioms can only be expressed on primitive roles and
attributes, respectively, the keys are trivially non-conflicting with
the new TGDs in the translation from DL-LiteA. Therefore, the
interesting cases (i.e., those where keys are potentially conflicting
with TGDs) are exactly the same as in the proof of Lemma 16, and
the rest of the proof goes in the same way.

Proof of Theorem 29. By induction along the construction of
chase(D, ), we define an isomorphism  from chase(D, ) to a
subset of M as follows. For every c    N that occurs in D, we
define (c) = c. Trivially,  maps D  chase(D, ) isomorphically
to D  M. Consider now any step of the construction of
chase(D, ), and let C be the result of the construction thus far.
Suppose that  maps C  chase(D, ) isomorphically to a subset
of M. Suppose that the next step in the construction of chase(D, )
is the application of the TGD  = (X, Y)  Z  (X, Z), which
produces the atom  (x, N) from the atoms in (x, y). We then
extend  by mapping the vector N of nulls N   ,Z, where the Zs
are the existentially quantified variables in  , to the vector f (x, y)
of terms f (x, y). Notice that  is injective, since every pair (x, y)
uniquely determines the atoms in (x, y) and thus at most one
application of the TGD  . Since ((x, y)) is a subset of M, and M
is a model of D and  f , also ( (x, N)) must belong to M. Hence,

Sj1

Sj1

) is a universal model of Sj1 and 

) is a universal model Si1 and  Si1

 also maps the result of applying  on C to a subset of M. We can
thus construct an isomorphism  from chase(D, ) to a subset M
of M. But since M is also a model of D and  f , as otherwise the
construction of chase(D, ) would be incomplete, and since M is
the least model of D and  f , we obtain M = M. Thus,  maps
chase(D, ) isomorphically to M. 
Proof of Proposition 30. Let a stratification of  be given by
: R  {0, 1, . . . , k}. By induction on the stratification , we now
show that for any construction of a canonical model S0, . . . , Sk,
every Si is a model of D and  
i . Thus, in particular, the canonical
k = . Observe first
model Sk of D and  is a model of D and  
i, where j  {0, . . . , i} and i  {0, . . . , k}, is the set of
that () if Sj
all atoms a  Si such that (pred(a))  j, then every Sj
i coincides
with Sj.
Basis: Since S0 = chase(D, 0), and chase(D, 0) is a universal
model of D and 0, in particular, S0 is a model of D and 0 =  
0.
Induction: Suppose that Si1 is a model of D and  
i1; we now
i . Recall first that Si =
show that also Si is a model of D and  
chase(Si1,  Si1
). We have to show that (i) D can be homomorphically mapped to Si and (ii) every    
is satisfied in
Si. As for (i), since Si1 is a model of D and  
i1 by the induction
hypothesis, D can be homomorphically mapped to Si1. Since Si =
chase(Si1,  Si1
, it follows
that Si1 can be homomorphically mapped to Si. In summary, D
can be homomorphically mapped to Si. As for (ii), consider any

i . Then,   j for some j  {0, . . . , i}, and since (1)
Sj = chase(Sj1, 
(or
Sj = chase(D, 0) is a universal model of D and 0, if j = 0) and
(2) Sj1
coincides with Sj1, by (), it follows that  is satisfied in
Sj, and since Sj coincides with Sj
i, by (), it follows that  is also
satisfied in Si. 
Proof of Proposition 31. Let a stratification of  be given by
: R  {0, 1, . . . , k}. By induction on the stratification , we now
show that for any two constructions of canonical models S0, . . . , Sk
and T0, . . . , Tk, it holds that Si is isomorphic to Ti, for every i 
{0, . . . , k}. Thus, in particular, the two canonical models Sk and Tk
of D and  are isomorphic.
Basis: Clearly, S0 = chase(D, 0) and T0 = chase(D, 0) are
isomorphic.
Induction: Suppose that Si1 and Ti1 are isomorphic; we now show
that also Si and Ti are isomorphic. Since Si1 and Ti1 are isomorphic
by the induction hypothesis,  Si1
is isomorphic to  Ti1

Following the construction of the chase, the isomorphism between
Si1 and Ti1 can then be extended to an isomorphism between
Si = chase(Si1,  Si1
Proof of Theorem 32. Let l = n  , where n = |Q +| + 1,
 = |R|  (2w)w  2|R|(2w)w , and w is the maximal arity of a
predicate in R. The result is proved in the same way as Lemma 4,
except that the atoms of Q may now belong to different levels of
a stratification (and thus the path P of length greater than  for
the proof by contradiction must be completely inside one level
of the stratification), and one also has to check that the negative
atoms (since Q is safe, their arguments are fully determined, once
some candidates for the images of the positive atoms under the
homomorphism are found) do not match with any of the atoms in
a canonical model of D and  (which is done separately for each
negative atom).
Proof of Theorem 33. The result is proved in the same way as
Theorem 6, which follows from Theorem 5. The main difference
is that the finite part of the guarded chase forest is now computed

) and Ti = chase(Ti1,  Ti1

). 

1 and Nf

1 and Mf

1 and Mf

2, it follows that Mf

for each level of a stratification, and that we now also have to check
that the negative atoms cannot be homomorphically mapped to
a canonical model. We first compute a stratification of , which
is possible in constant time. We then compute sets similar to the
Sis, i  {0, . . . , k}, of Theorem 32. But to obtain all side atoms, by
Theorem 5, with a slightly larger depth, namely, l = (n + 1)  ,
where n = |Q +| + 1,  = |R|  (2w)w  2|R|(2w)w , and w is the
maximal arity of a predicate in R. By the proof of Theorem 6, this
and the evaluation of Q + and all Q +  {a}, where a  Q , over Sk
is possible in polynomial time. 
Proof of Theorem 34. We use the same line of argumentation as
in the proofs of Theorem 9 and Corollary 10, except that we now
determine first a stratification  of  and then iteratively (for each
possible collection of database atoms with nulls as arguments) the
guarded chase forest of bounded depth (which depends only on Q
and R) for every level of , and we also check that the negative
atoms do not match with any of the atoms in the thus generated
canonical model. 
Proof of Lemma 35. Since M  HB is an isomorphic image
of both Mf
1 and Mf
2 are isomorphic.
Similarly, also Nf
2 are isomorphic, and the two subrelations
of that are obtained from by restriction to Mf
1Nf
2Nf

are isomorphic.
Proof of Proposition 36. () Let M be a perfect model of D
and . That is, (i) M  HB is an isomorphic image of a model Mf
of D and  f and (ii) M  N for all isomorphic images N  HB of
models of D and  f such that N is not isomorphic to M. Towards a
contradiction, suppose that Mf is not a minimal model of D and
 f . That is, there exists a minimal model Nf of D and  f such
that Nf  Mf . Thus, Mf  Nf
= . However, since  is empty,
M  N does not hold, and since N is not isomorphic to M, this
contradicts M being a perfect model of D and . This shows that
Mf is a minimal model of D and  f .
() Let M be an isomorphic image of the least model Mf of
D and  f , and let N be any isomorphic image of a model Nf of D
and  f such that N is not isomorphic to M. Since Mf  Nf , it
follows that Mf  Nf = . Hence, since M is not isomorphic to N,
it holds that M  N. This shows that M is a perfect model of D
and . 
Proof of Proposition 37. Consider any i  {0, 1, . . . , k  1}.
i+1 and  
i+1. That
is, (1) S is an isomorphic image of a model Mf of D
i+1)f
i+1 and ( 
and (2) S  N for all isomorphic images N  HB
i+1 of models
i+1)f such that N is not isomorphic to S. Hence,
of D
i )f and
(1) S is an isomorphic image of a model Sf of D
i and ( 
(2) S  N for all isomorphic images N  HB
i of models of D

i )f such that N is not isomorphic to S. That is, (i) S is a
and ( 
i . Furthermore, as for (ii), since S is an
perfect model of D
i+1)f , it follows that
isomorphic image of a model Mf of D
S is an isomorphic image of a model Mf of Sf  Di+1 and ( f
i+1)Sf .
We now show that Mf is also minimal. Towards a contradiction,
suppose that Mf is not minimal. That is, there exists a minimal
i+1)Sf such that Nf  Mf . It thus
model Nf of Sf  Di+1 and ( f
follows that Mf  Nf
= . Observe that Nf is also a model of D
i+1
i+1)f . Since Mf  (HB
i )f = Nf  (HB
i )f , where (HB
i )f is
and ( 
i by function symbols, S  N does
the natural extension of HB
not hold, where N is an isomorphic image of Nf . But, since N is not
isomorphic to S, this contradicts S being a perfect model of D
i+1
and  

() Suppose that S is a perfect model of D

i+1. This shows that Mf is also minimal.

() Suppose that (i) S is a perfect model of D
i and ( 

is an isomorphic image of a model Sf of D

i , and S
i and  
i )f , and (ii) S

i+1 and ( 

i+1 and ( 

i and  

A. Cali et al. / Web Semantics: Science, Services and Agents on the World Wide Web 14 (2012) 5783

i+1)Sf and ( f

is an isomorphic image of a minimal model Mf of Sf  Di+1 and
i+1)Sf . Thus, S is also an isomorphic image of a model Mf of
( f
i+1)f . We now show that S is a perfect model of D

i+1 and ( 
i+1
i+1. That is, S  N for all isomorphic images N of models
and  
i+1)f such that N is not isomorphic to S. Recall
Nf of D
i+1 and ( 
that S  N iff for every a  Mf  Nf , some b  Nf  Mf exists
with a  b. Clearly, by (i), if a  (Mf  Nf )  (HB
i )f , then ()
some b  (Nf  Mf ) (HB
i )f exists with a  b. W.l.o.g., both Mf
i+1)f and Nf  (HB
and Nf are minimal, and thus Mf  (HB
i+1)f
are obtained from Sf = Mf  (HB
i )f and T f = Nf  (HB
i )f ,
respectively, by iteratively applying an immediate consequence
i+1)T f , respectively. Let a0, a1, . . . be
operator via ( f
the ordered sequence of all elements in (Mf  Nf )  (HB
i+1)f
such that for every i  {0, 1, . . .}, it holds that ai is derived before
ai+1. Then, a0  (Mf  Nf )  (HB
i+1)f is justified either by some
a  (Mf  Nf )  (HB
i )f with a0  a (as argued above, this
implies ()) or by some b  (Nf  Mf )  (HB
i )f with a0  b.
Similarly, every ai  (Mf  Nf )  (HB
i+1)f is justified either by
some aj  (Mf  Nf )  (HB
i+1)f with j  {0, 1, . . . , i  1} and
ai  aj, (by induction on a0, a1, . . ., this implies () with a = aj),
by some a  (Mf  Nf ) (HB
i )f with ai  a (as argued above, this
implies ()), or by some b  (Nf  Mf )  (HB
i )f with ai  b.
In summary, this shows that for every a  Mf  Nf , there exists
some b  Nf  Mf such that a  b.
Proof of Theorem 39. Let : R  {0, 1, . . . , k} be a stratification
of . Let S0 = chase(D, 0) and Si+1 = chase(Si,  Si
i+1) for i 
{0, 1, . . . , k  1}. Recall that Sk is the canonical model of D and .
We now show by induction on i  {0, 1, . . . , k} that Si  (Di+1 
 Dk) is a perfect model of D
i . Hence, in particular, Sk is
k = D and  
a perfect model of D
Basis:By Theorem 29, S0 (D1Dk) is an isomorphic image of
the least model of D0 and  f
0. By Proposition 36, it thus follows that
S0  (D1    Dk) is a perfect model of D0 = D
0 and 0 =  
0.
i = Si  (Di+1    Dk)
Induction:By the induction hypothesis, S
is a perfect model of D
i is an
i and  
isomorphic image of a model Sf
i )f . By Theorem 29,
Si+1 is an isomorphic image of the least model of Si and ( f
i+1)Si.
i+1 = Si+1  (Di+2    Dk) is an isomorphic image of
Thus, S
i+1)S
the least model of S
i+1 is also an
isomorphic image of the least model of Sf
i . By
Proposition 37, S

i , which also implies that S
i of D

i . Hence, S
i  Di+1 and ( f
i+1)Sf
i+1. 
i+1 and  

i  Di+1 and ( f

i+1 is a perfect model of D

i and  
k = .

