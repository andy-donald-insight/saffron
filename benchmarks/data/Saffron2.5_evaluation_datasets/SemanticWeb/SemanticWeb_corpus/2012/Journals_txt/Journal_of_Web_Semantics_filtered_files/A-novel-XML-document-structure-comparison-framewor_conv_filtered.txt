Web Semantics: Science, Services and Agents on the World Wide Web 11 (2012) 1440

Contents lists available at SciVerse ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : h t t p : / / w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

A novel XML document structure comparison framework based-on sub-tree
commonalities and label semantics
Joe Tekli a,,1, Richard Chbeir b

a ICMC Computer Science and Statistics Institute, University of Sao Paulo, 13566-590 Sao Carlos, SP, Brazil
b LE2I Laboratory UMR-CNRS, University of Bourgogne, 21078 Dijon Cedex, France

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 24 May 2010
Received in revised form 27 September 2011
Accepted 31 October 2011
Available online 15 November 2011

Keywords:
XML (semi-structured) data
Structural similarity
Tree edit distance
Semantic similarity
Information retrieval
Vector space model

XML similarity evaluation has become a central issue in the database and information communities, its
applications ranging over document clustering, version control, data integration and ranked retrieval.
Various algorithms for comparing hierarchically structured data, XML documents in particular, have been
proposed in the literature. Most of them make use of techniques for finding the edit distance between
tree structures, XML documents being commonly modeled as Ordered Labeled Trees. Yet, a thorough
investigation of current approaches led us to identify several similarity aspects, i.e., sub-tree related
structural and semantic similarities, which are not sufficiently addressed while comparing XML docu-
ments. In this paper, we provide an integrated and fine-grained comparison framework to deal with both
structural and semantic similarities in XML documents (detecting the occurrences and repetitions of
structurally and semantically similar sub-trees), and to allow the end-user to adjust the comparison process according to her requirements. Our framework consists of four main modules for (i) discovering the
structural commonalities between sub-trees, (ii) identifying sub-tree semantic resemblances, (iii) computing tree-based edit operations costs, and (iv) computing tree edit distance. Experimental results demonstrate higher comparison accuracy with respect to alternative methods, while timing experiments
reflect the impact of semantic similarity on overall system performance.

O 2011 Elsevier B.V. All rights reserved.

1. Introduction

In the past few years, XML has emerged as the main standard for
data exchange on the Web. The ever-increasing amount of information
available on the Internet has reflected the need to bring more structure
and semantic richness, and thus more flexibility, in representing data,
which is where W3Cs XML (eXtensible Markup Language) comes to
play. The use of XML covers data description and storage (e.g., complex
multimedia objects such as SVG images [86], X3D graphics [82], MPEG-
7 meta-data [50] . . .), database information interchange, data filtering,
as well as web services interaction.

Owing to the increasing web exploitation of XML, XML document comparison becomes a central issue in the database and
information retrieval communities. The applications of XML document comparison range over: change management and data warehousing (finding, scoring and browsing changes between different
versions of a document, support of temporal queries and index
maintenance) [1214], data integration (identifying and merging

 Corresponding author. Tel.: +55 16 33739677; fax: +55 16 33739751.

E-mail addresses: joe.tekli@icmc.usp.br, jtekli@gmail.com (J. Tekli).

1 The author is partly supported by FAPESP, Fellowship No. 2010/00330-2. He is

currently with the Antonine University (UPA), Lebanon.

1570-8268/$ - see front matter O 2011 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2011.10.002

similar documents to provide a more complete view of the data)
[29,39], XML retrieval (finding and ranking results according to
their similarity) [66,90], as well as the clustering of XML documents gathered from the web [16,55] which would improve storage indexing [68] and thus positively affect the retrieval process.
The main goal of our study is the comparison of rigorously
structured heterogeneous XML documents, i.e., documents originating from different data-sources and not conforming to the same
grammar (DTD/XSD), which is the case of a lot of XML documents
found on the Web [55]. In fact, a range of solutions for comparing
semi-structured (XML) data has been proposed in the literature. On
one hand, most algorithms make use of techniques for finding the
edit distance between tree structures [12,16,55], XML documents
being treated as Ordered Labeled Trees (OLTs) [85]. On the other
hand, some works have focused on extending conventional information retrieval methods, e.g., [5,11], so as to provide efficient
XML similarity assessment. In this study, we bound our presentation to the former group of methods, i.e., edit distance based
approaches, since they target rigorously structured XML documents and are usually more fine-grained, mainly exploited in
data-warehousing, version control, structural querying and XML
classification and clustering applications (information retrieval
based methods, on the other hand, target loosely structured XML

data with long text fields  text-rich, and are usually coarse-
grained, mainly useful for fast simple XML retrieval [26,28]). We
particularly focus on comparing XML document structures, i.e.,
the structural disposition and ordering of element/attribute tag
names2 (central in XML structural classification and clustering appli-
cations, e.g., [10,55]), and disregard XML contents (i.e., element/attri-
bute values). In short, we view XML document structure comparison
as an independent line of study, as well as an essential and indispensable step to consequently address element/attribute contents
efficiently. In this context, two main problems arise:

 Elements structural similarity: this consists in considering par-
ent/child relationships and ordering among XML elements,
identified by their tag labels. In essence, a thorough investigation of the most recent and efficient XML structural similarity
approaches [12,16,55] led us to pinpoint certain cases where
the comparison outcome is inaccurate. These inaccuracies correspond to undetected sub-tree structural similarities, as we
will see in the motivating examples.

 Elements semantic similarity: this consists in evaluating the
semantic meanings of XML element/attribute labels. Most existing XML comparison approaches focus exclusively on the structure of XML documents,
ignoring the semantics involved.
However, evaluating the semantic relatedness between documents (mainly those published on the Web) is of key importance to improving search results: finding related documents,
and given a set of documents, effectively ranking them according to their similarity [44].

The relevance of semantic similarity in Web search mechanisms, as
well as the increasing use of XML-based structured documents on the
Web, motivated us to study XML similarity in both its structuraland
semantic facets and to provide a hybrid XML similarity method for comparing heterogeneous XML documents. We aim to develop a parameterized XML comparison approach able to (i) efficiently detect XML
structural similarity (preliminary work has appeared in [74,76]), (ii)
consider semantic relatedness while comparing XML documents, and
(iii) allow the user to tune XML comparison according to the scenario
and application requirements by assigning more importance to either
structural or semantic similarity (using an input structural/semantic
parameter). The contributions of our study can be summarized as fol-
lows. First, we provide a unified framework in which we extend and
combine existing structure comparison approaches, mainly those provided in [12,55], in order to consider the various sub-tree structural
similarities while comparing XML document trees. Second, we expand
XML structural similarity evaluation, combining the traditional vector
space model in information retrieval [47] and semantic similarity
assessment [41], to consider sub-tree semantic similarities in comparing XML documents. Such similarities encompass the evaluation of
semantic relatedness between XML node labels w.r.t. (with respect
to) a reference semantic information source. Third, we implement
our framework as an experimental prototype to test and evaluate our
approach. Experimental results reflect our methods high accuracy
and performance levels in comparison with existing solutions.

The remainder of this paper is organized as follows. Section 2 reviews background and related works in XML structural comparison
and semantic similarity evaluation. Section 3 presents motivation
examples highlighting different kinds of undetected XML similarities to be addressed in our study. Section 4 develops our integrated
XML document comparison approach. Section 5 provides theoretical
and computational comparative analyses, evaluating our method

2 Note that the XML tree structure is different from topological tree structure since
it relies on labels (i.e., element/attribute tag names) in identifying corresponding tree
nodes, whereas the latter only considers the interconnections among nodes,
disregarding the nodes labels.

against existing solutions. Section 6 presents our prototype and
experimental tests. Section 7 concludes with ongoing works.

2. Background

2.1. XML data model

XML documents represent hierarchically structured information and are generally modeled as Ordered Labeled Trees or OLTs
(Fig. 1). In a traditional DOM (Document Object Model) ordered labeled tree [85], nodes represent XML elements, and are labeled
with corresponding element tag names, ordered following their order of appearance in the document. Attributes usually appear as
children of their encompassing element nodes, sorted by attribute
name, and appearing before all sub-element siblings [55,90]. Other
types of nodes, such as entities, comments and notations, are commonly disregarded in most XML comparison approaches, e.g.,
[12,16,23,31,55], since they underline complementary information
and are not part of the core XML data.

In general, element/attribute values are disregarded when evaluating the structural properties of heterogeneous XML documents
(originating from different data-sources and not conforming to
the same grammar), so as to perform XML structural classifica-
tion/clustering [16,31,55,58] or structural querying (i.e., querying
the structure of documents, disregarding content [6,64]). Nonethe-
less, values are usually taken into account with methods dedicated
to XML change management [13,14], data integration [29,40], and
XML structure-and-content querying applications [66,67], where
documents tend to have similar structures (probably conforming
to the same grammar [36,83]).

2.2. Structural similarity and tree edit distance

Various methods for estimating the similarities between hierarchically structured data, particularly between XML documents,
have been proposed in the literature. Most of them exploit the concept of tree edit distance, deriving, in one way or another, the dynamic programming techniques for finding the edit distance
between strings [37,81,84].

In the following, we provide the basic notions related to the
concept of tree edit distance, and briefly review the corresponding
literature.

2.2.1. Tree edit distance: basic notions and concepts

Hereunder, we provide two basic definitions describing the con-

cept of tree edit distance.

Definition 1 (Edit script). It is a sequence of edit operations
ES =  op1, op2, . . ., opk  . When applied to a tree T, the resulting
tree T0 is obtained by applying edit operations of the edit script ES
to T, following their order of appearance in the script. By assigning
a cost, CostOp, to each edit operation, the cost of an edit script is
defined as the sum of the costs of its component operations:
CostES 14

jESj
i141CostOpi [7,12]. h

Fig. 1. A sample XML document with corresponding OLT.

J. Tekli, R. Chbeir / Web Semantics: Science, Services and Agents on the World Wide Web 11 (2012) 1440

Definition 2 (Tree edit distance). The edit distance between two
trees A and B is defined as the minimum cost of all edit scripts that
transforms A to B,TED(A,B) = Min{CostES}. Thus, the problem of
comparing two trees A and B, i.e., evaluating the structural similarity
between A and B, is defined as the problem of computing the corresponding tree edit distance, i.e., minimum cost edit script [89]. h

As for tree edit operations, they can be classified in two groups:
atomic operations and complex operations [16]. An atomic edit
operation on a tree (i.e., rooted ordered labeled tree) is either the
deletion of an inner/leaf node, the insertion of an inner/leaf node,
or the replacement (i.e., update) of a node by another one. A complex tree edit operation is a set of atomic tree edit operations, treated as one single operation, e.g., the insertion of a whole tree as a
sub-tree in another tree (which amounts to a sequence of atomic
node insertion operations), the deletion of a whole tree (i.e., a sequence of atomic node deletion operations), or moving a sub-tree
from one position into another in its containing tree (i.e., a sequence of atomic node insertion/deletion operations). In Section
4.1, we provide the formal definitions for each of the tree edit operations utilized in our approach.

2.2.2. Current tree edit distance methods

Tree edit distance algorithms can be distinguished by the set of
edit operations that they allow as well as their overall complexity/
performance and optimality/efficiency levels.

Early approaches: in [72], the author introduces the first nonexponential algorithm to compute the edit distance between
ordered labeled trees, allowing insertion, deletion and substitution (relabeling) of inner nodes and leaf nodes. The resulting
algorithm has a complexity of O(jAjjBj 
 depth(A)2 
 depth(B)2)
when finding the edit distance between two trees A and B (jAj
and jBj denote tree cardinalities while depth(A) and depth(B)
are the depths of the trees). Similarly, early approaches in
[70,89] allow insertion, deletion and relabeling of nodes anywhere in the tree. Yet, they remain greedy in complexity. For
is of O(jAjjBj 
 depth(A) 

instance, the algorithm in [70]
depth(B)). In addition, the approaches in [70,72,89] were not
developed in the XML context, and thus might yield results that
are not appropriate to XML data.
Quality versus performance: in [13,14], the authors restrict insertion and deletion operations to leaf nodes and add a move operator that can relocate a sub-tree, as a single edit operation, from
one parent to another. Yet, algorithms in [13,14] do not guarantee optimal results. In [13], the documents being compared
should match specific criterions and assumptions without
which the algorithm would yield suboptimal results. The algorithms complexity simplifies to O(n 
 e + e2), where n is the
total number of leaf nodes in the trees being compared and e
is the corresponding weighted edit distance.3 On the other hand,
the authors in [14] trade some quality (the edit distance obtained
is not always minimal, some sets of move operations not being
optimal) to get an algorithm which runs in average linear time:
O(N log(N)) where N is the number of nodes in the compared trees.
Methods in [13,14] were developed for XML change management
and version control. They consider XML element/attribute values
(XML structure-and-content, Fig. 1b) in contrast with remaining
methods in this section which target the structural properties of
XML documents (structure-only).
Combining efficiency and performance: the approach provided in
[12] restricts insertion and deletion operations to leaf nodes

3 Let S =  op1,op2, . . . , opn be the cheapest sequence of edit operations that
transforms tree A to B, then the weighted edit distance is given by e 14
114i14nwi
where wi, for 1=i=n, is equal to 1 if opi is an insert or delete operation, and 0 otherwise.

(which are viewed as natural operations in the XML context
[16]), and allows the relabeling of nodes anywhere in the tree,
while disregarding the move operation. The proposed algorithm
is a direct application of the famous WagnerFisher algorithm
[81] which optimality has been accredited in a broad variety
of computational applications [2,84]. It is also among the fastest
tree edit distance algorithms available. Chawathe [12] extends
his algorithm for external-memory computations and identifies
respective I/O, RAM and CPU costs. The overall complexity of
Chawathes algorithm is of O(N2).
Sub-tree similarity: in [55], the authors stress the importance of
identifying sub-tree structural similarities in XML comparison,
due to the frequent presence of repeated and optional elements
in XML document trees. Repeating elements often induce multiple occurrences of similar element/attribute sub-trees (pres-
ence of optional elements/attributes) or identical sub-trees in
the same document (such as sub-trees B1 and B2 in XML tree
B, Fig. 2) which reflects the need to consider these sub-tree
resemblances while comparing documents.
The authors in [55] extend the approach of Chawathe [12] by
adding two new operations: insert tree and delete tree, to discover sub-tree similarities, making use of thecontained in relation between trees/sub-trees. A tree S is said to be contained
in a tree T if all nodes of S occur in T, with the same parent/child
edge relationship and node order. Following [55], when comparing two trees A and B, a sub-tree S may be inserted (deleted)
in A only if S is already contained in the source tree A (destina-
tion tree B). Therefore, the proposed approach captures the subtree structural similarities between XML trees A/B in Fig. 2,
transforming A to B in a single edit operation (inserting sub-tree
B2 in A, sub-tree B2occurring in tree A as A1), which is less costly
(and thus yields a lower distance, i.e., higher similarity) than
transforming A to C, which requires three operations (inserting
nodes e, f and g).
The overall complexity of the algorithm in [55] simplifies to
O(N2), including a pre-computation phase for determining the
costs of tree insert/delete operations (which is of O(2 

N + N2) time). Structural clustering experiments in [55] show
that the proposed algorithm outperforms those in [12,89].
Structural summaries: on the other hand, Dalamagas et al. [16]
provide an edit distance algorithm combining features from
both [12,55] and propose to apply it on XML tree structural
summaries, instead of whole trees, in order to gain in perfor-
mance. Structural summaries are produced using a special rep-
etition/nesting reduction process (e.g., the structural summary
of tree B of Fig. 2 would be tree A). The algorithm is of O(N2)
time. Experimental results in [16] show improved clustering
quality w.r.t. Chawathes algorithm [12]. Note that while it
might be useful for structural clustering tasks, Dalamagas et
al.s reduction process yields inaccurate comparison results in
the general case (e.g., Dist(A, B)=0 despite their differences)
which is why it is disregarded in the remainder of our
discussions.

Other methods to XML structural similarity have also been pro-
posed. They exploit various techniques (e.g., edge matching [38],
path similarity [58], the Fast Fourier Transform [23], and entropy
[31], etc.), usually providing approximations of (more complex

Fig. 2. Sample XML trees, with sub-tree repetitions.

and accurate) tree edit distance approaches. Such tree edit distance
alternative and approximation methods have been thoroughly
investigated in [77], and thus will not be covered in this paper.
Here, we consider tree edit distance to be the optimal technique
for assessing similarity among structured documents [9], and
hence focus on tree edit distance for XML structural comparison.

2.3. Semantic similarity

Measures of semantic similarity are of key importance in evaluating the effectiveness of Web search mechanisms in finding and
ranking results [44]. In the fields of Natural Language Processing
(NLP) and Information Retrieval (IR), knowledge bases (i.e., ontolo-
gies, thesauri and/or taxonomies, such as ODP [44], Rogets thesaurus [88], WordNet [48], etc.) provide a framework for organizing
words/expressions into a semantic space [33]. A knowledge base
usually comes down to a semantic network made of a set of concepts representing groups of words/expressions (or URLs such as
with ODP), and a set of links connecting the concepts, representing
semantic relations (synonymy, hyponymy, etc. [48,61], Fig. 3).
Hence, evaluating semantic similarity between words/expressions
comes down to comparing the underlying concepts in the semantic
space.

Indeed, several methods have been proposed to determine
semantic similarity between concepts (and consequently related
terms) in a knowledge base (semantic network). They can be categorized as: edge-based approaches and node-based approaches [33].

2.3.1. Edge-based approaches

Edge-based methods underline an intuitive and straightforward
way to evaluate semantic similarity in a semantic network. They
generally estimate similarity as the shortest path (in edges, or
number of nodes) between the two concepts being compared:
the shorter the path from one node to another, the more similar
they are [34,35,57]. On the other hand, the authors in [71,87] evaluate semantic similarity between two concepts by identifying their
most specific common ancestor. The similarity measures employed
consider the distance between the compared nodes and their common ancestor, as well as the distance separating the common
ancestor from the root of the semantic network.

However, a known problem with edge-based approaches is that
they often rely on the idea that links, in the semantic network, represent uniform distances [33,60]. In real semantic networks, the
distance covered by a single link can vary with regard to network
density, node depth and information content of corresponding
nodes [61]. The authors in [33] add that link distances could also
vary according to link type (i.e., semantic relation type). In an attempt to solve the varying distance problem, the authors in
[33,61] suggest weighting links according to the above mentioned
characteristics.

Entity  260  = N, total number of word occurrences 

              for underlying concepts 

Person; Individual 

Enrollee 

Adult 

Leader

Worker 

Unit  81

Structure  78

Student; 
Scholar 

Professional 

Superior 

Employee  1 

Building 
Complex 

Establishment 17

PhD Student

Educator 

Supervisor

Plant

Academy

College  9 

Lecturer 

Academic

Factory

Professor

Concept (Synonym Set)
Hyponymy (IsA) relations  

2.3.2. Node-based approaches

Node-based approaches get round the problem of varying link
distances by incorporating an additional knowledge source: corpus
statistical analysis, to augment the information already present in
the semantic network. In fact, with node-based approaches, the
definition of similarity is estimated as the maximum amount of
information content they share in common [33,60]. In a hierarchical semantic network (i.e., taxonomy, cf. Fig. 3), this common information carrier can be identified as the most specific common
ancestor (also known as Lowest Common Ancestor, or LCA) that
subsumes both concepts being compared [60] (e.g., LCA(Lecturer,
Professor) = Educator in Fig. 3). Consequently, the similarity between
two concepts is defined as the information content of their lowest
common ancestor, obtained by estimating its probability of occurrences in a large text corpus [60].

Definition 3 (Information
content). In information theory, the
information content of a concept or class c is quantified as the
negative log likelihood logp(c) where p(c) is the probability of
encountering an instance of c [60]. h

Definition 4 (Probability of a concept). It is generally quantified
with respect to the frequency of occurrence of the words/expres-
sions, subsumed by the corresponding concept, in a given corpus
[33,60]. h

Slightly different mathematical formulations [33,60] have been
utilized to compute concept probabilities. Here, we present the basic formulation by Resnik [60]:

pc 14 Freqc

N :
 Freqc 14
w 2 wordsc
sumed by c, in a given corpus,

countw

: number of occurrences of words sub-

 N: total number of words encountered in the corpus.

Since in hierarchical semantic networks (i.e., taxonomies, consisting mainly of hierarchical semantic relationships, e.g., Is-A,
Part-Of. . .), concepts subsume those lower in the hierarchy, Freq(c)
and consequently p(c) increase as one moves up the hierarchy (the
occurrence of a word is counted for its corresponding concept, as
well as the concepts ancestors). Thus, following Definition 4, nodes
higher in the hierarchy (with higher probabilities) are less informative (more abstract). If the semantic network has a root node
(otherwise a virtual root is usually added), then its probability
would be equal to 1, its information content being equal to 0.

Fig. 3 depicts an extract of WordNet weighted with pre-com-
puted concept frequencies based on a sample text corpus (e.g.,
Brown Corpus of American English [25]). Formula (2) presents a
variation of the node-based measures by Resnik [60]:
SimNodew1; w2; 14 SimNodec1; c2; SN 14  logpc0:

 c1 and c2 are the semantic concepts corresponding to the words

(expressions) w1 and w2 being compared,4

 c0 is the most specific common ancestor of c1 and c2,
 p(c0), the occurrence probability of concept c0 (cf. Definition 4,

Formula (1)),

 SN underlines the weighted semantic network (cf. Fig. 3), i.e., a
semantic network SN augmented with concept frequencies (i.e.,
concept weights).

Fig. 3. A (weighted) taxonomy fragment extracted from WordNet. The numbers
next to concepts represent concept frequencies (computed based on the Brown text
corpus [25]).

4 Semantic concepts are identified after several linguistic pre-processing operations
such as tokenization, stemming, and word sense disambiguation. These are briefly
discussed in Section 4.1.

J. Tekli, R. Chbeir / Web Semantics: Science, Services and Agents on the World Wide Web 11 (2012) 1440

Following Resnik [60], the semantic similarity between two
concepts in the semantic network is approximated by the information content of their most specific common ancestor. Resniks
experiments [60] show that his similarity measure is a better predictor of human word similarity ratings, in comparison with a variant of the edge-based methods [35,57].

Improving on Resniks method [60], Lin [41] presents a formal
definition of the intuitive notion of similarity, and derives an information content measure from a set of predefined assumptions
regarding commonalities and differences. Following [41], the commonality between two concepts is underlined by the information
content of their lowest common ancestor (identified by Resniks
measure [60]). However, the difference between concepts depends
on their own information contents (disregarded in [60]):
SimLinc1; c2; SN 14

2 log pc0

log pc1  log pc2

 c0 is the most specific common ancestor of c1 and c2,
 p(c0) denotes the occurrence probability of concept c0.

When comparing two concepts c1 and c2, Lins measure [41] takes
into account each concepts information content (log p(c1) +
 log p(c2)), as well as the information content of their most specific
common ancestor (log p(c0)), in a way to increase with commonality (information content of c0) and decrease with difference (informa-
tion content of c1 and c2). Lins experiments [41] show that the latter
information content measure yields higher correlation with human
judgment in comparison with Resniks [60] measure. Furthermore,
Lins measure which targets hierarchical structures, i.e., taxonomies
(as most existing semantic similarity measures) is generalized in
[44] to deal with ontologies of hierarchical (made by Is-A links) and
non-hierarchical components (made by cross links of different types,
e.g., RelatedTo. . .). Another interesting extension of Lins measure is
provided in [24] to semantically compare two groups of concepts,
and to evaluate concept similarity in geographic information systems
[15]. A more recent variation of Lins measure was introduced in [69],
providing a new approach to compute information content based solely on the hierarchical structure of a semantic network (namely
WordNet [48]), disregarding corpus statistics.

2.4. Integrating structural and semantic similarity

In recent years, there have been a few attempts to integrate
semantic and structural similarity assessment in the XML comparison process. The INEX (INitiative for the Evaluation of XML Retrie-
val5) campaigns have stressed the relevance of semantic similarity
assessment in XML retrieval. One of the early approaches to propose
such a method is [78], where the authors make use of a textual similarity operator and utilize Oracles InterMedia text retrieval system
to improve XML similarity search. In a recent extension of their work
[65], the authors define a generic ontological model, built on Word-
Net, to account for semantic similarity (instead of utilizing Oracle
InterMedia). However, INEX related approaches focus on textual
similarity (i.e., similarity between element/attribute values made
of long text fields) which is out of the scope of our study since in
structure-based similarity, values are commonly disregarded.

Recent XML structure-based methods in [6,64] identify the need to
support tag similarity (synonyms and stems) instead of tag syntactic
equality while comparing XML documents. In [42], the authors introduce a structure and content based method for comparing XML documents having the same grammar (i.e., not heterogeneous), and
consider semantic similarity evaluation between element/attribute
values, using a variation of the edge-based methods. In [73], the

5 http://inex.is.informatik.uni-duisburg.de/.

authors introduce a hybrid XML similarity approach integrating Chawathes tree edit distance algorithm [12], with semantic similarity using
Lins measure [41] to compare XML tag names. Methods in [42,73] produce asymmetric similarity measures.

2.5. Discussion

On one hand, various methods have been proposed to evaluate
XML structural similarity (i.e., comparing the hierarchical relations
and ordering among XML elements, identified by their labels). Most
methods in this family are based on the concept of tree edit distance
as an optimal technique to compare structured data. On the other
hand, a range of techniques have been developed for semantic similarity evaluation (comparing word/expression concepts in a reference knowledge base). Most methods in this category compare
the information content values of concepts in a semantic network.
Nonetheless, despite the rich literatures in XML similarity and
semantic similarity, few methods have addressed the problem of
integrating XML structure and XML tag (or value) semantics to improve similarity evaluation. That is probably due to the relative novelty of the XML semantic/structural similarity problem. As will be
shown in the following sections, various kinds of XML (sub-tree re-
lated) structure and semantic similarities remain unaddressed by
most existing methods. Taking into account such resemblances
would obviously amend XML comparison effectiveness.

Note that the issue of integrating structural and semantic similarity evaluation has also been investigated in the contexts of
schema matching/integration [3,4,18], as well as ontology map-
ping/mediation [46,51,52]. Yet, while comparable to tree-based
XML documents, schemas and ontologies often underline more
intricate graph structures, and thus require graph-based algorithms and heuristics in evaluating similarity, which are out of
the scope of this paper (here, we limit our presentation to XML
tree-based approaches).

3. Motivations

The main objective of this study is to provide a fine-grained
method that captures both structural and semantic similarities
when comparing XML document structures. Hereunder, we discuss
the motivations of our work, highlighting the relevance of structural and semantic similarity evaluation in XML document compar-
ison. We specifically focus on similarities left unaddressed in
current approaches, which we aim to capture with our XML document similarity measure.

3.1. Structural similarity

XML documents can encompass many optional and repeated
elements [55]. Such elements induce recurring sub-trees of similar
or identical structures. As a result, algorithms for comparing XML
documents should be aware of such repetitions/similarities to
effectively assess structural similarity.

Our examination of existing XML structural comparison ap-
proaches, particularly fine-grained approaches based on tree edit
distance, e.g., [12,16,55], have led us to identify certain cases
where sub-tree structural similarities are disregarded.

These undetected similarities can be distinguished as:

 repetitions of structurally similar sub-trees,
 structural similarity between sub-trees occurring at different

depths,

 similarity between a sub-tree on one hand, and the whole XML

tree on the other,

 repetitions of leaf node sub-trees.

On the other hand, the F, I, J case differs from the previous ones
since structural similarities occur not only among sub-trees, but
also at the sub-tree/tree level (e.g., between sub-tree F1 and tree
I). Such similarities are usually disregarded with existing methods,
e.g., [12,16,55]:

 Dist(F, I) = Dist(F, J) = 6, which is the cost of updating root node a
of tree F, transforming it into b (h), updating node b into c (i),
deleting nodes c, dand e, and inserting node c (j) into tree I (J).

In addition, none of the approaches mentioned above is able to
effectively compare documents made of repeating leaf node sub-
trees. For example, following [12,16,55], identical similarity values
are obtained when comparing document K, of Fig. 4, to documents
L and M. That is because most existing approaches consider minimum unit (=1) operations costs, regardless of the leaf nodes involved in the operations.

 DistK; L 14 CostInsb 14 1
 DistK; M 14 CostInsc 14 1

Nonetheless, one can realize that document trees K and L are
more similar than K and M, node b of tree K appearing twice in
tree L, and only once in XML tree M. Likewise, identical distances
are attained when comparing document trees K/N and K/P, despite the fact that the node b is repeated three times in tree N,
and only once in tree P. In this study, we explicitly mention the
case of leaf node repetitions since (i) leaf nodes are a special kind
of sub-trees: single node sub-trees, (ii) leaf node repetitions are
usually as frequent as sub-tree repetitions in XML documents,
and (iii) detecting leaf node repetitions would help increase the
discriminative power of XML comparison methods as described
in the above examples.

3.2. Semantic similarity

In order to stress the need for semantic relatedness assessment
in XML document comparison, we first report from [73] the sample
XML document trees in Fig. 5. Using classic edit distance computations (e.g., [12,16,55]), the same structural similarity value is obtained when document X is compared to documents Y and Z:

 Dist(X, Y) = Dist(X, Z) = 3, corresponding to the cost of updating
root node of label Academy transforming it into College (Factory),
updating node Professor transforming it into Lecturer (Supervi-
sor), and deleting node Student.

However, despite having similar structural characteristics, one
can easily recognize that sample document X shares more semantic characteristics with document Y than with Z. For instance,
node labels Academy-College and Professor-Lecturer, from documents X and Y, can be commonly viewed as semantically more
similar than Academy-Factory and Professor-Supervisor, from documents X and Z (considering a domain independent semantic network such as WordNet
[48], describing concepts found in
everyday language). Therefore, taking into account the semantic
factor in XML similarity computations would obviously amend
similarity results.

The example in Fig. 5 underlines semantic similarities between
XML nodes with identical structural positions (i.e., identical depth
and ordering). Such relatively simple semantic similarities have
been covered in [73]. The authors in [73] complement Chawathes
tree edit distance algorithm [12], with a semantic cost scheme
taking into account semantic similarities between XML node labels
in assigning edit operations costs. They make use of Lins semantic

Fig. 4. Dummy XML trees, depicting various kinds of sub-tree structural
similarities.

The authors in [55] make use of tree insertion and tree deletion
operations, coupled with thecontained in relation between trees, to
capture sub-tree repetitions, such as the case of XML trees A/B and
A/C mentioned in Section 2.2.2 (repetition of sub-tree B1). Yet,
when the containment relation is not fulfilled, certain structural
similarities are ignored.

Consider, for instance, trees A and D in Fig. 4. Here, the XML
document sub-trees being repeated are not contained in the source
tree, but are similar (e.g., D2 and A1 are similar). Since D2 is not
contained in A, it is inserted via four edit operations instead of one
(insert tree), while transforming A to D, ignoring the fact that part
of D2 (sub-tree of nodes b, c, d6) is identical to A1. Therefore, equal distances are obtained when comparing trees A/D and A/E, disregarding A/
D0s structural resemblances (here, we assume the general case where
atomic insertion/deletion operations are of unit costs, =1):

 DistA; D 14 CostInsh  CostInsb
 DistA; E 14 CostInsh  CostInse

CostInsc  CostInsd  CostInsh 14 1  4 14 5
CostInsf  CostInsg  CostInsh 14 1  4 14 52

Other types of sub-tree structural similarities that are missed by
existing approaches can also be identified when comparing trees
F/G and F/H, as well as F/I and F/J. The F, G, H case is different than
its predecessor (the A, D, E case) in that the sub-trees sharing structural similarities (F1 and G2) occur at different depths (whereas with
A/D, A1 and D2 are at the same depth). Here, the approaches in
[12,16,55] for instance yield identical distance values when comparing trees F and G, as well as F and H, disregarding the structural similarity between sub-trees F1 and G2 (in comparison with F1 and H2):

 Dist(F, G) = Dist(F, H) = 7, which is the cost of updating node b,
transforming it into m, deleting nodes c, d and e of tree F, and
inserting sub-tree G2 (H2) into tree F.

6 In the examples, we designate nodes by their labels for simplicity.

J. Tekli, R. Chbeir / Web Semantics: Science, Services and Agents on the World Wide Web 11 (2012) 1440

Tree X

Academy 

Division 

Branch 

Professor 

Student 

Tree Y 

College 

Division 

Branch 

Lecturer 

Tree Z 

Factory 

Division 

Branch 

Supervisor 

Fig. 5. Sample XML document trees, with semantically meaningful node labels.

Fig. 6. Sample XML trees with sub-tree semantic similarities.

similarity measure developed in [41], provided a given reference
semantic network. Nonetheless, the approach in [12] was not designed to capture sub-tree repetitions and resemblances, making
use of single node-based edit operations (i.e., node update, leaf
node insertion and leaf node deletion, cf. Section 2.2.2). The same
goes for its extension in [73] which is not concerned with repetitions of semantically similar sub-trees.

Consider the sample XML document trees in Fig. 6. Here, as with
the sub-tree structural similarity examples mentioned in the previous section, different types of undetected sub-tree semantic similarities can also be identified:

 occurrence of semantically similar sub-trees,
 semantic similarity between sub-trees occurring at differ-

ent depths,

 semantic similarity between a sub-tree on one hand, and

the whole XML tree on the other,

 occurrence of semantically similar leaf node sub-trees.

Recall the A, B, C and A, D, E comparison cases in Fig. 4. XML
trees A and B (likewise A and D) are structurally more similar than
A and C (respectively, A and E) due to the occurrence of structurally
identical (similar) sub-trees, i.e., A2(D2) in tree B (tree D). In Fig. 6,
XML document trees A0, B0 and C0 underline a similar scenario.
While trees B0 and C0 are structurally indistinguishable w.r.t. tree
A0, one can realize that A0 is semantically more similar to B0, than
to C0. Sub-tree A0
1 made of nodes Academy, Professor and PhD Student is semantically similar to sub-tree B0
2 (made of nodes College,
Lecturerand Scholar) in tree B0, while it is semantically different
than sub-tree C0
2 (of nodes Factory, Supervisor and Worker) in tree

C0 (w.r.t. a generic reference semantic network such as WordNet
[48]). In other words, instead of only considering the occurrence
and repetition of identical or structurally similar sub-trees (as discussed in the previous section), there is a need to consider the
occurrences of sub-trees that are semantically similar as well.

1 and G0

In addition, as with the sub-tree structural similarity examples
in Fig. 4, similar types of sub-tree semantic similarities can be
identified when comparing trees A0/G0 and A0/H0, A0/I0 and A0/J0,K0/L0
and K0/M0, as well as K0/N0 and K0/P0. The A0,G0,H0 case is different
in that the sub-trees sharing semantic similarities (A0
2) occur at different depths. The A0,I0,J0 case differs from its predecessors
in that semantic similarities occur, not only among sub-trees, but
also at the sub-tree/tree level (e.g., between sub-tree A0
1 and tree
I). On the other hand, the K0, L0, M0 and K0, N0, P0 cases correspond
to leaf node semantic similarities. Here, one can realize that document trees K0 and L0 are more similar than K0 and M0, node Professor
of tree K0 being semantically more similar to node Lecturer in tree
L0, than to node Supervisor in tree M0. Likewise for K0/N0 with respect
to K0/P0 (node Professor in K0 is semantically similar to Lecturer and
PhD Student in tree N0 while it is relatively different from nodes
Supervisor and Worker in tree P0). Hence, we identify the need to
detect, not only the occurrences of identical leaf nodes (as discussed in the previous section), but also the occurrences of leaf
nodes baring semantically similar labels. Detecting such similarities would obviously amend comparison accuracy.

4. Proposal

We view the problem of XML document structure comparison
as that of detecting the occurrences and repetitions of structur-
ally/semantically similar sub-trees.
In sub-trees, we underline
structures made of multiple nodes, as well as single leaf nodes.
Thus, we aim to provide a unified and fine-grained method to deal
with both structural and semantic resemblances left addressed by
existing comparison methods. Our XML comparison method consists of four main algorithms:

i. Struct_CBS

for

identifying the Structural Commonality

Between two Sub-trees,

ii. Sem_RBS for quantifying the Semantic Resemblance Between

two Sub-trees,

iii. TOCXDoc for computing the Tree edit distance Operations Costs,
iv. TEDXDoc for computing the Tree Edit Distance between XML

document trees.

In short, the TOC algorithm makes use of Struct_CBS and
Sem_RBS to structurally and semantically compare all sub-trees
in the XML documents being compared. The produced sub-tree
similarity results are consequently exploited as edit operations
costs (particularly tree insertion and tree deletion costs, which
are central to detecting the occurrences and repetitions of similar
sub-trees), in an adapted version of [55]s main edit distance algo-
rithm, which we identify as TED (cf. Fig. 15). Hence, the inputs to
our XML comparison approach are as follows:

 the XML document trees to be compared,
 parameter a enabling the user to assign more importance to the
structural or semantic aspects of the XML documents being
treated,

 a reference (weighted) semantic network SN, for semantic sim-

ilarity evaluation.

Consequently, the method outputs the similarity between the
XML document trees being compared. Our methods overall architecture is depicted in Fig. 7.

Fig. 7. Simplified activity diagram of our XML similarity approach.

Note that the introduction of two separate algorithms: Struct_CBS to
evaluate structure, and Sem_RBS to evaluate semantics (instead of one
single hybrid algorithm), is a design choice to: (i) emphasize the modularity of our approach (allowing to easily integrate additional algorithms in the future, considering other XML-related information,
such as element/attribute values and/or hyperlinks), and (ii) enable
the user to easily parameterize the similarity measure (assigning more
importance to either structure or semantics) following her notion of
similarity. In addition, note that Struct_CBS and Sem_RBS can be applied
to whole trees. However, in our study, their use is coupled with subtrees so as to capture the various kinds of sub-tree similarities.

In the remainder of this section, we detail each of the algorithms and processes mentioned above. Section 4.6 formally defines our XML document similarity measure, and evaluates its
properties w.r.t. the formal definition of similarity. Consequently,
time and space complexity analyses are discussed in Section 4.7.

4.1. Preliminaries

As described in Section 2.1, XML documents represent hierarchically structured information and can be modeled as Ordered Labeled
Trees (OLTs) [85]. Recall that in our study, an XML document is represented as an OLT with a node corresponding to each XML element
and attribute. Attribute nodes appear as children of their encompassing element nodes, sorted by attribute name, and appearing before all sub-element siblings. As mentioned previously, we disregard
element/attribute values while studying the structural properties of
heterogeneous XML documents (structure-only XML comparison).

Definition 5 (Ordered Labeled Tree:). It is a rooted tree in which the
nodes are labeled and ordered. We denote by T[i] the ith node of T in
preorder traversal, T[i].its label, and T[i].d its depth. R(T)=T[0]
designates the root node of tree T. h

Definition 6 (Sub-tree:). Given two trees T and T0,T0 is a sub-tree of T if
all nodes of T0 occur in T, with the same parent/child edge relationship
and node order, such as no additional nodes occur in the embedding of
T0 (e.g., F1 in Fig. 4 is a sub-tree of F, whereas tree I does not qualify as a
sub-tree of F since node e occurs in its embedding in F). h

Definition 7 (First level sub-tree:). Given a tree T with root p of
degree k, the first level sub-trees, T1, . . . , Tk of T are the sub-trees
rooted at the children nodes of p, p1, . . . ,pk. h

Definition 8 (Ld-pair representation of a node:). it is defined, as the
pair (,d) where  and d are, respectively, the nodes label and depth
in the tree. We use p. and p.d to refer to the label and the depth of
an ld-pair node p, respectively. h

Definition 9 (Ld-pair representation of a tree:). It is the list, in pre-
order, of the ld-pairs of its nodes (cf. Fig. 8). Given a tree in ld-pair
representation T = (t1, t2,
. . . ,tn), T[i] refers to the ith node ti of T.
Thus, T[i]. and T[i].d denote, respectively, the label and the depth
of the ith node of T, i designating the preorder traversal rank of
node T[i] in T. h

Note that the ld-pair tree representation was introduced by
Chawathe in [12], and will be exploited in our study in comparing
XML sub-trees (cf. Section 4.2, Struct-CBS).

In the following, we present the definitions of the tree edit oper-

ations utilized in our approach (adapted from [12,55]).

Definition 10 (Atomic node operations:). An atomic operation is an
edit operation applied on a single tree node. Our approach exploits
three atomic operations: leaf node insertion (introducing a new leaf
node in the tree), leaf node deletion (removing a leaf node from the
tree), and node update (modifying the label on an existing tree node):

 Insert leaf node: Let p be a node in a tree T, and let T1, . . . ,Tm be
the first level sub-trees of p. Given a node x not belonging to T,
Ins(x, i, p,) is a node insertion applied to T, inserting x as the ith
child of p, yielding T0 with first level sub-trees T1, . . . , Ti1,x,-
Ti+1, . . . ,Tm+1 ,where is the label of x.

 Delete leaf node: Given a leaf node x in a tree T, Del(x) is a node
deletion operation applied to T that removes x from T, yielding
tree T0 with first level sub-trees T1, . . . ,Ti1,Ti+1,

. . . ,Tm.

 Update node: Given a node x in tree T, and a label , Upd(x,) is a
node update operation applied to x resulting in T0 which is identical to T except that in T0,x bears as its label. The update operation could be also formulated as follows: Upd(x, y) where
y.denotes the new label to be assumed by x. h

Note that the update operation in our approach targets nodes of
identical structural positions, i.e., nodes having identical depth and
ordering in the trees being compared, transforming the label of one
node into that of the other.

Definition 11 (Complex tree operations:). A complex tree edit operation is an edit operation applied on a sub-tree of nodes. Our
approach exploits two complex operations: tree insertion and tree
deletion:

 Insert Tree: Given a tree A and a tree T with an inner node p having first level sub-trees T1,T2,
. . . ,Tm, InsTree(A, i, p) is a tree
insertion applied to T, inserting A as the ith sub-tree of p, thus
yielding T0 with first level sub-trees T1, . . . ,Ti1,A,Ti+1, . . . ,Tm+1.
 Delete Tree: Given a tree A and a tree T with an inner node p, A
being the ith sub-tree of p, DelTree(A, p) is a tree deletion operation applied to T that yields T0 with first level sub-trees
T1, . . . ,Ti1,Ti+1, . . . ,Tm. h

In addition, we provide the formal definition of a semantic net-

work, adopted in our study.

Definition 12 (Semantic network:). It can be formally represented
as a 3-tuple SN=(C, E, R, f) where:

 C: set of concepts, synonym sets as in WordNet [48].
 E: set of edges connecting the concepts,E # Vc 
 Vc.
 R: set of semantic relations, R = {Is  A,Has  A,Part  Of, Has 
Part . . . }, the synonymous words/expressions being integrated
in the concepts themselves.

 f: function designating the nature of edges, f:E ? R.

Fig. 8. Ld-pair representations of all sub-trees in XML trees A, B, and C of Fig. 4.

J. Tekli, R. Chbeir / Web Semantics: Science, Services and Agents on the World Wide Web 11 (2012) 1440

We designate by SN a weighted semantic network, i.e., a semantic network SN augmented with concept frequencies (cf. Fig. 3),
based on a given text corpus (e.g., the Brown Corpus of American
English [25]). h

Note that XML element/attribute tag names generally consist of
single words, simple concatenations of words (usually not more
than two terms per label [79], using the underscore delimiter or
Java-style upper/lower case letters to distinguish the individual
terms), and/or word abbreviations [59,79]. Nonetheless, semantically meaningful XML labels are usually obtained after several linguistic pre-processing operations such as tokenization (parsing
names into tokens based on punctuation and case, to form simple
expressions, e.g., PhD_Std ? PhD Student), expansion (identifying
abbreviations and acronyms, e.g., CEO ? Chief Executive Officer)
and stemming (reducing inflected or derived words to their stem,
i.e., base or root, e.g., housing, housed ? house) [17,43]. In the case
of polysemous words (i.e., words with multiple senses), word sense
disambiguation techniques, e.g., [54,56,79], can be exploited in order to select the semantic concept that most likely describes the
meaning of the label in the given XML document. Note that linguistic pre-processing operations are executed offline [79], using dedicated thesauri and/or dictionaries (in our case, WordNet), and do
not affect the performance of our comparison approach (Fig. 7).

4.2. Structural similarity between sub-trees (Struct-CBS)

As shown in Section 3.1, sub-tree structural similarities are usually left undetected in current XML comparison approaches. In
[55], the authors were the first to address the issue and were able
to detect certain basic sub-tree structural similarities using tree
insertion and tree deletion operations, coupled with the tree contained in relation (cf. Section 2.2.2). Nonetheless, when the containment relation is not fulfilled, various structural similarities are
ignored, as discussed in the motivation examples.

Here, in order to capture the various kinds of sub-tree structural
similarities pinpointed in Section 3.1, we identify the need to replace
the tree contained in relation, making up a necessary condition for
executing tree insertion and deletion operations in [55], by introducing the notion of structural commonality between two sub-trees.

Definition 13 (Structural commonality between sub-trees:). Given
two sub-trees A = (a1, . . . ,am) and B = (b1, . . . ,bn), we define the
structural commonality between A and B, designated by StructCom
(A, B), as the set of pairs of nodes N form A and B, N = {(ar, bu)} 2
A 
 B, such that "ar 2 A, bu 2 B,ar and bu occur in A and B,
respectively, with the same label, depth and relative order (in
preorder traversal). For 1 6r 6 m and 1 6u 6 n:

(1) ar. = bu. 
(2) ar.d = bu.d
(3) For any (as,bv) 2 N such as r 6 s , then u 6 v. h

Following Definition 13, the problem of finding the structural
commonality between two sub-trees SbTi and SbTj is equivalent
to finding the maximum number of structurally matching nodes
in SbTi and SbTj(jStructCom (SbTi,SbTj)j). However, the problem of
finding the edit distance between SbTi and SbTj comes down to
identifying the minimal number of edit operations that can transform SbTi to SbTj. Those are dual problems since identifying the edit
distance between two sub-trees (trees) underscores, in a roundabout way, their maximum number of matching nodes. In other
words, the greater the edit distance, the larger the edit script, the
greater the number of edit operations, the greater the number of
node transformations, the lesser the number of matching nodes.

Therefore, we introduce in Fig. 9 the pseudo-code of our
Struct_CBS algorithm, based on the edit distance concept, to identify
the structural commonality between sub-trees (similarly to the
approach provided in [53], in which the author develops an edit distance based approach for computing the longest common subsequence between two strings). In Struct_CBS, sub-trees are treated
in their ld-pair representations (cf. Definition 9, Fig. 8). Using the ldpair tree representations, sub-trees are transformed into modified
sequences (ld-pairs), making them suitable for standard edit distance
computations. The algorithm starts by computing the sum of the
costs of deleting every node in the source sub-tree (Fig. 9, line 3),
and inserting every node of the destination tree (line 4). Conse-
quently, it identifies the set of insertion/deletion operations having
the minimum overall cost (lines 515). Structurally matching nodes
are associated null costs (line 10). Note that the update operation is
specifically disregarded in Struct-CBS, in order to allow the identification of structurally matching nodes (line 10). Consequently, the
overall sum of the minimum operations costs (i.e., minimum cost
edit script, cf. Definition 2) underlines an edit distance, i.e., Dis-
t[jSBTij][jSbTjj], between the sub-trees SbTi and SbTj being compared.
Hence, the maximum number of matching nodes between SbTi and
SbTj, jStructCom(SbTi,SbTj)j, is identified w.r.t. the edit distance score:

 Total number of deletions: we delete all nodes of SbTi except
Deletions 14 jSbTij

those having matching nodes in SbTj;
jStructComSbTi; SbTjj

 Total number of insertions: we insert into SbTi all nodes of SbTj
Insertions 14

those having matching nodes in SbTi;

except
jSbTjj  jStructComSbTi; SbTjj

 Following Struct_CBS, using constant unit costs (=1) for node
insertion and deletion operations, the edit distance between
sub-trees SbTi and SbTj becomes as follows:

Dist12jSbTij12jSbTjj 14

2 1 

2 1

Deletions

Insertions

14 jSbTij  jSbTjj  2 
 jStructComSbTi; SbTjj

Therefore:

jStructComSbTi; SbTjj 14 jSbTij  jSbTjj  Dist12jSbTij12jSbTjj

Fig. 9. Algorithm Struct_CBS for identifying the structural commonality between
sub-trees.

Table 1
Detailed computations, following Struct_CBS, when applied on sub-trees A1 and D1.

4.3. Semantic resemblance between sub-trees (Sem-RBS)

In addition to sub-tree structural commonalities (i.e., considering parent/child relationships and ordering among XML elements,
identified by their labels), we aim to consider sub-tree semantics
in XML similarity evaluation (i.e., semantic meaning of sub-tree
node labels). For the sake of clearness, we use expression semantic
resemblance, in the remainder of the paper, to avoid confusion between semantic and structural similarity, the latter designated as
structural commonality.

Various methods for detecting the semantic similarity between
pairs of words/expressions, based on a given reference semantic
network, have been proposed (cf. Section 2.3). Nonetheless, capturing the semantic relatedness between two sets of words/expres-
sions (e.g., node labels of two sub-trees) has not been effectively
covered in the literature. To our knowledge, two complementary
approaches have tackled the issue, i.e., [15,24], developed in the
context of concept similarity of ontology management systems
[24], and concept similarity in geographic information systems
[15]. While theoretically sound, the solution provided in [15,24]
does not seem practical, since it requires a minimum of O(N!) time
(a detailed mathematical analysis is provided in [75]).

Hence, to capture the semantic resemblance between two sub-
trees, we provide a new approach entitled Sem_RBS, that combines
the traditional vector space model in information retrieval [47],
with semantic similarity evaluation (cf. Section 2.3). In detail, we
proceed as follows. When comparing two sub-trees SbTi and SbTj,
each would be represented as a vector ~V~V i and ~V j, respectively)
with weights underlining the semantic similarities between their
corresponding node labels. Recall, that XML tag names undergo
several linguistic pre-processing operations (including tokeniza-
tion, expansion, stemming, and word sense disambiguation, cf. Section 4.1) so as to obtain semantically meaningful labels prior to
the comparison process.

Definition 14 (Sub-tree vectors:). Given two sub-trees SbTi and
SbTj, we define corresponding sub-tree vectors ~V i and ~V j in a space
which dimensions represent, each, a single node label r 2 SbTi U
SbTj, such as 1 <r < n where n is the number of distinct node labels

in both SbTi and SbTj. The coordinate of a sub-tree vector V i
on
!r, underlining the semantic weight of
dimension kr is noted w
V i
label kr in SbTi. h

! 
 D-factorv r 2 120; 1:

Definition 15 (Semantic sub-tree node weight:). The semantic

weight of a node vr in vector V i
, representing sub-tree SbTi, is com-
! and
posed of two factors: a node/vector similarity factorSimv r; V i
a depth D-factor(vr) factor:
!vr 14 Simv r; V i

V i
! quantifies the semantic similarity between the
Simv r; V i

label vr.k of node vr and sub-tree vector V i
. It is computed as
the maximum semantic similarity between label vr.k and all
node labels of SbTi w.r.t. a reference (weighted) semantic network SN (cf. Definition 12). Formally:

Simvr; ~V i 14 Max
v2Vi
When vr 2 SbTi, Sim v r; V i
SbTi.

SimLabelv r:; v:; SN 2 120; 1

! 14 1 underlines the nodes occurrence in

 D-factor underlines the semantic influence of node depth on
XML semantic similarity. It follows the intuition that information placed near the root node of an XML document is more
important than information further down in the hierarchy

Fig. 10. Sample sub-trees bearing structural commonalities.

To obtain structural commonality values comprised in the [0,1]
interval, we normalize jStructCom(SbTi,SbTj)j via corresponding
sub-tree cardinalities, Max(jSbTij,jSbTjj). Thus:
jStructComSbTi;SbTjj
MaxjSbTij;jSbTjj 14 0 When there is no structural commonality :

jStructComSbTi; SbTjj 14 0

jStructComSbTi;SbTjj
MaxjSbTij;jSbTjj 14 1 When sub-trees are identical :

jStructComSbTi; SbTjj 14 jSbTij 14 jSbTjj

Table 1 shows the detailed computations and results of applying
Struct_CBS to sample sub-trees A1 and D1 of Fig. 4 (reported in
Fig. 10).

The first line of the distance matrix, i.e., Dist[0][], corresponds to the
sum of the costs of inserting every node of the destination sub-tree D1.
Likewise, the first column, Dist[][0], underlines the sum of the costs of
deleting every node of A1. Consequently, the algorithm identifies the
combination of insertion/deletion operations of minimum overall cost
(cf. Fig. 9, lines 515) in populating the remainder of the matrix, Dis-
t[jA1j][jD1j] underlining the final distance value. Note that in Table 1,
matching nodes are highlighted, while the (final) distance value is
emphasized in italic format. Having Dist[jA1j][jD2j] = 1:
jStructComA1; D2j 14 jA1j  jD2j  Dist12jA1j12jD2j
nodesb; c; d: Consequently;Struct CBSA1; D1 14 3

Similarly; Struct CBSC2; G2 14 jStructComC2; G2j
having jStructComC2; G2j 14 1:

MaxjSbTij;jSbTjj 14 1

14 3  4  1
14 0:75:

14 0:25

14 3;

Note that applying Struct_CBS to leaf node sub-trees comes down to
comparing corresponding sub-tree root node labels (leaf node
sub-trees consisting of sub-trees made of single nodes: the sub-tree root
nodes themselves, bearing identical (=0) depth and ordering scores). For
instance, Struct_CBS(A11, D11) = 1, since sub-trees A11 and D11 consist of
leaf nodes of label c. Similarly, when computing the commonality between a leaf node sub-tree (e.g., A11) and a non-leaf node sub-tree
(e.g., D1), Struct_CBS compares the label of the root of the former
(R(A11), the leaf node itself) to that of the latter (R(D1)):

 Struct_CBS(A11, D1) = 0, roots of A11 (leaf node) and D1 having
 Struct_CBS(E22, H2) = 1/4 = 0.25 having jStructCom(E22, H2)j = 1

different labels,

(since R(E22) = R(H2) = g) and Max(jE22j,j H2j) = 4.

J. Tekli, R. Chbeir / Web Semantics: Science, Services and Agents on the World Wide Web 11 (2012) 1440

[6,90]. Thus, node labels higher in the XML tree hierarchy
should have a greater semantic influence than their lower coun-
terparts. This could be mathematically concretized using Formula (7), adapted from [90]:

D  factorvr 14

1  vr:d

2 120; 1

where vr.d underlines the depth of node vr in the document. h

As for the label semantic similarity measure, SimLabel, our
investigation of the literature (Section 2.3) led us to consider Lins
method [41] in our XML comparison process (i.e., SimLabel  SimLin).
Lins measure was proven efficient in evaluating semantic similar-
ity, in comparison with its predecessors, i.e., [60,87]. Its performance and theoretical basis are recognized and generalized by
[44] to deal with hierarchical and non-hierarchical structures.
However, it is important to note that our XML similarity approach
is not sensitive, in its definition, to the semantic similarity measure
used. Yet, choosing a performing measure would yield better similarity judgment.

Having transformed XML sub-trees into semantically weighted
vectors, the semantic relatedness between two sub-trees can be
evaluated using a measure of similarity between vectors such as
the inner product, the cosine measure, the Jaccard measure, etc.
Here, we adopt the cosine measure widely exploited in information
retrieval [8,63]:
Sem  RBSSbTi; SbTj 14 Cos~V i; ~V j 2 120; 1

where V i
ing to SbTi and SbTj, respectively.

are the semantically weighted vectors correspond-

and V j

Algorithm Sem_RBS consists in building the vector space corresponding to the sub-trees being compared, as well as computing
the semantic and cosine measures as explained above. It takes as
input the sub-trees SbTi and SbTj to be compared, and the reference
semantic network SN, and generates the sub-tree semantic similarity score (2 [0,1]). Sem_RBSs pseudo-code is a straightforward consequence of Definitions 14 and 15, and is thus omitted for clearness
of presentation (it can be found in [75]).

Sample computation examples when comparing sub-trees
1/B0
2 of Fig. 11 (reported from Fig. 6) are shown

2 and A0

1/C0

A0
hereunder.

1 and B0

When comparing A0

2, the corresponding vector space
consists of six dimensions corresponding to each distinct node
label in both sub-trees: Academy, Professor, PhD Student, College,
Lecture and Scholar. Thus, 6-dimensional vectors V A01 and V B02 are
produced:

Semantic similarity values are computed following Lins semantic similarity measure [41] (cf. Formula (3)). Here, in computing
label semantic similarities, we exploit the weighted semantic network in Fig. 3. Similarity values, following [41], between pairs
Academy/College, Professor/Lecturer, and PhD Student/ Scholar are
computed as follows:
SimLinAcademy; College 14

2log pEstablishment

log pAcademy  log pCollege

 log 9

2 log 17

log 8

14 0:7970

Likewise, SimLin(Professor,Lecturer) = 0.7674 and SimLin(PhD Student,
Scholar) = 0.8402.

Recall that the semantic weight of a given node vr, of label kr, in

vector V i
, is computed as the maximum semantic similarity be-


tween kr and all node labels of V i
(cf. Definition 15). In our exam-

ple, SimLin(Academy, College) underlines the maximum similarity


, and
value between label Academy and all labels of vector V B02


. The same is true for node labels Pro-
vice-versa for College and V A01

fessor and Lecturer, as well as PhD Student and Scholar, w.r.t. V B02

and V A01
, respectively, (Fig. 12b). Thus, final vector weights are obtained by multiplying both semantic similarity and depth factors
SimLabel 
 D  factor as shown in Fig. 12c (Definition 15). Hence,
the semantic resemblance between sub-trees A0

2, w.r.t.
the reference semantic network SN in Fig. 3:
Sem  RBS A0
Similarity, when comparing sub-trees A0
2, the corresponding
vector space consists of 6 dimensions corresponding to each distinct
node label in both sub-trees:


! 14 0:9754:
; V B02
1 and C0


14 CosV A010

1 and B0

1; B0

Semantic similarities between pairs of labels are computed

following Lin [41] (Fig. 13a):

SimLinAcademy; Factory 14

2 log pStructure

log pAcademy  log pFactory

14 0:2662

Likewise, SimLin(Professor,Supervisor) = 0.3608 and SimLin(PhD
Student, Worker) = 0.3608.

semantic

Consequently,

resemblance:

1; C0

Sem  RBS A0

CosV A01

*  14 0:5303.

; V C02

Results show that sub-tree A0

1 (made of node labels Academy,
Professor and PhD Student) is semantically more similar to sub-tree
2 (College, Lecturer, Scholar) than C0
B0
2 (Factory, Supervisor, Worker).

4.4. Tree edit operations costs (TOC)

As stated previously, TOC (Fig. 14) is an algorithm dedicated to
computing tree edit distance operations costs, particularly the
costs of tree insertion and tree deletion operations (cf. Definition
11, including single node insertions/deletions costs), which are
central to detecting sub-tree similarities when comparing two
XML document trees (note that the use and cost of the update

Fig. 12. Sub-tree vectors when comparing sub-trees A0

1 and B0
2.

Fig. 11. Sample sub-trees bearing semantic resemblances.

Fig. 13. Sub-tree vectors when comparing sub-trees A0

1 and C0
2.

The user can thus assign more importance to either structural or

semantic similarities by varying parameter a 2 [0,1]:

 For a = 1, TOC will only consider structural commonalities in
computing operations costs (via Struct_CBS).
 For a = 0, only sub-tree semantic resemblances will be considered in computing operations costs (via Sem_RBS).

The fine-tuning of parameter a so as to effectively combine sub-tree
structure similarity (Struct-CBS) and semantic similarity (Sem-RBS)
comes down to an optimization problem such as a should be chosen
to maximize the overall sub-tree similarity function (cf. Formula (9)).
This can be solved using a number of known techniques that apply machine learning in order to identify the best weights for a given problem
class [20,22,32,45,49]. The main idea with this family of techniques is to
assign a higher (lower) weight with higher (lower) similarity values, acting like contrast filters in image processing by increasing the contrast on
input matrixes. Providing such a capability, in addition to manual tuning,
would enable the user to parameterize and adapt the XML comparison
process following the scenario at hand, giving more emphasis to the
structural or (inclusive) semantic aspects of the XML documents being
compared. We do not further address the fine-tuning of parameter a
here since it is out of the scope of this paper (and will be addressed in
an upcoming technical study).

Thus, following TOC, tree operations costs vary as follows:

Lemma 1. Following TOC, the maximal insert/delete tree operation cost for
a given sub-tree SbTi (attained when no sub-tree structural commonalities
nor semantic resemblances with SbTi are identified in the source/destination
tree) is the sum of the costs (unit costs = 1)7 of inserting/deleting every
individual node of SbTi (the proof is evident). h

Lemma 2. Following TOC, the minimal insert/delete tree operation
cost for SbTi (attained when a sub-tree identical to SbTi is identified
in the source/destination tree, respectively) is equal to half its insert/
delete tree maximum cost. h

The minimal tree operation cost is defined in such a way in order to
guarantee that the cost of inserting/deleting a non-leaf node sub-tree
will never be less than the cost of inserting/deleting a single node
(single node operations having unit costs). In fact, TOC is based on the
intuition that tree operations are more costly than node operations.

7 An intuitive and natural way has been usually used to assign single node
operation costs and consists of considering identical unit costs for insertion and
deletion operations [13,55].

Fig. 14. Tree edit distance Operations Costs (TOC) algorithm.

Fig. 15. Tree edit distance algorithm (TED).

operation, cf. Definition 10, are discussed in the following section). TOC
combines the structural commonalities (Struct_CBS) and semantic
resemblances (Sem_RBS) between each pair of sub-trees (SbTi and SbTj)
in the source and destination XML trees (A and B), respectively, assigning tree insert/delete operations costs accordingly. Consequently, these
costs are exploited via an adaptation of Nierman and Jagadishs main
edit distance algorithm [55] (Fig. 15) providing an improved and more
accurate XML document similarity measure.

Following TOC, the similarity between two XML sub-trees, SS(SbTi,
SbTj), is evaluated as the weighted average of their structural commonality (Struct_CBS) and semantic resemblance (Sem_RBS) scores:
SSSbTi; SbTj; a 14 a 
 Struct CBSSbTi; SbTj  1  a


 Sem RBSSbTi; SbTj;

where a 2 [0,1] is provided as input.

J. Tekli, R. Chbeir / Web Semantics: Science, Services and Agents on the World Wide Web 11 (2012) 1440

Proof. The smallest non-leaf node sub-tree that can be treated via
a tree operation is a sub-tree consisting of two nodes. For such a
tree, the minimum insert/delete tree operation cost would be equal
to 1 (its maximum cost being equal to 2), equivalent to the cost of
inserting/deleting a single node. That is the lowest tree operation
cost attainable, for a non-leaf node sub-tree, following TOC. h

Hence, for leaf node sub-trees, the maximum insert/delete tree
operation cost is equal to 1, the cost of inserting/deleting the single
node at hand:

 CostInsTree/DelTree(SbTi)=CostIns/Del (x) 
 1=1, when SbTi is made
of single node x.

The minimum cost for inserting/deleting a single node sub-tree

is equal to 0.5, half its maximum insert/delete cost:

CostInsTree/DelTree(SbTi)=CostIns/Del(x) 
 1/2=0.5 , SbTi consisting
of single node x.

This is essential in order to detect the similarities and repetitions among leaf node sub-trees (such as with the K, L, M and K, N, P
comparison cases in Fig. 4, discussed in the motivation section).

On one hand, note that in our approach, single node insertions/
deletions are undertaken via tree insert/delete operations (cf.
Definition 11) applied on leaf node sub-trees. Insert/delete node
operations (cf. Definition 10), which are assigned unit costs as with
traditional edit distance approaches, are only utilized to compute
tree insertion/deletion operations costs (cf. Struct_CBS in Fig. 9, and
TOC in Fig. 14  lines 3 and 6). They do not however contribute to
the dynamic programming procedure adopted in our edit distance
approach (similarly to [16,55], cf. TED algorithm in Fig. 15).

On the other hand, algorithm TOC exploits tree insertion/deletion
operations to identify not only the structural/semantic similarities
between sub-trees (SbTi, SbTj) but also the similarities between the subtrees and the whole XML trees (A and B) being compared (cf. Fig. 14,
lines 1 and 4). This is necessary when one of the trees involved in the
comparison process shares structural/semantic similarities with one
(or more) of the sub-trees encompassed in the other XML document
tree (e.g., the F,I, J case in Fig. 4 where tree I is structurally similar to subtree F1, and the A0, I0, J0 case in Fig. 6 where tree I0 is semantically similar
to sub-tree A0
1). Nonetheless, note that inserting/deleting the whole
destination/ source trees is not allowed in our approach (cf. algorithm
TED in Fig. 15). In fact, by allowing such operations, one could delete the
entire source tree in one step and insert the entire destination tree in a
second step, which completely undermines the purpose of the
insert/delete tree operations.

To sum up, TOC computes the costs of tree insertion and
deletion operations based on their corresponding sub-trees structural commonality and semantic resemblance values (maximum
values inducing minimum tree operations costs), to be exploited in
the main tree edit distance algorithm (TED). h

4.5. Tree Edit Distance (TED)

The pseudo-code of the tree edit distance algorithm TED, utilized in our study, is developed in Fig. 15. It is an adaptation of
Nierman and Jagadishs main edit distance process [55]. In addition
to tree insertion/deletion operations costs which vary w.r.t. the
structural/semantic similarities between XML sub-trees, TED exploits update operations costs (Fig. 15, line 4) in computing the distance between two XML document trees. In short, the algorithm
recursively goes through the sub-trees of both XML document
trees being compared, combining node update, tree insertion and
tree deletion operations so as to identify those of minimal cost.
The node update operation (Definition 10) is applied to the roots

of the XML trees being compared, as well as the roots of each pair
of sub-trees considered in the recursive process (Fig. 15, line 4),
whereas tree insertion and tree deletion operations are applied
to corresponding first-level sub-trees (Fig. 15, lines 56, 1314).
Recall that the insertion/deletion of single nodes are undertaken
via tree insertion/deletion operations applied on leaf node subtrees (as described in the previous section).

While tree insertion/deletion operations costs allow detecting
the structural and semantic similarities between XML sub-trees
(cf. TOC), the update operation cost is central in evaluating the similarity between the roots of the XML document trees being com-
pared, as well as the roots of XML sub-trees considered in the
recursive process (TED).

With classical edit distance approaches, the cost of the update
operation underlines the equality/difference between node labels:

 Minimum cost when the compared element labels are identical,

CostUpd(a, b) = 0 when a. = b.

 Maximum unit cost otherwise,

i.e. CostUpd(a, b) = 1 when

a.  b.

Nonetheless, to consider the semantic similarities between element labels (not only label equality/difference) in our study, we
extend the update operation cost scheme as follows:

CostUdpa; b;a 14
121  1  a 
 SimLabela:; b:; SN 
 aDfacta:d
1aDfacta:d

where a 2 120; 1

if a:  b:
otherwise

Parameter a (which is the same utilized in TOC) allows assigning
more importance to either structural or semantic similarities:

 For a = 1, we only consider label equality/difference in computing the cost of the update operation, as with traditional structural edit distance approaches,

 For a = 0, node semantic similarities will be considered in computing the update operation cost. Here, the operation cost varies
in the [0,1] interval w.r.t. the semantic similarity between the
concerned node labels and corresponding depths (note that
nodes treated via the update operation are of the same depth,
i.e., a.d = b.d).

Consider for instance document trees X, Y and Zin Fig. 5. With
a = 0, the corresponding root update operations costs would be
as follows:

CostUpdRX;RY 14 1SimLinAcademy;College
 1 14 0:2030:

CostUpdRX;RZ 14 1SimLinAcademy;Factory
 1 14 0:7337:

It is clear that the cost of updating Academy and College is lesser
than that of transforming Academyinto Factory, identifying the fact
that the former couple is more semantically similar than the latter
(detailed computation examples are developed in the Appendix).

Here, as with Sem-RBS, we exploit Lins measure [41] to assess
the semantic similarity between node labels (i.e., Sim Label  SimLin).
However, recall that its use is not mandatory. We use it since it is
among the most efficient measures available, as discussed
previously.

4.6. XML document similarity measure (SimXDoc)

In our study, we adopt the formal definition of similarity as the
inverse of a distance function [21], i.e., tree edit distance. Given
XML document trees A, B and C:

SimXDocA; B 14 1  TEDA; B
jAj  jBj :
Note that TED(A, B)  TED(A, B, {CostInsTree}[{CostDelTree}, a,SN, and
likewise SimXDoc(A, B)  SimXDoc(A, B, a; SN, following our algo-
rithms. Yet, we omit the a; SN and {CostInsTree} [{CostDelTree} input
parameters in Formula (11) for ease of presentation.

Our similarity measure is consistent with the formal definition
of similarity [21,44], and comes down to a generalized metric  i.e.,
a similarity (distance) function satisfying all metric properties except for triangular inequality:

i. SimXDoc(A, B) 2 [0,1].
ii. SimXDoc (A, B) = 1 ) A and B are identical.
iii. SimXDoc

(A, B) = 0 ) A and B have no common

characteristics,8

iv. Similarity increases with the commonality between A and B,

and decreases with their difference.

v. SimXDoc (A, B) = 1) similarity is reflexive.
vi. SimXDoc (A, B) = SimXDoc (A, B)) similarity is symmetric.

In fact, triangular inequality is controversially discussed and
is usually domain and application-oriented [21]:

vii SimXDoc (A, C)P SimXDoc (A, B)
 SimXDoc (B, C) ) Triangular

inequality.

Regarding semantic similarity in particular, most methods in
the literature (e.g., [60,87], cf. Section 2.3) including Lin [41], do
not satisfy triangular inequality. An example by Tversky [80], reported by Maguitman et al. in [44], illustrates the impropriety of triangular inequality with an example about the similarity between
countries: Jamaica is similar to Cuba (geographical proximity); Cuba
is similar to Russia (political affinity); but Jamaica and Russia are not
similar at all. And since we evaluate semantic similarity via Lins
measure [41] in our approach, our integrated semantic/structural
approach does not transitively satisfy triangular inequality.

Note that when parameter a = 1, i.e., when our approach is utilized as a purely structural XML comparison method (i.e., only
Struct_CBS is taken into account), our method behaves similarly
to existing XML structural comparison methods, e.g., [12,16,55],
provided that the distance values generated by the latter are evaluated via the similarity variant in Formula (12).

4.7. Overall complexity

4.7.1. Time complexity

The overall complexity of our integrated structural and semantic similarity approach simplifies to O(jAj 
 jBj 
 jSNj 
 Depth(SN)),
where jAj and jBj denote the cardinalities of the compared trees,
jSNj the cardinality of the semantic network exploited for semantic
similarity assessment, and Depth(SN) its maximum depth. It is
computed as follows:

 Struct_CBS algorithm for the identification of the structural
complexity:
commonality between two sub-trees
O(jSbTij 
 jSbTjj) where jSbTij and jSbTjj denote the cardinalities
of the compared sub-trees.

is of

8 SimXDoc(A, B) = 0, means that computing the distance between A and B, consists of
deleting all the nodes of the source tree, and then inserting all the nodes of the
destination tree, i.e., TED(A,B) = jAj + jBj.

 Sem_RBSfor identifying the semantic resemblance between two
sub-trees is of complexity: O(jSbTij 
 jSbTjj 
 jSNj 
 Depth(SN)).
Note that O(jSNj 
 Depth(SN)) underlines the time complexity of
the semantic similarity measure itself [41].

 TOC algorithm for computing the costs of tree insert/delete
operations, which makes use of Struct_CBS and Sem_RBS in
identifying the structural commonalities and semantic resemblances between sub-trees in the source and destination trees,
j141OjSbTij 
 jSbTjj 
 jSNj

jT2j
is
DepthSN and simplifies to O(jAj 
 jBj 
 jSNj 
 Depth(SN)).
The mathematical proof is provided in [75].

complexity

jT1j
i141

of

time

 The edit distance algorithm TED (an adaptation of the algorithm
in [55]) which utilizes the results obtained by TOC (tree operations costs), is of complexity O(jAj 
 jBj 
 jSNj 
 Depth(SN)).

When disregarding semantic similarity assessment, i.e., when
input parameter a = 1 (thus disregarding algorithm Sem_RBS), our
approach simplifies to O(jAj 
 jBj), similarly to existing XML-based
tree edit distance comparison approaches, e.g., [12,16,55].

4.7.2. Space complexity

As for memory usage, our approach requires RAM space to store
the XML document trees being compared, as well as the distance
matrixes and semantic vectors being computed. It simplifies to
O(jAj 
 jBj)
space
e.g.,
[12,16,55]) since:

approaches,

(similarly

existing

to

 Struct_CBS requires jSbTij 
 jSbTjj space for storing the distance
matrix when identifying the structural commonalities between
any two sub-trees SbTi and SbTj. Hence, space complexity is of
O(jSbTij 
 jSbTjj).
 Sem_RBS requires 2 
 (jSbTij + jSbTjj) space for handling corresponding sub-tree vectors, each vector being of maximal
dimension jSbTij + jSbTjj. Hence, Sem_RBS is of O(jSbTij +
jSbTjj).Note that the semantic network is not stored in local
memory, but is stored on disk (and is managed via a database
system, cf. Section 6.6.1), and thus does not contribute to space
complexity.
j141OjSbTij 
 jSbTjj space, for storing the vari-
jT2j
ous distance matrixes (Struct_CBS) and sub-tree vectors
(Sem_RBS) between each pair of sub-trees in the source and destination XML trees. This simplifies to O(jAj 
 jBj) as shown in the
previous section.

 The edit distance algorithm TED is of O(jAj 
 jBj) space

 TOC is of

jT1j
i141

complexity.

5. Comparison with existing approaches

In the following, we provide both theoretical and computational
comparative analyses, evaluating our XML document similarity
method against existing approaches.

5.1. Formal comparison

A formal mathematical comparison shows that some existing
methods are lower bounds of our approach. This property conveys
the fact that our method reduces edit operations costs following
sub-tree similarities, and affects overall similarity values accord-
ingly, whereas existing approaches usually exploit maximum edit
operations costs regardless of the presence of sub-tree similarities,
hence producing minimum similarity scores.

Theorem. Let A and B be XML trees, and SimA; B 14 1  TEDA;B
jAjjBj ,
then:

 SimChawathe(A, B) 6 SimXDoc(A, B)

J. Tekli, R. Chbeir / Web Semantics: Science, Services and Agents on the World Wide Web 11 (2012) 1440

 SimDalamagas et al.(A, B) 6 SimXDoc(A, B)

Proof

 Proving that Chawathes algorithm [12] is a lower bound of our
XML comparison method is straight forward. When computing
the distance between two trees using Chawathes approach
[12], all sub-trees are inserted/deleted via single node inser-
tion/deletion operations regardless of the sub-tree similarities
at hand. The costs of these insertions/deletions are equivalent
to the maximum tree insertion/deletion operations costs following our TOC algorithm (Section 4.4), which yield a maximum edit distance, thus a minimum similarity value between
the compared trees. In other words, Chawathes algorithm
[12] always yields similarity values lesser or equal to those
computed via our approach.

 Proving that Dalamagas et al.s algorithm [16] is a lower bound
of our XML comparison method is also trivial. Indeed, the costs
of tree insertion/deletion operations in [16] are computed as the
sum of the costs of inserting/deleting all individual nodes in the
considered sub-trees. These costs come down to the maximum
tree operations costs computed following our method. Conse-
quently, Dalamagas et al.s algorithm [16] always yields similarity values that are lesser or equal to those computed via our
method. Note that we do not consider the methods repeti-
tion/nesting reduction process in our analysis since it yields
inaccurate comparison results in the general case (cf. Section
2.2.2). h

As for Nierman and Jagadishs approach in [55], tree insertion/
deletion operations costs are affected by the tree contained-in
relation (cf. Section 2.2.2). Maximum costs (i.e., the costs of
inserting/deleting all single nodes in the considered sub-trees) are
attained when the contained-in relation is not verified. Otherwise,
when the contained-in relation is verified, tree operations costs are
minimal, and amount to the cost of inserting/deleting leaf nodes
(normally unit costs = 1)9. Hence, we cannot mathematically conclude that the measure in [55] is a lower bound (or upper bound) of
our XML comparison method since sub-tree costs are computed
differently. In other words, the approach in [55] can yield similarity
scores which are higher/lower than those produced by our method
regardless of the similarities detected (since different mathematical
cost schemes are utilized). However, it is clear that Nierman and
Jagadishs approach only considers the contained-in relation between
sub-trees while varying tree operations costs. On the other hand, our
algorithm detects fined-grained structural and semantic similarities
between sub-trees, among which the structural containment rela-
tion. Thus, our approach is able to detect a wider set or similarities
w.r.t. the method in [55]. Thus, if we assume that sub-tree insertion/
deletion costs in [55] are defined in accordance with our method
(applying TOC while confining to the tree containment relation for
instance, i.e., we only compute sub-tree insertion/deletion costs
when the contained-in relation is verified), or vice-versa (assigning
unit costs to tree operations used in our approach  instead of
applying TOC  whenever sub-tree similarities are detected), then
Nierman and Jagadishs algorithm would clearly yield similarity
values that are lesser or equal to those obtained via our method.

Regarding the approach by Tekli et al. in [73], it focuses on the
special case of semantic similarities between pairs of single node
labels, particularly those having identical structural positions. Such
similarities are covered in our current study, in the context of
wider sub-tree semantic resemblances (an inner node would be

treated as the root of its underlying sub-tree, whereas a leaf node
would be simply viewed as a leaf node sub-tree). Yet, we cannot
provide a formal mathematical comparison between both meth-
ods. In fact, node insertion/deletion operations costs are computed
in a particular manner in [73], taking into account the semantic
similarity between the nodes label and that of its parent in the
source/destination document tree. Thus, the approach in [73]
yields similarity values that are not quantitatively comparable to
those produced via our current method. Consider or instance XML
document trees X, Y and Z in the example of Fig. 5:

 SimTekli et al.(X, Y) = 0.9432 > SimTekli et al.(X, Z) = 0.8741
 SimXDoc(X, Y) = 0.9093 > SimXDoc(X, Z) = 0.8352

Both methods detect that trees X and Y are semantically more
similar than X and Z, w.r.t. the semantic network in Fig. 3. Yet, the
similarity values are different, underlining that the methods are
not quantitatively comparable.

5.2. Similarity results for motivating examples

Hereunder, we present XML distance/similarity values obtained
when applying our approach to treat the various XML comparison
examples presented throughout the paper. Results in both Tables 2
and 3 show that our XML similarity method is able to efficiently
detect the various kinds of structural and semantic resemblances
mentioned throughout the paper, which are left unaddressed by
existing approaches (i.e., identical similarity values are obtained
with existing approaches, despite the presence of structural and/
or semantic similarities  values are omitted for ease of presenta-
tion), to the exception of a few cases detected by existing methods
(discussed in Section 3).

Computational details are provided in the Appendix.

6. Experimental evaluation

6.1. Prototype

We have developed a prototype system, entitled XS3 (XML
Structural and Semantic Similarity)10, to test, evaluate and validate
our XML document comparison method, including implementations
of its most recent alternatives in the literature. The XS3 prototype,
implemented using C#.Net, is made of four independent and interactive components, as well as various comparison and application
modules:

 The parser component starts by verify the integrity of XML doc-
uments, undertaking lexical pre-processing and transforming
documents into ordered labeled trees.

 The similarity evaluation component consists of several autonomous algorithms, including our approach and some of its most
prominent alternatives which we refer to as Chawathe [12], N.
& J. [55], DCWS [16], and TCY [73]. It is extensible to other
approaches.

 The Synthetic XML generator produces sets of XML documents
based on specific user requirements. It is an adaptation of the
IBM XML documents generator11 accepting as input: a DTD doc-
ument, a MaxRepeats12 value designating the maximum number
of times a node will appear as child of its parent (when * or +
options are encountered in the DTD), as well as a NbDocs value
underscoring the number of documents to be produced.

9 Please note that the minimum tree operation cost is not formally defined in [55].

We acquired this information from the authors.

10 Available at:http://www.u-bourgogne.fr/Dbconf/XS3.
11 http://www.alphaworks.ibm.com.
12 A greater MaxRepeats increases the probability of attaining variability with
optional and repeatable elements when generating XML documents.

Table 2
Distance/similarity values obtained when comparing structurally similar documents, with parameter a set to 1 (Struct_CBS is exploited in
computing tree operations costs).

Table 3
Distance/similarity values obtained when comparing semantically related documents with parameter a set to 0 (Sem_RBS is exploited in computing tree operations costs).

 Furthermore, a taxonomic analyzer component was introduced to
compute semantic similarity values between words (expres-
sions) in a given semantic reference (e.g., WordNet [108]), to
be subsequently exploited in evaluating XML element/attribute
label similarity. It currently includes semantic measures developed in [97,165] and is extensible to others.

In addition, XS3 includes four XML document comparison mod-
ules, One to One, One to Many, Many to Many (consequently enabling XML document clustering), and Set comparison (for
computing average inter-set and intra-set similarities, and evaluating clustering quality). The latter are thoroughly described in the
following sections.

and assess the attained scores to thea priori known DTDs. Results
are depicted in a matrix where element (i, j) underscores the average similarity value, Sim(Si,Sj), corresponding to every pair of distinct documents such that the first belongs to set Si(DTDi) and
the second to set Sj( DTDj).

The authors in [16,55] make use of clustering methods in order
to group together structurally similar documents and subsequently
evaluate how closely the obtained clusters correspond to the actual
XML grammars. In addition, the authors in [16] adapt two metrics
popular in information retrieval: precision and recall [62], in performing XML structural clustering evaluation. In the following,
we report the definitions of those metrics and propose a method
for extending their usage to obtain consistent experimental results.

6.2. Evaluation metrics

6.2.1. Background

How to experimentally evaluate the quality of an XML similarity method remains a debatable issue, especially in information re-
trieval. To our knowledge, the definition of standardized XML
similarity evaluation metrics remains a hot topic in the INEX evaluation campaigns.13 A few XML evaluation techniques have been
proposed in the literature [16,23,55]. All of them use XML grammars
(DTDs or XSDs) as reference for detecting structurally similar XML
documents.

In [23], the authors compute inter-set and intra-set average
similarities between documents corresponding to different DTDs

6.2.2. Metrics used

Owing to the proficient usage of their traditional predecessors
in classic information retrieval evaluation, we make use of the precision (PR) and recall (R) metrics defined in [16], to evaluate the
effectiveness of our approach and compare it to existing methods.
Following Dalamagas et al. [16], for an extracted cluster Ci that
corresponds to a given XML grammar Gi (the cluster/grammar
mapping issue is addressed subsequently):

 ai is the number of XML documents in Ci that indeed correspond

to Gi (correctly clustered documents).

 bi is the number of documents in Ci that do not correspond to Gi

(miss-clustered).

13 http://inex.is.informatik.uni-duisburg.de/.

 ci is the number of XML documents not in Ci, although they correspond to Gi (documents that should have been clustered in Ci).

PR 14

i141ai 

i141ai

i141bi

2 120; 1 and R 14

i141ai 

i141ai

2 120; 1

i141ci

Consequently, given n: the total number of generated clusters:

High precision denotes that the clustering task achieved high
accuracy, grouping together documents that actually correspond
to the XML grammars mapped to the clusters. High recall means
that very few documents are not in the appropriate cluster where
they should have been. In addition to comparing one approachs
precision improvement to anothers recall, it is a common practice
to consider the F-value, which represents the harmonic mean of
precision and recall:

F  value 14 2 
 PR 
 R
PR  R

2 120; 1

Therefore, as with traditional information retrieval evaluation, high
precision and recall, and thus high F-value (indicating in our case excellent clustering quality) characterize a good similarity method.

6.3. Mapping grammars to clusters

Mapping XML grammars to XML document clusters comes
down to mapping the groups of documents corresponding to each
grammar (which we identify as original grammar clusters) to those
created by the clustering process (which we identify as extracted
clusters, or simply clusters). To get such a mapping, we compute
the average intra-set similarity values between each original grammar cluster and extracted cluster and then identify the pairs of
matching grammars/extracted clusters following the highest values.
Note that in the following sections, the term cluster will always refer to extracted cluster.

6.4. Clustering XML documents

In our experiments, we chose the well known single link hierarchical clustering method [27,30] although any form of clustering
could be utilized. Given n XML documents, we construct a fully
connected graph G with n vertices (XML documents) and (n 

(n  1))/2 weighted edges. The weight of an edge corresponds to
the similarity between the connected vertices. Consequently, the
single link clusters for a similarity threshold si are identified by
deleting all the edges with weights <si. Therefore, the single link
clusters will group together XML documents that have pair-wise
similarity values greater or equal than si.

However, unlike Dalamagas et al. in [16], we do not utilize a
stopping rule to determine the most appropriate clustering level
for the single link hierarchies, and thereafter obtain only one PR/
R doublet for analysis with each clustering experiment. Instead,
we compute a whole series of PR/R doublets. Those series correspond to the different clustering sets obtained by varying the clustering threshold in the [0,1] interval. In other words, we construct a
dendrogram (cf. Fig. 16) such as:

 For the initial clustering level, where the similarity threshold
s1 = 0 (or s1 = minimum similarity attainable between any pair
of documents), XML documents appear in one global cluster:
the starting one.

 For the final clustering level, where the similarity threshold
sn = 1 (with n the total number of levels, i.e., number of clustering sets in the dendrogram), each distinct document will appear
in a different cluster.

 Intermediate clustering sets will be identified for thresholds si/

s1 < si < sn.

Fig. 16. Dendrogram and detailed PR/R computations when clustering 15 XML
documents sampled from the SIGMOD record (here, clustering is based on
structure, i.e., a = 1).

Then, we compute precision (PR) and recall (R) for each clustering set identified in the dendrogram, thus constructing PR and R
graphs that describe the systems evolution throughout the clustering process. We also compute average precision and recall val-
ues: Ave(PR) and Ave(R), considering the whole dendrogram, on
the basis of the obtained series, providing yet another indicator
of clustering quality.

A sample dendrogram underlining the clustering evolution of
15 XML documents of the SIGMOD Record14 (5 sampled from each
of the OrdinaryIssuePage.dtd, ProceedingsPage.dtd and SigmodRe-
cord.dtd grammars), is shown in Fig. 16.

6.5. Experimental results

We conducted experiments on real and synthetic XML documents to test our XML comparison method. Results indicate that
our approach yields improved clustering quality (i.e., comparison
quality) than current approaches, w.r.t. both XML structural and
semantic features. We detail each set of experiments in the following sub-sections.

6.5.1. Structural similarity evaluation

To test our methods effectiveness in evaluating XML structural
similarity, we conducted experiments on two sets of 750 docu-
ments, generated from 25 real-case15 and synthetic XML grammars,
using our adaptation of the IBM XML documents generator. We varied the MaxRepeats parameter to determine the number of times a
node will appear as a child of its parent node. For a real dataset,
we considered the online version of the ACM SIGMOD Record. We
experimented on a set of 104 documents corresponding to Ordinary-
IssuePage.dtd (30 documents), ProceedingsPage.dtd (47 documents)
and SigmodRecord.dtd (27 documents).16 The characteristics of the
document sets used are summarized in Tables 4 and 5.

14 Available at: http://www.sigmod.org/record/xml/.
15 From http://www.xmlfiles.com and http://www.w3schools.com.
16 We found only one XML file conforming to the SigmodRecord.dtd grammar:
SigmodRecord.xml. However, due to its relatively large size (479KB) in comparison
with the XML documents corresponding to the other two DTDs (10KB of average size
per document), we carefully decomposed SigmodRecord.xml to several documents,
creating a set of XML documents conforming to SigmodRecord.dtd.

Table 4
Characteristics of the SIGMOD Record document set.

Grammars (DTDs)

Number of documents

Average node depth (per doc)

Average no. of elements (per doc)

Average no. of attributes (per doc)

OrdinaryIssuePage
ProceedingsPage
SigmodRecord

Table 5
Characteristics of synthetic XML document sets.

Document set

Number of documents

Average node depth (per doc)

Average number of nodes (per doc)

MaxRepeats = 5
MaxRepeats = 10

Fig. 17. PR, R and F-value graphs for clustering real SIGMOD Record XML documents.

Precision, recall and F-value graphs are presented in Figs. 1719.
Corresponding Ave(PR), Ave(R) and Ave(F-value) values are reported
in Table 6.

Results, with respect to all three data sets, indicate that our approach yields improved global clustering quality (i.e., structural
comparison quality) in comparison with current alternative ap-
proaches. For the SIGMOD Record document set, our method yields
an average overall precision higher than that of N. & J. and identical
to those achieved by DCWS and Chawathes algorithms. As for re-
call, our approach shows better results than N. & J., DCWS as well
as Chawathe. In fact, average F-value results underline our methods higher clustering efficiency (i.e., comparison quality). For the
synthetic datasets, our method yields averageprecision levels lower
than those achieved by its predecessors, to the exception of the
first synthetic dataset (MaxRepeats = 5) where our approach outranks N. & J.s average precision level. However, our method consistently maintains recall levels higher than those of its alternatives.
In cases where higher/lower precision/recall levels are obtained
simultaneously, the F-value measure is fundamental in assessing
the overall loss and gain in average precision/recall, and evaluating
result quality. For both synthetic datasets, our method yields higher average F-values in comparison with N. & J., DCWS, and
Chawathe.

Note that the low precision levels obtained with the synthetic
datasets are probably due to utilizing relatively similar grammars
(we explicitly used grammars baring sub-tree similarities) in generating the document sets. Similar grammars would induce similar
documents. Such documents could thus be easily miss-clustered if
their structural similarities are detected, which is the case when
using our approach (the clusters include the right documents as
well as additional similar ones). Existing approaches disregard various kinds of similarities, e.g., sub-tree similarities, which is why

they tend to distinguish documents that are in fact similar. Such
undetected similarities might yield better precision levels (smaller
clusters including only portions of correctly clustered documents).
Nonetheless, they consistently yield lower recall values (lots of
documents are not in the appropriate clusters where they should
have been).

6.5.2. Evaluation of structural and semantic similarity

Various experiments were conducted in order to validate our
approachs ability of integrating semantic similarity evaluation in
XML document comparison. In addition to hierarchical clustering
[30], we utilized the inter-set/intra-set average similarity technique introduced in [23] which seemed effective in evaluating
the semantic relatedness between groups of XML documents. We
exploited (extracts of) WordNet as the reference semantic net-
work, weighted based on the Brown Corpus of American English
[25]17. Synthetic XML documents generated based on real and synthetic XML grammars18 were considered (All test documents and
grammars are published online19 to facilitate future comparative
evaluations). We selected general purpose XML grammars describing real world data, to allow relevant semantic evaluation using
WordNet (which is a general purpose semantic reference describing
every day English language [48]). Otherwise, it would be useless to
evaluate the semantics of XML labels given a reference that does
not encompass corresponding semantic concepts (for instance, it
would be futile to compare XML documents describing protein se-
quences, using the general purpose WordNet, since most semantic

17 http://www.cogsi.princeton.edu/cgi-bin/webwn.
18 From http://www.xmlfiles.com and http://www.w3schools.com.
19 www.u-bourgogne.fr/DbConf/XS3.

J. Tekli, R. Chbeir / Web Semantics: Science, Services and Agents on the World Wide Web 11 (2012) 1440

Fig. 18. PR, R and F-value graphs for clustering documents of synthetic set 1 (MaxRepeats = 5).

Fig. 19. PR, R and F-value graphs for clustering documents of synthetic set 2 (MaxRepeats = 10).

Table 6
Average PR, R and F-values obtained by varying the clustering threshold between [0, 1].

Chawathe

N. & J.

Our approach (a = 1)

SIGMOD

Set 1 (MaxRepeats = 5)

Set 2 (MaxRepeats = 10)

F-value

F-value

F-value

concepts related to protein descriptions do not exist in WordNet, and
require a dedicated semantic reference).

Note that the number of documents utilized in our combined
semantic/structural similarity evaluation is reduced w.r.t. the
structural similarity experiments, because of the complexity of
the semantic similarity process due to traversing the reference
semantic network (as shown in Section 6.6.1).

6.5.2.1. XML document clustering experiments. Clustering experiments were conducted on six sets of 15 XML documents, generated
based on 9 DTD grammars (some of which are shown in Fig. 26),
using our XML documents generator. We varied the MaxRepeats
parameter between 5 and 10. The characteristics of the produced
document sets are summarized in Table 7. PR, R and F-value graphs
are presented in Figs. 2025. Corresponding Ave(PR), Ave(R) and
Ave(F-value) values are reported in Tables 8 and 9.

Results, w.r.t. all six data sets, underline our approachs improved global clustering quality (i.e., XML comparison quality) in
comparison with alternative approaches, when it is exploited as
a purely structural comparison method (parameter a = 1), and specifically when it is utilized as an integrated structural and semantic
similarity method (a = 0 and a = 0.5).

 When a = 1, the system only considers sub-tree structural sim-

ilarities (via Struct_CBS, cf. Fig. 9) in the comparison process.

 When a = 0, the system only considers sub-tree semantic
resemblances (via Sem_RBS, cf. Section 4.3), disregarding subtree structural similarities in the comparison process.

 When a = 0.5, the system equally consider sub-tree structural
and semantic features in the comparison process. In other
words, all kinds of sub-tree similarities, structural and semantic
(detailed in Sections 4.2 and 4.3), are detected, both Struct_CBS
andSem_RBS algorithms being executed.

In fact, our integrated structural and semantic similarity approach consistently maintains higher recall levels, in comparison
with its structural version (a = 1), N. & J., DCWS as well as Chaw-
athe. As for precision, our method tends to yield average levels that
are identical to those attained using existing comparison methods,
which is underlined in the results corresponding to sets S2, S3, S5,
and S6. In a few cases, it achieved lower precision, i.e., with sets
S1 and S4.

Nonetheless, in all six tests, average F-value results, characterizing both precision and recall levels simultaneously, underits alternatives (with
line our methods effectiveness w.r.t.

Table 7
Characteristics of synthetic XML document sets.

Doc sets

Max repeats

Grammars

No. of Docs

Average depth (per doc)

Average number of nodes (per doc)

S1
S2
S3
S4
S5
S6

Academy.dtd, College.dtd, Factory.dtd
InstA.dtd, InstB.dtd, InstC.dtd
InstK.dtd, InstL.dtd, InstM.dtd
Academy.dtd, College.dtd, Factory.dtd
InstA.dtd, InstB.dtd, InstC.dtd
InstK.dtd, InstL.dtd, InstM.dtd

Fig. 20. PR, R, and F-value graphs for clustering documents of S1.

Fig. 21. PR, R, and F-value graphs for clustering documents of S2.

Fig. 22. PR, R, and F-value graphs for clustering documents of S3.

J. Tekli, R. Chbeir / Web Semantics: Science, Services and Agents on the World Wide Web 11 (2012) 1440

Fig. 23. PR, R, and F-value graphs for clustering documents of S4.

Fig. 24. PR, R, and F-value graphs for clustering documents of S5.

Fig. 25. PR, R,and F-value graphs for clustering documents of S6

both a = 0 and a = 0.5). Note that similarly to the structural
evaluation results shown in the previous section, our integrated methods low precision levels are due to utilizing relatively similar grammars in generating the document sets: we
explicitly used grammars baring semantic sub-tree similarities.
On one hand, higher recall scores are sometimes obtained with
a = 0 (Sem_RBS being considered with a maximum unit
in comparison with the case where a = 0.5 (where
weight),
both Struct_CBS and Sem_RBS are considered with equal 0.5
weights, hence downscaling the impact of sub-tree semantic

relatedness, and thus missing certain sub-tree semantic similarities when clustering documents). On the other hand, since
existing approaches disregard semantic similarities, they tend
to distinguish documents that are in fact similar, and place
them in separated clusters. Such undetected similarities might
yield better precision levels, i.e., smaller clusters including portions of correctly clustered documents. Nonetheless, they consistently yield lower recall values (and consequently low F-
values) since lots of documents are not in the appropriate clusters where they should have been.

Table 8
Average PR, R and F-values obtained by varying the clustering threshold between [0, 1].

Chawathe

N. & J.
Our App. (a = 1)
Our approach (a = 0)
Our approach (a = 0.5)

S1

F-value

S2

Table 9
Average PR, R and F-values obtained by varying the clustering threshold between [0, 1].

Chawathe

N. & J.
Our App. (a = 1)
Our approach (a = 0)
Our approach (a = 0.5)

S4

F-value

S5

F-value

F-value

S3

S6

F-value

F-value

Fig. 26. Sample DTD grammars inducing sets of XML document.

In the experiments above, we did not compare our methods
effectiveness to TCY [73] due to the latters asymmetric nature
which is not suitable for applying our clustering algorithms. How-
ever, we considered TCY in our inter-set/intra-set evaluation
experiments.

6.5.2.2. Inter-set and intra-set average similarities experiments. In
the following, we present inter-set and intra-set average similarity
results when comparing five sets of XML documents. Each set is
made of 10 documents synthetically generated w.r.t. the DTD
grammars shown in Fig. 26, varying the MaxRepeats factor between
5 and 10.

Recall that a priori known DTD grammars (inducing predefined
document sets) serve as a reference for assessing the similarity
results [23]. Intra-set average similarities are computed between
documents of the same set Si, reported as (i, i) values in the
similarity matrix. Remaining (i, j) values correspond to intra-set
average similarities, computed between documents belonging to
sets Si and Sj. Results are shown in Tables 10 and 11.

Note that we report our methods results when parameter a = 0
(detecting sub-tree semantic resemblances) and a = 1 (detecting
sub-tree structural similarities), and omit those corresponding to
a = 0.5 (considering both sub-tree structural and semantic fea-
tures) since our aim here is to contrast our systems capability in
detecting XML semantic resemblance w.r.t. structural similarity.

J. Tekli, R. Chbeir / Web Semantics: Science, Services and Agents on the World Wide Web 11 (2012) 1440

Table 10
Average inter-set/intra-set similarities (tests conducted on 25 documents, 5 of each set, generated with MaxRepeats = 5).

S1

S2

S3

S4

S5

(a) Our approach  semantic resemblance ( = 0)

S1 (Academy.dtd)

S2 (College.dtd)
S3 (Factory.dtd)

S4 (EduInst.dtd)
S5 (Inst.dtd)

(c) TCY [73]
S1 (Academy.dtd)
S2 (College.dtd)
S3 (Factory.dtd)
S4 (EduInst.dtd)
S5 (Inst.dtd)
(e) DCWS [16]
S1 (Academy.dtd)
S2 (College.dtd)
S3 (Factory.dtd)
S4 (EduInst.dtd)
S5 (Inst.dtd)

S2

S3

S1
S4
(b) Our approach  structural similarity ( = 1)

(d) N. & J. [55]

(f) Chawathe [12]

Table 11
Average inter-set/intra-set similarities (tests conducted on 25 documents, 5 of each set, with MaxRepeats = 10).

S1

S2

S3

S4

S5

(a) Our approach  semantic resemblance ( = 0)

S1 (Academy.dtd)

S2 (College.dtd)

S3 (Factory.dtd)

S4 (EduInst.dtd)
S5 (Inst.dtd)

(c) TCY [73]
S1 (Academy.dtd)
S2 (College.dtd)
S3 (Factory.dtd)
S4 (EduInst.dtd)
S5 (Inst.dtd)

(e) DCWS [16]
S1 (Academy.dtd)
S2 (College.dtd)
S3 (Factory.dtd)
S4 (EduInst.dtd)
S5 (Inst.dtd)

S3

S2

S1
S4
(b) Our approach  structural similarity ( = 1)

(d) N & J [55]

(f) Chawathe[12]

S5

S5

First of all, results show that our method, in both sub-tree structural
and semantic facets, produces intra-set average similarity values
underlining a straight distinction between documents belonging to a
given set (i.e., conforming to a given grammar) and others outside that
set, similarly to existing XML comparison approaches.

Yet, when considering the semantics of XML sub-trees (e.g.,
with parameter a = 0), our approach captures the semantic affinities between documents of different sets:

 Tables 10a and 11a show that document sets S1 and S2 share
more semantic resemblances than sets S1 and S3, sets S1/S2
being structurally almost as similar as S1/S3 (cf. Tables 10,
11b, df).

 Tables 10a and 11a also show that document set S1 shares more
semantic meaning with set S4 than with set S5, sets S1/S4 and S1/
S5 being structurally identical when factor MaxRepeats = 5
(Tables 10, 11b, df).

Thus, as shown in the inter/intra-set similarity values, semantic
resemblances are left undetected using existing XML comparison
methods, i.e., N. & J., DCWS and Chawathe.

Note that TCY [73] is able to capture certain semantic similarities as shown in the results above. Yet, as discussed previously, it

disregards various sub-tree semantic resemblances in comparing
XML documents (cf. Section 3.2). In addition, it is asymmetric
(e.g., Sim(S1,S2)  Sim(S2,S1) as shown in the average inter-set similarity results), which is not in accordance with the formal definition of similarity (Section 4.6).

6.6. Performance evaluation

6.6.1. Verifying complexity levels

As shown in Section 4.7, our XML comparison method is of
O(jT1j 
 jT2j 
 jSNj 
 Depth(SN)) time complexity. It simplifies to
O(jT1j 
 jT2j) when semantic similarity evaluation is disregarded
(Sem_RBS is disregarded). We start by verifying our approachs
polynomial (quadratic) dependency on tree size, i.e., O(jT1j 
 jT2j).
Timing experiments were carried out on a PC with an Intel Xeon
2.66 GHz processor with 2GB RAM. As predicted, results in
Fig. 27a reflect an almost perfect linear dependency on the size
of each tree being compared.

On the other hand, when evaluating both structural and semantic
similarity (i.e, when both Struct_CBS and Sem_RBS algorithms are con-
sidered), the size of the reference semantic network, exploited while
evaluating the semantic similarity measure (e.g., Lins measure [41])
to compute pair-wise XML node label similarity, comes to play.

Fig. 27. Timing results.

Fig. 28 depict our methods time performance as a structural similarity method, disregarding semantic evaluation for fairness of
comparison. Results demonstrate that our methods time performance is closely comparable to those of its alternatives, e.g., N. &
J.
[55], DCWS [16], and Chawathe [12] (which are also of
O(jT1j 
 jT2j) time). Note that Chawathes superior performance
was expected since the algorithm was originally conceived to provide higher efficiency levels [12] (in order to allow efficient exter-
nal-memory computations, cf. Section 2.2.2), in comparison with
our study (as well as N. & J. [55] and DCWS [16]), which targets result quality (e.g., clustering effectiveness [16,55]) and higher comparison accuracy. Nonetheless, we are currently investigating
several techniques related to XML similarity and performance
enhancement, such as Prufer sequence encoding [4], B-Tree indexing [19] and Entropy [31], aiming to improve our methods performance level, without however affecting its effectiveness and result
quality.

7. Conclusion

In this paper, we propose a fine-grained similarity approach for
comparing rigorously structured XML documents. We particularly
target document structure (i.e., structure-only XML, consisting of
element/attribute tag names) and disregard content (i.e., ele-
ment/attribute values), central in structural clustering/classifica-
tion and structural querying applications. Our method combines
tree edit distance computations and information retrieval semantic
similarity assessment, so as to capture the structural and semantic
resemblances between XML documents. We particularly focus on
previously unaddressed sub-tree structural and semantic similari-
ties, allowing the user to tune the comparison process according to
her requirements and needs. Our theoretical study and experimental evaluation showed that our approach yields improved similarity results w.r.t. existing alternatives. Timing analysis underlined
the impact of semantic similarity assessment, due to traversing
the semantic network at hand.

We showed our approachs applicability in a generic Information Retrieval context (using fragments of WordNet). Apparently,
adding semantic assessment to the edit distance computation process is a good thing, provided the semantic network (i.e., knowledge base) considered is relevant w.r.t. the documents at hand
(WordNet is relevant for comparing generic XML documents representing real world data, such as those utilized in our experiments,
but might not be useful when comparing XML documents describing gene and protein sequences [1], or multimedia MPEG-7 documents [50]. . .). Achieving improved XML similarity results would
require an accurate, domain specific and complete semantic net-
work, which up till now, rarely exist. Besides, the complexity of
the semantic similarity process due to traversing the reference

Fig. 28. Time comparison with existing approaches.

To our knowledge, timing analysis for Lins measure [41] was
not carried out previously. Theoretically, it can be estimated as
O(jSNj 
 Depth(SN)) [41] due to traversing the semantic network
when searching for the lowest common ancestor between two taxonomic nodes (cf. Section 2.3.2). Thus, in order to reduce our methods overall complexity, we pre-compute semantic similarities for
each pair of nodes in the taxonomy considered (which took about
20 s for the WordNet fragment depicted in Fig. 3, and more than
5 CPU hours for a 600 node semantic network) and store the results
in a dedicated indexed table (Oracle 9i DB)20. As a result, Sem_RBS
would access the indexed table to acquire semantic values instead
of traversing the taxonomy to compute semantic similarity each
time it is needed (pair-wise similarity values are computed once,
prior to XML document comparison). Due to this process, we eliminated the impact of taxonomic depth on overall timing complexity.
Timing results in Fig. 27b show that our approach becomes linearly
dependent on the size on the taxonomy considered, complexity simplifying from O(jT1j 
 jT2j 
 jSNj 
 Depth(SN)) to O(jT1j 
 jT2j 
 jSNj).
As for space complexity, memory usage results confirm that our
approach is quadratic in the combined size of the trees being com-
pares, O(jT1j 
 jT2j), which underlines a linear dependency on the
size of each tree (memory usage graphs are similar in overall shape
to those depicted in Fig. 27, and thus are omitted for clearness of
presentation, cf. [75] for details).

6.6.2. Comparison with existing approaches

In addition to verifying the complexity levels of our approach,
we assess its overall efficiency w.r.t. its most prominent alterna-
tives, e.g., N. & J. [55], DCWS [16] and Chawathe [12]. Results in

20 Oracle uses the B-Tree indexing technique.

J. Tekli, R. Chbeir / Web Semantics: Science, Services and Agents on the World Wide Web 11 (2012) 1440

semantic network remains a major drag to performance, to be
investigated in a dedicated future study.

In addition to improving the performance levels of our method,
we are also currently investigating various optimization tech-
niques, mostly based on machine learning such as Hopfield Neural
Networks [32], Sigmoid [20], and Harmony [49], in order to enable
a (semi-automatic) fine-tuning of our XML comparison process,
giving more/less emphasis to XML structural and/or semantic
properties (by calibrating parameter a) following the nature of
the XML documents being compared. Other future directions include exploiting semantic similarity to compare, not only the
structure of XML documents (element/attribute labels), but also
their contents (values). Here, XML Schemas, underlining element/
attribute data-types, come to play. In addition, we plan to extend
our method toward XML document/grammar comparison. Few
studies have addressed the latter issue, especially from a semantic
perspective, which remains virtually uncharted territory.

Acknowledgements

We are grateful to the reviewers for their valuable comments
and suggestions which have allowed us to further improve the
manuscripts presentation, organization, and contents.

This work is funded in part by the Research Support Foundation
of the State of Sao Paulo, Brazil, FAPESP Post-doctoral Fellowship
No. 2010/00330-2.

Appendix A. Computation examples

In the following, we present two computation examples. The first
shows how our approach considers structural commonalities in comparing XML trees. The second focuses on semantic resemblances between
sub-trees. Similarity results for all XML motivation examples mentioned in Section 3 are reported and discussed subsequently.

A.1. Structural similarity evaluation

In this example, we consider the case of dummy XML document
trees A, D and Ein Fig. A.1 (reported from Fig. 4 of the main paper).
Recall that trees D and E are considered identical with respect to A
following current approaches, i.e., [12,16,55], despite the fact that
trees A/D share more structural similarities than A/E (as discussed
in Section 3.1).

In order to compare trees A/D, we start by executing algorithm
TOC which computes operations costs. Note that in this example,
parameter a is set to 1 since we only focus on XML structural com-
monalities. In fact, node labels in trees A, D and E are made of simple characters and have no semantic meanings. Thus, it would be
useless to consider Sem_RBS in this case, which would obviously
return null results.
CostUpdRA; RD 14 0; where RA: 14 RD: 14 a

CostDelTreeA1 14

CostDelx
All nodes x of A1

14 3 


1  0:75

1  Struct CBSA1; D1
14 1:7143

Fig. A.1. XML trees A, D and E reported from Fig. 4.

Likewise, CostInsTree(D1) = CostInsTree(D2) = 4 
 1
10:75 = 2.2856 Related
Struct-CBS computations are provided in Section 4.2 of the main
paper.

Thus, when applied to XML trees A and D, with a = 1, our

approach yields TED(A, D) = 3.2856 (cf. Table A.1).

 Dist[0][0] = CostUpd(R(A), R(D)) = 0, having R(A).=R(D). = a,
 Dist[1][1] = 1, cost of transforming sub-tree A1 to D1 (inserting

node h).

 TED(A, D) = Dist[1][2] = 2.2856 + Dist[1][1] = 3.2856,

inserting

sub-tree D2 into tree A.

When applied to XML trees A and E, with a = 1, our approach
yields TED(A, E) = 5 (cf. Table A.2), which amounts to the costs of:

 Inserting node h, which is of maximum unit cost (=1) sinceh

does share similarities with A,

 Inserting sub-tree E2, which is of maximum cost (=4) since E2

does not share any structural similarities with A.

 Dist[1][1] = 1, transforming sub-tree A1 into E1 (inserting node

h).

 Dist[1][2] = 4 + Dist[1][1] = 5, cost of inserting sub-tree E2 into

tree A.

Therefore, our approach is able to effectively compare XML document trees A, D and E, underlining that document trees A/D are
more similar than A/E (pointing out structural similarities that
are not detected via existing approaches):
jAjjDj 14 1  3:2836
jAjjEj 14 1  5

 SimXDocA; D 14 1  TEDA;D
 SimXDocA; E 14 1  TEDA;E

13 14 0:7474
13 14 0:6154

Similarly to the case of XML trees A, D and E, our approach detects the various kinds of XML tree structural similarities identified
in our motivation examples in Section 3.1 (results are reported in
Table 2 of the main paper).

A.2. Integrating Semantic similarity evaluation

In this computation example, we consider the case of XML trees
A0, B0 and C0 in Fig. A.2 (reported from Fig. 6 of the main paper). As
discussed in motivation Section 3.2, trees B0 and C0 are structurally
indistinguishable with respect to A0 since they have different node
labels. Yet, one can realize that A0/B0 share more semantic similarities than A0/C0 (similarities between sub-tree node labels Academy/
College, Professor/ Lecturer, and PhD Student/Scholar, as discussed
previously).

Note that in this example, parameter a is set to 0 since we focus
on sub-tree semantic resemblances. In fact, for the A0, B0, C0 case, it
is useless to consider Struct_CBS since the considered trees/sub-
trees do not share structural similarities. In other words, Struct_CBS
would yield zero values (recall that XML structure underlines the
structural disposition and ordering of element/attribute tag labels.
Hence, label disparities induce minimum structural similarity),
which led us to maximize the weight of Sem_RBS. Edit distance results are shown in Tables A.3 and A.4:

Table A.1
Computing TED between XML trees A and D.

Table A.2
Computing TED between XML trees A and E.

Related Sem_RBS computations are provided in Section 4.3 of the
main paper.

Therefore, our approach is able to efficiently compare XML documents A0, B0 and C0 underlining that documents A0/B0 are more
similar than A0/C0 (pointing out semantic similarities that are disregarded via existing approaches):
; B0

SimXDocA0

SimXDocA0

; B0 14 1  TEDA0
; C0 14 1  TEDA0

jA0j  jB0j 14 1  1:5189
jA0j  jC0j 14 1  1:9604

; C0

14 0:8619

14 0:8218

Results for all motivations examples discussed throughout the

paper are reported in Table 3 of the main manuscript.
