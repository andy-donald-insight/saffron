Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 2240

Contents lists available at SciVerse ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : h t t p : / / w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

Context-dependent views to axioms and consequences of Semantic Web ontologies
Franz Baader a, Martin Knechtel b, Rafael Penaloza a,

a Theoretical Computer Science, TU Dresden, Germany
b SAP AG, SAP Research, Center Dresden, Germany

a r t i c l e

i n f o

a b s t r a c t

Article history:
Available online 2 December 2011

Keywords:
Access restrictions
Views
Contexts
Ontologies

The framework developed in this paper can deal with scenarios where selected sub-ontologies of a large
ontology are offered as views to users, based on contexts like the access rights of a user, the trust level
required by the application, or the level of detail requested by the user. Instead of materializing a large
number of different sub-ontologies, we propose to keep just one ontology, but equip each axiom with a
label from an appropriate context lattice. The different contexts of this ontology are then also expressed
by elements of this lattice. For large-scale ontologies, certain consequences (like the subsumption hier-
archy) are often pre-computed. Instead of pre-computing these consequences for every context, our
approach computes just one label (called a boundary) for each consequence such that a comparison of
the user label with the consequence label determines whether the consequence follows from the
sub-ontology determined by the context. We describe different black-box approaches for computing
boundaries, and present first experimental results that compare the efficiency of these approaches on
large real-world ontologies. Black-box means that, rather than requiring modifications of existing reasoning procedures, these approaches can use such procedures directly as sub-procedures, which allows us to
employ existing highly-optimized reasoners. Similar to designing ontologies, the process of assigning
axiom labels is error-prone. For this reason, we also address the problem of how to repair the labelling
of an ontology in case the knowledge engineer notices that the computed boundary of a consequence
does not coincide with her intuition regarding in which context the consequence should or should not
be visible.

O 2011 Elsevier B.V. All rights reserved.

1. Introduction

Description Logics (DL) [1] are a successful family of knowledge
representation formalisms, which can be used to represent the
conceptual knowledge of an application domain in a structured
and formally well-understood way. They are employed in various
application domains, such as natural language processing, conceptual modelling in databases, and configuration of technical sys-
tems, but their most notable success so far is the adoption of the
DL-based language OWL as standard ontology language for the
Semantic Web. From the DL point of view, an ontology is a finite
set of axioms, which formalize our knowledge about the relevant
concepts of the application domain. From this explicitly described
knowledge, the reasoners implemented in DL systems can then
derive implicit consequence. Application programs or human users
interacting with the DL system thus have access not only to the
explicitly represented knowledge, but also to its logical conse-
quences. In order to provide fast access to the implicit knowledge,

 Corresponding author.

E-mail addresses: baader@tcs.inf.tu-dresden.de (F. Baader), martin.knechtel@

sap.com (M. Knechtel), penaloza@tcs.inf.tu-dresden.de (R. Penaloza).

1570-8268/$ - see front matter O 2011 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2011.11.006

certain consequences (such as the subsumption hierarchy between
named concepts) are often pre-computed by DLs systems.

In this paper, we investigate how this sort of pre-computation
can be done in an efficient way in a setting where users can access
only parts of an ontology, and should see only what follows from
these parts. To be more precise, assume that you have a large
ontology O, but you want to offer different users different views
on this ontology with respect to their context. In other words, each
user can see only a subset of the large ontology, which is defined by
the context she operates in. The context may be the level of expertise of the user, the access rights that she has been granted, or the
level of detail that is deemed to be appropriate for the current set-
ting, etc. More concretely, one could use context-dependent views
for reducing information overload by providing only the information appropriate to the experience level of a user. For example, in
a medical ontology we might want to offer one view for a patient
that has only lay knowledge, one for a general practitioner, one
for a cardiologist, one for a pulmonologist, etc. Another example
is provided by proprietary commercial ontologies, where access
is restricted according to a certain policy. The policy evaluates
the context of each user by considering the assigned user roles,
and then decides whether some axioms and the implicit

consequences that can be derived from them are available to this
user or not.

One naive approach towards dealing with such contextdependent views of ontologies would be to materialize a separate
sub-ontology of the overall large ontology for each possible user
context. However, this could potentially lead to an exponential
number of ontologies having to be maintained, if we define one user
context for each subset of the original ontology. This would imply
that any update in the overall ontology needs to be propagated to
each of the sub-ontologies, and any change in the context model,
such as a new user role hierarchy or a new permission for a user role,
may require removing or adding such subsets. Even worse, for each
of these sub-ontologies, the relevant implicit consequences would
need to be pre-computed and stored separately. To avoid these prob-
lems, we propose a different solution in this paper. The idea is to
keep just the large ontology O, but assign labels to all axioms in
the ontology and to all users in such a way that an appropriate comparison of the axiom label with the user label determines whether
the axiom belongs to the sub-ontology for this user or not. This comparison will be computationally cheap and can be efficiently implemented with an index structure to look up all axioms with a given
label. To be more precise, we use a set of labels L together with a partial order 6 on L and assume that every axiom a 2 O has an assigned
label laba 2 L.1 The labels  2 L are also used to define user contexts
(which can be interpreted as access rights, required level of granular-
ity, etc.). The sub-ontology accessible for the context with label  2 L is
defined to be
OP :14 fa 2 Ojlaba P g:

Clearly, the user of a DL-based ontology is not only able to
access its axioms, but also the consequences of these axioms. That
is, a user whose context has label  should also be allowed to see all
the consequences of OP.

As mentioned already, certain consequences are usually precomputed by DL systems in order to avoid expensive reasoning
during the deployment phase of the ontology. For example, in
the version of the large medical ontology SNOMED2 that is distributed
to hospitals and doctors, all the subsumption relationships between
the concept names occurring in the ontology are pre-computed. For
a labelled ontology as introduced above, pre-computing that a certain consequence c follows from the whole ontology O is not suffi-
cient. In fact, a user whose context has label  should only be able
to see the consequences of OP, and since OP may be smaller than
O, the consequence c of O may not be a consequence of OP. As said
above, pre-computing consequences for all possible user labels is not
a good idea since then one might have to compute and store consequences for exponentially many different subsets of O. Our solution
to this problem is to compute a so-called boundary for the consequence c, i.e., an element m of L such that c follows from OP iff
 6 m. Thus, instead of pre-computing whether this consequence
is valid for every possible sub-ontology, our approach computes just
one label for each consequence such that a simple comparison of the
context label with the consequence label determines whether the
consequence follows from the corresponding sub-ontology or not.

There are two main approaches for computing a boundary. The
glass-box approach takes a specific reasoner (or reasoning tech-
nique) for an ontology language and modifies it such that it can
compute a boundary. Examples for the application of the glassbox approach to specific instances of the problem of computing a
boundary are tableau-based approaches for reasoning in possibilistic Description Logics [2,3] (where the lattice is the interval [0,1]
with the usual order), glass-box approaches to axiom pinpointing

1 We will in fact impose the stronger restriction that L; 6 defines a lattice (see
Section 2).

2 http://www.ihtsdo.org/snomed-ct/.

in Description Logics [48] (where the lattice consists of (equiva-
lence classes of) monotone Boolean formulae with implication as
order [8]), and RDFS reasoning over labelled triples with modified
inference rules for access control and provenance tracking [9,10].
The problem with glass-box approaches is that they have to be
developed and implemented for every ontology language and reasoning approach anew and optimizations of the original reasoning
approach do not always apply to the modified reasoners.

In contrast, the black-box approach can re-use existing optimized reasoners without modifications, and it can be applied to
arbitrary ontology languages: one just needs to plug in a reasoner
for this language. In this paper, we introduce three different blackbox approaches for computing a boundary. The first approach uses
an axiom pinpointing algorithm as black-box reasoner, whereas
the second one modifies the Hitting-Set-Tree-based black-box
approach to axiom pinpointing [11,12]. The third uses binary
search and can only be applied if the context lattice is a linear
order. It can be seen as a generalization of the black-box approach
to reasoning in possibilistic Description Logics described in [13].

Of course, the boundary computation only yields the correct
results if the axiom labels have been assigned in a correct way.
Unfortunately, just like creating ontology axioms, appropriately
equipping these axioms with context labels is an error-prone task.
For instance, in an access control application, several axioms that in
isolation may seem innocuous could, together, be used to derive a
consequence that a certain user is not supposed to see. If the knowledge engineer detects that a consequence c has an inappropriate
boundary, and thus allows access to the consequence by users that
should not see it, then she may want to modify the axiom labelling
in such a way that the boundary of c is updated to the desired label.
This problem is very closely related to the problem of repairing an
ontology. Indeed, to correct the boundary of a consequence, one
needs to be able to detect the axioms that are responsible for it,
since only their labels have an influence on this boundary. In a
large-scale ontology, this task needs to be automated, as analysing
hundreds of thousands of axioms by hand is not feasible.

To provide for such an automated label repair mechanism, we
develop a black-box method for computing minimal sets of axioms
that, when relabelled, yield the desired boundary for c; we call
these minimal change sets. The main idea of this method is again
based on the HST algorithms that have been developed for
axiom-pinpointing. However, we show that the original labelling
function can be exploited to decrease the search space. This algorithm can be used to output all minimal change sets. The knowledge engineer can then choose which of them to use for the
relabelling, depending on different criteria. Unfortunately, just as
in axiom-pinpointing, there may be exponentially many such minimal change sets, and thus analysing them all by hand may not be
possible. We thus also develop an algorithm that computes only
one change set having the smallest cardinality. This choice is motivated by a desire to make as few changes in the original labelled
ontology as possible during the repair. We show that, in this case,
a cardinality limit can be used to further optimize the algorithm.
All the algorithms described in this paper have been implemented and tested over large-scale ontologies from real-life appli-
cations, and using a context lattice motivated by an access control
application scenario. Our experimental results show that our
methods perform well in practice.

This paper extends and improves the results previously published in [14,15]. More precisely, the algorithms for computing
the boundaries of consequences were presented in [14], while
the problem of repairing the boundaries was addressed in [15].
Here, we (i) provide full proofs for all the theoretical results pre-
sented, (ii) present better optimizations to our algorithms, and
(iii) provide a thorough comparison of the different algorithmic
approaches through our experimental results. In order to make

F. Baader et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 2240

the paper accessible also for practitioners who want to apply the
general framework, but are not interested in the full formal details
and proofs, we use a running example that should provide enough
details to understand the main ideas underlying our approach.

2. Preliminaries

To stay as general as possible, we do not fix a specific ontology
language. We just assume that we have one such ontology language
determining which finite sets of axioms are admissible as ontologies,
such that every subset of an ontology is itself an ontology. If O0 is a
subset of the ontology O, then O0 is called a sub-ontology of O. Con-
sider, for instance, a Description Logic L (e.g., the DL SROIQ(D)
underlying the OWL 2 web ontology language). Then an ontology
is a finite set of general concept inclusion axioms (GCIs) of the form
C v D, with C; D L-concept descriptions, and assertional axioms of
the form Ca and ra; b, with C an L-concept description, a; b individual names, and r a role name. For a fixed ontology language, a
monotone consequence relation  is a binary relation between ontologies O of this language and consequences c such that, for every
# O and O0  c, then O  c. Examples
ontology O, it holds that if O0
of consequences in SROIQ(D) are subsumption relations A v B
for concept names A; B or assertions Ca. Note that we can abstract
from the details of the ontology language and the consequence relation since we intend to use a black-box approach, i.e., all we need is
that there is an algorithm that, given an ontology O and a consequence c, is able to deduce whether O  c holds or not.

If O  c, we may be interested in finding the axioms responsible
for this fact. Axiom-pinpointing is the task of finding the minimal
sub-ontologies that entail a given consequence (MinAs), or dually,
the minimal sets of axioms that need to be removed or repaired to
avoid deriving the consequence (diagnoses).

Definition 2.1 (MinA, diagnosis). A sub-ontology S # O is called a
MinA for O; c, if S  c and for every S0  S, it holds that S0 c.3

A diagnosis for O; c is a sub-ontology S # O such that O n S c and

O n S0  c for all S0  S.

The sets of MinAs and diagnoses are dual in the sense that from
the set of all MinAs, it is possible to compute the set of all diagno-
ses, and vice versa, through a Hitting Set computation [4].

restrictions, which is part of

As a running example, we will use the following scenario of
access
the research project
THESEUS/PROCESSUS [16]. Within this project, semantically annotated documents describe Web services offered and sold on a marketplace in the Web, like traditional goods are sold on Amazon,
eBay, and similar Web marketplaces. Different types of users are
involved with different permissions that allow them to create,
advertise, sell, buy, etc. the services. Access is restricted not only
to individual documents but also to a large ontology containing
all the semantic annotations at one place.

Example 2.2. Consider an ontology O from a marketplace in the
Semantic Web representing knowledge about the Ecological Value
Calculator service (ecoCalc), EU Ecological Services (EUecoS), High
Performance Services (HPerfS), services with few customers (SFew-
Cust), services generating low profit (LowProfitS), and services with
a price increase (SPrIncr) having the following axioms:

EUecoS u HPerfSecoCalc:

a1 :
a2 : HPerfS v SFewCust u LowProfitS:
EUecoS v SFewCust u LowProfitS:
a3 :
SFewCust v SPrIncr:
a4 :
LowProfitS v SPrIncr
a5 :

3 MinAs are sometimes also called justifications, e.g., in [6,11].

Fig. 1. A lattice with four contexts and five axioms assigned to it.

The assertion SPrIncr(ecoCalc) is a consequence of O that follows
from each of the MinAs fa1; a2; a4g, fa1; a2; a5g, fa1; a3; a4g, and
fa1; a3; a5g, and has three diagnoses, namely fa1g;fa2; a3g, and
fa4; a5g.
As mentioned before, our axiom labels come from an appropriate lattice. A lattice (L;) is a set L together with a partial order 6
on L such that a finite subset S # L always has a join (least upper
bound) S and a meet (greatest lower bound) 
S [17]. The lattice
(L;) is distributive if the join and meet operators distribute over
each other. Another lattice-theoretic notion that will be important
for the rest of the paper is that of join-prime elements.

Definition 2.3 (Join prime). Let L; 6 be a lattice. Given a finite set
K # L, let K
 :14 f
2MjM # Kg denote the closure of K under the
meet operator. An element  2 L is called join prime relative to K if,
for every K0 # K
,  6 k2K0 k implies that there is an k0 2 K0 such
that  6 k0.

i 3.

For instance, the lattice L; 6 depicted in Fig. 1 has four join
prime elements relative to L, namely 0; 2; 3, and 5. The element
4 is not join prime relative to L since 4 6 4 14 5  3, but

i 5 and 4
We now explain how lattices can be used to encode contexts,
and solve reasoning problems relative to them. From our running
example, we want to produce an access control system that regulates the allowed permissions for each user according to her user
role. Our example focuses on reading access only. A common representation of user roles and their permissions to access objects is
the access control matrix [18]. Using methods from Formal Concept Analysis, as presented in [19], a lattice representation of the
access control matrix can be obtained. In fact, the lattice depicted
in Fig. 1 was derived in this way.

In the general setting, we will use elements of the lattice L; 6
to define different contexts or views of an ontology. Depending on
the application in hand, these contexts can have different mean-
ings, such as access rights, level of expertise, trustworthiness, etc.
Given an ontology O, every axiom a 2 O is assigned a label
laba 2 L, which intuitively expresses the contexts from which
the axiom a can be accessed. An ontology extended with such a
labelling function lab will be called a labelled ontology. We will
use the expression Llab to denote the set of all labels occurring in
the labelled ontology O; that is, L lab :14 flabaja 2 Og. Each element  2 L then defines the context sub-ontology4
OP :14 fa 2 Ojlaba P g:

Conversely, every sub-ontology S # O defines an element kS 2 L,

called the label of S, given by kS :14 
a2Slaba.

Some simple relationships between ontologies and their labels

are stated in the following lemma.

4 To define this sub-ontology, an arbitrary partial order would suffice. However, the
existence of suprema and infima will be important for the computation of a boundary
of a consequence (see Section 4).

Lemma 2.4. Let L; 6 be a lattice, O an ontology, and lab : O ! L.
For every  2 L and S # O, it holds that

1.  6 kOP ,
2. S # OPkS , and
3. OP 14 OPkOP

Proof. For the first statement, by definition  6 laba holds for all
a 2 OP. Thus,  6 
a2OP laba 14 kOP . Regarding the second claim,
for every a 2 S it holds that kS 14 
s2Slabs 6 laba, which implies
that a 2 OPkS . Now, consider the last claim. First, as  6 kOP , it
holds trivially that OPkOP
# OP. From the second claim it also follows that OP # OPkOP

. h

Example 2.5. Let (L;) be the lattice shown in Fig. 1, where elements 0; 2; 3; 5 represent the different kinds of users (that is,
contexts) that have access to an ontology. Let lab be the labelling
function assigning to each axiom ai of the ontology O from Example
2.2 the label i, as depicted also in Fig. 1. The label 3 defines the
context of a development engineer for which the sub-ontology
OP3 14 fa1; a2; a3; a4g, along with all its consequences, is visible.

Notice that labels that are lower in the lattice define larger context sub-ontologies. In other words, a user assigned to a context
sub-ontology lower in the lattice will have access to more axioms
(and thus, consequences) than a user belonging to a context above
her.

3. Pre-computing context-dependent implicit knowledge

Just as every axiom is accessible only for certain contexts, a consequence of the ontology will only be derivable in those contexts
that have access to enough axioms to deduce it. We are interested
in computing adequate labels (called boundaries) for such implicit
consequences, which express, just as the labels of the axioms, which
contexts are capable of deducing them from their visible axioms.
Notice that, if a consequence c follows from OP for some  2 L,
it must also follow from OP0 for every 0 6 , since then OP # OP0 .
A maximal element of L that still entails the consequence will be
called a margin for this consequence.

Definition 3.1 (Margin). Let c be a consequence that follows from
the ontology O. The label l 2 L is called a O; c-margin if OPl  c,
and for every  with l <  we have OP

c.

If O and c are clear from the context, we usually ignore the prefix O; c and call l simply a margin. The following lemma shows
three basic properties of the set of margins, which will be useful
throughout this paper.

Lemma 3.2. Let c be a consequence that follows from the ontology O.
We have:

1. If l is a margin, then l 14 kOPl ;
2. if OP  c, then there is a margin l such that  6 l;
3. there are at most 2jO j margins for c.

Proof. To show 1, let l 2 L. Lemma 2.4 yields l 6 kOPl and
OPl 14 OPkOPl
, and thus OPkOPl  c. If l < kOPl , then this kOPl contradicts our assumption that l is a margin; hence l 14 kOPl . Point
3 is a trivial consequence of 1: since every margin has to be of
the form kS for some S # O, there are at most as many margins as
there are subsets of O.
For the remaining point, let  2 L be such that OP  c. Let
m :14 kOP . From Lemma 2.4, it follows that  6 m and OPm 14 OP,

and hence OPm  c. If m is a margin, then the result holds; suppose
to the contrary that m is not a margin. Then, there must exist an
1; m < 1, such that OP1  c. As m 14 kOPm , there must exist an
axiom a 2O such that m 6 laba, but 1
i laba. In fact, if
m 6 laba ) 1 6 laba would hold for
then
m 14 kOP 14 kOPm 14 
laba P mlaba P 1, contradicting our choice
of 1. The existence of this axiom a implies that OP1  OPm. Let
m1 :14 kOP1
; then m < 1 6 m1. If m1 is not a margin, then we can
repeat the same process to obtain a new m2 with m < m1 < m2 and
OPm  OPm1  OPm2 , and so on. As O is finite, there exists a finite k
where this process stops, and hence mk is a margin. h

a 2 O,

all

If we know that l is a margin for the consequence c, then we
know whether c follows from OP for all  2 L that are comparable
with l: if  6 l, then c follows from OP, and if  > l, then c does
not follow from OP. However, this gives us no information regarding elements that are incomparable with l. In order to obtain a full
picture of when the consequence c follows from OP for an arbitrary element  of L, we can try to strengthen the notion of margin
to that of an element m of L that accurately divides the lattice into
those elements whose associated sub-ontology entails c and those
for which this is not the case, i.e., m should satisfy the following: for
every  2 L, OP  c iff  6 m. Unfortunately, such an element need
not always exist, as demonstrated by the following example.

Example 3.3. Consider the lattice L; 6 depicted in Fig. 1 and let O0
be an ontology consisting of axioms b1 and b2, labelled with 4 and
2, respectively. Let now c be a consequence such that, for every
S # O0, we have S  c iff jSj P 1. It is easy to see that there is no
element m 2 L that satisfies the condition described above. Indeed,
if we choose m 2 f0; 3; 4; 5g, then 2 violates the condition, as
P2 14 fb2g  c. Similarly, if we choose m 14 2, then 1

violates the condition. Finally, if m 14 1 is chosen, then 1 itself
violates the condition: 1 6 m, but O0

i m, but 0

P1 14 ; c.

It is nonetheless possible to find an element that satisfies a
restricted version of the condition, where we do not impose that
the property (i.e., OP  c iff  6 m) must hold for every element
of the context lattice, but only for those elements that are join
prime relative to the labels of the axioms in the ontology.

Definition 3.4 (Boundary). Let O be an ontology and c a conse-
quence. An element m 2 L is called a (O; c)-boundary if for every
element  2 L that is join prime relative to Llab it holds that  6 m iff
OP  c.

As with margins, if O and c are clear from the context, we will
simply call such a m a boundary. When it is clear that the computed
boundary and no assigned label is meant, we also often call it consequence label. In Example 3.3, the element 1 is a boundary.
Indeed, every join prime element  relative to f4; 2g (i.e., every
element of L except for 1) is such that  < 1 and O0

P  c.

From a practical point of view, our definition of a boundary has
the following implication: we must enforce that contexts are
always defined through labels that are join prime relative to the
set Llab of all labels occurring in the ontology. In Example 2.5, all
the elements of the context lattice except 1 and 4 are join prime
relative to Llab and for this reason 0; 2; 3; 5 are all valid context
labels and can thus be used to represent user roles as illustrated.
Given a context label u, we will say that a consequence c is in
the context if u 6 m for some boundary m.

Notice however that the boundary is not guaranteed to be

unique, as shown in the following example.

Example 3.5. Consider the lattice L obtained from the lattice in
Fig. 1 by removing the element 4 and keeping the order relation
unchanged. Let now O 14 fa1; a2g and c be such that S  c iff a1 2 S.

F. Baader et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 2240

If we set laba1 14 3; laba2 14 5, it then follows that (i) 0; 3; 5
are all join-prime elements relative to Llab, and (ii) OP  c iff
 6 3. But notice that 3 6 2 and 5
i 2; thus, 2 and 3 are both
(O; c)-boundaries.

Before formally describing how to compute (Section 4) and correct (Section 5) boundaries for consequences of an ontology, we
briefly describe what are the requirements and benefits of our
method from a knowledge engineering point of view.

As a prerequisite, we assume that the context lattice L is known,
and that every axiom of the ontology is labelled with an element of L
expressing the set of contexts that have access to it. To obtain this
lattice and labeling, the knowledge engineer can first build a context
matrix relating every relevant context to the sub-ontology that it can
access. The knowledge engineer only needs to tag every axiom
with the corresponding contexts; tagging elements is already a common task in Web 2.0 applications, and no further effort is required
from our framework. Formal Concept Analysis [20] can then be used
to obtain a lattice representation of this matrix, together with a
labelling function. This labelling function is ensured to be the least
restrictive possible satisfying all the restrictions specified by the
knowledge engineer in the context matrix. Indeed, the context lattice depicted in Fig. 1 was derived in this way [19].

Given a labelled ontology, computing a boundary corresponds
to reasoning with respect to all contexts simultaneously, modulo
an inexpensive label comparison: given a boundary m for a consequence c, every context below m in the lattice can derive c, while
all others cannot.

Boundaries also simplify the work of verifying the correctness
of the labelling function, since the knowledge engineer needs only
compare the boundary of implicit consequences with the set of
contexts that should access them, rather than analysing every context independently. If a consequence has an undesired boundary,
then our method provides suggestions for correcting it, while keeping the changes in the labelling function to the minimum. In the
same manner, our approach is helpful for the maintenance of
labelled ontologies.

4. Computing a boundary

We now focus on the problem of computing a boundary. We
first present an algorithm based on axiom-pinpointing, which
introduces the main ideas for the computation of a boundary.
We then improve on these ideas by taking the labels of the axioms
into account during the computation. Finally, we show that, if the
lattice is a total order, then a modification of binary search can be
used to compute a boundary. All these algorithms are based on the
following lemma.
Lemma 4.1. Let l1; . . . ; ln be all (O; c)-margins. Then n
boundary for O,c.

i141li is a

Proof. Let  2 L be join prime relative to Llab. We need to show that
 6 n
i141li iff OP  c. Assume first that OP  c. Then, from 2 of
Lemma 3.2, it follows that there is a margin lj such that  6 lj,
and thus  6 n
i141li. From 1 of Lemma 3.2, it follows that
li 2 Llab
 for every i; 1 6 i 6 n. As  is join prime relative to Llab,
it then holds that there is a j such that  6 lj and hence, by the
definition of a margin and the monotonicity of the consequence
relation, OP  c. h

Conversely, let  6 n

i141li.

By Lemma 3.2, a consequence always has finitely many margins,
and thus Lemma 4.1 shows that a boundary always exists. As shown
in Example 3.5, a consequence may have boundaries different from
the one of Lemma 4.1. To identify the particular boundary of Lemma

4.1, we will call it the margin-based boundary. For the rest of this
section, we will focus on computing this boundary.

4.1. Using full axiom pinpointing

From Lemma 4.1 we know that the set of all margins yields sufficient information for computing a boundary. The question is thus
how to compute this set. We now show that every margin can be
obtained from some MinA.

Lemma 4.2. For every margin l for c there is a MinA S such that
l 14 kS.

Proof. If l is a margin, then OPl  c by definition. Thus, there
exists a MinA S # OPl. Since l 6 laba for every a 2 OPl, this in
particular holds also for every axiom in S, and hence l 6 kS. Addi-
tionally, as S # OPkS , we have OPkS  c. This implies l 14 kS since
otherwise l < kS, and then l would not be a margin. h

two of

the

Notice that this lemma does not imply that the label of any
MinA S corresponds to a margin. Indeed, for the ontology and consequence of Example 2.5,
are
fa1; a2; a5g;fa1; a2; a4g whose labels are 0 and 3, respectively,
and hence the label of the former cannot be a margin (since
0 < 3). However, as the consequence follows from every MinA S,
Point 2 of Lemma 3.2 shows that kS 6 l for some margin l. The
following theorem is an immediate consequence of this fact
together with Lemmas 4.1 and 4.2.

four MinAs

Theorem 4.3. If S1; . . . ; Sn are all MinAs for O andc, then n
margin-based boundary for c.

i141kSi is the

Example 4.4. We continue Example 2.5 where each axiom ai is
labelled with labai 14 i. We are interested in the boundary for
the consequence SPrIncrecoCalc, which has the MinAs fa1; a2; a4g;
fa1; a2; a5g;fa1; a3; a4g, and fa1; a3; a5g. From Theorem 4.3, it follows
that the margin-based boundary for c is 3  0  3  0 14 3. This in
particular shows that only the contexts of development engineers
and customer service employees, defined through the labels 3 and
0, respectively, can derive the consequence.

According to the above theorem, to compute a boundary, it is
sufficient to compute all MinAs. Several methods exist for computing the set of all MinAs, either directly [4,11,21] or through a socalled pinpointing formula [22,8,7], which is a monotone Boolean
formula encoding all the MinAs. The main advantage of using the
pinpointing-based approach for computing a boundary is that
one can simply use existing implementations for computing all
MinAs, such as the ones offered by the ontology editor Protege 45
and the CEL system.6 However, since not all MinAs may really contribute to computing the boundary, first computing all MinAs may
require extensive superfluous work.

4.2. Using label-optimized axiom pinpointing

From Lemma 4.2 we know that every margin is of the form kS
for some MinA S. In the previous subsection we have used this fact
to compute a boundary by first obtaining the MinAs and then computing their labels. However, this idea ignores that the relevant
part of the computation of a boundary are the labels of the MinAs,
rather than the MinAs per se. This process can be optimized if we
directly compute the labels of the MinAs, without necessarily computing the actual MinAs. Additionally, it is not necessary to com-

5 http://protege.stanford.edu/.
6 http://code.google.com/p/cel/.

pute the label of every MinA, but only of those that correspond to
margins, that is, those that are maximal w.r.t. the lattice ordering
6. For instance, in Example 4.4, we could avoid computing the
two MinAs that have label 0.

We present here a black-box algorithm that uses the labels of
the axioms to find the boundary in an optimized way. Our algorithm is a variant of the Hitting-Set-Tree-based [23] method (HST
approach) for axiom pinpointing [11,12]. First, we briefly describe
the HST approach for computing all MinAs, which will serve as a
starting point for our modified version.

The HST-based method for axiom pinpointing computes one
MinA at a time while building a tree that expresses the distinct
possibilities to be explored in the search of further MinAs. It first
computes an arbitrary MinA S0 for O, which is used to label the root
of the tree. Then, for every axiom a in S0, a successor node is cre-
ated. If O n fag does not entail the consequence, then this node is
a dead end. Otherwise, O n fag still entails the consequence. In this
case, a MinA S1 for O n fag is computed and used to label the node.
The MinA S1 for O n fag obtained this way is also a MinA of O, and it
is guaranteed to be distinct from S0 since a R inS1. Then, for each
axiom a0 in S1, a new successor is created, and treated in the same
way as the successors of the root node, i.e., it is checked whether
O n fa; a0g still has the consequence, etc. This process obviously terminates since O is a finite set of axioms, and the end result is a tree,
where each node that is not a dead end is labelled with a MinA, and
every existing MinA appears as the label of at least one node of the
tree (see [11,12] for further details).

An important ingredient of the HST algorithm is a procedure
that computes a single MinA from an ontology. Such a procedure
can, e.g., be obtained by going through the axioms of the ontology
in an arbitrary order, and removing redundant axioms, i.e., ones
such that the ontology obtained by removing this axiom from
the current sub-ontology still entails the consequence (see [21]
for a description of this and of a more sophisticated logarithmic
procedure for computing one MinA).

We will use this same idea as a basis for computing the marginbased boundary for a consequence. As said before, we are now not
interested in actually computing a MinA, but only its label. This
allows us to remove all axioms having a redundant label rather
than a single axiom. Algorithm 1 describes a black-box method
for computing the label of some MinA S based on this idea. More
precisely, the algorithm does not compute a single label, but rather
a MinLab of a MinA S.

return no MinA

Algorithm 1. Compute a MinLab of one MinA
Procedure min-lab(O; c)
Input: O: ontology; c: consequence
Output: ML # L: a MinLab
1: if O c then
2:
3: S :14 O
4: ML :14 ;
5: for every k 2 Llab do
if 
l2ML l i k then
6:
if Sk  c then
7:
8:
9:
10:
11: return ML

S :14 Sk
ML :14 ML n fljk < lg [ fkg

else

Definition 4.5 (Minimal label set). Let S be a MinA for c. A set
K #flabaja 2 Sg is called a MinLab of S if the elements of K are
pairwise incomparable and kS 14 
2K .

at

the

Line

denotes

Algorithm 1 removes all the labels that do not contribute to a
MinLab. If O is an ontology and  2 L, then the expression O
sub-ontology O :14
appearing
fa 2 Ojlabag. If, after removing all the axioms labelled with k,
the consequence still follows, then there is a MinA none of whose
axioms is labelled with k. In particular, this MinA has a MinLab not
containing k; thus, all the axioms labelled with k can be removed in
our search for a MinLab. If the axioms labelled with k cannot be
removed, then all MinAs of the current sub-ontology need an
axiom labelled with k, and hence k is stored in the set ML. This
set is also used to avoid useless consequence tests: if a label is
greater than or equal to 
2ML , then the presence or absence of
axioms with this label will not influence the final result, which will
be given by the infimum of ML; hence, there is no need to apply
the (possibly complex) decision procedure for the consequence
relation (Line 6).

Theorem 4.6. Let O and c be such that O  c. There is a MinA S0 for c
such that Algorithm 1 outputs a MinLab of S0.

Proof. As O  c, the algorithm will enter the for loop. This loop
keeps the following two invariants: (i) S  c and (ii) for every
 2 ML; S
c. The invariant (i) is ensured by the condition in Line
7 that must be satisfied before S is modified. Otherwise, that is, if
c, then  is added to ML (Line 10) which, together with the fact

that S is always modified to a smaller set (Line 8), ensures (ii).
Hence, when the loop finishes, the sets S and ML satisfy both
invariants. As S  c, there is a MinA S0 # S for c. For each  2 ML,
there must be an axiom a 2 S0 such that laba 14 , otherwise,
S0 # S and hence S  c, which contradicts invariant (ii); thus,
ML #flabaja 2 S0g and in particular kS0
It remains to show that the inequality in the other direction
holds as well. Consider now k 2 flabaja 2 Sg and let Mk
L be the
value of M when the for loop was entered with value k. We have
that 
2ML  6 
2Mk
 i k, and
thus it fulfills the test in Line 6, and continues to Line 7. If that test
is satisfied, then all the axioms with label k are removed from S,
contradicting the assumption that k 14 laba for some a 2 S.
Otherwise, k is added to ML, which contradicts the assumption
that 
2ML  i k. Thus, for every axiom a in S, 
2ML  6 laba;
hence 
2ML  6 kS 6 kS0 . h

. If 
2ML  i k, then also 
2Mk

2ML .

Once the label of a MinA has been found, we can compute new
MinLabs by a successive deletion of axioms from the ontology
using the HST approach. Suppose that we have computed a MinLab M0, and that  2 M0. If we remove all the axioms in the
ontology labelled with , and compute a new MinLab M1 of a
MinA of this sub-ontology, then M1 does not contain , and thus
M0
 M1. By iterating this procedure, we could compute all Min-
Lab, and hence the labels of all MinAs. However, since our goal is
to compute the supremum of these labels, the algorithm can be
further optimized by avoiding the computation of those MinAs
whose labels will have no impact on the final result. Based on this
we can actually do better than just removing the axioms with label : instead, all axioms with labels 6  can be removed. For an
element  2 L and an ontology O, Oi denotes the sub-ontology
obtained from O by removing all axioms whose labels are 6 .
Now, assume that we have computed the MinLab M0, and that
M1
 M0 is the MinLab of the MinA S1. For all  2 M0, if S1 is
not contained in Oi, then S1 contains an axiom with label 6 .
Consequently, 
m2M1 m 14 kS1

m2M0 m, and thus M1 need not
be computed. Algorithm 2 describes our method for computing
the boundary using a variant of the HST algorithm that is based
on this idea.

F. Baader et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 2240

Algorithm 2. Compute a boundary by a HST algorithm
Procedure HST-boundary (O; c)
Input: O: ontology; c: consequence
Output:boundary m for c
Global : C; H :14 ;; m
1:
2: M :14 minlabO; c
3:
4:
5:
6:
7:
Procedure expand-HSTO; c; H
Input: O: ontology; c: consequence; H: list of lattice elements
Side effects: modifies C, H, m
1:

C :14 fMg
m :14 
2M
for each label  2 M do

expand  HSTOi; c;fg

return m

(early path termination 

if there exists some H0 2 H such that fh 2 H0jh i mg # H
or H0 contains a prefix-path P with fh 2 Pjh i mg 14 H
then
return
if there exists M 2 C such that for all  2 M; h 2 H;  i h
and  i m
4: M0 :14 M
5:
6:
7:
8:
9:
10:
11:
12: else
13:

ifOim  c then
C :14 C [ fM0g
m :14 fm;
2M0 g
foreach label  2 M0 do

expand  HSTOi; ;H [ fg

M0 :14 min labOim; c

H :14 H [ fHg

(normal termination )

2:
3:

(MinLab reuse)

else

In the procedure HST-boundary, three global variables are
declared: C, H (initialized with ;), and m. The variable C stores all
the MinLab computed so far, while each element of H is a set of
labels such that, when all the axioms with a label less than or equal
to any label from the set are removed from the ontology, the consequence does not follow anymore; the variable m stores the supremum of the labels of all the elements in C and ultimately
corresponds to the boundary that the method computes. The algorithm starts by computing a first MinLab M, which is used to label
the root of a tree. For each element of M, a branch is created by
calling the procedure expand-HST.

The procedure expand-HST implements the ideas of HST construction for computing all MinAs [11,12] with additional optimizations that help reduce the search space as well as the number
of calls to min-lab. First notice that each M 2 C is a MinLab, and
hence the infimum of its elements corresponds to the label of some
MinA for c. Thus, m is the supremum of the labels of a set of MinAs
for c. If this is not yet the boundary, then there must exist another
MinA S whose label is not less than or equal to m. This in particular
means that no element of S may have a label less than or equal to m,
as the label of S is the infimum of the labels of the axioms in it.
When searching for this new MinA we can then exclude all axioms
having a label 6 m, as done in Line 6 of expand-HST. Every time we
expand a node, we extend the set H, which stores the labels that
have been removed on the path in the tree to reach the current
node. If we reach normal termination, it means that the consequence does not follow anymore from the reduced ontology. Thus,
any H stored in H is such that, if all the axioms having a label less
than or equal to an element in H are removed from O, then c does
not follow anymore. Lines 1 4 of expand-HST are used to reduce
the number of calls to the subroutine min-lab and the total search
space. We describe them now in more detail.

The first optimization, early path termination, prunes the tree
once we know that no new information can be obtained from further expansion. There are two conditions that trigger this optimi-
zation. The first one tries to decide whether Oim  c without
executing the decision procedure. As said before, we know that
for each H0 2 H, if all labels less than or equal to any in H0 are re-
moved, then the consequence does not follow. Hence, if the current
list of removal labels H contains a set H0 2 H we know that enough
labels have been removed to make sure that the consequence does
not follow. It is actually enough to test whether fh 2 H0jh i mg # H
since the consequence test we need to perform is whether
Oim  c. The second condition for early path termination asks
for a prefix-path P of H0 such that P 14 H. If we consider H0 as a list
of elements, then a prefix-path is obtained by removing a final portion of this list. The idea is that, if at some point we have noticed
that we have removed the same axioms as in a previous branch
of the search, we know that all possibilities that arise from that
search have already been tested before, and hence it is unnecessary
to repeat the work. The tree can then be pruned at this node. As an
example, consider a subtree reachable from the root by going along
the edges 1; 2 which has been expanded completely. Then all
Hitting Sets of its leaf nodes share the common prefix-path
P 14 f1; 2g. Now suppose the tree is expanded by expand-
HSTO; c; H with H 14 f2; 1g. The expansion stops with early termination since P 14 H.

The second optimization avoids a possibly expensive call to minlab by reusing a previously computed minimal label set. Notice that
our only requirement on min-lab is that it produces a MinLab.
Hence, any MinLab for the ontology obtained after removing all
labels less than or equal to any h 2 H or to m would work. The Min-
Lab-reuse optimization checks whether there is such a previously
computed MinLab. If this is the case, the algorithm uses this set
instead of computing a new one by calling min-lab. If we left out
the prefix-path condition for early termination, the MinLab reuse
condition would still hold. That means leaving out the prefix-path
condition leads to no more min-lab calls but leads to copying several branches in the tree without obtaining new information.

Before showing that the algorithm is correct, we illustrate its

execution through a small example.

continue Example 4.4 with the

Example 4.7. We
same
consequence SPrIncrecoCalc. Fig. 2 shows a possible run of the
HST-boundary algorithm. The algorithm first calls the routine min-
lab(O; c). Consider that the for loop of min-lab is executed using the
labels in the order 1; 2; 4; 3; 5 since Line 5 requires no specific
order. Thus, we try first to remove a1 labelled with 1. We see that
c; hence a1 is not removed from O, and ML is updated to
O1
ML 14 f1g. We then see that O2  c, and thus a2 is removed from
O. Again, O4  c, so a4 is removed from O. At this point,
O 14 fa1; a3; a5g. We test then whether O3  c and receive a
negative answer; thus, 3 is added to ML; additionally, since
3 < 1, the latter is removed from ML. Finally, O5
c, and so we
obtain ML 14 f3; 5g as an output of min-lab.

Fig. 2. An expansion of the HST method.

The MinLab f3; 5g, is used as the root node n0, setting the value
of m 14 3 
 5 14 0. We then create the first branch on the left by
removing all the axioms with a label 6 3, which is only a3, and
computing a new MinLab. Assume, for the sake of the example, that
min-lab returns the MinLab f2; 4g, and m is accordingly changed to
3. When we expand the tree from this node, by removing all the
axioms below 2 (left branch) or 4 (right branch), the instance
relation c does not follow any more, and hence we have a normal
termination, adding the sets f3; 2g and f3; 4g to H. We then create
the second branch from the root, by removing the elements below 5.
We see that the previously computed minimal label set of node n1
works also as a MinLab in this case, and hence it can be reused
(MinLab reuse), represented in the figure as an underlined set. The
algorithm continues now by calling expand-HSTOi2 ; c;f5; 2g. At
this point, we detect that there is H0 14 f3; 2g satisfying the first
condition of early path termination (recall that m 14 3), and hence
the expansion of that branch stops at that point. Analogously, we
obtain an early path termination on the second expansion branch
of the node n4. The algorithm then outputs m 14 3, which is the
margin-based boundary as computed before.

Theorem 4.8. Let O and c be such that O  c. Then Algorithm 2 computes the margin-based boundary of c.

Proof. Let g be the margin-based boundary which, by Lemma 4.1,
must exist. Notice first that the procedure expand-HST keeps as
invariant that m 6 g as whenever m is modified, it is only to join
it with the infimum of a MinLab (Line 9), which by definition is
the label of a MinA and, by Theorem 4.3, is 6 g. Thus, when the
algorithm terminates, we have that m 6 g. Assume now that
i m; in partic-
m  g. Then, there must exist a MinA S such that kS
ular, this implies that none of the axioms in S has a label 6 m and
thus S # Oim. Let M0 be the MinLab obtained in Line 2 of HST-
boundary. There must then be a h0 2 M0 such that S # Oih0 ; other-
wise, kS 6 
2M0  6 m. There will then be a call to the process
expand-HST with parameters Oih0 ; c, and fh0g. Suppose first that
early path termination is not triggered. A MinLab M1 is then
obtained, either by MinLab reuse (Line 4) or by a call to min-lab
(Line 6). As before, there is a h1 2 M1 with S #Oih0ih1
. Addition-
ally, since Oih0 does not contain any axiom labelled with h0, we
know h0 R M1. While iterating this algorithm, we can find a
sequence of MinLab M0;M1; . . . ;Mn and labels h0; h1; . . . ; hn such
that
all
i; j; 1 6 i < j 6 n. In particular, this means that the Mis are all dif-
ferent, and since there are only finitely many MinLab, this process
must terminate. Let Mn be the last set found this way. Then, when
and
expand-HST
H 14 fh1; . . . ; hng, no new MinLab is found. Suppose first that this
is due to a normal termination. Then, Rim
c. But that contradicts
the fact that S is a MinA for c since S #Rim. Hence, it must have finished by early termination.

called with R :14 Oih0ih1...ihn ; c

and (iii) hi R Mj

(i) hi 2 Mi,

S # Oihi ,

is

(ii)

for

Early termination can be triggered by two different causes.
Suppose first that there is a H0 2 H such that fh 2 H0jh i mg # H.
Then it is also the case that, for every h 2 H0 and S # Oih the
following holds: if h 2 H, then R # Oih; otherwise, h 6 m and
hence Oim # Oih. Let R0 :14 fa 2 Ojthere is no h 2 H0 with
laba 6 hg. As H0 2 H, it was added after a normal termination;
thus, c does not follow from R0im. As S #Rim, we obtain once again
a contradiction.

The second cause for early path termination is the existence of a
prefix-path P with fh 2 Pjh i mg 14 H. This means that in a previously explored path we had concluded that Rim  c, and a new
MinLab Mn1 was found. As in the beginning of this proof, we can
then compute sets Mn1; . . . ;Mm and hn1; . . . ; hm (n < m) such
that S # Oihi for all i; 1 6 i 6 m and the Mis are all different.

Hence this process terminates. As before, the cause of termination
cannot be normal termination, nor the first condition for early path
termination. Thus, there must exist a new H00 2 H that fulfills the
second condition for early termination. As H is a finite set, and each
of its elements is itself a finite list, this process also terminates.
When that final point is reached, there are no further causes of
termination that do not lead to a contradiction, which means that
our original assumption that mg cannot be true. Hence, m is the
margin-based boundary of c. h

4.3. Using binary search for linear ordering

Assume now that the context lattice L; 6 is a linear order, i.e.,
for any two elements 1; 2 of L either 1 6 2 or 2 6 1. We show
that in this case, the computation of the boundary can be further
optimized through a variant of binary search. First, we give a characterization of the boundary in this setting.

Lemma 4.9. Let O and c be such that O  c. Then the unique boundary
of c is the maximal element l of Llab with OPl  c.
Proof. Let l be the maximal element of Llab such that OPl  c.
Such a maximal element exists since Llab is a finite total order.
We need to show that  6 l iff OP  c. Obviously,  6 l implies
OP  OPl, and thus OPl  c yields OP  c. Assume now that
OP  c. Then the fact that l is maximal with this property
together with the fact that 6 is a linear order implies  6 l. Thus,
l is a boundary. h

return no boundary

Algorithm 3. Compute a boundary by binary search.
Input: O: ontology; c: consequence
Output: m: (O; c)-boundary
1: if  c then
2:
3:  :14 0lab; h :14 1lab
4: while l < h do
5:
6:
7:
8:
9:
10: return m :14 

set m;  < m 6 h, such that jd; m  dm; hjles1
if OPm  c then

h :14 predm

 :14 m

else

A direct way for computing the boundary in this restricted setting thus consists of testing, for every element in  2 Llab, in order
(either increasing or decreasing) whether OP  c until the desired
maximal element is found. This process requires in the worst case
n :14 jLlabj iterations. This can be improved using binary search,
which requires a logarithmic number of steps measured in n. Algorithm 3 describes the binary search algorithm. In the description of
the algorithm, the following abbreviations have been used: 0lab and
1lab represent the minimal and the maximal elements of Llab,
respectively; for 1 6 2 2 Llab; d1; 2 :14 jf0 2 Llabj1 < 0 6 2gj is
the distance function in Llab and for a given  2 Llab; pred is the
maximal element 0 2 Llab such that 0 < .

The variables  and h are used to keep track of the relevant
search space. At every iteration of the while loop, the boundary is
between  and h. At the beginning, these values are set to the minimum and maximum of Llab and are later modified as follows: we
first find the middle element m of the search space; i.e., an element
whose distance to  differs by at most one from the distance to h.
We then test whether OPm  c. If that is the case, we know that
the boundary must be larger or equal to m, and hence the lower
bound  is updated to the value of m. Otherwise, we know that

F. Baader et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 2240

the boundary is strictly smaller than m as m itself cannot be one;
hence, the higher bound h is updated to the maximal element of
Llab that is smaller than m; i.e., predm. This process terminates
when the search space has been reduced to a single point, which
must be the boundary.

We have thus shown methods to compute a boundary and different optimizations techniques that can be used to improve their
efficiency, as will be later shown in Section 6 in an empirical eval-
uation. Once this boundary has been computed, the knowledge
engineer may notice that the consequence belongs to an unwanted
set of contexts. In that case, she would like to change the labelling
function to correct the contexts to which this consequence belongs.
In the next section we will describe methods for finding minimal
changes for obtaining the desired boundary.

5. Repairing a boundary

Just as ontology development and maintenance is an error
prone activity, so is the adequate labelling of axioms. Indeed, several seemingly harmless axioms might possibly be combined to
deduce knowledge that is considered to be out of the scope of a
context. On the other hand, an over-restrictive labelling of axioms
may cause harmless or fundamental knowledge to be inaccessible
to some contexts.

Example 5.1. We continue Example 2.5. The ontology entails the
consequence c 14 SPrIncrecoCalc and the computed boundary of
c is 3 (see Example 4.4), which implies that only for contexts
labelled with 0 and 3, c is visible. That means the consequence c
can only be seen by the development engineers and customer service
employees (see Fig. 1). It could be, however, that c is not expected to
be accessible to customer service employees and development
engineers, but rather to customer service employees and customers.
In that case, we wish to modify the boundary of c to 5.

If the knowledge engineer notices that the boundary for a
given consequence differs from the desired one, then it would
be helpful if she could use automatically generated suggestions
for how to modify the labelling function in order to correct this
error. This problem can be formalized and approached in several
different ways. Here, we assume that the knowledge engineer
knows the exact boundary g that the consequence c should re-
ceive, and we try to find a set S of axioms of minimal cardinality
such that, if all the axioms in S are relabelled to g, then the
boundary of c will be g.

Definition 5.2 (Change set). Let O be an ontology, c a conse-
quence,lab a labelling function, S # O and g 2 L the goal label. The
modified assignment labS;g is given by
labS;ga :14 g;

if a 2 S;

laba; otherwise:

A sub-ontology S # O is called a CS for g if the boundary for O; c
under the labelling function labS;g equals g. It is a MinCS if the set
is minimal (w.r.t. set inclusion) with this property.

Obviously, the original ontology O is always a change set for any
goal label if O  c. However, we are interested in performing minimal changes to the labelling function. Hence, we search first for
minimal change sets, and later for a change set of minimum cardi-
nality. A change set of minimum cardinality, or smallest CS for
short, is obviously also a MinCS. However, the reverse is not necessarily true. A MinCS is minimal with respect to set inclusion but is
not necessarily a smallest CS since there might be several MinCS of
different cardinality. This is similar to the minimality of MinA (see
Definition 2.1), where a MinA is also not necessarily a MinA of
minimum cardinality. It follows from results in [22] that it is NPcomplete to determine whether the cardinality of a smallest CS is

equal to a given natural number, and thus smallest change sets
cannot be computed in polynomial time (unless P = NP).

Let g denote the goal label and c the margin-based boundary
 c, we have three cases which are illustrated in
for c. If g
Fig. 3: either (1) g < c (left), (2) c < g (right), or (3) g and c
are incomparable (middle). In our example, where c 14 3, the three
cases can be obtained by g being 0; 4, and 5, respectively. The
sets Lc and Lg contain the labels defining contexts that can, respec-
tively, deduce the consequence before and after the label changes.
Consider first the case where c < g. From Theorem 4.3 it follows
that any MinA S is a change set for g: since c < g, then for every
MinA S0, it follows that kS0 < g. But then, under the new labelling
labS;g it follows that

a2S
and hence when the least upper bound of all the labels of all MinAs
is computed, we obtain the boundary g, as desired.

labS;ga 14 

a2S

g 14 g;

For the case where g < c, we will use a similar argument as

before, based on a result dual to the result in Theorem 4.3:

Theorem 5.3. If S1; . . . ; Sn are all diagnoses

i141a2Si laba is a boundary for c.

for O; c,

then

Proof. Let first  2 L be such that OP  c, and let Si; 1 6 i 6 n be
a diagnosis for O; c. Since OP  c, there must be an axiom a 2 Si
such that a 2 OP. This means that
laba P  and hence
a2Si laba P . As this is true for each diagnosis, it holds that

i141a2Si laba P .
For the converse, let  2 L be a join prime element relative to Llab
such that  6 

i141a2Si laba. This in particular means that, for
every diagnosis Si for O; c,  6 a2Si laba. But since  is join prime
relative to Llab and for each a 2 Si laba is an element of Llab, it
holds that there must exist some ai 2 Si such that  6 labai.
Thus, OP \ Si
 ; for every i; 1 6 i 6 n. Since S1; . . . ; Sn are all
diagnoses for O; c, it follows that OP  c. h

Notice that, due to the duality between MinAs and diagnoses, if
the lattice L is distributive, then the boundary given by this theorem
is the same as the margin-based boundary. From Theorem 5.3, it
follows that, if g < c, then every diagnosis is a change set for g.

The third case can be addressed using a combination of the previous two approaches: if g and c are incomparable, we can first set
g 14 g 
 c. Thus, we can first apply the method
as a partial goal 0
dealing with the first case, to set the boundary to 0
g, and then,
using the second approach, modify this new boundary once more
to g. Rather than actually performing this task as a two-step com-
putation, we can simply compute a MinA and a diagnosis. The
union of these two sets yields a CS.

Unfortunately, the CS computed as described above is not necessarily a MinCS, even if a smallest diagnosis or a smallest MinA is
used, as shown in the following example.

Example 5.4. Let O; c and lab be as in Example 2.5 with the
consequence SPrIncrecoCalc. We then know that c :14 3 is a
boundary for O; c. Suppose now that c shall remain visible for those
who see it already and additionally made available to customers,
i.e., the goal label is g :14 4. Since c < g, we know that any MinA
is a change set. Since all MinAs for O; c have exactly three elements,
any change set produced this way will have cardinality three.
However, fa2g is also a CS. More precisely it is a MinCS.

To understand why the minimality of MinAs is not sufficient for
obtaining a MinCS, we can look back to Theorem 4.3. This theorem
states that, in order to find a boundary, we need to compute the
join of all kS, with S a MinA, and kS the meet of the labels of all axioms in S. But then, for any axiom a 2 S such that g 6 laba, mod-

Fig. 3. Hide consequence from some contexts (left), allow additional contexts to see consequence (right), and both at the same time (middle).

ifying this label to g will have no influence on the result of kS. In
Example 5.4, there is a MinA fa1; a2; a4g, where two axioms,
namely a1 and a4 have a label greater or equal to g 14 4. Thus,
the only axiom that needs to be relabelled is in fact a2, which yields
the MinCS fa2g shown in the example. Basically, we can consider
every axiom a 2 O such that g 6 laba as fixed in the sense that
it is superfluous for any change set. Analogously, one can view
some of the axioms in a diagnosis as being fixed when trying to
compute a change set for decreasing the boundary. For this reason,
we will introduce generalizations of MinAs and diagnoses, which
we call IAS and RAS, respectively.

I # Ojg

such

c.

and

for

that OPg [ I  c

A minimal removed axiom set RAS for g is a subset R # Oig such

Definition 5.5 (IAS, RAS). A minimal inserted axiom set IAS for g is a
subset
every
I0  I : OPg [ I0
that Oig n RAS c and for every RAS0  RAS : Oig n R0  c.
In the following, we will say that a set S is a minimal union of a RAS
and an IAS if (i) there exist a RAS R and an IAS I such that S 14 R [ I
and (ii) for every RAS R0 and IAS I0, R0 [ I0 is not strictly contained
in S. The following theorem justifies the use of IAS and RAS when
searching for the minimal change sets and a smallest change set.

Theorem 5.6. Let c be a boundary for O; c, g the goal label, and
S # O. Then, the following holds:

 if c < g then S is a MinCS iff S is an IAS,
 if g < c then S is a MinCS iff S is a RAS,
 if c and g are incomparable then S is a MinCS iff S is a minimal

union of a RAS and an IAS.

Proof. We prove only the first result. The other two can be shown
analogously. Let first S be a MinCS. From Theorem 4.3 it follows
that S # Ojg since otherwise S would not be minimal. Since S is
a change set, there is a MinA S0 such that 
a2S0 labS;ga P g; that
is, labS;ga P g for every a 2 S0. This means that S0
# OP [ S and
thus OP [ S  c. Hence S is an IAS.
Conversely, let S be an IAS; then S is clearly also a change set. If
it was not a MinCS, then there would exist an axiom a 2 S such that
S n fag is also a change set, but as shown before, this would imply
that S n fag is an IAS, which violates the minimality condition. h

Obviously, this theorem also yields a direct approach for com-

puting a CS of minimal cardinality.

Corollary 5.7. Let c be a boundary for O; c, and g the goal label. Then
a CS of minimal cardinality can be found by computing a RAS, an IAS
and a union of an IAS and a RAS of minimal cardinality.

The cardinality of a smallest union of an IAS and a RAS cannot be
computed from the cardinalities of a smallest RAS and a smallest
IAS since combining the smallest IAS and RAS does not necessarily
yield a smallest CS. The following example illustrates this.

Example 5.8. Assume fa1; a2g; fa2; a3g are the smallest RAS and
fa1; a4g is the smallest IAS, then fa1; a2; a4g is the smallest CS and
has cardinality 3. However, combining a smallest IAS and a
smallest RAS might yield a MinCS (but not a smallest CS) of
cardinality 4.

We now describe how to compute a smallest change set. As in
the previous section, we first present the most obvious approach
that is based on the computation of all MinAs and diagnoses.
Afterwards, we show how this idea can be improved by
considering fixed portions of the ontology and computing the set
of IAS and RAS, as described before. These methods compute all
minimal change sets,
from which those with the smallest
cardinality can be easily extracted. If one is only interested in a
smallest CS, then we can further improve this approach showing
that it suffices to compute only partial MinCS by putting a cardinality limit, thus reducing the search space and execution time of our
method.

Although we have shown in Example 5.4 that MinAs and diagnoses do not yield MinCS or even smallest CS directly, both of these
change sets can still be deduced from the set of all MinAs and diag-
noses, as shown by the following lemma.

Lemma 5.9. Let IAS (RAS) be an IAS (RAS) for g, then there is a MinA
(diagnosis) S such that IAS 14 S n OPgRAS 14 S n O6g ).

Proof. Let IAS be an IAS. Then OPg [ IAS  c, and hence there is a
MinA S # OPg [ IAS. As OPg \ IAS 14 ; it follows that IAS 14 S n OPg .
The case for RAS is analogous. h

Lemma 5.9 shows that we can compute the set of all IAS by first
computing all MinAs and then removing the set of fixed elements
from it. Thus, the most naive approach for computing a
OPg
change set of minimum cardinality is to first find all MinAs, then
compute the set of all IAS by removing all elements in OPg , and
finally search for the IAS having the least elements. The same
procedure applies to RAS, using diagnoses instead of MinAs.

As explained before, all MinAs can be computed using a HSTbased algorithm. Although not stated explicitly in the axiom pinpointing literature, it is clear that the same HST algorithm can be
used for computing all diagnoses. The only variant necessary is
to have a subroutine capable of computing one such diagnosis,
which can be obtained by dualizing the algorithm for computing
one MinA (see Algorithms 4 and 5 for an example on how this dualization works). In our experiments, we used this approach as a
basis to measure the improvement achieved by the optimizations
that will be introduced next.

Naively a CS with the lowest cardinality can be found by computing all MinCS and selecting one of minimal size. To find all
MinCS, we can use a HST algorithm that uses an auxiliary
procedure that computes a single MinCS. For this auxiliary proce-
dure, we can use two subprocedures extracting RAS and IAS,
respectively, as evidenced by Theorem 5.6. We now describe an ap-

F. Baader et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 2240

proach for computing a smallest CS directly, which again uses a
variant of the HST algorithm.

In Algorithm 4 we present a variation of the logarithmic MinA
extraction procedure presented in [21] that is able to compute an
IAS or stop once this has reached a size n, in which case it returns
the partial IAS computed so far. In this algorithm, the auxiliary procedure halve partitions an ontology into two disjoint subsets of axioms whose difference in cardinality is at most 1. We also show the
dual variant for computing a RAS in Algorithm 5.

Algorithm 4. Compute a (partial) IAS
Procedure extract-partial-IASOfix; Otest; c; n
Input: Ofix: fixed axioms; Otest: axioms; c: consequence;
n: limit
Output: first n elements of a minimal S # Otest such
that Ofix [ S  c

Subprocedure extract-partial-IAS-rOfix; Otest; c

l :14 l  1
return Otest

1: Global l :14 0; n
2: return extract-partial-IAS-rOfix; Otest; c
1: if n 14 l then
return ;
2:
3: if jOtestj 14 1 then
4:
5:
6: S1; S2 :14 halveOtest
7: if Ofix [ S1  c then
8:
9: if Ofix [ S2  c then
10:
11: S0
12: S0
13: return S0

return extract-partial-IAS-rOfix; S1; c
return extract-partial-IAS-rOfix; S2; c
1 :14 extract  partial  IAS  rOfix [ S2; S1; c
2 :14 extract  partial  IAS  rOfix [ S0
1; S2; c

1 [ S0

Given a goal label g, if we want to compute an IAS or a partial
IAS of size at most n for a consequence c, then we would make a
call to extract-partial-IASOPg ; Oig ; c; n. Similarly, a call to extract-
partial-RASOig ; Oig ; c; n yields a RAS of size 6 n or a partial
RAS of size exactly n. The cardinality limit will be used to avoid
unnecessary computations when looking for a smallest CS.

Algorithm 5. Compute a (partial) RAS
Procedure extract-partial-RASOnonfix; Otest; c; n
Input: Ononfix: axioms; Otest # Ononfix: axioms; c: consequence;

n: limit

Output: first n elements of a minimal S # Otest such that

Ononfix n S c

return ;
if jOtestj 14 1
l :14 l  1
return Otest

Global l :14 0; Ononfix; n
return extract-partial-RAS-r;; Otest; c
if n 14 l

1:
2:
Subprocedure extract-partial-RAS-rOhold; Otest; c
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13: return S0

S1; S2 :14 halveOtest
if Ononfix n Ohold [ S1
return extract-partial-RAS-rOhold; S1; c
if Ononfix n Ohold [ S2
return extract-partial-RAS-rOhold; S2; c
S0
1 :14 extract  partial  RAS  rOhold [ S2; S1; c
S0
2 :14 extract  partial  RAS  rOhold [ S0
1; S2; c
1 [ S0

c then

c then

With the help of the procedures to extract RAS and IAS, Algorithm 6 describes how to compute a MinCS with a cardinality limit.
In the first lines of this algorithm, lblc expresses the margin-based
boundary of the consequence c. In order to label a node, we compute a MinCS with extract  partial  MinCSO; lab;c; g; H; n, where
H is the set of all labels attached to edges on the way from the node
to the root of the tree. Note that all the axioms in H are removed
from the search space to extract the new IAS and RAS. Furthermore,
axioms in the IAS computed in Line 4 of this algorithm are considered as fixed for the RAS computation. The returned set is a MinCS of
size 6 n or a partial MinCS of size n.

i lblc ^ OPg

j lblc ^ Oig  c

Algorithm 6. Compute a (partial) MinCS
Procedure extract-partial-MinCSO; lab;c; g; H; n
iI :14 g
1:
iR :14 g
2:
return extract-partial-MinCSO; lab;c; g; iI; iR; H; n
3:
Procedure extract-partial-MinCSO; lab;c; g; iI; iR; H; n
Input: O; lab: labelled ontology; c: consequence; g: goal label;
iI: decision to compute IAS; iR: decision to compute RAS; H:
HST edge labels; n: limit

c then

(HST normal termination)

ifiI ^ OPg [ Ojg n H

return ;
if iI then
I :14 extract  partial  IASOPg ; Ojg n H; c; n

Output: first n elements of a MinCS S # O
1:
2:
3:
4:
5:
6:
7:

if iR and Oig n I  c then

return I [ R

R :14 extract  partial  RASOig n I; Oig n I [ H; c; n  jIj

Example 5.10. Returning to our running example, suppose now
that we want to hide c from development engineers and make it
available to customers, i.e., modify the label of consequence c to
g 14 5. Algorithm 6 starts by making a call to extract-partial-
IASOP5 ; Oj5 ; c; 1.7 A possible output for this call is IAS 14 fa3g.
We can then call extract-partial-RASOi5 n I; Oi5 n I; c;1, which
may output e.g., the set R 14 fa1g. Thus, globally the algorithm
returns fa3; a1g, which can be easily verified to be a MinCS for 5.
One of the advantages of the HST algorithm is that the labels
of any node are always ensured not to contain the label of any of
its predecessor nodes. In particular this means that even if we
compute a partial MinCS, the algorithm will still correctly find
all MinCS that do not contain any of the partial MinCS found during the execution. Since we are interested in finding the MinCS of
minimum cardinality, we can set the limit n to the size of the
smallest CS found so far. This limit is initially fixed to the size
of the ontology. If extract-partial-MinCS outputs a set with fewer
elements, we are sure that this is indeed a full MinCS, and our
new smallest known CS. The HST algorithm will not find all
MinCS in this way, but we can be sure that one MinCS with
the minimum cardinality will be found. The idea of limiting the
cardinality in order to find a smallest MinCS can be taken a step
further by not expanding each node for all the axioms in it, but
rather only on the first n  1, where n is the size of the smallest
CS found so far. This further reduces the search space by
decreasing the branching factor of the search tree. Notice that
the highest advantage of this second optimization appears when
the HST is constructed in a depth-first fashion. In that case, a
smaller MinCS found further below in the tree will reduce the
branching factor of all its predecessors. Hence, the cardinality

7 For the sake of this example, we ignore the cardinality limit, as we want to

describe only how one MinCS is computed.

limit reduces the search space in two dimensions: (1) the computation of a single MinCS is limited to n axioms and (2) only n  1
axioms are expanded from each node. Algorithm 7 is the resulting HST algorithm. The following theorem states that it is correct.

Algorithm 7. Compute a smallest CS by a HST algorithm
Procedure HST-extract-smallest-CSO; lab;L; 6; c; g
Input: O, lab: labelled ontology; L; 6: lattice; c:

consequence; g: goal boundary

Output: a smallest CS S

1: Global C; H; S :14 O; n :14 jOj; c;

isI :14 g
isR :14 g

ilblc ^ OPg
c;
jlblc ^ Oig  c

2: expand  HST  CS;
3: return S

Procedure expand-HST-CSH
Input: H: list of edge labels
Side effects: modifications to C and H

1: if there exists some H0 2 H such that H0 # H or
H0 contains a prefix-path P with P 14 H then

2: return
3: else if there exists some Q0 2 C such that H \ Q0 14 ;

(early termination 

then

(MinCS reuse)

if ; 14 Q then
H :14 H [ fHg
return

4: Q :14 Q0
5: else
6: Q :14 extract  partial  MinCSO; lab;c; g; isI; isR; H; n
7:
8:
9:
10:
11:
12:
13:
14: for the first n  1 axioms a 2 Qdo
15:

expand  HST  CSH [ fag

(normal termination )

if jQj < jSjthen

C :14 bfC [ fQg

n :14 jQj
S :14 Q

Theorem 5.11. Let O be an ontology, c a consequence with O  c, and
g a goal label. If m is the minimum cardinality of all CS for g, then
Algorithm 7 outputs a CS S such that jSj 14 m.

Proof. The described algorithm outputs a CS since the globally
stored and finally returned S is only modified when the output of
extract-partial-MinCS has size strictly smaller than the limit n, and
hence only when this is indeed a CS itself. Suppose now that the
output S is such that m < jSj, and let S0 be a MinCS such that
jS0j 14 m, which exists by assumption. Then, every set obtained by
calls to extract-partial-MinCS has size strictly greater than m, since
otherwise, S and n would be updated. Consider now an arbitrary
set S0 found during the execution through a call to extract-partial-
n :14 fa1; . . . ; ang be the first n elements of S0. Since
MinCS, and let S0
S0 is a (partial) MinCS, it must be the case that S0 # S0
n since every
returned MinCS is minimal in the sense that no axiom might be
removed to obtain another MinCS. Then, there must be an
i; 1 6 i 6 n such that ai R inS0. But then, S0 will still be a MinCS
after axiom faig has been removed. Since this argument is true
for all nodes, it is in particular true for all leaf nodes, but then they
should not be leaf nodes, since a new MinCS, namely S0 can still be
found by expanding the HST, which contradicts the fact that S is
the output of the algorithm. h

c to g 14 0. Algorithm 6 first calls extract-partial-RASOi0 ; Oi0 ; c; 5.
A possible output of this call is R 14 fa2; a3g. The tree now branches
through a2 and a3.
In the first case it calls extract-partial-
RASOi0 ; Oi0 n fa2g; c; 2, which could yield the RAS R 14 fa4; a5g.
This might be a partial MinCS since its size equals the cardinality
limit. The next call extract-partial-RASOi0 ; Oi0 n fa2; a4g; c; 2
yields a smallest R 14 fa1g, and the HST terminates. Notice that if
fa1g had been the first MinCS found, the process would have immediately terminated.

Efficient implementations of the original version of the HST
algorithm rely on several optimizations. Two standard optimizations described in the literature are node-reuse and early path termination (see, e.g., [11,12,14]). Node-reuse keeps a history of all
nodes computed so far in order to avoid useless (and usually
expensive) calls to the auxiliary procedure that computes a new
node. Early path termination, on the other hand, prunes the
Hitting Set Tree by avoiding expanding nodes when no new information can be derived from further expansion. In order to avoid
unnecessary confusion, we have described the modified HST algorithm without including these optimizations. However, it should
be clear that both, node-reuse and early path termination, can
be included in the algorithm without destroying its correctness.
The implementation used in our experiments applies these two
optimizations.

Example 5.13. We continue Example 2.5 with the same consequence SPrIncrecoCalc. For goal label g 14 5, Fig. 4 shows the
expansion of the HST trees computing all MinAs and all diagnoses
(left),
in comparison with the one obtained for computing a
smallest change set using both optimizations: fixed axioms and
cardinality limit (right). Obviously, the number of nodes, the node
cardinality and the number of tree expansions is lower.

6. Empirical evaluation

On large real-world ontologies, we empirically evaluated implementations of the algorithms to (1) compute a boundary for a consequence and (2) repair this boundary if needed. The following
sections describe the test data and the test environment first,
and then present the empirical results, which show that our algorithms perform well in practical scenarios.

6.1. Test data and test environment

We performed our tests on a PC with 2GB RAM and Intel Core
Duo CPU 3.16 GHz. We implemented all approaches in Java 1.6
and for convenient OWL file format parsing and reasoner interaction we used the OWL API for OWL 2 [24] in trunk revision 1150
from 21.5.2009.8

6.1.1. Context lattices

Although we focus on comparing the efficiency of the presented
algorithms, and not on practical applications of these algorithms,
we have tried to use inputs that are closely related to ones encountered in applications. The two context lattices Ld; 6d and Ll; 6l are
similar to ones encountered in real-world applications. The context
lattice Ld; 6d, already introduced in Fig. 1, was developed and applied in an access policy scenario [19]. The context lattice Ll; 6l is
a linear order with 6 elements Ll 14 Ld 14 f0; . . . ; 5g with the obvious ordering 6l :14 fn; n1jn; n1 2 Ll ^ 0 6 n 6 5g. This lattice
could represent an order of trust values as in [25] or dates from a
revision history, to name just two applications.

Example 5.12. Coming back to our running example, suppose that
we want to hide n from development engineers, i.e., set the label of

8 Subversion Repository https://owlapi.svn.sourceforge.net/svnroot/owlapi/

owl1_1/trunk.

F. Baader et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 2240

Fig. 4. Hitting Set Trees to compute all MinAs (left) and a smallest change set for g 14 5 (right).

6.1.2. Ontologies, label assignment and reasoners

We used the two ontologies OSnomed and OFunct with different

expressivities and types of consequences for our experiments.

The Systematized Nomenclature of Medicine, Clinical Terms
(SNOMED CT) is a comprehensive medical and clinical ontology
which is built using the DL EL. Our version of OSnomed is the Jan-
uary/2005 release of the DL version, which contains 379,691 concept names, 62 object property names, and 379,704 axioms.
Since more than five million subsumptions are consequences of
OSnomed, testing all of them was not feasible and we used the same
sample subset as described in [21], i.e., we sampled 0.5% of all concepts in each top-level category of OSnomed. For each sampled
concept A, all subsumptions A v B following from OSnomed with A
as subsumee were considered. Overall,
this yielded 27,477
subsumptions. Following the ideas of [21], we pre-computed the
reachability-based module for each sampled concept A with the
reasoner CEL 1.0 [26] and stored these modules. The module for
A is guaranteed to contain all axioms of any MinA and any diagno-
sis, thus also any IAS and RAS, for each subsumption A v B with A
the considered subsumee. This module was then used as the start
ontology when considering subsumptions with subsumee A, rather
than using the complete ontology.

The OWL ontology OFunct has been designed for functional
descriptions of mechanical engineering solutions and was presented in [27,28]. It has 115 concept names, 47 object property
names, 16 data property names, 545 individual names, 3,176 axi-
oms, and the DL expressivity used in the ontology is SHOIN (D).
Its 716 consequences are 12 subsumption and 704 instance relationships (concept assertions).

To obtain labelled ontologies, axioms in both ontologies received a random label assignment of elements from the set
Ll 14 Ld. Our test suite provides a great variety of cases: consequences with many or few MinAs, with very large or very small
MinAs, cases with a high or low boundary, etc. Hence, our results
should not differ greatly if a different label assignment is used.
As black-box subsumption and instance reasoner we used Pellet
2.0 [29], since it can deal with the expressivity of both ontologies.
For the expressive DL SHOIN (D)) it uses a tableau-based algorithm and for EL it uses an optimized classifier for the OWL2EL
profile that is based on the algorithm described in [30].

6.1.3. Test setting for computing a boundary

The boundary computation with full axiom pinpointing (FP)
uses log-extract-MinA (Algorithm 2 from [21], which is identical to
Algorithm 8 from [12]) and the HST based HST-extract-all-MinAs
procedure (Algorithm 9 from [12]). The set of extracted MinAs is
then used to calculate the label of the consequence. We stop the
execution after 10 MinAs have been found in order to limit the run-
time; thus, some of the labels found may not be the final result. The
boundary computation with label-optimized axiom pinpointing
(LP) with min-lab and HST-boundary are implementations of Algo-

rithms 4 and 5. The boundary computation with binary search
for linear ordering (BS in the following) implements Algorithm 3.
We tested 8 combinations resulting from the 2 ontologies OSnomed
and OFunct, with the two approaches FP and LP over the lattice
Ld; 6d and the two approaches LP and BS over the lattice Ll; 6l.

6.1.4. Test setting for repairing a boundary

We tested repairing access restrictions to implicit knowledge in
the following setting. We took the computed boundary c of each
consequence c of the ontologies from the first experiment and then
computed the MinCS to reach the goal boundary g which is constantly 3 in all experiments. Consequences were not considered
if c 14 g. Thus, from the 716 consequences in OFunct, we have 415
remaining with context lattice Ld; 6d and 474 remaining with
Ll; 6l. From the 27,477 consequences in OSnomed we have 23,695
remaining with context lattice Ld; 6d and 25,897 with Ll; 6l. The
MinCS computation with FP uses the procedures log-extract-MinA
and the HST based HST-extract-all-MinAs,
implemented by the
algorithms mentioned above. The MinCS computation with
extract-partial-MinCS and the smallest CS computation with
HST-extract-smallest-CS including optimizations for fixed axioms
and cardinality limit are implementations of Algorithms 6 and 7.
The required IAS and RAS extraction with extract-partial-IAS,
extract-partial-RAS are implementations of Algorithms 4 and 5,
respectively. We stop after 10 MinAs (or, respectively, MinCS or
partial MinCS) have been found in order to limit the runtime;
hence there might be no computed MinCS at all or a non-smallest
MinCS returned. We tested 12 combinations resulting from the
two ontologies OSnomed and OFunct, two context lattices Ld; 6d and
Ll; 6l and three algorithm variants (FP, fixed axioms, and fixed axioms in combination with cardinality limit). Running the fixed axioms optimization without cardinality limit can be done easily by
skipping Line 11 in Algorithm 7.

6.2. Experimental results

Our experiments show that our algorithms perform well on
practical large-scale ontologies. In the following we describe our
empirical results for each of the two discussed tasks with labelled
ontologies, i.e., computing a boundary to discover access restrictions to a given consequence and repair the boundary of a single
consequence by changing axiom labels.

6.2.1. Computing a boundary

The results for boundary computation by FP and LP, using lattice
Ld; 6d and the two ontologies OSnomed and OFunct are given in Table 1.
The table is divided into two parts. The upper part contains a set of
consequences that are easy, in the sense that each consequence
has fewer than 10 MinAs. This contains 21,001 subsumptions from
OSnomed and 307 consequences from OFunct. The lower part contains
a set of consequences that are hard, in the sense that each

Table 1
Boundary computation by FP vs. LP, using lattice Ld; 6d and two ontologies with an easy and a hard set of consequences.

]Early
termination

]Reuse

]Calls to extract MinA
(MinLab)

]MinA
(]MinLab)

]Axioms (]labels) PerMinA
(MinLab)

Lattice operations
time in ms

Total labelling time
in ms

OSNOMED
easy

OFUNCT

easy

OSNOMED
hard

OFUNCT

hard

Avg
Max
Stddev
Avg
Max
Stddev

Avg
Max
Stddev
Avg
Max
Stddev

Avg
Max
Stddev
Avg
Max
Stddev

10.20 16.38

Avg
Max
Stddev
Avg
Max
Stddev

4.41 0.56

consequence has at least 10 MinAs. This contains 6476 subsumptions from OSnomed and 409 consequences from OFunct.

While LP computed the boundary for each consequence following from the easy and the hard set, FP computed the boundary for
each consequence following from the easy but not for each following from the hard set. As described above, we stop the execution
after 10 MinAs have been found. A label computed for a consequence following from the hard set, called non-final label, might
be lower than the boundary since there might be further MinAs
providing a higher label. For a practical system, a lower label puts
an unnecessarily strong access restriction to a consequence, resulting in an overrestrictive policy.

For the easy set of OSnomed, the overall labelling time for all
21,001 subsumptions with FP was 50.25 min. For LP it was
1.50 min, which means that LP was about 34 times faster than
FP. For the hard set of OSnomed, the non-final labels of FP were
identical to the boundaries of LP in 6376 of the 6476 cases
(98%),
in most cases the missing MinAs would not have
changed the already computed label. FP took 2.5 h without final
results, whereas LP took 0.6% (a factor of 155) of that time and
returned final results after 58 s. We started a test series limiting
runs of FP to <30 MinAs, which did not terminate after 90 h, with
1572 labels successfully computed and 30 subsumptions skipped
since they had P30 MinAs. Interestingly, in both the easy and the
hard set, LP rarely takes advantage of the optimizations early
termination and reuse, which might be due to the simple structure of the lattice.

i.e.,

Similar results have been observed for the easy and the hard sets
of OFunct. Again, the computation of FP was restricted to <10 MinAs.
This time, only 363 out of 409 (88%) non-final labels of FP were
equal to the boundaries of LP. Although the ontology is quite small,

Fig. 5. Histogram of required ]MinAs (]MinLabs) to compute a boundary (respec-
tively, non-final label).

LP again performs much better than FP. The reason could be that, in
this ontology, consequences frequently have a large set of MinAs.
For a system designer, a question to decide could be to use
either (a) our approach of keeping one large ontology with labelled
axioms and pre-compute all consequences9 and their labels or (b)
the naive approach of managing separate ontologies and computing
all consequences of each separate ontology independently. We can

9 When we say all consequences we always mean all consequences the user is
interested in. These might be, e.g., all concept assertions of named individuals to
named concepts and all subsumptions between two named concepts. This restriction
is necessary since already from simple axioms,
infinitely many nonequivalent
c o n s e q u e n c e s m a y f o l l o w ,
t h a t
M v 9l:M; M v 9l:9l:M; etc.

f r o m M v 9l:M i t

f o l l o w s

e . g . ,

F. Baader et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 2240

Fig. 6. Histograms of time needed to compute a consequences boundary in OSnomed
(upper part) and OFunct (lower part) with the methods FP vs. LP.

Fig. 7. Histograms of time needed to compute a boundary for a consequence in
OSnomed (upper part) and OFunct (lower part) with the methods BS vs. LP.

make the following rough estimate while we assume that the lattice
is nonlinear but the details of its structure would not have any influ-
ence. Based on our test results with OSnomed, an estimate for the time
needed to compute a label for all of the more than 5 million subsumptions in OSnomed with LP would be 2:47 	 5	106
27477  449 min.
Assuming 20 min to compute all consequences with the current
CEL reasoner [12], our approach to compute and label all consequences would be as expensive as computing all consequences
20  23 times. However, two remarks need to be made here:

1. Taking the fast computation time of 20 min, achieved by CEL is
to some extent unfair, since the slower (see [12] for a compar-
ison) Pellet is used in our experiments for reasons explained
above. However, at the time of these experiments, Pellet fails
to classify the complete OSnomed because of memory exhaustion.
For this reason we process only the reachability-based modules
with Pellet and not the complete OSnomed, as described above. On
average, our reachability-based modules contain 53.21 axioms,
with a maximum size of 146 axioms; that is, their size is 0.01%
(maximum 0.04%) of the total size of OSnomed [21]. Presumably,
the realistic ratio is actually below 23.

2. The preparation step computing the reachability-based modules as described above took < 0:21 s [21] and can be neglected
here.

Our approach is as expensive as computing 23 views if we
assume that computing all consequences for each of the views
requires 20 min. For incomparable user labels, e.g., representing
user roles which do not inherit permissions from each other while
one user can have several roles, already the considerably low number of 5 incomparable user labels implies 25 14 32 sub-ontologies
(views), and thus our approach is already faster. For fewer user
labels, the naive approach is faster, but then separate subsumption
hierarchies would need to be stored for each of the views, whereas
in our approach only one labelled hierarchy needs to be stored.
Based on our test results with OFunct, a similar estimate can be
made. Computing all consequences requires 5 s and labelling all
consequences with LP requires 146 s. In this case our approach is
as expensive as computing all consequences 30 times. Again with
5 or more user labels, our approach is faster.

In statistics, histograms are often used to roughly assess probability distributions. The range of values on the x-axis is divided into

Table 2
Boundary computation by LP vs. BS on a sampled set of 27,477 subsumptions in OSnomed/all 716 consequences of OFunct with lattice Ll; 6l (time in ms).

]Early
term.

OSNOMED
Avg
Max
Stddev

OFUNCT
Avg
Max
Stddev

]Reuse

]Calls to extract
MinLab

]MinLab

]Labels per
MinLab

Lattice oper.
time

Total labelling
time

Iterations

Total labelling
time

Table 3
Results comparing variants to compute a smallest CS.

Ont.

Lattice Variant

OFunct

Ld; 6d

Ll; 6l

fixed
axioms
fixed
axioms,
card. lim.

fixed
axioms
fixed
axioms,
card. lim.

OSnomed

Ld; 6d

Ll; 6l

fixed
axioms
fixed
axioms,
card. lim.

fixed
axioms
fixed
axioms,
card. lim.

Runtime
limit per
goal

Time in
minutes

Ratio of
correct
solutions
(%)

Ratio of
optimal
solutions
(%)

MinA

MinCS

(partial)
MinCS

MinA

MinCS

(partial)
MinCS

MinA

MinCS

(partial)
MinCS

MinAs

MinCS

(partial)
MinCS

non-overlapping intervals and the y-axis provides the number of
observations. The histogram in Fig. 5 shows, for all four combinations of the two ontologies and the two computation methods,
the number of MinAs (respectively, MinLabs) required to compute
a boundary or non-final label. From this histogram and also from
Table 1, one can see that LP requires at most three MinLabs for
OSnomed, at most four for OFunct, and usually just one MinLab
whereas FP usually requires more MinAs.

The histograms in Fig. 6 compare the distribution of time
needed with FP vs. LP to compute a boundary of a consequence
from the union of the above described easy and hard sets. The
required time is given on the logarithmic x-axis, where the number
below each interval defines the maximum contained value. As can
be seen, FP takes more time than LP in general. Note that moving to
the left on the x-axis means a relatively high performance
improvement, due to the logarithmic scale. It can be further seen
that LP covers a few intervals while FP covers more. This indicates
that FP has a higher variability and the standard deviation values in
Table 1 confirm this.

Table 2 provides results for LP and BS using the total order Ll; 6l
as context lattice. For OSnomed, LP takes 130.4 and BS takes 77.1 s to

Fig. 9. Cumulative distribution of time needed to repair a boundary in OFunct with
lattices Ld; 6d and Ll; 6l.

label all 27,477 subsumptions. For OFunct, LP takes 133.9 and BS
takes 68.6 s to label all 716 consequences. Interestingly, labelling
all consequences of OFunct or all consequences of OSnomed takes
roughly the same time, perhaps due to a trade-off between ontology size and expressivity. Roughly, BS is twice as fast (factor 1.7
with OSnomed, 1.9 with OFunct) compared to LP.

60 	 5	106

Above, we already discussed the decision of a system designer
whether to use our approach or the naive approach for nonlinear
lattices. Based on our test results a similar estimate can be made
for linear lattices. Labelling all consequences of OSnomed would
27477  234 min. Similar to the explanation above, our
require 77:1
approach is as expensive as computing all consequences
20  13 times, i.e., with 13 or more context labels our approach

is faster. For O FUNCT, our approach is as expensive as computing all
5  14 times, i.e., with 14 or more user labels our
consequences 68:8
approach is faster.

Fig. 8. Time-quality diagram comparing variants to compute a smallest CS.

F. Baader et al. / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 2240

especially in their combination, are optimizations yielding significantly higher quality and lower runtime.

Instead of providing histograms of time needed to repair a
boundary for a consequence, we provide the cumulative distribution in Figs. 9 and 10. The difference to the histograms is that
not discrete intervals, but instead the continuous spectrum of time
needed is depicted, and the number of consequences is cumulated
over time until it reaches the number of all considered conse-
quences. For this reason, the maximum values on the y-axis are
415, 474, 23695 and 25897. The reason for those numbers of
consequences has been explained above. The x-axis is again
logarithmic, as it has been the case with the previous histograms.
It can be seen that in general a consequence from OSnomed is
repaired much faster than one from OFunct. Interestingly, even at
the start of the logarithmic x-axis, some consequences are repaired
already. In our test result log, the reported time for several consequences was even 0 ms. The reason is Javas limitation with respect
to measuring fractions of milliseconds. It can be seen, as already
known from Table 3, that for the two diagrams of OSnomed and the
upper right diagram of OFunct, most of the consequences are repaired roughly one order of magnitude faster with both of our optimizations enabled compared to the naive FP approach.

7. Conclusions

We have presented a general approach for defining and reasoning with contexts in large scale ontologies. Our approach assumes
that every axiom in the ontology is labelled with an element of a
context lattice. The different contexts of this ontology are then
expressed by elements of this lattice: each10 such element  yields
a sub-ontology consisting of the axioms whose label is greater or
equal to . This general framework can be instantiated to any notion
of context that can be expressed using a context lattice. Examples of
such instances are access control to ontological knowledge, trust
management, provenance, and granularity, among many others.
The main advantage of this approach is that it allows the knowledge
engineer to maintain only one large ontology that is usable in all different contexts, rather than separate sub-ontologies for each context.
We have shown that we can extend the labelling function to
arbitrary consequences of the ontology, in the sense that every
implicit consequence can be assigned a label, called its boundary,
which fully characterizes the set of all contexts in which the consequence can be derived. In this way, one can solve reasoning tasks
for all contexts simultaneously. For instance, if one is interested in
computing the concept hierarchy, one can compute the boundary
for each of the subsumption relations between concept names
holding in the full ontology. From this information one can easily
deduce the concept hierarchy derivable in each of the contexts.
Our algorithms are inspired by ideas from axiom pinpointing, but
are optimized to take advantage of the additional information provided by the lattice and the labelling function.

The principal assumption for our framework is that the axioms
have been assigned the correct label. However, assigning these
labels to all the axioms in the ontology is an error-prone task.
Indeed, a small change in the labelling function may hide relevant
consequences from a context, or apparently innocuous axioms may
in combination produce consequences not intended to be visible in
some contexts. To alleviate this problem, we propose a method for
finding minimal changes that should be made to the labelling func-
tion, in order to repair the boundary of a given consequence. Here,
we use two different notions of minimality. First we consider the
task of finding all the minimal (w.r.t. set inclusion) sets of axioms
that need to be relabelled to correct the boundary, i.e., all minimal

10 For technical reasons, only elements that are join prime relative to the axiom
labels can be used as context labels.

Fig. 10. Cumulative distribution of time needed to repair a boundary in OSnomed with
lattices Ld; 6d and Ll; 6l.

The histograms in Fig. 7 compare the distribution of time
needed to compute a boundary with BS and LP. Again the required
time is given on the logarithmic x-axis. They show that the performance gain with BS over LP is higher with OFunct compared to
OSnomed, as discussed already. They further show that there is no
clear winner with respect to variability, as was the case comparing
FP with LP; Table 2 confirms that observation.

6.2.2. Repairing a boundary

Table 3 contains results for the four combinations of the two
ontologies and the two context lattices. For each of them we tested
3 variants, leading to 12 test series overall. As described above, we
limit the number of computed MinAs and MinCS to 10, so our algorithms might not find any, or not a smallest change set before
reaching the limit. We measure the quality of the presented
variants given this limitation at execution time in the following
sense. Table 3 lists the ratio of correct solutions where at least 1
correct MinCS was computed, and the ratio of optimal solutions
where the limit was not reached during the computation and thus
yielded the smallest change set possible. Notice however that the
ratio of cases with the smallest change set successfully computed
might be higher, including those where the limitation was reached
but the smallest change set was already found.

Fig. 8 depicts a time-quality diagram of all variants from Table
3, where quality is the ratio of correct solutions multiplied by
the ratio of optimal ones. Obviously, a desirable variant is in the
upper left corner yielding maximum quality in minimal time. It
can be seen that FP is clearly outperformed by our optimizations.
The experiment shows that fixed axioms and cardinality limit,

change sets. This information can be then given to the knowledge
engineer, who can decide which change set is the best option.
However, the large number of minimal change sets available may
be overwhelming for the knowledge engineer, and hence finding
only one of these sets of minimal size can sometimes be more
desirable. We show how to improve the algorithms to find only
one change set of minimal cardinality, by including a cardinality
limit in the Hitting Set Tree construction.

An interesting property of our framework is that it is independent of the ontology language used. That is, it can be used for
finding the boundary of subsumption relations in the DL
SROIQ(D), as well as unsatisfiability of concepts w.r.t. acyclic
TBoxes in ALC, for example. This is the case since all our algorithms follow a black-box approach. This means that they do
not depend on a specific implementation of a reasoner, but can
be used together with any reasoner available. In particular, this
allows us to take advantage of the many optimizations of state-
of-the-art DL reasoners.

We have evaluated implementations of our algorithms empiri-
cally, using two large-scale ontologies that are used in real-life sce-
narios, and a context lattice developed for an access control
application. Our experimental results show that our implementations perform well in practical scenarios with large-scale ontologies.
For computing a boundary for a consequence, the full axiom
pinpointing approach is clearly outperformed by the label-opti-
mized axiom pinpointing approach, which is faster up to a factor
of 155. For the special case where the context lattice is a total
order, label-optimized axiom pinpointing is itself outperformed
by the Binary Search approach by roughly a factor of 2. We have
provided an estimate from the point of view of a system designer,
comparing our approach of labelled ontologies and consequences
to a naive approach of reasoning over separate ontologies. It
showed that our approach is faster when more than four incomparable user labels are present in a nonlinear lattice or when more
than 12 user labels are present in a linear lattice.

For repairing a boundary, which is only possible by changing
axiom labels, our experiments show that our algorithms and optimizations yield tangible improvements in both the execution time
and the quality of the proposed smallest CS defining a new axiom
labelling. In order to compute a CS of minimal cardinality, the
approach of computing all MinAs is outperformed up to a factor
of 12 by our optimized approach of computing IAS and RAS. Limiting cardinality further reduces computation time by up to a factor
of 2. In combination we observed a performance increase by up to a
factor of 18. But not only performance is improved, at the same
time both optimizations increase the quality of the computed
smallest CS under limited resources at runtime.

As future work, we plan to extend our methods for repairing a
boundary. In the current setting, the knowledge engineer must
specify the exact boundary that the consequence must receive.
However, it is sometimes desirable to set a constraint in the form
of an inequality, for instance, specifying that the consequence
should be visible from a given context, but without restricting its
visibility w.r.t. other contexts. Additionally, we plan to explore
other notions of minimality of the change sets, like the distance
that a label is moved, the number of users affected, or the number
of consequences that receive a new boundary.
