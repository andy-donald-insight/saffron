Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 131147

Contents lists available at SciVerse ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : h t t p : / / w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

An interaction-based approach to semantic alignment
Manuel Atencia a,b,

, Marco Schorlemmer c,d

a INRIA, 655 Avenue de lEurope, Montbonnot, 38334 Saint Ismier Cedex, France
b University of Grenoble, Grenoble, France
c Artificial Intelligence Research Institute, IIIACSIC, Campus de la UAB, 08193 Bellaterra, Catalonia, Spain
d Universitat Autonoma de Barcelona, Bellaterra, Catalonia, Spain

a r t i c l e

i n f o

a b s t r a c t

Article history:
Available online 17 December 2011

Keywords:
Semantic alignment
Agent interaction context
Interaction model
Communication product
Alignment protocol
Matching criteria

We tackle the problem of semantic heterogeneity in the context of agent communication and argue that
solutions based solely on ontologies and ontology matching do not capture adequately the richness of
semantics as it arises in dynamic and open multiagent systems.

Current solutions to the semantic heterogeneity problem in distributed systems usually do not address
the contextual nuances of the interaction underlying an agent communication. The meaning an agent
attaches to its utterances is, in our view, very relative to the particular dialogue in which it may be
engaged, and that the interaction model specifying its dialogical structure and its unfolding should not
be left out of the semantic alignment mechanism.

In this article we provide the formal foundation of a novel, interaction-based approach to semantic
alignment, drawing from a mathematical construct inspired from category theory that we call the communication product. In addition, we describe a simple alignment protocol which, combined with a probabilistic matching mechanism, endows an agent with the capacity of bootstrapping  by repeated
successful interaction  the basic semantic relationship between its local vocabulary and that of another
agent.

We have also implemented the alignment technique based on this approach and prove its viability by

means of an abstract experimentation and a thorough statistical analysis.

O 2011 Elsevier B.V. All rights reserved.

1. Introduction

The Semantic Web was envisioned, at the turn of the century, as
an extension of the Web in which information is given well-de-
fined meaning, better enabling computers and people to work in
cooperation [1]. A key concept playing a crucial role in this vision
is that of ontologies: documents or files that formally define vocabularies of terms and the relations amongst these terms. An important effort has gone into providing formal foundations for ontology
engineering, deployment, and maintenance, both from the logical
and the computational point of view [2]. As a result, much research
has focussed on the computationally tractable,
logic-based
representation formalisms that could provide a well-defined,
model-theoretic semantics to carry out inferences and drawing
conclusions on top of the standard web infrastructure, and thus
supporting this improved work in cooperation effectively and
efficiently [3,4].

 Corresponding author at: INRIA, 655 Avenue de lEurope, Montbonnot, 38334

Saint Ismier Cedex, France. Tel.: +33 476 61 53 55; fax: +33 476 61 52 07.

E-mail addresses: manuel.atencia@inria.fr

(M. Atencia), marco@iiia.csic.es

(M. Schorlemmer).

1570-8268/$ - see front matter O 2011 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2011.12.001

This view of cooperation on the Web takes well-defined meaning via ontologies as a prerequisite for successful interaction. By
adopting this stance, meaningful communication between, for in-
stance, separately engineered software agents in a multiagent system relies on an a priori commitment to a shared conceptualisation
of the application domain as to guarantee a shared understanding
of the terms being communicated [5,6]. Ontologies may indeed be
useful for specifying such a shared conceptualisation when dealing
with stable domains and closed communities of agents. But often it
is impossible to reach global semantic agreements because the cost
of being precise about semantics and guaranteeing this precision at
a global level soon increases very quickly when the number of
agents grows [7,8].

1.1. Semantic heterogeneity in the context of multiagent interaction

As a result, most state-of-the-art approaches that tackle semantic heterogeneity not only seek to agree on shared global ontolo-
gies, but also attempt to find semantic correspondences between
varying terminologies through ontology matching [9,10]. We ar-
gue, however, that by computing semantic correspondences of
separate terminologies focusing on ontologies and ontology

M. Atencia, M. Schorlemmer / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 131147

matching, the problem is only partially addressed. Already back in
the mid 1980s, Winograd and Flores recalled that, according to
modern hermeneutics, language is listened to in a background,
and that interpretation is not independent of the interpreter [11].
Meaning, they stressed, is always re-created in the context of the
intentions, purposes, expectations, and commitments the interpreter attaches to a particular utterance. Consequently, meaning
is ultimately interaction-dependent and relative to an implicit
background that cannot be fully de-contextualised.

Despite that, most state-of-the-art ontology matching systems
compute semantic alignments generally prior to and independently
of interaction. Moreover, most matching techniques follow a classical functional approach according to which two or more ontologies
are taken as input and a semantic alignment of ontological entities is
generated as output, as part of a larger ontology-alignment life cycle
[10]. Nonetheless, this approach has several drawbacks. On the one
hand, it limits the dynamism and openness of the interaction, as only
agents with previously matched ontologies  even if only partially 
may jointly participate in an interaction. On the other hand, it keeps
matching outside the context of interaction. Semantic correspondences are established by ontology matchers in an interaction-inde-
pendent fashion, for instance by exploiting the internal structure of
ontologies and ontological entities [12,13] or by resorting to external sources where semantic relations were determined prior to
interaction and independently from it (e.g. when using upper-level
ontologies [14], lexical databases [15], or background knowledge
available in the Semantic Web itself [16]).

Although recent approaches aim at approximating an ontology
alignment in the context of open and dynamic multiagent systems
[17] by using argumentation [18,19] and targeting only certain
ontologies fragments [20] or taking the task at hand into account
[21]  thus allowing for increased openness and dynamism  such
ontology matching techniques still fall back on a classical ap-
proach: when a mismatch occurs, semantic heterogeneity is solved
by some sort of functional ontology matcher, albeit using only relevant fragments of the ontologies and subject to further argumentation or negotiation of the alignment. Furthermore, although done
at run-time and task-oriented, matching is still carried out outside
the context given by the interaction.

1.2. Taking interaction as ontologically prior to meaning

In this paper we investigate how software agents can establish
semantic relationships between their respective terminologies on
the grounds of their communication in the context of a specific
interaction. We do that not by taking well-defined meaning as a
prerequisite of successful interaction, but instead by taking successful interaction as a prerequisite for shared understanding.

Take, for example, two agents engaged in a simple bargaining
dialogue. At the initial state of the dialogue the buyer may ask
the seller how much a certain good costs, to which the seller
may answer providing a price. In the context of a bargaining inter-
action, at this particular state of the dialogue, the price uttered by
the seller is not an actual offer but just a starting point for the bargaining dialogue to unfold. The answer given by the seller does not
have the same meaning in the context of this kind of dialogue and
at this particular dialogue state as if the buyer would have asked
for the price in a hotel store, for instance, where articles have a
fixed price. At this state of the bargaining dialogue the seller does
not expect the buyer to utter an acceptance of the price, and in certain cases not even to utter a refusal to continue bargaining. He or
she waits for a counteroffer from the buyer. After this interaction
state, however, the prices uttered by the buyer or seller do stand
for genuine offers that are subject to be accepted or not.

Hence, the meaning of terms uttered by an agent ultimately
arises when it actually makes use of these terms in the context of

an interaction. We shall assume, thus, that agents are part of a regulatory environment and follow interaction models, or protocols,
that regulate the utterances allowed or expected at particular dialogue states. One means to specify such regulatory environments
for multiagent systems, for instance, are electronic institutions,
which fix the performative structures of dialogues and the shared
ontology of the content language used in the utterances effectuated by agents, and which take the form of illocutionary speech
acts [22].

In the case that agents do not share the understanding of the
content language, we argue that the regulatory environment in
which the agents unfold their dialogue may provide the grounds
for establishing the semantic relationships between varying local
terminologies. Take again our simple bargaining dialogue and put
yourself in the role of the seller. If the buyer, after the utterance
of the starting price, had answered with an expression that you
did not understand, you would have to guess among the alternatives for possible answers from the buyer regarding your own view
of the interaction, the view of a seller, assuming that the buyer
considers the dialogue to be in the same state. That is, you might
take the foreign expression uttered by the buyer as a counteroffer,
hence establishing a semantic relationship between the expression
you did not know and the expression you were expecting. You
were listening to an utterance made by the buyer in the background of a particular dialogue state. If the buyer now walks away
and does not continue bargaining you realise that he or she considered to have reached a final state in the bargaining dialogue 
maybe because he or she uttered a refusal to accept the price
you said and to continue bargaining  while you considered the
dialogue not to have finished yet. It is this unsuccessful interaction
between you, the seller, and the buyer which indicates that the
semantic alignment of the foreign expression you did not understand with the expression of a counteroffer was not correct. If
the dialogue, however, had reached a final state for both participants in the bargaining interaction, it would be evidence for a correct semantic alignment. This is what
turns the successful
interaction into a prerequisite for shared understanding.

It is the assumption that agents repeatedly engage in dialogues
following a fixed performative structure and that they share a notion of success of the dialogue (for example when reaching a final
state) which allows agents to discover the semantic relationship of
their vocabularies. Semantics is in this view closely tied not only to
the illocutions allowed to be uttered at any particular state of the
interaction, but also to the notion of success: two agents have
understood each other if each one considers that the dialogue
has been completed successfully (such situations should strengthen the semantic alignment choices made during interaction).

1.3. Interaction-situated semantic alignment

In this paper we have set out to investigate to what extent two
agents are capable of aligning their respective local vocabularies without accessing ontologies of foreign agents  assuming that the only
way an agent has access to the vocabulary of another agents ontology
is by being aware of its utterance in the course of an interaction  nor
resorting to any shared ontology or external source that may guide
them in establishing semantic relationships. Instead we rely entirely
on the context provided by the interaction protocol and the concrete
interaction states at which a term is uttered or listened to.

For this we define a means of interaction by which agents follow their own interaction protocol and also an alignment protocol
in parallel. As a start we have focussed on two-agent protocols as
represented by finite-state machines, because this formalism
underlies most dialogue representation frameworks such as the
aforesaid electronic institutions. The alignment protocol acts as a
meta-protocol through which the actual communication is carried

out: any utterance that would have been a speech act at the objectlevel communication becomes ineffective and has an effective
counterpart at the meta-level. Additionally, we endow agents with
a matching mechanism that they use to perform the actual match-
ing. Matching elements are strengthened as many interactions are
completed, and this strengthening is based on statistical reasoning.
Eventually, expressions uttered and listened to by agents are
deemed semantically related if they trigger compatible interaction
state transitions. As content language we have initially constrained
ourselves to a propositional language.

As notion of success we have initially explored a very obvious
one, namely that of reaching a final state in the dialogue. This, of
course, can be made more complex, for example by paying attention to commitments taken during the course of a dialogue and
their posterior fulfilment or not. This, in turn, enriches the semantics implicit in the performative structure of a dialogue.

The initial ideas and a preliminary formalisation of the approach set forth in this paper were published in [23] and a first
set experimentation results were presented in [24]. In this paper,
however, we present the comprehensive description and experimental validation of our approach. For this we have taken a webbased reservation scenario, described in Section 2, as running
example with which to illustrate the key insights of our alignment
technique, which we put forth in Section 3. Section 4 presents the
complete formalisation, whereas Section 5 describes the alignment
dynamics, discussing several alternative matching criteria not
tackled in our initial work.

The theoretical model is not left by itself, and we have carried
out an implementation of the model, showing empirically in Section 6 its effectiveness in establishing the semantic alignment that
arises in the context of an interaction. For this we have generated
interaction protocols of varying complexity in terms of interaction
states and interaction state transitions, and we have let agents
repeatedly interact according to the dialogical structure specified
in these protocols to see how they are capable of bootstrapping a
basic alignment of their vocabularies  of different size and complexity  and hence to improve their success rate while interact-

ing. This confirms and adds to our initial results. We conclude in
Section 8 with some references to related ideas and a discussion
on future research directions.

2. A running example: online travel reservation

Imagine a travel agency that offers facilities to make reservations of flights and hotels. Consider also that this travel agency is
up to date with the new Semantic Web technologies and delegates
to a software agent the task of making reservations. This software
agent is thus programmed to interact with customers  whether
they are human or software agents  and satisfy all their requests.
We will particularly study a scenario where two software agents,
one as travel agent and the other as customer, participate in a travel reservation interaction.

2.1. Interaction models for the travel reservation scenario

Agent interactions can be specified by means of finite state
automata, which is the formalism that we will be using in this pa-
per. This is the way, for instance,
in which particular scenes
(bounded scopes of interactions) are specified for electronic institutions [22]. Fig. 1 depicts the message-passing behaviour of a customer and a travel agent
in a travel reservation scenario.
Transitions between states are labelled with illocution schemata
containing variables written in uppercase letters. Illocutions are
tuples the components of which are an illocutionary particle, the
identifier of the sender together with the role it is playing, the
identifier of the receiver together with the role it is playing, and
the content of the message uttered. The latter is expressed in some
language whose vocabulary is defined in a particular ontology.
During an interaction, the variables in illocution schemata are
bound to the values of the uttered illocutions. Variables get their
values in those illocutions in which they occur preceded by a question mark (?), and these values are subsequently used in those illocutions in which the corresponding variable occurs preceded by an
exclamation mark (!). We call this kind of automaton an interaction

Fig. 1. Interaction model for the customer agent.

M. Atencia, M. Schorlemmer / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 131147

Fig. 2. Interaction model for the travel agent.

model. Certainly, there exist other elements to be considered when
specifying agent interactions (e.g. time stamps), but this simplified
model is adequate for the purpose of this work.

According to Fig. 1, at the initial state s00, the customer is supposed
to send a message to the travel agent requesting either a flight (illo-
cution i1) or an accommodation i2. Each choice triggers a different
interaction. Assume that the customer asks the travel agent to book
a flight, in our terms, the customer sends the following illocution:
i1 14 hrequest;a : customer;b : travel agent; flighti
where a and b identify the customer and travel agent, respectively.
A flight trip may be a return trip or a single trip, and this is
something the customer must be specific about first (via illocutions i3 and i4). Once it is done, the customer is supposed to send
some required information about the desired flight. This information depends on the previous choice. Indeed, if the customer asks
for a single flight, she only needs to provide information about
the departure, but if she asks for a return flight then she needs to
give information about the return too. This information is of a varying nature: origin and destination i5; i6, dates i7; i9, times i8; i10,
and number of passengers i11.

In ontological terms, the travel agent is supposed to build a concept description, e.g., in a description logic, of the flight the customer is looking for with this information; something like
Flight u Return u

origin : Lyon u
destination : Barcelona u
departing : 2011-06-10 u
outboundTime : 18 : 00 u
returning : 2011-06-14 u
inboundTime : 20 : 00 u
numberOfPassengers : 2

(if variable X in i5 is grounded with Lyon, Y in i6 with Barcelona,
etc.).

Once a concept description is built, the travel agent is supposed
to collect all instances that satisfy it. Instances may differ, for
example, over the airline that operates the flight. Let 12a1; . . . ; an
be the resulting list of instances (we can think of ak as a URI which
identifies a flight). The travel agent informs the customer of the result of the search through
i12 14 hinform;b : travel agent;a : customer; results12a1; . . . ; ani

One of the suggested flights may be to the customers liking. If
so, the customer is supposed to inform the travel agent of her
choice i13. If not, she will request a new search i14. The remainder of the interaction involves informing of passenger details,
either accepting or rejecting reservation terms, and committing
to pay a reservation price, among others. The states s18 and s22
are final states. If agents reach s18 then the reservation is unfin-
ished, whereas if they reach s22, it is completed.

Imagine, however, that the customer and the travel agent have
different perspectives of the interaction and follow different interaction models. More specifically, assume that the customer follows
the one depicted in Fig. 1, while the travel agent the one in Fig. 2.
These interaction models differ in both transitions and ontologies.
For instance, while the customer agent uses terms such as return,
single or accommodation, the travel agent uses roundTrip,
oneWay and hotel, instead. In what follows, we present the insights of our approach to semantic alignment.

3. I-SSA insights

We consider a scenario in which two or more agents participate
in an interaction following distinct interaction models. Agents may
misunderstand each other because they do not share the same
ontology, or expect to receive or send messages in different order.

Our approach, called interaction-situated semantic alignment (I-
SSA), looks at the semantics of messages exchanged during an
interaction entirely from an interaction-specific point of view.

3.1. I-SSA principles

The I-SSA approach is founded upon a number of principles.
Here we give an informal account of these principles. A formalisation is provided in Section 4.

Principle 1. Whether to match a foreign term with a local one
depends on the particular interaction state where the former is
received.

This principle stresses the fact that, when an agent receives a
message, this is received in a particular interaction state, and,
regardless of the size of the agents vocabulary, the foreign message is to be matched with one of the local messages that the agent
expects to receive at that state. Imagine that the travel agent receives hrequest;a : customer;b : travel agent; flighti at the initial state t00. According to her interaction model, the travel agent
can only receive two messages at t00: flight and hotel. As a consequence of Principle 1, travel agents decision comes down to
these two options.

Principle 2. Whether to match a foreign term with a local one
depends on the illocutionary force with which the former is
uttered.

Messages arise along with particles that inform of the illocutionary force of their utterance. These illocutionary particles are
typically realised in terms of speech act verbs such as request,
inform or commit, among others. Principle 2 states that, when
matching two terms, their illocutionary particles must be the
same. For example, if it happens that the travel agent receives
hinform;a : customer;b : travel agent; choicei at t13, according
to Principle 2, choice cannot be matched with newSearch, since
the latter can only arise within an illocution with request as illocutionary particle.

These first two principles state compatibility between illocutions and rule step-by-step matching decisions. However, only if
agents succeed to interact, matching decisions prove to be valid,
and matched terms to be semantically related. Principle 3 synthesises the reverse of this statement.

Principle 3. Two terms are semantically unrelated if whenever they are matched agents interact unsuccessfully.

The above principle highly depends on when an interaction is
qualified as successful. One possibility is to consider an interaction to be successful as long as agents eventually jointly reach final
states. The following is thereby a more specific version of Principle
3.

Principle 3. Two terms are semantically unrelated if whenever they are matched agents do not eventually jointly reach
final states.

Let

us

the

travel

that

imagine

receives
agent
hrequest;a : customer;b : travel agent; flighti at
the initial
state t00. Neither Principle 1 nor Principle 2 are helpful for the travel agent to decide whether to match flight with her local message flight or hotel. Only the subsequent interaction unfolding
will show which matching decision leads agents to jointly reach final states.

These three principles are the basis for an interaction-situated
semantic alignment. For the purpose of this work, Principle 3* is
satisfactory, since it establishes a minimal requirement for an
interaction to be successful. Other more sophisticated versions of
Principle 3 can be proposed, though, and any new extension will
yield a different semantic alignment.

3.2. Global interaction

If the customer and travel agent interact by message passing,
another interaction unfolds. This contains more detail than the
ones specified in Figs. 1 and 2 which only capture a partial view
of the actual global interaction, namely, the view from the perspective of the customer and the travel agent, respectively. A global
interaction model matches all messages occurring in compatible
illocutions of agent interaction models, where compatibility is
based on Principles 1 and 2.

Actually, neither agent needs to be aware of the model followed
by the other for the interaction to unfold correctly in its totality. In
general, two (or more) agents are capable to interact following separate interaction models if their states are assumed to be projections of states of a global interaction  which, in general, is not
known to each of the agents  and each state transition that separate agents follow when an illocution is uttered has a corresponding state transition in the global interaction. In order for this to
happen, an alignment protocol is proposed in Section 5.1. Nonethe-
less, the global interaction model itself is helpful from a theoretical
point of view as it allows us to define the I-SSA semantic align-
ment. In Section 4.2 we give a formal account of the global interaction model through the idea of a product of interaction models,
which we call the communication product.

3.3. What is shared?

Even though we do not assume agents to share any ontology,
agents must agree on the following in order for I-SSA to be
effective.

A common language of illocutionary particles

These are typically realised in terms of speech act verbs, the
number of which can be taken as reasonably low. Wierzbickas dictionary is a remarkable effort to define a semantic dictionary of
English speech act verbs. It contains definitions of 250 speech act
verbs [25]. KQML contains no more than 35 performatives [26].

A family of roles

Senders and recipients of messages must be identified. This is
usually done by means of agent identifiers and roles, and, for this
reason, agents must share a collection of roles.

A content language

Although agents ontologies may be different, we assume that
agents agree on a language with which the content of illocutions
is expressed. This language is generally as expressive as first-order
logic, but we shall treat messages as propositions, that is, as
grounded atomic sentences, leaving the generalisation to first-or-
der sentences for future work.

M. Atencia, M. Schorlemmer / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 131147

An alignment protocol

This protocol will help agents resolving semantic mismatches. It
makes use of a minimal set of terms the semantics of which is also
assumed to be agreed by all interacting agents.

4. I-SSA formalisation

We model a multiagent system as a set MAS of agents. Each agent
in MAS has a unique identifier and may take one (or more) roles in
the context of an interaction. Let Role be the set of roles and Id the
set of agent identifiers. We write id : r, with r 2 Role and id 2 Id,
for the agent in MAS with identifier id playing the role r.

Each agent is able to communicate by sending messages from a
set M, which is local to the agent. We assume that a set IP of illocutionary particles is shared by all agents.

: r0; mi with i 2 IP, m 2 M, and id : r;id0

Definition 1. Given a non-empty set M of messages, the set of
illocutions generated by M, denoted by IM, is the set of tuples
hi; id : r;id0
: r0 agents
such that id  id0.
sender of u and id0
id0

If u 14 hi;id : r;id0
: r0i and m are called the head and content of u, respectively.

: r0; mi is an illocution then id : r is the
: r0 is the receiver of u. In addition, hi;id : r;

4.1. Interaction models

We model an interaction model as a (partial) deterministic fi-
nite-state machine whose transitions are labelled either with illo-
cutions, or with special transitions such as, e.g., timeouts, or null
transitions (k-transitions), which prompt state changes without
message passing.

Definition 2. An interaction model is a tuple IM 14 hQ ; q0; F; M; C; di
where:

 Q is a finite set of states,
 q0 2 Q is a distinguished element of Q called the initial state,
 F is a non-empty subset of Q whose elements are called final

states,

 M is a finite non-empty set of messages,
 C is a finite set of special transitions, and
 d is a partial function from Q 
 IM [ C to Q called the tran-

sition function.

Remark. Although not explicitly stated in Definition 2, for theoretical reasons we take for granted that every interaction model contains a special transition e such that dq; e 14 q for all q 2 Q.

Given an interaction model IM 14 hQ ; q0; F; M; C; di, we denote by
IIM (or simply I) the subset of IM made up of all the illocutions
present in IM, i.e., all the illocutions that appear in elements of the
domain
automaton,
AutIM 14 hQ ; q0; F; R; di, where R 14 I [ C.

associated with

IM is

of

d.

an

Example. As hinted before, all messages will be treated as
grounded atomic sentences. If we replace illocutions in Fig. 1 with
the ones bellow (not all are included), we obtain an interaction
model as in Definition 2 and similarly for Fig. 2. From here on these
will be the automata under consideration.
i1 14 hrequest;a : customer;b : travel agent; flighti
i2 14 hrequest;a : customer;b : travel agent; accommodationi
i3 14 hinform;a : customer;b : travel agent; returni
i4 14 hinform;a : customer;b : travel agent; singlei

i5 14 hinform;a : customer;b : travel agent; origini
i6 14 hinform;a : customer;b : travel agent; destinationi
i7 14 hinform;a : customer;b : travel agent; departingi
i8 14 hinform;a : customer;b : travel agent; outboundTimei
i9 14 hinform;a : customer;b : travel agent; returningi
i10 14 hinform;a : customer;b : travel agent; inboundTimei
i11 14 hinform;a : customer;b : travel agent; numberOfPassengersi
i12 14 hinform;b : travel agent;a : customer; resultsi

4.2. The communication product

We shall use the algebraic product of two interaction models in
order to capture all possible interactions between agents. In gen-
eral, a product of two objects is the natural algebraic construction
that represents all possible behaviours of the combination of these
two objects. The communication product (CP) defined below, thus,
captures the global interaction with respect to the message-pass-
ing behaviour of agents of two interaction models. It is not an
unconstrained product, as it considers compatibility of illocutions
in terms of illocutionary particles, senders, and receivers. In category theory a constrained product is called a pullback [27]. Theorem 1 states that the communication product is a pullback in the
natural category of interaction models.

Definition 3. Let IMi 14 hQ i; q0
i ; Fi; Mi; Ci; dii i 14 1; 2 be two interaction models. The communication product of IM1 and IM2, denoted
by IM1 
 IM2, is the interaction model hQ ; q0; F; M; C; di where:

 Q is the Cartesian product of Q 1 and Q 2, that is, the states in Q
are all possible ordered pairs hq1; q2i with q1 2 Q 1 and q2 2 Q 2,
 the initial state q0 is the pair hq0
2i,
1; q0
 F is the Cartesian product of F1 and F2,
 M is the Cartesian product of M1 and M2,
 C is the Cartesian product of C1 and C2,
 d is defined as follows: hq0
1; q0
: r0;hm1; m2ii and
i 14 diqi;hi; id : r;id0
: r0; mii or
q0
i 14 diqi; ci for i 14 1; 2.

 r 14 c1; c2 and q0

2i 14 dhq1; q2i; r if

 r 14 hi;id : r;id0

Remark. Notice that, according to the definition of d, e 14 he1; e2i is
such that dhq1; q2i; e 14 hq1; q2i for all hq1; q2i 2 Q 1 
 Q 2. Addition-
ally, special transitions of IMi are paired with ej of IMj (i  j). In this
way, we capture the idea that, although the global interaction state
changes, this may not be the case for one of the interaction models.

Example. The communication product of the interaction models
for the roles of customer and travel agent is partially depicted in
Fig. 3. For instance, there exists an arc from state hs00; t00i to state
hs02; t02i labelled with
k4 14 hrequest;a : customer;b : travel agent;
haccommodation; hotelii

This is due to the fact that (i) there is an arc from the state s00 to

the state s02 labelled with
i2 14 hrequest;a : customer;b : travel agent; accommodationi

in the customers interaction model, (ii) there exists an arc from t00
to t02 labelled with
j2 14 hrequest;a : customer;b : travel agent; hoteli
in the travel agents interaction model, and (iii) the two illocution
heads match up. Although not shown, this path leads to a final state.

for

: r0; mi,

: r0; mii 14 hi;id : r;id0

Let fi : IMi ! IM (with i 14 1; 2) defined by fiqi 14 q for qi 2 Q i,
fihi; id : r;id0
hi;id : r;
id0
: r0; mii 2 Ii while fici 14 e for each ci 2 Ci. It is straightforward to prove that fi i 14 1; 2 is a morphism of interaction models.
In the remainder of the proof we show that IM1 
 IM2 is a pullback
of the arrows f1 and f2 (see Fig. 4).
Let hi : IM1 
 IM2 ! IMi i 14 1; 2 be defined as the projection on
is, hihq1; q2i 14 qi; hihi;id : r;id0
: r0;hm1; m2ii 14
states,
that
hi;id : r;id0
: r0; mii, while hihc1; c2i 14 ci. hi is a morphism of
interaction models and f1h1 14 f2h2. Now, let us assume that there
exist two morphisms #1 and #2; #i : IM ! IMi i 14 1; 2, such that
f1#1 14 f2#2. We must prove that there exists a unique morphism
n : IM ! IM1 
 IM2 such that #i 14 hin. First of all, let us define
nq 14 h#1q; #2qi on the states of IM. Secondly, given an illocution
u of IM, the fact that f1#1 14 f2#2 ensures that #1u and #2u have
the same illocution head. Then we can write #iu 14 hi;id : r;
id0
: r0;
hm1; m2ii, and nc 14 h#1c; #2ci for each special transition c of
IM. It is straightforward to prove that n is a morphism of interaction
models, and also that n is the unique morphism in such
conditions. h

: r0; mii. Accordingly, we define nu 14 hi;id : r;id0

Fig. 3. Partial description of the communication product in the travel reservation
scenario.

Notice also that the term accommodation is paired with flight in
illocution k3. This path, though, does not lead to a final state.

4.3. A categorical characterisation of the communication product

As hinted at the beginning of Section 4.2, there exists a natural
categorical characterisation of the communication product.
In
what follows we define the category of interaction models and
prove that the communication product is a pullback in this
category.

Definition 4. Let IMi 14 hQ i; q0
i ; Fi; Mi; Ci; diii 14 1; 2 be two interaction models. A morphism of interaction models f : IM1 ! IM2 is a
pair of functions f 14 hg; hi, where g : Q 1 ! Q 2 and h : R1 ! R2,
such that:

1 14 q0

2 and gF1 # F2,

 gq0
 hI1 # I2, hC1 # C2 and he1 14 e2,
 gd1q1; r1 14 d2gq1; hr1 for all q1 2 Q 1 and r1 2 R1.
From here on, if f 14 hg; hi is a morphism of interaction models, we
use f both applying on states and transitions, providing that no confusion arises. Hence fq and fr replace gq and hr, respectively.

Definition 5. The category of interaction models IM has interaction models as objects, and morphisms of interaction models as
arrows. Both composition law and identity are defined in the
natural way.

Theorem 1. The communication product is a pullback in the category
IM.

Proof. Let IM be the interaction model with q and m as the only
state and message, respectively, and transition function d defined
as follows:
dq;hi;id : r;id0
for all hi;id : r; id0

: r0; mi 14 q
: r0; mi 2 Ifmg.

Fig. 4. Pullback diagram.

4.4. Semantic alignment through the communication product

Being a model of all compatible agent interactions of varying
interaction models, the communication product is the place to look
at if we want to define the I-SSA semantic alignment. From a theoretical viewpoint, in order to establish semantic relations among
messages, we examine the language generated by the communication product. This formally synthesises Principle 3 explained in
Section 3.1. Thus messages of different interaction models are
semantically related if they are paired in illocutions whose utterance makes the interaction reach a final state (that is, makes the
interaction successful) according to the global interaction determined by the communication product. This is formally given be-
low. We use v to denote subsumption of messages, while t to
denote disjunction. Semantic equivalence between messages, denoted with , arises when they subsume each other. We also pair
messages with natural numbers to keep syntactically identical
messages separate, since they may not be semantically equivalent.
i ; Fi; Mi; Ci; dii (with i 14 1; 2) be two

Definition 6. Let IMi 14 hQ i; q0
interaction models. Let m 2 M1 and m1; . . . ; mn 2 M2. We write
h1; mi v h2; m1i t 			 t h2; mni
if
if
hi;id : r; id0
for some
k 2 f1; . . . ; ng. If such m1; . . . ; mn 2 M2 do not exist, we simply write
h1; mi v ?
We define h2; mi v h1; m1i t 			 t h1; mni analogously.

: r0;hm; m0ii appears in x then m0 14 mk

for all strings x accepted by the product

IM1 
 IM2,

M. Atencia, M. Schorlemmer / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 131147

It is possible to establish relations amongst messages with re-

spect to a specific illocution particle.

Definition 7. Let IMi 14 hQ i; q0
i ; Fi; Mi; Ci; dii (with i 14 1; 2) be two
interaction models. Let m 2 M1 and m1; . . . ; mn 2 M2. Let i0 2 IP.
We write
h1; mi vi0 h2; m1i t 			 t h2; mni
if
if
hi0;id : r;id : r0;hm; m0ii appears in x then m0 14 mk
for some
k 2 f1; . . . ; ng. If such m1; . . . ; mn 2 M2 do not exist, we simply write
h1; mi vi0 ?
We define h2; mi vi0 h1; m1i t 	 		 t h1; mni analogously.

for all strings x accepted by the product

IM1 
 IM2,

The semantic alignment is made up of all these expressions (Def-
initions 6 and 7). It represents the formal synthesis of I-SSA
principles.

Example. The semantic relations among the customers and travel
agents messages are enumerated in Fig. 5. Only the semantic
alignment that corresponds to Definition 6 is shown, as the other
one is analogous.

Far from making a thorough numerical analysis, we have set I-SSA
against three state-of-the-art ontology matchers, namely, COMA++
[28], Falcon-OA [29] and OLA [30], in order to highlight more qualitative differences. For this, we have designed two ontologies that
conform to more complex versions of the interaction models presented in this paper and launched the three matchers. For a fully
description of this scenario we refer the reader to [31].

As an example, the three matchers failed to match accommodation and hotel. OLA and COMA++ (with a node strategy) returned
the equivalence of classes Accommodation  Account with confidence values 0.38 and 0.23, respectively, whereas Falcon-OA returned no relation involving any of these terms. In the extended
version of the travel agents interaction model, the travel agent
suggests the customer to create an account before informing the
customer of the rules and restrictions. Thus, the above equivalence
could have never be returned by I-SSA as accommodation and account come along with distinct illocutionary particles (inform and
suggest). Moreover, they cannot be uttered in concurrent interaction states.

Particularly, OLA resorts to WordNet [32] in order to discover
semantic relations. Nonetheless, there is no apparent relationship
between the synsets of the words hotel and accommodation.
They actually become related within this specific interaction.

4.5. Interaction vs. non-interaction-situated semantic alignment

5. I-SSA dynamics

The characteristics of I-SSA become more apparent if we compare it with matching techniques that are not interaction-situated.

Fig. 5. Semantic alignment in the travel reservation scenario.

As mentioned before, interaction models specify the space of
interactions that are allowed, and their communication product
captures the entire space of actual interactions when combining
particular ones. The semantic relations defined above are those
justified by the entire space of actual interactions. This product,
though, may not be accessible to agents. This is the case when
interaction models are not completely open for inspection, be-
cause, for example, they are based on commercially confidential
information, so agents are only aware of their local ones. Further-
more, interaction models can be of a size that computing the product becomes a high time and memory consuming task.

It is necessary to provide agents with a mechanism to discover
the above semantic relationships while interactions unfold  in
the kind of manner as intuitively described for our example above
 assuming that for all agents participating in the interaction, the
state they perceive stems from the actual global state (in other
words, their locally managed states are projections of the actual
global state), and this occurs throughout the entire interaction.

5.1. The alignment protocol

Let us consider a scenario where two agents A1 and A2, identified with id1 and id2, try to interact following (possibly distinct)
interaction models IM1 and IM2, respectively. Let us assume that
no other agents will take part in the interaction according to IM1
and IM2.

With agents knowing that they follow different interaction
models and that semantic mismatches are likely to occur, communication requires to be done at another level. For this reason we define an alignment protocol that acts as a meta-protocol that links
agents interaction models. The alignment protocol (henceforth
AP) is depicted in Fig. 6.

There are four states: the initial state q0, an intermediate state
q1, and two final states by name of letters s and u. These last ones
are the initial letters of the words successful and unsuccessful: if the
meta-level state s is reached, whatever path is followed, the objectlevel interaction is considered successful, otherwise unsuccessful.
In this sense, we distinguish for the moment only between two
kinds of interactions.

is considered semantically different from all local ones. The
key is that v is to be mapped with one of those messages
Ai expects to receive at state qi in the IMi context (Principle
1 stated in Section 3.1). Moreover, we can make a selection
and consider those messages contained in illocutions whose
head is equal to that of u (Principle 2 along with agent iden-
tification). In this way, Ai is to choose an element from the
following set:
D 14 fw jhi;idj : r;idi : r0; wi 2 domdiqi;	g
There are two possibilities: either D is empty or not.
(a) As long as D is not empty, Ai can select an element w of D
by making use of the matching mechanism explained in
i 14 diqi; w, where
Section 5.1.2. So qi becomes q0
w 14 hi;idj : r;idi : r0; wi.

(b) If D is empty, v cannot be matched. The interaction is
considered unsuccessful. Ai is to send a failure message
to Aj by uttering hinform;idi : algn;idj : algn;failurei
which matches with the illocution scheme d. Thus q0
becomes u in the AP context.

AP.4 If qi is a final state and Ai considers the interaction to be
finished, she can send the illocution hinform;idi : algn;
idj : algn;final statei to Aj, which matches with the illocution scheme a. Thus q0 turns to q1, and Aj is supposed to
ground b or c, either confirming or denying the completion
of the interaction, respectively. Grounding b makes agents
to reach the final state s, and the interaction is considered
successful; c, however, leads to an unsuccessful interaction.
AP.5 Finally, we have to take into account the possibility of a
deadlock. This is the case when, for example, successive
mappings have led the agents to states where both of
them only await messages. To avoid deadlocks,
the
special transition timeout is linked to the initial state q0
in AP. If a specific period of time is exceeded, this transition leads agents to finish the interaction, which is
unsuccessful.

5.1.2. The matching mechanism

As mentioned above, a matching mechanism is called whenever
a message is received. In a nutshell, it is based on three assertions:

 every foreign message is associated with a categorical variable
ranging over local messages, and a variable assignment represents a matching element;

 the matching mechanism computes frequency distributions of
all these variables on the basis of past successful interactions;
these

 matching decisions are determined by virtue of

distributions.

and

Past

frequency

information: histories

5.1.2.1.
distribu-
tions. Whenever an interaction is successfully performed, agents
record relevant information that will be helpful in future interac-
tions. This information is revealed in terms of histories that gather
all past matching decisions. These histories increasingly enlarge
the population on which a statistical reasoning for forthcoming
matching decisions will be based. Below we explain both statistical
updating and matching decisions in detail.

Agents build histories while interacting with the help of the
alignment protocol. Specifically, a history is a sequence of the form:
h 14 q0
computed recursively as follows:

i ; . . . ; qk1

i ; . . . ; qn1

i ; r1

i ; q1

i ; qn

i ; qk

; rn

; rk

 q0
 12u; q0

i is the initial state of IMi, and

i is queued in h if Ai is in case AP.1,

Fig. 6. The alignment protocol.

Regarding transitions, they are all listed below the figure except
one that has a special status. Note that agents can only adopt one
role, namely, the role of aligner (algn). There exist two sorts of
messages: failure and final_state. The former can be tagged
with the illocutionary particle inform, and the latter with inform,
confirm and deny.

The following illocution scheme links agents interaction mod-

els with the alignment protocol:

hutter;?X : algn;?Y : algn; ?Ii
Above X and Y are identifier variables, while I is an illocution vari-
able. Thus (1) can be seen as a meta-illocution, since its content is
also an illocution. It is grounded with illocutions of the form
hutter;idi : algn; idj : algn; ui, where u 14 hi;idi : r;idj : r0; vi
is an illocution of agent Ais interaction model IMi. The sender and
receiver of u must be equal to the instantiations of X and Y, respec-
tively. Further, let us stress that u has to come from the interaction
model associated with Xs instantiation. Consequently, the choice of
utter as illocutionary particle seems natural, as it expresses the
senders attitude with respect to its own interaction model: if Aj receives hutter;idi : algn; idj : algn; ui, Aj can safely assume that Ai
has decided to utter u according to IMi. In the following section
the dynamics of the alignment protocol is thoroughly explained.

5.1.1. Alignment protocol dynamics

Each agent is guided by both the alignment protocol and its
interaction model, whilst effective communication is done through
the former. When agents initiate an interaction, both of them are in
state q0 with respect to AP. Also Ai is in state q0
i with respect to IMi
i 14 1; 2. In order to cover all cases, let us assume that Ai is in an
arbitrary state qi 2 Q i. There are several possibilities:
AP.1 Ai decides to utter u 14 hi;idi : r;idj : r0; vi in the IMi con-
text, with u 2 diqi;	.1 The communication act is carried out
via
the meta-illocution
hutter;idi : algn;idj : algn; ui to Aj. The state remains the
i 14 diqi; u in
same in the AP context, whereas qi turns to q0
the IMi context.
AP.2 Ai prompts a state change by a special transition ci 2 Ci in
i 14 diqi; ci. This action is
the IMi context. Thus qi turns to q0
not reflected in AP since it does not involve any communication act.

AP.3 Ai receives hutter;idj : algn;idi : algn; ui in the meta-level
AP, with u 14 hi;idj : r;idi : r0; vi. Recall that from Ais
point of view v is a foreign message, and, for this reason, it

sends

agent

AP:

Ai

1 diqi; 	 is the function defined from Ri 14 Ii [ Ci to Q i in the natural way.

M. Atencia, M. Schorlemmer / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 131147

i is queued in h if Ai is in case AP.2,

 12ci; q0
 12hi;idj : r;idi : r0;12v=wi; q0
 qn

i is a final state of IMi.

i is queued in h if Ai is in case AP.3.a,

Notice that unsuccessful interactions are not considered. It is
not so easy to find out which particular matching is responsible
for a failure, or if we should blame one agent or another for a
wrong matching decision. For the purpose of this work we only
consider successful interactions and leave the study of unsuccessful interactions for future research.

Let H 14 fhkgn

In order to make the notation clearer, we will dispense
with subscripts. So we have two agents A and B,
identified
with a and b, and associated with interaction models IMa
and IMb.

k141 be the sequence of all past successful histories reported by agent A so far. Notice that it may happen
hk 14 hl for 1 6 k; l 6 n and k  l. If this is the case, as far as
agent A is concerned, there is no other distinction between hk
and hl but time occurrence. Now, from all information contained
in these histories, we will particularly pay attention to those
pairs of the form
p 14 hq;hi;b : r;a : r0;12v=wii

where hi;b : r;a : r0; 12v=wi comes straight after the state q in (at
least) one history of H. The reader should think of p as follows: at
some point
in the past and having received the illocution
hi;b : r;a : r0; vi at state q, agent A decided to match message v
with the local message w.

Forthcoming matching decisions will be based on successful
past matching decisions, represented by pairs as p in (2). Henceforth we will refer to these pairs with the abbreviation pmd (past
matching decision), or pmd on v if we want to specify the matched
message.

Assume that agent A received v in the past. Let us consider the
multiset (or bag) Pv of all pmd on v that appear in H (indeed, there
may be more than one occurrence of the same pmd). Pv 14 hPv ; pvi
where Pv is the underlying set of elements and pv : Pv ! N is the
multiplicity function. For the task at hand, message v will be treated as a statistical variable V : Pv ! Ma, where Ma is the set of As
local messages and V is defined in the natural way. If v turned
out to be matched with w 2 Ma (in other words, w is a member
of the range of V), the frequency associated with w is:

Vp14wpvp

pvp

FV 14 w 14

where summations range by default over p 2 Pv. There is another
attribute of the elements of Pv which is worth studying.
If
IP : Pv ! IP is defined in the natural way,
FV 14 wjIP 14 i 14

Vp14w;IPp14ipvp

IPp14ipvp

If H 14 fhkgn

We will make use of the symbol F v when referring to this
frequency distribution.
k141 is the resulting history
recording of n P 1 interactions with agent B, then H generates
a family of frequency distributions F 14 fF vgv2X, where X is
the set of all Bs messages received by A so far. At whatever time
a new interaction is successfully completed, F has to be
updated.

In principle, v 0 could be matched with any w 2 D, but this can be
refined. Let us distinguish between two cases: A has information
about past successful interactions with B that involve v0 or not.
In the case of no information, we let agent A to choose a mesif D 14 fw1; . . . ; wng,
sage w0 2 D randomly. More specifically,
w0 2 D is chosen with probability p 14 1
n. If agent A has information
about former successful interactions, this will become available in
terms of frequency distributions, F 14 fF vg, as we have already ex-
plained. If it so happens that F v0 2 F then agent A can benefit from
this information when making a matching decision on v0. One first
idea is to choose a local message w0 such that
FV 0 14 wjV 0 2 D 6 FV 0 14 w0jV 0 2 D
for every w 2 D. This leads us to the following criterion.

First Matching Criterion (maximal frequency criterion)
if F v0 2 F then

choose w0 2 D such that
FV 0 14 wjV 0 2 D 6 FV 0 14 w0jV 0 2 D
for all w 2 D

else

end if

choose w0 2 D with probability p 14 1

This criterion highly depends on how rich the frequency distributions are. If there is not much information about past interac-
tions, though, it does not make sense to fully rely on a matching
element with maximal frequency. As an alternative, we propose
fwi; pign
to
i141 where
pi 14 FV 0 14 wijV 0 2 D, and choose wi with probability pi.

distribution

probability

take

the

Second Matching Criterion (probability criterion)
if F v0 2 F then

choose w0 2 D with probability

p 14 FV 0 14 w0jV 0 2 D

else

end if

choose w0 2 D with probability p 14 1

Neither the maximal frequency criterion nor the probabilitybased one allow to discover new matching elements. In order to
overcome this we put forward a last criterion which consists in
contaminating the previous distribution with a discrete uniform
distribution (the contamination parameter s 2 0; 1 is usually a
number close to 1).

Third Matching Criterion (contaminated probability criterion)
Require: s 2 0; 1, s  1

if F v0 2 F then

choose w0 2 D with probability

p 14 s 	 FV 0 14 w0jV 0 2 D  1  s 	 1

choose w0 2 D with probability p 14 1

else

end if

The three matching criteria described above can be further refined by truncating with the event fIP 14 ig where i is the illocutionary particle of u.

5.2. Semantic alignment through the alignment protocol

5.1.2.2. Matching criteria. In this section we explain the reasoning
followed by agents when facing matching decisions. Imagine that
A receives u 14 hi;b : r;a : r0; v0i from B at state q 2 Q a. Let us
consider the set D defined in case AP.3.a:
D 14 fw jhi;b : r;a : r0; wi 2 domdaq;	g

The alignment protocol described in Section 5.1 helps agents to
interact successfully. The more interactions are completed, the
more messages become related. In what follows, we firstly pin
down these semantic relationships in a logical fashion, and then
expound the link with the semantic alignment deduced from the
communication product by means of Theorem 2.

Assume that agent Ai i 14 1; 2 has generated a family F of frequency distributions, and let v 2 Mj (j  i) for which F v 2 F . If
w 2 Mi is such that t 14 FV 14 w  0, we write
hj; vi v hi; wi12t
Additionally,
write
hj; vi vi hi; wi12t. In both cases, t 2 0; 1 can be seen as a confidence
degree of the subsumption.

t 14 FV 14 wjIP 14 i  0,

when

we

The way the alignment protocol is designed ensures the following  which has a clear counterpart regarding illocutionary
particles.

Theorem 2. Let us assume that hj; vi v hi; w1i t 	 		 t hi; wni
belongs to the semantic alignment drawn from the communication
product of the interaction models IM1 and IM2. If hj; vi v hi; wi12t is
computed through the alignment protocol, w 14 wk
some
k 14 1; . . . ; n.

for

The communication product then represents a boundary of the
semantic alignment that agents can reach through the alignment
protocol.

v hb; myFlighti12r1
v hb; myHoteli12r2

Example. With the help of the alignment protocol, the travel agent
is able to compute, among others, the following semantic relations:
ha; flighti
v hb; flighti121:0
ha; accommodationi v hb; hoteli121:0
ha; choicei
ha; choicei
with r1  r2 14 1. The customer can compute, among others, the
following:
hb; flightOutcomei
hb; hotelOutcomei
hb; flightSummaryi
hb; hotelSummaryi

v ha; resulti121:0
v ha; resulti121:0
v ha; reservationSummaryi121:0
v ha; reservationSummaryi121:0

6. Experimentation

Section 4 includes a formalisation of I-SSA whereas Section 5
comprises the description of an alignment protocol agents can follow to put I-SSA into practice. Here we present and analyse experimental results.

We set out to answer two research questions:

1. Is there a gain in communication accuracy  measured in the
number of successful interactions (interactions reaching a final
state)  by repeated semantic alignment through a meta-level
alignment protocol and use of a matching mechanism?

2. If so, how many repeated interactions between two agents are
needed in order to get sufficiently good alignments  measured
in the probability of a successful interaction?

The experimentation design opens the section followed by a
presentation of its execution and evaluation. A thorough statistical
analysis completes it.

6.1. Experimentation design

In this section the experiment design is explained. The alignment protocol is implemented in SICStus Prolog Release 4.0.7
[33] and random operations are executed with the SICStus Prolog
random library.

In order to overcome the lack of sufficiently complex examples
on which to run our implementation, we have proceeded as fol-
lows. First, an abstract alphabet made up of arbitrary illocutions
and special transitions is generated. Second, a regular expression
is built upon this alphabet and a previously fixed number of Kleene
star, concatenation and alternation operators. Finally, the regular
expression is compiled into an automaton  not necessarily minimal  making use of the FSA utilities toolbox [34]. This process is
illustrated in Fig. 7. Table 1 shows the variables considered in this
process and the range of values they may take.

Table 1
Relevant variables when generating abstract interaction models (N stands for the set
of all positive integers, and N0 for the set of non-negative integers, i.e., N0 14 N [ f0g).

Name

Variable

Range

No. of illocutions
No. of illocutionary particles
No. of roles
No. of messages
No. of special transitions
No. of Kleene star operators
No. of concatenation operators
No. of alternation operators

Nill
Nip
Nrole
Nmsg
Nspt
Nstar
Ncon
Nalt

N0
N0
N0
N0

In order to execute the simulations we first had to give values to
the variables above. Nonetheless, there was no need to choose
bounds for the number of illocutions Nill as we can always find lower and upper bounds in terms of the rest of variables. It is easy to
prove that Nill has this lower bound:

Nrole

Nill P max Nip; Nmsg;

Indeed we must have more illocutions than illocutionary particles,
otherwise some of them would be discarded, ditto messages and
roles (recall that each illocution has two roles, namely, the senders
and receivers roles).

Before presenting an upper bound for Nill, we need to explain
how regular expressions are built. It is straightforward to check
that any expression of n binary operators  concatenations and
alternations  has less than n  1 distinct alphabet symbols (the
number of Kleene star operators is not relevant in this regard). In
our case, these symbols may be illocutions or special transitions.
If ncon and nalt are the number of concatenation and alternation
operators included in a regular expression r, respectively, then

Fig. 7. Process of generating abstract interaction models.

M. Atencia, M. Schorlemmer / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 131147

Table 3
Generated interaction models.

imodel1

imodel2

imodel3

imodel4

imodel5

Nill
Nip
Nrole
Nmsg
Nspt
Nstar
Ncon
Nalt

matching criteria, we computed the ratio of failures to interactions,
that is, R 14 F
N.

Experiment 1 was performed on the basis of five interaction
models of varying complexity. Table 3 presents the parameter
choices.

The results of Experiment 1 are shown in Fig. 9. All the matching criteria did better than the case of no update of frequency dis-
tributions. This gives support to a positive answer to Research
Question 1 stated at the beginning of this section. Furthermore,
the ratio of failures to interactions approaches 0:0 in all interaction
models but imodel1. It is not surprising as in this case Nip 14 1. How-
ever, the amount of illocutionary particles is greater in imodel5
where even the alignment protocol itself without updating frequency distributions guaranteed a low number of failures. We will
take up this issue again in Section 6.3. Regarding the comparison of
matching criteria, both the maximal frequency criterion and the
probability criterion performed better than the contaminated
probability criterion as expected. The first did slightly better than
the second, specially after a number of interactions.

In Experiment 2 we simulated two agents interacting as in the
former so as to compute an alignment, again in series of N 14 2n
interactions, n 2 121::10. Only the contaminated probability criterion was applied. Later this alignment was used by agents to interact 50 times with no update of frequency distributions and
applying the maximal frequency criterion. This time we recorded
the ratio of successes to interactions, i.e., R 14 S
50.

Fig. 10 shows the results of Experiment 2 with the same five
interaction models. In all the cases the ratio R approaches 1.0. In
fact, no more than 256 interactions were needed to obtain a
semantic alignment that ensured a probability close to 0.8 to interact successfully. This answers research question 2.

6.3. Statistical analysis

When we look at the experimental results presented in Section 6.2, two natural questions arise: do all parameters influence
the final result? and, if so, what is their influence? Which values
do better for the parameters?

In order to answer these questions, Experiment 1 was executed
on the basis of a factorial generation of interaction models. The
matching criterion applied was the contaminated probability criterion s 14 0:1. We performed a statistical analysis of the resulting
experimental data by combining analysis of variance (ANOVA)
with post-hoc comparisons using the so-called Tukey test [39].
The first is useful to discover whether there was a significant relation between the independent variables  parameters in the simulation  and the dependent variable  ratio of failures to
interactions. The second is helpful to find out which values did better for each of the independent variables.

For ANOVA test results to be reliable, a number of conditions
must be satisfied. One refers to independence in the sample. This
led us to modify the input parameters, since restrictions (3) and
(4) explained in Section 6.1 violate the required independence.

Fig. 8. Tree representation of r 14 r

1  r2 	 r
3.

there exist ncon  nalt  1 placeholders in r to be filled with alphabet
symbols. These correspond to leaves in a tree representation of the
regular expression (see Fig. 8). In our implementation, operators
are randomly chosen, and placeholders are randomly filled with
either illocutions or special transitions.

Let us represent by Nleaf the number of leaves of a regular
Since

implementation.

built

with

our

expression
Nleaf 14 Ncon  Nalt  1 we have:
Nill  Nspt 6 Ncon  Nalt  1

max Nip; Nmsg;

Nrole

while putting together (3) and (4):

6 Nill  Nspt 6 Ncon  Nalt  1

Thus, Nill is lower and upper bounded if we give values for the variables Nip; Nmsg; Nrole; Nspt; Ncon and Nalt.

Table 2 summarises the ranges of the variables taken into account in our simulations. We have chosen upper bounds that cover
interaction models that have been actually deployed in several regulated environments (see, e.g., [3538]). Notice that Nill is not included this time in Table 2.

Table 2
Ranges of relevant variables when generating interaction models.

Name

No. of illocutionary particles
No. of roles
No. of messages
No. of special transitions
No. of Kleene star operators
No. of concatenation operators
No. of alternation operators

6.2. Execution and evaluation

Variable

Nip
Nrole
Nmsg
Nspt
Nstar
Ncon
Nalt

Range
121::15
121::15
121::100
120::5
120::100
120::100
120::100

Recall that in our model agents consider all foreign messages
semantically different a priori, even if they match syntactically local ones. It justifies our decision to let agents follow the same interaction model, since agents will deal with this situation as if they
conform to disparate models.

Two experiments were performed. In Experiment 1, we simulated two agents interacting via the alignment protocol and taking
decisions in accord with the first, second and third matching criteria (with contamination factor s 14 0:1), and also without applying
the matching mechanism (no update of frequency distributions).
Matching criteria were conditional to fIP 14 ig.
We ran our implementation in series of N 14 2n interactions,
n 2 121::10 (so the maximum number of consecutive interactions
was 1024). Each of the series was completed 50 times, each time
counting the number of failures and finally calculating the average
F 14 FN. In order to compare the performance of the different

M. Atencia, M. Schorlemmer / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 131147

imodel1

imodel2

matching1
matching2
matching3
no updating

interactions

imodel3

interactions

imodel4

interactions

interactions

imodel5

interactions

Fig. 9. Results of Experiment 1.

M. Atencia, M. Schorlemmer / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 131147

0.05, which is the standard threshold for statistical significance
tests. Therefore the ANOVA tests confirmed (or did not refute).

Hypothesis 1. The following factors affect the number of failures:

1. the variety of illocution heads,
2. the amount of local messages,
3. the structure of interaction models, and
4. the number of interactions.

imodel1
imodel2
imodel3
imodel4
imodel5

One also expects the hypothesis below to be confirmed.

Hypothesis 2. The following imply a lower number of failures:

interactions

Fig. 10. Results of Experiment 2.

One possible first step is to discard the number of special transitions Nspt. This is not a great loss, since we are more interested in
studying the effect of the illocution components and the structure
of the interaction model. In this way, Nleaf 14 Nill, so that an ANOVA
test can be run for each specific value of Nill. The following were
selected:
Nill 14 8; 16; 32; 64; 128

The number of alternation operators was not considered, since,
as already seen, Nalt 14 Nill  Ncon  1, so any statement about Ncon
has a counterpart statement about Nalt. We also replaced variables
Nip and Nrole with a unifying variable Nhead which accounts for the
number of illocution heads.

Once a particular value of Nill is selected, an upper bound for
both Nhead and Nmsg is laid down: 1 6 Nhead; Nmsg 6 Nill. Neverthe-
less, since an interaction model in which there are no repeated illocution heads is not interesting for the task at hand (agents would
always be able to distinguish the correct message between all
incoming ones, and, hence, they would not fail at all), 1
2 Nill is a
much more effective upper bound for Nhead. Interaction models
with only one message were not taken into account either. Concerning operators, we decided to generate regular expressions with
at least one operator of each type. Thus, 1 6 Ncon 6 Nill  2. Kleene
star operators, though, were left to be in any case lower than 1
2 Nill.
Again, we ran our implementation in series of N 14 2n interactions,
but this time with n 2 121::8. Table 4 shows the selected values in
the particular case of Nill 14 32.

Table 4
Selected values for Nill 14 32.

Name

No. of heads
No. of messages
No. of Kleene star operators
No. of concatenation operators
No. of interactions

Selected values

1, 2, 4, 8, 16
2, 4, 8, 16, 32
1, 2, 4, 8, 16
1, 2, 4, 8, 16, 30
1, 2, 4, 8, 16, . . .,256, 512

Before executing the ANOVA tests we verified that the resulting
data had a normal distribution through a QuantileQuantile test,
which is another precondition for the ANOVA results to be reliable.
We ran five ANOVA tests  one for each value of Nill  with the
software environment R [40].

The ANOVA results demonstrate that all the independent variables were statistically significant with a p-value much lower than

1. a higher number of illocution heads,
2. a lower number of messages, and
3. a higher number of interactions.

For this reason, we ran post-hoc comparisons using the Tukey
test. Fig. 11 shows the results of the tests in the case of Nill 14 32.
For the rest of values we obtained similar results. Hence, Hypothesis 2 was confirmed too. With regard to the operators of regular
expressions, the following was confirmed:

Hypothesis 3. A lower number of concatenations implies a lower
number of failures. Alternatively, a higher number of alternations
implies a lower number of failures.

Recall that our approach highly depends on the criterion followed when it comes to classify an interaction as successful or
unsuccessful (see I-SSA third principle in Section 3.1). In this paper,
in order for an interaction to be qualified as successful, agents must
jointly reach final states. As a general rule, the more alternation
operators a regular expression has, the more paths leading to final
states in the interaction model, and, thus, the more chances for the
agents to interact successfully. This gives an explanation to
Hypothesis 3. However, different notions of success  as a consequence of, for example, more expressiveness in interaction models
 would result in different hypotheses.

With respect to Kleene star operators, the Tukey tests provided
confusing results. Neither a higher nor a lower number of star
operators implied a lower number of failures. This fact made us
think that this might not be the proper parameter to study. A second option is to look into the complexity of an interaction model
by measuring its star height [41]. Actually, the three operators considered in this work are all involved in the star height measure.
However, a preliminary experimentation suggested that this is
not the right way either. It seems to be necessary to work on a specific notion of complexity appropriate for the case at hand. This
task has not been addressed for this paper and has been left for future work.

7. Related work

Other approaches share with ours the insight that semantics is

fundamentally interaction-specific.

Besana and Robertson attach probabilistic values to meanings of
terms that are determined by earlier and similar interactions [42].
These values are then used to predict the set of possible meanings
of a message. As with our approach, meaning is defined relative to
a particular interaction, but Besana and Robertson aim to reduce
the search space of possible a priori mappings between ontological
entities (computed in a classical sense), namely by assessing those
ones with highest probability in the context of an interaction. Instead of finite-state machines the formalism adopted to model

95% family-wise confidence level

95% family-wise confidence level

-0.12

-0.10

-0.04
Differences in mean levels of Heads

-0.08

-0.06

95% family-wise confidence level

-0.02

Differences in mean levels of Messages

95% family-wise confidence level

-0.10

-0.05

-0.05

Differences in mean levels of Interactions

Differences in mean levels of Concatenations

Fig. 11. Results of the Tukey tests.

agent interactions is LCC (Lightweight Coordination Calculus) [43].
Besana and Robertson do not provide any formal grounding for
their prediction reasoning. In contrast, our alignment protocol
and matching criteria are based on the communication product
which realises I-SSA principles.

Bravo and Velazquez discover pragmatic similarity relations
among messages in different agent interaction protocols [44]. Like
ours this approach is based on the analysis of transition functions
in finite automata. Two input messages (transitions) are equivalent
when their respective initial and final states are equal. This requires that the set of states is the same in all agent interaction pro-
tocols. Rather than separate transitions, we look at histories which
allows us to capture interdependence of messages. Bravo and Velazquez do not consider any content language since in their framework messages are actually performatives. In addition, no other
semantic relation but equivalence is studied, while subsumption
of messages is also defined in I-SSA.

Although Rovatsos et al. do not address the problem of semantic
heterogeneity, their approach has a number commonalities with I-
SSA [45]. Rovatsos et al. propose a semantics for agent communication languages (ACLs) in the context of open systems in which the
meaning of a message is defined in terms of its consequences,
namely, those messages and actions that are likely to follow it. It

is claimed that an agent strives to reduce the uncertainty about
others communicate behaviour (entropy), and at the same time
to increase her own autonomy (utility). Indeed this can be seen
as an alternative to the I-SSA Principle 3*. Furthermore, like ours,
this model
analysis of observed
communication.

relies on a

statistical

Our approach is reminiscent to the research of Steels in which
he explores how a group of distributed agents adapt to form an
ontology and a shared lexicon in an emergent, bottom-up manner,
with no central control authority and only local
interactions
[46,47]. This sort of self-organised emergence of shared meaning
is ultimately grounded on the physical interaction of agents with
the environment. In our approach, though, we have addressed
the case in which agents are already endowed with a top-down
engineered ontology (it can even be the same one), which they
do not adapt or refine, but for which they want to find the semantic
relationships with separate ontologies of other agents on the
grounds of their communication according to a specific interaction
model.

As with the work of Steels, our view of meaning and its role in
multiagent interaction is, to a certain extent, related to the idea of a
language game as put forth by Wittgenstein [48]. Interaction protocols can be seen as the game rules that constrained the moves

M. Atencia, M. Schorlemmer / Web Semantics: Science, Services and Agents on the World Wide Web 1213 (2012) 131147

 the words uttered  that are allowed at each state of the game.
The meaning an agent attaches to a term, then, is the state transition it thinks is the result from the terms utterance in a particular
speech act, according to the agents view of the interaction and of
the current interaction state. As with a language game, the guesses
of what the meanings of the words are may be wrong, which will
eventually lead to a breakdown of the communication: the interaction has not progressed in the direction foreseen by the interaction
models of each agent. Agents can be aware of such a breakdown if
they are capable to communicate to each other about the interactions themselves [49].

8. Concluding remarks and further work

In this paper we have laid the formal foundations for a novel
approach to tackle the problem of semantic heterogeneity in
multiagent communication. We did not take the predominant
stance that shared semantics is a prerequisite for successful
interaction, but instead attempted to establish semantic similarity on the grounds of successful interaction itself. For this we
have looked at the semantics of messages from an interactionbased viewpoint, as it arises in the context of a dialogue that
unfolds according to previously specified interaction models. In
our
are deemed semantically related
if they trigger compatible interaction-state transitions, where
compatibility means that the interaction progresses in the same
direction for each agent  albeit their interaction views (i.e.,
their own interaction models) may be more constrained than
the interaction that is actually happening.

approach messages

An advantage of this approach is that it takes meaning into account that is very interaction-specific and which cannot be derived
neither from a local ontology nor from sources that are external to
the interaction. In this sense we see our approach as a complement
to current state-of-the-art matching techniques as it may provide
valuable information for pruning the search space or disambiguating the results of candidate semantic alignments computed with
todays ontology-matching technology.

The viability of the I-SSA approach has been evinced through
our abstract experimentation and statistical study. Through the
combination of analyses of variance and Tukey tests we have been
able to identify which factors  number of illocution heads, messages and interactions  have an influence on the total amount
of failed interactions, and which values do better for each of the
independent variables.

The actual applicability, however, will depend largely on how
each potential application domain conforms to the underlying
assumptions of I-SSA, namely that (i) agents are part of a regulatory environment, (ii) they may engage repeatedly in the same
sort of dialogue, and (iii) they are able to communicate each
other some shared notion of dialogue success. The first two hold
for most implementations of the electronic institution paradigm,
which range from auctioning [35] and electronic markets [36] to
public-policy management [37] and online dispute resolution
[38]. As it stands, though, I-SSA has to go beyond current representational limitations for it to be readily applicable in these
domains.

So far we have taken content messages of illocutions to be
grounded atomic sentences, but we need to extend the content
language to cope with variables  and hence move into some degree of first-order expressiveness  if we want interaction models
to capture any realistic application as those mentioned above. Potential semantic relationships would then need to be expressed between complex, structured terms instead of simple, propositional
constants. How this could be done for conventional ontology
matching,
the

starting from the

semantic

alignment

at

terminological level, has been investigated by Giunchiglia et al.
applying ideas derived from the theory of abstraction combined
with tree edit distance algorithms [50]. An approach such as the
one put forward by I-SSA, however, would have to tackle this problem the other way around, investigating how relationships at the
structural level, determined by the actual use of complex terms
in the context of a particular interaction, relate to the semantic
alignment at the terminological level.

Also, finite-state automata are currently not expressive enough
as to capture the complexity of interaction in these domains, and richer interaction modelling formalisms, such as electronic institu-
tions, will have to be considered.
If we initially constrained
ourselves to finite-state automata and propositional languages, it
was because we wanted to check the viability of our approach with
a simple interaction model formalism before moving to more
expressive representation languages and richer specifications of
interactions.

Actually, a formalism of lesser expressivity, such as a finitestate automaton, allows for sharing only a rather weak notion of
dialogue success  our third assumption  as reflected in Principle
3* in Section 3.1. But other instantiations of the more general Principle 3 could have been proposed, particularly if the interaction
modelling formalism allowed for expressing them. One possible
extension could be to take into account commitments made by
agents while interacting (such as payments or deliveries) and to
check whether these commitments have been fulfilled for an interaction to be considered successful. In fact, commitments would enable agents to have checkpoints in mid-interactions, and, thus, to
detect failures earlier, before reaching a final state. Therefore we
expect richer interaction modelling formalisms to actually yield
even more accurate alignments, as those already achieved by I-
SSA in our experimentation.

Exploring the applicability of I-SSA would first need to address
the above mentioned issues and its implications, and we are currently looking into them in the context of the agreement computing
paradigm [51]  a distributed interaction-centred computational
paradigm based on an explicit notion of agreement between computational entities. More specifically, we are exploring eventual
semantic mismatches in the context of a two-agent negotiation
protocol as the one developed for the mWater system [37]  a regulated environment where autonomous agents trade rights for the
use of water in a closed basin  and for which the fulfilment of
commitments are paramount to the understanding of the protocol.
We claim that, even with shared ontologies, mismatches are susceptible of arising during interaction time, because no ontology
can foresee all potential uses of terminology. In these cases an I-
SSA alignment could be used to make explicit a lack of agreement
at the semantic level, which would need to be included into the
ontology for subsequent negotiations.

One of the main characteristics of I-SSA is that it is fully unaware of ontological information. Semantic alignment conforms solely to the agents use of messages while interacting, though
ontological information is actually implicit in this usage. Such limitation may be sensible in situations in which ontologies are not
open for inspection, but nothing prevents agents from taking
advantage of their own ontological information. Indeed an agent
could reason about the relations between their own messages
when matching a received one. Our choice not to assume agents
with previously formed individual ontologies was motivated  as
with the interaction modelling formalism  by our desire to focus
on the viability of a purely interaction-centred approach. I-SSA was
initially driven by the fact that most of the current state-of-the-art
matchers put little emphasis on pragmatics. But more than a
replacement or an alternative technique, we believe that I-SSA is
a good complement for these matchers, and it is in our mind to
work on this line in the future.

To conclude, we would like to point out that I-SSAs current
matching mechanism only keeps track of past successful interac-
tions, but unsuccessful interactions are simply discarded. Clearly,
this is a great loss, since agents could also learn from past
matching mistakes. The problem is that it is not straightforward
to figure out which matching is responsible of a failure, or if we
should blame one agent or another. Once more a probabilistic
approach seems to be appropriate for this matter, attaching values to matching elements that vary as more interactions are
completed, regardless of whether they are successful or unsuc-
cessful. This should considerably improve the matching mechanism in terms of learning speed.

Acknowledgements

This work was supported under Grant 2009-SGR-1434 from the
Generalitat de Catalunya, and under the projects Agreement Technologies (CONSOLIDER INGENIO 2010 CSD2007-00022) and CBIT
(TIN2010-16306) funded by the Spanish Ministry of Science and
Innovation. The authors also would like to thank the anonymous
reviewers for their valuable feedback.
