Finding Co-solvers on Twitter,  

with a Little Help from Linked Data 

Milan Stankovic1,3, Matthew Rowe2, and Philippe Laublet3 

1 Hypios Research, 187 rue du Temple, 75003 Paris, France  

2 Knowledge Media Institute, The Open University, Milton Keynes, UK, MK7 6AA 

3 STIH, Universite Paris-Sorbonne, 28 rue Serpente, 75006 Paris, France  

mail@milstan.net, m.c.rowe@open.ac.uk,  

philippe.laublet@paris-sorbonne.fr 

Abstract.  In  this  paper  we  propose  a  method  for  suggesting  potential 
collaborators  for  solving  innovation  challenges  online,  based  on  their 
competence, similarity of interests and social proximity with the user. We rely 
on  Linked  Data  to  derive  a  measure  of  semantic  relatedness  that  we  use  to 
enrich  both  user  profiles  and  innovation  problems  with  additional  relevant 
topics,  thereby  improving  the  performance  of  co-solver  recommendation.  We 
evaluate  this  approach  against  state  of  the  art  methods  for  query  enrichment 
based  on  the  distribution  of  topics  in  user  profiles,  and  demonstrate  its 
usefulness  in  recommending  collaborators  that  are  both  complementary  in 
competence and compatible with the user. Our experiments are grounded using 
data from the social networking service Twitter.com. 

Keywords: Linked Data, Twitter, Collaborator Recommendation. 

Introduction 

Modern  challenges  that  science  and  engineering  worlds  are  facing  today  are  often 
interdisciplinary and require research cooperation of teams of people in order to produce 
good solutions. Analysis of tendencies in research publications [1] shows that more and 
more  multi-university  teams  produce  accepted  papers.  Similarly,  industrial  innovation 
challenges  often  require  a  collaborative  effort  of  experts  from  across  different 
disciplines to work together. In this sense, innovation problem solving platforms, such 
as  Innocentive1,  have  started  to  propose  problem  challenges  for  teams  of  problem 
solvers.  Supporting  users  in  the  task  of  forming  productive  multidisciplinary  teams 
therefore plays an important role in a multitude of innovation-related situations. 

Existing  social  studies  [2]  on  the  topic  of  forming  teams  investigate  peoples 
preferences when it comes to the choice of co-workers, they underline the importance 
of  co-worker  similarity  (both  in  terms  of  shared  interests/expertise  and  in  terms  of 
shared social connections) together with the expertise of co-workers given the work 
task.  Conveniently,  more  and  more  data  about  users  (i.e.  their  social  connections, 
topics  of  interest,  their  work)  is  available  on  the  Web,  this  opens  the  way  for  a  

                                                           
1 http://www.innocentive.com/ 

E. Simperl et al. (Eds.): ESWC 2012, LNCS 7295, pp. 3955, 2012. 
 Springer-Verlag Berlin Heidelberg 2012 

M. Stankovic, M. Rowe, and P. Laublet 

co-worker recommendation approach that takes into account those different qualities 
of the user and performs useful recommendations. 

In this paper we are addressing the challenge of recommending potential co-solvers 
to people facing an innovation or research problem for which they are only partially 
competent.  This  recommendation  is  performed  based  on  the  data  available  in  social 
networks (both the users social graph and the user generated content), by taking into 
account both the compatibility of candidates with the user, and the complementarity of 
their competence.  The research questions driving our work are: how can we suggest 
appropriate co-solvers, which were potentially, previously unknown to the user? And: 
what  information  can  be  used  to  enrich  initially  available  user  and  problem  data  to 
provide  the  best  suggestions?  In  exploring  these  two  research  questions  we  have 
devised  an  approach  to  recommend  co-solvers  for  open  innovation  problems.  The 
contributions from this work are three-fold, and are as follows: (1) Profile Expansion: 
we present methods for expanding topics that measure semantic relatedness between 
topics  using  the  linked  data  graph;  (2)  Similarity  Measures:  we  describe  three 
similarity  measures  that  exploit  either  relations  between  topic  concepts  or  social 
connections; (3) Evaluation: we assess the performance of our approach when different 
profile expansion and similarity measures are used through two user studies. 

The remainder of the paper is organized as follows: In section 2  we describe the 
Open Innovation related scenario of use for which we developed our approach and we 
present  related  work  covering  a)  the  recommendation  of  co-workers;  b)  expert 
finding, and; c) measures of semantic relatedness. Our core approach is presented in 
section 3 together with different alternatives for several parts of the recommendation 
process.  In  section  4  we  present  two  user  study-based  evaluations  of  our  approach 
executed over the social network Twitter.com. In section 5 we present our directions 
of future work and conclude the paper. 

Background and Related Work 

2.1  Open Innovation and the Need for Co-solvers 

Open Innovation (OI) [3] has emerged as  way to accelerate industrial innovation by 
looking for diverse and unexpected perspectives to innovation problems outside of the 
company.  OI  platforms,  such  as  hypios.com,  Innocentive.com,  and  NineSigma.com 
have  emerged  to  support  this  practice.  Those  platforms  allow  innovation  seekers  to 
post  their  problems  for  solving  by  Web  users  and  award  the  best  solutions.  Such 
innovation  platforms  aim  to  allow  anyone  who  has  some  knowledge  or  idea  to 
participate  in  the  innovation  process.  They  value  diversity  in  solutions  over  the 
acclaim  and  level  of  expertise  of  solvers,  as  studies  have  shown  that  people  with 
marginal competence in the problems domain, but experts in some other domain, are 
able to bring more innovative solutions [4], often by transposing ideas from one field 
to another. Our work on co-solver recommendation, although generalisable to any use 
case of finding collaborators, is principally oriented at finding people to work with on 
the Open Innovation problems. This implies a preference towards candidates who are 
able to bring a novel perspective to solving the problem over those who are acclaimed 
experts in the exact domain of the problem. 
?

?

?
2.2  Recommending People 

A  number  of  approaches  have  been  proposed  for  challenges  similar  to  ours,  most 
notably for recommending people to befriend in social networks. Those recommender 
systems  usually  rely  on  a  measure  that  quantifies  the  similarity  of  two  users  or  the 
similarity of a user profile with a given document or query. Spertus et al. [5] present an 
empirical comparison of six measures of similarity for recommending communities to 
members  of  the  Orkut  social  network.  They  found  the  cosine  similarity  measure  to 
show the best empirical results against other measures. In [6] a transitive notion of user 
similarity is proposed to address the scarcity of user profiles in collaborative filtering 
systems  when  recommending  movies.  [7]  relies  only  on  Jacquards  similarity  to 
compare  different  sources  from  which  user  similarity  may  be  mined  (friendships, 
interests,  activities  in  same  places,  etc.)  in  terms  of  their  performance  in  different 
scenarios.  Another  study,  presented  in  [8]  shows  that  algorithms  based  on  a  users 
social connections are better in recommending known contacts, while those based on 
the  similarity  of  user-generated  content  perform  better  at  suggesting  new  contacts. 
Those studies however do not provide implications for the use case of recommending 
co-workers.  In  addition  to  similarity,  some  systems  like  Facebook,  consider  affinity 
towards a user calculated based on the level of mutual interactions on Facebook2. 

A number of multi-criteria recommender systems have been proposed, mostly using 
a (linear) combination of different similarity functions to deliver recommendations. For 
instance  a  collaborative  filtering  system  for  recommending  similar  users  [9]  uses  a 
machine learning approach to learn weight factors of different utility functions. [10] also 
uses  a  multitude  of  criteria  derived  from  different  interactions  users  make  with  Web 
objects.  [11]  develops  a  machine  learning  approach  for  leveraging  content  and  social 
criteria  in  providing  folksonomy-based  recommendations,  especially  on  Flickr. 
However,  to  our  best  knowledge  such  approaches  have  not  been  used  to  suggest  
co-solvers. 

2.3  Expert Finding 

A  multitude  of  approaches  for  expert  finding  from  a  range  of  sources  like  blogs, 
scientific  literature,  corporate  social  networks,  etc.  have  been  proposed  in  the  past   
many  of  which  in  TREC  conferences  [12].    Many  of  such  approaches  exploit 
microposts,  including  tweets,  for  expert  profiling,  thereby  confirming  the  viability  of 
this source for co-solvers. For instance, Zoltan and Johan [13] propose a system for the 
extraction of ontological topic concepts from tweets, topics are then weighted by their 
importance to  the expert profile.  Analysis of persistency of  topics [14] as  well as the 
awareness of profile dynamics [15,16] have been shown to improve user profiling, over 
static approaches.  Twitter lists have been shown to be a rich source for user profiling 
[17]. The construction of expert profiles  from Twitter data  using topic  models is also 
proposed by Wagner [18].  

Most  of  these  existing  approaches  focus  on  finding  people  with  expertise  in  a 
particular topic, while the question of fitting an expert to an innovation task involving 

                                                           
2 http://techcrunch.com/2010/04/22/facebook-edgerank/ 

M. Stankovic, M. Rowe, and P. Laublet 

a multitude of topics has not yet been fully explored. To the best of our knowledge, 
existing  approaches  do  not  respond  to  the  needs  of  OI  scenarios,  where  the 
requirements in terms of expertise of a potential problem solver are slightly different 
than  those  used  to  select  experts  in  most  expert-finding  approaches.  The  necessary 
focus  on  getting  diverse  and  laterally  relevant  experts  has,  to  the  best  of  our 
knowledge, also not been the focus of the existing expert-finding approaches. 

2.4  Measures of Semantic Relatedness Usable for Profile Expansion 

Our  approach  for  co-solver  recommendation  exploits  the  semantic  relatedness  of 
individuals  through  the  linked  data  graph  based  on  their  topical  expertise  and 
interests. Measures of semantic relatedness (MSRs) have been proposed for use in a 
variety of tasks and can be split into two major categories: 1) graph-based measures 
and; 2) distributional measures. 

Graph-based  measures  make  use  of  semantic  (e.g.,  hyponymy  or  meronymy) 
and/or lexical (e.g., synonyms) relationships within a network (graph) of concepts to 
determine  semantic  proximity  between  the  concepts.  For  example,  [19]  exploits  the 
hypernym graphs of Wordnet3; whereas [20] use the ODP taxonomy4 and [21] relies 
on  the  graph  of  Wikipedia  categories  to  provide  recommendations.  Among  graph 
measures used to calculate the semantic proximity of concepts shortest path is one of 
the  most  common,  and  is  often  enhanced  by  taking  into  account  the  informational 
content  of  nodes  in  the  graph  [22]. To  the  best  of  our  knowledge  these  approaches 
have not been applied to knowledge bases of comparable size and richness to that of 
DBPedia5. Even the Wikipedia-based measures that we found only used information 
about categories and did not leverage other information present in DBPedia. Our own 
MSR, hyProximity that we will describe shortly, builds upon the existing graph-based 
measures  but  is  highly  adapted  to  the  rich  structure  of  Linked  Data  sources,  as  it 
leverages different types of relations that concepts may have in the graph.  

Distributional measures mostly explain semantic relatedness through common use, 
usually by leveraging co-occurrence of concepts, and mostly do not make connections 
over the meaning of terms or concepts. For example, the approach presented in [23] 
uses co-occurrence in text of research papers to establish a notion of word proximity, 
while  others  rely  on  other  sources  such  as  search  results  [24].  In  addition  to  the 
measures of semantic relatedness, some authors propose the use of pseudo relevancefeedback to enrich an initial set of topics in a query, most notably in the domain of 
expert  search.  In  particular,  pseudo  relevance-feedback  is  used  to  enlarge  expert 
search  queries  based  on  additional  keywords  appearing  in  a  number  of  top  ranked 
documents [25] or top ranked user-profiles [25, 26]. The diversity of topics in expert 
profiles has been shown to negatively impact the quality of results when more narrow 
results are sought. No evaluation has been provided for the case when broadening of 
the space of found experts is desired for OI purposes. 

                                                           
3 http://wordnet.princeton.edu/ 
4 http://www.dmoz.org/ 
5 While DBPedia contains more then 3.5 million concepts, the current version of Wordnet has 
206941 word-sense pairs, and ODP has half a million categories. 

Finding Co-solvers on Twitter, with a Little Help from Linked Data 

Recommending Co-solvers 

Our  general  approach  for  recommending  co-solvers  is  based  on  a  users  social 
connections  and/or  the  content  he/she  created.  The  general  process  is  applicable  on 
any  social  network  with  user-generated  content,  however  we  discuss  our  concrete 
implementation of the process on data from the social network Twitter.  

3.1  General Approach 

In our general approach, a Web user (called a seed user) approaches our system with 
the  intention  to  find  potential  collaborators  for  a  particular  research  challenge  or 
innovation  problem  (called  problem  hereafter).  He  provides  the  text  of  the 
problem/challenge  and  gives  some  identifier  that  he  uses  on  a  social  networking 
system, this allows access to: (1) his social connections and (2) some content that he 
created. The system then proceeds with the creation of profiles for both the user and 
the problem. Those profiles contain Linked Data identifiers of topics extracted from 
the provided textual elements (from the text of the problem/challenge in the case of 
the  Problem  Profile  or  from  the  content  that  the  user  has  created  in  the  case  of  the 
User Profile). Optionally, an additional phase of profile enrichment may be performed 
(called Profile Expansion). This functions by expanding the initial profiles in order 
to broaden their topics and thus compensate for any incompleteness.  i.e. where the 
topics may be too specific. Similarity scoring is performed over a base of candidate 
user profiles in order to select those candidate users that: (1) are the most similar to 
the  seed  user  and;  (2)  whose  profile  fits  the  given  innovation  problem.  Similarity 
scoring  can  work  both  with  the  initial  user  and  problem  profile  as  well  as  with  the 
extended ones. Particular similarity functions will be further discussed in Section 3.3.  

3.2 

Profiling 

In the profiling phase, user and problem profiles are created from the provided textual 
elements (posts and biography in the case of user profiles and problem text in the case 
of problem profiles). The topic profiles (denoted TP in equation (1)), regardless of the 
type of entity (user or problem) that they concern, are sets of tuples assembled from a 
Linked Data URI of a topic concept and a value w representing the importance of this 
particular topic for the profile. In essence, this topic profile is a concept vector, where 
each elements index represents a unique concept. The value stored in a given element 
is the frequency of the concepts appearance in either: a) the users past information 
or;  b)  the  problem  definition.  In  the  phase  of  profile  expansion,  the  values  w  of 
additional related topics correspond to the relatedness of the topic to the given profile, 
as  expressed  by  the  particular  measure  of  semantic  relatedness  used  to  perform  the 
profile expansion.  
TP(entity) ={(URI1,w1),...,(URIn,wn)}   (1)      SP(user) ={user1,...,usern}   (2) 

M. Stankovic, M. Rowe, and P. Laublet 

Different operations are possible over the topic profiles. For instance, in our work we 
will  rely  on  the  difference  TP(problem)-TP(user),  called  difference  topics,  that 
represents the topics found in the problem topic profile that are not found in the topic 
profile of the seed user - this derives the topics for which there is no record of seed 
users  past  knowledge.  In  addition  to  topic  profiles,  social  profiles  (denoted  SP  in 
equation (2)) are also created for the users, and they contain the list of users social 
connections: 

3.2.1   Extraction of Topics 
Extraction  of  topics  from  text  plays  a  crucial  role  in  the  profiling  phase.  When  we 
refer to topics in our  work,  we consider concepts of general human  knowledge that 
have unique identifiers  e.g. a URI - and are described as resources somewhere in the 
Linked  Data  cloud.  Descriptions  of  such  concepts  may  be  found,  for  instance,  in 
knowledge  bases  such  as  Freebase.org  or  DBpedia.org.  A  number  of  entity 
recognition services propose the extraction of such concepts from given text, such as 
Zemanta6, OpenCalais7, DBpedia Spotlight8 etc. In our experiments we use Zemanta 
for topic extraction. This service has been shown to perform well (among the best) for 
the task of recognizing Linked Data entities from text in recent evaluations [27]. 

3.2.2   User Profiling on Twitter 
In  our  particular  implementation  on  Twitter,  we  use  the  users  biography  and  a 
number of last tweets (300 used in particular experiments) to extract the topics. The 
DBpedia URIs of extracted topics are stored in TP along with the frequency of their 
occurrence. This approach assures that the most recent interest topics are taken into 
account. On the other hand it is not very restrictive, as any topic tweeted about may 
be considered as part of a users profile.  Our approach  favours  the broader view of 
topics  in  accordance  with  the  need  for  laterality  and  inclusion  of  people  with 
borderline  interest/expertise  in  a  particular  topic,  who  might  bring  innovative 
perspectives  to  the  problem  solving  process    essential  for  our  Open  Innovation 
scenario. In cases where it is necessary to assure that only topics for which the user is 
really  experienced  about  are  represented,  it  is  possible  to  use  a  more  restrictive 
approach such as one of those proposed in [14], [15], and [16], mostly making use of 
the dynamics and persistence of topics in users tweets. 

3.2.3   Creating Candidate User Profiles 
Ideally,  candidate  users  should  be  all  the  users  of  the  Web.  While  it  is  theoretically 
possible  to  construct  such  a  base  of  user  profiles,  most  real  world  systems  are 
confronted with constraints in terms of both access to user data and processing time, and 
thus  have  to  restrict  themselves  to  a  set  of  candidate  user  profiles,  most  likely  to  be 
selected by the recommender system. In our case, for each seed user and problem, we 
perform searches on the raw social network data. In particular we perform two types of 
search: (1) to find all the users in the social proximity of the seed user, i.e. friends of 
friends, and (2) to find all the users corresponding to the topics found in the problem 

                                                           
6 http://developer.zemanta.com 
7 http://www.opencalais.com/ 
8 http://dbpedia.org/spotlight 
?

?

?
and  the  seed  user  profile,  as  found  by  the  search  function  of  the  particular  social 
network  used    in  the  case  of  Twitter  using  their  built-in  search  functionality.  Users 
found by those different queries constitute  a base of candidate user profiles  for every 
recommendation. These two particular ways of harvesting candidate users correspond to 
the general intention of finding people similar to the seed user (in the sense of interests 
and social connections) and relevant for the topics of the problem. Users that our seed 
user are already friends with are eliminated from the possible recommendations as we 
assume that they are known to the seed user and as such would not represent valuable 
discoveries. In cases  where they are considered relevant, it is relatively easy to tweak 
the system to also include the users friends in the recommendations. 

3.3  Core Similarity Measures and Similarity Scoring 

In accordance to our criteria described in the introduction, the ranking of the candidate 
users should favour the candidates: whose profile topics are similar to the topics in the 
seed  users  profile  (interest  similarity);  whose  social  connections  are  similar  to  the 
social  connections  of  the  seed  user  (social  similarity)  and  whose  profile  topics  are 
similar  to  the  difference  topics  (similarity  with  the  difference  topics).  In  order  to 
enforce such a ranking we use measures of similarity that enable the measurement of 
each  of  the  abovementioned  aspects.  We  also  use  a  combined  measure  in  order  to 
favour  candidates  who  satisfy  all  of  the  above  criteria.  All  the  similarity  measures 
operate  over  TP  and  SP  vectors  defined  in  3.2.  As  these  measures  take  vectors  as 
input  we  can  apply  two  well  established  functions  for  vector  similarity  Weighted 
Overlap and Cosine Similarity: 
  Weighted Overlap represents the sum of weights in the seed users profile, for 
all topics that the seed and candidate user profiles have in common. The use of 
this simple measure can be observed in many approaches, like [28]. 

  Cosine similarity measure is another commonly used vector similarity measure 
[29,  30]  and  it  is  defined  as  the  cosine  of  the  angle  of  the  two  vectors  to  be 
compared. 

We  define  three  measures  of  similarity,  each  of  which  are  used  with  the  above 
functions: 
 

Interest Similarity  The similarity of topic profiles TP of the seed user and a 
candidate user. When applied in this way we will refer to our functions with a 
suffix t, e.g., WeightedOverlapt, Cosinet; 

  Social Similarity  The similarity of social connection profiles SP of the seed 
user  and  the  candidate  user.  When  used  in  this  way,  we  will  refer  to  our 
functions with a suffix s, e.g., WeightedOverlaps, Cosines; 

  Similarity with difference topics  The similarity between the topic profile TP 
of a candidate user and the vector of difference topics. When used in this way, 
we will refer to our functions with a suffix dt, e.g., WeightedOverlapdt, Cosinedt. 
In  order  to  aggregate  the  values  of  all  3  different  similarity  measures  we  use  a 
composite  similarity  measure.  Given  that  the  values  of  the  elementary  similarity 
measures are in the range [0,1], and that they are normalized to this range, we use the 

M. Stankovic, M. Rowe, and P. Laublet 

product (PC) of the three elementary measures as the aggregate measure. For instance 
PC(Cosinet,Cosines,Cosinedt)= Cosinet(cid:129)Cosine s(cid:129)Cosine dt. Alternatively it is possible to 
use the sum of weighted values of elementary similarity measures, in which case the 
weights may be adjusted by a machine-learning approach [9] in order to adapt to the 
preference  of  each  user.  The  PC  measure,  as  opposed  to  any  linear  combination  of 
elementary  functions,  penalizes  the  candidates  that  rank  extremely  poorly  at  any 
single similarity function (0(cid:129)x=0), regardless of the high ranking at another function. 
The candidates ranked  highly at only one  similarity  function could  therefore not be 
ranked better then those being similar in all required aspects. 

3.4 

Profile Expansion Using Semantic Relatedness Measures 

Prior to calculation of similarity measures it is possible to enrich the seed user profile 
as  well  as  the  problem  profile  with  additional  topics  that  are  related  to  the  topics 
initially found in their topic vectors. Figure 2 shows a graph through which the seed 
user and the problem are linked to the potential candidate co-solvers. While the topics 
found initially in the seed user profile (T1 and T2) and in the problem profile (topics 
T1, T3, T4 and T5) do lead to some potential co-solvers, it is possible to consider the 
semantic relatedness of topic concepts and in that way reach a larger set of candidate 
users  and  in  general  have  a  richer  view  of  the  similarity  of  profiles.  By  semantic 
enrichment of profiles we consider adding topics to an initial profile that are found to 
be  related  to  the  initial  profiles  topics  according  to  a  particular  notion  of  semantic 
relatedness. This notion of semantic relatedness of topics may be derived in different 
ways.  In  this  section  we  present  3  of  such  different  measures:  a)  distributional 
semantic  relatedness  measure;  b)  hyProximity    a  Linked  Data-based  measure  of 
semantic relatedness  and; c) pseudo relevance-feedback. 

Fig. 1. The Graph of Social and Semantic Connections 

 

The first step in profile enrichment is to generate relevant concepts (according to 
the  measure  used)  for  each  topic  present  in  the  initial  profile.  This  expansion  is 
performed by first identifying related concepts to the original profile topics  e.g. T3 
in Figure 1 when considering the seed user profile. The relatedness is then calculated 
between each profile topic and related concept  e.g. T2 with T3, and T1 with T3  to 
derive individual relatedness values. The total relatedness between the profile and a 
given related concept is then given by the sum of these individual calculations, where 
?

?

?
the greater the cumulative relatedness the greater the relatedness between the profile 
and  the  related  concept.  The  top-n  topics  are  selected  based  on  their  cumulative 
relatedness  we set n=30 for our experiments. 

3.4.1   Distributional Measure of Semantic Relatedness (DMSR) 

DMSR(t1, t2) =

ocurrence(t1, t2)

ocurrence(t1) + ocurrence(t2 )  

(3) 

The distributional  measure of semantic relatedness (DMSR) relies on co-occurrence 
of  topics  in  profiles  to  conclude  that  two  topics  are  similar.  It  is  inspired  from  the 
distributional  measures  used  in  recommending  keywords  for  search  query  term 
suggestion  [24].  DMSR,  expressed  with  the  formula  (3)  considers  two  topics  to  be 
similar if they co-occur often in profiles. It represents the ratio of the number of joint 
occurrences  of  two  topics  t1  and  t2  in  user  profiles  and  the  sum  of  their  individual 
occurrences. It is calculated over  - the set of all user profiles taken into account as 
potential user candidates. 

3.4.2   hyProximity (HPSR) 
HyProximity is a measure of semantic relatedness (HPSR) that relies on Linked Data 
graphs  of  topic  concepts.  We  have  developed  this  notion  for  the  purposes  of 
discovering  laterally  relevant  topics  for  solver  finding  purposes.  While  only  a  short 
summary  of  the  notion  is  presented  here,  our  previous  paper  [31]  provides  more 
detailed descriptions together with corresponding algorithms and evaluations. 

In  data  sets  rich  with  topics  of  general  human  knowledge,  such  as  DBPedia  and 
Freebase, concepts are usually related using properties that might be classified in two 
main types: 
  Hierarchical  links  -  Those  created  over  properties  that  help  organize  the 
concepts  in  classes  (e.g.,  rdf:type9  and  rdfs:subclassOf)  or  categories  (e.g., 
dcterms:subject and skos:broader). The links created by those properties connect 
a concept to a category  the one serving to organize other concepts into classes. 
  Transversal links  Those created between ordinary, non-category concepts over 
properties  that  connect  concepts  without  the  aim  to  establish  a  classification  or 
hierarchy.  Those  properties  might  create  explicit  links  (connecting  two  concepts 
directly) or implicit links (when two concepts have the same value for the same 
property).  Through  the  analysis  of  concepts  appearing  in  past  open  innovation 
problems  and  their  solutions  received  on  hypios.com,  we  have  discovered  that 
only  a  small  set  of  properties  participate  in  forming  all  of  the  links  between 
concepts observed in OI scenarios. This set of properties, referred to as P, consists 
of dbo:product, dbo:industry, dbo:service, dbo:product and dbp:products.  

HPSR(t1, t2 ) =



C i C ( t1 ,t 2 )

ic(Ci) +



pP

link( p

, t1, t2)  pond( p, t1)

(4) 

Our  approach  uses  the  links  created  over  these  two  types  of  properties  in  different 
ways, appropriate to the nature of those links. According to the equation (4) the value 
                                                           
9 All the prefixes used in this paper can be looked up at http://prefix.cc 

M. Stankovic, M. Rowe, and P. Laublet 

of  our  HPSR  measure  for  two  topics  t1  and  t2  is  the  sum  of  valorisations  of  the 
connections  achieved  over  hierarchical  links  (first  component  of  the  formula)  and 
those  achieved  over  transversal  links  (second  component  of  the  formula).  In  the 
treatment of hierarchical links we take all the common categories C(t1, t2) of the two 
topics, and then for each common category Ci we count the informational content [22] 
of this category as -log(pb) where pb is the probability of finding the category in the 
graph of DBPedia categories when going from the bottom up. The sum of values for 
all common categories represents  the  strength of links established between  t1 and  t2 
over the hierarchical properties. The transversal links are treated slightly differently. 
For  each  property  p,  from  the  previously  defined  set  of  relevant  properties  P,  we 
count the number of links connecting t1 and t2 over the property p (given by function 
link(p, t1, t2)) and weight them using weighting function pond(p,t1). The value of the 
weighting function is calculated as -log(n/M), where n is the number of other concepts 
to  which  the  concept  t1  is  connected  over  the  same  property  p;  and  M  is  the  large 
constant  larger  then  any  possible  value  of  n  (in  our  case  it  is  the  total  number  of 
concepts in DbPedia). 

As our formula is not symmetric, i.e., HPSR(a,b) is not equal to HPSR(b,a), it is 
always calculated by putting the topics that belong to the seed user or to the difference 
topics  as  the  first  parameter,  and  the  topics  from  the  candidate  user  profiles  as  the 
second parameter. 

3.4.3   Pseudo Relevance-Feedback (PRF) 
Pseudo  relevance-feedback  (PRF)  is  a  technique  used  to  enlarge  search  queries,  in 
which  a  number  of  best-ranked  profile  suggestions/results  from  a  search  or 
recommendation system is taken and the co-occurrence analysis is performed on them 
to  discover  the  topics  that  appear  frequently  in  the  results,  there  are  then  used  to 
enlarge the initial topics and re-run the recommendation process. We mentioned some 
of the examples of the use of pseudo relevance-feedback in the Background section. 
Computation  wise,  the  measure  of  relatedness  based  on  pseudo  relevance  feedback 
(denoted PRF) is calculated by the same formula (3) as DMSR with the exception that 
only a  number (10 in our case) of the initially best ranked candidates are used as  
instead of considering the whole set of potential candidates. 

Evaluation 

In order to evaluate the performance of different similarity measures and approaches to 
profile  expansion  when  providing  co-solver  recommendations  we  performed  two 
experiments  involving  Twitter  users.  Recent  studies  show  the  growth  of  scholarly 
Twitter accounts10 and its use in communication in scientific communities, especially 
the Computer Science research community [32], thus making Twitter resourceful for 
co-solvers  recommendations.  We  first  created  three  multidisciplinary  innovation 
problems11, inspired from descriptions of existing research challenges and projects that 
we found online, each involving the topics related to Semantic Web and to at least one 
                                                           
10 Third of all scholars are said to have a Twitter account today 

  http://www.scribd.com/doc/37621209/2010-Twitter-Survey-Report 

11 Available on our website http://research.hypios.com/?page_id=184 
?

?

?
other  domain  (in  particular:  Sensors,  Online  Advertising  and  Venture  Capital 
Investments).  We  then  used  different  alternatives  of  our  method  to  suggest  possible 
collaborators corresponding to our raters, by relying on candidate user profiles created 
according to our approach described in 3.2.2 and 3.2.3.  In the first experiment (4.1) 
we used a gold standard obtained from 3 raters and then assessed the performance of 
different  permutations  of  profile  expansion  methods  with  the  interest  similarity 
measure and the difference topic measure. We omitted social similarity from this stage 
due  to  the  differences  in  the  social  networks  of  the  3  solvers    as  each  solver  has 
different potential candidates  the gold standard in this case uses the intersection of 
candidates recommended to each solver. In the second experiment (4.2) we evaluated 
all profile expansion methods with all ranking methods using a group of 12 raters. In 
this  case  we  did  not  take  interrater  agreement  for  the  gold  standard,  but  instead 
evaluated performance on an individual basis. We were therefore able to include social 
similarity as a ranking technique and evaluate its performance. Performing these two 
studies allows the comparison between performance of different profile expansion and 
similarity measures when a) recommending co-solvers to a group of users  in the case 
of experiment 1, and; b) recommending co-solvers to individual users in experiment 2. 
To gauge the performance of different permutations of profile expansion and similarity 
measures we used the following evaluation metrics: 

Discounted  Cumulative  Gain.  (DCG)  quantifies  the  value  of  items  in  the  top-n 
ranked suggestions as well as the quality of their ranking. For each ranking resulting 
from a particular ranking alternative, we take the 10 best-ranked user candidates and 
look at the ratings users generated for them. If the user candidate found at position i is 
rated positively by users we take rating to be 1, otherwise we consider it being equal 
to  0. The  importance  of  positively  ranked  candidates  found  on  lower  positions  in  a 
particular  ranking  is  downgraded  logarithmically  in  order  to  favour  ranking 
alternatives that put the best candidates towards the top.  
Average Precision. (AvePn) computes the average value of precision as a function of 
recall,  on  the  interval  recall  [0,1].  For  each  position  in  a  concrete  ranking  we 
calculate the precision up to that point, and the gain in recall acheived at that point as 
opposed to the previous point. The product of those gives an idea of the value a user 
would gain by looking at the suggestions up to a particular rank. 

DCG = rating1

+

10

i=2

ratingi
log2 i

(5)  

    

4.1  Evaluation 1 

(6) 

    

In our first evaluation, we approached a group of 3 researchers from the field of the 
Semantic  Web  and  presented  them  with  our  3  problems  for  which  they  were 
collectively,  as  a  group,  only  partially  competent.  For  each  rater  we  generated  cosolver  suggestions  using  different  combinations  of  similarity  measures  and  profile 
expansion  approaches.  We  then  took  the  top-10  suggestions  from  each  different  

M. Stankovic, M. Rowe, and P. Laublet 

method and mixed all the suggestions together in one randomized list. This resulted in 
reasonably  sized  lists  (i.e.,  30-50),  as  some  users  were  recommended  by  several 
methods, but on the other hand limited the possibilities of evaluation to the methods 
defined  prior  to  user  rating.  The  raters  then  rated  candidates  by  answering  if  they 
would  work  with  the  suggested  user  on  the  given  innovation  problem.  Raters  were 
instructed to base their ratings on a holistic perception of suitability of the suggested 
user, and only positively rate the users who are both competent and who seem to be 
potential co-workers. Prior to calculation of any performance measures we calculated 
the inter-rater agreement using the kappa statistic defined in [33] for each pair of raters. 
The value of k was, at first, inferior to the threshold of 0.6 for some of the rater pairs. 
We then allowed the raters to anonymously see the ratings of other group members and 
alter their ratings if they felt the others were right. After the second round the interrater agreement was superior to 0.6 for all 3 problems and for all problems (0.74 on 
average). We then used the majority agreement between raters to derive our decision 
labels for each candidate user (i.e., recommended or not recommended). 

 

Fig.  2.  DCG  of  rankings  obtained  with  different  methods  of  expansion  applied  to  problem 
profiles (right) and to seed user profiles (left) 

DCG  values  for  similarity  measures  based  on  Cosine  and  Weighted  Overlap 
functions run with all three expansions methods are shown on Figure 2. In the case of 
rankings based on the similarity with the difference topics, it is clear that the HSPR 
method of profile enrichment dominates the other expansion methods. This method is 
much  less  efficient  when  it  comes  to  ranking  based  on  the  interest  similarity  of 
candidate  users  to  the  seed  users,  where  DMSR  slightly  outperforms  the  other 
methods,  with  a  little  improvement  over  the  standard  approach.  The  figure  shows 
average values over all 3 problems, and the differences in method performance have 
been  confirmed  to  be  significant  by  the  T  test  (p<0.05)  for  HPSR  with  DMSR  in 
similarity with difference topics, but not in the case of interest similarity. It should be 
noted  that  our  expansion  methods  are  not  applicable  to  the  calculation  of  social 
similarity  as  this  measure  relies  on  SP  vectors  that  contain  no  topics.  It  is  indeed 
reasonable to expect that distributional measures, based on the distribution of topics in 
user profiles would work well on user-to-user similarity. The enrichment of problem 
topics using Linked Data-based measures, on the other hand, has already been shown 
to perform  well in keyword suggestion scenarios [31] and it is reasonable to expect 
that an enrichment based on the meaning of topics would allow better mapping of the 
problems  conceptual  space  and  reach  users  whose  profiles  have  a  more  complete 
coverage of this space.  
?

?

?
4.2  Evaluation 2 
In  our  second  evaluation,  we  solicited  ratings  from  12  individual  Twitter  users, 
experts in the field of Semantic Web. Similar to the previous study, we provided them 
with the list of candidate co-solvers and asked them to select those that they  would 
work  with  on  a  given  problem,  for  which  they  were  only  partially  competent.  The 
same  3  problems  were  used  by  each  rater,  thereby  resulting  in  36  sets  of  rated 
suggestions. This time, in order to generate a more reusable gold standard, we asked 
the  raters  to  evaluate  all  the  possible  user  candidates  we  collected  whose  profiles 
contained  at  least  one  of  the  difference  topics.  Each  set  of  suggestions  for  each 
problem-user  pair  contained  80-240  suggestions  to  evaluate.  This  was  timeconsuming  for  raters  but  resulted  in  a  gold  standard  that  covered  virtually  all 
candidates that could be recommended by any variation of our approach. Such a gold 
standard  allowed  us  to  perform  additional  comparisons  of  methods,  and  especially 
focus on composite similarity measures that were not the subject of the first study. 

Ranked  candidate  lists  were  generated  using  the  following  combinations  of 

similarity functions and profile expansion methods: 

composite similarity.  

  PC(Cosines,Cosinedt,Cosinet): composite function that is a product of interest, 
social and the similarity with difference topics counted using cosine similarity. 
  PRF(PC(Cosines,Cosinedt,Cosinet)):  PRF  problem  profile  expansion  with 
  PC(Cosines,HPSR(Cosinedt),Cosinet): HPSR expansion performed on difference 
  PC(Cosines,Cosinedt,DMSR(Cosinet)):  DMSR expansion performed over the 
  PC(Cosines,  HPSR(Cosinedt),DMSR(Cosinet)):  composite  function  in  which 
HPSR is used to expand profile topics and DMSR to expand seed user topic 
profile prior to calculating the similarities. 

topics prior to calculating the similarity with difference topics.  

seed user profile prior to calculating interest similarity.  

In the above user study we described the results obtained when using hyProximity and 
Distributional  profile  expansion  measures  over  the  elementary  similarity  functions. 
For  brevity,  in  this  section,  we  omit  these  results  from  the  second  study  and 
concentrate on the remaining permutations and their combinations using a composite 
similarity function  something that was not possible in the first study. We focus on 
composite measures as they allow us to gain a more complete insight in the impact of 
profile expansion on our multi-criteria recommendation task as a whole. As shown on 
Figure  3,  according  to  the  DCG  measure  for  the  first  10  ranked  suggestions,  the 
approaches with topic enrichment by either PRF, HPSR or DMSR consistently show 
better results than the basic approach, on all 3 problems. The overall values are on an 
expected  level  for  the  relevance  scale  used.  HPSR  performs  slightly  better  then  the 
other methods in most cases. However the mixed aggregate function (where HPSR is 
applied to the enrichment of problems and DMSR to the enrichment of user profiles) 
mostly  gives lower results than the  individual enrichment  approaches. The cause of 
this might simply be that expanding both problem and seed user profiles induces too 
much  of  a  difference  with  regards  to  the  input  data  and  might  divert  the  co-solver 
search to a non-desired direction. The results shown on the Figure 4 represent the case 
when  the  Cosine  similarity  function  is  used.  When  the  Weighted  Overlap  is  used, 
results show negligible differences with the order of best alternatives unchanged, and 
are omitted for brevity reasons.  

M. Stankovic, M. Rowe, and P. Laublet 

Fig. 3. Average DCG for all raters for different alternatives of composite similarity functions  

 

 

Fig. 4. AvePn of composite approaches (y axis), counted at different rank positions from 1-40 
(x axis). Better approaches reach higher AveP at lower ranks. 

Similar  results  are  observed  with  the  Average  Precision  used  as  the  performance 
metric (FIgure 4). It shows that even on a larger set of best ranked candidates (40) the 
individual  expansion  methods  dominate  the  mixed  one.  All  the  expansion  methods 
also  dominate  the  basic  approach.  The  methods  that  gain  higher  values  of  AveP  at 
lower numbers of rank positions are the ones that give more valuable suggestions at 
higher ranks and alow the user to discover valuable collaborators wile going through a 
lower number of suggestions. In this case, HSPR enrichment has slightly better results 
then  the  other  methods.  In  order  to  give  a  better  insight  into  the  usefulness  of  rhe 
results generated with our aproach we provide an example of co-solver suggestions on 
our website12. 

Conclusions and Future Work 

In this paper we proposed an approach for suggesting co-solvers to a person engaged 
in  solving  a  problem  (industrial  or  research  challenge)  that  has  only  partial 
competence  and  is  looking  for  a  complementary  and  compatible  collaborator.  Our 
work  explored  two  central  questions:  how  can  we  suggest  appropriate  co-solvers, 
which were potentially, previously unknown to the user? And: what information can 
be  used  to  enrich  initially  available  user  and  problem  data  to  provide  the  best 

                                                           
12 http://research.hypios.com/?page_id=184 
?

?

?
suggestions?  In  addition  to  standard  profiling  techniques  aimed  at  creating  profiles 
with  topic  concepts  referring  to  resources  defined  in  the  Linked  Data  Cloud,  we 
proposed ways for expanding the profiles with additional relevant profiles in order to 
improve the final co-solver suggestions based on commonly used similarity methods. 
Through two user studies we have demonstrated that our Linked Data-based measure 
of  semantic  relatedness  HPSR  performs  better  then  state  of  the  art  measures  when 
applied  with  the  expansion  of  problem  profiles,  while  a  commonly  used  measure 
based on the distribution of topics in user profiles performs better when it comes to 
expanding the seed user profile. When applied to composite similarity measures that 
reflect the social and interest similarity of candidate users (suggested co-solvers) with 
the seed user (user requiring help), as well as their complementarily with regards to 
the  problem,  all  of  the  profile  expansion  methods  outperform  the  simple  approach, 
while  HPSR  used  to  expand  problem  profiles  is  slightly  better  than  the  others. 
Combined  expansion  of  both  problem  and  seed  users  profiles  does  not  outperform 
individual expansions. One of the future work directions will be to experiment with 
the graph-based measures of similarity, in addition to the vector measures presented 
in this paper.  

Acknowledgments. The work of Milan Stankovic has been partially funded by ANRT 
under the grant number CIFRE N 789/2009. The work of Matthew Rowe was supported 
by the EU-FP7 projects WeGov (grant no. 248512) and Robust (grant no. 257859). 
