Unsupervised Learning of Link Discovery

Configuration

Andriy Nikolov, Mathieu dAquin, and Enrico Motta

Knowledge Media Institute, The Open University, Milton Keynes, UK

{a.nikolov,m.daquin,e.motta}@open.ac.uk

Abstract. Discovering links between overlapping datasets on the Web is
generally realised through the use of fuzzy similarity measures. Configuring such measures is often a non-trivial task that depends on the domain,
ontological schemas, and formatting conventions in data. Existing solutions either rely on the users knowledge of the data and the domain or on
the use of machine learning to discover these parameters based on training data. In this paper, we present a novel approach to tackle the issue of
data linking which relies on the unsupervised discovery of the required
similarity parameters. Instead of using labeled data, the method takes
into account several desired properties which the distribution of output
similarity values should satisfy. The method includes these features into
a fitness criterion used in a genetic algorithm to establish similarity parameters that maximise the quality of the resulting linkset according to
the considered properties. We show in experiments using benchmarks as
well as real-world datasets that such an unsupervised method can reach
the same levels of performance as manually engineered methods, and how
the different parameters of the genetic algorithm and the fitness criterion
affect the results for different datasets.

Introduction

Identity links between data instances described in different sources provide major added value of linked data. In order to facilitate data integration, newly
published data sources are commonly linked to reference repositories: popular
datasets which provide good coverage of their domains and are considered re-
liable. Such reference repositories (e.g., DBpedia or Geonames) serve as hubs:
other repositories either link their individuals to them or directly reuse their
URIs. However, establishing links between datasets still represents one of the
most important challenges to achieve the vision of the Web of Data. Indeed, such
a task is made difficult by the fact that different datasets do not share commonly
accepted identifiers (such as ISBN codes), do not rely on the same schemas and
ontologies (therefore using different properties to represent the same informa-
tion) and often implement different formatting conventions for attributes.

Automatic data linking often relies on fuzzy similarity functions comparing
relevant characteristics of objects in the considered datasets. More precisely, a
data linking task can be specified as the evaluation of a decision rule establishing

E. Simperl et al. (Eds.): ESWC 2012, LNCS 7295, pp. 119133, 2012.
c Springer-Verlag Berlin Heidelberg 2012

A. Nikolov, M. dAquin, and E. Motta

whether two individuals should be considered equivalent, based on the value of
a function aggregating the similarity comparisons of some properties of these
individuals. In most systems, establishing the appropriate decision rule is left
to the user, who needs to rely on his/her knowledge of the domain, of the data
in both datasets, and on his/her intuition regarding the performance of various
similarity functions in the considered linking situation. Other systems try to
alleviate the issue of establishing the decision rule for linking by using machine
learning techniques. They however require a substantial set of training data in
the form of pre-established links within a subset of the considered datasets.

In this paper, we investigate the question: can a suitable decision rule for linking two datasets be learned without possessing labelled training data, based only
on the characteristics of the datasets and on the distribution of similarity values
amongst their instances? Our hypothesis is that in a scenario which involves
establishing links to reference datasets, available information (e.g., knowledge
that the datasets do not contain duplicates and have high degree of overlap) can
provide sufficient evidence to learn a decision rule which would determine identity mappings between instances in two datasets with high accuracy. To learn
such rules, we propose an approach based on a genetic algorithm, which evolves
a set of initially random solutions to a problem according to a fitness criterion.
Following research in the area of record linkage in databases, we devise an applicable fitness criterion which relies on the distribution of links and similarity
values generated by applying a particular decision rule.

To test our assumptions, we apply this approach to the benchmark datasets
from the OAEI 2010 and 2011 instance matching contests. We show that applying the learned decision rule for data linking achieves results at the level of
the best state-of-the-art tools, without the need to configure linking parameters
for each task. We also experiment with subsets of real-world linked datasets to
demonstrate the robustness of the approach to different types of datasets in different domains and discuss the effects of some of the parameters of the genetic
algorithm on its behaviour in data linking tasks. The remainder of this paper
is structured as follows. In section 2, we provide an overview of the basic notions of the link discovery problem and relevant work in both Semantic Web and
database research communities. Section 3 describes our algorithm in detail. Section 4 describes the experiments we performed in order to validate our approach.
Section 5 concludes the paper and discusses directions for future work.

2 Problem Definition and Related Work

In this section, we specify the tasks of link discovery and of establishing the
necessary decision rule, together with a brief description of the relevant existing
work.

2.1 Link Discovery Problem

The problem of reconciliation was originally studied in the database community where it is known as record linkage or object identification [3]. With the
?

?

?
development of the linked data initiative, it gains importance in the Semantic
Web community where it is studied under the name of link discovery [14]. The

link discovery task takes as inputs two datasets D1 and D2 and tries to discover
all pairs of individuals (I1i, I2j) belonging to these datasets such that they describe the same entity  according to a chosen identity criterion. In the context
of linked data, datasets D1 and D2 represent RDF graphs and their individuals

are identified by URIs.

Existing techniques solving this task can be divided into two main categories:
individual matching and dataset matching. We essentially focus on individual
matching in this paper. Dataset matching techniques are built on top of individual matching ones: they take as input two datasets as a whole together with the
initial set of mappings produced by individual matching and further refine them.
These techniques take into account additional available information such as relations between individuals, axioms defined in the ontological schema, and mutual
impact of different mappings. The individual matching task can be defined as
follows.

Definition 1: Let I1i  I1 and I2j  I2 represent two individuals in instance
sets I1 and I2. The individual matching task takes I1i and I2j as input and makes
a decision whether I1i  I2j (in which case they are said to be matching) or not.
A profile P (I) is defined as a set of pairs {(ai, Vi)}, where ai represent attributes

This decision is made based on the comparison of the profiles of two individuals.

describing an individual (e.g., name, age, colour, etc.), each of which has a
set of values Vi. The output of individual matching is a set of mappings M =
{(I1i, I2j)} believed to represent equivalent individuals I1i  I2j .

Most individual matching techniques follow the approach proposed in a seminal paper by Fellegi & Sunter [6], in which the decision is based on a similarity

The similarity function commonly takes the form of aggregated similarity over

function sim(P (I1), P (I2)) which returns a degree of confidence that I1  I2.
attributes sim(P (I1), P (I2)) = fagg({simi(V1i, V2i)}), where fagg is an aggregation function and simi is a comparison function, which returns a degree of
similarity between two values of the attribute ai. The decision rule then takes
the form of applying a filtering criterion which determines whether the confidence degree returned by the similarity function is sufficient to consider a pair
of individuals as identical. The threshold-based criterion is commonly used: a

mapping (I1, I2) is returned if sim(P (I1), P (I2))  t, where t is a threshold.

2.2 Establishing a Decision Rule for Individual Matching

As can be seen from the description above, the key component of an individual
matching method is the decision rule. For a given pair of datasets to link, a decision rule has to be established that incorporates comparisons between relevant
pairs of properties using appropriate similarity functions, weights, and thresholds
to obtain an adequate discriminative ability.

Some systems assume that a pre-established, generic similarity measure can
be employed across domains. This approach is often followed by systems targeted for the global scale link discovery (e.g., OKKAM [13]), generic ontology

A. Nikolov, M. dAquin, and E. Motta

matching systems (e.g., RiMOM [9]), or systems which primarily rely on the
dataset matching stage (e.g., CODI [12]). However, in most other cases, a dedicated decision rule has to be established for each link discovery task (i.e., each
pair of datasets to link). Existing systems in the Semantic Web area take two
different approaches to realise this:

Manual configuration. where the decision rule is specified by the user. Besides requiring user effort, the clear disadvantage of such an approach is that
it relies on extensive knowledge from the user of the structure and content of
the two datasets to link, as well as on a reasonable level of intuition regarding the performance of (often complex) similarity functions in a particular
situation.

Learning from training data. where the appropriate decision rule is produced by analyzing the available labeled data. This method is followed, for
example, by the ObjectCoref system [7]. This alleviates the need for user input to establish the decision rule, but requires the availability of a substantial
set of robust training data (although some methods, like active learning [10]
can reduce the required amount of data).

Here we investigate a third category of approaches that relies on the characteristics of the datasets and of the similarity distributions resulting from comparing
them to establish high performing decision rules in an unsupervised way. Several
solutions in the database research community proposed to use the distribution
features of similarity functions. For example, in [2] individuals are clustered into
matching and non-matching classes based on the structure of their neighbourhood rather than on simple threshold filtering. Zardetto et al [15] proposed to
use prior knowledge about the features of the similarity distribution  namely,
that correct mappings are dominant in the area of high similarity values and that
matches are very rare in comparison with non-matches. These features are used
to build a mixture model, which is later used for classifying candidate mappings
into matching and non-matching.

Considering the task of linking to a reference repository, we can make several

assumptions about the datasets and the desired instance matching output:

 Assumption 1: While different URIs are often used to denote the same
entity in different repositories, distinct URIs within one dataset can be expected to denote distinct entities.

 Assumption 2: Datasets D1 and D2 have a strong degree of overlap.

 Assumption 3: A meaningful similarity function produces results in the
interval {0..1} and returns values close to 1.0 for pairs of matching individ-
uals.

The method described in this paper proposes to use a genetic algorithm guided
by a fitness criterion using these assumptions to assess the expected quality of
a decision rule, and of the derived set of links. Our method goes a step further
than existing methods, as it chooses an appropriate similarity function for a
given matching task as well as a suitable filtering criterion, rather than relying
?

?

?
on given similarity functions. Hence, producing a solution requires selecting multiple parameters of the decision rule simultaneously, such as similarity functions,
comparable attributes, and weights.

For such problems where a suitable complex function has to be found based
on its desired output, genetic algorithms are known to perform well on many
practical tasks, and have already been applied to the instance matching problem
in the context of supervised learning [1], [8]. The idea here is to use such an approach to evolve a population of candidate solutions (i.e., decision rules) using
selection and variation mechanisms to favour the fittest solutions in each gen-
eration, therefore presumably converging to decision rules that can be optimally
applied to link the two given datasets.

3 Algorithm

Applying a genetic algorithm to the problem of optimizing a decision rule requires solving three issues: how relevant parameters of a decision rule are encoded
as a set of genes, what fitness measure to use to evaluate candidate solutions,
and how to use selection and variation operators to converge on a good solution.

3.1 Representing Individual Matching in Terms of a Genetic

Algorithm

Definition 2: Let Ci represent a candidate solution to a given optimization task
T 1. Assume that Ci can be encoded as a set of numeric parameters. Then, the
term gene gij denotes the jth parameter of the candidate solution Ci, genotype
or chromosome G(Ci) =< gi1, . . . , gin > denotes a set of genes representing
a candidate solution Ci, and population G = {G1, . . . GN} represents a set of

N chromosomes encoding candidate solutions for the task. A fitness function
Ff it(Ci) is a function which provides an estimation of the quality of a solution.
An initial population is used as a pool of candidates, from which the algorithm
selects the best chromosomes according to the fitness function. In order to find
a solution which optimizes the fitness function, the algorithm updates the initial
population by using selection and variation operators:

 Selection chooses a subset of chromosomes in the original population to be

used in the creation of the new one.

 Variation changes the genes of the selected chromosomes to generate new
candidate solutions from the old ones. Commonly used variation operators
include crossover, which recombines elements of several parent chromosomes to produce several new chromosomes (or children), and mutation,
which produces a new chromosome by randomly tweaking the genes of the
original one.

1 The term individual is used both in the Semantic Web domain to denote ontological instances and in the evolutionary computation area, where it refers to candidate
solutions. To avoid confusion, we use it only in its first sense, while using the term
candidate solution when talking about the output of the genetic algorithm.

A. Nikolov, M. dAquin, and E. Motta

The updated population is created by applying these operators to selected chromosomes from the original one. Then, the same steps are performed for the
updated population, and the algorithm continues iterating until the optimal solution (or one sufficiently close to the optimum) is produced or a termination
condition is satisfied: e.g. maximal number of iterations is reached or the fitness of the population does not improve for a long time. The candidate solution
Cbest = argmax(Ff it(Ci)) is returned by the algorithm as its output.

To apply a genetic algorithm to the individual matching problem, we need to
represent candidate decision rules as a set of genes. Similarly to many existing
approaches (see section 2), we represent a decision rule using an aggregated
attribute similarity function.
Definition 3: A decision rule for an individual matching task is defined as:
f ilt(sim(P (I1), P (I2))) where sim(P (I1), P (I2)) is the similarity function
comparing profiles of two individuals, and f ilt(sim(P (I1), P (I2))) is a boolean
filtering function. The similarity function takes the form

sim(P (I1), P (I2)) = fagg(w11sim11(V11, V21), . . . , wmnsimmn(V1m, V2n))

 simij is the function which measures similarity between the values of the
attributes a1i of P (I1) and a2j of P (I2),
 wij is a numeric weight (0  wij  1),
 fagg is an aggregation function.

We considered two alternative filtering criteria: the threshold-based one and the

nearest neighbour one. The former requires that sim(P (I1), P (I2))  t, where t
is a threshold value. The latter chooses for each instance I1 in the source dataset
such I2 that sim(P (I1), P (I2)) = max(sim(P (I1), P (Ij ))). This criterion is applicable in cases where we expect each I1 to have a matching I2.

Each of these parameters is represented by a gene in the following way:

 simij are encoded as nominal values representing corresponding attribute
similarity functions (or nil, if a1i and a2j are not compared). We included a
number of character-based functions (edit distance, Jaro, I-Sub, etc., and the
corresponding token-based similarity metrics. The latter divide both string
values into sets of tokens, then compare each pair of tokens using a characterbased similarity function and try to find the best match between them.

 Weights of each attribute comparison pair wij and the threshold t are en-

coded using their real values.

 fagg is encoded as a nominal value representing one of two types of aggrewij simij (a1i,a2j )
gation functions: weighted average avg(P (I1), P (I2)) =
and maximum max(P (I1), P (I2)) = max({wij simij(a1i, a2j)}). In the latter case the weights wij can only take values 0 or 1.

wij
?

?

?
These genotypes are evaluated by applying the decision rule to the matching
task and calculating the fitness function.
?

?

?
3.2 Fitness Functions: Pseudo-F-measure and Neighbourhood

Growth

In the absence of labelled data it is not possible to estimate the quality of a set
of mappings accurately. However, there are indirect indicators corresponding to
good characteristics of sets of links which can be used to assess the fitness of a
given decision rule. To establish such indicators, we rely on the assumptions we
made about the matching task. Traditionally, the quality of the matching output
is evaluated by comparing it with the set of true mappings M t and calculating
|tp|+|f p| , where
the precision p and recall r metrics. Precision is defined as p =
tp is a set of true positives (mappings m = (I1, I2) such that both m  M and
m  M t) and f p is a set of false positives (m  M , but m / M t). Recall is
|tp|+|f n| , where f n is a set of false negatives (m / M , but
|tp|
calculated as r =
m  M t). In the absence of gold standard mappings, we use Assumption 1 to
formulate the pseudo-precision and pseudo-recall measures in the following way:

|tp|

|M|



=




value p

=

|{Ii|Ij:(Ii,Ij )M}|
?

?

?
Definition 4: Let M represent a set of mappings (Ii, Ij ) between two sets of
individuals I1, I2 such that Ii  I1, Ij  I2. Then, pseudo-precision is the
min(|I1|,|I2|) .
= 1: of two
mappings from the same individual one is necessarily an error. Similarly, in case
where r = 1, the number of returned mappings will be equal to the size of the

i |{Ij|(Ii,Ij )M}| , and pseudo-recall is the value r

In an ideal case where p = 1, if Assumption 1 holds, then p

overlap between two instance sets |M| = no = |I1  I2|, and the pseudo-recall
|M|
no = 1. However, estimating the true recall is problematic since no
is not known in advance. From Assumption 1 it follows that no  min(|I1|,|I2|),
while no = min(|I1|,|I2|) if one instance set is a subset of another. Incorrect
estimation of no can be misleading for the genetic algorithm: it can result in
lenient decision rules being favored and, in consequence, to many false positives in the resulting solution. To deal with such cases, we reduce the impact of
incorrect recall estimations in the final fitness function.

value r



=

A standard metric combining precision and recall is the F-measure F =
(1+2)pr
2p+r
, where  characterizes the preference of recall over precision, and  =
1 means equal importance of both. To reduce the impact of recall, we used
0.01p+r . In this way, solutions
 = 0.1 and the pseudo-F-measure F
which increase precision are favored, while recall is only used to discriminate
between solutions with similar estimated precision. This cautious approach is
also consistent with the requirements of many real-world data linking scenarios,
as the cost of an erroneous mapping is often higher than the cost of a missed
correct mapping.


0.1 = 1.01p

r




f it = F

In order to incorporate Assumption 3, the final fitness function gives a preference to the solutions which accept mappings with similarity degrees close to
 (1  (1  simavg)2). In this way, the fitness function is able
1: F
to discriminate between such decision rules as avg(0.5  jaro(name, label), 0.5 
edit(birthY ear, yearOf Birth))  0.98 and avg(0.05  jaro(name, label), 0.05 
edit(birthY ear, yearOf Birth), 0.9  edit(name, yearOf Birth))  0.098. While


0.1

A. Nikolov, M. dAquin, and E. Motta

While we used F

these two rules would produce the same output in most cases, comparing irrelevant attributes (like name and yearOf Birth) is not desirable, because it
increases a possibility of spurious mappings without adding any value.


f it as the main fitness criterion, to test the effect of the choice
of a fitness function on the performance of the genetic algorithm, we implemented
an alternative fitness function: the neighbourhood growth function F N G
f it . While
the pseudo F-Measure tries to estimate the quality of resulting mappings to guide
the evolution of candidate solutions, F N G
f it tries to exploit the desired property of
a good similarity function: namely, that it should be able to discriminate well
between different possible candidate mappings. To measure this property, we
adapt the neighbourhood growth indicator defined in [2] to achieve an optimal
clustering of instance matching results for a pre-defined similarity function, as
an alternative to the threshold-based filtering criterion. We adapt this indicator
as an alternative fitness criterion for selecting the most appropriate similarity
functions.
Definition 5: Let Mx represent a set of mappings (Ix, Ixj) between an individual Ii  I1 and a set of individuals Ixj  I|  I. Let simmax =
max(sim(P (Ix), P (Ixj ))) Then, neighbourhood growth N G(Ix) is defined as
the number of mappings in Mx such that their similarity values are higher than
1  c  (1  simmax), where c is a constant.

Intuitively, high values of N G(Ix) indicate that the neighbourhood of an instance is cluttered, and the similarity measure cannot adequately distinguish
between different matching candidates. Then the fitness function for a set of
compared instance pairs M is defined as F N G
f it = 1/avgx(N G(Ix)). As this function does not require applying the filtering criterion, it only learns the similarity
function, but not the optimal threshold. However, the threshold can be determined after the optimal similarity function has been derived: t is selected in such
a way that it maximises the F


f it function over a set of compared pairs.

3.3 Obtaining the Optimal Solution: Genetic Algorithm

The algorithm takes as input two instance sets I1 and I2 and two sets of potential
attributes A1 and A2. Each set of attributes Ai includes all literal property values
at a distance l from individuals in Ii. In our experiments we used l = 1, however,

also including the paths of length 2 if an individual was connected to a literal
through a blank node. In order to filter out rarely defined properties, we also
remove all attributes aij for which

|{P (Ii)|aijP (Ii),IiI}|

|I|

< 0.5.

As the first step, the algorithm initializes the population of size N . For the

initial population, all values of the genotype are set in the following way:

 A set of k pairs of attributes (a1i, a2j) is selected randomly from the corre-

sponding sets A1 and A2.

 For these pairs of attributes the similarity functions simij and the corresponding weights wij are assigned randomly while for all others are set to
nil.
?

?

?
 The aggregation function and the threshold are initialized with random val-
?

?

?
ues, and the weights are normalized so that

wij = 1.

All initial solutions only compare a single pair of attributes (k = 1): this is done
to identify highly discriminative pairs of attributes at the early iterations, and
then improve these solutions incrementally.

Each iteration of the algorithm consists of two stages: selection and repro-
duction. At the selection stage, each candidate solution is applied to produce

mappings between individuals from I1 and I2. In case of large-scale datasets,
random sampling can be applied, so that the solutions are only applied to a
 I1. The calculated Ff it fitness measure is used for the selection of
subset I S
candidate solutions for reproduction. Our algorithm uses the standard roulette
wheel selection operator: the probability of a chromosome being selected is proportionate to its Ff it fitness. At the reproduction stage, a new population of
chromosomes is generated by three different operators: elitist selection, crossover,
and mutation. In the new population, the proportion of chromosomes produced
by each operator is proportional to its rate: elitist selection rate rel, crossover
rate rc, and mutation rate rm (rel + rc + rm = 1). Elitist selection copies the
best subset of chromosomes from the previous population. The crossover operator takes two parent chromosomes and forms a pair of children: each gene of
the parent is passed to a randomly chosen child, while another child inherits a
corresponding gene of the second parent. Finally, mutation modifies one of the
genes of the original chromosome in one of the following ways:

 Adding or removing a comparison between attributes with a probability pm

att.
The operator either changes the similarity function for a pair of attributes to
nil or selects a random similarity function and weight for a pair of attributes
not compared in the original chromosome. The probability of adding a component (versus removing one) is calculated as padd = 1
n+ , where n+ is the
number of non-nil similarity comparisons in the original solution.
 Changing one of the weights wij for a pair of attributes where simij = nil,
wgt. The value of the change is calculated as 0.8rnd+0.2

with a probability pm
where rnd is a random number between 0 and 1.

n+

,

 Changing a non-nil similarity function for a pair of attributes into a ran-

domly selected one with a probability pm

sym.

 Modifying the threshold value with the probability pm

t : the algorithm decides
whether the current threshold should be increased or decreased with the
probability 0.5. The new threshold is set as tnew = told  t, where t =
rnd  (1  p
)told for decrease. The
rationale behind this is to make bigger steps if precision/recall values are far
from desired.

)(1  told) for increase and rnd  (1  r





 Changing the aggregation function with pm

agg.

At the new iteration, chromosomes in the updated population are again evaluated using the Ff it fitness function, and the process is repeated. The algorithm
stops if the pre-defined number of iterations niter is reached or the algorithm

A. Nikolov, M. dAquin, and E. Motta

converges before this: i.e., the average fitness does not increase for nconv gener-
ations. The phenotype with the best fitness in the final population is returned
by the algorithm as its result.

4 Evaluation

To validate our method, we performed experiments with two types of datasets.
First, we tested our approach on the benchmark datasets used in the instance
matching tracks of the OAEI 2010 and OAEI 2011 ontology matching competi-
tions2, to compare our approach with state-of-the-art systems. Second, we used
several datasets extracted from the linked data cloud to investigate the effect of
different parameter settings on the results.

4.1 Settings

As discussed above, a genetic algorithm starts with an initial population of random solutions, and iteratively create new generations through selection, mutation and crossover. In our experiments, we used the following default parameters:

 rates for different recombination operators: rel = 0.1, rm = 0.6, and rc = 0.3.
 rates for different mutation options: pm
sym = 0.15,
agg = 0.1 (ensuring equivalent probabilities for modifying the list

pm
t = 0.3, pm
of compared properties, comparison parameters, and the threshold).

att = 0.3, pm

wgt = 0.15, pm

 termination criterion: niter = 20 (found to be sufficient for convergence in

most cases).

 fitness function: F


f it, except when comparing F


f it with F N G
f it

The genetic algorithm is implemented as a method in the KnoFuss architecture [11]. Relevant subsets of two datasets are selected using SPARQL queries.
Each candidate decision rule is used as an input of the KnoFuss tool to create the
corresponding set of links. To reduce the computation time, an inverted Lucene3
index was used to perform blocking and pre-select candidate pairs. Each individual in the larger dataset was indexed by all its literal properties. Each individual
in the smaller dataset was only compared to individuals returned by the index
when searching on all its literal properties, and pairs of compared individuals
were cached in memory. Common pre-processing techniques (such as removing
stopwords and unifying synonyms) were applied to the literal properties.

4.2 Benchmark Test

The OAEI 2010 benchmark contains three test cases: Person1 and Person2,
which contain artificially distorted records of people, and Restaurants, which
includes data about restaurants from the RIDDLE repository4. Two versions

2 http://oaei.ontologymatching.org/
3 http://lucene.apache.org
4 http://www.cs.utexas.edu/users/ml/riddle/data.html
?

?

?
Table 1. Comparison of F1-measure with other tools on the OAEI 2010 benchmark [4]

KnoFuss+GA ObjectCoref ASMOV CODI LN2R RiMOM FBEM
Dataset
1.00
Person1
0.99
Person2
Restaurant (OAEI) 0.78
Restaurant (fixed) 0.98

1.00 1.00
0.91
0.97
0.94
0.36
0.81
0.75
0.72
N/A N/A N/A

1.00
0.35
0.70
N/A

1.00
0.95
0.73
0.89

N/A
0.79
N/A
0.96

of the Restaurants dataset exist: the version originally used in the OAEI 2010
evaluation which contained a bug (some individuals included in the gold standard
were not present in the data), and the fixed version, which was used in other
tests (e.g, [13], [7]). To be able to compare with systems which used both variants
of the dataset, we also used both variants in our experiments. The OAEI 2011
benchmark includes seven test cases, which involve matching three subsets of
the New York Times linked data (people, organisations, and locations) with
DBpedia, Freebase, and Geonames datasets.

We compared our algorithm with the systems participating in the OAEI 2010
tracks as well as with the FBEM system [13], whose authors provided the benchmark datasets for the competition. We report in Table 1 on the performance of
the KnowFuss system using decision rules learned through our genetic algorithm
(noted KnowFuss+GA) as the average F1-Measure obtained over 5 runs of the
algorithm with a population size N = 1000. The solution produced by the

Table 2. Example decision rules found by the algorithm with N = 1000

Test case
Person1

Person2

Similarity function
max(tokenized-jaro-winkler(soc sec id;soc sec id);
monge-elkan(phone number;phone number))

max(jaro(phone number;phone number);
jaro-winkler(soc sec id;soc sec id))

Restaurants avg(0.22*tokenized-smith-waterman(phone number;phone number);
(OAEI)
Restaurants avg(0.35*tokenized-monge-elkan(phone number;phone number);
(fixed)

0.65*tokenized-smith-waterman(name;name))

0.78*tokenized-smith-waterman(name;name))

Threshold
0.87
0.88
0.91
0.88

genetic algorithm managed to achieve the highest F1-measure on 3 out of 4
datasets and the second highest F1-measure on 1 out of 4. Examples of produced decision rules are provided in Table 2. We observed that the algorithm
took less time on identifying discriminative pairs of properties and the aggregation function and more on tuning weights and attribute similarity functions. To
test the robustness of the results achieved by the algorithm with different set-
tings, we performed tests on the benchmark datasets varying the crossover rates
rc, and mutation rate rm. Surprisingly, varying the crossover rate and the mutation rate did not lead to significant changes in the results, except for extreme
values. These parameters mostly affected the number of generations needed to

A. Nikolov, M. dAquin, and E. Motta

Table 3. Comparison of F1-measure with other tools on the OAEI 2011 benchmark [5]

KnoFuss+GA AgreementMaker SERIMI Zhishi.links
Dataset
DBpedia (locations)
0.89
DBpedia (organisations) 0.92
0.97
DBpedia (people)
0.93
Freebase (locations)
Freebase (organisations) 0.92
0.95
Freebase (people)
0.90
Geonames
0.93
Average

0.92
0.91
0.97
0.88
0.87
0.93
0.91
0.92

0.69
0.74
0.88
0.85
0.80
0.96
0.85
0.85

0.68
0.88
0.94
0.91
0.91
0.92
0.80
0.89

converge to the optimal solution, and the algorithm usually converged well before
20 generations5.

Given the larger scale of the OAEI 2011 benchmark, to speed up the algorithm we used random sampling with the sample size s = 100 and reduced the
population size to N = 100. To improve the performance, a post-processing step
was applied: the 1-to-1 rule was re-enforced, and for a source individual only 1
mapping was retained. As shown in Table 3, these settings were still sufficient
to achieve high performance: the algorithm achieved the highest F 1 measure on
4 test cases out of 7 and the highest average F 1 measure. These results verify
our original assumptions that (a) the fitness function based on the pseudo-F-
measure can be used as an estimation of the actual accuracy of a decision rule
and (b) the genetic algorithm provides a suitable search strategy for obtaining
a decision rule for individual matching.

4.3 LOD Datasets

To test the reusability of our method in different real-world scenarios, we have
defined the following three matching tasks:

Music Contributors. As a source dataset, we selected a list of music contributors from the LinkedMDB dataset6. This dataset of 3995 individuals was
matched against the set of all people from DBpedia7 (363751 individuals).
The gold standard was constructed manually and included 1182 mappings.
Book Authors. To construct this dataset, we extracted a set of 1000 individuals describing book authors from the BNB dataset8 (from the first part of
the dump, we selected 1000 authors with the highest number of published
books). This dataset was also matched against the set of all people from
DBpedia. The gold standard was constructed manually and included 219
correct mappings.

Research Papers. To generate a matching task with a larger number of reliable gold standard mappings, we used a subset of 10000 research publications

5 The datasets and test results are available for download from our website:

http://kmi.open.ac.uk/technologies/knofuss/knofuss-GA-tests.zip

6 http://www.linkedmdb.org/
7 http://dbpedia.org
8 http://www.archive.org/details/Bibliographica.orgBnbDataset
?

?

?
represented in the L3S-DBLP dataset9 (out of the snapshot of 366113 publications included in the BTC 2010 dataset10). For these publications, we
extracted their RDF descriptions from the DOI web-site11. We used equivalent DOI codes to create the gold standard and then removed corresponding
properties from respective datasets to prevent the algorithm from using them
as an easy solution.

On each of these datasets, we applied the algorithm with the same default settings as used in the benchmark tests. We performed the experiments using two

different fitness functions: the unsupervised F
f it fitness function and the actual
F 1-measure produced using the gold standard dataset. The latter case represents an ideal scenario, in which a complete set of labeled data is available in
advance, and the algorithm only has to produce an optimal decision rule which
would approximate this data. For Music contributors and Book authors, we varied the population size N in order to estimate the necessary number of candidate
solutions which the algorithm has to test before achieving stable performance.
The results for these datasets are summarised in Table 4, which shows average
precision, recall, and F 1-measure achieved using two different fitness functions,
as well as the standard deviation of F 1 measure F 1 over 5 runs and the time

of a single run for the unsupervised case12. In both cases, F
f it allowed reaching

Table 4. Results with different population size

Dataset

Pop. size N

Music
contributors 100
?

?

?
Book
authors

F1-fitness (ideal case)
Precision Recall F1
0.92
0.91
0.91
0.90
0.98
0.99

0.92
0.93
0.93
0.93
0.95
0.98

0.92 0.90
0.92 0.92
0.92 0.92
0.91 0.66
0.97 0.78
0.98 0.91


f it-fitness (unsupervised)

Precision Recall F1 F 1 Time (s)

0.90
0.91
0.92
0.69
0.89
0.91

0.90 0.021 520
0.92 0.003 931
0.92 0.003 4197
0.68 0.022 753
0.82 0.13 1222
0.91 0.009 7281

high performance (F 1 above 0.9), and increasing the population size N led to
improvement in performance as well as more robust results (lower F 1). In fact,

for the Music contributors test case, the results produced using F
f it and the ideal
case F 1 were almost equivalent. For the Research papers dataset (Table 5), we
trained the algorithm on several samples taken from the DOI dataset and then
applied the resulting decision rules to the complete test case (10000 individuals in
the DOI dataset). This was done to emulate use cases involving large-scale repos-
itories, in which running many iterations of the genetic algorithm over complete
datasets is not feasible. From Table 5 we can see that starting from 100 sample individuals the algorithm achieved stable performance, which is consistent

9 http://dblp.l3s.de/
10 http://km.aifb.kit.edu/projects/btc-2010/
11 http://dx.doi.org/
12 Experiments were performed on a Linux desktop with two Intel Core 2 Duo proces-

sors and 3GB of RAM.

A. Nikolov, M. dAquin, and E. Motta

Table 5. Results obtained for the Research papers dataset (for all sample sizes, population size N = 100 was used)

Sample size
?

?

?
F1-fitness (ideal case)
Precision Recall F1
0.50
0.95
0.96
0.95

0.76
0.88
0.85
0.88

0.60 0.58
0.91 0.998
0.90 0.99
0.91 0.99


f it-fitness (unsupervised)

Complete set

Precision Recall F1 F 1 Time (s) Precision Recall F1

0.36
0.72
0.73
0.67

0.44 0.063 162
0.83 0.068 255
0.84 0.046 842
0.79 0.065 3667

0.68
0.995
0.98
0.997

0.22
0.68
0.75
0.71

0.33
0.81
0.85
0.83

with the results achieved for the OAEI 2011 benchmark. Applying the resulting
decision rules to the complete dataset also produced results with precision and
recall values similar to the ones achieved on the partial sample. Finally, to test

Table 6. Comparing the F

f it fitness functions


f it and F NG


f it-fitness

N G-fitness

Dataset

Precision Recall F1 Precision Recall F1
0.92
Music contributors
0.78
Book authors
NYT-Geonames
0.88
NYT-Freebase (people) 0.60

0.92 0.90
0.82 0.97
0.84 0.87
0.74 0.47

0.91
0.78
0.92
0.66

0.91
0.89
0.82
0.97

0.91
0.85
0.89
0.55


f it and neighbourhood growth F N G

the effect of the chosen fitness function on the performance, we compared the
pseudo-F-measure F
f it fitness functions. We
applied the algorithm to the Music contributors and Book authors datasets, as
well as to the NYT-Geonames and NYT-Freebase (people) test cases from the
OAEI 2011 benchmark (without applying post-processing). The results reported

in Table 6 show that both functions are able to achieve high accuracy with F

f it
providing more stable performance. This validates our initial choice of F
f it as
a suitable fitness criterion and reinforces our assumption that features of the
similarity distribution can indirectly serve to estimate the actual fitness.

5 Conclusion and Future Work

In this paper, we proposed a method which exploits expected characteristics
of good sets of mappings to estimate the quality of results of the individual
matching task. We formalised these characteristics to propose a fitness function
for a genetic algorithm, which derives a suitable decision rule for a given matching
task. Experiments, which we performed with both benchmark and real-world
datasets, have validated our initial assumptions and have shown that the method
is able to achieve accuracy at the level of the top-performing state-of-the-art data
linking systems without requiring user configuration, training data, or external
knowledge sources.

We plan to use the results presented in this paper to pursue several promising
research directions, in particular, combining our approach with more knowledgeinvolving dataset matching methods. On the one hand, dataset matching systems
?

?

?
have to rely on individual matching techniques to provide initial sets of mappings
for refining. For such systems, using initial mappings of better quality can be
beneficial. On the other hand, domain knowledge can be used to improve the
unsupervised fitness functions, for example to reduce the fitness of decision rules
whose results violate ontological restrictions.

Acknowledgements. Part of this research has been funded under the EC 7th
Framework Programme, in the context of the SmartProducts project (231204).
