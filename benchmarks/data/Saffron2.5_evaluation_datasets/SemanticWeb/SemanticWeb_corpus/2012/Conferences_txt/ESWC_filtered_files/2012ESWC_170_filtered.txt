EAGLE: Efficient Active Learning of Link
Specifications Using Genetic Programming

Axel-Cyrille Ngonga Ngomo and Klaus Lyko

Department of Computer Science

University of Leipzig Johannisgasse 26, 04103 Leipzig

ngonga@informatik.uni-leipzig.de, lyko.klaus@gmail.com

http://limes.sf.net

Abstract. With the growth of the Linked Data Web, time-efficient approaches for computing links between data sources have become indis-
pensable. Most Link Discovery frameworks implement approaches that
require two main computational steps. First, a link specification has to be
explicated by the user. Then, this specification must be executed. While
several approaches for the time-efficient execution of link specifications
have been developed over the last few years, the discovery of accurate
link specifications remains a tedious problem. In this paper, we present
EAGLE, an active learning approach based on genetic programming.
EAGLE generates highly accurate link specifications while reducing the
annotation burden for the user. We evaluate EAGLE against batch learning on three different data sets and show that our algorithm can detect
specifications with an F-measure superior to 90% while requiring a small
number of questions.

Introduction

The growth of the Linked Data Web over the last years has led to a compendium
of currently more than 30 billion triples [3]. Yet, it still contains a relatively low
number of links between knowledge bases (less than 2% at the moment). Devising approaches that address this problem still remains a very demanding task.
This is mainly due to the difficulty behind Link Discovery being twofold: First,
the quadratic complexity of Link Discovery requires time-efficient approaches
that can efficiently compute links when given a specification of the conditions
under which a link is to be built [14,21] (i.e., when given a so-called link specifica-
tion). Such specifications can be of arbitrary complexity, ranging from a simple
comparison of labels (e.g., for finding links between countries) to the comparison
of a large set of features of different types (e.g., using population, elevation and
labels to link villages across the globe). In previous work, we have addressed this
task by developing the LIMES1 framework. LIMES provides time-efficient approaches for Link Discovery and has been shown to outperform other frameworks
significantly [20].

1 http://limes.sf.net

E. Simperl et al. (Eds.): ESWC 2012, LNCS 7295, pp. 149163, 2012.
c Springer-Verlag Berlin Heidelberg 2012

A.-C. Ngonga Ngomo and K. Lyko

The second difficulty behind Link Discovery lies in the detection of accurate link specifications. Most state-of-the-art Link Discovery frameworks such
as LIMES and SILK [14] adopt a property-based computation of links between
entities. To ensure that links can be computed with a high accuracy, these frameworks provide (a) a large number of similarity measures (i.e., Levenshtein, Jaccard for strings) for comparing property values and (b) manifold means for combining the results of these measures to an overall similarity value for a given
pair of entities. When faced with this overwhelming space of possible combina-
tions, users often adapt a time-demanding trial-and-error approach to detect an
accurate link specification for the task at hand. There is consequently a blatant
need for approaches that support the user in the endeavor of finding accurate
link specifications. From a users perspective, approaches for the semi-automatic
generation of link specification must support the user by

1. reducing the time frame needed to detect a link specification (time efficiency),
2. generating link specifications that generate a small number of false positives

and negatives (accuracy) and

3. providing the user with easily readable and modifiable specifications (read-

ability).

In this paper, we present the EAGLE algorithm, a supervised machine-learning
algorithm for the detection of link specifications that abides by the three criteria
presented above. One of the main drawbacks of machine-learning approaches
is that they usually require a large amount of training data to achieve a high
accuracy. Yet, the generation of training data can be a very tedious process. EAGLE surmounts this problem by implementing an active learning approach [27].
Active learning allows the interactive annotation of highly informative training
data. Therewith, active learning approaches can minimize the amount of training
data necessary to compute highly accurate link specifications.

Overall, the contributions of this paper are as follows:

 We present a novel active learning approach to learning link specifications

based on genetic programming.

 We evaluate our approach on three different data sets and show that we
reach F-measures of above 90% by asking between 10 and 20 questions even
on difficult data sets.

 We compare our approach with state-of-the-art approaches on the DBLPACM dataset and show that we outperform them with respect to runtime
while reaching a comparable accuracy.

The advantages of our approach are manifold. In addition to its high accuracy,
it generates readable link specifications which can be altered by the user at
will. Furthermore, given the superior runtime of LIMES on string and numeric
properties, our approach fulfills the requirements for use in an interactive setting.
Finally, our approach only requires very small human effort to discover link
specifications of high accuracy as shown by our evaluation.

The rest of this paper is organized as follows: First, we give a brief overview of
the state of the art. Thereafter, we present the formal framework within which

EAGLE is defined. This framework is the basis for the subsequent specification of
our approach. We then evaluate our approach with several parameters on three
different data sets. We demonstrate the accuracy of our approach by computing
its F-measure. Moreover, we show that EAGLE is time-efficient by comparing
its runtime with that of other approaches on the ACM-DBLP dataset. We also
compare our approach with its non-active counterpart and study when the use
of active learning leads to better results.

2 Related Work

Over the last years, several approaches have been developed to address the time
complexity of link discovery. Some of these approaches focus on particular domains of applications. For example, the approach implemented in RKB knowledge base (RKB-CRS) [11] focuses on computing links between universities and
conferences while GNAT [25] discovers links between music data sets. Further
simple or domain-specific approaches can be found in [9,23,13,28,24]. In addition,
domain-independent approaches have been developed, that aim to facilitate link
discovery all across the Web. For example, RDF-AI [26] implements a five-step
approach that comprises the preprocessing, matching, fusion, interlinking and
post-processing of data sets. SILK [14] is a time-optimized tool for link discov-
ery. It implements a multi-dimensional blocking approach that is guaranteed to
be lossless thanks to the overlapping blocks it generates. Another lossless Link
Discovery framework is LIMES [20], which addresses the scalability problem by
implementing time-efficient similarity computation approaches for different data
types and combining those using set theory. Note that the task of discovering
links between knowledge bases is closely related with record linkage [30,10,5,17].
To the best of our knowledge, the problem of discovering accurate link specifications has only been addressed in very recent literature by a small number
of approaches: The SILK framework [14] now implements a batch learning approach to discovery link specifications based on genetic programming which is
similar to the approach presented in [6]. The algorithm implemented by SILK
also treats link specifications as trees but relies on a large amount of annotated
data to discover high-accuracy link specifications. The RAVEN algorithm [22] on
the other hand is an active learning approach that treats the discovery of specifications as a classification problem. It discovers link specifications by first finding
class and property mappings between knowledge bases automatically. RAVEN
then uses these mappings to compute linear and boolean classifiers that can be
used as link specifications. A related approach that aims to detect discriminative
properties for linking is that presented by [29]. In addition to these approaches,
several machine-learning approaches have been developed to learn classifiers for
record linkage. For example, machine-learning frameworks such as FEBRL [7]
and MARLIN [4] rely on models such as Support Vector Machines [16,8], decision trees [31] and rule mining [1] to detect classifiers for record linkage. Our
approach, EAGLE, goes beyond previous work in three main ways. First, it is
an active learning approach. Thus, it does not require the large amount of training data required by batch learning approaches such as FEBRL, MARLIN and

A.-C. Ngonga Ngomo and K. Lyko

SILK. Furthermore, it allows to use the full spectrum of operations implemented
in LIMES. Thus, it is not limited to linear and boolean classifiers such as those
generated by FeBRL and RAVEN. Finally, it can detect property and class mappings automatically. Thus, it does not need to be seeded to converge efficiently
like previous approaches [14].

3 Preliminaries

In the following, we present the core of the formalization and notation necessary
to implement EAGLE. We first formalize the Link Discovery problem. Then, we
give an overview of the grammar that underlies links specifications in LIMES
and show how the resulting specifications can be represented as trees. We show
how the discovery of link specifications can consequently be modeled as a genetic
programming problem. Subsequently, we give some insight in active learning and
then present the active learning model that underlies our work.

3.1 Link Discovery

The link discovery problem, which is similar to the record linkage problem, is an
ill-defined problem and is consequently difficult to model formally [2]. In general,
link discovery aims to discover pairs (s, t)  S  T related via a relation R.
Definition 1 (Link Discovery). Given two sets S (source) and T (target) of
entities, compute the set M of pairs of instances (s, t)  S  T such that R(s, t).
The sets S resp. T are usually (not necessarily disjoint) subsets of the instances
contained in two (not necessarily disjoint) knowledge bases KS resp. KT . One
way to automate this discovery is to compare the s  S and t  T based on their
properties using a (complex) similarity measure . Two entities s  S and t  T
are then considered to be linked via R if (s, t)   [21]. The specification of the
sets S and T and of this similarity condition is usually carried out within a link
specification.
Definition 2 (Link Specification). A link specification consists of three parts:
(1) two sets of restrictions RS
k that specify the sets S
resp. T , (2) a specification of a complex similarity metric  via the combination
of several atomic similarity measures 1, ..., n and (3) a set of thresholds 1,
..., n such that i is the threshold for i.
A restriction R is generally a logical predicate. Typically, restrictions in link
specifications state the rdf:type of the elements of the set they describe, i.e.,
R(x)  x rdf:type someClass or the features that the elements of the set
must have, e.g., R(x)  (y : x someProperty y). Each s  S must abide by
m, while each t  T must abide by each of the
each of the restrictions RS
restrictions RT
k . Each similarity i is used to compare pairs of property
values of instances s and t. EAGLE relies on the approach presented in [20] to
detect the class and property mappings. Consequently, in the remainder of this
paper, the term link specification will be used to denote the complex similarity
condition used to determine whether two entities should be linked.

m resp. RT

1 ... RT

1 ... RS

1 ... RT

1 ... RS

3.2 Link Specifications as Trees

Our definition of a link specification relies on the definition of atomic similarity
measures and similarity measures. Generally, a similarity measure m is a function
such that m : ST  [0, 1]. We call a measure atomic (dubbed atomicM easure)
when it relies on exactly one similarity measure  (e.g., trigrams similarity for
strings) to compute the similarity of a pair (s, t)  S  T . A similarity measure
m is either an atomic similarity measure atomicM easure or the combination of
two similarity measures via a metric operator metricOp such as M AX, M IN
and linear combinations ADD.
1. m  atomicM easure
2. m  metricOp(m1, m2)
We call a link specification atomic (atomicSpec) if it compares the value of
a measure m with a threshold , thus returning the pairs (s, t) that satisfy
the condition (s, t)   . A link specification spec(m, ) is either an atomic
link specification or the combination of two link specifications via specification
operators specOp such as AN D (intersection of the set of results of two specs),
OR (union of the result sets), XOR (symmetric set difference), or DIF F (set
difference). Thus, the following grammar for specifications holds :
1. spec(m, )  atomicSpec(m, )
2. spec(m, )  specOp(spec(m1, 1), spec(m2, 2))
Each link specification that abides by the grammar specified above can be consistently transformed into a tree that contains the central constructs shown in
Figures 1, 2, 3 and 4.

4 Approach

As we have formalized link specifications as trees, we can use Genetic Programming (GP) to solve the problem of finding the most appropriate complex link
specification for a given pair of knowledge bases. Given a problem, the basic idea
behind genetic programming [18] is to generate increasingly better solutions of
the given problem by applying a number of genetic operators to the current pop-
ulation. In the following, we will denote the population at time t by gt. Genetic
operators simulate natural selection mechanisms such as mutation and reproduction to enable the creation of individuals that best abide by a given fitness
function. One of the key problems of genetic programming is that it is a nondeterministic procedure. In addition, it usually requires a large training data set
to detect accurate solutions. In this paper, we propose the combination of GP
and active learning [27]. Our intuition is that by merging these approaches, we
can infuse some determinism in the GP procedure by allowing it to select the
most informative data for the population. Thus, we can improve the convergence
of GP approaches while reducing the labeling effort necessary to use them. In
the following, we present our implementation of the different GP operators on
link specifications and how we combine GP and active learning.

A.-C. Ngonga Ngomo and K. Lyko

m



m

metricOp

m1

m2

Fig. 1. Atomic measure

Fig. 2. Complex measure

spec

m



spec

specOp

spec1

spec2



Fig. 3. Atomic specification

Fig. 4. Complex specification

4.1 Overview

Algorithm 1 gives an overview of the approach implemented by EAGLE. After
the detection of matching classes and properties using the approach explicated
in [22], we begin by generating a random population of individual link specifica-
tions. To evolve a population to the next one a number of steps is required: First,
all existing individuals must be assigned a fitness score. This score reflects how
well a link specification performs on the training data at hand. Subsequently,
the genetic operators reproduction, mutation and crossover are applied to the
individuals of the current population in order to let the individuals adapt to the
problem. The reproduction determines which individual is carried into the next
generation. Note that throughout this paper, we use a tournament setting of
two randomly chosen individuals. The mutation operator can applied to a single
individual. It alters this individual by randomly changing parts of its tree (i.e., of
his genome) with the aim of creating a new individual. The crossover operator
also aims at generating new individuals. It achieves this goal by crossing over
branches of the program trees of two parent individuals.

Algorithm 1. EAGLE
Require: Specification of the two knowledge bases KS and KT

Get set S and set T of instances as specified in KS respectively KT .
Get property mapping (KS, KT )
Get reference mapping by asking user to label n random pairs (s, t)  S  T
repeat

Evolve population(population,size) generations times.
Compute n most informative link candidates and ask user to label them.

until stop condition reached

Algorithm 2. Evolves a population

if population is empty then

create size random individuals

end if
Compute fitness of population
Apply genetic operators to population
return population

In the following, we will explicate each of the steps of our algorithm in more
detail. Each of these steps will be exemplified by using the link specification
shown in Figure 5.

spec

spec

0.9

spec

m

0.8

m

0.5

trigrams

Jaccard

Fig. 5. Examplary link specification

4.2 Evolution of Population

Evolution is the primary process which enables GP to solve problems and drives
the development of efficient solutions for a given problem. At the beginning
of our computation the population is empty and must be built by individuals
generated randomly. This is carried out by generating random trees whose nodes
are filled with functions or terminals as required. For this paper, we defined the
operators (functions and terminals) in the genotype for the problem to generate
link specifications as follows: all metricOp and specOp were set to be functions.
Terminal symbols were thresholds and measures. Note that these operators can
be extended at will. In addition, all operators were mapped to certain constraints
so as to ensure that EAGLE only generates valid program trees. For example, the
operator that compares numeric properties only accepts terminals representing
numeric properties from the knowledge bases.

Let gt be the population at the iteration t. To evolve a population to the
generation gt+1 we first determine the fitness of all individuals of generation gt
(see Section 4.3). These fitness values build the basis for selecting individuals
for the genetic operator reproduction. We use a tournament setting between two
selected individuals to decide which one is copied to the next generation gt+1.

A.-C. Ngonga Ngomo and K. Lyko

On randomly selected individuals the operator mutation is applied according
with a probability called the mutation rate. The mutation operator changes
single nodes in the program tree of the individuals. A mutation can affect an
individual in three different ways: First, it can alter the thresholds used by
the individual. Second, a mutation can alter the properties contained in the
individuals genome. Finally, mutations can modify the measures included in
the individuals (see Figure 6). The third genetic operator, crossover, operates
on two parent individuals and builds a new offspring by swapping two random
subtrees of the parent genotypes. Figure 7 exemplifies the functionality of the
crossover operator.

(a)

spec



(b)

spec

spec

0.9

spec

spec

0.9

spec

m

0.8

m

0.5

m

0.8

m

0.5

trigrams

Jaccard

trigrams

Jaccard

Fig. 6. Mutation example. Mutation changes boolean operator.

The individuals selected to build the population of gt+1 are the n fittest from
the union of the set of newly created individuals and gt. Note that we iteratively
generate new populations of potential fitter individuals.

4.3 Fitness

The aim of the fitness function is to approximate how well a solution (i.e., a link
specification) solves the problem at hand. In the supervised machine learning
setting, this is equivalent to computing how well a link specification maps the
training data at hand. To determine the fitness of an individual we first build the
link specification that is described by the tree at hand. Given the set of available
training data O = {(xi, yi)  S  T}, we then run the specification by using the
sets S(O) = {s  S : t  T : (s, t)  O} and T (O) = {t  T : s  S : (s, t) 
O}. The result of this process is a mapping M that is then evaluated against O
by the means of the standard F-measure defined as

2P R
P + R

where P =

|M  O|

|M|

and R =

|M  O|

|O|

.

(1)

Note that by running the linking on S(O) and T (O), we can significantly reduce
EAGLEs runtime.
?

?

?
spec



(b)

spec

spec

0.9

spec

m

0.8

m

0.5

trigrams

Jaccard

spec

0.9

spec

m

0.5

m

0.5

Jaccard

Jaccard

Fig. 7. Crossover example. Consider we have two individuals with a program tree like
in (a). A crossover operation can replace subtrees to produce an offspring like (b).

4.4 Computation of Most Informative Link Candidates

The main idea behind the reduced of the amount of labeling effort required by
active learning approaches is that they only required highly informative training
data from the user. Finding these most informative pieces of information is
usually carried out by measuring the amount of information that the labeling of
a training data item would bear. Given the setting of EAGLE in which several
possible solutions co-exist, we opted for applying the idea of active learning by
committees as explicated in [19]. The idea here is to consistently entertain a finite
and incomplete set of solutions to the problem at hand. The most informative
link candidates are then considered to be the pairs (s, t)  S T upon which the
different solutions disagree the most. In our case, these are the link candidates
that maximize the disagreement function ((s, t)):

((s, t)) = (n  |{Mt

i : (s, t)  Mi}|)(n  |{Mt

i : (s, t) / Mi}|),

(2)

where Mi are the mappings generated by the population gt. The pairs (s, t) that

lead to the highest disagreement score are presented to the user, who provides
the system with the correct labels. This training set is finally updated and used
to compute the next generations of solutions.

5 Evaluation

5.1 Experimental Setup

We evaluated our approach in three experiments. In our experiments, our main
goal not only to show that we can discover link specifications of different complexity with high accuracy. In addition, we also aimed to study the effect of the
population size and of active learning on the quality of link specifications. For
this purpose, we devised three experiments whose characteristics are shown in
Table 1.

A.-C. Ngonga Ngomo and K. Lyko

The goal of the first experiment, called Drugs, was to measure how well we can
detect a manually created LIMES specification. For this purpose, we generated
owl:sameAs link candidates between Drugs in DailyMed and Drugbank by using
their rdfs:label. The second experiment, Movies, was carried out by using the
results of a LATC2 link specification. Here, we fetched the links generated by a
link specification that linked movies in DBpedia to movies in LinkedMDB [12],
gathered the rdfs:label of the movies as well as the rdfs:label of their directors in the source and target knowledge bases and computed a specification that
aimed to reproduce the set of links at hand as exactly as possible. Note that this
specification is hard to reproduce as the experts who created this link specification applied several transformations to the property values before carrying out
the similarity computation that led to the results at hand. Finally, in our third
experiment (Publications), we used the ACM-DBLP dataset described in [17].
Our aim here was to compare our approach with other approaches with respect
to both runtime and F-measure.

Table 1. Characteristics of the datasets used for the evaluation of EAGLE. S stands
for source, T for target.

|S|  |T| Oracle size

Label
Drugs
Movies

Dailymed Drugbank 1.09  106
DBpedia LinkedMDB 1.12  106
6.01  106
?

?

?
Publications ACM

All experiments were carried out on one kernel of an AMD Opteron QuadCore processor (2GHz) with the followings settings: the population size was
set to 20 or 100. The maximal number of generations was set to 50. In all
active learning experiments, we carried out 10 inquiries per iteration cycle. In
addition, we had the population evolve for 10 generations between all inquiries.
The mutation and crossover rates were set to 0.6. For the batch learners, we
set the number of generations to the size of the training data. Note that this
setup is of disadvantage for active learning as the batch learners then have more
data and more iterations on the data to learn the best possible specification.
We used this setting as complementary for the questions that can be asked by
the active learning approach. During our experiments, the Java Virtual Machine
was allocated 1GB RAM. All experiments were repeated 5 times.

5.2 Results

The results of our experiments are shown in the Figures below3. In all figures,
Batch stands for the batch learners while AL stands for the active learners. The

2 http://lact-project.eu
3 Extensive results are available at the LIMES project website at

http://limes.sf.net

numbers in brackets are the sizes of the populations used. The results of the
Drugs experiments clearly show that our approach can easily detect simple link
specifications. In this experiment, 10 questions were sufficient for the batch and
active learning versions of EAGLE to generate link specifications with an F-
measure equivalent to the baseline of 99.9% F-measure. The standard deviation
lied around 0.1% for all experiments with both batch and active learner.
?

?

?
Fig. 8. Results of the Drugs experiment. Mean F-Measure of five runs of batch and
active learner, both using population sizes of 20 and 100 individuals. The baseline is
at 99.9% F-measure.

On the more complex Movies experiments, we required 50 inquiries to discover
the best link specification that led to an F-measure of 94.1%. This experiment
clearly shows the effect of active learning on genetic programming algorithms.
While the batch learners fed with any data size tend to diverge significantly
across the different experiments as shown by their standard deviation bars, the
active learning approaches do not only perform better, they are also more stable
as shown by the smaller standard deviation values. Similar results are shown on
the most complex and largest data set at hand, ACM-DBLP.

In addition to being accurate, our approach is very time-efficient. For example,
it only required approximately 250ms to run a specification on the first and
second data sets when all the data was in memory. On average, it requires less
than 700ms on the last data set. It is important to notice that the features of
this dataset include real numbers, which considerably worsen the runtime of link
specifications.

Our results suggest that the use of small populations affects the outcome of
the learning process significantly, especially when the specification to be learned
is complex. For example, on the Publications data set, the learners that rely
on solely 20 individuals per generation are up to 9.8% worse than the learners
which use populations of 100 individuals. Setting the population to 100 seems to

A.-C. Ngonga Ngomo and K. Lyko
?

?

?
Fig. 9. Results of the Movies experiment. Mean F-measures of five runs of batch and
active learner, both using population sizes of 20 and 100 individuals. The baseline is
at 97.6% F-measure.
?

?

?
Fig. 10. Results of the Publications experiment. Mean F-measures of five runs of batch
and active learner, both using population sizes of 20 and 100 individuals. The baseline
is at 97.2% F-measure.

generate sufficiently good results without requiring a large amount of memory.
Yet, when trying to link very complex datasets, an even larger setting would be
advisable.

5.3 Comparison with other Approaches

As stated above, we chose the ACM-DBLP data set because it has been used in
previous work to compare the accuracy and learning curve of different machine
learning approaches for deduplication. As our results show (see Table 2), we
reach an accuracy comparable to that of the other approaches. One of the main
advantages of our approach is that it is considerably more time-efficient that
all other approaches. Especially, while we are approximately 3 to 7 times faster
than MARLIN, we are more than 14 times faster than FeBRL on this data set.

Table 2. Comparison of best performances of different machine learning approaches
on ACM-DBLP

EAGLE FEBRL MARLIN MARLIN
(AD-Tree)

(SVM)

(SVM)
F-Measure 97.2% 97.5% 97.6%
Runtime
2196s

4320s

337s

96.9%
1553s

So far, only a few other approaches have been developed for learning link
specifications from data. RAVEN [22] is an active learning approach that view
the learning of link specifications as a classification task. While it bears the advantage of being deterministic, it is limited to learning certain types of classifiers
(boolean or linear). Thus, it is only able to learn a subset of the specifications that
can be generated by EAGLE. Another genetic programming-based approach to
link discovery is implemented in the SILK framework [15]. This approach is yet
a batch learning approach and it consequently suffers of drawbacks of all batch
learning approaches as it requires a very large number of human annotations to
learn link specifications of a quality comparable to that of EAGLE.

6 Conclusion and Future Work

In this paper we presented EAGLE, an active learning approach for genetic
programming that can learn highly accurate link specifications. We compared
EAGLE with its batch learning counterpart. We showed that by using active
learning, we can tackle complex datasets with more ease and generate solutions
that are more stable (i.e., that display a smaller standard deviation over different runs). We also compared EAGLE with other approaches such as FeBRL and
MARLIN on the ACM-DBLP dataset. We showed that for we achieve a similar
F-measure while requiring a significantly smaller runtime. We also demonstrated
that the runtime of our approach makes it suitable for interactive scenarios. In future work, we will study the effect of different parameterizations in more details.
Especially, we will utilize different fitness functions and study the correlation of
fitness functions with the overall F-score. Furthermore, we will aim at devising
automatic configuration approaches for EAGLE.

A.-C. Ngonga Ngomo and K. Lyko
