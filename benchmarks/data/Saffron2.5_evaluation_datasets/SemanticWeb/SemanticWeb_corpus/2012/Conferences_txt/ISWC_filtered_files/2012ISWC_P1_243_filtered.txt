Formal Verification of Data Provenance Records

Szymon Klarman1, Stefan Schlobach1, and Luciano Serafini2

1 VU University Amsterdam, The Netherlands

{s.klarman,k.s.schlobach}@vu.nl

2 Fondazione Bruno Kessler, Trento, Italy

serafini@fbk.eu

Abstract. Data provenance is the history of derivation of a data artifact from its original sources. As the real-life provenance records can
likely cover thousands of data items and derivation steps, one of the
pressing challenges becomes development of formal frameworks for their
automated verification.

In this paper, we consider data expressed in standard Semantic Web
ontology languages, such as OWL, and define a novel verification formalism called provenance specification logic, building on dynamic logic. We
validate our proposal by modeling the test queries presented in The First
Provenance Challenge, and conclude that the logic core of such queries
can be successfully captured in our formalism.

Introduction

In this paper, we propose and study a novel logic-based approach to formal
verification of data provenance records in the Semantic Web environment.

Motivation. Data provenance is the history of derivation of a data artifact from
its original sources [1,2]. A provenance record stores all the steps and contextual aspects of the entire derivation process, including the precise sequence of
operations executed, their inputs, outputs, parameters, the supplementary data
involved, etc., so that third parties can unambiguously interpret the final data
product in its proper context. It has been broadly acknowledged that provenance
information is crucial for facilitating reuse, management and reproducibility of
published data [3,1]. For instance, the ability of verifying whether past experiments conformed to some formal criteria is a key in the process of validation of
eScientific results [4]. As provenance records can cover thousands of data items
and derivation steps, one of the pressing challenges becomes development of formal frameworks and methods to automate verification. Such a logic back-end for
practical reasoning tools could, e.g. be useful for provenance-driven data query-
ing, or for validating conformance of provenance records to formal specifications.
Let us consider a concrete example taken from The First Provenance Challenge (FPC)  a community effort aimed at understanding the capabilities of
available provenance systems [5]. In FPC, 17 teams competed in answering 9
queries over data provenance records (see Figure 1) obtained from executing a

P. Cudr e-Mauroux et al. (Eds.): ISWC 2012, Part I, LNCS 7649, pp. 215230, 2012.
c Springer-Verlag Berlin Heidelberg 2012

S. Klarman, S. Schlobach, and L. Serafini
?

?

?
Fig. 1. A data provenance record describing a run of the FPC workflow [5]

real-life scientific workflow for creating population-based brain atlases of high
resolution anatomical data. One representative task was to:

Q6. Find all output averaged images of softmean (average) procedures, where the
warped images taken as input were align warped using a twelfth order nonlinear
1365 parameter model, i.e. where softmean was preceded in the workflow, directly
or indirectly, by an align warp procedure with argument -m 12.

A distinctive feature of this sort of queries is their inherent two-dimensionality:
the domain data (here: image identifiers) is queried relative to its meta-level
provenance description. To date all existing approaches to support such queries
are based on ad hoc combinations of techniques and formalisms, dependent on
the internal representation structures, and are procedural in nature. Given the
semantic character of the task, and in light of the soon to be expected standardization of the Provenance vocabularies by W3C,1 a logic-based language
for querying and verifying provenance graphs, which could significantly improve
reusability and generalisability, is critically missing. This paper closes this gap.

Methodology. We introduce provenance specification logic (PSLM ) which, to the
best of our knowledge, offers the first systematic view on the logical foundations
of formal verification of data provenance records. Our focus is on data expressed
in the Semantic Web ontology languages, such as OWL and RDF(S), whose
formal core is essentially captured by Description Logics (DLs) [6], underpinning
the Semantic Web architecture.

The basic idea is very intuitive. A data provenance record is represented as
a directed graph, with certain nodes being treated as identifiers for datasets,
containing the data involved in the respective stages of the computation. We
construct the basic variant of our logic, called PSL, by substituting atoms of
Propositional Dynamic Logic (PDL) with queries belonging to a selected query

1 See http://www.w3.org/2011/prov/wiki/Main_Page
?

?

?
language. The dynamic component, thus inherited from PDL, enables expressing
complex provenance patterns, while the embedded queries support access to
data artifacts. In the second step, we lift this approach to cater for scenarios
in which provenance graphs are themselves described in dedicated provenance
ontologies. This way, we obtain the target formalism PSLM , which, on top of the
functionalities offered by PSL, also facilitates the use of a rich metalanguage.

This mechanism is highly independent from the employed representation for-
malisms, and can be reused in a plug-and-play fashion for a number of combinations of ontologyquery languages. Moreover, we demonstrate that PSLM is
computationally well-behaved. By separating the DL-level reasoning tasks from
the pure model checking of provenance graphs, we obtain a PTime-completeness
result, carried over from the model checking problem in PDL, which remains invariant to the particular choice of the employed ontology/query languages.

Contents. In this work we deliver three main contributions: 1) We introduce
PSLM , a declarative language for expressing complex constraints over data
provenance records. 2) By systematically studying the collection of test queries
from FPC, mentioned above, we show that PSLM offers desired modeling ca-
pabilities. 3) Finally, we provide a computational analysis of the approach, and
report on some satisfying results.

In the remainder of this paper, we first give a short overview of the related
work (Section 2) and preliminary notions (Section 3). Next, we incrementally introduce PSLM (Sections 4, 5) and validate it against the test queries (Section 6).
Finally, we study the computational aspects of our framework (Section 7).

2 Related Work

Provenance is nowadays recognized as one of the critical problems to be addressed by the Semantic Web community, attracting increasing interest, e.g.
[7]. Existing Semantic Web-based approaches to the problem of verification and
querying, such as [8] are persistently technology-driven, and employ combinations of web services, ontologies, triple stores, SPARQL queries, etc. and fail to
lay down systematic perspectives on the formal foundations of the problem. Noteworthy exceptions are [9] and [10] which provide, respectively: reproducibility
semantics, which are executional in nature, and logic program-based framework
for reasoning with a provenance-annotated linked data, where both annotations
and data language are specifically restricted. Our paper goes beyond those proposals by providing a cohesive declarative semantic framework based on standard
logic and ontology languages, and rich metamodels.

On the formal level, the problem of provenance verification bears a strong resemblance to the traditionally studied verification of transition systems, which in
principle encourages the use of similar logic-based techniques [11]. This analogy,
however, must be treated with caution. While in usual transition systems states
represent complete, propositional abstractions of systems configurations, in the
data provenance context states are effectively datasets, reflecting the knowledge
of the system in a certain configuration. This creates a need for more expressive

S. Klarman, S. Schlobach, and L. Serafini

verification formalisms, extending the basic program logics, such as PDL [12].
Even Dynamic DLs [13], which are capable of modeling transition systems with
states corresponding to DL knowledge bases, are not flexible enough to express
rich constraints on the data level. Some other verification formalisms, of a more
suitable, data-oriented flavor, have been proposed for verification of data-driven
systems [14], knowledge base programs [15], or workflow schemas [16]. However,
the central motivation behind their design is to enable representation of all permissable data-altering operations over a fixed data language, with the aim of
studying general properties of programs composed of such operations. Conse-
quently, the considered representation languages are strongly restricted in order
to ensure decidability of those properties. Such general problems, however, are
not of a primary interest in our case, since a provenance record describes by
definition a single, completed computation process, which one wants to study
ex-post. Hence, rather than abstracting from the richness of a given system and
focusing on its possible behaviors, we must enable reasoning machinery which
can maximally utilize the available information about the system.

3 Preliminaries

For clarity of exposition, in this paper we consider data represented and managed
within the framework of Description Logics (DLs), noting that all claims made in
this context extend naturally to arbitrary fragments of OWL/RDF(S) languages.
In what follows, we briefly recap the preliminaries regarding DLs, and further
formalize the notion of data provenance record.

3.1 Description Logics

We use the standard nomenclature and notation for the syntax and semantics
of DLs. We refer the reader to [6] for full details. A DL language L is specified
by a vocabulary  = (NC , NR, NI ), where NC is a set of concept names, NR
a set of role names and NI a set of individual names, and by a selection of
logical operators enabling construction of complex concepts, roles and axioms.
Different combinations of operators give rise to DLs of different expressiveness
and computational complexity, from the highly expressive SROIQ, underpinning the OWL 2 DL language, to the lightweight EL++ or the DL-Lite family,
on which tractable OWL profiles are based [17]. For instance, the DL ALCO, a
substantial fragment of OWL 2 DL, permits the following constructors:

Concepts: |  | A  NC | C | C  D | C  D | r.C | r.C | {a}

Axioms:

C  D | C(a) | r(a, b)
where r  NR, a, b  NI and C, D are (possibly complex) concepts.

From the data management perspective, a set of concept inclusions C  D is
typically considered an ontology which provides access to instance data, represented as a set of assertions of the form A(a), r(a, b) [18]. We implicitly abide
?

?

?
by this distinction, but for simplicity refer rather to the general notion of a DL
knowledge base.
Definition 1 (Knowledge base). A knowledge base K over a DL language
L is a finite set of axioms allowed by the syntax of L. The set of all knowledge
bases over L is denoted by K(L).
The semantics of L is given in terms of the usual model-theoretic interpretations.
An interpretation I is a model of a knowledge base iff it satisfies all its axioms.
We say that an axiom  is entailed by a knowledge base K, denoted as K |= 
iff  is satisfied in every model I of K.

Further, we recall the notion of conjunctive queries (CQs)  the most popular
class of first-order queries studied in the context of DLs [19]. The problem of
answering CQs is known to be decidable for most DLs, and is effectively handled
by existing tools, such as DL reasoners (e.g. Pellet) or, as in case of DL-Lite
family, relational database management systems (e.g. Mastro2). Let NV be a
countably infinite set of variables. A conjunctive query over a DL language L
with the vocabulary  = (NC , NR, NI) is a first-order formula  = y.q(x, y),
where x, y  NV are sequences of variables and q is a conjunction of atoms over
denoted as avar(). For a CQ , a -substitution is a mapping  : avar() ! NI .
We write () to denote the formula resulting from applying  to . We call
 a certain answer to  w.r.t. a knowledge base K, whenever K |= (), i.e.
whenever () is satisfied in all models I of K.

. The free variables x occurring in  are also called the answer variables and

3.2 Data Provenance Records

The definition of a provenance record that we adopt here, and further refine in
Section 5, is the simplest abstraction of the proposals currently discussed in the
course of a W3C standardization effort. Those proposals, building largely on the
specification of the Open Provenance Model [2], consider a provenance record to
be a basic graph structure (such as presented in Figure 1) representing the whole
documented history of interactions between processes and data artifacts during a
certain computation, where data artifacts are in fact datasets (knowledge bases)
expressed in DLs. The choice of the OPM foundations for our approach is motivated largely by the fact that OPM is suggested as the intended formalism
for representing provenance in the expected W3C recommendation. In principle,
however, the level of abstraction which we endorse here goes beyond particular,
concrete encodings of provenance information, and builds only on generic provenance notions present also in other formalisms used for recording provenance,
such as Proof Markup Language [20,21]. Crucially, our approach generalizes over
any (transition) graph-based representation of data provenance.
A directed graph is a pair (V, E), where V is a non-empty set of nodes and
E is a set of ordered pairs from V  V , called edges. A bipartite graph is a
graph (V  W, E), where V  W is a set of nodes and E a set of edges such that
2 See http://www.dis.uniroma1.it/quonto/

S. Klarman, S. Schlobach, and L. Serafini

E  V  W  W  V . An edge-labeled graph is a triple (V, E, l), such that (V, E)
is a graph and l : E ! R assigns a relation name from a set R to every edge
in E. A graph (V, E) is called acyclic iff for every node v  V , there exists no
sequence w1, . . . , wn  V , such that (v, w1), . . . , (wn1, wn), (wn, v)  E.
Definition 2 (Provenance graph). An L-provenance graph is a tuple G =
(P, D, E, l, k), where (P  D, E, l) is a bipartite, directed, acyclic, edge-labeled
graph, and k is a function k : D ! K(L). The nodes in P are called processes
and in D data artifacts.

By convention, we identify process nodes with unique process invocations that
occurred during the recorded computation, and data artifact nodes with the
corresponding DL knowledge bases {k(d) | d  D} that were involved. Note,
that we do not presume any specific causal relationships between the represented
entities. We are only interested in the formal properties of the graphs.

4 Provenance Specification Logic

Formal verification is the task of checking whether a certain formal structure
satisfies the property described by a given formula of a dedicated specification
language. The properties of data provenance records which we aim to capture
here are essentially complex relationships between the structural patterns occurring in the provenance graphs and the contents of data artifacts. Three typical constraints, representative of most reasoning tasks requested from practical
provenance systems [3,4,5], are e.g.:

1. r(a, b) holds in data artifact d1 and d1 is reachable via edge succeeds from

processes p1 and p2,

2. a data artifact in which D(a) does not hold is reachable via a finite sequence
of two-step edge compositions wasGeneratedBy -used from a data artifact in
which D(a) holds,

3. if D(a) holds in any data artifact related to process p1 via either input 1 or
input 2, then p1 must be related via output to some data artifact in which
r(a, y) holds, for some arbitrary y.

These informally stated properties are clearly satisfied by the respective provenance graphs, illustrated in Figure 2, where nodes p1, p2 represent process nodes,
and d1, d2, d3 data artifacts, whose contents are listed inside the nodes.

The ability of expressing constraints of this flavor is the key feature of a big
family of program verification formalisms based on dynamic logics, in particular the prominent Propositional Dynamic Logic (PDL) [12]. The provenance
specification logic (PSL), which we introduce below, is a data-oriented extension
of PDL. Essentially, we substitute propositional letters of PDL formulas with
queries belonging to a certain query language. The dynamic component of PSL
enables explicit modeling of requested provenance patterns, while the queries allow for accessing the contents of data artifacts. The choice of an adequate query
language is in principle an application-driven decision, depending strongly on
?

?

?
Fig. 2. Sample provenance graphs

the underlying data language. For instance, if data artifacts use RDF(S) repre-
sentation, a natural candidate is SPARQL [22]. As our focus is on the general DL
setup, we consider the class of conjunctive queries, as introduced in Section 3.
Definition 3 (PSL: syntax). Let G = (P, D, E, l, k) be an L-provenance graph
and R the set of relation names used in G. Then the provenance specification
language over G is the smallest language induced by the following grammar:

Object queries:

Path expressions:

 | v? | ?

 := CQs over L
 := r | ;  |    | 
where r  R and v  P  D,
 := {} |  |  |    | 

 | 

Provenance formulas:

Whenever convenient we use the usual abbreviations  = , [] = ,
   = (  ) and    =   .

Following the CQ notation, by avar() we denote the set of all free (answer)
variables occurring in a provenance formula , i.e. the union of all answer variables from the CQs embedded in . Note, that different CQs are allowed to
share same answer variables. This way one can capture interesting data dependencies between the contents of data artifacts. An -substitution is a mapping
 : avar() ! NI and () denotes the result of applying  to . We say that
() is satisfied in an L-provenance graph G = (P, D, E, l, k) in a node v  P D
iff G, v  (), where the satisfaction relation  is defined as follows.
Definition 4 (PSL: semantics). The satisfaction relation  for PSL formulas
is given by a simultaneous induction over the structure of provenance formulas
and path expressions, w.r.t. a substitution . For an L-provenance graph G =
(P, D, E, l, k) and every v, w  P  D:
Provenance formulas:
G, v  {}
G, v  ,
G, v   iff there exists w  P  D, s.t. G  v  w and G, w  ,

iff v  D and k(v) |= (),

S. Klarman, S. Schlobach, and L. Serafini

G, v     iff G, v   and G, v  ,
G, v  

iff G, v  ,

Path expressions:
G  v r w iff (v, w)  E and l(v, w) = r,
G  v
G  v  w iff G  v  w or G  v  w,
G  v 
G  v 
G  v v? v,
G  v ? v iff G, v  .

 w iff G  w  v,
 w iff v( )


w, where ( )


 on G,

; w iff there is u  P  D s.t. G  v  u and G  u  w,

is the transitive reflexive closure of

Observe, that unlike in typical transition systems, only selected nodes in provenance graphs  exactly the data artifacts in D  represent the states over
which object queries can be evaluated. Irrespective of this deviation, the model
checking problem, underlying formal verification tasks, is defined as usual.
Model Checking 1 (PSL formulas) Given an L-provenance graph G = (P,
D, E, l, k), a node v  P D, a PSL provenance formula  and an -substitution
, decide whether G, v  ().

It is easy to check that the following PSL formulas express precisely the properties from the three examples presented in the opening of this section, and are
satisfied by the specified graphs, nodes and substitutions (Figure 2):

1.  := p1?; succeeds; d1?({r(x, y)}  succeeds
where G1, p1  () for  = {x ! a, y ! b},
2.  := {D(x)}  (wasGeneratedBy ; used )
where G2, d1  () for  = {x ! a},
3.  := p1?((input 1
where G3, p1  () for  = {x ! a}.

 input 2)



; p2?),

{D(x)},

{D(x)}  output{y.r(x, y)}),

For a more practical illustration, we model two use-cases from the eScience do-
main. The first one illustrates a typical problem of provenance-based validation
of an eScience experiment, reported in [4].

Example 1. A bioinformatician, B, downloads a file containing sequence data
from a remote database. B then processes the sequence using an analysis service.
Later, a reviewer, R, suspects that the sequence may have been a nucleotide
sequence but processed by a service that can only analyze meaningfully amino
acid sequences. R determines whether this was the case.

 := {y.Sequence(x)  analysis-result(x, y)} 

[output; analysis-service?; input]({Amino-acid(x)}  {Nucleotide(x)})
?

?

?
Solution: The requested property is satisfied by a graph G if G, v  () for
every v  P  D and -substitution  = {x ! a}, where a is the sequence
in question. Naturally, we presume a certain underlying representation model,
where e.g. analysis-service is the name of the cited service, the result of analysis
is given via an axiom of type analysis-result(a, y), etc. For lack of space we do
not sketch such models for any of the remaining examples, relying on a proper
reconstruction by the reader.

As the second example, we formalize one of the queries from FPC [5].

Example 2. See Q6 in Section 1 (cf. Figure 1).

 := {Image(x)}  wasGeneretedBy ; softmean 1...n; used({y.Image(y)} 

(wasGeneratedBy ; used )


)

; wasGeneratedBy ; align-warp1...m

where softmean 1...n := softmean 1?  . . .  softmean n? includes all invocations
of softmean process in the graph, while align-warp1...m := align-warp1?  . . . 
align-warpm? all invocations of align warp with the specified parameter value.
Solution: For every v  P  D and -substitution , if G, v  (), then  is
a requested resource.

Observe, that in the latter example not all information requested in the query
can be expressed is the PSL formula in a direct, declarative manner. Namely,
the selection of softmean and align warp invocations has to be encoded by an
exhaustive enumeration of all the nodes satisfying the specified description. This
shortcoming, which affects the high-level modeling capabilities of our formalism,
is exactly what motivates the extension introduced in the next section.

5 Provenance Metalanguage

In practice, the relevant provenance information can be much richer than reflected in our abstract notion of provenance graphs. Typically, provenance
records account also for the execution context of all processes, including their
parametrization, time, responsible actors, etc. [1,2,3]. Moreover, they use complex taxonomies for classifying all these resources. Consequently, the structure
of a provenance graph, along the accompanying contextual information, is commonly expressed by means of another DL-based language, used orthogonally to
that representing the contents of data artifacts [23,3]. For instance, the provenance graph G implicitly referred to in Example 2, would be likely represented
as a knowledge base containing, among others, the axioms listed in Table 1.
Formally, we define such a meta-level representation of provenance graphs as
follows.

Definition 5 (Metalanguage, metaknowledge base). Let G = (P, D, E, l, k)

be an L-provenance graph and R the set of relation names used in G. Let LG be
a DL language with the vocabulary  = (MC , MR, MI), such that R  MR and
P  D  MI , and KG a knowledge base over LG. Then, LG is called the metalanguage and KG = (KG, k) the metaknowledge base over G iff the following conditions

are satisfied:

S. Klarman, S. Schlobach, and L. Serafini

Table 1. A DL knowledge base encoding (part of) a provenance graph

Softmean  Process
Artifact  Process
Artifact  wasGeneratedBy .Process Align-warp  Process
Process  used .Artifact
Align-warp  hasArgValue.String
- for every node softmean i
Softmean(softmean i)
- for every node align-warpi
Align-warp(align-warpi)
- for every node align-warpi correhasArgValue (align-warpi, -m 12)
sponding to an invocation of align
warp with argument -m 12

1. D = {v  MI | KG |= Artifact(v)}, for a designated concept Artifact  MC,
2. for every r  R and v, w  MI, it holds that (v, w)  E and l(v, w) = r iff

KG |= r(v, w).

Assuming the names in MI are interpreted uniquely, it is easy to see that the
structure of G is isomorphically encoded in the set of role assertions, over role
names in R, entailed by KG. As the positions of data artifacts remain unaltered,
one can immediately rephrase the definition of the satisfaction relation , to
show that for any PSL formula , node v  P  D, and an -substitution  it is
the case that G, v  () iff KG, v  (). More interestingly, however, we can
instead slightly extend the provenance specification language to make a vital use
of the newly included meta-level information.
Definition 6 (PSLM : syntax). Let G = (P, D, E, l, k) be an L-provenance
graph and LG, KG the metalanguage and the metaknowledge base over G, respec-
tively. Then the provenance specification language (with metalanguage) over KG
is the smallest language induced by the grammar of PSL over G (Definition 3),
modulo the revision of path expressions:
 | 

 := r | ;  |    | 
where r  MR, v  MI and C is a concept in LG,

Path expressions:

 | v? | C? | ?

For a PSLM provenance formula , and an -substitution , we say that ()
is satisfied a metaknowledge base KG in an instance v  MI iff KG, v  (),
where the satisfaction relation  is defined as follows.
Definition 7 (PSLM : semantics). The satisfaction relation  for PSLM formulas is given by a simultaneous induction over the structure of provenance
formulas and path expressions, w.r.t. a substitution . Let LG be the metalanguage with vocabulary  = (MC, MR, MI ) and KG = (KG, k) the metaknowledge
base over an L-provenance graph G. For all individual names v, w  MI :

Provenance formulas:

KG, v  {} iff KG |= Artifact (v) and k(v) |= (),
KG, v   iff there exists w  MI, s.t. KG  v  w and KG, w  ,
?

?

?
Path expressions:

KG  v r w iff KG |= r(v, w),
KG  v
KG  v C? v iff KG |= C(v),

; w iff there is u  MI s.t. KG  v  u and KG  u  w,

where the remaining conditions are exactly as in Definition 4 (modulo G/KG).

The model checking problem is rephrased accordingly.

Model Checking 2 (PSLM formulas) Given a metaknowledge base KG over
an L-provenance graph G, an instance v  MI, a PSLM provenance formula ,
and an -substitution , decide whether KG, v  ().

The usefulness of the presented extension, in particular of the test operator C?,
which allows for referring to graph nodes generically by their types, inferred from
the metaknowledge base, can be observed in the following example.

Example 3. See Q6 in Section 1 and Example 2. We restate the formula  as:

 := {Image(x)}  wasGeneretedBy ; Softmean?; used

({y.Image(y)}  (wasGeneratedBy ; used)


(Align-warp  hasArgValue.{-m 12})?)

; wasGeneratedBy ;

where KG, in the metaknowledge base KG = (KG, k), contains (among others)

the axioms from Table 1.

Solution: For every v  MI and -substitution , if KG, v  (), then  is a

requested resource.

Compared to its PSL variant from Example 2, the PSLM formula used in Example 3 is much more succinct and explicitly represents all requested informa-
tion. More importantly, thanks to the use of a generic vocabulary for classifying
nodes (here: concepts Softmean, Align-warphasArgValue.{-m 12}), instead
of their enumerations, the formula is also more input-independent, in the sense
that it can be directly reused to verify/query alternative provenance records
obtained from running the same workflows.

6 Evaluation

In order to validate our approach in practical scenarios, we have analyzed the
complete list of test queries from The First Provenance Challenge, which to our
knowledge constitutes a so far unique golden standard for the provenance com-
munity. Below we model possible solutions using the logic PSLM and elaborate
on our findings.

Q1. Find the process that led to Atlas X Graphic / everything that caused Atlas
X Graphic to be as it is. This should tell us the new brain images from which
the averaged atlas was generated, the warping performed etc.

S. Klarman, S. Schlobach, and L. Serafini

1 := (  {(x)})  (used

  wasGeneratedBy




)

; Atlas-X-Graphic?

Solution: Every v  MI and  such that K, v  (1) are requested resources.

Q2. Find the process that led to Atlas X Graphic, excluding everything prior to
the averaging of images with softmean.
  wasGeneratedBy

; Softmean?
2 := 1  [(used
Solution: Every v  MI and  such that K, v  2 are requested resources.




)

]wasGeneratedBy



Q3. Find the Stage 3, 4 and 5 details of the process that led to Atlas X Graphic.

Comment: This is a complex search/verification task, whose reasoning parts
can be accomplished by a mix of formulas used in Q1, Q2. Essentially, one must
decide what the relevant details are and retrieve them by applying appropriate
provenance formulas over the provenance graphs.

Q4. Find all invocations of procedure align warp using a twelfth order nonlinear
1365 parameter model, i.e. align warp procedure with argument -m 12, that ran
on a Monday.

4 := (Align-warp  hasArgValue.{-m 12}  executedOn.Monday )?
Solution: Every v  MI such that K, v  4 is a requested resource.

Q5. Find all Atlas Graphic images outputted from workflows where at least one
of the input Anatomy Headers had an entry global maximum=4095. The contents
of a header file can be extracted as text using the scanheader AIR utility.
5 := AtlasGraphic?({Image(x)}  (wasGeneratedBy ; used)

AnatomyHeader ?{hasValue(global-maximum, 4095)})

Solution: For every v  MI and  such that K, v  (5),  is a requested

resource.

Q6. Example 3, discussed in the previous section.

Q7. A user has run the workflow twice, in the second instance replacing each
procedures (convert) in the final stage with two procedures: pgmtoppm, then pn-
mtojpeg. Find the differences between the two workflow runs. The exact level of
detail in the difference that is detected by a system is up to each participant.

Comment: This is a complex search/verification task, whose reasoning parts
can be accomplished by posing a number of model checking problems. Essentially,
for each relevant provenance formula one must verify it over both graphs and
compare the obtained answers.

Q8. A user has annotated some anatomy images with a key-value pair cen-
ter=UChicago. Find the outputs of align warp where the inputs are annotated
with center=UChicago.
?

?

?
8 := {(x)}  wasGeneratedBy ; Align-warp?; used ; AnatomyImage?

{y.(Image(y)  center(y, UChicago))}

Solution: For every v  MI and  such that K, v  (8),  is a requested

resource.

Q9. A user has annotated some atlas graphics with key-value pair where the
key is studyModality. Find all the graphical atlas sets that have metadata annotation studyModality with values speech, visual or audio, and return all other
annotations to these files.

9 := AtlasGraphic?;studyModality .{speech}?  studyModality .{visual}? 
Solution: Every v  MI such that K, v  9 is a requested resource. Finding

studyModality .{radio}?

other annotations can be accomplished by posing a number of model checking
problems w.r.t. the identified resources.

The above analysis shows that typical reasoning tasks over data provenance
records consist of two components: search and logical verification. As far as verification is concerned, the logic PSLM proves well suited for modeling requested
properties and queries. In particular, out of the 9 considered problems, at least
5  Q1, Q2, Q5, Q6, Q8  can be solved directly, using a combination of
all distinctive features of PSLM , namely: PDL-like path expressions, embedded
CQs and the metalanguage. Queries Q4, Q9 can be answered without the use
of embedded CQs. Problems Q3, Q7 and partially Q9 are in fact descriptions of
complex search/verification tasks, which can be decomposed into a number of
individual verification problems. Those, in turn, can be addressed using PSLM
in the same fashion as in the remaining cases.

7 Reasoning and Complexity

The close relationship of PSLM to PDL can be conveniently exploited on the
computational level. Crucially, PSLM model checking can be decoupled into two
separate problems:

1. construction of a finite-state transition system and a PDL formula (involving

polynomially many CQ answering / DL entailment problems),

2. PDL model checking.

This technically unsurprising, but fully intended result has some significant theoretical and practical implications. From the theoretical perspective, it allows for
identifying a complexity bound, invariant to the cost of reasoning with the particular DL languages used in the representation. From the practical viewpoint,
it opens up a possibility of building simple, yet well-grounded and efficient reasoning architectures based on existing, highly optimized DL reasoners, query
engines (e.g. Mastro), and PDL model checkers (e.g. MCPDL3).
3 See http://www2.tcs.ifi.lmu.de/~axelsson/veri_non_reg/pdlig_mc.html

S. Klarman, S. Schlobach, and L. Serafini

In the following, we sketch the reduction procedure. Its full description and
the missing proofs are presented in the online technical report [24]. First, recall
the notion of a finite-state transition system.
Definition 8 (Transition system). Let P = {p, q, . . .} be a set of propositional letters and A = {r, s, . . .} a set of atomic program names. Then a finitestate transition system is a tuple S = (W,{ r| r  A},I}), where:
 W is a finite, non-empty set of elements called states,
 r W  W is a transition relation corresponding to program r,
 I : W ! 2
Let  be a PSLM provenance formula,  an -substitution, LG a metalanguage
with vocabulary  = (MC, MR, MI ), and KG = (KG, k) a metaknowledge base
over an L-provenance graph G. Given this input, we define a finite-state transition system S(KG, ()) = (W,{ r| r  A},I}), essentially, by turning individuals of KG into states of the system, structuring the transition relations in
the system isomorphically to the corresponding role relationships in KG, and by
encoding all relevant information about the individuals in KG in the valuation
I over a designated set of propositional letters corresponding to concepts and
CQs. This reduction step involves a polynomial number of decision problems of
the form KG |= C(v) and k(v) |= (), where v  MI , C is a concept in LG

is a propositional valuation function.

and  is a CQ. Further, we transform the formula () by consistently applying
substitutions of designated propositions for the corresponding PSLM subformulas in (). The resulting expression ()PDL is a well-formed PDL formula.
Thanks to such propositionalization of the input we obtain the following reduction result, where S, v |=  denotes the model checking problem in PDL, i.e.
the problem of deciding whether a PDL formula  is satisfied in state v of the
transition system S.
Theorem 1 (PSLM vs. PDL). KG, v  () iff S(KG, ()), v |= ()PDL.
It is known that the complexity of model checking in PDL is PTime-complete
[12]. Moreover, the size of the transition system S(KG, ()) and of the formula
()PDL is polynomial in (KG, , ), where (KG, , ) is the total size of KG, 
and  measured in the number of symbols used. This means, that by disregarding
the cost of DL reasoning involved in the construction of S(KG, ()), we obtain

the following time bound.
Theorem 2 (PSLM model checking: complexity). Let KG be a metaknowledge base, expressed in LG, over an L-provenance graph G. Model checking
PSLM formulas over KG is PTimeDL-complete, where DL is an oracle answering CQs in L and deciding DL entailment in LG.
Finally, we observe that for a given problem KG, v   there are at most 2(KG,)
different -substitutions , and thus, maximum 2(KG,) different possible pairs
S(KG, ), ()PDL to be considered. In practice this number can be dramati-

cally reduced by using smart heuristics to guess only potentially promising
substitutions. Analogically, the described procedure of constructing the transition systems leaves a considerable space for practical optimizations.
?

?

?
8 Conclusion

In this paper we have introduced the provenance specification logic PSLM  a
dynamic logic-based formalism for verification of data provenance records. The
validation, which we have conducted using the test queries of The First Provenance Challenge, shows that a typically requested reasoning task over a data
provenance record consist of two components: search and logical verification. As
far as the search aspect goes beyond the scope of this work and remains an
interesting problem in its own right, requiring smart retrieval and heuristic tech-
niques, we have demonstrated that the logical reasoning part can be successfully
captured using the logic and the framework developed here. Moreover, we have
shown that the computational cost of performing such tasks is very moderate,
and depends mostly on the expressiveness of the languages used for representing
the data and the provenance record.

With this contribution, we hope to pave the way towards more systematic and
formal studies of the logical problems emerging on the intersection of data-level
representations with their meta-level provenance/contextual descriptions, which,
in our belief, are of rapidly growing importance in the large-scale, distributed,
data- and semantics-rich environments of the Semantic Web and eScience.

Acknowledgments. The authors thank Paul Groth for inspiring discussions
on the ideas presented in this paper, and Davide Ceolin for helpful comments.
