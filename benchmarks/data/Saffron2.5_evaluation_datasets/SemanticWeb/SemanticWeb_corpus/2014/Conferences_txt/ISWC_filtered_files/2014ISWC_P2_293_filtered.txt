Knowledge-Driven Activity Recognition

and Segmentation Using Context Connections

Georgios Meditskos, Efstratios Kontopoulos, and Ioannis Kompatsiaris

Information Technologies Institute

Centre for Research & Technology - Hellas

6th km Xarilaou - Thermi, 57001, Thessaloniki, Greece

{gmeditsk,skontopo,ikom}@iti.gr

Abstract. We propose a knowledge-driven activity recognition and segmentation framework introducing the notion of context connections. Given an RDF dataset of primitive observations, our aim is to identify, link
and classify meaningful contexts that signify the presence of complex ac-
tivities, coupling background knowledge pertinent to generic contextual
dependencies among activities. To this end, we use the Situation concept
of the DOLCE+DnS Ultralite (DUL) ontology to formally capture the
context of high-level activities. Moreover, we use context similarity measures to handle the intrinsic characteristics of pervasive environments in
real-world conditions, such as missing information, temporal inaccuracies or activities that can be performed in several ways. We illustrate
the performance of the proposed framework through its deployment in a
hospital for monitoring activities of Alzheimers disease patients.

Keywords: ontologies, activity recognition, segmentation, context.

Introduction

In recent years, the demand for intelligent, customized user task support has proliferated across a multitude of application domains, ranging from smart spaces
and healthcare [30] to transportation and energy control [10]. The key challenge
in such applications is to abstract and fuse the captured context in order to elicit
a higher level understanding of the situation. Towards this direction, a growing body of research has been investigating ontology-based (knowledge-driven)
frameworks for modelling and reasoning about context [4], [5], [7]. The idea is
to map low-level information (e.g. objects used, postures, location) and activity models onto ontologies, enabling the inference of high-level activities using
domain knowledge and ontology reasoning. In many cases, activity recognition
is further augmented with rules [12] for representing richer relationships not
supported by the standard ontology semantics, like e.g. structured (composite)
activities [19].

A significant challenge in activity recognition is the ability to identify and
recognise the context signifying the presence of complex activities. Time windows [21], [9] and slices [24], [20], background knowledge about the order [27], [23]

P. Mika et al. (Eds.) ISWC 2014, Part II, LNCS 8797, pp. 260275, 2014.
c Springer International Publishing Switzerland 2014
?

?

?
kettle1
cup1
teazone1

09:20

plate1

pen1

kettle2
teabag2

spoon1

teabag1

teazone2

cup2

kettle1
cup2

teabag1
cup1
teazone1

glass1
teabag2

tablezone1 kettle2

chair1
teazone2

09:22

08:42

08:48

Fig. 1. Example observations detected during tea preparation

or duration [32] of activities constitute commonly used approaches in knowledgedriven activity recognition. Such approaches, however, define strict contextual
dependencies, e.g. start/end activities or maximum activity duration, assuming
that all the information is available. Thus, they fail to capture many intrinsic characteristics of pervasive environments in real-world conditions, such as
imperfect information, noise or inaccurate temporal correlations.

An important factor to take into consideration is that contextual information
is typically collected by multiple sensors and complementary sensing modali-
ties. Each modality generates information from a different perspective, but by
combining them together we are in a position to infer far more about a persons
activities than by any sensor alone. Thus, a further challenge is to effectively fuse
multiple sources of heterogeneous, noisy and potentially inconsistent information
in a way that provides accurate and useful outputs.

In order to better highlight the challenges, consider the two example time-lines
in Fig. 1 that contain information regarding the location and the objects that
a person interacts with when preparing hot tea. These are subsets of real-world
data obtained by monitoring Alzheimers disease patients in the FP7 project
Dem@Care1. As illustrated in the figure:

 The duration of activities usually varies, even when they are performed by
the same person. The use of time windows, slices or background knowledge
regarding activity duration fails to capture this characteristic, or, at least,
the segmentation task becomes too complex.

 Many activities are carried out differently even by the same person. Thus,
the use of strictly structured background knowledge relevant to the order of
activities or their temporal boundaries is not always practical and flexible.
 The information integrated from heterogeneous sources is intrinsically noisy,
incomplete, with inaccurate temporal correlations. For example, the cup2
and teabag2 observations in the second time-line in Fig. 1 do not coincide
with information regarding the location of the person. Such information
cannot be processed by patterns that, e.g., explicitly enumerate the subactivities and temporal relations involved in a complex behaviour.

Towards addressing these intrinsic challenges of pervasive applications, this
paper presents a practical ontology-based activity recognition framework. The
framework detects complex activities in multi-sensor fusion environments based

1 Dementia Ambient Care: Multi-Sensing Monitoring for Intelligent Remote Manage-

ment and Decision Support, http://http://www.demcare.eu/

G. Meditskos, E. Kontopoulos, and I. Kompatsiaris

on loosely coupled domain activity dependencies rather than on strict contextual constraints. More specifically, given an RDF dataset of primitive activities (observations), we define a procedure for assigning context connections, i.e.
links among relevant groups of observations that signify the presence of complex activities. The connections are determined by semantically comparing local
contexts, i.e. the type and number of neighbouring observations, against context
descriptors, i.e. background knowledge about domain activity dependencies. We
formalise these descriptors by capitalising on the Situation concept of the DnS
pattern [13] of the DOLCE+DnS Ultralite (DUL) [11] ontology, exploiting the
OWL 2 meta-modelling capabilities (punning [15]) for defining generic relations
among classes. As a result, this paper features the following contributions:

 We deliver a flexible and reusable framework for recognising complex activ-

ities that is applicable to a wide range of activity recognition scenarios.

 We propose a simple and reusable ontology pattern for capturing common

sense background knowledge regarding domain activity dependencies.

 We present a context-aware activity recognition and segmentation algorithm
that incorporates the level of relaxation needed during context classification.

In this work we consider non-interleaving human activities, i.e. only one activity can be performed each time. Moreover, we focus on offline activity recog-
nition. We consider the support of interleaved and concurrent activities, as well
as, the real-time continuous activity recognition as very important research directions of our ongoing work. On the other hand, we believe our approach is
quite suitable for further research purposes, e.g. towards extracting behaviour
patterns and detecting behaviour changes, including the manner in which activities are performed, idiosyncratic and habitual knowledge, as well as recurrent
routines. We further elaborate on this direction in Section 5.

The rest of the paper is structured as follows: Section 2 reviews relevant
ontology-based activity recognition frameworks. Section 3 describes the ontology
pattern we use to associate high-level activities with generic context descriptors,
whereas the algorithms for segmentation and activity recognition are described
in Section 4. Section 5 presents the results of the evaluation of our approach on
real-world data. Conclusions and future directions are presented in Section 6.

2 Related Work

Ontologies have been gaining increasing attention as a means for modelling and
reasoning over contextual information and, particularly, human activities. Under this paradigm, OWL is used for describing the elements of interest (e.g.
events, activities, location), their pertinent logical associations, as well as the
background knowledge required to infer additional information. For example, a
tea preparation activity in the kitchen that is inferred on the basis of heating
water and using a tea bag and a cup could be modelled in OWL (TBox) as:
M akeT ea  Activity and (actor only (P erson and (uses some T eaBag)

and (uses some Cup) and (uses some Kettle) and (in some Kitchen)))
?

?

?
In such cases, the data (ABox) needs to be segmented into chunks of activities
to allow complex activities to be derived using standard OWL reasoning. How-
ever, the issue of data segmentation in ontology-based activity recognition has
received little attention. For instance, in [8] and [26], situations correspond to
OWL individuals, while DL reasoning [2] is used for determining which contextual concepts a specific situation falls into. However, no details are provided with
respect to the method used for segmenting the data. In [25] statistical inferencing
is used for segmenting the data and for predicting the most probable activities,
whereas symbolic DL reasoning is applied for further refining the results.

The most common approach for ontology-based activity segmentation involves
the use of time windows and slices. In [9] and [21] dynamically sliding time windows are used for activity recognition. The activities are specified as sequences
of user-object interactions, whereas subsumption reasoning is used for inferring
the ongoing activity. In [20], time slices are used for grouping activities and
inferring complex situations. In [24], one-minute fixed time slices are used for
activity recognition, using notions such as recently used and second last activity.
In most cases, though, such approaches require prior domain knowledge, such as
maximum duration of activities or window length, which results in inflexible and
difficult to implement approaches, even if they can be dynamically adjusted.

In [32], an approach is presented for the recognition of multi-user concurrent
activities where each activity is constrained by necessary conditions, e.g. activity prepare breakfast should occur in the morning and activity bath should
last more than 5 minutes. In [23], an ontology is used for capturing atomic and
compound events and for defining operators among event sets (e.g. sequence, con-
currency). In addition, many approaches combine ontologies with rules [20], [31],
[33], CEP patterns [18], [28] and SPARQL queries [29], [1], [3], [17]. The main
limitation of these approaches is that they encapsulate strict activity patterns
that cannot provide enough flexibility for handling the imprecise and ambiguous
nature of real-world events in multi-sensor fusion environments.

The authors in [27] conceive activity recognition as a plan recognition problem.
An activity plan consists of a partially ordered sequence of temporal constraints
and actions that must be carried out in order to achieve the activitys goals.
Though relevant to environments where the order of observations is accurate,
plans fall short when more intricate activity patterns are involved, e.g. when
fusing multi-sensor data with inherent temporal incoherences.

Our work has been mainly inspired by [22] and [14]. In [22], a data-driven
approach is described for human activity recognition based on the order of object
usage. The authors use web mining for extracting the objects most relevant
to specific activities and each activity is then associated with a key object.
The limitation is that each activity in the list is assumed to have a unique key
object. Moreover, the proposed algorithms handle only sequential traces without
overlaps. In our work, we follow a more formal and flexible approach, defining
the activities relevant to high-level situations in terms of an ontology, without
needing to specify key objects. Moreover, the recognition algorithms take into
account the type and number of overlapped activities.

G. Meditskos, E. Kontopoulos, and I. Kompatsiaris

dul:Situation

Context
Descriptor

dul:isSettingFor

Context
Descriptor

dul:isSettingFor

describes

_:a

MakeTea

dependency
[allValuesFrom]

describes
[exactly 1]

Domain Ontologies

(a)

rdfs:subClassOf
object property restriction

rdf:type

Cup

Kettle
Spoon

dependency

TeaBag

Sugar

TeaZone

(b)

rdfs:subPropertyOf

instance

object property assertion Domain class

Fig. 2. (a) The ContextDescriptor class, (b) Example annotation of the MakeTea
domain activity

In [14] a similarity-based segmentation approach is proposed. Generic activity
models are built that are specific to the deployment environment and contain sensor activation sets for each complex activity. The segmentation and recognition
are based on similarity measures for comparing timely ordered sensor sequences
and sensor models of activities. The key difference of our work is that we use an
ontology for modelling common sense high-level knowledge about activity depen-
dencies, which also allows us to incorporate hierarchical relationships in context
classification. Moreover, similarly to [22], instead of using window thresholds for
analysing input data, we examine neighbouring events.

3 Domain Context Descriptors

In order to describe the context pertinent to each high-level activity in an abstract yet formal way, we reuse the Situation concept of the Descriptions and
Situations (DnS) [13] pattern of DOLCE+DnS Ultralite (DUL) [11]. The aim
is to provide the conceptual model for annotating domain activity classes with
lower-level observation types. Fig. 2 (a) shows the specialisation of the Situation
class, along with two sub-properties of the isSettingF or upper-level property.

Our aim is to define relations among classes, therefore, the proposed ontology
treats classes as instances, allowing property assertions to be made among domain concepts. Intuitively, the ontology can be thought of as a conceptual (meta)
layer that can be placed on top of any domain activity ontology. This way, instances of the ContextDescriptor are used to link domain activities (describes
property) with one or more lower-level conceptualisations through dependency
property assertions. Fig. 2 (b) presents an example of annotating class M akeT ea
with class types relevant to objects (e.g Cup) and location (e.g. T eaZone).

The model also allows annotated classes to inherit the context dependencies

of the superclasses through the following property chain axiom:

describes  subClassOf  isDescribedBy  dependency  dependency
?

?

?
rdf:type Domain class
object property assertion

instance

Context
Descriptor

teabag1

o1

o4

kettle1

tablezone1

teacup1
o2

o5
teazone1

o3

(a)

spoon1

o9

teacup2
o7
teabag2

o6

o10
sitting1

o8

glass1

time

describes

_:b

DrinkTea

dependency

TeaCup
Sitting

Spoon

TableZone

(b)

Fig. 3. (a) Example observations relevant to making and drinking tea, (b) The context
descriptor of DrinkT ea

In the rest of the paper, we use the term context descriptor to refer to the
set of classes, denoted as dC , that a domain activity C has been annotated with.
For example, the context descriptor of M akeT ea is denoted as dMakeT ea and is
equal to the set {Cup, Kettle, Spoon, T eaZone, Sugar, T eaBag}.

4 Segmentation and Activity Recognition
Given a set O = {o1, o2, ..., on} with RDF instances representing low-level ob-
servations, e.g. objects, locations, postures, etc., and a set of domain context
descriptors D = {dC1, dC2, ..., dCk
}, we describe in this section the steps involved
in identifying meaningful contexts in O for recognizing higher level activities. We
use Fig. 3 (a) as a running example that involves observations relevant to making and drinking tea, while the corresponding context descriptors are depicted
in Fig. 2 (b) and Fig. 3 (b), respectively.

4.1 Local Contexts

The first step of the segmentation algorithm is to define the local contexts for
each observation oi  O that capture information relevant to the neighbouring
observations of oi and the most plausible activities that oi can be part of. More
specifically, let N r
i be the set of observations oj in the neighbourhood of oi that
either overlap with oi (oi  oj) or are the r-nearest to oi (n(oi, oj )  r), based on
their temporal ordering. Moreover, let T (oi) be the most specific class of oi, D
the set of domain context descriptors and  a local context similarity function.
Definition 1. A local context li of an observation oi  O is defined as the tuple
i = {oj | oj  O, oi  oj  n(oi, oj)  r} and C is the
oi, N r
high-level class of the most plausible classification of li, such that dA  D :
i,T , dC ), where dC  D, dC = dA and N r
i,T = {t | oj 
(N r
i , t = T (oj)}.
N r
The class C denotes the most plausible domain activity classification of li,
derived by computing the  similarity between the set with the most specific

i , C, where N r

i,T , dA) > (N r

G. Meditskos, E. Kontopoulos, and I. Kompatsiaris

i,T and the domain context descriptors dk  D. The sets
i,T are represented as multisets (duplicates are allowed), since the number of

observation classes N r
N r
observations with similar class types in the neighbourhood of oi is important.

Local Context Similarity . The  measure captures the similarity between
the multiset N r
T of a local context against the context descriptor set dC of a
class C. It is defined as
?

?

?
(n, c)

(N r

T , dC ) =

nN r

max
cdC
|N r
T|

(1)

where N r
T is the multiset with neighbouring observation class types and dC is
the context descriptor of C.  is computed as the mean value of the maximum
 similarities for each concept n  N r
T , since each n may have more than one
relevant concepts in dC . Intuitively,  captures the local plausibility of an observation oi to be part of a complex activity C. If  = 1, then all the classes
in N r
T appear in dC and, therefore, it is very likely that the corresponding local
context is part of the complex activity C.
ing observation class n  N r




T against a context descriptor class c  dC as

Equation (1) uses the  function that computes the similarity of a neighbour-

if n  c (includes n  c)
if c  n
otherwise

(n, c) =

(2)

1,
|U(n)U(c)|

|U(n)|

,

0,

where U (C) is the set of the superclasses of C, excluding the T hing concept,
such that U (C) = {A | C  A, A = }. Intuitively, an observation class n in the
neighbourhood of oi exactly matches a class c in the context descriptor set dC ,
if it is equivalent to or a subclass of c. In this case, n is subsumed by c and, thus,
fully satisfies the contextual dependency imposed by dC that there should be at
least one observation of type c. On the other hand, if c is subsumed by n (c  n),
then n is a more general concept than the one required by the context descriptor
and the similarity is computed based on the rate of the superclasses of n that
are also superclasses of c. For example, if Spoon is a direct subclass of Cutlery
(Spoon  Cutlery), n = Spoon and c = Cutlery, then (Spoon, Cutlery) = 1,
since Spoon is subsumed by Cutlery. If n = Cutlery and c = Spoon, then
(Cutlery, Spoon) < 1, depending on their superclasses.

Creating Local Contexts. Algorithm 1 describes the procedure for creating
set L with the most plausible local contexts for each oi  O. The algorithm
begins by defining set N r
i with the neighbour observations of oi (line 3). Then,
the partial context set Pi is created as the multiset of the most specific class types
of the observations in N r
i (line 4). The algorithm then computes the  similarity
Sk of Pi against each context descriptor dCk , creating the set Gi with tuples
?

?

?
Algorithm 1. Creating local contexts
Data: Observations: O = {o1, o2, ..., oi}, Domain context descriptors:

D = {dC1 , dC2 , ..., dCk}, Nearest observations threshold: r.

Result: The set L with the most plausible local contexts.

1 L  ;
2 foreach oi  O do

i , t = T (oj)};

i = {oj | oj  O, oi  oj  n(oi, oj)  r};
N r
Pi  {t | oj  N r
Gi  ;
foreach dCk  D do
forall the Ck, Sk  Gi with the max Sk do

if A  dCk , T (oi)  A then Gi  Gi  {Ck, (Pi, dCk )},  = 0
L  L  {oi, N r

i , Ck};

of the form Ck, Sk (lines 5 to 7). If the class type of oi does not semantically
belong to class descriptor dCk , then the corresponding similarity tuple is omitted
i , Ck is created for
(line 7), ignoring noisy observations. Finally, a tuple oi, N r
all Ck, Sk with the maximum similarity in Gi and inserted into L. Note that
Gi may contain more than one Ck, Sk tuples with the maximum similarity,
and, therefore, more than one local contexts can be generated for oi.

Example. We describe the definition of the local context for teacup2 (o7) in Fig.
3 (a), using r = 1. Observations o5, o6 and o8 overlap with o7, whereas o9 and
7 = {o7, o5, o6, o8, o9, o4} (line 3) and P7 =
o4 are the 1-nearest to o7. Thus, N 1
{T eaCup, T ableZone, T eaBag, Sitting, Spoon, Kettle} (line 4). According to
Figs. 2 (b) and 3 (b), the context descriptor set is D = {dMakeT ea, dDrinkT ea},
where dMakeT ea = {T eaCup, Kettle, Spoon, T eaZone, Sugar, T eaBag} and
dDrinkT ea = {T eaCup, Sitting, T ableZone, Spoon}. The class type for o7 is

T eaCup that exists in both context descriptors, therefore  will be computed
for both of them. According to (1), (P7, dMakeT ea) = 1+0+1+0+1+1
= 0.66
and (P7, dDrinkT ea) = 1+1+0+1+1+0
= 0.66 (assuming that there are no hierarchical relationships among the domain class types). Thus, there are two
local contexts for o7 with maximum plausibility 0.66: l7 = o7, N 1
similarity is also depicted for completeness): l1 = o1, N 1
o2, N 1
l5 = o5, N 1
T ea0.57, l9 = o9, N 1

7 , M akeT ea
7 , DrinkT ea. Similarly, we have the following local contexts (
1 , M akeT ea1.0, l2 =
4 , M akeT ea0.75,
8 , Drink-

7 = o7, N 1

2 , M akeT ea1.0, l3 = o3, N 1

6 , M akeT ea0.66, l8 = o8, N 1
9 , DrinkT ea0.5, l10 = -.

5 , DrinkT ea0.5, l6 = o6, N 1

3 , M akeT ea0.83, l4 = o4, N 1

and l

9 , M akeT ea0.5, l

9 = o9, N 1
?

?

?
4.2 Context Connections

Based on the local contexts obtained in the previous section, the next step is to
define context connections, that is, links among relevant local contexts that will
be used to create the final segments for activity recognition.

G. Meditskos, E. Kontopoulos, and I. Kompatsiaris

Algorithm 2. Creating context connections
Data: Local contexts: L = {l1, l2, ..., lj}, where lj = oj , N r
Result: Set Cset with context connections.

j , Ck.

foreach lj = oj, N r
Cset  Cset  {li

i , Cm  L do
j , Cn  L, where oi = o2, Cm  Cn and oi  N r
Cm lj}

j do

1 Cset  ;
2 foreach li = oi, N r

Definition 2. Two local contexts li = oi, N r
linked with a context connection, denoted as li

i , Cm and lj = oj , N r
Cm lj, if oi  N r

j , Cn are
j and Cm  Cn.

5 of table.zone1 (o5) (N 1

Intuitively, a context connection captures the contextual dependency between
two neighbouring observations oi and oj with respect to a common high-level
classification activity Cm (Cm  Cn). Note that symmetry and transitivity do
not hold. For example, in Fig. 3 (a), spoon1 (o9) belongs to the neighbourhood
5 = {o1, o3, o4, o5, o6, o7, o8, o9}), but table.zone1
set N 1
9 = {o6, o8, o9, o10}).
does not belong to the neighbourhood set N 1
Cset. Two local contexts li = oi, N r
j , Cn are retrieved
from L, such that oi belongs to the neighbourhood of oj (oi  N r
j ) and Cm  Cn
Cm lj is added to Cset (line 4).
(lines 2 and 3), and the context connection li
Example. Algorithm 2 creates 29 context connections among the local contexts
described in Section 4.1 for the running example in Fig. 3 (a). For example,

9 of spoon1 (N 1
i , Cm and lj = oj, N r

Algorithm 2 describes the process for creating the set of context connections
?

?

?
7 with classification class DrinkT ea. Therefore, l7

o7 belongs to the neighbourhood of the local contexts l5, l6 and l8, i.e. o7 
5 , o7  N 1
N 1
8 . As described in Section 4.1, the classification class of
l5 and l8 is DrinkT ea (DT ), whereas the classification class of l6 is M akeT ea
(M T ). Moreover, o7 has two local contexts: l7 with classification class M akeT ea
DT l5,
and l
 l2,

l

 l4,
l1
 l7,
l4
DT l7,
l6
l8

 l6 and l
DT l8. The other context connections that are generated are: l1
 l2, l3
 l3, l1
 l1, l4
 l3, l6
 l9, l9
DT l5, l8
DT l9, l9

 l4, l2
 l2, l4
 l6, l9
DT l5, l9

 l1, l2
 l3, l4
 l7, l5

 l3, l3
 l6, l4
DT l7, l5

6 and o7  N 1

 l1, l3
 l7, l6
DT l8, l8

DT l7, l9

DT l8.
?

?

?
4.3 Activity Situations and Recognition
The last step is to create activity situations, i.e. subsets of the initial set of
observations O, and to compute the similarity  to the context descriptor dC .
Definition 3. An activity situation S is defined as the tuple Obs, C, V , where
Obs  O is the set of the observations that belong to the activity situation
and V denotes the similarity of S to the context descriptor dC , such that V =
(dC , ObsT ), where dC  D and ObsT = {t | oi  Obs, t = T (oi)}.
?

?

?
Situation Similarity . The  measure captures the similarity between the
domain context descriptor of class C, namely dC , and set ObsT with the most
specific classes of the observations in a situation.
?

?

?
(dC , ObsT ) =

ndC

max
cObsT
|dC|
?

?

?
(c, n)

(3)

Similarly to  in (1),  denotes the similarity of two sets of concepts. However,
 aims to capture the local (partial) similarity of neighbourhood class types (N r
T )
against the context descriptor dC . In contrast,  captures the similarity of the
context descriptor dC against the set of situation observation class types (ObsT ),
in order to derive the final plausibility for the corresponding situation. If  = 1,
then all the classes in dC appear in ObsT , meaning that the situation can be
considered identical to the context descriptor dC , and, therefore, to class C.

Creating Activity Situations. An activity situation is derived by simply
Cm le,
traversing the path defined by context connections la
collecting the observations oi of the local contexts li found in the path. The
collected observations constitute set Obs of a situation S = Obs, Cm, V .

Cm ...

Cm lb

Algorithm 3 describes the aforementioned procedure. It begins by selecting
Cm lj, which has not been visited yet (line 2), as the
a context connection li
root of the current path, adding it to the Expand set (line 4). In each iteration,
Cm ll is selected from the Expand set and: (a) the
a context connection lk
observations of the pertinent local contexts are added to Obs (line 7), (b) the
current context connection is added to the V isited set (line 8), and (c) the
Cm lq are retrieved from Cset and added to the Expand
context connections lp
set, such that lp = ll (lines 9, 10). An empty Expand set denotes that there
are no other context connections in the current path. In this case, the context
descriptor of Cm (dCm) is compared against the set ObsT with the most specific
types of observations in Obs to compute the  similarity of S (line 11).

Example. By applying Algorithm 3 over the context connections presented in

Section 4.2, two situations are generated: S1 = Obs1, M akeT ea, 0.833 and
S2 = Obs2, DrinkT ea, 1.0, where Obs1 = {o1, o2, o3, o4, o6, o7, o9} and Obs2 =
{o5, o7, o8, o9}. It is worth noting that despite the overlapping and noisy nature
of the observations in the example (e.g. the location-related observations o3 and
o5 overlap), the algorithm is able to discriminate the two situations of making
and drinking tea by also connecting the relevant observations.

Moreover, the nearest observations threshold r in the running example was set
to 1, meaning that, apart from overlapping observations, the 1-nearest observations were also taken into account to define neighbourhood relations. If we instead
use r = 0, then we get the following situations: S
and S

1, M akeT ea, 0.666
?

?

?
2 =
{o5, o7, o8, o9}. In this case, o6 (teabag2) is not connected with observations

2 = Obs2, DrinkT ea, 1.0, where Obs
?

?

?
1 = Obs
?

?

?
1 = {o1, o2, o3, o4} and Obs
?

?

?
G. Meditskos, E. Kontopoulos, and I. Kompatsiaris

Algorithm 3. Creating activity situations
 lb, le
Data: Context connections: Cset = {la
Result: The set Sset with activity situations S.
Cm lj  V isited do

1 Sset, V isited  ;
2 foreach li

Cm lj  Cset  li

Ck

Obs  ;
Cm lj};
Expand  {li
while Expand =  do

Cl

 lf , ..., li

Cm lj}.

Cm ll  Expand.pop;
lk
Obs  Obs  {ok, ol};
V isited  V isited  {lk
Cons  {lp
Expand  Expand  Cons;
Sset  Sset  {S}, where S  Obs, Cm, (dCm , ObsT ) and
ObsT = {t | o  Obs, t = T (o)};

Cm ll};
Cm lq | lp = ll,lp

Cm lq  Cset, lp

Cm lq  V isited};

relevant to the M akeT ea activity, and is considered as noise, breaking also the
connection of o7 and o9 with the M akeT ea activity. Despite the fact that the
M akeT ea activity is detected with a lower plausibility when r = 0, it could be
argued that the resulted situations are more meaningful for further analysis. Intu-
itively, r allows to control the amount of contextual information taken into account
during the definition of the neighbourhood sets and local contexts of observations.
Currently, r is defined manually based on domain knowledge regarding the quality
and temporal characteristics of the data used.

5 Deployment, Results and Discussion

We have implemented our approach on top of OWLIM [6], following an ontologybased representation of local contexts, context connections and situations and
using SPARQL queries (rules) for implementing the algorithms (SPARQL Inferencing Notation - SPIN [16]). Fig. 4 presents a sample SPARQL query that
implements Algorithm 2 for creating context connections.

Our framework is part of a real-world deployment for monitoring Alzheimers
disease patients in a hospital2. The aim is to help clinicians assess the patients
condition through a goal-directed protocol of 10 Instrumental Activities of Daily
Living (IADL), e.g. preparing the drug box (Fig. 5). Based on primitive obser-
vations, high-level activities are recognised that inform the clinicians, who are
not present during the protocol, about activities with too long duration or activities that have been missed or repeated. The setting involves wearable and
ambient video and audio sensors, accelerometers and physiological sensors. Table
1 presents the context descriptors used for the detection of the 10 activities.
2 The system has been installed in the Memory Resource and Research Centre
(CMRR) of the University Hospital in Nice (CHUN), under Dem@Care FP7 Project.
?

?

?
CONSTRUCT {

[] a :ContextConnection; :li ?li; :lj ?lj; :classification ?Cm.

}
WHERE {

?li a :LocalContext; :obs ?oi; :classification ?Cm.
?lj a :LocalContext; :obs ?oj; :classification ?Cm; :neighbour ?oi.
FILTER (?oi != ?oj).
NOT EXISTS {[] a :ContextConnection; :li ?li; :lj ?lj; :classification ?Cm.}.

}

Fig. 4. SPARQL-based implementation of Algorithm 2

Table 1. The context descriptor dependencies of the high-level activities

Context Descriptor Classes

Establish account balance Sitting, Accounts, Table, TableZone, Pen
Prepare drug box
Prepare hot tea
Search for bus line
Make a phone call
Watch TV
Water the plant
Write a check
Read an article
Enter/Leave the room

Pillbox, Basket, MedicationZone
Kettle, TeaZone, TeaBag, Cup, Sugar, TeaBox
Map, MapZone, RouteInstructions
Phone, PhoneZone, PickUpPhone, Talk
Remote, TV, TVZone, Sitting
WateringCan, PlantZone, Bending, Plant
Sitting, Pen, Check, TableZone, Table
Sitting, TableZone, Newspaper, Table
DoorOpen, EmptyRoom

Table 2 summarises the performance on a dataset of 25 participants, where
True Positives (TP) is the number of IADLs correctly recognised, False Positives
(FP) is the number of IADLs incorrectly recognised as performed and False
Negatives (FN) is the number of IADLs that have not been recognised. The
True Positive Rate (TPR) and Positive Predicted Value (PPV) measures denote
the recall and precision, respectively, and are defined as:

T P R =

T P

T P + F N

, P P V =

T P

T P + F P

We used r = 0, since the dataset contains highly overlapping observations,
and we set a minimum threshold on  ( 0.65), so as to ignore activities with low
plausibility. To demonstrate the effect of a higher r value in our experiments,
we also present the performance using r = 5. By increasing the r value, the
number of neighbours for each observation also increases. This way, more local
contexts are generated, affecting precision and recall. As explained, the optimal r
value depends on the data quality and temporal characteristics and, in principle,
datasets with highly overlapping and incoherent observations need small r values.
Our approach achieves the best accuracy for activities Prepare hot tea,
Make a phone call, Watch TV and Water the plant, whose context descriptors encapsulate richer domain contextual information, compared to Pre-
pare drug box and Search for bus line. On the other hand, the recall of these

G. Meditskos, E. Kontopoulos, and I. Kompatsiaris

Table 2. Activity recognition performance

r = 0

r = 5

TP FP FN TPR% PPV% TPR% PPV%

Establish account balance 30 10

Prepare drug box

Prepare hot tea

Search for bus line

Make a phone call
Watch TV
?

?

?
Water the plant

Write a check

Read an article
Enter/Leave the room
?

?

?
88.24
92.00
79.31
96.30
89.29
84.00
80.00
87.50
95.83
98.00

75.00
88.46
95.83
86.67
96.15
95.45
95.24
77.78
85.19

85.71
85.19
76.67
92.86
86.21
80.77
80.00
87.50
92.00
98.00

73.17
82.14
88.46
83.87
92.59
91.30
86.96
75.68
85.19
98.00

(a) Writing a check

(b) Preparing the drug box

Fig. 5. Example IADL activities of the protocol (wearable and ambient camera)

activities is relatively low, since they are more susceptible to false negatives,
requiring richer contextual dependencies to be present.

Another interesting finding involves activities Establish account balance,
Write a check and Read an article. The context descriptors of these activities
have many members in common; e.g. Accounts and Checks are the only discriminating contextual objects between Establish account balance and Write
a check. This way, our approach detects both activities when the corresponding
observations are missing, resulting in low accuracy. Finally, the Enter/Leave the
room activities share exactly the same context descriptors; however, we distinguish them (in an ad hoc manner) by the order in which they take place.

As already mentioned, our approach is currently used in an offline mode,
where each participants data is collected and processed after the execution of the
protocol; therefore, the processing time is not a critical requirement in the current
setting. However, Fig. 6 gives a gist about the required time for processing
different sets of observations using a Dell Optiplex 7010 PC configuration (i7-
3770 Processor, Quad Core, 3.40GHz). In each protocol execution, approx. 500
to 800 observations are generated, depending on the participants performance.
?

?

?
)
c
e
s
(
 
e
m

i
t

#observations

Fig. 6. Activity recognition time in relation to the number of observations

Discussion. Our framework achieves an average TPR and PPV close to 90%,
demonstrating the feasibility of our approach in real-world settings. However,
there are still certain limitations, which we consider as very important research
directions for future work. First, our approach cannot handle interleaved activ-
ities, nor can it resolve conflicts after the recognition process, as argued for the
Establishing account balance and Write check activities. We are investigating the use of defeasible reasoning on top of the framework for further enhancing
the activity recognition capabilities. Second, our next step is to deploy the framework in homes for providing context-aware real-time assistance to Alzheimers
patients. To this end, we are currently investigating adaptations of our algorithms to allow the dynamic and incremental generation of local contexts and
context connections for real-time activity segmentation and recognition.

In addition, one of the most challenging tasks in pervasive healthcare is patient profiling, which can provide the behaviour interpretation and feedback
services with knowledge-driven personalisation capabilities and adaptive support services. To this end, we are exploring methods for extracting behaviour
patterns and detecting behaviour changes from activity situations that are generated based on the abstract context descriptors presented here. Regarding the
representation of these patterns, our objective is to take full advantage of the
DnS pattern, associating each Situation to one or more behavioural Description
instantiations pertinent to patients idiosyncratic and habitual information.

6 Conclusions

We propose a knowledge-driven framework towards activity recognition and seg-
mentation, coupling ontology models of abstract domain activity dependencies
with a context-aware approach for multi-sensor fusion and monitoring. We formalise activity dependencies, capitalising upon the Situation conceptualisation
of the DnS ontology pattern in DUL for defining generic context descriptors,
whereas activity segmentation and recognition is reduced in linking and classifying meaningful contextual segments. We elaborated on the obtained results
from the evaluation of our approach in a real-world deployment, monitoring activities of elderly people during the execution of a clinical protocol for assessing
Alzheimers disease. The use of generic context descriptors in representing activity models achieves very promising results, leading to handling the intrinsically
noisy and imperfect information in multi sensory environments, beyond strict
activity patterns and background knowledge (e.g. max activity duration).

G. Meditskos, E. Kontopoulos, and I. Kompatsiaris

The key directions that underpin our ongoing research involve (a) introducing
an additional layer for detecting interleaved activities and resolving conflicts,
(b) adapting our algorithms for supporting real-time context-aware monitoring,
and, (c) patient profiling through the extraction and learning of behavioural
patterns from the detected activity situations. In addition, we are investigating
extensions to the Situation model for capturing richer contextual dependencies,
such as compositions of context descriptors.

Acknowledgments. This work has been supported by the EU FP7 project
Dem@Care: Dementia Ambient Care  Multi-Sensing Monitoring for Intelligent
Remote Management and Decision Support under contract No. 288199.
