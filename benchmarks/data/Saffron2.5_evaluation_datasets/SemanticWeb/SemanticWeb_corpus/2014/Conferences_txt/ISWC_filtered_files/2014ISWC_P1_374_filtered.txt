Transferring Semantic Categories with Vertex

Kernels: Recommendations

with SemanticSVD++

Matthew Rowe

School of Computing and Communications, Lancaster University, Lancaster, UK

m.rowe@lancaster.ac.uk

Abstract. Matrix Factorisation is a recommendation approach that
tries to understand what factors interest a user, based on his past ratings
for items (products, movies, songs), and then use this factor information
to predict future item ratings. A central limitation of this approach however is that it cannot capture how a users tastes have evolved beforehand;
thereby ignoring if a users preference for a factor is likely to change. One
solution to this is to include users preferences for semantic (i.e. linked
data) categories, however this approach is limited should a user be presented with an item for which he has not rated the semantic categories
previously; so called cold-start categories. In this paper we present a
method to overcome this limitation by transferring rated semantic categories in place of unrated categories through the use of vertex kernels;
and incorporate this into our prior SemanticSV D++ model. We evaluated several vertex kernels and their effects on recommendation error,
and empirically demonstrate the superior performance that we achieve
over: (i) existing SV D and SV D++ models; and (ii) SemanticSV D++
with no transferred semantic categories.

Introduction

Recommender systems have become a ubiquitous information filtering device
that is prevalent across the web. At its core is the profiling of a user based on his
prior behaviour to then forecast how he will behave in the future: i.e. how he will
rate and consume items (movies, songs, products) thereafter. One of the most
widespread approaches to recommending items to users is matrix factorisation;
this method functions by mining a given users affinity with a range of latent
factors, in doing so allowing a users rating for a given item to be predicted based

on the dot-product (puqi) between the users latent factor vector (pu) and the
items latent factor vector (qi). The problem with such approaches is that one
cannot capture how a given users tastes have evolved over time, given that
the mined latent factors vary depending on the input - the factor consistency
problem: where the latent factor vector indices of equivalent factors differ each
time factorisation is performed. If we can capture information about how a users
tastes have changed then we can understand whether a user is likely to diverge
in their preferences, or not, in the future and use this information to inform

P. Mika et al. (Eds.) ISWC 2014, Part I, LNCS 8796, pp. 341356, 2014.
c Springer International Publishing Switzerland 2014

M. Rowe

what recommendations to give. This prompts two research questions: how can
we capture the evolution of a users tastes over time? And how can we include
taste evolution information within a recommender system?

In our recent prior work we presented a recommendation approach based on
matrix factorisation called SemanticSV D++ [9] - a modification of the existing
SV D++ model [4] - that captures a users preferences for semantic categories
of items, and how these preferences have evolved over time. One limitation of
this approach, however, is the existence of cold-start categories where a user has
not rated an item from a given category before. To overcome this limitation in
this paper we present a technique to transfer existing, rated semantic categories
via vertex kernels, thereby leveraging existing semantic category ratings into the
SemanticSV D++ model. Our contributions in this paper are as follows:

1. Identification and quantification of the cold-start categories problem, its implications on semantic recommendation approaches, and a method to transfer existing rated semantic categories via vertex kernels that function over
the linked data graph - presenting four of such vertex kernels.

2. An extension of the SemanticSV D++ recommendation approach that captures users taste evolution, based on semantic categories, and transfers rated
semantic categories to overcome the cold-start categories problem.

3. An empirical evaluation of our approach that demonstrates improved performance when transferring semantic categories over: (i) existing SV D and
SV D + + models; and (ii) not transferring rated semantic categories.

We have structured this paper as follows: section 2 presents the related work
within the area of semantic recommender systems and how such existing approaches have functioned to date; section 3 explains the movie recommendation
dataset that we used and the URI alignment procedure that we followed; section 4 explains the transferring of semantic categories to overcome the cold-start
category problem; section 5 presents our approach for modelling users taste profiles and how this enables the evolution of users tastes to be captured; section
6 describes the SemanticSV D++ model, the factors within the model, and the
model learning procedure that we followed; section 7 presents our experimental
evaluation of the model; section 8 discusses the limitations of this work and plans
for future work; and section 9 draws the paper to a close with the conclusions
gleaned from this work.

2 Related Work

There has been a flurry of recent work to combine recommender systems with
the semantic web, and in particular linked data. Earlier work in this space was
presented by Passant [8] to perform music recommendations by using the taste
profile of a users listening habits. The linked data graph could then be used to
find the different pathways that connect two arbitrary nodes (e.g. resources of
?

?

?
bands and artists) and how they can be linked together. These paths were then
used to gauge how close artists are, and thus recommend similar bands to what
the user had listened to. The linked data graph has also been used in recent work
by Di Noia et al. [2] to extract movie features for a content-based recommender
system in order to build user profiles. In this instance, features specific to movie
items (e.g. actors, directors of movies) were extracted from linked data based
on the surrounding context of the item. Work by Ostuni et al. [7] expanded on
the work of Di Noia et al. [2] by mining path-based features that link the past
ratings of users together; in doing so the authors were able to induce a top-
n ranking function for recommendations. Such is the potential for linked data
within recommender systems, that the Extended Semantic Web Conference 2014
has also held a recommendation challenge where participants must recommend
books to users; where such books are aligned with their semantic web URIs on
the web of linked data.1

Our recent work [9] combined semantic taste evolution information into a
recommender system by modelling users tastes at the semantic category level,
thereby overcoming the factor consistency problem - i.e. where mined latent factor vector indices of equivalent factors differ each time factorisation is performed.
However this approach is limited when presented with items assigned to coldstart categories; where a given user has not rated an items categories beforehand.
This paper extends our prior work by first explaining how the linked data graph
can be harnessed to identify similar, previously rated semantic categories, for
a given user, and transfer these into the recommendation approach - thereby
overcoming the problem of cold-start categories - to do this we use vertex ker-
nels. To aid reader comprehension, we provide a brief overview of how we model
and track users ratings for semantic categories, and how the SemanticSV D++
model functions - for a more thorough overview please see our prior work [9].

3 Movie Recommendation Dataset and URI Alignment

For our experiments we used the MovieTweetings dataset,2 obtained from the
RecSys wiki page3 after being provided with the data by Doom et al. [3]. This
dataset was obtained by crawling Twitter for Tweets that contained Internet
Movie DataBase (IMDB) links coupled with a rating (out of 10). To enable
unbiased testing of our recommendation approach, we divided the dataset up
as follows: we ordered the ratings by their creation time and maintained the
first 80% as the training set, the next 10% for the validation set, and the final
10% as the test set. As the dataset covers a period of around 30-weeks (March
2013 to September 2013), this meant that the training set contained the first
24 weeks, with the subsequent 3 weeks segments containing the validating and
testing portions. In the following sections the training set is analysed for users
semantic taste evolution and used to train the recommendation model, we use

http://2014.eswc-conferences.org/important-dates/call-RecSys

2 This was the November 2013 version.

http://recsyswiki.com/wiki/Movietweetings

M. Rowe

the validation set for hyperparameter tuning, and the held-out test set for the
final experiments.

Movie recommendation datasets provide numeric IDs for movie items, which
users have rated, and assign metadata to these IDs: title, year, etc. As we shall
explain below, the user profiling approach models users affinity to semantic
categories, therefore we need to align the numeric IDs of movie items to their
semantic web URIs - to enable the semantic categories that the movie has been
placed within to be extracted.4. In this work we use DBPedia SKOS categories
as our semantic categories.

The URI alignment method functioned as follows: first, we used the SPARQL
query from [7] to extract all films (instances of dbpedia-owl:Film) from DBPedia which contained a year within one of their categories.5 Using the extracted
mapping between the movie URI (?movie) and title (?title) we then identified the set of candidate URIs (C) by performing fuzzy matches between a
given items title and the extracted title from DBPedia - using the normalised
reciprocal Levenshtein distance and setting the similarity threshold to 0.9. We
used fuzzy matches here due to the different forms of the movie titles and abbreviations within the dataset and linked data labels. After deriving the set
of candidate URIs, we then dereferenced each URI and looked up its year to
see if it appears within an associated category (i.e. ?movie dcterms:subject
?category). If the year of the movie item appears within a mapped category
(?category) then we identified the given semantic URI as denoting the item.
This disambiguation was needed here as multiple films can share the same title (i.e. film remakes). This approach achieved coverage (i.e. proportion of items
mapped) of 69%: this reduced coverage is explained by the recency of the movies
being reviewed and the lack of coverage of this on DBPedia at present. Table 1
presents the statistics of the dataset following URI alignment.
From this point on we use the following notations to aid comprehension: u, v
denote users, i, j denote items, r denotes a known rating value (where r  [1, 10]),
r denotes a predicted rating value, c denotes a semantic category that an item
has been mapped to, and cats(i) is a convenience function that returns the set
of semantic categories of item i.

Table 1. Statistics of the MovieTweetings dataset with the reduction from the original
dataset shown in parentheses

#Users

#Items

#Ratings

Ratings Period

14,749 (-22.5%) 7,913 (-30.8%) 86,779 (-25.9%) [28-03-2013,23-09-2013]

4 E.g. The 1979 Sci-Fi Horrow film Alien is placed within the semantic categories of
Alien (franchise) films and 1979 horror films, by the dcterms:subject predi-
cate.

5 We used a local copy of DBPedia 3.9 for our experiments:

http://wiki.dbpedia.org/Downloads39
?

?

?
4 Transferring Semantic Categories

A recommendation approach based upon semantic categories will assess how
a user has rated items (books, movies, songs) beforehand, and associate those
ratings with the items categories to form a taste profile of the user. This taste
profile, that captures the users affinity for semantic categories, will then be used
to predict how the user will rate a new item, given its semantic categories. A
problem can arise here if the items semantic categories have not been rated by
the user: we define this as the cold-start categories problem. To demonstrate the
extent of the problem, consider the plots shown in Fig. 1. In the left subfigure,
the leftmost plot shows the association between the number of reviewed and
unreviewed categories for each user when using the training dataset as background knowledge to form the profile of the user and the validation split to
be the unseen data; while the rightmost figure shows the same association but
with the training and validation splits as background data and the test split
as the unseen data. In this instance we see that the more categories a user has
rated, then the fewer categories they have missed. The right subfigure shows the
relative frequency distribution of these missed categories, indicating a heavytailed distribution where a small number of categories are missed across many
users. This indicates that cold-start categories hold additional information that
a recommendation approach should consider.

Validation




?

?

?





















































































































































































































































 

































 



















































 


























 

 

































 





























 




 




























 





 


















 




















































 



 

 



 




 










 










































 













 



































 


 



























 





























































 

 
 

 











 


 


 





 








 



  
 




 


























 
 
 














 

 


 
 





 















 
 
 








 










 
 


  


 





  


 










 




 

 
 










 






 











   




















  



 

 




 
 






 

 


 




 













 








 

 





 



  


 




 


 























  


  




 











 

 
 





 


  












 








 
















 







 
 







 










 




 














 




 

 









  








 




 
 
 



 
 





  





 



 




 

 




 







 









 

 



 







 
 


 















 

 


 



 

 
 


















  

 





 

 


 




 
 

 






 












 







 









 














 
 
 










 












 

 










 











 


 



































 








 






 






 









 





























 
 




















































 












































































































































 






































































?

?

?
s
t
a

d
e
w
e
v
e
r
n

i

 

s
t
a

d
e
w
e
v
e
r
n

i

Test


?

?

?

?

?

?








































































































 













































































































  


































 



















 

















 






 






















 




















  


















 
  




















 








  









 






 





 










 







  





 



  












 












 







 








 




 






 
 






 


 








 
 

 





 



 



 






 



 


 


 





   









  




 



 



   
  

 



 
  
 

 
 

 

  

 



 



 
 
 





 

 
   

 
  



 


 


 
 

  





 



 

 

 
 




 
     


 



 
 





  



  




 
  



 
 

   


 












 



  

  

 



 
  




 
 




 



 
 




  




 



   

 

 




  

 
 



 


 
 
 






 













 

 

 


 


   

  
 





 

 


 
 



 
 

 
 



  


 


 










  

 
 

 



 
 
  
  
 
 



 

  
 

 









 


 
  
 






 


 



 


 



 



   


 

 

 
 

  



 



 



 








 

   
 



 
 
  





 

  



 

  


  

 
   
  




 




 





 


 

  





 





 

 



 



 





  
 

  

   






  


















 
 


 




 
 





 

 

 









 



  

 
 


 


 



 

 

 






 


 




















 










































































 











 




































 









































?

?

?
Reviewed

Reviewed

)
x
(
p
?

?

?
.
?

?

?
.
?

?

?
.



Validation

Test

)
x
(
p
?

?

?
.
?

?

?
.
?

?

?
.
?

?

?
.



=26











































100 101 102 103
#Categories









=23


































100 101 102
#Categories

(a) Reviewed vs. Unreviewed Categories

(b) Distribution of Unreviewed Categories

Fig. 1. The left plot shows the association between the number of reviewed and unreviewed categories for each user, and the right plot showing the relative frequency
distribution of unreviewed categories within each split

4.1 Category Transfer Function and Vertex Kernels

To overcome the problem of cold-start categories we can include a users preferences for rated semantic categories, where such categories are similar to the

M. Rowe

unreviewed categories. This is where the utility of the semantic web becomes
evident: as the semantic categories are related to one another via SKOS relations (i.e. broader, narrower, related, etc.), we can identify semantic categories
that are similar to the unreviewed categories by how they are related within the
linked data graph - in a similar vein to prior work [8,2]:
Definition 1 (Linked Data Graph). Let G = V, E, L denote a linked data
graph, where c  V is the set of concept vertices within the graph (i.e. resources,
classes), ecd  E is an edge, or link, connecting c, d  V and (ecd)  L denotes

a label of the edge - i.e. the predicate associating c with d.

Now, let C be the set of categories that a given user has rated previously, and
D be the set of categories that a given item has been mapped to, then we define
the Category Transfer function as follows:
f (C, D) = {arg max

: d  D}
?

?

?
k

c, d

cC

(1)

The codomain of the Category Transfer function is therefore a subset of the
  C). In the above
set of categories that the user has rated beforehand (i.e. C
function the vertex kernel k computes the similarity between categories c and
d: this is often between the features vectors of the categories returned by the
mapping function :

Definition 2 (Vertex Kernel). Given graph vertices c and d from a linked

data graph G
, we define a vertex kernel (k) as a surjective function that maps
the product of two vertices attribute vectors into a real valued space, where (c)
is a convenience function that returns kernel-specific attributes to be used by the
function (i.e. an n-dimensional attribute vector of node c: (c)  Rn). Hence:

k : V  V  R
k((c), (d))  x

(2)

(3)

Given this formulation, we can vary the kernel function (k(., .)) to measure the
similarity between arbitrary categories based on the topology of the linked data
graph that surrounds them. All the kernels considered in this paper function over
two nodes feature vectors. Therefore, to derive the feature vector for a given
category node (c), we include information about the objects that c is linked to
within the linked data graph. Let <c ?p ?o> define a triple where c appears
within the subject position. We can then populate a vector (x) based on the
object concepts that c links to over 1-hop: 1  Rm - where m denotes the
dimensionality of the vector space. This can also be extended to n hops away
from c by traversing edges away from c and collecting the objects within the
traversed triples. Each element in the vector is weighted by the out-degree of
c, thereby capturing the probability of c linking to a given category. Given the
derivation of a Triple-Object Vector, using n, for each category node, we varied
the vertex kernel between the four functions shown in Table 2.
?

?

?
Table 2. Vertex kernels used to measure concept node similarities

Vertex Kernel

Cosine

Dice

Function
kn
cos(c, d) = arccos

kn
dice(c, d) =

Squared Euclidean

kn
se(c, d) =

Jensen-Shannon Divergence kn

js(c, d) =

n(c)  n(d)
?

?

?
n(c)n(d)
n(c)  n(d)

n(d)|
|

i (c) +

i=1

i (c)  n
n
?

?

?
i (d)

i (c) ln

n(c)|
|
n
 |

n(c)|

n(c)|
i=1
|

i=1
?

?

?
+

n
n(d)|
i=1
|
?

?

?
i=1

n

i (d)

1

2

i (d)

2n
i (c)
i (c)  n

n
2n
i (d)
i (c)  n
n

i (d)

1

n

i (d) ln

5 User Profiling: Semantic Categories

Semantic taste profiles describe a users preferences for semantic categories at
a given point in time, we are interested in understanding how these profiles
change. Recent work [6] assessed user-specific evolution in the context of review
platforms (e.g. BeerAdvocate and Beer Review) and found users to evolve based
on their own personal clock . If we were to segment a users lifetime (i.e. time
between first and last rating) in our recommendation dataset into discrete lifecycle periods where each period is the same width in time, then we will have
certain periods with no activity in them: as the user may go away, and then
return later. To counter this we divided users lifecycle into 5 stages where each
stage contained the same number of reviews - this was run for users with  10
ratings within the training set. Prior work has used 20 lifecycle stages [6] to
model user development, however we found this number to be too high as it dramatically reduced the number of users for whom we could mine taste evolution
information - i.e. a greater number of stages requires more ratings.
?

?

?
], t < t

To form a semantic taste profile for a given user we used the users ratings
distribution per semantic category within the allotted time window (provided
by the lifecycle stage of the user as this denotes a closed interval - i.e. s =
). We formed a discrete probability distribution for category c at
[t, t
time period s  S (where S is the set of 5 lifecycle stages) by interpolating
the users ratings within the distribution. We first defined two sets, the former
(Du,s,c
train) corresponding to the ratings by u during period/stage s for items from
category c, and the latter (Du,s
train) corresponding to ratings by u during s, hence
Du,s,c
train

train, using the following construct:
train = {(u, i, r, t) : (u, i, r, t)  Dtrain, t  s, c  cats(i)}
Du,s,c

 Du,s

(4)

We then derived the discrete probability distribution of the user rating cattrain as containing all unique

egory c favourably as follows, defining the set Cu,s
categories of items rated by u in stage s:

M. Rowe

P r(c|Du,s

train) =
?

?

?
|Du,s,c
?

?

?
train

|
?

?

?
u,s,c
train

(u,i,r,t)D

cC

u,s
train

|Du,s,c

train

|

(u,i,r,t)D

train

r

r

u,s,c

(5)

We only consider the categories that item URIs are directly mapped to; i.e.

categories connected to the URI by the dbterms:subject predicate.

5.1 Taste Evolution

We now turn to looking at the evolution of users tastes over time in order to
understand how their preferences change. Given our use of probability distributions to model the lifecycle stage specific taste profile of each user, we can apply
information theoretic measures based on information entropy. We used conditional entropy to assess the information needed to describe the taste profile of a
user at one time step (Q) using his taste profile from the previous stage (P ). A
reduction in conditional entropy indicates that the users taste profile is similar
to that of his previous stages profile, while an increase indicates the converse:

H(Q|P ) =

p(x, y) log

p(x)
p(x, y)

(6)
?

?

?
xP,
yQ

Our second measure captures the influence that users in general have on
the taste profiles of individual users - modelling user-specific (local) taste development and global development as two different processes. We used transfer
entropy to assess how the taste profile (Ps) of a user at one time step (s) has been
influenced by (his own) local profile (Ps1) and global taste profile (Qs1) at
the previous lifecycle stage (s 1). For the latter taste profile (Qs1), we formed

a global probability distribution (as above for a single user) using all users who
posted ratings within the time interval of stage s. Now, assume that we have
a random variable that describes the local categories that have been reviewed
at the current stage (Ys), a random variable of local categories at the previous
stage (Ys1). and a third random variable of global categories at the previous
stage (Xs1), we then define the transfer entropy of one lifecycle stage to another
as [10]: TXY = H(Ys|Ys1)  H(Ys|Ys1, Xs1). Using the above probability

distributions we can calculate the transfer entropy based on the joint and conditional probability distributions given the values of the random variables from
Ys, Ys1 and Xs1:

TXY =
?

?

?
p(y, y

, x) log

p(y|y

, x)
p(y|y)

(7)
?

?

?
yYs,
Ys1,
xXs1

y
?

?

?
We derived the conditional entropy and transfer entropy over the 5 lifecycle

periods in a pairwise fashion, i.e. H(P2|P1), for each user, and plotted the curve

of the mean conditional and transfer entropy in Figure 2 using the training split
- including the 95% confidence intervals. For conditional entropy, we find that
users tend to diverge in their ratings and categories over time, given the increase
in the mean curve towards later portions of the users lifecycles. While for transfer
entropy, we find that users transfer entropy increases over time, indicating that
users are less influenced by global taste preferences, and therefore the ratings of
other users.

y
p
o
r
t

n

l

a
n
o

i
t
i

d
n
o
?

?

?
.
?

?

?
.
?

?

?
.
?

?

?
.








?

?

?
Lifecycle Stages

y
p
o
r
t

n

r
e
f
s
n
a
r
?

?

?
.
?

?

?
.
?

?

?
.






?

?

?
Lifecycle Stages



(a) Conditional Entropy

(b) Transfer Entropy

Fig. 2. Taste evolution of users at the semantic category level: (i) comparing their divergence from prior semantic category ratings (2(a)); and (ii) comparing their influence
of global semantic category taste trends (2(b))

6 SemanticSVD++

In this section we present a brief overview of SemanticSV D++ [9], an extension
of Koren et al.s earlier matrix factorisation model: SV D++ [4]. The predictive
function of the model is shown in full in Eq. 8, we now explain each component.

Static Biases

Category Biases

rui =

 + bi + bu +

ibi,cats(i) + ubu,cats(i)
?

?

?
pu + |R(u)| 1
?

?

?
q
i

+
?

?

?
jR(u)
?

?

?
Personalisation Component

yj + |cats(R(u))| 1
?

?

?
zc

ccats(R(u))

(8)

M. Rowe

6.1 Static Biases

The static biases include the mean rating score () across all ratings within the
training segment; the item bias (bi), and the user bias (bu). The item bias is the
average deviation from the mean bias for the item i within the training segment,
while the user bias is the average deviation from the mean bias from the training
segments ratings by user u.

6.2 Item Biases Towards Categories

We model the biases that an item may have given the categories it has been
linked to by capturing the proportional change in category ratings - i.e. in general
over the provided training portion. Let Qs be the global taste profile (discrete
probability distribution of all categories) in stage s, and k be the number of
stages back in the training segment from which either a monotonic increase or
decrease in the probability of rating category c began from, then the global taste
development for c is defined as follows:

4

c =

4  k

Qs+1(c)  Qs(c)

s=k

Qs(c)

(9)

From this we then calculated the conditional probability of a given category
being rated highly by accounting for the change rate of rating preference for the
category as follows:
?

?

?
Prior Rating

  

Change Rate

P r(+|c) =

Q5(c) +

cQ5(c)

(10)

By averaging this over all categories for the item i we can calculate the evolv-

ing item bias from the provided training segment:

bi,cats(i) =

|cats(i)|

P r(+|c)

(11)
?

?

?
ccats(i)

6.3 User Biases Towards Categories: Vertex Kernels

To capture the development of a users preference for a category we derived
the average change rate (u
c ) over the k lifecycle periods coming before the final
lifecycle stage in the training set. The parameter k is the number of stages back
in the training segment from which either a monotonic increase or decrease in
the probability of rating category c highly began from:

u
c =

4  k

s+1(c)  P u
P u
s (c)

P u

s (c)

(12)

4

s=k

We captured the change in transfer entropy for each user over time and modelled this as a global influence factor u, based on measuring the proportional
?

?

?
change in transfer entropy starting from lifecycle period k that produced a monotonic increase or decrease in transfer entropy:
T s+1|s
QP

4

u =

4  k

s=k

 T s|s1
QP
T s|s1
QP

(13)

By combining the average change rate (u

c ) of the user highly rating a given
category c with the global influence factor (u), we then derived the conditional
probability of a user rating a given category highly as follows, where P u
5 denotes
the taste profile of the user observed for the final lifecycle stage (5):

  

Prior Rating

  

Change Rate

  

Global Influence

P r(+|c, u) =

P u

5 (c) +

u
c P u

5 (c) +

uQ5(c)

(14)

We then took the average across all categories as the bias of the user given

the categories of the item:

bu,cats(i) =

|cats(i)|
?

?

?
ccats(i)

P r(+|c, u)

(15)

Although the above summation will quantify the bias for categories linked
to item i for which the user has provided a rating beforehand, the bias will
ignore any categories for which the user has yet to provide ratings - our so-called
cold-start categories - a limitation of the approach presented in our prior work
[9]. Therefore, to counteract this we used the Category Transfer Function for a
given vertex kernel to incorporate the most similar categories that the user u
has rated before. Let C  cats(Du
train), then we define the bias of the user given
the categories of item i as follows:
?

?

?
bu,cats(i) =

k

Prior Rated Categories
?

?

?
|C  cats(i)|
?

?

?
1  k

+

c{cats(i)C}
?

?

?
|fk(C, cats(i)/C)|
?

?

?
P r(+|c, u)
?

?

?
Transferred Categories

cfk(C,cats(i)/C)
?

?

?
P r(+|c, u)

(16)

Here we have k-weighted the influence of the transferred categories on the
bias in order assess the effects of the transferred categories on recommendation
accuracy. In essence, k forms one of our hyperparameters that we optimise
when tuning the model over the validation set for a given vertex kernel (k). As
k  [0, 1] we can assess its effect: a larger k places more emphasis on known
information, while a lower k places more emphasis on transferred categories by
the given kernel (k). As the category biases are, in essence, static features we

M. Rowe

included two weights, one for each category bias, defined as i and u for the
item biases to categories and the user biases to categories respectively - these
weights are then learnt during the training phase of inducing the model.

6.4 Personalisation Component

The personalisation component of the SemanticSV D++ model builds on the
existing SV D++ model by Koren et al. [4] by including four latent factor vectors:
qi  Rf denotes the f latent factors associated with the item i; pu  Rf denotes
the f latent factors associated with the user u; yj  Rf denotes the f latent
a new vector zc  Rf which captures the latent factor vector, of f -dimensions,

factors for item j from the set of rated items by user u: R(u); and we have defined

for a given semantic category c. This latter component captures the affinity of
semantic categories with latent factors.

6.5 Model Learning

In order to learn our recommendation model (item and user biases, category
bias weights, latent factor vectors) we sought to minimise the following objective
function (including L2-regularisation of parameters):
?

?

?
min

b,,p,q

(u,i,t,r)D

(rui  rui)2 + (b2

i + b2

u + 2

i + 2

u + ||qi||2

2 + ||pu||2
2)

Stochastic Gradient Descent (SGD) [1] was used to learn the parameters by
first shuffling the order of the ratings within the training set, and then running
through the set of ratings one at a time. For each rating we calculated the
predicted rating based on the user and item with the current model parameters,

we then updated the models parameters based on the error: eui = rui  rui. We
stopped the learning procedure once we converged on stable parameter vectors
7). The update rules for our
(i.e. the difference in parameters is less than 	 = 10
model are shown in table 3. A single regularisation weight () and learning rate
() are used for all parameters in the model.

One situation that arises within the data is where the user has no prior rating
information for a user within the training segment - i.e. cold-start users. In
this instance we used the mean rating (), the item static bias (bi) and the
category bias to the item (i) given the categories of the item (bi,cats(i)): rcold
ui =
 + bi + ibi,cats(i). This is an improvement of our prior approach [9] which did
not address cold-start users.

7 Experiments

To test the efficacy of our recommendation model we used the existing SV D
and SV D++ models as baselines, and tested two varieties of SemanticSV D++:
SV D++ with Semantic Biases (SBSV D); and SemanticSV D++ (SSV D),
?

?

?
Table 3. Update rules for each component within the SemanticSV D++ model

Update Rule
Model Parameter
bi  bi + (eui  bi)
Item bias
bu  bu + (eui  bu)
User bias
Item category bias weight i  i + (eui  i)
User category bias weight u  u + (eui  u)
Item vector
?

?

?
eui(pu + |R(u)| 1

jR(u) yj
+|cats(R(u))| 1
ccats(R(u)) zc)  qi
?

?

?
User vector
User items vector

User categories vector

qi  qi + 
pu  pu + (euiqi  pu)
j  R(u) :
yj  yj + (eui|R(u)| 1
c  cats(R(u)) :
zc  zc + (eui|cats(R(u))| 1

2 qi  yj)

2 qi  zc)

which was the full model that we proposed earlier that includes latent factors
for semantic categories. For these latter two models we tested the four vertex
kernels and with the use of no kernel - to see how category transfer affected
performance. We first performed model tuning, which we explain in more detail
below, before then applying the best model, once hyperparameters had been
selected. For model tuning, each recommendation model is trained using the
training split and applied to the validation split, while for model testing each
model is trained using both the training and validation split and applied to the
test split. Our aim in both instances is to minimise the Root Mean Square Error
(RMSE) over the respective test segment.

7.1 Model Tuning

In order to select the best model for application over the held-out test seg-
ment, we tuned the hyperparameters of each of the three models. For SV D and
SV D++ we had three hyperparameter to tune: the regularisation weight (), the
learning rate () and the number of factors (f ). While for SV D++ with semantic biases, and SemanticSV D++ we have four kernels, each of which requires
four hyperparameters to be tuned: the regularisation weight (), the learning
rate (), the number of factors (f ), and the preference of transferred categories
(k).6 We varied these hyperparameters through the following settings, using an
exhaustive grid search to find the combination that produced the lowest RMSE:
1}; f = {5, 10, 20, 50, 100};
 = {10
k = {0, 0.1, . . . , 1}. This was performed by searching the hyperparameter space

8, . . . , 100};  = {10

6, . . . , 10

9, 10

7, 10

using our parallel processing cluster (11 x AMD Quad Core machines each with
16Gb RAM and 2Tb disk space) - i.e. optimising the models parameters with
SGD given the hyperparameters and reporting the error over the validation split.

6 We set n = 1 for each of the kernels therefore we are only forming feature vectors

that are 1-top away from each category.

M. Rowe

7.2 Results: Ratings Prediction Error

We now report on the results from forecasting the ratings within the test set
based on the optimised models following hyperparmater tuning. Table 4 presents
the RMSE values that we achieved. In order to assess for chance effects we performed significance testing using the Mann-Whitney test to assess for differences
in location between the SV D++ baseline model and each of the proposed models
(with different kernels) - after randomly splitting the test segment into 25-folds
and macro-averaging the RMSE.7 We find that for all models we achieved a
statistically significant reduction in RMSE over the baseline - with the significance probability levels indicated. The results also indicate that the inclusion
of transferred categories reduces prediction error over the use of no vertex ker-
nel, thereby suggesting that the use of prior rating information from related
categories boosts performance.

We find that the Cosine kernel performs best over both SV D++ with semantic
biases, and SemanticSV D++, in each case with a higher k weighting. Under
this weighting scheme, a higher k places more emphasis on the items categories
that the user has previously rated, rather than transferring in ratings to cover
the unreviewed categories. We find varying levels across the other kernels where,
aside from the JS-Divergence kernel, the optimised k places more emphasis on
using rated semantic categories that the item is aligned to.

Table 4. Root Mean Square Error (RMSE) results with each models best kernel is
highlighted in bold with the p-value of the Mann-Whitney with the baseline marked

Kernel
Model
SV D
-
SV D++
-
SBSV D++ -

Cosine
Dice
Squared-Euclidean  = 10
JS-Divergence

SSV D++ -

1.786
1.591
1.590*

Tuned Parameters
 = 0.001,  = 0.1, f = 50
 = 0.01,  = 0.05, f = 100
5,  = 0.05, f = 100
 = 10
5,  = 0.05, f = 20, k = 0.9 1.588***
 = 10
 = 0.001,  = 0.05, f = 20, k = 0.7 1.589**
5,  = 0.05, f = 20, k = 0.6 1.589**
 = 0.01,  = 0.05, f = 50, k = 0.3 1.590*
 = 0.001,  = 0.05, f = 20
1.590*
1.588***
 = 0.01,  = 0.05, f = 5, k = 0.8
 = 0.001,  = 0.05, f = 20, k = 0.9 1.590*
1.590*
4,  = 0.05, f = 10, k = 0.8 1.589**

Cosine
Dice
Squared-Euclidean  = 0.05,  = 0.05, f = 5, k = 0.7
JS-Divergence

 = 10

Significance codes: p-value < 0.001 *** 0.01 ** 0.05 * 0.1 .

8 Discussions and Future Work

The introduction of semantic level taste information allows for the evolution of a
users preferences to be captured and used within a recommendation approach.
7 N.b. all tested models significantly outperformed SV D at p < 0.001, so we do not

report the different p-values here.
?

?

?
In this paper we have considered vertex kernels that transfer previously rated
semantic categories by computing pairwise category similarity using triple-object
vectors. One future direction of work will consider how the graph-space can be
used, via traversal-based metrics, to compute the similarity between arbitrary
pairs of category nodes. For instance, measures such as random walks hitting
time and commute time, and the mixing rate of a random walk, measured over a
subgraph of the linked data graph would be one future direction of work - forming
the subgraph using the n-order egocentric network of the given category nodes.
Within this work we used a recent recommendation dataset derived from
Twitter: MovieTweetings. Unlike existing movie recommendation datasets, such
as MovieLens and NetFlix, this dataset suffers from a recency problem where
the use of existing linked data datasets, such as DBPedia, are not timely enough
to cover the items within the recommendation dataset - i.e. to provide URIs for
those movie items. That said, we chose to use this single dataset as it presented
a more recent resource to test our recommendation approach - as opposed to the
heavily-subscribed MovieLens and Netflix datasets. Future work will examine
the use of additional datasets, such as Freebase, for item to URI alignment that
are more timely and could potentially lead to increased coverage of movie items
and thus their alignment with semantic web URIs.

The objective function that we considered in this work, when optimising the
presented recommendation approach, was the minimisation of the Root Mean
Square Error. This objective has been criticised [5] as being unrealistic - i.e.
in information filtering tasks limited screen-space renders a ranked list of items
more appropriate. Therefore future work will focus on the adaptation of the approach to use a ranked-loss objective. Additionally, the optimisation procedure
followed for identifying the best hyperparameters adopted an exhaustive gridsearch approach, which is often intractable as the dimensionality of the dataset
(i.e. number of items, and number of ratings) increases. Currently being explored is the use of Gaussian Processes in conjunction with Bayesian inference
to estimate which portion of the hyperparameter space to examine next. This
approach is necessary given the anticipated increased computational complexity
that the graph-based kernels, mentioned above, will incur.

9 Conclusions

Recommender systems function by forming taste profiles of users, based on how
they have rated items beforehand, and using those profiles to predict how the
users will rate items in the future (e.g. movies, songs, products). One approach
to forming such profiles is to capture how users have rated the semantic categories of items in the past, where such categories are linked to rated items.
This approach is limited however in the presence of cold-start categories; semantic categories for which we have no prior rating information. In this paper we
proposed a solution to this problem that uses the linked data graph space to
identity similar categories that a user had previously rated, and transfer rating
information from those categories to cover the unrated ones.. To demonstrate

M. Rowe

the efficacy of this solution, we extended our prior SemanticSV D++ approach
[9] to transfer semantic category ratings using a variety of vertex kernels. This
new approach was evaluated using the MovieTweetings dataset, collected from
users movie review Tweets, against the existing SV D and SV D++ models. We
significantly outperformed these baselines with the use of no kernel, thus using
the standard SemanticSV D++ approach, while using the the four tested kernel
functions improved performance further; significantly outperforming the standard SemanticSV D++ approach. Our results indicate that the use of vertex
kernels is an effective means to leverage ratings from previously rated semantic
categories and thus overcome the cold-start categories problem.
