Providing Alternative Declarative Descriptions
for Entity Sets Using Parallel Concept Lattices

Thomas Gottron1, Ansgar Scherp2, and Stefan Scheglmann1

1 WeST  Institute for Web Science and Technologies

University of Koblenz-Landau, Koblenz, Germany

{gottron,schegi}@uni-koblenz.de

2 Kiel University, Kiel, Germany

Leibniz Information Center for Economics, Kiel, Germany

mail@ansgarscherp.net

Abstract. We propose an approach for modifying a declarative description of
a set of entities (e.g., a SPARQL query) for the purpose of finding alternative
declarative descriptions for the entities. Such a shift in representation can help to
get new insights into the data, to discover related attributes, or to find a more concise description of the entities of interest. Allowing the alternative descriptions
furthermore to be close approximations of the original entity set leads to more
flexibility in finding such insights. Our approach is based on the construction of
parallel formal concept lattices over different sets of attributes for the same en-
tities. Between the formal concepts in the parallel lattices, we define mappings
which constitute approximations of the extent of the concepts. In this paper, we
formalise the idea of two types of mappings between parallel concept lattices,
provide an implementation of these mappings and evaluate their ability to find
alternative descriptions in a scenario of several real-world RDF data sets. In this
scenario we use descriptions for entities based on RDF classes and seek for alternative representations based on properties associated with the entities.

Keywords: #eswc2014Gottron.

1 Introduction

Declarative descriptions of sets of entities are used in many scenarios. For instance,
when querying a data backend using declarative query languages or in faceted browsing
when exploring a data set. In such scenarios it is commonly assumed that a user is
aware of all the declarative descriptions he may use. Quite often, however, finding an
appropriate description itself is an exploratory task. This is the case in particular when
dealing with data which is managed in a de-centralised manner and for which there is
no fixed and pre-defined schema.

In such a case, the task of seeking a suitable declarative description for an intended
data set is difficult. As the user does not know for sure what data model and vocabulary
the data engineers have used to model their data, he might encounter difficulties to
formulate an adequate declarative description for the data he is interested in. Even when
succeeding to find an initially successful entry point for the description of the desired

V. Presutti et al. (Eds.): ESWC 2014, LNCS 8465, pp. 364379, 2014.
c Springer International Publishing Switzerland 2014
?

?

?
set of entities, users might not be able to find the best description, i. e. a brief, concise
and exhaustive description.

Existing approaches for finding alternative descriptions so far operate locally, i.e.
they iteratively add or remove single declarative constraints [9]. While providing some
support, these approaches cannot help in breaking out of a local optimum. Furthermore,
they do not provide new inspirations to the users, which enable them to think out of the
box and get new ideas for how to describe the set of data they are interested in. In
traditional document search systems such problems have been encountered already and
addressed with methods such as automatic result set expansion, relevance feedback and
query reformulation. Similar approaches have recently been investigated for semantic
web data. For example, the LOD search engine LODatio provides services to generate
related, alternative SPARQL queries [9]. Other approaches aim at finding clusters of
related entities [19] or refining graph-based queries [21].

In this paper, we present a generic method for finding alternative declarative descriptions for a given set of entities. It is based on building parallel formal concept
lattices [22] over different sets of attributes of the data at hand and providing mappings
between these lattices. These mappings allow to find alternative descriptions while preserving the set of entities as far as possible. Given the structure of formal concept lat-
tices, we restrict ourself in this paper on conjunctive forms of declarative descriptions.
However, the method is generic as the lattices can be built over arbitrary attributes of
the data. A mapping between these lattices can make use of the set of described entities
(i. e. the extent of the formal concepts) to find alternative descriptions (i. e. the intent
of the formal concepts) for close approximations of the entity set. We present two such
mappings and analyse their behaviour and quality in finding alternative descriptions of
formal concepts from different lattices.

The rest of the paper is structured as follows: We provide a high level overview of the
idea of suggesting alternative declarative descriptions using formal concept lattices in
Section 2. In Section 3 we briefly review formal concept analysis [22] which provides
the foundation for our work before we present a thorough formalisation of our idea in
Section 4. In Section 5, we implement our approach and investigate its performance for
a particular use case of finding alternative representations based on properties for sets
of entities which are initially described on the basis of RDF type classes. We review
related work in Section 6, before we conclude the paper in 7.

2 Overview to Our Approach

The idea of our approach for finding alternative declarative descriptions for a set of
entities is based on two assumptions:
1. There are different sets of attributes which can be used to describe the data. In
the context of RDF such different attributes can be the class types of entities, the
properties used to describe them, the objects they are linked to, the vocabularies
used to model them or the data sources providing information about them.

2. The user has not found an ideal declarative description in the sense that the described data set either contains too many or too few entities. Accordingly, an alternative description may extend the data set with additional entities (as long as none

T. Gottron, A. Scherp, and S. Scheglmann

Fig. 1. Our approach is based on the idea of finding declarative descriptions X or R using an
alternative set of attributes which approximates a set of entities S defined by declarative description S as close as possible

of the original entities is lost) or may restrict the data set by removing some entities
(as long as no new entities are added).

Based on these assumptions, we build parallel formal concept lattices using different
attribute sets. The obtained lattices structure the data set under different conjunctive
combinations of the available attributes and their observed combinations. For a given
node in one lattice we then define mappings which look for alternative descriptions in
other lattices while trying to preserve the set of described entities as far as possible. The
result is a set of entities which extends or restricts the original set as much as required
to find a concise declarative description using the alternative attribute set.

Figure 1 illustrates the approach. Assume, we can alternatively use attribute sets A
or B to describe entities in a set E. The two sets of attributes give rise to two worlds of
possible declarative descriptions for sets of entities. Figure 1 depicts one element S
of the world of descriptions using the attribute set A. This description corresponds to a
subset S of entities in E. The idea is to look for alternative descriptions using the set of
attributes B. Such descriptions might correspond to extensions X of S (as in the case
of X) or to reductions R of S (as in the case of S).

The advantage of using a lattice structure in the world of possible declarative descriptions is that we can easily navigate in the hierarchy of sets and their subsets and
supersets while having at the same time the descriptions of these sets readily available.
Thus, we can efficiently explore the space of possible alternative descriptions.

3 A Review of Formal Concept Analysis

Formal concept analysis has been introduced as a mathematical framework for structuring data and deriving concepts based on the objects belonging to a concept and their
common attributes [22]. Therefore, the foundation is a formal context of objects and
their attributes.
?

?

?
Definition 1 (Formal Context, Derivative). Let G and M be sets and I  G  M
a relation. The elements in G are usually interpreted as objects, the elements in M as
attributes and the reading of (g, m)  I is that object g has attribute m. Then (G, M, I)
provides a formal context.
Let A  G be a set of objects in G. Then the derivative A

of A is defined as
 := {m  M : (g, m)  I,g  A}  M . Likewise, for a subset B of attributes (i. e.

B  M ), the derivative B
 := {g  G : (g, m)  I,m  B}  G.
?

?

?
is defined as B
?

?

?
Thus, A

is the set of attributes which is common to all objects in A and B

corre-
sponds to the set of all objects which exhibit all the attributes in B. The definition of
formal concepts is based on formal contexts and the notion of derivatives.
?

?

?
Definition 2 (Formal Concept, Extent, Intent). A formal concept (A, B) is defined
to consist of a subset A  G and a subset B  M , for which A
 = A. For
such a formal concept, the set of objects belonging to the concept (so A) is the extent
and the set of attributes (so B) is the intent of the concept. The set of all formal concepts
in a formal context is denoted with B(G, M, I).

 = B and B

According to this definition, we can use the derivative operator to shift between the
two representations for a formal concept: its extent and its intent. Furthermore, we
always have two particular formal concepts: the top concept  = (G,) containing all
objects and the bottom concept  = (, M ) containing all attributes.
Definition 3 (Formal Concept Lattice). A formal concept lattice B(G, M, I) is defined as the set of all formal concepts together with the partial order  induced by the
set inclusion, i. e. (A1, B1)  (A2, B2)  A1  A2 (which is equivalent to B1  B2).

Corollary 1 (Top and Bottom Concepts in a Formal Concept Lattice). From Definition 3, we can directly deduce that C  ,C  B and   C,C  B.

Example 1. We consider a set G of ten objects which for the sake of simplicity we
simply enumerate from 1 to 10. The set M of attributes shall be {a, b, c} and the left
side in Table 1 visualises the relation I of which object has which attributes.
The tuple ({1, 4, 6, 9, 10},{a, b}) constitutes a formal concept. The derivative of
{1, 4, 6, 9, 10} is {a, b}, as the objects 1, 4, 6, 9 and 10 have the attributes a and b in
common. Inversely, the derivative of {a, b} is {1, 4, 6, 9, 10} as these are the only objects exhibiting these properties.

When constructing a formal concept lattice over the formal context from Table 1, we
obtain a structure as shown on the left hand side in Figure 2. The visualisation arranges
concepts from the top concept above to the bottom concept below and connects two
concepts with a line, if there is no other concept between them w.r.t .

4 Using Parallel Lattices to Derive Alternative Descriptions

We now present our idea of building parallel concept lattices and how to exploit mappings between theses lattices for finding alternative descriptions.

T. Gottron, A. Scherp, and S. Scheglmann

Table 1. Example of two formal contexts over two different attribute sets

Object
?

?

?
b

a
c
  


 

 



 
 
  

{a}









{a, b}









 

 
qqqqqq
{b}

rrrrr

{a, c}

MMMMMM

rrrrr
rrrr





















{a, b, c}









{c}









{b, c}




?

?

?
{x}









{x, y}





Object

x

y
z
 



 


  
  

 



 

 
ppppppp
{y}
qqqqq







{x, y, z}













qqqq

{y, z}









Fig. 2. Formal concept lattice structures based on the relations in Table 1. The concepts are represented by their intentwhich provides a better overview.

4.1 Parallel Formal Concept Lattices

Assume we have two sets M1 and M2 which can serve as attributes to describe the
objects in G. Accordingly, there are two relations I1 and I2. Then, we can construct two
parallel formal concept lattices B(G, M1, I1) and B(G, M2, I2). Note, that while the
intent of the concepts in parallel lattices is defined over two different sets of attributes,
the extent of the concepts are always based on the same set G. The idea of parallel
lattices can easily be extended to an arbitrary number of attribute sets.

Example 2 (Parallel Concept Lattice). In Table 1, we have listed a second relation I2
over the set of attributes M2 = {x, y, z}. In I2 the same objects are related to a different
set of attributes. If we construct a formal concept lattice over this relation we obtain the
lattice on the right hand side in Figure 2.

4.2 Extension and Reduction Mappings between Parallel Concept Lattices

We now introduce two mappings between parallel lattices which are defined over the
extent of the formal concepts in the lattices. Such mappings will allow for the approximation of the extent of a concept from a base lattice using the extent of a concept in an
alternative lattice. The concept in an alternative lattice provides an alternative representation via its intent composed over a different set of attributes.
?

?

?
In this section, we use B(G, M1, I1) and B(G, M2, I2) as two formal concept lattices defined over the same set G and different sets M1 and M2. B(G, M1, I1) will
serve as the base lattice for which we seek descriptions of its concepts in the alternative
lattice B(G, M2, I2). For short notation we will refer to them as Bi := B(G, Mi, Ii)
and to the set of formal concepts by Bi := B(G, Mi, Ii).

Definition 4 (Maximum Reduction). Let C1 = (A1, B1) be a formal concept in B1.
We define the set of reductions of C1 on an alternative lattice B2 as red(C1)  P(B2)
by:

red(C1) := {(A2, B2)  B2 : A1  A2}

(1)
Technically, the set red(C1) contains all formal concepts in B2 where the extent is
a subset of A1. We then define the maximum reduction set max-red(C1) of a given
concept C1 as:

max-red(C1) := {C2  red(C1) : (C

2  red(C1) : C2  C
?

?

?
2)}
?

?

?
(2)

In other words: the maximum reduction contains formal concepts in the alternative
lattice for which the extent is an as large as possible reduced (i. e. subset) approximation
of A1. This means, there is no other formal concept which is larger (under the partial
order ) and which still has an extent that is a subset of A1. If no larger reduction is
found, max-red will contain the bottom concept as trivial solution.

Theorem 1 (Perfect Approximation in max-red). For a perfect approximation the
maximum reduction set is of size 1, i. e. if B2  M2 : (A1, B2)  max-red(A1, B1),
then | max-red(A1, B1)| = 1.

Proof: Trivial, as the perfect approximation is a superset of all reductions. Thus,

there cannot be any other concept in max-red.

Definition 5 (Minimum Extension). Let C1 = (A1, B1) be a formal concept in B1.
We define the set of extensions of C1 on an alternative lattice B2 as ext(C1)P(B2)
by:

ext(C1) := {(A2, B2)  B2 : A1  A2}

(3)

We then define the minimum extension set min-ext(C1) of a given concept C1 as:

min-ext(C1) := {C2  ext(C1) : (C

2  ext(C1) : C
?

?

?
2  C2)}
?

?

?
(4)

In words again: the minimum extension set contains formal concepts in the alternative lattice for which the extent is an as small as possible extension of A1. If no smaller
extension is found, min-ext will contain the top concept as trivial solution.

Theorem 2 (Size of min-ext). There is only one concept in the minimum extension,
i. e. | min-ext(C1)| = 1 for all C1.

T. Gottron, A. Scherp, and S. Scheglmann

{a}









{a, b}







 

 
qqqqqq
{b}

rrrrr







{a, c}





MMMMMM

rrrrr
rrrr













{a, b, c}

















{c}


{b, c}





min-ext
o

f ^ W
{x}









z

{x, y}
e



_

max-red
;



 

 
ppppppp

{y}
qqqqq











{x, y, z}
}

w





qqqq










{y, z}






M S Y _ e k q

max-red

Fig. 3. max-red and min-ext mapping between two parallel formal concept lattice structures

Proof: Assume we have C2 = (A2, B2)  min-ext(C1) and  C2 = (  A2,  B2) 
min-ext(C1). Now, let C1 = (A1, B1), then we have A2   A2  A1. Thus, we would
have a formal concept C2 = (A2   A2, B2   B2) which is in ext(C1) and for which
C2  C2 and C2   C2. This is a contradiction to the assumption that C2 and  C2 are
in min-ext(C1). Thus, there cannot be to two elements in min-ext(C1).

To find alternative declarative descriptions for a given concept C1 in the base lattice
B1 we map this concept onto the sets max-red(C1) and min-ext(C1) in the alternative
lattice B2.

Example 3 (Maximum Reduction and Minimum Extension). We use once more the two
lattices depicted in Figure 2. Let Babc = B(G,{a, b, c}, I1) and Bxyz = B(G,{x, y, z}
, I2), where I1 and I2 are defined as in Table 1. We now pick the formal concept
({1, 4, 6, 9, 10},{b, c}) and compute the min-ext mapping for this concept. In a first
step we compute the set ext({1, 4, 6, 9, 10},{b, c}). The only two concepts in Bxyz
which satisfy that their extent is a superset of {1, 4, 6, 9, 10} are the top concept (G,)
and ({1, 3, 4, 5, 6, 7, 9, 10},{y}). As the concept with intent y is smaller than the top
concept, the minimum extension is:

min-ext({1, 4, 6, 9, 10},{b, c}) = {({1, 3, 4, 5, 6, 7, 9, 10},{y})}

This is visualised via a dashed arrow in Figure 3 labelled min-ext. The maximum
reduction in this case consists of the two concepts ({4, 6, 10},{x, y}) and ({1, 4, 6, 9},
{y, z}). The corresponding mapping is marked via dashed arrows labelled max-red.

5 Experiments

As exemplary use case and evaluation scenario we consider the task of approximating
a set of Linked Data entities described through RDF type statements via a description
based on properties. This task is of importance for SPARQL query recommendations
in search engines [9], for deriving programmable interfaces on RDF data or when computing recommendations which vocabularies to use when modelling Linked Data [16].

&
&
?

?

?
Furthermore, it has been observed that sets of properties can provide good descriptors
for sets of types [8]. As such the two sets of features seem promising for an approximation setting via parallel lattices.

5.1 Implementation

We used the Colibri library1 for computing formal concept lattices [11]. The library
provides a simple interface to iteratively add tuples of entities and associated attributes
in order to define a formal context. These tuples can easily be extracted from RDF
triples for our use case. To this end, it is sufficient to distinguish between triples using
rdf:type as predicate and triples using any other URI as predicate. From the rdf:type
predicate triples, we pass the subject and object, i. e. the class type URI, of the triple as
entity-attribute tuple to the library for constructing a type based concept lattice. For all
other triples, we pass the subject and the predicate of the triple as entity-attribute tuple
to a second Colibri instance for constructing the property based lattice.

To implement the max-red and min-ext mappings, we employ a traversal of the
lattices. For max-red(C), we start from the bottom concept in the alternative concept
lattice structure and iteratively seek upper neighbour concepts as long as they fulfil the
ext(C) criteria. For computing min-ext, we seek a suitable concept approximation in
a similar fashion starting from the top concept and moving downwards.

5.2 Quality Metrics for the Approximations

First of all, we consider how often it is actually possible to find a non-trivial approximation in the sense that for the best match we found a concept different from top (for
min-ext) and bottom (for max-red).

Furthermore, we use information retrieval metrics to evaluate how accurate are the
approximative sets compared to the original set of entities. Assume, we have formal
concepts C1 = (A1, B1) in the base lattice and a concept C2 = (A2, B2) in the alternative lattice. We can measure the quality of the approximation of C1 through C2 by
means of recall (r) and precision (p) on the extent of the two concepts:

r(C1, C2) =

|A1  A2|

|A1|

, p(C1, C2) =

|A1  A2|

|A2|

Example 4 (Recall and Precision). To continue our example of the mappings from Figure 3: We approximate the concept ({1, 4, 6, 9, 10},{b, c}) with a concept from the
maximum reduction: ({1, 4, 6, 9},{y, z}). In this case, we observe a recall of:

|{1, 4, 6, 9}|
|{1, 4, 6, 9, 10}| =
The precision for this approximation is p = 1.

r =
?

?

?
= 0.8

Please keep in mind that for a given concept there might be multiple maximum reduc-
tions. Therefore, we select the best recall and precision values which can be achieved

1 https://code.google.com/p/colibri-java/, accessed: 12 Jan, 2014.

T. Gottron, A. Scherp, and S. Scheglmann

for the approximative description in order to judge the quality of the best proposed de-
scription. This means, we compute for each concept the best recall and precision values
achieved over the sets of all concepts provided as maximum reductions and select the
highest score. Formally this corresponds to:

r-maxmax-red(C) =

max

Cmax-red(C)

(r(C, C

))
))

p-maxmax-red(C) =

max

Cmax-red(C)

(p(C, C

To assess the global quality, we aggregate the macro average of these values over all

concepts in the base lattice:

Avg r-maxmax-red =

Avg p-maxmax-red =

|B1|

|B1|
?

?

?
CB1
?

?

?
CB1

r-maxmax-red(C)

p-maxmax-red(C)

Likewise, we define the aggregated metrics for min-ext. The only difference is that

there is no need for identifying a maximum value, as there is only one candidate.

5.3 Data Sets
For our experiments, we have worked with the Billion Triple Challenge2 (BTC) from
2012. The BTC data set was crawled from the web using a linked data spider. Thus,
it represents a real-world data set of mixed quality from various application domains.
While the entire BTC data set is too large to be processed with a standard implementation for formal concept analysis, the data set served as a rich resource for sampling
smaller data sets. We grouped the data by the pay level domain (PLD) of the servers
from which the data has been crawled originally. This lead to a total of 840 smaller data
sets, each of which can be considered to be controlled by an individual data provider [4].
We selected 20 of these smaller data sets, which each contained approximately between
1 and 40 million triples. Processing data sets of this size with the Colibri implementation took between a few minutes and up to 12 hours to compute all max-red and
min-ext mappings for all concepts in a pair of lattices.

For these 20 data sets, we identified the number of modelled entities, computed the
base lattices using the class type definitions and the alternative lattices over the properties of the entities. Furthermore, we computed the normalised mutual information I0
between type and property definitions. This normalised mutual information is a measure of redundancy, i. e., how well one set of attributes can explain the respective other3.
Table 2 lists the data sets we finally used for our experiments, their size and the degree
of redundancy.

2 BTC 2012 data set: http://km.aifb.kit.edu/projects/btc-2012/, accessed:

12 Jan, 2014.

3 For details we refer to [8].
?

?

?
Table 2. Data sets used for evaluation and their characteristics

Data set (PLD)

Triples

Entities

1,895,817
bbc.co.uk
1,705,287
concordia.ca
7,362,172
europa.eu
1,065,538
fao.org
938,434
geovocab.org
36,969,163
identi.ca
6,170,661
kasabi.com
39,200,538
legislation.gov.uk
3,753,070
lexvo.org
7,605,348
loc.gov
1,268,368
neuinfo.org
900,892
nytimes.com
ontologycentral.com 29,447,217
44,331,144
opera.com
5,765,802
ordnancesurvey.co.uk
5,447,983
oreilly.com
1,043,818
pokepedia.fr
14,949,592
rdfize.com
1,888,030
semanticweb.org
2,813,256
soton.ac.uk

345,087
359,215
579,497
44,095
260,427
4,004,911
974,307
4,850,236
751,022
1,714,943
333,061
57,072
3,773,117
3,547,299
589,165
6,307
25,190
766,905
137,742
356,701

I0

0.717
0.799
0.973
0.954
0.989
0.972
0.997
0.897
1.000
0.764
0.587
1.000
0.879
0.867
0.845
0.894
0.659
0.902
0.817
0.690

5.4 Results and Discussion

On the base and alternative lattice structures obtained for each of the PLD data sets, we
evaluated the ability of our max-red and min-ext mappings to find alternative declarative descriptions. To this end, we iterated over all the concepts in the base lattice except
top and bottom and computed for each of them approximations using max-red and
min-ext in the alternative lattice defined over properties. For these approximations we
computed the average recall and precision and the number of concepts for which we
could not find a better match than the top or bottom concept in the property lattice.

Table 3 gives an overview of how many concepts could be approximated successfully
with a concept which was not the trivial match of top (for min-ext) or bottom (for
max-red). We can see that for some data sets it is more difficult to find approximations
than for others. The lowest performance is observed on pokepedia.fr, where only
2% of the concepts lead to a non-trivial approximation. This can be explained by two
reasons: The number of alternative concepts is much lower than the number of concepts
in the base lattice (78  7556). Accordingly, there is much less potential to find a good
match. Moreover, as can be seen when looking at the I0 value of this data set in Table 2,
the type and property sets are not correlated very strong. Conversely, high values of
I0 and a larger number of alternative concepts are a good indicator that the mapping
will find a match. Good examples for this case are identi.ca, kasabi.com and
legislation.gov.uk. Moreover we see, that see that min-ext tendentially finds
more approximations then max-red.

T. Gottron, A. Scherp, and S. Scheglmann

Table 3. Number of concepts which could be approximated by max-red and min-ext

Data set (PLD)

max-red

min-ext

Base Concepts Alternative Concepts

bbc.co.uk
concordia.ca
europa.eu
fao.org
geovocab.org
identi.ca
kasabi.com
legislation.gov.uk
lexvo.org
loc.gov
neuinfo.org
nytimes.com
ontologycentral.com
opera.com
ordnancesurvey.co.uk
oreilly.com
pokepedia.fr
rdfize.com
semanticweb.org
soton.ac.uk

(90.00%)
(38.57%)
?

?

?
(75.00%)
(45.00%)
?

?

?
(92.11%)
(63.16%)
?

?

?
(77.59%)
(39.66%)
?

?

?
(80.00%)
(64.00%)
?

?

?
(86.67%)
(93.33%)

10 (100.00%)

(80.00%)
10 (100.00%)
10 (100.00%)
6 (100.00%)
6 (100.00%)

(85.71%)

(70.00%)

(47.37%)

(47.37%)
4 (100.00%)
4 (100.00%)
(47.62%)

(47.62%)

(80.00%)

(80.00%)
?

?

?
(79.03%)

(43.55%)
(92.31%)
(80.77%)
?

?

?
(99.96%)
( 2.01%) 7553

8 (100.00%)
(98.42%)
(88.35%)

8 (100.00%)
(39.68%)
(47.57%)
?

?

?
Table 4 shows the performance for successfully finding approximated declarative
descriptions w.r.t. the precision and recall metrics. We can see that on average the values are quite high indicating a good capability of our approach for approximating the
sets of entities. However, for a few data sets the quality of the approximations is lower
than for the others. We can again point out pokepedia.fr which shows the lowest
performance under both approximation mappings. Again, the explanation is the low
correlation between the attribute sets as well as low number of alternative concepts.
Also the data sets which behave good are consistent. For the data sets mentioned above
(identi.ca, kasabi.com, and legislation.gov.uk) we get very good approximations of high quality. When comparing the two mapping methods, we see that
the values for max-red are tendentially higher than the ones for min-ext. Combining
this with the observation made above, we can say, that max-red might find less approximations but of higher quality, while min-ext finds more approximations which are of
slightly lower average quality.

Also when looking into the obtained alternative descriptions we observed a plausible behaviour. In the identi.ca data set, for example, entities of type rss:Item
and sioc:MicroblogPost were described as having the properties such as foaf:maker,
sioc:has_ discussion, rss:link and dcterms:date, which suits the semantics of the RDF
types.

To obtain deeper insights into the behaviour of our mapping functions, we compared
the quality of their approximations to other indicators. Visual inspection revealed that
the size of the extent of a concept seems to play an important role. In Figure 4, we see
?

?

?
Table 4. Results on different data sets when approximating type descriptions by properties

Data set (PLD)

max-red

min-ext

Avg. r Avg. p Avg. r Avg. p

0.686
bbc.co.uk
0.977
concordia.ca
0.943
europa.eu
0.808
fao.org
0.693
geovocab.org
0.938
identi.ca
1.000
kasabi.com
0.963
legislation.gov.uk
0.987
lexvo.org
0.688
loc.gov
0.444
neuinfo.org
1.000
nytimes.com
ontologycentral.com 0.856
1.000
opera.com
0.770
ordnancesurvey.co.uk
0.831
oreilly.com
0.294
pokepedia.fr
0.874
rdfize.com
0.465
semanticweb.org
0.708
soton.ac.uk

1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000

1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000
1.000

0.265
0.539
0.636
0.510
0.512
0.909
0.807
0.907
0.534
0.473
0.210
1.000
0.859
0.500
0.517
0.677
0.017
0.929
0.141
0.401

a scatter plot of the size of the concepts and the quality of approximation for max-red
and min-ext. The plot has been generated over the difficult pokepedia.fr data set, but
demonstrates quite nicely a behaviour which we observed also for other datasets. We
can see a general trend for max-red to achieve lower recall values for larger concepts.
This is plausible as for higher concepts it will be difficult to get a common alternative
description which does not introduce other objects. On the other hand, for min-ext we
observe an increase in precision for larger concepts. Also this behaviour is plausible: if
a larger concept is extended by a few additional elements, the overall precision remains
quite high. Vice versa adding a few elements to a small concept drastically decreases
precision.

As consequence, we propose to operate in practical applications in a mixed mode
combining both methods. For small concepts it seems more fruitful to rather use minimal extension, while using for large concepts a maximal reduction. In this way, we can
expect a good behaviour in general.

6 Related Work

Formal concept analysis emerged in the 80s from restructuring lattice theory in order
to widen for its adoption in practice [23,22]. Various efficient algorithms have been
proposed to compute formal concepts and construct a lattice from it such as [13,18].
Formal concept lattices and their creation has been successfully applied in the past in

T. Gottron, A. Scherp, and S. Scheglmann

l
l

a
c
e

 0.8

 0.6

 0.4

 0.2

 0.1

Concept Size

(a) max-red

i

i

n
o
s
c
e
r

 0.8

 0.6

 0.4

 0.2

 0.1

Concept Size

(b) min-ext

Fig. 4. Comparison of the size of a concept and the quality of the achieved approximations on the
pokepedia.fr data set

the Semantic Web such as for analysing Linked Data [10,1] or semi-automatically constructing OWL DL ontologies [2,20]. Ferre et al. [6] describe an approach to build arbitrary relations in a formal concept lattice for the purpose of navigation. They compute
a set of navigation links for a query q in order to refine the query. As concrete application scenario, they implemented a navigable UNIX file system that allows for exploring
neighbouring concepts. While this allows to find related concepts, the approach does
not aim at suggesting alternative concepts (and their attribute sets). Other works use
formal concept analysis to compute mappings between the concepts of two (or more)
ontologies [17,3,5]. In a first step, a lattice is constructed by analyzing a set of entities
such as documents w.r.t. to the concepts defined in the ontologies. Subsequently, the
lattice is used to find, e. g., class subsumption relations and class equivalence relations.
Thus, the ontology alignment approaches apply a single lattice for computing the mappings between ontologies that are provided by different independent organisations. In
contrast, we compute mappings between two lattices that are constructed over two kinds
of intents (namely the RDF properties and the RDF types) taken from a linked data set
and ontology that is curated from a single organisation and pay-level domain, respec-
tively. Although not using formal concept analysis, we like to mention the ontology
mapping work by Parundekar et al. [14,15] that computes concept mappings between
two independent sources of Linked Data by considering conjunctions and disjunctions
of restriction classes.

Finding alternative declarative descriptions for a set of entities can also be related to
query recommendation approaches. For example, Meij et al. [12] align query logs with
DBpedia concepts. They use different features for query recommendation including the
history of previous queries and suggesting concepts related to the current candidate
concept based on the number of concepts pointing to it (using the DBpedia property
dbpprop:redirect) or concepts linked from it (count of skos:subject) [12]. Hermes [21]
guides the users through the query refinement process by providing simple means such
as a travel history, navigation panels, and result list panel. However, it does not proactively provide query suggestions. Based on an initial keyword query, Than et al. [19]
propose a system that computes k clusters of RDF entities and presents them to the
users. The clusters are computed based on their matches to the keyword query and consist of m property-value pairs. The users select relevant clusters and refine the search.
?

?

?
By this, the users implicitly contribute to an improved mapping of class and property
combinations observed with entities that match the same keyword. Recommending related queries is also part of the LODatio system [9]. Here, Google-style modifications
of SPARQL queries are provided in terms of monotonic generalisations and refine-
ments, i. e., removing query patterns or adding new query patterns. Finally it is worth
mentioning that there is also work on exact query reformulation on OWL-DL ontologies [7]. In summary, many approaches for query recommendation developed so far
require the availability of a proper query log for extracting ranking information. Only a
few approaches can conduct a query recommendation without such history knowledge.
Among those, none have used formal concept analysis.

7 Conclusions

We presented an approach for finding alternative declarative descriptions of sets of entities which allow for a certain flexibility with respect to the entities belonging to the
set. Our approach is based on using parallel formal concept lattices over the same set of
objects based on different sets of descriptive attributes. We defined mappings max-red
and min-ext on a base lattice, which approximate the extent of a given formal concept in an alternative concept lattice and use the intent of the approximated concept as
alternative declarative description. We implemented the approach and performed experiments on 20 different data sets using formal concept lattices constructed over class
types and properties of entities. The experiments showed the potential of the approach
and its applicability for the presented use case.

In the future we, we plan to extend the work to implement a disjunction operator.
Finally, we want to implement the approach in an application system with end users to
perform a user evaluation of the alternative declarative descriptions. This will be done
in the context of faceted browsing or an LOD search system.

Acknowledgements. The research leading to these results has received funding from
the European Communitys Seventh Framework Programme (FP7/2007-2013), REVEAL (Grant agree number 610928).
