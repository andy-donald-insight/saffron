Dedalo: Looking for Clusters Explanations

in a Labyrinth of Linked Data

Ilaria Tiddi, Mathieu dAquin, and Enrico Motta

Knowledge Media Institute

{ilaria.tiddi,mathieu.daquin,enrico.motta}@open.ac.uk

The Open University, United Kingdom

Abstract. We present Dedalo, a framework which is able to exploit
Linked Data to generate explanations for clusters. In general, any result
of a Knowledge Discovery process, including clusters, is interpreted by
human experts who use their background knowledge to explain them.
However, for someone without such expert knowledge, those results may
be difficult to understand. Obtaining a complete and satisfactory explanation becomes a laborious and time-consuming process, involving
expertise in possibly different domains. Having said so, not only does
the Web of Data contain vast amounts of such background knowledge,
but it also natively connects those domains. While the efforts put in
the interpretation process can be reduced with the support of Linked
Data, how to automatically access the right piece of knowledge in such
a big space remains an issue. Dedalo is a framework that dynamically
traverses Linked Data to find commonalities that form explanations for
items of a cluster. We have developed different strategies (or heuristics)
to guide this traversal, reducing the time to get the best explanation.
In our experiments, we compare those strategies and demonstrate that
Dedalo finds relevant and sophisticated Linked Data explanations from
different areas.

Keywords: #eswc2014Tiddi, Linked Data, Hypothesis Generation,
Knowledge Discovery.

Introduction

When running a Knowledge Discovery (KD) process, the last step usually consists in interpreting the results (sometimes called patterns) that have been
extracted from data during the data mining step. In most real-world scenar-
ios, those results are given to experts that, with their background knowledge,
analyse and give them their own interpretation. However, if given to someone
without such expertise, the results would hardly be understandable. Also, additional knowledge from domains that the expert might not be aware of could
affect the quality of the interpretation. This makes the interpretation process
laborious, manual and time-consuming.

With that said, the Web of Data links datasets of different areas using RDF
standards, making sources of knowledge accessible (and interpretable) by ma-
chines. With the amount of information shared through Linked Data, it should

V. Presutti et al. (Eds.): ESWC 2014, LNCS 8465, pp. 333348, 2014.
c Springer International Publishing Switzerland 2014

I. Tiddi, M. dAquin, and E. Motta

therefore be possible to find common characteristics (properties) of the items
of a cluster that significantly distinguish them from others, therefore forming
hypotheses for the explanation of their grouping. In this scenario, it is clear that
the major issue consists of deciding which is the correct piece of knowledge to
look at first, in order to quickly find a plausible explanation and not get lost in
the Linked Data web.

One of our use-cases consists of coherent clusters obtained through applying
Network Partitioning to the co-authorship graph of academic researchers of the
same department. While someone familiar with such a department, given those
clusters, would explain them saying that each cluster corresponds to a group
working on similar topics, someone without such knowledge would find the clusters meaningless. One might require even more background knowledge to state
that researchers of the same cluster have worked on projects led by the same per-
son. Our assumption is that, Linked Data can be used to give such explanations.
In this scenario, the major issue is to access the right information (research topics of academics, project memberships, etc.) in the Linked Data cloud, assuming
of course that such knowledge is herein represented, to find relevant explanations
in a short time.

In this paper, we present Dedalo, a framework that, based on a subfield of
Machine Learning (Inductive Logic Programming [15]), automatically provides
explanations for clusters using Linked Data. When given a set of clusters, Dedalo
traverses Linked Data in order to find the best explanation. We used different
strategies (or heuristic scoring measures of the properties to inspect) to guide
this traversal and in the experiments section we present an evaluation of their
performance.

2 Foundations and Related Work

Hypothesis Generation. Hypothesis generation is defined as the pre-decisio-
nal process by which it is possible to formulate explanations and beliefs regarding
the occurrences observed in a specific environment  [20]. Systems presented in
the literature can be classified according to different dimensions: (i) manual
or automatic, (ii) domain-specific or domain-independent and (iii) ontology- or
Linked Data-driven. In the past, ontologies revealed their usefulness for automatically generating hypotheses; however, this has been mostly shown in specific
contexts, e.g. medical computer science or biology, where systems such as Adam,
Eira or HyBrow [7,12,19] have used OWL reasoning and first-order logic to automatically derive explanations. Hypothesis generation is also the last step of
the KD process (sometimes called data post-processing), where results obtained from the data mining step are interpreted and refined to start a new
iteration on the data. Attempts at using ontologies to produce explanations for
KD results (clusters or association rules) can be found in [1,8,11]. While [1] describes a domain-specific but automatic process, [8,11] are domain-independent
but require the experts to manually validate the generated hypotheses.

In this

context, our first

challenge

is

to produce an automatic,

domain-independent process to generate hypotheses.
?

?

?
Assumption 1. Given a set of clusters C={C0,C1, . . . ,Cn} extracted from a
set of items R={r0, ..., rm} (where Ci  R), there exists a set of explanations
Hi = {h0, ..., hj} coming from some background knowledge B for each Ci  C.

Linked Data for Hypothesis Generation. The potential of Linked Data
for accessing cross-disciplinary linked knowledge is shown in research which uses
them to generate hypotheses starting from semi-structured data (such as web tables or statistics) [16,17,24]. The importance of selecting the correct background
knowledge in order to reduce the computational efforts required by the process
emerges from that research line. In the KD field, frameworks for analysing data
mining results still select the background knowledge from Linked Data manu-
ally, such as in [2,3,18,23]. Following this research line, our second challenge is
to automatically select the background knowledge from Linked Data to produce
explanations.

Assumption 2. Given a cluster Ci  C, Linked Data contains enough connected knowledge to produce a set of explanations Hi for each Ci  C.

Automatic Hypothesis Generation. The automatic generation of hypotheses has been investigated in a field at the intersection of Machine Learning and
Logic Programming, called Inductive Logic Programming (ILP, which first appeared in [15]). ILP constructs first-order logic clausal theories (as in Logic Pro-
gramming) starting from a set of positive and negative examples (as in Machine
Learning). To derive those theories, or hypotheses, ILP applies reasoning upon
some background knowledge about the examples (both positive and negative).
For example, imagine we want to automatically learn why someone attends
ESWC: attendsESWC(X). In Table 1, the examples show who is participating
in ESWC (e+), and who is not (e
). In the background knowledge, some more
information about those examples is given. While one can see that all the examples submitted a paper to ESWC, only two of them had their paper accepted.
So, in order to go to ESWC, a person will have to have submitted a paper but
also have it accepted:



Table 1. An example of the ILP framework

Examples

e+

e+
e

attendsESWC(MathieuDAquin).

attendsESWC(VanessaLopez).

attendsESWC(EnricoMotta).

Background Knowledge

submitted(MathieuDAquin).
submitted(EnricoMotta).
submitted(VanessaLopez).

acceptedPaper(MathieuDAquin,ESWC).
acceptedPaper(VanessaLopez,ESWC).

I. Tiddi, M. dAquin, and E. Motta

goesToESWC(X) <- submitted(X)paperAccepted(X,ESWC)

Lately, ontologies have attracted the interests of several researchers in this
area, as they see the formalised knowledge of ontologies as a possible support
to build the background knowledge for ILP. A survey of systems exploiting ontologies in ILP is presented in [10]. Similarly, other works have combined Logic
Programming and ontologies in the field of Description Logic Programming [6,13]
and Onto-Relational Learning [9].

While no work (other than our first attempt reported in [22]) in the ILP
field seems so far to have taken into consideration the Linked Data potential,
we consider Linked Data a promising set of resources to help the automatic
building of the ILP background knowledge. Given our second assumption, our
third challenge is to automatically build the background knowledge of an ILP
process using Linked Data.

Assumption 3. Given a set C+ of positive examples (where C+R and C+
C) which we want to find explanations for, a set of negative examples (the
=R\C+), we can use Linked Data as background
remaining clusters of C: C
knowledge B to find explanations about C+.

However, using the full Linked Data graph as background knowledge in an
ILP process is obviously unfeasible because of the time and computational costs
it would imply, while most of this knowledge would certainly be irrelevant. It
is then necessary to detect and select only the salient information for our background knowledge. Hence, in our ILP-based framework, we have to focus on
finding a clever heuristic to guide the traversal of Linked Data and select relevant background knowledge for generating explanations of the cluster in hand.

3 Dedalos Framework

Dedalo is conceived as a graph-search process. Here, Linked Data are considered
a graph of resources and properties (respectively nodes and edges) and traversed
to collect candidate hypotheses about the items ri  R, that are used as roots of
the graph. Our intuition is that, given a subset of items ri  R, there are paths
(i.e. chains of property assertions) and an end value they have in common: this
is how we define a hypothesis. We can then assume that when items in the same
cluster Ci share a hypothesis more commonly than items outside the cluster,
then that hypothesis constitutes an explanation for Ci.
Path. A chain of RDF properties defined as p=p0  p1  ...  pn.
Hypothesis. A path p and an end value vi, defined as hi = p.vi.

As our objective is to find the best hypotheses, the graph needs to be itera-

tively traversed. A complete iteration consists of (see Fig. 1 for an overview):
?

?

?
1. URI Expansion, to resolve a Linked Data entity;
2. Path Extraction, to know which path of the graph leads to a given entity;
3. Path Ranking, to choose the best path to use in the following iteration;
4. Path Values Selection, to select the values of a path that will be further
explored;
5. Hypotheses Evaluation, to extract and rank the hypotheses found at the
current iteration.

Fig. 1. Overview of Dedalos structure

Within a new iteration, two scenarios are possible: (i) we find a better hypoth-
esis, which explains more items ri  C+ than the previous one, or (ii) no better
hypotheses are found, and therefore we still consider the current hypothesis as
the best one. In other words, by augmenting the time of the traversal, results
can only increase in quality. Therefore, Dedalo can be considered an anytime
process.

As already introduced in the previous section, it becomes clear that, being
limited in time and computational resources, a complete graph traversal is not
conceivable. Moreover, in an ample space such as Linked Data connected through
the <owl:sameAs> predicates, the number of paths to follow increases exponen-
tially. This is why we developed several heuristics in order to find the one that
was able to predict the most promising path to follow, optimising the process of
quickly finding the best hypotheses.

3.1 Algorithm

This section presents the components of Dedalo. For a better understanding of
our framework, we will use the graph given in Fig. 2 as an example.

I. Tiddi, M. dAquin, and E. Motta

Fig. 2. Graph example using a group of academic researchers. Items in rectangles are
the roots of the graph: ri  R.

1  URI Expansion. Given a resource, we resolve its URIs and collect all the
property-value pairs <pi.vi> from the RDF entity description. For instance, we resolve the resource <ou:MathieuDAquin> and extract the couples <ou:memberOf.
ou:KMI> and <ou:participatedTo.ou:Watson>.

2  Path Extraction. We detect which is the path that has led us to a given
resource (which means, detecting which depth of the graph we have reached). As
we already defined a path as a sequence of properties, p=p0  p1  ...  pn,
in the case we reached the resource <ou:EnricoMotta>, p=ou:participatedIn 
ou:ledBy. A path p has also the following properties:
||p||  the number of properties composing it, showing how deep we descended

in the graph. In the current example, ||p||=2.

roots(p)  the set of roots that share this same path. As the three root items
<ou:MathieuDAquin>, <ou:MartaSabou> and <ou:VanessaLopez> are all
followed by p, |roots(p)|=3.
vals(p)  the set of ending values the path can have. In the current exam-
ple, |vals(p)|=2 because both <ou:EnricoMotta> and <ou:HarithAlani>
are ending values of p.

Each detected p is added to the list of paths to be ranked further (add (p, paths)).

3  Path Ranking. To deepen the graph exploration to collect new hypotheses,
we need to choose the best path to follow before starting a new iteration. The
set of paths discovered at that moment are therefore ranked according to one
of the strategies we have defined (presented in the next subsection). In our

example, we will have to establish whether we want to follow p1=ou:memberOf
or p2 = ou:participatedInou:ledBy.
?

?

?
4  Paths Values Selection. Once the best path is chosen, its values vals(p)
are expanded (as in step 1), and new (longer) paths are collected (as in step 2). If
we chose to follow p2, the next values to expand will be <ou:EnricoMotta> and
<ou:HarithAlani>. By iteratively expanding those values and collecting new
paths, we deepen the search in the Linked Data graph: this process is defined as
the Linked Data traversal, and it is detailed in the function in Algorithm 1.

Algorithm 1. Linked Data traversal
function traverseLinkedData(uris)
newValues  expandURI (uri)

for uri in uris do

end for
for value in newValues do

newPath  extractPath(value)
if newPath not in paths then

add (newPath, paths)

end if

end for

end function

 step 1

 step 2

5  Hypotheses Evaluation. This step is composed of two parts. At a first
stage (called hypos(p)), given the best p, we extract the hypotheses we can derive
from it, by chaining it to its end values vals(p). In a second phase (evaluate(hi)),
each hypothesis in hypos(p) is evaluated and associated to a score. The score is
based on the number of root items ri  C+ sharing the given hypothesis hi (i.e.,
the path p chained to one of its end values vi, or p.vi). The best scored will be
the best hypothesis top(H) of the current iteration.

The score is calculated according to the hypothesis evaluation measure. The
literature includes a wide range of rule evaluation measures [5]. Since the scope
of our work is to find the best strategy to traverse Linked Data and get the
best hypotheses, we briefly explored them and decided to use the Weighted Relative Accuracy (WRacc). A more complete assessment of evaluation measures
is planned for future work. WRacc is part of the probability-based rules classification measures, commonly used to establish the statistical significance of an
explanation. It takes into account both the generality (i.e. how big is the portion
of C+ that the hypothesis is matching, compared to the whole dataset) and the
reliability (how frequent is the hypothesis in the whole dataset) of a rule. The
generality of a hypothesis hi is defined by the number of roots ri  R matched
by hi, while its reliability is defined in terms of how much hi matches elements
from the cluster C+ compared to the size of R. WRacc is therefore defined as
follows:

W Racc(hi) =

|roots(hi)|

|R|

|roots(hi)  C+|

|roots(hi)|  |C+|
|R|
?

?

?
(1)

I. Tiddi, M. dAquin, and E. Motta

The detailed algorithm is shown in Algorithm 2.

Algorithm 2. Dedalos complete algorithm

cycle = 0
R  getRoots(R)
paths  list()
traverseLinkedData(R)
while (time < limit) do
rank (paths)
topPath  top(paths)
for hypo in hypos(topPath) do

evaluate(hypo)
add(hypo, hypos)

end for
topValues  vals(topPath)
traverseLinkedData(topValues)
remove(topPath, paths)
cycle++
end while

 R = {r0, ... ,ri}
 empty list of p
 steps 1-2 on roots

 step 3

 step 5

 step 4
 step 1-2 on the path values
 new iteration

3.2 Driving the Linked Data Search: Heuristics

With a limited time and computational resources, choosing the best strategy
becomes the most important factor to obtain the hypotheses. We adapted some
existing measures, in order to define the most effective one, where effective means
a measure giving the best hypotheses score in the shortest number of cycles.

1  Path Length. Our baseline to compare the other measures is the length of
p. This measure assumes that the best paths are the closest to a root item ri.
Len counts the number of properties pi composing a p, and favours the shortest
ones.

Len(p) =

1||p||

Ex. If p1=ou:MemberOf and p2=ou:participatedInou:ledBy, then Len(p1)
> Len(p2).
2  Path Frequency. F q estimates the frequency of a path p among the dataset
R by counting how many roots ri share p. It assumes that the most important
paths are the most frequent.

(2)

(3)

F q(p) =

|roots(p)|

|R|

Ex. In Fig. 2, if p1=ou:MemberOf and p2=ou:exMemberOf, then F q(p1)>
F q(p2).
?

?

?
3  Pointwise Mutual Information. PMI is used in Information Theory
and Statistics to measure the discrepancy of a pair of random variables x and y
given their joint distribution p(x|y) and individual distributions p(x) and p(y).
In our scenario, we measure the probability that p is shared by the root items
of the considered cluster C+.

PMI(p) = log

|roots(p)  C+|
|R|  |roots(p)|

(4)
Ex. If <ou:MathieuDAquin> and <ou:MiriamFernandez> are roots of C+, while
<ou:MartaSabou> and <ou:VanessaLopez> are not, by comparing p1=ou:Mem-
berOf with p2=ou:exMemberOf, then PMI(p1)>PMI(p2) because p1 is only
shared by the items of C+.

4  Adapted TFIDF. We adapted the very well known TFIDF measure to
evaluate the relevancy of a path p (the term) in a given cluster C+, compared
to its frequency across C (the set of documents).

T F IDF (p) =

|roots(p)  C+|

|C+|

 log

|C|

|{Ci  C|roots(p)  Ci = }|

(5)

Ex. If p1=ou:MemberOf and p2 = ou:exMemberOf and <ou:MathieuDAquin>
and <ou:MiriamFernandez> are in C+, then TFIDF(p1)>TFIDF(p2) as p1 is
only shared by roots belonging to C+.

5  Delta Function. We developed a function comparing the number of values
of a p and the number of clusters in the dataset.  assumes that the best p is
the one having a different end value vi for each cluster Ci  C, so |vals(p)| = |C|.
The closer the cardinality of vals(p) is to that of C, the better the score is.

(p) =

1 + ||vals(p)|  |C||

(6)
Ex. Given |C| = 2 and p=ou:participatedInou:ledBy, if |vals(p)|=2 means
that there is a different value for each cluster in C and therefore (p) is 1. On
the other hand, with p=ou:MemberOf, (p) would be low as the only value
of p is <ou:KMi>. Similarly, if the values of p were too sparse (i.e. |vals(p)|>2)),
(p) would also be very low.

6  Entropy. Starting with Shannons theory [21], a broad variety of works
have applied the notion of entropy to graphs a networks in different disciplines
(see [4,14]for detailed surveys). Entropy (H, the Greek letter eta) is a measure
analysing the performance of communication channels. According to [14], given

a random process X ={x0, x1, ..., xn} with n possible outcomes, the amount of

uncertainty removed by equiprobable messages increases monotonically with the
number of existing messages, meaning that the bigger is n, the less information
is gained (and the more X is uncertain). Considering this, we used a na ve
?

?

?
i=1

|R|

log

|R|

(7)

I. Tiddi, M. dAquin, and E. Motta

adaptation of Shannons Entropy, in which the random process X corresponds
to p, while its n possible outcomes are the values vi  vals(p).
|roots(p.vi)|

|roots(p.vi)|

|vals(p)|
?

?

?
Ex. p1=ou:MemberOf and p2= ou:interestedIn. p1 has only one possible

outcome, so there is no information gain (also defined as surprise) when finding it in the graph. The gain of information is much higher with p2, as it has
more uncertain values and therefore H(p2) > H(p1).

7  Conditional Entropy. Similarly, Conditional Entropy measures the information gain of a random variable X given the knowledge of a random variable
Y. In this scenario, H(p|C+) measures how much information gain p brings, if we
know which items belong to C+ (i.e. how specific p and its values are in C+).

H(p|C+) =

|vals(p)|
?

?

?
i=1

|root(p.vi)  C+|

|R|

|root(p.vi)  C+|)

|root(p.vi)|

log

(8)

Ex. If <ou:MathieuDAquin>, <ou:VanessaLopez> and <ou:MartaSabou> are
ri  C+, and p1=ou:MemberOf and p2= ou:interestedIn then H(p2) > H(p1)
because Semantic Web is specific to C+ only.

4 Experiments

This section presents the different experiments we ran to evaluate the paths ranking measures, in order to find the best one. The datasets, resulting hypotheses,
and evaluations here presented are also available online1.

4.1 Datasets

As an input for Dedalos Linked Data traversal, we used three datasets, differing
in topic (authors, papers and books), size and clustering methods (see Table 2).
While the two first can be seen as test examples in a restricted and well understood area, the third represents a realistically large use case (close to 7,000
root items, leading to the traversal of millions of triples distributed in several
datasets). This demonstrates the feasibility of the approach at different scales
and using clusters that can be easily understood and evaluated. Future work will
focus on increasing the complexity of the use cases.

KMiA  The Knowledge Media Institute co-authorship. A set of researchers
have been clustered according to the papers they have written together. We

http://linkedu.eu/dedalo/
?

?

?
Table 2. Detailed description of the datasets used for the experiments

Dataset Size
KMiA small
KMiP medium 865
Huds

large

6969 11 KMeans clustering

|R|

|C| Clustering method
6 Network partitioning clustering
6 X-KMeans clustering

obtained 6 clusters that an expert validated as consisting of people working on
the same topics.

KMiP  The Knowledge Media Institute publications. Research papers from the
department have been clustered according to the words that have been used in
the abstract (TFIDF-weighted keywords). In this case, the expert explained that
papers about the same topic have been clustered together.

Huds  The books borrowing observations. Books borrowed by university students have been clustered according to the Faculty the students belong to. The
expert explained that books of the same topics have been clustered together.

4.2 Best Hypotheses

Dedalo was run to find the best hypotheses for clusters of each dataset. Some
examples of the best hypothesis top(H) automatically found at different iterations are presented in Table 3. For the purpose of the readers understanding,
the second column shows the explanation the experts have given.

In KMiA1, the explanation for h2 is that people who worked on Semantic
Web have been clustered together because they have all been part of a project
whose director was someone working himself on the SmartProducts project2
(with a WRacc score of 12.8%), which is much deeper in the graph than h1 (those
people are associated to the Semantic Web topic, WRacc 7.6%). Also, this kind
of explanations could only be given by someone knowing the department well
enough to affirm that those people worked in projects under the same director.
Typically, this is an example in which explanations are hidden and only an expert
with the right background knowledge could provide it.

Those results also demonstrate that Dedalo is agnostic to the process used to
obtain the cluster, as well as the topic of the dataset, as by changing them, we
obtained satisfactory hypotheses.

Finally, we also remark how, by using the connections between datasets in
the Linked Data cloud, we can also get better explanations. In Huds1, while
first we get explanations from the British Library dataset3 (books borrowed by
students of the Music Technology faculty are about sound recording, WRacc
0.2%), when descending the graph we reach the Library Of Congress dataset4
and find a better explanation that those borrowed books are about a topic

http://www.smartproducts-project.eu/
http://bnb.data.bl.uk/
http://id.loc.gov/authorities/subjects.html

I. Tiddi, M. dAquin, and E. Motta

Table 3. Examples of top(H) in our experiments. The full URIs are indicated in the
online results.

|C+| top(H)

C+

i
?

?

?
i
?

?

?
s
d
u

(1) Semantic

Web

people

(2) Learning

Technology

people

(1) learning

data, user,

technology

papers

(2) ontology,

knowledge,

system

papers

(1) borrowings

of Music

Technology

students

(2) borrowings

of Theatre

students

WRacc
7.6%

12.8%

7.3%

12.7%

3.8%

4.2%

6.1%

7.3%

h1=tag:taggedWithTag.ou:SemanticWeb
h2=org:hasMembershipox:hasPrincipalInvestigator
org:hasMembership.ou:SmartProducts
h1=org:hasMembership.ou:open-sensemaking-communities
h2=org:hasMembershipox:hasPrincipalInvestigator
org:hasMembership.ou:SocialLearn
h1=dc:creatororg:hasMembership.ou:StoryMakingProject
h2=dc:creatororg:hasMembershipox:hasPrincipal-
Investigatorntag:isRelatedTo.ou:LearningAnalytics

h1=dc:creator.ou:EnricoMotta

h2=dc:creatorntag:isRelatedTo.ou:SemanticWeb
h1=dc:subject.bl:SoundsRecording
h2=dc:creatorbl:hasCreateddc:subject.bl:SoundsRecording
h3=dc:creatorowl:sameAsskos:broader
skos:broaderskos:broader.lcsh:PhysicalScience
h1=dc:subject.bl:EnglishDrama
0.4%
h2=dc:creatorowl:sameAsskos:narrower.lcsh:EnsembleTheatre 0.7%
h3=dc:creatorbl:hasCreateddc:subject.bl:EnglishDrama
1.3%

0.2%
0.4%

0.5%

referenced in the LCSH dataset as a narrower topic of Physical Science (WRacc
0.5%). Although it is an intuitively easier explanation to make, it shows that
more accurate explanations can be found using Linked Data connections among
datasets and domains.

4.3 Results and Discussion

We compared the measures presented in section 3 on our examples, to see which
was the fastest at reaching the best hypotheses given a fixed number of iterations.
In Fig. 35, the X axis represents the cycles the process has gone through, and
the Y axis represents the WRacc score (in %) of the top(H) found at that given
iteration. As we explained, each improvement of the WRacc score means that
new top(H) have been found by Dedalo.

Our experiments show that Entropy outperforms the other measures. The
Entropy method reduces redundancy (i.e. following wrongs paths) and allows
Dedalo to directly detect the most promising paths to follow. The Conditional
Entropy measure, showing a very good performance as well, is the second best
performing in 5 of out 6 experiments. In Fig. 5b, Conditional Entropy even finds
better explanations of the cluster. The reason is that items of that cluster had
hypotheses specific enough when compared to the rest of the dataset.
?

?

?
%

(
 
c
c
a
r

)

%

(
 
c
c
a
r

Dedalo: Looking for Clusters Explanations in a Labyrinth of Linked Data

Len
Fq

Ent
C.Ent
?

?

?
Len
Fq

Ent
C.Ent
?

?

?
)

%

(
 
c
c
a
r
?

?

?
Cycles

Cycles

(a) KMiA1. Semantic Web people.

(b) KMiA2. Learning Analytics

people.

Fig. 3. KMiA results. Dedalo ran 20 iterations.

Len
Fq

Ent
C.Ent
?

?

?
Len
Fq

Ent
C.Ent
?

?

?
)

%

(
 
c
c
a
r
?

?

?
Cycles

Cycles

(a) KMiP1. Learning analytics topic.

(b) KMiP2. Semantic Web topic.

Fig. 4. KMiP results. Dedalo ran 10 iterations.

Len
Fq

Ent
C.Ent
?

?

?
)

%

(
 
c
c
a
r

.

.

.

.

.

.

.

Len
Fq

Ent
C.Ent
?

?

?
)

%

(
 
c
c
a
r

.

.

.

.

Cycles

Cycles

(a) Huds1. Music Technology.

(b) Huds2. Theatre.

Fig. 5. Huds results. Dedalo ran 15 iterations.

The PMI, TFIDF and  measures have the worst performances, possibly
because our use-cases were homogeneously composed and each entity, regardless which cluster it belonged to, had approximately the same properties. For

I. Tiddi, M. dAquin, and E. Motta

instance, TFIDF works relatively well in the case illustrated in Fig. 3b. In that
case, the experts explained that we were dealing with a more heterogeneous cluster of data. Len and F q are good in finding an explanation in the first cycles,
but then they plateau and take time before getting any improvement. They are
not able to follow the correct path, until it finally shows up in the queue of paths
to further analyse. Len seems to have a better performance on big clusters with
smaller numbers of properties, as shown in Fig. 5a and 5b.

The

experiments

also
showed an apparent phenomenon that the bigger the
dataset, the lower is WRacc.
This can probably be explained by the fact that it is
harder to find strong explanations in a larger population.

Len
Fq

Ent
C.Ent
?

?

?
)
.
c
e
s
(
 

e
m

i

Hud.1

Hud.2

KMiA.1

In Fig. 6, we compared
the time the measures need
to reach the same hypothe-
sis. We choose as top(H) the
last and most common hypothesis after a fixed number
of iterations (20th, 10th and
15th). In most of the exam-
ples, relatively to the scale of
the dataset, Entropy is among
the fastest measures also in time, while Conditional Entropy appears slightly
slower.

Fig. 6. Time (in seconds) the measures needed to
reach top(H). The process assumes that the data
have been cached locally, as the times to retrieve
entities from different datasets are not comparable.

Cluster

KMiP.2

KMiA.2

KMiP.1

5 Conclusions and Future Work

In this work we presented Dedalo, an ILP-inspired approach that automatically
produces explanations for clusters using Linked Data as background knowledge.
We have shown not only that hidden explanations for clusters can be extracted
from Linked Data, and that this can come from the different domains connected
in the Linked Data cloud, but also that it is important to correctly choose
the direction in the graph in order to save computational effort and time. We
developed and evaluated different measures to traverse Linked Data to access
the explanation in the shortest time. The Entropy and Conditional Entropy
measures performed best in all test cases.

In our future work, we intend to pursue three main lines: (i) exploring different hypothesis evaluation measures, other than WRacc, to detect if the best
explanation or the heuristic are affected by changing the measure; (ii) refining
the discovery of paths, using inverse properties, and of hypotheses, combining
the best hypotheses to obtain a better score; and finally (iii) deal with the issue
of the lack of connections between datasets. In fact, we are aware that Dedalo
?

?

?
works as far as Linked Data sources (and therefore, domains) are interconnected.
In another example, in which students have been clustered according to the region they come from, it turned out that in certain regions, some faculties attract
more students than others (for instance, a lot of students have enrolled in the
Health&Social Care Faculty in the East-Midlands, while the Law&Business Faculty attracts students from regions around London). While we know that there
is a possibly eco-demographic explanation to this, and that Linked Data contain
datasets to give us such information, at the current stage we cannot obtain it
because of the lack of connections between these datasets. Our future work will
be focused on this issue.
