SemCCM: Course and competence management in
Learning Management Systems using Semantic Web

Technologies

Ana Gjorgjevik
FCSE, Ss. Cyril and
Methodious University

Skopje, Macedonia

ana.gorgevic@gmail.com

Riste Stojanov
FCSE, Ss. Cyril and
Methodious University

Skopje, Macedonia

riste.stojanov@finki.ukim.mk

Dimitar Trajanov
FCSE, Ss. Cyril and
Methodious University

Skopje, Macedonia

dimitar.trajanov@finki.ukim.mk

ABSTRACT
The knowledge embedded into the Learning Management
Systems (LMSs) contains great potential, but currently is
not utilized well enough because the learning content is
mainly tailored for human understanding and not for computer processing. The courses in the LMSs cover certain set
of topics that are usually exposed through a few general keywords and areas. In this paper the SemCCM system that
utilizes the state of the art Semantic Web tools, methods and
datasets for automatic semantic annotation of LMS courses
is presented. The SemCCM system complements the LMSs
through extraction and ranking of the relevant DBpedia resources for each of the courses, and uses their Wikipedia categories for more general area determination. The extracted
DBpedia resources, together with their categories represent
the specific topics covered by the courses and provide more
accurate course retrieval. Together with the users completed courses, the extracted DBpedia resources are used
for determination of the users competencies. The SemCCM
system presents the analysis results to the end users in several different perspectives, enabling semantically enhanced
course and user search, graph based course and competence
overview, as well as user comparison.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval

Keywords
Course Competence, Learning Management System, Semantic Web, DBpedia Annotation

INTRODUCTION

1.
The Learning Management Systems (LMSs) generate large
amounts of data about all aspects of the learning process.
They track the users enrollments and completed courses,

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from Permissions@acm.org.
SEM 14, September 04 - 05 2014, Leipzig, AA, Germany
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2927-9/14/09. . . $15.00.
http://dx.doi.org/10.1145/2660517.2660535

the time they spend in the system, results in assessments
and etc. The LMSs are powerful and widely used systems,
that provide unquestionable benefits. However, it is sometimes argued that the data they contain is not utilized well
enough for achieving the flexibility and adaptability that the
learning process needs [17] [14].

The large amounts of data generated by the LMSs can be
used to profile the users better, track their progress and
interests, as well as to identify trends or learning process
areas that need improvement. The analyses of the users
completed courses and acquired knowledge could enable the
institutions to compare the users in a better way, identify the
most skilled ones or the ones with knowledge gaps. These
features are especially useful in a corporate environment
where HR related tasks, like performance management, talent management and succession planning are crucial. Although most of the LMSs have implemented reporting features for long time, their increased usage and amount of
generated data have emphasized the need for deeper and
more comprehensive data analyses. The LMS vendors have
already started including more advanced analytic and visualization features in the LMSs, and research fields like
Educational Data Mining (EDM) [16] and Learning Analytics and Knowledge (LAK) [19] have emerged. However,
the need for more advanced data modeling and analyses is
still present and the learning domain would benefit from
new or improved approaches. The improved data analyses bring benefits to the learners also, leading to transition
from the old approaches that treat the LMSs only as a platform for learning content delivery and equate all learners,
to new ones which emphasize the differences between the
learners and address their specific needs (interests, starting
level of knowledge, learning style). The improved analyses of the learners data could enable the software to autonomously recommend the most suitable learning content
for each learner.

The integration and data exchange between different LMSs
is another challenge in the learning domain. Mergers, migrations or data exchanges between these systems can be
complex tasks if they have different data models and store
the data differently. Since more and more learning content
is becoming available through different LMSs, there is an
evident need for improvement of the collaboration and data
exchange between them.


lenges through the use of Semantic Web technologies.
It
tries to show how the learning domain could benefit from
their use and what is the prospective for future development that they could open. The paper presents a semantic course and competence management system called Sem-
CCM, which provides fully automatic semantic annotation
of LMS courses by taking into consideration the learning
content associated with them. The result of the annotation process is a set of DBpedia1 resources (referred to as
course annotations through this paper) and Wikipedia categories that describe the knowledge covered in the courses.
They also represent the competences that the users obtain
after completing the courses. The implemented system complements the LMSs by exposing course and competence retrieval features, as well as through different visualizations of
the course and user data. The structured representation of
a cross-domain data and the large number of links to other
cross-domain and domain-specific datasets, especially suitable if larger focus on certain domain is needed in future,
were the main reasons why the DBpedia dataset was used
as a base of the SemCCM system.

2. RELATED WORK
Linked Data, a term closely associated with the Semantic
Web [1], represents a collection of interrelated datasets on
the Web that form a giant global graph of billions of RDF
triples, covering many different topics. Today, the interlinking hub of the Linked Data is DBpedia, a dataset automatically extracted from the Wikipedia dumps [11]. DBpedias cross-domain coverage was used from the early stages
of the LOD project2 for interlinking all datasets into single
data space, resulting into extensive amount of links between
DBpedia and other datasets [8]. The research community
has also recognized the value of Wikipedia and its representation in the Semantic Web - DBpedia in the areas of
Natural Language Processing and semantic annotation of
text. Wikipedia shares many common properties with the
lexical semantic resources (dictionaries, thesauri), but also
adds unique features, as it encodes world and domain specific
knowledge [25] [13]. The Wikipedia category system exposes
similar properties with the well-known lexical semantic resources (e.g. WordNet3) [24], so the standard algorithms
for semantic similarity or relatedness calculation could be
adapted to it [20]. DBpedia exposes Wikipedias properties
following the Semantic Web standards, complementing the
above described values with those specific to the Semantic
Web.

Although primarily focused on the Web, the Semantic Web
principles are also useful in vertical application areas, in
which they improve the software effectiveness and user ex-
periences. In the learning domain they are seen as enabler of
more advanced learning analyses and of a new type of learning systems that are more flexible and adaptable. They are
also seen as a potential solver of the integration issues, coming from the large number of competing meta-data schemas

1http://dbpedia.org
2http://www.w3.org/wiki/SweoIG/TaskForces/Community
Projects/LinkingOpenData
3http://wordnet.princeton.edu/

for learning content description (e.g. IEEE LOM4, DCMI5)
[5]. In [2] an approach for learning content indexing based
on a domain ontology is presented. The algorithm is based
on linguistic-oriented WordNet-based processing and Latent
Semantic Indexing. LSI reduced matrices are computed for
both the learning content and the ontology concepts (ex-
tended with their WordNet synonyms), later compared using
a metric based on cosine similarity. In [15] an algorithm for
semantic annotation by exploring the relationships between
the DBpedia resources is presented, resulting in extraction
of the most suitable (sub)graphs from the DBpedia graph
for each learning resource. The relevant terms are extracted
trough syntactic and semantic text analyses, followed by a
depth-limited search through the DBpedia graph for extraction of the most suitable (sub)graph. In [9], the KIM framework6 is used for semantic annotation of learning or other
type of resources (e.g.
forum and chat messages) against
ontology form the software development patterns domain.
The purpose is recommendation of relevant resources from
an LMS, diverse collaboration tools or public repositories
to the users. The Apache Stanbol7 content enhancement
service is used in [18] to produce annotation suggestions to
users. The users are offered concepts from DBpedia and a
domain specific ontology to manually annotate the learning or other online resources they find while browsing. Advanced services, like semantic search and content retrieval
are provided.

Approaches that use publicly available Web services to extract entities relevant to the learning content exist also.
The mEducator project and the Metamorphosis+ application [23] use the DBpedia Spotlight8 and Bioportal9 Web
services to semantically annotate the content descriptions
against vocabularies like DBpedia, SNOMED10, MESH11.
Semi-automatic annotation is offered through the Metamor-
phosis+ application, enabling users to manually select from
suggested annotations. The system aims at integration of
existing biomedical educational repositories at service and
data level, in order to provide better interoperability.
In
[4] the DBpedia Spotlight Web service is used to extract
mentioned DBpedia resources in learning content. Their
relevance is calculated using Apache Lucene12 and recommendations based on the content similarity are then en-
abled. In [21] an approach for enriching the learning content
meta-data with DBpedia resources is proposed. The DBpedia Spotlight Web service is used to semantically annotate
the content titles and descriptions, which are first subject
to linguistic processing for identification of the most probable terms for annotation. The contents are represented as
vectors of DBpedia resources and compared with different
similarity measures. Clustering based on the similarity is
performed at the end.
[10] presents an approach for automatic learning content categorization against the Wikipedia

4http://standards.ieee.org/findstds/standard/1484.12.1-
2002.html
5http://dublincore.org/
6https://www.ontotext.com/kim
7https://stanbol.apache.org/
8http://spotlight.dbpedia.org/
9http://bioportal.bioontology.org/
10http://www.ihtsdo.org/snomed-ct/
11http://www.nlm.nih.gov/mesh/
12http://lucene.apache.org/


ing LMS and adapts it appropriately. It is preferable that
the courses are described and packaged according to the well
established standards/specifications in the learning domain.
The Sharable Content Object Reference Model (SCORM)13
is the most widely adopted specification, which, among the
rest, defines how the learning content should be packaged for
transfer between different systems. The SCORM package
contains meta-data description of its contents and their or-
ganization, as well as the learning content itself. Other content packaging specifications exist also. The Data Retriever
module is the only module that communicates with the LMS
and it is the only one that should be adjusted to the LMS. If
the LMS courses are organized according to the well established specifications (e.g. SCORM), the adjustment effort
decreases. The Course Annotator module is composed of
three sub-modules. The Content Retriever sub-module obtains the courses learning contents, previously retrieved from
the complementing LMS. It passes them to the Text Extractor sub-module, which extracts their unstructured text. The
Entity Extractor sub-module receives the extracted text and
identifies the mentioned DBpedia resources. All identified
resources are stored separately for each course and used in
the course and user analyses shown on Figure 2. The Course
Analyzer calculates the relevance of each extracted DBpedia
resource for the course, using weighting function similar to
TF-IDF [12]. Based on the ranked DBpedia resources, for
each course the most important Wikipedia categories are
identified. The User Analyzer determines the user competencies based on users completed courses and the ranked
DBpedia resources for each course. A detailed description
of the most important aspects of the SemCCM system will
follow.

3.1 Preparation of the datasets
In the process of course annotation and categorization, few
publicly available DBpedia datasets14 are used: the titles
of the DBpedia resources, redirect and disambiguation links
among the DBpedia resources, the extended abstracts of the
resources, and the Wikipedia categories dataset. The DBpedia resources refereeing to Wikipedia administrative pages
and lists, as well as Wikipedia categories that are used for
maintenance and administration are considered irrelevant
and are removed from all datasets.

3.2 Text extraction
In the LMSs one course usually groups more than one learning resource, which can be in various formats (PDF, PPT,
DOC and etc.). The Content Retriever sub-module obtains
all course resources, previously retrieved from the LMS as
SCORM or other kind of standard package. Their unstructured text is extracted by the Text Extractor sub-module,
that utilizes the Apache Tika15 library. The extracted unstructured text is then passed to the Entity Extractor sub-
module.

3.3 Entity extraction
The Entity Extractor sub-module receives the unstructured
text from the Text Extractor and identifies all mentioned

13http://www.adlnet.gov/scorm/
14http://wiki.dbpedia.org/Downloads39
15http://tika.apache.org/

Figure 1: SemCCM entity extraction workflow

categories, using the values from some of the IEEE LOM
meta-data fields (title, description, keywords and coverage).
The relevant terms for annotation are identified with NLP
techniques, the mentioned DBpedia resources are extracted
using the DBpedia Spotlight Web service and the appropriate DBpedia categories are determined using depth-limited
search through the DBpedia graph.

In [10] [21] [23] the entity extraction process uses the metadata fields that describe the learning resources (e.g. title,
description, abstract), while the SemCCM system uses the
whole text in the learning resources. The above described
systems are mainly based around the learning resource con-
cept, while the SemCCMs functionalities are based around
the concept of LMS courses, as basic organizational unit of
knowledge that can group more than one learning resource
to achieve specific learning goal. Since the LMSs record the
completion of courses in the users profiles, we think that
the enhancement of the LMSs functionalities is much easier
when the entities relevance is summarized on a course level.
The SemCCM systems also presents the results from the
course and user analyses with different visualizations that
are not typical for the learning domain.

3. SemCCM ARCHITECTURE
Figure 1 and 2 illustrate the general architecture of the SemCCM system with regard to the main system modules and
the data flow between them. The system is envisioned as a
complement to an existing LMS. It retrieves the course and
user data from the existing LMS, performs appropriate analyses and stores the results separately from the existing system data. These results are used for implementation of functionalities that are not offered by the standard LMSs and described in details in Section 4. The Data Retriever module


in two phases.
In the first phase all possible candidates
(mentioned DBpedia resources) are identified, while in the
second the relevance score for each candidate is computed
and only the most relevant ones are retained.

The first phase starts with lookup of the potential mentions of DBpedia resources in the text and is implemented
with the General Architecture for Text Engineering (GATE)
toolkit[3]. The SemCCM system implements custom GATE
component pipeline. The processing of the unstructured
text starts with the standard language processing tasks - tokenization of the text, sentence splitting, part-of-speech tagging and noun phrase detection. The Apache OpenNLP16
plugin17 for GATE is used in this step.
It does part-of-
speech tagging of the text and emits only the noun phrases,
nouns, verbs and adjectives to the next step of the GATE
pipeline, where the Large Knowledge Base (LKB) gazetteer
GATE plugin18 takes over the processing and identifies all
mentioned DBpedia resources. It uses ontology-aware natural language processing by converting the RDF data described in Section 3.1 into gazetteer and obtaining lookup
annotations in text. In some cases, the titles of the Wikipedia
articles are associated with more than one concept19, and
there is a need for disambiguation among the concepts they
can refer to. The next step of the processing pipeline checks
whether any of the recognized DBpedia resources corresponds
to a Wikipedia disambiguation page, or there is a disambiguation page for which this DBpedia resource is a primary
topic. If this is the case, all possible meanings of the ambiguous DBpedia resources are also included as candidates,
in order to prevent loss of information.

Since the first phase of the entity extraction process aimed
at identification of all potentially mentioned DBpedia resources in the text, the result from this phase can contain
ambiguous overlapping candidates which should be filtered
and only the most relevant ones for the specific context re-
tained. Thus, when two or more candidates overlap (e.g.
DBpedia resources with titles Engineering and Software
engineering), the second phase of the entity extraction process tries to select the most relevant one for the specific
context, and discards the others. The candidate relevance
is computed as a combination of the similarity between the
course textual content and the candidate resource context20,
and the candidate correlation with the other candidate DBpedia resources.
In each group of overlapping candidates,
Gx, the candidate with the highest score is selected. The algorithm implemented in this step adjusts the voting scheme
from [6] to our needs. In eq. 1 the vote that candidate a
receives from the other groups of candidates Gx is shown.


xGx

vote(Gx, a) =

cor(a, x)  sim(x, C)

|Gx|

, a / Gx

(1)

16https://opennlp.apache.org/
17http://gate.ac.uk/gate/doc/plugins.html#OpenNLP
18http://gate.ac.uk/sale/tao/splitch13.html#x18-
35100013.9
19http://en.wikipedia.org/wiki/Wikipedia:Disambiguation
20The dbpedia-owl:abstract property value is considered as a
context of the resource

Figure 2: SemCCM course/user analyses workflow

Here, Gx represents group of overlapping candidates (or one
candidate if it is unambiguous), sim(x, C) is the similarity
score of the candidate x with respect to the course content C,
|Gx| is the number of candidates in the group and cor(a, x) is
the correlation between the candidates a and x. The Apache
Lucene library is used to calculate the similarity sim(x, C)
as cosine distance between the context of x and course content C, favoring candidates that share more words with the
course content. The correlation between two candidates a
and b, cor(a, b), is shown in eq. 2, where categories(a) is the
set of Wikipedia categories which the resource a is member
of. These equations favor the candidates that are more similar with the course content and more related to the other
candidates, through sim(x, C) and cor(a, b) respectively.

|categories(a) categories(b)|
|categories(a) categories(b)|

cor(a, b) =

(2)

Candidates (including the unambiguous ones) that did not
receive vote from any other group are removed, since they
are considered unrelated to the context their mention was
identified in. Based on the score produced in this step, for
each group, the candidate with the highest score is selected
and all other candidates are removed. The extracted DBpedia resources are stored for each course separately and used
for further course/user analyses.

3.4 Course and user analyses
Figure 2 illustrates the course and user analyses workflow.
The Course Analyzer module calculates the relevance of each
extracted DBpedia resource for the courses through the Relevance Calculator sub-module. The calculation of the relevance score is based on variation of the term frequency -
inverse document frequency (TF-IDF)[12] scoring formula.
Here, the terms are replaced with the extracted DBpedia
resources, and the documents are replaced with the courses.
The relevance score of a DBpedia resource r for a course c is
shown in eq. 3, where rft,c is the occurrence frequency of the
resource r in course contents c, N is the number of courses
in the analyzed corpus and rft is the number of courses in
which the resource r appears. This weighting formula favors
the resources that are mentioned many times in one course,
and rarely in the others. The ranked DBpedia resources


through this paper.

rscore(r, c) = rfr,c  log(

rft

(3)

In the final step, the Category Calculator sub-module utilizes the categories of the course annotations21 to determine
the more general areas covered by the courses. Similarly to
the course annotations, the categories are also ranked. Since
one DBpedia resource may be categorized in more than one
category, its score is evenly distributed through all cate-
gories. This is shown in eq. 4, where cscore(cat, c) is the
score of the category cat with respect to the course c, ARcat,c
is the set of the course annotations that belong to that cate-
gory, and |ARcat,c| is the number of these annotations. The
rscore(r, c) is the value calculated in eq. 3.

cscore(cat, c) =


rARcat,c

rscore(r, c)
|ARcat,c|

(4)

The User Analyzer module utilizes the course annotations
and users completed courses, to determine the competencies that users posses. In the SemCCM system a user competency is a DBpedia resource that is relevant to a course
that some user completed. This means that while taking
the course, this user got familiar with that concept (DBpe-
dia resource) and knows about it to the extent to which the
concept was treated in the course. The more relevant the
DBpedia resource is for the course, the greater the users
knowledge/competency for that resource becomes once he
completes the course.

4. SemCCM FUNCTIONAL DESCRIPTION
This section describes the functionalities provided by the
Web module that is part of the SemCCM system. This
module represents a showcase on how the usage of Semantic
Web technologies can enrich the LMSs data and improve its
presentation to the end users. It is composed of two main
sub-modules, Course search and retrieval and User Competence search and retrieval, and its functionalities are based
on the previously extracted course annotations, categories
and user competencies.

4.1 Course search and retrieval
The goal of this sub-module is provision of semantically enhanced course search and retrieval to the end users, as well
as visual presentation of the course annotations and their re-
latedness. The semantic annotation of the courses moves the
search from a term based to a concept based level, overcoming some of the common problems in the classical Information Retrieval (synonyms and ambiguous terms). The users
are allowed to select the desired DBpedia resource with an
auto completion feature and then search for courses annotated with it. The sub-module handles the transitive redirections between the resources22 and presents a ranked list
21The Wikipedia page categories are used here
22It traverses the dbpedia-owl:wikiPageRedirects relation until the final DBpedia resource is reached

Figure 4: Courses similar with the Introduction to
Algorithms course

Figure 5: User competences display

of courses with respect to the queried DBpedia resource.
The users can then navigate through the resulting courses
and explore their annotations/categories in a graph-based
interface, as shown in Figure 3. This interface provides simple overview of the topics covered in the course and the way
they are connected, enabling the users to easily determine if
the course covers their interests. As shown in Figure 3, the
graph nodes have different color and size, depending on their
relevance, and they are connected through the grey nodes
that represent their Wikipedia categories. From Figure 3
it can be noticed that there are several isolated sub-graphs
which represent different topical areas covered in the course.

The Figure 4 illustrates the most similar courses to the
course Introduction to Algorithms, ranked by their similarity score. The similarity score between two courses is
calculated as cosine distance between the courses vectors
composed of the annotations relevance.

4.2 User Competence search and retrieval
The aim of this sub-module is presentation of the users acquired knowledge in a way different than the standard ones,
which offer a tabular view of the users completed courses


only. As shown in Figure 5, the users competencies (cal-
culated as described in section 3.4) are displayed in a bar
chart and in a graph-based interface. The bar chart simply ranks the users competences, whereas the graph-based
interface emphasizes the relationships between the competences (through the Wikipedia categories they belong to),
showing the areas the user has knowledge in. Clicking on
each bar or node presents the courses which the user obtained that competence from.

It is also possible to search for users that have knowledge
in specific area and receive a ranked list. Two users can be
compared with regard to their competences and a bar chart
based comparison is offered. This feature is particularly useful when some of the users has lack of some competence and
identification of the relevant courses that it can be obtained
from is needed. The system offers convenient comparison of
the courses which the two users obtained some competence
from.

5. DISCUSSION
The SemCCM system currently works with 150 courses obtained from MIT OpenCourseWare23 and processed as described in section 3. The distribution of the courses with regard to the MIT OpenCourseWare topics is given in the Table 1, and some courses belong in more than one topic. Both,
undergraduate and graduate courses with different sizes were
considered and for the purpose of the semantic annotation
the lecture notes associated with the courses were used. All
MIT OpenCourseWare course packages contain a set of free

Table 1: Courses by topic

Engineering

Social Science

Science
Business


Humanities

Fine Arts

Mathematics

Energy
Teaching and Education

text keywords that describe the course content, which were
used for manual evaluation of the SemCCMs results.

As discussed in [7], the recruitment process is crucial for the
companies and the candidate selection often includes matching of the competences required for some working position
with the candidates skills. Additionally, [22] emphasizes the
need for continuous training and development of the employees in order to have a workforce with an appropriate skills
and competences as a logical end result. The SemCCM system is designed to address these exact needs by helping the
candidates and the management in locating the appropriate
courses that correspond to the required competences, as well
as by ranking the employees or candidates based on their
competences obtained from the acquired courses. Following these premises, the questions that the SemCCM system
answers are described next in this chapter.

23http://ocw.mit.edu

Which courses cover the topic Depth-First Search?


user using the auto completion option, as described is section 4.1. The courses that the SemCCM system returns as
a result to this question are: Introduction to Algorithms,
Computer Algorithms in System Engineering and Artificial
Intelligence. On the other hand, only the course Introduction to Algorithms is returned as a result from the search
through the courses free text keywords. This SemCCM feature is of a crucial importance when the user wants to obtain
the courses which cover more specific concepts that are not
provided by the manual keyword annotation.
In contrast
to the classical full-text search, the system uses the scores
from eq. 3, which take into account the semantic annotations relevance among the whole set of courses, instead of
the word relevance through the documents. Additionally,
even in the cases when the system extracts bad annotation,
the graph visualization of the course annotations (shown in
Figure 3) can be used to correct this mistake, which means
that if the annotation is not connected to any of the other
course annotations, it can be ignored (which cannot be accomplished with the classical full-text search). This feature
gives visual overview of the particular course areas, which
are represented as connected sub-graphs. The next question
addressed by SemCCM is: Which courses are similar
to some course? The result for the course Introduction
to Algorithms is shown in Figure 4. This feature displays
ranked list of courses that share most of the annotations with
the selected course, and thus provides the users with alter-
natives. These features are targeting the candidates that
need to fill their knowledge gaps in order to be eligible for
a desired working position, and also helps the management
to better target courses that are suitable for their employees
who should be competent for given projects. It also gives
the training administrators and managers a global overview
of the related courses that exist in an LMS.

The SemCCM system also provides user search and ranking
features based on users completed courses. This is particularly useful in the process of recruitment[7]. One of the
most useful features in this process is the answer of the
question: Which candidates have some competence?
Every DBpedia resource that appears as course annotation
is considered a competence that is offered by the course and
which is acquired by the users that complete that course.
Thus, the companies can search and retrieve candidates or
employees based on specific competences, not just the general fields, and once they navigate to their profile page, they
can see all their competences, ranked as shown in Figure
5. SemCCM also shows which courses the users obtained
that competence from. The graph visualization of the users
competences, which is similar to the one shown in Figure
3, provides an overview of the users areas of competence,
and identification of the potential knowledge gaps. When
there is more than one user that has some competence, the
SemCCM system provides user comparison that is crucial in
the process of employee selection.

As mentioned, the courses from MIT OpenCoursWare are
originally annotated with free text keywords of arbitrary
number, but they are not annotated with resources from
DBpedia or any other formal vocabulary. This fact introduced an issue in the evaluation process, since there was a
lack of a gold standard annotations for comparison. This

Table 2: Annotations and keywords for course The
Law of Mergers and Acquisitions, Spring 2003

Keywords:
employment, non-US companies, employment-related
issues, legal implications of key roles and deal
structures, legal concerns of financial sponsors,
publicly-held company, deals involving distressed
and hi-tech companies, antitrust concerns,
allegations of misconduct
Extracted resources
dbpedia:Mergers and acquisitions
dbpedia:Statutory corporation
dbpedia:Shareholder
dbpedia:Stock certificate
dbpedia:Creditor
dbpedia:Bankruptcy
dbpedia:Subsidiary
dbpedia:Asset
dbpedia:Business judgment rule
dbpedia:Stock market

meant that the use of the standard Information Retrieval
measures (precision, recall and F-measure) was inapplicable for the SemCCMs evaluation. This kind of quantitative
evaluation requires mapping of the free text keywords to
DBpedia resources and it is planned as a part of our future
work. However, as described earlier, the graph visualization
of the courses annotations and the users acquired competences provides enough information to the end users, so they
can notice and reject the SemCCMs mistakes.

According to our manual evaluation, the SemCCM system
retrieves more accurate annotations for the courses that contain larger number of learning resources processed by the
system. An example is presented in Figure 3, where (in our
opinion) the displayed top 50 annotations are relevant for the
course. For the courses with fewer learning resources and
less textual content, the relevant annotations are present,
but the ranking is not always the most optimal one. Table 2
shows the 10 highest ranking annotations for a course where
no match between these 10 annotations and its free text
keywords exists. The course The Law of Mergers and Acquisitions belongs to the area of Legal Studies/Finances/In-
dustrial relations and HR management, and some of the keywords match the lower ranking annotations, which are not
presented here. In our opinion, most of the annotations provided by SemCCM are in the correct context again, but the
ranking might not be the most optimal one. The analysis
led to conclusion that this could be due to the small number of lecture notes this course contains and their small size.
The ranking in the SemCCM system is based on modified
TF-IDF, where the frequency of the annotations appearance
in the course documents is the main component.

6. CONCLUSION
The SemCCM system, presented in this paper, utilizes the
state of the art tools and methods to enrich the knowledge
embedded in the Learning Management Systems. The integration with standards like SCORM provides independence
from the complementing LMS specifics and course description methods.


liable to subjectivity, and in most cases shallow without coverage of the more specific course topics. The Semantic Web
technologies are the main enabler of the SemCCM system,
which offers profound automatic identification of the topics
covered in LMS courses and representation of user competences through use of the knowledge available in DBpedia.
The course annotations enable the SemCCM system to provide course and user competence retrieval and overview, features that can significantly simplify the process of employee
recruitment and competence improvement.

The conclusion from the manual evaluation and the supplementary analyses is that most of the annotations agree with
the courses context, especially noticeable when DBpedia resources with ambiguous titles are extracted from the courses
content. However, this evaluation is subjective and limited
to our understanding of the courses content. Even with these
manual and subjective analyses, we found that our process
of DBpedia resource extraction identifies most of the relevant course topics, but their scores and ranking should be
additionally validated and most probably improved. As part
of our future work, we plan to do quantitative evaluation of
the obtained annotations and the ranking algorithm.
