Web Semantics: Science, Services and Agents on the World Wide Web 26 (2014) 3657

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

journal homepage: www.elsevier.com/locate/websem

Linked knowledge sources for topic classification of microposts:
A semantic graph-based approach
Andrea Varga a,, Amparo Elizabeth Cano Basave b, Matthew Rowe c, Fabio Ciravegna a,
Yulan He d
a Organisations, Information and Knowledge Group, The University of Sheffield, UK
b Knowledge Media Institute, The Open University, UK
c School of Computing and Communications, Lancaster University, UK
d School of Engineering and Applied Science, Aston University, UK

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 28 June 2013
Received in revised form
20 March 2014
Accepted 7 April 2014
Available online 13 April 2014

Keywords:
Linked knowledge sources
Semantic concept graphs
Topic classification

Short text messages a.k.a Microposts (e.g. Tweets) have proven to be an effective channel for revealing
information about trends and events, ranging from those related to Disaster (e.g. hurricane Sandy) to those
related to Violence (e.g. Egyptian revolution). Being informed about such events as they occur could be
extremely important to authorities and emergency professionals by allowing such parties to immediately
respond.

In this work we study the problem of topic classification (TC) of Microposts, which aims to automatically classify short messages based on the subject(s) discussed in them. The accurate TC of Microposts
however is a challenging task since the limited number of tokens in a post often implies a lack of sufficient
contextual information.

In order to provide contextual information to Microposts, we present and evaluate several graph
structures surrounding concepts present in linked knowledge sources (KSs). Traditional TC techniques
enrich the content of Microposts with features extracted only from the Microposts content. In contrast
our approach relies on the generation of different weighted semantic meta-graphs extracted from linked
KSs. We introduce a new semantic graph, called category meta-graph. This novel meta-graph provides
a more fine grained categorisation of concepts providing a set of novel semantic features. Our findings
show that such category meta-graph features effectively improve the performance of a topic classifier of
Microposts.

Furthermore our goal is also to understand which semantic feature contributes to the performance of
a topic classifier. For this reason we propose an approach for automatic estimation of accuracy loss of a
topic classifier on new, unseen Microposts. We introduce and evaluate novel topic similarity measures,
which capture the similarity between the KS documents and Microposts at a conceptual level, considering
the enriched representation of these documents.

Extensive evaluation in the context of Emergency Response (ER) and Violence Detection (VD) revealed
that our approach outperforms previous approaches using single KS without linked data and Twitter
data only up to 31.4% in terms of F1 measure. Our main findings indicate that the new category graph
contains useful information for TC and achieves comparable results to previously used semantic graphs.
Furthermore our results also indicate that the accuracy of a topic classifier can be accurately predicted
using the enhanced text representation, outperforming previous approaches considering content-based
similarity measures.

 2014 Elsevier B.V. All rights reserved.

 Corresponding author. Tel.: +44 07508989022.

E-mail address: varga.andy@gmail.com (A. Varga).

http://dx.doi.org/10.1016/j.websem.2014.04.001
1570-8268/ 2014 Elsevier B.V. All rights reserved.

1. Introduction

Social media posts, and in particular Microposts collected from
Twitter, have been found to contain useful information for many
applications including disaster detection [1], seasonal mood level
changes [2], tracking influenza rates [3], box-office revenue forecast [4], political elections [5], stock market prediction [6], etc.

For instance, during the widespread protest in Egypt in 2013, Microposts were found to provide early warning signals of violent
events; such events were reported much faster than traditional
media sources.1 The real-time identification of such events could
be extremely important to authorities and emergency professionals by allowing such parties to immediately respond.

However, the classification of such messages poses unique
challenges, due to the special characteristics of the messages (i)
the limited length of Microposts (up to 140 characters), restricting
the contextual information necessary to effectively understand
and classify them; (ii) the noisy lexical nature of Microposts,
where new terminology and jargon emerges as different events are
discussed; (iii) the large topical coverage of Micropost.

Existing approaches have addressed these challenges by
proposing the use of social knowledge sources (KSs). These sources
provide additional textual data on a growing number of topics,
which can alleviate the sparsity of Micropostss content [712].
Furthermore these topic classifiers typically enhance the lexical
(e.g. bag-of-words (BoW)) representation of text by incorporating
additional contextual information about Microposts in the form of
semantic (bag-of-entities (BoE)) features extracted from the content of Microposts only. Unlike these approaches, recently in [13]
we proposed a TC framework which generates contextual information from graph structures surrounding concepts in multiple
complementary linked KSs. Among the several useful graph structures defined in KSs [8], such as the resource meta-graph providing
course grained classification of concepts by their type, or the category meta-graph which groups similar concepts together by their
topic, our original framework exploited the resource meta-graph
for context generation. Moreover, in [14] we also studied different content-based topic similarity (also called domain similarity
or dataset similarity [15]) measures, which quantify the similarity
between the KS data and Twitter data, serving as a proxy for the
performance of a topic classifier on Twitter data. These contentbased features correspond to simple BoW and BoE features derived
from the Micropost content only.

Unfortunately, current approaches still present some limita-
tions. The majority of the approaches model the entities using
very generic concept types. For example, in the case of the entity
Obama, the generic class Person is considered. When detecting Microposts related to the war topic, however, a more fine grained
categorisation of this entity, such as President of United States
(Presidents_of_the_United_States), could be more useful.

Further, the use of fine grained information in KSs provided
by the category meta-graph has been exploited for many other
problems, such as document classification [8], entity disambiguation [16], and semantic relatedness [17], and shown that it carries rich semantic information. However, to date no study has been
conducted to investigate the usefulness of this category meta-graph
graph structure for TC.

In this paper we thus present an extension of our TC framework [13], which exploits this new semantic graph, called category
meta-graph, providing a more fine grained classification of concepts based on their topics. We introduce a set of novel semantic
features derived from this graph, and present a comparative evaluation against those obtained from the resource meta-graph.

Furthermore our goal is also to understand which semantic
feature contributes to the performance of a topic classifier. For
this reason we propose an approach for automatic estimation
of accuracy loss of a topic classifier. We introduce novel topic
similarity measures, which in contrast to our previous contentbased similarity measures [14], aim to measure the similarity

1 http://irevolution.net/2013/07/07/twitter-political-polarization-egypt/.

between the KS documents and Microposts at a conceptual level,
considering the enriched representation of these documents.

To evaluate the usefulness of exploiting this new category metagraph for both TC and topic similarity, we present an extensive
analyses of our extended framework using a ground truth data
in the Emergency Response (ER) and Violence Detection (VD)
domains.
The main research questions we investigate are the following:
 How does the performance of a topic classifier vary using different
concept graphs? Which concept graph provides the most useful
semantic features for TC of Microposts?
 Are there differences in the roles (generalisation patterns) of the
concept graphs in the different TC scenarios?
 Can we predict the performance of a topic classifier? Which topic
similarity measure provides best estimate on the performance of a
topic classifier?

1.1. Contributions

To address the above research questions, we present an
approach which facilitates the exploitation of multiple semantic
meta-graphs from linked KSs for TC of Microposts. In particular, in
contrast to our previous work [13], in this paper our main focus
is to understand the differences between the different semantic
concept graphs, and present a comparative evaluation of these
graphs at different stages of our three-stage approach. The main
stages of our approach can be summarised as follows: (i) context
modelling; (ii) topic classification and (iii) topic similarity analysis.

The context modelling stage enriches the text using different
concept abstraction techniques. For this reason we extract various
semantic features about entities appearing in the text from two
distinct concept graphs built from linked KSs.

The second stage topic classification involves the creation of
statistical TC models, which incorporate various semantic features
obtained in the context modelling step. In this stage we investigate
two different scenarios: the Twitter only scenario in which we
build a topic classifier on Twitter data only, and the cross-source TC
case where we make use of the information from multiple linked
KSs. This allows us to analyse which concept graph provides better
semantic features for TC, and also whether the role of the semantic
features differ according to the TC scenarios. In particular, we
investigate whether the same semantic features which account for
modelling the specificity of the topic in the Twitter only scenario,
serve the same role in the cross-source scenarios.

The final stage topic similarity analysis uses the enhanced
representation of the documents (in both the KSs and Twitter)
following context modelling to provide an estimate on the
performance of the topic classifier on new, unseen Micropost data.
This allows us to analyse which semantic concept graph is better
suited to measure the topic similarity between KS documents and
Microposts for TC. In this stage, we also investigate whether this
novel representation of the documents provides a better measure
for topic similarity than our previous content-based statistical
measures [14].
The main contributions of this paper are four fold:
 We introduce a novel set of semantic features derived from the
category meta-graph of KSs;
 We present a systematic comparison of different semantic
concept graphs for TC of Microposts;
 We present an analysis of the different roles of semantic
concept graphs on ground truth data in the VD and ER domains;
 We propose a novel set of topic similarity measures for
estimating the performance of a topic classifier.

A. Varga et al. / Web Semantics: Science, Services and Agents on the World Wide Web 26 (2014) 3657

Table 1
Statistics about dbOwl, dbCat, yago, fbOnt KS ontologies.

Semantic features

Resource
Property (P)
Class (Cls)
Category (Cat)

DBpedia (dbKS)
dbCat
dbOwl
2.35  106

yago
447  106

Freebase (fbKS)
fbOnt
3.6  106

The remainder of this paper is structured as follows: Section 2
provides an overview of the employed linked KSs, and explains
their relevance for TC of Microposts; Section 3 presents the related
work on TC. Section 4 then provides an overview of the original TC
framework employed in this work, and describes its extension for
the newly introduced category meta-graph. Section 5 continues by
introducing a novel set of topic similarity measures. Next, Section 6
presents the gold standard datasets used in our experiments, and
Section 7 describes the baseline models employed. After that, in
Section 8 a comparative evaluation of the extended TC framework
and new topic similarity measures are discussed. This is followed
by a discussion on the shortcomings of our approach and possible
future extensions in Section 9. Finally, conclusions are drawn in
Section 10.

2. An overview of DBpedia and freebase linked knowledge
sources

The Linked Open Data (LOD) cloud2 consists of a large number
of interlinked KSs, covering a range of different topics. Among
these KSs, DBpedia3 [18] and Freebase4 [19] constitute some of
the largest datasets built in a collaborative manner. The main
advantages of these KSs are: (i) they provide plentiful amount
of data on a growing number of topics, (ii) they contain factual
information about a large number of entities, covering these topics.
This semantic information is also structured according to their own
KS ontology.

Exploiting these KSs can thus be useful to support topic classification of Microposts, as a KSs data can be used to provide
additional labelled data to train supervised topic classifiers of
Microposts. For example, for the topic violence we can consider DBpedias violence category (i.e. http://dbpedia.org/page/Category:
Violence). This category provides a large number of resources associated with it (e.g. http://dbpedia.org/page/Counter-terrorism).
Each of such resources include a short description of its content (the abstract). This data can then be used for enhancing the
lexical feature representation for the violence topic. Further, the
rich semantic information within a KS ontology can be used to
generate violence-related features at the graph level. The same
approach can be described for the representation of an entity
(e.g. http://dbpedia.org/page/Barack_Obama). An entitys representation extracted from these KSs can therefore provide additional contextual information. This information can be used to
enhance a Micropost representation mentioning the entity.

To provide context for our motivating example, we first present
statistics of the KSs used in this paper (i.e. DBpedia and Freebase),
summarised in Table 1.

The first KS, DBpedia (dbKS), is derived from Wikipedia.5 In DBpedia each resource is harvested from a Wikipedia article which

2 http://lod-cloud.net.
3 DBpedia, http://dbpedia.org.
4 Freebase, http://frebase.org.
5 Wikipedia, http://wikipedia.org.

is semantically structured into a set of DBpedia (dbOwl)6 and
YAGO2 (yago)7 ontologies, with the provision of links to external
knowledge sources such as Freebase, OpenCyc,8 and UMBEL.9 The
Wikipedia articles are furthermore grouped into categories, which
are represented using the SKOS vocabulary.10 The DBpedia dump
version 3.8 classifies 2.35 million resources into DBpedias ontology classes (dbOwl). These classes comprises 359 distinct classes,
and 740,000 SKOS categories (dbCat), which form a subsumption
hierarchy and are described by 1820 different properties. Con-
versely, the yago ontology [20] is a much bigger and fine grained
ontology. It contains over 447 million facts about 9.8 million entities which are classified into 365,372 classes, and 104 manually
defined properties.

In contrast to DBpedia, Freebase (fbKS) is a large online knowledge base which users can edit in a similar manner to Wikipedia. In
Freebase, resources are also harvested from multiple sources such
as Wikipedia, ChefMoz, NNDB and MusicBrainz11 along with data
individually contributed by users. These resources are semantically
structured into Freebases own ontology (fbOnt), which consists of
1450 classes and more than 7000 unique properties.

In summary, these different KS ontologies (i.e. dbOwl, yago,
fbOnt) provide a rich source of semantic information about entities
in many domains and topics. Further, in these KSs each entity
resource is related to different ontological classes or concepts
which can provide additional contextual information for that
resource. This contextual information allows us to exploit various
semantic structures of these resources.

Consider the two Micropost examples displayed in Fig. 1. In
these examples, the entity Obama is mentioned in two different
contexts, each of them corresponding to different roles this entity
plays (for e.g. president in Microposts (1); and husband in Micropost
(2)). In such cases, the role of this entity is defined by the contextual
information provided on the content of each Microposts.

In this paper, our main goal is to exploit this semantic contextual information about entities. In particular, we study different
semantic graph structures defined in linked KSs, and provide a
comparative evaluation of their usefulness for TC of Microposts.
Section 4 introduces our approach and the semantic meta-graphs
exploited in this work.

In addition, we explore the role of the semantic features derived
from these different semantic graphs in the representation of a
topic. For example, looking at the Micropost in Fig. 1, and the
semantic representation of the resource Barack Obama in Fig. 2,
we can observe that the semantic features derived about Obamas
resource (Barack Obama) can be indicative of the topic war. Our
aim is thus to investigate whether the different semantic structures
of a KS can aid in identifying which semantic features are more
representative of this topic. For this reason, Section 5 introduces
different metrics for analysing different semantic feature-based
topic similarity measures.

3. Related work

We classify the related approaches into two main strands:
research pertaining to generic topic detection approaches and the
use of KSs for linking topics to Microposts.

6 http://wiki.dbpedia.org/Ontology.
7 http://www.mpi-inf.mpg.de/yago-naga/yago/.
8 OpenCyc, http://sw.opencyc.org/.
9 UMBEL, http://www.umbel.org/.
10 http://www.w3.org/2004/02/skos/.
11 Freebase Datasources, http://wiki.freebase.com/wiki/Data_sources.

Fig. 1. Tweets exposing different contexts involving the same entity.

Fig. 2. Deriving a semantic meta-graph from multiple linked LOD KSs.

3.1. Topic detection in Twitter

The closest task to our multi-label topic classification task
is topic detection which aims to assign a set of topics or labels
to a given Micropost. Recent approaches for topic detection on
Twitter streams can be classified into: descriptive characterisation
of Microposts, topic models, and classification models.

The first approach, descriptive characterisation of topics, employs
various lexical (bag-of-word), syntactic (hashtags) and semantic
features (named entities) extracted from the content of Microposts.
Kwak et al. [21] utilised words, phrases and hashtags as indicators for trending topics in Twitter. Laniado and Mika [22] proposed different hashtag-based metrics for identifying community
interests and trending topics in Twitter. Their study revealed that
a great proportion of hashtags (more than 50%) can be associated
to Freebase concepts. Out of these, 40% were found to correspond
to named entities. Other work has shown [23,24], however, that
hashtags can be ambiguous and their meaning can differ geograph-
ically.

The second approach is based on topic models, which rely on
the popular probabilistic Latent Dirichlet Allocation (LDA) model
introduced in [25]. Zhao et al. [26] proposed an extended version
of the LDA model, called TwitterLDA, which aims to detect the
topics of short messages using only unlabelled data. Their approach
relies on distinguishing between background word (words which
occur in every topic), and content words (words specific to
a topic). Experiments comparing TwitterLDA with traditional
news media (e.g. New York Times) showed promising results
outperforming various other topic models. Mehrotra et al. [27]
proposed various pooling schemas for improving the performance
of the original LDA model for topic classification. These pooling

strategies aim to aggregate Microposts into longer documents
(called macro-documents), which are more suitable for training
LDA based models. The evaluated pooling strategies were: authorwise pooling (pooling Microposts according to an author), burstscore wise pooling (pooling Microposts according to a burst-score),
temporal pooling (pooling Microposts which are posted during
major events by a large number of users), hashtag-based pooling
(pooling Microposts according to a hashtag). Experimental results
on three different datasets suggest that hashtag-based pooling
leads to drastically improved topic modelling over unpooled
schemes.

Ramage et al. [28,29], on the contrary, utilised annotated data
for topic modelling. Ramage et al. [28] introduced the LabelledLDA
model, which extends the original LDA model by defining a one-
to-one correspondence between LDAs latent topics and social
media tags. Experimental results on a credit attribution problem,
extracting tag-specific snippets from del.icio.us, showed promising
results, outperforming supervised classifiers such as Support
Vector Machines.

Ramage et al. [29] further performed an extrinsic evaluation
of the LabelledLDA model on a user recommendation task. In
this case, the Microposts were classified according to several
dimensions including, e.g. style, substance, status, and other
social characteristics of posts. Experimental results showed
promising results, achieving a performance comparable to those
obtained using term frequency-inverse document frequency (TF-
IDF) feature vectors built on tokenised Microposts.

The third approach, classification models, is based on discriminative machine learning algorithms. Lin et al. [30] proposed to
combine a language model with a supervised classifier for predicting the hashtags characterising a Twitter post. The features used

A. Varga et al. / Web Semantics: Science, Services and Agents on the World Wide Web 26 (2014) 3657

for classification consisted of the perplexity of the unseen Micro-
posts. Tao et al. [31] studied different topic-dependent and topicindependent features for topic classification. The topic-dependent
features aimed to capture the relevance of the features to a topic
(using keyword-based (lexical) and semantic-based relevance fea-
tures). While the topic-independent features exploited various
syntactic (e.g. has hashtag) and semantic (number of entities, number of distinct entity types) Microposts characteristics. Experimental results in the context of microblog search revealed that the
topic-dependent features (the semantic relevance features) play
an important role in this task, outperforming approaches which do
not consider them.

3.2. Semantic linking using social knowledge sources

In this section we review the approaches which rely on the use
of Knowledge Sources (DBpedia or Freebase) for semantic linking.
In light of the classification we used in Cano et al. [13], we
distinguish between two main groups: approaches exploiting local
features, and approaches exploiting the link structure of KSs.

In the first class of approaches, Genc et al. [9] proposed a model
for mapping Microposts to the most similar Wikipedia articles, employing a simple BoW representation for the text content. Their
approach comprises two steps: mapping Microposts to Wikipedia
pages; and computing the semantic distance between Microposts.
For the computation of semantic distance, a new measure is pro-
posed, which approximates the distance between Microposts by
the link distance measure computed between the corresponding
Wikipedia pages. Experimental results showed that this new distance measure outperforms the String Edit Distance [32] and Latent
Semantic Analysis [33].

Song et al. [34] proposed a probabilistic approach for mapping
the terms within Microposts to the most likely resources in Probase
KS [35]. These resources were furthermore used as additional
features in a clustering algorithm, achieving superior results to the
simple BoW approach.

Shin et al. [36] proposed a graph-based approach for detecting
persistent topics (PT) from Microposts, which correspond to
topics of long-term, steady interest to a user. For their graph
based approach they introduced two novel scoring functions that
measure the properties inherent to PT terms: regularity and
topicality. They allow to distinguish between terms that represent
persistent topics, and terms which appear in static documents.
Experimental results showed that this approach outperformed
other existing alternatives (including LDA and keyword extraction
models).

Munoz Garcia et al. [10] proposed an unsupervised approach for
assigning topics to entities within Microposts written in Spanish.
Their approach first employs the Sem4Tags POS tagger [37] for
assigning POS tags to a Micropost. Following this process, a
list of key phrases are identified, and the corresponding topics
(DBpedia resource URIs) assigned to them. This topic recognition
phase further exploits only local metadata, such as BoW features
extracted from the keywords and contextual information in the
form of neighbouring words to the keyword.

Vitale et al. [38] proposed a clustering-based approach which
enriches the BoW representation of the Micropost using named
entities extracted by the proposed Tagme system. The main idea
behind Tagme is to assign the most likely topic to an entity, by
taking into account the similarity between the topics returned by
Tagme and Wikipedia categories for top-few categories. Experimental results showed that incorporating these new BoE features
into topic classification significantly outperformed approaches using BoW features only.

P.N. Mendes and Sheth [39] proposed the Topical Social Sensor
system, which allows users to subscribe to hashtags and DBpedia
concepts to receive updates regarding these topics. Their approach
relies on linking a Micropost to DBpedia concepts derived from the
entities contained in it. One of the main applications of the system
is to detect the peak of a topic defined a priori.

Recently, in Varga et al. [14], we studied the similarity between
linked KSs and Twitter using different content-based similarity
measures. This approach employs BoW and BoE features extracted
from multiple linked KSs (such as DBpedia and Freebase). Experimental results demonstrated that these KSs contain complementary information for TC of Microposts, with the lexical features
achieving the best performance.

For the second class of approaches, exploiting the link structure
of KSs, Michelson and Macskassy [40] proposed a model that discovers topics of interest of Twitter users based on their Microp-
osts. Their approach relies on first extracting and disambiguating
the entities mentioned within a Micropost. Following this process,
a sub-tree of Wikipedia categories is retrieved for each entity and
the most likely topic assigned.

Milne and Witten [7] proposed an approach for assigning
Wikipedia resources to key concepts within Microposts. In their
approach a Wikipedia article is considered as a concept. Following
this representation, a machine learning approach is presented,
which employs different Wikipedia n-gram and Wikipedia linkbased features.

Xu and Oard [41] proposed a clustering-based approach which
maps terms in Microposts to Wikipedia articles. To achieve this,
their approach leverages the linking history of Wikipedia and the
terms textual context information to disambiguate the terms
meaning.

Recently, in Cano et al. [13], we demonstrated that exploiting
the semantic information about entities from DBpedia and Freebase is beneficial. In particular, incorporating additional semantic
information about entities in terms of properties and concepts can
further improve the performance of a topic classifier against the
approach using Twitter data only.

There is little work on classifying blogposts into topics [42].
Husby and Barbosa [42] demonstrated that selecting data from
Freebase using distant supervision, in addition to incorporating
features about named entities is beneficial for TC.

Although previous work have focused on exploiting the
semantic information from linked KSs for TC, the majority of
these approaches still exploit a single KS. There is only little work
which exploits multiple, linked KSs [13,14]. In Varga et al. [14], we
presented an approach which makes use only of the data within
KSs, ignoring the semantic information about entities present in
KSs. In Cano et al. [13], we exploited a specific semantic graph
defined in KSs (called resource meta-graph) which groups entities
together by their types. In contrast to our previous work, in
this paper we focus on understanding the usefulness of different
semantic graphs defined in KSs. For this reason we extended
our previous framework [13] by exploiting semantic information
from these different semantic meta-graphs, and examined their
usefulness for TC and measuring topic similarity.

In particular, our framework proposes novel weighting strategies for the explored semantic graphs. These weights can further be
used to filter on KS semantic features relevant to a Micropost. This
feature selection strategy also largely differs from state-of-the-art
feature selection techniques (Forman et al. [43]) used in text clas-
sification, as they typically make use of the scores obtained for the
features based on the text content only (e.g. occurrences of a feature in training positive- and negative-class training examples sep-
arately).

Fig. 3. Architecture of cross-source TC framework using semantic features derived from semantic meta-graphs.

4. Framework for topic classification of microposts

We now describe an extension of our TC framework proposed
in [13]. This extension exploits a new type of semantic graph
structure defined in KSs, named category meta-graph, and employs
a novel set of semantic features derived from this graph for TC.

As depicted in Fig. 3, our framework makes use of multiple
linked KSs (from LOD) for TC of Microposts. The main stages of this
framework can be summarised as follows:
(1) dataset collection and content modelling
(2) context modelling

(2.1) dataset enrichment
(2.2) semantic feature derivation from different semantic

(3) construction of a topic classifier based on the semantic features

meta-graphs

obtained.

4.1. Dataset collection and content modelling

In the first stage of our framework, data collection, data from
both Twitter and KSs is retrieved. The Twitter dataset comprises a
set of topically annotated Microposts. Conversely, the KSs dataset
is build from a set of articles relevant to a given topic extracted
from multiple, linked LOD KSs. This study considers two linked
KSs (from LOD), namely DBpedia (DB) and Freebase (FB), which
are applied both independently and as a merged KS. Therefore
we consider three cross-source scenarios for the use of these KS
articles: (i) DBfrom DBpedia only; (ii) FBfrom Freebase only;
and (iii) DBFBfrom both DBpedia and Freebase.

Having the documents selected from both KS and Twitter, a
simple BoW representation is employed for modelling the content
of these documents. This allows these datasets to be represented
based on what is discussed in these documents. In order to capture
the importance of each word mentioned in these documents, the
TF-IDF weighting schema is applied.

4.2. Context modelling

The second step of our framework aims to enrich the representation of both KS and Twitter documents using information about
the entities and concepts mentioned in these documents.

In order to achieve this, two main steps are first performed:
(i) entity extractionemploying the OpenCalais12 and Zemanta13
services for extracting the named entities in the documents; and
(ii) semantic mappingwhere the obtained named entities are
mapped to their KS resource counterpart if it exists.14

12 OpenCalais, http://www.opencalais.com.
13 Zemanta, http://zemanta.com.
14 Following this process, the percentage of entities without a deferenced URI is
35% in DBpedia, 40% in Freebase, and 36% in Twitter.

Following this process, different semantic meta-graphs are
exploited from the different KSs, and a set of semantic features
derived, leveraging the rich semantic information about entities
described in these semantic meta-graphs. This stage comprises
two steps: (i) semantic meta-graph construction and (ii) semantic
feature creation. In the following subsections we discuss each of
these steps.

4.2.1. Semantic meta-graphs construction

The mapping of entities to DBpedia and Freebase URIs allows
the incorporation of rich semantic representations into a topic
classifier. In particular, the presented DB and FB KSs provide a rich
source of structured information about concepts.

Fig. 2 presents an overview of the semantic features extracted
for the entity Obama. Similar to our previous work [13], rather than
focusing on the <subject, predicate, object> instances associated
with a resource, we focus on each triples semantic structure at a
meta-level, and for that we introduce two semantic meta-graphs:
the resource meta-graph and the category meta-graph.

The first proposed in our original framework [13], resource
meta-graph, exploits semantic information about an entitys KS
resource. The second is the category meta-graph which exploits
the semantic information extracted from the Wikipedia categories
to which an entity belongs. This second graph can be effectively
considered as a subset of the first one, as it groups similar
entities belonging to the same topic under the same label. The
category meta-graph thus categorises entities into more granular
taxonomies.

We define these semantic meta-graphs as follows:

Definition (Resource Meta Graph). Is a sequence of tuples G :=
(R, P, Cls, Y ) where
 R, P, Cls are finite sets whose elements are resources,
properties and classes;
 Y is the ternary relation Y  R  P  Cls representing a
hypergraph with ternary edges. The hypergraph of a Resource
Meta Graph Y is defined as a tripartite graph H (Y) = V, D
where the vertices are V = R  P  Cls, and the edges are:
D = {{r, p, cls}| (r, p, cls)  Y}.
A resource meta-graph provides information regarding the set
of ontologies and properties used in the semantic definition of
a given resource. The meta-graph of a given entity e can be
represented as the sequence of tuples G(e) = (R, P, Cls, Y), which
is the aggregation of all resources, properties and classes related
to this entity. In addition, we introduce two further notations:
R(cls) = {e1, . . . , en} for referring to the set of all entity resources
whose rdf:type is class cls; and R(cls) = {e1, . . . , em} for denoting
the set of entity resources whose types are specialisations of clss
parent type (i.e. resources whose rdf:types are siblings of cls).

A. Varga et al. / Web Semantics: Science, Services and Agents on the World Wide Web 26 (2014) 3657

Table 2
Top 5 features extracted from the DBpedia KS for the entity Obama of type Person.

Category
dbCat:Presidents_of_the_United_States
dbCat:Obama_family

Class
dbOwl:Person
dbOwl:Author
dbOwl:OfficeHolder dbCat:Harvard_Law_School_alumni
yago:LivingPeople
yago:President

dbCat:Democratic_Party_Presidents_of_the_United_States
dbCat:United_States_presidential_candidates,_2012

Table 3
Top 5 semantic features extracted from the DBpedia KS for the entity Syria of type
Country.

Class
dbOwl:Place
dbOwl:PopulatedPlace

yago:Country
yago:YagoGeoEntity
yago:MiddleEasternCountries

Category
dbCat:Countries_of_the_Mediterranean_Sea
dbCat:Arabic-
speaking_countries_and_territories
dbCat:Eastern_Mediterranean_countries
dbCat:Member_states_of_the_United_Nations
dbCat:Western_Asian_countries

Definition (Category Meta Graph). Represents a qualified subset
of the resource meta graph G in which all classes are of type
:=
dbCat:concept (skos:Concept). We define it as follows: Gcat
(R, P, Cat, Y ) where Cat is a finite set whose elements are classes
of type dbCat:concept.

For the sake of comparison, Tables 2 and 3 present the top
few class and category features derived from these graphs for two
different entity types (Obama of type Person, and Syria of type
Country). As we can observe, the dbCat features group entities by
topic, while the dbOwl features group entities by type.15

In light of the proposed three KS cross-source scenarios we
construct three different resource meta-graphs: (i) one from DB
using the dbOwl and yago ontologies; (ii) one from FB using the
fbOnt ontology; and (iii) another one from DBFB using the joint
ontologies. For the joint scenario we use the concepts from dbOwl
ontology together with the classes obtained after mapping the yago
and fbOnt ontologies.16 For the category meta-graphs we derived a
concept graph only from DBpedia, given that there is no category
structure defined in Freebase. The three category meta-graphs in
this case correspond to (i) one from DB using the dbCat categories;
(ii) one from FB using the dbCat categories obtained after mapping
the FB URIs to DB URIs (iii) another one from DBFB using dbCat
categories.

4.2.2. Semantic feature creation

Once a semantic meta graph has been constructed for a given
entity, three main features can be derived from it: class, category
and property features. Among these features the class and category
features are particular to a semantic meta-graph: class being
extracted from the resource meta-graph, and category being derived
from the category meta-graph; while the property features are
common to both meta-graphs.
We now describe each semantic feature as follows:
 Semantic class features (Cls): Extracted from the resource meta-
graph, this feature set consists of all the classes an entity refers
to. This set captures fine-grained information about this en-
tity. For example, for Barack Obama these features would be
yago:PresidentsOfTheUnitedStates, fbOnt:/book/author, yago:

LivingPeople, and dbOwl:Person. Our main intuition is that
the relevance of an entity to a given topic could be inferred
from an entitys class type. For example, the class yago:
PresidentsOfTheUnitedStates could be considered more relevant to the topic violence, than the class yago:Singer.
 Semantic category features (Cat): Extracted from the category
meta-graph, this feature set captures the Wikipedia categories
an entity is related to. Similar to the semantic classes,
these categories provide additional fine-grained information
about entities, as entities about similar topics are grouped
together in categories. For example, for Barack Obama these
category features would be dbCat:American_political_writers,
dbCat:People_from_Honolulu,_Hawaii.
 Semantic property features (P): Common to both semantic
meta-graphs, this feature set captures all the properties an
entity is associated with. Our intuition is that given a context,
certain properties of an entity may be more indicative of this
entitys relevance to a topic than others. For example, given
the role of Tahrir Square in the Egyptian revolution, properties
such as dcterms:subject could be more topically informative
than geo:geometry. The relevance of a property to a given topic
can be derived from the semantic structure of a KS graph by
considering the approach proposed in Section 4.3.1.

4.3. Supervised topic classifier creation

The final stage of the framework aims to build supervised topic
classifiers corresponding to the different cross-source scenarios,
which make use of the generated KS semantic features. The
Support Vector Machine (SVM) [45] with polynomial kernel was
selected as a base classifier, which we detail in Section 8.

For incorporating the presented KS semantic features into
a topic classifier, this framework employs different weighting
strategies for the semantic features and feature combinations, as
well as different semantic augmentation strategies for extending
the initial feature spaces of both KS and Twitter documents. In
this section we review these two strategies  originally proposed
in [13]  and present their adoption for the category meta-graph.

4.3.1. Semantic feature weighting strategies

The goal of the feature weighting strategies is to capture the
importance of the semantic features for a given topic, based on the
structure of the KS ontologies.

In the following we present an overview of the weighting
strategies applied for the different semantic features derived from
the resource meta-graph and category meta-graph:
 Semantic Feature Frequency (W-Freq): This weighting strategy
provides a light-weight approach for weighting the different
semantic features f (ontological class, category and property
features) derived for entities. This weighting function aims to
enrich the feature space of a document (i.e. KSs article, or
Tweet) x by considering all the semantic meta-graphs extracted
from the entity resources appearing in this document.

Formally, the frequency of a semantic feature f in a given
document x with Laplace smoothing can be defined as follows:
W-Freqx(f ) =


Nx(f ) + 1
Nx(f ) + |F|

(1)

f F

15 Further statistics about these semantic features are provided in Table 5.
16 The mapping of Freebase entity classes to the most likely Yago classes was done
by a combined element and instance based technique
(www.l3s.de/~demidova/students/master_oelze.pdf [44] and is available at
http://iqp.l3s.uni-hannover.de/yagof.html).

where Nx(f ) is the number of times feature f appears in all
the semantic meta-graphs associated to document x; and F
is the semantic features vocabulary. This weighting function
captures the relative importance of a documents semantic
features against the rest of the corpus; while the normalisation
prevents bias towards longer documents.

While the W-Freq (semantic feature frequency) weighting
function depends on the occurrences of features in a particular
document, other generalised weighting information can be
derived from a KSs semantic structure to characterise a
semantic meta-graph. To derive a weighted semantic metagraph the following W-SG weighting strategy is proposed.
 Class/CategoryProperty Co-Occurrence Frequency (W-SG):
The rationale behind this weighting strategy is to model the
relative importance of a property p (e.g. dbOwl: leader) to a
given class cls (yago:President) or category cat (dbCat:United_
States_presidential_candidates,_2012), together with the generality of the property in a KSs graph.

(2)

This weighting function computes how specific and how
general a property is to a given class or category based on a set
of semantically related resources derived from a KSs graph.
In particular, given the semantic meta-graph of an entity e
(i.e. G(e)), the relative importance of a property p  G(e) to a
given class cls  G(e) in a KS graph GKS can be computed by first
defining the specificity of p to cls as follows:
specificityKS (p, cls) = Np(R(cls))
N(R(cls))
where Np(R(cls)) is the number of times property p appears in
all resources of type cls in the KS graph GKS, and N(R(cls)) is
the number of resources of type c in GKS. This measure captures
the probability of the property p being assigned to an entity
resource of type cls.
For example for the Obama entity, considering the dbOwl:leader
property and yago:President class, the specificity value of
dbOwl:leader in the DBpedia graph GDB is computed as follows:
specificity_DB(dbOwl:leader, yago:President)
= {| < ?headofstate, dbOwl : leader, ?leader >,
< ?headofstate, rdf : type, yago : President > G_DB|}/
{| < ?headofstate, rdf : type,
yago : President > G_DB|}.

(3)
As indicated in Eq. (2), the computation of the specificity value is
independent of the entity e and differs according to the KS graph
from which it is derived.17 Higher specificity values indicate
that the property p occurs frequently in resources of the given
class cls.
Conversely, the generality measure captures the specialisation
of a property p to a given class cls, by computing the propertys
frequency within other semantically related classes R(cls). The
generality measure of a property p to a class cls in a KS graph
GKS is defined, as follows:

generalityKS (p, cls) = N(R(cls))
(4)
Np(R(cls))
where N(R(cls)) is the number of resources whose type is either cls or a specialisation of clss parent classes. This measure
captures the relative generalisation of a property p to a broader
set of specialised sibling classes derived from cls, and its computation is independent of the entity e. In this case the generality
of property dbOwl:leader given the class yago:President for the
DB graph is computed as:
generality_DB(dbOwl:leader, yago:President)
= {| < yago : President, rdf : subClassOf , ?parent >,

17 It might be worth mentioning that for each entity resource the specificity values
for the properties are the same, capturing in this way the generalisation of the
property for the same concept type.

< ?group, rdf : subClassOf , ?parent >
< ?agroup, rdf : type, ?group > G_DB|}/
{| < yago : President, rdf : subClassOf , ?parent >,
< ?group, rdf : subClassOf , ?parent >
< ?agroup, rdf : type, ?group >
< ?agroup, dbOwl : leader, ?leader > G_DB|}.

(5)
Higher generality values indicate that a property spans over
multiple classes, and is less specific to a given class cls. These
two measures (generality and specificity) of a property p to a
given class cls are combined as follows:
W-SG(p, cls) = specificity(p, cls)  generality(p, cls).

(6)

4.4. Incorporating semantic features into TCs feature space

This section provides an overview of the semantic augmentation strategies supported by the TC framework proposed in [13],
and presents its extension to the category meta-graph. Examples for
the various semantic features, feature combinations and semantic
augmentation strategies employed for the entity Obama are provided in Table 4.

4.4.1. Semantic augmentation

This strategy (F

A1P

A1Cls

A1) augments the initial lexical features (e.g.
BoW and BoE features) of the datasets with additional semantic
information extracted for the entities appearing in them.

| = |F| + |Fcls| for the Cls features and |F

In the case of the resource meta-graph, for both Cls and P
features, the original lexical feature set F has been extended
with a set of unique Cls (including for e.g. dbOwl:Author) and P
(including for e.g. dbOwl:writer) features derived from this graph.
In this case, the expanded feature space vocabulary size becomes
|F
| = |F| + |Fp|
for the P features, where |Fcls| denotes the total number of unique
class features added and |Fp| denotes the total number of unique
property features added. Furthermore, for the combined Cls + P
feature set this augmentation strategy creates the novel feature set

A1Cls+P , in which the feature set F is expanded with the properties
< p, cls > tuple features derived from the semantic meta-graphs.
In this case, the size of the expanded feature set is: |F
| =
|F|+|Fp||Fcls| (see the Cls1+P2 and Cls2+P1 examples in Table 4).
Similarly, for the category meta-graph, the expanded feature set
| =
becomes |F
|F| + |Fp| for the P features. In this case, |Fcat| refers to the total number of unique category features and |Fp| denotes the total
number of unique property features derived from this graph. Fur-
thermore, for the combine Cat + P feature set this augmentation
strategy creates the novel feature set F
A1Cat+P , in which the feature
set F is expanded with the properties < p, cat > tuple features
derived from this semantic meta-graph. In this case, the size of the
expanded feature set is: |F

| = |F| + |Fcat| for the Cat features, and |F

| = |F| + |Fp|  |Fcat|.

A1Cls+P

A1Cat

A1P

A1Cat+P

4.4.2. Semantic augmentation with generalisation

This augmentation strategy (F

A2) aims to further improve the
generalisation of a TC by exploiting the subsumption relation
among classes within the DBpedia or Freebase ontologies.
In the case of the resource meta-graph, the feature set F is
enhanced with the set of parent classes of cls where cls  Cls.
Therefore the size of the enhanced feature set F
A2Cls is computed
as |F
| = |F| + |Fparent(cls)|, where |Fparent(cls)| denotes the total
number of unique parent classes of cls. Similarly, the enhanced
A2Cls+P which uses the Cls+ P features is built by adding
feature set F
the < p, parent(cls) > tuple features. The size of the F
A2Cls+P is

A2Cls

A. Varga et al. / Web Semantics: Science, Services and Agents on the World Wide Web 26 (2014) 3657

Table 4
Example semantic augmentation strategies for the entity Obama using semantic features derived from resource meta-graph. The first column stands for the augmentation
strategies used to incorporate semantic features into a TC classifier, the second column provides example features to which the augmentation strategies are applied, while
the third column gives examples of possible values for each such feature. As possible semantic features two different features are considered: P1, P2 corresponding to
top semantic property features, and Cls1, Cls2 referring to top semantic class features for Obama. These features are considered alone as well as in combination (for e.g.
Cls1 + P2). For the sake of completeness, in the first row, the original feature space denoted by F, consisting of BoW features, is also presented. For this feature representation
no augmentation strategy is applied. For the semantic features further two different augmentation strategies are presented: F
A1 extending the F features with semantic
features, and F
A2 augmenting the F features with semantic features derived from the class hierarchies of KSs (e.g. considering the parent classes of a class (parent(Cls))). For
both augmentation strategies two different weighting strategies are presented: W-Freq corresponding to the semantic feature frequency weighting, and W-SG corresponding
to the classproperty co-occurrence weighting. When these strategies are applied for the feature combinations (e.g. Cls1 + P2), two additional features are added to the TC
classifier (e.g. fW-Freq(yago:President), fW-SG(dbOwl:writer, yago:President)).

A1

A2

Augmentation strategy

Baseline
P(W-Freq)
P(W-Freq)
P(W-SG)
P(W-SG)
Cls(W-Freq)
Cls(W-Freq)
Cls + P(W-SG)
Cls + P(W-SG)
parent(Cls)(W-Freq)
parent(Cls)(W-Freq)
parent(Cls)(W-Freq) + P(W-SG)
parent(Cls)(W-Freq) + P(W-SG)

Feature name
BoW
P1
P2
P1
P2
Cls1
Cls2
Cls1 + P2
Cls2 + P1
parent(Cls1)
parent(Cls2)
parent(Cls1)+P2
parent(Cls2)+P1
| = |F| + |Fp|  |Fparent(cls)|, where |Fparent(cls)|
therefore: |F
denotes the total number of unique parent(cls) classes derived
from this graph.

A2Cls+P

When applying this strategy over the category meta-graph,
however, the subsumption relations among the SKOS categories
are considered. In this case, the expanded feature set size for the
Cat features is |F
| = |F| + |Fparent(cat)|, and for the combined
Cat + P is |F
| = |F| + |Fp|  |Fparent(cat)| features. In this case
A2Cat+P
|Fparent(cat)| stands for the number of unique parent SKOS classes
of cat, and |Fp| denotes the number of unique properties extracted
from this category meta-graph.
The following section introduces a set of metrics we proposed
for analysing the relevance of these semantic features to the
performance of a topic classifier.

A2Cat

5. Measuring topic similarity

In the previous section we presented different semantic
features extracted from two semantic meta-graphs, which can be
used to enhance the representation of documents with additional
contextual information. While feature expansion can be beneficial
in some cases, in others it rather undermines the performance
of a topic classifier. In order to understand the relevance of the
proposed semantic features to the performance of a topic classifier,
in this section we study different topic similarity (also called
domain similarity [15]) measures which can provide an estimate
of the usefulness of these structures for TC.

Designing such topic similarity measures can be extremely
important for a cross-source topic classifier, as they could help in
providing an estimation of usefulness of a KS graph to previously
unseen lexical data. One such example could be, the application
of our model to a different genre, longer posts e.g. blogposts or
Facebook comments. Another situation could be, in building a topic
classifier for a new topic (e.g. Politics), in which case we want to
have an a priori estimate of the similarity between KS data and
Twitter data.
In light of the semantic features (f = {Cls, P, Cat}) and feature combinations (f = {Cls + P, Cat + P}) introduced in Section 4.2.1, we thus propose a set of entropy-based measures for
topic similarity.

Feature value
Obama
fW-Freq(dbOwl:leader)
fW-Freq(dbOwl:writer)
fW-SG(dbOwl:leader, yago:President)
fW-SG(dbOwl:writer, dbOwl:Author)
fW-Freq(yago:President)
fW-Freq(dbOwl:Author)
fW-Freq(yago:President), fW-SG(dbOwl:writer, yago:President)
fW-Freq(dbOwl:Author), fW-SG(dbOwl:leader, dbOwl:Author)
fW-Freq(yago:HeadOfState)
fW-Freq(dbOwl:Thing)
fW-Freq(yago:HeadOfState), fW-SG(dbOwl:writer, yago:President)
fW-Freq(dbOwl:Thing), fW-SG(dbOwl:leader, dbOwl:Author)

dataset T: HT (f ) = 

Entropy is an information theoretic measure which defines a
probability distribution p18 over a random variable X, capturing the
dispersion of the variable f among the different classes in a given
fX p(f ) log p(f ). In our context, we introduce this measure, as it allows to capture the semantic ambiguity
and uninformativeness of a topic based on the entities mentioned
in the documents and the KS structure.19 That is, entities that are
evenly distributed over multiple KS concepts/categories will have
high entropy and thus topics mentioning these entities are less focused (more ambiguous) in the subject(s) they discuss.

A summary of the proposed measures can be given as follows:
1. TopicClass bag entropy (Class Entropy): We took the class
bag for each topic derived from the resource meta-graphs and
measured the entropy of that class bag, capturing the dispersion
low
of classes used for a particular topic. In this context,
entropy indicates a focused topic, while high entropy indicates
an unfocused topic, which is more random in the subjects that
this topic discusses. We define this measure as follows:

HT (Cls) = |ClsT|

j=1 p(clsj) log p(clsj), where p(clsj) denotes
the conditional probability of a concept clsj, within the topics
concept bag ClsT .

2. TopicCategory bag entropy (Category Entropy): We constructed the category bag for each topic derived from the category meta-graphs and measured the entropy of that category
bag, capturing the dispersion of categories used for a particular topic. In this context, low entropy indicates a focused topic,
while high entropy indicates an unfocused topic, which is more
random in the subjects that this topic discusses. We define this
measure as follows:

HT (Cat) = |CatT|

j=1 p(catj) log p(catj), where p(catj) denotes the conditional probability of a category catj, within the
topics category bag CatT .

18 In this paper we used the shorthand notation p for Prp(X = f ). We reserve the
capital P for the property features.
19 Compared to previous content-based similarity measures (e.g. cosine), these
measures can explicitly measure the informativeness of a topic by capturing the
dispersion of the entities among different KS classes/categories according to the
various semantic meta-graphs presented.

3. TopicProperty bag entropy (Property Entropy): We considered
the property bag for each topic derived from the KS graphs and
measured the entropy of that property bag, capturing the dispersion of properties used for a particular topic. In this context,
low entropy indicates a focused topic, while high entropy indicates an unfocused topic which is more random in the subjects
that this topic discusses. We define this measure as follows:

j=1 p(pj) log p(pj), where p(pj) denotes the
conditional probability of a property pj, within the topics property bag PT .

4. TopicEntity bag entropy (Entity Entropy): We took the entity
bag for each topic extracted by the named entity recogniser and
measured the entropy of that entity bag, capturing the dispersion of entities used for a particular topic. In this context, low
entropy indicates a focused topic, while high entropy indicates
an unfocused topic which is more random in the subjects that
this topic discusses. We define this measure as follows:

HT (Ent) = |EntT|

HT (P) = |PT|

j=1 p(ej) log p(ej), where p(ej) denotes the
conditional probability of an entity ej, within the topics entity
bag EntT .

HT (Cls|E) = |ET|

HT (Cat|E) = |ET|

5. EntityClass entropy (EntityClass Entropy): We computed this
measure for each topic, by considering the class bags for each
entity mentioned in a topic, based on the extracted resource
meta-graphs. This measure captures the dispersion of the entities in each class. That is, low entropy indicates that the topic is
less ambiguous, consisting of entities belonging to few classes,
while high entropy refers to higher ambiguity at the level of en-
tities.
j=1 p(ej)HT (Cls|E = ej), where p(ej) denotes the conditional probability of an entity ej within the
topics entity bag ET , and HT (Cls|E = ej) refers to topicclass
entropy given the entity ej.
6. EntityCategory entropy (EntityCategory Entropy): In an analogy with the EntityClass entropy, we computed this measure
for each topic, by considering the category bags for each entity mentioned in a topic based on the extracted category meta-
graphs. In this case, low entropy indicates that the topic is less
ambiguous, consisting of entities belonging to few categories,
while high entropy refers to higher ambiguity at the level of en-
tities.
j=1 p(ej)HT (Cat|E = ej), where p(ej)
denotes the conditional probability of an entity ej within the
topics entity bag ET , and HT (Cat|E = ej) refers to topic
category entropy given the entity ej.
7. EntityProperty entropy (EntityProperty Entropy): Similarly,
we took the property bag for each entity mentioned in a topic
based on the extracted KS graphs. In this context, low entropy
indicates that the topic is less ambiguous, consisting of entities
being associated to few properties, while high entropy refers to
higher ambiguity at the level of entities.
j=1 p(ej)HT (P|E = ej), where p(ej) denotes
the conditional probability of an entity ej within the topics entity bag ET , and HT (P|E = ej) refers to topic property entropy
given the entity ej.
8. ClassProperty entropy (ClassProperty Entropy): We measured
this by taking the property bag for each class appearing in each
topic derived from the resource meta-graphs. In this context, low
entropy indicates that a topic is less ambiguous, few properties
spanning over multiple classes, while high entropy reveals high
property diversity. The corresponding measure is defined as fol-
lows:
j=1 p(clsj)HT (P|Cls = clsj), where p(clsj)
denotes the conditional probability of a class clsj within the
topics class bag ClsT , and HT (P|Cls = clsj) refers to topic
property entropy for the class clsj.

HT (P|Cls) = |ClsT|

HT (P|E) = |ET|

HT (P|Cat) = |CatT|

9. CategoryProperty entropy (CategoryProperty Entropy): Sim-
ilarly, we computed the categoryproperty entropy for each
topic. In this context, low entropy indicates that a topic is less
ambiguous, few properties spanning over multiple categories,
while high entropy reveals high property diversity. The corresponding measure is defined as followed:
j=1 p(catj)HT (P|Cat = catj), where
p(catj) denotes the conditional probability of a category catj
within the topics class bag CatT , and HT (P|Cat = catj) refers
to topic property entropy for the category catj.
Considering that our aim is to estimate the performance of
a topic classifier on a new unseen test dataset, we furthermore
define the entropy difference (DE) measure for capturing the
differences between a training dataset (Ttrain)used to train a topic
classifier-, and a test dataset (Ttest)used to test a topic classifier.
Let Ttrain and Ttest be the probability distributions estimated from
the training and test datasets. For instance, given the Cri topic, and
the cross-source topic classifier built on DBpedia KS data, the Ttrain
training dataset corresponds to a dataset collected for the Cri topic
from DBpedia, while the Ttest dataset corresponds to the dataset
collected from Twitter. According to the above entropy measures,
for each semantic feature (e.g. f = P) and feature combination
(e.g. f = Cat + P),20 we define the entropy difference measure as
follows:
DE(f , Ttrain, Ttest ) = |HTtrain

(7)
Intuitively, having features (e.g. Cls or Cat) with low DE values
means that the features have similar values with respect to the
training and test datasets. It is also expected that the lower the DE
values are, the better the performance of a topic classifier.

(f )  HTtest (f )|.

These measures will be examined in Section 8 by correlating
them with the performance of different topic classifiers. Our
approach was evaluated in the Emergency Response and Violence
Detection domains. The following section introduces the datasets
in which the proposed framework and topic similarity metrics
were tested.

6. Dataset

Our experiments make use of a Twitter dataset and two KSs
datasets previously introduced in [13,14]. These datasets belong
to the Emergency Response (ER) and Violence Detection (VD)
domains. This section provides a brief description of these datasets.
The Twitter dataset was derived from Abel et al. [46]. It
comprises Microposts collected over a period of two months
starting in November 2010. Some of the notable Emergency events
discussed in these messages are Mexican drug war, Egyptian
revolution and Indonesia Volcano Eruption. This dataset was
annotated with 17 OpenCalais topics.21 Each of these topics
consists of 1000 randomly selected Tweets excluding re-tweets.

This resulted in a collection of 10,189 Tweets,22 which were
manually re-annotated by two annotators, achieving an interannotator Kappa score of 71.25%. The final dataset is a multilabelled dataset, consisting of Tweets annotated with up to 6

20 For clarity we mention here that for the feature combinations (e.g. f = Cat + P)
(f = P|Cat)), as this
we employ the conditional entropy measure (e.g. HTtrain
provides a natural way for capturing the relationships among multiple semantic
features.
21 The full
list of topics include: Business & Finance, Disaster & Accident,
Education, Entertainment & Culture, Environment, Health & Medical & Pharma,
Hospitality & Recreation, Human Interest, Labour, Law & Crime, Politics, Religion
& Belief, Social Issues, Sports, Technology & Internet, Weather and War & Conflict.
22 For each given topic (e.g. Cri) then the number of positive instances is 1000 and
the number of negative instances is 9189.

A. Varga et al. / Web Semantics: Science, Services and Agents on the World Wide Web 26 (2014) 3657

Fig. 4. The multi-label distribution of the three gold standard datasets: DBpedia, Freebase and Twitter datasets. The numbers on the x axis represent the number of topics
assigned to a document, ranging from 1 topic to 9 topics. The numbers on the y axis correspond to the percentage of documents labelled with different topics [14].

labels (as shown in Fig. 4). For the purpose of these experiments
we considered the following three topics related to ER and
VD domains: War & Conflict (War), Law & Crime (Cri) and
Disaster & Accident (DisAcc) topics.

The two KS datasets were compiled by querying each KS for
1000 randomly selected resources for each of these three specific
topics.

In the case of DBpedia, we SPARQL23 queried for all resources whose categories (dcterms:subject) and sub-categories
(skos:narrower) are similar to the topic of interest. The final DBpedia dataset comprised 9465 articles.24 While the majority of these
articles belong to a single topic, less than 1.% of them are annotated with 3, 4, 5, 6, 7 or 9 topics (as shown in Fig. 4). For querying
the Freebase KS we used the Freebase Text Service API.25 The final
Freebase dataset comprises 16,915 articles,26 where the majority
belong to a single topic (as shown in Fig. 4). From the returned re-
sources, we kept each resources abstract or title to build the annotated dataset for the given topic.

Looking at the overall distribution of the entities in the three
datasets, we observe that the KS datasets contain more entities
than the Twitter dataset; the DBpedia dataset contains on average
22.24 entities per article, the Freebase dataset contains 8.14
entities per article, and the Twitter dataset contains on average
1.73 entities. The distribution of the top 15 entity types is
presented in Fig. 5, indicating that the most frequent entity types
are Country, Person, Organisation, Natural Feature, Position and
City (as reported in [14]).

an entity. Examples of such properties from DBpedia include:
rdfs:comment, abstract, wikiPageExternalLink, and from Freebase in-
clude: type/object.

These feature spaces were also reduced by considering only the
top 5 entity classes and top 5 properties derived from the different
KS graphs for each OpenCalais entity type (e.g. Person). The same
strategy was used for reducing the number of category features.
The statistics of the lexical and semantic features derived for these
datasets is summarised in Table 5.

Comparing the statistics obtained for the resource meta-graph
and category meta-graph, we observe that the frequency of dbCat
categories are generally higher than those of dbOwl and yago
classes. In addition, the average number of distinct categories
for an entity (cat/ent) double the number of distinct classes per
entities (cls/ent). This indicates that the categories form much
larger clusters than the classes.

In addition, we observe that in all the three datasets the number
of unique categories is higher than the number of unique classes.
This indicates that the datasets are more diverse in terms of
categories than in terms of classes.

Following the concept generalisation process, in the resource
meta-graph the number of unique dbClass classes reduced by 76%,
the number of unique yagoClass classes reduced by 92%, and the
number of unique fbClass classes by 88%. While in the category
meta-graph the number of unique dbCat classes reduced by 42%.

6.1. Dataset pre-processing

The pre-processing steps for generating lexical features (i.e.
BoW) included: (i) removal of stopwords; (ii) transformation of
each word to lowercase (iii) stemming each word using the Lovins
stemmer [47].

For generating the semantic features we used the BoE features derived from a document. For each entity feature we looked
for its resource representation in both KSs (DBpedia and Free-
base). Using these KS resources we then generated different semantic meta-graphs (i.e. GDB and GFB) as indicated in Section 4.2.1.
In addition, for generating the semantic meta-graphs we disregarded properties which contained general information about

23 http://www.w3.org/TR/rdf-sparql-query/.
24 For each given topic (e.g. Cri) then the number of positive DBpedia instances is
1000, and the number of negative DBpedia documents equals to 8465.
25 Freebase Text Service API, http://wiki.freebase.com/wiki/Text_Service.
26 For each given topic (e.g. Cri) then the number of positive Freebase instances is
1000 and the number of negative Freebase instances is 15,915.

7. Baseline feature sets and models

We compared the performance of the proposed framework
against several baseline models corresponding to state-of-the-art
approaches for TC. These baseline models employ three baseline
features namely: BoW, BoE, part-of-speech (POS). These features
are typical baseline features for TC and have been evaluated in
previous work [13,14]. In addition, a new baseline feature set (bag-
of-concepts (BoC)) is also introduced. The BoC feature set consists
of a collection of OpenCalais-derived semantic classes which are
assigned to entities. As opposed to the semantic classes from
KS semantic graphs, classes derived with the OpenCalais service
represent more generic concepts.
A summary of these baseline features is given as follows:
 Bag-Of-Words Features (BoW): The first baseline feature set
consists of simple unigram features, which captures our natural
intuition to utilise what we know about a particular topic.
The BoW features consists of a collection of words weighted
by term frequency-inverse document frequency (TF-IDF). This
weighting metric captures the relative importance of a word in
a document to its use in the whole corpus. This feature set is

Fig. 5. The distribution of top 15 concept types in the three gold standard datasets: DBpedia (DB), Freebase (FB) and Twitter (TW) datasets for the Crime (Cri), Disaster
(DisAcc), and War (War) topics.

Table 5
General statistics for the DBpedia (DB), Freebase (FB) and Twitter (TW) datasets used in the context of ER and VD for the two semantic meta-graphs analysed (resource
meta-graph and category meta-graph). The rows labelled as BoW and BoE represent the size of the vocabulary of the BoW and BoE (without BoW) features. Statistics about
the resource meta-graph (as reported in [13]): dbCls, yagoCls and fbCls stand for the unique number of classes extracted from the DBpedia and Freebase knowledge graphs.
dbprop counts the number of unique DBpedia properties, and correspondingly fbprop counts the number of unique Freebase properties. Considering the category meta-
graph: dbCat refers to the unique number of categories extracted from DBpedia knowledge graph. cls/ent refers to the average number of dbOwl and yago classes per entity;
cat/ent quantifies the average number of dbCat categories per entity, while fbcls/ent denotes the average number of fbOnt classes per entity. Similarly prop/ent denotes the
average number of dbOwl and yago properties per entity, and fbprop/ent refers to the average number of fbOnt properties per entity.

Statistics

Lexical

Semantic features

DisAcc

BoW
BoE
dbCls
yagoCls
fbCls
dbCata
dbprop
fbprop
cls/ent
cat/enta
prop/ent
fbcls/ent
fbprop/ent

Cri

War

DisAcc

Cri

War

DisAcc

Cri

War

a The statistics correspond to the new category meta-graph analysed in this paper.

A. Varga et al. / Web Semantics: Science, Services and Agents on the World Wide Web 26 (2014) 3657

very competitive, previous work on cross-source TC has shown
that this features set outperforms on average the BoE features
presented below [14].
 Bag-Of-Entities Features (BoE): This feature set extends the
lexical BoW features with entities and concepts extracted using
available annotation services, e.g. OpenCalais API, weighted by
TF-IDF. These web services annotate each entity with generic
types. For example in the case of Obama, rather than recognise it
as being of type dbOwl:President the majority of these services
will annotate this entity with the label Person [48]. In this case
the value of the BoE feature thus captures the co-occurrence of
the entity and concept pairs fBoE (BarackObama  Person).
 Part-of-Speech Features (POS): Similar to the BoE feature set,
this feature set aims to capture some generalisation patterns for
the words. For this reason, the syntactical patterns within the
documents are considered and used to extend the lexical BoW
features. In light of our previous work [13], we used Ritter et al.s
[49] Twitter NLP Tool; this POS tagger has been trained on short
text messages. For each POS tag again the TF-IDF weighting was
assigned.
 Bag-Of-Concepts Features (BoC): This feature set extends the
lexical BoW features with concepts extracted with the OpenCalais API. The API provides one single (often generic) concept type for each entity. For example assuming that Barack
Obama is annotated as Person by OpenCalais, this feature set
captures the presence of the Person class type fBoC (Person).27
This new baseline feature set provides an alternative comparison between the newly proposed semantic meta-graph derived
features (Cls) and those obtained from the OpenCalais service.
Considering the above baseline features, two strong baseline
supervised machine learning models are employed28:
 TW single source topic classifier, in which an SVM topic classifier
is built on Microposts only (TW).
 KS cross source topic classifier, in which an SVM topic classifier
is built on KS (DBpedia and/or Freebase) data only.

8. Experimental setup

In this section we present a series of experiments to evaluate
the TC framework and topic similarity measures using the two
semantic meta-graphs introduced in Section 4.2.1. In particular,
these experiments aim to compare and contrast the results obtained for the resource meta-graph (used in our previous experiments [13]) with the results obtained for the newly introduced
category meta-graph.

For evaluating the TC framework for the different single-source
and cross-source scenarios, we took the commonly used one-vs-
all approach [50]. In this approach we decompose the multi-label
problem into multiple independent binary classification problems.
Following this approach, each TC system was evaluated using
5-fold cross-validation. The training dataset for the TW TC system
consisted of 80% of the original Twitter data. For the KS classifier
the training set consisted of the full KS data. For the KS + TW

27 This comparison also allows us to investigate whether modelling each entity
with more than one KS concept (in our case 5) is more suitable for TC than with a
single one.
28 The motivation behind the selection of these discriminative models, is that
they correspond to typical baseline methods used in cross-source (multi-source)
learning [15]. Previous approaches on single-source TC are not directly comparable
with our current setting and results. For instance, the majority of the generative
LDA based approaches (e.g. TwitterLDA) were trained on unlabelled data only using
simple BoW features. However our approach exploits labelled data from KSs, and
further focuses on the evaluation of the usefulness of different semantic features
for TC.

classifier the full KS data was combined with 80% of Twitter data.
Using the Weka Software29 we applied different discriminative
classifiers including the Maximum Entropy, Perceptron and
Support Vector Machine. After comparing the results of these
classifiers we found the SVM with polynomial kernel to be that
which achieved the best results. Therefore, in this paper we only
report results for the SVM classifier.

In order to assess the usefulness of the different semantic metagraph structures for TC we conducted a series of experiments. In
the first set of experiments, we compared the performance of the
topic classifiers using the resource meta-graph and category meta-
graph. First, the results obtained for the single-source TC case are
discussed in Section 8.1.1. Then we discuss the results obtained
for the cross-source TC case in Section 8.1.2. The main research
questions that we aim to address are How does the performance of
a topic classifier vary using different concept graphs? Which concept
graph provides the most useful semantic features for TC of Microposts?
Next, our second set of analyses aim to investigate whether
there are any differences in the roles (generalisation patterns) of
semantic features derived from the two semantic concept graphs
in TC. In this case, we address the research question Are there
differences in the roles of the concept graphs in the different TC
scenarios?

Finally, in the third set of experiments, we look at the roles of
the semantic features in predicting the performance of a topic clas-
sifier. For this reason we proposed and compared various entropybased measures using the semantic features which characterise a
topic. We then correlated these entropy-based measures with the
performance of SVM topic classifiers. In this case we investigate
the questions of Can we predict the performance of a topic classifier?
Which topic similarity measure provides a better estimate on the performance of a topic classifier?

8.1. Comparison of multiple semantic structures for topic classifica-
tion

We start our analysis by assessing the usefulness of the different
semantic meta-graphs in both single-source TC (Section 8.1.1) and
cross-source TC (Section 8.1.2) scenarios.

8.1.1. Evaluation of semantic concept graphs in single-source topic
classification

This section details the results obtained for the single-source TC
case. In particular, it compares and contrasts the results reported in
our previous work for the resource meta-graph [13] with the results
obtained for the category meta-graph introduced in this paper.

In our experiments we employed three different single-source
TW classifiers. These classifiers make use of single KS ontol-
ogies: TW(dbKS) and TW(fbKS); and the combined KS ontologies:
TW(dbKS + fbKS). In particular, in the case of the resource meta-
graph, dbKS denotes the dbOwl+ yago ontologies, while in the case
of the category meta-graph, dbKS stands for the dbCat ontology.
These classifiers are evaluated against several baseline models, as
presented in Table 6.

Looking at the performance of the baseline models, we observe
that the best performance was achieved by the BoE features, which
performed better than the BoC and BoW features. Further, the POS
features did not improve on the baseline model using only BoW
features. An explanation for this could be that the language in
Tweets is quite complex, and exhibits less regularity than longer
texts used from KSs (KS abstracts).

29 Weka Software, http://www.cs.waikato.ac.nz/ml/weka/.

Table 6
The performance of the single-source TW SVM topic classifiers using different KSs ontologies (DBpedia dbKSs ontologies, and Freebase fbKSs ontology) and two semantic
meta-graphs derived from these KSs (resource meta-graph (Resource) and category meta-graph (Category)). The results obtained for the semantic features derived for the
resource meta-graph (reported in [13]) using the W-Freq weighting schema correspond to: class (Cls(W-Freq)), upper-class (parent(Cls)(W-Freq)) and property (P(W-
Freq/Cls)); while using the W-SG weighting schema are: classproperty co-occurrence (Cls + P(W-SG)), upper-classproperty co-occurrence (parent(Cls) + P(W-SG)) and
property (P(W-SG/Cls)). The results obtained for the semantic features derived for the category meta-graph using the W-Freq weighting schema are: category (Cat(W-Freq)),
upper-category (parent(Cat)(W-Freq)) and property (P(W-Freq/Cat)); while using the W-SG weighting schema are: categoryproperty co-occurrence (Cat + P(W-SG)),
upper-categoryproperty co-occurrence (parent(Cat) + P(W-SG)) and property (P(W-SG/Cat)). The baseline models (Baseline) employed are bag-of-words (BOW), bag-of-
entities (BOE), part-of-speech (POS) and bag-of-concepts (BOC).

TW(dbKS + fbKS)

F1

TW(dbKS)

F1

TW(fbKS)

F1

Dataset

Semantic graph

Features

Baseline

War

Resource

Categorya

Baseline

Cri

Resource

Categorya

Baseline

DisAcc

Resource

Categorya

BOCa
Cls(W-Freq)
parent(Cls)(W-Freq)
P(W-Freq/Cls)
Cls + P(W-SG)
parent(Cls) + P(W-SG)
P(W-SG/Cls)
Cat(W-Freq)a
parent(Cat)(W-Freq)a
P(W-Freq/Cat)a
Cat + P(W-SG)a
parent(Cat) + P(W-SG)a
P(W-SG/Cat)a

BOCa
Cls(W-Freq)
parent(Cls)(W-Freq)
P(W-Freq/Cls)
Cls + P(W-SG)
parent(Cls) + P(W-SG)
P(W-SG/Cls)
Cat(W-Freq)a
parent(Cat)(W-Freq)a
P(W-Freq/Cat)a
Cat + P(W-SG)a
parent(Cat) + P(W-SG)a
P(W-SG/Cat)a

BOCa
Cls(W-Freq)
parent(Cls)(W-Freq)
P(W-Freq/Cls)
Cls + P(W-SG)
parent(Cls) + P(W-SG)
P(W-SG/Cls)
Cat(W-Freq)a
parent(Cat)(W-Freq)a
P(W-Freq/Cat)a
Cat + P(W-SG)a
parent(Cat) + P(W-SG)a
P(W-SG/Cat)a

a The results correspond to the new results obtained for the newly introduced category meta-graph.

Comparing the results obtained for the best baseline feature
 BoE feature  with those for the semantic features derived
from the two semantic meta-graphs, we observe that the best
results were obtained for the resource meta-graph for the combined
TW(dbOwl + yago tplus fbOnt) scenario using the P features with
the W-SG weighting strategy, which significantly outperforms the
baseline lexical features (t-test with  < 0.05). As reported in
our previous work [13], in the case of the War category, the F1
measure increases with 2.8% with respect to the BoW features
and 2.2% with respect to the BoE features; in the case of the Cri
category the F1 measure increases with 2.3% with respect to the

BoW feature and 0.6% with respect to the BoE features, while in
the case of DisAcc an improvement of 1.5% over the BoW features
can be observed. Further, for both semantic meta-graphs, our novel
classproperty co-occurrence weighting schema (W-SG) for the
properties (P(W-SG)) shows a significant improvement over the
feature frequency strategy (P(W-Freq)) (t-test with  < 0.01).
These results demonstrate that capturing the importance of the
property within a given semantic meta-graph (with respect to
concepts in the resource meta-graph or to categories in the category
meta-graph), improves the generality of the properties and the
performance of the TC classifier for each topic.

A. Varga et al. / Web Semantics: Science, Services and Agents on the World Wide Web 26 (2014) 3657

While employing the P features have been shown to provide a
positive gain over the baseline features for most of the topics, the
usefulness of the semantic features and augmentation strategies
merely depend on a number of factors. For instance, one of the
factors which influences the performance of a TC classifier is the
number of entities identified in a Micropost. For instance, in the
case of the War topic, a higher number of entities have been
extracted than for the other two topics. This can explain the
higher gain achieved for this topic, resulted from a larger number
of Microposts being enriched. Further, the lower performance
achieved by the Cls features, could be due to the level of ambiguity
(measured as cls/ent) of the Cls features and their discriminative
power for a given topic. Looking at the Table 5, it can be observed
that there are a larger number of property features defined in KSs
for an entity (prop/ent) than for a class (cls/ent, fbcls/ent). This
allows the incorporation of very fine grained information into TC,
which indeed seems to improve the performance of the classifier
upon the baseline features. In order to capture these factors and
provide an insight into the usefulness of these features for topic
classification, the reminder of the reader, we employed a set of
topic similarity measures which we will evaluate in Section 8.3.

Inspecting the results obtained for the different taxonomies, we
observe similar trends for the resource meta-graph and category
meta-graph. That is, for both semantic graphs the dbKS ontologies
(dbOwl + yago for resource meta-graph; and dbCat for category
meta-graph) provide a significant improvement over the semantic
features derived from fbKS ontology for the War and DisAcc topics,
except for Cri (t-test with  < 0.05). This could be explained
by the fact that in the Cri topic the entities extracted from the
dbKS graph are more ambiguous than those found within the
War and DisAcc topics (see cls/ent values in Table 5). Similarly,
the entities extracted from the fbKS are less ambiguous in the
Cri topic than in the other two topics (see fbcls/ent values in
Table 5). The best overall results were obtained by the combined
dbOwl + yago + fbOnt and dbCat tplus fbOnt ontologies using
the property features, indicating that the three ontologies contain
complementary information (properties) about the entities.

Further, we found that the augmentation strategies are beneficial for both semantic graphs. In the case of the resource meta-
graph, we found different trends for the fbOnt and dbOwl + yago
ontologies. When using fbOnt ontology, both (parent(Cls)(W-Freq)
and parent(Cls)+ P(W-SG)) showed a consistent improvement over
the initial non-generalisation case (Cls(W-Freq) and Cls+ P(W-SG))
for each topic. However, when using the dbOwl + yago ontology
encoding the very specific classes of the entities were found to be
more beneficial for some topics (e.g. War). These results are understandable because after generalisation, the entities which have
the same parent class in the KS graphs will be unified to the same
semantic concept type, losing as a result the very specific meaning
of the entity. In the case of yago ontology, the number of unique
classes reduces with 92% after generalisation, while in fbOnt, the
number of unique classes becomes 88% less. In the case of the category meta-graph, further, we found that the parent(Cat)(W-Freq)
and parent(Cat)+ P(W-SG) features significantly improved over the
Cat(W-Freq) and Cat + P(W-SG) features for each topic (t-test with
 < 0.05).

8.1.2. Evaluation of semantic concept graphs in multi-source topic
classification

This section continues with the description of the results
obtained for the cross-source TC case. In particular, it compares and
contrasts the results reported in our previous work for the resource
meta-graph [13] with the results obtained for the category metagraph introduced in this paper.

Based on the three scenarios analysed, in our experiments
we employed six different cross-source TW classifiers. Among

these cross-source classifiers, four make use of individual KS
ontologies: DB making use of dbKSs ontologies, FB making use of
fbKSs ontology, DB + TW exploiting dbKSs ontologies, FB + TW
employing fbKSs ontology. The remaining two cross-source TC
classifiers make use of the combined KS ontologies: DB + FB and
DB + FB + TW. In particular, in the case of the resource meta-
graph, dbKS denotes the dbOwl+ yago ontologies, while in the case
of the category meta-graph, dbKS stands for the dbCat ontology.
These classifiers are evaluated against several baseline models, as
presented in Table 7.

Looking at the performance of the baseline models, we observe
a different trend compared to the TW only scenario. The syntactic
classes provided by the POS taggers, in this cross-source scenario,
were found to be more beneficial, compared to the BoW cases.
While for the BoE and BoC features, we did not obtain an
improvement on the baseline BoW features. An explanation for this
could be that the entities which appear in the TW dataset could be
quite different from the entities appearing in the KS data for each
topic, in which case exploiting the semantic information from KSs
seems to be more beneficial.

Inspecting the best overall performance for the various features,
feature weighting strategies and augmentation strategies, we
notice that the resource meta-graph achieved the best results using
the DB(dbOwl + yago) + FB(fbOnt) + TW topic classifier. As
reported in our previous work [13], this classifier significantly
outperformed the baseline single KS classifiers: by 11.9%30.7%
(over DB + TW) and 13.4%31.4% (over FB + TW) (t-test with  <
0.05). Considering the category meta-graph, the improvements
were slightly smaller, a significant improvement of 11.5%30.2%
was observed over DB + TW and 13%30.9% over FB + TW (t-test
with  < 0.05). Comparing the results against the TW baseline
models, we observe a significant improvement of 9.3%28.2% over
the TW (dbOwl+yago+fbOnt) when using the resource meta-graph,
and 8.9%27.7% over the TW (dbCat+fbOnt) classifiers when using
the category meta-graph.

Comparing the different enrichment strategies, we observed
similar trends for both resource meta-graph and category meta-
graph. The best enrichment that consistently improved over the
baseline for both concept graphs was the W-SG for P, indicating
that encoding the specificity of a property for each semantic
concept graph is beneficial for TC. For the W-Freq features,
however, we found that in the case of the resource meta-graph,
the semantic augmentation by feature frequency (Cls(W-Freq)) and
by generalisation (parent(Cls)(W-Freq)) (Table 7, column 8) worked
consistently better than the baseline models. However, in the case
of the category meta-graph, the performance of the Cat(W-Freq) and
parent(Cat)(W-Freq) were only comparable to those of the baseline
models.
Despite of the accuracy gain obtained with the P and Cls
features for the DB+ FB+ TW classifier, an interesting observation
about these results is however, that the semantic features do not
always improve upon the baseline models. For instance in the
case of DB + FB topic classifier, the results are comparable or
slightly worst than those obtained by the BoW feature set ignoring
semantic augmentation. An explanation for this could be that the
distribution of entities in the DB and FB datasets may slightly be
different to the one in Twitter. Further given that these classifiers
do not make use of any Microposts data, this mismatch provides
challenges for the topic classifier. A possible reason for this could
be the level of ambiguity of the entities in the different datasets. In
order to capture the differences between the datasets and provide
an estimation on the usefulness of the different semantic features,
the reminder of the reader, we employed a set of topic similarity
measures which we will examine in Section 8.3.

Contrasting the results for all three topics, we observe, that the
biggest overall improvement was achieved for the Cri topic using

A. Varga et al. / Web Semantics: Science, Services and Agents on the World Wide Web 26 (2014) 3657

the resource meta-graph. In particular, the DB + FB + TW achieved
an improvement of 31.4% over FB+TW. For the case of the category
meta-graph, the DB + FB + TW achieved an improvement of 30.9%
over FB + TW.
Also for the Cri topic, we observe, that the FB + TW single KS
classifier using BoW features performed better than the DB + TW
single KS classifier. However, when looking at the results obtained
for the BoE features, we observe the opposite trend, the DB + TW
performed better than the FB + TW. An explanation for this could
be that a relatively large number (3377) of articles do not contain
any entity, and thus are not semantically enriched.

Further, we noticed that the coverage of entities is lower in the
Freebase than in DBpedia. For example from the total number of
entities extracted by OpenCalais a large proportion (40%) of the
entities were not found in the Freebase KS, while in the case of
DBpedia 35% of the entities were not assigned any URI. Regardless
of this, an improvement in F1 measure was obtained for both
semantic graphs when combining the two linked KSs. This thus
indicates that the two linked KSs complement each other well. In
one hand, Freebase brings its strength in content coverage for the
topics, while DBpedia brings useful semantic evidence about the
entities which are covered [13].

In conclusion, considering the results obtained for both singlesource and cross-source scenarios for the various semantic features
derived from the three KS graphs, our findings are as follows:
1. Semantic meta-graphs (both resource meta-graph and category
meta-graph) built from KSs contain useful semantic features
about entities for TC. In particular, incorporating semantic
features about properties (P) using our novel classproperty
co-occurrence weighting schema (W-SG) proved a significant
improvement over previous state-of-the-art approaches.
2. Combining the evidence about the semantic features from
multiple, linked KS taxonomies (TW (dbKS + fbKS)) is beneficial
for TC, showing a significant improvement over approaches
considering a single KS (TW (dbKS), TW (fbKS)).

8.2. The role of semantic concept graphs in single-source and crosssource topic classification

In the previous section we compared the overall performance
of a topic classifier using semantic features derived from two
semantic meta-graphs (resource meta-graph and category meta-
graph). In this section, we continue our discussion focusing on
the differences in roles of these semantic features in different TC
scenarios.

Looking at the results obtained for the individual semantic
features (Cat, Cls, P) we observe different patterns for the singlesource and cross-source TC scenarios.

Inspecting the results obtained for the single-source topic
classifier, we notice that the performance of the SVM topic
classifier was consistently higher using the Cat features than using
the Cls features for both W-Freq and W-SG weightings (see Table 7)
(t-test with  < 0.05). These results indicate that the information
about the category features seems to be more beneficial than the
information about the classes in the single-source TC scenario.
However, for the P features, we found that the weights obtained
from the resource meta-graph are better than those obtained from
the category meta-graph. This behaviour could be understood by
the fact that the category meta-graph consists of a larger number
of Cat than the number of Cls in the resource meta-graph, and in
addition the Cat are more ambiguous (less focused) than the Cls in
terms of the number of properties associated to them.

In contrast to these observations,

in the cross-source TC
scenarios we notice different trends for the Cat and C features
(t-test with  < 0.05). While for the TW only scenario, the Cat
features worked better than the Cls features, in the cross-source

scenario we observe the opposite trend, the Cls features are more
useful than Cat features. An explanation for this could be that the
different datasets contain a larger number of Cat features than
the Cls features (compare dbCat with dbClass, yagoClass and fbClass
in Table 5), making it harder for the cross-source classifiers to
generalise over the Cat features than the Cls features.

In conclusion, considering the results obtained for both single-

source and cross-source scenarios, our findings are as follows:
1. The semantic features derived from the resource meta-graph and
category meta-graph exhibit different roles (generalisation pat-
terns) in the different TC scenarios. The class features derived
from the resource meta-graph exhibit better generalisation patterns in the cross-source setting, while the category features derived from the category meta-graph are better suited to encode
the specificity of a topic in a single-source setting.

2. Despite the differences in roles of the semantic features
derived from the two semantic meta-graphs, incorporating
semantic features from both semantic graphs is beneficial for
TC, achieving performance superior to previous approaches
utilising lexical features.

8.3. Evaluating topic similarity measures

The previous sections analysed the benefit of using semantic
features derived from KS graphs for the topic classification task
in both single-source and cross-source scenarios. These results
have also shown that there is variation in the performance levels
between topics. This suggests that differences between the KS
and Twitter datasets affects the performance levels. In order to
understand these variations, we analysed the relevance of these
semantic features for the representation of a given topic. For this
reason, we computed the entropy difference values between the
training and test datasets for each topic as introduced in Section 5.
In order to assess the relevance of a semantic feature type to
the performance of a topic classifier, we analysed these metrics by
considering the following cases:
1. Measuring entity dispersion (Entity Entropy)Since this metric
captures only the entity dispersion in topics, we correlated it
against topic classifiers build on BoE features;

2. Measuring class dispersion (Class Entropy, EntityClass En-
tropy)In this case we took the topic classifiers trained using
Cls features;

3. Measuring category dispersion (Category Entropy, Entity
Category Entropy)In this case we considered the topic classifiers built using the Cat features; and

4. Measuring property dispersion (Property Entropy, Entity
Property Entropy, ClassProperty Entropy, and CategoryProperty
Entropy)we considered the topic classifiers using P features.
Fig. 6 presents the Pearson correlation values obtained for each
topic. The correlation was calculated between the entity difference
scores and the performance of the cross-source (DB+FB+TW) and
single-source (TW(dbKS + fbKS)) classifiers in terms of F1 measure
obtained using 80% of TW data for training (in addition to the KS
data), and 20% TW data for test.

A positive correlation indicates that the performance increases
as the entropy difference decreases (the distributions are more
similar); while a negative correlation indicates that the performance increases as the divergence increases (the distributions are
less similar).
These figures show that in the cross-source (DB+FB+TW) sce-
nario, the EntityProperty Entropy yields the best correlation scores,
over 70% in two out of three topics. When looking at the values obtained for Class Entropy, Category Entropy, Property Entropy and Entity Entropy measures, we observe, that the Class Entropy showed

A. Varga et al. / Web Semantics: Science, Services and Agents on the World Wide Web 26 (2014) 3657

Fig. 6. Pearson correlation values between the entropy difference measures and the performance of the DB + FB cross-source (left), and TW (dbKS + fbKS) single-source
(right) topic classifiers.

the highest correlation values with the performance of the crosssource topic classifiers. For the DisAcc and War these values were
higher than 54%, however, for the Cri topic the correlation values
were 11%. When examining the class dispersion measures, we see
that the EntityClass Entropy showed higher correlation than Class
Entropy. In the case of the category dispersion values, for some topics (e.g. DisAcc) the EntityCategory Entropy was found to be better,
while for others (e.g. War) the Category Entropy was more benefi-
cial. Moreover, among the property dispersion values the Entity
Property Entropy values showed the highest correlation values.
Considering the results obtained for the single-source TC
(TW(dbKS + fbKS)) case, the ClassProperty Entropy yields the
best correlation value, over 60% for all three topics. Among the
Class Entropy, Category Entropy, Property Entropy and Entity Entropy
measures, however, the Property Entropy values were found to be
the best. As opposed to the cross-source case, among the class
dispersion measures, the Category Entropy values were higher
than the EntityClass Entropy values. For the category dispersion
measures, the Category Entropy values were higher than the
EntityCategory Entropy values in two out of three topics. These
results indicate that in the single-source case analysing a single
semantic feature (e.g. P, Cls or Cat) can provide a good estimate
of the performance of the topic classifier. In the case of the
cross-source scenario the representation of the topics seems to
be more complex, requiring the modelling of the entropy of two
semantic features (in our case in the form of conditional entropy
values). Nonetheless, among the property dispersion values, the
best results were obtained by the ClassProperty Entropy values.

We also compared these results with the content-based
similarity measures studied in our previous work [14]. That is,
we computed the ( 2)1 measure between the training and test
datasets for the DB + FB + TW and TW(dbKS + fbKS) classifiers
using BoW and BoE features, and correlated these values with
the performance of these classifiers. According to these results, in
the single-source case the best correlation values obtained were:
21% (BoE) for DisAcc, 58% (BoW) for Cri, and 23% (BoE) for War;
while in the cross-source case, these values were 14% (BoW) for
DisAcc, 45% (BoE) for Cri, and 20% (BoE) for War. As we observe,
our novel entropy based similarity measures (EntityProperty
Entropy for cross-source TC and ClassProperty Entropy for singlesource TC) achieve better correlation with the performance of the
topic classifier, showing the usefulness of incorporating semantic
features from KSs for enhancing the representation of a topic.

Given the above observations, our general findings about the

entropy-based measures are as follows:
1. The performance of a topic classifier can be accurately assessed
following the proposed entropy-based measures. These measures when applied over a particular Topics concept graphs
generated from multiple linked KSs, outperform previous content based similarity measures derived from the sole text con-
tent.

2. The usefulness of these entropy based measures varies among
different topics and TC scenarios. However, the property-based
dispersion measures achieved best correlation values in both
single-source and cross-source TC scenarios.30

9. Discussion and future directions

Our three-stage approach for topic classification analysis of
microposts functions by (i) context modelling; (ii) topic classification
and (iii) topic similarity analysis.

We now discuss the issues and findings from each stage.

9.1. Context modelling

The presented semantic meta-graphs (both resource meta-graph
and category meta-graph) are capable of providing contextual
information about concepts in short text. Our method for TC makes
use of various semantic features that are constructed from these
semantic meta-graphs. By extracting the named entities we were
able to enhance the lexical feature space of a topic classifier
with additional contextual information about these concepts. In
addition, our approach takes into account the information about
concepts (e.g. resource type-hierarchies, resource properties)
present in multiple semantic concept graphs of multiple linked
KSs.

30 We also mention here that the inconsistencies for the entropy values (achieving
both positive and negative correlations for a given entropy measure) may be the
result of many different factors, such as the noisy lexical nature of Microposts or
the distributional differences between the KS and TW datasets in term of entities.
In order to understand these variations, a more in-depth analysis would need to be
conducted, which we aim to investigate in the future.

The current framework employed two large coverage LOD KSs
for demonstrating the usefulness of structured data in the TC
task. However, LOD contains many other KSs interlinked with
DBpedia, such as Geonames31 or MusicBrainz.32 A new LOD KS can
easily be integrated into the current framework, by exploiting the
data (if available) for training a topic classifier, and the semantic
information present in the KSs ontology as additional semantic
features.

For other KSs, which are not part of the LOD cloud (e.g. Wiki-
data33), the proposed framework could still be applied provided
that a mapping between the DBpedia KS and the newly explored KS
exists. A possible future direction could be to utilise the data from
DBpedia, and derive contextual information about entities from the
semantic meta-graph of the new KS.

One of the main factors which influence the performance of our
approach, is the performance of the named entity recogniser (NER)
used to extract the named entities from short text messages. In
this paper we employed one of the most popular entity recognisers
(OpenCalais and Zemanta) for this purpose. Although there have
been several NER available [48] for extracting entities from textual
data, these approaches were built on newswire corpora, and
therefore to date it is not well understood which provides the best
performance on Microposts. Our future work will thus concentrate
in evaluating our framework using other NERs [51].

A second factor which has some drawback to the performance
of our approach is the incompleteness and the inconsistencies within
the KSs. For e.g. in Freebase the fbOnt:/crime/crime_accuser class is
derived from a very generic fbOnt:/common/topic class, while another related class type fbOnt:/crime/convicted_criminal extends
the fbOnt:/people/person class. In the case of the category structure of Wikipedia, we also note that the category tree is not a strict
taxonomy and does not always contain an is-a relationship [8].
Given that for both semantic concept graphs we applied concept
generalisation strategies, this mismatch can affect the generalisation of the patterns learned by our topic classifier, in that entities
which should be considered together might belong to different entity types. One possible solution to overcome this problem could
be to perform a cross-consistency validation, by investigating the
overlapping properties between the entities assigned to the same
entity classes, and consider the most likely entity classes [52].

9.2. Topic classification

The described method for topic classification uses supervised
SVM machine learning models to detect the topic of Microposts.
These models make use of the lexical (BoW) and semantic features
extracted from different semantic meta-graphs.

Given the vocabulary differences between KSs and Tweets,
one of the challenges faced by these models is the frequent
usage of grammatically incorrect English in Microposts. Due to
the restricted size of short messages, entities such as country
names (e.g. nkorea) are often abbreviated, as in the following
Tweet: nkorea prepared nuclear weapons holy war south official tells
state media usa. These irregularities mean that current annotation
services (including OpenCalais API) will ignore these entities, and
therefore no semantic information will be exploited for these
entities by the TC system. A possible solution to address these
challenges is to apply lexical normalisers especially developed for
Tweets [53] to normalise these words to standard English terms.

In addition, these methods model the content of text using
simple 1-gram (unigram) features. A possible extension of our

31 http://www.geonames.org.
32 http://musicbrainz.org.
33 http://www.wikidata.org.

approach could be to incorporate other n-gram features into these
models also, for e.g. 2-grams or a combination of 1-grams with
2-grams [54].

Moreover, when building the cross-source topic classifiers,
our models still require a large number of annotated Tweets to
outperform the single-source Twitter models. Previous research
on cross-domain (cross-source) learning has also shown that
outperforming the target (Twitter) classifier is extremely difficult
for many text classification tasks [55,15]. In order to further
increase the effectiveness and robustness of the current model,
our future work in this direction will thus focus on investigating
unsupervised multi-source adaptation models which require less
annotation from Twitter [56].

9.3. Topic similarity analysis

The examined entropy-based measures make use of the enhanced representation of topics exploiting contextual information
from semantic concept graphs about concepts from linked KSs. This
new representation led us to induce a new semantic feature space
for a topic consisting of semantic features extracted from the semantic meta-graphs of multiple linked KSs. Our results on both
single-source and cross-source scenarios show that this new semantic representation can be useful for providing a good estimate
on the performance of a TC, achieving correlation values over 60%
on the single-source scenario and over 70% on the cross-source sce-
nario.

In contrast to our previous work using content-based similarity measures [14] for topic similarity, we also showed an improvement in correlation values. These results provided further evidence
of the benefit of exploiting the information from KSs for the representation of a topic. Considering, however, that our entropy-based
measures also depend on the performance of a NER at hand, a
promising future direction of this research could be to propose
measures that combine the contribution of both content-based
lexical similarity and entropy-based similarity measures (e.g. as
in [57]).

10. Conclusion

The real-time classification of Tweets is important since they
act as social sensors revealing emerging events occurring in the
world. In this work we investigated the use of semantic concept
graphs of linked knowledge sources for topic classification of social
media posts. We demonstrated the feasibility of this approach
by implementing classification models that make use of semantic
graph structures in multiple knowledge sources (DBpedia and
Freebase). In particular, we introduced and evaluated various
semantic features derived from two distinct concept graphs
(resource meta-graph and category meta-graph) of these KSs, and
showed that they can help to build accurate topic classifiers of
Tweets.

By exploring the research question How does the performance of
a topic classifier vary using different concept graphs?, we found that
although both semantic concept graphs contain useful information
for TC of Tweets, the best overall performance was achieved by the
features derived from the resource meta-graph. More importantly,
for both concept graphs, we obtained a significant improvement
over previous approaches using only lexical features derived from
the single Twitter dataset content.

Through addressing the question Are there differences in the roles
(generalisation patterns) of the concept graphs in the different topics
and TC scenarios?, we compared the usefulness of the semantic
features for two different scenarios: the cross-source scenario
utilising KS data and the single-source scenario utilising only
Twitter data. Our results in this respect revealed different roles

A. Varga et al. / Web Semantics: Science, Services and Agents on the World Wide Web 26 (2014) 3657

(generalisation patterns) for the features derived from the two
concept graphs. In particular, we found that some features from
the category meta-graph were better used to encode the specificity
of a topic, achieving the best performance in the single-source
case, however, when considering the cross-source scenario other
features derived from the resource meta-graph were found to be
better. Nonetheless, despite the different roles of the features, our
topic classifier exploiting multiple linked KSs achieved significant
results over the baseline models.

These insights have provoked our final question Can we predict
the performance of a topic classifier? To address this question,
we introduced and evaluated various entropy-based measures
defined over these semantic concept graphs and showed that the
performance of a topic classifier can be predicted with reasonably
high accuracy using the property dispersion entropy measures.
Further, we showed a significant improvement over previous
content-based lexical similarity measures proposed for TC.

Overall, our approach demonstrated that semantic meta-graphs
derived from linked KSs: (i) provide useful semantic features
helpful in accurately detecting topics in Microposts (ii) can be used
as a measure for predicting the accuracy of a topic classifier.

Acknowledgement

The authors would like to express their gratitude to Aba-Sah

Dadzie for proofreading this paper.
