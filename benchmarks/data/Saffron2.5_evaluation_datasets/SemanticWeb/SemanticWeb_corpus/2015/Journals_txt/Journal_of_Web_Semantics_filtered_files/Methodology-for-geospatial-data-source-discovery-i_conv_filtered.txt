Web Semantics: Science, Services and Agents on the World Wide Web 32 (2015) 115

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

journal homepage: www.elsevier.com/locate/websem

Methodology for geospatial data source discovery in ontology-driven
geo-information integration architectures
Milos Bogdanovic, Aleksandar Stanimirovic, Leonid Stoimenov

Computer Science Department, Faculty of Electronic Engineering in Nis, University of Nis, Aleksandra Medvedeva 14, 18000 Nis, Serbia

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 21 January 2014
Received in revised form
13 July 2014
Accepted 23 January 2015
Available online 4 February 2015

Keywords:
Geo-information
Discovery
Ontology
Geoportal
Usability

Due to advances in information, communication and sensing technologies, the amount of generated
geospatial information is constantly growing. Since geospatial information is generated and made
available over the Internet by different stakeholders, heterogeneity of geospatial data and geospatial data
sources becomes inevitable. This heterogeneity of globally available geospatial data sources introduces
great challenges for individuals who are trying to discover and assemble geospatial data from distributed
geospatial data sources. From the standpoint of individuals who do not belong to Geo-Information
System (GIS) realm but belong to a group of geoportal users group, the process of discovering and
accessing heterogeneous geospatial data has proven to be a difficult one to govern. Since geoportals are
foreseen as single points of discovery and access to geo-information, geoportal users expect geoportal to
provide them with a mechanism to easily find (discover) what they are searching for, using their own
language. Such mechanism would significantly improve the usability of a geoportal and user satisfaction.
The implementation of such mechanism highly depends on the infrastructure a geoportal relies onan
interoperable geo-information dissemination environment.

To enhance discoverability of geospatial data and lay the knowledge foundation that can be used for
geoportal usability improvement, scientists and engineers have developed interoperable geoinformation
dissemination environments based on the following approaches: syntactic standardization and semantic
annotation of Web-accessible geo-information sources, and ontology-driven geoinformation integration.
Despite these approaches enhance discovery of heterogeneous and distributed geospatial data sources,
there are still some issues which should be addressed to make geospatial data sources fully discoverable.
As an example, in most cases geoportal users are not provided with an explicit description of the meaning
of geospatial resources or may not know what keywords they should use to discover appropriate geo-
information.

Given these challenges, we have defined a novel methodology used for geoportal usability im-
provement. Our methodology is foreseen to be used within geoportals relying on ontology-driven geoinformation integration architectures. An approach implemented within this methodology utilizes terms
extracted from a natural language description of geo-information, defined by the end users. User-defined
description is disambiguated through means of a combination of unsupervised word sense disambiguation methods. Once disambiguated, this description is matched with the sense of the (domain/local) ontology concept names. The matching process is performed through semantic similarity measurement
between disambiguated user-defined description and the sense of the (domain/local) ontology
concepts.

Our methodology simplifies geospatial data discovery and can be easily implemented because it
uses ontological components of the underlying architectures in their original form. The methodology
we describe in this paper will be discussed in the context of similar prominent solutions. Also, this
paper will present a prototype which will demonstrate the applicability of the proposed methodology.
The implemented prototype is a stand-alone desktop application, which uses two resources as input:
userdefined geo-information description and (domain/local) ontologies developed using Web Ontology
Language (OWL). We will provide an overview of benefits over approaches that have been previously used
for geospatial data discovery and offer guidelines for future improvement and development.

 2015 Elsevier B.V. All rights reserved.

 Corresponding author.

http://dx.doi.org/10.1016/j.websem.2015.01.002
1570-8268/ 2015 Elsevier B.V. All rights reserved.

E-mail address: milos.bogdanovic@elfak.ni.ac.rs (M. Bogdanovic).

M. Bogdanovic et al. / Web Semantics: Science, Services and Agents on the World Wide Web 32 (2015) 115

1. Introduction

Because of the advances in information, communication and
sensing technologies, we are witnessing a constant growth in
the amount of globally available geospatial
information. This
growth is driven by a necessity of different stakeholders (citizens,
public institutions, scientists) to share information. Since different
stakeholders generate geospatial information simultaneously and
make it available over the Internet, the diversity of the geospatial
data and geospatial data sources becomes inevitable. The diversity
introduced in this way poses great challenges for individuals
who are trying to discover and assemble geospatial data from
heterogeneous and distributed geospatial data sources.

Since the emergence of (national) spatial data infrastructures
((N)SDI) [1], the problem of discovering and accessing geospatial
data assembled from heterogeneous and distributed geospatial
data sources gains importance. As access is foreseen as a central
component in an (N)SDI, significant effort has been put into the
development of geoportalsa single points of discovery and access
to information within (N)SDI. The primary objective of geoportal
is rather simple: among all referenced data (services, geospatial
layers, documents, etc.), geoportal users need a mechanism to
easily find (discover) what they are searching forusing their own
words, their own language [2,3]. Discovery process should include
both data description (metadata) and content. However, the
discovery process details hidden behind these sentences are much
more complex. Hence, geoportal usability issues emerge [4,5].

Recent geoportal research and development report usability issues from the standpoint of individuals who do not belong to Geographic Information System (GIS) world, also referred to as non
GIS professionals [4]. As stated in [2], non professionals require
rapid performance, good background information, and simple but
elegant GUI. In case of geospatial data discovery, this request has
proven to be a difficult one to achieve using current geoportal ar-
chitecture. Contemporary geoportals rely on the usage of metadata
catalogs (usually the OGC standard CSW (Catalog Service)) [69]
which results in their inability to: obtain relevance percentage of
the returned results, search with approximation of the spelling,
classify the result using keywords or analyze relationships between words used for geospatial data discovery [2]. The described
state inspired the research in this paper. Our research addresses a
part of these problems by presenting a novel geospatial data discovery methodology which can be effectively used to solve some
of the geoportal usability issues. In particular, the implementation of our methodology enables users to discover heterogeneous
geospatial data source by simply providing a natural language of
geo-information they are interested in. Our research started with
an analysis of the geo-information dissemination infrastructures
which provide the ability to resolve geospatial data source het-
erogeneity. Geoportal is foreseen as a front end of these infras-
tructures, thus the methodology we propose enhances geoportal
usability by simplifying the discovery of geospatial data sources
within these infrastructures.

Over the years, scientists and engineers have struggled to develop an interoperable geo-information dissemination environment by taking two seemingly different approaches: syntactic
standardization and semantic annotation of Web-accessible geoinformation sources [1012], and the development of ontologydriven geo-information integration architectures [13,14].

As concerns syntactic standardization, probably the most
prominent contribution was given by Open Geospatial Consortium (OGC) in the form of standards the geo-information Web
services and data structures [1518]. Research community devoted lots of attention to enhancing geospatial data source discovery in architectures relying on these standards through means
of semantic annotation of geospatial data and Web services

[19,20,14]. Even in cases where ontologies are used for semantic annotation, recent researches like [21] have demonstrated that
these approaches are still highly dependent of transformation between UDDI [22,23] and languages used for ontology development
and can suffer from restricted semantic reasoning capabilities. If
geoportals would rely solely on this type of architecture, these
characteristics indicate that geoportals would suffer from reduced
geospatial data source discovery capabilities. It is our opinion that
a solution for these shortcomings can be found among ontologydriven geo-information integration architectures [24].

Ontology-driven geo-information integration architectures provide powerful semantic reasoning capabilities and utilize ontologies for the discovery and retrieval of geo-information
[25,14], whereas the process of geo-information retrieval utilizes
connections (mappings) between ontologies and geo-information
sources [2629]. This form of geoinformation retrieval can be also
observed as a part of ontology-based data access (OBDA) paradigm
that tackles the problem of accessing data sources with a complex
structure. Geoportals relying on these architectures, e.g. on architectures relying on OBDA, could benefit in terms of their usability by taking advantage of powerful discovery mechanisms these
architectures proclaim. However, there still seems to be a gap between the way geoportal users (e.g. non GIS professionals) may
perceive the underlying geospatial data, and the way this data is
conceptualized from the standpoint of GIS professional developing the semantic description (e.g. ontology) of the same data. This
can lead to a situation in which users may not know what keywords
they should use to discover appropriate geo-information. The main
contribution of the methodology we propose in this paper is to fill
this gap by allowing users to discover geospatial data sources using their own words, which will in turn lead to geoportal usability improvement. Our proposal is based on a number of best of
the breed existing mechanisms combined to form a novel methodology used for geoportal usability improvement. The methodology described in this paper utilizes terms extracted from a natural
language description of geo-information, disambiguates the terms
through means of a combination of unsupervised word sense disambiguation methods and matches their sense with the sense of
the ontology concept names. The proposal we present in this paper can be equally applied on both domain and local ontologies.
We consider local ontologies as a combination of domain ontology
and task ontology in order to fulfill the specific purpose of an application [30]. Our methodology simplifies geospatial data discovery
and can be easily implemented because it uses ontological components of the underlying architectures in their original form. It does
not require the existence of semantic annotation of geospatial data
source interface and can be implemented as a separate engine/Web
service.

The rest of this paper is organized as follows. Section 2 discusses
related work involved in semantic annotation and integration
of geospatial information. In Section 3, related work considering
word sense disambiguation (WSD) is discussed. In particular,
Section 3 discusses unsupervised WSD methods based on the use
of computational lexicons. Section 4 describes the methodology
for enhancing discovery of geospatial data sources in ontologydriven geo-information integration architectures. The details of the
prototype implementation and several evaluation results are given
in Section 5. Section 6 concludes with an outlook to future work.

2. Related work

Contemporary Geographic Information Systems (GISs) rely on
data from distributed geo-information sources to provide users
with a single uniform access point over the refined data, whereas
the single access point is commonly implemented in the form of
a geoportal [2]. While searching for the data they are interested

in, GIS users expect to be provided with search results in the form
of homogeneous data set(s) shorn of details regarding the data
origin. This introduces a necessity to perform integration of data
and computation resources belonging to several autonomous systems [31], which leads to the development of a federated geoinformation system [32]. To be able to integrate data originating
from distributed and heterogeneous geospatial data sources, federated GISs need to overcome the problem of semantic heterogeneity between different geospatial data sources [13,14]. Within
different (geo-)information integration architectures and federated (geo-)information systems, semantic heterogeneity problems
are most commonly solved through means of ontologies [33,14].

Regardless of the approach used for the development, if a
(geo-)information integration architectures is to provide a single access point used for data discovery, it has to be capable
of solving two additional problems: develop mappings between
(global/local) ontologies and information sources [34,35], and define discoverable Web interfaces which represent information
source access points [36,21]. If distributed geo-information sources
can be discovered by utilizing their Web interfaces and integrated
through means of their semantic description (mostly ontologies),
then mappings between ontologies and information sources can
be used to retrieve integrated data. If a geoportal would be implemented as a front-end application of an architecture that fulfils these prerequisites, in that case a geoportal would be capable
of providing users with integrated data originating from heterogeneous sources. It is our opinion that this ability would significantly
improve the usability of a geoportal.

Although problems encountered in the process of developing mappings between (global/local) ontologies and information
sources and defining discoverable geo-information source Web
interfaces belong to the same scope, they have mostly been investigated independently: the former within the development
of ontology-to-relational database (RDB) mapping methodologies,
ontology matching and integration [34,37,38,35,39] and the latter within the development of a semantic description of geospatial Web services and Web service discovery systems [25,39,12,21].
However, a majority of proposals from both groups is missing explicit support for geospatial data, or at least an empirical study
which confirms that a proposal can be equally applied within
geospatial domain. Another common characteristic of these proposals is lack of an explicit definition of a discoverable Web
geospatial service interface used to access the mapped data source.
Both advantages and disadvantages introduced by any of solution
proposals for each of the aforementioned problems are directly reflected onto the mechanism that can be implemented for information discovery. Thus, both advantages and disadvantages directly
influence the usability of a geoportal. Since geoportal usability improvement is an overall goal of the methodology described in this
paper, we will describe the reasons why we have decided to use
geo-information integration architecture over similar proposals by
briefly describing the shortcomings of similar proposals.

Previously reported approaches have proven that semantic
annotation of geospatial information and services can be utilized
as a mean for overcoming semantic heterogeneity problems
and enabling geospatial data source discovery [25,39,12]. A
number of proposals on how to enrich geospatial Web services
with semantics using ontologies have been published [10,
11,40]. Mostly, these proposals perform semantic enrichment
of geospatial Web services by generating explicit relationship
between the data schema and domain ontologies. A majority of
domain ontologies is modeled using formalized languages like
Web Service Modeling Ontology (WSMO) or OWL-S [12,41,42]. In
the GIS domain, significant effort has been put into semantically
annotating OGC Web services by means of linking OGC capabilities
documents to ontologies [19]. In addition, OGC released a standard

used to support representing and querying geospatial data on
the Semantic WebOGC GeoSPARQL [43]. This standard defines a
vocabulary for representing geospatial data in RDF. It defines an
extension to the SPARQL query language for processing geospatial
data. Although these proposals represent a significant research
contribution, there seems to be a lack of discovery systems
developed on the bases of these research results so the usability
of this work is yet to be discovered.

Other than utilizing Web service ontologies, the development
of discovery systems in GIS domain has taken a different path
recently. In a majority of implementations, reported systems discover OGC services through UDDI interface [44] using service catalogs [45]. Since first implementations had to support for semantic
querying, service catalogs have grown into semantically-enhanced
service registries. Such registries use mappings of OWL, OWL-S and
WSMO constructs to UDDI data structures [46,47,36,48]. Although
these services enhance the capability to discover geospatial Web
services, they also expose some weaknesses. Reported systems use
different standards (OGC capabilities XML document, OWL, OWL-
S, WSMO and UDDI) within different architectural tiers to express
Web service characteristics, resulting with them being highly dependent on transformation between these standards. This makes
semantic reasoning over the entire architecture very hard to im-
plement.

Also, there are few systems, like the one proposed by Tian and
Huang [21], which perform service matchmaking through semantic reasoning. Even if it exists, service matchmaking through semantic reasoning is restricted to reasoning over domain ontology.
For example, Tian and Huang [21] system is restricted to a custom
lightweight domain ontology. Though Tian and Huang [21] make
a step forward in service catalog development, their system does
not have the ability to use and reason over existing or third-party
developed ontology, or to become usable in architectures based on
multiple or hybrid ontology approach. Furthermore, the usage of
word sense disambiguation (WSD) methodologies to aid services
discovery, or at least the usage of computational lexicons for the
same purpose, was not found by the authors of this paper in the
reported systems. It is our opinion that WSD algorithms have the
potential to enhance service discovery by being integrated into this
process as an intermediate task. For this reason, our methodology
envisions the use of a combination of unsupervised word sense disambiguation methods for geospatial data source discovery.

3. Word sense disambiguationunsupervised methods based
on the use of computational lexicons

Word Sense Disambiguation (WSD) is considered to be one
of the core tasks in Natural Language Processing (NLP) [49]. The
aim of WSD is to assign for each word of a text the appropriate
sense(s). Algorithms used to perform WSD are classified into
supervised and unsupervised methods. A supervised algorithm
depends on labeled training data to compare information, whereas
the unsupervised method does not. Aside from this classification,
Zesch and Gurevich [50] proposed another classification of WSD
methods: path-based, information content based, gloss based, and
vector based.

A majority of WSD methods use external knowledge sources as
fundamental components to perform WSD. There is a variety of
resources used as external knowledge sources: corpora of texts,
computational lexicons, thesauri, glossaries, ontologies etc. An
external knowledge source that has been widely used in the
context of WSD is WordNet [51]. WordNet is a computational
lexicon organized over synonym sets (synsets). The latest version
of WordNet (3.1) is available online (see Appendix A) and it
contains over 155 000 terms for 117 000 synsets. Each synset
represents a structure, which contains a term (word), its class

M. Bogdanovic et al. / Web Semantics: Science, Services and Agents on the World Wide Web 32 (2015) 115

(verb, noun, adjective etc.) and connections to all semantically
related words along with a brief definition (gloss) illustrating the
use of the synset members. Semantic relations defined for a single
synset apply to all its members. Among the semantic relations,
the most frequently used ones are the following: hypernymy
(also called kind-of or isa), hyponymy (the inverse relations of
hypernymy), meronymy (also called part-of ) and holonymy (the
inverse of meronymy).

WordNet can be effectively used within a majority of unsupervised WSD methods, which introduce semantic similarity
measures used to perform word disambiguation. Usually, these
methods use semantic relations defined within WordNet to determine the similarity between terms (synsets). For example, pathbased methods measure the length of the path between two
words in a graph-like structure and WordNet can be used as a resource which supplies the paths. A number of path-based meth-
ods, such as Rada et al. [52]; Leacock and Chodorow [53]; Wu and
Palmer [54], have successfully utilized WordNet as a graph-like
structure to perform word similarity measurement. Furthermore,
information-based methods use tree structure (WordNet) to measure how much information the two words share, by measuring
the number of nodes in the tree structure that the two words have
in common. Information-based methods reported in [55], [78] and
[79] modify this idea to define similarity measures which indicate
the probability of a word appearing in a corpus. WSD methods,
which further exploit semantic relationships contained in Word-
Net, can be found among gloss-based and vector-based methods.
As a starting point, both gloss-based and vector-based methods often use an approach defined by Lesk (1986) that relies on word
definition usage. This approach determines the similarity of all the
words in the two word definitions and measures the similarity by
overlapping the two word definitions. This approach was successfully adapted by Patwardhan et al. [56], Patwardhan [57] and Zesch
and Gurevich [50] to create approaches which make a better use
of semantic relations (synonym, hypernym, hyponym, holonym,
meronym, troponym, and attribute) defined within WordNet.

4. Geospatial data source discovery approach

The approach we have developed is focused on geoportals that
rely on federated geo-information systems as their spatial data in-
frastructure. In particular, federated geo-information systems utilized in our methodology resolve semantic heterogeneity through
means of meta-data, used to describe geospatial data sources. Although it can be adapted for different meta-data, our approach was
intended to be used within federated GISs which utilize ontological
components, e.g. domain/local ontologies, for geospatial data integration purposes [14]. In such systems, domain/local ontology elements are usually matched against geospatial data sources through
means of different mapping files or schema transformations
[29,21]. Thus, geospatial data sources become discoverable at the
level of ontology elements. In particular, our approach is used to
determine an appropriate sense of a user-defined geospatial data
search description, and match this description against global/local
ontology concepts. Fig. 1 illustrates a general architecture of a system in which our approach can be implemented.
The main facilities of the system are described as follows:
 Natural language termsa set of terms extracted from a natural
language description of geo-information, given by a user.
 Federated Geographic Information Systems (Federated GISs)
GISs which rely on data from distributed and heterogeneous
geo-information sources; these systems utilize meta-data
to overcome semantic heterogeneity problems and enable
geospatial data source discovery.

 Meta-datadata used to describe the content of different
geospatial data sources. This data can be stored in different
forms: semantic annotations of geospatial data and services,
ontological components (local/global ontologies), UDDI docu-
ments, OGC capabilities documents, etc. Each federated GIS
maintains its meta-data within a central meta-data repository.
 Meta-data repositorya repository capable of storing different
forms of meta-data for each of the federated GISs; it is an
optional component, e.g. it can be implemented if federated
GISs use hybrid ontology approach to overcome semantic
heterogeneity problems, or omitted if each part of federated GIS
stores meta-data locally.
 Computational lexiconstructured machine-readable lexicon
of terms; it is used as a knowledge source to associate the most
appropriate senses with terms (words) given by the user.
 Geospatial Data Source Discovery Enginea stand-alone geospatial data source discovery module. It implements the discovery
process by matching federated GIS meta-data elements with
user-defined geospatial data description; for this purpose, discovery engine utilizes computational lexicons as knowledge
sources.
According to the aforementioned focus of our approach, the
core of the geospatial data source discovery is a matching process,
based on a similarity measurement. The problem of similarity
measurement among geospatial concepts has been previously
studied in the geospatial domain [58,59]. In the methodology we
propose, similarity measurement process is performed between
terms extracted from the user-defined geospatial data description
and global/local ontology concepts. The matching process is
performed by Geospatial Data Source Discovery Engine and starts
with extracting terms from user description. After stripping the
extracted terms from suffixes, Geospatial Data Source Discovery
Engine will load a global/local ontology of a federated GIS, extract
ontology concepts and determine similarity between the extracted
terms and the ontology concepts. The similarity measurement is
based on the use of a combination of unsupervised word sense
disambiguation methods, which utilize WordNet computational
lexicon. The global/local ontology concepts, whose similarity with
user-defined terms exceeds a predefined threshold value, will be
added to a result set.

In the rest of this section, we will go into the details of the approach we have defined for the purpose of geospatial data source
discovery. Our approach will be presented in the form of an algorithm which uses user-defined geospatial data description as its
input. As the output, this algorithm will determine a set of (do-
main/local) ontology concepts mapped to geospatial data sources.
Step 1: Disambiguate user-defined description of geospatial data
The algorithm starts with utilizing natural language description
of geo-information. This description, defined by the end users, is
tokenized into a list of words through means of a regular expression (Fig. 2a). Afterwards, the correct part of speech (noun, verb,
pronoun or adverb) is identified for each of the words by utilizing
WordNet computational lexicon (Fig. 2b). The identification process is based on the usage of WordNet library functions, starting
with findtheinfo method as a primary search function for WordNet database. Also, the identification process includes the stripping
of suffixes from words which we have implemented according to
algorithm proposed in [60]. At the end of step 1, words identified as
nouns are extracted to a separate term set, which will be referred
to as input term set.
Step 2: Expand the input term set through means of WordNet
computational lexicon

Among the semantic relations defined in WordNet,

this
algorithm utilizes synonymy, hypernymy and hyponymy semantic

Fig. 1. The environment used for geospatial data source discovery.

Fig. 2.

(a) Tokenizing input description of geo-information. (b) Identifying words by utilizing WordNet.

relations. For each term from the input term set, a new term set
is created and it consists of the terms synonyms, hypernyms and
hyponyms (Fig. 3). Each of the newly created term sets will be
referred to as expanded term set.
Step 3: Repeat steps 47 for each of the expanded term sets

Step 4: Create a term set which contains the names of
(domain/local) ontology concepts

This step can be equally applied to both domain and local ontologies which are mapped to geospatial data sources. Regardless
of its position in the geo-information integration architecture, the

M. Bogdanovic et al. / Web Semantics: Science, Services and Agents on the World Wide Web 32 (2015) 115

Fig. 3. Expanding the input term set through means of WordNet computational lexicon.

Fig. 4. Creating and caching a concept term set.

ontology is loaded, and traversed for the purpose of extracting concept names. Each of the concept names is added to a new term set
which will be referred to as concept term set (Fig. 4). The result of
this step is cached e.g. the concept term set is created during the
first iteration and reused in the following ones.
Step 5: Initialize a result container

As previously stated, the output of the algorithm is a set of (do-
main/local) ontology concepts mapped to geospatial data sources.
Therefore, each item within the result container represents a structure which consists of two elements:

1. an ontology concept whose similarity to expanded term set

terms is being measured and

2. a dictionary of semantic similarity measurement resultseach
item in the dictionary is a keyvalue pair, where key represents
a term from the expanded term set while the value represents
a similarity measured between the term and the ontology
concept (Fig. 5).

Step 6: Semantic similarity measurement

For each pair of terms TEX and TC , TEX being a term from the
expanded term set and TC being a term from the concept term set for

Fig. 5. An example of a dictionary created for an ontology concept named Road.

the current iteration, perform the geospatial data source discovery
process by repeating the following steps:
1. Measure a similarity between the terms TEX and TC.

a. Compute edit distance similarity for terms TEX and TC.

Edit distance similarity is measured according to Levenshtein distance [61]. The Levenshtein distance calculates the
least number of edit (insert, delete) operations that are necessary to modify one string to obtain another string. Edit
distance similarity is given by dist(length(TEX ), length(TC ))
where
distTEX ,TC

) = 0

, jTC

otherwise.


(iTEX

, jTC
Max(iTEX

, jTC

distTEX ,TC

), when  Min(iTEX
) + 1
(iTEX  1, jTC
, jTC  1) + 1
distTEX ,TC
(iTEX
(iTEX  1, jTC  1)
distTEX ,TC
+ 1(TEX[iTEX
]=TC[jTC

1]),

Min

b. Compute semantic similarity sim(TEX , TC ) between the terms
TEX and TC according to the algorithm described in [54]. Wu
and Palmer [54] approach measures the path length to the
root node from the least common subsumer (LCS) of the
two concepts compared. The least common subsume can be
interpreted as a concept in a lexical taxonomy (in this case
WordNet), which has the shortest path length from the two
concepts compared. The measured distance between the root
node and the least common subsumer of the two concepts
is scaled by the sum of the path lengths from the individual
concepts to the root. According to this algorithm, sim(TEX , TC )
is determined by considering the depths of the TEX and TC
synsets in the WordNet computational lexicon, along with
the depth of their least common subsumer (LCS). The LCS
of synsets TEX and TC is the most specific synset that is an
ancestor of both synset TEX and TC.

sim(TEX , TC ) = 2  depth(LCSTEX ,TC
depth(TEX ) + depth(TC )

c. Determine final semantic similarity according to the follow-

ing equation:
semsim(TEX , TC ) = Max(dist(length(TEX ), length(TC )),
sim(TEX , TC )).

2. For this method a fixed constant has to be defined as a similarity
threshold, usually 0.8 or greater. If the measured semantic
similarity exceeds the threshold value, populate the result
container in the following way:
a. If the ontology concept C, which corresponds to the term TC,
does not exist in the result container, create an item in the
result container as defined in step 5.

b. Create a dictionary item as a keyvalue pair, where the
key represents the term TEX while the value represents
sim(TEX , TC ), and add it to the dictionary which corresponds
to the ontology concept C (Fig. 5).

Step 7: Ordering the results

Results will be ordered according to the following criteria:

a. Precedence will be given to ontology concept whose name was
determined to be similar to the largest number of terms from
the input set.

b. If several ontology concepts were determined to be similar
to the same number of terms from the expanded term sets,
precedence will be given to ontology concept which has the
highest average semantic similarity value, where this value is
computed for each concept as an average of all outputs from
step 6c.

5. Evaluation

The solution presented in this paper is implemented as a part of
our GeoNis framework. GeoNis is a framework for interoperability
of GIS applications that have to provide infrastructure for data
interchange in the local community environment [62]. The GeoNis
framework was developed to perform the intelligent, on-demand
integration of
information from multiple heterogeneous GIS
(spatial and geographic) and nonspatial (thematic) data sources,
which consist of local community services and offices that own
geodata in some format [63]. Semantic interoperability in GeoNis,
resolved by Semantic Mediator [64], is the ability of sharing
geospatial information at the application level, without knowing
or, understanding terminology of other systems.

In GeoNis Semantic Mediator we propose a semantic based
integration approach that uses multiple ontologies, instead of an
integrated view [65]. Our Semantic Mediator uses hybrid ontology
approach. Our solution is to formally specify the meaning of the
terminology of each Geoinformation Community (GIC) (i.e. local
service or office) using local ontologies and to define a translation
between each GIC terminology (local ontology) and shared domain
terminology (in top-level ontology). In this context, ontologies are
virtually linked by inter-ontology relationships, which are then
used to indirectly support query processing. Semantic Mediator
provides a methodology and software support for semantic
mismatches (conflicts) resolving between terminologies. This
methodology uses the defined ontology mappings between each
community terminologies and a top-level ontology or the common
data model (reference ontology).
GeoNis ontology (local or domain) is an abstraction of domain of interest D, represented by triple O = (C, R, isa), where
C = {ci|i = 1, n} is a set of concepts, R = {ri|i = 1, n}, is a set
of binary typed roles (or relations) between concepts, and isa
is a set of inheritance relationships defined between concepts.
In an (local or top-level) ontology, inheritance relationships define a partial order over concepts and carry subset semantics.
Set of semantic relations between concepts defines semantics
of concepts and their relevance. We have defined the following
set of relations between concepts in ontology: R = {synonym,
hypernym, hyponym, meronym, T}, where T is a set of topological
relations. More details about formal definition of GeoNis ontologies are given in [66,67].

For the evaluation purposes of the proposed algorithm, GeoNis framework was extended with a software component named
Geospatial Data Source Discovery Engine (Fig. 6). As stated in its
name, this component facilitates the discovery of existing geospatial data source to GIS application users within GeoNis envi-
ronment. For these purposes, Geospatial Data Source Discovery
Engine utilizes local ontologies and domain ontology implemented
for GeoNis environment, as well as a natural language description
of geo-information defined by users (this process is described in
Section 4). During the implementation of Geospatial Data Source

M. Bogdanovic et al. / Web Semantics: Science, Services and Agents on the World Wide Web 32 (2015) 115

Fig. 6. The position of geospatial data source discovery Engine in GeoNis framework.

Discovery Engine prototype, the usage of GeoNis ontologies, implemented according to formal definitions given in [66,67], has proven
to be highly complex. Since we were performing feasibility testing,
we have decided to use a different approach, which is in accordance
with ontology standardizations efforts in geospatial domain [68].
To evaluate our research efforts we tried to implement
lightweight version of GeoNis ontology. This lightweight version of GeoNis ontology is implemented in accordance with formal
definition of GeoNis ontology, is interoperable with full geospatial ontologies and takes into account ontology standardizations
efforts in geospatial domain. Lightweight GeoNis ontology is a
rather simple ontology that defines some of the geospatial features and a number of spatial relationships between them. The
term geospatial feature in this ontology refers to any entity with
an inherently or indirectly associated spatial dimension. Expressiveness of formalization of implemented ontology is limited using

ontology OWL Lite representation language [69]. After evaluation of different geospatial ontologies, for implementation of
lightweight GeoNis ontology, we decided to reuse GeoOWL standard [68] and Geonames feature type hierarchy [70].

W3C Geospatial Incubator Group developed GeoOWL [68] as a
minimum geo-vocabulary which follows GeoRSS guidelines [71].
Lightweight GeoNis ontology imports GeoOWL as the core
ontology, thus supposing a Simple GML Geometry definition and
an easy alignment with existing GeoRSS feeds (Fig. 7). The central
part of the GeoOWL ontology [68] is a object property geo:where
which takes as its domain any OWL/RDF class that it makes sense
(after ISO 19109) to cast as a geographic feature. This property
takes as its range the abstract class _Geometry. Subclasses of
_Geometry include gml:Point, gml:Linestring, gml:Polygon, and
gml:Envelope after the corresponding GML objects. The properties
of these classes are a subset of the corresponding properties

utilizing Microsoft Windows Forms as a graphical application
programming interface (API), included as a part of Microsoft .NET
Framework 4.0 [73]. The functionalities of the implemented
prototype will be presented through a simple walkthrough which
consists of five steps. Each walkthrough step will be explained
through details considering three components: input, discovery
algorithm step(s) implemented within the current walkthrough
step, and output. In Fig. 9, user interface (UI) parts conforming
to each walkthrough step are placed in a separate frame. Frame
numbers (15) conform to walkthrough steps.

For the purpose of simplifying feasibility evaluation, discovery
example will be conducted and presented under the following
assumptions:
 User describes the data he/she is looking for as streets and rivers
in Serbia.
 First step of our algorithm (Step 1 in Section 4) has partially
been performed e.g. the description given by the user has
been tokenized into a list of words and each word has been
stripped of suffixes. For this purpose, the prototype application
uses an implementation of the Porter stemming algorithm [60]
developed by Leif Azzopardi [74]. The output is the following
list of words: {street, river, Serbia}.
 The prototype application will be given only the word street.
Thus, the discovery process will be performed on the basis of a
single term.

Walkthrough step 1 (frame 1 in Fig. 9):
 Input: word street, which was previously stripped of suffixes;
user will activate the search button within prototype application UI.
 Discovery algorithm step: a part of step 1; word street is
identified as a noun with five different descriptions in WordNet
lexicon.
 Output: word street is identified to be a term street in
WordNet lexicon.

Walkthrough step 2 (frame 2 in Fig. 9):
 Input: WordNet term (noun) street; user will activate create
term set button within prototype application UI.

Fig. 7. Geometry definition in GeoNis ontology.

defined in the GML model and schema. This represents GeoRSS
GML. Other subproperties of geo:where represent GeoRSS Simple
and include geo:Point, geo:Line, geo:Polygon, geo:Circle, and
geo:Box. These properties each take a literal list of doubles as their
range, but are equivalent in definition to (are a shorthand for)
geo:where plus the corresponding GeoRSS GML classes and their
properties. For backwards compatibility, geo:lat and geo:long are
retained as subproperties of geo:where.

GeoOWL just offers two free text tags for representing feature
types and feature relations, and it expects the deployment of
folksonomies from this tagging. In our scenario we need some
complex classification schemas. For this reason, we decided to
reuse Geonames ontology [70]. Geonames ontology provides a
rich taxonomy of feature types based in SKOS thesauri [72]. We
have defined all concept schemes from Geonames in lightweight
GeoNis ontology as subclasses of GeoNis_Feature class (Fig. 8).
Fig. 8 shows a fragment of GeoNis taxonomy presenting only the
particular subclasses that are used in examples outlined in this
paper. This design allows the alignment with Geonames database,
with more than 6.5 million features.

5.1. Feasibility testing

To evaluate the feasibility of the proposed algorithm within the
GeoNis framework, a prototype Geospatial Data Source Discovery
Engine was developed. The prototype, shown in Fig. 9, represents a
stand-alone desktop application which implements the algorithm
described in Section 4. The implementation was performed by

Fig. 8. A fragment of GeoNis taxonomy.

M. Bogdanovic et al. / Web Semantics: Science, Services and Agents on the World Wide Web 32 (2015) 115

Fig. 9. A prototype of Geospatial Data Source Discovery Engine (frames, numbered 15, conform to walkthrough steps). (For interpretation of the references to color in this
figure legend, the reader is referred to the web version of this article.)

 Discovery algorithm step: step 2; an expanded term set is
created for term street; it consists of synonyms, hypernyms
and hyponyms discovered in WordNet lexicon for the term
street.
 Output: expanded term set contains 66 terms: {artifact, whole,
thoroughfare, abstraction, entity, gathering, abstract_entity,
attribute, physical_entity, object, chance, road, street,
opportunity, physical_object, possibility, route, way,
neighborhood, state, situation, unit, artifact, social_group,
neighborhood, existence, community, being, grouping,
group, assemblage, state_of _affairs, possibleness, environment,
beingness, two-way_street, Wall_St., Quai_dOrsay, Bowery,
main_street, avenue, Downing_Street, Park_Ave., boulevard,
Park_Avenue, back_street, local_street, Broadway,
Great_White_Way, alley, alleyway, one-way_street, local_road,
side_street, Fleet_Street, high_street, mews, Wall_Street,
cross_street, Strand, Champs_Elysees, rue,

Whitehall, Pall_Mall, Lombard_Street, Harley_Street}; this term
set is shown within a list (frame 2 in Fig. 9).

Walkthrough step 3 (frame 3 in Fig. 9):
 Input: GeoNis.owl ontology; user will activate load ontology
button within prototype application UI and will be provided
with a dialog used to select the appropriate ontology from the
file system.
 Discovery algorithm step: step 4; concept term set is created by
traversing GeoNis ontology.
 Output: concept term set: {Accommodation, Cable,
Road_Feature, Substation, Taxi_Stop, Populated_Place_Feature,
Shopping, Hotel, Main_Street, Vegetation_Feature, Food,
Consumer_Connection, Area_Feature, Electric_Utility, Bus_Stop,
Hydrographic_Feature, Population_Feature, Utility_Feature,
Road, Street, Building_Feature, Semantic_Topological_Relation,
Point_Of _Interest_Feature, Administrative_Feature, Hostel,
Local_Street, GeoNis_Feature, Sight, Service}; once the term set

Fig. 10. Summarized discovery results.

is created, prototype application will report that the chosen ontology has been successfully loaded by displaying the name of
the loaded ontology, as shown in frame 3 in Fig. 9.

Walkthrough step 4 (frame 4 in Fig. 9):
 Input: expanded term set created for the term street and
concept term set created for GeoNis ontology; user will activate
perform discovery button within prototype application UI.
 Discovery algorithm step: steps 5 and 6; a result container is
initialized and semantic similarity measurement is performed
for each pair of terms from the expanded term set and
concept term set; these term sets were previously created in
walkthrough steps 2 and 3, respectively.
 Output: the result container is populated for each pair of
terms whose semantic similarity exceeds a similarity threshold,
which was in this evaluation example set to 0.7; results are
divided into the following three groups according to semantic
similarity value (column SCORE in the grid placed within frame
4 in Fig. 9):
 Group 1: semantic similarity value between 0.7 and 0.8
these pairs of terms are marked using yellow color in the
prototype application UI, as shown in frame 4 in Fig. 9.
 Group 2: semantic similarity value between 0.8 and 0.9
these pairs of terms are marked using blue color in the
prototype application UI, as shown in frame 4 in Fig. 9.
 Group 3: semantic similarity value is 0.9 or higherthese
pairs of terms are marked using red color in the prototype
application UI, as shown in frame 4 in Fig. 9.

Walkthrough step 5 (frame 5 in Fig. 9):
 Input: the result container populated in step 4; user will
activate display results in semantic tree button within prototype
application UI.
 Discovery algorithm step: step 7; discovered ontology concepts
will be ordered according to criteria defined in step 7 of the
discovery algorithm.
 Output: discovered ontology concepts are the following:
{Street, Road, Main_Street, Local_Street, Service, Shopping,
Cable, Accommodation, Food, Substation, Hostel, Hotel,
Administrative_Feature, Point_Of _Interest_Feature, Sight,
Hydrographic_Feature, Area_Feature}; each of the discovered
ontology concepts is displayed as a tree node; also, for each of
the concepts, users can traverse the semantic tree of its parent
ontology classes, as shown in frame 5 in Fig. 9.
Summarized discovery results are shown in Fig. 10. This figure displays average semantic similarity computed for each ontology concept against all terms from the expanded term set. The
number of terms whose similarity to an ontology concept exceeds
predefined threshold value of 0.7 is also shown for each of the
ontology concepts. Some of the results are rather straightforward.
As expected, ontology concept Street has the largest number of
matches and the highest average semantic similarity. Similarly, ontology concepts Main_Street and Local_Street have been highly

ranked mostly because a high level of semantic similarity was detected on the basis of edit distance similarity measurement. The
discovery of ontology concept Road reveals the good sides of the
proposed algorithm. Although edit distance similarity for this concept was quite low, the usage of path-based method for semantic
similarity measurement resulted in this concept becoming the second highest ranked concept within the analyzed ontology. The rest
of the ontology concepts have been matched against a significantly
lesser number of terms which indicates that this search should result in acquiring the data from (geo-)information sources mapped
to ontology concepts {Street, Road, Main_Street, Local_Street}.

5.2. An analysis of performances and discovery results

Besides evaluating the feasibility of the proposed algorithm
within the GeoNis framework, our proposal was also tested for the
following purposes:
 determining the quality of the discovery results;
 determining the most adequate similarity threshold value;
 estimating an overhead the algorithm might cause in the
GeoNis system.
In order to achieve these goals, the proposed algorithm was
tested against a testing term set. We have defined this term set
as a set of terms that can be used for naming spatial data feature
types. The testing term set used for the analysis was extracted
from schemas belonging to the Spatial Data Standards for Facilities,
Infrastructure, and Environment (SDSFIE) [75]. The same term set
was used for the evaluation of performances of the developed
prototype engine.

Each term belonging to testing term set was extracted as a
key part of feature type name proposed by SDSFIE standard. In
this way, a term set consisting of 37 terms has been extracted
and used as a testing term set, as shown in Table 1. Although the
term set has been extracted from an official standard, the adequacy
of the selected terms was confirmed by examining the description of feature codes in Geonames ontology [70]. This examination has shown that 81% (30 terms) appear as keywords within
feature descriptions. Since we have defined all concept schemes
from Geonames in lightweight GeoNis ontology as subclasses of
GeoNis_Feature class, we considered this term set to be adequate
for the analysis of results and performances of the algorithm we
propose.

The testing was conducted using GeoNis ontology through 37
runsone per each term from the testing term set. During each run,
an expanded term set was created for each term from the testing
term set. As described in algorithm steps 47, the similarity was
measured between each term from the expanded term set and each
GeoNis ontology concept. Similarity measurement results, varying
from 0.0 to 1.0, were divided into 10 groups whereas each group
occupies a range of values with step 0.1 between groups (0.00.1,
0.10.2..., 0.91.0).

M. Bogdanovic et al. / Web Semantics: Science, Services and Agents on the World Wide Web 32 (2015) 115

The output of all 37 runs was analyzed for the purpose of
determining the quality of the discovery results and the most
adequate similarity threshold value. The first step of the analysis
was a determination of the correct output in the form of a set
of ontology concepts expected to be found similar to a particular
term from the testing term set. The correct output was determined
for each term from the testing term set as a union of the sets of
ontology concepts defined as correct output by 3 domain ontology
experts (the authors of the paper). During the analysis, proposed
algorithm considers a term from the testing term set similar to an
ontology concept if the expanded term set, created for the observed
term, contains at least one term whose similarity value belongs to
at least one of the groups whose lower range bound value is greater
or equal to a predefined threshold value.

To determine the most adequate similarity threshold value, the
following indicators were used:
 discovery rate (DR)number of ontology concepts determined
to be similar to a particular term;
 false discovery rate (FDR)number of false discoveries among
ontology concepts determined to be similar to a particular term;
 discovery rate matching domain expert expectations (DR-
MDEE)number of ontology concepts determined to be similar
to a particular term and matching domain experts expectation
to be similar to a particular term.
These values were analyzed in the context of different similarity threshold values. The analysis results are given in Table 1. The
result analysis has shown that in cases where the similarity threshold value is set under 0.7, the average percentage of false discoveries in some cases exceeds 70%. For similarity threshold value set to
0.7 and larger, the average percentage of false discoveries is significantly lower. For example, the average percentage of false discoveries will be decreased by 25.06% if the similarity threshold value
is set to 0.8 instead of being set to 0.7. At the same time, the discovery rate matching domain expert expectations will be decreased by
only 6.85% (from 62.39% to 55.61%). If the similarity threshold value
is set to 0.9 instead of being set to 0.8, the average percentage of
false discoveries will be decreased by 59.26%. However, the discovery rate matching domain expert expectations will be decreased by
25.06% which can lead towards significant loss of relevant discovery results. Therefore, we consider that similarity threshold value
can be set to 0.8 without jeopardizing the quality of the discovery
process while lowering the false discovery rate at the same time.
Aside from the previously described result analysis, the testing
process was used to observe the time needed for the discovery
process to be performed, as shown in Table 1. The observation
was needed in order to estimate the overhead proposed algorithm
might cause in the GeoNis system. The observation was conducted
on the machine using Intel(R) Core(TM) i5-4440 CPU (3.10 GHz)
with 8 GB of RAM on Windows 8.1 64-bit operating system. The
application was considered to be a black box using 10 background
working threads for each of 37 discovery runs. The time needed
for a single run to be performed was analyzed in the context of two
indicators: the number of WordNet synsets (SSN in Table 1) and the
number of terms in the expanded terms set (ETSN in Table 1) used
within the particular run. Terms with several distinct meanings
are represented in as many distinct synsets and all synsets are
used during the discovery process. Since the proposed algorithm
determines the depth and the least common subsumer for each
synset of the term, whereas each synset has a different hierarchical
structure in the lexicon, we expected the number of used synsets
and their lexicon structure to highly influence the time needed
to perform discovery. Also, we expected the increased number
of terms in the expanded term set to negatively influence the
discovery process performances.

The expectations we envisioned can be easily identified from
the results shown in Table 1. The shortest time was needed to perform a test run for the term marina550 ms. Within the Word-
Net, this term has only one synset. Also, the expanded term set
created for this term consists of only 16 terms. On the other hand,
the longest time was needed to perform a test run for the term
transportation12 297 ms. This term has 6 synsets and the expanded term set created for this term consists of 113 terms. How-
ever, this is not the term with the largest number of synsets and
expanded term set terms. Term land has 11 synsets and the expanded term set created for this term consists of 346 terms. This
example demonstrates that the hierarchical structure in the lexicon of the used synset highly influences the algorithm perfor-
mances. The average depth of synsets within WordNet for the term
transportation is 8.3 while the average depth of synsets within
WordNet for the term land is 5.9, which resulted in discovery
process for the term transportation taking longer time to per-
form.

6. Conclusion

For the purpose of enhancing geospatial data source discov-
ery, this paper proposes a methodology used in ontology-driven
geo-information integration architectures, which implement the
retrieval of geo-information through means of connections (map-
pings) between ontologies and geo-information sources. The
methodology core is a process of matching terms extracted from
a natural language description of geo-information, defined by the
end users, with the sense of the (domain/local) ontology concepts.
The matching process utilizes a combination of unsupervised word
sense disambiguation methods, based on the use of WordNet computational lexicon. The output of the matching process is a set
of (domain/local) ontology concepts mapped to geospatial data
sources. To evaluate our methodology, we developed a prototype
desktop application which implements the matching process. Our
methodology provides a number of benefits over methods that
have been previously used for geospatial data discovery. These
benefits can be summarized as follows:
 Simplify geospatial data discovery using natural language terms
rather than requiring the users to fill any kind of interactive
form.
 The method can be implemented as a separate engine/Web ser-
vice. Therefore, it is independent of the systems architectural
tier that implements geo-information data source interfaces.
 Does not require the existence of semantic annotation of
geospatial data source interface, such as UDDI records, OWL-S
and WSMO elements. Thus, the problem of translation between
different semantic annotation schemes is completely avoided.
 Ontological components of federated GISs are used in their original form. Therefore, this method utilizes existing ontologies
while retaining their full expressiveness and reasoning capabil-
ities.
 Previously presented evaluation confirms the feasibility of our
approach within (geo-)information integration architectures
based on single ontology approach. By utilizing interontology
mappings (relationships between the ontologies), this method
can be used within (geo-)information integration architectures
based on multiple and hybrid ontology approaches.
Despite this methodology represents a feasible approach
for discovering heterogeneous and distributed geospatial data
sources, further efforts are required to make geospatial data
sources fully discoverable. In future work we will address following
issues:

M. Bogdanovic et al. / Web Semantics: Science, Services and Agents on the World Wide Web 32 (2015) 115

 Enhance the discovery process by introducing natural language
processing algorithm capable of parsing complex text expressions involving conjunctions, disjunctions, negations, contextspecific indexicals and metaphors. This enhancement will be
addressed by authors in the nearest future since we consider it
to be very important. The level of importance can be observed in
the following example. Currently, if a geoportal user would enter a description of information such as not streets nor rivers,
our discovery methodology would produce the exact opposite
of the expectedthe result would be data sources containing
streets and rivers since those words would the identified as
nouns.
 Enhance the discovery process by introducing gloss-based word
sense disambiguation methods. Currently, natural language
terms are tokenized from a user-defined description of
geospatial data, and for each of them an appropriate sense is
determined. However, user-defined description of geospatial
data can be utilized as a sentence which can be compared to the
description of terms from WordNet computational lexicon, e.g.
user-defined description can be compared to WordNet synset
glosses. For this purpose, separate heuristic techniques will
have to be developed and coupled with existing gloss-based
methods.
 Enhance the discovery process by taking advantage of toponyms extracted from users natural language description. The
toponyms will be extracted through usage of Web-accessible
gazetteer services and used for improving the process of filtering discovery results.
 Utilize natural language spatial relations for semantic similarity measurement. Spatial relations are very important parts of
semantic description of geospatial data. Previously reported re-
search, such as Schwering [76], have proven spatial relations
to be very significant for semantic similarity measurement.
Therefore, this methodology will be enhanced with mechanisms to detect, extract and utilize spatial relations from the
user-defined natural language description.
 Organize discovery results into an OGC-compliant document.
The methodology should take advantage of discovered geospatial data source interfaces by organizing them in the form of
an OGC-compliant document. For this purpose, we envision
the usage of OGC Web Map Context Documents Implementation Specification [77]. In this way, each user could be provided
with a standardized document describing access points towards
geospatial data sources containing the data he/she needs.
 Usability testing with the prototype. Preliminary prototype
testing only approves its feasibility. To evaluate performances
and effectiveness, appropriate usability study is necessary. For
these purposes, current prototype will be replaced with a Web
service which will implement the same algorithms.

Appendix A. Supplementary data

Supplementary material related to this article can be found

online at http://dx.doi.org/10.1016/j.websem.2015.01.002.
