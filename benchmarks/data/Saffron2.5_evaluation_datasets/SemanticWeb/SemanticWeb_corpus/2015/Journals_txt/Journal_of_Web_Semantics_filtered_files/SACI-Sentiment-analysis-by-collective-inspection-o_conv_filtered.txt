Web Semantics: Science, Services and Agents on the World Wide Web 34 (2015) 2739

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

journal homepage: www.elsevier.com/locate/websem

SACI: Sentiment analysis by collective inspection on social media
content
Leonardo Rocha a,, Fernando Mourao a, Thiago Silveira a, Rodrigo Chaves a, Giovanni Sa a,
Felipe Teixeira a, Ramon Vieira a, Renato Ferreira b
a Universidade Federal de Sao Joao Del Rei, Department of Computer Science, Sao Joao Del Rei, MG, Brazil
b Universidade Federal de Minas Gerais, Department of Computer Science, Belo Horizonte, MG, Brazil

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 5 September 2014
Received in revised form
9 April 2015
Accepted 25 May 2015
Available online 15 June 2015

Keywords:
Sentiment analysis
Classification
Transition graph

Collective opinions observed in Social Media represent valuable information for a range of applications.
On the pursuit of such information, current methods require a prior knowledge of each individual opinion
to determine the collective one in a post collection. Differently, we assume that collective analysis could
be better performed when exploiting overlaps among distinct posts of the collection. Thus, we propose
SACI (Sentiment Analysis by Collective Inspection), a lexicon-based unsupervised method that extracts
collective sentiments without concerning with individual classifications. SACI is based on a directed
transition graph among terms of a post set and on a prior classification of these terms regarding their
roles in consolidating opinions. Paths represent subsets of posts on this graph and the collective opinion is
defined by traversing all paths. Besides demonstrating that collective analysis outperforms individual one
w.r.t. approximating collection opinions, assessments on SACI show that good individual classifications do
not guarantee good collective analysis and vice-versa. Further, SACI fulfills simultaneously requirements
of efficacy, efficiency and handle of dynamicity posed by high demanding scenarios. Indeed, the
consolidation of a SACI-based Web tool for real-time analysis of tweets evinces the usefulness of this work.
 2015 Elsevier B.V. All rights reserved.

1. Introduction

Social media has emerged as an important environment
wherein people publish their opinions about distinct topics on the
Web, providing an unprecedented source of information for modeling and understanding user behavior. Hence, a growing number
of efforts aim to adapt traditional computational analysis to this
new scenario. Given the practical value of such subjective content,
particular attention has been given to Sentiment Analysis (SA) on
Social Media, that is, the automatic extraction and identification of
subjective information from textual data [14]. However, SA on Social Media is even more challenging than on other scenarios, such
as product reviews, since its content constitutes a fast-evolving
stream of short, unstructured and domain-specific textual data [5].
This work addresses the challenge of identifying the collective
sentiment about a target entity (e.g., product, person or service)

 Corresponding author.

E-mail addresses: lcrocha@ufsj.edu.br (L. Rocha), fhmourao@ufsj.edu.br

(F. Mourao), tssilveira@ufsj.edu.br (T. Silveira), rachaves@ufsj.edu.br (R. Chaves),
giovannisa@ufsj.edu.br (G. Sa), fcteixeira@ufsj.edu.br (F. Teixeira),
ramonv@ufsj.edu.br (R. Vieira), renato@dcc.ufmg.br (R. Ferreira).

http://dx.doi.org/10.1016/j.websem.2015.05.006
1570-8268/ 2015 Elsevier B.V. All rights reserved.

mentioned in a stream of textual documents. By collective sentiment we mean the predominant sentiment observed in the whole
set of documents. Traditionally, each document is classified individually w.r.t. its sentiment and the resulting classifications are
combined in order to compose an aggregated analysis, since individual perspectives are in general not representative enough. How-
ever, classifying short documents (e.g., posts) is difficult due to the
absence of contextual information. A typical domain that depicts
this scenario is the SA of political candidates or parties in social
networks. In this case, usually, we are not concerned about the
opinion of a given individual, but about the predominant opinion
of a population. Classifying each post published by each individual
and, then, deriving a collective opinion might be challenging and
unreliable. Differently, we intend to determine the collective sentiment by classifying bunches of documents simultaneously, which
we named collective analysis, instead of each one individually. In
this sense, we propose SACI (Sentiment Analysis by Collective In-
spection), a new lexicon-based unsupervised method that handles
efficiently a huge volume of documents extracting the collective
sentiment without concerning with individual classifications.

SACI uses a directed probabilistic graph of transitions among
terms that occur in a document set D about a target entity. Each
node represents a term (i.e., a single word) and edges express the

L. Rocha et al. / Web Semantics: Science, Services and Agents on the World Wide Web 34 (2015) 2739

probability of a term being adjacent to another in at least one
document of D. Further, each node has an attribute that represents
its lexicon-semantic class, which defines specific transformations
performed by each single term on the sentiment of a sentence.
Thus, each path in our graph represents a distinct subset of
sentences observed within documents of D. We assign a single
lexicon-semantic class to each path by traversing it and applying
successive semantic transformations, according to the class of each
reached term. As each path also has a probability of occurrence,
the collective sentiment of the whole set D is given by summing
up the probability of occurrence associated with positive, negative
and neutral paths. The main hypothesis exploited by SACI is that
the overlap among distinct documents may emphasize consensual
or most frequent opinions, whereas rare individual viewpoints
become less relevant for the collective sentiment.

Aiming to evaluate SACI, we compare its collective analysis with
four aggregated strategies derived from two unsupervised [1,3]
and two supervised [5,4] methods well-established in the literature in two real domains. The first domain comprises 20 USA TV
series and the second one refers to the 2012 USA presidential elec-
tion. Despite not being the most effective method to determine
individual opinions, SACI outperformed aggregated analysis when
identifying the collective opinion. These results evince that good
individual sentiment classifications do not guarantee good collective analysis and vice-versa. Further, the proposed collective analysis allows us to fulfill simultaneously three main requirements
posed by Social Media content, which are usually not aligned:
1. Accuracy: Collective analyses, such as performed by SACI, might
provide statistical robustness against noises and complex behaviors (e.g., irony) by exploiting consensual opinions. Further,
inductive and inferential procedures become more reliable,
since more information is available in a set of opinions than in
a single one, mainly within short textual data.

2. Efficiency and scalability: Besides not requiring a labeled
training set, SACI relies only on a fast construction and analysis
of transition graphs among terms, allowing us to classify quickly
even data streams.

3. Handle of dynamicity: The probabilistic graphs defined by SACI
can be instantaneously updated as soon as new data arrives, reflecting the most recent textual information while keeping the
most common interactions among terms.
Indeed, SACIs execution time grows linearly with the number
of analyzed tweets. Further, the approximation error between the
actual sentiment distribution and SACIs distribution was up to
86% smaller than the errors obtained by the aggregated strategies,
even those based on supervised methods. In summary, we point
out SACI as a promising method of collective SA, mainly, for high
demanding scenarios, such as Social Media. As proof of concept,
we also present a SACI-based Web tool able to conduct real-time
analysis of tweets.

2. Related work

In the past few years, we have observed a growing interest in
Sentiment Analysis (SA), whose goal is to extract subjective information from textual data [4,2,5,3]. Such interest stems from the
consolidation of social media as a new, rich and huge source of
subjective information about users. However, several studies have
found that traditional methods of sentiment analysis, employed in
scenarios such as product reviews, are not suitable for this new scenario [6,7]. Hence, some works have attempted to use additional
information in order to enhance SA in this case. In [8], for instance,
the authors used emoticons to train a Naive Bayes classifier in order to perform the sentiment classification on tweets. Further, [6]

presented a mathematical formulation for exploiting some sociological theories, such as sentiment consistency and emotional con-
tagion. Besides facing difficulties to classify short textual data, due
to the absence of contextual information, most of these methods
cannot handle efficiently a huge volume of data. Several supervised machine learning algorithms, even when considering additional features extracted by natural language processing methods
(e.g., syntactic classes of terms), struggle to perform properly SA
on this scenario [9]. Thus, unsupervised methods are assuming an
important role in the pursuit of effective and efficient approaches
for sentiment analysis in social media content [10,1,11].

Most of the unsupervised sentiment analysis methods are based
on sentiment lexicons and have usually two distinct steps. In the
first one, the consolidation of a lexicon is performed. Based on
such lexicon, the second step focuses on identifying the sentiment of each distinct document. Concerning about the consolidation of lexicons, most of the efforts can be divided into three
main categories [6]. The first one refers to methods based on human annotations, in which terms are classified manually [12]. Despite providing good lexicons, these methods are labor intensive
and, therefore, unfeasible for social media applications. The second category comprises dictionary-based methods that identify
the sentiment of a term from semantically related terms in a specific dictionary (e.g., WordNet) [13,14]. These methods are, in gen-
eral, computationally efficient, however, they do not take into
account the application domain. Thus, terms always exhibit the
same sentiment, regardless its domain of occurrence. Finally, the
third category is known as corpus-based methods [15,1] on which
a context-dependent sentiment is constructed, defining the sentiment of terms according to relations between terms observed in a
corpus. The lexicons built by these methods might be as good as
the manual construction with a reduced computational cost.

Considering the step of identifying the sentiment of each doc-
ument, some works perform a straightforward use of the lexicons.
For instance, [10] defined the sentiment of each tweet by verifying whether it contains positive or negative words, according to
a lexicon from OpinionFinder [16]. Similarly, [11] used OpinionFinder and GPOMS (Google-Profile of Mood States) to determine
the mood of each individual tweet. The goal in this case was to
evaluate the correlation between mood states in Twitter and the
Dow Jones Industrial Average over time. In turn, [17] investigated
Twitter as a forum for political deliberation on the context of the
German federal election. The authors used LIWC [18] to extract
the sentiment of a set of tweets. LIWC is a text analysis tool that
counts words in psychologically meaningful categories in order
to assess emotional, cognitive, and structural components of text
samples. Similarly, [19] developed a measure of positive/negative
influence for popular users on Twitter using a term-based matching technique based on LIWCs output. Aiming to handle the lack
of contextual information in the short text data from Social Media,
recent works are taking advantage of all textual features available
on posts [2022]. For instance, Xia Hu et al. propose a new framework that considers emotional signals, such as emoticons or product ratings, present in each post to determine its sentiment [20]. In
turn, the length of each word is exploited as another evidence of
sentiment by [21].

Differently from previous efforts, SACI did not intend to classify documents individually on the second step. To the best of our
knowledge, the only proposal in the literature that evaluates a collection of documents, instead of an individual approach, is [17]. The
authors count word occurrence in a collection of documents, according to psychological categories defined by LIWC, and determine the collection sentiment as the categories distribution. By
modeling documents as a bag-of-words, this approach fails to capture useful information, such as co-occurrences and order of occurrence of words into each sentence. On the other hand, SACI uses a

directed transition graph among terms that provides a global representation of frequent and discriminative relationships useful for
SA. This strategy may provide a more robust analysis, attenuating the impact of individual misclassified opinions on the collective sentiment. Furthermore, SACIs output is semantically distinct
from the output provided by the method proposed in [17]. While
SACI outputs a probability distribution of classes, the latter outputs a 12-dimensional score that quantifies, using a 03 continuous scale, the strength of 12 psychological and structural categories
on a text sample. Thus, a proper comparison between them requires a careful conversion of value scale and interpretation, which
was left as future work.

3. SACI

In this section we present our technique originally proposed
in [23]. As previously mentioned, SACI is based on the construction of a directed probabilistic graph of transitions among terms, on
which each node represents a term, and edges express the probability of a term being adjacent to another one in a set of documents.
Each node has an attribute that represents its lexicon-semantic
class and the collective sentiment is determined by traversing this
graph and applying successive semantic transformations. Thus, we
divide this section into two subsections which describe each SACI
component.

3.1. Sentiment lexicon construction

The first component of our technique consists of identifying the
lexicon-semantic class of each term, which refers to the contribution of each term for the sentiment opinions. As we presented in
Section 2, this kind of classification of terms is exploited in the literature by distinct proposals [12,6,15,1,13,14]. The primary premise
of these methods is that there are distinct classes of words that play
specific roles on the consolidation of subjective sentences [24,25,
20]. More specifically, we consider that the input lexicon classifies each term according to a pre-defined set of lexicon-semantic
classes presented in Table 1, a subset of six polar morphological classes from [26]. We selected these classes since they impact
on the identification process of collective sentiment performed by
SACI. Moreover, we assume that some terms may take different
classes according to the analyzed domain. For example, the word
fun may have a positive connotation on a TV series context or a
negative one in a political context. Therefore, we propose a new
strategy for building sentiment lexicons that classify each term according to the domain of analysis.

Basically, the proposed strategy consists in propagating lexiconsemantic classes on a transition graph of terms, starting by a few
seed terms that have a previously known lexicon-semantic class,
defined for example by specialists of the evaluated domain. In this
sense, we use the pre-defined set of lexicon-semantic classes presented in Table 1. We selected only those classes that impact on
the collective sentiment identification process proposed by SACI.
Then, given a set T = {t1, t2, . . . , tk} of distinct terms appearing
in a finite set of opinions present in a document set D, we build a
transition graph among the terms of T as follows. We first determine a collection of synonyms and antonyms (i.e., a thesaurus) for
the language used in the set D. In this paper, we used the thesaurus
available at.1 Based on this thesaurus, we define two types of edges
between terms in the graph. There is a s-edge between two terms
t1, t2  T, if they are synonyms in the thesaurus and an a-edge if
they are antonyms. Once the graph has been constructed, the next

1 http://www.thesaurus.com/.

step is to classify manually a subset S  T of terms (i.e., the seed
set) regarding the six lexicon-semantic classes. We assume that S is
much smaller than T (i.e., S  T) and its terms are selected based
on their occurrence frequency in the document set D, in which the
most frequent terms will compose the set S.

auxilarySet  classifiedTerms
for ti  classifiedTerms do

SentimentClass  invertSentiment(SentimentClass)

SentimentClass  retrieveSentimentClass(ti)
neighbors  getNeighbors(ti, G)
for all tj  neighbors do

edgeType  retrieveEdgeType(ti, tj, G)
if edgeType  a-edge then

classifiedTerms  V
unknownClasses  U
auxilarySet  {}
propag  0
while (classifiedTerms = auxilarySet)&(propag < ) do

Algorithm 3.1 Propagation of Lexicon-Semantic Classes
1: function defineSentimentLexicon(G, V , U, ,  , )
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:

numPropagations  getNumTuples(propagations, ti)
majorClass  getMajorClass(propagations, ti)
majorClassFreq  getClassFreq(propagations, ti, majorClass)
confidence  majorClassFreq/numPropagations
if (numPropagations > )&(confidence >  ) then

propagations.push(tj, SentimentClass)

for all ti  propagations do

SentimentLexicon[ti]  majorClass
classifiedTerms  classifiedTerms  ti
unknownClasses  unknownClasses  ti

propag + +
return SentimentLexicon

The consolidation of our sentiment lexicon, essentially, consists
of propagating classes from the seed nodes in graph G, as described
by Algorithm 3.1. First, we define two distinct sets of terms.
One of them represents the set V of all terms with known class
(i.e., initially V = S) and the second set U comprises the remaining
terms, which are assigned to the neutral class (i.e., U = T  V ).
The propagation is an iterative procedure (lines 625). At each
iteration, all nodes tj adjacent to each node ti  V are checked.
If the edge that link ti to tj is a s-edge, then the class of ti is
propagated to tj. If the edge is an a-edge, then we propagate the
reverse sentiment of ti to tj, wherever applicable (i.e., positive
 negative and amplifier  reductor only). At the end of each
iteration (lines 1624), there is a decision step that determines
whether we should change the class of a node tj. Specifically,
we evaluate all propagation paths that reach tj using two input
parameters. The first one is the support  that determines the
minimum number of neighbors who propagated its class to tj
in order to reclassify tj. The second parameter is the minimal
confidence  that is the relative frequency of the most frequent
lexicon-semantic class among those propagated to tj (i.e., the major
class). If these two criteria are satisfied, the class of tj is updated
to the major class. Then, tj is removed from the set U and inserted
into the set V . In the next iteration, this process is repeated with the
new set V and the process continues until the set V does not change
any more or a maximum propagation distance  is reached. All the
terms not reached by our algorithm (e.g., terms with no synonyms
or antonyms in the thesaurus) are assumed to be neutral in the
sentiment analysis process described in the sections that follow.

3.2. Sentiment identification

The second component of SACI comprises the sentiment identification in document collections. First, it constructs a transition
graph among terms using D, as well as the input lexicon. Then, the
collective sentiment is extracted, in the second step, by traversing
all paths in the resulting graph. The following sections detail each
of these steps. Further, although not being our goal, we briefly describe how to adapt SACI to perform individual sentiment analysis
on documents of D.

L. Rocha et al. / Web Semantics: Science, Services and Agents on the World Wide Web 34 (2015) 2739

Table 1
Lexicon-semantic classes of the English vocabulary.

Class
Positive
Negative
NEutral
Inverter
Reductor
Amplifier

Transformation
Makes positive the sentiment of a sentence.
Makes negative the sentiment of a sentence.
Does not change the sentiment of a sentence.
Reverses the sentiment of a sentence.
Attenuates the sentiment of a sentence.
Intensifies the sentiment of a sentence.

Examples
good, nice, amazing
terrible, ugly, bad
most nouns
not, never
feel, small, decreasing
much, big, too

3.2.1. Graph construction

We build the transition graph of terms based on directed paths
extracted from the analyzed documents. First, we define as central
nodes all terms, or n-grams, that represent the target topics of
analysis (e.g., product, person or service). Then, starting from each
occurrence of each central node in a document, we extract its
predecessor and successor terms belonging to the same sentence
and define this ordered sequence of terms as a directed path. Thus,
we define one distinct path for each occurrence of each target topic
in the document set. Finally, we transform the extracted set of
paths into a graph by considering each distinct term as a node and
defining one edge for each pair of terms adjacent to each other in
at least one of the extracted paths.

Formally, let D be the set of analyzed documents and M the
set of central nodes. Also, we define a parameter l (maximum
radius) that stands for the applicability radius of each sentiment
transformation within each sentence. First, we extract from each
document di  D a set Fi of sentences. For each occurrence of a
central node mj  M in a sentence fk  Fi, we extract a path ck
that is composed by the l predecessor terms of mj, the central node
mj itself, and the l successor terms of mj, preserving the order of
occurrence of the terms.2 Through this process, we define a set C of
all paths extracted from all sentences in the whole document set.
Then, taking into account the set T of distinct terms observed in D,
we define a graph G in which each term ti  T corresponds to a
node, and for each pair of terms ti, tj  T there is a directed edge
from ti to tj if ti precedes tj in at least one path ck  C. The edge
weight is defined as the probability of ti precede tj in the entire
set C. We also defined the Entry and Exit states that represent the
input and output nodes of our graph, respectively. If a term ti starts
a path, there will be an edge from node Entry pointing to it, as well
as whenever a term ti ends a path, it will be connected to node
Exit. Thus, each path may represent more than one sentence of
Fi. Further, each node ti of G has an attribute that determines its
sentiment class, such as defined by the input lexicon which is a
SACIs parameter.

It is noteworthy that the graph size is linear w.r.t. the number
of distinct terms, rather than the number of analyzed posts. As
presented in [27], the number of terms is much smaller than the
number of posts, therefore, we keep the resulting graph size small
even when processing large datasets. Further, such graph can be
updated in order to reflect the most recent opinions or opinions
issued in a specific period of time. By adding new edges and
nodes or recalculating the probabilities of edges already existing
in the graph, we perform such updates without the need of
reconstructing the whole graph. Fig. 1 illustrates the construction
process of our graph for a small set of sentences extracted from
a dataset of movie reviews, where the movie Pulp Fiction is the
central node. For simplicity, we consider only two sentences and
adopt an applicability radius l = 2. Moreover, this figure illustrates
the lexicon-semantic class assigned to each term. As discussed in

2 Terms shorter than three characters are ignored at this step, since they usually
comprise prepositions and articles that do not help to infer the semantics of a
document.

Fig. 1. Example of graph construction with parameter l = 2. In this case, we have
only two sentences, which define two distinct paths.

the next section, the navigation through this graph, considering the
lexicon-semantic class associated with each of its nodes, defines
the collective sentiment inherent to the analyzed document set D.

3.2.2. Collective analysis

Motivated by the goal of identifying the opinion of a set of doc-
uments, rather than each one individually, we evaluate paths in a
directed transition graph among terms. The premise, in this case,
is that the overlapping among distinct documents may emphasize
consensual or most frequent opinions, while individual viewpoints
are smothered. Therefore, the existence of overlapping discussions
among a set of documents is fundamental for a meaningful collective analysis. Further, as we intend to evaluate highly dynamic en-
vironments, such as social media, it is important that the evaluated
content presents a high temporal locality w.r.t. topics. Otherwise,
there will be no overlap.

SACI determines the sentiment associated with each path via
a state-transition process wherein the next state depends only
on the current state and the input data. This process resembles
systems modeled by Mealy machines [28], motivating us to describe SACI through this formalism. A Mealy machine is a 6-tuple
(F , F0, , , TS , TO), where F is a finite set of states, F0 is the start
state,  is the input alphabet,  is the output alphabet, TS is the
transition function that maps a state and input symbol pair to an
output state, and TO the output function that maps a state and
an input symbol pair to an output symbol. In our case, we define
F = {P, N, E, I, R, A}, which corresponds to the lexicon-semantic
classes, F0 = {E}, since the initial sentiment of each path is set
to neutral,  = {p, n, e, i, r, a} is the lexicon-semantic class of the
next term on the path in the transition graph,  = {p, n, e, } is the
path sentiment, where TS and TO are depicted in Fig. 2. Each combination of current state and input results in an output symbol that
represents the new paths sentiment, and in an output state. The
path is sequentially traversed and whenever a term is reached, the

Fig. 3. Computation of probability for path C1 (Entry, Entertaining, Pulp Fiction,
Exit) in our transition graph, highlighted by dotted lines.

Fig. 2. Transformation rules (TS and TO) through the Mealy machine.

paths sentiment is updated according to rules defined by the Mealy
machine. This process continues until the last term of the path is
reached. In this case, the last output symbol different from  corresponds to the sentiment assigned to each path ck (sentiment[ck]).
Considering the path C1 in Fig. 1, it starts with neutral sentiment
in the state Entry and the Mealy machine starts in state E (neu-
tral). Reading the term entertaining and assuming that this word
has positive sentiment in the lexicon, the Mealy machine changes
the paths sentiment to positive and assumes the state P (positive).
The next term is neutral, which is the target Pulp Fiction. In this
case, the Mealy machine keeps the positive sentiment of the path
and continues in state P. As the next state of the graph is Exit, the
Mealy Machine assumes, therefore, the final sentiment of this path
as positive. In order to analyze the next path, the Mealy machine is
reinitialized to state E.

It is important to point out that this sentiment updating process
through transformation rules is always done by modifying the
current path sentiment according to the lexicon-semantic class of
the next term ti. An exception occurs when the lexicon-semantic
class of ti is the Inverter. In this case, we must take into account
one aspect: in the human communication an inverter term, like
never or not, in general, reverses the sentiment of successor
terms, instead of predecessor ones. Thus, rather than inverting the
input sentiment of ti, we should reverse the resulting sentiment
given by the first term that succeeds ti on the path. Also, we should
mention that the lexicon-semantic classes Amplifier and Reductor
are not currently used in the sentiment updating process of each
path, as shown by Fig. 2. As we will discuss in Section 6, a deeper
study on how we can use these classes for this purpose is necessary.
Currently, SACI uses these classes for avoiding some terms to be
misclassified as negative or positive during the class propagation
process, and changing the probability of each path. For instance,
we consider the term Much as an Amplifier, although it might be
seen as a Neutral term, for simplicity. This latter case, however,
ignores completely the impact of this term on SACIs analysis.
By considering terms as an Amplifier or Reductor they may be
exploited in the future, in order to refine the probabilities derived
by SACI.
Besides a sentiment, each path has a probability of occurrence.
Formally, each path ck = {Entry, t1, t2, . . . , tk, Exit}, from the
path set C being analyzed, defines a probability prob[ck], as shown

by Eq. (1), where prob[tj
| ti] corresponds to the probability of
reaching tj starting from ti and prob[C] denotes the sum of the
probabilities of all paths from C. The sum of the logarithms was
chosen instead of a simple multiplication of probabilities in order
to avoid that probabilities of long paths become quickly close to
zero. Fig. 3 illustrates the calculation of probability for a path from
the example graph presented in Fig. 1.
prob[ck] =

prob[C]  [log(prob[t1|Entry]  prob[t2|t1]  
  prob[tk|tk1]  prob[Exit|tk])]
prob[C]  [log(prob[t1|Entry]) + log(prob[t2|t1])
 + log(prob[tk|tk1]) + log(prob[Exit|tk])].

(1)
Finally, using the sentiment related to each distinct path ck 
C (sentiment[ck]), as well as the probability associated with it
(prob[ck]), we define the probability of occurrence related to each
collective sentiment class  {neutral, positive, negative} in D, as
shown by Eq. (2). Thus, unlikely paths and sub-paths in the graph
are less relevant for the analysis process, whereas paths with high
probabilities are prioritized. Hence, the collective sentiment tends
to reflect the most common interactions among terms, smoothing
errors caused by uncommon individual paths that express complex
or unexpected patterns, such as irony. It is also important to
note that our algorithm does not require a training step, reducing
significantly its computational complexity and processing cost.
prob[class] =


prob[ci].

(2)

{ciC|sentiment[ci]=class}

3.2.3. Individual analysis

Although an individual analysis is not the focus of our study, it
emerges naturally from SACI. Individual analysis of documents is,
basically, the most studied task in sentiment analysis: given a doc-
ument, determine whether its content expresses a sentiment and,
if so, classify its general sentiment. As our analysis is made at the
sentence level, we can evaluate the sentiment of each document di
individually by considering only the sentences related to this doc-
ument. In this case, we first construct our transition graph among
terms based only on sentences of di. Then, the sentiment of di is
given as the probability distribution of sentiment classes derived
from paths within this transition graph, such as we do for collective analyses.

L. Rocha et al. / Web Semantics: Science, Services and Agents on the World Wide Web 34 (2015) 2739

4. Experimental evaluation

Table 2
Dataset descriptions.

In this section, we present the experiments performed to evaluate SACI. First, we describe the datasets used in all experiments.
Then, we present the evaluation of the proposed sentiment lexicon
construction. In order to analyze the sentiment analysis performed
by SACI, first we present the decisions adopted for experimental
setup. Hereafter, we discuss the parameter setting with respect
to SACIs performance. Later, we evaluate in-depth the collective
analysis performed by SACI, as well as validate its main hypothe-
sis. Finally, we contrast the collective analysis against aggregated
one derived from supervised and unsupervised models.

Datasets
TV series
USA elections

#Doc.

Positive
27.94%
20.33%

Negative
4.52%
30.88%

Neutral
67.53%
48.79%

Distinct terms

Table 3
Lexicon-semantic classes distribution.

Dataset
TV series
USA elections

4.4%
5.1%

2.2%
2.5%

90.5%
89.0%

0.6%
0.7%

0.6%
0.7%

1.7%
2.0%

4.1. Datasets and ideal lexicons

4.2. Sentiment lexicon evaluation

As mentioned earlier, one of our main hypotheses is that there
is a temporal locality of topics on social media content that influences the overlapping among discussed topics on data streams
and, consequently, affects SACIs results. For example, tweets produced temporally close, probably present high levels overlapping
of topics and, consequently, may emphasize consensual or most
frequent opinions. Aiming to evaluate this hypothesis, instead of
using well-evaluated datasets for which we do not have any information about this locality, we consolidate two real datasets from
Twitter, with distinct temporal characteristics by applying different
gathering strategies.

The first dataset (TV Series) consists of tweets related to 20
American TV Series with global audience, such as The Big Bang
Theory and Two and a Half Men, among others. In this case, tweets
were collected along continuous time periods, from 03/05/2012
to 03/17/2012, maintaining the temporal locality of the topics
discussed by the users. The second dataset (USA Elections)
comprises tweets related to the 2012 USA presidential elections
and were gathered considering non-continuous time periods. In
this sense, first, we collected all tweets from January to May 2012.
Then, we randomly sampled 30 distinct days from this period and
used all tweets published in these days. In the TV Series dataset, all
the 20 distinct series were used as target topics, while we defined
as target topic for USA Elections only the re-elected president
Barack Obama. Further, aiming to provide inputs for the evaluation
metrics, each tweet from both of the datasets was manually
classified, as well as each distinct term observed in each collection
w.r.t. its lexicon-semantic class, defining a gold standard tweet set
and an ideal lexicon, respectively. In both cases, each tweet or term
was classified into one of three distinct classes (positive, negative
and neutral) by five different people and, for each tweet or term,
the class with majority votes was taken as the gold standard and
ideal lexicon, respectively. The ambiguous tweets and terms were
assigned to the neutral class. We consider as ambiguous tweets
and terms the ones with inter-annotator agreement equal to 50%
(i.e., two classes with two votes each). These cases represent less
than 8% for both dataset (i.e., for tweets and terms).

We gathered both collections through the Twitter search API by
using hashtags and common words related to each target topic as
search keyword. Specifically, we used Obama and Barack Obama
as keywords for US Election and the official name of each series,
without special characters, for TV Series. Further, inspired by previous works [1,29], we performed a text preprocessing in order
to reduce noises and improve the text quality. Specifically, we removed from each tweet punctuation, special characters, repetitive
patterns (e.g., LOOOOVE becomes love), as well as convert all letters to lowercase. Also, words with less than three or more than 12
letters, URLs and quotes to users were removed from both datasets.
Since our goal is to demonstrate the usefulness of the proposed
graph-based model for collective SA, we are not concerned about
the additional information that this preprocessing may remove,
such as emoticons. Table 2 presents detailed information about
each dataset after the preprocessing.

The first step of our analysis consists of evaluating the proposed
sentiment lexicon construction component of SACI. In this sense,
we first generate an ideal lexicon for each dataset, in which all
terms were manually classified, taking into account each domain of
analysis. Table 3 shows the distribution of lexicon-semantic classes
in each ideal lexicon. We can observe that neutral terms represent approximately 90% of all terms, in both datasets. This behavior is not surprising, since, besides the fact that human language is
composed mostly by neutral terms, tweets typically comprise a single sentence whose sentiment tends to be defined by few distinct
terms.

Using these ideal lexicons for comparison, we defined an experiment set to measure the quality of our resulting sentiment
lexicons, considering four requirements, which will be explained
along this section: coverage, efficacy, scope of generality and ef-
ficiency. In turn, these requirements are affected by four parameters given to SACI: the initial seed set (S), the maximum propagation distance (), the confidence ( ) and the minimum support
(). Aiming to better understand the relevance of each of these
parameters, as well as the correlation pattern among them, we
defined an appropriate discrete interval for their values and performed a factorial experiment in which several parameter combinations were evaluated by contrasting the resulting lexicons with
the ideal lexicon. First, we discretize the confidence into intervals
of size 0.1, from 0 to 1. Also, we vary the size of the initial seed set
from 1 to 100 by using distinct subsets of the most frequent terms
found in each ideal lexicon. We do not evaluate values greater than
100, since it is important to construct semantic lexicons minimizing the manual effort (i.e., manual classification of terms). For the
minimum support, we vary the values from 2 to 40. However, we
observed that values greater than 10 do not bring significant differences in the quality of sentiment lexicons. Finally, we vary the
maximum propagation distance values from 1 to 10, however there
was no difference on the quality of semantic lexicons for values
greater than 6. Thus, we present a pairwise analysis of parameters,
considering just the intervals in which the differences were significant and fixing the two remaining parameters to the following val-
ues:  = 3,  = 3,  = 0.8 and |S| = 100, which correspond to
values that exhibited the best results for the lexicon construction.
We start this analysis by the coverage requirement, which
refers to the percentage of terms in a domain classified by SACI.
We measure coverage through the Global Recall of the ideal lexicon,
which accounts for the percentage of the ideal lexicon classified
by our algorithm. Fig. 4(a) shows that we classify a significant
percentage of each ideal lexicon by starting from a relatively
small set of seeds in both collections. The best combinations of
parameters present coverages of 75% and 83% for TV Series and USA
Elections, respectively. These results also show that high values
for minimum support, as well as high confidence values, degrade
the coverage. Finally, we found that the greater the propagation
distance, the higher the resulting coverage, since, by increasing this

(a) Global recall.

(b) Macro-F1.

Fig. 4. Qualitative analysis of the parameters in the sentiment lexicon construction.

distance, the number of reached terms tends to grow exponentially
in this type of graphs.

The second assessed requirement refers to efficacy that concerns the correct classification of the resulting lexicon terms with
respect to the lexicon-sentiment classes. We evaluated efficacy
through the well-known Macro-F1 metric, which corresponds to
the average of per class F1,3 since it exhibits a greater capability
of handling skewed class distributions than other traditional met-
rics, such as Accuracy. By analyzing Fig. 4(b), we observe that, with
respect to efficacy, neither higher values of minimum support nor
lower ones should be used. High support values filter out almost
all terms and, consequently, most of them remain as neutral. On
the other hand, low support values do not filter out noises and
unreliable propagations. In general, this noise stems from originally neutral terms that have some synonyms or antonyms different from neutral and, consequently, are assigned to another class.
Analogously to the coverage evaluation, confidence has little impact on the lexicon quality in the evaluated scenarios. Finally, we
note that, despite high maximum propagation distances providing
high coverages, these distances are not suitable regarding efficacy,
since they increase the number of misclassifications. This problem
stems from the absence of the transitivity property on the mean-
ing, given that the synonym of a synonym may not have a meaning
close to the original one. The highest Macro-F1 values were 64%
and 54% for TV Series and USA Elections, respectively.

The third evaluated requirement is the scope of generality, as
well as the ease of instantiation in distinct domains, for which
we analyze the behavior of the seed set on Fig. 4. We note that,
as expected, the larger the set of initial seeds, the higher the

3 F1 metric is calculated as the weighted harmonic mean between the precision
and recall of each class [30].

coverage and effectiveness of the generated lexicon. However, for
the TV Series dataset, an initial set of only 50 seeds was enough
for achieving high coverage and efficacy levels. On the other hand,
the USA Elections dataset required a larger initial set with at least
90 seeds. This fact is related to levels of subjectivity and specificity
inherent to the vocabulary of each domain. For instance, while in
TV Series positive terms such as good and funny are quite common,
sharing the same sentiment and positive synonyms or negative
antonyms with many domains, in USA Elections, the most frequent
positive terms are very specific to this domain, such as vote or
reelect. Thus, the number of seeds required for properly identifying
the lexicon-semantic class of specific vocabularies tends to be
high, since most of their terms are usually neutral. However, the
number of seed terms required for achieving good coverage and
efficacy levels represents less than 3% of the vocabulary size in both
collections. This fact evinces that our method has a good scope of
generality and can be easily instantiated on distinct domains.

Finally, since our goal is to evaluate huge volumes of data in
short periods of time, the lexicon construction process must be
simple and efficient. Thus, we assess the efficiency requirement by
performing a worst-case asymptotic analysis of complexity on the
lexicon construction component of SACI, allowing a broader and
more robust evaluation. The worst case occurs when the number
of initial seeds is equal to one and each term has only a unique
and distinct neighbor, defining a linear list of size equal to the
vocabulary size. In this case, at each iteration, just one term is classified and, consequently, the time complexity required for the sentiment lexicon convergence is O(k2), on which k is the number of
distinct terms being classified. However, this worst-case scenario is
quite unlikely in practice, and the average number of neighbors per
term tends to be significantly higher than one. Additionally, empirical evaluations corroborate this last observation. For any set of
seeds used in both datasets, the experiments showed that only 10

TV  Series123456MaximumDistance250750.10.30.50.70.9Confidence1030507090 Seeds246810MinimumSupport123456MaximumDistance0.10.30.50.70.9ConfidenceUSA  Elections123456MaximumDistance25083CoverageCoverage0.10.30.50.70.9Confidence1030507090 Seeds246810MinimumSupport123456MaximumDistance0.10.30.50.70.9Confidence123456MaximumDistance25064MacroF10.10.30.50.70.9Confidence1030507090 Seeds246810MinimumSupport123456MaximumDistance0.10.30.50.70.9Confidence123456MaximumDistance15054MacroF10.10.30.50.70.9Confidence1030507090 Seeds246810MinimumSupport123456MaximumDistance0.10.30.50.70.9Confidence34

L. Rocha et al. / Web Semantics: Science, Services and Agents on the World Wide Web 34 (2015) 2739

iterations were required for the lexicon convergence. Moreover, by
measuring the execution time of our approach for generating a specific lexicon for each dataset, considering a thesaurus with 71,000
words, we have found times lower than 9 s. The execution time was
calculated as the average of 10 executions, varying the seed set, on
an Intel Core i5 1.8 GHz machine with 4 GB of RAM and running
Ubuntu 12.04.

An immediate question raised by the foregoing discussion is
how to obtain, in a practical manner, a proper parameter calibra-
tion. As the previous analyses use both an ideal lexicon, whose consolidation is expensive, and a costly exhaustive search for the best
combination of parameters, we should point out feasible strategies for setting these parameters, enhancing the applicability of
our method. A feasible strategy would be to extract a small subset of the most frequent terms present in the analyzed dataset and
build the ideal lexicon for this subset. Then, an almost exhaustive
experiment could be performed to find the parameter values that
produce a resulting lexicon closest to the ideal one. Next, these parameters could be used for obtaining the sentiment lexicon for the
original dataset. Thus, we highlight, as immediate ongoing step of
this work, the proposal and evaluation of distinct feasible parameter calibration strategies.

Finally, we perform an evaluation by contrasting the lexicons
defined by our strategy in our collections against four baseline
lexicons commonly used in the literature [12,31,15,13]. The first
baseline, Multi-Perspective Question Answering (MPQA), was originally proposed in [12] and has 8221 words manually classified,
with 2718 positive, 4912 negative and 571 neutral words. This lexicon also has the grammatical class of each word, as well as its level
of importance in a sentence. The second baseline, Harvard General
Inquirer (INQ) [31], has words manually classified syntactically, semantically and grammatically. INQ has 11,788 words, 1915 posi-
tive, 2291 negative and 7582 neutral words. As our third baseline,
we evaluate the SentiWordNet [13] lexicon (version 3.0) that assigns three numerical values for each word, which corresponds to
its levels of positivity, negativity and neutrality. SentiWordNet has
148,610 classified words on which, considering that the highest
value assigned to a word corresponds to its class, 2078 are posi-
tive, 4309 are negative and 142.223 are neutral. Finally, our fourth
baseline was proposed by Bing Liu (BL) in [15]. It has two lists of
words, one positive and other negative with 2006 and 4783 words,
respectively. It is noteworthy that BL lexicon also presents morphological variants of words and slang. For this analysis, we use the
resulting lexicon of SACIs strategy obtained with 100 seeds (the
100 most frequent words in each collection), minimum support 3,
confidence 0.8 and maximum distance 3, which corresponds to the
best parameter configuration w.r.t. Macro-F1 in our previous eval-
uations. This configuration resulted in a lexicon with 1875 positive
words, 1103 negative and 67,674 neutral for the TV Series dataset
and 1966 positive, 2625 negative and 66,061 neutral words for USA
Elections dataset.

The effectiveness of each lexicon was evaluated through traditional classification metrics of quality, using the ideal lexicon as
ground truth. Specifically, we derived the F1 metric for each class
(i.e., positive, negative and neutral), such as presented by Table 4.
Despite the high F1-N value achieved by SentiWordnet in USA
Elections, we also observe it presented the worst Mac-F1 value,
which summarize the F1 of all classes. This behavior may be related to the fact that this lexicon is a dictionary-based one and does
not consider any context. A second observation is that the lexicons
MPQA and INQ presented good results, as expected, since they are
based on human annotations. However, we point out that these
methods are labor intensive and, therefore, are unfeasible for social media applications. Finally, we observe that the strategy BL
and SACI presented the best results w.r.t. to F1 and Mac-F1 for
almost all evaluations. This result demonstrates that taking into
account the application context is important to provide good lexi-
cons. Moreover, these results suggest that SACIs may be effectively
instantiated into distinct domains.

4.3. Sentiment analysis evaluation

4.3.1. Experimental setup

Since our goal

is to determine the collective sentiment
expressed through a document set, the performed quality assessments are based on contrasting the actual probability distribution of sentiment classes in each dataset against the distributions
defined by each method. We consider as output distribution defined by methods focused on individual document classifications
the percentage of documents assigned to each class. In turn, SACI
provides as output a probability distribution of sentiment classes.
We searched in the literature symmetric and easy-to-interpret
metrics for this type of low-dimensional space [32,33]. Thus, we
take into account three traditional approximation error metrics
for comparing distinct distributions: (i) Euclidean Distance [34]
(E.D.), which is the length of a straight line between two vectors;
(ii) Quadratic-Form Distance (Q.D.) [35], which considers crossbin
relationships between pair of vectors; and (iii) KL-Divergence (KL),
a non-symmetric measure of the difference between two probability distribution [36]. For all metrics, the higher the value, the more
different two distributions are. All results were found through a
10-fold cross-validation strategy and we applied a 2-tailed paired
t-test with 95% of confidence when contrasting SACI against other
methods.

We contrast SACI against an aggregated analysis derived from
four state-of-the-art SA techniques with distinct characteristics.
The first one is a supervised method proposed by Pang, Lee and
Vaithyanathan (PLV) [4], which is based on traditional Machine
Learning techniques. Specifically, we used the SVM classifier with
unigrams as features, since the authors pointed it out as the best
evaluated combination for SA. The second technique, proposed by
Dave, Lawrence and Pennock (DLP) [5], presents a supervised classification model that assigns scores from 1 to 1 for each n-gram
observed in a training set, according to its frequency in previously
classified positive or negative documents. Then, the sentiment of
a document is defined as the sentiment class with highest sum of
n-gram scores. Again, we evaluated this strategy using only uni-
grams, as it is pointed out by the authors as the best configura-
tion. These two techniques classify documents between positive or
negative only, ignoring the existence of neutral documents. In order to allow comparing them with the other techniques, we added
a previous classification step, which distinguishes documents between subjective and non-subjective (i.e., neutral). This step is the
same for each respective classification method, however rather
than considering positive or negative classes, we consider subjective or non-subjective classes. The documents identified as subjective are then sent to the second step, where they are classified as
positive or negative.

As third technique, we evaluated the unsupervised lexiconbased approach proposed by Wilson, Wiebe and Hoffman (WWH)
[3] for phrase-level sentiment analysis. Assuming a prior term
sentiment, this technique aims to disambiguate the sentiment of
terms or phrases in a sentence according to the context in which
they are embedded. This is a costly natural language processing
approach that applies a linguistic parser and generates a dependency tree between terms. Differently from the original work,
which adopts a manual classification of lexicons, we define the
prior sentiment of each term as its most frequent sentiment in the
SentiWordNet lexicon [37]. The sentiment classification is done as
proposed by the authors, that is, whenever a document contains
solely sentiment terms from a single class, it is classified as belonging to that class. Otherwise, it is classified as neutral. The fourth
technique is another unsupervised lexicon-based method presented by Pak and Paroubek (PP) in [1]. This technique uses a Naive
Bayes classifier of lexicons, based on part-of-speech tags and bigrams information. It is important to mention that, as reported by
the authors, we also use the feature selection methods presented
by them. The source codes of all evaluated algorithm versions are
available at http://dcomp.ufsj.edu.br/saciWeb/source.php.

(a) TV series.

(b) USA elections.

Impact of the maximum radius of transformation on the SACIs collective analysis. Small radiuses do not reach terms that contain the sentiment related to each target

Fig. 5.
topic, whereas large radiuses may include terms not related to it.

Table 4
Comparison of effectiveness among distinct lexicon consolidation methods into two distinct domains. The best results for each metric are shaded. We found that SACIs
strategy presented the best results.

Method

SentiWordNet

SACIs Strategy

TV series
F1-P(%)

F1-N(%)

F1-E(%)

Mac-F1(%)

USA elections
F1-P(%)

F1-N(%)

F1-E(%)

Mac-F1(%)

4.3.2. SACIs parameter setting

SACI is based on a graph of terms composed of paths extracted
by parsing distinct documents. A broad analysis of this construction requires characterizing and understanding the behavior of its
second parameter: the maximum radius of transformation (l) on
the paths. Such radius impacts directly on the SA accuracy, and the
choice of a proper value is domain dependent. Fig. 5 presents the
results of the collective analysis performed by SACI varying l. The
value  means that the maximum radius l of each path is limited
to the size of each parsed document. We observe that ls values impact significantly the quality of the collective SA. Low values often
do not allow reaching terms that contain the sentiment related to a
central node, which represents the target topic, whereas high values may include terms that do not necessarily refer to the central
node. Therefore, radiuses from 3 to 6 tend to bring up a broader
and more reliable set of sentiment information about each central
node. In the light of these results, we use a maximum radius equal
to 4 in the remaining experiments for both datasets.

4.3.3. Collective sentiment analysis through SACI

Our first concern is to distinguish the gains related to collective
analysis itself
from those inherent to the adopted network
model. In this sense, we contrast the results of identifying the
collective sentiment through SACI against aggregated analysis over
individual classifications performed using the graph. We perform
individual classifications such as described in Section 3.2.3 and
calculate the percentage of documents assigned to each class.
Table 5 presents the results found by each strategy through a
10-fold cross-validation. The symbol  denotes significant gains,
 non significant gains or losses and  significant losses. We
observe that collective analysis presents significant gains over the
aggregated strategy on TV Series, reducing the errors by 42.45%,
43.59% and 58.84% for E.D., Q.D. and KL, respectively. On the other
hand, there were no statistically valid differences between these

Table 5
Results comparing aggregated analysis against collective one. SACI added useful
information for SA, over those already modeled by the graph itself, only in the
collection with temporal locality, which tends to present more correlated topics,
increasing the overlapping among documents.

Collective
Aggregated
Collectives Gain (%)

TV series
E.D.

42.45  43.59  58.84  5.56  11.11  5.31 

USA elections
Q.D.
E.D.

Q.D.

methods in USA Election. It means that the collective analysis
added useful information for SA, over those already modeled by
the graph, only in one of the evaluated domains. We hypothesize
that such results are related to the level of overlapping among
distinct documents existing in each collection, which is affected
by the temporal locality.4 Unlike TV Series, on which tweets tend
to be more correlated, once they were published in temporally
close moments, USA Elections comprises tweets that are less well
correlated, published at various moments. Since the three metrics
presented similar behavior in all experiments, in order to shorten
discussions, the remainder of the paper takes into account only the
E.D. and Q.D. measures.

A straightforward strategy to measuring such overlap on each
dataset would be by assessing the edges frequencies in the
analyzed graph of terms. Fig. 6(a) plots the CCDF (Complementary
Cumulative Distribution Function) of edges frequencies in the
evaluated datasets. We note that high edges frequencies present
higher probability of occurrence in TV series than in USA Election,

4 We assume that temporal locality affects overlapping since it has been observed
on the Web [38], although we do not know to what extent it happens on our
datasets. A further study about this issue is an immediate future work.

 0 0.05 0.1 0.15 0.2 0.25 0.31246810DistanceMaximum Length(l)Euclidean DistanceQuadratic-Form Distance 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.41246810DistanceMaximum Length(l)Euclidean DistanceQuadratic-Form Distance36

L. Rocha et al. / Web Semantics: Science, Services and Agents on the World Wide Web 34 (2015) 2739

(a) Probability distribution.

(b) Transition probability.

Fig. 6. Analysis of transition probability per edges frequency. High edges frequencies present higher probability of occurrence in TV series than in USA Election (a), evincing
more overlapping on the former dataset. Also, the most frequent edges tend to present higher transition probabilities in both collections (b), becoming more relevant to
determine the probability of each sentiment class.

Table 6
Results comparing the aggregated method with the collective one for USA Elections
considering only frequent edges. In this case, SACI outperformed aggregated
analysis that exploits only the relational information expressed in the graph,
demonstrating that overlapping is crucial for SACI.

Gain (%)


Datasets
Metrics
E.D.
Q.D.

USA elections with frequency  20
Aggregated
Collective

evincing more overlapping among distinct posts on the former.
Fig. 6(b) presents the mean transition probability per frequency of
occurrence of the edges. For this analysis, we leave out edges with
frequency 1, since their transition probability is 100%. We observe
that the most frequent edges tend to present higher transition
probabilities in both collections. Since the transition probabilities
affect directly the probability of each sentiment class, edges with
higher probabilities become more relevant for SACI, prioritizing
the consensual opinions captured by the overlapping. As in USA
Elections there are fewer frequent edges, the collective analysis is
dominated by infrequent edges, such as in individual analyses.

Aiming to validate this hypothesis, we derive a synthetic dataset
from USA Elections that contains tweets presenting at least one
edge with frequency greater than or equal to 20. Table 6 shows
SACIs results for this dataset. In this case, collective analysis reduces the errors by 88.24% compared to aggregated inspection,
validating the hypothesis that SACIs analysis depends on the
existence of overlapping discussions among documents.

4.3.4. Aggregated vs. collective analysis

In order to evaluate the gains of collective analysis against
aggregate one, we conducted a set of experiments designed to
answer five main issues inherent to this comparison. We discuss
in detail each of these issues raising some important conclusions
about collective analysis.
1. How does the collective analysis compare to the aggregated one?

We contrasted aggregated analysis derived from traditional SA
algorithms with SACI taking into account the adopted approximation error metrics in both domains, as shown in Table 7. We aggregated individual classifications performed by each traditional
method, determining the probability of occurrence of each sentiment class as the percentage of individual documents assigned
to it. Again, we evaluate SACI considering the best parameter setting presented in Section 4.3.2 and all experimental setup defined

in Section 4.3.1. We observe that SACI outperforms all other techniques in the TV Series dataset, which exhibits high levels of over-
lapping, reducing the approximation errors by 86.14% and 77.32%,
w.r.t. E.D. and Q.D., respectively. On the other hand, SACI showed to
be statistically comparable to the aggregated analysis for USA Elec-
tion, since the overlapping of information in this case is restricted,
as previously discussed.
2. Is SACI good to perform individual classifications?

As discussed in Section 3.2.2, SACI can perform individual classification of documents. Table 8 presents the results achieved by
each of the implemented techniques when we perform this task,
without any type of aggregation on the results. We present the results in terms of Accuracy and Macro-F1 and consider the sentiment class with the highest probability in the individual analysis
of each document as the predicted one by SACI. We note that, in
most of the cases, SACIs performance was worse than the other al-
gorithms, which are originally designed to perform individual clas-
sifications. This result also shows that our comparison is fair, as we
chose good individual classification algorithms to derive our aggregate approach.

Considering the performance of traditional methods, in most
of the cases, supervised strategies were better than unsupervised
ones, corroborating the literature results. However, it is important
to mention that supervised strategies have high computational
costs and need to be re-trained periodically. Another important
observation is that results related to TV Series were better than
those of USA Elections. This fact suggests that, even in the
individual analysis, performed by traditional SA techniques, the
overlapping of information may help to achieve more accurate
classification models.

Although these results demonstrate that SACI is not suitable for
individual classifications, they also bring an important conclusion.
Good individual sentiment classifications do not guarantee good
collective analysis and vice-versa. We observe this fact by contrasting Table 8 against Table 7. This fact corroborates our hypothesis
that a proper identification of collective opinions does not require
a prior and good identification of individual opinions. We explain
this counter intuitive conclusion by the fact that exploiting the
overlapping among documents brings additional information useful for SA.
3. What is a meaningful approximation error for the collective
sentiment?

Despite the results presented in Table 7 depict SACI as the best
method for collective sentiment, the relevance of these values is

 0.2 0.4 0.6 0.81 1.2210202838467482101109164172Average Transition ProbabilityEdges FrequencyTV SeriesUSA ElectionsL. Rocha et al. / Web Semantics: Science, Services and Agents on the World Wide Web 34 (2015) 2739

Table 7
SACIs collective analysis compared with others SA techniques. SACI outperforms all other techniques in TV Series, which has high overlapping of topics due to its temporal
locality, while it is statistically comparable to the other methods in USA Election, which exhibits low overlapping.
USA elections
E.D.

Value

TV series
E.D.

Value

SACIs Gains
14.29% 
0.00% 
14.29% 
38.46% 

Dataset
Metric

Q.D.

Value

SACIs Gain
62.71% 
54.17% 
45.00% 
77.32% 

SACIs Gain
51.59% 
53.08% 
65.92% 
86.14% 

SACIs Gain
0.99% 
6.42% 
27.50% 
1.92% 

Q.D.

Value

Table 8
SACIs individual analysis compared with others SA techniques. In most of the cases, SACI underperformed the others methods, demonstrating that good individual
classifications do not necessarily mean good approximations to the collective sentiment and vice-versa.

Dataset
Metric

TV series
Accuracy (%)

Value

SACIs Gain
1.37% 
2.15% 
32.26% 
35.66% 

Macro-F1 (%)

Value

SACIs Gain
20.91% 
6.90% 
29.38 % 
40.40 % 

USA elections
Accuracy (%)

Value

SACIs Gain
11.11% 
31.68% 
13.95% 
19.32% 

Macro-F1 (%)

Value

SACIs Gains
11.55% 
35.26% 
14.14% 
20.91% 

unclear. Also, we are aware that percentages on small quantities
tend to inflate differences. Understanding the actual relevance of
such differences for the final users requires better describing the
types of mistake on SA that would affect users actions, such as decision making. In this sense, we consider three relevant types of
collective sentiment distribution. The first one includes distributions that present one major sentiment class. In this case, overestimating and underestimating the major class would lend users to
wrong conclusions. The second type refers to balanced occurrences
of the three sentiment classes. Distorting this equilibrium would be
a hazardous mistake of SA methods. Finally, we consider scenarios
with one almost inexistent class that should not be overestimated.
Based on these scenarios, we evaluate the chances of a SA
method making each one of the raised mistakes according to the
observed approximation errors. It is expected that low approximation errors represent lower chances of making these mistakes.
Thus, we relate the approximation error value with the difference between the actual percentage of occurrence of the relevant
class in each type of mistake and the percentage predicted by each
method, such as follows. First, we define 10 random samples of
each dataset for each type of mistake, obeying the corresponding
class distribution. Then, we calculate the approximation error and
the difference of percentage in each sample. Finally, we define the
mean approximation error and difference of percentage found for
all samples. Due to lack of space, we restrict our discussion to the
first type of mistake, which is common in several scenarios with
predominance of the neutral class, and the Q.D. metric, such as presented by Fig. 7. Indeed, the higher the approximation error, the
higher the difference of percentages. It means that high approximation errors represent significant differences in the distribution
of collective sentiment observed in a document set, which may
induce wrong decision making. Considering again the results, we
found that SACI overestimates or underestimates the major class
by 3% only. On the other hand, the approximation error achieved
by PP (0.09) corresponds approximately to 20% of difference. When
the neutral class is the major one, such difference means that we
are inducing a wrong decision making, since we are increasing the
percentage of the positive and negative classes by 20%.
4. How much information does SACI need to achieve a close
approximation to the actual collective sentiment?

In order to answer this question, we perform an experiment
on which we evaluate the approximation error varying the total of analyzed tweets. For this experiment, we have used the TV

Fig. 7. Correspondence between approximation error (Q.D.) and hazardous
mistake in predominant classes. While SACI introduces small variations on the
major class, other SA methods overestimate or underestimate such class affecting
users action wrongly.

Impact of the amount of information on SACIs collective sentiment analyses.

Fig. 8.
We found that 1500 tweets were enough to converge the approximation error.

Series collection, since it maintains the temporal locality of the
discussed topics, a fundamental requirement of SACI. For sake of
discussion, we consider only the Q.D. approximation error metric,
since both metrics presented similar results. Fig. 8 presents these
results. As expected, the higher the number of tweets evaluated
by SACI, the smaller the approximation error. Further, 1500 tweets
were enough to achieve a convergence of the error close to the best
approximation found by SACI.
5. What is the overhead, w.r.t. computational costs, related to SACIs
collective analysis?

Besides accuracy, efficiency is an important requirement for SA
on high demanding scenarios. SACI presents an efficient collective

 0.020 0.04 0.06 0.08 0.1 0.12 0.14 0.16Approximation Error (Q.D.)SACIWWHDLPPLVPP05101520253035Difference of Percentage (%)Quadratic DistanceDataset Size (# of tweets)00.010.020.030.040.050.06010002000300038

L. Rocha et al. / Web Semantics: Science, Services and Agents on the World Wide Web 34 (2015) 2739

analyses such as evaluation of governments. While some analyses
could be derived by tracking explicit mentions to a president,
we could define complementary analyses by evaluating his/her
Cabinet as well.

The second feature refers to efficacy. As discussed in Section 4,
by exploiting the overlapping among distinct posts, SACI is able
to outperform state-of-the-art methods w.r.t. collective sentiment
analysis. At this way, the challenge posed by the absence of
contextual information present in short textual data is attenuated
by a collective analysis of bunches of posts simultaneously.

Since we are concerned about real-time analysis of data
streams, efficiency and scalability are of paramount relevance,
defining our third feature. SACI-Web is able to gather and analyze
huge volumes of data, providing only few minutes of delay between the moment a set of posts are issued and the moment we
present to the users the collective sentiment expressed on such
posts. Indeed, the main constraint about this delay is the minimum
period of time required to compose a representative set of posts,
which depends on the analyzed topics. Thus, users can set distinct
periods of gathering for each analysis they start on SACI-Web.
A version of SACI-Web is currently available on http://dcomp.
ufsj.edu.br/saciWeb/ (User = swsa and Password = swsa). Users
can start new analysis by providing keywords related to the
target entities to be tracked by SACI-Web. We also present some
example analyses for the users. For instance, we conducted a
real-time analysis on the broadcast of the XLVIII Super Bowl
2014, evaluating tweets related to both teams: Seattle Seahawks
and Denver Broncos. We performed two distinct analyses, one
related to Broncos (using only the keyword broncos) and another
related to Seahawks (using only the keyword seahawks), which
gathered tweets from 02/01/2014 04 PM to 02/03/2014 8 AM.
During this period SACI-Web collected approximately 2,500,000
tweets, achieving peaks of 180,000 tweets per hour during the
game (the maximum limit allowed by Twitter API). Also, we set
the minimum period of gathering for this analysis as 2 min, which
means that at each 2 min the collective sentiment is updated. We
used a consolidated lexicon generated by our approach described
in Section 3.1. In this case, after an initial gathering of tweets,
we selected the 100 most frequent terms and manually classified
each of them. Then, our method propagates the sentiments of
these seeds along the graph of synonyms and antonyms built
with the thesaurus. Fig. 10 shows the results of this analysis.
Before the game, both teams were well evaluated by Twitter users,
however, when the game started, the evaluation of Seahawks
became more positive whereas the sentiment related to Broncos
got more negative, reflecting the fact that Seahawks played better
and won the match. Despite the fact that this finding does not
validate SACI-Webs results, it supports the collective sentiment
identified by our tool.

6. Conclusion and future work

This work demonstrates that a more accurate and efficient
analysis of collective sentiments may be reached by classifying
bunches of documents simultaneously, exploiting the overlapping
among them. Further, we found that good individual sentiment
classifications do not guarantee a good collective analysis and vice-
versa. By evaluating SACI, a new lexicon-based unsupervised SA
method that extracts collective sentiments from a transition graph
of terms, on two real domains, we reduced the approximation
errors by 86% over methods that aggregate individual analysis,
with a significantly low computational complexity. These results
point out SACI as a promising collective SA method for short textual
data streams. Indeed, the consolidation of a SACI-based Web tool
for real-time SA of tweets evinces the practical usefulness of SACI.
In summary, we highlight as our main contributions for the area:

Fig. 9. SACIs execution time. SACIs execution time grows linearly with the number
of analyzed tweets.

analysis due to three main characteristics. First, the training step of
SACI consists in the straightforward construction of a graph among
distinct terms observed in a document set. Second, this graph is
defined over the space of terms, which tends to be much smaller
than the space of posts available in Social Media [27]. Although in
our datasets the number of distinct terms is larger than the number
of posts, as the number of posts increases the number of distinct
post tends to overcome the number of distinct terms [39]. Third,
as new data arrive, the graph can be updated, avoiding the need
for model reconstruction.

Aiming to corroborate this statement, we evaluate the worstcase asymptotic complexity of SACI, which depends on the total
number of distinct paths. In the worst case, there is no overlapping
of paths. Assuming|T| as the mean length of all paths, the complexity of analyzing a single path is O(|T|). For analyzing a whole graph
with |D|  |F| distinct paths, where |D| is the number of distinct
documents to be analyzed and|F| the mean number of distinct sentences within each document, such complexity is O(|D||F||T|).
As|D| is larger than|T| and|F|, the complexity of SACI is linear w.r.t.
the total of distinct documents. Thus, SACI is also scalable in domains with documents containing long sentences, such as product
reviews. Additionally, we perform an experiment measuring SACIs
execution time with distinct number of evaluated tweets. For this
experiment, we use a large sample from TV Series, where we do not
know the sentiment class of each post, since our goal is constrained
to efficiency. The execution times, presented in Fig. 9, were measured by considering the mean of 10 executions in an Intel Core i5
2.4 GHz and 4 GB of RAM. We observe that, indeed, SACIs execution
time grows linearly with the number of analyzed tweets. Thus, it is
possible, for instance, to process about 10,000 tweets per second,
evincing the applicability of SACI even for real-time analysis.

5. Real-time web analytic tool

Aiming to demonstrate the usefulness of SACI in data stream
scenarios, we also present SACI-Web, a tool prototype for realtime SA on Twitters content. SACI-Web collects tweets related to
any topic defined by a user and extracts the collective sentiment
observed in the set of tweets collected on a pre-determined period
of time. We consider SACI-Web as an SA tool suitable for data
stream scenarios due to three main features.

First, SACI-Web allows users to evaluate the collective sentiment
related to multiple entities simultaneously. For instance, users
may be interested in the collective sentiment about a company
(e.g., Apple). Through SACI-Web, there are two ways to identify
this sentiment. By tracking mentions to Apple on Twitter directly
or tracking simultaneously distinct products closely related to
this company (e.g., iphone, ipad). While in the former case, only
names, hashtags and acronyms related to Apple are used as central
nodes on the graph evaluated by SACI, the latter one defines a set
of central nodes related to all products. Thus, SACI can identify
the collective sentiment for a same real-word entity by different
perspectives. Such flexibility would be useful, mainly for complex

0123456016000320004800064000Time (s)Dataset size (# of tweets)y=8.20-5x+0.07L. Rocha et al. / Web Semantics: Science, Services and Agents on the World Wide Web 34 (2015) 2739

Fig. 10. Example of SACI-Webs usage. First, we collected tweets related to Denver Broncos and Seattle Seahawks during the broadcast of XLVIII Super Bowl 2014. Then, by
applying SACI, SACI-Web shows the audiences sentiment about this game within 2 min of delay.

 Proposal of a new consolidation strategy for sentiment lexicon
that classifies the terms according to each domain of analysis.
 Comparative evaluation between aggregated and collective
strategies for collective sentiment analysis;
 Proposal of SACI, an efficient method able to exploit overlapping
among distinct documents for the sake of collective SA;
 Consolidation of two new gold-standard Twitter dataset;
 Consolidation of a Web analytic tool for real-time collective
sentiment analysis.
As future work, we aim to contrast SACI against other state-
of-art unsupervised SA methods using SA benchmarks, in order
to determine the relevance of collective analysis in well-known
scenarios. Further, we highlight studies about exploiting other
types of information extracted from posts [8,6,21,22], such as
emoticons or social connections among users, in SACIs analyses.
Although extitSACI exploits only terms and their relationships,
we aware that these other types of information are relevant for
SA. Hence, extending our method to incorporate new type of
information represents an important research direction.

Acknowledgments

This work was partially supported by CNPq, CAPES, FINEP,

Fapemig, and INWEB.
