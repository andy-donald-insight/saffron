Web Semantics: Science, Services and Agents on the World Wide Web 32 (2015) 4353

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

journal homepage: www.elsevier.com/locate/websem

Ontology paper
The Data Mining OPtimization Ontology
C. Maria Keet a,, Agnieszka awrynowicz b,, Claudia dAmato c, Alexandros Kalousis d,
Phong Nguyen e, Raul Palma f, Robert Stevens g, Melanie Hilario h
a Department of Computer Science, University of Cape Town, South Africa
b Institute of Computing Science, Poznan University of Technology, Poland
c Department of Computer Science, University of Bari, Italy
d Department of Business Informatics, University Of Applied Sciences, Switzerland
e Department of Computer Science, University of Geneva, Switzerland
f Poznan Supercomputing and Networking Center, Poland
g School of Computer Science, University of Manchester, United Kingdom
h Artificial Intelligence Laboratory, University of Geneva, Switzerland

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 12 March 2014
Received in revised form
14 November 2014
Accepted 6 January 2015
Available online 4 February 2015

Keywords:
Ontology

Data mining
Meta-learning
Semantic meta-mining

The Data Mining OPtimization Ontology (DMOP) has been developed to support informed decisionmaking at various choice points of the data mining process. The ontology can be used by data miners
and deployed in ontology-driven information systems. The primary purpose for which DMOP has been
developed is the automation of algorithm and model selection through semantic meta-mining that makes
use of an ontology-based meta-analysis of complete data mining processes in view of extracting patterns
associated with mining performance. To this end, DMOP contains detailed descriptions of data mining
tasks (e.g., learning, feature selection), data, algorithms, hypotheses such as mined models or patterns,
and workflows. A development methodology was used for DMOP, including items such as competency
questions and foundational ontology reuse. Several non-trivial modeling problems were encountered and
due to the complexity of the data mining details, the ontology requires the use of the OWL 2 DL profile.
DMOP was successfully evaluated for semantic meta-mining and used in constructing the Intelligent
Discovery Assistant, deployed at the popular data mining environment RapidMiner.

 2015 Elsevier B.V. All rights reserved.

1. Introduction

The primary goal of the Data Mining OPtimization Ontology
(DMOP, pronounced dee-mope) is to support all decision-making
steps that determine the outcome of the data mining (DM)
process. It can be used by data mining practitioners to inform
manual selection of various ingredients (algorithms, models, and
parameters) that are used for constructing DM processes. Most
of all, DMOP has been designed to support the automation of such
selections in order to optimize DM processes.

 Corresponding authors.

E-mail addresses: mkeet@cs.uct.ac.za (C.M. Keet),

agnieszka.lawrynowicz@cs.put.poznan.pl (A. awrynowicz),
claudia.damato@uniba.it (C. dAmato), Alexandros.Kalousis@hesge.ch
(A. Kalousis), Phong.Nguyen@unige.ch (P. Nguyen), rpalma@man.poznan.pl
(R. Palma), robert.stevens@manchester.ac.uk (R. Stevens),
melanie.hilario@unige.ch (M. Hilario).

http://dx.doi.org/10.1016/j.websem.2015.01.001
1570-8268/ 2015 Elsevier B.V. All rights reserved.

The DM process is standardized by CRISP-DM [1], a highlevel standard DM process model. According to CRISP-DM, the
DM process is composed of the following phases: business
understanding, data understanding, data preparation, modeling,
evaluation, and deployment. DMOP focuses on those three
phases that can be best automated: from data preparation to
evaluation. CRISP-DM provides only methodological framework
and guidelines, however, and not details on the internals of the
DM process components. Similarly, other available DM models
and ontologies (discussed in Section 2.2) treat DM algorithms as
black boxes, focusing mostly on the inputs (data) and outputs
(hypotheses) the algorithms specify. The optimization of a DM
process requires knowledge not only on how components from
its different phases interact, but also on how the components
internal characteristics influence the process performance. Thus,
despite the existence of DM domain models, the optimization of
the DM process was not possible because the necessary additional
detailed knowledge was missing. This means that a comprehensive
analysis of DM processes was not possible, and, consequently

C.M. Keet et al. / Web Semantics: Science, Services and Agents on the World Wide Web 32 (2015) 4353

(e.g. datasets, workflows, results). The two-tiered top layer in the
figure represents DMOP (denoted TBox) and its KB (denoted ABox),
where the latter uses knowledge from DMOP to model existing
data mining algorithms. Both, DMOP and its associated KB, are
implemented in OWL 2. An RDF database (denoted Operator DB)
contains descriptions of operators, i.e., implementations of algorithms described in DMOP and particularly those implementations
that are a part of popular DM software (such as RapidMiner1 or
Weka2). The ABox, together with the operator database, provides
accepted knowledge about DM tasks, algorithms and operators. Altogether these are application-independent resources that constitute the meta-miners prior DM knowledge. Meta-data recorded
during data mining experiments are described using DMOP and
its associated resources, and thus constitute application-specific
training and testing data for a meta-miner. They are stored in
application-dedicated RDF triple stores (denoted DMEX-DBs) and
describe datasets, workflow descriptions, and data mining experi-
ments.

This paper describes v5.5 of DMOP, which has 723 classes,
96 object properties, 15 data properties, and 2425 logical axioms
(4291 in total, including annotations), and has a SROIQ(D)
DL expressivity; it can be downloaded from http://www.dmo-
foundry.org.

DMOP provides a unified conceptual framework for analyzing DM tasks, algorithms, models, datasets, workflows and performance metrics, and their relationships, as described in Section 3
whilst methodological aspects are described in Section 2. To fulfil requirements of this in-depth analysis, we have encountered
a number of non-trivial modeling issues in DMOP development,
of which the main ones are discussed in Section 4. DMOPs goals
and required coverage resulted in using almost all OWL 2 features.
DMOP was successfully applied in semantic meta-mining, and deployed in RapidMiner data mining environment (download statistics provided), which is described in Section 5. Conclusions are
drawn in Section 6.

2. Ontology development

There are several methodologies for ontology development in
the literature, including Methontology [4], NeON [5], Melting
Point [6], and DiDOn [7]. Although these methodologies may differ in scope and focus, they have some commonalities that can
be roughly mapped in three main stages of the ontology development process: (1) specification with a domain analysis (including
use cases, competency questions), (2) conceptualization, formal-
ization, and implementation, and (3) maintenance with refinement
and evolution of the ontology. Many developers have contributed
to DMOP over the years, who had different perspectives on extant
methodologies, and had different levels of modeling experience as
to whether sticking to a single methodology is important, and if so,
a lean one or a comprehensive one. Therefore, the common components were taken as reference and guideline, and tailored it to
the specific micro-level details as applicable to DMOP.

During the first stage, requirements with competency questions
 i.e., questions that an ontology should be able to answer  were
formulated (see Section 2.1), the use cases for semantic metamining specified, such as providing DM expertise to an intelligent
knowledge discovery assistant (see Section 5.1), and related
domain ontologies were investigated and assessed to what extent
they would be able to meet the requirements (see Section 2.2). The
outcome of that stage was fed into stage two, leading to a design of
the DMOP architecture, and the subsequent ontology authoring by

1 http://rapidminer.com/.
2 http://www.cs.waikato.ac.nz/ml/weka/.

Fig. 1. Architecture of the ontology, its associated knowledge base, operator
database, and satellite triple stores, which are organized conceptually (right) and
in implementation (left), resulting in an integrated pyramid of 4 layers.

nor was the optimization of the performance of the DM process.
DMOP fills this gap. It conceptualizes the internals of the DM
algorithms: their multiple characteristics and building blocks,
such as algorithm assumptions, optimization problems they solve,
decision strategies, and others. This distinguishing design feature
(beyond the state of the art) allows one to use DMOP to optimize
DM processes with semantic meta-mining [2], which is a novel form
of meta-learning.

Meta-learning [3], or learning to learn,

is defined as the
application of machine learning techniques to meta-data about
past machine learning experiments with the goal of modifying
some aspects of the learning process in order to improve the
performance of the resulting model. Traditional meta-learning
focused only on the central (modeling) phase of the DM process,
where machine learning algorithms are executed to build a model.
However, the quality of the mined model depends strongly also on
other phases of a DM process. Traditional meta-learning regarded
learning algorithms as black boxes, correlating the observed
performance of their output (learned model) with characteristics
of their input (data). However, the algorithms that have the same
types of input/output may differ in internal characteristics.

Semantic meta-mining is distinguished from traditional metalearning by the following three properties. First, it extends the
meta-learning approach to meta-mining, i.e. learning from the full
DM process. Second, it is co-driven by knowledge of DM process
and its components, which are represented in the DM ontology and
knowledge base (KB), in contrast to purely data driven traditional
meta-learning. Third, it breaks open the black box by explicitly
analyzing DM algorithms along various dimensions to correlate
observed performance of learned hypotheses resulting from DM
processes with both data and algorithm characteristics. Semantic
meta-mining is thus an ontology-based, process-oriented form of
meta-learning that exploits in-depth knowledge of DM processes.
To support semantic meta-mining, DMOP contains a detailed
taxonomy of algorithms used in DM processes. They are each described in terms of their underlying assumptions, cost functions
and adopted optimization strategies, generated classes of hypotheses (models or pattern sets), and other properties. Following such
a glass box approach makes explicit internal algorithm charac-
teristics. This allows meta-learners using DMOP to generalize over
algorithms and their properties, including those algorithms that it
did not learn from directly.

Performing semantic meta-mining requires knowledge about
various layers of data mining experiments, which are reflected in
the DMOP architecture (see Fig. 1): a top-layer with the formal
conceptual framework of the data mining domain (e.g. algorithm
class specification), a middle layer of accepted knowledge about
the DM domain (e.g. particular algorithms and their known imple-
mentations), and a bottom layer of application specific DM data

people residing at different institutions and with overlapping and
complementary knowledge of the subject domain. The tool used
was Protege 4.x.3 The ontology has gone through various cycles
of design and evaluation, including a testing phase on meeting
the requirements. Besides content experts, also ontology experts
were consulted, who provided additional modeling guidance and
solutions. The ontology is in the third stage since late 2011,
where novel methods and tools at the level of axiom enhancement
and debugging are being used, such as [8,9], new sections have
been added, such as on clustering, and, as the ontology became
larger and more complex, more structure has been added to the
ontology by aligning it to a foundational ontology (see Section 2.3),
which are the main changes that resulted into a v5.3 and v5.4 of
DMOP. Tidying up the ontology merited a v5.5, which entailed,
among others, adding more annotations (n = 188) and removing
unused entities (n = 108). The ontology is now also available in
documentation format, generated by LODE [10].

We will highlight three salient aspects of the process followed:
the competency questionsimportant for the success of deployment of the ontology; related domain ontologies to assess to what
extent we could reuse existing domain ontologies in data mining;
and the alignment of DMOP with a foundational ontology.

2.1. DMOP competency questions

The principal competency question for the DMOP was:

CQ1.1 Given a data mining task/dataset, which of the valid or
applicable workflows/algorithms will yield optimal results
(or at least better results than the others)?

This competency question is decomposed into many other questions and we present a selection of them here. Coarse-grained
questions include:
CQ2.1 Given a set of candidate workflows/algorithms for a given
task/dataset, which dataset characteristics should be taken
into account in order to select the most appropriate one?

CQ2.2 Given a set of candidate workflows/algorithms for a task/
dataset, which workflow/algorithm characteristics should
be taken into account in order to select the most appropriate
one?

which can be refined into more detailed questions, such as:
CQ3.1 Are there learning algorithms that I can use on highdimensional data without having to go through preliminary
dimensionality reduction?

CQ3.2 Which induction algorithms should I use (or avoid) when

my dataset has many more variables than instances?

CQ3.3 Which learning algorithms perform best on microarray or

mass spectrometry data?

How they are satisfied will be discussed in Section 3.5 (CQ3.1) and
5.2 (CQ1.1, CQ2.x, CQ3.2, and CQ3.3).

2.2. Related domain ontologies

An overview of early approaches to methodical descriptions of
DM processes may be found in [2]. The majority of work concerning
formal representation of data mining in ontology languages is
aimed at the construction of DM workflows. One strand of
this research deals with the development of distributed DM
applications on the Grid [11,12]. The pre-OWL DAMON ontology
provides a characterization of available data mining software
to enable semantic searching for appropriate DM resources and

tools [11]. The ontology of GridMiner Assistant (GMA) [12] aims
to support dynamic, interactive construction of DM workflows in
Grid-enabled data mining systems.

Other ontologies developed for DM workflow construction are
KDDONTO [13], KD ontology [14] and DMWF [15], all of them using
OWL as a major representation language. These ontologies focus
on modeling an algorithms inputs/outputs to enable generation
of valid compositions of them. For instance, a Hierarchical Task
Network (HTN) based planner eProPlan [15], uses DMWF to
plan a set of valid workflows based on operator (algorithm
implementation) preconditions and effects modeled in DMWF by
means of SWRL4 rules.

Few existing DM ontologies go beyond supporting workflow
construction. OntoDM [16] aims to provide a unified framework
for data mining and contains definitions of the basic data
mining concepts, but lacks a particular use case. Expose [17]
aims to provide a formal domain model for a database of data
mining experiments. It uses OntoDM together with the data
mining algorithms from DMOP, and a description of experiments
(algorithm setup, execution, evaluation) to provide the basis of
an experiment markup language. The primary use of OntoDM and
Expose may thus be viewed as providing controlled vocabulary for
DM investigations.

None of the related ontologies was developed with the
goal of the optimization of the performance of DM processes,
what is expressed by our principal competency question. They
do not provide sufficient level of details needed to support
semantic meta-mining. The ontologies that are focused on
workflow construction do not model the internal characteristics of
algorithms (cf. competency question CQ2.2) but just their inputs
and outputs. Hence they help in answering the question how to
build a valid workflow, but not necessarily how to build an optimal
workflow.

2.3. Alignment of DMOP with a foundational ontology

There are multiple good reasons to use a foundational ontology
in theory, and it has been shown to improve the ontology quality,
understandability, and interoperability in praxis [18]. It comes at
the cost for figuring out how to align a domain ontology with it,
and it can have implications for the language used for the overall
ontology. The principal issues from a language viewpoint are: (1) to
import or to extend, (2) if import, whether that should be done in
whole or just the relevant module extracted from the foundational
ontology, (3) how to handle the differences in expressiveness that
may exist  and possibly be required  between the foundational
ontology and the domain ontology, and (4) how to rhyme different
modeling philosophies between what comes from Ontology, what
is represented in foundational ontologies, and what is permitted in
OWL.5

There were two main reasons to align DMOP with a foundational ontology; first, they have solutions to the modeling issue about attributes and data properties for measurements in
data mining; second, the reuse of the foundational ontologys object properties (see Sections 3.4 and 4.3). In order to determine
the most suitable foundational ontology to be used for modeling
DMOP, both a manual assessment was conducted and the automated recommender ONSET v1.2 [19] was used. The outcome of
this study determined DOLCE [20] as the comparatively optimal
foundational ontology for DMOP, given its requirements. The reasons were, among others, that there is an OWL version of it, that
the modeling of measurements and parameters needed by DMOP

3 http://protege.stanford.edu.

4 http://www.w3.org/Submission/SWRL.
5 i.e., features that are objectionable from an ontological viewpoint, such as class-
as-instance, nominals, and data properties.

C.M. Keet et al. / Web Semantics: Science, Services and Agents on the World Wide Web 32 (2015) 4353

Fig. 2. Simplified overview of the core concepts of DMOP.

was solved in DOLCE with its qualities and qualia (see Section 4.3),
that it accommodates abstract entities (part of the DMOP domain),
and that some of the object properties in DOLCE matched the ones
in DMOP or were highly usable (see Section 3.4). In the meantime,
it has been shown that it is not impossible to swap DOLCE for BFO
or GFO, but most alignments will be lost in the process due to the
use of a substantial amount of entities specific to DOLCE [21].

Determining the suitable DOLCE category for alignment and
carrying out the actual mapping has been done manually (see
Section 3.4); some automation to suggest mappings would be a
welcome addition.

2.4. Contributing to DMOP

There are now three ways of contributing to the ontology, each
targeted to a different type of contributor. Mode 1 is the open,
bottom-up collaborative ontology development approach for domain and/or ontology experts, which relies on Cicero Argumentation Tool6 [22], the DMOP forum for input, and the Editorial Board
to review community input.

Mode 2: Data miners not familiar with ontology tools can fill
in predesigned templates  alike user-friendly Ontology Design
Content Patterns  to populate areas of the ontology with relatively
stable concept and property definitions, e.g. relating operators to
their algorithms, which will be screened by the ontologys Editorial
Board prior to integration into the target ontology.

Mode 3: The contributor is a data mining expert and conversant
with ontology development who not only contributes new data
mining content, but also defines new concepts and relations
needed for content formalization, so that the domain expert on
her specific topic will impact ontology design (at least locally)
and conceptualization. The expert contributor will develop the
assigned module using her preferred ontology editor, and will
submit it to the ontologys Editorial Board in the form of an
OWL file. After validation, the module becomes an integral part
of the ontology. These modes of collaboration are accessible from
http://www.dmo-foundry.org.

3. DMOPs contents

The core concepts of DMOP (Fig. 2) are the different ingredients

that go into the data mining process (DM-Process):

6 http://cicero.uni-koblenz.de/wiki/index.php/Main_Page.

 The input of the process is composed of a task specification (DM-
Task) and training/test data (DM-Data) provided by the user;
 Its output is a hypothesis (DM-Hypothesis), which can take the
form of a global model (DM-Model) or a set of local patterns
(DM-PatternSet).
Tasks and algorithms are not processes that directly manipulate
data or models, rather they are specifications of them:
 A DM-Task specifies a DM process (or any part thereof) in terms
of the input it requires and the output it is expected to produce.
 A DM-Algorithm is the specification of a procedure that
addresses a given DM-Task, while a DM-Operator is a program
that implements a given DM-Algorithm and that is executed by
a DM-Operation.
 Instances of DM-Task and DM-Algorithm do no more than
specifying their input/output types (only processes have actual
inputs and outputs).

Some of the object properties of DM processes are:
 It hasInput and it hasOutput some IO-Object (DM-Data or DM-
Hypothesis);
 A process that executes a DM operator also realizes the DM
algorithm that isImplementedBy that operator;
 A DM algorithm addresses a DM task, and the process achieves
the DM task addressed by the algorithm.

Finally, a DM-Workflow is a complex structure composed of DM-
operators, while a DM-Experiment is a complex process composed
of operations (or operator executions). An experiment is described
by all the objects that participate in the process: a workflow,
datasets used and produced by the different data processing
phases, the resulting models, and meta-data quantifying their
performance.

3.1. DM tasks

The top-level DM tasks listed below are defined by their inputs

and outputs.

A DataProcessingTask receives and outputs data. Its four subclasses produce new data by cleansing (DataCleaningTask), reducing (DataReductionTask), extracting a compact representation
(DataAbstractionTask) or otherwise transforming the input data
(DataTransformationTask). These classes are further articulated in
subclasses representing more fine-grained tasks.

An InductionTask consumes data and produces hypotheses.
It can be either a ModelingTask or a PatternDiscoveryTask,
based on whether it generates hypotheses in the form of global

Fig. 3. Data characteristics modeled in DMOP. Rectangles: subclasses of DM-Data class; unbounded text near the rectangles denote subclasses of the DataCharacteristic class
associated to a DM-Data class through an OWL object property, where those in italics font are information-theoretic measures and the ones in bold are geometric indicators.

models or local pattern sets. Modeling tasks can be predictive
(e.g. classification) or descriptive (e.g., clustering), while pattern
discovery tasks are further subdivided into classes based on
the nature of the extracted patterns: associations, dissociations,
deviations, or subgroups.

A HypothesisProcessingTask consumes hypotheses and transforms (e.g., rewrites or prunes) them to produce enhanced  less
complex or more readable  versions of the input hypotheses.
A HypothesisEvaluationTask quantifies the quality of an induced
hypothesis with respect to a specific criterion (e.g., predictive per-
formance). A HypothesisApplicationTask applies an induced hypothesis to new data.

3.2. Data

As the primary resource that feeds the knowledge discovery
process, data have been a natural research focus for data miners.
Over the past decades meta-learning researchers have actively
investigated data characteristics that might explain generalization
success or failure. Fig. 3 shows the characteristics associated
with the different Data subclasses (shaded boxes). Most of these
are statistical measures, such as the number of instances or the
number of features of a dataset. Others are information-theoretic
measures (italicized in the figure). Characteristics in bold font are
geometric indicators of dataset complexity, such as the maximum
value of Fishers Discriminant Ratio that measures the highest
discriminatory power of any single feature in the dataset (see [23]
for detailed definitions).

3.3. DM algorithms

The top levels of the DM-Algorithm hierarchy reflect those of
the DM-Task hierarchy, since each algorithm class is defined by
the task it addresses. However, the DM-Algorithm hierarchy is
much deeper than the DM-Task hierarchy: for each leaf of the
task hierarchy, there is often a dense subhierarchy of algorithms
that specify diverse ways of addressing each task. For instance,
the leaf concept ClassificationModelingTask maps directly onto
the ClassificationModelingAlgorithm class, whose three main
subclasses  generative, discriminative, and discriminate function
algorithms [24]  are illustrated here. A GenerativeAlgorithm
computes the class-conditional densities p(x|Ck) and the priors
p(Ck) for each class Ck. Examples of generative methods are
normal (linear or quadratic) discriminant analysis and Naive

Bayes. A DiscriminativeAlgorithm, such as logistic regression,
computes posterior probabilities p(Ck|x) directly to determine
class membership. A DiscriminantFunctionAlgorithm builds a direct
mapping f (x) from input x onto a class label; neural networks
and support vector classifiers (SVCs) are examples of discriminant
function methods. These three DM-Algorithm families spawn
multiple levels of descendant classes that are distinguished by the
type and structure of the models they generate.

One innovative feature of DMOP is the modeling and exploitation of algorithm properties in meta-mining. All previous research
in meta-learning has focused exclusively on data characteristics
and treated algorithms as black boxes. DMOP-based meta-mining
brings to bear in-depth knowledge of algorithms as expressed in
their elaborate network of object properties. One of these is the
object property has-quality, which relates a DM-Algorithm to an
AlgorithmCharacteristic (Fig. 4). A few characteristics are common
to all DM algorithms; examples are characteristics that specify
whether an algorithm makes use of a random component, or handles categorical or continuous features. Most other characteristics
are subclass-specific. For instance, characteristics such as LearningPolicy (Eager/Lazy) are common to induction algorithms in gen-
eral, whereas ToleranceToClassImbalance and HandlingOfClassificationCosts make sense only for classification algorithms.

Note that has-quality is only one among the many object
properties that are used to model DM algorithms. An induction
algorithm, for instance, requires other properties to fully model its
inductive bias. Some examples are the properties: assumes which
expresses its underlying assumptions concerning the training data;
specifiesOutputClass which links to the class of models generated
by the algorithm, making explicit its hypothesis language or
representational bias; hasOptimizationProblem which identifies its
optimization problem and the strategies followed to solve it, thus
defining its preference or search bias.

3.4. Content alignment to DOLCE

The following subsumption axioms were added to align DMOP
with DOLCE. DOLCEs dolce:process in the perdurant branch
has as subclasses DM-Experiment and DM-Operation, whereas
most DM classes, such as algorithm, software, strategy, task,
and optimization problem, are subclasses of dolce:non-physical-
endurant. Characteristics and parameters of such entities have
been made subclasses of dolce:abstract-quality, and for identifying

C.M. Keet et al. / Web Semantics: Science, Services and Agents on the World Wide Web 32 (2015) 4353

Fig. 4. Data mining algorithm characteristics: the main top-level classes and a selection of their attributes (subclasses of Characteristic).

discrete values, classes were added as subclasses of dolce:abstract-
region. Thus, each of the four DOLCE main branches have been
used. Regarding object properties, DMOP reuses mainly DOLCEs
quality, quale, and parthood. DMOPs hasPart initially had an
equivalence alignment to dolce:part, but this duplication has been
removed in v5.5 to reduce the size of the ontology. Mapping DMOP
into DOLCE had the most effect on representing DM characteristics
and parameters (attributes), which is discussed in Section 4.3.

4. Modeling challenges

In this section we present the main modeling choices, issues
arisen, and solutions adopted, therewith providing some background as to why certain aspects from the overview in the preceding section are modeled the way they are.

4.1. Meta-modeling in DMOP

3.5. Answering competency questions

The competency questions may be divided into two groups:
those that may be already answered by the DMOPs KB and those
that may be answered with use of the DMOP based meta-mined
model, the product of semantic meta-mining. The latter ones that
are related to performance of DM processes will be discussed
in Section 5. The former ones are the questions that deal with
characteristics of particular DM entities, which is illustrated here
with competency question CQ3.1, which can be answered by
querying the ontology for the DM algorithms whose characteristic
ToleratesHighDimensionality has quale Yes (i.e., not having to
go through the dimensionality reduction). In Proteges DL Query
notation, this is:

DM-Algorithm and

has-quality value ToleratesHighDimensionality

The query answer obtained consists of a list of algorithm families
(classes ClassificationRuleInductionAlgorithm, ClassificationTreeIn-
ductionAlgorithm, and SVC-Algorithm) and particular algorithms
of those classes (among others, C4.5, C4.5Prob, CARTc, CHAID, De-
cisionStump, ID3, LogisticModelTree, NBTree, RandomTree of the
ClassificationTreeInductionAlgorithm class).

Once DMOP is classified by the reasoner, answering the DL
Queries (for those tested with) takes less than a minute with
HerMiT 1.3.8, else the classification time of the ontology has to be
added to the query evaluation time.

Right from the start of DMOP development, one of the most
important modeling issues concerning DM algorithms was to
decide whether to model them as classes or individuals. Though
DM algorithms may have different implementations, the common
view is to see particular algorithms as single instances, and not
collections of instances. However, the modeling problem arises
when we want to express the types of inputs and outputs
associated with a particular algorithm. We describe this problem
and how it was solved using an example, shown in Fig. 5.

Recall that: (i) only processes (executions of workflows) and
operations (executions of operators) consume inputs and produce
outputs; (ii) DM algorithms (as well as operators and workflows)
can, in turn, only specify the type of input or output; (iii) inputs
and outputs (DM-Dataset and DM-Hypothesis class hierarchy,
respectively) are modeled as subclasses of IO-Object class. Then
expressing a sentence like the algorithm C4.5 specifiesInputClass
CategoricalLabeledDataSet became problematic. Based on our
original design (reflected in Fig. 5(a)), it would mean that a
particular algorithm (C4.5, an instance of the DM-Algorithm class)
specifies a particular type of input (CategoricalLabeled-DataSet, a
subclass of DM-Hypothesis class), but classes cannot be assigned as
property values to individuals in OWL.

Our initial solution was to create one artificial class per each
single algorithm with a single instance corresponding to this
particular algorithm, as recommended in [25] (e.g. C4.5Algorithm
class with single instance C4.5). However, such modeling led
to technical problems. Since each of the four properties 
hasInput, hasOutput, specifiesInputClass, specifiesOutputClass 
were assigned a common range  IO-Object  it opened a way
to make problematic ABox assertions like C4.5 specifiesInputClass

property on the right-hand side. In this case, hasFeatures domain is
DataTable that is a sister-class of hasMainTables domain DataSet,
but the chain forces that each participating entity in hasFeature
has to be a subclass of its declared domain class, hence DataSet 
DataTable is derived to keep the ontology consistent. Ontologically,
this is clearly wrong, and hasFeatures domain is now set to DataSet
or DataTable. Each chain has been analyzed in a similar fashion and
adjusted where deemed necessary (see [8] for the generic set of
tests and how to correct any flaws for any property chain).
DMOP contains more elaborate property chains than the aforementioned one. For instance, realizes  addresses  achieves, so
that if a DM-Operation realizes a DM-Algorithm that addresses a
DM-Task, then the DM-Operation achieves that DM-Task, and with
the chain implements  specifiesInputClass  specifiesInputClass,
we obtain that when a DM-Operator or OperatorParameter implements an AlgorithmParameter or DM-Algorithm that specifies the
input class IO-Class, then the DM-Operator or OperatorParameter
specifies the input class IO-Class.

4.3. Qualities and attributes

A seemingly straightforward but actually rather intricate, and
essentially unresolved, issue is how to handle attributes and,
in a broader context, measurements in OWL ontologies. For
instance, each FeatureExtractionAlgorithm has as an attribute a
transformation function that is either linear or non-linear. One
might be tempted to take the easy way out and reuse the UML
approach where an attribute is a binary relation between a class
and a datatype; e.g., with a simplified non-DMOP intuitive generic
example, given a data property hasWeight with as XML data type
integer, one can declare Elephant  =1 hasWeight. integer.
And perhaps a hasWeightPrecise with as data type real may be
needed elsewhere. And then it appears later on that the former
two were assumed to have been measured in kg, but someone
else using the ontology wants to have it in lbs, so we would
need another hasWeightImperial, and so on. Essentially, with this
approach, we end up with exactly the same issues as in database
integration, precisely what ontologies were supposed to solve.
Instead of building into ones ontology application decisions about
how to store the data in the information system (and in which
unit it is), one can generalize the (binary) attribute into a class,
reuse the very notion of Weight that is the same in all cases,
and then have different relations to both value regions and units
of measurement. This means unfolding the notion of an objects
property, like its weight, from one attribute/OWL data property
into at least two properties: one OWL object property from the
object to the reified attribute  a so-called quality property,
represented as an OWL class  and then another property to
the value(s). The latter, more elaborate, approach is favored in
foundational ontologies, especially in DOLCE, GFO and YAMATO.
DOLCE uses the combination Endurant that has a qt relation to
Quality (disjoint branches) that, in turn, has a ql relation to a
Region (a subclass of the yet again disjoint Abstract branch).
While this solves the problem of non-reusability of the attribute
and prevents duplication of data properties, neither ontology
has any solution to representing the actual values and units of
measurements. But they are needed for DMOP too, as well as
complex data types, such as an ordered tree and a multivariate
series.

We considered related work on qualities, measurements and
similar proposals from foundational ontologies, to general on-
tologies, to domain ontologies for the experimental sciences
[20,2730]. This revealed that the measurements for DMOP are not
measurements in the sense of recording the actual measurements,
their instruments, and systems of units of measurements, but more
alike values for parameters, e.g., that the TreeDepth has a certain

Fig. 5.
Illustration of a modeling problem and its solution based on metamodeling.
(a) Original design problem: expressing types of inputs/outputs associated with an
algorithm; (b) Initial solution: one artificial class per each single algorithm with a
single instance corresponding to this particular algorithm; (c) Final solution: weak
form of punning available in OWL 2; IO-Class as meta-class of all classes of input
and output objects.

Iris, where Iris is a concrete dataset. Clearly, any DM algorithm is
not designed to handle only a particular dataset.

In our final solution, we decided to use the weak form of punning available in OWL 2 (see Fig. 5(c)). We had noticed that CategoricalLabeledDataSet could be perceived as an instance of a
meta-classthe class of all classes of input and output objects,
named IO-Class in DMOP. In this way, the sentence C4.5 specifiesInputClass CategoricalLabeledDataSet delivered the intended
semantics. However, we also wanted to express sentences like DMProcess hasInput some CategoricalLabeledDataSet. The use of the
same IO object (like CategoricalLabeledDataSet) once as a class
(subclass of IO-Object) and at other times as an instance required
some form of meta-modeling. In order to implement it, we investigated some available options. This included an approach based
on an axiomatization of class reification proposed in [26], where
in a metamodeling-enabled version Ometa of a given ontology O,
class-level expressions from O are transformed into individual assertions such that each model of Ometa has two kinds of individuals,
those representing classes and those representing proper individ-
uals, and meta-level rules are encoded in class level. We chose not
to follow this technique due to its possible efficiency issues.

Punning in our approach is only applied to leaf-level classes
of IO-Object; non-leaf classes are not punned but represented by
associated meta-classes, e.g., the IO-Object subclass DataSet maps
to the IO-Class subclass DataSetClass. Similarly, the instances of
DM-Hypothesis class represent individual hypotheses generated
by running an algorithm on the particular dataset, while the class
DM-HypothesisClass is the meta-class whose instances are the leaflevel descendant classes of DM-Hypothesis. Except for the leaflevel classes, the IO-Class hierarchy structure mimics that of the
IO-Object hierarchy.

4.2. Property chains in DMOP

DMOP has 11 property chains, which have been investigated in
detail in [8]. The principal issues in declaring safe property chains,
i.e., that are guaranteed not to cause unsatisfiable classes or other
undesirable deductions, are declaring and choosing properties, and
their domain and range axioms. To illustrate one of the issues
in declaring property chains, we use hasMainTable  hasFeature
 hasFeature: chaining requires compatible domains and ranges
at the chaining points, such as the range of hasMainTable and
domain of hasFeature, and with the domain and range of the

C.M. Keet et al. / Web Semantics: Science, Services and Agents on the World Wide Web 32 (2015) 4353

Fig. 6. Condensed section and partial representation of DMOP regarding attributes.

value and a LearningPolicy is eager or lazy, and that some propos-
als, such as OBOE [28], are versions of DOLCEs approaches.7

This being the case, we opted for the somewhat elaborate
representation of DOLCE, and added a minor extension to that
for our OWL ontology in two ways (see Fig. 6): (i) DM-Data is
associated with a primitive or structured DataType (which is a
class in the TBox) through the object property hasDataType, and
(ii) the data property hasDataValue relates DOLCEs Region with
any data type permitted by OWL, i.e., anyType. In this way,
one obtains a chain from the endurant/perdurant through the
dolce:has-quality property to the quality, that goes on through
the dolce:q-location/dolce:has-quale property to region and on
with the hasDataValue data property to the built-in data type
(instead of one single data property between the endurant and
the data type). For instance, we have ModelingAlgorithm  =1
has-quality.LearningPolicy, where LearningPolicy is a dolce:quality,
and then LearningPolicy =1 has-quale.Eager-Lazy, where EagerLazy is a subclass of dolce:abstract-region (that is a subclass
of dolce:region), and, finally, Eager-Lazy  1 hasDataValue.
anyType, so that one can record the value of the learning policy
of a modeling algorithm. In this way, the ontology can be linked
to many different applications, who may even use different data
types, yet still agree on the meaning of the characteristics and
parameters (attributes) of the algorithms, tasks, and other DM
endurants.

A substantial number of classes have been represented in this
way: dolce:regions subclass dolce:abstract-region has 44 DMOP
subclasses, which represent ways of carving out discrete value
regions for the characteristics and parameters of the endurants
DM-Data, DM-Algorithm, and DM-Hypothesis. Characteristic and
Parameter are direct subclasses of dolce:abstract-quality, which
have 110 and 46 subclasses, respectively.

4.4. Modeling object properties and their inverses

Early ontology development guidelines tended to favor adding
both an object property and its inverse, e.g., realizes and realizedby and declaring them inverse with the OWL InverseOb-
jectProperties(OPE1 OPE2), and not doing so counts as a
pitfall in the OOPS! catalog [9]. This practice was also followed
in DMOP up to and including v5.4; however, this was chosen

purely for reasons of easier readability, for OWL 2 has a feature ObjectInverseOf(OP) so that only one of the two object properties suffices in the ontology.8 Given that DMOP had
many object properties and non-trivial axioms involving them,
and slow classification times (1020 min), we experimented
with the ObjectInverseOf(OP) feature that affected 45 properties of v5.4, which resulted in a reasoner performance improvement of over a third [31]. This substantial performance
improvement outweighed the readability argument, and the explicit inverses have been removed and replaced with respective
ObjectInverseOf(OP) declarations in v5.5.

5. Usage of DMOP in semantic meta-mining

Todays DM platforms offer many algorithm implementations
(operators) that support different steps of the DM process. For
instance, RapidMiner (version 5.3, Community Edition) offers 688
operators, either implemented by developers of RapidMiner or
acquired through the implementation of wrappers for popular
DM libraries such as Weka. The user of the platform must select
the appropriate operators, and their combination to build a DM
workflow best addressing her goal. To assist the user in the design
of an effective workflow, Intelligent Discovery Assistants (IDAs)
have been proposed (a recent survey is presented in [32]). In the
following, we describe how DMOP was used to construct the e-
LICO IDA [2] that is the first IDA capable of both planning and
ranking DM workflows. We discuss the evaluation of DMOP-based
semantic meta-mining and the deployment of the e-LICO IDA in
RapidMiner. Finally, we describe some other applications of DMOP
to meta-mining.

5.1. The e-LICO Intelligent Discovery Assistant

The e-LICO IDA architecture is grounded on planning-based
data analysis system [33,32] since it uses artificial intelligence (AI)
planning to construct a set of workflows. The planned workflows
are all valid for the given task, but there may potentially be billions
of them. Therefore, the planner-based IDA exploits the results
of semantic meta-mining to rank the workflows before they are
presented to the user.

The architecture of the IDA is shown in Fig. 7. The user who
interacts with the IDA is required to do no more than to upload

7 DOLCE materials differ slightly, with quale as relation in [20] and as unary
in [27] and in DOLCE-lite.owl, and Region is a combination of a (data)
value+ measurement unit (e.g. 80 kg) in [20] to deal with attribute values/qualia
(there were no examples in [27] and the DOLCE-lite.owl).

8 An axiom containing, e.g., realized-by is easier to read than the cognitive jump
required when reading (in Protege notation) inverse(realizes) for realized by.

5.2.1. Predicting the performance of DM workflows

Building a classifier that predicts whether a workflow is in the
class of the best performing workflows or in the class of the rest of
the workflows was addressed by [2] and [34].

The authors of [2] evaluated two scenarios. In the first scenario,
meta-mined models exploited only data characteristics. In the second scenario, meta-mined models exploited data characteristics
and patterns mined from parse trees of the DM-workflow. The
parse trees, that represented the order of execution of the workflow operators and their hierarchical relation, were augmented using terms from DMOP in order to derive frequent patterns over
DMOP-based generalizations of the workflow components.

The experiments were conducted on the meta-data of 2275
DM experiments performed on 65 high-dimensional datasets
concerning microarray experiments on different types of cancer;
the datasets had many more variables than instances. The default
rule (baseline) simply predicted the majority class and had
45.38 error rate. In the two semantic meta-mining scenarios, the
models that were built using data and workflow characteristics
performed better (38.24 error rate) than those based on data
characteristics alone (40.44 error rate), and meta-mined workflow
patterns proved to be discriminatory even for new algorithms
and workflows (that is those not yet encountered in previous DM
experiments) [2].

The capability of DMOP based meta-mined models to predict
the relative performance of DM workflows was confirmed in [34].
This study used 1581 RapidMiner workflows solving a predictive
modeling task on 11 UCI9 datasets with various characteristics,
whose meta-data was stored in the DMEX-DB containing over 85
million of RDF triples.10 The workflow patterns were represented
as SPARQL queries using DMOP entities. McNemars test for pairs
of classifiers was performed with the null hypothesis that a
classifier built using dataset characteristics and a mined pattern
set has the same error rate as the baseline that used dataset
characteristics and only the names of the learning DM operators.
The test confirmed that classifiers trained using workflow patterns
performed significantly better (accuracy of 0.927) than the
baseline (accuracy of 0.890).

The experiments proved that DMOP-based semantic metamining was effective in answering competency questions dealing
with performance of DM algorithms and/or DM workflows.
Learning algorithms performing best on microarray data (CQ3.3)
and the ones that should be used or avoided when an input dataset
has many more variables than instances (CQ3.2) were found in
patterns resulting from meta-mining experiments described in [2].
In both mentioned studies, the computed meta-mined models
proved to be effective in selecting better performing workflows
from among the valid ones (CQ1.1).

5.2.2. Planning well performing DM workflows

Recall from Fig. 7 that the AI Planner constructs valid DM
workflows step by step by selecting applicable operators according
to their pre/post-conditions [33]. The AI Planner alone does not
have the means to differentiate between operators that have
equivalent conditions since it does not take the quality of the
resulting workflows into account. There may be several operators
that have fitting conditions at each step.

The authors of [35] experimentally evaluated the Semantic
Meta-Miner in the operator selection task. The goal was to select
at a given step among a set of candidate operators the best ones to

9 http://archive.ics.uci.edu/ml/datasets.html.
10 All experimental data, datasets, and workflows are available at http://www.
myexperiment.org/packs/421.html.

Intelligent Discovery Assistant;

Fig. 7.
it is composed of the AI-planner,
Probabilistic Ranker and Semantic Meta-Miner. The user provides the data and
specifies the data mining goal (1). The AI-planner generates a (possibly huge) set
of valid workflows (2). The Probabilistic Ranker ranks the workflows (4) based on
the meta-mined model (3) previously computed off-line (6) by the Semantic Meta-
Miner. Top ranked workflows are presented to the user (5).

annotated data (specifying roles and the types of the attributes)
and to select the DM goal to be achieved (e.g., prediction) (1). Data
characteristics together with the DM Workflow Ontology (DMWF)
are used by the IDAs AI-planner to generate a set of valid DM
workflows (2). Valid workflows are those that fulfil the user goal,
take the dataset characteristic into account, and combine operators
in the way that all their pre-conditions and post-conditions are
met.

Those workflows are passed to the probabilistic ranker that
applies a default rule or a meta-mined model (3) computed by
the semantic meta-miner to rank the workflows (4) which enables
the AI planner to provide a list of top-ranked workflows to the
user (5). The workflows are ranked according to the estimated
values of the performance measure of the DM hypotheses they
produce (for instance, for a workflow addressing the classification
task, accuracy can be such a measure). Best workflows, from the
functional point of view, are those that achieve relatively best
values for the measure.

The meta-mined model is computed off-line by the meta-miner,
which is trained on a semantic repository of meta-data of data
mining experiments (DMEX-DB) based on DMOP (6).

5.2. Evaluation of DMOP-based semantic meta-mining

The meta-mined model is induced from a DMEX-DB repository
that stores meta-data concerning all aspects of past DM experiments such as the dataset description, the workflow, the learned
model, predictions, and performance results. The model generalizes this knowledge with use of patterns extracted from meta-data
of the collection of DM workflows; DM workflows are described
in terms of the presence or absence of the extracted patterns. The
extracted patterns capture (structural) characteristics of the workflows and the characteristics of the workflow components. The
model employs patterns to discriminate between configurations
of dataset and workflow/algorithm/operator characteristics associated with good or bad performance (cf. CQ2.x). The efficacy of the
model in making predictions depends on the discriminatory power
of the characteristics used to induce it. The quality of the characteristics represented in DMOP is thus crucial for the meta-mined
models efficacy.

The efficacy of meta-mined models that exploit DMOP has
been evaluated empirically in the following problems: predicting
whether a workflow is good or bad (in terms of performance) and
planning good workflows.

C.M. Keet et al. / Web Semantics: Science, Services and Agents on the World Wide Web 32 (2015) 4353

build not only valid but also optimal DM workflows. The Semantic
Meta-Miner used a quality function that scored a given plan by
the quality of the operators that formed the plan. The quality
optimized the performance measure associated with the data
mining goal of the user and the input dataset.

The experiments were conducted with the same set of DM
workflows as in [2]. The baseline strategy was based on the
popularity of the RapidMiners DM operators. The results were
statistically significantly better for the meta-mining selection
approach than for the baseline (with the average performance
improvement of around 6%). The meta-mining strategy was better
than the baseline in selecting the best workflow for 53 datasets
out of 65. The results show the validity of the approach in planning
good workflows for a given learning problem.

The experimental results for the operator selection task proved
that the Semantic Meta-Miner was capable to answer which of
the applicable DM algorithms would yield best results given a
DM task and dataset (CQ1.1). These were those implemented by
best scoring DM operators and DM algorithms sharing similar
characteristics with them, according to DMOP.

is linked to known theoretical characteristics of algorithms and
datasets to provide insight into the behavior of learning algorithms
on particular datasets, and the effect of parameters and data pre-
processing, for which fine-grained knowledge, as represented in
DMOP, was necessary. The stored meta-data can be queried (e.g.,
about the very building blocks of learning algorithms), or it can be
mined to build predictive models of algorithm performance on particular datasets, or to answer why algorithms work or fail on certain datasets.

Another notable application of DMOP to meta-mining investi-
gations, described in [40], is in the domain of Quantitative StructureActivity Relationship (QSAR) studies. QSAR modeling is an
important step in drug discovery processes, and a QSAR modeling
algorithm is typically a DM algorithm. DMOPs terms dealing with
algorithm parameters, and dataset characteristics were used to annotate QSAR studies. The goal of that annotation is to run metalearning studies, meta-QSAR, to determine what combinations
of datasets, DM algorithms, and drug targets work best and subsequently to better apply existing QSAR methods.

5.3. Deployment of the Intelligent Discovery Assistant

6. Conclusions

The meta-mined model resulting from DMOP-based semantic
meta-mining is used in the IDA extension of RapidMiner developed
within the e-LICO project [33].

After the IDA produces the top ranked workflows and
suggests them to the user, he or she can execute the chosen
workflow in RapidMiner. The data mining services required to
enact the workflow (data, text, image mining) are provided by
RapidAnalytics.11 RapidAnalytics also serves as a centralized data
mining experiment repository for different teams collaborating on
a given application domain. It stores all relevant meta-data related
to the execution of the workflow. The raw meta-data from the
RapidAnalytics repository can then be parsed and organized into a
semantic repository of annotated experiments (DMEX-DB) based
on DMOP. In this form, the parsed meta-data can be exploited
by the meta-miner that uses DMEX-DB as the systems long-term
memory and the source of training data.

The RapidMiner IDA Extension is available in the Rapid-
I marketplace12 since 1 September 2012. In March 2014, this
RapidMiner plugin has been downloaded 8751 times and was
bookmarked 23 times, and it continues to attract attention, with
10 046 downloads and 52 bookmarks in November, 2014. It is
among the Top Favourites listed in the Rapid-I marketplace.

The workflows generated by the IDA can also be executed in the
Taverna [36] IDA extension using an instance of a RapidAnalytics
server providing RapidMiner operators as web-services. The
user also can upload the workflow generated by the IDA to
myExperiment, a web portal for sharing workflows and other
resources [37]. This feature is available in both RapidMiner and
Taverna.

5.4. Other applications of DMOP to meta-mining

DMOPs conceptualization of data mining algorithms has
been used elsewhere for constructing data mining experiment
databases. Experiment databases [38,39] provide a platform for
DM researchers and practitioners for storing the thousands of their
data mining experiments in a central repository and allowing them
to exploit meta-knowledge of the experiments. This empirical data

11 http://rapid-i.com/content/view/182/196/.

productId=rmx_ida.

http://marketplace.rapid-i.com/UpdateServer/faces/product_details.xhtml?

In this paper, we have presented the DMOP ontology. It provides
a conceptual framework for analyzing data mining domain 
DM tasks, algorithms, models, datasets, workflows, performance
metrics, and their relationships  in a way that enables optimizing
DM processes.

While modeling data mining knowledge in DMOP, we have
encountered a number of non-trivial modeling issues. These
include: (i) the hurdle of relating instances to classes and
using classes as instances (and vv.), which has been solved by
exploiting the weak form of metamodeling with OWLs punning
available in OWL 2; (ii) finding and resolving in a systematic
way the undesirable deductions caused by property chains;
(iii) representation of attributes, where its solution is ontologydriven yet merged with OWLs data property and built-in data
types to foster their reuse across applications; (iv) linking to a
foundational ontology. In order to properly solve these issues, we
have used almost all of OWL 2s features. The resulting ontology is
highly axiomatized and complex in comparison to many state-of-
art domain ontologies, especially those whose primary goal is to
provide common vocabulary for annotation of resources.

We described the evaluation of DMOP-based semantic metamining in two tasks: predicting the performance of DM workflows
and planning well performing DM workflows. Finally, we described
the usage of DMOP for constructing the Intelligent Discovery
Assistant deployed at the leading data mining environment
RapidMiner.

The deep modeling of the DM domain in DMOP has moved
forward the field of meta-learning: traditional meta-learning has
been lifted to the level of semantic meta-mining; that is, to an
ontology-based form of meta-learning capable of analyzing and
optimizing whole DM processes.

Acknowledgments

This work was supported by the European Union within
FP7 ICT project e-LICO (Grant No. 231519). The second author
acknowledges the support from the PARENT-BRIDGE program of
Foundation for Polish Science, co-financed from European Union,
Regional Development Fund (Grant No. POMOST/2013-7/8). We
thank all our partners and colleagues who have contributed to
the development of DMOP: Huyen Do, Simon Fischer, Dragan
Gamberger, Lina Al-Jadir, Simon Jupp, Petra Kralj Novak, Babak
