Web Semantics: Science, Services and Agents on the World Wide Web 31 (2015) 2738

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

journal homepage: www.elsevier.com/locate/websem

Mining various semantic relationships from unstructured
user-generated web data
Pei-Ling Hsu, Hsiao-Shan Hsieh, Jheng-He Liang, Yi-Shin Chen

Institute of Information Systems and Applications, Department of Computer Science, National Tsing Hua University, Taiwan

a r t i c l e

i n f o

a b s t r a c t

With the emergence of Web 2.0, the amount of user-generated web data has sharply increased. Thus,
many studies have proposed techniques to extract wisdom from these user-generated datasets. Some of
these works have focused on extracting semantic relationships through the use of search logs or social
annotations, but only hierarchical relationships have been considered. The goal of this paper is to detect
various semantic relationships (hierarchical and non-hierarchical) between concepts using search logs
and social annotations. The experimental results demonstrate that our proposed approach constructs
adequate relationships.

 2014 Elsevier B.V. All rights reserved.

Article history:
Received 6 July 2013
Received in revised form
30 September 2014
Accepted 14 November 2014
Available online 24 November 2014

Keywords:
Semantic relationships
Search logs
Social annotations
Large-scale web data

1. Introduction

Collecting human knowledge has been a common goal since ancient times. The advent of the computer, followed by the Internet
and the World Wide Web offers a means to continue this quest.
The Web has become the largest repository of human knowledge
in the world, and because the Web is open, it allows anyone with
Internet access to create or generate knowledge. However, the generated datasets in the repository are usually scattered, mutually
redundant, and mutually complementary. Organizing these usergenerated datasets automatically is crucial.

Wikipedia, a well-known user-generated dataset, has been organized by many researchers. Collaboratively created by crowd
users, Wikipedia preserves users viewpoints and interests. The
Wikipedia articles are further organized by contributors into structured information, including keyword lists in the infobox, classes,
and directories. The structured information is entity based and follows a predefined schema. To generate an infobox of an article, a
template is provided with suggested properties based on the classified entity type of the article; as such, the infobox is based on the
properties of the entity rather than a summary of the article. Hence,
the information in the infobox loses certain perspectives that are
of value to users.

These lost perspectives are usually preserved in search logs
and social annotations, which are usually linked to certain sub-
jects/news/events through user behavior and could contain more

 Corresponding author.

E-mail addresses: lopihsu@gmail.com (P.-L. Hsu), coral0350040@gmail.com
(H.-S. Hsieh), otirafuu@gmail.com (J.-H. Liang), yishin@gmail.com (Y.-S. Chen).

http://dx.doi.org/10.1016/j.websem.2014.11.004
1570-8268/ 2014 Elsevier B.V. All rights reserved.

up-to-date but not organized information. Because of their unstructured characteristic, these wide-ranging users perspectives
are difficult to reuse.

Constructing semantic relationships for the unstructured data
is one approach to organize information. The semantic relationships gather relevant concepts and clearly indicate the relevance
between corresponding concepts. Such organizations not only preserve various users perspectives but are also practical to execute.
Some studies [15] constructed semantic relationships from
search logs or social annotations. These semantic relationships
were hierarchical relationships; however, non-hierarchical rela-
tionships, which were not the main consideration of these studies,
were not constructed. Some studies [6,7] were able to construct hierarchical and non-hierarchical relationships based on externally
structured information. However, keywords, presenting users
viewpoints, cannot be mapped with controlled vocabularies in
structured information and thus cannot be easily connected to controlled vocabularies or other keywords by semantic relationships.
We believe that search logs and social annotations can provide
sufficient evidence to construct semantic relationships that are
not based on structured information. The extracted semantic
relationships supplement well-established ontologies.

The goal of this paper is to detect semantic relationships between concepts from search logs and social annotations. Each relationship connects two relevant concepts semantically. To determine the concept, detect the relevant concepts, and infer a semantic relationship in such unstructured and ambiguous datasets are
the main challenges of this paper.

The common characteristics of the datasets are investigated
first. Based on the nature of inconsistent and unstructured data,

P.-L. Hsu et al. / Web Semantics: Science, Services and Agents on the World Wide Web 31 (2015) 2738

formal definitions are constructed, and thus the data can be treated
as structured thereafter. We further discuss the semantic meaning
of the defined semantic properties, which can be used to infer various semantic relationships, including is a, has subclass, is equal
to, has meaning, has website, and has data about.
The major contributions of this paper are as follows:

1. A generalized model for keyword-based unstructured data is
given. This model can handle user-generated tagging data, usage records, and all other keyword-based data. Through this
model, the homogeneous data (i.e., semantic relationships and
their corresponding concepts) are extracted from heterogeneous datasets.

2. Inference rules for extracting semantic relationships are
demonstrated. This paper shows that semantic relationships
with semantic labels can be directly extracted from unstructured data, which is left out of most studies.

3. The constructed ontology can supplement existing ontologies.
This new exploratory outcome demonstrates the possibility of
understanding the rapidly evolving vocabularies and concepts
in Web 2.0.

2. Related work

Numerous approaches have been proposed to automatically
construct relationships from collaborative data. The first type of
collaborative data comes from Wikipedia. DBpedia [8] and YAGO
[9] are the most famous systems for handling such data. Both
systems use structured information on Wikipedia, which includes
links, categories, and infoboxes.

DBpedia [8] mainly uses infobox data [10,8], which collects
and organizes the corresponding information of specified entities
based on different templates. Each template involves different
attribute sets. The template attributes specify the semantic
relationships of a specified entity to other predefined entities. For
example, the entity Harry Potter has several attributes in its
infobox. One of the attributes is Author, and the corresponding
attribute value is J.K. Rowling. The semantic relationship of
Author is constructed between the entities Harry Potter and
J.K. Rowling.

Instead of using only one type of structured data, YAGO [9]
unifies Wikipedia data with WordNet. YAGO extracts candidates
(for concepts, entities, and relationships) from Wikipedia category pages, which are lists of articles in a specific category. Various relationships between candidates are then extracted based
on the corresponding properties. The relationships in YAGO are
fixed and can be classified into five different types, including the
following: (1) TYPE relationships extracted from conceptual categories in Wikipedia; (2) SUBCLASSOF relationships (i.e., the hierarchical structures in YAGO) integrated from the leaf categories
of Wikipedia and synsets of WordNet; (3) MEANS relationships
extracted from words, synsets of WordNet, and the entities in
the redirect pages of Wikipedia; (4) OTHERS relationships, from
Wikipedia categories (e.g., BornInYear); and (5) META relationships to store additional information for further applications.

DBpedia and YAGO emphasize the structured data of Wikipedia,
which could be considered a minority dataset. The majority of the
records on Wikipedia, such as articles, are unstructured. Although
extracting semantic relationships from unstructured data is more
challenging, few research studies [11,12] have tried to extract relationships from Wikipedia articles to expand data coverage. Unlike
other articles on the Web, Wikipedia articles have two characteris-
tics: (1) their sentences have a high level of grammaticality; and (2)
Wikipedia maintains only one article for each corresponding realworld entity. These two characteristics ease the processing diffi-
culty.

Using the first characteristic, Ruiz-Casado et al. [13] proposed
a lexical pattern-matching algorithm to automatically extract relationships from a Simple English version of Wikipedia. This algorithm associates each Wikipedia entity with its corresponding
WordNet synset. Subsequently, the definition sentences in the
Wikipedia entity are associated with certain words with hyper-
links. If the associations between the entity and the words are
confirmed in WordNet, a relationship is extracted, and a corresponding lexical pattern (based on the part-of-speech tags) is
generated. Afterward, all lexical patterns are compared to form
generalized patterns. These generalized patterns detect additional
relationships from Wikipedia. This algorithm successfully automatically extracted more than 1200 new relationships with
0.610.69 precision.

To improve the accuracy results, the second characteristic was
widely used in several other studies. One example system proposed by Culotta et al. [14] detects relationships in biographical
texts. Since each biographical text has only one primary entity, this
system then uses linear chain conditional random fields (i.e., undirected Markov networks) to identify the potential relationships between the primary entity and other associated entities based on a
labeling semantic role and conjunctions of base features. However,
this system detects only person-to-person relationships.

The relationships identified by Nguyen et al. [11,12] are more
general. Their proposed systems exploit the syntactic structures of
the sentences to construct a tree-like representation, which indicates the relationships between entity pairs. Next, the sequence
pattern-matching algorithms identify relationships based on seed
patterns, which can be either manually selected [11] or extracted
from a Wikipedia infobox [12].

Although Wikipedia can provide rich datasets for extracting
sufficient relationships, newly invented/generated concepts might
not be edited on Wikipedia in time. These concepts might appear
on blogs and micro-blogs, and, consequently, might be searched by
users. Therefore, usage records could likely contain more up-to-
date information; usage records, along with user-generated tagging data, emerge as another important type of user-generated
data. These datasets are usually composed of few words, in which
the grammar structures are completely ignored and consequently
cannot be analyzed at the syntactic level. Some approaches [6,7]
have relied completely on other structured data to detect name
entities and relationships. However, structured data usually cannot capture the newest concepts.

Some researchers [1,2,15,16,35,17,18] have constructed relationships by examining the associations between data sources.
Some of these approaches [15,16] examine the associations between tags, tagged-URLs, and users who give the tags and denote
the associations in semantic relationships, such as tagged by or
used by between tags and users. Other approaches [15] address the associations between (tag, URL) pairs and (query, clicked
URL) pairs in bipartite graphs. Tags and queries are classified into
different sets based on the bipartite graphs. Once two sets share
common elements (such as annotated URLs or clicked URLs)
in the bipartite graphs, the corresponding hierarchical relationship is then constructed based on the converged dataset. These
approaches interpret only the numerical relationships and so
constructing various semantic non-hierarchical relationships is
infeasible.

To automatically map semantic meanings or concepts to data-
sets, several approaches have used ontologically structured data,
such as WordNet, to detect name entities and various relationships
in unstructured data. Since more ontologically structured data requires higher precision mapping [6], several studies [6,7] have
used multiple ontologically structured datasets, such as WordNet,
OpenCyc, and YAGO, to map vocabularies of unstructured data to
ontologies. However, some vocabularies cannot be matched, even

though several ontologies have been used [6]. Moreover, the main
limitation of such an approach is the limited coverage of currently
available ontologies [19].

Unlike these studies, our approach not only uses the content
of the structured/unstructured data but also leverages human behaviors and intentions, as detected from the data. Users intentions
were usually classified as navigational or informational [20,21].
Navigational search intention means that users intend to access
specific web pages.

Therefore, navigational queries are usually followed by fewer
than two clicked URLs [20,22,21,23]. Informational search intention means that users intend to find some piece of information.
Given this intention, informational queries are followed by several
clicked URLs. By adopting this additional perspective, additional
semantic relationships can be extracted to complement the existing ontologies.

3. Data

Instead of using Wikipedia data to generate semantic relation-
ships, we use different types of keyword-based user-generated
data to construct supplementary information to complement wellestablished ontologies. In this paper, we emphasize English information on two types of collaborative data: search logs and Open
Directory Project (ODP) data.
 Search logs: Search logs, which contain successive interactions
between users and search engines, are some of the mostupdated collaborative data in the world. When users look for
specific information, they enter several keywords as queries in
search engines. Search engines then return a list of pages that
match these queries. After receiving the querying results, users
might click on several web pages in the results list or refine the
queries to obtain other sets of results. These behaviors, such as
submitted queries, refined queries, and clicked-through data,
are recorded in search logs. Therefore, search logs contain the
most up-to-date crowd wisdom, for example, the hottest news
or the newest trend. This crowd wisdom constitutes the dataset
from which we wish to extract the supplementary ontology.
 ODP: ODP [24] data contains the most comprehensive manually
edited directory of the Web. For each annotated web page, the
titles and corresponding categories are suggested by numerous
web contributors. ODP categories are composed of successive
classes or categories, separated by slashes, that are ordered
hierarchically. The ODP titles summarize the web pages, and the
multiple categories reflect the organization of the web pages
based on different perspectives. Therefore, ODP data is one of
the most important resources for associating web information.
To integrate the heterogeneous data, the data is normalized
and decomposed into the smallest elements, which share certain
common characteristics.
Definition 3.1 (Word Sequences). Let W be the set of all words.
A finite word sequence ws with length m can be represented as
ws = w1, w2, . . . , wm, wi  W. Let W be the set of all finite
word sequences. Note that each word can also be a word sequence
with length m = 1, i.e., w  W,w  W.
Definition 3.2 (Concept Sequences). Let C be the set of all concepts.
A finite concept sequence cs with length n can be represented as
cs = c1, c2, . . . , cn, ci  C. Let C be the set of all finite concept
sequences.

These collaborative datasets have one characteristic, i.e., short
and fragments. The average length of queries is 3.11. Because of this
characteristic, we have difficulty to adapt the natural language pro-

cessing (NLP) techniques in this paper, since NLP will have best performance if a full statement can be provided. Furthermore, because
the compositions of word sequences among collaborative data are
free, with various lexical forms and even misspellings, C  W.
Moreover, some word sequences, such as URLs and ODP categories,
share a common pattern: that is, the word sequence can be divided
into shorter word sequences by a special symbol, such as a slash or
a colon. These shorter word sequences are usually hierarchically
associated and correlated with certain concepts. The definitions of
URLs and ODP categories are as follows:

Definition 3.3 (URL). Let l be a URL and be an element of a URL set
L. Each URL l can be divided into a hostname h(l) and a resource
path p(l). A hostname h(l) is an element of the hostname set H,
where H  W. Given a hostname h  H, it contains a secondlevel domain name d2(h), where d2(h)  W. In addition, each
resource path p(l) can be further decomposed into a sub-path, i.e.,
pi(l), where i is an integer and pi(l)  W.

Moreover, according to the URL protocol [25], the hostname of a
URL is a unique noun (thus, a word as well) referring to an identical
location of a specific web site on Internet. The second-level domain
name of a URL usually represents the name of the company or the
product/service provided by the company; the URL information is
more general by truncating a subset of the resource path from the
end.

The URL protocol merely describes the association among host-
names, IPs, and resource paths and does not define a standard for
generating these data records.

. Each sub-category gODP

Different from the web administrators who can generate any
URL they wish, ODP contributors must follow strict rules for generating ODP titles and map the titles to pre-defined ODP categories,
where the categories are manually defined concepts. The corresponding definitions of ODP are as follows:
Definition 3.4 (ODP). Let  ODP (l)  TODP be an ODP title for the
corresponding URL l, which is a word sequence, i.e.,  ODP  W.
Each ODP title might have one to many corresponding ODP cate-
gories, where each ODP category gODP  GODP can be partitioned
 C is
into several sub-categories gODP
a concept sequence and more general than the sub-category gODP
i+1 .
ODP titles are crowd wisdom for the associated URLs. Likewise,
queries are word wisdom for the clicked URLs based on user
browsing behaviors. Queries and clicked-URLs are recorded in
search logs. The corresponding definitions of search logs are as
follows:
Definition 3.5 (Search Logs). A search log can be divided into a
clicked log logc and a query log logq. A clicked log logc might have
several clicked records k  K. A clicked record k includes a query id
qid(k), a query q(k), a clicked URL l(k), and a clicked time time(k).
Each query q(k) is a word sequence q(k)  W. Note that q(k)  Q,
where Q is the set of all queries. On the other hand, a query log logq
might also have several queries q(logq)  Q. Each q(logq) is a word
sequence q(logq)  W.

These word sequences are freely composed, which might be
mapped to certain concepts. In the next section, we introduce
the challenges of detecting concepts in word sequences and the
proposed methods for addressing these challenges.

The terminologies are summarized in Table 1.

4. Word sequences process

A concept can be described from many perspectives and is
typically associated with many meaningful word sequences, where
each word sequence could have emerged from the decomposition
of different word sequences. For example, the concept Harry

Table 1
Notations.
Notation

Qfre

ws
cs

h(l)
p(l)
pi(l)
d2(h)
gODP
gODP

 ODP (l)

l(k)
q(k)
q(logq)
as + bs
as  bs
as  bs
stripn()
abbr()
gramn()
splitof ()

P.-L. Hsu et al. / Web Semantics: Science, Services and Agents on the World Wide Web 31 (2015) 2738

Description
A set of all of words
A set of all finite word sequences
A set of all of concepts
A set of all finite concept sequences
A set of nouns
A set of all URLs
A set of all hostnames
A set of clicked records
A set of all queries
A set of all frequent queries
A set of all ODP categories
A set of all ODP titles
A word sequence
A concept sequence
A URL
A hostname of a URL
A resource path of a URL
Each resource path contains a sub-path
A second-level domain name of hostname
An ODP category
A sub-category of an ODP category gODP
An ODP title
A clicked record k  K
A clicked URL of a clicked record k
A query of a clicked record k
A query of a query log
Combine Word Sequences Function, where as, bs  W
Remove Word Function, where as, bs  W
Contain Function, where as, bs  W
Strip Words Function
Abbreviation Function
N-gram Function
Split-by-Of Function

Fig. 1. Example of separations of word sequences.

4.1. Processing functions

To process the word sequences, we identified seven fundamental functions, which usually involve one or two word sequences. Let
as, bs  W denote two word sequences waiting for processes.
as = a1, a2, . . . , ama, bs = b1, b2, . . . , bmb, where ai denotes
the ith word in the as sequence and |as| = ma number of words
in this sequence. Given these definitions, several functions are formally defined (examples of each function are given in Table 2) as
follows:
Let as, bs  W be two word sequences. as = a1, a2, . . . , ama,
bs = b1, b2, . . . , bmb, ai denotes the ith word in as sequence,
and |as| = ma number of words in this sequence. Given these
definitions, several functions are defined as follows:

Potter might come from Harry Potter Movie,
Harry Potter
Series, harry potter and the deathly hallows, Mr. H. Potter,
and the one who lived. In other words, word sequences can be
decomposed into a set of shorter meaningful word sequences. For
instance, travel agent phone can be separated into travel agent,
agent phone, travel, agent, and phone.

Because of this divisibility characteristic, automatically decomposing word sequences into different concepts is challenging. For
example, as illustrated in Fig. 1, the separated positions vary, based
on different word sequences. Although these separated positions
are different in these two examples, the criterion for splitting is
the same, i.e., the separated sets should completely represent certain concepts, and the re-merged sets should correctly refer to the
concepts of the original word sequences.

The first possible solution is decomposing word sequences
based on general English grammar, i.e., the key concept of a set
of successive nouns is usually the final noun, and the remaining
nouns are adjectives of this key concept. The main challenge of
this solution is that the grammar structures of word sequences are
often incomplete or even noisy. These general grammar notions
are not always suitable for word sequences. For example, the word
sequence modeling agency Madison wisconsin shows the key
concepts in the leading noun and the adjectives in the final noun.
Moreover, the difficulty in separating increases when the word
sequences are composed incorrectly, such as chicken noodle
soup books, where noodle is a misplaced word. Checking for
chicken noodle soup books might mislead one to a recipe book
for chicken soup or for chicken noodles. This word sequence should
be corrected to chicken soup books, referring to books about
chicken soup for the soul. To consider these challenges, several
functions are proposed in Section 4.1 to introduce flexibility
into determining the decompositions and compositions of word
sequences.

Definition 4.1 (Contain Function). The Contain function examines
the subset relationships between two input word sequences: as
and bs. as is contained by bs if the set of all elements in as, {a1, a2,
. . . , ama} is a subset of the set of all elements in bs,{b1, b2, . . . , bmb},
that is as  bs = {a1, a2, . . . , ama}  {b1, b2, . . . , bmb}.
Definition 4.2 (Combine Word Sequences Function). The Combine
Word Sequences function combines two word sequences (as and
bs) into one. as + bs = a1, a2, . . . , ama
Definition 4.3 (Remove Words Function). The Remove Words
function removes one word sequence (bs) from another word
sequence (as).

, b1, b2, . . . , bmb.

if as = as1 + bs + as2.
otherwise.

as  bs =as1 + as2

error

Definition 4.4 (Strip Words Function). The Strip Words function
deletes the last n words from the word sequence as, where n should
be an integer and smaller than the length of as.
stripn(as) = a1, a2, . . . , aman.
Definition 4.5 (N-Gram Function). The N-gram Function extracts
ai, ai+1, . . . , ai+(n1)|1  i  ma  (n  1) the n-gram of
different sets of n successive words among the input word
sequence. Let I be the set of integers and i  I, then gramn(as) =
as. For example, the two-gram word sequences for the given word
sequence apple banana cat dog fog are apple banana, banana
cat, cat dog, and dog fog.

Definition 4.6 (Abbreviation Function). The Abbreviation function
generates an abbreviation format of given word sequences. The
notation for abbreviation is abbr(as). Take the first letter of all

Table 2
Example of word sequence functions.

as
harry potter book
harry potter
harry potter book 7 release date
harry potter book 7 release date
harry potter movie
Dumbledores Army
book of harry potter

bs
harry potter
movie
book 7

Function
bs  as
as + bs
as  bs
strip2(as)
gram2(as)
abbr(as)
splitof (as)

Output
{harry potter}  {harry potter book}
harry potter movie
harry potter release date
harry potter book 7
harry potter, potter movie

book, harry potter

elements, ai, in a word sequence, as, and combine these letters into
a single word, a. After this function, the space of the word sequence
is from a word sequence set to a word set, abbr : W  W.
Definition 4.7 (Split-by-Of Function). The Split-by-Of
function
generates sequences of several words by splitting the input word
sequences based on the word of. This function uses grammar
patterns to identify shortened word sequences.

splitof (as) =(as1, as2)

(,)

if as = as1 + of  + as2.
otherwise.

The space for this is denoted as splitof

: W  W2 since
{{ws1 of ws2}} becomes {{ws1},{ws2}} in the word sequence set.
The outputs of these functions are word sequences, where some
might represent concepts and some might be meaningless. Section 4.2 introduces the evaluation criteria to filter the meaningless
ones.

4.2. Concept candidate criteria

The outputs from the processing functions are then evaluated
by several evaluation criteria that rely on the applied functions,
the input data sources, and the possible semantic meaning. Once
the outputs qualify one of the criteria, the outputs are considered
concept candidates.

Mapping with existing concepts.

If the output word sequences
can be matched with existing concepts, the sequences are
concept candidates.
Mapping with dictionaries.

If the output word sequences can be
discovered in dictionaries and they are nouns, the sequences are concept candidates.

Crowd wisdom. The term crowd wisdom indicates that information aggregated from the crowd is usually better than
that from an individual user. This suggests that incorrect
compositions of word sequences can be ignored, since
the crowd might not produce the same mistakes repeat-
edly. Moreover, information aggregated from the crowd
might complete or correct the composition of word se-
quences. For example, the incorrectly composed word
sequence star wars light saber is relatively rare when
compared to the frequently seen star wars lightsaber.
The latter word sequence is the correct form. The sources
of crowd wisdom could be social annotation data or query
logs. Frequently seen word sequences, such as ODP titles
and frequent queries, are concept candidates. To label a
query frequent or not, we define the function in Definition 4.9 to calculate the frequency and then extract frequent queries.

The word sequences containing of.

Of is a unique keyword. In
the Oxford English Dictionary, the word of means belonging to something; being part of something; relating
to something. By inference from this definition, if the
something (i.e., the first part of the word sequences
before of) is a concept candidate (e.g., noun), then the

word sequence containing of is a concept candidate, too.
Using this criterion, the system can identify many word
sequences as concept candidates, even though these sequences cannot be found in dictionaries or as existing
concepts.

Definition 4.8 (Noun). A noun is a set of word sequences and is
denoted as NOUN. A word sequence belongs to the noun category
if and only if the word sequence can be found and denoted as a
noun in dictionaries.
Definition 4.9 (Frequent Query). Let Qfre denote a set of all frequent
queries in word sequences. A word sequence belongs to Qfre if and
only if the word sequence satisfies the following criteria: (1) the
word sequence belongs to Q and thus can be denoted Qfre  Q; (2)
the number of occurrences of the queries among Q is larger than
threshold .

Finally, the word sequences can be decomposed and recomposed by the proposed functions. The outputs, which are also word
sequences, can then be inspected through several concept candidate criteria. The inspection process could filter meaningless word
sequences and make sure the output results are concept candi-
dates.

5. Deducting semantic relationships

After the concept candidates are identified among the word se-
quences, the semantic relationships can be constructed from the
concept candidates. Two challenges must be addressed before the
final semantic relationships are identified. The first is identifying
the correlated concept candidates. These correlations can be derived from the contextual information, such as co-occurred word
sequences, in the word sequences.

The second challenge is labeling the semantic meanings of the
relationships. To address this challenge, we detect common relationships in other ontologies, since the output ontology should
supplement other ontologies. These common relationships include
hierarchical relationships (introduced in Section 5.1) and synonymous relationships (described in Section 5.2). In addition to these
common relationships, semantic relationships that are less common in other ontologies but are still quite useful for users are also
identified and introduced in Sections 5.2.3 and 5.2.4.

5.1. Hierarchical relationships

Hierarchical relationships, i.e., has subclass and is a, are very
common and constitute necessary relationships in most ontolo-
gies. Two examples of these two types of constructed relationship
are plant has subclass tree and tree is a plant, respectively. The
only difference between the two semantic relationships is that the
two concepts connected by the has subclass relationship must be
classes, but there is no such constraint for the is a relationship.
The common property between the two relationships is that one
correlated concept is more general than the other. To automatically
distinguish general characteristics between two concepts, several

P.-L. Hsu et al. / Web Semantics: Science, Services and Agents on the World Wide Web 31 (2015) 2738

elements of contextual information, which are usually deduced
from the crowd wisdom, are used in this paper.
Classes in ODP categories. The ODP categories are pre-existing

concepts with hierarchical structures.

General words suggested by of. When word sequences contain
of, they can be separated into two parts. Under such
conditions, one separated word is usually more general
than another, based on the grammar structure.

The inferences regarding these two relationships are introduced

as follows:

5.1.1. Has Subclass

The two concepts connected by the has subclass relationship
must be classes. Among the data sources used in this paper, ODP
is the only data source that indicates class information, i.e., ODP
categories. Consequently, ODP categories constitute the primary
data to use for this relationship.
Based on Definition 3.4, each ODP category gODP  GODP can be
separated into many subcategories gODP
. Each subcategory can be
mapped to a word sequence, which might have many meanings
that do not reference other word sequences. If we ignore the
anchoring word sequence (i.e., the word sequence of the supercategory gODP
i1 ) and directly apply the has subclass relationship to
the gODP

, the outcome might be odd and incorrect.

i1 , and gODP

category

Example 5.1. The ODP
Healthcare/Products-and-
Services/Emergency/Vehicles can be separated into four word
sequences: Healthcare, Products-and-Services, Emergency,
and Vehicles. Even though the hierarchical structure of the original ODP category looks reasonable, it would be strange to assert
that Products-and-Services has an Emergency subclass or Emergency has a Vehicles subclass.

Evidence for the reasonableness of the original ODP category
is that the reader uses the super-category information as an anchor to interoperate the subcategory information. For example,
Healthcare Products-and-Services has an Emergency subclass
and Emergency has an Emergency Vehicles subclass are more
reasonable than the previous example. To adapt this anchoring
concept in the has subclass relationship, an N-gram function in
Definition 4.5 (specifically, a two-gram function) concatenates the
anchoring information and the subcategory data. However, if any
super-category is concatenated, the subcategory data might generate the wrong concept.

Additionally, the concatenation forms are uncertain. Some anchoring concepts should be placed before the modified subcate-
gory, while others should be placed after the modified subcategory.
For example, the anchoring concept (harassment) should be
placed after the subcategory (sexual) as sexual harassment;
in other instance, the concept (public) should be placed ahead of
the subcategory (high schools) as public high schools.
Thus, whether the newly generated word sequences (through
concatenation) are still concept candidates must be verified. Based
on the discussion in Section 4.2, the only reasonable mapping
criterion for this scenario is through checking crowd wisdom.
Accordingly, only word sequences that are concatenation outputs
and frequent queries can construct has subclass relationships.
This relationship can be defined as follows:

Definition 5.1 (Has Subclass). Let gODP be one ODP category from
the set GODP. The constructions of the has subclass relationship
can be deduced from the RHSC relationship, where ws1 has a
ws1, ws2 subclass or ws1 has a ws2, ws1 subclass:
RHSC =(ws1,ws1, ws2)|ws1, ws2  Qfre
Given gram2(gODP ) = gODP
i+1  = ws1, ws2,
, gODP
 (ws1,ws2, ws1)|ws2, ws1  Qfre.

Example 5.2 (Example of RHSC). An ODP category gODP = Top/
Arts/Music/Lyrics has two grams gram2(gODP ) = ws1, ws2
= Top, Arts, or Arts, Music, or Music, Lyrics. One of
these two grams maps with a frequent query q = music lyrics.
Based on RHSC, ws1 = Music, ws2 = Lyrics, and ws1,
ws2 = music lyrics  Qfre, then, a relationship Music has
subclass music lyrics has constructed.

5.1.2. Is A

Deducting is a relationships is a necessary feature in all work
in ontology construction. Since this study identifies new concepts
as a supplement to existing ontologies, we focus on frequent
queries and ODP titles that have not been investigated in previous
work as our main data sources.

Based on Section 4.2, the first step in evaluating and detecting
is a relationships from these two data sources is checking the
word sequences containing of. Using the Split-by-Of Function in
Definition 4.7, a word sequence ws containing of, {ws1ofws2}, is
converted into word sequences {ws1} and word sequence {ws2}.
Usually, the word sequence {ws1} is more general than word sequence {ws2}. However, it could be incorrect if we directly constructed an is a relationship from {ws1} and {ws2}.
Example 5.3. In the word sequence background of happy faces,
the word background is more general than the other word
sequence, happy faces. However, if we directly constructed an is
a relationship such as happy faces is a background, this would
be inaccurate.

The reason for its incorrectness is similar to that for Example 5.1, i.e., each word sequence might contain multiple meanings.
Consequently, as with the procedures for constructing has subclass relationships, an anchoring word must be used to confine the
meaning of a word sequence. For example, background of happy
faces is a background is more reasonable than the previous exam-
ple. Based on this deduction, deducing the is a relationship from
word sequences containing of can be defined as follows:
Definition 5.2 (is a from Word Sequences Containing of). The
definition of the is a relationship can be deduced from word sequences containing of by the RIsA|of relationship, where ws is a
ws1:

RIsA|of =(ws, ws1)|ws  {Q  TODP},

splitof (ws) = (ws1, ws2), ws1  NOUN.

Example 5.4 (Example of RIsA|of ). An ODP title University
Washington contains of. Based on RIsA|of , ws =
of
TODP, splitof (ws) =
University of Washington, ws
(ws1, ws2) = (University, Washington), and ws1  NOUN
because University is a noun. Accordingly, a relationship
Washington is a University is con-
University
structed.

of


In addition to deducing is a relationships from word sequences containing of, the crowd wisdom extracted from query
logs and the ODP titles can also become a data source for extracting this relationship. The main challenge is classifying the general
word sequences and the corresponding specific word sequences,
as each word sequence might have multiple meanings. In other
words, identifying anchoring words is essential to constrain the
meaning of the word sequences.

In some query refinement studies [26,27], anchoring words are
distinct among two similar word sequences. For example, for the
two word sequences mac company and mac cosmetics com-
pany, the anchoring word is cosmetics. By using this anchoring word, the users search intention can be detected. In this
example, the users intention for the latter query is cosmetically
oriented, even though the users intention in the previous one is

Qnavi =

 #occurrencesq

#occurrencesq


completely different. However, if we use the anchoring word in the
constructed relationships, which follows the notion of retrieving
anchoring word as ws1 in Definition 5.2, the constructed relationship mac cosmetics company is a cosmetics would be incorrect,
since these two connected concepts are not hierarchically related.
Therefore, directly using the anchoring words of two queries to
construct an is a relationship is quite dangerous, since hierarchically related relationships can be identified only from two word
sequences with the same user intention. Following this inference,
using clicked URLs of queries and the corresponding ODP titles of
the clicked URLs is a more reasonable approach, since the clicked
URLs are confirmed as having the same intentions as the intentions
of the queries submitted by the users. Furthermore, among the data
extracted from the clicked URLs, second-level domain names are
more suitable for this relationship, since they are usually proper
nouns for web pages and can be concept candidates, based on
Definition 4.8. Based on this deduction, the procedures for deducing the is a relationship from crowd wisdom (i.e., frequent
queries, clicked URLs, and ODP titles) can be defined as follows:
Definition 5.3 (is a from the Crowd Wisdom). The constructions
of the crowd wisdom is a relationship can be deduced from the
RIsA|sld relationship as follows:

Given k  K, d2(h) = d2(h(l(k))),

RIsA|sld =(ws, ws1)|ws  d2(h) = ws1, ws1  NOUN,

where ws  q(k), or ws   ODP (l(k)).
Example 5.5 (Example of RIsA|sld). A clicked record k contains
a query q(k) = apple company and a clicked URL l(k) =
www.apple.com. According to the clicked URL, a second level
domain d2(h) = d2(h(l(k))) = apple. Based on RIsA|sld, ws =
apple company, ws  q(k), ws  d2(h) = apple company 
apple = company = ws1, and ws1  NOUN because company is
a noun. Therefore, a relationship apple company is a company
is constructed.
Definition 5.4 (Is A). An is a relationship is constructed either
based on Definition 5.2 or based on Definition 5.3:
RIsA = RIsA|of  RIsA|sld.

5.2. Non-hierarchical relationships

Unlike with hierarchical relationships, the properties of concepts cannot be directly translated into correlated concepts
through non-hierarchical relationships. Even though nonhierarchical relationships are also common and important in ontologies,
various relationships are covered, including synonymous relationships (such as is equal to and has meaning) and correlated relationships (such as has website and has data about).

Synonymous relationships connect synonymous word sequences with slightly different formats. The main challenge is gathering word sequences that refer to the same meanings, since each
word sequence has multiple meanings. To overcome this chal-
lenge, synonymous word sequences are identified based on user
search intentions, i.e., two word sequences are synonymous only if
the two word sequences have the same user searching intentions.
Traditionally, as mentioned in the final paragraph of Section 2,
user search intentions are classified as either informational
or navigational [20,21]. Compared to informational intentions,
navigational intentions, which refer to queries that usually have
only one clicked URL, are relatively easy to identify with high
accuracy. Thus, in this paper, synonymous word sequences are
gathered based only on navigational queries and the corresponding
data, which are defined as follows:
Definition 5.5 (Navigational Query). Let Qnavi be the set of navigational queries that can be extracted based on the following
equation [23]:

click count2
click count1

where q is a distinct query that could be submitted several
times. A distinct query could be submitted by users several
times. Each submitted query is denoted as sq. A submitted query
likely follows no clicked URLs, one clicked URL, or several clicked
URLs. The occurrence of the submitted queries with equal to or
more than one clicked URLs and that of submitted queries with
several clicked URLs are summed as #occurrencesq
click count1 and
#occurrencesq
click count2, respectively.  is a threshold between classifying informational and navigational queries [23]. This formula
emphasizes the majority of the following clicked numbers to a distinct query; this avoids biased domination of a few queries with
a large amount of clicked numbers or zero clicked. Let the clicked
records of these navigational queries be denoted as K|navi
Q , where
K|navi

Q =k|q(k)  Qnavi.

Unlike synonymous relationships, which detect the same
meanings among different word sequences, correlated relationships emphasize locating frequent co-occurrence word se-
quences. In traditional information retrieval communities, the cooccurrence of word sequences usually refers to words that co-exist
on the same pages. However, these co-existing word sequences
might not be correlated in meaning. To address this challenge, we
adopt frequent co-occurrence word sequences between queries
and clicked URLs.

Compared to a query, which might refer to several meanings,
the referring meaning of a URL, which is related to a specific web-
site, is clear. Hence, the associated queries related to a specified
hostname can be gathered. The frequent co-occurring word sequence between queries and the hostname can be identified by utilizing a constant threshold to filter infrequent co-occurred pairs.
Selecting the threshold value then becomes a challenging task
since an inappropriate threshold value might keep or filter too
many word sequences.

The number of submitted queries and clicked URLs occurring in
search logs are usually in power-law distribution [2830]. Only a
few queries or URLs have high submitted or clicked numbers while
many queries and URLs have low numbers. Therefore, setting the
threshold value according to the distributions of the queries for
each hostname would be more reasonable than setting a global
constant value. Hence, the frequent co-occurrence queries should
be identified for each hostname.
Definition 5.6 (Frequent Co-Occurrence Queries). Let Q(h) = {q1,
. . . , qn} denote the set of queries relevant to the hostname h, h 
H. The queries in Q(h) are sorted based on frequency, with
normalized weights weighth,qi:
q  Q(h), weighth,qi =

sth,qi
(sth,qj ),

max
qjQ(h)

where sth,qi represents the number of occurrences of qi for the
hostname h. We also believe that the frequent co-occurrence
queries for each hostname should have comparably larger weights
than those filtered ones. Hence, the value of threshold h is set as
the weight that achieves the maximum difference between its successively sorted queries. With a weight higher than the threshold,
the query could be one of the frequent co-occurrence queries to a
hostname h. The threshold h is obtained by the following formula:
h = weighth,qi ,
where qi = arg max
qiQ(h)

(weighth,qi  weighth,qi+1 ).

The set of frequent co-occurrence queries of hostname h can be denoted as Q(h)

fre , where q  Q(h)

fre , weighth,q > h.

P.-L. Hsu et al. / Web Semantics: Science, Services and Agents on the World Wide Web 31 (2015) 2738

Based on Definition 5.5, the clicked records of navigational
queries, i.e., K|navi
Q , would be utilized as input datasets in Sections 5.2.1 and 5.2.2. Then, based on Definition 5.6, the set of frequent co-occurrence queries of hostname h, i.e., Q(h)
fre , are input
datasets in Sections 5.2.3 and 5.2.4.

5.2.1. Is Equal To

In practice, many second level domain names are aggregated
from several words, such as alice1059 comes from Alice
105.9. It is challenging to divide these aggregated word sequences
into proper segments with the same meaning since these proper
nouns might not be listed in any dictionary. The is equal to relationship tries to identify the correct segments from the second
level domain names by utilizing queries and ODP titles.

To identify synonymous word sequences, navigational datasets
(which include navigational queries, the corresponding clicked
URLs, and the corresponding ODP titles) are collected and classified
based on navigational intentions. For each navigational intention
dataset, the word sequences are decomposed into the smallest
elements and compared with the corresponding second level
domain names. Once the two word sequences have the same
permutations (by excluding the punctuations), the is equal to
relationship is constructed for these two word sequences. The
detailed procedures for deducing the is equal to relationship are
defined as follows.

Given k  K|navi

Definition 5.7 (Is Equal To). The constructions of the is equal to
relationship can be deduced from the RIE relationship:
Q , q = q(k), d2 = d2(h(l(k))), and  =

RIE =(d2, q)|d2 = q (q,  )|q =  (d2,  )|d2 = .

 ODP (l(k)),

Q , q = q(k),  =  ODP (l(k)), and d2 =

Given k  K|navi

d2(h(l(k))),

RHM =(q,  )|q    q = abbr( )
 (d2,  )|d2    d2 = abbr( )
 (q, d2)|q  d2  q = abbr(d2).

Example 5.7 (Example of RHM). A clicked record k  K|navi
contains a query q = asha and its corresponding ODP title  =
American Speech-Language Hearing Association. Based on
RHM, q = asha = ASHA = abbr(American Speech-Language
Hearing Association) = abbr( ). Therefore, a relationship
asha has meaning American Speech-Language Hearing
Association is constructed.

5.2.3. Has Website

The has website relationship correlates the co-occurrence of
frequent queries and websites. This relationship usually provides
a general description of the web pages and gathers scattered
information on different web pages. For example,
online dictionary has the websites www.m-w.com and dictionary.
cambridge.org. The deduced rule is shown in the following.
Definition 5.9 (Has Website). The constructions of
the has
website relationship can be deduced from the RWS relationship,
where ws1 has a ws2 website:
fre of hostname
h, a clicked record k containing a frequent query q = q(k)  Q(h)
fre ,
a hostname h = h(l(k)), and a correlated ODP title  =  ODP (l(k)),

Given a set of frequent co-occurrence queries Q(h)

(ws1, ws2)|ws1 q, , ws2 = h

RWS =


Example 5.6 (Example of RIE). One clicked record k  K|navi
Q contains a second level domain name d2 = uneedapart and an ODP
title  = U Need A Part. Based on RIE, because d2 = uneedapart
= U Need A Part =  , the relationship uneedapart is equal to
U Need A Part is constructed.

Example 5.8 (Example of RWS). A query q = az lyrics frequently co-occurs with the hostname name h = www.azlyrics.com.
Based on RWS, ws1 = az lyrics, ws1  q, and ws2 =
www.azlyrics.com = h, the relationship az lyrics has website
www.azlyrics.com is constructed.

5.2.2. Has Meaning

Unlike the is equal to relationship, the has meaning relationship connects synonymous word sequences even if the word sequences might also contain other meanings. For example, apple
has the meanings found in apple company and apple recipes.
In other words, there are no letter constraints in the has meaning
relationship. The only constraint is that one synonymous word sequence should contain the other synonymous word sequence, or
one is the abbreviation of the other. Due to this constraint, of the
synonymous word sequences connected by the has meaning re-
lationship, one is usually more general than the other.

Based on our observations, shorter word sequences are usually
more general than longer word sequences, as in, for example,
apple and apple company. Thus, the shorter word sequence
should represent the subject term, and the longer word sequence
should act as the object term in the has meaning relationship.

As in the procedures for the is equal to relationship, navigational data records are collected and classified based on navigational intentions. For each navigational intention datum, the word
sequences are decomposed into the smallest elements and checked
through the Contain Function and the Abbreviation Function. Once
there is a match, the shorter word sequence is then used to construct a has meaning relationship with the longer word sequence.
The detailed procedures are defined as follows:

Definition 5.8 (Has Meaning). The constructions of the has meaning relationship can be deduced from the RHM relationship.

5.2.4. Has Data About

The has data about relationship connects websites and their
correlated concepts. This relationship provides a specific description of the web pages and suggests possible data on the web
pages. For example, www.mtv.com has data about music artist,
mya, and seether.

The has website and has data about relationships seem
opposite; however, the properties in search behaviors are different.
The has website relationship is a general approach to detect
frequent co-occurrence between a search query and a hostname.
The has data about relationship is the search query containing
specific sources provided by a frequent co-occurrence website.

Moreover, the has website relationship declares a meaning of
a web site while the has data about relationship indicates a data
source provided by a website. For example, the meaning of the
website www.starbucks.com would be declared as Starbucks
by the relationship Starbucks has website www.starbucks.com
rather than as card by the relationship Starbucks has data about
card.

The possible correlated concepts on the websites are resource
paths of URLs, where the frequent resource paths are crowd wisdom (the occurrence number of the frequent URLs with the resource paths among SL is larger than threshold ). Similar to the
explanation in Section 5.1.1, this relationship should also adapt
the anchoring concepts; i.e., an N-gram function (particularly twogram function) concatenates the anchoring information and the
subcategory data, and the possible entity candidates (i.e., frequent
queries and ODP titles) are checked. Then, the correlated concepts

are verified by frequent co-occurrence queries in the hostname h,
as defined in Definition 5.6. The detailed procedures are defined as
follows:
Definition 5.10 (Has Data About). The constructions of the has
data about relationship can be deduced from the RDA relation-
ship:
Given a clicked record k  K having a hostname h = h(l(k)),
a query q = q(k)  Q(h)
fre ,  =  ODP (l(k)), p = p(l(k)), and
pi = pi(l(k)). If pi =  or pi = q, then,

RDA =(ws1, ws2)|ws1 = h, ws2 = pi

Example 5.9. A clicked record k contains a hostname h = www.
apple.com, a frequent co-occurrence query q = ipod nano, and a
resource path p = /uk/ipodnano/. Based on the resource path p,
a sub-path pi = uk or ipodnano when i = 2, pi = ipodnano =
ipod nano = q. Then, based on RDA, ws1 = www.apple.com
= h, ws2 = ipodnano = pi. Finally, the following relationship
is constructed: www.apple.com has data about ipodnano.

6. Experiments

6.1. Experimental setup

Various datasets were used in the experiments. A MSN search
log was included. The MSN search log released by Microsoft
contains approximately 15 million queries sampled from May 1,
2006 to May 31, 2006. The sample was uniformly distributed over
sessions of US users; a session is identified by the life of the browser
window. These sessions include 13 million clicked records. Besides
search logs, ODP data consisting of nearly 5 million records, and
WordNet [31] for its noun list. These datasets were preprocessed to
remove non-English data and punctuation (except for hyphen (-),
apostrophe (), dot (.), colon (:) and slash (/)). Several parameters
in this experimental test were set. The threshold of frequency
queries , the threshold of frequent URLs , and the threshold for
classifying navigational queries  were set as 5, 3, and 13.445%,1
respectively.

To compare the performance of our proposed technique
(termed the Semantic Context Relationship technique, SCR), the
parts of the Query Log Graphs (QLG) [5] technique are implemented since it is the newest approach for constructing hierarchical relationships only based on unstructured data sources. The
partial implemented procedures include (1) constructing clicking
graphs and (2) finding the cores of the graphs. The procedure for
expanding cores to local areas is omitted in this implementation
since the accuracy of the local areas would be lower than the
cores. The SCR and QLG use the same datasets, including clicked
records gathered based on frequency queries Qfre, navigational
queries Qnavi, and frequent co-occurrence queries Q(h)
fre . In this ex-
periment, SCR is implemented in Python and QLG is implemented
in C#. Both are executed on a Windows 7 personal computer
with an Intel Core i7 4770 processor and 14 GB RAM. The implementation of the proposed system can be downloaded from
http://idea.cs.nthu.edu.tw/SCRcode.tar.

The relationships constructed from the QLG indicate only
the hierarchical concept without corresponding semantic labels.
However, the folksonomy could be induced from hierarchical
clustering on a graph [5]. The relationships are constructed as the
following procedures: (1) within a cluster, each query is with a tfidf score; (2) different thresholds to the query tf-idf score could
gather various hierarchical query groups among a cluster. Pairs of
queries are retrieved from two relevant hierarchical query groups

1 These values are based on a study by Liu [23].

Table 3
Computational time in SCR and QLG.

Computational time (in minutes)

Table 4
Number of relationships.

Relationship

SCR constructed
number

QLG constructed
number

hierarchical related

is related to

has

has subclass
is a
is equal to
has meaning
has website
has data about

1,899,814

for two given thresholds; (3) the relationships extracted from the
QLG were annotated with semantic labels by human experts based
on their semantic meanings between query groups.

The correctness of constructed relationships is evaluated by
human experts through Amazon Mechanical Turk platform [32].
To avoid biased evaluations, each relationship is evaluated by
three different evaluators. The correctness or incorrectness of one
relationship was indicated only if three evaluators have consistent
opinions. The accuracy of each relationship type r is to verify the
proportion of the correct relationships.

Accuracy(r) = |consistentAgreedcorrect|
|consistentAgreed|

(1)

For each experimental setup, we randomly select 125 relationships from each extracted dataset, e.g., 125 relationships for has
data about extracted from the SCR. In the end, among all 3375
evaluated relationships, only 2534 were successfully validated,
which received consistent opinions, in Amazon Mechanical Turk
by 134 evaluators, whose confidence level is 0.95.

6.2. Experimental results

The computational time of main procedures in SCR (construct-
ing relationships) and those in QLG (building graphs and inducing relationships) are listed in Table 3. Table 3 indicates that the
computational complexity of both techniques are comparable, although SCR is slightly faster than QLG.

The quantity of the constructed results was also verified. The
number of relationships generated for the six semantic relationship types with the SCR and QLG is shown in Table 4. In general, all
semantic relationship procedures can yield outputs as those produced by large-scale input records. Moreover, SCR can extract at
least 10 times more semantic relationships than QLG does. The
possible reason for this is that we have omitted the procedure for
expanding cores to local areas from QLG; this procedure can generate more relationships but reduces the accuracy, which should
be a more important metric than the quantity.

The number of generated has website relationships is the
largest number of relationships because the constructing rule is the
least strict among all the relationship types. Moreover, the number
of generated has subclass relationships is the lowest number of
relationships since matching word sequences from hierarchical
data to frequent queries is more difficult. These two observations
suggest that the number of outputs might be correlated to the
strictness of the rules.

Fig. 2 illustrates the accuracy of 375 sampled relationships generated based on the frequent query dataset. In practice, assigning is a and has subclass relationships to the relationships
constructed from QLG is difficult since there is no semantic label for
the QLG relationship. The hierarchy of the QLG cannot directly refer

P.-L. Hsu et al. / Web Semantics: Science, Services and Agents on the World Wide Web 31 (2015) 2738

Fig. 3. Comparisons among relationships from the navigational query dataset.

Fig. 2. Comparisons among relationships from the frequent query dataset.

Table 5
Sampled is a relationships.

Relationship

Cabin 26 Hardware
cervis inc
Jacobi medical center

is a
is a
is a

hardware
inc
center

Technique

to the real semantic meaning. For example, find name of cell number is in the superset of free phone number and address search.
However, it is odd to directly assign has subclass between them.
Consequently, the label hierarchical related is a more appropriate
label for QLG relationships in this case. To fairly compare the QLG
results with those of the has subclass and is a relationships from
the SCR, we aggregated them into the hierarchical related relationships in Fig. 2.

As illustrated in Fig. 2, the SCR performs much better than QLG
in general. Moreover, the SCR has the best performance for the has
subclass relationships, indicating that the ODP hierarchical classes
are familiar and acceptable to evaluators. We sampled several
relationships, as shown in Table 5, to illustrate the reasons for
incorrect is a relationships.

It is difficult for evaluators to correctly evaluate a hierarchical
relationship between two concepts in free format. Among 125
QLG hierarchical related relationships, only 50 relationships (40%)
could be consistently evaluated. More SCR is a relationships, 82
out of 125 relationships (65%), were consistently evaluated. This
suggests that when the general concept in an is a relationship is
a single-word format, this relationship is easier for evaluators.

The SCR is a relationship is likely incorrect due to the error
detection of the relationships general concept. For example, the
general concept of Cabin 26 Hardware should be store
rather than hardware. The error detection is likely caused by poor
recognition of proper nouns in the SCR approach. In addition, a detected general concept in an is a relationship is likely an incomplete word sequence (e.g., inc instead of incorporation).
The incomplete word sequences usually result in inconsistent eval-
uations.

Fig. 3 illustrates the accuracy of 375 relationships constructed
based on the navigational query dataset. Again, since assigning is
equal to and has meaning labels to the relationships constructed
from QLG is too challenging, the human experts assigned is related
to labels to the extracted relationships, where the concepts in the
corresponding query groups are similar. Note that the is related
to label is a more relaxed concept as compared to is equal to and
has meaning. We directly aggregated the results of the is equal
to and has meaning relationships constructed from the SCR to
the is related to relationships in Fig. 3. This figure shows that the
SCR and QLG have equivalent performances, where the SCR slightly
outperforms in accuracy.

Fig. 4. Comparisons among relationships from the frequent co-occurrence query
dataset.

Fig. 4 shows the accuracy of 375 relationships constructed
based on the frequent co-occurrence query dataset. For the same
reasons described above, we aggregated the results for the has
website and has data about relationships constructed from the
SCR into the has relationships shown in Fig. 4. Compared to the
high accuracy of the QLG in is related to relationships, the accuracy of QLG in has relationships is much lower. A possible reason
might be incorrectly clicked URLs, as suggested in Franciscos paper [5].

The accuracy of has data about is 81.81%. The accuracy of
has website is 89.90%. Based on the observations, the incorrect
relationships for these two relationships types are usually related
to a website that contains a large pool of information and a
website with a specific piece of information in an inconspicuous
location. The specific piece of information is difficult to identify by
evaluators.

To evaluate the effects of thresholds for frequent queries on
the accuracy of SCR constructed relationships, three datasets were
constructed based on various thresholds (i.e., 2, 3, and 4). The SCR
then extracted relationships from the three constructed datasets.
For each dataset, 125 relationships were randomly selected and
evaluated by evaluators in Amazon Mechanical Turk. Table 6
illustrates the corresponding accuracy results.

As revealed in Table 6, the effect of thresholds for frequent
queries on the accuracy of constructed relationships is insignifi-
cant. In most relationship types, the accuracies gradually improve
with increasing threshold values. The has website relationship
type is the only one that the accuracies are not related to the
threshold values. The has data about relationships have the lowest accuracy among all relationships types and much lower than
the accuracies in Fig. 4. The lower accuracy might be related to the
lower thresholds, where more infrequent webpages are extracted

Table 6
Relationships accuracies in various frequent query thresholds.

Relationship

has subclass
is a
is equal to
has meaning
has website
has data about

Accuracy in  > 4
input datasets
100%
92.72%
100%
84.61%
91.15%
68.66%

Accuracy in  > 3
input datasets
100%
81.08%
100%
83.33%
88.04%
68.75%

Accuracy in  > 2
input datasets
99.22%
79.54%
100%
70%
90.10%
57.14%

Table 7
SCR relationships in WordNet and Swoogle.

Relationship
has subclass
is a
is equal to
has meaning
has website
has data about

#matched in WordNet

#matched in Swoogle
Not applicable

Not applicable

in order to construct the less confident relationships. Moreover, by
analyzing the evaluated results, we found out the most of inaccurate relationships are correlated to certain domain name registrars.
It is likely that the domain names could be expired, thus the evaluators have difficulty to locate the corresponding information which
is shown in 2006 (note that the search logs were collected in 2006).
In order to compare the differences between SCR relationships
with the existing ontologies, we tried to locate the corresponding
matched relationship for each identified SCR relationship from
two ontology sources, WordNet and Swoogle (a search engine for
searching information on ontologies). If the same concept pair for
a certain SCR relationship can be obtained from the ontologies
and the two concepts are connected by an edge or through the
same parent, the corresponding semantic label is then examined.
If the semantic label and the SCR relationship type have similar
meanings, the SCR relationship has a matched relationship in the
existing ontology. For example, a matched WordNet relationship
fish subclass of fish and a retrieving fish has
bony
subclass bony fish represent the same meaning even though
the semantic labels subclass of  and has subclass are different.
Table 7 shows the number of matched relationships for two different ontologies. Note that data results for Swoogle are incomplete since the Swoogle website is closed in the middle of the
experiments for a long time and we cannot finish the experiments
since the website is no longer accessible. However, we believe that
although the data results are incomplete, they are still valuable.
Table 7 indicates there is only a small portion of constructed relationships that can be matched in the existing ontologies. This
demonstrates that our proposed techniques can indeed find the
supplementary relationships for the existing ontologies. Moreover,
the matched relationships also demonstrate that our SCR techniques can correctly extract the hierarchical relationships, such as
subclass of  relationships from WordNet and 115 type relationships from Swoogle (e.g., university of washington type
university).

In summary, our experimental results suggest our proposed
technique can extract satisfactory relationships from heterogeneous datasets. Because our technique uses hierarchical data (such
as ODP and URL path data), our Semantic Context Relationship
technique significantly outperforms the Query Log Graphs [5] technique by accuracy.

7. Discussion

We propose an approach based on semantic properties among
search logsusers search interests, which could reveal different
perspectives of user interest. The experimental results demon-

strate that the proposed approach does construct satisfactory re-
lationships. However, we realize this approach has several limita-
tions.

First, even though the constructed relationships might reveal
different perspectives of user interests, the coverage of the perspectives could be incomplete since there is no guarantee that the
constructed relationships cover all meanings of a specific word se-
quence. Take the word sequence apple as an example. This consists of at least two different concepts apple company and apple
juice, where one is a subclass of company and the other a subclass of fruit. Our approach can only extract the relationship, such
as apple company, to be annotated and searched when apple
is the indexing word. The very common relationship, apple juice,
might not appear in the final output since apple is too common
a search item.

We are aware of the incompleteness property of our proposed
method and try to avoid the completeness inspection for the extracted relationships. Hence, some popular semantic relationships,
such as means, which can be found in YAGO [9], and subclass
of , which can be found in WordNet, are not extracted in our proposed techniques. In order to construct these relationships, the set
memberships (such as those that contain relationships) should be
verified, but these data are not applicable in our data sources. In
order to avoid the set memberships checkup, we extracted similar
relationships instead, such as has subclass and has meaning.

The second limitation is that it is difficult to reveal or explain
some user interests with our utilized datasets, such as secondlevel domain names or ODP titles. Take the popular television series Desperate Housewives aired weekly for one hour from 2004
to 2012. Many relevant queries reveal this television series attracts
users, such as abc desperate housewives, desperate housewives
recently, Last nights Desperate Housewives, desperate housewives deleted scene for season finale, and where is Wisteria Lane
located in the Desperate Housewives show. Since these queries
contain various word sequences, it is challenging to extract frequent word sequences from our data sources. Consequently, only
very well-known concepts, such as abc, which can be found from
the second-level domain names or ODP titles, or websites can be
related to Desperate Housewives. To address these problems,
more data sources will be included in our future work. One possible
data source is Twitter, which likely contains many user interests in
short sentences.

8. Conclusion

The contribution of this study is the use of unstructured
collaborative data to construct various semantic relationships.
We observed the semantic characteristics of heterogeneous data
(search logs and social annotations) and formally defined these
data and their common semantic characteristics. Various semantic
relationships include relationships commonly found in ontologies,
such as has subclass, is a, is equal to, and has meaning,
as well as other relationships, such as has data about and has
websites. These relationships were evaluated by 134 evaluators
in Amazon Mechanical Turk and achieved satisfactory levels of
efficiency, as indicated by accuracy.

In our future work, we will use more heterogeneous collaborative data sources in our proposed method to further prove that our
definitions of common semantic characteristics transform heterogeneous data into homogeneous data. We will further modify the
rules of some relationships for more accuracy. The heterogeneous
data would include Twitter that might provide more information
and thus the semantic meanings of the information attracting users
interests could be revealed.
