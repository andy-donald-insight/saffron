Semantic Web 0 (0) 127
IOS Press

Probabilistic Description Logics under the
Distribution Semantics

Editor(s): Wolfgang Faber, University of Huddersfield, UK; Domenico Lembo, Sapienza University of Rome, Italy
Solicited review(s): Claudia dAmato, University of Bari, Italy; Umberto Straccia, ISTI-CNR, Italy; one anonymous reviewer

Fabrizio Riguzzi a Elena Bellodi b Evelina Lamma b Riccardo Zese b
a Dipartimento di Matematica e Informatica, University of Ferrara, Via Saragat 1, I-44122, Ferrara, Italy
E-mail: fabrizio.riguzzi@unife.it
b Dipartimento di Ingegneria, University of Ferrara, Via Saragat 1, I-44122, Ferrara, Italy
E-mail: {elena.bellodi,evelina.lamma,riccardo.zese}@unife.it

Abstract. Representing uncertain information is crucial for modeling real world domains. In this paper we present
a technique for the integration of probabilistic information in Description Logics (DLs) that is based on the
distribution semantics for probabilistic logic programs. In the resulting approach, that we called DISPONTE, the
axioms of a probabilistic knowledge base (KB) can be annotated with a real number between 0 and 1. A probabilistic
knowledge base then defines a probability distribution over regular KBs called worlds and the probability of a
given query can be obtained from the joint distribution of the worlds and the query by marginalization. We present
the algorithm BUNDLE for computing the probability of queries from DISPONTE KBs. The algorithm exploits
an underlying DL reasoner, such as Pellet, that is able to return explanations for queries. The explanations are
encoded in a Binary Decision Diagram from which the probability of the query is computed. The experimentation
of BUNDLE shows that it can handle probabilistic KBs of realistic size.

Keywords: Probabilistic Ontologies, Probabilistic Description Logics, OWL, Probabilistic Logic Programming,
Distribution Semantics

1. Introduction

Representing uncertain information is of foremost importance in order to effectively model real
world domains. This has been fully recognized
in the field of Artificial Intelligence where uncertainty has been the focus of much research since its
beginnings. In particular, the integration of logic
and probability allows to model complex domains
with many entities interconnected by uncertain re-
lationships. This problem has been investigated by
various authors both in the general case of first
order logic [42,22,6] and in the case of restricted
logics, such as Description Logics (DLs) and Logic
Programming (LP).

DLs are fragments of first order logic particularly useful for knowledge representation. They are

at the basis of the Semantic Web. The Web Ontology Language (OWL) is a family of languages
that are syntactic variants of various DLs. Many
proposals have appeared on the combination of
probability theory and DLs [23,24,35,39,40]. Probabilistic DLs play an important role in the Semantic Web where knowledge may come from different
sources and may have different reliability.

In LP, the distribution semantics [65] has
emerged as one of the most effective approaches
for representing probabilistic information. It underlies many probabilistic logic programming languages such as Probabilistic Horn Abduction [47],
PRISM [65,66], Independent Choice Logic [48],
Logic Programs with Annotated Disjunctions [74],
ProbLog [50] and CP-logic [75]. A program in
one of these languages defines a probability distri-

1570-0844/0-1900/$27.50 c 0  IOS Press and the authors. All rights reserved

F. Riguzzi et al. / Probabilistic Description Logics under the Distribution Semantics

bution over normal logic programs called worlds.
This distribution is extended to queries and the
probability of a query is obtained by marginalizing the joint distribution of the query and the pro-
grams. The languages following the distribution
semantics differ in the way they define the distribution over logic programs but have the same
expressive power: there are transformations with
linear complexity that can convert each one into
the others [73,16].

The distribution semantics was applied successfully in many domains [50,66,7] and various inference and learning algorithms are available for it
[31,54,8].

In [9,60,61] we applied this approach to DLs obtaining DISPONTE for DIstribution Semantics
for Probabilistic ONTologiEs (Spanish for get
ready). The idea is to annotate axioms of a theory
with a probability and assume that each axiom is
independent of the others. A DISPONTE knowledge base (KB) defines a probability distribution
over regular KBs (worlds) and the probability of
a query is obtained from the joint probability of
the worlds and the query. The DISPONTE semantics differs from previous proposals because it provides a unified framework for representing different
types of probabilistic knowledge, from assertional
to terminological knowledge. DISPONTE can be
applied to any DL, here we present it for a prototypical expressive DL, SHOIN (D), that is the
basis of OWL DL.

We also present the algorithm BUNDLE for
Binary decision diagrams for Uncertain reasoNing on Description Logic thEories [62], that performs inference over DISPONTE DLs. BUNDLE
exploits an underlying reasoner such as Pellet [69]
that returns explanations for queries. BUNDLE
uses the inference techniques developed for probabilistic logic programs under the distribution se-
mantics, in particular Binary Decision Diagrams
(BDDs), for computing the probability of queries
from a covering set of explanations. BUNDLE first
finds explanations for the query and then encodes
them in a BDD from which the probability can be
computed in time linear in the size of the diagram.
BUNDLEs worst case complexity is high since
the number of explanations may grow exponentially while the computation of the probability
through BDDs has #P-complexity in the number
of explanations. Nevertheless, we applied BUN-

DLE to various real world datasets and we found
that it is able to handle domains of significant size.
The present paper extends previous work [9,60,
61,62] in various ways. With respect to the most
recent work [62], the DISPONTE semantics is described in more detail with several examples; inference under this semantics is illustrated according to different techniques; we discuss how a lower
bound on the probability of a query can be com-
puted, with the quality of the bound monotonically increasing as more time for inference is al-
lowed; BUNDLE is presented in more detail together with an extended description of Pellets
functions and a discussion about its computational
complexity. Moreover, we elaborated a detailed
comparison with related work and performed an
extensive experimental analysis of BUNDLE in order to investigate its performance in practice. In
particular we present a more in-depth comparison with PRONTO, a system for inference in the
probabilistic DL P-SHIQ(D), and an analysis on
the inference time trend with increasing sizes of
the Tbox, the Abox and the set of probabilistic
axioms.

The paper is organized as follows. Section 2 introduces Description Logics with particular reference to SHOIN (D) while Section 3 discusses
DISPONTE. Section 4 illustrates how to compute
the probability of queries to DISPONTE DLs and
Section 5 describes the BUNDLE algorithm. Section 6 discusses the complexity of reasoning and
Section 7 related work. Section 8 shows the results
of experiments with BUNDLE and, finally, Section
9 concludes the paper.

2. Description Logics

Description Logics are knowledge representation
formalisms that possess nice computational properties such as decidability and/or low complex-
ity, see [3,5] for excellent introductions. DLs are
particularly useful for representing ontologies and
have been adopted as the basis of the Semantic
Web.

While DLs are a fragment of predicate logic,
they are usually represented using a syntax based
on concepts and roles. A concept corresponds to a
set of individuals of the domain while a role corresponds to a set of couples of individuals of the
domain. In order to illustrate DLs, we describe

SHOIN (D) as a prototype of expressive description logics. In the rest of the paper we use A,
R and I to indicate atomic concepts, atomic roles
and individuals, respectively. A role is either an
atomic role R  R or the inverse R of an atomic
role R  R. We use R to denote the set of all
inverses of roles in R. Concepts are defined as fol-
lows. Each A  A,  and  are concepts and if
a  I, then {a} is a concept called a nominal. If
C, C1 and C2 are concepts and R  R R, then
(C1 (cid:117) C2), (C1 (cid:116) C2) and C are concepts, as well
as R.C and R.C and  nR and  nR for an
integer n  0.
An RBox R consists of a finite set of transitivity axioms T rans(R), where R  R, and role
inclusion axioms R (cid:118) S, where R, S  R  R.
A TBox T is a finite set of concept inclusion axioms C (cid:118) D, where C and D are concepts. We
use C  D to abbreviate C (cid:118) D and D (cid:118) C.
An ABox A is a finite set of concept membership
axioms a : C, role membership axioms (a, b) : R,
equality axioms a = b and inequality axioms a = b,
where C is a concept, R  R and a, b  I. A knowledge base K = (T ,R,A) consists of a TBox T , an
RBox R and an ABox A.
A SHOIN (D) KB K is assigned a semantics
in terms of interpretations I = (I,I) where
I is a non-empty domain and I is the interpretation function that assigns an element in I
to each a  I, a subset of I to each A  A
and a subset of I  I to each R  R. The
mapping I is extended to all concepts (where
RI(x) = {y|(x, y)  RI} and #X denotes the cardinality of the set X) as:

(R)I = {(y, x)|(x, y)  RI}

I = I
I = 
{a}I = {aI}
(C1 (cid:117) C2)I = CI
(C1 (cid:116) C2)I = CI

1  CI
1  CI
(C)I = I \ CI

(R.C)I = {x  I|RI(x)  CI}
(R.C)I = {x  I|RI(x)  CI = }
( nR)I = {x  I|#RI(x)  n}
( nR)I = {x  I|#RI(x)  n}

new concept definitions involving datatype roles
are added that mirror those involving roles introduced above. We also assume that we have predicates over the datatypes.
The satisfaction of an axiom E in an interpretation I = (I,I), denoted by I |= E, is defined
as follows: (1) I |= T rans(R) iff RI is transitive,
(2) I |= R (cid:118) S iff RI  SI, (3) I |= C (cid:118) D
iff CI  DI, (4) I |= a : C iff aI  CI, (5)
I |= (a, b) : R iff (aI, bI)  RI, (6) I |= a = b iff
aI = bI, (7) I |= a = b iff aI = bI. I satisfies a set
of axioms E, denoted by I |= E, iff I |= E for all
E  E. An interpretation I satisfies a knowledge
base K = (T ,R,A), denoted I |= K, iff I satisfies
T , R and A. In this case we say that I is a model
of K.
A knowledge base K is satisfiable iff it has a
model. An axiom E is entailed by K, denoted K |=
E, iff every model of K satisfies also E. A concept
C is satisfiable relative to K iff K has a model I
such that CI = .

A DL is decidable if the problem of checking
the satisfiability of a KB is decidable. In particu-
lar, SHOIN (D) is decidable iff there are no number restrictions on non-simple roles. A role is nonsimple iff it is transitive or it has transitive sub-
roles.

A query over a KB is usually an axiom for which
we want to test the entailment from the KB. The
entailment test may be reduced to checking the
unsatisfiability of a concept in the KB, i.e., the
emptiness of the concept. For example, the entailment of the axiom C (cid:118) D may be tested by checking the unsatisfiability of the concept C (cid:117) D.

3. The DISPONTE Semantics for DLs

DISPONTE applies the distribution semantics
[65] of probabilistic logic programming to DLs. A
program following this semantics defines a probability distribution over normal
logic programs
called worlds. Then the distribution is extended to
queries and the probability of a query is obtained
by marginalizing the joint distribution of the query
and the programs.

SHOIN (D) adds to SHOIN datatype roles,
i.e., roles that map an individual to an element
of a datatype such as integers, floats, etc. Then

3.1. Syntax and Intuition

In DISPONTE, a probabilistic knowledge base K
is a set of certain axioms or probabilistic axioms.

F. Riguzzi et al. / Probabilistic Description Logics under the Distribution Semantics

Certain axioms take the form of regular DL ax-
ioms. Probabilistic axioms take the form

p :: E

(1)

where p is a real number in [0, 1] and E is a DL
axiom.

The idea of DISPONTE is to associate independent Boolean random variables to the probabilistic
axioms. By assigning values to every random variable we obtain a world, the set of axioms whose
random variables are assigned the value 1.

Every formula obtained from a certain axiom
is included in a world w. For each probabilistic
axiom, we decide whether to include it or not in w.
A world therefore is a non probabilistic KB that
can be assigned a semantics in the usual way. A
query is entailed by a world if it is true in every
model of the world.

The probability p can be interpreted as an epistemic probability, i.e., as the degree of our belief
in axiom E. For example, a probabilistic concept
membership axiom

p :: a : C

means that we have degree of belief p in C(a). The
statement that Tweety flies with probability 0.9
can be expressed as

0.9 :: tweety : F lies

A probabilistic concept inclusion axiom of the
form

p :: C (cid:118) D

(2)

represents the fact that we believe in the truth of
C (cid:118) D with probability p. For example, the axiom

0.9 :: Bird (cid:118) F lies

(3)

means that birds fly with a 90% probability.

3.2. Semantics

We follow the approach of [49] and first give
some definitions. An atomic choice is a couple
(Ei, k) where Ei is the ith probabilistic axiom and
k  {0, 1}. k indicates whether Ei is chosen to be
included in a world (k = 1) or not (k = 0). A set of

(Ei,1) pi

atomic choices  is consistent if only one decision is
taken for each probabilistic axiom; we assume independence between the different choices. A composite choice  is a consistent set of atomic choices.
The probability of a composite choice  is P () =

(Ei,0)(1pi), where pi is the probability associated with axiom Ei. A selection  is
a total composite choice, i.e., it contains an atomic
choice (Ei, k) for every probabilistic axiom of the
theory. A selection  identifies a theory w called
a world in this way: w = C  {Ei|(Ei, 1)  }
where C is the set of certain axioms. Let us indicate with SK the set of all selections and with WK

the set of all worlds. The probability of a world w
(Ei,0)(1  pi).
P (w) is a probability distribution over worlds,

(Ei,1) pi

is P (w) = P () =
i.e.,

wWK P (w) = 1.

We can now assign probabilities to queries.
Given a world w, the probability of a query Q is
defined as P (Q|w) = 1 if w |= Q and 0 other-
wise. The probability of a query can be obtained
by marginalizing the joint probability of the query
and the worlds:

wWK

wWK

P (Q) =

P (Q, w)

P (Q|w)P (w)

P (w)

wWK:w|=Q

(4)

(5)

(6)

where (4) and (5) follow for the sum and product
rule of the theory of probability respectively and
(6) holds because P (Q|w) = 1 if w |= Q and 0
otherwise.

Example 1. Consider the following KB, inspired
by the people+pets ontology proposed in [43]:
0.5 :: hasAnimal.P et (cid:118) N atureLover

(kevin, fluffy) : hasAnimal

(kevin, tom) : hasAnimal

fluffy : Cat

tom : Cat
0.6 :: Cat (cid:118) P et

(7)

(8)

(9)

(10)

(11)

(12)

The KB indicates that the individuals that own an
animal which is a pet are nature lovers with a 50%

probability and that kevin has the animals fluffy
and tom. Fluffy and tom are cats and cats are pets
with probability 60%. The KB has four possible
worlds, corresponding to the selections:

{((7), 1), ((12), 1)}
{((7), 1), ((12), 0)}
{((7), 0), ((12), 1)}
{((7), 0), ((12), 0)}

and the query axiom Q = kevin : N atureLover
is true in the first of them, while in the remaining
ones it is false. Each pair in the selections contains
the axiom identifier and the value of its selector
(k).
The probability of the query is P (Q) = 0.50.6 =

0.3.

Example 2. Let us consider a slightly different
knowledge base:

hasAnimal.P et (cid:118) N atureLover
(kevin, fluffy) : hasAnimal

(kevin, tom) : hasAnimal

0.4 :: fluffy : Cat

0.3 :: tom : Cat
0.6 :: Cat (cid:118) P et

(13)

(14)

(15)

Here individuals that own an animal which is a pet
are surely nature lovers and kevin has the animals
fluffy and tom. Moreover, we believe in the fact
that fluffy and tom are cats and that cats are pets
with a certain probability.

This KB has eight worlds and the query axiom
Q = kevin : N atureLover is true in three of them,
those corresponding to the following selections:

{((13), 1), ((14), 0), ((15), 1)}
{((13), 0), ((14), 1), ((15), 1)}
{((13), 1), ((14), 1), ((15), 1)}

so the probability is
P (Q) = 0.40.70.6+0.60.30.6+0.40.30.6 = 0.348.

Note that if the regular DL KB obtained by
stripping the probabilistic annotations is inconsis-
tent, there will be worlds that are inconsistent too.
These worlds will entail the query trivially, as does

the regular KB. A DISPONTE KB with inconsistent worlds should not be used to derive conse-
quences, just as a regular DL KB that is inconsistent should not.

However, apparently contradictory probabilistic

information is allowed. For example, the KB

0.9 :: Bird (cid:118) F lies
0.1 :: tweety : F lies

tweety : Bird

states that the probability of flying for a bird is 0.9
and the probability of flying for tweety, a particular bird, is 0.1. The two probabilistic statements
are considered as independent evidence for tweety
flying and are combined giving the probability 0.91
for the query tweety : F lies. In fact, this KB has
four worlds and tweety : F lies is true in three of
them, giving P (Q) = 0.9 0.1 + 0.9 0.9 + 0.1 0.1 =
0.91. Thus knowledge about instances of the domain may reinforce general knowledge and vice-
versa.

Example 3. The knowledge base

kevin : friend .P erson
(kevin, laura) : friend

(laura, diana) : friend

0.4 :: T rans(friend )

means that all individuals in the friend relationship with kevin are persons, that kevin is a friend
of laura, that laura is a friend of diana and that
given three individuals a, b and c, there is a 40%
probability that if a is a friend of b and b is a
friend of c then a is a friend of c. In particular, we
have a 40% probability that, if kevin is a friend of
laura and laura is a friend of diana, then kevin
is a friend of diana. Since the first two are certain
facts, then kevin is a friend of diana with a 40%
probability and diana is a person also with a 40%
probability.

The final report of the W3C Uncertainty Reasoning for the World Wide Web Incubator Group
[71]
discusses the challenge of reasoning with
uncertain information on the World Wide Web.
Moreover,
it also highglights several use cases
for the representation of uncertainty: combining

F. Riguzzi et al. / Probabilistic Description Logics under the Distribution Semantics

knowledge from multiple, untrusted sources; discovering and using services in the presence of
uncertain information on the user requirements
and the service descriptions; recommending items
to users; extracting and annotating information
from the web; automatically performing tasks for
users such as making an appointment, and handling healthcare and life sciences information and
knowledge.
By introducing probability in an expressive description logic, such as SHOIN (D) that is one
of the bases of OWL, we are able to tackle these
problems as shown in the following example.

Example 4. Consider a KB similar to the one of
Example 2 but where we have a single cat, fluffy.
Suppose the user has the knowledge

hasAnimal.P et (cid:118) N atureLover
(kevin, fluffy) : hasAnimal
Cat (cid:118) P et

and there are two sources of information with different reliability that provide the information that
fluffy is a cat. On one source the user has a degree
of belief of 0.4, i.e., he thinks it is correct with a
40% probability, while on the other source he has
a degree of belief 0.3, i.e., he thinks it is correct
with a 30% probability. The user can reason on
this knowledge by adding the following statements
to his KB:

0.4 :: fluffy : Cat

0.3 :: fluffy : Cat

(16)

(17)

The two statements represent independent evidence on fluffy being a cat.

The query axiom Q = kevin : N atureLover is
true in 3 out of the 4 worlds, those corresponding
to the selections:

{((16), 1), ((17), 1)}
{((16), 1), ((17), 0)}
{((16), 0), ((17), 1)}

So P (Q) = 0.4  0.3 + 0.4  0.7 + 0.6  0.3 = 0.58.
This is reasonable if the two sources can be considered as independent. In fact, the probability comes
from the disjunction of two independent Boolean

random variables with probabilities respectively 0.4
and 0.3:

P (Q) = P (X1  X2)

= P (X1) + P (X2)  P (X1  X2)
= P (X1) + P (X2)  P (X1)P (X2)
= 0.4 + 0.3  0.4  0.3 = 0.58

4. Inference

We propose an approach for performing inference over DISPONTE DLs in which we first find
explanations for the given query and then compute
the probability of the query from them. In order
to discuss the approach, we first need to introduce
some definitions.
A composite choice  identifies a set of worlds
 = {w|  SK,   }, the set of worlds whose
selection is a superset of , i.e., the set of worlds
compatible with . We define the set of worlds
identified by a set of composite choices K as K =

K .
A composite choice  is an explanation for a
query Q if Q is entailed by every world of .
A covering set of explanations for Q is a set of
composite choices K such that every world w in
which the query is true is included in K.

Two composite choices 1 and 2 are incompatible if their union is inconsistent. For exam-
ple, the composite choices 1 = {(Ei, 1)} and
2 = {(Ei, 0)} are incompatible where Ei
is a
probabilistic axiom. A set K of composite choices
is pairwise incompatible if for all 1  K, 2 
K, 1 = 2 implies 1 and 2 are incompatible.
For example

K = {1, 2}

with

and

1 = {(Ei, 1)}

2 = {(Ei, 0), (El, 1)}

is pairwise incompatible.

(18)

(19)

We define the probability of a pairwise incom-

patible set of composite choices K as

P (K) =

P ()

(20)

Two sets of composite choices K1 and K2 are
equivalent if K1 = K2, i.e., if they identify the
same set of worlds. For example, K in (18) is
equivalent to
K = {

(21)

2}
1, 

with

and

1 = {(Ei, 1)}


2 = {(El, 1)}


4.1. Inference with the splitting algorithm

If E is an axiom and  is a composite choice
such that   {(E, 0), (E, 1)} = , the split of
 on E is the set of composite choices S,E =
{  {(E, 0)},   {(E, 1)}}. It is easy to see that
 and S,E identify the same set of possible
worlds, i.e., that  = S,E . For example, the
split of 
2 in (22) on Ei contains 2 in (19) and
{(Ei, 1), (El, 1)}.

Poole [49] proved the following result.

Theorem 1. Given a finite set K of finite composite choices, there exists a finite set K of pairwise
incompatible finite composite choices such that K
and K are equivalent.

Proof. Given a finite set of finite composite choices
K, there are two possibilities to form a new set
K of composite choices so that K and K are
equivalent:

and 1  2, let K = K \ {2}.

1. removing dominated elements: if 1, 2  K
2. splitting elements: if 1, 2  K are compatible (and neither is a superset of the other),
there is a (E, k)  1 \ 2. We replace 2 by
the split of 2 on E. Let K = K \ {2} 
S2,E.

In both cases K = K. If we repeat these two
operations until neither is applicable we obtain a
splitting algorithm (see Figure 1) that terminates
because K is a finite set of finite composite choices.
The resulting set K is pairwise incompatible and
is equivalent to the original set. For example, the
splitting algorithm applied to K (21) can return
(cid:117)(cid:116)
K (18).

Theorem 2 ([47]). If K1 and K2 are both pairwise incompatible finite sets of finite composite
choices such that they are equivalent then P (K1) =
P (K2).
2} with
For example, K in (18) and K = {
1 = {(Ei, 1), (El, 0)} and 
2 = {(El, 1)} are

equivalent and are both pairwise incompatible.
Their probabilities are

1 , 

P (K) = pi + (1  pi)pl = pi + pl  pipl

(22)

and

P (K) = pi(1  pl) + pl = pi + pl  pipl

Note that if we compute the probability of K in
(21) with formula (20) we would obtain pi + pl
which is different from the probabilities of K and
K above, even if K is equivalent to K and K,
because K is not pairwise incompatible.

We can thus define the probability P (K) of a
generic set of composite choices K as P (K) =
P (K), where K is a mutually incompatible set
of composite choices that is equivalent to K, i.e.,
such that K = K. Given a query Q, the set
KQ = {|  SK  w |= Q} is a set of pairwise
incompatible composite choices. Since P (Q) =

P (), then P (Q) = P (KQ).

If K is a set of explanations for Q that is cov-
ering, then K and KQ are equivalent so P (Q) =
P (KQ) = P (K). Thus we do not have to generate
all worlds where a query is true in order to compute its probability, finding a mutually incompatible covering set of explanations is enough. More-
over, an additional result is given by the following
theorem.

Theorem 3. Given two finite sets of finite composite choices K1 and K2, if K1  K2, then
P (K1)  P (K2).

F. Riguzzi et al. / Probabilistic Description Logics under the Distribution Semantics

Input: set of composite choices K
Output: pairwise incompatible set of composite choices equivalent to K
loop

1: procedure split(K)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16: end procedure

end if
end loop

end if

else

if 1, 2  K and 1  2 then

K  K \ {2}
if 1, 2  K compatible then

else

choose (E, k)  1 \ 2
K  K \ {2}  S2 ,E

exit and return K

Fig. 1. Splitting Algorithm.

Proof. Let K
1 be the result of the application of
the splitting algorithm to K1. We can apply the
same operations of the algorithm to K2 obtaining
1K for a certain K. At this point, we can
K = K
continue applying the splitting algorithm. If there
exists a   K and a   K such that   ,
at least one of  and  must not belong to K
1,
otherwise  would have been removed when splitting K
1.  is removed from K while  remains. If
there is a compatible couple 1 and 2 in K, we
can assume that one of the two, say 2, does not
belong to K
1, since otherwise it would have been
split before. We add to K the split of 2 on an
atomic choice in 1 but not in 2.
Let K
2 be the results of the splitting algorithm
so applied. K
2 is such that, for each element 1 of
2 contains an element 2 such that 2  1.

1, K
Therefore, in the summation in (20), for each term
1) there will be a term in P (K
in P (K
2) with a
1)  P (K
(cid:117)(cid:116)
larger or equal value so P (K
2).

Thus, if K is a finite set of finite explanations
for a query Q but we dont know if K contains
all possible explanations for Q, i.e., we dont know
whether K is covering, then P (K) will be a lower
bound of P (Q). So we can compute progressively
more accurate estimates from below of P (Q) by
considering an increasing set of explanations. Only
when K contains all possible explanations, then
P (K) = P (Q).

The problem of computing the probability of a
query can thus be reduced to that of finding a
covering set of explanations K and then making
it pairwise incompatible, so that the probability
can be computed with the summation of (20). To
obtain a pairwise incompatible set of explanations,
the splitting algorithm can be applied.

4.2. Inference through Binary Decision Diagrams

As an alternative to the splitting algorithm,
given a covering set of explanations K for a query
Q, we can define the Disjunctive Normal Form
(DNF) Boolean formula fK as

fK(X) =

Xi

Xi

(23)

(Ei,1)

(Ei,0)

The variables X = {Xi|(Ei, k)  ,   K} are independent Boolean random variables whose probability of being true is pi for the variable Xi. The
probability that fK(X) assumes value 1 is equal to
the probability of Q. We can now apply knowledge
compilation to the propositional formula fK(X)
[15], i.e. translate it to a target language that allows answering queries in polynomial time. A target language that was found to give good performances is the one of Binary Decision Diagrams
(BDD). From a BDD we can compute the probability of the query with a dynamic programming
algorithm that is linear in the size of the BDD [50].
Riguzzi [54] showed that this approach is faster
than the splitting algorithm.

A BDD for a function of Boolean variables is a
rooted graph that has one level for each Boolean
variable. A node n in a BDD has two children:
one corresponding to the 1 value of the variable associated with the level of n, indicated with
child1(n), and one corresponding to the 0 value
of the variable, indicated with child0(n). When
drawing BDDs, the 0-branch - the one going to
child0(n) - is distinguished from the 1-branch by
drawing it with a dashed line. The leaves store either 0 or 1.

BDDs can be built by combining simpler BDDs
using Boolean operators. While building BDDs,

n1

X1

X2

X3

n3

n2

Fig. 2. BDD for function (24).

simplification operations can be applied that
delete or merge nodes. Merging is performed when
the diagram contains two identical sub-diagrams,
while deletion is performed when both arcs from
a node point to the same node. In this way a reduced BDD is obtained, often with a much smaller
number of nodes with respect to the original BDD.
The size of the reduced BDD depends on the order of the variables: finding an optimal order is
an NP-complete problem [10] and several heuristic techniques are used in practice by highly efficient software packages such as CUDD1. Alternative methods involve learning variable order from
examples [20].

For instance, a BDD for the function

f (X) = (X1  X3)  (X2  X3)

(24)

K (X) (f X

K (X)  X  f X

is shown in Figure 2. A BDD performs a Shannon expansion of the Boolean formula fK(X), so
that, if X is the variable associated with the root
level of a BDD, the formula fK(X) can be represented as fK(X) = X  f X
K (X)
where f X
K (X)) is the formula obtained
by fK(X) by setting X to 1 (0). Now the two
disjuncts are pairwise exclusive and the probability of fK(X) can be computed as P (fK(X)) =
P (X)P (f X
K (X)). In other
words, BDDs make the explanations pairwise in-
compatible. Figure 3 shows function Prob that
implements the dynamic programming algorithm
for computing the probability of a formula encoded as a BDD.

K (X)) + (1  P (X))P (f X

1Available at http://vlsi.colorado.edu/~fabio/CUDD/

1: function Prob(node)
2:
3:

Input: a BDD node
Output: the probability of the Boolean function associ-

ated with the node

if node is a terminal then

return value(node)

else

4:
5:
6:
7:
8:
9:
10:
11:
12: end function

end if

let X be v(node)
P1 Prob(child1(node))
P0 Prob(child0(node))
return P (X)  P1 + (1  P (X))  P0

Fig. 3. Function that computes the probability of a formula
encoded as a BDD, where value(node) is 0 or 1 and v(node)
is the variable associated with node.

The function should also store the value of already
visited nodes in a table so that, if a node is visited again, its probability can be retrieved from
the table. For the sake of simplicity Figure 3 does
not show this optimization but it is fundamental
to achieve linear cost in the number of nodes, as
without it the cost of the function Prob would
be proportional to 2n where n is the number of
Boolean variables.

Let us discuss inference on some examples.

Example 5. Let us consider the KB of Example 2. A covering set of explanations for the
query axiom Q = kevin : N atureLover is
K = {1, 2} where 1 = {((13), 1), ((15), 1)} and
2 = {((14), 1), ((15), 1)}. If we associate the random variables X1 to (13), X2 to (14) and X3 to
(15), fK(X) is shown in (24) and the BDD associated with the set K of explanations is shown in
Figure 2. By applying the algorithm in Figure 3
we get

Prob(n3) = 0.6  1 + 0.4  0 = 0.6
Prob(n2) = 0.4  0.6 + 0.6  0 = 0.24
Prob(n1) = 0.3  0.6 + 0.7  0.24 = 0.348

so P (Q) = Prob(n1) = 0.348 which corresponds
to the probability given by the semantics.

F. Riguzzi et al. / Probabilistic Description Logics under the Distribution Semantics

X1

X4

X2

X3

n1

n2

n3

n4

Fig. 4. BDD for Example 6.

Example 6. Let us consider a slightly different
knowledge base:

hasAnimal.P et (cid:118) N atureLover
(kevin, fluffy) : hasAnimal

(kevin, tom) : hasAnimal

0.4 :: fluffy : Dog

0.3 :: tom : Cat
0.6 :: Cat (cid:118) P et
0.5 :: Dog (cid:118) P et

(25)

(26)

(27)

(28)

A covering set of explanations for the query
axiom Q = kevin : N atureLover is K =
{1, 2} where 1 = {((25), 1), ((28), 1)} and 2 =
{((26), 1), ((27), 1)}. If we associate the random
variables X1 to (25), X2 to (26), X3 to (27) and
X4 to (28), the BDD associated with the set K of
explanations is shown in Figure 4.
By applying the algorithm in Figure 3 we get

Prob(n4) = 0.6  1 + 0.4  0 = 0.6
Prob(n3) = 0.3  0.6 + 0.7  0 = 0.18
Prob(n2) = 0.5  1 + 0.5  0.18 = 0.59
Prob(n1) = 0.4  0.59 + 0.6  0.18 = 0.344

so P (Q) = Prob(n1) = 0.344.

base that follows the DISPONTE semantics. It
first finds a covering set of explanations for the
query and then makes them pairwise incompatible by using BDDs. Finally, it computes the probability from the BDD by using function Prob in
Figure 3.

The problem of finding explanations for a query
has been investigated by various authors [27,29,21,
30]. Schlobach and Cornet [67] called it axiom pinpointing and considered it a non-standard reasoning service useful for tracing derivations and debugging ontologies. In particular, they define minimal axiom sets or MinAs for short.
Definition 1 (MinAs). Let K be a KB and Q an
axiom that follows from it, i.e., K |= Q. We call
a set M  K a minimal axiom set or MinA for
Q in K if M |= Q and M is minimal w.r.t. set
inclusion. The set of all possible MinAs is called
All-MinAs(Q,K). The problem of enumerating
all MinAs is called min-a-enum.

All-MinAs(Q,K) can be used to derive a covering set of explanations. min-a-enum can be
solved either with reasoner dependent (glass-box)
approaches or reasoner independent (black-box)
approaches [30]. Glass-box approaches are built
on existing tableau-based decision procedures and
modify the internals of the reasoner. Black-box approaches use the DL reasoner solely as a subroutine and the internals of the reasoner do not need
to be modified.

The techniques of [28,29,21,30] for axiom pinpointing have been integrated into the Pellet reasoner [69]. By default, Pellet solves min-a-enum
with a hybrid glass/black-box approach: it finds
a single MinA using a modified tableau algorithm
and then finds all the other MinAs using a black
box method (the hitting set tree algorithm). The
method involves removing an axiom of the MinA
from the KB and looking for alternative explana-
tions. By repeating this process until the query is
not entailed, the set of all explanations is found.

BUNDLE is based on Pellet and uses it for solving the min-a-enum problem. In the following, we
first illustrate Pellets algorithm for solving min-
a-enum and then we show the whole BUNDLE
algorithm.

5. BUNDLE

5.1. Axiom Pinpointing in Pellet

The BUNDLE algorithm computes the probability of queries from a probabilistic knowledge

Pellet exploits a tableau algorithm [68] that decides whether an axiom is entailed or not by a

KB K by refutation: axiom E is entailed if E
has no model in the KB. The algorithm works on
completion graphs also called tableaux : they are
ABoxes that can also be seen as graphs, where
each node represents an individual a and is labeled
with the set of concepts L(a) it belongs to. Each
edge (cid:104)a, b(cid:105) in the graph is labeled with the set of
roles L((cid:104)a, b(cid:105)) to which the couple (a, b) belongs to.
The algorithm starts from a tableau that contains
the ABox of the KB and the negation of the axiom
to be proved. For example, if the query is a membership one, a : C, it adds C to the label of a. If
we query for the emptyness (unsatisfiability) of a
concept C, the algorithm adds a new anonymous
node a to the tableau and adds C to the label of a.
The axiom C (cid:118) D can be proved by showing that
C (cid:117)D is unsatisfiable. The algorithm repeatedly
applies a set of consistency preserving tableau expansion rules until a clash (i.e., a contradiction)
is detected or a clash-free graph is found to which
no more rules are applicable.

In the following we describe the tableau algorithm used by Pellet for concept unsatisfiability,
which checks if it is possible or not for a class to
have any instances. Instance and subclass checking can be performed similarly. The algorithm is
shown in Figure 5.

The rules used by Pellet to answer queries to
SHOIN (D) knowledge bases are shown in Figure 8. Some of the rules are non-deterministic,
i.e., they generate a finite set of tableaux. Thus
the algorithm keeps a set of tableaux T . If a nondeterministic rule is applied to a graph G in T ,
then G is replaced by the resulting set of graphs.
For example, if the disjunction C (cid:116) D is present
in the label of a node, the rule  (cid:116) generates two
graphs, one in which C is added to the node label
and the other in which D is added to the node
label.

An event during the execution of the algorithm
can be [27]: 1) Add(C, a), the addition of a concept
C to L(a); 2) Add(R,(cid:104)a, b(cid:105)), the addition of a role
R to L((cid:104)a, b(cid:105)); 3) M erge(a, b), the merging of the
nodes a, b; 4) =(a, b), the addition of the inequality
a=b to the relation =; 5) Report(g), the detection
of a clash g. We use E to denote the set of events
recorded during the execution of the algorithm. A
clash is either:

 a couple (C, a) where C and C are present
in the label of node a, i.e. {C,C}  L(a);

 a couple (M erge(a, b),=(a, b)), where the
events M erge(a, b) and =(a, b) belong to E.
Each time a clash is detected in a completion
graph G, the algorithm stops applying rules to G.
Once every completion graph in T contains a clash
or no more expansion rules can be applied to it, the
algorithm terminates. If all the completion graphs
in the final set T contain a clash, the algorithm
returns unsatisfiable as no model can be found.
Otherwise, any one clash-free completion graph in
T represents a possible model for C(a) and the
algorithm returns satisfiable.

Each expansion rule updates as well a tracing
function  , which associates sets of axioms with
events in the derivation. For example,  (Add(C, a)),
( (Add(R,(cid:104)a, b(cid:105)))) is the set of axioms needed to
explain the event Add(C, a) (Add(R,(cid:104)a, b(cid:105))). For
the sake of brevity, we define  for couples (con-
cept,
individual) and (role, couple of individu-
als) as  (C, a) =  (Add(C, a)) and  (R,(cid:104)a, b(cid:105)) =
 (Add(R,(cid:104)a, b(cid:105))) respectively. The function  is
initialized as the empty set for all the elements
of its domain except for  (C, a) and  (R,(cid:104)a, b(cid:105))
to which the values {a : C} and {(a, b) : R} are
assigned if a : C and (a, b) : R are in the ABox
respectively. The expansion rules (Figure 8) add
axioms to values of  .

Tableau is S =

If g1, ..., gn are the clashes, one for each tableau
G of the final set, the output of the algorithm
i{1,...,n}  (gi) \ {C(a)} where
a is the anonymous individual initially assigned
to C. However, this set may be redundant because additional axioms may also be included in
 , e.g., during the  rule, where axioms responsible for each of the successor edges are considered
[27]. Thus S is pruned using a black-box approach
shown in Figure 6 [27]. This algorithm executes a
loop on S in which it removes one axiom from S in
each iteration and checks whether the concept C
turns satisfiable w.r.t. S, in which case the axiom
is reinserted into S. The idea is that, if the concept
turns satisfiable, we can conclude that the axiom
extracted is responsible for the unsatisfiability and
hence has to be inserted back into S. Vice-versa,
if the concept still remains unsatisfiable, we can
conclude that the axiom is irrelevant and can be
removed from S. The process continues until all
axioms in S have been tested and then returns S.
The algorithm for computing a single MinA,
shown in Figure 7, first executes Tableau and
then BlackBoxPruning.

F. Riguzzi et al. / Probabilistic Description Logics under the Distribution Semantics

Input: C (the concept to be tested for unsatisfiability)
Input: K (the knowledge base)
Output: S (a set of axioms) or null
Let G0 be an initial completion graph from K containing an anonymous individual a and C  L(a)
T  {G0}
repeat

1: function Tableau(C, K)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24: end function

return null

end if

else

Select a rule r applicable to a clash-free graph G from T
T  T \ {G}
Let G = {G
T  T  G

n} be the result of applying r to G

1, ..., G

until all graphs in T have a clash or no rule is applicable
if all graphs in T have a clash then

for all G  T do
let sG the result of  for the clash of G
S  S  sG
end for
S  S \ {C(a)}
return S

Fig. 5. Tableau algorithm executed by Pellet.

Input: C (the concept to be tested for unsatisfiability)
Input: S (the set of axioms to be pruned)
Output: S (the pruned set of axioms)
for all axiom E  S do

1: function BlackBoxPruning(C, S)
2:
3:
4:
5:
6:
7:
8:
9:
10:
end for
11:
return S
12: end function

S  S  {E}
if C is satisfiable w.r.t. S then

S  S  {E}

end if

Fig. 6. Black-Box pruning algorithm.

1: function SingleMinA(C, K)
2:
3:
4:

K) or null

Input: C (the concept to be tested for unsatisfiability)
Input: K (the knowledge base)
Output: S (a MinA for the unsatisfiability of C w.r.t.
S Tableau(C, K)
if S = null then

return null

5:
6:
7:
8:
9:
10:
11: end function

end if

else

return BlackBoxPruning(C, S)

Fig. 7. SingleMinA algorithm.

The output S of SingleMinA is guaranteed to
be a MinA, as established by the following theo-
rem, where All-MinAs(C,K) stands for the set
of MinAs in which C is unsatisfiable.

Theorem 4. [27] Let C be an unsatisfiable concept w.r.t. K and let S be the output of the algorithm SingleMinA with input C and K, then
S  All-MinAs(C,K).

SingleMinA returns a single MinA, i.e. a single explanation. To solve min-a-enum and find

the remaining ones, Pellet exploits the hitting set
algorithm [52].
Reiter considers a universal set U and a set
CS  PU of conflict sets, where P denotes the
powerset operator. The set H  U is a hitting set
for CS if each ci  CS contains at least one element of H, i.e. if ci  H =  for all 1  i  n
(in other words, H hits or intersects each set in
CS). H is a minimal hitting set for CS if H is a
hitting set for CS and no H  H is a hitting set
for CS. The hitting set problem with input CS, U
is to compute all the minimal hitting sets for CS.
The idea here is that the explanations for unsatisfiability correspond to minimal conflict sets and
an algorithm that generates minimal hitting sets
can also be used to find all minimal conflict sets
[27,30]. The universal set corresponds to the total
set of axioms in the KB, and an explanation (for a
particular concept unsatisfiability) corresponds to
a single conflict set.

The algorithm constructs a labeled tree called
Hitting Set Tree (HST) starting from a single ex-
planation, the MinA S; then it removes each of
the axioms in S individually, thereby creating new
branches of the HST, and finds new explanations
along these branches. The first step consists of initializing an HST T = (V, E,L) with S in the label
of its root node, i.e. V = {v0}, E = ,L(v0) = S.
Then it selects an arbitrary axiom E in S, generates a new node w with an empty label in the
tree and a new edge (cid:104)v0, w(cid:105) with axiom E in
its label. Then, the algorithm invokes SingleM-

 CE: if (C (cid:118) D)  K, with C not atomic, a not blocked, then

 unfold: if A  L(a), A atomic and (A (cid:118) D)  K, then

if D / L(a), then
Add(D, L(a))
 (D, a) := ( (A, a)  {A (cid:118) D})

if (C (cid:116) D) / L(a), then

Add((C (cid:116) D), a)
 ((C (cid:116) D), a) := {C (cid:118) D}

if {C1, C2}  L(a), then

Add({C1, C2}, a)
 (Ci, a) :=  ((C1 (cid:117) C2), a)

 (cid:117): if (C1 (cid:117) C2)  L(a), a is not indirectly blocked, then

 (cid:116): if (C1 (cid:116) C2)  L(a), a is not indirectly blocked, then

if {C1, C2}  L(a) = , then

Generate graphs Gi := G for each i  {1, 2}
Add(Ci, a) in Gi for each i  {1, 2}
 (Ci, a) :=  ((C1 (cid:116) C2), a)
 : if S.C  L(a), a is not blocked, then

if a has no S-neighbor b with C  L(b), then

create new node b, Add(S, (cid:104)a, b(cid:105)), Add(C, b)
 (C, b) :=  ((S.C), a)
 (S, (cid:104)a, b(cid:105)) :=  ((S.C), a)

 : if (S.C)  L(a), a is not indirectly blocked and there is an S-neighbor b of a, then

if C / L(b), then

 +: if (S.C)  L(a), a is not indirectly blocked

Add(C, b)
 (C, b) :=  ((S.C), a)   (S, (cid:104)a, b(cid:105))
and there is an R-neighbor b of a, T rans(R) and R (cid:118) S, then
Add(R.C, b)
 ((R.C), b) :=  ((S.C), a)   (R, (cid:104)a, b(cid:105))  {T rans(R)}  {R (cid:118) S}

if R.C / L(b), then

: if ( nS)  L(a), a is not blocked, then

if there are no n safe S-neighbors b1, ..., bn of a with bi = bj , then

create n new nodes b1, ..., bn; Add(S, (cid:104)a, bi(cid:105)); =(bi, bj )
 (S, (cid:104)a, bi(cid:105)) :=  (( nS), a)
 (=(bi, bj )) :=  (( nS), a)

: if ( nS)  L(a), a is not indirectly blocked,

and there are m S-neighbors b1, ..., bm of a with m > n, then
For each possible pair bi, bj , 1  i, j  m; i = j then

Generate a graph G
 (M erge(bi, bj )) :=  (( nS), a)   (S, (cid:104)a, b1(cid:105))...   (S, (cid:104)a, bm(cid:105))
if bj is a nominal node, then M erge(bi, bj ) in G,
else if bi is a nominal node or ancestor of bj , then M erge(bj , bi)
else M erge(bi, bj ) in G
if bi is merged into bj , then for each concept Ci in L(bi),

 (Ci, bj ) :=  (Ci, bi)   (M erge(bi, bj ))
(similarly for roles merged, and correspondingly for concepts in bj if merged into bi)

 O: if, {o}  L(a)  L(b) and not a=b, then M erge(a, b)

 (M erge(a, b)) :=  ({o}, a)   ({o}, b)
For each concept Ci in L(a),  (Add(Ci, L(b))) :=  (Add(Ci, L(a)))   (M erge(a, b))
(similarly for roles merged, and correspondingly for concepts in L(b))
 N N : if ( nS)  L(a), a nominal node, b blockable S-predecessor of a

and there is no m s.t. 1  m  n, ( mS)  L(a)
and there exist m nominal S-neighbors c1, ..., cm of a s.t. ci=cj , 1  j  m, then

generate new Gm for each m, 1  m  n
and do the following in each Gm:

Add( mS, a),  (( mS), a) :=  (( nS), a)  ( (S, (cid:104)b, a(cid:105))
create b1, ..., bm; add bi=bj for 1  i  j  m.
 (=(bi, bj ) :=  (( nS), a)   (S, (cid:104)b, a(cid:105))
Add(S, (cid:104)a, bi(cid:105)); Add({oi}, bi);
 (S, (cid:104)a, bi(cid:105)) :=  (( nS), a)   (S, (cid:104)b, a(cid:105));  ({oi}, bi) :=  (( nS), a)   (S, (cid:104)b, a(cid:105))

Fig. 8. Pellet tableau expansion rules for SHOIN (D) from [27].

F. Riguzzi et al. / Probabilistic Description Logics under the Distribution Semantics

inA with arguments C and the knowledge base
K = K  {E}, to test the unsatisfiability of C
w.r.t. K. If C is still unsatisfiable it obtains a new
explanation for C and it labels w with this set.
The algorithm repeats this process (removing an
axiom from S and executing SingleMinA to add
a new node) until the unsatisfiability test returns
negative (the concept turns satisfiable): in that
case the algorithm labels the new node with OK
and makes it a leaf. The algorithm also eliminates
extraneous unsatisfiability tests based on previous
results: once a path leading to a node labeled OK
is found, any superset of that path is guaranteed
to be a hitting set as well, and thus no additional
unsatisfiability test is needed for that path, as indicated by a X in the node label. When the HST
is fully built, all leaves of the tree are labeled with
OK or X. The distinct non leaf nodes of the tree
collectively represent the set All-MinAs(C,K) of
the unsatisfiable concept. The algorithm is shown
in Figure 9. The correctness and completeness of
the hitting set algorithm are given by the following
theorem.

Theorem 5. [27] Let C be a concept unsatisfiable
in K and let ExpHST(C,K) be the set of explanations returned by Pellets hitting set algorithm.
Then

ExpHST(C,K) = All-MinAs(C,K).

Pellets ExpHST(C,K) can also take as input a
maximum number of explanations to be generated.
If the limit is reached during the execution of the
hitting set algorithm, Pellet stops and returns the
set of explanations found so far.

5.2. Overall BUNDLE

The main algorithm, shown in Figure 10, first
builds a data structure P M ap that associates each
probabilistic DL axiom Ei with its probability pi.
Then it uses Pellets ExpHST(C,K) function to
compute the MinAs for the unsatisfiability of a
concept C. These MinAs correspond to all conflict
sets found by the Hitting Set Algorithm. BUNDLE
exploits the version of this procedure in which we
can specify the maximum number of explanations
to be found.

Two data structures are initialized: V arAx is
an array that maintains the association between

1: procedure HittingSetTree(C, K, CS, H, w, E, p)
2:
3:
4:

Input: C (the concept to be tested for unsatisfiability)
Input: K (the knowledge base)
Input/Output: CS (a set of Conflict Sets, initially con-

taining a single explanation)

Input/Output: H (a set of Hitting Sets)
Input: w (the last node added to the Hitting Set Tree)
Input: E (the last axiom removed from K)
Input: p (the current edge path)
if there exists a set h  H s.t. (L(p)  {E})  h then

L(w)  X
return
if C is unsatisfiable w.r.t. K then

else

5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30: end procedure

end if

end if

m SingleMinA(C, K)
CS  CS  {m}
create a new node w and set L(w)  m
if w = null then

create an edge e = (cid:104)w, w(cid:105) with L(e) = E
p  p  e

end if
loop for each axiom F  L(w)

K = K  {F}
HittingSetTree(C, K, CS, H, w, F, p)

else

end loop
L(w)  OK
H  H  L(p)

Fig. 9. Hitting Set Tree Algorithm.

Boolean random variables (whose index is the array index) and couples (axiom, probability), and
BDD stores a BDD. BDD is initialized to the zero
Boolean function (lines 8-9).

Then BUNDLE performs two nested loops that
build a BDD representing the set of explanations.
To manipulate BDDs we used JavaBDD2 that is
an interface to a number of underlying BDD manipulation packages. As the underlying package we
used CUDD.

In the inner loop, BUNDLE generates the BDD
for a single explanation,
indicated as BDDE,
which is initialized to the one Boolean function
(lines 11-25). The axioms of each MinA are considered one by one. If the axiom is certain, then
the one Boolean function is stored in BDDA (line
14). Otherwise, the value p associated with the axiom Ax is extracted from P M ap. The axiom is
searched for in V arAx to see if it has already been
assigned a random variable. If not, a cell is added
to V arAx to store the couple (line 19). At this
point we know the couple position i in the array
V arAx, that is the index of its Boolean random
variable Xi. We obtain a BDD representing Xi = 1
with BDDGetIthVar in BDDA. BDDA is fi-

2Available at http://javabdd.sourceforge.net/

Input: K (the knowledge base)
Input: C (the concept to be tested for unsatisfiability)
Input: maxEx (the maximum number of explanations to find)
Output: the probability of the unsatisfiability of C w.r.t. K
Build Map P M ap with sets of couples (axiom, probability)
M inAs ExpHST(C, K, maxEx)
Initialize V arAx to empty
BDD BDDZero
for all M inA  M inAs do
BDDE BDDOne
for all Ax  M inA do

if K contains a certain axiom Ax then

BDDA BDDOne
p  P M ap(Ax)
Scan V arAx looking for Ax
if !found then

1: function Bundle(K, C, maxEx)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29: end function

end for
return Prob(BDD)

else

Add to V arAx a new cell containing (Ax, p)

end if
Let i be the position of (Ax, p) in V arAx
BDDA  BDDGetIthVar(i)

end if
BDDE BDDAnd(BDDE,BDDA)

end for
BDD BDDOr(BDD,BDDE)

 Pellet is called to compute the MinAs for the concept C
 V arAx is an array of couples (Axiom, P rob)

 V arAx is used to compute P (X) in Prob

Fig. 10. Function Bundle: computation of the probability of an axiom C given the KB K.

nally conjoined with the current BDDE to get the
BDD representing a single explanation (line 24).

In the outermost loop, BUNDLE combines
BDDs for different explanations through disjunction between BDD and the current explanation
BDDE (line 26).

After the two cycles, function Prob of Figure
3 is called over BDD to return the probability of
the query to the user.

We now prove BUNDLE correctness.

Theorem 6 (BUNDLE correctness). Given a
DISPONTE knowledge base K, a query Q and
a limit maxEx for the number of explanations
to find,
the probability returned by BUNDLE,
Bundle(K, Q, maxEx) is:

 a lower bound on P (Q) if a maximum number of explanations to compute is set, i.e.,
Bundle(K, Q, maxEx)  P (Q)
 equal to P (Q), i.e., Bundle(K, Q,)= P (Q)

otherwise

Proof. Let K be ExpHST(C,K, maxEx). By
Theorem 5

K  All-MinAs(C,K)

if a maximum number of explanations is set and

K = All-MinAs(C,K)

otherwise. Since BUNDLE computes P (fK(X))
for the Boolean function

(F,1)

fK(X) =

the theorem holds.

(cid:117)(cid:116)

Example 7. Let us consider the KB presented
in Example 5 and the query C = kevin :
N atureLover. Let us also consider the corresponding P M ap = {(fluffy : Cat, 0.4), (tom :
Cat, 0.3), (Cat (cid:118) P et, 0.6)}, V arAx =  and
the covering set of explanations K = {1, 2}
where 1 = {(fluffy : Cat, 1), (Cat (cid:118) P et, 1)} and
2 = {(tom : Cat, 1), (Cat (cid:118) P et, 1)}. Here we
restrict explanations to contain only probabilistic
axioms for the sake of simplicity.

At the start, BUNDLE initializes BDD to the
zero Boolean function and starts to loop over the
explanations. It enters the inner loop considering the explanation 1 and initializing BDDE to
the one Boolean function. At this time V arAx is
empty, thus random variable X1 is associated to
(fluffy : Cat, 0.4) by adding this pair to V arAx in
position 1. Function BDDGetIthVar returns a
BDD in BDDA that corresponds to the expression
X1 = 1. Then BDDA is combined with BDDE
using the and operator. Now, the computation con-

F. Riguzzi et al. / Probabilistic Description Logics under the Distribution Semantics

tinues by analyzing the second axiom of 1. The
axiom Cat (cid:118) P et does not have a random variable associated with it yet, so the new variable X2
is created and the pair (Cat (cid:118) P et, 0.6) is added
to V arAx in position 2. BDDA is then generated and combined with the BDDE corresponding
to the current explanation using the and operator.
Now all the axioms in 1 have been considered, so
the final BDDE is combined with BDD with the
or operator.

Then, BUNDLE starts to consider 2. BDDE
is set to one. The axiom T om : Cat does not
appear in V arAx so variable X3 is associated to
(T om : Cat, 0.3) and BDDA, representing X3 =
1, is joined with BDDE. The axiom Cat (cid:118) P et
is found in V arAx in position 2, so the function
BDDGetIthVar returns the BDD representing
X2 = 1. Finally BDDA is combined with the current BDDE. BDDE corresponding to the second
explanation is completed so it is combined with
BDD obtaining the one shown in Figure 2. Now
BUNDLE calls function Prob which computes the
probability and returns P (C) = 0.348.

6. Computational Complexity

Jung and Lutz [26] considered the problem of
computing the probability of conjunctive queries
to probabilistic databases in the presence of an on-
tology. Probabilities can occur only in the ABox
while the TBox is certain. In the case where each
ABox assertion is associated with a Boolean random variable independent of all the others, they
prove that only very simple conjunctive queries
can be answered in PTime, while most queries are
#P-hard when the ontology is a DL-Lite TBox
and even when the ontology is an ELI TBox.

The class #P [72] describes counting problems
associated with decision problems in NP. More for-
mally, #P is the class of function problems of the
form compute f (x), where f is the number of
accepting paths of a nondeterministic Turing machine running in polynomial time. A prototypical
#P problem is the one of computing the number
of satisfying assignments of a CNF Boolean for-
mula. #P problems were shown very hard. First, a
#P problem must be at least as hard as the corresponding NP problem. Second, [70] showed that a
polynomial-time machine with a #P oracle (P#P)

can solve all problems in PH, the entire polynomial hierarchy.

The setting considered by [26] is subsumed by
DISPONTE as it is equivalent to having probabilistic axioms only in the ABox of a DISPONTE
KB. So the complexity result provides a lower
bound for DISPONTE.

In order to investigate the complexity of BUN-
DLE, we can consider the two problems that it
solves for answering a query. The first one is axiom pinpointing. Its computational complexity has
been studied in a number of works [44,45,46].
Baader et al. [4] showed that there can be exponentially many MinAs for a very simple DL that
allows only concept intersection.
Example 8. Given an integer n  1, consider the
TBox
Tn = {Bi1 (cid:118) Pi(cid:117)Qi, Pi (cid:118) Bi, Qi (cid:118) Bi|1  i  n}
The size of Tn is linear in n and Tn |= B0 (cid:118) Bn.
There are 2n MinAs for B0 (cid:118) Bn since, for each
i, 1  i  n, it is enough to have Pi (cid:118) Bi or
Qi (cid:118) Bi in the set.
Thus the number of explanations for SHOIN (D)
may be even larger. Given this fact, we do not consider complexity with respect to the input only. We
say an algorithm runs in output polynomial time
[25] if it computes all the output in time polynomial in the overall size of the input and the output.
Corollary 15 in [46] shows that min-a-enum cannot be solved in output polynomial time for DLLitebool TBoxes unless P = N P . Since DL-Litebool
is a sublogic of SHOIN (D), this result also holds
for SHOIN (D).

The second problem to be solved is computing
the probability of a query, that can be seen as computing the probability of a sum-of-products, as
explained below.

Definition 2 (sum-of-products). Given a Boolean
expression S in disjunctive normal form (DNF),
or a sum-of-products, in the variables {V1, . . . , Vn}
and P (Vi), the probability that Vi
is true with
i = 1, . . . , n, compute the probability P (S) of S,
assuming all variables are independent.

sum-of-products was shown to be #P-hard
[see e.g. 51]. Given that the input of the sum-
of-products problem is of at least exponential
size in the worst case, this means that computing

the probability of an axiom from a SHOIN (D)
knowledge base is intractable.

However, the algorithms that have been proposed for solving the two problems were shown to
be able to work on inputs of real world size. For ex-
ample, all MinAs have been found for various entailments over many real world ontologies within
a few seconds [27,30]. As regards the sum-of-
products problem, algorithms based on BDDs
were able to solve problems with hundreds of thousands of variables (see e.g. the works on inference on probabilistic logic programs [50,53,54,57,
31,59,58,55,56]). Also methods for weighted model
counting [64,12] can be used to solve the sum-of-
products problem.

Moreover, Section 8 shows that in practice we
can compute the probability of entailments on KBs
of real-world size with BUNDLE, too.

7. Related Work

Bacchus [6] and Halpern [22] discuss first-order
logics of probability and distinguish statistical
statements from statements about degrees of be-
lief. Halpern [22] presents two examples: the probability that a randomly chosen bird flies is 0.9
and the probability that Tweety (a particular
bird) flies is 0.9. The first statement captures
statistical information about the world while the
second captures a degree of belief. In order to
express the second type of statement, called a
Type 2 statement, Halpern proposes the notation w(F lies(tweety)) = 0.9, where the function w
is used to indicate the probability, while in order to
express the first, called a Type 1 statement, he
proposes the notation wx(F lies(x)  Bird(x)) =
0.9wx(Bird(x)). The latter formula can be read
as: given a randomly chosen x in the domain, if
x is a bird, the probability that x flies is 0.9, or
the conditional probability that x flies given that
it is a bird is 0.9. DISPONTE allows to define only
Type 2 statements since the probability associated with an axiom represents the degree of belief
in that axiom as a whole.
Lutz and Schr oder [41] proposed Prob-ALC that
is derived directly from Halperns probabilistic
first order logic and, as DISPONTE, considers
only Type 2 statements. They do so by adopting a possible world semantics and allowing concept expressions of the form PnC and PnR.C

in the language, the first expressing the set of individuals that belong to C with probability greater
than n and the second the set of individuals a
connected to at least another individual b of C
by role R such that the probability of R(a, b) is
greater than n. Moreover, the ABox may contain
expressions of the form PnC(a) and PnR(a, b)
directly expressing degrees of belief, together with
PnA where A is an ABox. Prob-ALC is 2-
EXPTIME-hard even when probability values are
restricted to 0 and 1. Prob-ALC is complementary to DISPONTE ALC as it allows new concept
and assertion expressions while DISPONTE allows
probabilistic axioms.

Jung and Lutz [26] presented an approach for
querying probabilistic databases in the presence
of an OWL2 QL ontology. Each assertion is assumed to be stored in a database and associated
with probabilistic events. All atomic events are assumed to be probabilistically independent, resulting in a semantics very similar to the distribution
semantics. The authors are interested in computing the answer probabilities to conjunctive queries.
Probabilities can occur only in the data, but neither in the ontology nor in the query. Two types of
ABoxes are considered: a general one where events
are Boolean combinations of atomic events, and a
restricted one, where each assertion is associated
with a distinct atomic event. For Boolean conjunctive queries, the latter setting is subsumed by
DISPONTE. Only very simple conjunctive queries
in the latter setting can be answered in PTime,
while most queries are #P-hard. The authors underline the general interest and usefulness of the
approach for a wide range of applications including the management of data extracted from the
web, machine translation, and dealing with data
that arise from sensor networks.
Heinsohn [23] proposed an extension of the description logic ALC that is able to express statistical information on the terminological knowledge such as partial concept overlapping. Sim-
ilarly, Koller et al. [35] presented a probabilistic description logic based on Bayesian networks
that deals with statistical terminological knowl-
edge. Both Heinsohn and Koller et al. do not allow probabilistic assertional knowledge about concept and role instances. Jaeger [24] allows assertional knowledge about concept and role instances
together with statistical terminological knowledge
and combines the resulting probability distribu-

F. Riguzzi et al. / Probabilistic Description Logics under the Distribution Semantics

tions using cross-entropy minimization but does
not allow Type 2 statements as DISPONTE.

C as P (C) =

Ding and Peng [17] proposed a probabilistic extension of OWL that admits a translation into
Bayesian networks. The semantics defines a prob-
i.e.
ability distribution P (a) over individuals,
a P (a) = 1, and assigns a probability to a class
aC P (a), while we assign a probability distribution to worlds. PR-OWL [13,11] is
a probabilistic extension to OWL that consists of
a set of classes, subclasses and properties that collectively form a framework for building probabilistic ontologies. It allows to use the first-order probabilistic logic MEBN [36] for representing uncertainty in ontologies.

DISPONTE differs from [23,24,35] because it
provides a unified framework for representing different types of probabilistic knowledge: from assertional to terminological degree of belief knowl-
edge.

DISPONTE differs from [17] because it specifies
a distribution over worlds rather than individuals
and from [13,11] because it does not resort to a full
fledged first-order probabilistic language, allowing
the reuse of inference technology from DLs.
Luna et al. [40] proposed an extension of ALC,
called crALC, that adopts an interpretationbased semantics. crALC allows statistical axioms
of the form P (C|D) = , which means that for
any element x in the domain D, the probability
that x is in C given that it is in D is , and of the
form P (R) = , which means that for each couple
of elements x and y in D, the probability that x
is linked to y by the role R is . The semantics
of crALC is based on probability measures over
the space of interpretations with a fixed domain.
crALC allows to express Type 1 knowledge but
not Type 2. A crALC KB K can be represented
as a directed acyclic graph G(K) in which a node
represents a concept or a role and the edges represent the relations between them: if a concept
C directly uses concept D, then D is a parent of
C in G(K). Moreover, each restriction R.C and
R.C is added as a node to G(K). G(K) contains
an edge from R to each restriction directly using
it and from each restriction to the concept C appearing in it. G(K) is a template for generating,
given the domain D, a ground graph in which each
node represents an instantiated logical atom C(a)
or R(a.b). Inference can then be performed by a

first order loopy belief propagation algorithm on
the ground graph.

A different approach to the combination of DLs
with probability is taken in [18,38,39]. The logic
proposed in these papers is called P-SHIQ(D)
and allows both terminological probabilistic knowledge as well as assertional probabilistic knowledge
about instances of concepts and roles. Terminological probabilistic knowledge is expressed using
conditional constraints of the form (D|C)[l, u] that
informally mean generally, if an object belongs
to C, then it belongs to D with a probability in
[l, u]. PRONTO [32,34] is a system that performs
inference under this semantics. Similarly to [24],
the terminological knowledge is interpreted statistically while the assertional knowledge is interpreted in an epistemic way by assigning degrees of
beliefs to assertions. Moreover it also allows to express default knowledge about concepts that can
be overridden in subconcepts and whose semantics
is given by Lehmanns lexicographic default entailment [37]. These works are based on Nilssons
probabilistic logic [42], where a probabilistic interpretation P r defines a probability distribution
over the set of interpretations Int. The probability
of a logical formula F according to P r, denoted
P r(F ), is the sum of all P r(I) such that I  Int
and I |= F . A probabilistic knowledge base K is a
set of probabilistic formulas of the form F  p. A
probabilistic interpretation P r satisfies F  p iff
P r(F )  p. P r satisfies K, or P r is a model of K,
iff P r satisfies all F  p  K. P r(F )  p is a tight
logical consequence of K iff p is the infimum of
P r(F ) in the set of all models P r of K. Computing tight logical consequences from probabilistic
knowledge bases can be done by solving a linear
optimization problem.

Nilssons probabilistic logic differs from the distribution semantics: while the first considers sets
of distributions, the latter computes a single distribution over possible worlds. Nilssons logic allows
different conclusions: consider a DISPONTE KB
composed of the axioms 0.4 :: a : C and 0.5 :: b : C
and a probabilistic theory composed of C(a)  0.4
and C(b)  0.5; DISPONTE allows to say that
P (a : C  b : C) = 0.7, while with Nilssons logic
the lowest p such that P r(C(a)C(b))  p holds is
0.5. This is due to the fact that, while in Nilssons
logic no assumption about the independence of
the statements is made, in the distribution semantics the probabilistic axioms are considered as in-

dependent. While independencies can be encoded
in Nilssons logic by carefully choosing the values
of the parameters, reading off the independencies
from the theories becomes more difficult.

The assumption of independence of probabilistic axioms does not restrict expressiveness as one
can specify any joint probability distribution over
the logical ground atoms, possibly introducing new
atoms if needed. This is testified by the fact that
Bayesian networks can be encoded in probabilistic logic programs under the distribution semantics [74] and by the applications of the distribution
semantics to a wide variety of domains [50,66,7].
For example, the Bayesian network in Figure 11
can be encoded with the following ProbLog pro-
gram

burglary:0.1.
earthquake:0.2.
alarm :- burglary,earthquake.
alarm :- burglary,\+ earthquake,al_tf.
alarm :- \+ burglary,earthquake,al_ft.
alarm :- \+ burglary,\+ earthquake,al_ff.
al_tf:0.8.
al_ft:0.8.
al_ff:0.1.

where an additional probabilistic fact has been
added for each row of the conditional probability
table for alarm (excluding the first that models a
deterministic dependency).

Other approaches, such as [14,19], combine
a lightweight ontology language, DL-Lite and
Datalog+/- respectively, with graphical models,
Bayesian networks and Markov networks respec-
tively. In both cases, a KB is composed of a set of
annotated axioms and a graphical model. The annotations are sets of assignments of random variables from the graphical model. The semantics
is assigned by considering the possible worlds of
the graphical model and by stating that an axiom
holds in a possible world if the assignments in its
annotation hold. The probability of a conclusion
is then the sum of the probabilities of the possible worlds where the conclusion holds. Our approach represents a special case of these in which
each probabilistic axiom is annotated with a single
random variable and the graphical model encodes
independence among the random variables. This
special case is of interest as inference technology
from DLs can be directly employed.

8. Experiments

In order to test the performance of BUNDLE

we performed several experiments.

8.1. Comparison with PRONTO

We compared BUNDLE with PRONTO by running queries w.r.t. increasingly complex ontologies.
The experiments have been performed on Linux
machines with a 3.10 GHz Intel Xeon E5-2687W
with 2GB memory allotted to Java.

In the first experiment we generated the test ontologies by randomly sampling axioms from a large
probabilistic ontology that models breast cancer
risk assessment (BRCA) as shown in [33]. The
main idea behind the design of the ontology was
to reduce risk assessment to probabilistic entailment in P-SHIQ(D). The BRCA ontology contains a certain part and a probabilistic part. The
tests were defined by randomly sampling axioms
from the probabilistic part of this ontology which
were then added to the certain part. So each sample is a probabilistic KB with the full certain part
of the BRCA ontology and a subset of the probabilistic constraints. We varied the number of these
constraints from 9 to 15, and, for each number, we
generated 100 different consistent ontologies.

In order to generate a query, an individual
a is added to the ontology: a is randomly assigned to each class that appears in the sampled conditional constraints with probability 0.6.
If the class is composite, as for example Post-
menopausalWomanTakingTestosterone, a is assigned to the component classes rather than to
the composite one. In the example above, a will
be added to PostmenopausalWoman and Wom-
anTakingTestosterone. The ontologies were translated into DISPONTE by replacing each constraint (D|C)[l, u] with the axiom u :: C (cid:118) D. For
each ontology, we performed the query a : C where
the class C is randomly selected among those
that represent women under increased and lifetime risk such as WomanUnderLifetimeBRCRisk
and WomanUnderStronglyIncreasedBRCRisk. We
then applied both BUNDLE and PRONTO to
each generated test and we measured the execution time for inference and the memory used. Figure 12(a) shows the execution time averaged over
the 100 KBs as a function of the number of probabilistic axioms and, similarly, Figure 12(b) shows

F. Riguzzi et al. / Probabilistic Description Logics under the Distribution Semantics

Burglary

Earthquake

Alarm

burg

earthq

alarm

b=t,e=t
b=t,e=f
b=f,e=t
b=f,e=f

Fig. 11. Bayesian network

the average amount of memory used. As one can
see, inference times are similar for small knowledge bases, while the difference between the two
reasoners rapidly increases for larger knowledge
bases. The memory usage for BUNDLE is always
less than 53% than PRONTO.

A second test was performed over larger KBs,
following the method of [34]. We considered three
different datasets: an extract from the Cell3 on-
tology, an extract from the NCI Thesaurus4 and
an extract from the Teleost anatomy5 ontology.
The Cell ontology represents cell types of the
prokaryotic,
fungal, and eukaryotic organisms.
The NCI ontology is an extract from the NCI
Thesaurus that describes human anatomy. The
Teleost anatomy (Teleost for short) ontology is a
multi-species anatomy ontology for teleost fishes.
For each of these KBs, we considered the versions of increasing size used by [34]: they add
250, 500, 750 and 1,000 new probabilistic conditional constraints to the publicly available nonprobabilistic version of each ontology. We converted these KBs into DISPONTE in the same way
as for the BRCA ontology and we created a set of
100 different random subclass queries for each KB.
For generating the queries we built the hierarchy
of each KB and we randomly selected two classes
connected in the hierarchy, so that each query had
at least one explanation. We imposed a time limit
of 5 minutes for BUNDLE to answer each query. If
this limit is reached, BUNDLEs answer is time-
out.

In Table 1 we report, for each version of the
datasets, the average execution time and the number of queries that terminated with a time-out
(TO) for BUNDLE. The averages are computed

3http://cellontology.org/
4http://ncit.nci.nih.gov/
5http://phenoscape.org/wiki/Teleost_Anatomy_

Ontology

on the queries that did not end with a time-out. In
addition, for each KB we report its expressiveness
and its number of non-probabilistic TBox axioms.
In all these cases, PRONTO terminates with an
out-of-memory error.

As can be seen, BUNDLE can manage larger
KBs than PRONTO due to the lower amount
of memory needed, as confirmed by the previous
tests on BRCA. Moreover, BUNDLE answers most
queries in a few seconds. However, some queries
have a very high complexity that causes BUNDLE to reach the time-out, confirming the complexity results. In these cases, since the time-out
is reached during the computation of the explana-
tions, limiting the number of explanations is nec-
essary, obtaining a lower bound on the probability that becomes tighter as more explanations are
allowed.

8.2. Tests with not entailed queries

In a further test we investigated cases for which
subsumption does not hold. Thus, for the same
versions of increasing size of the Cell, NCI and
Teleost KBs we randomly created 100 different
subclass queries that do not have explanations. In
Table 2 we report for each KB the runtime in sec-
onds. As for the previous test, we setted a time-out
of 5 minutes but this limit was never reached.

8.3. Inference with a limit on the number of

explanations

We studied how the execution time and the
probability of queries vary when imposing a limit
on the number of explanations. The experiments
have been performed on Linux machines with a
3.10 GHz Intel Xeon E5-2687W with 2GB memory
allotted to Java.

(a) Average execution time (s) for inference.

(b) Average memory consumption (Kb) for inference.

Fig. 12. Comparison between BUNDLE and PRONTO on the BRCA KB.

Table 1

Average execution time for the queries to the Cell, Teleost
and NCI KBs and number of queries terminated with a
time-out (TO). The first column reports the expressiveness
of each KB and the size of the non-probabilistic TBox.

Size of the Probabilistic TBox

Dataset & Infos

Cell
ALE+, 1,263 TBox axioms
Teleost
ALEI+, 3,406 TBox axioms

ALE+, 5,423 TBox axioms

runtime (s)

runtime (s)

runtime (s)

Average execution time for the queries without explanations to the Cell, Teleost and NCI KBs.

Table 2

Dataset

Cell

runtime (s)

Teleost

runtime (s)

runtime (s)

Size of the Probabilistic TBox

We chose the Grid6 KB that is part of the myGrid project. The Grid KB has already been used
for testing the performances of Pellet in [30]. It
belongs to the bioinformatics domain and contains concepts at a high level of abstraction. For
the test, we used a version of the Grid KB with
SHOIN expressiveness that contains 2,838 ax-

ioms, 550 atomic concepts, 69 properties and 13 in-
dividuals, downloaded from the Tones repository7.
We associated a probability of 0.5 to each axiom
of the KB and then we ran 100 different subclass
queries.

6http://www.myGrid.org.uk/

browser

7http://rpc295.cs.man.ac.uk:8080/repository/

F. Riguzzi et al. / Probabilistic Description Logics under the Distribution Semantics

Fig. 13. Mean relative error of the probability of queries as
a function of the limit on the number of explanations for
the Grid KB.

We first computed the correct probability of
each query by using BUNDLE without a limit on
the number of explanations. Then we ran each
query several times, each time with an increasing limit. The maximum number of explanations
is 16: there were 20 queries with 16 explanations
but most of the queries have a number of explanations between 1 and 5. We computed the relative error e between the correct probability p of
a query and the probability p returned by BUNDLE with a limit on the number of explanations
with the formula e = pp
p . Then we averaged the
relative error over all the queries.

In Figure 13 we show how the mean relative error varies with respect to the limit on the number
of explanations. As can be seen, the quality of the
answer increases as the limit on the number of explanations increases. Table 3 reports the execution
times, averaged over all the 100 queries. The row
of Table 3 with  in the first column contains
the average execution time for BUNDLE without
a limit on the number of explanations. Figure 14
shows the execution time as a function of the limit
on the number of explanations, based on the values of Table 3.

8.4. Scalability of BUNDLE

Finally, we did a scalability test with two different KBs: the full version of the NCI Thesaurus
(NCI full for short) with SH expressiveness that
contains 3,382,017 axioms and the Foundational

Fig. 14. Average execution time (s) as the limit on the
number of explanations to the queries varies for the Grid
KB.

Model of Anatomy Ontology (FMA for short)8
with ALCOIN (D) expressiveness. FMA is a KB
for biomedical informatics that models the phenotypic structure of the human body anatomy. It
contains 88,252 axioms in the TBox and RBox and
237,382 individuals. The experiments have been
performed on a Linux machine with a 2.33 GHz
Intel Dual Core E6550 with 2GB memory allotted
to Java.

For NCI full we generated 10 ontologies of increasing size that contain 10%, ..., 100% of the
axioms. Then we randomly selected an increasing number of certain axioms from these subontologies and made them probabilistic. We sampled 5,000, 10,000, 15,000, 20,000, 25,000 different probabilistic axioms, obtaining 50 different
probabilistic KBs with total size from 338,201 to
3,382,017 axioms. Then we randomly created 100
subclass queries for each of the 50 subontologies
and ran them. Figure 15 shows the trend of the
runtime averaged over the queries with respect to
the total size of the ontologies and the subset of
probabilistic axioms. The maximum time spent for
computing the probability of a query is 266.24 seconds with the KB that contains 90% of the ax-
ioms.

Finally, we exploited the FMA ontology for running a scalability test where only the size of the
ABox varies. We generated versions of the ontology that contain the entire TBox and RBox, 500

8http://sig.biostr.washington.edu/projects/fm/

index.html

Average execution time depending on the limit on the number of explanations for the Grid KB. The last row reports the
time spent for finding the set of all explanations.

Table 3

Limit on the
explanations Runtime (s)


Fig. 15. Average execution time (s) for the queries to the
NCI full KB on versions of increasing size of the ontology
and of the probabilistic part. On the x axis is reported the
total number of axioms of the KB (including the probabilistic ones) and on the y axis the number of probabilistic
axioms considered.

probabilistic axioms and an increasing number of
individuals. The size of the ABox varies between
50,000 and all the individuals contained in the
full ABox with a step of 50,000. We generated
100 instance-of queries by randomly selecting an
individual and a class among those to which it
belongs. Figure 16 shows how the runtime averaged over the queries varies with respect to the
size of the ABox. With 237382 individuals, that
correspond to the entire ABox, BUNDLE raises
an out-of-memory error. The maximum inference
time reached is 298.98 seconds with 200,000 indi-
viduals.

Fig. 16. Average execution time (s) for the queries to the
FMA KB with respect to the increasing size of the ABox.
BUNDLE cannot manage the entire ABox (237382 individ-
uals).

As can be seen, BUNDLE can manage very large
ontologies and answer queries in a relatively short
time.

9. Conclusions

We have presented the DISPONTE semantics for probabilistic DLs that is inspired by the
distribution semantics of probabilistic logic pro-
gramming. We have discussed the application of
DISPONTE to SHOIN (D), a prototype of an
expressive DL. DISPONTE minimally extends
the language to which it is applied and allows
both assertional and terminological probabilistic

F. Riguzzi et al. / Probabilistic Description Logics under the Distribution Semantics

knowledge. We have also presented the algorithm
BUNDLE that is able to compute the probability of queries from DISPONTE KBs. BUNDLE
has been both compared with the probabilistical reasoner PRONTO and tested for scalability
on several real world KBs. The experiments show
that BUNDLE is able to deal with ontologies of
significant complexity, even if in some situations
only an approximated answer takes a reasonable
amount of time. BUNDLE is available for download from http://sites.unife.it/ml/bundle
together with the datasets used in the experi-
ments.

In the future, we plan to consider extensions
of the semantics including statistical or Type 1
knowledge in the terminology of [22]. Moreover,
alternative approaches for inference will be consid-
ered, in particular reasoning algorithms returning
a pinpointing formula [2,1]: such a formula compactly encodes explanations for the query and can
be converted directly into a BDD. We will also consider non-Boolean conjunctive queries and develop
inference algorithms for answering them. One possibility would be to first retrieve the instances satisfying the query and then compute explanations
for each of them. We have also started to study
the problem of learning the parameters [63] and
we are planning to tackle the problem of learning
the structure of probabilistic KBs.
