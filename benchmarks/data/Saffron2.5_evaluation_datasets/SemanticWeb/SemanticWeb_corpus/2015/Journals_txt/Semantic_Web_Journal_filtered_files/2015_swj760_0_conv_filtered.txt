Semantic Web 0 (2014) 0
IOS Press

A logical characterisation of SPARQL
federation

Editor(s): Oscar Corcho, Universidad Politecnica de Madrid, Spain
Solicited review(s): Jurgen Umbrich, Vienna University of Economics and Business, Austria; Carlos Buil Aranda, Pontificia Universidad
Catolica de Chile, Chile; Maria-Esther Vidal, Universidad Simon Bolivar, Venezuela

Audun Stolpe
Norwegian Defence Research Establishment (FFI), Postboks 25, 2027 Kjeller, Norway
E-mail: audun.stolpe@ffi.no

Abstract. The paper provides a logical characterisation of distributed processing of SPARQL queries. The principal notion
analysed is that of a distribution scheme; a pair consisting of an evaluation rule and a distribution function. Different choices
of evaluation rules and distribution functions give different federation schemes that are proved to be sound and complete wrt.
different selections of RDF datasets. Three distribution functions are singled out for special attention, called the even-, standardand prudent distribution respectively. All yield sound and complete federation schemes when combined with an evaluation rule
named the collect-and-combine rule. The completeness results thus obtained are next compared to existing federation systems
with the aim of illustrating the potential utility of a framework in which salient properties can be formulated and explored. The
final section, relates distribution schemes to the heuristic notion of a join-ordering to yield sound and complete execution plans
for the aforementioned federation schemes.

Keywords: SPARQL federation, distributed query processing, logical foundation, completeness, distribution scheme

1. Introduction

That the exploitation and dissemination of Semantic Web data requires powerful federation engines, is
a claim that hardly needs an argument. Unedited and
decentralized, the Semantic Web is also a singularly
fluid computational environment. Therefore any federation engine that aims to be generic must be capable of operating in a dynamic network topology where
datasets may be discovered at run time, and where little is known about the structure and content of these
datasets prior to querying.

SPARQL federationthe decomposition and distribution of SPARQL queriesis one approach that
seems both principled and promising. Its emerging importance is mirrored by the number of publications devoted to this topic in the last five to ten years. How-
ever, the wealth of experimental systems and empirical research contrasts sharply with the paucity of foundational work, and attempts to formulate a theoretical

framework in which to explore and compare different
approaches mathematically are largely absent.

This remains true even when the query language is
abstracted away so as to include the comparatively rich
literature on distributed databases. Thus, whilst the
150+ references in Kossmans excellent The State of
the Art in Distributed Query Processing [22] together
with the 150+ references in Hose et al.s Database
foundations for scalable RDF processing [19] span
more than 30 years of research, none of the listed references gives a general logical characterisation of distributed query answering.

The present paper provides some tentative indications that the working out of such a framework may
be both an interesting and worthwhile pursuit. Although the concepts introduced ought to be of more
general validity, focus will be placed on federation in
a zero-knowledge environment, that is, on federation
performed in the absence of specific information about

1570-0844/14/$27.50 c 2014  IOS Press and the authors. All rights reserved

the structure and content of contributing datasets (apart
from their signaturesa concept to be defined).

Also, only the fragment of SPARQL that consists
of simple conjunctive queries aka. basic graph patterns
will be considered. The operative assumption is that
these restrictions form a natural base-line for a theory,
from which more complex cases can be derived.

The present paper does not advocate an approach
to SPARQL federation. Rather, it is more aptly seen as
giving expression to properties and observations that
are already part of the folklore of the Semantic Web
community, and in the process developing a formal apparatus in which the relevant distinctions can be drawn
and their ramifications explored.

Indeed, the results that are to be presented are not
even essentially tied to SPARQL, but could easily
be generalized to apply to any class of conjunctive
queries [1, chap. 4] expressible in first-order logic.
Thus, the relationship between the present theory and
the SPARQL 1.1. federation extension [11,30] is essentially one of abstraction: the latter, by providing the
SERVICE keyword for source selection, provides one
way of implementing the former.

The paper is organized as follows: After a review
of related work in section 2, section 3 recalls a few
essential notions of SPARQL semantics, fixes notation and declares theoretical assumptions for subsequent developments. Section 4 introduces the principal
unit of analysis, which is that of a federation scheme
defined as pair consisting of a distribution function
and an evaluation rule. A number of concrete federation schemes are presented, obtained by combining a
particularly natural evaluation rule, called collect-and-
combine-rule, with three different distribution func-
tions, called the even-, standard- and prudent distribution respectively. Section 5 investigates the notions of
soundness and completeness as they apply to federation schemes, where soundness/completeness is measured wrt. families (i.e. sets) of sets of RDF graphs.
Intuitively different families represent different admissible ways of selecting RDF sources for federation,
whence they will also be called, more suggestively,
sets of selections of RDF datasets. The investigation
is restricted to soundness and completeness in a zeroknowledge environmentthat is, to the case where the
distribution of data over the sources in a selection is
unconstrained. This corresponds to the case where all
sets of RDF graphs constitute admissible selections.
Next, section 6 compares the completeness results of
section 5 with some examples of existing federation

systems, with the principal aim of illustrating the potential utility of having a framework in which salient
properties can be formulated and explored. Finally,
since no federation engine can be expected to perform
well without a carefully crafted optimizer, the paper is
rounded off in section 7 by showing how the notion of
a join-ordering fits together with that of a federation
scheme. This section can be considered a corollary to
the preceding ones.

2. Related work

Fairly recent surveys of the state of the art wrt. RDF
federation can be found in Betz et al. [8], Gorlitz and
Staab [14] and Hose et al. [19]. Based on these sources,
it is possible to distinguish between at least three major
trends in RDF federation, namely lookup-based feder-
ation, warehousing and distributed query processing.
Lookup-based federation, which may also be called
federation-by-traversal (or follow-your-nose traversal,
as in [4]), iteratively downloads and evaluates data
based on links (usually as prescribed by the Linked
Data principles [9]) from one dataset into another. The
answer to a query is composed by cumulatively adding
answers from incoming data during the traversal pro-
cess. This approach is exemplified by e.g. [17,18] and
[23].

Approaches based on warehousing, on the other
hand, collect all data in advance and combines it into
a central triple store against which queries are evalu-
ated. Recent efforts in this direction focus on the use
of cluster technology such as MapReduce and hadoop,
e.g. [12,20,21] and [29].

Finally, approaches based on distributed query processing rely on analysing a query to identify a set
of relevant RDF graphswith or without
the aid
of statisticsto which subqueries can be assigned.
Like federation-by-traversal and unlike warehousing,
queries are evaluated remotely. Recent example of this
approach include [3,7,27,31] and [34].

I should be said that this classification is very rough,
cutting across important and interesting topics such as
adaptivity and opportunism, indexing, join-order opti-
mization, statistics-generation and more. The reader is
referred to the aforementioned surveys for more detail.
The present paper is most comfortably subsumed
under the category of distributed query processing, although it ought to be of relevance to the other two as
well. To the authors knowledge it is the first foundational study of distributed query processing that ap-

A. Stolpe / A logical characterisation of SPARQL federation

proaches the discipline from a purely logical point of
view. There do exist a few formal studies of what can
be considered the more general topic of querying the
Web, for instance Abiteboul and Vianu [1] and Bouquet et al. [10]. The former is concerned with the computability of queries over the Web expressed in Dat-
alog, and predates the SPARQL query language. The
latter describes three different ways in which a query
can be answered and characterizes their answers semantically in complete abstraction from query languages and distribution algorithms. These references
have little in common with the present study, apart
from being formal and about queries on the Semantic
Web.

3. Preliminaries

In order to lighten the notation somewhat, curly
braces will be omitted from singletons in set-theoretic
expressions and applications of functions if no confusion is likely to ensue, e.g. P  t instead of P {t} and
f (t) instead of f ({t}). Also, when f is a function and
A a subset of fs domain, then f (A) will be used as a
shorthand for the set of elements b such that b = f (a)
for some a  A.

Turning now to RDF specifics, let I, B and L denote pairwise disjoint infinite sets of IRIs, blank nodes,
and literals respectively. An RDF triple is an element
(s, p, o)  (I  B)  I  (I  B  L) where s is the
subject, p the predicate and o the object. In conformity
with the nomenclature of [5], IL abbreviates I  L and
T abbreviates I  B  L. These latter sets will be referred to collectively as RDF terms.

Definition 3.1 An RDF graph is a finite set of RDF
triples.

An RDF graph will sometimes also be referred to as an
RDF dataset, or simply a dataset [5] or even a source.
These are all interchangeable, but will tend to be used
in different contexts for the purpose of making the terminology more suggestive. The notation Gi will be
used to denote an RDF graph. The subscript may be
omitted when idle.

Let V be an infinite set of variables. Variables
will be denoted by capital letters prefixed by question
marks ?X, ?Y, ?Z and so on.

Definition 3.2 A basic graph pattern (BGP), aka. a
conjunctive graph pattern, is defined as follows:

1. Any triple pattern in (ILV )(IV )(ILV )
2. if P1 and P2 are BGPs, then so is P1  P2.

is a BGP.

The notation ti is used to denote triple patterns.
Again, subscripts may be omitted when they serve no
purpose. In order to avoid tedious limiting cases in
proofs, it will be assumed that the set of triple patterns
is disjoint from the set of RDF triples, that is, a triple
pattern is assumed to contain at least one variable.

As in [5] conjunctive graph patterns are conceived
of as queries matching RDF graphs. Answers are eligible substitutions of values from the RDF graph in
question for variables in the graph pattern in ques-
tion. In conformity to [5], sets of answers will be formalized in terms of partial functions  : V  T .
The domain of  is the subset of V where  is de-
fined. Two mappings 1 and 2 are compatible when
for all ?X  dom(1)  dom(2) it is the case that
1(?X) = 2(?X). Thus two mappings with disjoint
domains are always compatible. Let 1 and 2 be
sets of mappings. The join of 1 and 2 is denoted
1  2 and is defined as the set of compatible pairs
in 1  2.

The set of answers to a BGP P over a graph G is

denotedPG and is defined as follows:

Definition 3.3 Let G be an RDF dataset, and P a
BGP. Let (t) denote the triple obtained by replacing
the variables in t according to , and let var(t) denote
the set of variables occurring in t. Then

1. PG =df {| dom() = var(t) and (t)  G},
2. P1G P2G, if P = P1  P2.

if P is a triple pattern t, or

Taking stock, the reader should note two things:
first, as announced in the introduction, the present theory only considers the fragment of SPARQL that consists of conjunctive queries. Secondly, the distinction
between the syntax and the semantics of SPARQL
queries has been blurred, and this is deliberate. Usu-
ally, one would treat a SPARQL graph pattern as a
syntactic object, and the query mapping that links it to
an RDF dataset as a semantic object. However, defining a basic graph pattern as a set of triple patterns, as
in definition 3.2, is mathematically convenient, and it
simplifies formal developments without loss of preci-
sion. Abiteboul et al. [2] established this precedent in
database theory.

Now, considered from an abstract or logical point
of view, the problem of characterizing SPARQL federation is essentially that of generalizing definition 3.3
to the case that G is a finite set of RDF graphssets
of RDF graphs will henceforth be denoted G , possibly
with subscripts. This generalization will proceed along
the following two lines:
Definition 3.4 Let G be a set of RDF datasets and P
a BGP. Then:

1. PG =df P G

Here G denotes the union of all the elements of G .

2. [P ]G =df

It will be assumed that blank nodes are never shared
between datasets. This is no real restriction since one
can always rename blank nodes without altering the
information content of the datasets in question.

4. Federation schemes

Presupposing a selection of RDF datasets G , the
problem of evaluating a query Q reduces to two interrelated sub-problems: 1) 1) how to assign to members
of G the proper subquery of Q, and B) how to combine the answers to these subqueries into an answer to
Q itself. Varying either of these parameters, including
the selection of sources, may change the final answer.
That is, the outcome of the federation process will in
general be sensitive to how the contributing datasets
are selected, how subqueries of the global query are allocated to these datasets and how the partial results are
subsequently combined.

Therefore any general property of distributed query
processing must be similarly parametrised, that is, in
terms of a decomposition- or distribution function, an
evaluation rule and some notion capturing the permissible ways of selecting contributing datasets.

The last of these concepts will be discussed in more
detail in the next section. As regards the former two,
the general idea expounded in the following is to distribute a (global) query over a selection of datasets
by decomposing it into subqueries that can be evaluated directly against the sources that cover its signa-
ture. Using signatures to route subqueries is a common
stratagem in the literature (cf. [13] and [34]).
Definition 4.1 Let S be a BGP or a set of RDF triples.
The signature of S written sig(S) is defined as

sig(S) =df S2 \ (V  B)

where S2 denotes the projection of S onto its second
coordinates.

Note that variables and blank nodes do not add to the
signature of a graph pattern, and that blank nodes do
not add to the signature of an RDF graph.

Definition 4.2 If P is non-empty, then

G (P ) =df {G  G : sig(P )  sig(G)}

Otherwise G (P ) =df .
It is a simple consequence of definitions 4.1 and 4.2
that if t2  V  B for some triple pattern t, that is,
if t has a variable or blank node in predicate position,
then G (t) = G for any G . A consequence of this is
that a triple pattern that has a blank node or variable
in predicate position will be routed to all datasets in a
selection.

Definition 4.3 (Distribution function) A distribution
function is a binary function  that takes a set of RDF
datasets G and a BGP P and returns a set of pairs
(Pi, Gj) such Pi =  and such that both of the following hold:
1. Gj  G (Pi)
2. if (P1, Gi), (P2, Gj)  (G , P ) and P1 = P2 then

3. 

Gi = Gj

(Pi,Gj )  (G ,P ) Pi = P

Clause (1) prevents a distribution function from behaving erratically when it comes to assigning subqueries
to datasets. That is, a BGP is only assigned to datasets
that can potentially answer it. Clause (2) ensures that
the value of a distribution function on any selection of
datasets G and any BGP P is itself a function, that is,
that every subquery of P is assigned to exactly one
subset of G . Finally, clause (3) expresses a necessary
condition for soundness:  distributes P over G only if
P is decomposed into sub-queries that jointly exhaust
P . Note that  as so defined is a partial function, that
is, (1) and (3) can not be satisfied for arbitrary choices
of G and P , reflecting the fact that the accumulated
signature of the datasets may not cover the signature
of the global query. If it does then  will henceforth be
said to be defined at G and P .

A distribution function will be said to be egalitarian

if it satisfies the converse of definition 4.3(2):

Definition 4.4 (Egalitarian distribution) A distribution function is egalitarian if (Pi, Gj)  (G , P ) implies G (Pi)  Gj.

A. Stolpe / A logical characterisation of SPARQL federation

Egalitarianism has an important bearing on zeroknowledge completeness. It is therefore investigated
in more detail in section 5. Several of the distribution
functions introduced in the next section are egalitarian.
If  is egalitarian, then condition 4.3(2) is redundant.

4.1. Examples of distribution functions

Let the notion of an exclusive subset of P pertaining
to a given dataset G relative to a selection of datasets
G be defined as follows:

Definition 4.5 The subpattern of BGP P that is exclusive to a dataset G, relative to a set of RDF datasets
G , is the set:

EG(P ) =df {t  P : G (t) = {G}}

A triple pattern that is not an element of an exclusive
group is called a non-exclusive triple pattern relative
to the same selection of datasets.

In this form, definition 4.5 goes back to [34].

The following theorem gives examples of egalitar-

ian distribution functions:
Theorem 4.1 Let G be any set of RDF datasets and P
any BGP. Stipulate that (Pi, Gi)  (G , P ) iff Gi =
G (Pi) and one of the following conditions hold:
1. Even distribution: Pi is a singleton t  P .
2. Standard distribution: either

a) Pi is a non-exclusive singleton t  P , or
b) Pi = EG(P ) for some G  G

3. Prudent distribution: either

a) Pi is a non-exclusive singleton t  P , or
b) Pi is a maximal join-connected subset of

EG(P ) for some G  G

Then  is a distribution function in the sense of definition 4.3.

Proof The proof considers only the standard distribu-
tion. The other cases are similar. So suppose (Pi, Gi) 
(G , P ) iff Gi = G (Pi). If the signature of P is not
covered by G , then  is vacuously a distribution func-
tion. Suppose the opposite. Since Gi = G (Pi) for
all (Pi, Gi)  (G , P ), definition 4.3(1) is satisfied
and definition 4.3(2) is entailed. For 4.3(3) it suffices
to note that all exclusive and non-exclusive patterns,
which together exhaust P , are assigned to some dataset
in G , by condition 2(a) and 2(b).

Here, the join-connectedness of a BGP P means:
Definition 4.6 Let P := {ti}iI be a BGP. Then the
join-graph induced by P is the set of pairs (ti, tj) such
that var(ti)  var(tj) = . A subset of P is joinconnected if it induces a connected join-graph.

Stated in words, a BGP being join-connected means
that it cannot be split into sub-patterns that do not share
a variable.

Anticipating subsequents developments, the even-,
standard- and prudent distribution are all suitable for
a zero-knowledge environment insofar as they yield
sound and complete federation schemes (wrt. the set
of all selections of RDF graphs) when paired with the
collect-and-combine evaluation rule that will be introduced shortly.

Moreover, all three distribution functions can be
said to heed the fact that one dataset may be able to
generate new results when joining with partial results
from another [31, p. 120]. Stated differently, a join
may span two or more datasets, in which case the evaluation of a non-singleton graph pattern over a given
dataset may come to suppress intermediate results that
are needed for cross-site joins: in the simplest case, the
answer to a pair of triple patterns P := {t1, t2} over a
source G1 may not contain every triple g1 that matches
t1. Since, there could be a triple pattern g2 in a different source G2 that matches t2, there may very well be
an answer to P in the union of G1 and G2. Yet, this
answer may happen to escape the distributed query answering process, since the distribution does not guarantee intermediate results from G1 and G2 respectively
that when combined yield the cross-site join g1  g2.
The even distribution averts this risk by breaking a
graph pattern into its singleton constituents, but this
may be considered to be overly cautious. The standard
distribution, in contrast, carves a query at its natural
joints in the sense that whenever the pattern in question is exclusive to a dataset, then it is assigned to that
dataset as-is. This is safe too, since grouping exclusive
patterns cannot incur a loss of information [13,34]. Fi-
nally, the prudent distribution, which does not seem to
have been mentioned in the literature yet, is halfway
between the other two. Like the even distribution it
treats non-exclusive triples as singletons, and like the
standard distribution it groups together (some) exclusive triples. However, unlike the standard distribution,
the prudent distribution splits exclusive groups into
maximal join-connected components, each of which is
assigned to the dataset for which it is exclusive.

SELECT ? drug ? keggUrl ? c h e b i I m a g e WHERE {

? drug r d f : t y p e drugbank : d r u g s
? drug drugbank : keggCompoundId ? keggDrug .
? drug drugbank : genericName ? drugBankName .
? keggDrug b i o 2 r d f : u r l ? keggUrl
? chebiDrug p u r l : t i t l e
? drugBankName .
? chebiDrug b i o 2 r d f : image ? c h e b i I m a g e

Listing 1: Query LS5 from FedBench

Example 4.1 Consider the query in listing 1. This is
query LS5 from the FedBench suite [33] which asks for
all drugs from Drugbank, together with the URL of the
corresponding page stored in KEGG and the URL to
the image derived from ChEBI.

The signature of the query divides among the FedBench datasets as specified in table 1. Presupposing
this division, table 2 gives the even, standard and
prudent distributions respectively. Blocks in a column
correspond to subqueries and are labelled with the
datasets to which that subquery is assigned. For in-
stance, the standard distribution assigns the subquery
consisting of line 2 and 3 to KEGG, since 2 and 3 form
and exclusive group for it. The non-exclusive triple
pattern in line 4, in contrast, is assigned to both KEGG
and ChEBI.

Table 1

Distribution of the signature of query LS5.

Signature element/property
rdf:type
drugbank:keggCompundId
drugbank:genericName
bio2rdf:url
purl:title
bio2rdf:image

Endpoint
All
Drugbank
Drugbank
KEGG, ChEBI
KEGG, ChEBI
ChEBI

The standard- and prudent distributions of LS5 over
KEGG, ChEBI and Drugbank are identical for this
particular selection of datasets. The difference between them is revealed by reducing the selection to
ChEBI and Drugbank only, viz. table 3. Here, the standard distribution assigns the subquery consisting of
line 4,5 and 6 to ChEBI, since this larger set now constitutes an an exclusive group for ChEBI. Note, how-
ever, that its join-graph is not connected since none
of the variables in line 4 occur in line 5 or 6. There-
fore, the prudent distribution divides {4, 5, 6} into its
two join-connected components {4} and {5, 6} which

are both assigned to ChEBI, only this time as separate
subqueries.

The relative merits of these distribution schemes is
not really visible unless looked at from the perspective
of join-order heuristicsa topic which is otherwise
postponed until section 7. If a join-ordering is perceived as a partial order over the power set of a graph
pattern P then the even distribution is the finest ordering of P . In computational terms, the even distribution makes each triple pattern in P executable independently of every other, and therefore leaves maximum
control to query planning on the side of the federator.
The standard distribution, on the other hand, strikes a
balance between query optimization on the side of the
federator and on the side of the contributing datasets.
That is, exclusive patterns effectively bracket joins,
thus suspending optimization and delegating it to the
RDF source in question. The prudent distribution, being halfway between the other two, is more discerning than the even distribution, but, one might say, less
dogmatic about the heuristic value of exclusive subpatterns than the standard distribution. Specifically, if an
exclusive subpattern can be split into several components without severing joins, then the prudent distribution hands responsibility for preferring between these
components back to the federator in order, possibly,
to avoid requesting cartesian products from the remote
RDF source.

Turning now to the notion of an evaluation rule, the
second proposed component of federation schemes, it
suffices for now to define it in complete abstraction
simply as a function that produces a set of answers
from a distribution:

Definition 4.7 (Evaluation rule) An evaluation rule
is a function E that takes any distribution (G , P ) and
returns a set of variable mappings  : V  T .

Obviously, this definition hides great variety. Next:
Definition 4.8 A federation scheme is a pair (E, )
consisting of an evaluation rule and a distribution
function.

The central claim of the present paper is that a federation scheme is the proper unit of analysis for distributed query processingor at any rate, for the
purposes of logical analysis. That means that metaproperties such as soundness and completeness are relations that hold between federation schemes on the

A. Stolpe / A logical characterisation of SPARQL federation

Distribution of LS5 over KEGG, ChEBI and Drugbank

Table 2

Nr.

Triple pattern
?drug rdf:type drugbank:drugs
?drug drugbank:keggCompoundId ?keggDrug
?drug drugbank:genericName ?drugBankName
?keggDrug bio2rdf:url ?keggUrl
?chebiDrug purl:title ?drugBankName
?chebiDrug bio2rdf:image ?chebiImage

even
All
Drugbank
Drugbank
KEGG, ChEBI
KEGG, ChEBI
ChEBI

standard
All

prudent
All

Drugbank
KEGG, ChEBI
KEGG, ChEBI
ChEBI

Drugbank
KEGG, ChEBI
KEGG, ChEBI
ChEBI

Table 3

Distributions of LS5 over ChEBI and Drugbank

Nr.

Triple pattern
?drug rdf:type drugbank:drugs
?drug drugbank:keggCompoundId ?keggDrug
?drug drugbank:genericName ?drugBankName
?keggDrug bio2rdf:url ?keggUrl
?chebiDrug purl:title ?drugBankName
?chebiDrug bio2rdf:image ?chebiImage

even
Both
Drugbank
Drugbank
ChEBI
ChEBI
ChEBI

standard
Both

prudent
Both

Drugbank

Drugbank
ChEBI

ChEBI

ChEBI

Table 4

Summary of notation

description
a triple pattern
a conjunctive graph pattern
an RDF dataset
a set of RDF datasets
the variables occurring in P
partial function from V to T
the domain of 
P evaluated over G
P evaluated over the union of G
the union of evaluating P over each G  G
the signature/the set of predicates of P
the datasets in G whose signature cover P

Nomenclature
ti
Pi
Gi

var(P )

dom()


[P ]G

sig(P )
G (P )

one hand and sets of selections of RDF datasets on the
other. The former specifies how a graph pattern is to
be distributed and evaluated, the latter demarcates the
permissible ways of selecting sources over which to
distribute the decomposed query:
Definition 4.9 Let {Gi}iI be a set of selections of
RDF graphs. A federation scheme (E, ) is sound wrt.
any i  I. It is complete wrt. {Gi}iI if the converse
inclusion holds.

{Gi}iI if E((Gi, P ))  PGi for any BGP P and

Bordering on circularity, one might say that a set of
selections of RDF datasets represents a way of choosing RDF datasets that keeps a federation scheme correct and exhaustive. The role of soundness and completeness theorems is to act as chopsticks (borrowing
a metaphor from Makinson [26]) to pin down a federation scheme and a set of selections that is perfectly
matched in the sense that the federation scheme neither
invents nor ignores answers when restricted to that set.

5. Completeness in the zero-knowledge case

As mentioned in section 3, the problem of giving a
logical characterisation of SPARQL federation can be
construed as the problem of generalizing the semantics of conjunctive queries to multiple RDF graphs.
Standard SPARQL semantics defines the evaluation

PG of a BGP P over an RDF graph G in terms

of partial functions or maps from variables to RDF
terms. The conjunction of different sets of answers

P1G1 P2G2 is defined in terms of the union of

pairs of compatible maps, where compatibility means
agreement on shared variables. However, the standard
semantics requires that a) G1 and G2 are singletons
and that b) G1 = G2.

The distributed query processing semantics that is
developed in the present paper sticks to the general
idiom of the standard semantics but relaxes restric-

tions a) and b). Considered in the abstract, this involves
working out an account of combinations

 g(P2)Gj

f (P1)Gi

and (not necessarily different) and the operator 

(1)
where f and g is either of the evaluation functions []
is either  or . Given the present emphasis on com-
pleteness, not all such combinations are of interest,
only those for which

f (P1)Gi

 g(P2)Gj =P1  P2GjGj

an equation that places severe restrictions on eligible
pairs of distribution functions and evaluation rules.

This section focuses on one particularly natural set
of such pairs, namely those formed from distributions functions that are egalitarian and satisfy a condition called granularity combined with the announced
collect-and-combine evaluation rule that will be defined shortly.

The set of federation schemes that are sound and
complete in a zero-knowledge environmentthat is,
sound and complete wrt. to the set of all selections of
RDF datasetsis larger then this, though, and in fact
does not presuppose neither granularity nor egalitari-
anism. Examples of non-granular and non-egalitarian,
but zero-knowledge sound and complete, federation
schemes are provided in subsection 5.2.

The account is built up from simple principles, start-

ing with the following lemma:

Lemma 5.1 (Dataset monotony) P1Gi  P2Gj

whenever Gi  Gj.
Proof Immediate from the assumption that no RDF
graphs share blank nodes.

Although dataset monotony does require the nontrivial property of disjointness for every pair of elements in a set of RDF graphs wrt. blank nodes,
this is not a real restriction since renaming of blank
nodes does not change the semantics of an RDF graph.
Hence, one can always assume that blank nodes have
been standardized apart in a pre-processing step.

The next lemma gives the case of equation (1) for

f = g = and  = :
some set of RDF graphs G . Thent1  t2(GiGj ) =
t1Gi t2Gj .

Lemma 5.2 Let G (t1) = Gi and G (t2) = Gj for

Proof For the left-to-right direction suppose  t1
t2(GiGj ). Then   t1(GiGj )  t2(GiGj ),
whence  = 1  2 for 1  t1(GiGj ) and
2  t2(GiGj ). Since t1 and t2 are triple patterns,

and 1 and 2 are functional, there is exactly one triple
g1  Gm s.t. 1(t1) = g1 and exactly one triple g2 
Gn s.t. 2(t2) = g2 for some Gm, Gn  Gi  Gj. If t2
is a blank node then sig(t1) =  otherwise sig(t1) =
sig(g1). Both cases entail sig(t1)  sig(Gm). A similar argument establishes sig(t2)  sig(Gn). There-
fore, since by the supposition of the lemma G (t1) =
Gi and G (t2) = Gj it follows that Gm  Gi and

Gn  Gj. Hence 1  t1Gi and 2  t2Gj , so
  t1Gi  t2Gj as desired. The converse di-

rection follows immediately from dataset monotony
(lemma 5.1).

lowing property holds in general:

The restriction on the families of datasets Gi and Gj
is essential. That is, lemma 5.2 does not hold for arbitrary pairs (ta, Gk) and (tb, Gl), which is as one would
expect.

As regards the interplay between [] and, the folLemma 5.3 [P1]Gi  [P2]Gj P1  P2(GiGj )
Proof Suppose [P1]Gi  [P2]Gj . Then there are 1 
[P1]Gi and 2  [P2]Gj s.t.  = 1  2. By definition
3.4 (2) there are Gm  Gi and Gn  Gj such that 1 
P1Gm and 2  P2Gn. Thus, applying lemma
5.1 gives 1  P1(GiGj ) and 2  P2(GiGj ),
whence  P1  P2(GiGj ) as desired.

The converse does not, but there is the following qualified version of it:

Lemma 5.4 Put G (P1) = Gi and G (P2) = Gj for
some set of selections of RDF datasets G and suppose

P1Gi = [P1]Gi andP2Gj = [P2]Gj . ThenP1 
P2(GiGj )  [P1]Gi  [P2]Gj .
Proof By definition 3.4(1), P1  P2(GiGj ) =
P1(GiGj )  P2(GiGj ). By the supposition of
P1(GiGj )  P2(GiGj ) = P1Gi  P2Gj .
SinceP1Gi = [P1]Gi andP2Gj = [P2]Gj , it follows thatP1  P2(GiGj ) = P1Gi  P2Gj =
[P1]Gi  [P2]Gj , so P1  P2(GiGj ) = [P1]Gi 

the lemma G (P1) = Gi and G (P2) = Gj so

[P2]Gj which is clearly sufficient.

A distribution function that satisfies both directions
will be said to be agnostic:

A. Stolpe / A logical characterisation of SPARQL federation

Definition 5.1 (Agnosticism) A distribution function
 is agnostic if for every set of selections of RDF
datasets G , every BGP P , and every (P1, Gi), (P2, Gj) 

(G , P ) it follows that [P1]Gi  [P2]Gj = P1 
P2(GiGj )
not in general coincide withPG ,  is not agnostic.

Example 5.1 As an example of a distribution function
that is not agnostic, consider the trivial distribution defined by putting (G , P ) = {(P, G )}. Since [P ]G does

The significance of the property of agnosticism consists in the fact that for agnostic distribution functions
there exists a natural and simple evaluation rule that
yields a sound and complete federation scheme for the
zero-knowledge case. This is the announced collect-
and-combine rule:
Definition 5.2 (Collect-and-combine rule) Put  :=
(G , P ). If  is not defined at G and P we put
Ec() =df , otherwise

Ec() =df  {[P1]Gi : (P1, Gi)  }

For a concrete example of how the collect-and-combine
rule is implemented in a popular SPARQL 1.0 federation system, the reader may want to peak ahead to subsection 6.1. From a theoretical point of view the rule
may be motivated follows: To produce a result set from
a distribution, each cell in the distribution has to be
evaluated against its designated datasets and the partial
answers that are returned have to be combined in order
to yield an answer to the global query. The question,
is how to unpack combine. Note that just fixating on
one operator will not do. Consider for instance, the

ible i and j (i.e. suppose t contains a variable ?X
such that i(?X) = j(?X)). Then neither i or j is

case where i tGi and j tGj for incompatintGi  tGj , even though they are both answers
compatible i  P1Gi and j  P2Gj . Then 
need not be inP1Gi P2Gj , whereas i and j

to the query t. Alternatively, form the union of partial
answers, and consider the case where  = i  j for

always are, despite the fact that  but not i and j
may be an answer to P1  P2.
The collect-and-combine rule is designed to balance
the need for both  and  as result-set forming opera-
tors, and to apply them in equal measure so to speak.
Theorem 5.5 If  is agnostic and egalitarian then
(Ec, ) is sound and complete wrt. to the set of all selections of RDF graphs.

Proof Let G be any selection of datasets and P any
BGP. In the limiting case that  is not defined at G and

P we have Ec((G , P )) =  =PG by the limiting

case of definition 5.2. For the principal case, suppose
(G , P ) = (P1, G1), . . . , (Pn, Gn). Then

Ec((G , P )) = [P1]G1  . . .  [Pn]Gn

=P1  . . .  Pn(G1...Gn)
=P(G1...Gn)
=PG

(1)

(2)

(3)

(4)

(2) follows from (1) by applying agnosticism in a
straightforward induction on the number of arguments
to the operator , (3) follows from (2) by definition
4.3(3), and (4) follows from (3) by definition 4.3(1)
and egalitarianism (its converse).

As the next subsection will show, the even-, standardand prudent distributions are all agnostic and egalitarian in this sense. Hence, table 2 and 3 give examples of
agnostic and egalitarian decompositions of FedBench
query LS5.

5.1. The even-, standard- and prudent distribution

Theorem 5.5 specialises in a straightforward way to
the even-, standard- and prudent distribution by way
of the property egalitarianism (definition 4.4) and the
following property of granularity:

Definition 5.3 (Granularity) A distribution function
 is granular iff for every (P1, Gi)  (G , P ), either
P1 or Gi is a singleton.

It is evident by inspection of definition 4.3 that the
even-, standard- and prudent distribution are all granular in this sense. Stretching the terminology somewhat,
the federation scheme itself will be said to be granular
if its distribution function is.

Granular distribution functions have the important

property that they make sets [P ]G andPG coincide:
Lemma 5.6 If G is a singleton then [P ]G =PG for

any BGP P

Proof

[P ]G =

G{G}PG
=PG
=P{G}
=PG

any selection of RDF graphs G .

Proof suppose P is a singleton t. The limiting case

Lemma 5.7 If P is a singleton then [P ]G =PG for
that [P ]G =  = PG is immediate since P contGi  
Gi  G such that (t)  Gi whence  tGi. Now,
converse, suppose   [t]G = 
GkGtGk = [t]G so   [t]G . For the
GkGtGk then for
some Gi  G it follows that   tGi  tG , by

tains no joins. Assume the opposite, then there is a

dataset monotony.

Thus,
Corollary 5.8 Suppose  is granular and that (P1, G ) 

(G , P ), thenP1G = [P1]G .

Now, if a distribution function is egalitarian then granularity suffices for agnosticism:

Theorem 5.9 If  is granular and egalitarian then  is
agnostic.
Proof Let (P1, Gi), (P2, Gj)  (G , P ) and assume
that  is granular. We show that [P1]Gi  [P2]Gj =

direction, so it suffices to prove the converse. Since  is
egalitarian it follows that G (P1) = Gi and G (P2) =

P1  P2(GiGj ). Lemma 5.3 gives the left to right
Gj. Since  is granular we also have that P1Gi =
[P1]Gi andP2Gj = [P2]Gj . Thus, the conditions of
lemma 5.4 are satisfied, whenceP1  P2(GiGj ) 

[P1]Gi  [P2]Gj as desired.

Corollary 5.10 Suppose  is the even-, standard or
prudent distribution. Then (Ec, ) is sound and complete wrt. the set of all selections of RDF graphs.

5.2. Non-granular and non-egalitarian federation

schemes

It is a fact of some importanceand one that there
shall be occasion to refer back to in the next section
that neither granularity nor egalitarianism are necessary conditions for the completeness of a federation
scheme in a zero-knowledge environment. It also depends on the choice of evaluation rule.

In order to show examples of this, it will be necessary to introduce a couple of new notational conven-
tions: first, given a set of variables W  V , by the restriction of  to W , denoted |w, will be meant a partial function such that dom(|w) = dom()  W and
|W (?X) = (?X) for every ?X  dom()  W [5].
Next, given a tuple (1, . . . , n) of compatible partial
functions from V to U, it is a simple fact of general set
theory that the union of all the elements in any permutation of this sequence is also a partial function from V
to U. Moreover, all these permutations yield the same
function modulo the union of its elements. Therefore,
any permutation of (1, . . . , n), considered as a func-
tion, can be identified with (1  . . .  n). By exten-
sion, if 1 and 2 are two sets of partial functions of
the requisite type and every element of 1 is compatible with every element of 2, then 1  2 will be
treated as a set of partial functions of that type. Note
that  considered in this way as a function-forming
operator is both associative and commutative.

Now, consider BGPs that are as unconstrained as
can be in the sense of having no joins and only variables or blank nodes in subject or object position:

Definition 5.4 An unconstrained BGP P , is any BGP
satisfying the following conditions:
1. if t1, t2  P then var(t1)  var(t2) = 
2. t1

i  V  B for i  {1, 2}

i , t3

Referring back to table 2, the BGP that consists of row
3 and 4 is unconstrained in this sense, as no two triples
in it share a variable (5.4(1)) and as none of the terms
in subject or object position is a URL or a literal value
(5.4(2)). Indeed, it is a maximal unconstrained subset
of 1-6, for row 1 has a URL in object position, whereas
all other triple patterns share a variable with either 3 or
4.

A distribution function that lumps together triple
patterns in unconstrained BGPs, in one way or the
other (there are of course many), will henceforth be
said to be coalescent:

A. Stolpe / A logical characterisation of SPARQL federation

Definition 5.5 Call  a coalescent distribution function if for every set of RDF graphs G and every BGP
P1, if (P2, Gi)  (G , P1) and |Gi|  2 then P2 is
unconstrained.

Example 5.2 Consider the decomposition of the LS5
query from the FedBench suite given by table 5. This
decomposition is coalescent but not granular: line 2
and 3 form an exclusive group relative to the Drugbank dataset, line 6 is an exclusive group relative to
the ChEBI datasetalbeit a singleton onewhereas
line 1 is a non-exclusive triple pattern assigned to all
involved datasets. As regards lines 4 and 5, they form a
group that is neither a singleton nor assigned to a single dataset, whence it is a group that violates the property of granularity. The two lines do not share vari-
ables, however, and do not have instantiated subjects
or objects, and is therefore unconstrained in the sense
of definition 5.4. It follows that the decomposition is
coalescent in the sence of definition 5.5.

The thing about an unconstrained BGP P is that it
can be evaluated as-is against any RDF source G that
covers its signature without any real loss of informa-
tion. More precisely, the answer to each t  P over G
can be reconstructed from the answers to P by splitting
off the relevant chunks of the latter:

Definition 5.6 Let G be any set of RDF graphs and P
a conjunction of triple patterns t1, . . . , tn. The splitting of [P ]G is defined as the empty tuple if [P ]G = ,
otherwise it is a sequence of sets 1, . . . , n where
i =df {|var(ti) |   [P ]G}.
The following lemma verifies that the splitting of a result set suffices to recover all information:

Lemma 5.11 Let P be an unconstrained BGP, G a set
of RDF graphs such that sig(P )  sig(G) for every
G  G . Then

|P|

i=1


[P ]G

PG =

Proof By induction on the complexity of P . For the
base case let P := t1  t2. It needs to be shown that

[t1  t2]G

t1  t2G =

i=1

Consider first the limiting case thatt1  t2G = .
Then, since t1  t2G has been defined as t1 

put


[t1  t2]G as desired.

Therefore [t1  t2]G =  by definition 3.4, whence

i=1
For the left-to-right direction of the principal case


t2 G and G  G , it follows by dataset monotony
(lemma 5.1) thatt1  t2G =  for every G  G .

[t1  t2]G := 1, 2 and suppose  t1  t2G .
Since   t1  t2G = t1G  t2G it follows that  = 1  2 for some 1  t1G1 and
some 2  t2G2. Suppose for reductio ad absurdum thatt1  t2G1 = t1G1  t2G1 = . Then
t2G1 = , which since Sig(t2)  Sig(t1  t2) 
2 / V  B for j = 1
Sig(G1) can only happen if tj
Assume therefore that there is an element  t2G1.
or j = 3. However this contradicts definition 5.4(2).
Since var(t1)  var(t2) =  by definition definition 5.4(1) it follows that 1 and  are compati-
ble, and thus that 1    t1  t2G1. Therefore
1 = (1  )|var(t1), i.e. 1 is the restriction of a
partial function int1  t2G1  [t1  t2]G from which
it follows, by definition 5.6, that 1  1. A simi-
(1, 2) = 1  2 =2
lar argument establishes 2  2. Hence 1  2 =

[t1  t2]G , which completes the case. The converse direction is straightforward and is left for the reader.
For the induction step, suppose P = P1  P2 and
assume as the induction hypothesis that the theorem
holds for P1 and P2. Then

i=1

PG =P1  P2G

=P1G P2G
=P1G P2G
|P1|
|P2|
|P|


[P1]G 

i=1

i=1


[P ]G


[P2]G

(2)
(3)
(4)

(5)

(6)

i=1

(4) follows from (3) by the assumption that var(P1) 
var(P2) =  and (6) follows from (5) by the fact that
 considered as a function-forming operator is both
commutative and associative.

Theorem 5.11 suggests the following evaluation rule:
Definition 5.7 Put  := (G , P ). If  is not defined at
G and P we put E() =df , otherwise

E() =df  {f (P1, Gi) : (P1, Gi)  }

A coalescent distribution of LS5 over KEGG, ChEBI and Drugbank

Table 5

Nr.

Triple pattern
?drug rdf:type drugbank:drugs
?drug drugbank:keggCompoundId ?keggDrug
?drug drugbank:genericName ?drugBankName
?keggDrug bio2rdf:url ?keggUrl
?chebiDrug purl:title ?drugBankName
?chebiDrug bio2rdf:image ?chebiImage

a non-granular distribution
All

Drugbank

KEGG, ChEBI
ChEBI

where

f (P1, Gi) =

|P1|

i=1
[P1]Gi


[P1]Gi

if P1 is unconstrained
otherwise

Given the conditions on the definition of a distribution
function, it is not difficult to show that:
Theorem 5.12 Let  be a coalescent distribution func-
tion. Then the federation scheme (E, ) is sound and
complete wrt. the set of all selections of RDF graphs.

The proof is a straightforward rerun of theorem 5.5
based on generalizing the property of agnosticism so
that it reflects the E rather than the Ec rule. Since the
bulk of the work consists in proving lemma 5.11, the
rest has been omitted for reasons of economy.

A similar result can easily be shown to hold for
the property of egalitarianism, that is, there are nonegalitarian distribution functions that induce complete
federation schemes wrt. the set of all selections of RDF
graphs. Indeed, there are non-egalitarian  such that
(E, ), specifically, is complete in this sense.
To see this, let  be any coalescent distribution function and let  be exactly like , except that it also satisfies the following condition: if (P1, Gi)  (G , P )
and |P1|  2  |Gi| then (t, G)  (G , P ) for some
t  P1 and some G  Gi.

Explained in words, for every unconstrained subquery P1 of P which is assigned by  to a set Gi with
strictly higher cardinality than 1,  selects a random
triple t  P1 and assigns it as a singleton subquery
to a randomly selected dataset G  Gi. For example,
assigning the triple pattern in line 5 of table 5 as a singleton subquery to, say, ChEBI would make that distribution both non-granular and non-egalitarian. Yet, it
is entirely routine, given the results already presented,
to prove that E would still preserve zero-knowledge
completeness.

Although these examples of non-granular and nonegalitarian distribution functions are admittedly somewhat contrived, their mere existence is a fact of some
importance insofar as they prove that granularity and
egalitarianism are not necessary for completeness.
Contrapositively therefore, non-granularity and nonegalitarianism are not sufficient for incompleteness
not even in combination.

6. Some examples from the literature.

With new federation engines being developed virtually by the hour, only a small sample can be discussed
in the present section. The systems that are mentioned
are not here claimed to be representative of ones left
out. They have been selected merely because they are
described, in text, with a sufficient level of precision
to be amenable to an analysis using the concepts and
techniques developed in the preceding sections.

The primary concern of the present section is to illustrate the application of the conceptual framework
with an eye to the completeness of a federation scheme
wrt. a set of selections of RDF graphs. It is only secondarily an evaluation of existing systems, and not at all
an empirical evaluation. Specifically, none of the arguments and opinions adduced in the following are based
on testing or inspecting source code.

Yet, if the said arguments miss their mark for that
reason alone, that is if the systems discussed turn out
to behave differently than described, then one way of
looking at that fact is to take it as underlining the general theme of this paper: there is a need for a framework to allow implementation to be derived from theory rather than vice versa.

Having said that, it should be stressed that there are
many approaches to federation for which completeness legitimately is not an important property. This
applies to traversal-based federation [16,17,18,23], to
top-k query processing [25,36,38], and in general to
any approach based on the idea of probing the network

A. Stolpe / A logical characterisation of SPARQL federation

in an exploratory fashion. For such systems it is usually either not clear what completeness would be completeness with respect to, or it is simply not feasible to
attain it.

Keeping the possibility open that there are also other
valid reasons for deviating from completeness, the material that follows should not be taken as an argument
to the effect that any of the approaches being discussed
is inherently flawed.

6.1. FedX, DARQ and SPLENDID

The standard distribution has emerged as a point
of convergence between several distributed query processing engines that have been proposed in the last half
decade or so. Although one should probably be cautious about crediting any single reference with the idea,
an early comer seems to have been the DARQ system
proposed in Quilitz and Leser [31]. Later FedX [34]
and SPLENDID [13] were based on the same ideano
dependencies implied.

All these approaches share three key observations:
1) that RDF properties can be used to assign subqueries to RDF sources, 2) that if the property of triple
pattern occurs in multiple datasets, then that triple pattern must be sent as a singleton subquery to each of
datasets in question in order not to neglect cross-site
joins, and 3) if the signature of a subquery is covered
by exactly one subquery, then that subquery does not
need to be decomposed further but can be assigned to
the dataset in question as-is. These three steps taken
together amount to the standard distribution function.
It is has proved difficult to find a clear statement
of evaluation rulesthe importance of which seems
largely to be ignored. However, Schwarte et al. [34] at
least offer an example of how the Life Sciences 6 query
from the FedBench suite would be evaluated according
to their algorithm. The LS6 query is here reproduced
in table 6 which also displays the signature coverage
of each triple wrt. to the datasets KEGG, drugbank and
DBpedia. The query execution plan from [34] is given
in figure 1, with minor adjustments of notation: the
leaves are numbered according to table 6, the brackets
indicate the grouping of the sub-queries, and the @-
tag above a leaf indicates a selection against the dataset
suffixed to the tag.
There is reason to believe, however, that this execution plan contains a mistake, for the group {3, 4} is
not exclusive to drugbank and should therefore not, according to the express intents of Schwarte et al. [34],
be evaluated as a single subquery.

@drugBank

@drugBank

@drugBank

@KEGG

@DBpedia

{1, 2}

{3, 4}

{5}

{5}

{5}

Fig. 1. Execution plan for LS6 from Schwarte et al. [34].

Triple pattern 3 is ?keggDrug rdf : type kegg : Drug
whose signature is rdf : type, and that property belongs to all datasets in question. Therefore, the execution plan in figure 1 is not compatible with the standard
distribution.

However, by separating 3 from 4 and inserting the

branch

. . .


@drugBank

@KEGG

@DBpedia

{3}

{3}

{3}

somewhere below the root node of the execution tree,
the tree does instantiate an evaluation rule for the
standard distribution which is in fact the collect-and-
combine-rule Ec. It is a particular version of the Ec
rule in which joins are ordered by preference and exclusive groups come firstthere will be a few more
things to say about this in section 7.

It is reasonable to believe that it is this rule that is
intended by [34] in which case the federation scheme
proposed by FedX is (, Ec), where  is the standard
distribution. This makes FedX a zero-knowledge ap-
proach.

6.2. DEFENDER/ANAPSID

DEFENDER [28] is a query decomposition engine
that is built on top of the better known ANAPSID federator [3]. The main feature of the latter is that it adapts
query execution plans to data availability and run-time
conditions by providing physical SPARQL operators
that detect when a source becomes blocked. These operators produce answers opportunistically as soon as
data becomes available.

Given the opportunistic nature of DEFENDER that
it inherits from ANAPSID, completeness of query an-

Table 6

FedBench setup for the Life Sciences 6 query.

Nr.

Triple pattern
?drug drugBank:drugCategory drugbank-category:micronutrient
?drug drugbank:casRegistryNumber ?id
?keggDrug rdf:type kegg:Drug
?keggDrug bio2rdf:xRef ?id
?keggDrug dc:title ?title

Signature coverage
drugBank
drugBank
All

All

swering wrt. to the selected datasets is not necessarily an overriding concernthe discussion towards the
end of [28] indicates that it is not. Nevertheless, it is
natural to expect DEFENDER to at least approximate
completeness in the limiting case that the contributing
sources are sufficiently responsive. That is, it seems
reasonable to expect completeness to act as a norm
from which DEFENDER as well as ANAPSID itself
will deviate only if circumstances dictate it.

The DEFENDER decomposition algorithm is based
on evaluating so-called star-shaped query patterns, a
notion which in turn derives from Vidal et al. [37]:

Definition 6.1 Every pattern (?X, p, o) or (s, p, ?X)
such that s =?X, p =?X and o =?X is a star-shaped
pattern wrt. ?X. If P1 and P2 are star-shaped patterns
wrt. ?X and var(P1)var(P2) = {?X}, then P1P2
is a star-shaped pattern wrt. ?X.

Vidal et al. demonstrate that the two-step procedure of
evaluating star-shaped patterns jointly before merging
the result will typically be more efficient than evaluating and merging singleton triple patterns one-by-one.
DEFENDER implements this idea in a straightforward way. The relevant passage reads: [DEFENDER]
implements a greedy algorithm to group in the same
subquery the triple patterns that share one variable
and can be executed by the same endpoint. The query
decomposer begins creating single sub-queries with
triple patterns, then it merges the sub-queries that share
exactly one variable, and repeats this process until a
fixed-point is reached in the process of creating the
sub-queries [28, p. 2] .

In other words, DEFENDER assigns to each endpoint a maximal star whose signature is covered by an
endpoint. One has to be careful with the maxtalk here,
though, as the preceding sentence conceals two distinct senses: in the first sense a star P   P is maximal with respect to an endpoint G, i.e. there is no
P   P s.t. P   P  and sig(P )  sig(G). In
the second sense P  being maximal means that there
is no P  with P   P   P such there is some G

with sig(P )  sig(P ). One could call the former local maximality and the latter global maximality. The
point is that a star can be locally maximal without being globally maximal: suppose P  is maximal wrt. G
in the local sense. Then there is no strictly larger subpattern P  of P whose signature is included in the signature of G. Yet, the signature of P  may be included
in the signature of some other endpoint G, in which
case P  is not a globally maximal star.

The DEFENDER decomposition algorithm can now
be described with more precision: it decomposes a
query into globally maximal stars and assigns these
stars to each endpoint whose signature includes that of
the star. It is easy to verify that this algorithm is indeed a distribution function in the sense of definition
4.3. Table 7 shows the result of applying this algorithm
to the LS5 query from the FedBench suite. Here each
column of crosses represents a star-shaped pattern, and
the header under which it is subsumed indicates the
endpoint/dataset to which it is assigned.

Certain features of the induced distribution function can be read off from this table directly. For one,
the distribution is egalitarian: the set of endpoints that
a star is assigned to is precisely the set of endpoints
that cover its signature. Indeed, this property generalizes and is due to the fact that stars are maximal in
the global senseinterestingly, maximality in the local sense does not induce egalitarianism.

Moreover the decomposition in table 4.3 is granular
too: every subquery is either a singleton or assigned to
a singleton. Yet, this is incidental to the example: to see
this, add another dataset encoded in, say, the ChEBI
vocabulary to the datasets over which the LS5 query is
distributed, call the two ChEBI datasets ChEBI 1 and
ChEBI 2. In terms of the decomposition algorithm this
has the effect of copying the stars assigned to ChEBI 1
into the columns of ChEBI 2 yielding the distribution
in table 8 which is not granular since the non-singleton
pattern consisting of row 5 and 6 is assigned to both of
the ChEBI sources.

Note that column-copying, which corresponds to the
distribtuion of a query over a set of sources some of

A. Stolpe / A logical characterisation of SPARQL federation

Distribution of LS5 over KEGG, ChEBI and Drugbank according to DEFENDER.

Table 7

Maximal stars

Nr.

Triple pattern
?drug rdf:type drugbank:drugs
?drug drugbank:keggCompoundId ?keggDrug
?drug drugbank:genericName ?drugBankName
?keggDrug bio2rdf:url ?keggUrl
?chebiDrug purl:title ?drugBankName
?chebiDrug bio2rdf:image ?chebiImage

ChEBI


Drugbank


which have the same signature, is not a far-fetched
possibility. Relating to the example, ChEBI is part of
the Open Biomedical Ontologies effortan effort to
create controlled vocabularies for shared use across
different biological and medical domains. Indeed, the
eventuality of multiple sources encoded in the same
vocabulary is arguably both a desirable and an inevitable feature of the Semantic Web.

By the results of subsection 5.2, the non-granularity
and unegalitarianism of a distribution function is not
sufficient warrant to conclude that a federator is incomplete wrt. to the set of all selections of RDF
graphs. Nevertheless, for DEFENDER this turns out to
be so:
Example 6.1 Put G1 := {(s1, p1, o1), (s2, p2, o2)},
G2 := {(s2, p1, o1), (s1, p2, o2)} and G := {G1, G2}.
Consider the star-shaped pattern P := {(?X, p1, o1),
(?X, p2, o2)}. The DEFENDER distribution function
assigns the whole of P to both G1 and G2,
i.e.
(G , P ) = {(P, G )}. By definition 3.4 [P ]G =

PG1 PG2 butPG1 PG2 =  so [P ]G = .
Yet, PG1G2 contains two answers 1(?X) = s1
and 2(?X) = s2. Hence [P ]G =PG .
PG , but the example in fact shows more: Since
PG1 = PG2 = , no subsequent manipulation

It follows immediately that Ec((G , P )) = [P ]G =

of these sets will suffice to extract a complete answer
from G . It follows that the DEFENDER distribution
is not complete wrt. the set of all selections of RDF
graphs given any evaluation rule E that manipulates
only the cells of the distribution it receives as an ar-
gument. Thus, if ad hoc evaluation rules are excluded,
it follows that DEFENDER is zero-knowledge incomplete essentially.

6.3. ADERIS

The Adaptive Distributed Endpoint RDF Integration System (ADERIS) from Lynden et al. [24] is an-

other example of an adaptive distributed query proces-
sor. That is, ADERIS seems to have a principal design
goal that is similar to that of DEFENDER/ANAPSID,
namely to have join-orderings change during query execution as a means of continual refinement and optimization of the execution plan at run-time.

ADERIS too is a distributed query processing system in the sense described in section 2, which means
that it relies on a decomposition algorithm to distribute
subqueries to contributing sources.

The ADERIS decomposition algorithm is rather different from that of DEFENDER, however, and is based
on generating for each data source, a source query (...)
that contains all of the triple patterns from the federated query that could possibly match the triples in the
given data source [24, p. 182]. Unlike Montoya et al.
[28], Lynden et al. [24] state explicitly that completeness is a property they wish the decomposition algorithm to have: Source queries are constructed for each
of these data sources, with the aim of retrieving all the
data needed to answer the query (p. 181).

In mathematical terms, the ADERIS distribution
translates to a function which for every RDF source
G  G and a BGP P assigns the set of triples t  P
whose property occurs in G to G. That is, the ADERIS
distributions consists of pairs ({t  P | sig(t) 
sig(G)}, G). Again, it is easy to verify that this relation is a distribution function in the sense of definition
4.1.

Table 9 shows the result of applying the ADERIS
distribution to the LS5 example. This particular de-
composition, like that in table 9, is granular but not
egalitarian. This time it is the group consisting of line
4 and 5 that constitutes the counterexample to egalitar-
ianism: since the signature of this group is covered by
both KEGG and ChEBI, egalitarianism dictates that it
be assigned to both, which it is not.

The parallel extends further, for granularity is again
incidental in precisely the same sense as for the distribution in table 7, i.e. non-granularity can be shown

Distribution of LS5 over ChEBI 1, ChEBI 2, KEGG and drugbank according to DEFENDER.

Table 8

Nr.

Triple pattern
?drug rdf:type drugbank:drugs
?drug drugbank:keggCompoundId ?keggDrug
?drug drugbank:genericName ?drugBankName
?keggDrug bio2rdf:url ?keggUrl
?chebiDrug purl:title ?drugBankName
?chebiDrug bio2rdf:image ?chebiImage

Maximal stars

ChEBI 1

ChEBI 2


Drugbank


Table 9

Distribution of LS5 over KEGG, ChEBI and Drugbank according to ADERIS.

Nr.

Triple pattern
?drug rdf:type drugbank:drugs
?drug drugbank:keggCompoundId ?keggDrug
?drug drugbank:genericName ?drugBankName
?keggDrug bio2rdf:url ?keggUrl
?chebiDrug purl:title ?drugBankName
?chebiDrug bio2rdf:image ?chebiImage

ChEBI


Drugbank


by column-copying. Moreover, ADERIS and DEFENDER are in complete agreement wrt. to example
6.1 insofar as they both yield the same distribution. It
follows that the ADERIS too is incomplete wrt. the
set of all selections of RDF graphs for any reasonable
choice of evaluation rule E.

6.4. AVALANCHE

The AVALANCHE system is a query answering
system for the Semantic Web that, in the words of
Ba sca and Bernstein [6], is designed to embrace the
WWW uncertainties rather than to try to dispense with
them. According to Ba sca and Bernstein, this means
querying the Semantic Web without making any prior
assumptions about the data location or distribution,
schema-alignment, pertinent statistics, data evolution,
or accessibility of servers [6, p. 2].

This is not to say, though, that AVALANCHE is a
zero-knowledge federator in the present sense of the
termit is not. It merely means that AVALANCHE
does not utilize prior information about the availability of endpoints, their schemas and/or their statistical characteristics. Rather AVALANCHE is designed
to produce that information as part of an execution
pipeline whose overall purpose is to answer an incoming query.

In the general case, AVALANCHE, like ADERIS
and DEFENDER/ANAPSID, is opportunistic: it is de-

signed to deliver partial results as they become avail-
able, favouring those that are easier to assemble. Like
the other two approaches it relies on cost-reducing
heuristics that adjust to the current computational envi-
ronment, but it also relies on heuristics that is applied
to query planning regardless.

For instance, the AVALANCHE query planner restricts the search for an optimal plan by considering
only those distributions that assign a triple pattern to
exactly one source (henceforth this will be called the
single-source restriction). That is, the plans that are
considered are such that a triple pattern will never be
executed against more than one RDF dataset.

Ba sca and Bernstein [6, listing 2, page 7] illustrate
this decomposition algorithm by giving an example
distribution of the LS5 query reproduced here in table
10 (note that the example assumes the bio2rdf : image
property to belong to the signature of KEGG as well).
It is immediate by inspection of the table that this
particular decomposition is granular. This time granularity is not an incidental property of the example but
a consequence of the single-source restriction. Equally
obviously, and for the same reason, AVALANCHE is
not egalitarianviz. row 6 is assigned only to KEGG
although it is also covered by ChEBI.

In fact, AVALANCHE like DEFENDER/ANAPSID
and ADERIS, can easily be seen to be incomplete wrt.
to the set of all sets of RDF graphs for any reasonable
choice of evaluation rule E. Again example 6.1 suffices

A. Stolpe / A logical characterisation of SPARQL federation

Table 10

Distribution of LS5 over KEGG, ChEBI and Drugbank according to AVALANCHE.

Nr.

Triple pattern
?drug rdf:type drugbank:drugs
?drug drugbank:keggCompoundId ?keggDrug
?drug drugbank:genericName ?drugBankName
?keggDrug bio2rdf:url ?keggUrl
?chebiDrug purl:title ?drugBankName
?chebiDrug bio2rdf:image ?chebiImage

ChEBI


Drugbank


to show this: if, relating to this example, the singlesource restriction is to be observed, then the the distribution needs to choose to evaluate the BGP P1 against
exactly one of the datasets G1 and G2. It should be
clear that no matter which one is chosen, the result set
will be empty, whence no subsequent manipulation of
result sets will be able to extract a complete answer.

As an afterthought, it is instructive to contrast this
conclusion with the discussion of the homonymous notions of completeness in [6] itself: it cannot be the
aim of AVALANCHE to deliver global completeness,
Ba sca and Bernstein argue, if a globally complete answer is understood as one that comprises all answers
to a query that is to be had on the entire Web. How-
ever, considering only the datasets that are selected for
the query answering process, so the argument goes, it
is natural to aim for query-contextual completeness, by
which is meant that the answer is complete wrt. the set
of selected datasets if none of them go down or become unavailable. If the query execution process is not
stopped, [6, p. 4] claim, AVALANCHE is eventually
complete in the query-contextual sense.

This notion of query-contextual completeness does
not coincide with the formal notion of completeness
promoted in this paper, according to which all answers
that are contained by the union of the contributing
datasets are always obtained by the federator.

6.5. Discussion

The preceding discussion cannot pretend to do justice to the systems discussed. They are all much
broader in scope and ambition than the narrow focus
on completeness suggests, covering besides a plethora
of interesting and important topics such as adaptiv-
ity, opportunism, indexing, join-order optimization,
statistics-generation and more.

As to the question of the significance of completeness itself, a two-fold answer is probably most ap-
propriate: from a pragmatic point of view completeness is essentially subservient to user needs. An in-

complete answer that returns in reasonable time is usually preferable to a complete one that makes excessive
demands on time and memory.

Looked at from a theoretical perspective, however,
a completeness result offers an exhaustive characterisation of the behaviour of a federation scheme. Being
complete wrt. a set of selections of RDF graphs, entails being incomplete wrt. to its complement. Knowing how a federator behaves is knowing the conditions
under which it crosses this line. In working out these
conditions one is effectively giving an account of when
a federation engine will miss answers and why.

As argued throughout this paper, an exhaustive characterisation of a federation strategy is obtained by turning three knobs: the way a query is decomposed into
sub-queries, the way the partial answers are subsequently combined, and the way that a selection of RDF
graphs is chosen for federation.

Depending on how much one turns one knob, it
may not have any effect turning another. For instance,
example 6.1 has shown that the DEFENDER/ANAP-
SID, ADERIS and AVALANCHE distribution functions are incomplete wrt. to the set of all selections
of RDF graphs for all reasonable choices of evaluation rule E. Thus, the only way to obtain an exhaustive
characterisation of these systems behaviour is to constrain the selection of RDF datasets to the point where
it matches the federation scheme. Although, this intersection point may be too restrictive to adhere to in
practise, characterising it will serve to make assumption about the structure, content, and relationship between contributing RDF sources explicit. Examples of
what these assumptions may amount to are: do the contributing sources have disjoint sets of subjects and/or
objects? Do they have disjoint signatures? Can all subjects be assumed to be typed? Can the RDF graphs be
assumed to conform to some predefined schema, pattern or shape (cf. Ryman et al. [32])? And so on and so
forth.

Needless to say, there is large variety of ways in
which a set of selections of RDF sources can be con-

strained in this manner, and therefor also a large number of distribution schemes to match.

1. d is a bijection between L(d) and 
2. if out(x) > 1 then d(x) = 

7. A corollary wrt. join-order heuristics

The account of distributed query processing given
so far is entirely abstract and declarative, and it is far
from obvious how one would move towards the implementation level from the theory. As a stepping stone,
this section operationalizes the distribution semantics
by showing how to fit a federation scheme into a joinordering in order to obtain an execution plan for a
given distribution that is provably sound and complete.
Attention is restricted to zero-knowledge completeness
and the collect-and-combine rule.

A join-ordering will be represented as usual as an
operator tree, based on the following definitions from
[15]:
Definition 7.1 (Tree domain) A tree domain D is a
non-empty subset of the set of all strings N over the
natural numbers, satisfying the following conditions:
1. For each u  D every prefix of u is also in D.
2. For each u  D and i  N, if ui  D then for

every j, 1  j  i, uj  D.

Given a tree domain D the relation x  y denotes the
prefix relation on strings of D. The covering relation
x  y is defined by stipulating that if x  y and x 
z  y then either x = z or z = y.
Definition 7.2 Given a set  of symbols, a tree over 
is a function d : D   where D is a tree domain.
Definition 7.3 (Subtrees) Given a tree d and a node
u in dom(d), the subtree rooted at u is the tree d/u
whose domain is the set {v : uv  dom(d)} and such
that (d/u)(v) = d(uv) for all v in dom(d/u).

Every element of a domain D of a tree d will be called
a node of d. The outdegree out(u) of a node u is the
cardinality of the set {i : ui  dom(d)}. A node u
with out(u) = 0 is called a leaf. The leaves of d are
denoted L(d). Indegrees are defined as in(u) = {i :
iu  dom(d)}. Of course all nodes in a tree have indegree equal to 1 except one, the root, which has indegree
zero. If d is a tree, r(d) denote the root of d.
Definition 7.4 (Ordered distribution) Let  be a
distribution. A join-ordering of  is a tree d over
{}   such that:

Definition 7.4 represents a generalisation of the usual
notion of the join-ordering of a BGP. It is a generalization in the sense that the carrier set of the poset is not
a set of triples but a distribution, that is, itself a set of
BGPs.

In computational terms it is natural to see this generalization as an adaptation in which the join-ordering
also distributes the responsibility for executing joins: a
distribution assigns a subquery of a global query to a
set of contributing sources. If the subquery in question
contains more than one triple patternwhich will be
the case if it is e.g. an exclusive groupthen the subquery is handed over to the contributing sources along
with the responsibility for executing the joins involved.
It should be fairly obvious how to relate definition

7.4 to the completeness results from section 5:

1. [P ]G if dom(d) contains a single leaf x such that

Definition 7.5 (Evaluation) The evaluation of an or-

dered distribution d, writtend, is
2. otherwise it is the application of r(d) tod/y1
andd/y2 for i  [1, 2]

d(x) = (P, G )

We have:

Corollary 7.1 Let  be either of the even-, standardor prudent distributions and suppose it is defined at
G and P . Let d be a join-ordering of (R, P ). Then

d = Ec((G , P )).
have that d =  (d(L(D)). Therefore, since we
thatd = Ec((G , P )) as desired.

Proof By definition 7.4(2) and definition 7.4(2) we

have d(L(d)) = (G , P ) by definition 7.4(2) it follows

None of this is surprising, which is why it is presented
as a corollary.

Nevertheless there are a couple of things to note:
First, the unit of heuristic significance in a distributed
setting is the subpattern, not the triple pattern, and all
subpatterns are by default equally privileged. That is,
there is no constraint on the shape of a tree that dictates
that e.g. exclusive groups be processed first. As hinted
at in subsection 6.1, this contrast with how evaluation
is performed by e.g. FedX where exclusive groups are
given priority based on the claim that they are usually
more constrained than singleton triple patterns [34, p.
607].

A. Stolpe / A logical characterisation of SPARQL federation

This is probably true, but it is not necessarily so.
Heuristic rules that do not rely on statistics will usually determine a priority ordering between patterns by
analysing their lexical form. Typically the heuristic
value of a single triple will be determined by assessing how selective that triple pattern is relative to oth-
ers. For instance a pattern of form (?X, p, o) can
plausibly taken to be more constrained than (?X, p,
?Y) and so forth, whereas the heuristic value of a join
t1  t2 will be determined by ranking the position and
number of shared variables involved (cf. [35]). There
is no a priori reason why such a procedure, generalised from triple patterns to BGPs in the obvious man-
ner, should assign a higher accumulated heuristic value
to an exclusive group, say. On the contrary it is not
too difficult to come up with intuitive counterexamples
that involve exclusive groups with a high variable to
term ratio and a small number of joins, being ranked
below a single triple pattern with an instantiated subject and object.

The second thing to note, is the generality of the
collect-and-combine rule which yields sound and complete heuristics for each of the even-, standard and
prudent distributions in one fell swoop. Indeed, one
may speculate that there is little reason for employing a different evaluation rule with these distributions
functionsor, at any rate, at least in the zero knowledge case. If there were, then it would be for heuristic reasons. However, in the absence of detailed knowledge about the contributing sources there seems to be
no reason to think that some other particular evaluation
order would do better than the collect-and-combine
rule. Whilst evaluating the two pairs ({t1, t2}, Gi)
and (t3, Gj), say, by distributing joins over unions
([t1]Gi  [t3]Gj )  ([t2]Gi  [t3]Gj ) would preserve
completeness, the lexical form alone of the patterns involved does not lend support to this evaluation procedure over the collect-and-combine rulenor vice
versa of course.

8. Conclusion

This foundational study has provided some first
steps towards a logical framework for reasoning about
distributed query processing in SPARQL in a formal
manner. The analysis is based on the general idea of
correlating a syntactic object consisting of a distribution function and an evaluation rule with a semantic
object consisting of a family of sets of RDF graphs,

each one of which represents an eligible selection of
sources for the federation process.

The combination of granular and egalitarian distributions function with the collect-and-combine evaluation rule has emerged as a trait that induces completeness in a zero knowledge computational environment
for several natural examples of distribution functions,
including the standard distribution, so-called, which
occurs frequently in the literature.

Federation schemes have a simple and transparent interface towards the heuristic notion of a joinordering of a query. This interface connects execution
plans to soundness and completeness results in a manner that makes it evident that whole classes of execution plans preserve these properties.

An interesting line of future research would be to investigate natural candidates for some-knowledge federation schemes, and to furnish them with completeness results by restricting the set of eligible selec-
tions. This should include a characterization of existing some-knowledge approaches. For instance; what
needs to be assumed about the distribution of data over
a selection of RDF datasets for a distribution scheme
based on maximal stars in the manner of Vidal et al.
[37] to be complete? Or, are there any established resource shapes [32] that could be analysed this way?
This ought to be a rich field for future work.
Acknowledgements. The author is grateful to Carlos
Buil-Aranda, Jurgen Umbrich, and one other anonymous reviewer for constructive criticism and insightful questions regarding earlier drafts of this paper. The
author also wishes to thank Jonas Halvorsen and Bjrn
Jervell-Hansen for stimulating discussions leading up
to and advancing the present line of research.
