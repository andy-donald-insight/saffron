Opportunistic Linked Data Querying Through

Approximate Membership Metadata

Miel Vander Sande(B), Ruben Verborgh, Joachim Van Herwegen,

Erik Mannens, and Rik Van de Walle

Multimedia Lab, Ghent University  iMinds,

Gaston Crommenlaan 8 Bus 201, 9050 Ledeberg-Ghent, Belgium
{miel.vandersande,ruben.verborgh,joachim.vanherwegen,

erik.mannens,rik.vandewalle}@ugent.be

Abstract. Between uri dereferencing and the sparql protocol
lies
a largely unexplored axis of possible interfaces to Linked Data, each with
its own combination of trade-offs. One of these interfaces is Triple Pattern
Fragments, which allows clients to execute sparql queries against lowcost servers, at the cost of higher bandwidth. Increasing a clients
efficiency means lowering the number of requests, which can among
others be achieved through additional metadata in responses. We noted
that typical sparql query evaluations against Triple Pattern Fragments
require a significant portion of membership subqueries, which check the
presence of a specific triple, rather than a variable pattern. This paper
studies the impact of providing approximate membership functions, i.e.,
Bloom filters and Golomb-coded sets, as extra metadata. In addition
to reducing http requests, such functions allow to achieve full result
recall earlier when temporarily allowing lower precision. Half of the tested
queries from a WatDiv benchmark test set could be executed with up
to a third fewer http requests with only marginally higher server cost.
Query times, however, did not improve, likely due to slower metadata
generation and transfer. This indicates that approximate membership
functions can partly improve the client-side query process with minimal
impact on the server and its interface.

Keywords: Linked data  Querying  Availability  Scalability  sparql

1 Introduction

For a long period of time, querying Linked Data has been a story of two extremes,
with Linked Data documents on the one side and the sparql protocol on the
other. Currently, neither of them is able to drive real-world applications on
the Web. On the one hand, public sparql endpoints are limited in number
and suffer from frequent downtime [4,22]. Their resource consumption is hard to
predict, caused by the expressiveness of the language and individual user demand.

For Johan De Smedt. Thanks to Daniel P. Miranker for his suggestions on Bloom
filters.

c Springer International Publishing Switzerland 2015
M. Arenas et al. (Eds.): ISWC 2015, Part I, LNCS 9366, pp. 92110, 2015.
DOI: 10.1007/978-3-319-25007-6 6
?

?

?
This downtime results in insufficient reliability for client applications. Linked
Data documents, on the other hand, are more predictable, but link-traversal-
based query methods are significantly slower and result sets have varying levels
of completeness, both of which are undesired traits for user applications. The
issues with these two query solutions hint at a need for other client/server trade-
offs.

Linked Data Fragments (ldf) [25] aim to analyse such trade-offs by proposing
an uniform view on all interfaces to rdf. This reveals a complete spectrum
between Linked Data documents and the sparql protocol, in which the state-
of-the-art of Linked Data publishing can be advanced. This axis can be explored
in the following two dimensions.
 Selector: allowing different, more complex questions for the server
 Metadata: extending the response with more information clients can use

In prior work, Triple Pattern Fragments (tpf) [25] were introduced as an
alternative api with low-server cost. This interface offers a single triple pattern
as selector and includes an estimated number of total matching triples as meta-
data. sparql queries can be evaluated client-side by combining several tpfs,
using the metadata for optimization. Higher query execution time and more
bandwidth are accepted in exchange for a small load on the server, thereby
striking a more sustainable load balance between client and server. Recently, an
algorithm that reduces bandwidth was proposed within the same server restrictions [23]. Another direction for improvement is to have servers support other
features along the selector and/or metadata dimensions in addition to tpf.

In this paper, we explore the metadata dimension by adding approximate
membership functions (amf) as a composable feature for Linked Data Fragments apis. An amf is a space-efficient data structure that is able to indicate
whether a set contains an item. False positives can occur with a fixed probability,
but false negatives can not. This work studies their applicability as a server-side
feature in addition to tpf, in order to reduce the number of http requests during client-side sparql query execution. We study two different amf techniques:
Bloom filters [3] and Golomb-Coded Sets (gcs) [19]. Concretely, we present i) an
in-depth comparison between different client-side algorithms with or without
Bloom and gcs; ii) a vocabulary to describe approximate membership functions
as metadata for self-descriptive apis; iii) an evaluation of opportunistic querying,
where we strive for result completeness first and validate their correctness later.
First, we present the preliminary concepts and related work in Section 2.
Then, we discuss the motivation, research questions and hypotheses for this
work in Section 3. Next, Section 4 shows how the tpf interface is extended with
amf metadata. After that, we demonstrate how the client benefits from this in
Section 5, and how it enables a more opportunistic form of querying in Section 6.
Finally, we evaluate the query algorithms with and without amf metadata in
Section 7, and conclude in Section 8.

M. Vander Sande

2 Core Concepts and Related Work

2.1

SPARQL Query Evaluation Using Traditional Web APIs

Linked Data can be published on the Web using different apis, of which
data dumps and sparql endpoints are highly common [5]. The Linked Data
Fragments conceptual framework [25] enables the analysis and comparison of
Web apis by abstracting each api according to how it provides access to parts
of a certain dataset. Each such part is called a Linked Data Fragment (ldf),
which consists of data, metadata, and controls. The data is a set of those triples
of the dataset that match a given interface-dependent selector. The metadata
set consists of triples that describe the dataset and/or the current fragment or
related fragments. Finally, the controls are hypermedia links and/or forms that
allow clients to retrieve other fragments of the same or other datasets.

Both data dumps and sparql endpoint responses can be considered ldfs.
A data dump of a dataset employs all triples in that dataset, usually in a compressed archive, as the data. The metadata set contains data such as publication
date and/or license. No controls are present, because all available data is contained within the archive. The main drawback of dumps that they cannot be
queried live: they need to be downloaded in their entirety to evaluate queries.
The sparql protocol [6] exposes rdf graphs on the Web using the sparql
query language [10]. Each response to a CONSTRUCT or DESCRIBE query can be seen
as an ldf, where the data consists of the rdf triples in the dataset that match
the query. The metadata and control sets are empty; controls are implicitly in
the sparql protocol. An advantage of sparql endpoints is their expressiveness:
clients can ask very specific questions about a dataset. However, public sparql
endpoints suffer from a two-sided availability problem: the majority of datasets
is not published as a sparql endpoint (543 opposed to 9960 datasets)1, and
endpoints that are on the Web experience frequent downtime [4].

2.2

SPARQL Query Evaluation Using Triple Pattern Fragments

In addition to describing existing interfaces, ldf also allows defining new interfaces with different characteristics. The Triple Pattern Fragments (tpf) interface [24,25] combines the desirable characteristics of data dumps (low server-side
cost) and sparql endpoints (live queryable). Clients can ask a server for triple
patterns; in response, the server sends a tpf, consisting of the triples of the
dataset matching the triple pattern (paged to keep the fragment size reasonably
small), metadata expressing the total number of matching triples, and controls
to retrieve all other tpfs of the same dataset. Complex sparql queries are
evaluated by clients, which split a query into triple patterns and use the metadata in fragments to determine an efficient execution order. The advantage of
tpfs is that they only require low processing power on the server side, and are
thus less expensive to host with high availability [25]. The drawback is that

1 http://stats.lod2.eu
?

?

?
sparql queries have longer query times than on a sparql endpoint. More than
600,000 crawled rdf files are available as tpfs through the lod Laundromat [21].
dbpedia, arguably the most well-known dataset on the Semantic Web, has an
official tpf interface with 99.999% availability [26].

tpfs move the query planning problem to the client. It is up to the client to
make optimal use of metadata exposed by the server. The originally proposed
query planning algorithm is greedy [25]. Assuming a Basic Graph Pattern (bgp)
query, the client downloads results for the triple pattern with the lowest cardi-
nality, based on the count metadata. Possible mappings for each resulting triple
are bound to each remaining pattern, of which the one with lowest cardinality
is subsequently requested from the server.

Van Herwegen et al. improve the greedy algorithm [23], aiming to minimize
the number of http calls by making global instead of local decisions. This is
achieved by downloading two triple patterns separately in case this requires fewer
http calls. Multiple estimation techniques, based on the intermediate results of
the algorithm, are used to predict which query path is least expensive. If the
current path is suboptimal, the algorithm continues from the new path. This
decrease in http requests results, however, in more computational work for the
client because of the more complex join process.

This paper seeks to provide an optimized balance between server-side cost
and query execution time by extending the tpf interface with additional meta-
data, as we will discuss in Sections 4 to 6. The goal is to maintain a low perrequest cost for the server, while reducing the number of requests clients need
to execute to evaluate typical queries.

2.3 Approximate Membership Techniques
In the following, we summarize the Approximate Membership Function (amf)
families of Bloom filters and Golomb-Coded Sets. Both offer approximate membership assessment with a predefined false positive probability, but with different
size and speed. Recall and precision are important parameters of an amf f. Given
the set of actual members M and a set of elements T for which we want to test
membership, the set of positively tested elements PT = {t  T : f(t) = true}.
We define recall f (T ) = |M  PT|/|M| and precision f (T ) = |M  PT|/|PT|. Both
Bloom filters and Golomb-Coded Sets have 100% recall, i.e., all valid members
of M will always be identified, but less than 100% precision.
Bloom Filters. A Bloom filter [3] is a bitmap of m bits populated using k
different hash functions, initialized with all bits set to 0. An item is added by
calculating k locations in the bitmap, which are set to 1. Each one is calculated
by using a different hash function to ensure randomness. An item can be tested
by calculating k locations using the same hash functions. Hence, both insertion
and testing are O(k). The result of a bit-wise AND of those locations in the filter
determines if the item is a member. If false, the item is definitely not in the set.
If true, the item might be in the set, because of false positives.
proportional to its number of members n. The required size is m = n  log2

For a desired false positive probability rate p, the bit-size of a Bloom filter is
e 

M. Vander Sande

log2
p. For a given m, the optimal number of hashes k that minimizes false
positive probability can be calculated with k = m/n ln 2. Despite their compact
representation, their size can be too large for network transfer. A solution is using
compressed Bloom filters [15], at the cost of compression and decompression
delays.
Golomb-Coded Sets. Golomb-coded sets (gcs) [19] provide a cleaner variation of compressed Bloom filters. The outputs of a single hash function are
considered a uniformly distributed list of values instead of a bitmap. The differences between all values form a geometrically distribution with a parameter p.
Golomb-coding is applied since it is an optimal encoding for discrete geometric
distributions [8].
In terms of size, gcs approaches the theoretical minimum of m = n  log2
p
more closely than the equivalent Bloom filter. Compared to compressed Bloom
filters, gcs have a minimal size overhead for the same p, but they are more
easily chunked and indexed to deal with uncompressed size issues. Compared to
plain Bloom filters, the query time is magnitudes slower due to decompression.
However, this drawback can be minimized by including an index to quickly find
areas of interest in the filter.

2.4 Query Evaluation with Approximate Membership

In the context of rdf querying, approximate membership functions are included
in several related works, covering i) query routing in networks, ii) selectivity
estimation for optimizing joins, iii) evolutionary querying, and iv) local database
indexes.

Query routing applies Bloom filters in caches and indexes for peer-to-peer,
MapReduce or cloud clusters, and Linked Data networks. Most systems [7,14,20]
construct a data summary of neighboring nodes or clusters to make a query
forwarding decisions. Some algorithms exchange these filters between nodes to
maintain their network [11]. This is common in combination with Distributed
Hash Tables (dht) [11,27], where a dht is used for data routing and Bloom
filters for efficient communication between nodes.

More directly applicable is selectivity estimation of query patterns, e.g., graph
patterns, to improve join performance. One approach is to group different chain-
patterns, i.e. two distinct triple patterns connected by a single variable, according
to their frequency [13]. A Bloom filter tests in what frequency group a chain
pattern resides, which optimizes the pattern execution order. Other applications
include representing equivalent classes to optimize hash joins, ranges of values
for merge joins [16], and distributed n-way joins [2]. Although these works inspire
future directions, many require more than a single triple pattern and have high
demands for the server. Highly relevant is the proposal to extend the ask query
response [12] with combinations of bindings, i.e. two variables in a triple pattern,
to improve source selection in sparql query federation frameworks. Bloom filters
from different sources indicate overlap and save redundant requests. However, the
benefit in a single-server setup is unclear.
?

?

?
Evolutionary querying is an alternative way of sparql query processing. Possible solutions are first guessed, and then incrementally refined. Oren et al. use a
combination of fingerprinting and Bloom filters to rapidly evaluate approximate
answers against large rdf datasets [17]. Although this is a centralized solution,
it advocates anytime answers, which is in line with the opportunistic querying
presented in this paper. The algorithm is initiated with random values, which
returns initial results fast, but with low accuracy.

Finally, in the area of databases, Bloom filters are an efficient technique to
prevent unnecessary disk access [18]. In such cases, the size of the filter and its
impact on transfer delays are not applicable.

3 Problem Statement

3.1 Analysis of Query Execution Using Triple Pattern Fragments

The required time for a client evaluate certain sparql queries against tpf interfaces can still be unacceptable for responsive applications. A dominant factor
in this time is the high number of http requests. Therefore, by analyzing the
nature of these requests, we can locate possible areas for changing the clien-
t/server trade-offs in the interface. To this end, we executed sample sparql
queries from the WatDiv benchmark [1] against a tpf interface using the greedy
algorithm [25]. WatDiv consists of 20 query templates grouped in four categories,
namely linear (L), star (S), snowflake-shaped (F) and complex (C).2

The execution logs revealed a high number of requests for triple patterns
without variables, i.e. testing the membership of a specific triple in the dataset.
The templates L2, L4, and F3 respectively produced 50%, 51% and 74% membership subqueries. For S5, F5, C1, and C2, this proportion even reached 95% to
98%. Furthermore, the absolute number of requests of some of these templates is
high (e.g., F3 needed 1,335 membership subqueries). A third of query templates
is thus affected; the remaining 13 templates produced no membership subqueries
at all. While these numbers do not allow generalized conclusions, they are certainly an important indication that a reduction of membership subqueries can
have a considerable influence on the number of http requestsand thus the
overall query execution time.

3.2 Research Questions and Hypotheses

In the tpf interface, metadata is crucial for clients to evaluate sparql queries
efficiently. By estimating the total number of matches per triple pattern, patterns with higher selectivity can be followed first [23,25]. If we augment this
metadata, clients might be able to make more informed decisions and hence
reduce the number of membership subqueries required to evaluate a sparql

2 The 20 WatDiv templates are graphically displayed at http://db.uwaterloo.ca/
watdiv/basic-testing.shtml. Note that the number of templates per category does
not necessarily reflect actual query distributions for specific datasets.

M. Vander Sande

query, at the cost of higher per-request costs. This paper studies the impact of
adding approximate membership functions to fragments in order to reduce the
amount of http requests. In this regard, we pose the following research question:
Question 1: To what extent can approximate membership metadata for tpfs
reduce the number of http requests necessary to evaluate sparql queries?
Probabilistic queries also enable new ways of generating results: uncertain results
can be returned early, and validated later on. We investigate this as follows:
Question 2: To what extent can approximate membership metadata for tpfs
reduce the time to achieve complete recall of sparql query results?
Adding such metadata requires amfs to be generated on the server side, the
impact of which should be investigated:
Question 3: What is the overhead of generating approximate membership metadata on the server cpu load at runtime?
The answers to these questions validate our exploration of the metadata dimension using amfs. Concretely, we test the following hypotheses about the effectiveness of an interface I, which adds an amf feature to the baseline tpf interface I.
First, given the presence of amfs, the client should be able to omit a portion of
requests over http, hence:
Hypothesis 1: The number of http requests required to evaluate minimum a
third of the WatDiv queries against I can be significantly reduced.
Next, as stated above, the reduction in http requests has a direct impact on
the overall execution time, thus:
Hypothesis 2: The time to achieve complete recall when executing WatDiv
queries against I is significantly reduced on average.
Finally, we do not expect much extra load on the server, since an amf using a
non-cryptographic hash function can be computed fast:
Hypothesis 3: The interface I increases server cpu usage only slightly compared to I for the same queries.

4 Extending the TPF Interface with AMF Metadata

The tpf interface responds with rdf documents and is self-descriptive [25],
meaning that i) extensions to the tpf interface are features of a composable
api, ensuring backward-compatibility; ii) clients can discover at runtime which
features are supported. Therefore, servers can add an interface feature, e.g., amfs
as extra metadata, without any interference. This section introduces a generic
ontology to express membership functions such as amfs, followed by its implementation as a feature on top of the tpf interface.

We created a membership modeling ontology, which we publish and maintain
at http://semweb.mmlab.be/ns/membership and denote with the prefix ms in
?

?

?
the remainder of this paper. It defines ms:Function for generic functions and
its subclasses ms:ApproximateMembershipFunction and ms:HashFunction. To allow
for Bloom filters and Golomb-coded sets, the former has ms:BloomFilter and
ms:GolombCodedSet as subclasses. Finally, ms:hashFunction associates instances
of these classes with hash functions that can be instances of algorithms such
as ms:MD5 or ms:MurmurHash3.

Using this ontology, we define an interface feature that provides amf metadata in the metadata graph of responses. In regular tpfs, each fragment contains
a void:triples statement expressing the approximate total number of triples in
the dataset that match the tpfs triple pattern [24]. For instance, each page of
the tpf for the pattern ?x rdf:type foaf:Person contains a metadata triple
stating there are 96,300 matching triples in the dataset. Given a page size of
100 data triples, these data triples would be spread across 963 pages. Suppose
that during the execution of a certain sparql query, the client arrives at a list of
215 potential mappings for ?x rdf:type foaf:Person. In order to verify with
a minimum number of http requests whether these mappings are valid, the
215 tpfs for the corresponding triples need to be downloaded, checking which
mappings result in a triple that exists within the dataset.

By defining an interface feature that allows this fragment to contain an
results
amf, the clients can determine approximately whether a certain ?x
in a triple of the dataset. Listing 1 shows an example amf for the triple pattern ?x rdf:type foaf:Person. In this case, it is a Bloom filter with two specific Murmur functions as hash functions. The hash functions themselves are
not detailed in the listing, but their parameters need to be explicitly available
(either in the response or by dereferencing their URL). Listing 1 explicitly specifies that the members of the collection are the triples of the fragment, and
that the amf has been built by using the subject of these triples. This allows
the client to interpret how exactly this amf can be used. For instance, if the
triple dbp:Elvis_Presley rdf:type dbo:Artist is part of the dataset, then the
full uri of dbp:Elvis_Presley must yield a positive value in the membership
function. Note that the false positive rate is also specified, allowing a client to
estimate the certainty of each result. Finally, the amf data itself has been made
available in base64-encoded form.

This metadata allows a client to unambiguously recreate the amf and verify
the approximate membership of elements. Note that this self-descriptive approach does not require a contract between the client and the server, e.g., no hash
function has to be agreed upon silently. Furthermore, clients that do not use
this metadata feature, such as the original tpf client [25], will not be affected by
it and can thus continue to use the interface. It is up to the servers discretion
whether or not to provide an amf on a page. If it is present, an amf-aware client
can use it; if not, the original algorithm without amfs can be followed. This lets
the server choose freely what metadata to includebased on, for instance, the
computational effort to create the amf.

M. Vander Sande

<#metadata> foaf:primaryTopic <#fragment>.
<#metadata> {

<#fragment> void:triples 96300.
_:membershipFunction a ms:BloomFilter; # AMF metadata

# existing count metadata

ms:hashSize 524288;
ms:hashFunction <MyMurmur1>, <MyMurmur2>;
ms:memberCollection [

ms:sourceCollection <#fragment>;
ms:projectedProperty rdf:subject

];
ms:falsePositiveRate 0.05;
ms:falseNegativeRate 0.0;
ms:binaryRepresentation "QmF...ZTY"^^xsd:base64Binary.

}
Listing 1. The self-descriptive amf metadata in the tpf fragment for ?x rdf:type
foaf:Person allows the client to interpret and evaluate approximate membership.

To facilitate implementation, the amf interface feature is the subject of a specification in the Hydra w3c Community Group, which is available at http://www.
hydra-cg.com/spec/latest/linked-data-fragments/membership-metadata/.

5 SPARQL Query Execution with AMF-enabled TPFs

In order to explain the algorithm to query tpfs with amf metadata, we will
consider the following example query for dbpedia:

Query 1. This sparql query finds artists born in cities named York.

}, we obtain the count metadata {(tp1

Given a regular tpf interface, the algorithms presented in Section 2.2 will compute results for each bgp B by recursively evaluating and binding each triple
 B in an order determined by the count metadata in their respective
pattern tpi
fragments. For example, by fetching the first page of the tpfs for Query 1 where
B = {tp1
, 625 811),
, 2)}. Therefore, we start iterating over tp3, which will supply values for ?c.
(tp3
This leads to 2 subqueries B = {tp1
} where the remaining triple patterns
are bound to concrete values of ?c (note that tp1 is unaffected because it does
not contain ?c). For instance, for ?c = dbp:York, we obtain count metadata
, 207)}. Query execution thus continues with the smallest frag-
{(tp1
} in which tp1 is bound
ment tp

2, which results in 207 subqueries B = {tp

, 96 300), (tp

, 96 300), (tp2

, tp2

, tp3

, tp
?

?

?
Fig. 1. The triple patterns of Query 1 with the least number of matches at each stage
become nodes in the evaluation tree. Note how the third level of consists entirely of
membership subqueries (single triples), and can thus be evaluated with the help of an
amf.

to possible values of ?p. These 207 subqueries are indeed membership queries,
because they check the presence of a concrete triple without variables, e.g.,
dbp:Adam_Thomas rdf:type dbo:Artist. All values of ?p that result in a match
are solution mappings to the query. This process leads to an evaluation tree, as
shown in Figure 1.

An efficient way to realize such evaluation trees are iterator pipelines [9],
which allow for incremental query results. In existing tpf algorithms [23,25],
two principal
iterator types are responsible for sparql query evaluation
over tpfs: a TriplePatternIterator for triple patterns and a GraphPatternfor bgps. The whole of Section 5 is executed by a GraphPattern-
Iterator
Iterator, which chains together TriplePatternIterators for each of the three
levels in the tree. Each TriplePatternIterator reads solution mappings from
the iterator above it and tries to extend them with mappings for a given triple
pattern. For instance, the iterator at level 2 with pattern ?p dbo:birthPlace ?c
receives mappings for ?c from the iterator at level 1. For each ?c, it tries to find
mappings for ?p, which are then passed on to level 3. Finally, the TriplePatternIterator on level 3 with pattern ?p rdf:type dbo:Artist either confirms or
rejects mappings depending on whether the triple for a given ?p exists. This
produces a total of 207 requests, which amount to 98% of the total http traffic.
Algorithm 1 presents an extension of the original TriplePatternIterator [25]
is initiated,
to make use of amf metadata. When a TriplePatternIterator
the corresponding tpf for its initial triple pattern is requested (line 2). This
fragment typically already resides in the client cache, since it was formerly
requested by a GraphPatternIterator for count metadata. If the response contains amf metadata, a membership test function is created and assigned to the
iterator (line 4). In our example, this translates to a request for the tpf for ?p
rdf:type dbo:Artist, which contains an amf for all mappings of ?p. If no amf
metadata is found, we assign a constant function True that always returns true
(possible match), so that a verification request is always necessary.

When GetNext is called, the TriplePatternIterator first reads an upstream
mapping s from its source iterator Is (line 14). Then, we test whether the triple
(pattern) tp resulting from this mapping is present in the current amf. If the

M. Vander Sande

1 Function TriplePatternIterator.Init()

Data: A source iterator self.Is; A triple pattern self.tp
ftp  GET tpf for self.tp;
if ftp contains amf metadata then

self.membership test  ftp.metadata.amf;
self.membership test  True where x : True(x) = true;

else

end
self.current fragment  ;

9 end

10 Function TriplePatternIterator.GetNext()

Output: The next mapping n or nil when no such mappings are left
  nil;
while  = nil do

while self.current fragment does not contain unread triples do

self.s  self.Is.GetNext();
return nil if self.s = nil;
tp  self.s[self.tp];
if self.membership test(tp

self.current fragment  GET tpf for tp

) = true then

;

end

end
t  an unread data triple from self.current fragment;
  a mapping 
) = vars(self.tp) and 
end
return   self.s;

with dom(

[self.tp] = t;

25 end

Algorithm 1. A TriplePatternIterator with support for amf metadata

test returns true, we have a true positive or false positive, so the tpf corresponding to tp is fetched and assigned to the iterator. For instance, if the mapping
{?p = Adam_Thomas} returns true, we retrieve the tpf for dbp:Adam_Thomas
rdf:type dbo:Artist to verify whether this triple is a true or false positive.
If the test returns false, tp is a true negative and need not be checked. For
instance, if the mapping {?p = Barry_Tait} returns false, we are sure the corresponding tpf is empty, so we do not need to perform the http request.

For each negative amf result, this proposed extension of the algorithm saves
an http request. Depending on the type of query, cumulative savings can be
extensive, as with Query 1. The positive results, however, still need to be verified in case false positives would have occurred. While we cannot eliminate the
verification http calls without endangering the correctness (precision) of query
results, it is possible to further reduce the query time, as we will discuss in the
next section.
?

?

?
Fig. 2. This sparql query execution timeline compares regular and opportunistic
query execution, assuming r total query results and f false positives. Note how both
approaches achieve 100% recall and precision at a shared point in the end, but there
exists a period during which only opportunistic execution reaches 100% recall (shaded).

6 Opportunistic Query Results

In general, query execution does not necessarily end when all valid results have
been obtained; it could be that the engine still spends some time to rule out
possible result candidates before being able to decide that the result set is in
fact complete. Due to the approximate nature of amfs, it is possible that at
a certain point during line 1, the in-memory result set R already contains all r
valid results. However, they cannot be returned yet, because R can still contain
a number of false positives f. Only after the membership of all positive results
of the amf has been verified against the tpf interface, the f false positives can
be discarded and all r matches can be returned safely.

For some use cases, it might be acceptable to temporarily consider incorrect results, especially if we are able to indicate which results can be trusted
and which results cannot. If at first, we optimistically assume that all positive
matches of the amf are actual matches (i.e., we disregard the false positive rate),
the client is able to reach 100% recall earlier, temporarily tolerating a precision
below 100%. For each of those approximate matches, the client can express the
probability that it is valid, namely 1 p with p the false-positive rate of the amf.
As membership subqueries progress, the client can update the probability for
true positives from 1  p to 1, and retract false positives by setting their probability to 0. This opportunistic method of providing query results is important
if fast results and eventual full precision are preferred over slower results with
immediate precision. At no point in time, incorrect query results are presented
as correct results of the query.

Figure 2 compares regular querying and opportunistic querying. Note in particular how both approaches eventually reach 100% recall and precision at the
same time. In other words, even though the opportunistic algorithm temporarily
allows uncertain results and thus a precision of less than 100%, the application
eventually obtains the accurate result set. Also, the application that receives the
result knows at each moment in time whether a result is certain or not, and can
thus decide to either use it or not.

As an example, consider an application that displays photos of artists based
on the results a certain sparql query. After a few http calls, the query client
returns 50 matches, all of which have a probability of 99%. The application can

M. Vander Sande

decide to already start downloading photos of the 50 matching artists, without
displaying them to the user yet. Once 48 of the 50 matches are confirmed, the
48 photos can be displayed immediately; only 2 photos need to be discarded.
The user thus sees the photos faster than if they had only been retrieved after
full precision was achieved. This example indicates that opportunistic query
answering has direct concrete uses in Web applications.

7 Evaluation

In the following, we discuss our evaluation of executing sparql queries against
tpf interfaces with an amf feature. From these experiments, we aim to assess
whether amfs are a valuable asset in the metadata dimension. We first describe
the experiments and their setup. Then, we discuss their results to validate the
three hypotheses of Section 3.2.

7.1 Experimental Setup

We extended the existing implementations of the tpf client3 and server4 to
support both Bloom filters and Golomb-coded sets. The server is configured by
specifying the amf and the desired false positive probability. We chose the 32-bit
MurMurHash3 hash function for gcs and fnv-1 for the Bloom filter. The server
calculates a membership function on the fly for each request for a triple pattern
with a single variable.
We ran the experiments with different false positive probabilities p: 1/1024 
0.1%, 1/128  1%, and 1/64  1.6%. In each experiment, we executed 250
queries generated from 125 diverse WatDiv sparql templates on three interfaces:
i) regular tpf interface ii) tpf with Bloom filters, and iii) tpf with gcs. All
three cases were tested with both the original and the optimized client; the last
two setups were tested with and without opportunistic querying. All experiments
were run on a single Amazon ec2 machine with an 8-core Intel Xeon e2680 v2
cpu and 15gb ddr3 ram, using a query timeout of 3 minutes and the WatDiv
100M triples dataset from [1]. The http requests were routed through an nginx
cache instance to enable http caching and to enforce a realistic Web bandwidth
of 1Mbps per request. We published the full result logs online.5

7.2 HTTP Requests

Tables 1 to 4 summarize the results of the experiments. They compare each amfenabled setup against a regular tpf client/server setup, grouping each of the
250 queries on whether they resulted in an equal, lower, or higher measurement
for i) number of requests, ii) time to first result, iii) time to 100% recall (i.e., with

3 https://github.com/LinkedDataFragments/Client.js/tree/amq
4 https://github.com/LinkedDataFragments/Server.js/tree/amq
5 https://github.com/LinkedDataFragments/TPF-Membership-Metadata-Results
?

?

?
Table 1. Comparison of regular tpf versus tpf with Bloom filter setup (greedy tpf
algorithm)

Table 2. Comparison of regular tpf versus tpf with gcs setup (greedy tpf algorithm)

opportunistic querying enabled), and iv) total query execution time. The number
of queries per group is indicated, together with their average measurement value
in the regular setup, and the average decrease or increase in respectively the
lower and higher groups. For example, the top-left value cell of Section 7.1
shows that, for Bloom filters with p = 1/1024, 126 queries had a lower number
of http requests; for each of these 126 queries, the regular setup needed on
average 45,213 requests, whereas the amf-enabled setup required 15,217 fewer
requests.

Our experiments show that, with p = 1/1024, amf metadata decreases
the number of http calls for roughly half of all considered queries (Bloom:
126 queries or 50.4%; gcs: 123 queries or 49.2%). As expected from the analysis
in Section 3, those queries that benefit from improvements are queries with relatively many http requests: the average number of requests per query in the lower
group is 45,213 (gcs: 45,598), compared to 2,953 (gcs: 2,271) for queries that
do not improve. The improvements let us conclude that a substantial number of

Table 3. Comparison of regular tpf versus tpf with Bloom filter setup (optimized
tpf algorithm)

M. Vander Sande

Table 4. Comparison of regular tpf versus tpf with gcs setup (optimized tpf algo-
rithm)

these 45,000+ requests per query were membership subqueries; the amf-based
query algorithm manages to decrease their number by 15,217 (gcs: 11,761) on
average. 43 queries (gcs: 43) result in a slightly higher number of requests, albeit
negligible compared to the total number: 10 versus 24,312 (gcs: 18 / 26,919).
Note that in general, the number of requests per query is very high because of
the potentially high number of results in the WatDiv dataset. While numbers
of this scale clearly highlight query patterns, many real-world queries can be
evaluated with tighter constraints.

A similar pattern arises with the optimized tpf algorithm [23], which consumes fewer http requests overall because of full client-side joins, but has potentially longer query times for the same reason. Even more queries benefit from
lower request numbers: 155 (62%) for Bloom and 147 (58.8%) for gcs. We see
a reduction of roughly the same ratio, both with Bloom filters and gcs, although
the absolute request numbers are lower.

The observations generalize to the cases for p = 1/128 and p = 1/64, albeit
with slightly different observations. As is expected from a higher number of false
positives, we see a decreasing average gain with increasing p. Interestingly, we
see the number of queries with fewer http requests increase slightly for higher p
values; we assume this is correlated with the smaller response size, which allows
for a higher throughput.

The above results confirm a substantial positive impact on the number of

http requests, validating Hypothesis 1.

7.3 Query Execution Time

In all cases (excluding 1 or 2 exceptions), both the first result times and total
query times remain the same or even increase, contrarily to what we had
expected. As Tables 1 and 2 indicate, about one in three queries have their
execution time prolonged with about 20 seconds, or a third of their time. This
prolongation is higher for Bloom filters than gcs, which see a more limited effect
absolutely (18 seconds) and proportionally (about a quarter). The cause of these
elevated query times is likely the increased response size: since the server automatically sends amfs for all patterns with one variable (even if the client does
not use the amf), the server-side computation time and client-side retrieval time
increase. Given a connection of 1Mbps and on-the-fly amf generation, as in this
experiment, the decreased number of requests is apparently insufficient for the
considered queries and dataset to result in temporal gains. This is confirmed
?

?

?
by the fact that gcs performs better, as gcs representations are encoded more
efficiently.

Interestingly, higher false-positive probabilities do not have a profound effect
on query time. For the given constrains, the higher number of requests seems
to be compensated by the decreased complexity of generating, transferring, and
interpreting amfs. This is an indication that further experimentation with low
probabilities might be beneficial.

The prolonged total query time also hinders the effectiveness of opportunistic querying. Whereas its goal is to achieve full recall earlierat the expense of
temporarily allowing <100% precisionthe slower overall execution prevented
a globally positive result. The potential benefit of opportunistic querying is evidenced by the 3 queries that, with Bloom filters, achieve 100% recall 41 seconds
about a thirdearlier. Since opportunistic results have no negative influence on
query time, the increased recall times for 95 queries must be entirely due to the
slower speed of the amf approach under the 1Mbps and on-the-fly constraints.
Should we succeed in speeding up amf generation and/or transfer time, we could
expect to see a broader influence of opportunistic results. Furthermore, the number of false positives that needed to be revoked was either 0 or 1 for all of the
considered queries, revealing a low temporary impact on precision.

The obtained results for execution time thus invalidate Hypothesis 2, as we
were not able to decrease the time to full recall in general. Further research
will need to assess the relation of this observation to on-the-fly generation and
bandwidth, and perhaps also even higher false positive rates.

7.4 Server Impact

Finally, we measured the average cpu load during query execution for two different amf configurations and two different false positive probabilities. Compared
to the normal server cpu usage (9.2%), the amf configurations show an increase
of 1.6% (p = 1/1024), 2% (p = 1/128) and 5.7% (p = 1/64) for Bloom, and
1% (p = 1/1024), 1.6% (p = 1/128), and 1.9% (p = 1/64) for gcs. This is a
very acceptable overhead which does not impact the servers low-cost nature.
Bloom has a higher impact than gcs because of the many hashes it needs to
calculate, which apparently outweigh the overhead of Golomb compression. Note
that all amf metadata is created at query time and can still benefit from precomputation and/or caching. Given the limited increase, the aforementioned
numbers validate Hypothesis 3.

8 Conclusions

The Triple Pattern Fragments api enables client-side sparql execution on lowcost servers, at the cost of higher execution time and bandwidth usage. In this
paper, we studied the effect of incorporating approximate membership metadata
as an interface feature. In particular, we aimed at reducing http requests by
avoiding expensive triple membership checks. We observed that, for one third of

M. Vander Sande

a set of diverse query types, most of the request overhead are in fact membership subqueries. At the expense of one extra request to fetch the approximate
membership metadata, potentially many more could be saved. Indeed, the experimental results confirm a drastic decrease in requests for half of the 250 randomly
generated WatDiv queries, while others experience little overhead thanks to local
caching. Furthermore, this addition does not affect the low-cost nature of the
server, which only has a limited load increase. However, there is a computational
overhead on the client for queries that are not improved. An intelligent client
should minimize this, by deciding when to use membership metadata based on
the query type.

Despite the reduction of requests, the total execution time is higher on average because of long delays introduced to generate amfs. Therefore, we conclude
that this metadata is not suitable for real-time computation. We therefore recommend to pre-compute or pre-cache it in advance. A strong benefit of http
caching has been proven for tpf querying [25] due to the limited possible number of requests, and this mechanism can be applied efficiently to tpfs with augmented metadata. While Bloom filters are preferred for lower computation time,
the smaller size of Golomb-coded sets would prevail in the presence of caching.
To prevent the overhead of generating and transferring amfs, they could be
served in a separate resource that clients explicitly request when needed.

While positive membership tests introduce a slight overhead, this can be compensated by enabling opportunistic querying. Our results show that retracting
results after validation is rare and only effects a small number of results. There-
fore, it makes sense to design Web applications that can deal with temporarily
imprecise results.

A major advantage of adding amf metadata to the tpf interface is that it
happens transparently and in a self-descriptive way. The server can choose freely
whether or not to add metadata to a certain response; clients can reactively use
metadata when possible, or ignore it when they do not support or need it. Where
count metadata has proven crucial for the initial design of tpf querying [25], this
first exploration of a new metadata feature was proven an interesting direction.
In the future, we could imagine different such types of join optimizations, based
on optional selectivity information that servers send as metadata to help clients
make intelligent decisions. Studying their impact on real-world scenarios such as
human-crafted knowledge bases can shape further directions.
