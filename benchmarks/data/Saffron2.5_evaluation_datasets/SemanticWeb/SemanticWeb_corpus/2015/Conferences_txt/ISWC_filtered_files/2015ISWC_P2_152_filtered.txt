Assessing and Refining Mappings

to RDF to Improve Dataset Quality

Anastasia Dimou1(B), Dimitris Kontokostas2, Markus Freudenberg2,
Ruben Verborgh1, Jens Lehmann2, Erik Mannens1, Sebastian Hellmann2,

and Rik Van de Walle1

1 iMinds - Multimedia Lab, Ghent University, Ghent, Belgium

{anastasia.dimou,ruben.verborgh,erik.mannens,rik.vandewalle}@ugent.be
{kontokostas,freudenberg,lehmann,hellmann}@informatik.uni-leipzig.de

2 Institut Fur Informatik, AKSW, Universitat Leipzig, Leipzig, Germany

Abstract. rdf dataset quality assessment is currently performed primarily after data is published. However, there is neither a systematic
way to incorporate its results into the dataset nor the assessment into
the publishing workflow. Adjustments are manually but rarely applied.
Nevertheless, the root of the violations which often derive from the mappings that specify how the rdf dataset will be generated, is not identified.
We suggest an incremental, iterative and uniform validation workflow
for rdf datasets stemming originally from (semi-)structured data (e.g.,
csv, xml, json). In this work, we focus on assessing and improving their
mappings. We incorporate (i) a test-driven approach for assessing the
mappings instead of the rdf dataset itself, as mappings reflect how the
dataset will be formed when generated; and (ii) perform semi-automatic
mapping refinementsbased on the results of the quality assessment. The
proposed workflow is applied to diverse cases, e.g., large, crowdsourced
datasets such as dbpedia, or newly generated, such as iLastic. Our evaluation indicates the efficiency of our workflow, as it significantly improves
the overall quality of an rdf dataset in the observed cases.

Keywords: Linked data mapping  Data quality  rml  r2rml 

rdfunit

1 Introduction

The Linked Open Data (lod) cloud1 consisted of 12 datasets in 2007, grew to
almost 300 in 20112, and, by the end of 2014, counted up to 1,0003. Although
more and more data is published as Linked Data (ld), the datasets quality and
consistency varies significantly, ranging from expensively curated to relatively
low quality datasets [29]. In previous work [21], we observed that similar violations can occur very frequently. Especially when datasets originally stem from

http://lod-cloud.net/
http://lod-cloud.net/state
http://linkeddatacatalog.dws.informatik.uni-mannheim.de/state/

c Springer International Publishing Switzerland 2015
M. Arenas et al. (Eds.): ISWC 2015, Part II, LNCS 9367, pp. 133149, 2015.
DOI: 10.1007/978-3-319-25010-6 8

A. Dimou et al.

semi-structured formats (csv, xml, etc.) and their rdf representation is obtained
by repetitively applying certain mappings, the violations are often repeated,
as well. semantically annotating data to acquire their enriched representation
using the rdf data model. A mapping consists of one or more mapping definitions (mds) that state how rdf terms should be generated, taking into account a
data fragment from an original data source, and how these terms are associated
to each other and form rdf triples.

The most frequent violations are related to the datasets schema, namely
the vocabularies or ontologies used to annotate the original data [21]. In the
case of (semi-)structured data, the datasets schema derives from the set of
classes and properties specified within the mappings. A mapping might use a
single ontology or vocabulary to annotate the data, or a proprietary vocabulary
can be generated as the data is annotated. Lately, combinations of different
ontologies and vocabularies are often used to annotate data [28], which increases
the likelihood of such violations. A violation might derive from (i) incorrect usage
of schemas in the mds; and (ii) mistakes in the original data source. The second
category of violations can be resolved by cleansing the data. In this work, we
focus specifically on the first, which is directly related to the mapping process.
Only recently, several research efforts started focusing on formalising Linked
Data quality tracking and assessment [29]. Nevertheless, such formalisation
approaches remain independent of the Linked Data mapping and publishing
process quality assessment is not even mentioned in the best practices for publishing Linked Data [18]. Existing quality assessment refers to already published
data and is, in most cases, performed by third parties rather than data publish-
ers. Thus, incorporating quality assessment results corresponds to incorporating
a Linked Data feedback loop: existing Linked Data infrastructures still neither
intuitively process end-users input, nor properly propagate the modifications to
the mapping definitions and original data. Consequently, the results are rarely
and, if so, manually used to adjust the dataset, with the risk of being overwritten
when a new version of the original data is published.

In this paper, we therefore propose a methodology that extends Linked Data
quality assessment from data consumption to also cover data publication. We
transform the assessment process normally applied to the final dataset so that
it applies to the mappings as well. This allows publishers to discover mistakes
in mapped rdf data before they are even generated. Our methodology (i) augments the mapping and publishing workflow of (semi-)structured source formats
with systematic Linked Data quality assessments for both the mappings and
the resulting dataset; and (ii) automatically suggests mapping refinements based
on the results of these quality assessments. We consider iterative, uniform, and
gradual test-driven quality assessments to improve the datasets overall quality.
The paper is organized as follows: Section 2 details the need of quality assessment during the mapping process, followed by the introduction of a mapping
workflow with quality assessment in Section 3. Next, Section 4 explains how
quality assessments are applied to mappings, the results of which are used to
refine mapping definitions in Section 5. Section 6 highlights different cases where
?

?

?
the proposed workflow was used, followed by an evaluation in Section 7. Finally,
Section 8 and Section 9 summarize related solutions and conclusions.

2 Incorporating Quality in Mapping and Publishing

Data quality is commonly conceived as fitness for use for a certain application
or use case [19]. A data quality assessment metric, measure, or indicator is a
procedure for measuring a data quality dimension [3]. A data quality assessment
methodology is defined as the process of evaluating whether a piece of data meets
the information that consumers need in a specific use case [3]. In this respect,
our use case is focused on the quality of the generated rdf dataset compared to
the ontologies and vocabulary definitions of its schema. The uppermost goal is
aiding data publishers to finally acquire valid and high quality Linked Data by
annotating (semi-)structured data. We focus on the intrinsic dimension of data
quality [29].

The earlier dataset quality is assessed, the better: we argue that mapping and
publishing data can be considered software engineering tasks, and the cost of fixing a bug rises exponentially when a task progresses [4]. In software development,
a common way to validate correct behaviour of a function is to accompany it by
a set of unit tests. Similarly, a data mapping function can be accompanied by a
set of test cases assigned to the mappings to ensure the correct generation of rdf
datasets from input data. In this respect, incorporating quality assessment as
part of the mapping and publishing workflow becomes essential, especially taking into account that it prevents the same violations to appear repeatedly within
the dataset and over distinct entities. After all, in the mapping phase, structural
adjustments can still be applied easily, since it allows us to pinpoint the origin of
the violation, reducing the effort required to act upon quality assessment results.
Our approach has two main pillars: (i) uniform quality assessment of mapping definitions and the resulting dataset, as their quality is closely related; and
(ii) mapping definition refinements to automatically improve mappings when
problems are detected at the quality assessment.

Uniform Quality Assessment. Instead of assessing an rdf dataset for its
schema quality, we apply the quality assessment to the mapping definitions
directly, before they are used to generate the rdf dataset. Their assessment
results are correlated, since mds specify how the dataset will be formed. For
example, violations of the range of a certain property can be assessed by inspecting the corresponding md, which defines how triples with this property are gen-
erated. Even though quality assessment of mds can cover many violations related
to vocabularies and ontologies used to annotate the data, some schema-related
violations depend on how the mds are instantiated on the original data. For
example, a violation occurs if an object of integer datatype is instantiated with
a floating-point value from the original source. Therefore, a uniform way of incrementally assessing the quality of the rdf dataset and the mapping definitions
should cover both the mappings and the dataset.

A. Dimou et al.

Fig. 1. Quality Assessment enabled Linked Data mapping and publishing workflow

If violations are only corrected in the
Mapping Definition Refinements.
resulting dataset, they will have to be corrected every time a new version of the
dataset is generated. Also, when a violation is found, it is not straightforward to
discover its cause, as the connection with the mds and the source data is not appar-
ent. A more effective approach is to refine the mds that generate those triples, so
the violation cannot occur in future versions. Furthermore, if the violation is associated with a md, it can be addressed directly on the place where it occurred, and
instead of having to regenerate the entire dataset, only the triples affected by the
refinement need to be regenerated to correct the violation.

3 Linked Data and Mappings Assessment and Refinement

Uniform quality assessment requires that, in addition to the generated dataset,
the mapping definitions themselves are also rdf triples. This way, the same rdfbased techniques can be applied. Additionally, performing (automated) refinement of mds requires that machines can process and update them. Such direct
processing of mds is difficult if mappings are tightly coupled to the implemen-
tation, as is the case with most existing mapping solutions. In this respect, we
focus on rdf-based mapping languages for stating the mds. Below, we describe
such a workflow (Section 3.1) and a solution that materializes it (Section 3.2).

3.1 Linked Data and Mappings Assessment and Refinement

Workflow

We propose a uniform, iterative, incremental assessment and refinement workflow (Fig. 1) that produces, at the end, a high-quality rdf dataset. Its steps:

1. The schema, as stated in the mds, is assessed against different quality assess-

ment measures, as it would have been done if it was the actual dataset.

2. The Quality Assessment report lists each violation identified.
3. The Mapping Quality Assessment (mqa) results are used to refine the mds.
The mqa can be repeated until a set of mds without violations is generated
or if the mds cannot be further refined.

4. A refined version of the mds is generated and used to execute the mapping

of data or a sample of the data.

5. The generated rdf output is assessed, using the same quality assessment
framework. The Dataset and optionally the Mapping Quality Assessment
(dqa) can be repeated until an ameliorated set of mds is generated.
?

?

?
<#Mapping> rml:logicalSource <#InputX> ;

rr:subjectMap [ rr:template "http://ex.com/{ID}"; rr:class foaf:Person ];
rr:predicateObjectMap [ rr:predicate foaf:knows;

rr:objectMap [ rr:parentTriplesMap <#Acquaintance> ].

<#Acquaintance> rml:logicalSource <#InputY> ;

rr:subjectMap [ rml:reference "acquaintance"; rr:termType rr:IRI; rr:class ex:Person ]

].

Listing 1. RML mapping definitions

6. When the mds are finalized, the actual mapping is performed and the rdf

dataset is generated exempt of violations to the greatest possible extent.

3.2 Quality Assessment and Refinement with [R2]RML and

RDFUnit

We provide a solution that implements the aforementioned workflow. The two
main components of our solution are: the rml (Section 3.2) that uses mapping definitions expressed in rdf, a prerequisite for uniform quality assessment
and automated refinements, as we discussed above, and the rdfunit validation
framework (Section 3.2) due to its associated test-case-based architecture [20]. A
proof-of-concept implementation relies on the rmlvalidator which can be found
at https://github.com/RMLio/RML-Validator.git.

RML. r2rml [6] is the only w3c standardised mapping language for defining
mappings of data in relational databases to the rdf data model. Its extension
rml [10] broadens its scope and covers also mappings from sources in different
(semi-)structured formats, such as csv, xml, and json. rml documents [10]
contain rules defining how the input data will be represented in rdf. The main
building blocks of rml documents are Triples Maps (Listing 1: line 1). A Triples
Map defines how triples of the form (subject, predicate, object) will be generated.
A Triples Map consists of three main parts: the Logical Source, the Subject Map
and zero or more Predicate-Object Maps. The Subject Map (line 2, 6) defines how
unique identifiers (uris) are generated for the mapped resources and is used as
the subject of all rdf triples generated from this Triples Map. A Predicate-Object
Map (line 3) consists of Predicate Maps, which define the rule that generates the
triples predicate (line 3) and Object Maps or Referencing Object Maps (line 4),
which define how the triples object is generated. The Subject Map, the Predicate
Map and the Object Map are Term Maps, namely rules that generate an rdf term
(an iri, a blank node or a literal). A Term Map can be a constant-valued term
map (line 3) that always generates the same rdf term, or a reference-valued
term map (line 6) that is the data value of a referenced data fragment in a
given Logical Source, or a template-valued term map (line 2) that is a valid string
template that can contain referenced data fragments of a given Logical Source.

A. Dimou et al.

RDFUnit [21] is an rdf validation framework inspired by test-driven software
development. In software, every function should be accompanied by a set of unit
tests to ensure the correct behaviour of that function through time. Similarly,
in rdfunit, every vocabulary, ontology, dataset or application can be associated
by a set of data quality test cases. Assigning test cases in ontologies results in
tests that can be reused by datasets sharing the same ontology. This fits well to
the mapping and publishing pipeline as we focus on the [R2]RML ontologies.

The test case definition language of rdfunit is sparql, which is convenient
to directly query for identifying violations. For rapid test case instantiation,
a pattern-based sparql-template engine is supported where the user can easily bind variables into patterns. An initial library of 17 common patterns was
developed in [21, Table 1] which is now further extended4. rdfunit has a Test
Auto Generator (tag) component. tag searches for schema information and
automatically instantiates new test cases. Schema can be in the form of rdfs or
owl axioms that RDFUnit translates into sparql under Closed World Assumption (cwa) and Unique Name Assumption (una). These TCs cover validation
against: domain, range, class and property disjointness, (qualified) cardinal-
ity, (inverse) functionality, (a)symmetricity, irreflexivity and deprecation. Other
schema languages such as IBM Resource Shapes 5 or Description Set Profiles 6 are
also supported. rdfunit includes support for automatic schema enrichment via
DL-Learner [23] machine learning algorithms. rdfunit can check an rdf dataset
against multiple schemas but when this occurs, rdfunit does not perform any
reasoning/action to detect inconsistencies between the different schemas.

4 [R2]RML Mapping Definitions Quality Assessment

It is straightforward to process [r2]rml mapping definitions as datasets, because
they have a native rdf representation and are written from the viewpoint of the
generated triples. Our assessment process targets both (i) consistency validation
of the mapping definitions against the r2rml and rml schema and, mainly,
(ii) consistency validation and quality assessment of the dataset to be generated
against the schema defined in the mapping definitions. This first point is handled
directly by rdfunit; the second point is handled by emulating the resulting rdf
dataset to assess its schema conformance.

Consistency Validation of the Mapping Definitions. The validation of mapping
definitions against the [r2]rml schema is directly handled by rdfunit extending
the supported owl axioms. New rdfunit tags were defined to support all owl
axioms in [r2]rml ontology, e.g., each Triples Map should have exactly one Subject
Map, producing a total of 78 automatically generated test cases.

https://github.com/AKSW/RDFUnit/blob/master/configuration/patterns.ttl
http://www.w3.org/Submission/2014/SUBM-shapes-20140211/
http://dublincore.org/documents/dc-dsp/
?

?

?
Consistency Validation and Quality Assessment of the Dataset as Projected by
Its Mapping Definitions. In order to assess a dataset based only on the mapping definitions that state how it is generated, we considered the same set of
schema validation patterns normally applied on the rdf dataset (cf. Section 5).
Nevertheless, instead of validating the predicate against the subject and object,
we extract the predicate from the Predicate Map and validate it against the Term
Maps that define how the subject and object will be formed. For instance, the
extracted predicate expects a Literal as object, but the Term Map that generates
the object can be a Referencing Object Map that generates resources instead.

To achieve this, the properties and classes in the mds are identified and their
namespaces are used to retrieve the schemas and generate the test cases as if
they were the actual dataset. We extended the corresponding rdfunit test cases
to apply to the mds, adjusting the assessment queries.7 For instance, the WHERE
clause of the sparql test case that assesses a missing language is:
?

?

?
?resource ?P1 ?c .
FILTER (lang(?c) =

)

In order to detect the same violation directly from a mapping definition, the
WHERE clause of the assessment query is adjusted as follows:
?

?

?
?poMap rr:predicate ?P1 ;

rr:objectMap ?resource .
?P1 rdfs:range rdf:langString .
FILTER NOT EXISTS {?resource rr:language ?lang}

The validation is Predicate-Map-driven in principle. The

expected
value (line 3), as derived from the Predicate Map, is compared to the defined
one (line 4), as derived from the corresponding Object Map. The next example is an rdfunit sparql test case for assessing if the rdf:type of a triples
ObjectMap conforms to the rdfs:range definition of an object property. Applying
this test case to the aforementioned md (cf. Listing 1), a violation is registered,
as foaf:knows has foaf:Person and not ex:Person as range  assuming the
ontology does not define ex:Person as equivalent or subclass of foaf:Person.
?

?

?
SELECT DISTINCT ?resource WHERE {

?mappingTo rr:subjectMap ?resource .
{ ?resource rr:class ?T1 . } UNION {

?mapping rr:predicateObjectMap ?classPoMap .
?classPoMap rr:predicate rdf:type ;

rr:objectMap/rr:constant ?T1 . }

?mappingFrom rr:predicateObjectMap ?poMap .
?poMap rr:predicate/rdfs:range ?T2

;

rr:objectMap ?objM .

?objM rr:parentTriplesMap ?mappingTo .
FILTER NOT EXISTS {

?T2 (rdfs:subClassOf|(owl:equivalentClass|^owl:equivalentClass))* ?T1.}}

In order for our assessment to be complete, the defined test cases cover all possible alternative ways of defining equivalent mds that generate the same triples.
For instance, the default way to generate the type for a resource is through the

https://github.com/AKSW/RDFUnit/blob/master/data/tests/Manual/www.w3.org/ns/r2rml/
rr.tests.Manual.ttl

A. Dimou et al.

rr:class property in the Subject Map (e.g., line 2 of Listing 1). However, one may
also define the type via a Predicate Object Map having rdf:type in its Predicate Map.
rdfunit can annotate test cases by requesting additional variables and binding them to specific result properties. Using the example of Listing 4 we map, for
instance, variable ?T1 as spin:violationValue and variable ?T2 as the expected
class. When a violation is identified, the annotations are applied and a result
like the following is registered:
?

?

?
<5b7a80b8> a rut:ExtendedTestCaseResult;

rut:testCase rutt:rr-produces-range-errors ;
# (...) Further result annotations
spin:violationRoot ex:objectMapX ;
spin:violationPath rr:class ;
spin:violationValue ex:Person ;
rut:missingValue foaf:Person ;
ex:erroneousPredicate foaf:knows ;

However, some of the test cases normally applied to a dataset rely on
the final values or refer to the complete dataset and thus, can only be validated after the mapping is performed detected at data-level quality assessment (dqa). Such examples are (qualified) cardinality, (inverse) functionality,
(a)symmetricity and irreflexivity. For example, we cannot validate an inverse
functional property such as foaf:homepage without the actual values. Invalid
mappings can occur as the mapping definitions are instantiated based on
the input source, even though the mapping definitions appear to be valid.
For instance, if the input data returns a value like American, instead of
http://dbpedia.org/resource/United States, it would result in generating the
uri <American>, which is invalid.

5 [R2]RML Refinements Based on Quality Assessment

The results of Mapping Quality Assessment (mqa) can be used to suggest modifications or even automatically refine mapping definitions. The rdfunit ontology
provides multiple result representations in different formats [20],including rdfbased serialisations (rut:ExtendedTestCaseResult result type). Therefore, its results
are easily processed by an agent that can automatically add and delete triples
or suggest actions to the data publisher. In Section 5, we outline all examined
violation patterns and indicate which Term Map should be refined and how. The
suggested refinements are the minimum required actions to be taken to refine the
mapping definitions, e.g., turn an Object Map into generated resources instead of
literals, and serve as indicative proof-of-concept of the automations feasibility.

Mapping Refinements. Dealing with range-level violations requires different
actions, depending on the value of the Object Map or Referencing Object Map.
The Predicate Map is used to retrieve the property and identify its range, which
is then compared to the corresponding Object Map or Referencing Object Map.

If the Predicate Map contains an object property, for instance, but the object
is generated by a Referencing Object Map, which generates resources with type
?

?

?
Table 1. Violations detected by assessing the mapping definitions. The first column
describes the type of violation, the second its level (Warning or Error). The third
specifies the expected rdf term according to the ontology or schema, while the fourth
the term map defining how the rdf term is generated. The last specifies the refinement.

OWL axiom 
Violation type
class disjointness
property disjointness
rdfs:range 
class type
rdfs:range 
iri instead of literal
rdfs:range 
literal instead of iri

rdfs:range 
missing datatype
rdfs:range 
incorrect datatype
missing language
rdfs:domain
missing rdf:type
deprecation
owl:complementOf

Level Expect Define

Automatic refinement
?

?

?
SbjMap
SbjMap
PreMap PreMap
PreMap




(Ref)ObjMap DEL: ObjMap

PreMap

(Ref)ObjMap DEL: (Ref)ObjMap

ADD: PreMap domain to RefObjMap

PreMap ObjMap

ADD: ObjMap with literal termType
DEL: ObjMap
ADD: (Ref)ObjMap or
ADD: ObjMap with IRI termType

PreMap

(Ref)ObjMap DEL: ObjMap

PreMap

(Ref)ObjMap DEL: (Ref)ObjMap

ADD: ObjMap with PreMap datatype

ObjMap ObjMap

SbjMap

PreMap
W SbjMap
SbjMap
W PreMap PreMap
SbjMap
W PreMap

ADD: ObjMap with PreMap datatype

ADD: PreMap domain to SbjMap
ADD: PreMap domain to SbjMap



different than the predicates range as defined by the corresponding vocabulary or ontology, the predicates range is added as class to the Referencing Object
Map. Such a violation was reported at the example mentioned in the previous section (Section 5). Besides manual adjustments like defining ex:Person
as equivalent or a subclass of foaf:Person, the statement that the Referencing
Object Map type should be a ex:Person, can be replaced by a foaf:Person:
?

?

?
DEL: ex:objectMapX rr:class ex:Person .
ADD: ex:objectMapX rr:class foaf:Person.
MOD: adjust the definition of ex:Person

Automatically refining domain-level violations requires comparing recursively the type(s) assigned to the Subject Map with each predicates domain,
as specified at the different Predicate Maps. If not explicitly defined or inferred
via a subclass, the predicates domain is additionally assigned. This also requires
a follow-up check for disjoint classes, which is of crucial importance especially
when composition of different vocabularies and ontologies occurs.

Mapping Refinements Based on Dataset Quality Assessment. Violations identified when the mds are instantiated with values from the input source, can lead
to a new round of refinements, if violations can be associated with a certain md.

Mapping Refinements Impact on Dataset Quality. The number of automated resolutions for violations detected at the mapping level depends on (i) the number of
iterations over the data chunks of the input source (e.g., number of rows), (ii) the
number of references to the input source (e.g., number of referred columns) and

A. Dimou et al.

(iii) the number of returned values from the input source for each reference.
To be more precise, if I is the number of iterations, R is the set of references
the input source, and V(r) values are returned for r  R, then the total number of errors per violation is equal to the number of triples generated from this
mapping definition: I  
rR V(r). This means that the number of errors per
violation identified (and resolved) at mapping level grows linearly in function of
the number of iterations, and geometrically, in the worst case, if multiple references and returned values occur. For instance, assuming a mapping definition
with 2 references to the input, where up to 3 values can be returned for each
reference, contains a violation. Applied to an xml file with 1,000 elements, this
could cause up to 9,000 error-prone triples in the worst case.

6 Use Cases and Adoption

Our Mapping Assessment and Refinement workflow with rml and rdfunit
is already being used in multiple different contexts. The dbpedia community
adapted our mapping assessment solution to improve its mappings. Other popu-
lar, medium-sized datasets also benefit of our solution to ameliorate their map-
pings, such as dblp. Moreover, various projects fully relied on our solution for
their dataset generation, such as cdflg and iLastic. Last, the proposed workflow was used to refine a challenge submission. Every dataset is unique in the
way mappings are applied and different types of errors arise in each case. We
indicatively describe a number of representative use cases below.

DBpedia [24] provides a collaborative mapping approach of Wikipedia infoboxes
to the dbpedia ontology8 through the dbpedia mappings wiki 9. dbpedia uses a
wiki markup syntax for the mapping definitions and the output is adjusted in
conformance to the dbpedia ontology. Although dbpedia uses the same wikitext syntax as Wikipedia its original source to define the mds, the quality of
wikitext-based mds cannot be assessed directly, and thus certainly not in the
same way as their resulting dataset. Thus, we automated the conversion of all
dbpedia mappings to rml in order to make them processable from our tool
stack. We introduced wikitext serialisation as a new Reference Formulation, since
rml can be extended to express mds for any type of input source. In total, we
generated 674 distinct mapping documents for English, 463 for Dutch and a
total of 4,468 for all languages. We used the dbpedia 2014 release and focused
on a complete evaluation on the English and Dutch language editions as well
as a mapping-only evaluation of all languages supported in the dbpedia mappings wiki. dbpedia originates from crowdsourced and (semi-)structured content
and can thus be considered a noisy dataset. The mqa report was provided to the
dbpedia community10, who took advantage of it to manually refine dbpedia mds.
Automated refinements were not applicable in this case as dbpedia framework
still functions with the original mds in wiki markup.

http://wiki.dbpedia.org/Ontology
http://mappings.dbpedia.org
http://goo.gl/KcSu3E
?

?

?
Faceted DBLP. The Computer Science bibliography (dblp) collects open bibliographic information from major computer science journals and proceedings.
Faceted dblp builds upon the dblp++ dataset, an enhancement of dblp, originally stored in a mysql database. dblp mds are originally defined using d2rq [5]
and were converted to rml using d2rq-to-r2rml11 to be processable by our
workflow. dblp, is a medium-sized dataset of very good quality according to our
evaluation. Nonetheless, the workflow resulted in improvements.

Contact Details of Flemish Local Governments Dataset (CDFLG). 12
In the scope of the ewi13 project, the cdflg dataset was generated using our
workflow [7]. This is a real case of contact details for local governments in Flan-
ders. cdflg is annotated using the oslo ontology14, defined by the Open Standards for Linking Governments Working Group (V-ICT-OR, oslo) under the
oslo (Open Standards for Local Administrations) Programme. Two subsequent
versions of its rml mapping definitions were used to generate this dataset were
assessed for their quality. The decrease of mapping violations over the mapping
evolution indicates that our methodology can correctly identify errors.

iLastic. 15 Our methodology was used in a use case for iMinds16, a research
institute founded by the Flemish Government, which published its own data
regarding researchers, publications, projects, external partners etc., using the
proposed workflow. The mapping definitions that specify how the data is mapped
to the rdf model were stated using rml. After the primary mapping definitions
were stated, they were fed to our proposed implementation and were refined
twice, once based on the mqa results and once based on the dqa results, leading
to their final version which is free of violations.

CEUR-WS. The eswc2015 Semantic Publishing Challenge (spc)17 is focused
on refining and enriching ceur-ws18 linked dataset originally generated at the
eswc2014 edition19. It contains Linked Data about workshops, their publications
and their authors. The workflow was well aligned with the requirements of this
years challenge and was used to evaluate last years submission based on rml [9]
and refine it to produce the base for this years submission [16].

7 Evaluation and Discussion

The datasets mentioned in Section 6 were used for our evaluation. In this section,
the results are described and certain observations are discussed in more details

https://github.com/RMLio/D2RQ to R2RML.git
http://ewi.mmlab.be/cd/all
http://ewi.mmlab.be
http://purl.org/oslo/ns/localgov#
http://explore.ilastic.be/
http://iminds.be
https://github.com/ceurws/lod/wiki/SemPub2015
http://ceur-ws.org
http://challenges.2014.eswc-conferences.org/index.php/SemPub

A. Dimou et al.

Table 2. Evaluation results summary. In the Dataset Assessment part, we provide the
Size (number of triples), number of test cases, evaluation Time, Failed test cases and
total individual Violations. In the Mapping Assessment part, we provide the mapping
document Size (number of triples), evaluation Time, Failed test cases and Violation
instances. Finally, we provide the number of dataset violations that can be addressed
refining the mappings and estimated corresponding dataset violations that are resolved.

Dataset
DBpEn
DBpNL
DBpAll

iLastic

CEUR-WS

Dataset Assessment

Mapping Assessment

Size
62M 9,458
21M 10,491

?

?

?

12M
150k
0.6k
2.4k

TC Time Fail. Viol. Size Time Fail. Viol. Ref.



?

?

?
16.h 1,128 3.2M 115k
1.5h
53k



 511k
7 8.1M 368
12h
37k
12s

678 558k
7s
6s
?

?

?
1 1,316
?

?

?
815k
?

?

?
11s
6s
32s
12s
15s
13s
5s

Affect.
triples
255k
106k

8M
37k
?

?

?
for each dataset and overall. The results are aggregated in Section 7 and are
available at http://rml.io/data/ISWC15. For our evaluation, we used an 8-core
Intel i7 machine with 8gb ram and 256 ssd hd.

Overall, it is clear that the computational complexity and time are significantly reduced when assessing the mapping definitions compared to the complete
rdf dataset (cf. Section 7). It takes 11 seconds to assess the approximately 700
mappings of English dbpedia, compared to assessing the whole dbpedia dataset
that takes of the order of several hours. In the latter case, the assessment requires
examining each triple separately to identify, for instance, that 12M triples violated the range of foaf:primaryTopic, whereas with our proposed approach, only 1
triple needs to be examined. It is indisputable the workflows effectiveness, as,
in all cases that the dataset generation fully relies on its mapping definitions,
the majority of violations is addressed. Moreover, if a set of rml mapping definitions is assessed for its quality, for every other new data source also mapped
using these mapping definitions, the quality assessment does not need to be
repeated for that part. Next, we discuss the results for each dataset in details:

DBpedia. Most violations in dbpedia have a range-level origin. When rdf is
generated from the wikitext, the object type is not known and may result in
wrong statements, as the dbpedia extraction framework automatically adjusts
the predicate/object extraction according to the dbpedia ontology definitions.
Domain-level violations occur as well, because users manually provide the class a
Wikipedia infobox is mapped to and the ontology properties each infobox property will use. Our framework can, in this case, identify mismatches between the
user-defined class and the rdfs:domain of each provided property. We observe that
8% of the errors in dbpedia in English and 13% of dbpedia in Dutch can be fixed
directly at mapping-level. Not only are the errors as such directly pinpointed,
but it also takes negligible time to have the refinements of the violations accom-
plished. The evaluation of all mappings for all 27 supported language editions
resulted in a total of 1316 domain-level violations.
?

?

?
DBLP dataset has 7 individual violations, leading to 8.1M violated triples.
The swrc:editor predicate defined in a Predicate Map expects a resource of
swrc:Person type for its domain instead of foaf:Agent as defined in the corresponding Subject Map causing 21k errors. Similarly, approximately 3M errors
occurred because a Predicate Map exists with dcterms:bibliographicCitation
as its value whose rdfs:domain is bibo:BibliographicResource. However,
the corresponding Subject Map(s) generate resources of type dcmitype:Text,
foaf:Document or swrc:Book but definitely not the expected one, thus data publishers should remain warned for potential contradictions. Moreover, the missing
range of foaf:page and foaf:homepage can be fixed by refining the mapping
definitions but, for links to external resources, it is common practice not to define
their type. Except for 12k inverse functional violations for foaf:homepage that
can not be addressed directly from the mapping definitions, all remaining violations (98%) could be refined.

In the first version of the cdflg dataset, we found four viola-
CDFLG.
tions: One caused by Predicate Object Maps that all have predicates that expect
oslo:Address as their domain. However, the Subject Map is defined to be of type
oslo:BasicAddress. In the same context, an incorrect range violation was identified
for oslo:availableAt property. In general, violations related to Referencing Object
Maps are among the most frequently encountered. Last, the object property
schema:nationality was mapped as literal. The second version of cdflg is a result
of manually refining the mapping definitions according to the first mapping
assessments results. Besides the domain level violation, only few of the range
violations remained (7%).

iLastic is particularly interesting because the workflow was used from the primary version of the mapping definitions, until they became free of violations.
The first version was assessed and even contained r2rml schema violations, e.g.,
rr:constant had a string-valued object instead of a resource. If these mapping
definitions were used, almost one fourth (25%) of its triples would be prone
to errors. Every violation was fixed after a couple of iterations assessing and
refining the mapping definitions. For example, cerif:isClassifiedBy expects
a cerif:Classification and not a skos:Concept, while bibo:uri expects a
literal and not a resource as range. Similarly, dcterms:issued expects xsd:date
and not xsd:gYear. A violation that occurred repeatedly was associated with the
cerif:internalidentifier that requires a string-valued object, whereas it was
associated with an Object Map that generated xsd:positiveInteger objects.

CEUR-WS. 12 violations were identified in the dataset generated using rml
for eswc 2014 challenge and 10 out of them could already be detected at the
mapping definitions. Most of them (7) were domain-level violations, annotating,
for instance, resources of type bibo:Volume with properties for bibo:Document
or for <http://www.loc.gov/mads/rdf/v1#Address>, e.g., for specifying the
city, implying unwittingly that resources are both Documents and Addresses.
The rest of the detected violations were related to contradicted datatypes, for

A. Dimou et al.

instance, incorrectly specifying the datatype as xsd:gYear, while it is expected
to be string. The mapping definitions for eswc 2015 submission were produced
using our workflow, were assessed and do not contain violations any more.

8 Related Work

We summarize the state of the art of the relevant fields: data mappings to the
rdf data model and Linked Data quality assessment.

Mapping Languages. Several solutions exist to perform mappings from different
data formats and serialisations to the rdf data model. In the case of data in xml
format, existing xml solutions were used to define the mappings, such as xslt,
e.g., AstroGrid-D20, or xpath, e.g., Tripliser21, while the only mapping language
defined specifically for xml to rdf mappings is x3ml22. In the same context,
existing querying languages were also considered to describe the mappings, e.g.,
xsparql [2] which is a language that combines xquery and sparql or Tarql23.
Due to the lack of query languages or other ways to refer to data in csv format
or spreadsheets, different mapping languages were occasionally defined, e.g., the
XLWraps mapping language [22] that converts data in spreadsheets to rdf,
or the declarative owl-centric mapping language Mapping Masters M 2 [26]
that converts data from spreadsheets into the Web Ontology Language (owl).
For relational databases, different mapping languages were defined [15], but the
w3c-standardized r2rml prevailed.

Quality Assessment. Different approaches have been developed that try to tackle
various aspects of Linked Data quality. These approaches can be broadly classified into (i) manual (e.g. [1,3,25,29]); (ii) semi-automated (e.g. [11,17]); or
(iii) automated (e.g. [8,14]) methodologies. These approaches introduce systematic methodologies to assess the quality of a dataset. Depending on the app-
roach, we notice inability to produce easily interpretable results, a considerable
amount of user involvement, application on specific datasets only or inability
to evaluate a complete dataset during the assessment. spin24 is a w3c submission aiming at representing rules and constraints on Semantic Web models using
sparql. The approach described in [13] advocates the use of sparql and spin
for rdf data quality assessment. In a similar way, F urber et al. [12] define a
set of generic sparql queries to identify missing or invalid literal values and
datatypes and functional dependency violations. Another related approach is
the Pellet Integrity Constraint Validator 25, which translates owl integrity constraints into sparql queries. A more light-weight, although less expressive, rdf

http://www.gac-grid.de/project-products/Software/XML2RDF.html
http://daverog.github.io/tripliser/
https://github.com/delving/x3ml/blob/master/docs/x3ml-language.md
https://github.com/cygri/tarql
http://www.w3.org/Submission/spin-overview/
http://clarkparsia.com/pellet/icv/
?

?

?
constraint syntax that is decoupled from sparql is offered from Shape Expressions (ShEx) [27] and IBM Resource Shapes 26.

9 Conclusions and Future Work

In this paper, we propose a methodology for assessing Linked Data quality
for data originally stemming from (semi-)structured formats. We propose a
workflow that relies on assessing the mapping definitions, rather than the rdf
dataset they generate. The assessment report points exactly to the root causes
of the violations and can be actively used to refine the mapping definitions. The
automation of refinements or suggestions is facilitated based on a comprehensive analysis of different cases, and encountered violations are addressed at the
origin. This essentially allows publishers to identify and correct violations before
they even occur; moreover, fixing violations early avoids propagation where one
flawed mapping rule leads to many faulty triples. The evaluation shows that our
methodology is applicable to (i) datasets without native [r2]rml mapping defini-
tions, such as dblp, (ii) large datasets, such as dbpedia, as well as (iii) datasets in
the whole process of defining their mappings, such as iLastic. It was proven that
assessing the quality of mapping definitions is more efficient in terms of computational complexity, and requires significantly less time to be executed compared
to assessing the entire dataset. As our evaluation indicates, it takes only a few
seconds to assess the mapping definitions, while it can be time-consuming and
performance-intensive when this happens at dataset level. Especially with large
datasets, this can take up to several hours. Our methodology was adopted by
both the community of significant public datasets, such as dbpedia, and several
projects, resulting in published Linked Data of higher quality. In the future, we
plan to automate and improve the application of mapping definition refinements
and integrate this step into the workflow of an interactive user interface.

Acknowledgements. This papers research activities were funded by Ghent Univer-
sity, iMinds, the Institute for the Promotion of Innovation by Science and Technology
in Flanders, the Fund for Scientific Research-Flanders and by grants from the EUs 7th
& H2020 Programmes for projects ALIGNED (GA 644055), GeoKnow (GA 318159)
and LIDER (GA 610782).
