Introducing Defeasibility into OWL Ontologies

Giovanni Casini1,2,4, Thomas Meyer3,4, Kody Moodley4,5(B), Uli Sattler6,

and Ivan Varzinczak4,7

1 University of Luxembourg, Luxembourg City, Luxembourg

2 Department of Philosophy, University of Pretoria, Pretoria, South Africa

3 Department of Computer Science, University of Cape Town,

4 Centre for Artificial Intelligence Research, CSIR Meraka, Pretoria, South Africa

5 School of Mathematics, Statistics, and Computer Science,

Cape Town, South Africa

University of KwaZulu-Natal, Durban, South Africa

kody.moodley@gmail.com

6 University of Manchester, Manchester, UK

7 Universidade Federal Do Rio de Janeiro, Rio de Janeiro, Brazil

Abstract. In recent years, various approaches have been developed for
representing and reasoning with exceptions in OWL. The price one pays
for such capabilities, in terms of practical performance, is an important
factor that is yet to be quantified comprehensively. A major barrier is
the lack of naturally occurring ontologies with defeasible features - the
ideal candidates for evaluation. Such data is unavailable due to absence
of tool support for representing defeasible features. In the past, defeasible
reasoning implementations have favoured automated generation of defeasible ontologies. While this suffices as a preliminary approach, we posit
that a method somewhere in between these two would yield more meaningful results. In this work, we describe a systematic approach to modify
real-world OWL ontologies to include defeasible features, and we apply
this to the Manchester OWL Repository to generate defeasible ontologies for evaluating our reasoner DIP (Defeasible-Inference Platform). The
results of this evaluation are provided together with some insights into
where the performance bottle-necks lie for this kind of reasoning. We
found that reasoning was feasible on the whole, with surprisingly few
bottle-necks in our evaluation.

1 Introduction

Reasoning with exceptions has been a major topic in AI since the 80s. Classical monotonic formalisms such as OWL, assume that represented knowledge is
infallible and do not admit exceptions; such systems generally cannot accommodate the addition of new information which contradicts what is known. For
example, if a monotonic system is told that Students do not pay taxes then,
upon encountering an exception (a student who works), it will still conclude that
this student is exempt from taxes [10].

Defeasible reasoning is concerned with the development of formalisms which
are able to represent and reason with defeasible (non-strict) facts: Typically,
c Springer International Publishing Switzerland 2015
M. Arenas et al. (Eds.): ISWC 2015, Part II, LNCS 9367, pp. 409426, 2015.
DOI: 10.1007/978-3-319-25010-6 27

G. Casini et al.

students do not pay taxes is the defeasible counterpart of Students do not pay
taxes.

Key approaches for defeasible reasoning in KR formalisms have been through
adaptations and combinations of the following systems: Circumscription [4],
Default Logic [22], Negation as failure [15], Probabilistic logic [17] and Preferential reasoning [6,8,10].

The theoretical foundation of our work is a Description Logic (DL) [1] adaptation of the preferential reasoning approach by Lehmann et al. [16]. DLs form
the logical underpinning of OWL and so our approach is applicable in this setting
as well.

The motivation for focusing on the preferential approach is that it derives
intuitive inferences using procedures that reduce to classical OWL reasoning.
This gives the advantage of being able to use off-the-shelf OWL reasoners
such as FaCT++ (owl.man.ac.uk/factplusplus) and HermiT (hermit-reasoner.com),
to perform defeasible inference. In particular, we have implemented a defeasible
entailment regime called Rational Closure (RC) in our reasoner DIP (Defeasible-
Inference Platform) [21]. This implementation is a variant of the one by Casini
and Straccia [8].

However, there is a lack of insight into the expected practical performance of
implementations such as DIP. A major barrier is the lack of tools for representing
defeasibility in OWL, which in turn leads to the absence of naturally occurring
data using defeasible features - the ideal candidates for testing performance.
Currently, the majority of datasets for testing defeasible extensions of OWL,
are automatically generated with the only mature attempt at a standardisation
being LoDEN (loden.fisica.unina.it).

Our main goal in this paper is to take the next step from completely synthetic data, to a systematic approach for introducing defeasible features into
naturally occurring ontologies that do not contain such features. We apply this
approach to construct a dataset for evaluating our RC implementation in DIP.
First, we introduce ALC, the DL of choice for our implementation and a defeasible notion of subsumption that we introduce into the logic. We then give a
concise description of RC for this logic and sketch the algorithms for computing
the construction. Section 3 is the heart of the paper, here we detail a procedure
for introducing defeasible subsumption into real-world ontologies and apply it
to the Manchester OWL Repository to generate data for evaluating the performance of RC. We present the results and compare these with related work.
Finally, we conclude by mentioning future work to be undertaken in the area.

2 Preliminaries

2.1 Description Logics

DLs are decidable fragments of first-order logic with a variety of applications,
notably the formalisation of ontologies. They are very popular since they represent the logical underpinning of the Web Ontology Language (w3.org/TR/
owl-features). In this paper we focus on ALC, a representative member of the
?

?

?
family of DLs, although our algorithms are applicable to a wide class of DLs, in
particular SHIQ [14] .
Let NC = {A1, A2, . . .} (resp. NR = {r1, r2, . . .}) be a finite set of class names
(resp. role names) s.t. (NC  NR = ). The language, L, of complex classes is:

C ::= A | C | C  D | C  D | r.C | r.C |  | 

ALC has a standard set-theoretic semantics defined in the provided reference [1].
A classical DL ontology consists of a TBox T (and optionally an ABox A),
T contains the terminology describing the domain of discourse, i.e., T is a finite
set of inclusion axioms C  D; such an axiom is read as C is subsumed by D,
that is, every individual that falls under the class C, falls also under the class
D. A is a finite set of instance axioms (called assertions) of the form C(a) or
R(a, b), where the former represents that a is an instance of the concept C, and
the latter that a is related to b via the role R. ALC has a classical monotonic relation of entailment, and we use |= to indicate this standard entailment relation,
i.e., T  A |=  indicates that all the interpretations satisfying all the axioms
contained in T and A also satisfy the axiom . There are efficient tools for
deciding ALC entailment. More details on DLs (ALC in particular [1]) and the
relationship between OWL and DL [9] can be found in the provided references.

2.2 An Algorithm to Compute Rational Closure in ALC
RC has a series of desirable properties from a formal perspective: the consequence
relation has a solid logical foundation, is characterised by a set of structural
properties that should be satisfied by any nonmonotonic formalism [5,16], and
its computation can be reduced to classical monotonic decision steps.
The applicability of RC to ALC is predicated on the ability to represent
defeasible information. To model such information, we introduce a type of inclu-
sion, i.e., a defeasible inclusion C  D, which is read as Typically an instance
of C is also an instance of D, that is, if we know that an object x is in the set
referred to by C, we can conclude that x is in the set referred to by D, unless
we have knowledge to the contrary. For the semantics of such axioms, we refer
the reader to the work by Britz et al. [5,6].
We consider knowledge bases (KBs) of the form K = T ,D, where T is a
DL TBox and D is known as a defeasible TBox (DTBox) which is a finite set
of defeasible inclusions. We are not considering ABoxes here - the algorithm we
introduce (based on the one by Casini and Straccia [8]), computes RC only considering classes. Given K = T ,D, it decides if C  D or C  D is a defeasible
consequence of K.
Example 1. Consider the KB K = T ,D, with T = {BactMen  Men, VirMen 
Men} and D = {Men  Fatal, BactMen  Fatal}. K is about meningitis (Men),
bacterial meningitis (BactMen), viral meningitis (VirMen), and their fatality
(Fatal).

G. Casini et al.

If all axioms in K were classical inclusion axioms, we derive BactMen   because
the facts lead to bacterial meningitis being both fatal (BactMen  Fatal) and
non-fatal (BactMen  Men, Men  Fatal). We would rather relax some strict
facts to cater for the atypicality of BactMen (meningitis is usually not fatal, but
bacterial meningitis is an exceptional type of meningitis because it usually is
fatal).
We shall indicate the set of materialisations of the axioms in D by D, where
the materialisation of an axiom C  D denotes the class expressing the same
subsumption relation of the axiom (i.e., C  D). Hence D = {C  D | C  D 
D}.
The classical translation of C  D is C  D. Similarly, for a set D = {C1
 D1,
...,Cn

 Dn}, the classical translation of D is D = {C1  D1, ..., Cn  Dn}.

The RC algorithm consists of a main procedure and two sub-procedures. The
first sub-procedure is called Exceptional. Its aim is to determine which of the lefthand side (LHS) classes in our inclusions are exceptional. Intuitively, a class is
exceptional in a KB if it is atypical w.r.t. one of its superclasses (e.g. BactMen in
the example above). The exceptionality of a class can be decided using |=, since
D  C. A
a class C is exceptional in K = T ,D if and only if T |=
defeasible axiom C  D  D is considered exceptional if its antecedent (LHS-
concept) C is exceptional. Given a finite set E of defeasible inclusion axioms,
Procedure Exceptional gives back the subset of E containing the exceptional
axioms.

Procedure Exceptional(T ,E)
Input: T ,E  D
Output: E  E such that E

1 E
2 foreach C  D  E do

E  C then
:= E  {C  D};

is exceptional w.r.t. E

:= ;
if T |=
E
5 return E

;

Since, in general, there may be exceptions-to-exceptions (perhaps a strain of
bacterial meningitis that is usually not fatal), we can compute this exceptionality ranking by recursive application of Procedure Exceptional. I.e., we associate a value to each axiom in the KB representing its degree of exceptionality.
ComputeRanking is the second sub-procedure that, using Exceptional, partitions the set D into R = {D0,D1, . . .}, where each set Di contains the defeasible
axioms having i as ranking value.
ComputeRanking receives KB K = T ,D as input and outputs an equivalent
KB K = T ,D (i.e., satisfied in the same interpretations as K [5]), but
in which implicit strict knowledge contained in the DTBox has been moved
to the TBox, and all the information in the DTBox has been ranked w.r.t. its
exceptionality. We call axioms which are implicitly strict and yet concealed in the
?

?

?
Procedure ComputeRanking(K)
Input: KB K = T ,D
Output: KB T ,D and the partitioning (ranking) R = {D0, . . . , Dn} for D
:=D; R:=;

}; D

:= D \ D
;

1 T 
2 repeat

:=T ; D
i := 0; E0 := D
E1 := Exceptional(T ,E0);
while Ei+1 = Ei do
i := i + 1; Ei+1 := Exceptional(T ,Ei);
:= T   {C  D | C  D  D
D
 := Ei; T 

;

 = ;

8 until D
9 for j = 1 to i do

11 return T ,D,R;

Dj1 := Ej1 \ Ej; R := R  {Dj1};

DTBox, totally exceptional axioms. Consider the KBs: K1 = {C  D, C  D}
and K2 = {E  D, C  E, C  D}. C is unsatisfiable w.r.t. K
2. In K
1 and K
1,
the unsatisfiability does not indicate an exception, whereas in K
2, it does. The
former case is a knowledge engineering problem, indicating logical incoherence
in defeasible KBs, while the latter is not considered such.
Sub-procedure Exceptional reaches a fixed point Ei = Ei + 1 (Ei is possibly
empty) during Procedure ComputeRanking. If Ei is not empty, then it represents
a set of totally exceptional axioms, and we assign  as the ranking value to each
of these axioms (indicated by D
). We move such information to the TBox (that
is, if C  D is in D
, we eliminate it from D and add C   to T ). We repeat
the procedure (Lines 2-8) until all implicit strict facts in D are moved to the
TBox. Consider the example:
Example 2. Consider K = T ,D, with T = {E  D} and D = {F  r.C,
C  D, C  E}. Applying Procedure ComputeRanking, we obtain that C is
 =
exceptional,
{C  D, C  E}, and therefore, T  = {E  D, C  } and D = {F  r.C}.
Repeating Lines 2-8 of the procedure we get E1 = E0 = {F  r.C}, hence
 = {F  r.C} and we end up with a TBox T  = {E  D, C  , F  }
D
and an empty DTBox.
Once the procedure has identified T ,D, it ranks the remainder axioms in the
DTBox (if any): an axiom has ranking value i if i is the highest label for which it
turns out to be exceptional. The result is a partition of D into R = {D0, . . . ,Dn}.
Example 3. Consider K in Example 1. ComputeRanking takes K as input, executes Lines 2 - 8 to obtain the sequence E0 = D, E1 = {BactMen  Fatal}, E2 = 
and the TBox T  = T . Finally, applying Lines 9 - 10, we obtain the partition
D of D0 = {Men  Fatal}, D1 = {BactMen  Fatal}.
Given our computed ranking, we can ask queries of the form C  D. Note that if
we are confronted with a strict query (classical inclusion axiom C  D), one can

i.e., E2 = E1 = {C  D, C  E}. This means that D

G. Casini et al.

Procedure RationalClosure(K,)
Input: KB K = T ,D with no implicit strict facts, E0, . . . , En, query
Output: true iff C  D is in the RC of K
Ei  C   and i  n do

 = C  D.

1 i := 0;
2 while T  |=
i := i + 1;
4 if i  n then
return T  |=
return T  |= C  D;

6 else

Ei  C  D;

determine if it is in the RC of the KB by checking if it is classically entailed by the
strict facts alone in K (that is, T ). This was implemented as an optimisation.
However, for simplicity, Algorithm RationalClosure considers only the case in
which the query is a defeasible inclusion axiom. The algorithm takes the ranking
R and query C  D as input, determines which portion of R is compatible with
the class C, i.e., which portion of defeasible knowledge does not imply that C is
exceptional, starting from the most normal situations up to increasing levels of
exceptionality. By example:

ranking R in Example

the

Example 4. Consider
and the query
E0  VirMen, which
VirMen  Fatal. The RC algorithm checks if T  |=
E0  VirMen  Fatal, which
is not the case. Hence, we have to check if T  |=
is true. However, if our query is BactMen  Fatal, we obtain a different result:
E1  BactMen, BactMen is an
since T  |=
exceptional class of level 1, compatible with D1, and we have to move one level
higher in the ranking eliminating the facts in D0 from consideration. It turns
E1  BactMen  Fatal, and that is the right conclusion since
out that T  |=
we have BactMen  Fatal in our KB.

E0  BactMen but T  |=

The correctness of Algorithm RationalClosure follows from the procedure by
Casini and Staccia [8] as it is a reformulation thereof. The computational complexity of the entire procedure is the same as that of the underlying monotonic
entailment relation |=, i.e., it is an EXPTIME-complete problem ([5] and [8,
Corollary2]). Moreover, note that the defined procedures can be applied to DLs
more expressive than ALC, still preserving the computational complexity of the
decision problem w.r.t. the underlying monotonic entailment relation, and, is
still sound and complete for logics up to SHIQ. Using a more expressive DL
than ALC, the defeasible information will still be represented only by defeasible
inclusion axioms C  D, while the strict information different from ALC inclusion axioms (role inclusion axioms, role transitivity, etc.) must be considered as
background knowledge at each step of the decision procedure.
?

?

?
3 Performance Evaluation

An important question about RC is: how much do we pay for the additional
expressivity, in terms of practical reasoning performance? We have shown that
the worst case computational complexity of RC in ALC is not higher than reasoning with classical ALC. This is good news, but does not guarantee good
performance in practice. As illustrated in our algorithms (Section 2.2), we have
to perform some additional computation over and above the classical decision
checks. In general, we perform multiple classical entailment checks to answer a
single defeasible entailment question. The question is how much more work are
we doing. We aim to investigate this in order to provide evidence of the feasibility
of adding defeasible features to ontologies.

In terms of data, the norm until now has been the use of automatically
generated ontologies with defeasible features (the most notable attempt at a
benchmark of synthetic defeasible ontologies is LoDEN). Indeed, we have also
used synthetic data in the past as a preliminary indicator of performance [7].
Naturally, there are obvious shortcomings with such an approach, such as possible biases in the ontology generation methodology. However, there is no question
of finding representative data because there are virtually no naturally occurring
ontologies with intended defeasible features.

We instead choose a middle-ground approach, taking advantage of the rich
set of (classical) OWL ontologies on the Web in various repositories and cor-
pora. The basic idea is to modify selected subsumptions in these ontologies to
be defeasible, thereby making them useful as data to evaluate our defeasible
reasoner. Of course, this has to be done with care to generate cases which are
challenging for the reasoner. For example, we need to ensure that there are
cases where there are multiple ranks in the ranking of the ontology (see Procedure ComputeRanking). Our method is described in Section 3.2, together with
a discussion about its strengths and weaknesses. Now, we describe the curation
process used for sampling our initial set of unmodified OWL ontologies.

3.1 Non-defeasible Dataset

For our initial data, we sample some classical OWL ontologies which we can
later pass through our procedure for the introduction of defeasible features. The
natural choice is to select the same data that is traditionally used to evaluate
the performance of existing classical OWL reasoners. However, even in such a
setting, there is no precise concensus on what data to use. The result is that data
is generally curated manually by choosing well-known ontologies and corpora
from which to sample, or arbitrarily selecting from the variety of respectable
corpora on the web.
Choice of Corpora: While there are bona fide ontology benchmarks available such as LUBM [11] and its extensions, it was pointed out that there are
shortcomings in manual selection of ontologies and ontology corpora for evaluation [18]. In particular, the main limitation with such selections is that they lack

G. Casini et al.

sufficient variety. Thus the results of evaluations can be heavily biased towards
the selected benchmarks. The Manchester OWL Repository [19] is an effort to
address this issue. The Repository is a framework for sharing ontology datasets
for OWL empirical research. The current version of the repository contains three
core datasets, namely versions of NCBO Bioportal (bioportal.bioontology.org),
The Oxford Ontology Library or OOL (cs.ox.ac.uk/isg/ontologies) and MOWLCorp [18]. While Bioportal and OOL are established corpora actively used in
reasoner evaluations, MOWLCorp is a recent gathering of ontologies through
sophisticated web crawls and filtration techniques [18].

We obtain a recent snapshot of the Manchester OWL Repository as the
base dataset for our evaluation. There are 344, 793 and 20,996 ontologies in the
Bioportal, OOL and MOWLCorp corpora respectively.
Filtration Process and Choice of OWL Reasoner: For loading and
analysing ontologies of our dataset, we use the popular and well-supported Javabased OWL API [13]. The API contains parsers for a wide variety of different
syntaxes of ontologies such as RDF, Turtle and OBO. As we have shown in
Section 2.2, our algorithms are built upon classical entailment checks. Thus, we
would need to select an existing OWL 2 DL reasoning implementation to perform these classical entailment checks from within our defeasible reasoner. While
running our evaluation with multiple reasoners would have been interesting, such
an investigation is not necessary to ascertain the price we pay for reasoning with
defeasible (in addition to classical) subsumption. We chose to utilise a single
OWL 2 DL reasoner for our evaluation. In particular, we would ideally like to
use the fastest and most robust implementation.

Consulting the latest results of the OWL Reasoner Evaluation Workshop (dl.
kr.org/ore2014/results.html), we identified the top three OWL 2 DL reasoners for
the standard reasoning tasks of: classification, consistency checking and satisfiability testing (in terms of performance and robustness). Robustness was measured as the number of ontologies that were successfully processed in the allotted
time. The top reasoners were Konclude (derivo.de/produkte/konclude.html), Her-
miT, MORe (cs.ox.ac.uk/isg/tools/MORe), Chainsaw (chainsaw.sourceforge.net),
FaCT++ and TrOWL (trowl.org). As we shall see in Section 3.2, we require
to check incoherence of ontologies before introducing defeasible subsumptions
into them. Modern OWL reasoners are optimised for classification (computing
the subsumption relationship between each pair of class names in the ontology),
and identifying unsatisfiable class names (incoherence) is usually performed by
first classifying the ontology, and then reading the unsatisfiable class names
from the results. Thus, we chose to focus on the reasoners which performed best
in OWL 2 DL classification. These were respectively, Konclude, HermiT and
MORe. Konclude, unfortunately, does not yet support the OWL API. There-
fore, our choice was to select the next best reasoner - HermiT.

Given our choice of tools for manipulating and reasoning with the ontologies
in our dataset, we filtered out the ontologies that could be loaded and parsed
by the OWL API (each within an allotted 40 minutes). The resulting ontologies were then tested to determine if they were classifiable by HermiT within an
?

?

?
additional 40 minutes each. Ontologies which did not pass this test were removed
from the data. In order to remove some of the cases which are very likely to be
easy for our reasoner, we elected to remove ontologies with less than 100 logical axioms (ignoring annotations and other axioms carrying meta-information).
This is justifiable because ontology size is proven to be an overwhelmingly dominant factor in reasoning performance [24]. Finally, we stripped the ontologies
of ABox data because our defeasible reasoner is currently purely equipped with
(D)TBox entailment procedures. This leaves us with 252, 440 and 2335 ontologies
in Bioportal, OOL and MOWLCorp respectively.

3.2 Defeasible Dataset

In this section, we describe a systematic technique to introduce defeasible subsumptions into ontologies, thereby making them amenable to defeasible reasoning evaluation.
Methodology: Our approach hinges upon an important correspondence
between class exceptionality (as described in Section 2.2) and classical class
unsatisfiability:
Lemma 1. If a class C is exceptional w.r.t. a defeasible KB T ,D then C is
unsatisfiable w.r.t. T  D, where D is the classical translation of D.

Lemma 1 states that if a class is exceptional in a defeasible ontology then
it will necessarily be unsatisfiable in the classical translation of the ontology.
This result is useful because we can use it to identify possible exceptional classes
in classical ontologies. Taking the contrapositive of Lemma 1, we obtain the
result that if a class is satisfiable w.r.t. a classical ontology then it is necessarily
not exceptional w.r.t. any defeasible translation of the ontology. Therefore, we
can eliminate ontologies from our dataset without LHS-classes of subsumptions
that are unsatisfiable, because these could never become exceptional by turning
classical subsumption into defeasible ones.

The following definition is a generalisation of standard incoherence to axioms

with complex left hand side (LHS) concepts:
Definition 1. A classical TBox T is LHS-coherent if each C  D  T is
s.t. T |= C  . T is LHS-incoherent if it is not LHS-coherent.
Eliminating all ontologies from our dataset that are LHS-coherent leaves us
with 11, 46 and 77 ontologies in the Bioportal, OOL and MOWLCorp corpora
respectively. Figure 1 provides some average properties of the ontologies in our
dataset.

Thus, in total we have 134 ontologies for our performance evaluation. Now,
the task is to relax some of the subsumptions of our ontologies to be defeasible.
The obvious na ve approach to introducing defeasibility would be to convert all
subsumptions to defeasible ones. Naturally, this is not likely to be the general
approach of defeasible-ontology engineers in practice. The other extreme would

G. Casini et al.

Fig. 1. Ontology metrics for the LHS-incoherent cases in the dataset.

be to develop an approach to identify the minimal (for some defined notion of
minimality) amount of defeasibility to introduce into the ontology in order to
successfully cater for all the exceptions. The latter approach would be ideal,
and we are currently investigating such an approach; however, we propose that
a reasonable approximation of such an ideal procedure yields meaningful data
for performance evaluation. The approach that we discuss here is in the spirit of
such an approximation.
Example 5. Consider the following TBox T about different types of mechanics
(Mech), general (GenMech), car (CarMech) and mobile (MobileMech):
{1. Mech  hasWorkshop., 2. Mech  hasSpecialisation.,
3. MobileMech  GenMech  CarMech  Mech, 4. MobileMech 
hasWorkshop., 5. MobileMech  status.OnStandBy  hasWorkshop.,
6. GenMech  hasSpecialisation., 7. CarMech  hasSpecialisation.Car}
The classes MobileMech, GenMech and the class expression MobileMech 
status.OnStandBy are unsatisfiable w.r.t. T . An intuitive analysis of T tells us
that the ontology engineer probably intended to model that mechanics usually
have a workshop (Mech  hasWorkshop.) and usually specialise in certain types
of equipment that they repair (Mech  hasSpecialisation.). This translation of
Axioms 1 and 2 in Example 5, is a minimal and intuitive way to introduce
defeasibility into T , catering for exceptional types of mechanic - i.e., mobile and
general mechanics.
However, we also have an exceptional type of mobile mechanic in T
(an exception-to-an-exception). That is, mobile mechanics who are no
longer on standby or on call (MobileMech  status.OnStandBy). These
mechanics would then be assigned a workshop for their repair tasks. To
cater for such mechanics we would have to relax Axiom 4 of Example 5
as well, to express that mobile mechanics usually dont have a workshop
(MobileMech  hasWorkshop.).

We now define a general defeasible translation function (DTF) for converting

classical subsumptions to defeasible subsumptions in classical ontologies.
Definition 2. (DTF) Let T be a set of classical subsumptions of the form C 
D, then F : T  {C  D | C  D  T }  T is a DTF for T .
We also have to formalise what we mean when a particular DTF caters for all
exceptions in the TBox. We call such a function a safe DTF.
?

?

?
Definition 3. (safe DTF) Let T be a set of classical subsumptions, let F be
a DTF for T and let D be the special DTF that translates all subsumptions in
T to defeasible ones. Then, F is a safe DTF for T if C is totally exceptional
w.r.t. D(T ) if and only if C is totally exceptional w.r.t. F (T ), for each C 
D  T .
We define a safe DTF that places a small upper bound on the subset of axioms
to relax using the well-known notion of justification [12]. A justification for an
entailment  of an ontology is a minimal (w.r.t. set inclusion) subset of the
ontology that entails . If we compute the justifications for T |= MobileMech  
(concise reasons for MobileMech being unsatisfiable and possibly exceptional)
we obtain a single justification {1, 3, 4}. Relaxing these axioms is sufficient for
catering for mobile mechanics (in fact, it is only necessary to relax Axiom 1 as
mentioned earlier). Similarly, we arrive at {2, 3, 6} to cater for general mechanics
and {4, 5} for mobile mechanics no longer on call.

The basic idea is thus to take the union of the justifications for the unsatisfiable LHS-classes and relax these axioms to defeasible ones. We obtain that
{1, 2, 3, 4, 5, 6} should be relaxed in Example 5, which is admittedly a large proportion of our TBox. However, as we discover in Section 3.4, the proportion is
much smaller in practice on larger real-world ontologies. However, while computing all justifications has been shown to be feasible in general on real-world
ontologies, black-box (reasoner-independent) procedures are known to be exponential in the worst case [12]. To avoid this potential computational blowup, we
obtain a small upper bound of the union of justifications by extracting a star
locality based module [23] for the ontology in question, w.r.t. the set of unsatisfiable LHS-classes. A module of an ontology w.r.t. a signature (set of terms from
the ontology) is a small subset of the ontology that preserves the meaning of
the terms in the signature. We specifically choose star locality based modules
because of two key properties: (i) they preserve all justifications in the ontology
for all entailments (or axioms) that can be constructed with the given signature (depleting property [23, Section3]), and (ii) they are smaller in size relative
to other modules which have the depleting property. The pseudocode of our
procedure is given in Algorithm 1.

Algorithm 1. relaxSubsumption
Input: LHS-incoherent TBox T , C = {C | (C  D  T for some
Output: Defeasible ontology T ,D

D)  (T |= C  )}

1 T := ; D := ;M := extractStarM odule(O, sig(C)); T := O\M;
2 foreach X  Y  M do
D := D  {X  Y };
4 return T ,D;

G. Casini et al.

Theorem 1. (safety of our DTF) Let F be the DTF defined by Algorithm 1
and let T be a set of classical subsumptions, then F is a safe DTF for T .
Discussion: There are two conflicting issues with the procedure we have presented for introducing defeasibility into OWL ontologies: (i) minimality of modification to the original ontology and (ii) the representative quality of the resulting defeasible ontology as something that might be built by a ontology engineer.
While (i) and (ii) would be the ultimate goal for a methodology automating the
introduction of defeasible features into OWL ontologies, our approach does not
yet meet such desiderata. It is clear that the minimal axioms to relax in Example 5 would be {1, 2, 4}, yet we relax {3, 5, 6} as well. On a related note, relaxing
{1, 2, 3, 4, 5, 6} does not capture a natural defeasible translation. For instance,
it does not make sense, intuitively, to relax MobileMech  Mech (all mobile
mechanics are mechanics) to MobileMech  Mech (typical mobile mechanics are
mechanics). Such constraints should ideally remain strict.

Furthermore, a critical observation is that incoherence in classical ontologies
may be caused by erroneous modelling. In ontology development tools, large
emphasis has been placed on debugging incoherence by making modifications
to the ontology to remove the unwanted entailments such as C  . This is
likely to have prevented many developers publishing incoherent ontologies.

Given the above main shortcomings of our approach, we do not argue that our
approach is the ideal methodology. Rather, we hope that it serves as a stepping
stone from purely synthetic approaches to investigate and develop more suitable
methodologies.
Hypotheses: Our general predictions for the evaluation are that (i) the ranking computation will be dramatically more performance intensive than testing
entailment, (ii) entailment testing will be feasible for on-demand use and (iii)
the number of incoherent LHS-classes (and the number of defeasible subsump-
tions) will affect the performance significantly, (iv) we anticipate the occurrences
of totally exceptional LHS-classes to be rare and minimal, (v) since these cases
also require recursive execution of the ranking procedure, we also anticipate such
cases to be significantly harder for reasoning and (vi) in terms of the ranking of
the defeasible subsumptions in the ontologies, we expect there to be not more
than 2 levels of exceptionality (or 3 ranks in total). I.e., we expect exceptions-
to-exceptions in the data, although we anticipate very few of these cases. We
expect the majority of cases to have either no exceptions or 1 level of exception
(2 ranks in total). Of course, we also predict a general trend of the higher the
number of (logical) axioms in the ontology, the longer to compute inferences.

3.3 Experiment Setup

Our setup, methodologies and design choices for the experimental evaluation can
be summarised as follows:
Data Summary: The input data for our experiments are 134 LHS-incoherent
ontologies (curated as described in Section 3.1) from the Manchester OWL
?

?

?
Repository. The ontologies are divided across three corpora: 11 , 46 and 77 in
Bioportal, OOL and MOWLCorp respectively. The average ratio of defeasible to
strict axioms in each ontology is 8%, the median being 1.5%, the minimum ratio
being 0.01% and the maximum being 98%. The DL expressivity distribution of
the data ranges from variants of ALC all the way up to SROIQ. There are 35
DL variants in total represented in the data.
Additionally, we generated a set of entailment queries (defeasible subsumptions of the form C  D and strict subsumptions of the form C  D) for each
ontology to present to our defeasible reasoner. For the Cs, we focus on all LHSincoherent classes in the ontology. The motivation is two-fold: (i) if we instead
focus on Cs that are satisfiable, we would not require execution of Lines 2-3 of
Algorithm RationalClosure in Section 2.2 because C could never be exceptional
(see Lemma 1). Thus, we focus on incoherent Cs since these are the only ones
which could possibly be exceptional and result in harder cases for reasoning.
Instead of generating such incoherent Cs, we use the existing LHS-concepts
that are unsatisfiable in the ontology as a preliminary strategy. Admittedly,
generating incoherent Cs might also be interesting for future evaluation.
For the Ds we first take the -syntactic locality module for the ontology
w.r.t. to the signature of C (including ), and then take all nested class expressions present in the axioms of this module. The reason being that we want to
preserve entailments over the signature of C in the module. We collect all LHSincoherent classes C from the ontology and then collect all class expressions in
the -module for C to be the consequents D. We then test if C  D (and C  D)
is in the RC of the defeasible ontology. All our data is available for download in
ZIP format (cair.za.net/ontologies).
Tasks: The first task is precompiling exceptionality rankings for each ontology
in the dataset. Rankings are then stored on file for later use in entailment testing.
It is important to note that the computation of the ranking is considered as an
offline, precompilation process for each stable version of an ontology. Such a
task is not meant to be executed on-demand during defeasible entailment tests.
Lemma 1 is used as an optimisation in the ranking procedure. We only need check
exceptionality of C  Ds where C is unsatisfiable w.r.t. the classical translation
of T ,D (see Lines 2 to 4 of procedure Exceptional in Section 2.2).

The entailment tests are then performed on the stored rankings and results
of both tasks are recorded. We recorded the average time it took to compute
the rankings, and to answer entailment questions, with some additional metrics
which we present in Section 3.4. For entailment tests, we made no use of any
optimisation.
Equipment: The evaluation was carried out on an Intel Core i7 2.5Ghz processor running MacOSX 10.10. 8GB of memory is allocated to the Java Virtual
Machine (Java version 1.6 is used). HermiT is the classical OWL 2 DL reasoning
implementation.
Reproducible Steps: Assuming we have already obtained our dataset (set
of ontologies) and generated set of queries for each ontology (as described in

G. Casini et al.

the above data summary), the steps required to conduct the evaluation are as
follows: (1) Compute the ranking (according to Procedure ComputeRanking)
of each ontology, record the time required and store it to file (use optimisation
described in Lemma 1 to avoid checking if satisfiable concepts are exceptional),
(2) for each ontology, execute its set of queries on its stored ranking (using
Procedure RationalClosure) and record timings.

3.4 Results and Analysis
The overall results for computing the rankings and testing entailment have
proven to be extremely promising. Figure 2 gives an overview of some of the
more pertinent results w.r.t. the computation of rankings.

Fig. 2. Ontology metrics and ranking computation results for the dataset.

Ranking Performance: Examining the ranking times in Figure 2, we notice
that on average over the entire dataset, it takes 10 minutes to rank a single
ontology. However, looking at the median column of the ranking shows the
majority of rankings were computed in less than a second. There are just four
outlier ontologies which breach the 2000 second mark, while the maximum
ranking time for the remainder of the data is 1000 seconds. The reason is that
these four ontologies have the most number of unsatisfiable LHS classes in the
data (requiring more exceptionality checks). It must be stressed that the ranking computation is concerned with stratifying only the defeasible axioms in the
ontologies. Therefore, in general, the ranking times increase with the number of
defeasible axioms (see Figure 3a). A key insight is when the number of entailment
checks and ontology size (number of subsumptions we are checking entailment
w.r.t.) is maximised, then performance will be worst for these cases.

The most challenging cases, in theory, for our reasoner are those with totally
exceptional LHS-classes in the ontology. These cases are more intensive because
we have to recursively apply the ranking procedure (see Lines 2-8 of Procedure ComputeRanking in Section 2.2), until all the totally exceptional information is added to the TBox. In our dataset of 134 ontologies, roughly 30% of them
have totally exceptional LHS-classes.

Figure 3b shows that, even restricted to cases with totally exceptional LHS-
classes, the ranking performance is well inside 100 seconds for the vast majority of the cases. The reason, we conjecture, is that the numbers of defeasible axioms in these ontologies stay relatively low allowing the performance to
stay in check. Figure 4a illustrates the number of recursions required in Procedure ComputeRanking for these cases.
?

?

?
(a) V.s. no. of defeasible axioms.

(b) V.s. totally exceptional LHS-classes.

Fig. 3. Ranking computation performance (ranking time).

(a) Iterations required of ranking proce-
dure.

(b) Inference performance across dataset.

Fig. 4. Recursion in ranking procedure (4a) and defeasible inference performance (4b).

While there are some cases with 3 and 4 repetitions, the majority of cases
require just one repetition. This, together with the fact the average number of
defeasible axioms for these ontologies is just 127, explains the very low impact
on performance that these hard cases have. In fact, the average number of
defeasible axioms for these cases is significantly lower than that of any of the 3
general corpora in the dataset (see the table in Figure 2). We also notice that
a key factor in performance is the number of LHS-classes that are unsatisfiable.
Because of the optimisation represented by Lemma 1, we only need check exceptionality for these classes. Therefore the ratio of these incoherent classes to the
ontology size will have a major impact on performance. Finally, we note that
our hypothesis turns out to be correct concerning the number of ranks in the
computed rankings. The average is 2 (single level exceptions), while there are a
sprinkling of cases in which there are 3 ranks.
Entailment Performance: The performance of defeasible entailment in the
data is also encouraging. It seems that once the ranking of an ontology is
obtained, the majority of defeasible entailment queries can be answered instantly.
The average time to decide a defeasible entailment was 145ms.

The median is just 4ms highlighting that most of the entailments can be be
computed almost instantly. As in the case of the ranking performance behaviour,
there are a few outlier cases which prove much harder than in general. In one
particular BioPortal ontology (the most difficult ontology in the data), it takes
on average 9.6 seconds to compute a defeasible entailment. There are, however,

G. Casini et al.

421,268 logical axioms in this ontology, of which 6010 are defeasible and 4716
have LHS-concepts that are classically unsatisfiable.

94% of the ontologies in our dataset take less than 200ms on average to
decide defeasible entailment. It is not surprising that the prevalence of totally
exceptional concepts does not significantly impact the performance of defeasible inference. This is likely because such information was moved to the TBox
in the ranking step and therefore of little importance performance-wise during
inference.

The dominant factor in performance (for both ranking compilation and
query performance) remains ontology size and number of defeasible axioms (see
Figure 4b). Because of the low variance in the number of ranks in ontology rankings (between 0 and 3), it is not surprising that this does not significantly impact
performance, although we omit the graph illustrating this due to space con-
straints. It must be stated, though, that in theory the number of ranks will affect
performance especially in the case where the exceptionality of the antecedent of
the query is high. I.e., in such cases the number of repetitions of the while loop
in Procedure RationalClosure will be higher.

4 Related Work

From a practical standpoint, the most closely related work is that of Bonatti et
al. [2]. They introduce a new DL called DLN
for handling exceptions by allowing
or blocking inheritance of certain properties to these exceptions. While the extra
features of DLN
can be built on top of any classical DL, the authors apply their
evaluation to ontologies of EL-variants [1]. They also use an underlying classical
OWL reasoner ELK (cs.ox.ac.uk/isg/tools/ELK) which is highly optimised for
such logics. In addition, they exploit incremental reasoning capabilities of ELK
so unnecessary repetition of computations is not required with small changes to
the ontology.

The authors use two approaches

for extending the Gene Ontology
(GO) (geneontology.org), with defeasible features. The first, is a principled injection of purely synthetic defeasible inclusions into GO, and the second is the
translation of a random subset of classical inclusions in GO to defeasible ones.
A direct comparison of their results with ours is non-sensical. (i) Their data is
derived through synthetic modifications of GO which are expressed in variants
of EL (rather than our ALC variants of different ontologies), (ii) they generate
cases with between 5 and 25 percent of subsumptions being defeasible (whereas
we utilise our DTF with no direct control of this percentage), (iii) their experiment machine is allocated 18GB of memory (whereas ours is restricted to 8GB)
and (iv) they exploit the incremental reasoning of ELK which greatly increases
the performance of reasoning (whereas we do not make use of such facilities).
Nevertheless, for interests sake, their KB precompilation times (query time is
negligable after precompilation) roughly vary between 25 and 115 seconds under
these conditions.
We have, ourselves, also employed synthetic generation of data [7] in the
past. All of the data in this evaluation were ALC ontologies and had between
?

?

?
150 and 5150 axioms. We varied the percentage of defeasible to strict axioms
in the ontologies, in increments of 10, between 10 and 100 percent. A direct
comparison with our results is also not suitable here, although our ranking times
ranged between 0.5 seconds in the 10 percent case, to roughly 8 seconds in the
100 percent case. Query times, thereafter, ranged between 3 and 18 milliseconds
for these respective cases.

We also know of some mature Circumscriptive [20] approaches that have been
implemented [3,4]. However, the performance results of such implementations
remain unpublished to the best of our knowledge.

5 Conclusions and Future Work

We have presented a systematic and intuitive approach to introduce defeasible
subsumption into real-world OWL ontologies. Applying this to the Manchester
OWL Repository, we were able to generate test cases to evaluate the performance of Rational Closure implemented in DIP (Defeasible-Inference Platform).
We report that this kind of defeasible reasoning is quite feasible on our principally
generated data. While there are some mentioned limitations of our approach, we
argue that the data we generate can give meaningful insight into the performance of RC for real-world ontologies. In conclusion, we hope that our approach
provides a stepping stone to developing more sophisticated methodologies for
introducing defeasible features into real-world ontologies, and that it will spur
more investigations into the performance of defeasible reasoning in general.

Acknowledgments. Part of the work of Giovanni Casini has been supported by the
Fonds National de la Recherche, Luxembourg, and cofunded by the Marie Curie Actions
of the European Commission (FP7-COFUND) (AFR/9181001).
