A Linked Data Platform for Finite Element Biosimulations

Muntazir Mehdi, Yasar Khan, Andre Freitas,

Joao Jares, Stefan Decker, and Ratnesh Sahay

Insight Centre for Data Analytics

National University of Ireland, Galway (NUIG)

{firstname.lastname}@insight-centre.org

Ireland

ABSTRACT
Biosimulation models have been recently introduced to understand the exact causative factors that give rise to impairment in human organs. Finite Element Method (FEM)
provides a mathematical framework to simulate dynamic biological systems, with applications ranging from human ear,
cardiovascular, to neurovascular research. Due to lack of
a well-integrated data infrastructure, the steps involved in
the execution and comparative evaluation of large Finite Element (FE) simulations are time consuming and are performed in isolated environments. In this paper, we present
a Linked Data platform to improve the automation in inte-
gration, analysis and visualisation of biosimulation models
for the inner-ear (cochlea) mechanics. The proposed platform aims to help domain scientists and clinicians for exploring and analysing Finite Element (FE) numerical data
and simulation results obtained from multiple domains such
as biological, geometrical, mathematical, physical models.
We validate the platform by conducting a qualitative survey and perform quantitative experiments to record overall
performance.

Keywords
Healthcare and Life Sciences (HCLS), Biosimulation, Linked
Data, Reference Architecture, Finite Element Method

1.

INTRODUCTION

The creation of computational biosimulation models plays
a fundamental role in the scientific practice with regard to
the understanding of biological systems [4]. Mathematical
models have been recently introduced into the study of human organ physiology and pathology, giving insight into the
systems behaviour and attributes that would have been impossible to have with human in-vivo studies. Finite Element Method (FEM) provides a mathematical and computational framework to simulate dynamic biological systems,
with applications ranging from human ear, cardiovascular,
to neurovascular research. A FE biosimulation depends on

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

SEMANTiCS 15, September 15-17, 2015, Vienna, Austria

c 2015 ACM. ISBN 978-1-4503-3462-4/15/09. . . $15.00
DOI: http://dx.doi.org/10.1145/2814864.2814884

the creation of models which span across multiple, complex
and semantically incompatible domains, such as biological
models, geometrical structures and mathematical-physical
models.

With the growing complexity and sophistication of FE
biosimulation models, the effort associated with the creation
and analysis of an FE model can grow unmanageable. In
many cases these FE models are neither interoperable, nor
are they annotated in a sufficiently consistent manner to support intelligent searching or integration of available models.
In the extreme case, a biosimulation model contains no explicit information about what it represents  it is only a system of mathematical equations encoded in a computational
language. The subject of the model is implicit in the code
with an abstraction of a system into mathematical parameters and equations that must be interpreted by a researcher.
The FE model, representing different and often heterogeneous mathematical parameters are simulated within a few
days or even overnight. Due to lack of a well-integrated data
infrastructure, the steps involved in the execution and comparative evaluation of a large-scale finite element simulation
such as preparing input numerical parameters, solver usages,
visualisation and result/output interpretation are time consuming and often performed in isolated environments.

In this paper we present a Linked Data platform aiming
to improve the automation in integration, interpretation and
visualisation of biosimulation models for inner-ear (cochlea)
mechanics. The aim of the proposed platform is to facilitate the reproducibility, reuse, interoperability and automation of FE models with the support of Semantic Web standards and tools. As most of FE data is numerical, this work
explores mechanisms to bridge (link) data on the numerical to the conceptual (ontology) level, facilitating and automating the interpretation of the simulation results. A link
established between a numerical parameter to an ontological concept enables exploring intrinsic dependencies between
the simulation data and its associated algorithmic resources
(equations, parameters). The main contributions of this paper are: i) a Linked Data enabled reference architecture for
FE biosimulation domain; ii) a brief definition of a conceptual model for automating the interpretation of FE data
based on Semantic Web standard; iii) development of the
proposed platform as an open-source framework; and) validating the proposed platform on a real-life use case including
experimental datasets, terminologies, and models provided
by clinical organisations. Although, the proposed platform
is validated against an inner-ear use case, we argue that the
platform can be tailored with minor adjustments to other


This paper is organized as follows: Section 2 describes
the motivational scenario behind our work; Section 3 describes the proposed reference architecture for biosimulation domain with semantic technologies; Section 5 presents
the concrete architecture designed to sustain our use-case;
Section 6 describes related work preceding conclusions and
future work given in Section 7.

2. MOTIVATION SCENARIO

Our work is motivated by the need of clinical organisations and labs conducting biosimulation experiments to understand the exact pathophysiological consequences and risk
factors of hearing impairment in humans. Our work is conducted in context of the SIFEM EU project1, which aims
at developing an open-source linked data platform for Finite Element multi-scale modeling and biosimulation of the
sensorineural hearing loss. There are three major parts to
the ear, with distinct functions; The outer ear collects sound
waves and funnels them towards the middle ear. The middle
ear ossicular chain oscillates in response to the airborne pressure waves, generating pressure waves in the inner ear fluid
chambers. The inner ear turns pressure waves into electrical
signals that our brain can understand. The hearing impair-
ments, which could lead to hearing loss, are mainly caused
by cochlear and cochlear nerve pathology and are classified
as sensorineural hearing loss [9]. This is by far the com-
monest, and may be caused by the normal ageing process
(presbyacusis), noise (noise-induced hearing loss), medica-
tions, or genetic causes.

The inner ear is inaccessible during life, which leads
to unique difficulties in studying its normal function and
pathology. Thus, biopsy, surgical excision and other conventional techniques of pathologic studies are not feasible,
without further impairing function [9]. Therefore, insight
into the pathologic basis of inner-ear disease can be obtained
only by post-mortem studies of the cochlea and by developing credible animal models. Mathematical modelling is
therefore particularly attractive as a tool in researching the
cochlea and its pathology. Mathematical models were introduced into the study of cochlear pathology and physiology,
providing a useful tool in order to observe the systems be-
haviour, which was impossible in previous human in-vivo
studies [11]. The Finite Elements Method (FEM)  a mathematical framework  is assisting researchers to study the
structure-function relationship in normal and pathological
cochlear. Also, FEM could assist the rehabilitation of sensorineural hearing loss by providing insights into the planning of novel surgical procedures.

Figure 1 shows a set of FE parameters, values and their
datatypes required to model the cochlea (inner-ear). Usu-
ally, hundreds of such parameters and millions of instances
(i.e, values) are required to construct a full-fledged cochlea
(inner-ear) model. Once a set of parameters and values are
collected a numerical solver  called PAK Solver [6] developed by the SIFEM consortium  performs the finite element
calculations with simulation results displayed in graphical
format. The proposed linked data platform addresses following challenges in integrating, interpreting and visualising numerical parameters along with simulation results: (i) resolve
different data formats by transforming them into standard

1http://www.sifem-project.eu/

Parameter  Type 

Parameter  Value 

Datatype 

MESH DIVISIONS 

4.0 4.0 3.0 

DIV_L, DIV_W, DIV_H   

GEOMETRY 

0.035 0.001 0.001 3.0E-4 5.0E-5 

(DOUBLE)LENGTH (DOUBLE)HEIGHT 
(DOUBLE)WIDTH 

LOAD FREQUENCY  

50  1.0 

(DOUBLE)FREQUENCY (DOUBLE)VALUE  

MATERIAL PROPERTY 

1000  1500.0  

0.000000  14101716.454877 

YOUNG MODULUS 
FUNCTION  

EXTERNAL LOAD 
FREQUENCY  

DENSITY_RHO, 
(DOUBLE)SPEED_OF_SOUND 

(DOUBLE)X_AXIS, (DOUBLE)Y_AXIS  

1.000000e-03 1 1 1 0 1 1 1 1     
0.000000e+00 

DISPLACEMNT_X, DISPLACEMNT_Y, 
DISPLACEMNT_Z 

HEADING CARD  

6060    1    1    1    1    0 

IFORM, ISOLVER 

NODAL POINT DATA  

 1    0    0   90  0.000000 1.00e-
002    2    1  1000.000    

FREQUENCY 

Figure 1: Finite Element (FE) numerical parameters, terminologies and format

RDF format. For instance, all the eight (8) parameters and
their values shown in Figure 1 are taken from separate experimental data files stored in different formats (e.g., .dat, unv,
.pak, etc.); (ii) resolve heterogeneous terminologies originating from multiple disjoint domains by building a conceptual
model using multiple reference ontologies from biological,
geometrical, mathematical, and physical domains; (iii) providing links across input parameters/values and simulation
results in-order to reuse relevant data analysis in future ex-
periments; and (iv) visualisation and data analysis over FE
simulation results.

The cochlea (inner-ear)

represents a complex biomechanical device and a complete understanding of its behaviour is still an open research challenge. The creation
of a complete cochlea model depends on the integration of
heterogeneous models at different scales (e.g., basilar mem-
brane, organ of corti and outer hair cells) and theoretical
domains (e.g., mechanical, geometrical, and electrical). Ad-
ditionally, the model should be validated by clinical and experimental data. To the best of our knowledge, the proposed
linked data platform is a first unified infrastructure that
brings together numerical parameters, models, terminolo-
gies, storage, querying, visualisation and analysis to conduct
a finite element biosimulation.

3. SIFEM REFERENCE ARCHITECTURE
The SIFEM reference architecture shown in Figure 2 is designed to ensure that the generic template will lead to a more
concrete infrastructure for SIFEM platform. The concrete
platform derived from the reference architecture addresses
the necessary pointers for solving and developing an application which requires Finite Element Methods (FEM) and
Semantic Web technologies.

Figure 2: SIFEM Reference Architecture


The Consumers layer refers and represents the different
types of system users, desiring the usage of underlying port-
folio. The layer is composed of three major blocks, 1) Presentation service: with the sole purpose of visualizing, ac-
cessing, and managing the lower layers. 2) External Tools
and Applications:
to provide add-ons, and interfaces for
other applications or tools to access the lower layers, and
3) Consumer Services: a packaged set of standard consumer
services for cross-platform access of lower layers.

3.2 Data and Applications Layer

The Data and Applications layer represents various types
of data generated from simulation experiments. The sublayer components are further discussed in following sections.

3.2.1 Data Transformation

 FEM IO Transformation: There are different Finite Element Modeling Solvers such as OpenFOAM2,
CodeAster3, Kratos4, etc.
that use different and/or
varying input and output data formats.
In order
to perform experimental simulations via these FEM
solvers, they need to be fed in respective solver-specific
format. And simulation results need to be transformed
into an application native format. The input data of
a biosimulation experiment can be specified from an
interface or via files depending on each solver.

 RDFization: Since the RA highlights the use of
FEM solvers along with Semantic technologies, the input data is thus required to be semantified into RDF
format using the conceptual model. The conceptual
model is a set of vocabularies and ontologies that address the use-case under study (e.g., cochlear mechan-
ics, cardiovascular, etc.) and created using semantic
web layer. The RDFization component is responsible
for annotating all the data being used in the simulation experiment. The main aim of RDFizing the data
is to achieve interoperability by providing a standard
structure to the data. For example there are different types of solvers, such as PAK and OpenFOAM,
involved in the simulation experiments. The structure
of the input and output data to these solvers are different and hence are not interoperable with each other
or any other solver.

 Data Discovery and Linking: One of the biggest
advantages of linked data are the interlinked datasets
that enables the reuse and linking of information.
However, one of the core problems in this area is discovery of relevant datasets within the Linked Open
Data (LOD) cloud. The Data Discovery and Linking
component is thus responsible for the identification,
detection, and discovery of such datasets across LOD
Cloud and linking with the identified LOD datasets [8].

 Data Sharing: The experimental input and output
simulation data, in either RDF or non-RDF format
needs to be shared across different components within

2http://www.openfoam.com/
3http://www.code-aster.org/V2/spip.php?rubrique2
4http://www.cimne.com/kratos/

the same layer or other layers. Data Sharing component is responsible for sharing any type of data with
other components of the architecture.

3.2.2 Data Analysis

Data Analysis component is responsible for analysing
graphs generated from simulation experiments. The subcomponents of the Data Analysis are mainly responsible
for Feature Definition, Identification, and Extraction and
Data Analysers Definition and Selection. Feature Identification and Extraction refers to identification and extraction
of useful features from the experimental data which is visualised in a graph. Examples of such features are graph
behaviours, such as periodic, linear etc. These features are
determined based on the results obtained from all selected
analysers. The analyser selection refers to selecting the appropriate analyser for data analysis. Examples of Analysers
are Data Type Analyser, Extrema Analyser, Interpretation
Analyser, and Projection Analyser etc. These analysers are
designed to perform different data analysis in a layered fashion which contributes towards the complete data analysis of
the experimental results. For example, Data Type Analyser
analyses the data to get the type of data (experimental re-
sults) which has been plotted in the graph. The data type
can be continuous or discrete, for example. The results of
Data Type Analyser can act as input to the following analysers to help them perform their own analysis of data. This
means that the order of analyser selection is important due
to dependencies between analysers. The Data Type Analysers results can also be used to determine which kind of
operations can be performed on the data. This component
is also responsible for handling the serialization of messages,
into RDF/JSON or RDF/XML, as well as just JSON or
CSV. This allows the data to be manipulated by other applications as well (if needed), thus increasing the data interoperability of the platform.

3.2.3 Storage and Indexing

The Storage and Indexing component is designed mainly
for storing the data generated from simulation experiments
and indexing the data for efficient processing of the data.
As the simulation experiment data is semantified into RDF
format, thus it is stored in a triple store. To increase the
performance in terms of data retrieval, the most frequently
used experimental data is indexed or cached in an SQL or
NoSQL database. This indexing will result in significantly
faster access to the data needed for processing in a sense that
it avoids running complex SPARQL queries on large amount
of data persisted in the triple store. An example of indexed
or cached data can be the visualisation data, configuration
data, reference and log data etc.

3.2.4 Finite Element Method (FEM) Solvers

The Finite Element Solver layer is responsible for handling the solver components, a key aspect of the SIFEM
RA. These components are responsible for computing the
solutions for the Finite Element Model, after receiving an
input, such as the cochlear geometry, material properties or
cochlear geometry mesh (for example, boundary condition
etc).

3.3 Semantic Web Layer

The semantic web layer assists in creation of a conceptual
model using all layers of Semantic Web Layer Cake [1].


a rule, saying the value of frequency should not be greater
than 20 kHz as it is maximum frequency limit a human ear
can hear. While running the simulation, results will be validated by the rule validator based on the rules specified by
the domain expert. While receiving input from GUI, the
data interpretation engine performs an initial transformation using Input Transformation Services. The inputs
are transformed as there might be employment of different
or multiple Finite Element Method (FEM) solvers within
the same application setup. And most of these FEM solvers
might have their own input formats. In our use-case, we use
PAK FEM solver for performing simulation experiments [6].
The PAK FEM solver is used to provide the means for finding approximate solutions to boundary value problems with
partial differential equations.

input.cfg
#GEOMETRY PARAMETERS
#(DOUBLE)LENGTH (DOUBLE)HEIGHT (DOUBLE)
0.035 0.001 0.001 3.0E-4 5.0E-5
##LOAD PARAMETERS
#(DOUBLE)FREQUENCY (DOUBLE)VALUE
50 1.0
#MATERIAL PROPERTIES
#(DOUBLE)DENSITY_(DOUBLE)SPEED_OF_SOUND_C

output.dat
C /1/ HEADING CARD (80A1)
C NASLOV
Cochlea Model
C /2/ FORMAT FOR INPUT DATA (I5)
C INDFOR
C /3/ BASIC DATA (I10, 5I5)
C NP,NGET,NMATM,NDIN,NPER,PRINT
6060 1 1 1 1 0
C /4/ BASIC DATA FOR THE PROBLEM (4I5)

Listing 1: Biosimulation Input and Output Parameters

bw:BoxModel1ExcitationFrequencyValue a sim:ScalarValue;
sim:hasScalarDataValue 1000.000;

bw:BoxModel1ExcitationFrequency a fem:Frequency;
sim:hasScalarValue bw:BoxModel1ExcitationFrequencyValue;

bw:BoxModel1Node5357 a fem:Node;
fem:hasZCoordinate 3.3333E5;
pakFemSet:hasNodeSettings bw:BoxModel1NodeSettings5370;

bw:BoxModel1Node1 a fem:Node;
fem:hasNumberOfUnusedBlock15Values 2;
fem:hasZCoordinate 0.001;
fem:hasYCoordinate 0.0;
fem:hasXCoordinate 0.0;

Listing 2: RDFized Output Parameters

Just like Input Transformation Services, the Output
Transformation Services are responsible for transforming
the solver specific output to SIFEM data. As mentioned be-
fore, we use PAK FEM solver, which receives an input.cfg
file as input and generates output.dat (see Listing 1). In addition to this transformation, the engine also semantifies the
input and output by using RDF data model. The semantification is achieved by RDFization and Semantification
Services using SIFEM Conceptual Model. An example
of RDFized data is shown in the Listing 2.

The SIFEM Conceptual Model is designed to support
simulation of hearing processes and the biological system of
inner ear [3]. The simulation of any biological system, in
our case inner ear, requires two types of models; 1) models

Figure 3: SIFEM Layered Components and Work Flow

The conceptual model thus serves as a back-bone in sustaining the idea of semantification of experimental results.
Additionally, the aim of the semantic web layer is twofold.
Firstly, to achieve interoperability through the annotation
of simulation experiment data using a conceptual model.
Secondly, to provide validation of the results obtained from
simulation experiments in an automated fashion.

Integration, Management, and Security
Layers

The Integration layer ensures provision of all the necessary
means to mediate, protocol, route, and integrate all other
layers as well as their components. Similarly, the management and security layers represent the services responsible
for management and provision of necessary security to all
other layers.

4. SIFEM LAYERED COMPONENTS AND

WORK FLOW

Figure 3 shows the SIFEM technical components derived
from the reference architecture shown in Figure 2. Horizon-
tally, from left to right the Figure 2 presents the workflow
of the SIFEM platform. Vertically, the technical components are stacked and grouped together to form sub-layers,
specifically, the two sub-layers of the SIFEM architecture
are, 1) Data Interpretation Engine, and 2) Data Extraction,
Storage, and Querying Layer. The workflow as well as both
sub-layers are detailed in the following sub-sections.

4.1 Data Interpretation Engine

The Data Interpretation Engine is comprised of major
components responsible for processing and interpreting the
user input in a way that: 1) it is transformed to and from
a solver-specific input and output; 2) it is semantified using
RDF data model; 3) validated as per the SIFEM conceptual
model; and 4) analysed and visualised.

The SIFEM GUI is designed for input, management, validation and visualisation of simulation experimental data.
The simulation input parameters such as Material Properties (fluid viscosity, damping factor,
frequency, etc.),
Cochlear Geometry and Mesh of Cochlear Geometry are
initially specified by the user via GUI. The Rule creation
and Validation Services are used by the experimenter
via GUI to define and validate rules before running a sim-
ulation, specifically to validate the results of a simulation


Experimental
Measurement

Derived
Value

dimension

dimension

dimension

Data 
View

has

Feature

prv:was GeneratedBy

has

Feature 
Value

has

has

cogs:Data

Transformation 

cogs:Program

prv: wasDerived

dimension

From

is a

function of

prv:Activity

has

Solver

is realized by

Numerical 

Method

Timestamp

Position

is calculated by

is part of

has

has

Simulation 
Configuration

Simulation 

has

State

Physical 

Quantity Value

has

Physical 

Model

is part of

has

function

is a

of

Object

Physical 
Quantity

has

function of

is topologically 

related to

is geometrically 

related to

has

has

Physical 
Object

has

Physical 

Type

has

is a

Material 
Property

Anatomical

Element

Figure 4: Excerpt of SIFEM conceptual model

Figure 5: 2D Visualisation Example

for conceptual representation of the studied phenomenon,
and 2) mathematical/numerical models for describing the
behaviour of the system. Specifically, for our use-case, hearing models give us conceptual representation of inner ear
system from different perspectives. Geometric modelling
specifies the physical structures and their relations. Mechanical modelling defines the characteristics of sound vi-
brations, and electrical modelling describes the electrical re-
sponses. These three models provide complementary views
for understanding the phenomenon of inner ear mechanics.
The SIFEM conceptual model is designed to accommodate
all the necessary terminologies which form this phenomenon.
The terminologies are divided into major classes, such as ar-
gumentation, anatomy, topology, physiology, data analysis,
finite element etc. An excerpt of SIFEM Conceptual Model
is shown in Figure 4.

The Model Consistency Validation Layer is responsible for providing the means of validating the semantified
data produced. The services are mainly responsible and
developed to ascertain the consistency of generated (trans-
formed) RDF data, specifically to ensure that the generated
RDF adheres to SIFEM conceptual model.

The Visualisation Service is responsible for generating
2D and 3D graphs using the simulation experiment data.
Both 2D and 3D graphs are displayed in a sub-window on
the GUI. An example simulation experiment data graph
plotted as a 2D and a 3D graph can be seen in the Figures
5 and 6 respectively.

The simulation experiment data is analysed using the
Data Analysis component, which has a two-fold duty. Ini-

Figure 6: 3D Visualisation Example

tially, the component identifies and extracts different features from the experiment data output. The feature extractor is the main component responsible for the extraction
of useful features from the experimental data. The output
data from an experiment is usually plotted as a graph. The
feature extractor reads the dimensions of a two dimensional
graph and performs data analysis on the two dimensions
extracted. Examples of data features are maximum and
avg. first derivative and avg. second derivative. It can be
used, for example, to find all the experimental result graphs
that exhibit certain behaviour that deemed to be of some
physical significance to the experimenter, for example, having a maximum value occurring in a particular range of the
x-axis followed by a sharply increasing positive slope. Another example of feature that can be extracted is that an
experimental results graph has a periodic pattern. The feature extractor extracts such features and then annotates the
data with these features using the Data Analysis Ontology.
An example semantic interpretation of data analysis output
is shown in Listing 3.

@prefix dao:<http://www.sifemontologies.com/ontologies/DataAnalysis.owl

#> .

:DataViewBMMagnitude dao:hasDimensionX :translationX ;

dao:hasMinmumX 4.2027E258 ;
dao:hasMaximumX 2.57604E258 ;
dao:hasDimensionY :translationY ;
dao:hasMinimumY 2.95927E257 ;
dao:hasMaximumY 3.59028E257 ;
dao:hasGlobalMinima (4.2027E258, 2.95927E257) ;
dao:hasGlobalMaxima (2.57604E258, 3.59028E257) ;
dao:hasFeature dao:Periodic .

Listing 3: Semantic Interpretation of Data Analysis Output

4.2 Data Extraction, Storage, and Querying

Layer

4.2.1 Persistence and cache

In the use-case scenario of SIFEM project, the performance is a critical quality of service parameter. The caching
mechanism is thus deemed important to be baseline component to handle quick access to data. The significance of using
a caching mechanism is further highlighted in the Evaluation
Section. On the other hand, there needs to be a store that
holds and stores data for later use. This is where the concrete persistence comes in. For our particular case, we use
MongoDB as a temporary caching mechanism (with a lifetime of a simulation experiment), and Openlink Virtuoso as


4.2.2 Query Services

As discussed before, we have a caching mechanism to store
important parameters of a simulation experiment and a storage mechanism that holds the experimental simulation data
for later use. Therefore, in order to retrieve, and manipulate
the cache and the triple store, there needs to be a querying
mechanism. The query services are therefore the core services that are responsible for managing the persistence store
and the data it contains.

The SIFEM platform is built as a Web application. A
screenshot of the platform is depicted in Figure 7. A video,
depicting a sample simulation experiment of the running
SIFEM platform can be found at https://goo.gl/wDC0am.
The initial version of the platform is released as an open
source version, the source code of beta-version 1 is available at: https://goo.gl/sxePc8.

5. EVALUATION

This section presents the results obtained from empirical
evaluation of SIFEM platform. We have performed both
qualitative and quantitative evaluations. For qualitative
evaluation, we identified two types of users, namely domain
experts and technical users to cover the technical (software)
and domain (inner ear) requirements of the platform. The
questionnaires were answered by sixteen clinical experts. To
perform quantitative evaluation, we used a dedicated computer running 64-bit Windows 7 OS, with 8GB RAM and
an Intel Core i7 (2.60 GHz) CPU, and 500GB hard drive.
Virtuoso has been used as a triple store.

Qualitative Evaluation:. A survey has been carried out
to evaluate the design, system, user, and run-time qualities
of the SIFEM platform. Figure 8 and Figure 10 show users
feedback on the different aspects of automation and run-time
qualities. We observe in the Figure 8 that each biosimulation
task (from input parameter preparation to data interpreta-
tion) is scored from average to excellent level. It is important
to note that currently  at the time of writing this article
 the proposed platform is in the beta-version 1 stage,
therefore, the poor scoring given by the users largely reflect
the improvement need to implemented for releasing a matured platform. Similarly, the Figure 10 shows a significant
improvement on the run-time aspects of the platform. The
Figure 9 shows the SIFEM platform qualities (i.e., design,
system, usages) which are rated from average to excellent.
The overall satisfaction of the users is shown in Figure 11,
where 86.7 percent of the users are either satisfied or above
the satisfaction level.

Quantitative Evaluation:. Table 1 shows a set of tasks in
a biosimulation workflow  starting from input parameter
collection to analysis and visualisation  completed in a total time of 1) 171173 milliseconds (in case of querying the
triple store), 2) 81857 milliseconds (in case of querying the
in-memory Jena model), and 72763 milliseconds (in case of
querying the cache) as compared to several hours taken to
complete the similar workflow in a normal biosimulation en-
vironment. Usually, all the tasks in Table1 are performed
in isolated environments and take substantial manual effort
to align data, models, and simulation results to complete a

Figure 7: Screenshot of the SIFEM Platform.

Figure 8: Automation Parameters (AP-1=input parameter
preparation, AP-2=input specification, AP-3=solver usage, AP-
4=data analysis, AP-5=visualisation, AP-6=data interpretation)

workflow. Since, varying simulation might have different input parameters, and different simulation functions, in order
to ascertain the credibility of execution time - all the experiments were performed for a single type of simulation and
function. From Table 1, it is also pertinent to note that the
caching mechanism significantly reduces the execution time
as compared to while querying the triple store or in-memory
model.

Table 1: Execution time (in milliseconds) for biosimulation tasks
in a single workflow

Task

input.cfg creation

input RDFization

Solver execution

output RDFization

Querying Triple Store

Querying in-memory model

Querying Cache

Data Analysis

Data Analysis output RDFization

Total (Triple Store Query)

Total (in-memory model Query)

Total (Cache Query)

Execution
(milliseconds)

Time

171173


Figure 10: Run-time Quality (RQ): RQ-1=Availability, RQ-
2=Interoperability, RQ-3=Manageability, RQ-4=Performance, RQ-
5=Reliability, RQ-6=Scalability, RQ-7=Security

Figure 11: Over-all satisfaction

6. RELATED WORK

In [14] an ontology-based framework is proposed for finite element analysis in a product development environ-
ment. It uses a three-stage automated finite element modeling (FEM) method to identify and classify structural configurations and analysis modeling knowledge into a set of
formal ontologies described in OWL. Gennari et al [4, 10]
integrates three different biosimulation models of the heart,
at three different scales: (i) a cardiovascular fluid dynamics model; (ii) a model of heart regulation; and (iii) a subcellular model of the arteriolar smooth muscle. Gennari et
al built a lightweight ontological framework, called Application Model Ontology (AMO), using small subsets of the
reference ontologies, to annotate these biosimulation models
semantically and to map between matching concepts. Fur-
ther, to merge computational models of biological processes
into reusable, multi-scale models, two reference ontologies
were used, namely the Foundational Model of Anatomy
(FMA) [12] and the Ontology of Physics for Biology (OPB).
The researchers were then able to address the question of
how heart rate and blood pressure depend on calcium uptake
into arteriolar smooth muscle cells, a question that could
not be answered using one biosimulation model alone. The
representation of biosimulation models has been steadily developed in the literature (Sauro & Bergmann [13]), including
CellML [7] and SBML [5]. Ontologies such as the Systems
Biology Ontology (SBO) [2] and Terminology for the Description of Dynamics (TEDDY) [2] have been used to conceptualize biosimulation and its results.

All the approaches mentioned above focus on ontologising
finite element constructs into the various domains such as

cardiovascular, product development, and systems biology.
Similarly, the SIFEM consortium has developed an ontological multi-scale model of the human cochlea (inner-ear) [3].
However, in order to use above ontologies into a complete
finite element biosimulation process, a well-integrated infrastructure is required to improve automation at all the
biosimulation stages starting from the numerical parameter
collection to visualising the simulation results. To the best
of our knowledge, the proposed linked data platform is a
first initiative to develop such infrastructure that combines
together numerical parameters, models, terminologies, stor-
age, querying, visualisation and analysis to conduct a finite
element biosimulation for the human cochlea (inner-ear).

7. CONCLUSIONS AND FUTURE WORK

We present a linked data platform that improves inte-
gration, reproducibility and automation of Finite Element
(FE) biosimulations. The proposed platform is based on
a unified reference architecture that combines together numerical parameters, models, terminologies, storage, query-
ing, visualisation and analysis to conduct a finite element
biosimulation. The platform is developed on a use-case to
understand the exact pathophysiological consequences and
risk factors of hearing impairment in humans. The experimental biosimulation data and models are from scientific and
clinical studies about the structure-function relationship in
normal and pathological cochlear. The platform is capable of
executing a complete biosimulation in 1) 171173 milliseconds
(in case of querying the triple store), 2) 81857 milliseconds
(in case of querying the in-memory Jena model), and 72763
milliseconds (in case of querying the cache) as compared to


Portugal, July 7-9, 2014, pages 3945, 2014.

[9] S. Merchant, M. McKenna, J. Adams, J. Nadol Jr.,

J. Fayad, R. Gellibolian, F. Linthicum Jr.,
A. Ishiyama, I. Lopez, G. Ishiyama, R. Baloh, and
C. Platt. Human temporal bone consortium for
research resource enhancement. Journal of the
Association for Research in Otolaryngology, 9(1):14,
2008.

[10] M. L. Neal, J. H. Gennari, T. Arts, and D. L. Cook.

Advances in semantic representation for multiscale
biosimulation: A case study in merging models. In
R. B. Altman, A. K. Dunker, L. Hunter, T. Murray,
and T. E. Klein, editors, Biocomputing 2009:
Proceedings of the Pacific Symposium, Kohala Coast,
Hawaii, USA, 5-9 January 2009, pages 304315, 2009.

[11] S. T. Neely. Finite difference solution of a

two-dimensional mathematical model of the cochlea.
The Journal of the Acoustical Society of America,
9(1):69, 1981.

[12] C. Rosse and J. L. Mejino Jr. The foundational model

of anatomy ontology. In Anatomy Ontologies for
Bioinformatics, pages 59117. Springer, 2008.

[13] H. Sauro and F. Bergmann. Standards and ontologies

in computational systems biology. Essays Biochem,
45:211222, 2008.

[14] W. Sun, Q. Ma, and S. Chen. A framework for

automated finite element analysis with an
ontology-based approach. Journal of mechanical
science and technology, 23(12):32093220, 2009.

several hours taken in a normal isolated environment. The
platform demonstrates 86.7 percent overall satisfaction from
users having technical and domain background. We argue
that the platform can be tailored with minor adjustments
to other FE biosimulation domains.

As part of the future work, we plan to provide a set of
alignments between the data analysis features and the concepts described in the TEDDY ontology [2]. There is a
strong connection between the data analysis feature set and
the concepts modelled in TEDDY. At the time of writing
this article we are switching to beta-version 2 and the platform will be re-evaluated against improved automation and
run-time qualities.

Acknowledgment
This publication has emanated from research supported in
part by the research grant from Science Foundation Ireland (SFI) under Grant Number SFI/12/RC/2289 and EU
project SIFEM (contract Number 600933).
