Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 204219

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

Querying for provenance, trust, uncertainty and other meta knowledge in RDF
Renata Dividino, Sergej Sizov, Steffen Staab, Bernhard Schueler

ISWeb - Information Systems and Semantic Web, University of Koblenz-Landau, Universitatsstrae 1, 56072 Koblenz, Germany

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 28 January 2009
Received in revised form 1 June 2009
Accepted 13 July 2009
Available online 24 July 2009

Keywords:
Semantic Web
Meta knowlegde
SPARQL

1. Introduction

The Semantic Web is based on accessing and reusing RDF data from many different-sources, which one
may assign different levels of authority and credibility. Existing Semantic Web query languages, like
SPARQL, have targeted the retrieval, combination and re-use of facts, but have so far ignored all aspects
of meta knowledge, such as origins, authorship, recency or certainty of data.

In this paper, we present an original, generic, formalized and implemented approach for managing
many dimensions of meta knowledge, like source, authorship, certainty and others. The approach re-uses
existing RDF modeling possibilities in order to represent meta knowledge. Then, it extends SPARQL query
processing in such a way that given a SPARQL query for data, one may request meta knowledge without
modifying the query proper. Thus, our approach achieves highly flexible and automatically coordinated
querying for data and meta knowledge, while completely separating the two areas of concern.

 2009 Elsevier B.V. All rights reserved.

Integrating and re-using Semantic Web data becomes more
and more fruitful and worthwhile in order to answer questions
and deliver results. Typically, engines like Swoogle provide points
of access for RDF data, crawlers may fetch relevant RDF data,
and query languages like SPARQL with their corresponding query
engines allow for selecting and re-using data in the appropriate
format. With the arrival of more and more data in the Semantic
Web and more sophisticated processing through query and reasoning engines, one now, however, encounters challenging questions
linked to meta knowledge about the data like:

 Where is this data from?
 Who provided the data?
 When was this data provided?
 Was the provider certain about the truth of this data?
 Was the data believed by others, too?

 This proposal is a completely revised and extended version of Schueler et al. [B.
Schueler, S. Sizov, S. Staab, D.T. Tran, Querying for meta knowledge, WWW08: Proceeding of the 17th International Conference on World Wide Web, ACM, New York,
NY, USA, 2008]. Major changes include proofs showing that the meta knowledge
evaluation of SPARQL queries is equivalent to the standard SPARQL evaluation, a discussion of soundness and completeness, as well as an extended empirical evaluation
section.
 Corresponding author.
E-mail addresses: dividino@uni-koblenz.de (R. Dividino), sizov@uni-koblenz.de

(S. Sizov), staab@uni-koblenz.de (S. Staab).

1570-8268/$  see front matter  2009 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2009.07.004

For instance, when querying the Semantic Web with the help
of SPARQL for the affiliation of a person named James Hendler,
one finds (at least) two answers, i.e. University of Maryland and
Rensselaer Polytechnic Institute. Without further indication as
to where, by whom, when, etc. such information was given, it is
impossible to decide which of the two affiliations is still valid.

The problem might be remedied in several ways. First, an
ideosyncratic solution by the search engine, such as returning
the corresponding RDF files or links to sources of knowledge extraction (say < http://www.cs.umd.edu/survey.pdf> and <
http://www.rpi.edu/report.doc>), might help in this special case.
However, an ideosyncratic solution may not be appropriate in a second case in which the when was more relevant than the where
or in a third case where such a piece of information had to be
aggregated from several resources. Second, the person or system
requesting the meta knowledge might manually extend the SPARQL
query formalizing the request for the affiliation in order to return
the where, the who and the when. Such a modification will, how-
ever, be very tedious, as it will include a number of additional
optional statements, and expressing it manually will be error prone.
Also, it will not help in delivering meta knowledge that arises from
joining several statements, e.g. meta knowledge about uncertainty
that was based on several meta knowledge statements with different values of uncertainty. Therefore, querying Semantic Web data
requires a principled, generic approach to the treatment of meta
knowledge that is able to adapt to many dimensions of meta knowledge and that is open to accommodate to new dimensions when
the need arises. Such a principled, original framework is given in
this paper. We start to explain our approach with a discussion of
important design choices in Section 2. We model meta knowledge
in existing RDF structures by embedding a slightly more expressive

language, which we call RDF+, into RDF. We define the abstract syntax of RDF+, its semantics and its embedding in RDF in Section 4. In
Section 5, we extend the SPARQL syntax and semantics to work on
data and meta knowledge of RDF+. The extension allows the user to
extend a given conventional SPARQL query by a keyword for meta
knowledge triggering the construction of meta knowledge by the
query processor. Section 6 summarizes the overall use and processing of SPARQL queries with meta knowledge. Sections 7 and 8 report
on initial graceful results for meta knowledge processing from a
theoretic point of view. Finally, Section 9 provides pointers to the
prototype implementation of the system and initial experimental
testing.

2. Scenario

In our scenario, the sample user aims to explore the knowledge
and meta knowledge by querying knowledge extracted from Web
pages of Computer Science departments. Here, we assume that he
aims to find experts in the domain of Semantic Web and their affil-
iations. Example 2.1 shows the relevant facts that may have been
obtained from websites of different universities.

Example 2.1. Relevant facts obtained from different websites
JamesHendlers research topic is SemanticWeb.
Site A
JamesHendler is affiliated with RensselaerPI

Site B

JamesHendlers research topic Robotics.
JamesHendler affiliated with UnivMaryland.
RudiStuders research topic SemanticWeb.
RudiStuder affiliated with Univ. Karlsruhe

In addition, the user wants to exploit meta knowledge for
obtaining results with best certainty and for analyzing contradicting answers (e.g. different affiliations for the same person James
Hendler in Example 2.1). An example of meta knowledge associated to the extracted facts is presented in Example 2.2 and shows
that the facts have been extracted from different-sources, at different timepoints, and with different degrees of extraction confidence.

Example 2.2. Associated meta knowledge of facts presented in
Example 2.1
Site A

source = www.rpi.edu/report.doc
certainty degree = 0.9
timestamp = 5/5/2007

Site B

source = www.cs.umd.edu/survey.pdf
certainty degree = 0.6
timestamp = 6/6/2001

In the next section, we discuss design choices for representing
meta knowledge taking into consideration the existing Semantic
Web representation structures.

3. Design choices

This section summarizes and shortly motivates the design

choices for our meta knowledge framework.

3.1. Reification

Establishing relationships between knowledge and meta knowledge requires appropriate reification mechanisms for supporting
statements about statements. Our general objective is to execute
queries on original data (i.e. without meta knowledge) directly
without complex transformations. For compliance with existing
applications that access the repository in a common way (e.g. using
SPARQL queries), we do not modify existing user data. This requirement does not allow us to use mechanisms like RDF reification,
which decompose existing triples and fully change the representational model. In our framework described in section 4, we adopt the

notion of Named RDF Graphs for meta knowledge representation
[5,6].

3.2. Storage mechanisms

Following the overall philosophy of RDF, we do not separate meta
knowledge from normal user knowledge in the repository. Following this paradigm, a user or developer has unlimited access to
all contents of the triple store and can manipulate meta knowledge directly. In other words, the user can directly access meta
knowledge (e.g. using suitable SPARQL queries). Beyond explicitly designed queries for meta knowledge access, in Section 5 we
describe the extension of SPARQL that allows us to access meta
knowledge about the result set automatically without user inter-
vention.

3.3. Dimensions of meta knowledge

An important point for the application design is the definition
of relevant meta knowledge properties and their suitable interpretation for arbitrarily complex query patterns. In general, these
properties are application dependent and must be carefully chosen
by the system administrator. In our scenario (Sections 2 and 6) we
discuss common and widely used properties, such as timestamp,
source, and (un)certainty, and show ways of defining and utilizing
them in our framework.

3.4. Syntax extensions

Seamlessly integrated access to meta knowledge requires corresponding extensions of existing querying mechanisms. These
can be realized at different levels, for instance at the level of
query languages (e.g. SPARQL) or at the level of applicationspecific interfaces (e.g. Sesame API). In Section 5 we describe
our SPARQL extension for constructing query results with associated meta knowledge. It is system-independent and not related
to some particular implementation of the RDF repository. Further-
more, it fully supports the existing SPARQL syntax and semantics.
Compliance with existing established standards makes the integration with existing applications and interfaces substantially
easier.

4. Syntax and semantics for RDF with meta knowledge

In order to adapt our sample application scenario to our frame-
work, we formalize it using the notion of Named RDF Graphs [5,6].
We assume that the user utilizes knowledge which has been initially extracted from Web pages of Computer Science departments
and stored in form of RDF triples in his personal active space [21],
backed by a local RDF repository. Example 4.1 shows the relevant
facts already presented in Example 2.1 in RDF triple language TriG
[1] with Named Graphs in a simplified form that abstracts from
(default) namespaces.

Example 4.1. Facts of Example 2.1 represented in TriG with Named
Graphs
G 1

G 2

{ JamesHendler researchTopic SemanticWeb.
JamesHendler affiliatedWith RensselaerPI }
{ JamesHendler researchTopic Robotics.
JamesHendler affiliatedWith UnivMaryland.
RudiStuder researchTopic SemanticWeb.
RudiStuder affiliatedWith UnivKarlsruhe }

Likewise, the meta knowledge associated to the extracted
knowledge presented in Example 2.2 is stored into the same RDF
repository using the notion of Named RDF Graphs.

R. Dividino et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 204219

Example 4.2. Meta knowledge of Example 2.2 represented in TriG
with Named Graphs
G 3

{ G 1 mk:source <www.rpi.edu/report.doc>.
G 1 mk:certainty 0.9.
G 1 mk:timestamp 5/5/2007 }
{ G 2 mk:source <www.cs.umd.edu/survey.pdf>.
G 2 mk:certainty 0.6.
G 2 mk:timestamp 6/6/2001 }

G 4

In the examples above we have used existing RDF modeling
possibilities in order to represent meta knowledge. However we
must distinguish the notation of RDF with only implicit notation of
meta knowledge, but no semantic consequences specifically due to
this meta knowledge, from a formally extended model of RDF with
explicit notation of meta knowledge.

In the course of representing and reasoning with meta knowledge we embed a language with meta knowledge reasoning, i.e.
RDF+, in a language without such specific facilities, i.e. in RDF. This
embedding implies that we may consider an RDF snippet in its
literal sense and we may possibly interpret it as making a meta
knowledge statement. Embedding meta knowledge in RDF is not
the most expressive means to deal with all needs of meta knowledge processing, but it retains upward compatibility with existing
usage of the language and corresponding tools and methods, which
is a major concern for Semantic Web approaches. The following definition of RDF+ helps us to draw this line very clearly and concisely.
First we briefly describe existing foundations of RDF in Section 4.1,
then the abstract syntax for this embedded language, RDF+, is given
in Section 4.2 and its semantics in Section 4.3. Last we show how
to embed RDF+ in RDF with named graphs.

4.1. Basic definitions

RDF is a graph-based knowledge representation language. The
nodes in a graph are URIs, blank nodes (a kind of existentially quantified variables) or literals. Arcs between the nodes, labeled with
URIs, represent their relationships. In the following definitions, we
simplify the RDF graph model in order to come up with a more
concise formal characterization like [17].

Definition 4.1 (RDF terms, triples, and variables). Let U be the set
of URIs, L the set of RDF Literals and B the set of Blank Nodes as
defined in [14]. U, L and B are pairwise disjoint. Let R = U  L  B. A
statement is an RDF triple in R  U  R. If S = (s, p, o) is a statement,
s is called the subject, p the predicate and o the object of S. it We
denote the union U  L  B by T (RDF terms). Assume additionally
the existence of an infinite set V of variables disjoints from sets
aboves.

Definition 4.2 (RDF graph). An RDF graph G is a set of statements.
For every two RDF graphs G1 and G2 the sets of blank nodes used in
G1 and in G2 are disjoint.

Named graphs [5,6] offer means to group a set of statements in
a graph and to refer to this graph using a URI. This way information
about the graph can be expressed in RDF using its name as subject
or object:

Definition 4.3 (RDF named graph). A named graph is a pair (u, G)
of a URI u, called name, and an RDF graph G, called the extension.

Finally, RDF datasets can be defined as followed:

Definition 4.4 (RDF dataset). An RDF dataset D is a set
{(G0), (u1, G1), . . . , (un, Gn)}, denoted by names (D), where each Gi
is a graph and each ui a URI. G0 is called the default graph of D,
= ui and
and each pair (ui, Gi) is a named graph; define name (Gi)D
gr(ui) = Gi.

4.2. An abstract syntax for RDF+

The abstract syntax of RDF+ is based on the same building blocks

as RDF:
 U are Uniform Resource Identifiers (URIs).
 L are all RDF literals.
 G  U is the set of graph names.
 P  U is the set of properties.

In addition, we must be able to refer to statements directly without use of reification. For this purpose, we exploit the notion of
(internal) unique statement identifiers:
 	 is a set of statement identifiers, which is disjoint from U and L.

Now, we may define RDF+ literal statements that are placed
in named graphs and have, in addition to RDF, a globally unique
statement identity.
Definition 4.5 (RDF+ literal statements). The set of all RDF+ literal
statements, S, is defined as quintuples by:

S := {(g, s, p, o, 
)|g  G, s U, p P, o U  L, 
  	}.
Thereby, 
 and (g, s, p, o) are keys such that there exists a bijection f1 with f1(g, s, p, o) = 
  f
1(
) = (g, s, p, o). Moreover, we
define the overloaded function f5 to return the complete quintuple
given either 
 or (g, s, p, o), i.e. f5(
) := (g, s, p, o, 
) =: f5(g, s, p, o),
when f1(g, s, p, o) = 
.

The reader may note that we assume that f1 is fixed and given
before any statement is defined. Furthermore, this definition of literal statements and the rest of this paper abstracts from RDF blank
nodes in order to keep the formalization more concise. However,
there is no conceptual problem in extending our treatment to blank
nodes, too. The two statements of Graph G1 of Example 4.1 may now
be represented in RDF+ in the following way:
Example 4.3. Knowledge statements in RDF+
S  K {
(G 1, JamesHendler, researchTopic, SemanticWeb,
1),
(G 1, JamesHendler, affiliatedWith, RensselaerPI,
2) }

Thereby, the exact form of statement identifiers in 	 is up to the

implementation, as they are only used for internal processing.

Having represented the literal interpretation of RDF statements
in RDF+, we may now address the representation of selected RDF
statements as RDF+ meta knowledge. This is done using a structure
of RDF+ meta knowledge statements, M, that is separate from the
set of RDF+ literal statements:
Definition 4.6 (RDF+ meta knowledge statements). Let 	  P be the
set of meta knowledge properties. Let  , with   	, be sets providing possible value ranges for the meta knowledge property   	.
Then, the set of all RDF+ meta knowledge statements, M, is defined
by: M := {(
, , )| 
  	,   	,   }.

The following example illustrates the target representation of
the first two meta knowledge statements of graph G3 from Example
4.3.
Example 4.4. Meta knowledge statements in RDF+
M  M  {
(
1, mk:source, <www.rpi.edu/report.doc>).
(
1, mk:certainty, 0.9)}

Together we may now define a RDF+ dataset.
+ of literal stateDefinition 4.7 (RDF+ dataset). A RDF+ dataset D
+ =
ments and associated meta knowledge statements is a pair D
(K, M) referring to a set of literal statements K  S and a set of
meta knowledge statements M  M.

A (partial) example for such a dataset given by the pair (K, M)
with definitions for K  S and M  M has been given in Examples
4.3 and 4.4, respectively.

4.3. Semantics for RDF+

We now have an abstract syntax for representing RDF triples like
James-Hendler researchTopic SemanticWeb as part of G1 and meta
knowledge statements like the source of the statement that James
Hendlers research topic is Semantic Web is found in the document <
www.rpi.edu/report.doc >.

However, such an abstract syntax may remain remarkably
ambiguous if it cannot be linked to a formal semantics. Assume
two meta knowledge statements:

(
1, mk:source, <www.rpi.edu/draftReport.doc >)
(
1, mk:source, <www.rpi.edu/finalReport.doc >)
For the same literal statement identified by 
1, the question
may arise whether this means a disjunction, i.e. one of the two
documents has provided the fact, or a conjunction, i.e. both documents have provided the fact, or a collective reading, i.e. the two
documents together gave rise to the fact, or whether this situation constitutes invalid meta knowledge. In order to prevent such
ambiguities we introduce a generic semantic framework for meta
knowledge in RDF+. However, the framework must also be able to
reproduce the literal interpretations found in RDF. For the latter
purpose, we first define a standard model for a RDF+ dataset.

Definition 4.8 (Standard interpretation and model). A standard
interpretation Is : S  {,} for a dataset D
+ = (K, M) assigns
truth values to all statements1 in K. A standard interpretation for K
is a standard model for K if and only if it makes all statements in K
become true. This is denoted by Iss(K, M).

For instance, any standard model Is for (K, M) in Example 4.3
would include (G1, JamesHendler, researchTopic, SemanticWeb, 
1)
in its set of literal statements evaluating to . In order to address
the level of meta knowledge we foresee an additional model layer
that provides a different interpretation to each meta knowledge
property.

Definition 4.9 (	-Interpretation and model). A 	-interpretation
I : S   for a property   	 is a partial function mapping statements into the allowed value range of .
A 	-interpretation I is a 	-model for (K, M) if and only if for all
meta knowledge statements (
, , ) M where f1(
) = (g, s, p, o)
the value of the interpretation equals to , i.e. I ((g, s, p, o, 
)) = .
This is denoted by I (K, M).

As an example, consider the literal statement (G1, JamesH-
endler, researchTopic, SemanticWeb, 
1) from Example 4.3, and the
meta knowledge statement (
1,certainty, 0.9) from Example 4.4. A
	-interpretation Icertainty, that is a 	-model, would map the literal
statement onto 0.9.

The standard interpretation and 	-interpretation may now be

combined to define what an overall, unambiguous model is:

Definition 4.10 (Meta knowledge interpretation). A meta knowledge interpretation I is a set including a standard interpretation
Is and the 	-interpretations I for all meta knowledge properties
  	.
Definition 4.11 (Meta knowledge model). A meta knowledge inter-
+ = (K, M) if and only
pretation I is a model for a RDF+ dataset D

1 Note that because f1 is fixed there are no two tuples (g, s, p, o, 
1), (g, s, p, o, 
2),
where 
1 /= 
2. This implies that the standard interpretation is independent of the
identifiers 
1, 
2.

if all its interpretations I  I are a standard model or 	-models for
(K, M). This is denoted by I  (K, M).

4.4. Mapping between RDF and RDF+

The mapping between RDF and RDF+ needs to be defined in two
directions. First, one must be able to map from RDF, as given in the
examples from Section 2, to RDF+. Second, one must be able to map
from RDF+ to RDF. Because RDF+ is more fine-grained than RDF the
first direction will be easy. For the second a compromise on the
granularity of the representation has to be made.

4.4.1. From RDF to RDF+

The examples of Section 2 reify groups of statements, i.e. the
ones found in G1 and G2, in order to associate meta knowledge, such
as given in G3 and G4. In order to allow for an interpretation of the
meta knowledge as defined in the preceding section, we map RDF
into RDF+. For all RDF statements, including statements in graphs
G1 and G2 of Example 4.1, the mapping performed is close to an
identity mapping. One only needs to add statement identifiers. The
result for G1 in RDF+ is:

Example 4.5. Representing graph G1 in RDF+
K  {
(G 1, JamesHendler, researchTopic, SemanticWeb,
1),
(G 1, JamesHendler, affiliatedWith, RensselaerPI,
2)}
with

1 := f1 (G 1, JamesHendler, researchTopic, SemanticWeb)
and

2 := f1 (G 1, JamesHendler, affiliatedWith, RensselaerPI)

The same mapping  close to the identity mapping  is performed for meta knowledge statements like statements of graph
G3, resulting in their representation as literal statements:

Example 4.6. Representing graph G3 in RDF+
K  {
(G 3, G 1, mk:source, < www.rpi.edu/report.doc >, 
3),
(G 3, G 1, mk:certainty, 0.9, 
4),
. . . }

Note that this step is necessary in order to achieve upward and
 limited  downward compatibility between RDF+ and RDF. The
interpretation of statements, like the ones found in G3, also require
an interpretation as meta knowledge. This is achieved by mapping
RDF statements with designated properties from 	 like mk:source
and mk:certainty to the additional meta knowledge layer:

Example 4.7. Meta knowledge representation of statements in G3
M  {
(
1, mk:certainty, 0.9),
(
1, mk:source, < www.rpi.edu/report.doc >),
. . . }

The mapping of predicates of these meta knowledge statements
from RDF to RDF+ is obvious, they are mapped to itself. Objects
are mapped to the corresponding elements of the value ranges
 . For the subjects, however, there arise modeling choices. For
instance, if mk:certainty were interpreted using probability the-
ory, one might assign a distributive or a collective reading. In
the distributive reading, each fact in G1 receives the probability
value of 0.9 and, eventually, the distributive reading will assign
a joint probability of close to 0 for a large number of n stochastically independent facts, i.e. the joint probability 0.9n. In the
collective reading, the collection of facts in G1 as a whole will
receive the probability value 0.9. Therefore, the collective reading
will assign an individual certainty close to 1 for each individual
fact, when the number of facts is high and each fact is inde-

pendent from the others, i.e. the individual probability would
be n
0.9. A priori, none of the two (and more) modeling choices

R. Dividino et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 204219

is better than the other, but they constitute different modeling
targets.

The mapping from RDF to RDF+ for the distributive reading of a

meta property  is easy to achieve.

Definition 4.12 (Distributive embedding). Given an RDF statement
G{s p o} and an RDF meta knowledge statement H{G  }, a distributive embedding of RDF+ in RDF adds the meta knowledge
statement
{(
, , )| 
 = f1(G, s, p, o)  f5(
) K}

Example 4.9. Group of meta knowledge values
K:= {
(G 5, JamesHendler, researchTopic, SemanticWeb, 
1).
(G 5, JamesHendler, affiliatedWith, UnivMaryland, 
2)}
M:= {
(
1, mk:source, < www.rpi.edu/report.doc >).
(
2, mk:source, < www.cs.umd.edu/survey.pdf >)}
-is mapped to-
G 5 { JamesHendler researchTopic SemanticWeb,
JamesHendler affiliatedWith UnivMaryland }
G 6 { G 5 mk:source < www.rpi.edu/report.doc >,

< www.cs.umd.edu/survey.pdf >}

to M.

This means that such a meta knowledge statement is applied
individually to all statements in the graph to which it refers in RDF,
as indicated in the example above. For certain  there might be
several RDF meta knowledge statements H {G  i} which attach
different values i to a graph G via a single meta knowledge property . In that case set-valued ranges have to be elements of  in
order to be consistent with Definition 4.9.

4.4.2. From RDF+ to RDF

The serialization of RDF+ data in an RDF knowledge base is
straightforward. Each quintuple (g, s, p, o, 
) is realized as a corresponding triple in a named graph and the tuple identifier 
 is
discarded.

Example 4.8. Serialization of some RDF+ statements in G5 in RDF
(G 5, JamesHendler, researchTopic, SemanticWeb, 
)
-is mapped to-
G 5 {JamesHendler researchTopic SemanticWeb}

For meta knowledge statements the situation is more challeng-
ing, because literal statements with different statement identifiers
may belong to only one named graph. Their corresponding meta
knowledge statements may differ, but the realization of the meta
knowledge statements in RDF does not allow for retaining these
fine-grained distinctionsunless one chooses to change the modeling approach drastically, e.g. by assigning each literal statement
to a named graph of its own, which is undesirable (cf. discussion in
Section 3).

We have preferred to pursue a more conventional modeling
strategy for RDF with named graphs. Therefore, we weaken the
association between meta knowledge statements and their corresponding literal statements when mapping to RDF, i.e. we group
sets of meta knowledge property values into one complex value.

Definition 4.13 (Grouped meta knowledge). Given an RDF+ dataset
(K, M), RDF meta knowledge is generated by grouping RDF+ meta
knowledge statements as follows:
 := hashGraph(g) for

) to the RDF graph g

Add the triple (g  

each

:= 1 . . . n,


where (
, , i) M  (g, S, P, O, 
) K. Further, hashGraph is a
function mapping existing graph names onto graph names suitable
for associating meta knowledge and  is an operation defined on

If 

 is set-valued then a set of triples is added to g

 in order to
. The suitability of hashGraph may be application sperepresent 
cific. A general strategy may map graph names g to graph names
prefixed by < http://metaknowledge.semanticweb.org> in a deterministic manner. Operations on meta knowledge properties are
discussed in Section 5.2. In the following example the grouping of
meta knowledge values is illustrated.

In Example 4.9, the resulting grouped value is the set consisting
of the two documents <report.doc> and <survey.pdf> which is
represented by two triples. For specific meta knowledge properties,
an additional function may be necessary to provide a mechanism
for representing grouped values in an appropriate RDF data struc-
ture.

5. SPARQL for RDF and meta knowledge

For querying RDF repositories with meta knowledge awareness,
we exploit the capabilities of the SPARQL query language. In this
section we first introduce a small extension to standard SPARQL
syntax [20] and then define how SPARQL can be applied to an RDF+
knowledge base. The objective of our considerations is the derivation of meta knowledge about query results.

5.1. SPARQL syntax revisited

In our scenario, we assume that the user aims to explore the
knowledge and meta knowledge using the RDF query language
SPARQL. The following SPARQL query shown in Example 5.1 enables
the user to find experts in the domain of Semantic Web and their
affiliations evaluated on the RDF dataset presented in Example 4.1.

Example 5.1. SPARQL query to be evaluated on the RDF knowledge
base in Example 4.1
CONSTRUCT {?x worksAt ?z}
FROM G 1
FROM G 2
WHERE { GRAPH ?g { ?x affiliatedWith ?z.
?x researchTopic SemanticWeb }}

When using SPARQL to query RDF+ we introduce one additional
expression WITH META MetaList. This expression includes the
named graphs specified in MetaList for treatment as meta knowl-
edge. This statement is optional. When it is present the SPARQL
processor may digest the RDF+ meta knowledge statements derivable from the RDF named graphs appearing in the MetaList. The
SPARQL processor will then use this meta knowledge to compute and output all the meta knowledge statements derivable by
successful matches of RDF+ literal statements with the WHERE pat-
tern.

According to SPARQL semantics, FROM g expressions replicate all
RDF triples of g into the default triple space of the query. When the
same triple appears in multiple source graphs (say (s, p, o) appears
in both G1 and G2, and the query contains a clause FROM G1 FROM
G2), its meta knowledge may become ambiguous. As an intermediate step of our query processing, this meta knowledge is aggregated
using RDF+ interpretations as introduced in Section 4.3. We note
that this intermediate step is not necessary for queries with WITH
NAMED g clauses, which are also fully compatible with our frame-
work.

Thus, SPARQL queries on RDF+ have one of the two following

overall forms:

Definition 5.1 (SPARQL SELECT query). The structure of a SPARQL
SELECT query has the following form:

where KG := #1=name(G)(K), i.e. the selection of statements in K
belonging to graph G and  denotes vector concatenation.

G , we say that   (	()) is a solution for

If   (	()) [[[P]]]D

P in G.

	() =


if (P) = (g, s, p, o)
(g, s, p, o, 
) KG
f1(g, s, p, o) = 
,

 else

SELECT SelectExpression
(WITH META MetaList)?
(FROM GraphName)+
WHEREP

Definition 5.2 (SPARQL CONSTRUCT query). The structure of a
SPARQL CONSTRUCT query has the following form:

CONSTRUCT ConstructExpression
(WITH META MetaList)?
(FROM GraphName)+
WHEREP

In these definitions, P refers to a graph pattern that explains how
RDF+ literal statements from named graphs specified using FROM
statements are matched. Matches bind variables that are used for
providing results according to the SelectExpression or the Construc-
tExpression.

5.2. SPARQL semantics revisited

In this subsection we define the semantics of SPARQL queries
evaluated on an RDF+ theory. For our definitions we use two
building blocks: algebraic semantics of SPARQL [15,17] and the howprovenance calculated via annotated relations (cf. [10]).

The algebraic semantics of SPARQL queries are given based on
set-theoretic operations for sets of variable assignments. Such a set
of assignments may be assigned information about the so called
how-provenance [10], i.e. the assignments may be annotated with
formulae describing the individual derivation tree used to assign
the variables. The how-provenance annotation may be represented
by a function 	 : (U  L)
is the set of all
tuples of the length |V| over the domain U  L and F is the set of
formulae annotating variable assignments. The set of formulae F
is given by all Boolean formulas constructed over the set of literal
statements S and including a bottom element  and a top element
. The formulae constitute an algebra (F,,,,,). The special
element  is used as annotation of variable assignments which are
not in the result set. The special element  may be omitted, but it
allows for simplification of complex formulas.

|V|  F, where (U  L)

|V|

The following definition shows how a set of variable bindings is
generalized to SPARQL queries of arbitrary complexity by a recursive definition of simultaneous query evaluation and computation
of the annotations. The first step in evaluating a graph pattern
is to find matches for the triple pattern contained in the query.
+ consists of quintuples, we need to
Because the RDF+ dataset D
adapt the SPARQL evaluation procedures. The statement identifiers
do not need to be matched, as they depend functionally on graph
name, subject, predicate and object. Therefore, we consider that the
matching of triple patterns P = ( , , ), given a graph name  U,
is always defined by the following SPARQL grammar (GRAPH P).
As a simplification of our formalization we assume that the keyword GRAPH together with a URI or a graph variable is used in any
given SPARQL query. If it is not used, we may expand a given SPARQL
query to include it.

Definition 5.3 (Basic graph pattern matching). Given a basic graph
pattern P = (   ), a graph name  U and a mapping  such that
+ be an RDF+ dataset, G = gr() a RDF graph
var(P)  dom(). Let D
+, and (P) is the set of triples obtained by replacing the variin D
ables in the triples of P according to . The (meta) evaluation of
P over G, denoted by [[[P]]]D
is defined as the set of annotated
mappings 	,   dom(	):

[[[P]]]D

= {  (	())| : V  U  L

|V|  F
	 : (U  L)
dom() = var(P)

(name(G)  (P)  (
) KG)}

Assume, for the next SPARQL queries example, the following

RDF+ knowledge base D

+:

+ dataset D

+ = (K, M)

Example 5.2. RDF
K = {
(G 1, JamesHendler, researchTopic, SemanticWeb, 
1),
(G 1, JamesHendler, affiliatedWith, RensselaerPI, 
2),
(G 2, JamesHendler, researchTopic, Robotics, 
3),
(G 2, JamesHendler, affiliatedWith, UnivMaryland, 
4),
(G 2, RudiStuder,researchTopic,SemanticWeb, 
5),
(G 2, RudiStuder,affiliatedWith,UnivKarlsruhe, 
6)}
For correspondingM, see Example 5.14

Let the SPARQL query in Example 5.3 be evaluated on the dataset
+:
Example 5.3.
base D
SELECT ?g ?x ?y
FROM G 1
FROM G 2
WHERE {

SPARQL query to be evaluated on the knowledge

GRAPH ?g {?x researchTopic ?y} }

For the query of Example 5.3, we may find the following variable
assignments in Example 5.4 using standard SPARQL processing and
we may indicate, which atomic formulae, i.e. RDF+ quintuples in this
simple example, led to these variable assignments. This indication
s given by the statement identifiers representing their statements.

Example 5.4. Variable assignments for query of Example 5.3

Basic pattern matching is not directly applicable, if an expression GRAPH  appears outside a complex triple pattern. In such a
case, we first need to distribute the expression GRAPH  appropriately to atomic triple patterns in order to prescribe atomic SPARQL
expressions accessible by basic pattern matching. Because named
graphs cannot be nested, this distribution is always possible and
unambiguous.

In the following we use the function quads(P) to denote the query
resulting from this transformation. In Example 5.5 this transformation is demonstrated on a conjunction of two triple patterns.

Example 5.5. Distributing the expression GRAPH  in a complex
triple pattern with the function quads(P)
P1 =
GRAPH ?src {

{?x researchTopic?y .}
{?x affiliatedWith ?z.}}

quads(P1) =
GRAPH ?src {?x researchTopic ?y.}
GRAPH ?src {?x affiliatedWith ?z.}

Now we define the evaluation of complex graph patterns by

operations on sets of variable assignments similar to [15,17].

R. Dividino et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 204219

Definition 5.4 (Complex graph pattern matching). Given the basic
triple graph patterns P, P1, P2 and a graph name  U. Let D
+ be an
RDF+ dataset, G = gr() a RDF graph in D
+. The meta evaluation of

P, P1, and P2 over G, denoted by [[[.]]]D
G , is defined recursively as
follow:
 [[[P]]]D
 [[[P1 AND P2]]]D
 [[[P1 OPT P2]]]D
 [[[P1 UNION P2]]]D
 [[[P1 FILTER C]]]D

= [[[P1]]]D
	[[[P2]]]D
G ,

= [[[P1]]]D
= 	[[P2]]]D
G ,

 [[[P2]]]D
= [[[P1]]]D
G ,

= c([[[P1]]]D
G ).

G is given by Definition 5.3,

The definition uses the operation AND. In standard SPARQL the
operation AND is denoted by the absence of an operator. Like [15,17]
we still use the explicit term AND in order to facilitate referencing
to this operator.

The recursion in the SPARQL query evaluation defined in
Definition 5.3 is indeed identical to [15,17] (the work of [15,17] on
the SPARQL semantics is briefly summarized in Appendix A). Only
the basic pattern matching has been changed slightly. Basic pattern matching now considers the basic pattern triple with named
graph matching, and it annotates variable assignments 	() from
basic matches with atomic statements from S and variable assignments from complex matches with Boolean formulae F  F over
these statements.

The following definition specifies how complex formulae from
F, which are used to construct formulas representing the howprovenance and serve as annotations for results of matching
complex graph pattern, are derived using algebraic operations on
sets of annotated variables bindings.

= 	1(1)  	2(2), where

Definition 5.5 (Algebra of annotated relations). Let 	, 	1 and 	2
be sets of annotated variable assignments. We define 	, = 	, , \,
, and   via operations on the annotations of the assignments (two
binary operations  and , a unary operation ) as following:
x  dom(1) 
 (	1		2)()
dom(2) : 1(x) = 2(x) and where 1 and 2 are compatible
and  = 1  2
 (	1  	2)() = 	1()  	2(),  	1 or  	2
 (	1 \ 	2)()
x  dom(i)  dom() : i(x) = (x).
 (	1 = 		2)() = (	1		2)()  (	1 \ 	2)().
 (c(	())) = 	()  fc(), where fc() denotes a function mapping  to either  or  according to the condition c.
 ( X(	())) =

i, 	2(i) /= 	2(i)

= 	1()  

, dom()=X, 	() /= 	().

, where

2,

 Commutativity:

	1(1)  	2(2) = 	2(2)  	1(1)
	1(1)  	2(2) = 	2(2)  	1(1)

 Associativity:

	1(1)  (	2(2)  	3(3)) = (	1(1)  	2(2))  	3(3)
	1(1)  (	2(2)  	3(3)) = (	1(1)  	2(2))  	3(3)

 Distributivity:

	1(1)  (	2(2)  	3(3))
= (	1(1)  	2(2))  (	1(1)  	3(3))
	1(1)  (	2(2)  	3(3))
= (	1(1)  	2(2))  (	1(1)  	3(3))

 Complement:

	1(1)  	1(1) =
	1(1)  	1(1) = 

 Absorption:

	1(1)  (	1(1)  	2(2)) = 	1(1)
	1(1)  (	1(1)  	2(2)) = 	1(1)

 De Morgans:

(	1(1)  	2(2)) = 	1(1)  	2(2)
(	1(1)  	2(2)) = 	1(1)  	2(2)

In order to show the evaluation of a SPARQL query, we consider
the query from Example 5.6 to be evaluated on the knowledge base
+.

SPARQL query to be evaluated on the knowledge

Example 5.6.
base D
SELECT ?h1 ?h2 ?x ?y
FROM G 1
FROM G 2
WHERE {

{GRAPH ?h1 {?x affiliatedWith ?y}}AND
{GRAPH ?h2 {?x researchTopic SemanticWeb}}
FILTER {?x=JamesHendler}}

Furthermore,

following the algebraic definition of howprovenance formula, we present the set of laws for annotated
relations.

Definition 5.6 (Laws of annotated relations). Let 	1, 	2 and 	3
be sets of annotated variable assignments. We define the laws
for annotation relations via operations on the annotations of the
assignments as following:
 Idempotency:

	1(1)  	1(1) = 	1(1)
	1(1)  	1(1) = 	1(1)

Let P be the graph pattern contained in the WHERE clause of the
query. Then the evaluation of P is defined by an algebraic expres-
sion:

[[[P]]]D

= [[[{P1 AND P2}FILTER{?x = JamesHendler}]]]D

= ?x=JamesHendler([[[P1AND P2]]]D
G )

= ?x=JamesHendler([[[P1]]]D
= ?x=JamesHendler(	1		2)

	[[[P2]]]D

G )

where 	1 and 	2 are relations representing variable assignments and their annotations.
In this example and in the
preceding definition we have used algebraic operations on sets
of annotated bindings.
In order to evaluate the expression
?x=JamesHendler(	1		2) we need to determine 	1 and 	2 using
Definition 5.3. The intermediate result is shown in Example 5.7.

2 Two mappings 1 and 2 are compatible when for all x  dom(1)  dom(2), it
is the case that 1(x) = 2(x), then 1  2 is also a mapping.

Example 5.7. Determining 	1 and 	2-intermediate result of the
expression ?x=JamesHendler(	1		2)

. Thus we do not consider meta knowledge interpretations of such
bindings over formulae. Remember that meta knowledge interpretations allow for only one  per 
  	 and   	 (cf. Definition 4.9).
In order to make use of the how-provenance represented by the
annotations we require that for each meta knowledge property  an
algebra ( , , , , , ) with three operations  , ,
and two special elements  ,   is defined. The definition of
the algebras can be supplied by a modeler according to the intended
semantics of the different meta knowledge properties.
Definition 5.8 (	-Interpretation of formulae). Let F, F1, F2  F be
Boolean formulae over S, let Fa  S be an atomic formula. We define
the interpretation If
 If
 If
 If
 If

 (Fa) := I (Fa);
 (F) is  If
 (F);
 (F1) If
 (F1  F2) is If
 (F1) If
 (F1  F2) is If

 (F2);
 (F2);

 as follows:

To evaluate the conjunction of two patterns, the operation 	 is
applied, the result is shown in Example 5.8. The annotation 
1  
2
of the first row represents that this assignment has been derived
from the conjunction of the two literal statements 
1 and 
2 (see
Example 5.2).
Example 5.8. Determining 	1		2-intermediate result of the
expression ?x=JamesHendler(	1		2)

Application of the -operation to the intermediate results gives

the annotated relation shown in Example 5.9.
Example 5.9. Result of ?x=JamesHendler(	1		2)

The annotations 	() can now be used to assign truth values
for each tuple binding . Is (cf. Definition 4.8) assigns truth values
to all atomic statements si  K  S. We extend the interpretation Is
to capture all the Boolean formulae over statements S.
Definition 5.7 (Standard interpretation of formulae). Let F, F1, F2  F
be Boolean formulae over S, let Fa  S be an atomic formula. We
define the standard interpretation of formulae If
 If
 If
 If
 If

s (F) = ; If
s (F1) = If
s (F1) =  or If
s returns  for the assignment shown in the first
row of 	1		2 from Example 5.8, because the statements 
1 and

2 are in the knowledge base.

s (Fa) := Is(Fa);
s (F) := if If
s (F1  F2) is  if If
s (F1  F2) is  if If

s (F) :=  if If
s (F) =;
s (F2) = , otherwise 

s (F2) = , otherwise .

For instance, If

s as follows:

Basically, the standard interpretation of formulae If

s assigns truth
values for all variable bindings that are in the knowledge base,
as well as capture all the Boolean formulae over these statements
bindings. For producing the result set, we dismiss all variable bindings with  value assigned.

Analogously to If

s , we can extend a 	-interpretation I over RDF+
statements to a 	-interpretation If
 over formulae. Similar to definition the standard interpretation of formulae, the 	-interpretation
assigns values which represent meta knowledge properties for all
variable bindings which are not in a set of bindings annotated with

The definition of knowledge dimensions can be supplied by the
administrator of the knowledge base, according to the intended
semantics of particular meta knowledge properties. For illustration
we consider in Example 5.10 the definition of fuzzy logic operations to calculate a possibility measure on variable assignments,
operations defined on timestamps which calculate the time of the
last modification, and set operations defined for source documents
that construct the combined how-provenance.

certainty(x1)

certainty(x2))
certainty(x2))

certainty(x1), If
certainty(x1), If

Example 5.10. Fuzzy logic operations for meta knowledge prop-
erties
certainty = [0, 1]
certainty(x1  x2) = min(If
If
certainty(x1  x2) = max(If
If
certainty(x1) = 1  If
If
time = [0,)
time(x1  x2) = max(If
If
time(x1  x2) = min(If
If
time(x1) = 0
If
source = 2D, D the set of document URIs
source(x1  x2) = If
If
source(x1  x2) = If
If
source(x1) = {}
If

source(x1)  If
source(x1)  If

time(x1), If
time(x1), If

time(x2))
time(x2))

source(x2)
source(x2)

As discussed earlier, the graph pattern queries evaluation with
meta knowledge algorithm proposed in this paper follows a com-
 sub-pattern of P the result of
positional semantics, i.e. for each P
 can be used to evaluate P. In order to solve this probevaluating P
lem algorithmically, we have implemented, analogously to [15,16],
a depth-first strategy algorithm for evaluating SPARQL query pat-
+, has
terns with meta knowledge. This algorithm, denoted by Eval
been implemented so that it emulates exactly the recursive definition of [[[.]]] for well-designed pattern as defined in [19]. Formally,
+, we define the evaluation of pattern P with
given an RDF+ dataset D
the set of mappings , denoted by Eval

D+ (P, ) as follows:

Eval

D+ (P, ) =

Eval
if = then return ()
ifPis a triple patterntthen return (	[[[t]]]D+ )
ifP = (P1 AND P2)then return
ifP = (P1 OPT P2)then return
ifP = (P1 FILTER R)then return
D+ (P1, )  fR()}

Eval
{	() Eval
wherefR()denotes a function mappingto either
oraccording to the conditionR

D+ (P2, Eval
D+ (P1, ))
D+ (P1, ) = 	 Eval

D+ (P2, Eval

D+ (P1, ))

R. Dividino et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 204219

Then, the evaluation of P against a dataset D

D+ (P), is Eval
simply by Eval
mapping with empty domain.

+, which we denote

D+ (P, 	()), where 	() is the

5.3. SPARQL query forms

As mentioned before, in this paper we are only interested in standard SPARQL SELECT and CONSTRUCT query forms. The evaluation
of SPARQL queries on RDF+ data differs in that meta knowledge is
attached to the results.

The evaluation of SELECT queries on an RDF+ dataset is based on

 X([[[P]]]D
G ) (see Definition 5.5), where X denotes the set of variables specified in the SelectExpression (see Definition 5.1). If X forms
a proper subset of the variables used in the graph pattern then the
annotations of all bindings  are grouped. This grouping is analogous to the generation of grouped meta knowledge described in
Definition 4.13. As an example consider the query shown in Example
5.11, which is a slight modification of the query from Example 5.6,
applied to the data shown in Example 5.2. For the result see Example
5.12. In contrast to Example 5.8 there is only one row for JamesH-
endler.

Example 5.11. SPARQL query to be evaluated on knowledge base

SELECT ?x
WITH META G 3, G 4
FROM G 1
FROM G 2
WHERE {

{GRAPH ?h1 {?x affiliatedWith ?y}}AND
{GRAPH ?h2 {?x researchTopic SemanticWeb}}}

The result of a SELECT query is a set of extended bindings. Such
an extended binding contains values for the specified variables
and values for each meta knowledge property   	 which can be
regarded as additional variables.

Example 5.12. Determining  {?x}(	1		2)-intermediate result of
the expression defined in Example 5.11

For each binding  of query from the Example 5.11, the vari-

ables  are bound to If
 ( X([[[P]]]D
G )(i)) (see Example 5.13).
For this result the meta knowledge from Example 5.14 has
certainty((
1  
2)  (
1  
4)) = 0.9. If no
been used. For instance If
meta knowledge statement (
, , ) exists for a particular RDF+
literal statement f5(
) and a particular meta knowledge property  then  serves as default value. For the result of a

SELECT query all bindings from  X([[[P]]]D
G ) are extended in this
way.

Example 5.13. Variable bindings for If
of the expression defined in Example 5.11

 ( X([[[P]]]D

G )(i))-results

+ = (K, M)

Example 5.14. Meta knowledge statements, D
M = {
(
1, mk:certainty, 0.9)
(
1, mk:time, 5/5/2007)
(
2, mk:certainty, 0.9)
(
2, mk:time, 5/5/2007)
(
3, mk:certainty, 0.6)
(
3, mk:time, 6/6/2001)
(
4, mk:certainty, 0.6)
(
4, mk:time, 6/6/2001)
(
5, mk:certainty, 0.6)
(
5, mk:time, 6/6/2001)
(
6, mk:certainty, 0.6)
(
6, mk:time, 6/6/2001)}

Analogously to standard evaluation, the evaluation of a CONSTRUCT query on an RDF+ dataset results in a single RDF+ graph
which is built using the graph template specified in the ConstructExpression (see Definition 5.2). This is in line with the fact that the
graph template consists of a conjunction of triple patterns and a
named graph thus quadruple patterns cannot be stated.3

Similar to the evaluation of SELECT queries, the evaluation of

CONSTRUCT queries is based on  X([[[P]]]D
G ), where X denotes the
set of variables specified in the ConstructExpression. The RDF+ graph
is constructed as described in the following:

Let tj be the triple pattern j specified in the ConstructExpres-
sion, P denote the graph pattern specified in the WHERE-clause,
(si,j, pi,j, oi,j) denote the triple obtained by replacing the variables in
tj according to a mapping i and g denote a new graph name. Then,

for each binding i   X([[[P]]]D
G ) and for each tj the quintuple
(g, si,j, pi,j, oi,j, 
i,j) is added to S, where 
i,j is the statement identifier f1(g, si,j, pi,j, oi,j). Further (
i,j, , i,j) is added to M, where
i,j = If

 ( X([[[P]]]D

G )(i)).

Each new quintuple inherits the meta knowledge properties 
associated with the binding which has been used to create that
quintuple. The value of i,j is determined by applying If
 to the for-

mula which annotates the binding. Note that since  X([[[P]]]D
G )
and the interpretations If
 are functions and further the graph template in ConstructExpression is a set of triples the meta knowledge
properties (
i,j, , i,j) are unique for a given 
i,j.

As an example for a CONSTRUCT statement consider Example
5.15. Meta knowledge for some of the RDF+ statements presented
in Example 5.2 is specified in Example 5.14. For graph pattern P

contained in this query the result of  X([[[P]]]D
G ) is identical to
the annotated relation shown in Example 5.8 except for the first
two columns. Based on the single triple pattern (?x worksAt ?y)
contained in the graph template and the two bindings contained

in  X([[[P]]]D
G ) two quintuples are constructed and added to the
RDF+ literal statements Kres as shown in Example 5.16. Mres contains the corresponding meta knowledge statements resulting from
If
 ( X([[[P]]]D
Example 5.15. SPARQL query CONSTRUCT
CONSTRUCT {?x worksAt ?y}
WITH META G 3, G 4
FROM G 1
FROM G 2
WHERE {

G )(i)).

{GRAPH ?h1 {?x affiliatedWith ?y}}AND
{GRAPH ?h2 {?x researchTopic SemanticWeb}}}

3 Standard SPARQL does not allow for giving this graph a name. In order to associate meta knowledge, multiple named graphs as outputs are convenient. In order to
remain standard compliant, the SPARQL engine may however also return data and
meta knowledge in two different batches distinguished by some implementationspecific mechanism.

Example 5.16. Variable binding for query of the Example 5.15
Kres = {
(Gnew, JamesHendler, worksAt, RensselaerPI, 
new1)
(Gnew, JamesHendler, worksAt, UnivMaryland, 
new2)
(Gnew, RudiStuder, worksAt, UnivKarlsruhe, 
new3)}
Mres = {
(
new1, mk:certainty, 0.9)
(
new1, mk:time, 5/5/2007)
(
new2, mk:certainty, 0.6)
(
new2, mk:time, 6/6/2001)
(
new3, mk:certainty, 0.6)
(
new3, mk:time, 6/6/2001)}

5.4. Advanced query forms

The SPARQL query forms presented so far can be seen as a
straightforward adaptation of querying capabilities to a knowledge
base with associated meta knowledge. Beyond this, the presented
framework can potentially be extended for more complex query
forms with meta knowledge awareness.

5.4.1. Queries with conditions on meta knowledge

A possible interesting extension of our framework is the support
for additional selection and/or ranking conditions on associated
meta knowledge attributes. From the conceptual point of view, this
functionality can be seen as an extension of the WHERE clause.
In our example introduced in Section 2, the query about affiliations of researchers (Example 5.1) may also require that only
certain facts (say with associated certainty values greater 0.8)
shall be used. This restriction would result in exclusion of triples
from graph G2 (with insufficient certainty of 0.6) from evalua-
tion. Consequently, the result set would only contain the statement
JamesHendlerworksAtRensselaerPI which is completely constructed
using triples from remaining graph G1, with its high certainty of
0.9. This idea is reflected in [4], which gives examples of querying RDF through SPARQL queries with meta knowledge constraints,
using the notion of Named Graphs. Such functionality can be realized in our framework in a straightforward manner, using nested
queries (or querying with meta knowledge from views). Since
nested queries and result ranking are expected to become part of
the SPARQL2 specification in near future, the presented extension
can be seen as a promising upcoming task.

We note that integration of nested queries with our approach
would result in a substantially more flexible and powerful solution
than the approach from [4]. In particular, our framework potentially allows to express filtering and/or ranking conditions on meta
knowledge of query results. Conceptually, this functionality can be
seen as an extension of the HAVING clause (in the common SQL like
sense). For instance, for our sample query from Example 5.1 we may
require the minimum overall certainty of each result to be greater
0.8. The resulting filter condition is then applied to query results
from Example 5.16, which contain complex interpretations of meta
knowledge for possible variable bindings.

5.4.2. Nested meta knowledge

The nested meta knowledge (i.e. meta knowledge about meta
knowledge) can potentially be expressed through RDF capabilities.
Following our example from Section 2, in the nested setting we
would be able to specify conditions regarding recency or reliability of associated meta knowledge. For instance, we may require
that only query results with high certainty of their extraction
sources shall be returned. This kind of queries was not yet a concern in our framework presented so far. However, the required
adaptation is not too difficult. As discussed in Section 3, there is
no conceptual separation between knowledge and meta knowledge in our repository. For this reason, complex queries may treat
meta knowledge as knowledge and obtain its meta annotation (i.e.

nested meta knowledge) in a quite straightforward manner. Like-
wise, advanced querying mechanisms with nested meta knowledge
support can easily be supported. As a consequence from the preceding discussion, we note that advanced conditions with nested
meta knowledge can also be specified both for repository contents
(i.e. kind of advanced WHERE clause) and for results of complex
queries (i.e. kind of advanced HAVING clause).

6. Tasks and benefits

This section summarizes the discussed steps of meta knowledge representation and utilization for the sample scenario that
was introduced in Section 2.

6.1. Tasks for the administrator

In order to represent and utilize meta knowledge, the system
administrator has to make some design choices. In particular, the
application-specific meta knowledge properties must be defined. In
our sample scenario, we consider three meta knowledge properties:
source, certainty, and timestamp. In the next step, the administrator defines the intended semantics of these properties in order to
facilitate query processing with complex expressions and pattern
combinations. For evaluating graph pattern expressions, we use the
definition from Section 5.2, and we assume that the corresponding
definitions for meta knowledge properties are defined, e.g. the fuzzy
logic operations presented Example in 5.10.

Finally, data and available associated meta knowledge are represented in RDF using named graphs [5,6], and imported into our
RDF+-based repository.

6.2. Processing performed by the system

We assume that the system imports the small sample dataset
introduced in Section 2. The knowledge base is transformed into the
RDF+ quintuples shown in Example 5.2 as discussed in Section 4.
Associated meta knowledge is transformed into further RDF+ literal
statements and RDF+ meta knowledge statements. For the properties mk:time and mk:certainty an example is presented in Example
5.14.

Following our sample scenario, the query from Example 5.1 can
be reformulated as the query from Example 5.15 which retrieves
names of Semantic Web experts together with their affiliations
and the associated meta knowledge. Internally, the query processor evaluates this query using graph patterns as discussed in Section
5.2. If P denotes the graph pattern from this query then all matches
for all variables in P are given by the evaluation [[[P]]]. The resulting
set of annotated variable assignments is shown in Example 5.8. It
contains possible variable assignments, and the how-provenance
(S3) that explains how these source statements have been used.

By combining this information with definitions for meta knowledge properties and available meta knowledge statements, the
query processor constructs the result shown in Example 5.16. This
result is then serialized in RDF.

6.3. Benefits for the user/developer

The user or application developer can access the knowledge
stored in the RDF+-based repository in different ways. On one hand,
the repository does not change the existing SPARQL semantics and
thus fully supports common SPARQL queries. This is an important
advantage for compatibility with existing applications and inter-
faces. On the other hand the repository supports the SPARQL with
meta knowledge (Section 5.2). Thus, the user obtains additional
access to valuable meta knowledge that can be used for relevance

R. Dividino et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 204219

ranking, conflict resolution, or other applications in connection
with retrieved knowledge.

In our application scenario, the user may realize that the query
answer is potentially contradictive (James Hendler is affiliated with
Rensselaer PI and University of Maryland). By inspecting the associated meta knowledge, he would realize that the second fact was
generated by mistake. In fact, it is based on outdated information (knowledge from the document survey.pdf with timestamp
6/6/2001) that was wrongly combined with knowledge from a
more recent source (namely document report.doc with timestamp
5/5/2007). It turns out that the affiliation of James Hendler has actually changed from University Maryland to Rensselaer PI, and the
erroneous tuple can be safely excluded from further processing.

7. Equivalences

The main goal of this section is to show the equivalence holding
between the standard evaluation of SPARQL queries, denoted by
[[.]] (see Appendix A), and the evaluation with meta knowledge,
presented in this paper denoted by [[[.]]]. For this purpose, we first
define the meta knowledge projection operator 	 as following:

Definition 7.1 (Meta knowledge projection). Let 	 be an annotated
relation representing the set of tuples of variable assignments and
their annotations, then
	(	) = 	var(P)((Is)(	))
where var(P) is the set of variables occurring in P, and Is  
denotes the standard interpretation Is of an annotation formula
evaluated to .

Basically, the meta knowledge projection operator selects all
the statements corresponding the variables bindings of the evaluation and ignores the meta knowledge properties assigned to the
statements in the knowledge base. As discussed earlier the standard interpretation Is of an annotation formula evaluates to  if
and only if the statements in the knowledge base are elements
of the variable assignments obtained via evaluation, i.e. the corresponding variable assignment is in the set of variable assignments
obtained via standard SPARQL evaluation extended with identifiers
(see Definition 5.3). Based on this, the next proposition defines the
equivalence holding between the evaluation with meta knowledge
and the standard SPARQL evaluation.

+ dataset D

Proposition 7.1. Given a graph pattern expression P, we say that the
meta projection on the results of evaluation with meta knowledge of
+ is equivalent
the graph pattern expression P over a RDF
to the standard evaluation of P over the RDF dataset D,denoted by
	[[[P]]]D

+ = [[P]]D.
Proof.
(sketch) For sets of variable assignments obtained via basic
pattern, this follows immediately from Definition 5.3 and the application of operator 	 over 	, so that for each substitution 	()
obtained by evaluation over a dataset D
, can be reduced
to a substitution  obtained from the evaluation P over a RDF
dataset D, [[P]]D, defined in [15,17] by selecting all  where Is of an
annotation formula evaluates to  and dropping all remaining substitutions of 
. For complex graph patterns, the evaluation defined
(see Definition 5.3) is indeed identical to [15,17]. 

, [[[P]]]D

For relations annotated with Boolean formulae and standard

relational algebra a proof for Proposition 7.1 can be found in [9].

Now, we can define the equivalence holding between equivalence graph pattern expressions with respect to the evaluation
with meta knowledge, i.e. show that the evaluation of equivalent
queries are annotated with equivalent meta knowledge properties.
By equivalence we mean that the interpretation of formulae used to

annotate bindings contained in the results of the equivalent queries
are equivalent.
We use for the algebra of annotation formulae as syntactic
objects (F,,,,,) (see Section 5). The elements of F are
Boolean formulae built over the set of all literal RDF+ statements S.
Instead of the statements themselves we use their identifiers. In the
tagged tuple model which we adopt here a relation is represented
by a function mapping all tuples of a domain to an annotation.
Since we use F only as a placeholder we could just as well directly
annotate variable bindings with elements of different meta knowledge algebras. Therefore, first we need to define restrictions on the
algebra for meta knowledge interpretation for each meta knowledge property , ( , , , , , ) as defined in Section 5,
so that the equivalence holds. As a motivation for the reader, before
presenting the restrictions for the meta knowledge algebra, in the
next example we show one case where the equivalence holds and
another where the equivalence does not hold when the meta knowledge properties are defined using the fuzzy logic operations as
presented in Example 5.10. Let P = (P1 AND P2) and P
 = (P2 AND P1)
be equivalent complex graph pattern expressions. The annotation
 consist of (F1  F2), and (F2  F1), respectively,
results for P and P
where F1 and F2 denote annotation Boolean formulae. We are going
 with the meta knowledge property time. The 	-
to evaluate P and P
time(F1  F2) =
interpretation for Itime for the (F1  F2) formulae is If
max(If
time(F2)). Likewise, the
time(F2  F1) =
	-interpretation for Itime for the (F2  F1) formulae is If
max(If
time(F1)). As shown in this example the meta knowl-
 leads to the same result, thus it
edge evaluation for P and P
is equivalent. Now consider the equivalent graph patterns P and
((P)), and the respective annotation results F and ((F)), where
F denote an annotation Boolean formula. The 	-interpretation for
Itime for the (((F))) formulae is bounded to 0 which is not the
case for the formulae F. Consequently the annotation results F and
((F)) for the equivalent graph pattern expressions P and ((P))
are not equivalent.

time(F2)) = max(If

time(F1)timeIf

time(F2), If

time(F1), If

In the following we summarize some of the restrictions on the
meta knowledge algebra. Let P1, P2 and P3 be graph pattern expressions and the built-in condition P:

(i) [[[[P1 AND P2]]]D

= [[[P2 AND P1]]]D

G , and

= [[[P2 UNION P1]]]D

[[[[P1 UNION P2]]]D

Since annotations for results of graph pattern of the form P1
AND P2 are of the form F1  F2, where F1 and F2 denote annotation formulae, and annotations for results of graph pattern of
the form P1 UNION P2 are of the form F1  F2 we require that:
and  are associative and commutative.

for annotation formulae in order to guarantee that results of
equivalent queries are associated with equivalent meta knowl-
edge.

(ii) [[[[(P1 AND (P2 UNION P3))]]]D

= [[[((P1 AND P2) UNION (P1 AND P3))]]]D

In order to satisfy this equivalence, the annotation formulae
and algebras used to interpret these formulae need to satisfy
the equivalence:
 (F1  (F2  F3))  If
If

 ((F1  F2)  (F1  F3))

(iii) [[[[((P1 UNION P2) FILTER R)]]]D

[[[((P1 FILTER R) UNION (P2 FILTER R))]]]D
[[[[((((P1 FILTER R1) FILTER R2)))]]]D

[[[[(((((P1 FILTER (R1  R2))))]]]D
G .

G , and

Now we look at equivalences in the context of FILTER expres-

sions. Equivalence requires:
 ((F1  F2)  r)  If
If

 ((F1  r))  If

 ((F2  r))

which follows from (i) and (ii).

Analogous:
 ((F1  r1)  r2)  If
If
where r3 = r1  r2.
(iv) [[[[(P1 AND P1)]]]D

 (F1  r3)

= [[[[P1]]]D

Equivalence requires idempotency:
 (F  F)  If
If

 (F)

Based on the restrictions presented above, we see evidences for
requiring the meta knowledge algebra to form such a commutative
semiring [10] since the laws of commutative semirings are forced by
certain expected identities in the meta knowledge algebra. For this
purpose, we define in the next theorem that the meta knowledge
algebra has to take form of a commutative ring algebraic structure in
order to hold the equivalences presented above for meta knowledge
interpretations. With the commutative ring approach, the extendability of our approach increases due to the low restriction level on
the meta knowledge algebra required for the equivalences.

Theorem 7.1.
sions using AND, OR, and FILTER operator and D
We have that [[[P1]]]D
properties form a commutative semiring.

Let P1 and P2 be equivalent graph pattern expres-
+ dataset.
if and only if all meta knowledge

+ = [[[P2]]]D

+ a RDF

Proof.
(sketch) This proof is an immediate consequence of the
laws of commutative semirings defined in [10]. Suppose that the
meta knowledge algebra ( , , , , ) is not a commutative semiring with the following identities (see Definition 5.5 and
Definition 5.6): union is associative, commutative and has iden-
tity; and is associative, commutative and distributive over union;
projections and selections commute with each other as well as with
unions and joins. However, according to [10] these identities hold
for meta knowledge algebra if and only if ( , , , , ) is a
commutative semiring, which contradicts our assumption. Hence
the meta knowledge algebra is a commutative semiring, i.e. algebraic structure ( , , , , ) such that ( , , ) and
( , , ) are commutative monoids,  is distributive over  and
a, 0, a  0 = a  0 = 0 

To illustrate an instance of this theorem, consider the meta
knowledge formula F1  F2 and F2  F1 for the graph pattern expres-
 = (P2 AND P1). Evaluating them in any
sions P = (P1 AND P2) and P
of the meta knowledge dimensions, we get indeed the same value
from the interpretation.
8. Complexity of Eval+

In this section we analyze how the construction of the annotations influences the complexity of the decision problem related to
SPARQL. The decision problem associated with the standard evaluation of a SPARQL query can be stated as following [15]: Given an
RDF dataset D, a graph pattern P and a mapping , determine whether
 is in the result of P applied to D. For this decision problem, which
we denote by EvalD(P), an analysis of the complexity is presented
in [15,16]. In the context of RDF+ datasets and annotated variable
assignments we have a slightly different decision problem: Given
+ graph pattern P, a variable assignment
an RDF
 and an annotation   determine whether   is the correct annotation

+ dataset D

+, an RDF

D+ (P). An annotation is corof . We denote this problem by Eval
rect iff the formula is equivalent (in the logical sense) to the formula
obtained by evaluation as defined in Section 5.

With the following theorems we show the time complexity and
+ for patterns that do not use the OPTIONAL
space complexity of Eval
+ is built over a set of RDF lit-
operator. Note that the RDF+ dataset D
eral statements and meta knowledge statements of the RDF dataset
+ = (K, M), we assume that the size of
D (see Section 4.4). For D
|D
+| = |K|  |M|  1/2|D|2, and consequently the time complexity of
building D

+ is the order of O(|D|2).

The RDF counterparts of both theorems have been established by
[15,16]. Like [15,16] we restrict to graph patterns which do not contain blank nodes. In the first theorem we consider graph patterns
which use only AND and FILTER operations. Bindings obtained by
such patterns are annotated with formulae which do not contain
any other operator besides  according to Definition 5.4.
+|) for graph patTheorem 8.1. Eval
tern expressions constructed by using only AND and FILTER operators
and for annotation formulas using only the operation .
Proof. The proof consists of two parts: In the first part we construct a correct annotation   for  and in the second we check
whether   and   are equivalent. In the following let pi denote pattern i from P and (pi) denote the triple obtained by replacing the
variables in the pattern pi according to .

+ can be solved in time O(|P|  |D

In order to construct   we start by evaluating [[[pi]]]D
for all
+ needs to be
pattern using Definition 5.3. In order to achieve this D
+|). Then,
searched for all (pi). This can be performed in O(|P|  |D

we construct the algebraic expression 	 by evaluating [[[P]]]D
using Definition 5.4. This can be performed by traversing P. The cor-
+ is defined as
rect annotation   of  in the result of evaluating on D
	() (see Definition 5.5). We can construct   = 	() in a depthfirst traversal of 	 as following:
Let 	1, 	2 be algebraic expressions part of 	. For each join
operation in 	 the annotation of (	1		2)() is given by 	1() 
	2(). For each select operation c(	)() is given by 	() if condition c is fulfilled otherwise it is given by . Since traversing and 	
each has time complexity O(|P|) the evaluation of   = 	() remains
in O(|P|  |D
Now we determine whether for a given annotation   holds   
 . We transform both formulas into a normal form in O(|P|  log |P|)
using associativity, commutativity and idempotency of . First, we
remove all brackets then establish an order among atomic formulas
(identifiers and,) and finally remove duplicates. For   and   normalized this way syntactic equality bi-implies logical equivalence.
Assuming |P| < |D
+|).

+| the overall complexity remains in O(|P|  |D

+|).

Theorem 8.2. Eval
constructed by using only AND, FILTER and UNION operators.

+ is NP-complete for graph pattern expressions

Proof. The proof consists of two parts: In the first part we show
+ is contained in NP and in the second we establish NPthat Eval
+. As above, let pi denote triple pattern i from P and
hardness of Eval
(pi) denote the triple obtained by replacing the variables in the
pattern pi according to .

The first part consists of two steps as well: first we construct
a correct annotation   for  and then we check whether   and
  are equivalent. In order to construct   we start by evaluating

[[[pi]]]D
for all pattern using Definition 5.3. In order to achieve
+ needs to be searched for all (pi). Then, we construct the
this D
algebraic expression 	 by evaluating [[[P]]]D
using Definition 5.4.
This can be performed by traversing P. The correct annotation   of 
+ is defined as 	(), see Definition
in the result of evaluating P on D
5.5. We can construct   = 	() in a depth-first traversal of 	 as
following:

R. Dividino et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 204219

Time complexity for evaluating 	() is O(|P|  |D

Let 	1, 	2 be algebraic expressions part of 	. For each join
operation (	1		2)() is given by 	1()  	2(). For each union
operation (	1  	2)() is given by 	1()  	2(). For each select
operation c(	)() is given by 	() if condition c is fulfilled otherwise it is given by .
+|). The evaluation of      is more difficult if UNION operations are contained in
P. But it is subsumed by checking equivalence of Boolean formulae

which is a NP-complete problem. Thus, the decision problem Eval
is contained in NP.
+ is an NP-complete problem if Eval,
which has been shown to be NP-complete [15,16], can be reduced
+ if the evaluation defined in
to it. Eval can be reduced to Eval
Section 5 results in an annotation    exactly for such bindings
which are not in the result of standard SPARQL evaluation. For
graph patterns that do not contain the OPTIONAL operator this can
be shown by induction over the structure of algebraic expressions
using Definition 5.4 and its standard SPARQL counterpart from [15].

We can deduce that Eval

9. Implementation

The framework metaK described in this paper has been implemented in Java language, using libraries from the Sesame Project4.
The prototype of metaK is available as an open source implementation at < http://isweb.uni-koblenz.de/Research/MetaKnowledge
>.

From the practical point of view, the framework can easily be
customized for new meta knowledge aspects. Dimension-specific
interpretations of meta knowledge properties are implemented
separately, as small Java classes. For defining a new meta knowledge aspect, the corresponding interpretation function must be
implemented with respect to framework interfaces.

In order to evaluate the overhead produced by the evaluation of
meta knowledge properties for results of SPARQL queries we carried
out two experiments based on the well-known LUBM benchmark
[11]. Our main aim is to find out whether the evaluation of SPARQL
queries remains feasible if meta knowledge is provided within the
query results, i.e. conduct a family of experiments to validate the
theoretical results of Section 8.

A key question is how to separate the additional effort for
the evaluation of provenance and meta knowledge from standard
SPARQL processing. Triples describing meta knowledge receive an
additional meta knowledge interpretation according to Section 4.
At the same time they are also treated as ordinary RDF triples (and
thus can be queried using standard SPARQL). Thus, if we add meta
knowledge to a knowledge base this increases its overall size which
also increases the workload for standard query processing. In order
to account for this we compare query evaluations performed on
the same knowledge base which includes meta knowledge. Our
implementation is built on top of Sesame5 2.0 (beta 6) using query
rewriting. The triple store is used to store both, knowledge and meta
knowledge. We expect that a native implementation of the meta
knowledge framework can achieve an increased performance.

9.1. Query evaluation

For the evaluation of SPARQL on RDF+ we defined the results
of SELECT queries to be set-valued (see Section 5.2). For standard SPARQL [20], however, a SELECT query returns a solution
sequence which may contain duplicate elements. All 14 queries of

the LUBM benchmark are SELECT queries. To allow for a consistent
comparison of extended evaluation on one side and standard evaluation on the other we added the keyword DISTINCT to the queries
for standard evaluation. This tells the query processor to eliminate duplicates. Since the evaluation of individual meta knowledge
properties can be arbitrarily complex we compare the following
three kinds of query evaluation:
 Standard evaluation with additional duplicate elimination (SD),
as performed by Sesame,
 Evaluation of provenance formulae for each query result (PF) and
 Evaluation of four basic meta knowledge properties (M4), namely
agent, confidence, creation time and source, see Example 5.10 (we
evaluate agent analogously to source).

Only the last type of query processing actually makes use of the

additional triples.

9.2. Data

We added artificial meta knowledge to the LUBM data. Amount
and granularity of the additional meta knowledge are key properties of the resulting dataset.

We created two datasets containing a different percentage of
meta knowledge triples. The first dataset (MK29) was created based
on LUBM OWL data for 10 Universities. We added the meta knowledge by putting groups of 10 consecutive original triples into one
named graph and associating random values of the meta knowledge properties agent, confidence, creation time and source with this
graph name, see Example 9.1. As a consequence the dataset contains 29 percent of meta knowledge which might be a reasonable
scenario in a real world scenario. The resulting dataset consists of
1.8 million triples of which 1.3 million triples were created by the
LUBM generator to which we added 0.5 million meta knowledge
triples. It contains 0.3 million (additional) graph URIs.

Example 9.1. Original triples of dataset MK29 in one named graph
associated with meta knowledge properties
<graph>

<uri>http://www.x-media-project.org/ontologies/someGraph#0-0 30</uri>

<triple>

<uri>http://www.Department0.University0.edu/FullProfessor1</uri>
<uri>http://www.lehigh.edu/0401/univ-bench.owl#doctoralDegreeFrom </uri>
<uri>http://www.University882.edu</uri>

</triple>

<triple>

<uri>http://www.University882.edu</uri>
<uri>http://www.w3.org/1999/02/22-rdf-syntax-ns#type</uri>
<uri>http://www.lehigh.edu/0401/univ-bench.owl#University</uri>

</triple>

. . .

<graph>

<uri>http://www.metaknowledge.semanticweb.org0-0 30</uri>

<triple>

<uri>http://www.x-media-project.org/ontologies/someGraph#0-0 30</uri>
<uri>http://www.x-media.org/ontologies/metaknow#source</uri>
<uri>http://www.x-media-project.com/ex#source30</uri>

</triple>

<triple>

<uri>http://www.x-media-project.org/ontologies/someGraph#0-0 30</uri>
<uri>http://www.x-media.org/ontologies/metaknow#confidence degree</uri>
<typedLiteral datatype=http://www.w3.org/2001/XMLSchema#double>0.7

</typedLiteral>
</triple>

. . .

4 Sesame Project: < http://www.openrdf.org >
5 Sesame: open source framework for storage, inferencing and querying of RDF

data (www.openrdf.org)

The data set MK400 was created based on LUBM OWL data for
three Universities and we assigned each triple to a different graph

and the four meta knowledge properties are associated with it. This
way the knowledge base contains four times as many meta knowledge triples as knowledge triples. The resulting dataset consists of
1.7 million triples of which 0.35 million are original LUBM data and
1.4 million are additional metadata. Note that the overall sizes of the
two datasets are comparable. As indicated above the overall size of
the knowledge base influences the workload for query processing.
In fact, main memory consumption appeared to be a key factor. By
choosing similar sizes for the two datasets we reduce the influence
of factors related to the size of the knowledge base and concentrate
on how the different evaluations influence the processing time.

9.3. Random query sequence

We conducted two experiments with each of the two datasets.
One experiment aims at simulating behavior of a query engine in
a real life scenario: first a dataset is loaded and then a sequence of
queries is submitted to the query engine. We measured the average
processing time of these queries. The query sequence was created
based on 8 of the 14 queries from the LUBM benchmark. Query
2 was not included since we were not able to obtain results for
this query with this version of Sesame, this dataset and an average
machine. Five more queries are discarded since they require OWL
inferencing or hierarchy information to obtain complete results and
Sesame 2 was not able to obtain bindings using plain SPARQL pro-
cessing. Since no meta knowledge needs to be calculated if the
result set is empty using these queries would bias the evaluation in
favor of the meta knowledge processing. The authors of the benchmark identified three main characteristics of queries with respect to
plain SPARQL processing: input size, selectivity and complexity. The
remaining 8 queries still cover different settings for these features.
Experiments with single queries will be presented below.

The query sequence consisted of a random shuffle of 20 copies
of each of the remaining queries. For each query in the sequence we
measured the time which elapses during issuing the query, obtaining the result and traversing the result sequentially. This measure is
similar to the query response time defined in [11]. The only difference
is that in [11] each query is performed 10 times after the knowledge
base has been loaded to measure the caching performance of the
query engine. For each run we determined the average of the execution times of the queries in the sequence in question. The results
are summarized in Table 1.

Evaluation of provenance formulae (PF) given dataset MK29
almost tripled the average query execution time. On average, the
evaluation took about half a second longer than standard evaluation (SD). The evaluation of four meta knowledge properties (M4)
adds again half a second to the evaluation of provenance. The overall
overhead to obtain meta knowledge is about a second given a nontrivial dataset. We consider this to be an indication for the feasibility
of our approach. Since these numbers are average values the question remains whether reasonable processing times are achieved for
all individual queries as well. This will be analyzed below.

For the dataset MK400 the computations were faster for all three
kinds of evaluations. This can be explained by the fact that this
dataset contains a smaller number of knowledge triples and therefore the result sets for some of the queries contain fewer bindings as
we will see below. Surprisingly, evaluation of provenance formulas
needed less time than standard evaluation. A possible explanation

Table 1
Random query sequence experiments: average processing time
(ms).

MK29
MK400

M4

Table 2
Processing time of query evaluation with and without provenance and meta knowledge for individual queries and the MK29 dataset. Processing times are average
values of 10 runs each.

Query

Q1
Q4
# bindings

Q5

Q6

Q7

Q8

Q10

Q14

Av.

Processing time (ms)

M4

is optimization performed by the query processor of Sesame 2.
Since our implementation uses query rewriting different queries
are evaluated for the different kinds of evaluations. Optimization
techniques might be easier to apply to some of them. Why does
the evaluation of MK29 not show similar characteristics? Here a
possible explanation is the larger number of bindings involved in
the evaluation. Main memory consumption was quite large in both
cases. Possibly there was no space left for caching of (intermedi-
ary) results given dataset MK29. The calculation of the four meta
knowledge properties did result in an increase in processing time
as expected.

9.4. Single LUBM queries

We also measured processing times for single queries. As stated
above we measured the time which elapsed during issuing the
query, obtaining the result and traversing the result sequentially.
In contrast to the previous experiment and to the definition of the
query response time from [11] the application was restarted before
each single query execution. That way each query was evaluated
against a newly loaded knowledge base since we want to measure
the effort it takes to evaluate the queries and not the caching strategy of the query engine. This procedure was repeated 10 times for
each query and each method of query evaluation. The average values from these runs are summarized in Tables 2 and 3. The standard
deviations estimated from these 10 runs are less than or equal 10
percent for all queries and methods evaluated on the two datasets.
On average the calculation of provenance formulas (PF)
increases processing time by factor 1.5. In absolute numbers the
average increase is about 0.2 s. The largest increase (1.3 s for the
MK29 dataset) can be observed for query 14 which also gives the
largest result set. We attribute this to the main memory consumption of our implementation. For query 8 there even is a decrease
in processing time. As for the case of a random query sequence
evaluated on MK400 a possible explanation are optimizations of
the query processor. The additional querying for meta knowledge
might guide the optimization of the query execution.

Calculation of the four basic provenance properties (MD4)
causes an average increase of factor 4.1 (1.5 s) for the MK29 dataset

Table 3
Processing time of query evaluation with and without provenance and meta knowledge for individual queries and the MK400 dataset. Processing times are average
values of 10 runs each.

Query

Q1
Q4
# bindings

Q5

Q6

Q7

Q8

Q10

Q14

Av.

Processing time (ms)

M4

R. Dividino et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 204219

and factor 1.9 (0.3 s) for the MK400 dataset compared to standard
evaluation. We ascribe the larger increase for the runs based on
dataset MK29 to the larger number of results for queries 6 and 14
and the non-optimized memory consumption of our implementa-
tion. These results are in line with the results from the experiments
using a random query sequence shown in Table 1. For query 8
the processing time decreases for query evaluation including meta
knowledge as well which might be explained by query optimization
of the underlying triple store as stated above.

9.5. Discussion

At first we consider the experiments with individual queries.
From the estimated standard deviations of the 10 runs for each
query, kind of evaluation and dataset we conclude that the measurements are reliable enough to draw two general conclusions:
On the one hand we can observe a noticeable increase of processing
time using our implementation and on the other hand the amount
of this increase can be described by a small linear factor.

The results of the experiments using a random sequence of
queries indicate that similar results also hold for real world sce-
narios. Here caching can be applied by a query processor. A few
times evaluations of the same query which was repeated directly
one after another in the sequence. The resulting average processing
times are smaller but still comparable to the average values for the
evaluations of single queries. A key insight is that the overall processing times remain feasible for evaluations on a dataset of up to
1.8 million triples and results of up to 75,000 bindings.

If we compare the processing times obtained for the two
different datasets we might expect that for dataset MK400 processing times increase by a larger factor if meta knowledge is
involved. MK400 contains a larger number of meta knowledge
triples which need to be processed in order to evaluate meta
knowledgeespecially compared to the number of knowledge
triples. However, at least with our implementation, the dominant
characteristic of query evaluation appears to be the size of the result
set.

10. Related work

The importance of better understanding the ways by which the
result came about is fundamental to many Semantic Web applications and scenarios. The specification of the Semantic Web proof
layer was discussed in [13,18,12].

Meta knowledge has been initially studied as an extension for
relational databases (i.e. data management systems based on relational algebra), probabilistic databases [9], and later adopted for
RDF knowledge bases (i.e. for semantics of SPARQL query language).
In the area of database systems, meta knowledge is often represented using an extension of the relational data model, coined
annotated relations. Its purpose is primarily the description of data
origins (provenance) and the process by which it arrived as a query
answer [7,2,3,8]. Basically they define custom (possibly different)
interpretations for algebraic operations of Boolean formulas (built
on tuple identifiers as Boolean variables) for particular dimensions of meta knowledge (e.g. agent, timestamp, source, certainty)
to obtain the m-dimensional record (i.e. query result). Indeed, a
Boolean expression of the result set build from tuple identifiers
does not only carry the information which triples have contributed
to a variable assignment (why-provenance) but also how they contributed (how-provenance). Basically, our methodology follows the
same idea and adopts the notion of provenance semirings which
was introduced, as a generalization framework, in [10]. In contrast
to other approaches discussed in [10] (based on the notion of annotated tuples in a relational schema), our solution is customized
for RDF graphs (i.e. annotated RDF quadruples). The same holds

for the corresponding query language (basically, SPARQL vs. SQL)
and its semantics. An important conceptual difference to the relational model is the natural ability of RDF/SPARQL repositories for
result serialization and thus seamless exchanging and utilization of
knowledge and meta knowledge from our framework across multiple Semantic Web nodes without additional schema integration
efforts.

In the Semantic Web field, meta knowledge has been recently
considered in applications for assessing the trustworthiness of
information [4,8]. In particular, meta knowledge shows how statements are organized among agents on the Web. Our approach is
focused on an RDF language model and provides fine-grained meta
knowledge management for retrieval queries with SPARQL that is
not directly comparable with proof traces for OWL reasoning.

The use of Named Graphs for meta knowledge management and
querying RDF with meta knowledge constraints is introduced in
[4]. As discussed in Section 5.4, this functionality can be realized in
our framework in a straightforward manner by the means of nested
queries (or querying from views), which are expected features of
the upcoming SPARQL2 query language. Moreover, our framework
potentially allows to express filtering and/or ranking conditions on
meta knowledge of query results and thus is more expressive and
flexibe than the solution presented in [4].

11. Conclusion and future work

In this paper, we presented an original, generic, formalized and
implemented approach for the management of many dimensions of
meta knowledge, like source, authorship, certainty, and others, for
RDF repositories. Our method re-uses existing RDF modeling possibilities in order to represent meta knowledge. Then, it extends
SPARQL query processing in such a way that given a SPARQL query
for data, one may request meta knowledge without modifying the
query proper. We achieve highly flexible and automatically coordinated querying for data and meta knowledge, while completely
separating the two areas of concern. Our approach remains compatible to existing standards and query languages and can be easily
integrated with existing applications and interfaces.

In the future, we will investigate the meta knowledge support
for OWL-based knowledge bases with advanced reasoning capa-
bilities. Due to the substantially higher complexity of inferencing
and retrieval algorithms (e.g. reasoning in OWL-DL vs. RDF querying with SPARQL) and the distributed nature of knowledge sources
in the Semantic Web, the notion of meta knowledge will require
further, non-trivial justification.

Our long-term objective is the generic, efficient and effective
infrastructure for meta knowledge management as an integral part
of the proof layer of the Semantic Web.

Acknowledgements

This work was supported by the X-Media project (www.x-
media-project.org) funded by the European Commission under
EC grant number IST-FP6-026978 and by the project WeKnowIt
(www.weknowit.eu) funded by the European Commission under
EC grant number FP7-215453.

Appendix A. SPARQL semantics

SPARQL is a query language for RDF based on graph pattern
matching, which is defined in [20]. Query results in SPARQL are
given by partial substitutions (mapping) of the query variables by
RDF terms. The following definitions describe existing foundations
of SPARQL introduced in [15,17].

Definition Appendix A.1 (Triple and basic graph patterns). A tuple
t in (U  L  V)  (U  V)  (U  L  V) is a triple pattern. A Basic
Graph Pattern is a finite set of triple patterns. Given a triple pattern t, var(t) is a set of variables occurring in t. Similarly, given a
basic graph pattern P, var(P) =
t  Pvar(t), i.e. var(P) is the set of
variables occurring in P.
Definition Appendix A.2 (Mapping). A mapping  from V to U  L
is a partial function  : V  U  L. The domain of , dom(), is a
subset of V where  is defined. The empty mapping  is a mapping
such that dom() =  (i.e.  = ). Two mappings 1 and 2 are
compatible when for all x  dom(1)  dom(2), it is the case that
1(x) = 2(x), then 1  2 is also a mapping.

Let 1 and 2 be set of mappings; join, union, the difference,

and left outer-join between 1 and 2 are defined as:
 1	2 = {1  2|1  1, 2  2 are compatible mappings},
 1  2 = {| 1or 2},
 1 \ 2 = { 1|for all
 1 = 	2 = (1	2)  (1 \ 2).

are not compatible},

  2, and

Definition Appendix A.3 (Basic graph pattern and mappings).
Given a basic graph pattern P and a mapping  such that var(P) 
dom(), we have that (P) =
{(t)}, i.e. (P) is the set of
triples obtained by replacing the variables in the triples of P according to .

t  P

Definition Appendix A.4 (Basic graph pattern matching). Let G be
an RDF graph over a RDF dataset D, and P a basic graph pattern.
The evaluation of P over G, denoted by [[P]]D
G is defined as the set of
mappings:
[[P]]D

= { : V  U  L|dom() = var(P)and(P)  G}
G, we say that  is a solution for P in G.

If  [[P]]D

Definition Appendix A.5 (Complex graph pattern matching). Let G
be an RDF graph over a RDF dataset D, and P, P1 and P2 basic graph
patterns. The evaluation of P, P1, and P2 over G is defined recursively
as follow:
 [[P]]D
 [[P1 AND P2]]D
 [[P1 OPT P2]]D
 [[P1 UNION P2]]D
 [[P1 FILTER C]]D
 [[u GRAPH P]]D
 [[?X GRAPH P]]D

G is given by Definition A.4,
= [[P1]]D
	[[P2]]D
G,
= [[P1]]D
= 	[[P2]]D
G,
= [[P1]]D
 [[P2]]D
G,
= c([[P1]]D
G),
= [[P]]D

gr(u)D
v names(D)([[P]]D

= 	?Xv)

gr(u)D

Finally, [15] defines the notion of equivalence for graph patterns.

Definition Appendix A.6 (Equivalence of graph patterns). Two
graph pattern expressions P1 and P2 are equivalent, denoted by

P1  P2, if [[P1]]D
D.

= [[P2]]D

G for every graph G and RDF dataset

Let P1, P2 and P3 be graph pattern

Proposition Appendix A.1.
expressions and R a built-in condition then:
 AND and UNION are associative and commutative.
 (P1 AND (P2 UNION P3))  ((P1 AND P2) UNION (P1 AND P3))
 (P1 OPT (P2 UNION P3))  ((P1 OPT P2) UNION (P1 OPT P3)).
 ((P1 UNION P2) OPT P3)  ((P1 OPT P3) UNION (P2 OPT P3)).
 ((P1 UNION P2) FILTER R)  ((P1 FILTER R) UNION (P2 FILTER R)).
