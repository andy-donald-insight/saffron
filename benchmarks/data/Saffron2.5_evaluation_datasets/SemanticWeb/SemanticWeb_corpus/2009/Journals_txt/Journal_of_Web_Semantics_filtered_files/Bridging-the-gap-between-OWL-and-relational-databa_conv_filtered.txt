Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 7489

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

Bridging the gap between OWL and relational databases
Boris Motik a,, Ian Horrocks a, Ulrike Sattler b

a Computing Laboratory, University of Oxford, Wolfson Building, Parks Road, Oxford OX1 3QD, UK
b Department of Computer Science, University of Manchester, UK

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 13 September 2007
Received in revised form 20 February 2009
Accepted 22 February 2009
Available online 6 March 2009

Keywords:
Integrity constraints
Relational databases

Semantic Web

1. Introduction

Despite similarities between the Web Ontology Language (OWL) and schema languages traditionally used
in relational databases, systems based on these languages exhibit quite different behavior in practice. The
schema statements in relational databases are usually interpreted as integrity constraints and are used
to check whether the data is structured according to the schema. OWL allows for axioms that resemble
integrity constraints; however, these axioms are interpreted under the standard first-order semantics
and not as checks. This often leads to confusion and is inappropriate in certain data-centric applications.
To explain the source of this confusion, in this paper we compare OWL and relational databases w.r.t.
their schema languages and basic computational problems. Based on this comparison, we extend OWL
with integrity constraints that capture the intuition behind similar statements in relational databases.
We show that, if the integrity constraints are satisfied, they need not be considered while answering a
broad range of positive queries. Finally, we discuss several algorithms for checking integrity constraint
satisfaction, each of which is suitable to different types of OWL knowledge bases.

 2009 Elsevier B.V. All rights reserved.

The Web Ontology Language (OWL) is a W3C standard for modeling ontologies in the Semantic Web. The logical underpinning of
OWL is provided by description logics (DLs) [2]. OWL can be seen as
an expressive schema language; however, its axioms have a different meaning from similar statements in relational databases.
Ontology designers sometimes intend OWL axioms to be read as
integrity constraints (ICs)checks that verify whether the information explicitly present in the ontology satisfies certain conditions.
The formal semantics of OWL, however, does not interpret these
axioms as integrity constraints, so the consequences that one can
draw from such ontologies differ from the ones that the users intuitively expect.

To understand the nature of the problem, consider an application for managing tax returns in which each person is required to
have a social security number. In a relational database, this would
be captured by an inclusion dependency stating that a social security number exists for each person. During database updates, such a
dependency is interpreted as a check: whenever a person is added
to the database, a check is performed to see whether that persons
social security number has been specified as well; if not, the update

 This is an extended version of the paper with the same name published at WWW
2007 [31].
 Corresponding author. Tel.: +44 1865 283544.
E-mail address: boris.motik@comlab.ox.ac.uk (B. Motik).

1570-8268/$  see front matter  2009 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2009.02.001

is rejected. An apparently similar dependency can be expressed in
OWL using an existential restriction, but this will result in quite a
different behavior: adding a person without a social security number to an OWL knowledge base does not raise an error, but only leads
to the inference that the person in question has some (unknown)
social security number. OWL is thus closely related to incomplete
databases [43]databases whose data is specified only partially.1
OWL axioms, just like dependencies in incomplete databases, do
not check the integrity of the database data; instead, they show
how to extend the database with missing information.

In fact, it is not possible to formalize database-like integrity constraints in OWL, which has caused problems in practice. Axioms
such as domain and range constraints look like ICs, so users often
expect them to behave accordingly, which often leads to problems.
On the one hand, such axioms do not check whether the data has
been input correctly and, on the other hand, they cause considerable
performance overhead during reasoning. These problems could be
addressed if OWL were extended with true database-like integrity
constraints.

There is a long research tradition in extending logic-based
knowledge representation formalisms with database-like integrity
constraints. In his seminal paper, Reiter observed that integrity constraints are not objective sentences about the world; rather, they

1 Dependencies in incomplete databases are often called constraints in the litera-
ture. To avoid confusion, in this paper we reserve the term integrity constraint for
axioms that behave as database-style checks.

describe the allowed states of the database, and are therefore of an
epistemic nature [38]. Hence, most extensions of DLs with integrity
constraints are based on autoepistemic extensions of DLs, such
as the description logics of minimal knowledge and negation-as-
failure [16] or various nonmonotonic rule extensions of DLs [39,32].
While these approaches do solve the outlined problem to a certain
extent, such a solution is not in the spirit of relational databases. As
we discuss in more detail in Section 8, integrity constraints in these
approaches do not affect TBox reasoning at all, and they are applied
only to ABox individuals. Such constraints are thus very weak, as
they do not say anything about the structure of the world; they
only constrain the structure of ABoxes.

In relational databases, however, integrity constraints have a
dual role: on the one hand, they describe all possible worlds, and, on
the other hand, they describe the allowed states of the database [1].
Integrity constraints are used in data reasoning tasks, such as checking the integrity of database data, as well as in schema reasoning
tasks, such as computing query subsumption. The semantic relationship between these two roles of integrity constraints is much
clearer than in autoepistemic ICs, which simplifies modeling.

In order to make schema modeling in OWL more natural for
data-centric applications, in this paper we study the relationship
between OWL and databases. Based on our analysis, we propose
an extension of OWL that mimics the behavior of integrity constraints in relational databases, while keeping the main benefits
of OWL such as the capability to model hierarchical domains. The
contributions of this paper are as follows.

 In Section 2, we compare OWL and relational databases w.r.t. their
schema languages, main reasoning problems, and approaches to
modeling integrity constraints. Furthermore, we discuss in detail
the relationship between OWL and incomplete databases.
 To allow users to control the degree of incompleteness in OWL, in
Section 3 we introduce extended DL knowledge bases. The schema
part of such knowledge bases is separated into the standard TBox
that contains axioms which are interpreted as usual, and the
integrity constraint TBox that contains axioms which are interpreted as checks. We also define an appropriate notion of IC
satisfaction based on the notion of minimal models.
 In Section 4, we show that our ICs indeed behave similarly to
ICs in relational databases: if the ICs are satisfied in an extended
DL knowledge base, they need not be considered while answering a broad class of positive ABox queries. This result promises
a significant performance improvement of query answering in
practice, as it allows us to consider a subset of the TBox during
query answering.
 In Section 5, we show how to incorporate the modeling of ICs
into the general ontology modeling process, and we also discuss
the types of axiom that are likely to be designated as integrity
constraints.
 In Section 6, we present an alternative characterization of IC satisfaction by embedding the problem into logic programming. This
provides us with additional intuition behind the notion of IC sat-
isfaction, and it also lays the foundation for a practical decision
procedure.
 In Section 7, we present several algorithms for checking IC
satisfaction in different types of knowledge bases. For knowledge bases without positively occurring existential quantifiers,
IC satisfaction can be checked using existing logic programming
machinery. For knowledge bases with existential quantifiers, we
embed the IC satisfaction problem into the monadic secondorder logic on infinite k-ary trees SkS [36]. We do not expect this
procedure to be practical; rather, it merely shows us that IC satisfaction is decidable, and that a more practical procedure might
exist.

 In Section 8, we discuss how our approach relates to the existing
approaches for modeling integrity constraints.

We assume the reader to be familiar with the basics of OWL and
DLs; please refer to [2] for an introduction. It is well-known that the
OWL DL variant of OWL corresponds to the DL SHOIN(D). Because
of that, we refer to OWL and DLs interchangeably throughout this
paper.

2. OWL vs. relational databases

An obvious distinction between OWL/DLs and relational
databases is that the former use open-world semantics, whereas the
latter use closed-word semantics. We argue that the two semantics actually complement each other and that the choice of the
semantics should depend on the inference problem.

2.1. Schema language

The schema part of a DL knowledge base is typically called a
TBox (terminology box), and is a finite set of (possibly restricted)
universally quantified implications. For example, a TBox can state
that each person has a social security number (SSN), that a person
can have at most one SSN, and that each SSN can be assigned to
at most one individual. These statements are expressed using the
following TBox axioms:
Person  hasSSN.SSN
Person  1 hasSSN

SSN  1 hasSSN

(2)

(1)

(3)

Most DLs can be seen as decidable fragments of first-order logic
[8], so axioms (1)(3) can be translated into the following first-order
formulae:
x : [Person(x)  y : hasSSN(x, y)  SSN(y)]
x, y1, y2 : [Person(x)  hasSSN(x, y1)  hasSSN(x, y2) 

(4)

y1  y2]

(5)

(6)

x, y1, y2 : [SSN(x)  hasSSN(y1, x)  hasSSN(y2, x)  y1  y2]

The schema of a relational database is defined in terms of relations and dependencies. Many types of dependencies have been
considered in the literature, such as functional, inclusion, and join
dependencies. As discussed in [1], most dependencies can be represented as first-order formulae of the form (7), where   and  are
conjunctions of function-free atoms:
x1, . . . , xn : [ (x1, . . . , xn) 

y1, . . . , ym : (x1, . . . , xn, y1, . . . , ym)]

(7)

Although the expressivity of DLs underlying OWL and of relational dependencies is clearly different, the schema languages of
the two are quite closely related. In fact, formula (4) has the form
of an inclusion dependency, whereas (5) and (6) correspond to key
dependencies.

2.2. Interpreting the schema

DL TBoxes and relational schemata are interpreted according to
the standard first-order semantics: they distinguish the legal from
the illegal relational structuresthat is, the structures that satisfy
all axioms from the structures that violate some axiom. In DLs, the
legal structures are called models, whereas in relational databases

B. Motik et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 7489

they are called database instances, but the underlying principle is
the same.

There is a slight technical difference between models and
database instances: models can be infinite, whereas database
instances are typically required to be finite since only finite
databases can be stored in practical systems. For many classes of
dependencies, whenever an infinite relational structure satisfying
the schema exists, a finite structure exists as well (this is known as
the finite model property), so the restriction to finite structures is
not really relevant. Languages such as OWL do not have the finite
model property: ontologies exists that are satisfied only in infinite
models [2]. Even though the complexity of finite model reasoning is, for numerous DLs, the same as the complexity of reasoning
w.r.t. arbitrary models, the former is usually more involved [30,35].
Hence, in the rest of this paper, we drop the restriction to finite
database instances and consider models and database instances to
be synonymous.

2.3. Domains and typing

Relational databases assign domain types to columns of rela-
tions; for example, the second position in the hasSSN relation could
be restricted to strings of a certain form. Typing is used in practice to
determine the physical layout of the database. In contrast, typing
is often not considered in theory (e.g., in algorithms for checking
query containment); rather, all columns are assumed to draw their
values from a common countable domain set [1].

In DLs underlying OWL, datatypesa simplified variant of c

oncrete domains [3]can be used to specify types of data.

In this paper, we consider neither typed relational schemata nor
DL knowledge bases with datatypes, and we interpret both in standard first-order logic. This simplifies both formalisms significantly.
For example, keys can be straightforwardly added to untyped DLs
[11], while adding keys to DLs with datatypes is much more involved
[29].

2.4. Schema reasoning

Checking subsumption relationships between concepts has
always been a central reasoning problem for DLs. A concept C is
subsumed by a concept D w.r.t. a DL TBox T if the extension of C
is included in the extension of D in each model I of T. This inference has many uses; for example, in ontology modeling, derived
subsumption relationships can be used to detect modeling errors.
Concept subsumption has been used to optimize query answering
[19], especially when generalized to subsumption of conjunctive
queries [12,18]. Another important TBox inference is checking concept satisfiabilitythat is, determining whether a model of T exists
in which a given concept has a nonempty extension. Concepts are
unsatisfiable mainly due to modeling errors, so this inference can
also be used to detect ontology modeling errors.

Reasoning about the schema is certainly not the most prominent
feature of relational databases, yet a significant amount of research
has been devoted to it. The most important schema-related inference in databases is checking query containment [1]: a query Q1 is
contained in a query Q2 w.r.t. a schema T if the answer to Q1 is contained in the answer to Q2 for each database instance that satisfies
T. This inference is used by database systems to rewrite queries into
equivalent ones that can be answered more efficiently. Another useful schema reasoning problem is dependency minimizationthat is,
computing a minimal schema that is equivalent to the given one.

In both DLs and relational databases, schema reasoning problems correspond to checking whether some formula  holds in
every model (i.e., database instance) of Tthat is, checking whether
T  . In other words, the schema reasoning problems in both DLs
and relational databases correspond to entailment in a first-order

theory. Since the problems are the same, it should not come as a
surprise that the methods used to solve them are closely related:
reasoning in DLs is typically performed by tableau algorithms [4],
and the state-of-the-art reasoning technique in relational databases
is chase [1]. Apart from notational differences, the principles underlying these two techniques are the same: they both try to construct
a model that satisfies the schema T but not the formula .

To summarize, DLs and databases treat schema reasoning problems in the same way. Thus, DLs can be understood as expressive
but decidable (database) schema languages.

2.5. Query answering

Apart from the schema (or TBox) part, a DL knowledge base
K typically also has a data (or ABox) part. The main inference for
ABoxes is instance checkingthat is, checking whether an individual a is contained in the extension of a concept C in every model of
K, commonly written as K  C(a). Instance checking can be generalized to answering conjunctive queries over DL knowledge bases
[12,18], so a DL query can be viewed as a first-order formula  with
free variables x1, . . . , xn. Just like schema reasoning, the semantics
of query answering in DLs is defined as first-order entailment, so it
takes into account all models of K: a tuple a1, . . . , an is an answer
to  over K if K  [a1/x1, . . . , an/xn], where the latter formula is
obtained from  by replacing all free occurrences of xi with ai.

Queries in relational databases are first-order

formulae
(restricted in a way to make them domain independent) [1], so
they are similar to queries in DLs. A significant difference between
DLs and relational databases is, however, the way in which queries
are evaluated. Let  be a first-order formula with free variables
x1, . . . , xn. A tuple a1, . . . , an is an answer to  over a database
instance I if I  [a1/x1, . . . , an/xn]. Hence, unlike in DLs, query
answering in relational databases does not consider all databases
instances that satisfy the knowledge base K; instead, it considers only the given instance I. In other words, query answering in
relational databases is not defined as entailment, but as model
checking, where the model is the given database instance.

Although the definition of query answering in relational
databases from the previous paragraph is the most widely used one,
a significant amount of research has also been devoted to answering queries over incomplete databases [25,21,43]a problem that is
particularly interesting in information integration. An incomplete
database DB is described by a set R of incomplete extensions of
the schema relations and a set S of dependencies specifying how
the incomplete extensions relate to the actual database instance.
Queries in incomplete databases are also (possibly restricted) firstorder formulae. In contrast to complete databases, a tuple a1, . . . , an
is a certain answer to  over DB if I  [a1/x1, . . . , an/xn] for each
database instance I that satisfies R and S. In other words, query
answering in incomplete databases is defined as first-order entailment just like in DLs, where the relation extensions correspond to
the DL ABox and the schema corresponds to the DL TBox. Hence,
from the standpoint of query answering, DLs can be understood as
incomplete databases.

2.6. Checking satisfaction of integrity constraints

Integrity constraints play a central role in relational databases,
where they are used to ensure data integrity. We explain the
intuition behind ICs by means of an example. Let T be a relational schema containing the statement (4), and let I be a database
instance containing only the following fact:

Person(Peter)

(8)

To check whether all data has been specified correctly, we can now
ask whether the ICs in T are satisfied for I; that is, whether I  T. In

our example, this is not the case: integrity constraint (4) says that
each database instance must contain an SSN for each person. Since
I does not contain the SSN of Peter, the ICs in T are not satisfied.2
The database instance is fully specified by the facts available in the
database; hence, all data is assumed to be complete. Thus, IC satisfaction checking in relational databases is based on model checking.
In DLs, we can check whether an ABox A is consistent with a
TBox Tthat is, whether a model I of both A and T existsand thus
detect possible contradictions in A and T. This inference, however,
does not provide us with a suitable basis for IC satisfaction checking.
For example, let T and A contain axiom (1) and fact (8), respec-
tively. The knowledge base A  T is satisfiable: axiom (1) is not
interpreted as a check, but it implies that Peter has some (unknown)
SSN. This clearly does not match with our intuition behind integrity
constraints. First-order satisfiability checking verifies whether the
facts in A can be extended to a relational structure that is compatible with the schema T, thus assuming that our knowledge about
the world is incomplete. To the best of our knowledge, no description logic currently provides an inference that matches with the
intuition behind database-like integrity constraints.

2.7. Discussion

Integrity constraints are mostly useful

From the standpoint of conceptual modeling, DLs provide a very
expressive, but still decidable language that has proven to be implementable in practice. The open-world semantics is natural for a
schema language since a schema determines the legal database
instances. In fact, when computing the subsumption relationship
between concepts or queries, we do not have a fixed instance. There-
fore, we cannot interpret the schema in either OWL or relational
databases under the closed-world assumption; rather, we must
employ the open-world semantics in order to consider all instances.
in data-centric
applicationsthat is, applications that focus on the management of large volumes of data. In practice, relational databases are
typically complete: any missing information is either encoded metalogically (e.g., users often include fields such as hasSpecifiedSSN
to signal that particular data has been supplied in the database),
or it is represented by null-values (that can be given first-order
interpretation [21]). In contrast, ABoxes in DLs are closely related
to incomplete (relational) databases. Clearly, problems may arise if
certain aspects of the information about individuals in ABoxes are
expected to be complete. To understand the problems that occur in
such cases, consider the following example taken from the Biopax3
ontology used for data exchange between biological databases.
This ontology defines the domain of the property NAME to be the
union of bioSource, entity, and dataSource:
NAME.  bioSource  entity  dataSource
The intention behind this axiom is to define which objects can be
namedthat is, to ensure that a name is attached only to objects
of the appropriate type. The actual data in the Biopax ontology is
complete w.r.t. this integrity constraint: each object with a name is
also typed (sometimes indirectly through the class hierarchy) to at
least one of the required classes. Axiom (9) is, however, not interpreted as an integrity constraint in OWL; rather, this axiom says
that, if some object has a name, then it can be inferred to be either
a bioSource, an entity, or a dataSource. Therefore, axiom (9) cannot
be used to check whether all data is correctly typed. Furthermore,
since axiom (9) contains a disjunction in the consequent, an OWL
reasoner processing the Biopax ontology must use reasoning-by-

(9)

2 In practice, ICs are incrementally checked after database updates; these dynamic

aspects are, however, not important for this discussion.

3 http://www.biopax.org/.

case, which is one of the reasons why DL reasoning is intractable
([2], Chapter 3). Hence, axiom (9) causes two types of problems: on
the one hand, it does not exhibit the intended behavior and, on the
other hand, it introduces a performance penalty during reasoning.
Representing incomplete information is, however, needed in
many applications. Consider the following axiom stating that married people are eligible for a tax cut:
marriedTo.  TaxCut
To draw an inference using this axiom, we do not necessarily need to
know the name of the spouse; we only need to know that a spouse
exists. Thus, we may state the following fact:
(marriedTo.Woman)(Peter)
We are now able to derive that Peter is eligible for a tax cut even
without knowing the name of his spouse. Providing complete information can be understood as filling in a Spouse name box on a tax
return, whereas providing incomplete information can be understood as just ticking the Married box. The existential quantifier
can be understood as a well-behaved version of null-values that
explicitly specifies the semantics of data incompleteness [21]. Thus,
DLs provide a sound and well-understood foundation for use cases
that require reasoning with incomplete information.

(10)

(11)

We would ideally be able to explicitly control the amount of
incompleteness in an ontology. Such a mechanism should allow
us to explicitly state which data must be fully specified and which
can be left incomplete. This goal can be achieved through an appropriate form of integrity constraints that check whether all data has
been specified as required. Transforming inappropriate and/or erroneously introduced axioms into integrity constraints should also
speed up query answering by eliminating unintended and potentially complex inferences.

3. Integrity constraints for OWL

In this section, we extend DL knowledge bases with ICs in order
to overcome the problems discussed in the previous section. Since
TBoxes are first-order formulae, it is straightforward to apply the
model checking approach described in Section 2 to DLs. In such an
approach, an ABox would be interpreted as a single model and the
TBox axioms as formulae that must be satisfied in a model, and the
ICs would be satisfied if A  T. Such an approach is, however, not
satisfactory as it requires an all-or-nothing choice: the ABox is
then considered to be a complete model, and TBox axioms can only
be used as checks and not to imply new facts.

To obtain a more versatile formalism, we propose a combination of inferencing and model checking. The following example
demonstrates the desirable behavior of our approach. Let A1 be
the following ABox:

Student(Peter)

hasSSN(Peter, nr12345)

SSN(nr12345)

(12)

(13)

(14)

(15)

Student(Paul)
Furthermore, let T1 be the following TBox:
Student  Person
Person  hasSSN.SSN
Let us now assume that we choose (17) to be an integrity constraint,
but (16) to be a normal axiom. Since (16) is a normal axiom, we
should derive Person(Peter) and Person(Paul). Axiom (17) is an IC,
so it should be applied as a check. Hence, we expect the IC to be

(16)

(17)

B. Motik et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 7489

satisfied for Peter since an SSN for Peter has been specified; fur-
thermore, no SSN has been specified for Paul, so we expect IC (17)
to be violated for Paul.

Following this intuition, we define extended DL knowledge
bases to distinguish the axioms that imply new facts (i.e., the axioms
that act as deductive rules) from the integrity constraints (i.e.,
the axioms that act as checks). It is important to understand that,
whether an axiom is to be treated as an IC or not, depends mainly
on the requirements and the assumptions of the application and
is often not inherent in a particular axiom. In fact, given the same
ontology, different applications might choose to interpret different
subsets of the ontologys axioms as ICs. Thus, it might be beneficial to keep the information about which axioms are treated as ICs
independently from the core ontology, thus allowing applications
to create application-specific views of the ontology. A discussion
of such a mechanism, however, is out of scope of this paper; here,
we focus on the semantic and computational aspects of integrity
constraints.

The following definition is applicable to any DL, so we do not
formally introduce here a particular description logic; please refer
to related literature [2] for a formal definition of the DLs used in
the Semantic Web. Furthermore, our definition allows ABoxes to
contain only possibly negated atomic concepts. This does not result
in any loss of generality because S can be used to introduce names
for nonatomic concepts.

An extended DL knowledge base is a triple

Definition 1.
K = (S,C,A) such that
 S is a finite set of standard TBox axioms,
 C is a finite set of integrity constraint TBox axioms, and
 A is a finite set of ABox facts ()A(a), R(a, b), a  b, or a / b, for A
an atomic concept, R a role, and a and b individuals.

In the rest of this section, we explore the possible notions of IC
satisfaction. Several variants have already been considered in the
literature.
In the consistency approach for open databases [24], ICs are satisfied if A  S is consistent with Cthat is, if A  S  C is satisfiable.
Reiter, however, has already observed that such a treatment of ICs
is too weak [38]: C is then treated as a standard first-order theory,
so, as explained in Section 2.6, ICs do not behave as checks.
In the entailment approach for open databases [37], ICs are satisfied if they are true in each model of A  Sthat is, if A  S  C.
The following example, similar to the one by Reiter [38], shows
that this does not satisfy our intuition. Let A2 contain only fact (12),
let S2 = , and let C2 contain only axiom (17). The interpretation
I = {Student(Peter), Person(Peter)} is a model of A2  S2 that does
not satisfy C2, which would make C2 not satisfied for A2  S2. Intu-
itively, though, the fact Person(Peter) is not implied by A2  S2, so
we should not check whether Peter has an SSN at all. We want C2
to hold only for the facts that are implied by A2  S2.

Consistency and entailment approaches were applied to closed
databases (see [40,33] for consistency and [27] for entailment),
where ICs are satisfied if the Clarks completion [14] of A  S is
consistent with (resp. it entails) S. Such approaches, however, are
applicable only to Prolog-like databases for which Clarks completion is definedthat is, they are not applicable to databases
containing disjunction or existential quantification [38]and are
therefore not applicable to most description logics.

The example from the discussion of the entailment approach in
open databases suggests yet another definition of IC satisfaction:
C should hold for all first-order consequences of A  S. On A2, C2,
and S2 this produces the desired behavior: Person(Peter) is not a
consequence of A2  S2, so the integrity constraint from C2 should
not be checked for Peter. Consider, however, the ABox A3 containing

only the following fact:

(18)

(19)

(22)

(20)

(21)

 over I such that I

Cat(ShereKahn)
Furthermore, let S3 contain the following axiom:
Cat  Tiger  Leopard
Finally, let C3 contain the following two integrity constraints:
Tiger  Carnivore
Leopard  Carnivore
Neither Tiger(ShereKahn) nor Leopard(ShereKahn) is a first-order
consequence of A3  S3, which means that the ICs in C3 are sat-
isfied; furthermore, A3  S3 / Carnivore(ShereKahn). This does not
satisfy our intuition: in each model of A3  S3, either the fact
Tiger(ShereKahn) or the fact Leopard(ShereKahn) is true, but the fact
Carnivore(ShereKahn) is not necessarily true in either case. Hence,
by treating (20)(21) as integrity constraints and not as standard
axioms, we neither get an IC violation nor derive the consequence
Carnivore(ShereKahn).
Intuitively, integrity constraints should check whether the facts
derivable from A  S  C are also derivable using A  S only. This
notion seems to be nicely captured by minimal models; hence, we
check C only w.r.t. the minimal models of A  S. Roughly speaking, a
model I with an interpretation domain I of a formula  is minimal
  I is not a model of ,
if each interpretation I
where we consider an interpretation to be equivalent to the set of
positive ground facts that are true in the interpretation. Consider
again A2, S2, and C2. The fact Person(Peter) is not derivable from
A2  S2 in any minimal model (in fact, there is only a single minimal model), so integrity constraint (17) is not violated. In contrast,
A3  S3 has exactly two minimal models:
I1 = {Cat(ShereKahn), Tiger(ShereKahn)}
I2 = {Cat(ShereKahn), Leopard(ShereKahn)}
These two models can be viewed as the minimal sets of derivable
consequences. The integrity constraint TBox C3 is not satisfied in
all minimal models (in fact, it is violated in each of them); thus, as
intuitively desired, the ICs are not satisfied. In contrast, let A4 = A3
and C4 = C3, and let S4 contain the following axiom:
Cat  (Tiger  Carnivore)  (Leopard  Carnivore)
The fact Carnivore(ShereKahn) is derivable whenever we can derive
either Tiger(ShereKahn) or Leopard(ShereKahn), so the ICs should be
satisfied. Indeed, A4  S4 has the following two minimal models:
1 = I1  {Carnivore(ShereKahn)}

2 = I2  {Carnivore(ShereKahn)}

2 satisfyC4, which matches our intuition. Also, observe
Both I
that A4  S4  Carnivore(ShereKahn); hence, we derive exactly the
same consequences, even though we treat (20)(21) as ICs.

1 and I

Minimal models have been used, with minor differences, in an
extension of DLs with circumscription [7] and in the semantics
of open answer set programs [20]. These well-known definitions,
however, seem inappropriate for the definition of IC satisfaction.
Consider the following ABox A5:
Woman(Alice)

(23)

Man(Bob)
(24)
Furthermore, let S5 =  and let C5 contain the following integrity
constraint:
Woman  Man 
No axiom implies that Alice and Bob are the same, so we expect
them to be different by default, thus making integrity constraint

(25)

(25) satisfied. The definitions from [7,20], however, consider all
interpretation domains, so let I = { }. Because I contains only
one object, we must interpret both Alice and Bob as  . Clearly,
I = {Woman( ), Man( )} is a minimal model of A5, and it does not
satisfy C5.

This problem might be remedied by making the unique name
assumption (UNA)that is, by requiring each constant to be interpreted as a different individual. This, however, is rather restrictive
and is not compatible with OWL, which does not employ the UNA.
Another solution is to interpret A  S in a Herbrand model (i.e.,
a model in which each constant is interpreted by itself) where 
is a congruence relation; then, we minimize the interpretation of
 together with all the other predicates. In such a case, the only
 = {Woman(Alice), Man(Bob)} since the
minimal model of A5 is I
extension of  is empty due to minimization, so C5 is satisfied in I

Unfortunately, existential quantifiers pose a whole range of
problems for integrity constraints. Let A6 contain these axioms:
HasChild(Peter)

(26)

HasHappyChild(Peter)

(27)

(29)

(28)

TwoChildren(Peter)
Furthermore, let S6 contain these axioms:
HasChild  hasChild.Child
HasHappyChild  hasChild.(Child  Happy)
Finally, let C6 contain the following integrity constraint:
TwoChildren  2hasChild.Child
(31)
IC (31) is satisfied inA  S6, which might be considered intuitive: no
axiom in S6 forces the children of Peterthe two individuals whose
existence is implied by (29) and (30)to be the same, so we might
conclude that they are different.
Now consider the following quite similar example. Let C7 = C6,
and let A7 contain the following axioms:
HasChild(Peter)

(32)

(30)

(33)

TwoChildren(Peter)
Furthermore, let S7 contain the following axiom:
HasChild  hasChild.Child  hasChild.Child
(34)
If we follow the intuition from the previous example, thenC7 should
be satisfied in A7  S7: no axiom in S7 makes the two individuals
introduced by axiom (34) the same, so we can assume that these
individuals are different. In contrast, let S 
7 be a standard TBox containing only the following axiom:
HasChild  hasChild.Child
Now C7 should not be satisfied in A  S 
7 since (35) implies the
existence of only one child. Given that S 
7 is equivalent to S7 in
first-order logic (i.e., S 
7 and S7 have the same models), this is rather
unsatisfactory; furthermore, it suggests that C7 should not be satisfied in A7  S7, since (34) can be satisfied in models containing only
one child. Recall, however, that S6 and S7 are quite closely related:
the effect of (34) with respect to Child is the same as that of (29) and
(30). Hence, if (34) should introduce only one individual, then (29)
and (30) should do so as well, which is in conflict with our intuition
that C6 should be satisfied in A6  S6.

(35)

Thus, our intuition does not give us a clear answer as to the
appropriate treatment of existential quantifiers in the standard
TBox: the names of the concepts and the structure of the axioms
suggest that the existential quantifiers in (29) and (30) should introduce different individuals, whereas the existential quantifiers in
(34) should reuse the same individual. These two readings pull in

opposite directions, so a choice between the two should be based
on other criteria.

The example involvingS7 andS 

7 reveals an important disadvantage of the first reading: if we require each existential quantifier to
introduce a distinct individual, then it is possible for an IC TBox C
to be satisfied in A  S, but not in A  S , even though S and S  are
semantically equivalent. As we have seen, C7 is satisfied in A7  S7,
but not inA7  S 
7 are equivalent. It is clearly
undesirable for IC satisfaction to depend on the syntactic structure
of the standard TBox.

7, even thoughS7 andS 

The introduction of distinct individuals for each existential quantifier can be justified, however, by Skolemization [34],
the well-known process of representing existential quantifiers
with new function symbols. For example, the Skolemization
of the formula  = y : [R(x, y)  C(y)] produces the formula
sk() = R(x, f (x))  C(f (x)): the variable y is replaced by a term
f (x) with f a fresh function symbol. Skolemized formulae are usually interpreted in Herbrand models, whose domain consists of all
ground terms built from constants and function symbols in the
formula. If a formula contains at least one function symbol, then
its Herbrand models are infinite; furthermore, the models of DL
axioms are forest-like (i.e., they can be viewed as trees possibly
interconnected at roots). We use these properties in our procedure
for checking IC satisfaction that we present in Section 7.

Definition 2. Let  be a first-order formula and sk() the formula
obtained by outer Skolemization of  [34]. A Herbrand interpretation w.r.t.  is a Herbrand interpretation defined over the signature
of sk(). A Herbrand interpretation I w.r.t.  is a model of , written
I  , if it satisfies  in the usual sense. A Herbrand model I of 
 w.r.t.  such
is minimal if I
  I. We write sk() MM   if I    for each minimal Herbrand
that I
model I of .

 /  for each Herbrand interpretation I

We now define the notion of IC satisfaction, which is based on
a translation into first-order logic. For a set of DL axioms S, with
(S) we denote the first-order formula with equality and counting
quantifiers that is equivalent to S. Such translations are well known
for most DLs [2,8].

Let K = (S,C,A) be an extended DL knowledge
Definition 3.
base. The integrity constraint TBox C is s atisfied in K if sk((A 
S)) MM (C). By an abuse of notation, we often omit  and simply
write sk(A  S) MM C.

The addition of ICs does not change the semantics of DLs or
OWL: Definition 3 is only concerned with the semantics of ICs, and
an ordinary DL knowledge base (T,A) can be seen as an extended
knowledge base (T,,A). For subsumption and concept satisfiability tests, we should use S  C together as one common schema, just
as it is the case in standard DLs. All inference problems are defined
as usual; for example, a concept C is subsumed by a concept D if the
extension of C is included in the extension of D in every model of
S  C.
Integrity constraints become important only in combination
with an ABox A. We invite the reader to verify that, on the examples
presented thus far, Definition 3 indeed provides a semantics for ICs
that follows the principles from relational databases. In Section 4
we show that, if ICs are satisfied, we can throw them away without
losing any positive consequences; that is, we can answer positive
queries by taking into account only A and S. This further shows
that our ICs are similar to the integrity constraints in relational
databases.
Let A8 be an ABox with only the following axioms:
Vegetarian(Ian)

We now discuss a nonobvious consequence of our semantics.

(36)

eats(Ian, soup)

(37)

B. Motik et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 7489

Furthermore, let S8 = , and let C8 contain only the following IC:
Vegetarian  eats.Meaty
(38)
One might intuitively expect C8 not to be satisfied for A8 since the
ABox does not state Meaty(soup). Contrary to our intuition, C8 is
satisfied in A8: the interpretation I containing only the facts (36)
and (37) is the only minimal Herbrand model of A8 and I  C8. In
fact, the IC (38) is equivalent to the following IC:
Vegetarian  eats.Meaty 
When written in the latter form, it can be seen that the IC should
be satisfied, since Meaty(soup) is not derivable.

(39)

(40)

As this example illustrates, the intuitive meaning of integrity
constraints is easier to grasp if we transform them into the form
C  D, where both C and D are negation-free concepts. This is
because, by Definition 3, our ICs check only positive facts. To check
negative facts, we must give them atomic names. Let A9 = A8; fur-
thermore, let S9 contain the following axiom:
NotMeaty  Meaty
Finally, let C9 contain the following integrity constraint:
Vegetarian  eats.NotMeaty
(41)
IC (41) is now of the positive form C  D, so it is easier to understand the intuition behind it: everything that is eaten by an instance
of Vegetarian should provably be NotMeaty. Now A9  S9 has the
following two minimal models, and I3 / C9, so C9 is not satisfied in
A9 and S9:
I3 = {Vegetarian(Ian), eats(Ian, soup), Meaty(soup)}
I4 = {Vegetarian(Ian), eats(Ian, soup), NotMeaty(soup)}
If we add to A9 the fact NotMeaty(soup), then only I4 is a minimal model, and C9 becomes satisfied as expected. Hence, it may be
advisable to restrict ICs to positive formulae in order to avoid such
misunderstandings.

4. Integrity constraints and queries

We now present an important result about answering unions
of positive conjunctive queries in extended DL knowledge bases: if
the ICs are satisfied, we need not consider them in query answering.
This suggests that our semantics of IC satisfaction is reasonable: ICs
are checks and, if they are satisfied, we can disregard them without
losing relevant consequences. This result is practically important
because it simplifies query answering. In Section 7 we show that, for
certain types of OWL ontologies, both checking IC satisfaction and
query answering can be easier than standard DL reasoning. Note
that ICs can still be useful for semantic query optimizationthat
is, they can be used to reformulate a query into one that can be
evaluated more efficiently over all databases that satisfy the ICs
(see, e.g., [13,6,22]). A discussion of semantic query optimization is,
however, beyond the scope of this paper; our main concern here is
to show that, if the ICs are satisfied, they are redundant from the
semantic point of view.

Before proceeding, we first remind the reader of the definition

of unions of conjunctive queries over DL knowledge bases [12].

Definition 4. Let x be a set of distinguished and y a set of nondistinguished variables. A conjunctive query Q (x, y) is a finite conjunction
of positive atoms of the form A(t1, . . . , tm), where each ti is either a
constant, a distinguished, or a nondistinguished variable.4 A u nion

4 The predicate A can be the equality predicate , an atomic concept, a role, or an
n-ary predicate in case of n-ary DLs.

yi : Qi(x, yi).
of n conjunctive queries is the formula U(x) =
A tuple of constants c is an a nswer to U(x) over a DL knowledge
base K, written K  U(c), if (K)  U(x)[c/x].

i=1

We first prove an auxiliary lemma.

Lemma 1.
model I

Let  be a first-order formula. If sk() has a Herbrand
, then sk() has a minimal Herbrand model I such that I  I

Proof. The following property (*) is well-known: if a set of formulae has a Herbrand model, then it has a minimal Herbrand model
as well. Such a model can be constructed, for example, using the
model-construction method used to show the completeness of resolution [5]. Let I
}.
S={sk()}{A|A is a ground fact over the signature of sk() and A /I
; furthermore, for each Herbrand model
Clearly, S is satisfied in I

. Now by (*), a minimal Herbrand model
 of S, we have I

I of S exists. Clearly, I  I
, and it is a minimal Herbrand model
of sk(). 

 be a Herbrand model of sk(), and let

The main result of this section is captured by the following the-

orem:

Let K = (S,C,A) be an extended DL knowledge base
Theorem 1.
that satisfies C. Then, for any union of conjunctive queries U(x) over K
and any tuple of constants c, we have A  S  C  U(c) if and only if
A  S  U(c).
if K satisfies C, then
Proof. We show the contrapositive:
S  A  C / U(c) if and only if S  A / U(c). The () direction
holds trivially, so we consider the () direction. If S  A / U(c),
then sk(S  A  {U(c)}) is satisfiable in a Herbrand model I

yi : Qi(c, yi). It does
The formula U(c) is equivalent to
not contain existential quantifiers, so it is not Skolemized:
sk(S  A  {U(c)}) = sk(S  A)  {U(c)}. By Lemma 1, a minimal
Herbrand interpretation I  I
 exists such that I  sk(S  A). Now
  yi : Qi(c, yi) for each 1  i  n. Hence, for
  U(c), so I

each tuple t of
the Herbrand universe,
the elements of
  Qi(c, yi)[t/yi]. But then, since I  I
 and all atoms from Qi(c, yi)

are positive, we have I  Qi(c, yi)[t/yi] for each t as well, so
I  yi : Qi(c, yi), and therefore I / yi : Qi(c, yi). Thus, we conclude I / U(c). Since the ICs are satisfied in K, the axioms in C are
satisfied in each minimal Herbrand model of , so I  C. Hence, we
conclude that I  S  A  C and I / U(c). 

i=1

Consider, for example, the following knowledge base. Let the

standard TBox S10 contain the following axioms:
Cat  Pet
hasPet.Pet  PetOwner
(43)
Let the integrity constraint TBox C10 contain the following axiom:
CatOwner  hasPet.Cat
(44)
Finally, let the ABox A10 contain the following facts:
CatOwner(John)

(42)

(45)

hasPet(John, Garfield)

(46)

Cat(Garfield)
(47)
Under the standard semantics, K implies the following conclusion:

S10  C10  A10  Pet Owner (John)
Furthermore, it is easy to see that IC (44) is satisfied in K: the only
derivable fact about CatOwner is CatOwner(John) and the ABox contains the explicit information that John owns Garfield who is a Cat.
Therefore, we do not need axiom (44) to imply the existence of the

owned cat: whenever we can derive CatOwner(x) for some x, we
can derive the information about the cat of x as well. Hence, we can
disregard (44) during query answering, and our conclusion holds
just the same:
S10  A10  PetOwner(John)

Note that both entailments in Theorem 1 use the standard semantics of DLs; that is, we do not assume a closed-world semantics
for query answering. Furthermore, Theorem 1 does not guarantee
preservation of negative consequences; in fact, such consequences
may change, as the following example demonstrates. Let S11 = ,
let C11 contain the integrity constraint
Cat  Dog 
(48)
and let A11 contain axiom (47). Taking S11 into account, we get the
following inference:
S11  C11  A11  Dog(Garfield)
Furthermore, integrity constraint (48) is satisfied in S11  A11; how-
ever, if we disregard C11, we lose the above consequence:
S11  A11 / Dog(Garfield)

A similar example can be given for queries containing universal
quantifiers.

 such that I

  sk(S  A) and I

The proof of Theorem 1 reveals why U(x) is restricted to positive
 / A(a).
atoms. Consider a model I
For a minimal model I of sk(S  A), it might be that A(a) I
 \ I, so
I  A(a). Intuitively, IC satisfaction ensures that all positive atoms
derivable through ICs are derivable without ICs as well; this, how-
ever, does not necessarily hold for negated atoms. This proof also
reveals why the entailment of universally quantified formulae is
not preserved. Intuitively, for such formulae, we should not consider only the Herbrand models of sk(S  A) because they may be
too small. For example, let A = {A(a)} and U = x : A(x). Clearly,
A / U, but the only Herbrand model of A is I = {A(a)} and I  U.
The problem is that I does not take into account the individual that
would be introduced by negating and Skolemizing the query.

Theorem 1 has an important implication with respect to TBox
reasoning. Let U1(x) and U2(x) be unions of conjunctive queries
such that (K)  x : [U1(x)  U2(x)]. Provided that C is satisfied
in K, each answer to U1(x) w.r.t. A  S is also an answer to U2(x)
w.r.t. A  S. In other words, we can check subsumption of unions
of conjunctive as usual, by treating C  S as an ordinary DL TBox;
subsequently, for knowledge bases that satisfy C, we can ignore C
when answering queries, but query answers will still satisfy the
established subsumption relationships between queries.
We conclude this section with the remark that, if an extended DL
knowledge baseK = (S,C,A) does not satisfyC, then the ICs inC cannot be ignored during query answering. In such a case it might not
actually make sense to attempt to answer any queries over Kthat
is, IC satisfaction should be taken as a prerequisite for query answer-
ing. This is similar to the situation in relational databases systems,
which typically reject database updates that violate one or more
integrity constraints; thus, ICs are satisfied at all times, which is
taken as a precondition for query answering.

5. Using integrity constraints in practice

To clarify our ideas and provide practical guidance, we present
in Fig. 1 a sequence of steps that, we believe, could be followed to
integrate ICs into ontology-based applications. In the rest of this
section we consider different steps in more detail.

5.1. Modeling the domain

The difference between ICs and standard axioms plays no role
during domain modeling; that is, the domain should be modeled
as usual. For example, to describe that each person should have
a social security number, we should simply state axiom (1), and
we should not worry at this point whether this axioms should be
placed into the standard or the integrity constraint TBox. Since no
data is available during domain modeling, the ontology is modeled
as usual. Hence, we classify the knowledge base and check concept
satisfiability using well-known tools and techniques.

5.2. Identifying integrity constraints

The axioms in both the standard and the integrity constraint
TBox describe the general properties of modeled domain; for exam-
ple, axiom (1) states that each person must have an SSN. In addition
to describing the domain, ICs also describe the admissible states of
the knowledge basethat is, they describe the assumptions that
applications make about the data. It makes sense to consider the
applications assumptions about the data separately from domain
modeling; hence, we should model a knowledge base first and then
subsequently identify certain axioms as integrity constraints.5 For
example, if an application requires the SSN of each person to be
known explicitly, then (1) should be moved into the integrity constraint TBox C; otherwise, it should be kept in the standard TBox S.
In the rest of this section, we discuss three kinds of axioms that are
likely to be identified as ICs.

Participation constraints involve two concepts C and D and a
relation R between them, and they state that each instance of C
must participate in one or more R-relationships with instances of
D; often, they also define the cardinality of the relationship. The
general form of such constraints is as follows, where 	 {,,=}
and n is a nonnegative integer:
C  	n R.D
Participation constraints are closely related to inclusion dependencies from relational databases.

(49)

Axiom (1) is a typical participation constraint. Another example
is the following statement, which allows each person to have at
most one spouse:
Person  1marriedTo.Person
To understand the difference in treating (50) as a standard axiom
or as an integrity constraint, consider the following ABox A:
Person(Peter)

(50)

(51)

marriedTo(Peter, Ann)

(52)

marriedTo(Peter, Mary)
(53)
If we treat (50) as a standard TBox axiom (i.e., as part of S), then
A  S is satisfiable; furthermore, due to (50), we derive Ann  Mary.
If, however, we identify (50) as an integrity constraint, then the only
minimal model of A contains exactly facts (51)(53). This is because
the equality predicate  is minimized as well, so Ann is different
from Mary. This matches our intuition, as there is no axiom in S that
would force Ann and Mary to be the same. Thus, Peter is married to
two different people, so integrity constraint (50) is not satisfied in
A.

Typing constraints can be used to check whether objects are
correctly typed. Typical examples of such statements are domain

5 In practice, domain modeling might be interleaved with IC modeling; however,

it is beneficial to separate the two steps at least conceptually.

B. Motik et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 7489

Fig. 1. Using knowledge bases with integrity constraints.

and range restrictions: when interpreted as integrity constraints
for a role R and a concept C, they state that R-links can only point
from or to objects that are explicitly typed as C. Domain and range
constraints are generally of the forms (54) and (55), respectively.
R.  C
  R.C

(54)

(55)

Axiom (9) is a typical example of a domain constraint. Another
example is the following axiom, which states that the marriedTo
relation can point only to instances of the Person class:
  marriedTo.Person
(56)
Consider an ABox A containing only fact (52). If (56) were a part
of the standard TBox S, then A  S would be satisfiable; further-
more, due to (56), we would derive Person(Ann). If we put (56) into
the integrity constraint TBox C, then the only minimal model of A
contains only the fact (52). Thus, Ann is not explicitly typed as an
instance of Person, so integrity constraint (56) is not satisfied in A.
Naming constraints can be used to check whether objects are
known by name. For example, an application for the management
of tax returns might deal with two types of people: those who have
submitted a tax return for processing, and those who are somehow related to the people from the first group (e.g., their spouses
or children). For the application to function properly, it might not
be necessary to explicitly specify the SSN for all people; only the
SSNs for the people from the first group are of importance. In such
an application, we might use axioms (1)(3) not as ICs, but as elements of the standard TBox S. Furthermore, to distinguish people
who have submitted a tax return, we would introduce a concept
PersonTR for such persons and make it a subset of Person in S:
PersonTR  Person

(57)

Two things should hold for each instance of PersonTR: first, we
require each such person to be explicitly known by name, and sec-
ond, we require the SSN of each such person to be known by name
as well. Although ICs can be used to check whether an individual is present in an interpretation, they cannot distinguish named
(known) from unnamed (unknown) individuals. We can, however,
solve this problem using the following trick. We can use a special
concept O to denote all individuals known by name and state the
following two integrity constraints:
PersonTR  O
PersonTR  hasSSN.(O  SSN)
Furthermore, we add the following ABox fact for each individual a
occurring in an ABox:

(59)

(58)

O(a)
(60)
In any minimal model of S  A, the facts of the form (60) ensure
that O is interpreted exactly as the set of all known objects. Hence,
IC (58) ensures that each individual in the extension of PersonTR is
known, and IC (59) ensures that the social security number for each
such person is known as well.

One might object that this solution is not completely model-
theoretic: it requires asserting (60) for each known individual,
which is a form of procedural preprocessing. We agree that our

solution is not completely clean in that sense; however, we believe
that it is simple to understand and implement and is therefore
acceptable.

For TBox reasoning, facts of the form (60) are, by definition, not
taken into account. Instead of these facts, one might be tempted to
use the following axiom, where ai are all individuals from the ABox:
O  {a1, . . . , an}
This, however, requires nominals in the DL language, which makes
reasoning more difficult [42]. Furthermore, since O occurs only
in integrity constraints, facts of the form (60) are sufficient: the
minimal model semantics ensures that O contains exactly the individuals a1, . . . , an.

(61)

5.3. Data-related tasks

After the axioms from the domain model have been correctly
separated into the standard TBoxS and the integrity constraint TBox
C, we are ready to add data. After appending an ABox A, we then
check IC satisfaction using Definition 2. We present algorithms that
can be used for this purpose in Section 7.6 If the ICs are satisfied,
then we know that all data satisfies the applications assumptions.
Furthermore, by Theorem 1, we can disregard the integrity constraints while computing answers to unions of positive conjunctive
queries without the danger of losing some answers.

6. Characterization via logic programming

We now develop an alternative characterization of IC satisfaction based on logic programming. Given an extended DL knowledge
base K = (S,C,A), we compute a (possibly disjunctive) stratified
logic program that entails a certain atom if and only if K satisfies C.
We first show how to evaluate C in a model using a stratified datalog
program. This result is reminiscent of the Lloyd-Topor transformation of complex formulae in logic programs [28].

Definition 5. For a first-order formula , let E be an n-ary predicate symbol uniquely associated with , where n is the number
of the free variables in . For a first-order formula , the integrity
constraint program IC() is defined recursively as follows, for  and
sub as defined in Table 1:
IC() = () 

IC( )

   sub()

As one can easily see from Definition 5, the program IC() is
stratified and nonrecursive. For a finite set of formulae T, we define
   T  , and we use ET as a synonym

IC(T) = IC() where  = 

for E.

Intuitively, the rules in IC() encode the semantics of the
propositional connectives and the quantifiers. Thus, when IC() is
evaluated in some model I (that contains the fact HU(a) for each
element of the domain), the predicate E will contain exactly those

6 Integrity constraints can clearly be checked incrementally, while adding facts
to the ABox. We consider this an implementation issue and do not consider it any
further.

()

A(t1, . . . , tm)  E(x1, . . . , xn)
HU(x1)  . . .  HU(xn)  not E (x1, . . . , xn)  E(x1, . . . , xn)
E 1 (y1, . . . , ym)  E 2 (z1, . . . , zk)  E(x1, . . . , xn)
HU(x1)  . . .  HU(xn)  E 1 (y1, . . . , ym)  E(x1, . . . , xn)
HU(x1)  . . .  HU(xn)  E 2 (z1, . . . , zk)  E(x1, . . . , xn)
E (y1, . . . , ym)  E(x1, . . . , xn)
HU(x1)  . . .  HU(xn)  not Ey: (x1, . . . , xn)  E(x1, . . . , xn)

i=1

sub()


{ }
{ 1,  2}

{ 1,  2}

{ }
{y :  }

Table 1
The definition of the operators  and sub


A(t1, . . . , tm)

 1   2

 1   2

y :  
y :  

{ }
{k+1y :  }

Note: x1, . . . , xn are the free variables of ; y1, . . . , ym are the free variables of   and  1; and z1, . . . , zk are the free variables of  2. The predicate A can be . not is the stratified
negation of logic programs.

not yi  yj  E(x1, . . . , xn)
HU(x1)  . . .  HU(xn)  not Ek+1y: (x1, . . . , xn)  E(x1, . . . , xn)

E (y1, . . . , ym)[yi/y] 

1i<jk

ky :  
ky :  

facts E(t) for which [t/x] is true in I for each subformula  of .
We formalize this as follows.
Lemma 2. For a Herbrand model I, let A(I) be exactly the set of facts
containing I and a fact HU(t) for each ground term t from the universe
of I. For a first-order formula  with free variables x and a tuple of
ground terms t, we have I  [t/x] i f and only if A(I)  IC() c E(t).
Proof. The proof is by an easy induction on the structure of . For
the induction base, if  is an atomic formula, then IC() contains a
rule of the form (1) from Table 1, and the claim is obvious. Let us now
consider the possible forms of a complex formula . For  =  ,
the program IC() contains a rule of the form (2) from Table 1,
which ensures that E(t1, . . . , tn) holds exactly if E (t1, . . . , tn)
does not hold. The cases for  =  1   2 and  =  1   2 are
proved in a similar way. For  = y :  , the program IC() contains a rule of the form (5) from Table 1. This rule ensures that
E(t1, . . . , tn) holds whenever there is some ground term s such that
E (t1, . . . , s, . . . , tn) holds, which implies the claim. For  = y :  ,
the program IC() contains a rule of the form (6) which reflects
the fact that  is equivalent to  = y :  . Finally, for ky :  
and ky :  , the claim follows from the standard translation of
counting quantifiers into first-order logic. 

 by

Next, we show how to convert the schema S into an equivalent

positive logic program LP(S).
 be the translation
Definition 6. For a first-order formula , let 
of sk() into conjunctive normal form, and let LP() be the logic
program obtained from 
 converting each clause A1  . . .  An  B1  . . .  Bm into a rule
A1  . . .  An  B1  . . .  Bm;
 adding an atom HU(x) to the body of each rule in which the variable x occurs in the head but not in the body;
 adding a fact HU(c) for each constant c; and
 adding the following rule for each n-ary function symbol f:
HU(x1)  . . .  HU(xn)  HU(f (x1, . . . , xn))
Due to the distributive laws for  and , LP() can be exponential in the size of . Here, we are interested only in the semantic
properties of LP(); we address the potential exponential blowup
in Section 7.1.

We are now ready to present a characterization of IC satisfiability

For  = sk(S), the formula 

using logic programming.
Theorem 2. An extended DL knowledge base K = (S,C,A) satisfies
the integrity constraints C if and only if LP(S)  A  IC(C) C EC.
 in Definition 6 is obtained
Proof.
using standard equivalences of first-order logic, which preserve
satisfiability of formulae in any model, so the minimal Herbrand
models of sk(S  A) and {
}  A coincide. Furthermore, the facts
and rules introduced in the third and fourth item of Definition 6
just enumerate the entire Herbrand universe, so each minimal Her-
}  A corresponds exactly to a minimal Herbrand
brand model of {
model of LP(S)  A augmented with HU(t) for each ground term t.
The rules of IC(C) contain only the predicates E in their heads, and
each predicate depends only on the predicates corresponding to the
subformulae of . Hence, the program IC(C) is stratified, and IC(C)
just extends each minimal model I of LP(S)  A to a minimal model
 of LP(S)  A  IC( ) by facts of the form E(t), for  a subformula

of C. By Lemma 2, I
  C, which implies our claim.

  EC if and only if I

Theorem 2 is significant for two reasons. On the one hand, it
provides the foundation for IC satisfaction checking in several practical cases (see Section 7). On the other hand, it provides us with a
slightly more procedural intuition about the nature of integrity con-
straints. Rules of the form A  B from LP(S) do not contain negated
atoms, and they can be seen as procedural rules of the form from
A conclude B. Thus, an extended DL knowledge base satisfies the
integrity constraints in C if these are satisfied in each minimal set
of facts derivable from S  A.

7. Checking satisfaction of integrity constraints

We now consider algorithms for checking whether an extended
DL knowledge base K = (S,C,A) satisfies C. The difficulty of that
task is determined primarily by the structure of the standard TBox
S. This is because evaluating a formula in a Herbrand model is easy
regardless of the formula structure; the difficult task is the computation of the minimal models of sk(S  A). In the rest of this section,
we consider different possibilities for doing so depending on the
form of S.
If S contains no functions symbols, no existential quantifiers
under positive polarity, and no universal quantifiers under negative

polarity, then we can use Theorem 2: the program LP(S)  A  IC(C)
then does not contain function symbols, so we can use any (disjunc-
tive) datalog engine for checking IC satisfaction. A minor difficulty is
caused by the fact that LP(S) can be exponential in size. Therefore, in
Section 7.1, we show how to perform the translation without such
a blowup, and we apply this result to existential-free knowledge
bases in Section 7.2. Finally, in Section 7.3, we consider schemata
expressed in the DL ALCHI.

7.1. Structural transformation and minimal models

It is well-known that the translation into conjunctive normal
form, employed in Definition 6, can incur an exponential blowup,
which can be avoided by applying the structural transformation [34]
as follows. For a first-order formula , the result of applying the
structural transformation to a single occurrence of a subformula 
is the formula   shown in the Table
  x1, . . . , xn : [Q (x1, . . . , xn)  ]
  x1, . . . , xn : [Q (x1, . . . , xn)  ]
  x1, . . . , xn : [Q (x1, . . . , xn)  ]

if  occurs negatively in  

if  occurs positively in  


if  occurs both positively
and negatively in  

where x1, . . . , xn are the free variables of , Q is a fresh predicate,
 is obtained from  by replacing the mentioned occurrence of
and 
 with the atom Q (x1, . . . , xn). With occurs positively and occurs
negatively we mean that  occurs in   under even and odd number
of (both explicit and implicit) negations, respectively; furthermore,
 occurs in   both positively and negatively if it occurs under the
equivalence symbol . It is well known that this transformation
preserves the satisfiability of  [34].

We illustrate the above definition by means of an example. Con-

sider the formula
 = x : [A(x)  y : R(x, y)  (B(y)  C(y))].
To transform  into conjunctive normal form, we would need to
distribute  over , which would double the size of the formula. To
prevent this, we apply the structural transformation to the occurrence of the subformula  = B(y)  C(y), resulting in
  = x : [A(x)  y : R(x, y)  Q (y)]  y : [Q (y)  B(y)  C(y)].

If we apply the structural transformation to all nonatomic
subformulae of some formula, we can transform the result into conjunctive normal form without an exponential blowup. Furthermore,
the transformation is applied at most once to each subformula
of a formula, so the result can be computed in polynomial
time.

The structural transformation introduces additional symbols, so
it is not immediately clear that it preserves the minimal models.
Therefore, in the rest of this section we investigate the precise
relationship between the minimal models before and after the
transformation. We use the following notation. For an interpretation I and a set of predicates , let I/ be the restriction of I to the
predicates in , defined as follows:
I/ = { A(t1, . . . , tn) I | A  }
For a formula , let pred() be the set of all predicates in . We will
use I/ as an abbreviation for I/pred().

Let  be a formula and   a formula obtained from  through
structural transformation. Since this transformation extends the
signature of , it is clear that  is not equivalent to  . Ideally,
we would like each minimal model I of  to have a counterpart

minimal model I
/; conversely, for each minimal model I
/ to be a minimal model of
. Unfortunately, this property does not hold. For example, the

 of   such that I = I
 of  , we would like I

B. Motik et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 7489

only minimal Herbrand model of 1 = A  C  [A  B  (C  D)] is
I = {A, C}. Applying the structural transformation to 1 produces
the formula  1 = A  C  (A  B  Q )  (Q  C  D) with the
= I,
minimal models I
which is as expected; however, I
2 does not correspond to a minimal
model of 1.

2 = {A, B, C}. Now I

1 = {A, Q, C} and I

1/1

To precisely describe the relationship between the formulae
before and after the structural transformation, we use the following
definition.

Definition 7. A Herbrand interpretation I is a -minimal model of
 such that
a formula   if I    and I

/  I/. Furthermore, for a formula , the interpretation I is a

-minimal model of   if and only if it is a pred()-minimal model
of  .

 /   for each interpretation I

Thus, an -minimal model is a model in which the extensions
of the predicates in  are minimal; the extensions of the remaining predicates need not be minimal. As a consequence, the model

1 from the previous example is pred(1)-minimal, whereas I

is not.

The relationship between the models before and after
transformation is described by the following

the structural
theorem.

Theorem 3. Let  be a first-order formula and   a formula obtained
from  by applying the structural transformation to an occurrence of
a subformula . Then,

1. for each minimal Herbrand model I of , a minimal model I

 of  

exists such that I = I

/, and

2. for each -minimal Herbrand model I

is a minimal Herbrand model of .

 of  , the interpretation I

Proof. Let ,  , and  be as stated in the theorem. The following
 of  , we have
properties are well-known [34]: (*) for each model I

 of   exists such
/  ; and (**) for each model I of , a model I

that I

/ = I.

 be a
(Claim 1) Let I be a minimal Herbrand model of , and let I
Herbrand model of   whose existence is implied by (**). Clearly,

 of   must exist such that I  I

a minimal Herbrand model I
/ = I.
and I

/  .
(Claim 2) Let I
Let us assume that I
/ is not a minimal model of that is, that
/ and I  . Then, by the
an interpretation I exists such that I  I
/ = I and
first claim, a minimal model I

 of   exists such that I
 is not a -minimal model of  . 

 be a -minimal Herbrand model of  . By (*), I

/. Hence, I

/  I

The situation is easier for Horn formulaedisjunctions of literals
with at most one positive atom. It is well known that such formulae
can have at most one minimal Herbrand model, so the following
corollary follows immediately from Theorem 3.

Corollary 1. Let   be a conjunction of Horn formulae obtained from
some formula  by one or more applications of the structural trans-
formation. If I is a minimal model of  , t hen I/ is a minimal model
of .

7.2. Checking IC satisfaction for existential-free KBs

In this section we consider the quite common case of exis-
tential-free extended DL knowledge bases, which are defined as
follows.
Definition 8. An extended DL knowledge base K = (S,C,A) is
existential-free if no formula in (S) contains a function symbol, an

existential quantifier occurring positively, or a universal quantifier
occurring negatively.

Thus, S can contain an axiom x : [[y : R(x, y)]  C(x)], but
not an axiom x : [C(x)  y : R(x, y)]: in the first case, the existential quantifier occurs on the left-hand side of the implication
and is effectively equivalent to a universal quantifier, whereas in
the second case, the existential quantifier occurs positively in the
formula and it implies the existence of individuals in a model.
The integrity constraint TBox C can contain existential quantifiers
both under positive and negative polarity; these quantifiers, how-
ever, represent requirements on the facts that must be present in
the ABox. Hence, all individuals in an existential-free knowledge
base are explicitly known by namethat is, it is not necessary to
consider unnamed individuals. We expect many data-centric applications of OWL to fall into this category. Existential-free knowledge
bases exhibit a useful property that can be exploited in checking IC
satisfaction.

Proposition 1.
function symbols.

If K is existential-free, then LP(S) does not contain

The restricted way in which function symbols in LP(S) are introduced makes it is easy to see that this proposition is truenamely,
they are introduced only by the Skolemization of the existential
quantifiers occurring positively or universal quantifiers occurring
negatively in S.

Thus, for existential-free knowledge bases, we can check IC
satisfaction using standard logic programming machinery. If the
computation of LP(S) does not incur an exponential blowup, then
we do not need the structural transformation, and we can apply
Theorem 2 directly. If we apply the structural transformation, but
the program LP(S) is nondisjunctive, we can also use Theorem 2
due to Corollary 1. The problem arises if LP(S) is disjunctive and
we apply the structural transformation: by Theorem 3, we must
then consider the -minimal models of LP(S)  A  IC(C) where 
is the set of predicates before the structural transformation. Next
we show how to check -minimality for propositional formulae.

Theorem 4.
Let  be a set of propositional symbols,  a propositionalbi formula, and I an interpretation such that I  . Then, I is a
-m inimal model of  if and only if (, I, ), defined as follows, is
unsatisfiable:
(, I, ) =   neg(I, )  pos(I, )

neg(I, ) =

pos(I, ) =


A \I
A I

. Due to neg(I, ), if I / A for A , then I

For the () direction, assume that (, I, ) is satisfiable
 / A as well;
 / B.
/  I/, so I is not -minimal. For
 of
 satisfies both neg(I, ) and

Proof.
in a model I
also, due to pos(I, ), there is at least one atom I  B such that I
Hence, I
the () direction, if I is not a -minimal model of , a model I
 exists such that I
/  I/. Clearly, I
pos(I, ), so (, I, ) is satisfiable. 

 is a model of  and I

Thus, given an existential-free knowledge base K = (S,C,A),
checking whether LP(S)  A  IC(C)  EC can be performed by
grounding the program, guessing a Herbrand interpretation I for
it, checking whether I is a model of the program, checking whether
I is a -minimal model, and checking whether I does not contain
EC; the minimality check can be performed by checking the satisfiability of (, I, ). Clearly, the complexity of such an algorithm is
not worse than the complexity of disjunctive logic programming:
2 for data complexity and in coNExpTimeNP for combined
it is in 	p
complexity [17].

We finish this section with a note on equality. Most existing
implementations of disjunctive logic programming engines support

equality as a built-in predicate that is interpreted as identity and is
allowed to occur only in rule bodies. The program LP(S), however,
can contain equality in the rule heads as well. This type of equality is traditionally not supported in logic programming; however,
it can be simulated by introducing a new predicate and explicitly
axiomatizing the equality properties for it. Note that the logic program IC(C) can also contain equality, but only in rule bodies. Hence,
IC(C) cannot constrain two constants to be equal; it can only check
whether two constants have been derived to be equal. If IC(C) contains equality but LP(S) does not, then we can simply interpret
equality in IC(C) as identity and use the built-in implementation of
equality.

7.3. Checking IC satisfaction for general KBs

We now consider the problem of checking IC satisfaction when S
contains existentials. This turns out not to be easy, mainly because
the Herbrand models of sk(S) are infinite, so we cannot represent
them explicitly.
In this section we present an algorithm for IC satisfaction checking that can be used if S is expressed in the DL ALCHI. On the
one hand, this DL contains constructs characteristic of most DL lan-
guages, and on the other hand, the decision procedure does not get
too complex. We conjecture that this technique can be extended
to handle other constructs found in OWL, such as number restrictions or nominals; however, the technical details would obscure the
nature of our result. We do not intend our algorithm to be used in
practice; rather, our result should be understood as evidence that
checking IC satisfaction is, in principle, possible for nontrivial DLs.
Therefore, we leave the development of a more practical procedure
as well as extending it to more expressive DLs for future work. Note
that we place no restrictions on the form of the ICs in C: they can
be arbitrary first-order formulae.
To make this paper self-contained, we start with a formal definition of the DL ALCHI. The basic components of an ALCHI
knowledge base are atomic concepts, which correspond to unary
predicates, and atomic roles, which correspond to binary predi-
 for R an
cates. A role is either an atomic role or an inverse role R
) = R.
atomic role; furthermore, we define Inv(R) = R
The set of ALCHI concepts is defined inductively as the smallest
set containing the atomic concepts, C (negation), C  D (conjunc-
tion), C  D (disjunction), R.C (existential quantification), and R.C
(universal quantification), for C and D concepts. An ALCHI knowledge base K = (S,A) consists of a TBox S, which is a set of general
concept inclusion axioms C  D for C and D concepts, role inclusion
axioms R  S for R and S roles, and an ABox A, which is a set of
facts of the form A(a) and R(a, b) for A an atomic concept and R
an atomic role. The semantics of K can be given by translating S
into a first-order formula (S), where the definition of  is given in
Table 2.7

 and Inv(R

We embed the problem of checking IC satisfaction into the problem of checking satisfiability of monadic second-order formulae
on infinite k-ary trees SkS [36]. We use SkS because it allows us
to encode the tree-like structure of Herbrand models, and it provides for second-order quantification that can be used to express
the minimality criterion. SkS terms are built as usual from firstorder variables (written in lowercase letters), a constant symbol ,
and k unary function symbols fi. For SkS terms t and s, an SkS atom is
of the form t = s or X(t), where X is a second-order variable (writ-
ten in uppercase letters). SkS f ormulae are obtained from atoms
in the usual way using propositional connectives , , and , firstorder quantification x and x, and second-order quantification X

7 The operators x, y, xy, and yx are mutually recursive, and they reuse the

variables x and y for nested expressions.

B. Motik et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 7489

Table 2
The semantics of ALCHI by translation to FOL

Table 4
Transforming interpretations

yx(R) = R(y, x)
) = R(x, y)
yx(R

y(A) = A(y)
y(C) = y(C)
y(C  D) = y(C)  y(D)
y(C  D) = y(C)  y(D)
y(R.C) = x : yx(R)  x(C)
y(R.C) = x : yx(R)  x(C)

The translation of roles to FOL
xy(R) = R(x, y)
) = R(y, x)
xy(R

The translation of concepts to FOL
x(A) = A(x)
x(C) = x(C)
x(C  D) = x(C)  x(D)
x(C  D) = x(C)  x(D)
x(R.C) = y : xy(R)  y(C)
x(R.C) = y : xy(R)  y(C)
The translation of axioms to FOL
(C  D) = x : x(C)  x(D)
(R  S) = x, y : xy(R)  xy(S)
(A(a)) = A(a)
(R(a, b)) = R(a, b)
(K) =
 K( )

and X. For the semantics of SkS, please refer to [36]. Intuitively,
first-order quantification ranges over domain elements, whereas
second-order quantification ranges over domain subsets. The sym-
bol= denotes true equality in SkS, and it is different from the symbol
 used so far, which denotes a congruence relation on Herbrand
models. We use P  R as an abbreviation for x : P(x)  R(x), and
P  R as an abbreviation for P  R  (R  P).
Let K = (S,C,A) be an extended DL knowledge base in which S is
an ALCHI TBox, and let   = sk(S  A). We now show how to compute an SkS formula SkSK that is satisfiable if and only if   MM C.
The formula   contains binary atoms and is therefore not an SkS
formula. We proceed as follows. First, we observe that   contains
subformulae of the form shown in Table 3. Next, based on the formula structure, we show that all models of   are forest-likethat
is, they contain binary atoms only of a certain form. Due to their
restricted form, we show that such binary atoms can be encoded
using unary atoms. Finally, since SkS provides only for one constant
, we encode all constants in   using function symbols. The result
is an SkS formula, and we simply encode the minimality condition
using second-order quantifiers.
Without loss of generality, we assume that all concepts in S
are in negation-normal formthat is, that negation occurs only in
front of atomic concepts. Then, it is easy to see that the formula
  = sk(S  A) can be computed as follows, where  is the operator
from Table 3:
  = A   1   2
 1 =

x, y : [xy(R)  xy(S)]

 2 =

x : (NNFC  D, x)

RS S

We now define different types of models that we consider:

Table 3
Skolemization of concepts in NNF

C1  C2
C1  C2
R.C

.C
R.C

.C
Note: The symbol  is a placeholder for actual terms supplied as the second argument
to . The function symbol f and the variable y are fresh in each invocation of .

(C,)
A()
(A,)
(C1,)  (C2,)
(C1,)  (C2,)
R(, f ())  (C, f ())
R(f (),)  (C, f ())
y : [R(, y)  (C, y)]
y : [R(y,)  (C, y)]

Forest-like

R(t, f (t))
R(f (t), t)
R(a, t)


Tree-like

Rf (t)

f (t)

Ra(t) for t not of the form f (a)

Definition 9. A Herbrand interpretation I is forest-like if it contains
only unary and binary atoms, all function symbols are at most unary,
and all binary atoms are of the form R(a, t), R(t, f (t)), or R(f (t), t),
where a is a constant and t is a term. A Herbrand interpretation
I is monadic if it contains only unary predicates and all function
symbols are at most unary.

One might expect forest-like models to contain the facts of the
form R(a, b) instead of facts of the form R(a, t); we discuss the rationale behind our definition after Definition 10. We next prove the
core property of the models of  .

the formula

All minimal Herbrand models of

Lemma 3.
  = sk(S  A) are forest-like.
Proof.
If I is a model of   that is not forest-like, it contains a
binary atom of the form R(s, t) that is not of the form specified in
 be an interpretation obtained from I by removDefinition 9. Let I
ing all atoms of the form S(s, t) such that S
R, where  is the
reflexivetransitive closure of {R  S, Inv(R)  Inv(S)|R  S S}. For

the subformula  1 of  , it is clear that I   1 if and only if I
because, whenever we remove some R(s, t) from I, we remove also
all S(s, t) such that S 
R. For the subformula  2 of  , we show that
   2 by a straightforward induction on the for-
I   2 if and only if I
mula structure. Note that only positive binary atoms could have a
. All such atoms in  2 stem from lines
different truth value in I and I
5 and 6 of Table 3 and are thus of the form R(t, f (t)) or R(f (t), t).
 whenever they are included
Therefore, they are included in I
in I. 

For each binary predicate R, function symbol f, and constant a

f , and Ra in order to

in  , we introduce the unary predicates Rf , R
encode binary atoms in a forest-like model.

Definition 10.
For a forest-like Herbrand interpretation I, the
monadic encoding  I is obtained by replacing each atom from the
left-hand side of Table 4 with the corresponding atom on the righthand side. For a monadic Herbrand interpretation I, the forest-like
encoding  I is obtained by replacing each atom from the right-hand
side of Table 4 with the corresponding atom on the left-hand
side.

We clarify an important point of Definition 10. To be consis-

tent, we might be tempted to encode R(f (t), t) as R
f (f (t)). Similarly,
we might restrict the forest-like interpretations only to atoms
of the form R(a, b) instead of R(a, t). But then, we would lose
the one-to-one correspondence between forest-like and monadic

interpretations: decoding a monadic atom R
f (a) is not possible
because there is no predecessor for a; similarly, decoding an atom
Ra(f (f (a))) would produce an atom R(a, f (f (a))), which would not be
tree-like. Our definitions ensure that each forest-like interpretation
can be encoded as a monadic one and vice versa. The requirement
in Table 4 that t is not of the form f (a) ensures that the transformation is uniquely defined. We now define an encoding of binary
literals, which we then apply in Theorem 5 to the standard TBox
and the ICs.

Definition 11. For R a binary predicate and 	 a set of function symbols and constants, the formula [R, 	](x, y) is defined as follows,

where a are constants and f are function symbols:
[R, 	](x, y) = 1[R, 	](x, y)  2[R, 	](x, y)  3[R, 	](x, y)
1[R, 	](x, y) =

[x = a  Ra(y)]

a 	

f  	

f  	

2[R, 	](x, y) =

3[R, 	](x, y) =

[y = f (x)  Rf (x)]

[x = f (y)  R


f (y)]

For a formula , the formula [, 	] is obtained from  by replacing
each atom R(s, t) with [R, 	](s, t).8

Lemma 4. Let  be a formula containing only unary and binary pred-
icates, 	 a set containing all constants and function symbols from ,
and  = [, 	]. T hen,
 I   implies  I   for each forest-like Herbrand interpretation I, and
 J   implies  J   for each monadic Herbrand interpretation J.

Proof. For the first claim, we prove a slightly more general prop-
erty: for  a formula containing only unary and binary predicates
with free variables x,  = [, 	], and t a vector of terms, we have
I  [t/x] if and only if  I  [t/x]. The proof is by induction on the
structure of . The base case for unary atoms is trivial since I and
 I coincide on unary atoms. Let  = R(u, v); the formula  is of the
form as in Definition 11. Since I is forest-like, I  [t/x] if and only if
[t/x] is of the form R(a, t), R(t, f (t)), or R(f (t), t). In the first case,  I
satisfies 1[R, 	](u, v); in the second case, it satisfies 2[R, 	](u, v);
and in the third case, it satisfies 3[R, 	](u, v). The induction step
for Boolean connectives and quantifiers is trivial and is omitted for
the sake of brevity. The proof of the second claim is completely
equivalent to the proof of the first one. 

Our final obstacle is caused by the fact that SkS provides for only
one constant , while   can contain n different constants a1, . . . , an
(w.l.o.g. we assume that ai /= ), so we encode ai using function
symbols.

Definition 12. Let   be a Skolemized formula containing the constants a1, . . . , an and the function symbols f1, . . . , fm, respectively.
For k = m + n, let fm+1, . . . , fk be new unary function symbols. For a
formula , the formula cs () is obtained from  by replacing each
constant ai with fm+i().

In the rest of this section, we use ai as an abbreviation for fm+i().
The number k from Definition 12 defines the number of successors
of the SkS formula we are computing. The following proposition follows trivially from the fact that  and fm+1, . . . , fk do not occur in  :

Proposition 2.
to exactly one minimal Herbrand model I
Furthermore, for such I and I
for any formula .

Each minimal Herbrand model I of   corresponds
 of cs ( ) and vice versa.
  cs (),

, we have I   if and only if I

To check satisfaction of ICs in K = (S,C,A), we now construct a

formula SkSK that is satisfiable if and only if sk(S  A) MM C.
Let K = (S,C,A) be an extended DL knowledge
Definition 13.
base. Then, SkSK is the SkS formula defined as follows, where Pi

are all the predicates occurring in SkS , P
i are all the predicates
occurring in SkS  , and 	 contains all the constants and function

8 We assume that the atoms R

(s, t) in  are represented as R(t, s).

symbols occurring in  .
  = sk(S  A)
  = cs ( )

is obtained by replacing each predicate P in   with a fresh
predicate P

 = cs (C)
SkS  = [ , 	]
SkS  = [ 

, 	]
SkS = [, 	]
SkS = (P

SkSMM = P
SkSK = P1, . . . , Pn : [(SkS   SkSMM)  SkS]

 Pn)  (P

n : SkS  SkS 

 P1  . . .  P

1, . . . , P

 P1  . . .  P

 Pn)

For K = (S,C,A) an extended DL knowledge base,

Intuitively, the outer quantifiers P1, . . . , Pn in the formula SkSK
fix a valuation I of propositional symbols; the formula SkS  evaluates A  S in I; the formula SkSMM ensures that I is a minimal model
for A  S; and, finally, the formula SkS evaluates C in I.
Theorem 5.
  MM C if and only if SkSK is valid.
() If SkSK is not valid, a monadic interpretation I of the
Proof.
predicates Pi exists such that I  SkS  and I  SkSMM, but I / SkS.
By Lemma 4,  I    and  I / . We next show that  I is a minimal model
of  , which implies that   / MM ; by Proposition 2, we then have
that   / MM C. Assume that  I is not a minimal model of  that is,
that an interpretation J   I exists such that J   . By Lemma 3, J is
forest-like. But then,  J  I, so  J  SkS; furthermore, by Lemma 4,
 J  SkS  . These two claims now imply that I / SkSMM, which is a
contradiction.
() If   / MM C, by Proposition 2, we have   / MM . But then, by
Lemma 3, a forest-like model I of   exists such that I / . By Lemma
4,  I  SkS  and  I / SkS. To complete the proof that SkSK is not valid,
we just need to show that  I  SkSMM. Assume that the latter is not
the case; then, a monadic interpretation J exists such that J   I and
 and  J  I, so I is not a minimal
J  SkS  . But then, by Lemma 4,  J   
model of  . 

Theorem 5 shows that checking IC satisfaction is decidable
for nontrivial description logics. Unfortunately, it gives us only a
nonelementary upper complexity bound: the complexity of SkS is
determined by the number of quantifier alternations [36], which is
unlimited because SkS can be any first-order formula. In our future
work, we shall try to derive tight complexity bounds, as well as a
more practical algorithm.

8. Related work

The usefulness of integrity constraints was recognized early on
by the knowledge representation community, and KL-ONE [10] as
well as many of its successors provide a variant thereof. For exam-
ple, CLASSIC [9] provides a kind of derivation rule that can be used
to axiomatize ICs. Rules and ICs in such systems, however, typically
do not have a formal underpinning. For example, the derivation
rules in CLASSIC were given only a procedural semantics that has
not been tightly integrated with the core description language.

ICs were given formal semantics in first-order databases using
the consistency [24] and the entailment [37] approaches, and
these approaches were also applied to closed Prolog-like databases
[40,33,27]. Reiter conducted a comprehensive study of the nature
of ICs [38], in which he argued against all these approaches. He
observed that ICs are statements of an epistemic nature; conse-
quently, he proposed to capture their semantics in an extension

B. Motik et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 7489

of first-order logics with an autoepistemic knowledge operator K
that allows an agent to reason about his own knowledge. Lifschitz
presented the logic of Minimal Knowledge and Negation-as-Failure
(MKNF) which, additionally, provides for a negation-as-failure
operator not [26].

MKNF was used to obtain an expressive and decidable nonmonotonic DL [16]. One of the motivations for this work was to provide a
language capable of expressing integrity constraints. For example,
integrity constraint (1) can be expressed using the following axiom
(the modal operator A corresponds to not in MKNF):
K Person   A hasSSN.A SSN

(62)

MKNF was also used to integrate DLs with logic programming
[32]. Again, one of the motivations for this work was to allow for the
modeling of integrity constraints. For example, integrity constraint
(1) can be expressed by the following logic program:
K OK(x)  K hasSSN(x, y), K SSN(y)
 K Person(x), not OK(x)

(64)

(63)

Although these existing approaches are motivated similarly to
the approach presented in this paper, there are several important
differences.

First, rules (63)(64) do not have any meaning during TBox rea-
soning; they can only be used to check whether an ABox has the
required structure. Axiom (62) can be taken into account during
TBox reasoning, but it has a significantly different meaning from our
ICs: it only interacts with other modal axioms, but not with the standard first-order axioms. In contrast, the integrity constraint TBox C
has the standard semantics for TBox reasoning and is applicable as
usual; it is only for ABox reasoning that C is applied in a nonstandard way (i.e., as a check). Thus, the semantics of C is both closer
to the standard first-order semantics of description logics, and it
mimics more closely the behavior of ICs in relational databases. In
our proposal, ICs have a dual role: they describe the domain, as well
as the admissible states of the ABox.

Second, the semantics of MKNF makes it difficult to express
integrity constraints on unnamed individuals. For a DL concept C,
the concept K C contains the individuals that are in C in all models of
C. In most cases, K C contains only explicitly named individuals, and
not unnamed individuals implied by existential quantifiers, because
in different models one can choose different individuals to satisfy an
existential quantifier. Therefore, MKNF-based approaches usually
cannot interact with unnamed individuals, so they cannot express
the naming constraints mentioned in Section 5.2that is, they cannot be used to check whether all existentially implied individuals
are explicitly named.

Third, MKNF-based integrity constraints work at the level of
consequences and are therefore not applicable to disjunctive facts.
Consider again the ABox A3 containing axiom (18) and the standard TBox S3 containing axiom (19). We might express integrity
constraints (20)(21) using the following MKNF rules:
 K Tiger(x), not Carnivore(x)
 K Leopard(x), not Carnivore(x)
(66)
These rules are satisfied in A3  S3 because, roughly speaking,
K Tiger(x) can be understood as Tiger(x) is a consequence.
Due to disjunction in axiom (19), neither Tiger(ShereKahn) nor
Leopard(ShereKahn) is a consequence ofA3  S3; hence, the premise
of neither rule is satisfied and the integrity constraints are not vio-
lated.

(65)

Integrity constraints are commonly available in object-oriented
deductive databases. ConceptBase9 is such a system, and it is based

on the Telos [33] language. IC satisfaction in Telos was formalized similarly as in the consistency approach for closed databases
[40]. FLORA-210 is an object-oriented deductive database based
on F-Logic [23]. F-Logic provides for typing constraints that are
formalized in logic programming; furthermore, general logic programming rules can be used to express arbitrary checks. OWL-Flight
[15] is an ontology langauge that also provides for typing constraints and formalizes them in logic programming. Furthermore,
techniques are known that can be used to check satisfaction of
such integrity constraints incrementally, after each database update
[41].

The encodings of ICs using rules in these approaches are closely
related to the one given in Section 6. Just like MKNF-based integrity
constraints, however, ICs in object-oriented deductive databases
only describe the allowed states of the database and play no
role during subsumption reasoning. In fact, DL-style subsumption
inferences have generally not been considered in object-oriented
databases, so the influence of ICs on such inferences is irrelevant.
In contrast, the ability to determine subsumption relationships
between schema elements is used in many applications of DLs and
OWL, so the role of ICs in subsumption reasoning is much more
important.

A further difference is that the languages of object-oriented
deductive databases typically do not provide for existential quan-
tification. Languages such as F-Logic allow for function symbols,
which can be used to capture our semantics of IC satisfaction based
on skolemization (see Section 3). In such a case, however, checking IC satisfaction in these languages easily becomes undecidable
due to the presence of arbitrary rules. Decidability of IC satisfaction
plays an important role in our work, and in Section 7.3 we identify
a case for which decidability is guaranteed.

9. Conclusion

Motivated by the problems encountered in data-centric applications of OWL, we have compared OWL and relational databases
w.r.t. their approaches to schema modeling, schema and data reasoning problems, and checking of integrity constraint satisfaction.
We have seen that both databases and OWL apply the standard firstorder semantics to schema reasoning, and the differences between
the two are found mainly in data reasoning problems. In relational databases, answering queries and IC satisfaction checking
correspond to model checking, whereas the only form of IC checking available in OWL is checking satisfiability of an ABox w.r.t. a
TBoxa problem that is not concerned with the form of the data.
This has caused misunderstandings in practice: OWL ontologies
can be understood as incomplete databases, while the databases
encountered in practice are usually complete.

To control the degree of incompleteness, we have proposed
the notion of extended DL knowledge bases, in which certain TBox
axioms can be designated as integrity constraints. For TBox reason-
ing, integrity constraints behave just like normal TBox axioms; for
ABox reasoning, however, they are interpreted in the spirit of relational databases. We define the semantics of IC satisfaction such
that they indeed check whether all required facts are entailed by
the given ABox and TBox.

We have also shown that, if ICs are satisfied, we can disregard them while answering positive queries. This suggests that our
semantics of IC satisfaction is indeed reasonable, and it suggests
that answering queries with integrity constraints may be easier in
practice because one needs to consider only a subset of the TBox.
Finally, we have presented an alternative characterization of IC sat-

9 http://dbis.rwth-aachen.de/CBdoc/.

10 http://flora.sourceforge.net/florahome.php.

isfaction based on logic programming, as well as several algorithms
for IC satisfaction checking.

The main theoretical challenge for our future research is to
derive tight complexity bounds for IC satisfaction checking for
knowledge bases with existentials, as well as to define practical
algorithms for that case. A more practical challenge is to apply the
presented approach in applications and validate its usefulness.

Acknowledgment

We thank the anonymous reviewer for numerous comments

that have contributed to the quality of this paper.
