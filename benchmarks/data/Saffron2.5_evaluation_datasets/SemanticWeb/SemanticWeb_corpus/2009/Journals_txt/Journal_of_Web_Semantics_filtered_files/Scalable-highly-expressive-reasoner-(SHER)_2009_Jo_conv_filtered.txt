Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 357361

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

Scalable highly expressive reasoner (SHER)
Julian Dolby, Achille Fokoue, Aditya Kalyanpur, Edith Schonberg, Kavitha Srinivas

IBM TJ Watson Research Center, 19 Skyline drive, Hawthorne, NY 10532, USA

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 9 January 2009
Received in revised form 18 May 2009
Accepted 28 May 2009
Available online 6 June 2009

Keywords:
Scalable ontology reasoner

Summarization
Explanations

In this paper, we describe scalable highly expressive reasoner (SHER), a breakthrough technology that
provides semantic querying of large relational datasets using OWL ontologies. SHER relies on a unique
algorithm based on ontology summarization and combines a traditional in-memory description logic
reasoner with a database backed RDF Store to scale reasoning to very large Aboxes. In our latest exper-
iments, SHER is able to do sound and complete conjunctive query answering up to 7 million triples in
seconds, and scales to datasets with 60 million triples, responding to queries in minutes. We describe
the SHER system architecture, discuss the underlying components and their functionality, and briefly
highlight two concrete use-cases of scalable OWL reasoning based on SHER in the Health Care and Life
Science space. The SHER system, with the source code, is available for download (free for academic use)
at: http://www.alphaworks.ibm.com/tech/sher.

 2009 Elsevier B.V. All rights reserved.

1. Introduction

In this paper, we describe scalable highly expressive reasoner
(SHER), a breakthrough technology that provides semantic querying of large relational datasets using OWL ontologies. SHER provides
standard description logic reasoning services including consistency
checking and conjunctive query answering, and supports the logic
OWL-DL excluding nominals and datatypes (i.e., SHIN).

One strategy to achieving scalability is to perform all possible
inferences when the data is loaded, so that no reasoning is needed
to answer queries. However, inference-on-load is not complete for
OWL-DL. Also, if the database is updated frequently, this strategy
requires complicated incremental reasoning, or frequent reloading.
SHER performs very limited inferencing on load. All other reasoning is performed at query-time. In our latest experiments, SHER is
able to do sound and complete conjunctive query answering on an
example with 7 million triples in seconds, and scales to datasets
with 60 million triples, responding to queries in minutes. SHER has
also been used to semantically index 300 million triples from the
medical literature.

Other two key features of SHER include its ability to tolerate
logical inconsistencies in the data, by pointing users to the source
of inconsistencies; and providing explanations (or justifications) for
why a particular result set is an answer to the query, which is useful
for validation by domain experts. Finally, SHER also includes two

 Corresponding author.
E-mail addresses: dolby@us.ibm.com (J. Dolby), achille@us.ibm.com
(A. Fokoue), adityakal@us.ibm.com (A. Kalyanpur), ediths@us.ibm.com
(E. Schonberg), ksrinivs@us.ibm.com (K. Srinivas).

1570-8268/$  see front matter  2009 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2009.05.002

fast, sound reasoner (FSR) implementations which can either be
used independently or in conjunction with the core SHER algorithm
to do sound and complete reasoning.

The remainder of this paper describes the SHER system archi-
tecture, our FSR implementations and two concrete use-cases of
scalable OWL reasoning based on SHER. The SHER system, with
the source code, is available for download (free for academic use)
at: http://www.alphaworks.ibm.com/tech/sher. Detailed installation and usage instructions, along with some sample data, queries
and scripts to test the system are included in the download. The
system can be run on a Windows or Linux machine and requires
little memory (512 M) to run the basic operations.

2. SHER system architecture

SHER relies on a unique combination of an in-memory description logic reasoner and a database backed RDF Store to scale
reasoning to very large Aboxes. A key feature of our algorithm is
that we perform consistency detection on a summarized version of
the Abox rather than the Abox in secondary storage [7]. A summary
Abox A can be constructed by mapping all individuals in the original Abox A, with the same concept set to a single individual in the
summary A. The summary has three key properties:
(1) For every individual a in the original Abox A, if a has type C in
A, the summarized individual a in A also has the same type C.
(2) For every pair of individuals (a, b) in the original Abox A, if
the relation R(a, b) exists in A, then a relation R (a, b) holds
between their respective summarized individuals in A.

(3) The same principle as in (2) applies to different-from assertions

between pairs of individuals.

J. Dolby et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 357361

be fed to an in-memory reasoner. The IMSB module functions in
two distinct modes. First, it acts as a filter that filters out irrelevant
assertions (from the point of view of the reasoning task at hand)
from the summary Abox built in the RDBMS by the SOR module.
Second, if a previously built in-memory summary Abox was not
precise enough to be conclusive, the IMSB is responsible for building
a more precise in-memory summary Abox.

2.3. Fast sound reasoner (FSR)

Fast, sound, but not necessarily complete, reasoners (as
described in the next section) can be plugged into SHER to quickly
find obvious answers to a given reasoning task, which can significantly improve the performance of SHER by limiting the number of
candidates to test. Section 3 discusses the currently implemented
FSRs in SHER.

2.4. Consistency check and justification computation modules

As most DL reasoners, SHER operates by reducing all reasoning tasks to consistency detection [8]. However, unlike other DL
reasoners, SHER performs the consistency check on a dramatically
reduced in-memory summary Abox. For example, for a membership query C(x), the in-memory filtered summary Abox built by
the IMSB module is modified by adding the negation of the query
to all summary individuals except those corresponding to obvious answers or obvious non-answers as determined by a FSR.
The modified in-memory summary Abox is then checked for con-
sistency. In the membership query example, a consistent summary
indicates that the only solutions are the ones found by the FSR.
For an inconsistent summary, a subset of the justifications for the
inconsistency is computed. Currently, SHER relies on Pellet [13] for
consistency check and justification computation. Note that previous
work [9] has shown that the complexity of justification computation for OWL-DL entailments is no worse than the OWL-DL tableau
reasoning algorithm, and thus does not affect system performance
much.

2.5.

Justification analyzer

Given a justification J for an inconsistency in the in-memory
summary Abox, the justification analyzer module determines,
based on the structure of J [3], whether the portion of the summary
corresponding to J needs to be made more precise by the IMSB or
whether it is already precise enough to be conclusive. Note that a
precise justification denotes a real inconsistency in the Abox, and
thus solutions can be derived from information in the justification.
On the other hand, an imprecise justification forces the IMSB to
perform further refinement of the portion of the summary Abox
corresponding to the justification to check for any real inconsis-
tency/solutions. Thus, using justifications makes the entire process
efficient and scalable (without it, randomly refining the summary
does not make sense).

3. Fast, sound reasoners (FSRs)

We have implemented several fast, sound reasoners (FSRs) in
SHER that can quickly find a large number of obvious solutions to
a query. These FSRs can be used independently or can be used in
conjunction with SHER to perform sound and complete reasoning.
In the latter case, we have devised a hybrid algorithm where the
results of the FSR are used to refine the initial summary to isolate
known solutions, and the rest of refinement proceeds normally to
find any remaining solutions to the query. In this section, we discuss
the two FSRs we have implemented and provide an overview of the
hybrid algorithm.

Fig. 1. SHER architecture.

We have shown that if the summary Abox A is consistent w.r.t.
a given Tbox T and a Rbox R, then A, is consistent w.r.t. T and R.
However, the converse does not hold. In general, an inconsistency in
the summary may reflect either a real inconsistency in the original
Abox, or could simply be an artifact of the summarization process.
In the case of an inconsistent summary, we use a process of iterative refinement described in [3] to make the summary more precise,
to the point where we can conclude that an inconsistent summary
A, reflects a real inconsistency in the actual Abox A. Refinement
is a process by which only the part of the summary that gives rise
to the inconsistency is made more precise, while preserving the
summary Abox properties(1)(3). To pinpoint the portion of the
summary that gives rise to the inconsistency, we focus on the justification for the inconsistency, where a justification is a minimal set
of assertions which, when taken together, imply a logical contra-
diction. The refinement process continues until one of two things
happen: either the inconsistency disappears (in which the original
Abox is deemed consistent); or we are left with an inconsistent portion of a summary that cannot be refined any further (in which case
the original Abox is really inconsistent). A key point here is that in
either case, we rarely fallback to dealing with specific Abox individ-
uals, and the scalability comes from making decisions on groups of
individuals as a whole.

Fig. 1 shows the main components of SHER that implement our

scalable reasoning algorithm.

2.1. Scalable ontology repository (SOR) subsystem

SOR [10] serves as a high-performance OWL ontology storage system based on relational database management systems
(RDBMS). It is responsible for loading OWL, RDF and triple files into
the underlying RDBMS. It also builds and maintains, in the RDBMS,
the summary Abox of the whole knowledge base. It can be configured to perform either no inferencing on load or a limited number
of inferences1 on load. Finally, it provides SPARQL and SQL query
end-points to the stored knowledge base.

2.2. In-memory summary builder (IMSB)

The in-memory summary builder (IMSB) module builds, for a
given reasoning task, an in-memory version of the relevant subset
of the summary Abox stored in the RDBMS. This summary can then

1 Typically application of domain and range inference rules.

3.1. Query expansion

4. Use cases

Query expansion is a well-known technique to find implicit solutions to a query by expanding the query (in effect, producing a
union of conjunctive queries) based on axioms in the ontology, e.g.,
expanding a membership query C(x) by adding query atoms for
all subclasses of C in the ontology. QuOnto [1] is one such implementation of a query expansion algorithm which is sound and
complete for the logic DL-Lite. Our query expansion algorithm is
similar in spirit to QuOnto, however, we differentiate ourselves in
a few ways. First, we use an OWL-DL reasoner to compute explicit
plus inferred subclasses for a concept in the query and use these
as a basis for expansion. The inferred results found by the reasoner helps the algorithm cover more cases. Second, we use a
Datalog engine to compute same individuals in the Abox based
on deterministic mergers (i.e., inferences due to functional and
inverse-functional property axioms, and sameAs axioms), and use
the results to expand our solution set. Finally, since query expansion
can produce a large number of queries, we eliminate queries that
have no solutions by checking for potential matches in the summary Abox (e.g., if the query contains atom C(x) but the concept
assertion C(a) is not present in the summary Abox, we discard the
query as it cannot have a match in the original Abox). Details of
our query expansion algorithm are provided in a related report
[4]. Note that our algorithm is sound and complete for DL-Lite,
and for the logic EL when the KB is acyclic, and is otherwise
incomplete.
3.2. EL+reasoner

We have implemented a polynomial-time sound and complete
EL+ reasoner based on the algorithm described in [2]. Note that
many ontologies in the health-care and life-sciences community
such as the gene ontology (GO) fall in this fragment, which can
express (among other things) general concept inclusions, sub-roles
and transitive relations.

We have two separate implementationsan highly optimized
in-memory version, and a database-backed version that uses a
Datalog engine to evaluate the EL+rules. In our experiments,
the in-memory EL+ reasoner has been able to fully classify the
SNOMED OWL ontology in under 15 min. Also, the in-memory version supports incremental updates and provides explanations for
subsumption (i.e., smallest set of axioms responsible for the sub-
sumption).

3.3. Hybrid reasoner

The main idea of our hybrid reasoning approach is that it can
incorporate any sound and incomplete reasoning algorithm (or FSR)
into the core SHER summarization and refinement process to provide efficient, complete, and yet highly scalable reasoning over
large Aboxes. The key insight is that the solutions from the FSR
can be used as a partitioning function for refinement instead of
partitioning based on edges. This effectively removes the obvious
solutions from the summary Abox. If the FSR finds all solutions,
there will be no solutions left in the summary Abox after this
first refinement, so the algorithm will converge very quickly. Any
remaining inconsistencies are spurious, and can be resolved in
one or a few refinement steps. If the FSR finds only some of the
solutions, then the refinement process will find the rest of the
solutions with fewer refinement steps. We have demonstrated
the value of this hybrid approach in our Clinical Trials use case
(described in the next section), where we achieved noticeable
improvement in performance using our query expansion algorithm
as the FSR, and summarization/refinement to find only remaining
solutions.

We used SHER to build two solutions within the healthcare and
life sciences domain: the first used SHER to semantically query
patient records using SNOMED-CT, and the second used SHER to
provide a semantic search capability over the medical literature
from the National Library of Medicine. Each of these use cases is
described below.

4.1. Semantic querying of patient records

In collaboration with Columbia University Medical Center, we
used SHER to design a solution for the problem of finding matching
patient records for clinical trials criteria [11]. Currently, there are
approximately 65,000 clinical trials that are designed to test various drugs and procedures. Each clinical trial posts the criteria for
recruitment on a central website http://clinicaltrials.gov. Common
criteria for recruitment include patients being on drugs with certain
active ingredients, or patients being diagnosed with various medical conditions. Electronic patient records contain vendor-specific
drugs that a patient is taking, or specific radiological or laboratory findings; they never contain the ingredients of the drugs that
patients are on, nor do they contain detailed diagnostic medical
conditions2. In order to find patient records that satisfy the clinical trials criteria, we need to bridge the semantic gap between, for
example, the vendor-specific drug information that is part of the
patient record, and the specific active ingredients of the drug that
is not part of the record, but that is part of the domain-specific
knowledge of medicine. We investigated if we could bridge this
semantic gap using SNOMED-CT as our knowledge base3, and SHER
as the reasoning engine. There were three key technical challenges
in building this solution:
 (a) Transforming the patient data into a SNOMED-CT knowledge base. This step included mapping the local terminology of
Columbia called MED into SNOMED-CT.
 (b) Scaling reasoning to SNOMED-CT, with a very large Abox (1
year worth of patient data for 250 K patients at Columbia, which
was about 60 million RDF triples).
 (c) The expressivity of the ontology, which wasSHIN due to negation in the Abox (e.g., we had to model complex negation where
a certain laboratory finding was ruled out).

In our initial results, the performance of our initial solution on
nine queries drawn from http://clinicaltrials.gov ranged between
26 and 370 min, because of the expressivity of the knowledge base.
Although this performance is acceptable within a domain where the
clinical trial matching is largely a manual and tedious process, it is
less than ideal for other use case scenarios. We gained a significant
performance improvement by adding a fast sound reasoner (FSR)
component into our system to find as many solutions as quickly as
possible. With the addition of the FSR, our performance improved
to between 11 and 21 min for the same data (see [4] for details). For
the 9 test queries, the FSR component found all answers. Although
our knowledge base was expressive, and we were in general not
complete for all queries, for the specific sets of queries we used, the
FSR component was sufficient in providing fast answers to the ques-
tion. In fact, because FSR uses nothing more than a SQL expansion
of the query, performance for just the FSR component is significantly under the 1121 min range reported in [4]; the majority of the

2 Medical diagnoses recorded for billing purposes do not necessarily satisfy the

granularity needed for clinical trials recruitment.

3 We used the SNOMED CT KRSS version from 2005 and converted the KRSS format

to OWL.

J. Dolby et al. / Web Semantics: Science, Services and Agents on the World Wide Web 7 (2009) 357361

1121 min is spent in summarization and refinement steps post-FSR
to check for completeness.

4.2. Semantic search of medical literature: anatomylens

In searching the biomedical literature, using the concepts in an
ontology can help improve recall. For instance, if users want to
search for medical articles that mention the heart, they implicitly
mean articles that either mention the heart or any of its subparts.
An ontology like the Foundational Model of Anatomy (FMA) formally defines part hierarchies that can be used to automatically
improve recall of medical data. Similarly, when users want to find
genes that are involved in a certain biological process such as neuron development, they implicitly mean any subprocesses of neuron
development (such as axon or dendrite development). Ontologies
(such as the gene ontology (GO)), which formally describe these
subprocesses, can be used to improve recall of relevant genes or arti-
cles. Anatomy Lens4 is a SHER-based solution for semantic search of
the medical literature using ontologies such as GO, FMA, and MeSH.
The data set used in this solution was based in part on the
Banff HCLS Demo5. We integrated the following data into one large
knowledge base with 300 million RDF triples:
 PubMed 2008 distribution from NLM (National Library of
Medicine) with only article titles and their links to MeSH.
 Gene annotations GOA, linking genes and gene products to arti-
cles, specific evidence codes, and gene ontology processes (such
as dendrite development) defined in the gene ontology.
 The gene ontology, which contains definitions of the biological,
cellular, and molecular functions of genes
 The foundational model of anatomy, which contains definitions
of anatomical parts and their subparts. We used the OWL version
of FMA created by Golbreich, Zhang, Bodenreider (2006).
 Mappings from the MeSH annotations for PubMed articles to
FMA concepts. This was achieved by using UMLS to map MeSH
to FMA, but it missed some key mappings. We augmented
the mappings with additional matches from the MMTx tool
from NLM http://mmtx.nlm.nih.gov/index.shtml, keeping only
matches with a perfect score.
 The MeSH taxonomy, which is really three separate trees. For
example, the concept program evaluation appears in three trees,
but it contains the subclass benchmarking in only two of the three
trees. To be consistent in our reasoning, we treated these separate
trees as a directed acyclic graph.

The four key technical challenges in this solution were as fol-

lows:
 It is well known that certain combinations of constructors are
particularly problematic for OWL reasoning. An example of this
may be seen in reasoning on FMA. FMA is a deep partonomy,
with both hasPart and partOf relations and an inverse relation
between partOf and hasPart. This particular combination of constructs causes reasoners to fail (see http://www.w3.org/2001/sw/
BestPractices/OEP/SimplePartWhole/index.html). We therefore
included only partOf relations in FMA, as is recommended. This
version of FMA falls into the OWL dialect EL+, and we used the
EL+ reasoner in SHER to reason on this dataset.
 Even with theEL+ reasoner, scalability was a serious challenge for
a Web service. The combined Tbox for AnatomyLens has 75,000
FMA concepts, 30,000 GO concepts, and 15,000 MeSH concepts.

4 http://services.alphaworks.ibm.com/anatomylens/.
5 http://esw.w3.org/topic/HCLS/Banff2007Demo.

Fig. 2. Sample explanation in anatomy lens: in this case, given the query respiratory tube development, the engine also returns articles that talk about alveolus
development and explains why.

Reasoning at query time on this combined Tbox took a few minutes with the EL+ reasoner, which is not acceptable for a web
based application. We exploited the fact that the Abox in AnatomyLens does not contain any relations which could be used to
infer new types. We therefore precomputed all subclasses and
subparts for each concept in advance, and used this expansion to
expand the query for each concept. For any given queried concept
C, we translate the query into a membership query where we look
for all instances of the concept (partOf.C)  C.
 A key issue in semantic search is to be able to rank the returned
results. In keyword search, it is obvious what constitutes a match,
and there are various techniques to rank the result set. For semantic search, one measure that can be used to rank the results is the
semantic distance between an answer concept Q and the queried
concept C. Our metric of semantic distance was the size of the justification set for any given concept Q which was an answer to the
query (partOf.C)  C (i.e., the more the number of axioms needed
to infer a relationship between Q and the query, the greater the
semantic distance between them). We used this metric to rank
the returned results, and grouped each set of results by justifica-
tions. We also provided the natural language descriptions of the
justification sets to enable users to understand why a set of results
were a match (see Fig. 2 for an example). The ability to provide
explanations for matches is critical in semantic search, where the
link between the query and the returned results may not always
be obvious to the user.
 Another issue in query-expansion based semantic search is dealing with peculiar modeling issues. For example, in the partonomy
in FMA, the concept Cell is a transitive sub-part of each body part,
but including articles that talk about cells when the query is about
a specific body part such as the Lung would produce a lot of extraneous results. To solve this problem, we ensure that the expanded
sub-concept is dominated by the queried concept in the partonomy tree. Finally, we allow the user to control the expansion by
presenting results closest in semantic distance to the queried con-
cept, and prompting users for whether they want to continue to
expand the semantic search.

These examples show that large-scale, expressive ontologyreasoning based applications can be built using SHER. We
hope that the academic community can leverage this opensource technology to build more real-world semantic web
applications.
