Exploiting Partial Information in Taxonomy

Construction

Rob Shearer and Ian Horrocks

Oxford University Computing Laboratory, Oxford, UK

Abstract. One of the core services provided by OWL reasoners is classification:
the discovery of all subclass relationships between class names occurring in an
ontology. Discovering these relations can be computationally expensive, particularly if individual subsumption tests are costly or if the number of class names
is large. We present a classification algorithm which exploits partial information
about subclass relationships to reduce both the number of individual tests and the
cost of working with large ontologies. We also describe techniques for extracting such partial information from existing reasoners. Empirical results from a
prototypical implementation demonstrate substantial performance improvements
compared to existing algorithms and implementations.

1 Introduction

Among the most important relationships between the class names occurring in an ontology is subclassing: a class B is a subclass of a class A if and only if every member of B
must also be a member of A. One of the core services provided by reasoners for ontology languages is classification, the discovery of all such subclass relationships. In fact,
classification is the primary (and often the only) reasoning service exposed by ontology
engineering tools. The Prot eg e-OWL editor, for example, includes a Reasoning button which performs classification. The resulting hierarchy of subclass relationships is
used to organize classes within all aspects of Prot eg es interface, and the subclass relationships which arise as implicit consequences of an ontology are the primary mechanism authors use to check that the axioms they write are consistent with their intuitions
about the structure of the domain. Finally, other reasoning services, such as explanation
and query answering, typically exploit a cached version of the classification results;
classification is thus usually the first task performed by a reasoner.

For some less expressive ontology languages, such as the OWL 2 EL profile,1
it may be possible to derive all subclass relationships in a single computation
[Baader et al., 2005]. For OWL (2) DL, however, it is in general necessary to deduce
the set of all such relationships by performing a number of subsumption tests; each
such test checks whether or not there is a subclass relationship between two particular
ontology classes.

In this paper, we present a novel algorithm which can greatly reduce the number of
subsumption tests needed to classify a set of ontology classes. Our algorithm is also
able to exploit partial information about subclass relationshipsfor example, the set of

1 http://www.w3.org/TR/owl2-profiles/

A. Bernstein et al. (Eds.): ISWC 2009, LNCS 5823, pp. 569584, 2009.
c Springer-Verlag Berlin Heidelberg 2009

R. Shearer and I. Horrocks

subclass relationships which are explicitly stated in the ontologyto further reduce the
number of tests; our approach thus generalizes a wide range of commonly-implemented
optimizations. We further describe how a great deal of such partial information can
be gathered from the data generated by reasoning systems when performing individual subsumption or consistency tests. Finally, we present an empirical evaluation that
demonstrates the significant advantages of our techniques over the approaches implemented in existing reasoners, such as Pellet and FaCT++.

2 Overview

For a set of n classes, there are a total of n2 possible subclass relationships, thus a
na ve representation of classification results can require large amounts of storage. Most
systems exploit the transitivity of subclassing and store only the most specific superclasses and most general subclasses of each class; we call such a compressed representation a taxonomy. A taxonomy lends itself to representation as a graph or tree, often
called a class hierarchy.

It is clear that a set of n class names can be classified by simply performing all n2
individual subsumption tests, but for the tree-shaped class hierarchies typically found
in realistic ontologies much better results can be achieved using algorithms that construct the taxonomy incrementally. Class names are inserted into the taxonomy one by
one, and the correct location for each is found by traversing the partially-constructed
hierarchy, performing subsumption tests as each node of the graph is visited.

This kind of algorithm suffers from two main difficulties. First, individual subsumption tests can be computationally expensivefor some complex ontologies, even state-
of-the-art reasoners may take a long time to perform a single test. Second, even when
subsumption tests themselves are cheap, an ontology containing a very large number of
class names will obviously result in a very large taxonomy, and repeatedly traversing
this structure can be costly. This latter problem is particularly acute for the relatively
flat (i.e., broad and shallow) tree-shaped hierarchies often found in large biomedical on-
tologies. In general, subsumption tests must be performed between every pair of class
names with the same direct superclass(es), thus broad hierarchies require many such
tests. These two difficulties clearly interact: large numbers of class names require large
numbers of subsumption tests, each of which can be expensive.

The first difficulty is usually addressed by using an optimized construction that
tries to minimize the number of subsumption tests performed in order to construct the
taxonomy. Most implemented systems use an enhanced traversal algorithm due to
Ellis [1991] and to Baader et al. [1994] which adds class names to the taxonomy one at
a time using a two-phase strategy. In the first phase, the most specific superclasses of a
class C are found using a top-down breadth-first search of the partially-constructed tax-
onomy. In this phase, subtrees of non-superclasses of C are not traversed, which significantly reduces the number of tests performed. The second phase finds the most general
subclasses of C using a bottom-up search in a similar way. The algorithm exploits the
structure of the ontology to identify obvious superclasses (so-called told-subsumers)
of each class, and uses this information in a heuristic that chooses the order in which
?

?

?
classes are added, the goal being to construct the taxonomy top-down; it also exploits
information from the top-down search in order to prune the bottom-up search.2

The second difficulty can be addressed by optimizations that try to identify a subset
of the class names for which complete information about the subclass relationships can
be deduced without performing any individual subsumption tests. This can be achieved,
e.g., by identifying completely-defined classes [Tsarkov et al., 2007]those between
which only structurally-obvious subclass relationships hold. Having constructed part of
the taxonomy using such a technique, the remaining class names can be added using
the standard enhanced traversal algorithm.

In Section 3 we present a new classification algorithm that generalizes and refines the
above techniques. Our approach is based on maintaining, and incrementally extending,
two sorts of information: a set of pairs of classes A and B such that we know that A
is a subclass of B (the known subsumptions), and a set of pairs of classes such that we
know that A is not a subclass of B (the known non-subsumptions). The key insight is
that information from these two sets can often be combined to derive new information.
For example, if we know that A is a subclass of B, and that A is not a subclass of C,
then we can conclude that B is not a subclass of C. In section 3.1 we show how to
derive the largest possible set of such inferences.

Our classification algorithm is straightforward: at each stage we pick a pair of classes
A and B which does not appear in either the set of known subsumptions or the set of
known non-subsumptions, perform a subsumption test between the two, and use the result of the test to further extend the sets of known subsumptions and non-subsumptions.
Each such test adds at least one pair to one of the sets (i.e. A and B themselves). Even-
tually, every possible pair of classes is present in one set or the other, and the set of
known subsumptions thus contains all subsumptions between class names.

An important advantage of our algorithm is that

the initial sets of known
(non-)subsumptions may be empty, may include partial information about all classes,
and/or may include complete information about some classes; in all cases the information is maximally exploited. Such information can be derived from a variety of sources,
ranging from syntactic analysis of the ontology to existing classification results for a
subset of class names from the ontology (e.g. independent modules or classified sub- or
super-sets of the ontology) to data derived in the course of reasoning.

In Section 4 we show how the models constructed by (hyper)tableau-based reasoners
in the course of subsumption and satisfiability testing can be used as sources of partial
information about subclass relationships. For example, if a reasoner produces a model
containing an individual which is a member of both the class A and the complement
(negation) of the class B, then A is clearly not a subclass of B; more sophisticated analysis based on the dependency tracking structures typically maintained by tableau reasoners also allows detection of subclass relationships. The models generated by tableau
reasoners are typically very rich sources for this type of information; in fact, for ontologies which do not result in nondeterminism, including all OWL 2 EL ontologies, the
model constructed by a hypertableau-based reasoner when checking the satisfiability of

2 Other optimizations can be used to decrease the cost of individual subsumption tests
(see, e.g., [Tsarkov et al., 2007]), but these techniques are largely orthogonal to classification
optimizations.

R. Shearer and I. Horrocks

a class A will contain sufficient information to determine if A is (not) a subclass of B
for all class names B occurring in the ontology.

Our approach to partial-information derivation provides an efficient generalization
of the told-subsumer and completely-defined optimizations, both of which derive
partial information from structural analysis of the ontology. When the known (non-)
subsumption information is incomplete, our algorithm incrementally computes additional (non-)subsumption relationships, and maximally exploits the resulting information to refine the sets of known and possible subsumers; this can be seen as a
generalization of the search-pruning optimizations introduced by Baader et al..

We have used a prototypical implementation of our new algorithm to compare its
behavior with that of the classification algorithms implemented in state-of-the-art OWL
reasoners. The comparison shows that our algorithm can dramatically reduce the number of subsumption tests performed when classifying an ontology. Moreover, in contrast
to the completely-defined optimization, the behavior of our algorithm degrades gracefully as the gap between the sets of initially-known and possible subsumption relationships increases.

3 Deducing a Quasi-Ordering

We first introduce some notation and definitions that will be useful in what follows.
Given a set of elements U = {a, b, c, ...}, let R be a binary relation over U , i.e., a
subset of U  U . We say that there is a path from a to b in R if there exist elements
c0, ..., cn  U such that c0 = a, cn = b, and ci, ci+1  R for all 0  i < n.
The transitive closure of R is the relation R+ such that a, b  R+ iff there is a path

from a to b in R. The transitive-reflexive closure R
of R is the transitive closure of the
reflexive extension of R, i.e. R+  {a, a | a  U}.

A binary relation is a quasi-ordering if it is both reflexive and transitive. Clearly, the
subsumption relation on a set of classes is a quasi-ordering. Note, however, that it is not
a partial-ordering, because it is not antisymmetric: C  D and D  C does not imply
that C = D.
The restriction of a relation R to a subset D of U is the relation R[D]= R (D  D).
All restrictions of a reflexive relation are reflexive, and all restrictions of a transitive relation are transitive; thus, a restriction of a quasi-ordering is itself a quasi-ordering.
Further, if R  S for relations R and S, then R[D]  S[D] for all D  U .
Given a universe U , a quasi-ordering R over U and a finite set of elements D 
U , we consider the problem of computing the restriction R[D] via tests of the form
a, b? R. If U is the set of (arbitrary) class expressions which can be represented
in ontology language L, R is the subsumption relation over U , and D is the set of
class names occurring in an ontology O written in language L, then computing R[D] is
equivalent to classifying O, and the relevant tests are subsumption tests.
We assume that we begin with partial information about R: we are provided with a
set K = {a0, b0, ...,am, bm} where ai, bi  R for 0  i  m, and also with a
set Kneg = {c0, d0, ...,cn, dn} where ci, di  R for 0  i  n. We call the set
K the known portion of R. In this paper we do not operate on the set Kneg directly;
our presentation instead refers to its complement U  U \ Kneg, which we denote by
?

?

?
c

only if

b

a

only if

d

v

only if

u

v

u

(a) Simple cases

(b) General case

Fig. 1. Eliminating possible edges: if the solid edges are known to be in quasi-ordering R, then
the gray edges can be in R only if the indicated dashed edges are in R

P and call the possible portion of R. It is thus the case that K  R  P . If no partial
information is available, then K =  and P = U  U .
We can use the result of each test a, b? R to further refine the bounds on R by
either adding a, b to K or removing it from P ; eventually K[D] = R[D] = P [D]. We
next show, however, that the bounds on R can sometimes be refined without performing
additional tests by combining information from K and P .

3.1 Maximizing Partial Information



The key to minimizing the number of explicit tests required to discover R[D] is maximizing the information gained from K and P . To do so, we exploit the knowledge that
  R, so we can
R is a quasi-ordering. In this case, K  R obviously implies that K
to obtain a tighter lower bound on R. Less obvious is the fact that we can also
use K
obtain a tighter upper bound on R by identifying tuples in P which are not consistent
with K and the transitivity of R.
For example, consider the case shown in Figure 1(a). If we know that b is a successor
of a in R (i.e., a, b  K), then an element c can be a successor of b only if it is also
a successor of a (if a, c  P then b, c  R). Further, a can be a successor of an
element d only if b is also a successor of d.
?

?

?
and v

, requiring v

to be a successor of u

 = u or v = v
and v
?

?

?
Both of these examples are special cases of the structure shown in Figure 1(b): if u
is a successor of v, then an edge from u to v would form a
to v
. Since R is reflexive
to see that v can be a successor of u only if v is a
is also a successor of u. We use this to formalize a subset  P!K

is a successor of u
path all the way from u
we can choose u
successor of u
of P , and show that  P!K is the tightest possible upper bound on R.
Definition 1. Let K and P denote two relations such that K
reduction  P!K of P due to K as follows:
: {u
?

?

?
 P!K = P  {u, v | u

  P . We define the

, u,v, v

}  K

  u
?

?

?
  P}

, v
?

?

?
, v
?

?

?
R. Shearer and I. Horrocks
?

?

?
, v

, u,v, v

such that {u

, u,v, v
, v

  P . (i) For all quasiLemma 1. Let K and P denote two relations such that K
orders R such that K  R  P , it is the case that R   P!K. (ii) Let S be a proper
subrelation of  P!K. Then there exists a quasi-ordering R such that K  R  P and
R  S; i.e.  P!K is minimal.
}  K
Proof. (i) Let u, v be a tuple in R. For every u

,
}  R. Because R is transitive and u, v  R,
  R implies that {u

it must also be the case that u
  P . Consequently,
  R and thus that u
u, v   P!K, so R   P!K.
(ii) Choose elements a and b such that a, b   P!K but a, b  S. Let R be the
transitive-reflexive closure of the relation K  {a, b}. Clearly K  R and R  S.
Let u, v be any tuple in R. There are three cases:
1. u, v = a, b. Then u, v  P since a, b   P!K and  P!K  P .
2. u, v  K+. Then u, v  P since K
3. u, a  K
and b, v  K+. Then u, v  P since a, b   P!K.
For any tuple u, v  R, it is the case that u, v  P , thus K  R  P and R  S."
Note that  P!K itself is not necessarily transitive: given three elements a, b, and c and
the relation P = {a, a,b, b,c, c,a, b,b, c}, it is the case that  P! = P . Of
course no transitive subrelation R of P contains both a, b and b, c.

  P .

, v



3.2 Taxonomy Construction and Searching
As described in Section 3.1, given relations K and P such that K  R  P for
some unknown quasi-ordering R, a tuple a, b is an element of R if a, b  K
, and
a, b is not an element of R if a, b   P!K; the only unknown elements of R
are the tuples in  P!K \ K
, then a test of the form
a, b? R provides additional information which can be used to extend K or restrict
P . This suggests the following simple procedure for deducing the restriction R[D] of a
quasi-ordering R to domain D:

. Further, if a, b   P!K \ K







do choose some a, b  D such that a, b   P!K \ K

[D] =  P!K[D]
if a, b? R then add a, b to K

COMPUTE-ORDERING(K, P, D)
1 while K
?

?

?
return K[D]

else remove a, b from P





and  P!K in each iteration of the above loop is clearly
Completely recomputing K
inefficient. Practical implementations would instead maintain both relations and update
them as P and K change. Techniques for updating the transitive-reflexive closure of a
 
relation are well-known; we provide below a na ve algorithm that, given  P!K, K
K and P
The algorithm exploits the technique for eliminating edges that was described in
Section 3.1 and Figure 1(b): it removes a tuple u, v from the set of possible tuples

  P , computes an updated relation  P

!K.
?

?

?
).
?

?

?
, v

First,  P!K is copied to  P

!K. Then, in lines 24, each tuple u
?

?

?
, u in Figure 1(b), and one where they correspond to v, v
 in K
, then u, v is clearly not possible (it would imply that u

, v
, but u

 P!K when adding it to the set of known tuples K
would imply, due to the transitivity
of R, that some other tuple would be at the same time both known (i.e., in K
) and
not possible (i.e., not in  P
!K). This is done incrementally by considering tuples that
 \ K) or been shown to be impossible (i.e.,
have either become known (i.e., are in K
are in  P!K \ P
 that has been
, u and v, v
 in K
shown to be impossible is considered and, if there are tuples u

,
then u, v is clearly not possible either (it would imply that u
 is not only possible

, v
but known) and so is removed from  P!K. Next, in lines 513, each tuple x, y that has
become known is considered. There are two possible cases: one where x, y correspond
to u
. Lines 69 deal with
the first case: if there are tuples u, v in  P!K and v, v
, but u
 is not in

 is not only possible

but known) and so is removed from  P!K. Lines 1013 deal similarly with the second
case: if there are tuples u, v in  P!K and u

, then
u, v is removed from  P!K.
PRUNE-POSSIBLES( P!K, K, P

   P!K \ P

, v

do remove u, v from  P
?

?

?
  x and u  y
?

?

?
!K   P!K
do for each u, v such that u

do if there exists u
!K

for each x, y  K
?

?

?
let v  x and v

do if there exists v
  y

for each v such that u, v   P!K
such that v, v
then remove u, v from  P

  K
!K
do for each u such that u, v   P!K
such that u

then remove u, v from  P
?

?

?
for each u

and v, v

  K

, u  K
!K

, u  K
!K

 is not in P
?

?

?
, u in K
?

?

?
return  P

and u
?

?

?
and u
?

?

?
  P
?

?

?
, v

  P
?

?

?
, v

 \ K

do let u
?

?

?
)

, K
?

?

?
, v
?

?

?
, v
?

?

?
In the case where no information about the quasi-ordering R[D] is available other than
K and P , the COMPUTE-ORDERING procedure performs well. In many cases, how-
ever, some general properties of R[D] can be assumed. In the case where R represents
subsumption relationships between class expressions, for example, R[D] is typically
much smaller than D D (i.e., relatively few pairs of class names are in a subsumption
relationship). In such cases, it is beneficial to use heuristics that exploit the (assumed)
properties of R[D] when choosing a and b in line 2 of the above procedure.

We summarize below a variant of COMPUTE-ORDERING which performs well when
the restriction to be computed is treelike in structure and little information about the ordering is available in advance. This procedure is designed to perform individual tests in
an order similar to the enhanced traversal algorithm; however, it minimizes the number
of individual tests performed by maximally exploiting partial information.

R. Shearer and I. Horrocks

The algorithm chooses an element of a  D for which complete information about
  D of elements b for which
R[D] is not yet known. It identifies the subset V
a, b  R, and the subset V
  D of elements b for which b, a  R, updating
K and P accordingly. In order to compute these sets efficiently, we make use of the
subroutines SUCCESSORS and PREDECESSORS, which perform the actual tests. The
SUCCESSORS and PREDECESSORS functions are derived from the enhanced traversal
of the
algorithm: they perform a breadth-first search of the transitive reduction K

known subsumptions Kthe smallest relation whose transitive closure is K
. In order
, we restrict the searches to, respectively,
to avoid the cost of repeated traversals of K
the possible successors and predecessors of a. We omit the details of these search routines for the sake of brevity.

 

 

COMPUTE-ORDERING-2(K, P, D)
1 while K
?

?

?
11 return K[D]

[D] =  P!K[D]
or x, a   P!K \ K

let B be the possible successors of a, i.e. D  {b | a, b   P!K \ K
}
if B =  then V

do choose some a, x  D s.t. a, x   P!K \ K
 [B])

let B be the possible predecessors of a, i.e. D  {b | b, a   P!K\K
if B =  then V

  SUCCESSORS(a, K
add a, b to K for every element b of V
remove a, b from P for every element b of B \ V
  PREDECESSORS(a, K
add b, a to K for every element b of V
remove b, a from P for every element b of B \ V

 [B])







}





3.3 Example

Consider the process of using COMPUTE-ORDERING-2 to discover the subsumption
relation {a, a,b, a,b, b,c, a,c, c,d, a,d, b,d, d} with no initial partial information available. We initialize K to {a, ab, b,c, c,d, d} and P to {a, b, c, d}
{a, b, c, d}; this situation is shown in the left diagram of Figure 2. Each element appears
 \  P!K, so on the first execution of line 2 of COMPUTEin a tuple occurring in K
ORDERING-2 we are free to choose any element; assume that we choose d. Then SUCCESSORS performs the tests d? a, d? b, and d? c (discovering that a and b are
the only successors of d), we add a, d and b, d to K, and we remove c, d from P .
PREDECESSORS performs the tests a? d, b? d, and c? d (discovering that d has no
predecessors), and we remove each of a, d, b, d, and c, d from P . Further, because
d  a but d  c, we can conclude that a  c; similar reasoning shows that b  d;  P!K
is thus restricted to the set {a, a,a, b,b, a,b, b,c, a,c, b,c, c,d, a,d, b,
d, d}. The states of K
and  P!K at this point are shown in the left-center diagram
of Figure 2.



In the next iteration through the COMPUTE-ORDERING-2 loop we cannot choose d
\ P!K; assume that we instead choose b. The
since it does not occur in any tuple of K
only possible successor of b is a, so SUCCESSORS searches this one-element subgraph
by performing the single test b? a (which returns TRUE), and we add b, a to K. The
element d is already known to be a predecessor of b, so PREDECESSORS searches the
?

?

?
a

c

b

d

classify d

(6 tests)

a

c

b

d

classify b

(3 tests)

a

c

b

d

classify c

(1 test)

a

c

b

d

Fig. 2. As classification proceeds, known edges (denoted by solid black arrows) are discovered,
and possible edges (denoted by dotted gray arrows) are eliminated

 [{a, c}] by performing the tests a? b and c? b, finding no predecessors,
and  P!K are
\ P!K contains only the pair c, a; if we choose c in
 =  P!K.
and is shown in the right-hand diagram

subgraph K
and the two corresponding tuples are removed from P . The states of K
shown in the right-center diagram of Figure 2.
the next iteration then SUCCESSORS tests c? a, we add c, a to K, and K
The final subsumption relation is given by K
of Figure 2.



After two iterations, the set K



COMPUTE-ORDERING-2 thus classifies this ontology using 10 subsumption tests instead of the 16 required by a na ve brute-force approach. Note, however, that the results
of the seven tests a? c, a? d, b? a, b? d, c? a, c? b, and d? b are sufficient
 =  P!K, providing a full classification for
to extend K and restrict P such that K
this ontology. Identifying such a minimal set of tests is, however, extremely difficult
without prior knowledge of the final taxonomy.

4 Extracting Subsumption Information from Models

We next turn our attention to the specific case of identifying all subsumption relationships between the class names occurring in an ontology O. Instead of treating a reasoning service as an oracle that answers boolean queries of the form is A subsumed by B
w.r.t. O? (which we will write O |=? A B), we consider how information generated
internally by common reasoning algorithms can be exploited to discover information
about the subsumption quasi-ordering.

4.1 Identifying Non-subsumptions

Most modern reasoners for Description Logics, including HermiT, Pellet, and FaCT++,
transpose subsumption queries into satisfiability problems; in particular, to determine
if O |= A, these reasoners test whether the class A is satisfiable w.r.t. O. They
do this by trying to construct (an abstraction of) a Tarski-style model of O in which
the extension of A is nonempty. We begin by providing an abbreviated formalization of
such models (see Baader et al. [2003] for more details):

Definition 2. Given sets of class names NC, property names NR and individual names
NI, an interpretation I = (

and an interpretation
function I
, every element of NR to

,I) consists of a nonempty set 
?

?

?
which maps every element of NC to a subset of 

R. Shearer and I. Horrocks

I  

and every element of NI to an element of 

a subset of 
I is a model of an axiom A  B if A
of statement); it is a model of an ontology O if it models every statement in O.
is nonempty; it is a witness for the non-subsumption A  B w.r.t. O if A

. An interpretation
(similar definitions hold for other kinds
Let A and B be classes. A model I of O is a witness for the satisfiability of A w.r.t. O
I  B
?

?

?
,
if A
i.e., if there exists i  

s.t. i  A

and i  B

I  B

.

I  C

The algorithms in question typically represent the model being constructed as an ABox,
i.e., as a set of assertions of the form x : C and x, y : R for individuals x, y, classes
C, and properties R [Baader et al., 2003]. An ABox including the assertion x : C represents a model in which x
. To construct a witness for the satisfiability of a
class A, the ABox is initialised with an assertion x : A and the construction proceeds in
a goal-directed manner by adding further assertions only as necessary in order to ensure
that the ABox represents a model of O.
Assuming that the construction is successful, the resulting ABox/model provides a
rich source of information. For example, for any class B such that x :(B) is in the
; thus the model is a witness for the non-subsumption
ABox, it is the case that x
O |= A B for all such classes B. In many cases, the non-presence of x : B in the
ABox is sufficient to conclude the relevant non-subsumption; in fact, when using a
hypertableau algorithm, this is always the case. When using a tableau algorithm, the
non-subsumption conclusion can be drawn if B is a so-called primitive concept, i.e.,
if the unfoldable part of the TBox includes an axiom B  C for some concept C;
in this case, adding x :(B) to the ABox trivially results in a witness for the nonsubsumption (this is closely related to the widely employed model merging optimization [Tsarkov et al., 2007]).

I  B

The goal-directed nature of the ABox construction means that the models constructed
are typically quite small. As a result, these models tend to be extremely rich in nonsubsumption information: in a typical witness for the satisfiability of A, i.e., a model I
, there will be relatively few other class names B such that i  B
of O with i  A
?

?

?
,
and thus I will identify the vast majority of class names in K as non-subsumers of A.
For this reason, it is almost always more efficient to record the set PA = {B | i 
?

?

?
for some i} of possible subsumers of A.

and i  B

4.2 Identifying Subsumptions

While single models allow us to detect non-subsumptions, additional information about
the space of possible models is required in order to identify subsumption relationships.
Sound and complete tableau reasoning algorithms systematically explore the space of
all canonical models (typically tree- or forest-shaped models), on the basis that, if
any model exists, then one of these canonical models also exists. In particular, when
O includes disjunctions or other sources of nondeterminism, it may be necessary to
choose between several possible ways of modeling such statements, and to backtrack
and try other possible choices if the construction fails.

For such algorithms, it is usually easy to show that, if the ABox was initialized with
x : A, the construction did not involve any nondeterministic choices, and the resulting
ABox includes the assertion x : B, then it is the case that in any model I of K, i  A

Exploiting Partial Information in Taxonomy Construction

implies i  B
, i.e., that K |= A B. Moreover, as we have already seen in Section 4.1,
such an ABox is (at least in the hypertableau case) a witness to the non-subsumption
K |= A B for all class names B such that x : B is not in the ABox. Thus, when testing
the satisfiability of a class A, it may be possible to derive complete information about
the subsumers of A.
The hypertableau-based HermiT reasoner is designed to reduce nondeterminism, and
avoids it completely when dealing with Horn-SHIQ (and OWL 2 EL) ontologies; for
such ontologies it is thus able to derive complete information about the subsumers of
a class A using a single satisfiability test. This allows HermiT to derive all relevant
subsumption relationships in a Horn-SHIQ ontology as a side effect of performing
satisfiability tests on each of the class names [Motik et al., 2007].

This idea can be extended so as to also derive useful information from nondeterministic constructions by exploiting the dependency labeling typically used to enable
dependency-directed backtrackingan optimization which reduces the effects of
nondeterminism in reasoning [Horrocks, 1997]. In the resulting ABoxes, each assertion
is labelled with the set of choice points on which it depends. An empty label indicates
that the relevant assertion will always be present in the ABox, regardless of any choices
made during the construction process. Thus, if the ABox is initialized with x : A, an
empty-labelled assertion x : B in the resulting ABox can be treated in the same way as
if the construction had been completely deterministic. Performing a satisfiability test on
A may, therefore, allow some subsumers of A to be identified even when nondeterministic choices are made during reasoning. In practice, almost all of the actual subsumers
of A can usually be identified in this way.

It is easy to see that this idea is closely related to, and largely generalizes, the told
subsumer and completely-defined optimizations. For a completely defined class name
A, a satisfiability test on A will be deterministic (and typically rather trivial), and so
will provide complete information about the subsumers of A. Similarly, if B is a told
subsumer of A, then an ABox initialized with x : A will always produce x : B, and
almost always deterministically. (It is theoretically possible that x : B will be added
first due to some nondeterministic axiom in the ontology).

5 Related Work

Computing a quasi- (or partial-) ordering for a set of n incomparable elements clearly
requires n2 individual testsna vely comparing all pairs is thus optimal by the simplest standard. The literature therefore focuses on a slightly more sophisticated metric
which considers both the number of elements in the ordering as well as the width of
the orderingthe maximum size of a set of mutually incomparable elements.
Faigle and Tur an [1985] have shown that the number of comparisons needed to
deduce an ordering of n elements with width w is at most O(wn log(n/w)) and
Daskalakis et al. provide an algorithm which approaches this bound by executing
O(n(w + log n)) comparisons [2007]. Taxonomies, however, tend to resemble trees
in structure, and the width of a subsumption ordering of n elements is generally close
to n/2. Further, the algorithms of Faigle and Tur an as well as Daskalakis et al. rely
on data structures which require O(nw) storage space even in the best case, and thus
exhibit quadratic performance when constructing a taxonomy.

R. Shearer and I. Horrocks

A taxonomy-construction strategy which performs well for tree-like relations is described by Ellis [1991]: elements are inserted into the taxonomy one at a time by finding,
for each element, its subsumers using a breadth-first search of all previously-inserted
elements top-down, and then its subsumees using a breadth-first search bottom-up.
Baader et al. further refine this technique to avoid redundant subsumption tests during each search phase: during the top search phrase, a test K |=? A B is performed
only if K |= A C for all subsumers C of B [1994]. This can be seen as a special case
of our  P!K pruning of possible subsumers, with the restriction that it only applies to
subsumption tests performed in a prescribed order.

taxonomies result

The traversal algorithms described by Ellis and by Baader et al. perform subsumption tests between every pair of siblings in the final taxonomy. Such algorithms are
thus very inefficient for taxonomies containing nodes with large numbers of children;
completely flat
in a quadratic number of subsumption tests.
Haarslev and M oller propose a way to avoid the inefficiencies of these traversals by
1in Ai to
clustering a group of siblings A1, ..., An by adding the class expression
the taxonomy [2001]. Our approach can easily incorporate this technique by including partial or complete information about such new class expressions in K and P . In
practice, however, the partial information extracted from tableau models almost always
includes non-subsumptions between siblings in such flat hierarchies, so these refinements are unnecessary.
?

?

?
Baader et al. also describe techniques for identifying subsumers without the need for
multiple subsumption tests by analyzing the syntax of class definitions in an ontology:
if an ontology contains an axiom of the form A  B  C where A and B are class
names, then B is a told subsumer of A, as are all the told subsumers of B. The various simplification and absorption techniques described by Horrocks [1997] increase
the applicability of such analysis. Haarslev et al. further extend this analysis to detect
non-subsumption: an axiom of the form A  B  C implies that A and B are dis-
joint, thus neither class name subsumes the other (unless both are unsatisfiable) [2001].
Tsarkov et al. describe a technique for precisely determining the subsumption relationships between completely defined classesclass names whose definitions contain
only conjunctions of other completely defined classes [2007]. All these optimizations
can be seen as special cases of (non-)subsumption information being derived from (pos-
sibly incomplete) calculi as described in Section 4.

6 Empirical Evaluation

In order to determine if our new algorithm is likely to improve classification performance in practice we conducted two experiments using large ontologies derived from
life-science applications.

First, we compared the performance of our new algorithm with the enhanced traversal algorithm. In order to analyze how much improvement is due to the information
extracted directly from models and how much is due to our new approach to taxonomy
construction, we extend the enhanced traversal algorithm such that it first performs a
satisfiability test on every class name and constructs a cache of information derived
from the resulting models using the techniques described in Section 4. During the subsequent taxonomy construction, subsumption tests are performed only if the relevant
?

?

?
Table 1. Algorithm Comparison

Relation Size

Possible
Known
335 476
335 476
335 476 2 244 050
335 476 4 147 689
335 476 6 046 804
335 476 7 940 847
251 880
335 476
251 880 2 244 050
251 880 4 147 689
251 880 6 046 804
251 880 7 940 847
168 052
335 476
168 052 2 244 050
168 052 4 147 689
168 052 6 046 804
168 052 7 940 847

New

Tests

152 362
303 045
455 054
606 205
80 878
439 002
794 513
1 151 134
1 506 752
143 913
673 768
1 201 904
1 729 553

-

Seconds

Tests

Seconds
?

?

?
-

24 796
49 308
73 945
98 613
19 773
50 143
79 038
107 416
136 190
62 153
146 823
226 670
304 784
381 330
?

?

?
subsumption relationship cannot be determined by consulting the cache. Note that this
caching technique strictly subsumes the told subsumer and primitive component
optimizations described by Baader et al..

We implemented both algorithms within the HermiT reasoner [Motik et al., 2007]
and performed testing using an OWL version of the well-known US National Cancer Institute thesaurus (NCI), a large but simple ontology containing 27,653 classes.3
The models constructed by HermiT during satisfiability testing of these classes provide complete information about the subsumption ordering for this ontology, so both
algorithms are able to classify it without performing any additional tests. To study how
the algorithms compare when less-than-complete information is available, we limited
the amount of information extracted from HermiTs models, reducing the number of
known subsumptions and increasing the number of possible subsumptions to varying
degrees. The number of full subsumption tests required for classification as well as
the total running times (including both classification and satisfiability testing) for each
implementation are given in Table 1.

As the table shows, our simple implementation of the enhanced traversal algorithm
(ET) is substantially slower than the new algorithm even when complete information is
available; this is the result of the insertion sort behavior of ET described in Section 5.
When complete information is not available, our algorithm consistently reduces the
number of subsumption tests needed to fully classify the ontology by an order of
magnitude.

In a second experiment, we compared the implementation of our new algorithm in
HermiT with the widely-used Description Logic classifiers FaCT++ and Pellet. Both of

3 The latest version of the NCI ontology contains over 34,000 classes; the older version used

here was, however, sufficient for our purposes.

R. Shearer and I. Horrocks

Table 2. System Comparison

Ontology Classes

Tests

Seconds

Tests

Seconds Tests Seconds

FaCT++

Pellet

HermiT


?

?

?

?

?

?

?

?

?
GALEN 2749

?

?

?
2.3
4.4
5.1

-
-

-
-

10 659 876

27 653
27 653 4 506 097
27 654
27 654 8 658 610
27 655 8 687 327
48 389
27 656 18 198 060 473.9 10 746 921 1098.3 27 656
19 529 26 322 937
19 529
19 530 26 904 495
19 530
21 280 377 170.0 32 614
19 531 26 926 653
?

?

?
8.6
12.7
15.5
11.1
473.5
450.5

131 125
170 244
175 859

313 627
327 756
329 394

16.1
16.7
95.4

6.0
6.9

8.4
9.7
9.8

21.0
37.0
20.8
9.2
9.7
15.2
3.3
3.5
40.5

these systems are quite mature and implement a wide range of optimizations to both
taxonomy construction and subsumption reasoning; we were thus able to compare our
new algorithm with existing state-of-the-art implementations.

In this case, in addition to NCI we used the Gene Ontology (GO), and the wellknown GALEN ontology of medical terminology4. Both NCI and GO have been specifically constructed to fall within the language fragment which existing reasoners are able
to classify quickly; GALEN, in contrast, necessitates substantially more difficult subsumption testing but contains an order of magnitude fewer class names. In order to
estimate how the different algorithms would behave with more expressive ontologies,
for each ontology O we constructed two extensions: O
, which adds the single axiom
  R.A for a fresh property name R and fresh class name A, and O!
which adds
the axiom   A" B for fresh class names A and B. For NCI we constructed a further
by adding the axioms   R.A and C  R.B for each of the
extension NCI
17 most general class names C occurring in the ontology. Each of these extensions increases the complexity of individual subsumption tests and reduces the effectiveness of
optimizations that try to avoid performing some or all of the tests that would otherwise
be needed during classification.



The number of class names occurring in each ontology as well as the number of tests
performed (including all class satisfiability and subsumption tests) and the total time
taken by each reasoner to fully classify each ontology are shown in Table 2. The Pellet system makes use of a special-purpose reasoning procedure for ontologies that fall
within the EL fragment [Baader et al., 2005]; for such ontologies we do not, therefore,
list the number of subsumption tests performed by Pellet.

As Table 2 shows, HermiTs new classification algorithm dramatically reduces the
number of subsumption tests performed when classifying these ontologies. This does
not, however, always result in faster performance. This is largely due to optimizations used by the other reasoners which greatly reduce the cost of subsumption testing

4 All test data is available from

http://www.comlab.ox.ac.uk/rob.shearer/2009/
iswc-classification-ontologies.tgz
?

?

?
for simple ontologies: the overwhelming majority of subsumption tests performed by
FaCT++, for example, can be answered using the pseudo-model merging technique described by Horrocks [1997].

Most of these optimizations could equally well be used in HermiT, but in the existing implementation each subsumption test performed by HermiT is far more costly. The
number of subsumption tests performed by HermiT is, however, far smaller than for the
other reasoners, and its performance also degrades far more gracefully as the complexity of an ontology increases: adding a single GCI or disjunction to an ontology can
prevent the application of special-case optimizations in Pellet and FaCT++, greatly increasing the cost of subsumption testing and, due to the very large number of tests being
ontology,
performed, vastly increasing the time required for classification. The NCI
for example, eliminates any benefit from the pseudo-model merging optimization (since
no two pseudo-models can be trivially merged), and this causes the classification time
to increase by roughly two orders of magnitude for both Pellet and FaCT++. In contrast,
HermiTs classification time is unaffected. The relatively poor performance of HermiT
!
ontology is due to the fact that the underlying satisfiability testing proon the GALEN
cedure is particularly costly when there are large numbers of branching points, even if
no backtracking is actually required.



7 Discussion and Future Work

We have described a new algorithm for taxonomy construction that effectively exploits
partial information derived from structural analysis and/or reasoning procedures, and
we have shown that, when compared to the widely-used enhanced traversal algorithm,
it can dramatically reduce both the number of individual comparisons and the total
processing time for realistic data sets. For simple ontologies, our prototype implementation makes the HermiT reasoner competitive with state-of-the-art reasoners which
implement special-purpose optimizations of the subsumption testing procedure for such
cases; on more expressive ontologies our new system substantially outperforms existing
systems.

Future work will include extending HermiT to incorporate some of the subsumption
testing optimizations used in other systems, in particular reducing the overhead cost
of individual subsumption tests. We believe that this will greatly improve HermiTs
performance on simple ontologies; as we have seen, it is already highly competitive on
more complex ontologies.

The procedure we describe in Section 4 extracts subsumption relationships involving only the class used to initialize a model. This is because the dependency labeling
implemented in tableau reasoners is currently designed only to allow the application
of dependency-directed backtracking, and discards a great deal of dependency infor-
mation. We intend to explore more sophisticated dependency labeling strategies which
allow the extraction of additional subsumption information.

We also want to investigate meaningful complexity bounds for taxonomy searching
and construction tasks. As we have seen, a completely na ve search routine is optimal if
only the number of elements is considered. We will attempt to obtain tighter bounds for
certain classes of relation: relations with linear taxonomy graphs, for example, can be

R. Shearer and I. Horrocks

deduced with only n log n comparisons. Bounds based on more sophisticated metrics
may also be possible; e.g., bounds based on the size of the subsumption relation instead
of the number of elements.

Finally, preliminary testing demonstrates that when significant partial information
is available, the COMPUTE-ORDERING-2 procedure, based on the breadth-first search
of the enhanced traversal algorithm, offers little advantage over COMPUTE-ORDERING,
which performs tests in an arbitrary order; in many cases the performance of COMPUTE-
ORDERING-2 is actually worse. Investigating other heuristics for choosing the order in
which to perform tests will also be part of our future work.
