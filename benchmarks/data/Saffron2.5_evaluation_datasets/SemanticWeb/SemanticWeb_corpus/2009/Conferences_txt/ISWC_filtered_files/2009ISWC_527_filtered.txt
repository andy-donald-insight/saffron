Multi Visualization and Dynamic Query for Effective 

Exploration of Semantic Data 

Daniela Petrelli1, Suvodeep Mazumdar2, Aba-Sah Dadzie2, and Fabio Ciravegna2 

1 Department of Information Studies 

2 Department of Computer Science, University of Sheffield 
Regent Court - 211 Portobello Street, S1 4DP, Sheffield, UK 

{d.petrelli,s.mazumdar,a.dadzie,f.ciravegna}@shef.ac.uk 

Abstract. Semantic  formalisms represent content in a uniform  way according  
to  ontologies.  This  enables  manipulation  and  reasoning  via  automated  means 
(e.g. Semantic Web services), but limits the users ability to explore the semantic  data  from  a  point  of  view  that  originates  from  knowledge  representation  
motivations. We show how, for user consumption, a visualization of semantic 
data according to some easily graspable dimensions (e.g. space and time) provides effective sense-making of data. In this paper, we look holistically at the 
interaction between users and semantic data, and propose multiple visualization 
strategies and dynamic filters to support the exploration of semantic-rich data. 
We discuss a user evaluation and how interaction challenges could be overcome 
to create an effective user-centred framework for the visualization and manipulation of semantic data. The approach has been implemented and evaluated on a 
real company archive. 

Keywords: Semantic Web, semantic multimedia data, graphical visualization, 
user interaction. 

1   Introduction 

Organisational memory, the ability of an organisation to record, retain and make use 
of  information  from  the  past  to  bear  upon  present  activities  [27],  is  a  key  issue  for 
large organisations. The possibility of observing and reflecting on the past is particularly  valuable  in  highly  complex  domains  as  it  can  inform  and  sustain  decision-
making.  Civil  aerospace  engineering  is  one  example:  the  life  cycle  of  a  gas  turbine 
(commonly referred to as a jet engine) can last for 40-50 years from initial conception until the last engine is removed from service. During this long product lifetime a 
vast amount of heterogeneous data is created, i.e., text reports, numeric data, images, 
CAD  (Computer  Aided  Design)  drawings  etc.  [21].  Several  everyday  tasks  require 
engineers to engage in sense-making activities, i.e., a motivated, continuous effort to 
understand connections (which can be among people, places, and events) in order to 
anticipate their trajectories and act effectively [16]. For example, issue identification 
and resolution for jet engines (a task performed when a generalised issue is suspected 
in a product, e.g. frequent excessive wear and tear of a set of components) can require 
access  to  information  contained  in  tens  of  resources,  including  textual  repositories 

A. Bernstein et al. (Eds.): ISWC 2009, LNCS 5823, pp. 505520, 2009. 
 Springer-Verlag Berlin Heidelberg 2009 

D. Petrelli et al. 

(each containing several dozen of thousands of texts, spreadsheets, etc.), image repositories (same cardinality), raw data (a jet engine produces about 1G of vibration data 
per  hour  of  flight)  and  some  very  large  databases.  Engineers  must  go  through  the 
different repositories searching and sieving for relevant information and any piece of 
evidence that can confirm or disprove their current hypothesis, or browse for patterns 
and trends that can spark an intuition. In a word, they use dispersed and diverse data 
and information to build up knowledge about a specific phenomenon.  The task can 
last for several months [8].  

Currently the work of evidence gathering and meaning structuring is done manually 
with the support of keyword search on textual documents and querying of unconnected 
distributed databases. Keyword based querying in this domain is rather ineffective due 
to low precision/recall [17]. Moreover the long time required to read each document 
and manually abstracting the data to identify trends and their possible causes implies 
only a limited number of hypotheses can be explored.  

Semantic Web (SW) technologies can be  used to  semanticise such resources [8]. 
Semantic  information  enables  to  (i)  formalise  the  unstructured  information  in  texts, 
images  and  raw  data,  (ii)  reconcile  information  contained  in  different  information 
sources  via  a  central  ontology  or  a  series  of  interconnected  ontologies  [3]  and  (iii) 
enable information integration across resources and formats. Semantic information is 
being generated over large scale using technologies for a) ontology-based knowledge 
capture using forms [3] and b) for information extraction from text that can be ported 
to new corpora by trained final users. 

In this paper we explore the issue of browsing, querying and visualizing semantic 
information in such semantic repositories in a way that allows  users to dynamically 
explore the data during a complex task such as issue identification and resolution. The 
solution provided is based on (i) the visual contextualisation of semantic information 
according to some easily graspable dimensions (e.g. space, time and topology) and (ii) 
the  browsing  of  the  displayed  information  by  querying  the  knowledge  base  via  dynamic  filters  that  modify  the  visualization  in  order  to  focus  on  possible  trends  and 
patterns. This approach enables exploration of information and data currently highly 
challenging  with  existing  technologies  (especially  commercial  keyword-based  sys-
tems) that could save thousands of hours a year of valuable resources to a company. 

The  paper  is  organized  as  follows:  Section  2  overviews  related  work.  Section  3 
discusses the framework, section 4 the design rational, and section 5 provides some 
details on the implementation. Section 6 presents the user evaluation and our findings. 
An outline of the future work concludes the paper. 

2   Related Work   

Visualization is required whenever humans need to discover and reason about complex combinations of high volumes of data (e.g., [5]). Information visualization and 
visual data mining is not limited to the display, but aims at supporting human perceptual abilities during the data exploration process [15]. A vast literature exists on the 
topic. Cluster visualization has been used in such diverse fields as intelligence (i.e. to 
show  correlation  between  people  [36])  and  image  collection  access  (i.e.  to  show  
similarity in images [10]). Alternative visualizations have been used to make easy to 
?

?

?
identify patterns in homogeneous data (e.g. in geospatial data [1]); multiple visualiza-
tions, instead, map the strength of relationships between elements [4]. In text retriev-
al,  much  research  has  investigated  the  visualization  of  search  results  (see  [12]  and 
[13] for an overview), the visualization of the whole document collection (e.g., Treemaps [35]) or a large text corpus (e.g. Jigsaw [26]). Information exploration, an openended process that is iterative and multi-tactical [18, 33] is currently gaining interest 
and stimulating new user interactions beyond traditional text search [34, 24]. 

The issue of visualization of Semantic Web (SW) data has been recognized since 
the publication of the seminal book [11]. A tension exists: the Semantic Web emphasises formal, machine readable [...] approaches. It focuses on the formal and even the 
meaning achieved through rigorously defined forms. In contrast, information visualization  emphasizes  the  semantics  and  the  meaning  that  can  be  conveyed  by  visualspatial models to the users. [6]. Much research effort in semantic-based visualization 
has  been  spent  on  finding  ways  of  visualizing  complex  graphs  that  derive  from  the 
interlinking of semantic data, the relation between different concepts [28], the different granularities [31], and (dis)connections [19]. The result is a large number of on-
tology-based visualization systems (some are reviewed in [9]).  

More recent research has tried to make use of the special features of RDF to provide end-users with intuitive ways of accessing semantic data. BrowseRDF [20] uses 
the  faceted  browsing  paradigm:  facets  are  generated  automatically  from  the  data  it-
self; the user can constrain one or more of the faceted provided to filter the data set.  

Similarly,  mSpace  [23]  sequences  lists  of  facets,  the  item  selected  in  a  list  constrains the following step. Users can combine facets in different ways: this allows an 
intuitive composition of complex filters for the purpose of exploration.  

In IVEA [30, 31] the user creates their own view over a text collection by dragging 
and dropping ontology concepts onto a scatter plot panel. The filters provide a multidimensional view of the document collection as a matrix with colour coded values.  

Exhibit, as part of the SIMILE Project1, provides an interactive, web-based visualization widget developed to demonstrate the application of SW technologies to heterogeneous  metadata.  It  interlinks  geographical  mapping  and  a  timeline  to  display  
information about the USA (past) presidents, e.g., place of birth, term(s) in power, etc. 

3   A User-Interaction Framework for Semantic Data Exploration 

In a SW framework, information in text, images, tables and other forms of data can all 
be  captured  and  mapped  to  ontology  concepts,  instances  or  relations  and  be 
represented as triples. SW technologies can pull together heterogeneous material in a 
single unified form and create a single organizational memory out of many different 
and  scattered  archives.  However,  SW-based  organizational  memory  can  be  huge 
when derived from very large collections, encompassing dozens of repositories containing tens of thousands of documents which in turn produce millions or billions of 
triples. A real problem in knowledge discovery occurs when making use of such extremely large data set as no human could be expected to hold all the information in 
their mind. Specific tools that help users explore the knowledge and draw hypotheses 

                                                           
1 The SIMILE Project: http://simile.mit.edu; Exhibit: http://simile.mit.edu/wiki/Exhibit 

D. Petrelli et al. 

from it are essential for effective  use of SW-based organizational  memory. This requires the following fundamental steps: 

1.  The RDF repository has to be planned to support effective human interaction: 
Triples may not hold any context if it has not been captured, e.g. it is impossible to plot triples by time if the date is not there; A single ontology should map 
heterogeneous material into a single representation.  

2.  The  visualization  has  to  be  intuitive  to  properly  contextualize  semantic  data 
and  the  interaction  tools  have  to  be  easy-to-use  to  support  exploration  and 
knowledge discovery, e.g. space and time contextualize semantic data in an in-
tuitive, factual way.  

3.  Tools to facilitate data annotation should be smoothly integrated in the interaction flow to guarantee a sustained improvement of the quality of the repository 
along its use, especially when data is generated using automated means (e.g. 
by applying information extraction on legacy data).  

In this paper we focus on the second point and propose the use of multiple visualizations as a way to help users explore, discover and reason; find confirmation of their 
intuition; and drill down to the data level when needed.  

As discussed in the next section, the dimensions of visualization should come from 
the ontology and the values for each dimension from the semantic repository. Dimensions should be then mapped onto a structure that is appropriate for the final user. For 
example the dimension date can be structured as a linear timeline (as done in this 
work)  or  as  a  calendar,  e.g.,  to  visualize  publications.  Both  visualizations  map  the 
same semantic data but serve two very different user purposes.  

Some dimensions are generic and likely to be valid across a wide range of applica-
tions. This is the case of time and space. Other dimensions are valid across a subset of 
domains,  for  example  this  paper  uses  topology,  useful  in  engineering  where  a  machine  of  some  sort  is  the  core  of  the  domain  ontology.  Finally  the  user  may  define 
their own perspective, e.g., time and a continuous attribute could be plotted to facilitate the monitoring, for example, of financial markets.  

4   Knowledge Visualization and Manipulation  

For data and information visualization, Shneiderman advocated tools that provide the 
user  with  a  progressive  focus:  overview  first,  zoom  and  filter,  then  details-on-
demand [25]. The overview is to gain a sense of the whole data set; zoom and filters 
are used to focus the attention on (potentially) interesting patterns; details on demand 
to drill down to the level of single data and carefully inspect the content.  

This section discusses our proposal for a concrete visualization of semantic data. 
This visualization complements ontology-based visualization, as it reduces the cognitive effort needed to understand the semantic data.  

We adopted a user-centred iterative design approach [8]. The design rationale discussed  in  the  next  section  emerged  after  workshops  and  observations  with  users 
aimed at collecting requirements, and a number of participatory design sessions with 
engineers in which layout and interaction were refined to maximise their usefulness. 
In opposition to the generic trend of using a single visualization to display semantic 
?

?

?
data and its connection, we contextualize data in multiple, complementary and inherently different  visualizations  where each  view offers a  perspective over the data: 
the user dynamically filters the data and moves from one view to another while following a personal investigation trial. 
 

 

Fig.  1.  The  triple-store  displayed  on  a  world  map  -  dots,  flags  and  notes  add  meaning.  The 
numbers in the map indicate the number of cases found per location. The filters used are identical to those in Figure 2. 

Figure  1  shows  the  GeoPlot  of  34,750  triples  extracted  from  4,958  event  reports 
that are part of Rolls-Royces organisational memory2. The extracted triples are displayed on a world map showing the distribution of events; the size of the dots codifies 
the  number  of  events.  Flags  and  comments  can  be  added  to  keep  track  of  personal 
intuition during the sense-making process.    

Fundamental for effective exploration is the dynamic update of the display when 
the user manipulates the filters, called dynamic querying [2]. The filters (Fig. 2, left) 
allow the user to quickly set the parameters of interest and immediately see the effect 
on  the  display  (Fig.  2,  centre).  The  filters  interactive  features  depend  on  the  data 
type:  a  slider  to  set  a  range  for  numeric  data;  a  text  field  to  enter  codes;  a  single 
selection list items and group of check boxes for multiple selection. The result of the 
filtering is dynamically plotted: in Figure 2 the blue (darker) crosses match the query 
                                                           
2  These  are  just  a  fraction  of  the  triples  that  we  generated  from  Rolls-Royce  organisational 
memory. They were extracted by semi-automated information extraction and machine learning as part of a general effort to semanticise their legacy data. The final data set holds several 
hundreds of thousands of documents and covers several different types: one-page reports sent 
from all airports in the world covered by the Rolls-Royce service agreements, extended reports of workshop inspections, technical updates, workshop photos, tables, etc. 

D. Petrelli et al. 

(multiple  filtering),  while 
Filters  on  one  visualization
maintain consistency. The 
dimensions,  but  the  Time
be  dynamically  changed  u
(Figure 2, right) onto the pl
 

the  gray  (lighter)  ones  are  triples  outside  the  result 
n  are  applied  to  all  the  others  simultaneously  in  order
geographical and the topological visualization needs t
eLine  is  uni-dimensional  and  therefore  the  Y  axis 
using  drag-and-drop  with  any  concept  from  the  ontolo
lot.  

set. 
r  to 
two 
can  
ogy 

Fig. 2. The dynamic query  fil
is  time,  the  Y  axis  is  the  num
documents. 

lters (left) set the values  for the TimeLine (centre). The X-A
mber  of  airframe  cycles;  the  top  right  the  number  of  match

Axis  
hing  

 

Fig. 3. The TopologicalPlot: e
to  zoom-in  a  more  detailed  v
Numbers  is  blue  show  the  tot
same as in Figure 2. 

ach component in gray in the Engine Map (left) can be clicked
view  of  the  information  associated  to  its  subcomponents  (rig
tal  count  of  issues  identified  per  component.  The  filters  are

d on 
ght). 
e  the 

 
?

?

?
A third visualization  uses topological information, in our case a TopologicalPlot, 
as  intuitive  dimension  to  plot  triples.  Figure  3  left  shows  an  engine  overview:  gray 
areas correspond to high-level ontology concepts. Hovering on an area shows a summary of the documents mapped to this engine part; clicking on the area opens a detailed map of that part where the documents are plotted, Figure 3 right, respect to finer 
grained concepts, the engine components. Their position is as faithful as the ontology 
allows, that is to say, the finer the grain of the ontology concept the more precise the 
position of the cross on the graph. 

The  three  visualizations,  TimeLine,  GeoPlot  and  TopologicalPlot  show  the  same 
data with respect to different dimensions that complement one another. The structure 
itself can be semantically enriched therefore adding new knowledge to the visualization  that  is  not  present  in  the  data,  i.e.  providing  semantic  services  attached  to  the 
world map. The visualization could be enriched father by coding properties the user 
wishes to monitor in a more salient and graphical way, e.g., suppose the user is interested in instances of the concept wear, an event often associated with sand friction, 
then  these  events  could  be  highlighted  in  red  and  a  GeoPlot  can  easily  show  their 
pattern in deserts regions. 

5   Implementation  

The starting point is an existing semantic repository (triple store) and its related on-
tology; interactive filters are automatically generated on the basis of the data found in 
the ontology. Data tables are created where each row is a document in the dataset, and 
each column is a concept annotated within the document. In Figure 4, the attributes 
hasFormattedEventDate,  hasLocation,  hasComponent  are  extracted  to  build  Time-
Line, GeoPlot and TopologicalPlot respectively.  
 

<rdf:Description 

rdf:about="http://kmi.open.ac.uk/projects/xmedia/RR1.owl#Event_Report.BKK.Event_Report_237"> 

<rdf:type rdf:resource="http://kmi.open.ac.uk/projects/xmedia/RR1.owl#Event_Report"/> 
<j.0:has_file_location>BKK/Event_Report_237</j.0:has_file_location> 
<j.0:hasFormattedEventDate>26-Jul-1922</j.0:hasFormattedEventDate> 
<j.0:hasEventDate>26-Jul-22</j.0:hasEventDate> 
<j.0:hasAssociatedDate>28-Aug-22</j.0:hasAssociatedDate> 
<j.0:hasTSN>14613</j.0:hasTSN> 
<j.0:hasEngine_Serial_Number>ESN12345</j.0:hasEngine_Serial_Number> 
<j.0:hasLocation>BKK</j.0:hasLocation> 
<j.0:hasRegime>GROUND</j.0:hasRegime> 
<j.0:hasCSN>5362</j.0:hasCSN> 
<j.0:hasComponent>Fuel Metering Unit</j.0:hasComponent> 
</rdf:Description>  

Fig. 4. An example of the annotations of a document in RDF format. (Values shown are realistic but fictitious and do not correspond to a real instance of an Event Report.) 

While  only  some  of  the  ontology  concepts  and  relations  become  visualization 
structures, all of them become filters. The data table is read and each column is converted into a graphical widget, which one depends on its value range. A core set of 
filters,  with  different  interaction  affordances,  is  used  to  capture  different  aspects  of 

D. Petrelli et al. 

the data set: sliders are used to define ranges of continuous data; text input is used to 
capture  meaningful  strings,  e.g.  engine  serial  number;  check  boxes  and  menus  for 
selections in a closed set, e.g., hasTSN and hasCSN are mapped onto a slider; hasEngine_Serial_Number uses a text field; hasRegime uses a group of check box. 

Different toolkits have been used to build the visualization modules. Prefuse [14], 
an  interactive  visualization  toolkit  with  sophisticated  visual  features  is  used  for  the 
TimeLine. The X-Axis represents time, and the Y-Axis a  continuous numeric value 
such as CSN ([flight] cycles since new). The user can dynamically change the Y-Axis 
concept  using  drag-and-drop  from  the  ontology.  This  enables  all  the  ontology  concepts to be plotted against the timeline. A visibility filter controls the display of each 
visual item: the ones in the filtered set are highlighted, the others are greyed out.  

The  GeoPlot  visualization  is  generated  using  the  JXMapKit  API  that  plots  geographic  coordinates  on  a  world  map  downloaded  from  OpenStreetMaps.com.  The 
geographic locations are airports, identified by their IATA (International  Air Transport Association) codes, as extracted from the dataset. The IATA codes are used to 
automatically find the airport details such as geo-coordinates (used in the plot), airport 
name,  city  and  country.  The  size  and  colour  of  the  waypoints  are  calculated  on  the 
number of visual items associated with the airport.  

The Topological Plot is composed of two interactive maps manually created using 
drawings  from  an  engine  user  manual.  For  the  top  level,  selected  regions  are  annotated with high-level ontology concepts corresponding to the engine parts, each showing  the  number  of  visual  items  associated  with  the  concept.  A  detailed  view  of  the 
part  is  displayed  on  click;  this  drawing  too  has  been  manually  annotated  with  finer 
grained concepts from the ontology that corresponds to engine components. Although 
the  maps  have  been  manually  created  it  is  easy  to  imagine  a  situation  in  which  the 
CAD drawings of an engine has semantics associated and therefore the generation of 
the maps is automatic.  

6   User Evaluation 

The usability of the visualization and manipulation was carried out. Results are used 
to adjust and re-design the system before it is deployed for a monitored field trial at 
Rolls-Royce plc as an additional support to  actual investigations. While the trial allowed us to measure the impact this technology has on real practice and observe its 
use in a naturalistic setting, the user evaluation reported here focuses on assessing its 
usability, that is to say to find out what works and what instead could be perfected. 
This evolutionary approach to user evaluation, from lab to the field, has proved to 
be robust for the development of new technology for professional use [22].  

6.1   Setup and Procedure 

The user evaluation was set up to assess the usability of the visualization and dynamic 
querying  of  semantic  data.  12  participants  took  part  in  the  evaluation  and  were  recruited by acquaintance, they were 4 women and 8 man, their age ranged from 25 and 
45, they were PhD students and researchers; 3 participants were aware of information 
visualization tools but none had used any. As the time of professional engineers is a 
?

?

?
limited resource and the focus of this evaluation was the usability we considered the 
sample  acceptable  for  the  goal  at  hand.  Participants  carried  out  a  number  of  small 
tasks to determine if: 

1.  The visualization mechanisms supported knowledge discovery: patterns were to 

be found in the data that could represent phenomena of interest; 

2.  The dynamic queries were intuitive to use: participants were required to manipu-

late different types of filters, slider, checkbox, text; 

3.  The overall visualization and dynamic queries strategy were usable. 

 
The test was done individually. At arrival participants were introduced to the project 
and the purpose of the user evaluation. They were talked through the main features of 
the  visualization  and  manipulation  by  an  evaluator.  Then  participants  familiarized 
themselves with the system using 7 simple, 1-step tasks covering the three visualizations and the filters. An indication of which visualization(s) was the most appropriate 
and  how  to  use  it  (them)  was  given  for  each  task.  During  the  training  participants 
could  ask  for  explanation  or  support  from  the  experimenter.  Participants  were  then 
requested to carry out another 8 tasks on their own: each of these tasks asked the user 
to perform 2 or 3-steps, for a total of 18 steps. These tasks were slightly more complicated than the training to stimulate more articulated interactions and were designed to 
test different aspects of the system. Flexibility is a key point for user acceptance and 
we wanted to find out if our solution accommodated personal attitudes. Task distribution  per  visualization 
in  Table  1,  T-TimeLine,  G-GeoPlot,  E-
TopologicalPlot, and ALL the visualizations; C-F is for commenting and flagging in 
the GeoPlot. 

is  reported 

The tasks were designed for users with no expertise on jet engines and did not require participants to understand the content of the documents that could be displayed 
on click. As users were not experts they were not required to identify trends directly, 
however the tasks used simulated the ones that an engineer will perform in order to 
identify trends. They generally required to identify (geographical, time or topological) 
areas where the count of events was either clearly above average or had specific cha-
racteristics. Most tasks were cumulative (i.e. they built on the results of the previous 
tasks) so to simulate a multi-step investigation.  

Examples of cumulative tasks are3: 

a)  How  many  documents  refer  to  the  registration  number  

9V-SQD with number of airframe cycles >6500? 

b)  Consider  only  what  happened  in SIN (Singapore),  how  many 

events occurred there? 

c)  Which component seems to have the highest number of cases 

associated with the flight regime CLIMB? 

These  tasks  required  the  use  of  the  different  tools  and  strategies  while  performing 
each query:  

a)  The registration number requires entering text in a form field, setting an 

airframe cycle number requires manipulating a slide.  

                                                           
3  Tasks are simplified here for the sake of clarity of exposition. Task b) was to be performed on 

the results of a); c) was to be performed on information retrieved in b). 

D. Petrelli et al. 

b)  Requires to interpret the previously retrieved data by focussing on a spe-

cific area of the GeoPlot 

c)  Requires now to move to the topological display and to drill down to the 

level of components. Flight regime is a checkbox.  

 
The  tasks  enabled  to  measure  all  the  available  interactive  features  in  a  limited  test 
time  of  30-40  minutes.  During  the  test  the  screen  activity  was  recorded  for  further 
data analysis. 

At the end of the evaluation participants were requested to fill in a user satisfaction 
questionnaire composed of 16 closed and open questions. Close questions were on a 
5-points  scale  and  addressed  the  system  overall,  its  learnability,  the  task  flow,  the 
result display, the systems speed and reliability. Open questions asked about the most 
positive and negative aspects of the system. No questions focussed on comparison of 
visualizations as all three have been seen in use during the user requirements phase: 
timelines in presentations to summaries observed phenomena; geographical information was reported as one of the first inquiry done; and maps of the engine covered in 
post-it  and  annotations  hung  in  meeting  rooms.  We  are  therefore  confident  on  the 
usefulness of all three. 

6.2   Analysis and Results  

The results are analysed with respect to: efficiency, effectiveness, and user satisfaction (as in the ISO definition of usability [32]). Minor issues of interface inconsistency across the three visualizations were also identified, e.g. display of the number of 
results in the set displayed in different positions in the three panels. Both objective, 
numeric data, and subjective data, participants opinion, have been analysed. Qualitative  analysis,  i.e.  observation  of  participants  interaction,  has  been  used  to  explain 
qualitative results, i.e. statistic on numeric values.  
 
Efficiency has been calculated on the time participants needed to finish a task (that 
could include few different steps). Performance in both training and test varied greatly 
from task to task and from participant to participant, and from a min of 18 sec. to a 
max of 420 sec. Table 1 shows this variability by task, Table 2 by participants. The 
average time to complete a test task (including the time to think how to solve the task) 
was 87 sec. The average time for a simple 1-step training task was 67 sec. while the 
average  time  spent  for  complete  1-step  during  the  test  was  46  sec.  showing  an  increase in efficiency after only an average of about 8 minutes training. The good efficiency is reflected on participants opinion collected in the questionnaire: 82% rated 
the system speed very high.  

On average, interactions with the GeoPlot lasted longer than other visualizations: 
T= 147 sec.; G=200 sec., E=138 sec. (cumulative  values  for participant, task only); 
however this is not statistically significant (one-way repeated measures ANOVA on 
time on T, G and E). Observation of the interaction shows that some users had difficulties in manipulating the GeoPlot: when zooming-in they were too fast and found 
themselves, for example, in Africa instead of Europe. Then, instead of zooming-out 
they preferred panning, an action that requires more time. 

Table  2  shows  the  average  time  per  participant.  Variability  among  participants 
emerges during task with a polarization in two groups. Observations of the interaction 
 
?

?

?
namic Query for Effective Exploration of Semantic Data 

Table  1.  Time  on  task  in  se
was  designed  to  test  some  fe
proach.  The  letters  in parenth
types of tools that the user wa
to perform the task in an app
the  users  used  at  least  the  e
carry out each task. 

conds.  Each  task 
eatures  of  the  apheses  describe  the 
as expected to use 
ropriate  way.  All 
expected  tools  to 

Table  2.  Average  time  per  task  for  e
participant 

each  

 

 

t strategies with faster participants setting all the filter
he  visualization  and  the  slower  participants  going  step
of one filter then look at the result than set a second fil
ot requested during training. Flexibility of use is one of 
data exploration environment; therefore we consider th
r could adopt personal strategies despite time difference

rs at 
p  by 
lter. 
f the 
his a 
es. 

on the accuracy of the answer provided as every task ha
n advance. In 74% of tasks the exact answer was provid
2% when the simpler tasks of the training set are includ
near miss, i.e. participants incorrectly selected a value
rong value for a filter due to very similar spelling. Mi
re  needed  to  avoid  unintended  mistakes.  Moreover  we
ling  problems  in  field  use  as  users  knowledgeable  in 
e  terms.  Effectiveness  was  also  affected  by  data  dens
of zooming-in to gain a clearer view selected the wrong

ad a 
ded. 
ded. 
e on 
inor 
e  do 
the 
sity: 
g set 

behaviour showed different
once  and  then  exploring  th
step, i.e. setting the value o
Multi filter selection was no
main requirements of any d
positive result showing user
 
Effectiveness is calculated 
correct answer identified in
The effectiveness rises to 8
All wrong answers were n
the slide or selected the  wr
changes  in  the  interface  ar
not  expect  to  see  any  spel
domain  would  not  mistake
some participants instead o
in dense GeoPlot display. 

Overall the approach em
a triple store, as the mistake
confirmed  by  the  fact  that 
condition, i.e. visualization 
 
User Satisfaction. Overall 
easy  (64%),  satisfying  (64
While this result shows a v
mulating judgement), it als

merges as effective in supporting the user browsing throu
es were due to interface issues that are easily fixable; thi
t  the  errors  were  scattered  and  not  linked  to  any  spec
or user.  

ugh 
is is 
cific 

participants opinion was positive; the system was jud
4%),  stimulating  (82%),  fast  (82%),  and  reliable  (91
very high level of engagement and trust (mainly in the 
so points out to usability problems due in part to (i) so

dged 
%). 
sti-
ome 

D. Petrelli et al. 

sub-optimal  interaction  strategy  participants  adopted  to  perform  the  tasks  and  (ii) 
interface limitations, that will be discussed below. Discussion with users showed that 
the latter accounted for the largest majority of the difficulty the user found (affecting 
the judgement on ease of use and their satisfaction). The dissatisfaction  was  not related to the general idea and users commented that  if the issues were fixed  their 
judgement would have changed.  

Both issues above can be easily addressed: the first with a more extended training 
(which  will  be  in  any  case  given  to  the  engineers);  the  second  by  re-designing  the 
weak points in the interface.  

Three questions addressed learnability: participants judged it easy to learn (82%), 
easy  to  explore  (75%)  and  straightforward  to  use  (63%). This  last  value  was,  again 
influenced by the same difficulties in manipulating some graphical elements. The task 
flow was considered easy to start (73%) and carry on (90%) while the manipulation of 
the results was problematic for some of the participants. 35% found the manipulation 
easy or very easy, 45% were neutral and 20% considered it difficult. Again, there is a 
dichotomy  in  judgement  between  the  recognized  value  of  the  tool  and  the  practical 
difficulties in manipulating it. Observations of the interaction and the comments left 
in  the  questionnaire  most  negative  aspects  explain  this  fact:  as  the  values  on  the 
interface come from the RDF data, the values on the slide were not continuous nor the 
progression smooth. This was quite confusing for some participants who tried hard to 
set the slide to an inexistent value, e.g. the first value for airframe hours (Figure 2) is 
4350  but  the  slide  starts  from  0  so  there  is  no  change  in  the  display  until  the  user 
scrolls to 4350, that is halfway through the slide. This point can be fixed in the redesign by creating a tagged-slide that highlights the valid values (from the RDF) on a 
standard continuous slide. 

The judgement on the browsing of the results was split: 45% judged it easy, 45% 
were  neutral  and  10%  find  it  difficult.  Observing  the  interactions  we  noticed  that 
participants  who  lamented  difficulties  had  problems  in  selecting  the  right  graphical 
element: In the GeoPlot dots representing two different airports could overlap making 
it  difficult  to  select  one  airport  over  the  other.  When  the  overlap  occurs  the  correct 
interaction  is  to  zoom-in  but  some  participants  did  not  use  it  despite  having  been 
demonstrated  the  feature  before  the  test.  Another  point  of  difficulty  occurred  when 
documents were very dense, as for some engine components. I this case the zoom-in 
(enlarging the picture) is not effective in discriminating instances as the action does 
not add further details. A further level in the ontology would allow mapping to a more 
detailed drawing of the component and therefore a finer localization of the triple on 
the  engine  spatial  representation.  Alternatively  instances  can  be  listed:  selecting  an 
element highlights its position on the map and double clicking would open it. 

Two open questions asked for the most negative and more positive aspects of the 
system.  Besides  the  already  mentioned  problems  with  the  slide,  listed  as  negative, 
participants did not like to scroll up and down the filters (the list can indeed be very 
long if filters like the airport location is left open) and found some of the filters name 
cryptic. This last comment does not hold for professional engineers, as they are familiar with the data.  

Appreciated across the whole sample was the tidy design of the interface, its intuitiveness  and  the  instantaneous  reaction  and  change  of  display  after  a  new  filter  has 
been set, all features listed in the open question most positive aspects. In addition 
?

?

?
participants  commented  positively  the  fact  that  the  filter  manipulation  changes  the 
three visualizations simultaneously therefore supporting an active engagement in the 
data exploration activity by simply swapping view. 

6.3   Discussion 

The user evaluation showed that the approach is efficient and effective and the interaction  largely  intuitive  even  with  very  limited  training.  Users  found  the  approach 
stimulating and were able to identify trends in the data via interactive querying. The 
methodology used showed this in an indirect way: as participants were not experts in 
the domain, the tasks simulated the querying path that an expert would follow in order 
to identify trends. The simulated exploration paths have been observed and discussed 
with users, therefore the successful completion of the tasks would provide material to 
an expert for the identification of trends.  

Some limited aspects of the interface needs some degree of re-design as the simple 
action  of  taking  the  data  out  of  the  RDF  repository  and  into  the  user  interface  may 
produce  a  less-than  optimal  interaction,  i.e.  slides  dont  have  a  smooth  progression 
but  more of a  jumpy interaction style. Data-generated interactive  filters and dense 
data  display  need  careful  considerations  and  specific  interaction-design  strategies 
particularly  when  scaled  up  to  hundreds  of  thousands  of  triples  displayed.  Indeed 
what appeared to be critical is the combination of very dense semantic data onto small 
space and the tendency of participant to not zoom-into the detail to clarify the vision. 
A research question concerns efficiency and effectiveness with respect to the technology  currently  available  to  our  final  users.  We  believe  that  the  approach  has  the 
potential to save thousands of hours a year of search time (efficient) and to provide a 
way  to  more  widely  explore  different  hypotheses  and  therefore  to  discover  more 
trends  and  patterns  (more  effective).  We  derive  this  by  reflecting  other  evaluations 
where users performed similar tasks using other types of technologies, both semantic 
and  more  traditional.  Performing  the  same  tasks  using  traditional  keyword-based 
searches  would  have  required  several  weeks  of  searching  and  manually  collating 
information4. Also, our approach is more effective because as side effect of efficiency 
users  are  enabled  to  explore  different  hypotheses  and  therefore  to  discover  more 
trends and patterns. Such extensive exploration is currently largely impossible due to 
the scarce efficiency of the current methodologies (exploring more hypothesis means 
more time dedicated to the analysis, an often impossible task under the time pressure 
that  some  knowledge  management  tasks  are  worked  under).  Moreover  traditional 
methods  carry  imprecision  due  to  tiredness,  which  affects  the  quality  of  results  on 
very long task.   

Performing the same tasks with a semantic search-based system (e.g. [17]), would 
have required some days of work to extract different pieces of evidence and to group 
them  manually  around  trends5.  Questions  like  which  component  reported  most  
issues would have required several dozens of queries.   

                                                           
4  This  estimate  is  based  on  discussion  with  real  users  and  direct  observation  of  working 

practices.  

5  This estimate is based on observation of search behaviour of users during the evaluation of 

the semantic search system.  

D. Petrelli et al. 

7   Conclusions and Future Work 

In this paper  we proposed to complement  the ontology-based, graph-based perspective  with  views  that  contextualise  the  concepts  into  vertical  dimensions,  like  time, 
space and topology.  The list of dimensions that could be used for this purpose is not 
exhaustive  and  others  than  those  we  used  could  be  identified  (mostly  domain-
specific). The different visualizations are created starting from the RDF data and, like 
a kaleidoscope, show different views on the same data set. Direct manipulation complements the display and engages users in the exploration: dynamic queries generated 
from the data are used to instantaneously change the visualizations.  

Our  aim  was  to  provide  a  largely  automatic  way  to  visualize  semantic  data  and 
support users in dynamic exploration and manipulation. We used the case of an existing  organisational  memory  and  complex  knowledge  management  tasks  observed  in 
real work situations, i.e., issue identification and resolution in aerospace engineering. 
The user evaluation has demonstrated that this automatic  mapping of  multiple, context sensitive visualizations to ontology-based information stores provides an efficient 
way  to  display  the  result  of  complex  queries  that  can  combine  several  attributes. 
Moreover users can explore the result and effectively detect patterns and trends. The 
combination  of  powerful  multiple,  contextual  visualizations  and  a  highly  dynamic 
interaction allows the exploration of semantic data to be carried out at scale. We have 
shown how our visualization approach improves in terms of efficiency and effectiveness  with  respect  to  technologies  that  are  currently  available  to  our  users,  i.e.  key-
word-based  search  and  semantic  search.  To  our  knowledge  this  is  the  first  study  to 
show that  using  multiple visualizations  is effective  for document  sense  making in a 
complex organisational memory.  

In our experience large organizations are willing to invest in semantic technologies 
for knowledge management, if they see a clear benefit and it is sustainable. The set of 
4,958 documents used in this study correspond to a small chunk of the archives  we 
are currently considering in the context of Rolls-Royce plc, but was instrumental to 
show the clear benefit of this innovative technology over the current practice. At the 
time of writing we are working in partnership with the company to extract information  from  large  and  heterogeneous  archives  and  create  a  new  semantic  data  set  to 
support a field trial in the context of real practice. In the perspective of sustainability, 
we have already developed a technology to provide ontology-based knowledge capture using forms [3] and  we  are studying information extraction  methodologies that 
can be ported to new corpora by a trained final users. In light of the experience above, 
the  approach  and  tools  proposed  in  this  paper  are  deemed  extremely  useful  as  they 
allow engineers to rapidly make sense of the information and data.  

The next prototype will incorporate the changes in the user interface pointed out in 
this study and will be applied to a larger and heterogeneous data set with the perspective on incrementally increase the size of the repository when new semantic data will 
be made available. Tests done on much larger document repositories show no particular  strain  on  the  technique  adopted.  A  field  trial  at  Rolls-Royce  premises  in  Derby, 
UK, with the new prototype and new data is planned for the autumn and will last for a 
few months.  
?

?

?
Acknowledgments. The work reported in this paper is part of the X-Media (www.x-
media-project.org)  project  sponsored  by  the  European  Commission  as  part  of  the 
Information Society Technologies (IST) programme ISTFP6-026978. We are grateful 
to  Mr.  Ravish  Bhagdev  for  providing  the  triples  and  the  participants  who  took  part  
in  the  evaluation.  We  are  indebted  to  Mr.  Andy  Harrison,  and  Mr.  Colin  Cadas,  
Rolls-Royce  plc.,  for  their  continuous  support  and  fruitful  discussions.  Finally  we 
thank the anonymous VC for their useful comments and their encouragement.  
