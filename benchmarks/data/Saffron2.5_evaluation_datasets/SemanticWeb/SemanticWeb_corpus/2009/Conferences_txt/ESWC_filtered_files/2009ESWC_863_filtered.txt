Utilizing Semantics in the Production of iTV Shows 

Georg Guntner, Dietmar Glachs, and Rupert Westenthaler 

Salzburg Research Forschungsgesellschaft m.b.H. 

Jakob Haringer Strae 5/III, A-5020 Salzburg, Austria 

{georg.guentner,dietmar.glachs, 

rupert.westenthaler}@salzburgresearch.at 

Abstract. This paper gives an overview of the semantic aspects of an advanced, 
semantics-based broadcasting production support system designed to enable the 
creation  of  interactive  multi-channel  television  shows.  The  Intelligent  Media 
Framework  forms  the  middleware  of  this  system  and  was  developed  in  the 
context of the European integrated project LIVE. The envisaged intelligence 
is based on formal, machine understandable descriptions of the content and the 
events.  We  demonstrate  the  successful  usage  of  the  system  by  a  broadcasting 
corporation  in  a  field  trial  with  several  hundred  end  consumers,  conducted  
during the Olympic Games in Beijing, August 2008.  

1   Introduction 

The European integrated project "LIVE Staging of Media Events" (LIVE, www.live-
ist.org) aims at the creation of novel intelligent content production methods and tools 
for broadcasters to stage live media events such as the Olympic Games 2008 in Bei-
jing. In the terminology of the project, "staging live media events" is a notion for the 
real-time creation of non-linear multi-channel video shows, whose format is adaptive 
according to the interests of the consumers. While the development of the envisaged 
interactive  content  formats  forms  a  research  strand  of  its  own  [1]  the  concept  also 
imposes several conceptual and technical challenges from a software engineering and 
semantic modelling point of view. Fig. 1 depicts the environment the LIVE production  support  system  needs  to  work  in  to  support  the  preparation  and  production  of 
shows as envisioned above. 

Staging  of  media  events  in  the  novel  TV  format  comprises  all  knowledge  of  an 
event e.g.  the  schedule and participants; knowledge of all  related information about 
the event including archived content and - foremost - a detailed knowledge of how the 
staged  event  is  to  be  presented  to  the  targeted  consumer  audience.  Typically  such 
information is collected during the preparation phase of a show. However, the LIVE 
production support system addresses not only the preparation, but also the real time 
staging of media events where archival knowledge related to the event must be combined with real-time information of what is actually happening during the event. Fur-
thermore, the actual production is influenced by accurate, real-time feedback from the 
viewing  audience.  An  overview  of  the  preparation  and  staging  workflow  is  also 
shown in Fig. 1 which shows the activities of the professional users in their dedicated 
user spaces. 

L. Aroyo et al. (Eds.): ESWC 2009, LNCS 5554, pp. 841845, 2009. 
 Springer-Verlag Berlin Heidelberg 2009 

G. Guntner, D. Glachs, and R. Westenthaler 

The remainder of this paper is structured as follows: Section 2 provides details of 
the LIVE production support system used for this demonstration; Section 3 outlines 
how  the  Intelligent  Media  Framework  (IMF)  uses  semantic  technologies  to  support 
knowledge and information integration in the LIVE staging domain. 

Fig. 1. Overview on the LIVE staging environment 

 

2   Showcasing the LIVE Production Support System 

Our demonstrator is based on the LIVE production support system used in a field trial 
during  the  Summer  Olympic  Games  in  August  2008.  Over  500  households  participated in the iTV trial and gave explicit (e.g. voting) and implicit (e.g. channel switch-
ing) feedback to the production team.  At the production  site in Vienna at ORF, the 
Austrian Broadcasting Corporation, annotators manually annotated up to twelve live 
video  feeds  from  the  Olympic  Games.  ATOS  origin,  the  supplier  for  the  Olympic 
Sports Information System provided event information in real time. This resulted in 
about  12.000  messages  per  hour  that  were  sent  to  the  Intelligent  Media  Framework 
(IMF). The IMF had to interpret the messages, align them to the knowledge model, 
maintain the semantic index and propagate a filtered set of messages to the consuming 
systems (e.g. the recommender system). A dedicated application called Staging Con-
sole displayed a set of messages filtered according to their relevance for the production process (e.g. priority, schedule). 
?

?

?
The demonstrator outlines the complete information flow by starting with the captured  sport  event  and  by  simulating  the  information  created  by  the  Olympic  Sport 
Information System. The Staging Console as shown in Fig. 2, visualizes the scenery 
by outlining the observed live feeds (1), the scheduled events presented along a time 
line  (2)  and  as  a  schedule  of  upcoming  events  (3).  It  further  shows  manually  and 
automatically  generated  messages  to  the  production  team  (4).  Optionally,  details  of 
each message can be retrieved in a dedicated panel (5). 

Besides the Staging Console, the Recommender Application (see [3]) is part of 
the LIVE system and allows the production team to easily retrieve video clips from 
the production archive according  to the context of the show. The Feedback Panel 
shows  the  viewers  channel  switching  behaviour  (implicit  feedback)  and  polling  results (explicit user feedback). In the field trial the feedback was collected via the back 
channel of the set-top boxes of the used IPTV infrastructure (aon.tv1). 

(1) 

(2)

(4)

(3) 

(5) 

 

Fig. 2. LIVE Staging Console 

The  demonstration  is  a  time  shifted  replay  based  on  data  gathered  during  the 
Olympic field trial. The demonstration  shows the usage of the different tools in the 
workflow starting with the live capture of video streams, showing the semantic annotation  and  the  bundling  of  streams  into  "shows"  by  the  so  called  "video  conductor" 
who can also react to consumer feedback and change the broadcast accordingly. 

                                                           
1 aon.tv  see http://www.aon.tv/ (in German)   last visited 06.03.2009. 

G. Guntner, D. Glachs, and R. Westenthaler 

3   Intelligent Media Framework 

The  Intelligent  Media  Framework  (IMF)  implements  the  knowledge  based  middleware component of the LIVE production support system. This section gives first an 
overview of the knowledge model used and then describes the principal architecture 
of the LIVE production support system. 

The  IMF  is  based  on  a  knowledge  structure  divided  into  three  sub-models:  the 
Term Model, The Event Domain Model and the Intelligent Content Model. The Term 
Model forms the foundation of this knowledge structure and is based on functionalities defined in the Simple Knowledge Organization System (SKOS). It supports the 
features  of  SKOS,  but  in  addition  it  defines  a  base  typology  for  terms,  the  Term 
Type  Hierarchy.  This  typology  aims  to  simplify  the  structuring  of  the  controlled 
vocabulary and provides additional semantics to the other knowledge  models of the 
IMF. All terms in the controlled vocabularies are aligned to the Term Type Hierarchy. 
Details of the entire knowledge model can be found in [2]. 

On top of the Term Model is the Event Domain Model. This model supports the 
definition  of  formal  statements  describing  the  current  state  (annotating)  or  a  future 
state  (planning)  of  events.  Such  statements  are  used  to  describe  the  staged  event  as 
well as the staging process  itself. They are  instantiations of concepts defined  in the 
Event Domain Model (e.g. Agent, Activities, Events, Settings). Terms and part of the 
controlled vocabulary are used to parameterize such statements. 

The Intelligent Content Model defines knowledge-based content objects called Intelligent  Media  Assets  (IMAs)  which  manage  the  relation  between  content  and  the 
knowledge. To achieve this, an IMA consists of two main parts: (i) Content annotations define knowledge about features of the essence such as storage location(s), en-
coding, access rights or publication rights. Dedicated elements of existing standards 
such  as  MPEG-7  and  NewsML  are  used  for  such  annotations.  (ii)  Subject  matter  
annotations define  information items expressing  formal descriptions of  what the essence is about. Subject matter descriptions include a spatial-, temporal-, topic based 
(includes terms as well as instances of the event domain model) and free text classifi-
cation. In addition they hold information about the creator (professional user/software 
agent and user role) to support collaborative filtering. 

The  Intelligent  Media  Framework  provides  the  knowledge  infrastructure  for  the 
LIVE production support system and is based on a multi-tier service-oriented architecture in which all interfaces to external components are modeled as Web Services. 
The service interfaces are structured along the three parts of the knowledge model and 
provide access to the controlled vocabulary, the event domain model and the intelligent media assets. In addition to these pull-type services, the IMF uses a messaging 
system to support the real-time aspect of the staging process. Asynchronous messaging is used to process information from internal and external sources (automatic anno-
tators, human annotator and information sent by the event information system). The 
IMF aligns the information to the already available knowledge of the event as well as 
the  show  and  propagates  the  resulting  knowledge  by  publishing  it  to  subscribing  
applications  of  the  LIVE  production  support  system.  This  information  enrichment 
uses statements as defined by the Event Domain model to formally describe the current state of the event as well as the staged show. 
?

?

?
The  IMF  also  maintains  a  semantic  index  over  the  whole  knowledge  base.  This 
semantic index uses the relations defines in the Event Domain- and the Term Model 
to  provide  tagging-like  classifications  for  all  resources.  Real-time  changes  to  the 
knowledge structure are reflected in the semantic index.  

During the Olympic Trial the IMF processed around 20.000 terms, around 100.000 
semantic relations between the terms; 120.000 event participations and about 100.000 
statements describing specific situations in the various events. Around 20.000 Intelligent Media Assets were created during the Olympic Field Trial. 

4   Conclusion 

In the field trial, content-based information was combined with event information in 
real-time,  using  a  common  knowledge  model.  The  combination  of  content  management  systems  with  event  information  systems  was  successfully  tested.  The  LIVE 
production support system demonstrated how a knowledge based system can enable 
knowledge workers to create the envisioned LIVE iTV format: Editors and directors 
at the production site at ORF, the Austrian Broadcasting Corporation, confirm that it 
would not be feasible to create such non-linear multi-channel video shows by using 
traditional production methods. 

A survey by GfK Austria showed that the quality of the new format was rated with 
1,5 (out of 5 with 1 expressing highest satisfaction) by the viewers. 82% of them 
expressed a high interest in a continuation of the interactive multi-channel format.  

The LIVE approach differs from related research primarily with respect to the real 
time nature of the production methods (see [4] for a comparable approach in the area 
of non-linear, yet non real time narrative structures). 

Acknowledgments 

The LIVE project (Live Staging of Media Events) is an integrated project partially 
funded  by  the  European  Commission  within  the  6th  Framework  of  the  IST  under 
grant  number  FP6-27312. All statements in this  work reflect the personal ideas and 
opinions of the authors and not necessarily the opinions of the European Commission. 
