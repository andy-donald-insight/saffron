SIM-DLA: A Novel Semantic Similarity Measure
for Description Logics Reducing Inter-concept to

Inter-instance Similarity

Krzysztof Janowicz and Marc Wilkes

Institute for Geoinformatics, University of Muenster, Germany

{janowicz,marc.wilkes}@uni-muenster.de

Abstract. While semantic similarity plays a crucial role for human categorization and reasoning, computational similarity measures have also
been applied to fields such as semantics-based information retrieval or
ontology engineering. Several measures have been developed to compare
concepts specified in various description logics. In most cases, these measures are either structural or require a populated ontology. Structural
measures fail with an increasing expressivity of the used description logic,
while several ontologies, e.g., geographic feature type ontologies, are not
populated at all. In this paper, we present an approach to reduce interconcept to inter-instance similarity and thereby avoid the canonization
problem of structural measures. The novel approach, called SIM-DLA,
reuses existing similarity functions such as co-occurrence or network measures from our previous SIM-DL measure. The required instances for
comparison are derived from the completion tree of a slightly modified
DL-tableau algorithm as used for satisfiability checking. Instead of trying to find one (clash-free) model, the new algorithm generates a set of
proxy individuals used for comparison. The paper presents the algorithm,
alignment matrix, and similarity functions as well as a detailed example.

1 Introduction and Motivation

Semantic similarity measurement plays an important role in information retrieval on the semantic Web [1]. It supports users in searching and browsing
through structured data. To improve human computer interaction, i.e., to be
successfully integrated into semantics-aware user interfaces, such measures need
to fulfill two criteria. First, they need to be able to handle the expressivity of
the used description logics. Second, the similarity rankings produced by these
measures have to correlate with human similarity rankings for the same set
of compared concepts or individuals. In our previous work [2,3], we developed
a structural similarity measure (SIM-DL1) for information retrieval on the semantic geospatial Web which fulfills these requirements [4]. It defines similarity
as measure of conceptual overlap. As SIM-DL compares concept definitions, it

1 The SIM-DL similarity server and Prot eg e plug-in are free and open-source software

and can be downloaded at http://sim-dl.sourceforge.net/downloads/.

L. Aroyo et al. (Eds.): ESWC 2009, LNCS 5554, pp. 353367, 2009.
c Springer-Verlag Berlin Heidelberg 2009

K. Janowicz and M. Wilkes

does not require a populated ontology. This is especially important for various
applications in geoinformation science (GIScience) such as Web gazetteers. In
addition to simple place name queries, gazetteers also support type queries (such
as for archaeological sites in Crete). In the past, thesauri have been used for the
definition and retrieval of these types. Advanced gazetteer interfaces support
semantics-based retrieval and rely on geographic feature type ontologies [3]. For
various reasons not discussed here in detail, the millions of geographic places defined over the last decades cannot be directly mapped to instances within such
ontologies. While a semi-automatic mapping is part of the long term agenda
towards a semantic geospatial Web, many geographic feature type ontologies
remain unpopulated until now. As SIM-DL is a structural measure, its major
shortcoming is the need for canonization, i.e., concept definitions have to be
rewritten to a common form to eliminate syntactic influence. Hence, SIM-DL
fails to handle expressive knowledge representation languages such as OWL. In
this paper, we propose a novel measure called SIM-DLA. It overcomes these
difficulties by reducing inter-concept to inter-instance similarity and reuses the
similarity functions defined for SIM-DL. Our approach is based on a modified
tableau algorithm which generates a set of proxy individuals for comparison.

2 Semantic Similarity Measurement

The theory of similarity has its roots in philosophy and psychology and was
established to determine why and how entities are grouped into categories, and
why some categories are comparable to each other while others are not [5,6].
Nowadays, similarity measures play an important role for ontology engineering,
alignment and matching [7,8,9,10], as well as for information retrieval [3,11]. The
main challenge for semantic similarity measurement is the comparison of meanings as opposed to a purely structural (syntactical) comparison. Depending on
the representation language, concepts are specified as collections of features [12],
regions in a multidimensional space [13], or formal restrictions specified on sets
using description logics [14,15,16,2]. Besides representation, context is a major
challenge for similarity. In most cases, meaningful measures cannot be defined
without specifying a context in which similarity is measured [6,17,18,19,20].

2.1 Semantics of Similarity
As argued by Goodman [21], there is no global and application independent law
on how similarity is measured. Strictly speaking, there is even no single definition of what similarity measures [6]. This makes the selection of an appropriate
measure for a particular application area and also the comparison of existing
similarity measures difficult. In the past, we have examined several measures for
different applications and found generic patterns which jointly form a framework
explaining how (inter-concept) similarity is measured [3]. It consists of the following seven steps. Their concrete realization depends on the similarity measure
and the used representation language. While some of these steps are important
for a particular measure, they may play a marginal role for another.
?

?

?
1. Definition of application area and intended audience
2. Selection of search (query) and target concepts
3. Transformation of concepts to canonical form
4. Definition of an alignment matrix for concept descriptors
5. Application of constructor specific similarity functions
6. Determination of standardized overall similarity
7. Interpretation of the resulting similarity value(s)

Every similarity measure should define in which way it implements the proposed steps and thereby specifies the semantics of similarity (values) as well as its
properties, i.e., whether it is reflexive, symmetric, transitive, strict, minimal, etc.;
see [22,23,5] for a detailed discussion. It is interesting to note that researchers
from both cognitive science and artificial intelligence claim that most of these
properties contradict with the nature of (human) similarity judgments. Finally,
the framework allows for a better separation between the process of measuring
similarity (i.e., what is measured) and the used similarity functions (i.e., how it
is measured). In the following, a brief description of the steps is given.

Application Area and Intended Audience. While similarity measurement is not
restricted to solve a particular task, most similarity functions have been developed for a specific purpose. Therefore, the question which functions should be
selected depends on the application area. Theories developed for information
retrieval and in cognitive science tend to use asymmetric similarity functions to
explaining human similarity reasoning [5]. In contrast, measures developed for
ontology alignment prefer symmetric functions (as there is no specific role between compared ontologies). Additionally, in case of disjunction one can choose
between computing maximum, minimum [24], or average similarity [3]. Finally,
human similarity judgments are influenced by age, language, and cultural background which may play a crucial role in human computer interaction [6,18].

Search and Target Concepts. Before similarity can be measured the compared
concepts have to be selected. Depending on the application area, the search (or
query) concept Cs can be either part of the examined ontology or phrased using
a shared vocabulary [2,3]. The target concepts Ct1 , ..., Cti form the so-called context of discourse Cd [18] and are selected by hand or automatically determined
by specifying a context concept Cc. In the latter case, the target concepts are
all concepts subsumed by Cc (Cd = {Ct | Ct  Cc}). The distinction between
search and target concept is especially important for asymmetric similarity. The
selection of a context concept does not only determine which concepts are com-
pared, it also affects the measured similarity (see section 3.4). Based on search,
target, and context concept similarity queries may look like the following ones:

 How similar is Canal (Cs) to River (Ct)?
 Which kind of Waterbody (Cc) is most similar to Canal (Cs)?

In the first case, Canal would be compared to River, while it is compared to
all subconcepts of Waterbody (e.g., River, Lake, Reservoir) in the second case.

K. Janowicz and M. Wilkes

Canonical Form. Semantic similarity should depend on what is said about con-
cepts, not how it is said. If two concept descriptions (specified in a given lan-
guage) denote the same facts using different language elements, they need to be
rewritten to a common form to eliminate unintended syntactic influences. This
step mainly depends on the underlying representation language and is most important for structural similarity measures. A simple examples is:

Condition R.C  R.C

 Rewrite R.C  R.C

 to R.(C  C

)

The complexity of such rewriting rules increases with the expressivity of the
used language and is a major obstacle in defining structural measures for concepts phrased in high expressive description logics.

Alignment Matrix. While the first steps of the framework determine which concepts are selected for comparison, the alignment matrix specifies which and how
concept descriptors (e.g., dimensions, features, super/subconcepts) are com-
pared. The term alignment is chosen here following research from psychology
which investigates how structure and correspondence influences similarity judgments [25,6]. For instance, overlaps.C can be compared to inside.C because
the involved roles are part of the same (topological) conceptual neighborhood
[26]. In contrast, both cannot be compared to likes.C. Likewise, the green
wheel of a car cannot be aligned for comparison to the green hood of a truck
to increase their similarity [5]. The term matrix points out that the selection of
comparable tuples of descriptors requires a matrix CDs  CDt (where CDs and
CDt are the sets of descriptors forming Cs, and Ct, respectively).

Similarity Functions. After selecting the compared concepts and aligning their
descriptors, similarity is measured for each selected tuple. Depending on the
used representation language different similarity functions have to be applied.
For instance, in case of the Matching Distance Similarity Measure (MDSM)
[12], features are distinguished into different types during the alignment process:
parts, attributes, and functions. Although a context weighting is computed for
each of these types, the same similarity function is applied to all of them. SIMDL distinguishes between several similarity functions for roles and their fillers,
e.g., functions for conceptual neighborhoods, role hierarchies, or co-occurrence of
primitives. While we focus on inter-concept similarity here, some similarity functions also take individuals into account [15,24,20]. In most cases, each similarity
function takes care of standardization (to values between 0 and 1) itself.

Overall Similarity. Next, the single similarity values derived from applying the
similarity functions to all selected tuples (of the compared concepts) are combined to an overall similarity. In most theories this step is implemented as
weighted summation function. For MDSM, the overall similarity is the weighted
sum of the similarities determined for functions, parts, and attributes. The
weights f, p, and a indicate the relative importance of each feature type
using either a commonality or variability model [12]. At the same time, the
weights act as standardization factors (
 = 1). For conceptual space-based
?

?

?
approaches, the overall similarity is given by the normalized, i.e., z-transformed
sum of compared values [13]. In case of SIM-DL, the overall similarity is simply
the sum of the similarities computed for the compared tuples.

Interpretation. Finally, a single similarity value is difficult to interpret. For in-
stance, it does not answer the question whether there are more or less similar
target concepts in the examined ontology, i.e., the distribution of similarities
within the ontology is unknown. Moreover, an isolated comparison puts too
much stress on the specific similarity value. It is difficult to argue that and why
the result is (cognitively) plausible without other reference values. Therefore,
SIM-DL focuses on similarity rankings visualized as lists of descending similari-
ties, font-size scaling as known from tag clouds, or the clustering of the results.

3 The Novel SIM-DLA-Measure

In this section, the novel SIM-DLA-Measure is introduced. It reduces interconcept to inter-instance similarity to avoid the problem of canonization known
from purely structural measures. As SIM-DLA should not require a populated
ontology, the instances have to be generated before similarity is measured. This
is achieved by creating a representative set of instances for both the search and
target concept(s) using a slightly modified tableau algorithm as known from satisfiability checking. The algorithm produces additional models, if necessary, in
order to account for all possible interpretations of a concept. To be tailored to
the users needs and application area (see step one of the framework), SIM-DLA
supports symmetric and asymmetric versions of maximum and minimum sim-
ilarity. For reasons of simplification, i.e., to avoid substraction operations [27]
on DL concepts, the context concept is restricted to primitive concepts. In this
paper, we discuss the modified tableau algorithm for the description logic SHI
and focus on step three to six of the similarity framework. Hence, we start with
the alignment matrix and introduce the applied similarity functions afterwards.
A detailed example is given in section 4.

3.1 Syntax and Semantics of SHI
Primitive concepts and roles can be combined using constructors to build complex concepts. The language SHI provides the constructors intersection, union
existential quantification, value restriction, and complex concept negation
(table 1). In addition, roles can be defined to be transitive, inverse or form
a role hierarchy. In the following, the letters C, D represent concepts and R,
S roles. NC denotes the set of concept names, accordingly NR represents the
set of role names. N +
R is the subset of NR which contains only transitive roles.
Finally, the letters x, y, and z represent individuals. The formal semantics of
a SHI-concept is given by its interpretation I. I consists of a non-empty set
I, which is called the domain of interpretation, and an interpretation function
I  I) and a role R to
which maps a concept name C to a set of individuals (C

K. Janowicz and M. Wilkes

I  I I). An interpretation that satisfies the
a set of pairs of individuals (R
axioms of a TBox T is called a model of T . Accordingly, in the presence of an
ABox A, an interpretation is called a model of A if it satisfies (x

I for
I for all concept assertions C(x)  A.
all role assertions R(x, y)  A, and x

I)  R

I  C

, y

Table 1. Syntax and semantics of SHI

Name
Atomic concept
Atomic role
Concept negation
Concept intersection
Concept union
Existential quantification
Value restriction
Inverse role
Transitive roles
Role inclusion

Syntax
?

?

?
C
C  D
C  D
R.C
R.C


R  N +
R  S
?

?

?
Semantics
I  I

I  I  I

I\C

I  D

I  D

I  y  C
I}
{x  I|y.(x, y)  R
I  y  C
{x  I|y.(x, y)  R
I}
{(x, y)  I  I|(y, x)  R
I}
I}
I  (y, z)  R
{(x, z)|(x, y)  R
I  S

3.2 Similarity Tableau for SHI
The tableau algorithm introduced in this section is part of the fourth step of
the similarity framework  the definition of an alignment matrix. Before the
matrix can be constructed, the third step requires the concepts to be rewritten
to a canonical form. Sim-DLA is designed to avoid a complex canonization, i.e.,
the concepts are simply rewritten to negation normal form (NNF). Additionally,
concept inclusion is rewritten to equivalence using the primitiveness of concepts
[28]. For example, C  A can be rewritten as C  A  C

.

Tableau algorithms prove the satisfiability of a concept C by trying to construct a model of C. More precisely, as soon as the algorithm constructed one
model of C the satisfiability is affirmed and the algorithm terminates. In con-
trast, the expansion rules presented in this section do not aim at constructing
only one model of C, but rather a number of models which act as proxies for
the extension of C. These models are called proxy models here. In the following,
the tableau expansion rules are presented. Since these rules differ only slightly
from those used for checking satisfiability, readers interested in more details are
referred to the work of Horrocks et al. [29,30].
The application of the expansion rules yields a completion tree T. For a concept
C, this is a tree where each node is labeled with a set L(x) of concept expressions
occurring in C. An edge x, y is either labeled with  or  (and indicates another
potential proxy model starting at the y-node), or with L(x, y) = R, where R is
a role occurring in C [29]. For a node x, L(x) contains a clash if, for some concept
C, {C,C}  L(x). Those branches of the tree T which do not contain a clash
are proxy models and enter the similarity measurement process. A node y is called
a R-neighbor of x if either y is a successor of x (i.e., x and y are connected by an
edge x, y) and L(x, y) = S or y is a predecessor of x (x and y are connected by
?

?

?
an edge y, x) and L(y, y) = Inv(S)2 for some S within the transitive closure of
R (S 
R). A node x is blocked if one of the ancestors is blocked or L(x) = L(y),
where ancestor is the transitive closure of predecessor.
In contrast to the original tableau algorithm [30], two expansion rules are
modified. First, the -rule is modified in order to generate a third possible new
model allowing an individual for being an instance of both concepts participating
in the union. Second, the -rule is modified. In the absence of -expressions,
the modified -rule generates two possible models. One of these models will be
unchanged (as in standard tableau algorithms), the other will be enriched by an
existential quantification. When a value restriction was explicitly specified for a
given concept, this should impact similarity and hence has to be reflected by a
proxy model. The following expansions rules are applied:

The -rule:
Condition: C1  C2  L(x), x is not indirectly blocked, and {C1, C2} / L(x).
Action: L(x) := L(x)  {C1, C2}.
The -rule:
Condition: C1  C2  L(x) and x is not indirectly blocked.
Action: Create three -successors w, y, z of x with:
L(w) := (L(x)\{C1  C2})  {C1}
L(y) := (L(x)\{C1  C2})  {C2}
L(z) := (L(x)\{C1  C2})  {C1, C2}
The -rule:
Condition: (R.C)  L(x), x is not blocked, and x has no R-neighbor
y with C  L(y).
Action: Create a new node y with L(y) = {C} and the edge L(x, y) = R.
The -rule:
Condition: (R.C)  L(x), x is not indirectly blocked.
Action:
If there is an R-neighbor y of x and C / L(y):
L(y) := L(y)  {C}.
If there is no R-neighbor y of x, create two -successors y, z of x with:
L(y) := L(x) (y will then be blocked)
L(z) := L(x)  {R.C}.

The +-rule:
Condition: (R.C)  L(x), x is not indirectly blocked, there is some S which
is transitive and S  R, and there is an S-neighbor y of x with S.C / L(y).
Action: L(y) := L(y)  {S.C}.

3.3 Alignment Matrices

For a search concept Cs and a target concept Ct, the completion tree obtained
from applying the modified tableau algorithm serves as starting point to derive

2 Inv(S) := S

, if S is a role name. Inv(S) := R, if S = R

 for a role name R [30].

K. Janowicz and M. Wilkes

the alignment matrices (the fourth step of the framework). We distinguish two
levels of matrices, the model level and assertion level matrices.

Model Level Matrix  Selecting Models for Comparison. For Cs and Ct, each
completion tree contains a set of proxy models. These proxy models define the
matrix MM (where M indicates that models are compared). More precisely, the
number of columns is determined by the number of models created for the search
concept. Accordingly, each model created for the target concept corresponds to
one row in the matrix. For each field in MM, the similarity between the two
models is computed and entered into the matrix. Which of these tuples are
selected for comparison depends on the application and user. For example, if
an application requires maximum similarity, the tuple with the highest value is
returned. For minimum similarity, the tuple with the lowest similarity is selected.

Assertion Level Matrix  Computing Similarity between Models. While the first
matrix is concerned with selecting appropriate models for comparison, the following matrix MA (where A indicates that assertions are compared) addresses the
comparison of two actual instances. Therefore, each primitive concept that is instantiated by a models root individual is added as a column/row to the matrix.
Furthermore, each outgoing edge (representing a role assertion) is added as well.
Now, the similarity between two primitive concepts can be computed. The similarity between role assertions consists of two steps. First, the similarity between the
roles is computed. The role similarity determines which role assertions are aligned,
i.e., filler similarity is only computed when appropriate. If the filler similarity needs
to be determined, another assertion level alignment matrix for the two filler individuals is created. Once the matrix is filled, those pairs of assertions with the
highest similarity values are selected for comparison. It is important to note that
each column and each row is only selected once, avoiding a too heavy influence
of single assertions. The similarity values are summed up and standardized. The
standardization factor  (see equation (4)) depends on whether the symmetric or
asymmetric measure is chosen [2,3]. In the latter case,  is the number of assertions
of the search individual (i.e., the number of columns). In the symmetric case, the
maximum number of either columns or rows is used.

With respect to step one of the framework, the distinction between maximum
and minimum similarity is reflected in the model level matrix. It determines
which of the proxy models are compared. Symmetry and asymmetry are reflected
in the assertion level matrix which selects assertions for comparison. This way,
and in contrast to measures such as MDSM [12], SIM-DLA can be tailored to a
specific application area without altering the similarity functions themselves.

3.4 Measuring Inter-instance Similarity
In this section, we introduce the concrete similarity functions used to determine
the tuples selected for comparison. Each assertion is either of the form A(x) or
r(x, y), where A is a primitive concept instantiated by x and r(x, y) is an ordered
I. Following the introduced framework, three similarity
pair of individuals in R
functions are necessary: one for primitives, roles, and role-filler-pairs.
?

?

?
Primitive Concepts. Primitives (base symbols) occur only on the right-hand side
of axioms, i.e., they are not definable. To measure similarity between primitives
(simp; see equation (1)), an adapted version of the Jaccard Similarity Coefficient
is used. It measures the degree of overlap between two sets S1 and S2 as ratio
of the cardinality of shared members from S1  S2 to the cardinality retrieved
from S1  S2. MDSM [12] uses an asymmetric version of Jaccards coefficient,
while in case of SIM-DL [3] it is adapted to compute the context-aware cooccurrence of primitives within the definitions of other (non-primitive) concepts.
Two primitives are the more similar, the more complex concepts are defined using
both (and not only one) of them. If simp(A, B) = 1, both primitives always cooccur in complex concepts and cannot be distinguished. Hence, to measure the
similarity between assertions of the type A(x) and B(y), the similarity between
A and B is measured. As similarity also depends on the context of discourse
[18], we only consider those concepts Ci which are subconcepts of Cc (see step
two of the similarity framework).

sim(A(x), B(y)) = simp(A, B) =

| {C | (C  Cc)  (C  A)  (C  B)} |
| {C | (C  Cc)  ((C  A)  (C  B))} |

(1)

Role Hierarchy. SHI supports role hierarchies, i.e., role inclusion, but does not
support intersection or composition. Same as argued for primitives, there are
no role definitions which can be compared for similarity. Because of the missing
intersection constructor we cannot apply Jaccards coefficient here. Instead, a
network-based approach [31] is taken to compute the similarity of roles (R and
S) within a hierarchy. Similarity (simr; see equation (2)) is defined as ratio
between the shortest path from R to S and the maximum path within the graph
representation of the role hierarchy; where the universal role U (U  I  I)
forms the graphs root. Compared to simp, similarity between roles is defined
without reference to the context. This would require to take only such roles into
account which are used within quantifications or restrictions of concepts within
the context. The standardization in equation (2) is depth-dependent to indicate
that the distance from node to node decreases with increasing depth level of
R and S within the hierarchy. In other words, the weights of the edges used
to determine the path between R and S decrease with increasing depth of the
graph. If a path between two roles crosses U, similarity is 0. The lcs(R, S) is the
least common subsumer, in this case the first common super role of R and S.

simr(R, S) =

depth(lcs(R, S))

depth(lcs(R, S)) + edge distance(R, S)

(2)

SIM-DL uses a second function to compare roles within a conceptual neighborhood [2]. This is necessary for topological and temporal relations as used in
GIScience3. One could also define network-based similarity functions for other
roles such as part-of. These functions can be integrated into SIM-DLA.
3 See [32] on the problems of integrating topological relations and reasoning in DL.

K. Janowicz and M. Wilkes

Roles and Fillers. The similarity between assertions of the type r(x, y) and
s(w, z), is the similarity of the involved roles R and S times the overall similarity
of the assertions about y and z; where x and w are the individuals to be compared
(see equation (3)).

sim(r(x, y), s(w, z)) = simr(R, S)  simo(y, z)

(3)

Some similarity measures define role-filler similarity as weighted average of the
role and filler similarities, but the multiplicative approach has turned out to be
cognitively plausible [4] and allows for simple approximation and optimization
techniques not discussed here in detail.

3.5 Overall Similarity
As simp and simr deliver similarity values between 0 and 1, the overall instance
similarity (simo; see equation (4)) in SIM-DLA is simply the standardized sum of
the similarities computed for all assertion tuples selected during the alignment;
see section 3.3. The similarity of compared concepts is either the similarity of
the most or least similar proxy individuals (computed using simo).
?

?

?
simo(x, y) =

MAij


; where MAij is a selected tuple from the matrix MA.

(4)

4 Exemplary Application of SIM-DLA

The previous section presented the novel SIM-DLA measure. In order to illustrate
the steps involved in a comparison process between a search concept Cs and a
target concept Ct, this section provides a detailed example. A, B, D, and E are
primitive concepts, R and S are roles with R  S.

Cs  A  (B  D)  R.E

Ct  A  (B  A)  S.E  S.D

For Cs, the expansion rules are applied as follows, the expansion tree Ts and
resulting models are shown in figure 1.

1. Unfold Cs and convert it to NNF.
2. Initialize Ts containing a node s0.
3. Apply the -rule to A(B D)R.E 
4. Apply the -rule to B  D  L(s0).

L(s0).
Create three -successors s1, s2, s3 of s0.

5. Apply the -rule to R.E  L(s1).
6. Apply the -rule to R.E  L(s2).
7. Apply the -rule to R.E  L(s3).

Create a node s4 and an edge s1, s4.
Create a node s5 and an edge s2, s5.
Create a node s6 and an edge s3, s6.

A  (B  D)  R.E
L(s0) = {A  (B  D)  R.E}
L(s0) := L(s0)  {A, B  D,R.E}
L(s1) := L(s0)\{B  D}  {B}
L(s2) := L(s0)\{B  D}  {D}
L(s3) := L(s0)\{B  D}  {B, D}
L(s4) = {E}
L(s1, s4) = {R}
L(s5) = {E}
L(s2, s5) = {R}
L(s6) = {E}
L(s3, s6) = {R}
?

?

?
Fig. 1. a) Expansion tree for Cs. b) Models for Cs.

For Ct, the expansion tree Tt is slightly more complex. It results from applying
the expansion rules as listed below. The tree as well as the models are shown in
figure 2.

1. Unfold Ct and convert it to NNF.
2. Initialize Tt containing a node t0.
3. Apply the -rule to
A(BA)S.E S.D  L(t0).
4. Apply the -rule to BA  L(t0).
Create three -successors t1, t2, t3
of t0.

5. Apply the -rule to S.E  L(t1).
Create two -successors t4, t5 of t1.
6. Apply the -rule to S.E  L(t5).
Create a node t6 and an edge t5, t6.
7. Apply the -rule to S.D  L(t5).
There is a S-neighbor t6 of t5, but
D / L(t6).

A  (B  A)  S.E  S.D
L(t0) = {A  (B  A)  S.E  S.D}
L(t0) := L(t0){A, BA,S.E,S.D}
L(t1) := L(t0)\{B  A}  {B}
L(t2) := L(t0)\{B  A}  {A} (clash)
L(t3)
:= L(t0)\{B  A}  {B,A}
(clash)
L(t4) := L(t1) (t4 is blocked by t1)
L(t5) := L(t1)  {S.E}
L(t6) = {E}
L(t5, t6) = {S}
L(t6) := L(t6)  {D}

Fig. 2. a) Expansion tree for Ct. b) Models for Ct.

K. Janowicz and M. Wilkes

The application of the tableau algorithm generates three proxy models for Cs
and two for Ct. As shown in figure 3a), the similarity between each possible tuple
of models is computed. In the model level matrix, a model is represented by its
root node. Given that the user queries for the maximum similarity between Cs
and Ct, MM12 is selected and yields the similarity value 0.83. The assertion level
matrix is shown in figure 3b). As described in section 3.3, each concept and role
assertion is added as a column (or row, respectively) in the alignment matrix.
For simplification we assume that Cc =  and sim(A, B) = 0.5. Whereas the
similarity between primitive concepts can directly be computed using function
(1), those fields in the alignment matrix representing tuples of role assertions are
computed using similarity function (3), hence demanding for two calculations,
simr(R, S) and simo(s4, t6). The former function calculates the similarity between two roles. R is a direct subrole of S and for simplification we assume that
sim(R, S) yields 0.5. As the role similarity is above 0 and there are no other role
assertion tuples, the filler similarity is computed. To do so, another alignment
matrix for s4 and t6 is created, resulting in simo(s4, t6) = 1 (see figure 3c).

Fig. 3. The alignment matrices for comparing Cs and Ct. Given that asymmetric maximum similarity is chosen, the green fields show the tuples selected for
comparison.

5 Conclusions and Further Work

In this paper, we introduced the novel Sim-DLA measure which reduces interconcept to inter-instance similarity by generating proxy models using a modified
tableau algorithm for SHI. The algorithm can still be used for satisfiability
checking, although its performance decreases with an extensive use of disjunctions and value restrictions, since additional models have to be created. Conse-
quently, it should be implemented as optional completion strategy as known from
the Pellet reasoner. The complexity of Sim-DLA depends on the used DL (i.e.,
the tableau rules) and the complexity of computing the similarity for the ma-
trices. Nevertheless, structural measures would require to define and implement
a complete set of canonization rules. Following the introduced similarity frame-
work, Sim-DLA clearly separates similarity modes such as maximum/minimum
similarity and symmetry/asymmetry, which are used to tailor the measure to
the users needs, from the concrete similarity functions. This allows to replace
particular functions without changing the measurement process.
?

?

?
Our next steps involve the extension of the presented approach to more expressive description logics such as SHIQ, i.e., to account for qualified number
restrictions. We also work on the integration of Sim-DLA into the SIM-DL server
and Prot eg e plug-in. In this paper we focused on the theory. While the new measure relies on the same similarity functions, the alignment process differs. Hence,
we have to redo our human participants tests [4] to verify that the Sim-DLA similarity rankings correlate with human rankings. We also need to investigate how
the creation of proxy individuals impacts similarity. Like the work of Ara ujo and
Pinto [16] our measure could also be extended to compare ontologies. Finally, one
could try to express similarity as the ratio of clashing versus clash-free models
of compared concepts. The clashes can then be presented (in natural language)
to the end-user to explain the resulting similarity values.

Acknowledgments

The comments from four anonymous reviewers as well as from Simon Scheider
provided useful suggestions to improve the content and clarity of the paper.
This work is funded by the SimCat project granted by the German Research
Foundation (DFG Ra1062/2-1), as well as the International Research Training
Group on Semantic Integration of Geospatial Information (DFG GRK 1498).
