A Heuristics Framework for Semantic Subscription 

Processing 

Martin Murth and eva Kuhn 

Vienna University of Technology 
Institute of Computer Languages, 
Space Based Computing Group 

Argentinierstrae 8, 1040 Vienna, Austria 

{mm,eva}@complang.tuwien.ac.at 

Abstract.  The increasing adoption of semantic  web technology in application 
scenarios with frequently changing data has imposed new requirements on the 
underlying tools. Reasoning algorithms need to be optimized for the processing 
of dynamic knowledge bases and semantic frameworks have to provide novel 
mechanisms  for  detecting  changes  of  knowledge.  Today,  the  latter  is  mostly 
realized  by  implementing  simple  polling  mechanisms.  However,  this  implies 
client-side  post-processing  of  the  received  results,  causes  high  response  times 
and  limits  the  overall  throughput  of  the  system.  In  this  paper,  we  present  a 
heuristics  framework  for  realizing  a  subscription  mechanism  for  dynamic 
knowledge bases. By analyzing similarities between published information and 
resulting  notifications,  heuristics  can  be  employed  to  guess  subsequent 
notifications.  As  testing  the  correctness  of  guessed  notifications  can  be 
implemented efficiently, notifications can be delivered to the subscribers in an 
earlier  processing  phase  and  the  system  throughput  can  be  increased.  We 
experimentally evaluate our approach based on a concrete application scenario.  

Keywords: Semantic subscription processing, heuristics framework, continuous 
queries, similarity heuristics, incremental result set updates. 

1   Introduction 

The  employment  of  semantic  web  technology  in  an  ever  increasing  number  of 
different application areas has imposed new requirements on the underlying tools and 
frameworks.  Besides  the  traditionally  high  requirements  on  storing,  querying  and 
reasoning about large static data sets, efficient processing of more dynamic data has 
become a central issue in many application scenarios, e.g., knowledge distribution for 
synchronization  or  clustering  [1],  semantically-enabled  data 
integration  [2], 
knowledge  monitoring  [3],  semantic  message  routing  [4-5],  and  knowledge-driven 
coordination [6-7].  

The new requirements can  generally be divided into two  groups. First, reasoning 
algorithms  and  engines  need  to  be  optimized  for  the  processing  of  frequently 
changing  data.  Different  approaches  have  already  been  investigated  in  this  field  of 

L. Aroyo et al. (Eds.): ESWC 2009, LNCS 5554, pp. 96110, 2009. 
 Springer-Verlag Berlin Heidelberg 2009 
?

?

?
is  described,  which  allows  for  improvements  of  reasoning  about (cid:2285)(cid:2274)(cid:2281)(cid:2283)  and (cid:2285)(cid:2274)(cid:2275)(cid:2283) 

research. In [8], for instance, an incremental reasoning technique for dynamic ABoxes 

description logics [9] of up to three orders of magnitude. 

Second,  semantic  frameworks  need  to  provide  novel  mechanisms  for  detecting 
changes  of  knowledge  in  a  knowledge  base.  Today,  this  is  often  realized  by 
implementing a simple client-side polling mechanism. The client system executes the 
query, retrieves the full result set and compares it with previously received result sets.  
Although the client is actually only interested in relevant updates, it needs to store the 
entire query result sets and analyze potentially large amounts of data. 

Accounting  for  this,  we  developed  a  lightweight  framework  that  implements  a 
simple subscription mechanism for semantic repositories. Whenever data is added to 
the  repository,  subscribers  are  notified  about  new  results  of  the  registered  queries. 
With  this  approach,  the  client  does  not  need  to  store  and  post-process  the  received 
results  and  the  amount  of  data  that  needs  to  be  transferred  between  the  semantic 
repository  and  the  client  is  minimized.  However,  it  is  still  necessary  to  execute  all 
registered queries whenever new data is added.  This often causes high response times 
and limits the overall throughput of the system (cf. [6]).  

In  this  paper,  we  present  a  mechanism  for  reducing  the  time  required  to  notify 
subscribers by applying heuristics on the published data for finding new query results. 
The  core  idea  is  based on  the  following  observation:  While  adding  new  data  to  the 
knowledge base often entails a costly reasoning and query execution task to find new 
query  results,  the  contents  of  the  published  graphs  and  the  new  query  results  can 
frequently  be  correlated  following  simple  patterns.  Hence,  finding  such  patterns 
would allow the system to "guess" possible new results and to test whether they are 
valid  in  the  new  system  state.  Testing  of  possible  results  can  be  implemented 
efficiently and the valid results can be sent to the subscriber already before the usually 
much more expensive query is executed. Furthermore, if the heuristic is able to find 
the  majority  of  new  results,  query  execution  can  even  be  skipped  for  several 
processing cycles. This decreases the average time required to process a publication 
request and therefore increases the throughput of the semantic subscription system. 

The rest of this paper is organized as follows: The remainder of Section 1 discusses 
related  work  in  this  field.  Section  2  introduces  SENS  (Semantic  Event  Notification 
Service),  our  subscription  processing  framework  for  semantic  repositories,  and 
describes  an  extension  for  heuristic  result  set  update  algorithms.  A  simple  heuristic 
for this framework is developed in Section 3. Section 4 evaluates the approach based 
on  a  concrete  application  scenario.  Conclusions  and  future  work  are  presented  in 
Section 5. 

1.1   Related Work 

The  work  presented  in  this  paper  was  motivated  by  experiences  with  application 
development  using  semantic  tuplespace  technology.  Semantic  tuplespaces  (e.g., 
sTuples [10], TSC [11], Semantic Web Spaces [12], TripCom [13]) are usually built 
upon a semantic repository and implement a Linda-based [14] or a publish/subscribe-
based  interface  to  access  the  stored  knowledge.  Clients  interact  with  each  other  by 
adding knowledge to the knowledge base and by retrieving notifications about events 
they have subscribed for. Although the proposed systems allow for elegant solutions 

M. Murth and e. Kuhn 

of many complex coordination problems (e.g. [15]), the implementation of real world 
applications  showed  that  the  existing  systems  do  not  perform  well  for  bigger 
knowledge bases as the continuous execution of queries causes a too high load on the 
server.  In  the  TripCom  project,  mechanisms  are  being  developed  for  clustering  and 
distributing  the  data  to  multiple  server  instances.  While  this  approach  aims  at 
improving  scalability  by  intelligently  distributing  the  load,  our  approach  focuses  on 
improving  the  performance  of  a  single  server  instance.  Thus,  both  approaches 
complement each other. 

Many  semantic  repositories  and  frameworks  implement  a  simple  subscription 
mechanism.  Jena  [16]  and  Sesame  [17],  for  example,  implement  listener  interfaces 
that generate events whenever new triples are added to the repository. However, they 
do  not  support  expressive  subscription  languages  and  notify  listeners  only  about 
explicitly  inserted  triples.  Consequently,  subscribers  are  not  notified  about  inferred 
information  which  is  one  of  the  crucial  advantages  of  communicating  via  a  shared 
knowledge base.  

Some  RDF  query  engines  (e.g.  [18-19])  employ  caches  for  improving  the 
performance  of  query  answering.  While  this  technique  leads  to  good  results  for 
querying static data, it is hardly applicable for highly dynamic knowledge bases as the 
caches are invalidated each time new data is published.  

Several  algorithms  for  continuous  queries  on  RDF  data  have  been  proposed  in  
[4-5,20-21].  However,  these  algorithms  require  RDF  triples  as  input  data,  which 
requires  to  instantiate  all  triples  at  least  in  memory.  For  applications  that  employ 
ontologies with extensive use of transitive properties or classification conditions, this 
might  cause  the  instantiation  of  a  huge,  possibly  exponentially  growing  number  of 
RDF triples. In contrast, our approach builds upon repeated query executions but tries 
to  find  the  optimal  intervals  and  to  reduce  the  number  of  execution  cycles.  Thus, 
triples only need to be instantiated if they are requested by the reasoning or the query 
engine.  Moreover,  the  heuristics  work  independently  of  the  employed  query  engine 
and reasoning technology. 

2   A Heuristics Framework for Semantic Subscriptions 

In this section we briefly introduce the subscription framework SENS and present a 
framework extension for heuristic result set update algorithms. 

2.1   SENS  Semantic Event Notification Service 

SENS (Semantic Event Notification Service) [6] is a framework for implementing and 
controlling  complex  and  heterogeneous  application  scenarios  by  leveraging  the 
reasoning capabilities of logic-based reasoning systems. Software clients can publish 
data at SENS and subscribe to changes of particular parts of the inferable knowledge. 
In  contrast  to  conventional  publish/subscribe  systems,  the  published  data  is  not 
directly  forwarded  to  the  subscribers  but  is,  in  a  first  step,  added  to  the  systems 
knowledge  base.  Afterwards,  the  system  evaluates  the  new  state  of  the  knowledge 
base and notifies the subscribers about the according updates.  

SENS is accessed via the API shown in Listing 1.  
?

?

?
public interface SENS { 

Listing 1. SENS API (Java) 

           // publishes knowledge in the form of RDF triples to the knowledge base 
 

void publish(Graph graph); 

 

 
 

// deletes all triples that match the given statement pattern  
void delete(StatementPattern pattern); 

// creates an event channel by providing a channel name and defining a graph  

 
           // pattern based query  
 

void createChannel(String channelQN, GraphPattern query); 

           // registers a subscription at the given channel  
 

void subscribe(String channelQN, Subscriber subscriber); 

// removes a subscription 
void unsubscribe(String channelQN, Subscriber subscriber); 

 

 
 

} 

 

 

Clients  can  add  knowledge  to  SENS  in  form  of  an  RDF  graph  data  structure 
(publish). The system tries to infer new knowledge right after the publication operation.  
RDF  triples  can  also  be  removed  from  the  knowledge  base  by  providing  a 
statement  pattern  matching  the  triples  to  be  deleted  (delete).  The  deletion  of  triples 
also  removes  the  knowledge  that  has  been  inferred  from  these  triples.  Previously 
inferred knowledge is thus not invalidated, but it is no longer guaranteed to be true. 

For  being  notified  about  changes  of  knowledge,  clients  have  to  subscribe  to  a 
semantic  event  channel  via  its  qualified  name  (subscribe/unsubscribe).  A  semantic 
event channel generates notifications about changes of a part of a knowledge base that 
has to be defined by means of a query statement (createChannel). As state-of-the-art 
semantic  repositories  implement  a  variety  of  different  query  languages,  the  current 
version of SENS only accepts query statements formulated as simple graph patterns 
as  these  can  be  expressed  with  most  existing  RDF  query  languages.  However,  it  is 
planned to add support for SPARQL [22] queries in the next version. Whenever the 
knowledge  base  is  updated,  SENS  executes  the  channels  queries  and  tags  the 
returned bindings. If it finds bindings that were not contained in the previous result set 
of  a  particular  channel  (i.e.,  are  not  tagged  yet),  the  subscribers  are  notified  about 
these  new bindings. Notifications are  sent to the subscriber as variable bindings for 
the channels query and can be accessed in tabular form or as variable substitutions of 
the querys graph pattern (analogous to SPARQL select and construct forms). 

One of the main advantages of employing a semantic subscription framework like 
SENS is the high expressivity of the subscription mechanism. The use of logic-based 
reasoning allows detecting and reacting to complex dependencies between distributed 
clients which are not explicitly modeled in the application scenario but which can be 
inferred from the provided data. For describing the same dependencies using a query 
on  a  database  or  an  event  stream  [23],  one  would  require,  e.g.,  nested  subqueries, 
constraint  evaluation,  special  treatment  of  null  values,  explicit  case  differentiations, 
and  client-side  post-processing  of  the  received  results.  Besides  this,  the  semantic 
publish/subscribe 
the 
communicating clients with respect to time (clients do not need to be connected to the 
system  at  the  same  time),  reference  (clients  do  not  need  to  know  each  other 

strong  decoupling  of 

interaction  pattern 

facilitates 

M. Murth and e. Kuh

hn 

explicitly), and data schem
semantics).  This  increases
autonomous system architec

ma (clients do not rely on homogenous data structures 
s  flexibility  in  application  design  and  allows  for  m
ctures. 

and 
more 

2.2   An Extension for Heu

uristic Query Result Update Algorithms 

For the improvement of no
framework  extension  for 
algorithms try to find new 
and found notifications, but
As  notification  time  (
between  the  client-side  inv
notification and the client-s
notification  time  (C)  for 
times of those notifications
their registration time.  

otification times and throughput of SENS, we develope
heuristic  query  result  set  update  algorithms.  Th
query results by analyzing the history of published gra
t they do not execute the actual query itself. 
(notifyi.j)  of  a  notification1  notifyi.j,  we  define  the  ti
vocation  of  the  publish  operation  pubi  that  triggered 
side reception of the notification. Accordingly, the aver
a  channel  C  is  defined  as  the  average  of  all  notificat
s that were delivered to the subscribers of a channel dur

ed a 
hese 
aphs 

ime 
the 
rage 
tion 
ring 

Generally, the performan
supported operations (publi
applications  we  investigate
significant  impact  on  the  o
throughput  (S)  of  a  sema
requests  that  can  be  proce
subscribers) within a certain
For the development of 
model  of  SENS.  The  orig
operation are illustrated in F

nce of the system is determined by the performance of
ish, delete, createChannel, un/subscribe). However, for 
ed,  only  the  efficiency  of  publication  processing  ha
overall  system  performance.  Consequently,  we  define 
antic  subscription  system  S  as  the  number  of  publicat
essed  (i.e.,  publication  and  notification  of  all  concer
n time unit.  
the framework extension, we had to adapt the process
ginal  processing  phases  executed  after  each  publicat
Figure 1. 

f all 
the 
ad  a 
the 
tion 
rned 

sing 
tion 

Fig. 1. SENS publication processing 

 

When a publication requ
first stored (s) in the connec
to  infer  new  knowledge 
subscriptions of all defined
repository,  the  execution 
knowledge base. Whenever
to the concerned subscriber
                                            
1 Notify operations are given w
operation that triggered the n
that were triggered by the sam

uest is issued to SENS (e.g., pub3), the contained graph
cted RDF repository. Then a reasoning engine is emplo
(r)  and  finally,  SENS  executes  the  queries  (q)  of 
 channels. Depending on the query and the employed R
of  the  query  may  involve  additional  reasoning  on 
r a new binding is found, a notification is immediately s
rs (e.g., notify3.1).  
               
with two subscript numbers. The first one refers to the publica
notification and the second one is used to distinguish notificati
me publication operation. 

h is 
yed 
the 

the 
sent 

ation 
ions 
?

?

?
ristics Framework for Semantic Subscription Processing 

The main benefit of emp
of  subscriptions  is  that  test
complete  execution  of  a  q
triples of the graph pattern a
Figure 2 illustrates the ad

ploying a heuristic algorithm for finding potential bindi
ting  single  bindings  takes  considerably  less  time  than 
query.  The  system  only  has  to  verify  whether  the  bou
also exist in the new state of the RDF repository.  
dditional phases of the extended processing model. 

ings 
the 
und 

Fig. 2. SENS publicat

tion processing extension for result set update algorithms 

 

Like in the original proc
stored  (s)  in  the  RDF  re
knowledge  (r).  Afterwards
with the new graph and ret
SENS  tests  (t)  for  each  ca
event,  i.e.,  whether  it  is  a 
delivered to the subscriber
about  the  new  binding.  In 
executed in order to reliabl
the  testing  phase.  Finally
improve its heuristic metho
correlations  between  publi
found notifications and the 

cessing model, the content of a publication request is f
epository  and  the  reasoning  engine  tries  to  infer  n
s,  the  heuristic  analyzer  component  of  SENS  is  provi
turns a list of candidate bindings for each defined chan
andidate  binding  whether  it  represents  a  new  notificat
valid  binding  for  the  defined  query  and  has  not  yet  b
s. If this is the case,  subscribers are immediately  notif
the  next  step,  the  standard  query  processing  task  (q
ly find all new bindings that have not been discovered
y,  the  heuristic  analyzer  component  tries  to  adjust 
od for subsequent requests. It therefore searches for furt
ished  graphs  and  resulting  notifications  (a)  based  on 
history of preceding publication operations.  

first 
new 
ded 
nel. 
tion 
been 
fied 
q)  is 
d in 
and 
ther 
  all 

3   Simple Similarity H

Heuristic 

In the following, we presen
framework.  The  algorithm
solution and should motiva
illustrate  the  algorithms  fu
integration  application.  In 
manage  organizational  an
telephone number, courses,
(heterogeneous) systems are
several  different  terminolo
concepts  of  one  terminolog
implementing  client-to-clie

nt a result set update heuristic for the previously descri
m  should  serve  as  a  proof  of  concept  rather  than  a  fi
ate the development of more advanced algorithms. We w
functionality  by  means  of  a  simplified  example  of  a  d
the  application  scenario,  a  semantic  repository  is  used
nd  reference  data  of  a  university,  e.g.,  name,  addr
 publications, etc. of students and employees. A numbe
e storing and retrieving data from the shared repository.
ogies  are  being  used,  an  ontology  is  employed  that  m
gy  to  semantically  equivalent  concepts  of  the  others. 
ent  communication  via  publishing  and  subscribing

ibed 
final 
will 
data 
d  to 
ess, 
er of 
. As 
maps 
By 
g  to 

M. Murth and e. Kuhn 

knowledge  at  SENS,  data  of  different  data  schemas  is  translated  automatically  and 
transparently for the client.  

In the example, a client registers the following subscription in order to be notified 

whenever new information about a Course of a Lecturer becomes available: 
 

Statement Patterns of Subscription Query 
?L  
http://www.w3.org/1999/02/22-rdf-syntax-ns#type 
http://www.uni.org./onto/Lecturer 
?L 
http://www.uni.org/onto/holdsCourse 
?C 

 
Each  time  a  new  binding  for  this  query  is  found,  the  binding  and  the  previously 
published  graph  are  assigned  to  a  particular  binding  and  graph  category.  The 
following two tables show a published graph consisting of one single triple and a new 
binding resulting from the according publication operation. Note that in the ontology 
of the example, an individual is classified as Lecturer, if it teaches at least one course. 
The role teaches is defined to be the same as holdsCourse. 

Published Graph

http://www.uni 1.org/dep 1/Professor 137 

http://www.uni.org/onto/teaches 
http://www.uni 1.org/courses/Course 148 

                                                                                                                                        Graph Category = 23 

Number of Elements 

 

Binding 
?L = http://www.uni 1.org/dep 1/Professor 137 
?C = http://www.uni 1.org/courses/Course 148 
                                                                                                                               

Number of Elements 
?

?

?
    Binding  Category = 17 

 
Both  categories  are  determined  by  the  number  of  elements  of  the  objects  (i.e., 
graph  or  binding)  textual  representation.  Elements  (underlined  text  blocks)  are 
character  sequences  that  are  separated  by  either  a  delimiter  character  (e.g.,  :,  /, 
., #, etc.) or by a digit following a letter character (e.g., Course-1, Professor-
137). Accordingly, the graph of the above example is assigned to the graph category 
23 (9+6+8) and the binding is assigned to the binding category 17 (9+8). 

Whenever  a  similar  binding  is  found,  it  is  checked  whether  the  graphs  that  were 
published  before  are  similar  as  well.  Similarity  is  defined  by  means  of  a  relation 
between two bindings or graphs. In our heuristic, we simply define similarity via an 
objects  category:  If  and  only  if  two  objects  belong  to  the  same  category,  they  are 
considered  to  be  similar.  While  more  complex  similarity  relations  would  obviously 
allow for a more accurate detection of similar objects, simple relations can usually be 
evaluated more efficiently.  

The following two tables show a second graph that is published after the first one 

and the new binding that results from this publication. 

 

                                                           
2 We added white space characters in the URIs for a better illustration of single elements. 
?

?

?
Published Graph 
http1://www1.uni1 11.org1/dep1 11/FullProfessor1  137 2 
http1://www1.uni1.org1/onto1/teaches1 
http1://www1.uni1 11.org1/courses1/Course1  259 2 
                                                                                      

                                                Graph Category = 23 

Number of Elements 

Binding 
?L = http1://www1.uni1 11.org1/dep1 11/Professor1  137 2 
?C = http1://www1.uni1 11.org1/courses1/Course1  259 2 
                                                                                                                                 
 
According  to  our  heuristic,  both  bindings  as  well  as  both  published  graphs  are 
similar.  The  bindings  and  graphs  elements  are  now  further  separated  into  two 
groups: 

  Binding  Category = 17 

Number of Elements 

  Structure elements: These elements (almost) always remain the same for all 
members of a category. They represent a common structure of members of a 
category. 

  Key  elements:  These  elements  exhibit  high  diversity.  They  represent  the 

distinguishing parts of members of a category. 

In order to determine the group of an element, a history of added elements is kept 
for each category. If the n-th element of a graph or binding has not yet been added at 
the same position before, then the diversity index of this position is increased by one 
(shown as superscript number). As long as the diversity index of an element does not 
exceed a certain  threshold (here < 2), it is considered to be a structure element.  As 
soon as it exceeds the threshold, it is considered to be a key element (shown as framed 
text block).  

If all key elements of a binding can also be found in the published graph, then a 
new  mapping  entry  is  generated.  The  following  mapping  entry  defines  that  the 
publication of a graph of graph category 23 has caused the detection of a new binding 
of  binding  category  17  for  the  query  of  channel  NewCourseChannel.  The  key 
elements of the binding at positions 9 and 17 were found in the published graph at the 
positions 9 and 23, respectively. 

 
Graph Category 
... 

Channel (Query) 
... 
NewCourseChannel 

Binding Category 
... 

Key Element Mappings 
... 
BC(9)=GC(9), BC(17)=GC(23) 

 
When the next graph is published, it is looked up in the mapping table whether it 
already  contains  entries  for  similar  graphs,  i.e.  for  the  respective  graph  category.  If 
this is the case, candidate bindings are generated by taking the structure elements of 
the binding category and the key elements of the published graph.  

The described heuristic will, obviously, not always find all new bindings. The hit 
ratio  highly  depends  on  particular  characteristics  of  the  registered  channels  query. 
The heuristic  will probably  find  most new bindings  for queries  with  high  structural 
similarities between published graphs and found new bindings (independently of the 
complexity of the required querying and reasoning task), but it may not be able to find 
any new bindings for queries with indirect relations between the key elements of the 

M. Murth and e. Kuhn 

published graph and the new bindings. For example, it will be difficult to predict new 
bindings of a query that reports the name of the lecturer who held the same course in 
the  previous  semester,  since  the  newly  published  graph  does  not  contain  any 
information about this lecturer. In the worst case, a certain (configurable) amount of 
time is spent for testing and analysis without finding any new bindings. However, we 
saw that in many applications that build upon semantic technologies, a large number 
of queries exhibit high similarity between published graphs and new bindings and our 
approach  can  therefore  help  to  significantly  improve  the  performance  of  these 
applications. 

4   Evaluation 

In this section, we present an experimental evaluation of the proposed heuristic result 
set update algorithm. We therefore implemented an application scenario based on the 
LUBM benchmark [24]. We employed SENS to manage organizational and reference 
data of universities and realized client-to-client interaction by publishing knowledge 
and subscribing to knowledge updates. For populating the knowledge base, we took 
the  data  set  of  LUBM(10)  (~106  explicit  statements)  and  split  it  into  n  =  114789 
separate  graphs,  each  of  which  containing  2-20  semantically  related  statements. 
Graphs  describing  resources  of  the  same  type  differ  in  size,  structure  and  order  of 
statements. This allows us to investigate whether the heuristic is capable to handle a 
certain level of noise in the published data. In the test scenario, we published n  
1000 graphs to SENS in random order. We then created a semantic event channel for 
each  of  the  14  LUBM  benchmark  queries  and  registered  one  subscriber  at  each 
channel. Finally, we published the remaining 1000 graphs and measured the average 
notification  time  of  the  resulting  notifications  and  the  publication  throughput  of  the 
system. 

In  the  test  setting,  SENS  was  run  with  SwiftOWLIM  2.9  [25],  a  semantic 
repository  with  a  native  full  materialization3  rule  entailment  engine  that  supports 
RDFS [26], OWL DPL [27], OWL Horst and most features of OWL Lite (cf. [25]). 
All tests were run on a Pentium IV HT 3,2GHz, 4GB RAM Windows Vista server. 

4.1   Notification Time 

For  our  measurements,  we  implemented  a  benchmark  framework  that  executes  all 
tests in two runs. In the first run, SENS is started without heuristic result set updates 
and  with  a  query  execution  phase  for  each  publication  operation.  The  framework 
records which publication operation preceded a notification, assigns each operation a 
unique ID and stores benchmark configuration and reference data to an XML file. In 
the  second  run,  the  framework  restarts  the  Java  virtual  machine,  loads  the 
configuration and runs the benchmark using the heuristic result set update algorithm. 
By comparing the results with the results of the first run, notifications can be traced 
back  to  the  publication  operations  they  resulted  from,  even  if  multiple  graphs  are 
published at once.  

The notification time benchmark results are shown in Table 1.  

                                                           
3 Materialization can be switched off for transitive closure to reduce memory consumption. 
?

?

?
ristics Framework for Semantic Subscription Processing 

Table 1. LU

UBM(10)/SwiftOWLIM 2.9 Notification Times  

Tests

Pos. Hitrate  Mapping
Entries

Num. of 
Channel Notif's

Q1
Q2
Q3
Q4
Q5
Q6
Q7
Q8
Q9
Q10
Q11
Q12
Q13
Q14
Q1-14
?

?

?
Positives Negativ
ves (Pos./Notifs#)
?

?

?
0%
0%
0%
0%
69%
93%
18%
94%
0%
0%
89%
0%
0%
96%
91%

Avg. Notification Time
Standard
Heuristic
12 ms
11 ms
0 ms
0 ms
10 ms
10 ms
12 ms
12 ms
14 ms
18 ms
57 ms
526 ms
12 ms
12 ms
19 ms
148 ms
394 ms
381 ms
12 ms
11 ms
12 ms
19 ms
14 ms
13 ms
0 ms
0 ms
31 ms
447 ms
813 ms
95 ms

stic
Heur. vs. Std.
Heuri
head
(-1+Heur./Std.) Overh
2 m
ms
4 m
ms
3 m
ms
1 m
ms
1 m
ms
64 m
ms
1 m
ms
1 m
ms
23 m
ms
1 m
ms
1 m
ms
1 m
ms
1 m
ms
13 m
ms
21 m
ms

9%
0%
0%
0%
-22%
-89%
0%
-87%
3%
9%
-37%
8%
0%
-93%
-88%
?

?

?
The  channels  with  the 
processing mode are Q6, Q
average notification time d
notification time of ~500ms
imposes a high load on the 
The  update  heuristic  w
notifications  (Q5,  Q6,  Q8
published graphs and found
The resulting average notif
the original notification tim
The  tests  showed  that  t
particularly  long  notificati
reduced in the heuristics mo
number  of  notifications  o
notifications provides for b
 

highest  average  notification  time  in  the  SENS  stand
Q8, Q9, and Q14 (marked rows). In this configuration, 
directly corresponds to the query execution time. Henc
s not only causes recognizable delays for the client but a
server.  
works  best  for  those  channels  with  a  high  number
8,  and  Q14).  Since  more  statistical  information  ab
d bindings can be collected, also the hit rate is improv
fication times are reduced by 22%, 89%, 87%, and 93%
mes.  
the  notification  times  for  three  of  the  four  channels  w
ion  times  in  the  standard  mode  could  be  significan
ode (Q6, Q8, and Q14). The reason for this lies in the h
of  these  channels.  On  the  one  hand,  a  high  number
better hit rates during the test phase. On the other hand

dard 
the 
e, a 
also 

r  of 
bout 
ved. 
% of 

with 
ntly 
high 
r  of 
d, a  

Fi

ig. 3. Average notification times (ms) 

M. Murth and e. Kuhn 

high number of notifications is also often the cause for high response times. The result 
sets  of  queries  with  many  result  updates  grow  steadily  (74,  454,  487,  and  359  
notifications) and even if the size of a result set is decreased by deleting knowledge 
from the knowledge base, the average amount of contained bindings is typically high. 
Since the execution time of a query primarily depends on the complexity of the query 
and on the size of the result set, the execution time of these queries is usually higher 
than the execution time of those with a low number of notifications.  

A comparison of response times of all 14 channels is provided in Figure 3.  
Employing the result set update algorithm led to response times of less than 60ms 
for all channels except of Q9. For Q9, the high response time of originally 381ms is 
primarily caused by the structure and complexity of the registered query but not by a 
large result set (only 14 notifications). The query is characterized by the most classes 
and properties of all 14 LUBM queries and includes a triangular relationship between 
its variables. Moreover, new query results frequently contain key elements which are 
not contained in the published graph and this prevents the result set update heuristic 
from  predicting  correct  new  bindings.  Consequently,  the  high  response  time  in  the 
heuristics  mode  results  from  the  original  processing  time  plus  a  small  overhead 
generated by the test and analysis phases. 

While the tests showed promising results with respect to the achieved notification 
times, it also needs to be taken into account that the test  and analysis phases of the 
publication  operations  cause  a  certain  processing  overhead.  Especially  for  those 
channels  with  a  high  number  of  mapping  entries,  these  two  phases  could  even  last 
longer  than  the  query  execution  phase.  If  this  is  the  case,  the  heuristic  update 
mechanism should either be deactivated (for the particular channel) or the number of 
mapping entries should be reduced, e.g., by dropping those with comparably low hit 
rates. 

In summary, the tests showed that the most significant improvements are obtained 
for channels  with a high  number of notifications. However, the effectiveness of the 
heuristic also highly depends on particular characteristics of the published graphs and 
the  registered  query.  Generally,  the  highest  hit  rates  will  be  achieved  when  (i)  key 
elements of bindings are typically contained in the published graphs and (ii) there is 
high similarity between the published graphs and the new bindings. 

4.2   Throughput 

In  the  previous  section  we  showed  that  the  proposed  query  result  update  heuristic 
reduces  response  times  of  certain  kinds  of  queries.  However,  employing  the  update 
heuristic  does  not  yet  improve  the  throughput  of  the  system.  For  this  purpose,  the 
collected statistics can be leveraged in another way: If most of the new bindings are 
found  by  the  update  heuristic,  then  the  query  processing  phase  could  be  skipped  in 
certain intervals. In many cases, query processing is the most costly task of publication 
processing and skipping this phase would save the according processing time.  

Figure 4 and Figure 5 show how many of the previous 10 notifications were found 
by the update heuristic for the channels Q5 and Q6, respectively. Both figures show 
the last 1000 publication operations.  
?

?

?
ristics Framework for Semantic Subscription Processing 

0              200           400            600     

       800          1000 

0              200           400            600            800          100

Fig. 4. Hits per 10 Notific

cations (Q5) 

Fig. 5. Hits per 10 Notifications (Q6) 

For channel Q5, the num
operation and then remains
executed in certain greater 
not be found immediately. 
the next query processing  p
In contrast, the number of 
number  100  and  after  abo
almost all new bindings. Co
introduces only a low risk o
We implemented a simp
per publication as well as th
experimental configuration
than 0.1 notifications per p
the  new  bindings,  then  th
processing cycles. Table 2 
time required for processin
publication operations per s
SENS with heuristic result 
applying the throughput opt

mber of found bindings increases until the 400th publicat
s between 7 and 10. If the query processing would only
intervals, an average of ~20% of the notifications  wo
These notifications would be sent to the subscribers a
phase and exhibit essentially increased notification tim
found bindings for channel Q6 increases until publicat
out  200  publication  operations,  the  update  heuristic  fi
onsequently, skipping the query processing for this chan
of missing new bindings. 
le extension for SENS that records the rate of notificati
he rate of notifications found by the update heuristic. As
n,  we defined that if a channel  exhibits an average of l
publication or the update heuristic finds more than 80%
he  query  processing  is  skipped  for  up  to  10  publicat
shows a comparison of average notification time, aver
ng a publication, and the publication throughput (proces
second) for all three configurations: SENS standard mo
set updates, and SENS with heuristic result set updates 
timization configuration. 

tion 
y be 
ould 
after 
mes. 
tion 
inds 
nnel 

ions 
s an 
less 
% of 
tion 
rage 
ssed 
ode, 
and 

Table 2.

. LUBM(10)/SwiftOWLIM 2.9 Throughput  

Standard
Avg. Notif.  Avg. Pub.
Proc. Time

Heuristic
Avg. Notif.  Avg. Pub.
Proc. Time

Heuristic - Optim. Query. Proc
c.

Avg. Notif.  Avg. Pub.
Proc. Time

Channel

Q1
Q2
Q3
Q4
Q5
Q6
Q7
Q8
Q9
Q10
Q11
Q12
Q13
Q14
Q1-14

Time
11 ms
0 ms
10 ms
12 ms
18 ms
526 ms
12 ms
148 ms
381 ms
11 ms
19 ms
13 ms
0 ms
447 ms
813 ms

10 ms
32 ms
10 ms
12 ms
19 ms
556 ms
11 ms
150 ms
394 ms
11 ms
20 ms
13 ms
11 ms
462 ms
1425 ms

Pub./sec

100.0
31.3
100.0
83.3
52.6
1.8
90.9
6.7
2.5
90.9
50.0
76.9
90.9
2.2
0.7

Time
12 ms
0 ms
10 ms
12 ms
14 ms
57 ms
12 ms
19 ms
394 ms
12 ms
12 ms
14 ms
0 ms
31 ms
95 ms

12 ms
36 ms
13 ms
13 ms
20 ms
620 ms
12 ms
151 ms
417 ms
12 ms
21 ms
14 ms
12 ms
475 ms
1446 ms

Pub./sec

83.3
27.8
76.9
76.9
50.0
1.6
83.3
6.6
2.4
83.3
47.6
71.4
83.3
2.1
0.7

Time
163 ms
0 ms
164 ms
149 ms
122 ms
66 ms
188 ms
53 ms
510 ms
163 ms
60 ms
104 ms
0 ms
47 ms
171 ms

10 ms
32 ms
10 ms
12 ms
14 ms
145 ms
11 ms
41 ms
77 ms
11 ms
13 ms
11 ms
11 ms
93 ms
299 ms

Pub./
/sec
0.0

.3
?

?

?
0.0
.3

.4
?

?

?
6.9

0.9
4.4

.0
?

?

?
0.9

6.9

0.9

0.9
0.8

.3

M. Murth and e. Kuhn 

The channels with the highest average publication processing times in both SENS 

standard and heuristics mode are Q6, Q8, Q9, and Q14 (marked rows). 

As expected, the throughput optimization extension works best for channels with a 
hit  rate  greater  than  80%  (see  Table  1),  namely  Q6,  Q8,  and  Q14.  For  these  three 
channels, the publication rate increased by a factor of 3.7-5.0. Since the extension also 
skips  query  processing  cycles  for  channels  with  a  low  notification  frequency,  the 
publication  throughput  of  Q9  could  also  be  increased  from  2.5  to  13.0  publications 
per second (factor 5.1). 

For the other channels, only small throughput improvements could be achieved. As 
query  processing  takes  only  a  view  milliseconds  for  these  channels,  the  overhead 
introduced by the testing and analysis phase is almost as  high as the time  saved by 
skipping  a  query  processing  cycle.  Furthermore,  these  channels  exhibit  essentially 
worse notification times, as SENS requires up to 10 processing cycles until it finds a 
new binding.  

In summary, we saw that there is a trade-off between notification time and system 
throughput for all 14 channels. By skipping query processing cycles, more operations 
can be processed, but the probability of  missing  notifications increases accordingly. 
Concluding  from  the  implemented  tests,  skipping  query  processing  cycles  is  thus  
best  applied  for  channels  with  (i)  high  query  processing  times  and  (ii)  either  low 
notification  frequency  or  a  high  percentage  of  notifications  found  by  the  update 
heuristic. 

5   Conclusion 

In this paper, we introduced a heuristics framework for incremental result set updates 
for continuous queries on highly dynamic  knowledge bases. We presented a simple 
heuristic  for  this  framework  and  described  how  the  collected  statistical  information 
can  be  employed  to  improve  responsiveness  and  throughput  of  the  semantic 
subscription  system.  We  conducted  an  experimental  evaluation  based  on  a  concrete 
application  scenario,  which  demonstrated  that  the  approach  can  successfully  be 
employed to reduce response times of continuous queries by up to 90% of the original 
response  times.  Moreover,  by  leveraging  the  collected  statistics  for  optimizing  the 
query execution intervals, throughput could be improved by a factor of 3.7-5.1 for the 
most heavyweight publication operations. 

Nonetheless, we also saw that the performance improvement highly depends on the 
concrete  query.  Consequently,  we  plan  to  further  investigate  the  behavior  of  the 
heuristic  in  other  benchmark  environments  as  well  as  in  real  world  applications  in 
order  to  derive  more  detailed  characteristics  of  applications  for  which  the  heuristic 
approach is best applied. Moreover, future work will include the improvement of the 
heuristic algorithm and the development of a framework extension that automatically 
selects the most suitable out of a collection of heuristics based on previously collected 
statistics. 

Acknowledgements. We would like to thank Vesna Sesum-Cavic and Laszlo Keszthelyi 
for their valuable suggestions and numerous comments on this work. 
?

?

