Available online at www.sciencedirect.com

Web Semantics: Science, Services and Agents

on the World Wide Web 6 (2008) 3853

Discovering shared conceptualizations in folksonomies

Robert J aschke a,b, Andreas Hotho a, Christoph Schmitz a,

Bernhard Ganter c, Gerd Stumme a,b,

a Knowledge & Data Engineering Group, University of Kassel, Wilhelmsh oher Allee 73, 34121 Kassel, Germany1

b Research Center L3S, Appelstr. 9a, 30167 Hannover, Germany2

c Institute for Algebra, Dresden University of Technology, 01062 Dresden, Germany3

Received 8 June 2007; received in revised form 30 August 2007; accepted 6 November 2007

Available online 17 November 2007

Abstract

Social bookmarking tools are rapidly emerging on the Web. In such systems users are setting up lightweight conceptual structures called
folksonomies. Unlike ontologies, shared conceptualizations are not formalized, but rather implicit. We present a new data mining task, the mining
of all frequent tri-concepts, together with an efficient algorithm, for discovering these implicit shared conceptualizations. Our approach extends
the data mining task of discovering all closed itemsets to three-dimensional data structures to allow for mining folksonomies. We provide a formal
definition of the problem, and present an efficient algorithm for its solution. Finally, we show the applicability of our approach on three large
real-world examples.
 2007 Elsevier B.V. All rights reserved.

Keywords: Folksonomies; Tagging; Formal Concept Analysis

1. Introduction

Social resource sharing systems on the web, such as
the shared photo gallery Flickr4 or the bookmarking system
del.icio.us,5 have acquired large numbers of users within a few
years. Flickr is known to have more than 1.5 million users,6 while
del.icio.us has celebrated crossing the 1 million users threshold
in 2006.7 The reason for their immediate success is the fact that
no specific skills are needed for participating, and that these tools
yield immediate benefit for each individual user (e.g., organizing
ones bookmarks in a browser-independent, persistent fashion)
without too much overhead.


Corresponding author.
E-mail addresses: jaeschke@cs.uni-kassel.de (R. J aschke),

hotho@cs.uni-kassel.de (A. Hotho), schmitz@cs.uni-kassel.de (C. Schmitz),
bernhard.ganter@tu-dresden.de (B. Ganter), stumme@cs.uni-kassel.de
(G. Stumme).

1 http://www.kde.cs.uni-kassel.de
2 http://www.l3s.de
3 http://www.math.tu-dresden.de/ganter/
4 http://www.flickr.com
5 http://del.icio.us
6 http://money.cnn.com/magazines/business2/business2 archive/2005/12/01/

8364623/

7 http://blog.del.icio.us/blog/2006/09/million.html

1570-8268/$  see front matter  2007 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2007.11.004

The core data structure of a social resource sharing system is a folksonomy. It consists of assignments of arbitrary
keywordscalled tagsto resources by users. Folksonomies
are thus a lightweight knowledge representation for sharing
knowledge on the web.

1.1. Discovering shared conceptualizations

Unlike ontologies, folksonomies do not suffer from the
knowledge acquisition bottleneck, as the significant provision
of content by many people shows. On the other hand, folksonomiesunlike ontologies [29]do not explicitly state shared
conceptualizations, nor do they force users to use the same tags.
However, the usage of tags of users with similar interests tends
to converge to a shared vocabulary. Our intention is to discover
these shared conceptualizations that are hidden in a folksonomy.
To this end, we present in this paper an algorithm, Trias, for discovering subsets of folksonomy users who implicitly agree (on
subsets of resources) on a common conceptualization.

Our algorithm will return a tri-ordered8 set of triples, where
each triple (A, B, C) consists of a set A of users, a set B of tags,
and a set C of resources. These triplescalled tri-concepts in

8 See Section 2.4 for details.

With its sets of users, tags, and resources, folksonomies
have one additional dimension compared to typical basket analysis datasets (which consist of the two dimensions items
and transactions). Informally spoken, the task of mining all
frequent tri-sets is to discover all triples of sets of users,
tags, and resources, resp., such that, for each triple of sets,
all users in the first set have assigned all tags in the second
set to all resources in the third set, and that the cardinalities of the three sets are above predefined minimum support
thresholds.9

As in the classical case, the resulting set of all frequent trisets is usually too large, and can be condensed without any loss
of information. To this end, we adapt the notion of iceberg concept lattices/closed itemsets to the three-dimensional nature of
folksonomies. With our Trias algorithm, we provide an efficient
method for computing all frequent tri-concepts.

1.3. Contribution and organization of the paper

In this paper, we present the following contributions:

concepts,

 a formal definition of the problem of mining frequent tri-
 Trias, an efficient algorithm for solving the problem,
 and a conceptual analysis of two social bookmarking systems

and an IT security manual by means of this algorithm.

The paper is organized as follows. In the next section, we
introduce folksonomies and social resource sharing systems in
more detail and motivate the need of a conceptual clustering
approach for this kind of data. In Section 2, we discuss the state
of the art and related work in the research areas of folksonomies,
ontology learning, Formal Concept Analysis, and closed itemset mining. In Section 3.1, we provide the formal definition
of the problem of mining all frequent tri-concepts; in Section
3.2, we introduce our Trias algorithm; and in Section 3.3, we
evaluate its performance. In Section 4, we apply our approach
on three large-scale real-world applications: the folksonomy of
the popular bookmark sharing system del.icio.us, the collection of publications in our social reference management system
BibSonomy, and a manual for protecting IT infrastructure.
Section 5 concludes with an outlook on future work. Parts of
this article have been presented as a short paper at the Intl. Conf.
on Data Mining 2006 [35] and at the Intl. Conf. on Conceptual
Structures 2007 [36].

2. Basic notions and state of the art

In this section, we recall the basic notions and discuss the
state of the art of the research areas relevant to this article: folk-
sonomies, Ontology Learning, Formal Concept Analysis and its
triadic version, and the mining of closed itemsets.

9 In classical association rule mining, the thresholds equal the minimum sup-

port and minimal length thresholds.

Fig. 1. History of iceberg tri-lattices.

the sequelhave the property that each user in A has tagged
each resource in C with all tags from B, and that none of these
sets can be extended without shrinking one of the other two
dimensions. Each retrieved triple indicates thus a set A of users
who (implicitly) share a conceptualization, where the set B of
tags is the intension of the concept, and the set C of resources
is its extension. We can additionally impose minimum support
constraints on each of the three dimensions users, tags, and
resources, to retrieve the most significant shared concepts only.

1.2. The problem of closed itemset mining in triadic data

From a data mining perspective, the discovery of shared conceptualizations opens a new research field which may prove
interesting also outside the folksonomy domain: Closed itemset
mining in triadic data, which is located on the confluence of the
research areas of association rule mining and Formal Concept
Analysis.

Formal Concept Analysis (FCA) [74,25] is a mathematical
theory that formalizes the concept of concept, and allows for
computing concept hierarchies out of data tables. At the end
of last century, one discovered that it also provides an elegant
framework for significantly reducing the effort of mining association rules [50,78,64]. A new research area emerged which
became known as closed itemset mining in the data mining
community and as iceberg concept lattices [68] in FCA.

Independent of this development, Formal Concept Analysis
has been extended about ten years ago to deal with threedimensional data [40]. This line of Triadic Concept Analysis
did not receive a broad attention up to now. With the rise of
folksonomies as core data structure of social resource sharing systems, however, the interest in Triadic Concept Analysis
increased again.

With this paper, we initiate the confluence of both lines of
research, Triadic Concept Analysis and closed itemset mining
(see Fig. 1). In particular, we give a formal definition of the
problem of mining all frequent tri-concepts (in other terms: the
three-dimensional version of mining all frequent closed item-
sets), and present our algorithm Trias for mining all frequent
tri-concepts of a given dataset.

R. J aschke et al. / Web Semantics: Science, Services and Agents on the World Wide Web 6 (2008) 3853

Fig. 2. Bibsonomy displays bookmarks and (BibTEX-based) bibliographic references simultaneously.

2.1. Social resource sharing systems and folksonomies

Social resource sharing systems are web-based systems that
allow users to upload their resources, and to label them with
arbitrary words, so-called tags. Each system has a specific type
of resources it supports. Flickr, for instance, enables the sharing
of photos, del.icio.us the sharing of bookmarks, CiteULike10
and Connotea11 the sharing of bibliographic references, and
43Things12 even the sharing of goals in private life. Our own
system, BibSonomy 13([33], see Fig. 2), allows the sharing of
bookmarks and BibTEX entries simultaneously.

In their core, these systems are all very similar. Once a user
is logged in, he can add a resource to the system, and assign
arbitrary tags to it. The collection of all his assignments is his
personomy, the collection of all personomies constitutes the folk-
sonomy. The user can explore his personomy, as well as the
personomies of the other users, in all dimensions: for a given
user one can see all resources he has uploaded, together with the
tags he has assigned to them (see Fig. 2); when clicking on a
resource one sees which other users have uploaded this resource
and how they tagged it; and when clicking on a tag one sees who
assigned it to which resources.

The word folksonomy is a blend of the words taxonomy
and folk, and stands for conceptual structures created by the
people [73]. Folksonomies are thus a bottom-up complement to
more formalized Semantic Web technologies, as they rely on
emergent semantics [61,62] which result from the converging

10 http://www.citeulike.org
11 http://www.connotea.org
12 http://www.43things.com
13 http://www.bibsonomy.org

use of the same vocabulary. The main difference to classical
ontology engineering approaches is their aim to respect to the
largest possible extent the request of non-expert users not to be
bothered with any formal modeling overhead. Intelligent techniques may well be inside the system, but should be hidden from
the user.

tags, and resources, resp.,

A folksonomy describes the users, resources, and tags, and
the user-based assignment of tags to resources. We recall here
our formal definition of folksonomies [34], which is also underlying our BibSonomy system.
Definition 1. A folksonomy is a tuple F := (U, T, R, Y,)
where
 U, T , and R are finite sets, whose elements are called users,
 Y is a ternary relation between them, i.e., Y  U  T  R,
whose elements are called tag assignments (tas for short),
and
  is a user-specific subtag/supertag-relation, i.e.,  U 
T  T , called is-a relation.
The personomy Pu of a given user u U is the restric-
i.e., Pu := (Tu, Ru, Iu,u) with Iu :=
tion of F to u,
{(t, r) T  R | (u, t, r) Y}, Tu := 1(Iu), Ru := 2(Iu), and
u := {(t1, t2) T  T | (u, t1, t2) }, where i denotes the
projection on the ith dimension.

Users are typically described by their user ID, and tags may
be arbitrary strings. What is considered as a resource depends on
the type of system. For instance, in del.icio.us, the resources are
URLs, in flickr, the resources are pictures, and in BibSonomy
they are either URLs or publication entries.

As the is-a relation  was only implemented in a rudimentary way (so-called bundles in del.icio.us) in one of the systems
considered in our paper at the time of writing,14 we will ignore it
for the purpose of this paper. Therefore, we will consider a folksonomy as a four-tuple F := (U, T, R, Y), without the relation.
Related work: While the scientific community has only begun to
explore folksonomies as a knowledge representation mechanism
as well as a source of data which can be mined for different pur-
poses, there is a growing number of publications concerned with
the various aspects of this new phenomenon. Overviews of social
bookmarking tools with special emphasis on folksonomies are
provided by [31,43], as well as [46,60] who discuss strengths
and limitations of folksonomies. Recent papers include [28,21]
which focus on analyzing and visualizing the structure of folk-
sonomies. The knowledge discovery, information retrieval, and
knowledge engineering communities are currently becoming
involved in this development, e.g., by enhancing recommendations given by the systems, improving search and ranking, and
structuring the knowledge in a systematic way.

Cattuto et al. [17] investigate statistical properties of tagging
systems and introduce a stochastic model of user behaviour;
[30] analyses the dynamics and semantics of tagging systems,
and [39] introduces further techniques to structure the tripartite
network of folksonomies. Recently, work on more specialized
topics such as structure mining on folksonomies, e.g., to visualize trends [21] has been presented.

In Ref. [34], we presented FolkRank, a differential version
of the PageRank algorithm [11] for computing topic-specific
rankings of users, tags, and resources in a folksonomy. In Ref.
[57], we computed association rules on del.ico.us data.

2.2. Ontology learning

The term ontology learning was first introduced by Maedche
and Staab in Ref. [44]. It stands for the task of (semi-) automatically constructing an ontology or a domain model. Usually
machine learning or data mining algorithms are applied mostly
on textual data to extract the hidden conceptualization from the
data and to make it explicit. Revealing the hidden conceptualization of an author partially written in a text document can be seen
as a kind of reverse engineering task (cf. Ref. [18]). All ontology
learning approaches try to support the knowledge engineer by
setting up the ontology. Recent advances in ontology learning
are described in Ref. [12].

In this paper, we describe one step for learning ontologies
from folksonomies. Other approaches are discussed in the next
paragraph.

Related work: Approaches trying to analyze the weakly
structured information of folksonomies and use this to learn
conceptualization or ontologies are still rare. Among them is
the work of Mika [47], who defines a model of semantic-social
networks for extracting lightweight ontologies from del.icio.us.
Besides calculating measures like the clustering coefficient,
(local) betweenness centrality or the network constraint on the

14 BibSonomy now provides the  hierarchy as relations.

extracted one-mode network, Mika uses co-occurrence techniques for clustering the folksonomy.

Heymann and Garcia-Molina [32] propose a new clustering algorithm to construct a tag hierarchy. Schmitz proposes
in Ref. [58] the construction of a subsumption tree consisting
of Flickr tags based on the tag co-occurrence network of tags.
Both approaches are showing ways to construct an ontology, but
both are using only parts of the information of an folksonomy
as they are based on an aggregated graph rather than the full
folksonomy.

2.3. Formal Concept Analysis

Formal Concept Analysis (FCA) is a conceptual clustering technique that formalizes the concept of concept
as established in the international standard ISO 704
a concept is considered as a unit of thought constituted of two
parts: its extension and its intension [74,25]. This understanding of concept is first mentioned explicitly in the Logic of
Port Royal [4]. To allow a formal description of extensions and
intensions, FCA starts with a (formal) context:
Definition 2 ([74]). A formal context is a triple K := (G, M, I)
which consists of a set G of objects [German: Gegenst ande], a set
M of attributes [Merkmale], and a binary relation I  G  M.
(g, m) I is read as object g has attribute m.

This data structure equals the set of transactions used for
association rule mining, if we consider M as the set of items and
G as the set of transactions.
Definition 3 ([74]). For A  G, let
AI := {m M | g A : (g, m) I};
and dually, for B  M, let
BI := {g G | m B : (g, m) I}.
Now, a formal concept is a pair (A, B) with A  G, B 
M, AI = B and BI = A. A is called extent and B is called intent
of the concept.

This is equivalent to saying that A  B  I such that neither

A nor B be can be enlarged without violating this condition.

Definition 4 ([74]). The set B(K) of all concepts of a formal context K together with the partial order (A1, B1) 
(A2, B2) : A1  A2 (which is equivalent to B1  B2) is a
complete lattice, called the concept lattice of K.

The concept lattice is a hierarchical conceptual clustering
of the data which can be visualized by a Hasse diagram. This
visualization technique has been used in many applications for
qualitative data analysis [24]. An example of a Hasse diagram
is given in Fig. 6 and described in more detail in Section 4.1.

Related work: FCA has grown over the years to a powerful
theory for data analysis, information retrieval, and knowledge
discovery [65]. In Artificial Intelligence (AI), FCA is used as
a knowledge representation mechanism [66] and as conceptual
clustering method [63,15,48]. In database theory, FCA has been

R. J aschke et al. / Web Semantics: Science, Services and Agents on the World Wide Web 6 (2008) 3853

extensively used for class hierarchy design and management
[49,77,20,72,56,27].

The amount of publications on Formal Concept Analysis is
abundant. A good starting point for the lecture are the textbooks
[25,16,24], the collection of FCA publications in BibSonomy,15
and the proceedings of the Intl. Conference on Formal Concept
Analysis16 and the Intl. Conference on Conceptual Structures17
series.

2.4. Triadic Concept Analysis

Inspired by the pragmatic philosophy of Charles S. Peirce
with its three universal categories [54], Rudolf Wille and Fritz
Lehmann extended Formal Concept Analysis in 1995 with a
third category:
Definition 5 ([40]). A triadic formal context is a quadruple
F := (G, M, B, Y) where G, M, and B are sets, and Y is a ternary
relation between G, M, and B, i.e., Y  G  M  B. The elements of G, M, and B are called (formal) objects, attributes, and
conditions, resp., and (g, m, b) Y is read object g has attribute
m under condition b.
folksonomy F := (U, T, R, Y) without tag hierarchy .
Definition 6 ([40]). A triadic concept of F is a triple
(A1, A2, A3) with A1  G, A2  M, and A3  B with A1 
A2  A3  Y such that none of its three components can be
enlarged without violating this condition.
From each of the three dimensions one obtains a quasi-order
3, resp., on the set of all tri-concepts: For i =

1, 
1, 2, 3, let (A1, A2, A3)

A triadic formal context models exactly the structure of a

i(B1, B2, B3) iff Ai  Bi.

2, and 

The definition of a triadic concept is the natural extension of
the definition of a formal concept to the triadic case. Alternatively the definition can be described with I operators similar to
the dyadic case, but as there are now three dimensions involved,
the notation (which we omit here, cf. Ref. [40]) becomes more
complex.
Lemma 1 ([40]). For two tri-concepts a and b, and for i = j =
k = i, a

b implies b

b and a

a.

This implication is the triadic version of the dyadic proposition that for two dyadic concepts (A1, A2) and (B1, B2) holds
A1  B1 iff B2  A1. In the dyadic case, the two orders induced
by the concept extents and the concept intents, resp. are thus
dually isomorphic. This allows for visualizing the concept lattice
in just one diagram and is at the same time the justification for
the famous support pruning strategy in the Apriori algorithm. In
the triadic case, the relationship between the three quasi-orders
is unfortunately weaker (as seen above), which makes both the
mining (see Section 3.2) and the visualization (see Section 4.2)
more complex. Figs. 79 show examples of diagrams of triadic
concept lattices; they are discussed in detail in Section 4.

15 http://www.bibsonomy.org/tag/fca
16 http://www.informatik.uni-trier.de/ley/db/conf/icfca/
17 http://www.informatik.uni-trier.de/ley/db/conf/iccs/

Lehmann and Wille present in Ref. [40] an extension of
the theory of ordered sets and (concept) lattices to the triadic
case, and discuss structural properties. This approach initiated
research on the theory of concept tri-lattices.

Whereas there have been some significant publications on
the mathematical properties of tri-lattices (see below), this
approach had no large impact on real-world applications up
to now. This is mainly due to its above-mentioned resistance
to scalable visualizations. With the rise of social resource
sharing systems on the web,
triadic data move again in
the focus of many researchers. In this setting, one needs
beside a more scalable visualization paradigmknowledge discovery and information retrieval methods and algorithms that
are able to handle very large datasets.

Related work: Following the initial paper [40] by Lehmann
and Wille, several researchers started to analyze the mathematical properties of tri-lattices, e.g., [79,19,23,75,76]. Refs.
[40,19] present several ways to project a triadic context to a
dyadic one. Ref. [67] presents a model for navigating a triadic
context by visualizing concept lattices of such projections. In
Ref. [57], we discussed how to compute association rules from
a triadic context, based on these (and other) projections. A first
step towards truly triadic association rules has been done in
Ref. [23].

2.5. Closed itemset mining

In terms of Formal Concept Analysis, the task of mining
frequent itemsets [1] can be described as follows: Given a formal context K = (G, M, I) and a threshold minsupp [0, 1],
determine all subsets B of M where the support supp(B) :=
card(BI)/card(G) (with BI as defined above) is larger than the
threshold minsupp. In warehouse basket analysis, M is the set
of items and G is the set of transactions.

The set of these so-called frequent itemsets itself is usually
not considered as a final result of the mining process, but rather
an intermediate step. Its most prominent use are association rules
[1]. Association rules are for instance used in warehouse basket analysis, where the warehouse management is interested in
learning about products that are frequently bought together.

Since determining the frequent itemsets is the computationally most expensive part, most research has focused on this
aspect. Most algorithms follow the way of the well-known
Apriori algorithm [2], which is traversing iteratively the set of
all itemsets in a levelwise manner. Algorithms based on this
approach have to extract the supports of all frequent itemsets
from the database. However, this is by no means necessary.

It turned out that FCA can significantly improve both the
efficiency and the effectiveness of frequent itemset mining.
[50,78,64] discovered independently that it is sufficient to consider the intents of those concepts where the cardinality of their
extent is above the minimum support threshold. These frequent
concept intents are called closed itemsets in association rule min-
ing, because the set of all concept intents is a closure system (i.e.,
it is closed under set intersection). The corresponding closure
operator is the consecutive application of the two I operators
defined in the previous subsection, i.e., for an itemset B, the

set BII is the smallest concept intent containing B. This closure
operator will be used in the Trias algorithm in Section 3.2.

In FCA,

the equivalent notion is
lattice [68], which is

that of an ice-
the
-semi-lattice
berg concept
{(A, B) B(K) | card(A)/card(G)  minsupp} with the order
defined in Section 2.3. The iceberg concept lattice visualizes
the most frequent concepts of a dataset [68], and allows for an
efficient visualization of a basis (condensed set) of association
rules [69,52]. These bases allow to reduce the number of rules
significantly without losing any information.

Related Work: The problem of mining frequent itemsets arose
first as a sub-problem of mining association rules [1], but it
then turned out to be present in a variety of problems: mining sequential patterns [3], episodes [45], association rules [2],
correlations [59], multi-dimensional patterns [37,41], maximal
itemsets [6,79,42], closed itemsets [71,50,51,53].

The first algorithm based on the combination of association
rule mining with FCA was Close [50], followed by A-Close
[51], ChARM [78], Pascal [5], Closet [53], and Titanic [68],
each having its own way to exploit the closure operator which is
hidden in the data. Many algorithms can be found at the Frequent
Itemset Mining Implementations Repository.18

Beside closed itemsets, other condensed representations have
been studied: key sets [5]/free sets [10], -free sets [10], nonderivable itemsets [14], disjunction free sets [13], and k-free sets
[55]. Closed itemsets and other condensed representations can
be used for defining bases of association rules [69,52].

3. Mining all frequent tri-concepts of a folksonomy

In this section we formalize the problem of mining all frequent tri-concepts of a folksonomy, present the Trias algorithm
for its efficient solution, and discuss its performance.

3.1. The problem of mining all frequent tri-concepts

We will now formalize the problem of mining all frequent tri-
concepts. We start with an adaptation of the notion of frequent
itemsets to the triadic case.
Definition 7. Let F := (U, T, R, Y) be a folksonomy/triadic
context. A tri-set of F is a triple (A, B, C) with A  U, B  T ,
C  R such that A  B  C  Y.

As folksonomies have three dimensions which are completely
symmetric, one can establish minimum support thresholds on all
of them. The general problem of mining frequent tri-sets is then
the following:

(Mining

frequent

tri-sets). Let F :=
Problem 1
(U, T, R, Y) be
and let
context,
u-minsupp,t-minsupp,r-minsupp [0, 1]. The task of mining
all frequent tri-sets consists in determining all tri-sets (A, B, C)
| B | /| T |  t-minsupp,
of F with | A| /| U |  u-minsupp,
and | C | /| R|  r-minsupp.

folksonomy/triadic

all

18 http://fimi.cs.helsinki.fi/

This is actually a harder problem than the direct adaptation
of frequency to one more dimension: In classical frequent itemset mining, one has a constraintthe frequencyonly on one
dimension (the number of transactions). Thus the equivalent
triadic version of the problem would need two minimum support thresholds only (say u-minsupp and u-minsupp). However,
this seems not natural as it breaks the symmetry of the prob-
lem. Hence we decided to go for the harder problem directly
(which equals in the dyadic case the addition of a minimal
length constraint on the itemsets). The lighter version with
only two constraints is then just a special case (e.g., by letting
r-minsupp := 0).

As

in the dyadic case, our

thresholds are mono-
tonic/antimonotonic constraints: If (A1, B1, C1) with A1 being
maximal for A1  B1  C1  Y 19 is not u-frequent, then all
(A2, B2, C2) with B1  B2 and C1  C2 are not u-frequent
either. The same holds symmetrically for the other two dimen-
sions.

With the step from two to three dimensions, however, the
direct symmetry between monotonicity and antimonotonicity
(which results in the dyadic case from the dual order isomorphism between the set of concept extents and the set of concept
intents) breaks. All we have in the triadic case is the following
lemma which results (via the three quasi-orders defined in Section 2.4) from the triadic Galois connection [8] induced by a
triadic context.

Lemma 2 (cf. Ref.
[40]). Let both (A1, B1, C1) and
(A2, B2, C2) be tri-sets with Ai being maximal for Ai  Bi 
Ci  Y, for i = 1, 2.20If B1  B2 and C1  C2 then A2  A1.
The same holds symmetrically for the other two directions.

As the set of all frequent tri-sets is highly redundant, we will
in particular consider a specific condensed representation, i.e.,
a subset which contains the same information, namely the set of
all frequent tri-concepts.

Definition 8. A tri-set is a frequent tri-concept if it is both a
tri-concept and a frequent tri-set.

all

(Mining

frequent

Problem 2
tri-concepts). Let
F := (U, T, R, Y) be a folksonomy/triadic context, and let
u-minsupp,t-minsupp,r-minsupp [0, 1]. The task of mining all
tri-concepts consists in determining all
(A, B, C) of F with |A|/|U |  u-minsupp,
tri-concepts
|B|/|T |  t-minsupp, and |C|/|R|  r-minsupp.

frequent

Sometimes it is more convenient to use absolute rather than
relative thresholds. For this case we let u := | U|  u-minsupp,
t := |T|  t-minsupp, and r := |R|  r-minsupp.

Once Problem 2 is

solved, we obtain the answer
to Problem 1
straightforward
as
{(A, B, C) |  frequent tri-concept ( A, B, C) : A  A, B  B,
C  C,|A|  u,|B|  t,|C|  r}.

enumeration

in

19 In the dyadic case this condition is implicitly covered by the use of BI in
the definition of the support since, for any given B  M, the set BI is always
maximal with BI  B  I.
20 This holds in particular if the tri-sets are tri-concepts, see Lemma 1.

R. J aschke et al. / Web Semantics: Science, Services and Agents on the World Wide Web 6 (2008) 3853

3.2. The Trias algorithm for mining all frequent
tri-concepts

Our algorithm for mining all frequent tri-concepts of a folksonomy F := (U, T, R, Y) is listed as Algorithm 1. A prior
version was used for analysing psychological studies [38]. That
application varied from Trias as it aimed at an iterative pruning
of the data set. Furthermore, it did not take into account any
frequency constraints.
We let  Y := {(u, (t, r))|(u, t, r) Y}, and we identify the elements of U, T, and R with natural numbers, i. e. U = {1, . . . ,|U|}
(and symmetrically for T, R). In both its outer and its inner
loop, Trias calls the pairs of subroutines FirstFrequentConcept
((G, M, I), ) and NextFrequentConcept ((A, B), (G, M, I), ).
These two routines provide an enumeration of all frequent dyadic
concepts (A, B) of the formal (dyadic) context (G, M, I). The
context is passed over as input parameter. FirstFrequentConcept
returns in (A, B) the first concept of the enumeration. NextFrequentConcept takes the current concept (A, B) and modifies it
to the next concept of the enumeration. This way, we compute
all frequent maximal cuboids in the relation Y by consecutively
computing maximal rectangles in the binary relations  Y and
I, resp., where the condition in line 9 of Algorithm 1 checks
if the rectangle layers form a maximal cuboid. Note that A 
(B  C)  Y trivially holds, because of A = I
 Y and (B  C)  I.
Hence, only  has to be checked.

Algorithm 1. The Trias algorithm for mining all frequent tri-
concepts

Algorithm 2. The FirstFreqentConcept function of the Trias
algorithm

Algorithm 3. The NextFreqentConcept function of the Trias
algorithm

For computing all (frequent) maximal rectangles in a binary
relation, one can resort to any algorithm for computing (iceberg)
concept lattices. The enumeration can be done in any convenient
way. For the inner and the outer loop, one could use different
algorithms for that task.

In our implementation we equipped the NextClosure algorithm [22,25] of the fourth author with frequency pruning for
implementing the FirstFrequentConcept and NextFrequentConcept routines (see Algorithms 2 and 3, resp.) for both the outer
and the inner loop. This algorithm has the advantage that it needs
almost no space in main memory.

NextClosure computes the concepts of a dyadic formal context (G, M, I) in a particular order, starting with the concept
(I ,II). For a given concept (A, B), NextClosure computes the
concept (C, D) whose intent D is the next set after B in the socalled lectic order. The lectic order on sets is a total order and is
equivalent to the lexicographic order of bit vectors representing
those sets.
To find the next concept we define, for B  M and i M,

B  i := (B  {1, . . . , i  1})  {i}.
By applying the closure operator X  XII to B  i, the algorithm computes, for a given B, the set D := (B  i)II. This is
the lectically next intent, if B<iD holds, meaning that i is the
smallest element in which B and D differ, and i D.
The method NextFrequentConcept adopts this idea and additionally checks if the computed extent A := (B  i)I fulfills the
minimal support criterion before computing the intent D := AI.
This is done in line 4 of Algorithm 3 by considering the extent
A only if it is large enough.
Taking a closer look on the function I revealed that it
demands the computation of several set intersections at a time.
Since profiling showed that this is the main bottleneck of the
algorithm, we optimized this by first ordering the sets to be intersected by size (with the smallest set first). Then the algorithm
recursively intersects them with a procedure used for merge-
sort. This is possible, since every itemset of the binary context
can be accessed as ordered list in the data structure described in
the following.

Because two sortings of Y are needed, instead of storing both,
we just store the permutations for every order and an additional
offset table which allows constant time access to the triples of a
given tag, user, or resource. The chosen approach is exemplified
in Fig. 3. The table on the left contains the unsorted triples Y

Fig. 3. Accessing triples in sorted order.

of which only the values from U are shown here. The table in
the middle describes the permutation which allows to access the
triples in lexicographic order. Finally, the right table contains,
for every element u U, an offset which points to the position
in the second table, which points to the first triple of that user
in the Y list. Together, all this allows constant time access to the
sorted tag-resource set of every user.

3.3. Performance of the Trias algorithm

As in the dyadic case, the number of (frequent) tri-concepts
may grow exponentially in the worst case. Biedermann has
shown in Ref. [9] that the concept tri-lattice of the triadic context
of size n  n  n where only the main diagonal is empty has size
3n. In typical applications, however, one is far from this theoretical boundary. Therefore we focus on empirical evaluations on
a large-scale real-world dataset.

For measuring the runtime and the number of frequent concepts we have evaluated the performance of Trias on a snapshot
of the del.icio.us system (which is described in more detail in
Section 4.1). It consists of all users, tags, resources and tag
assignments we could download that were entered to the system on or before June 15, 2004. From this base set we created
monthly snapshots as follows. F0 contains all tag assignments
performed on or before December 15, 2003, together with the
involved users, tags, and resources; F1 all tag assignments performed on or before January 15, 2004, together with the involved
users, tags, and resources; and so on until F6 which contains all
tag assignments performed on or before June 15, 2004, together
with the involved tags, users, and resources. This represents
seven monotonously growing contexts describing the del.icio.us
folksonomy at different points in time. For mining frequent trisets and frequent tri-concepts we used minimum support values
of u := t := r := 2 and measured the run-time of our Java
implementations on a dual-core Opteron system with 2 GHz
and 8 GB RAM.

Fig. 4 shows the number of frequent tri-concepts versus the
number of frequent tri-sets on the logarithmically scaled y-axis,
whereas the x-axis depicts the number of triples in Y which
grows from 98,870 triples in December 2003 to 616,819 in June
2004. It shows a massive increase of frequent tri-sets in June
2004 with only a modest growth of the number of frequent tri-
concepts. This difference results from the fact that more and
more users appear and start to agree on a common vocabulary,

Fig. 4. Number of frequent tri-sets vs. number of frequent tri-concepts.

which leads to more frequent tri-concepts with larger volumes
from June 2004 on. Such large concepts (like those shown in
Table 1) contain many frequent tri-sets.

One can observe that the number of frequent tri-sets of every
snapshot is always at least one magnitude of size larger than the
number of frequent tri-concepts. Consequently, computing frequent tri-sets is much more demanding than computing frequent
tri-conceptswithout providing any additional information.

A comparison of the speed improvement gained from not
computing all tri-concepts with an algorithm like Next Closure and afterwards pruning the non-frequent concepts but using
the Trias algorithm for directly mining frequent tri-concepts is
shown in Fig. 5. The logarithmically scaled y-axis depicts the
runtime of the algorithms in seconds while the x-axis shows
again the size of the Y relation. One can see that computing

Table 1
Examples of frequent tri-concepts of del.icio.us

bibi poppy
women cinema film

http://www.reelwomen.org/
http://www.people.virginia.edu/pm9k/libsci/womFilm.html
http://www.lib.berkeley.edu/MRC/womenbib.html
http://www.beaconcinema.com/womfest/
http://www.widc.org/
http://www.wftv.org.uk/home.asp
http://www.feminist.com/resources/artspeech/media/femfilm.htm
http://www.duke.edu/web/film/pioneers/
http://www.womenfilmnet.org/index.htm#top
http://208.55.250.228/

fischer gnat
css design web

http://www.quirksmode.org/
http://webhost.bridgew.edu/etribou/layouts/
http://www.picment.com/articles/css/funwithforms/
http://www.alistapart.com/articles/sprites/

angusf carlomazza
css design web

http://www.positioniseverything.net/index.php
http://www.fu2k.org/alex/css/layouts/3Col NN4 FMFM.mhtml
http://glish.com/css/home.asp
http://www.maxdesign.com.au/presentation/process/index.cfm
http://unraveled.com/projects/css tabs/

R. J aschke et al. / Web Semantics: Science, Services and Agents on the World Wide Web 6 (2008) 3853

Table 1 shows three examples. The first of them shows that
the two users bibi and poppy have assigned the three tags women,
cinema, and film to all the ten listed web pages, which are all
about women in movies or women in the movie industry.

The two lower tri-concepts show that different tri-concepts
with the same extent can co-exist.22 The first of them shows
that the two users fischer and gnat agree (implicitly) in their
assignments of the tags css, web, and design to the four listed
URLs, while the users angusf and carlomazza agree in assigning
the same tags to five completely different URLs. When inspecting the corresponding web pages, one finds out that the content
of all resources is indeed very much related. These two related
tri-concepts may be exploited further for extracting relations
between tags or for recommending to all of the four users to
study the posts of the other three.

) Y}|))  k2, for a given k2  [0, 1].

Next, we wanted to study in more detail shared conceptualizations around the tags css, web, and design. To this end, we
computed the concept lattice that is shown in Fig. 6. Its formal context (G, M, I) was constructed as follows. Its set G of
objects was extracted from the set of all resources by selecting all those resources which were tagged with at least one of
these three tags by at least k1  N users. The set M contains all
tags. A tag t  M is defined to be related to a resource r  G
(i.e., (r, t) I) iff ((|{u U | (u, t, r) Y}|)/(|{u U |r
  R :
(u, t, r
In this analysis, we have set k1 = 5. This means that a
resource was considered only if at least five users assigned it
to at least one of the tags css, web, and design. This resulted
in 575 resources. The second pruning parameter was set to
k2 = 0.5, i.e., at least half of the users who considered a
resource had to use a particular tag, otherwise the tag was not
assigned to the resource. This resulted in a relatively sparse
assignment which reflects only rather strong shared conceptu-
alizations. This way, only 22 tags were assigned to at least one
resource; and only 297 out of the 575 resources received at least
one tag.

The resulting concept lattice is displayed in Fig. 6. Because of
space restrictions, we pruned from it the tags rest, cms, wiki, xml,
fonts, wordpress, google, search, colour, art, and music. These
tags formed singletons (i.e., separate nodes that were connected
only to the top and to the bottom element of the lattice) with one
or two resources each.

Each node in the diagram is a formal concept according to
the definition in Section 2.3, i.e., a pair (A, B) where A is its
extent (all resources belonging to it), and B is its intent (all
tags belonging to it). In the diagram, the extent of a concept
consists of all resources attached to the concepts or to any of
its sub-concepts; and the intent consists of all tags that are
attached to the concept or to any of its super-concepts. The
left-most concept, for instance, has the two URLs starting with
http://www.fiftyfoureleven. . . as extent, and the set {php,css}
of tags as intent. The top node represents the concept (G, GI),
and the bottom node the concept (MI , M).

Fig. 5. Runtime of triadic Next Closure and Trias algorithm on del.icio.us
datasets.

all tri-concepts is more than one magnitude more expensive
than mining only the frequent tri-concepts one is interested
in.

With these observations we conclude that the Trias algorithm
provides an efficient method to mine frequent tri-concepts in
large-scale conceptual structures.

4. Applications

We have applied the algorithm on three real-world data
sets: the social bookmarking system del.icio.us, the IT Baseline
Security Manual of the German Federal Office for Information Security, and the collection of publications in our social
reference management system BibSonomy.

4.1. The social bookmarking system del.icio.us

First, we have analyzed the popular social bookmarking
sytem del.icio.us with our approach. Del.icio.us is a server-based
system with a simple-to-use interface that allows users to organize and share bookmarks on the internet. It is able to store for
each URL, in addition to the tags assigned to it, a description
and a note.

For detecting communities of users which have the same tagging behaviour (an thus share their conceptualizations), we ran
the Trias algorithm on a del.icio.us snapshot consisting of all
users, resources, tags and tag assignments we could download
that were entered to the system on or before June 15, 2004
[34]. The resulting folksonomy consists of |U| = 3, 301 users,
|T| = 30, 416 different tags, |R| = 220, 366 resources (URLs),
which are linked by |Y| = 616, 819 triples.
As a first step, we ran Trias on the dataset without restricting
the minimum supports (i.e., u := t := r := 0). The resulting concept tri-lattice consists of 246, 167 tri-concepts. We then
investigated the concepts which contain two or more users, tags
and resources, i.e., with u := t := r := 2. There were 1,062
such tri-concepts.21

21 Larger thresholds did not provide any results any more. This comes from
the fact that we took a rather early snapshot of del.icio.us, where the numbers
of users, tags, and resources were still rather small. See also Section 3.3.

22 This is in contrast to the situation in the dyadic case, where equality in one
dimension implies equality in the other one.

Fig. 6. Most relevant tags and resources related to css, web, and design.

Fig. 7. All frequent tri-concepts of the IT Baseline Security Manual for u = t = r = 3.

The diagram shows that most agreement exists for the usage
of the tag css, as it was assigned (according to our majority vote
with the k2 threshold) to 235 resources, while web was assigned
to only 14 resources, and design to 31 resources. Apparently,
the latter are too general or polysemous terms to reach a large
agreement about their usage.

The resulting concept

lattice could now be used for
building a concept hierarchy. It suggests to the ontology engi-
neer, e.g., to model architecture as a sub-concept of design.
Another use of the concept lattice is a collaborative filtering approach to web search. When a user is for instance
searching for web design, the system could recommend him
the web pages http://www.alistapart.com/articles/elastic and
http://9rules.com/version2/.

4.2. IT baseline protection manual

To illustrate another use of iceberg tri-lattices, we focus
now on a non-folksonomy application. The IT Baseline
Security Manual [26] of the German Federal Office for
Information Security provides a description of a threat scenario and standard security measures for typical IT systems,

and detailed descriptions of safeguards to assist with their
implementation.23

Unlike a folksonomy, this manual has not been set up by
an open group of users, but by a closed group of experts of
the federal office. The manual has thus carefully been designed
by domain specialists, and can be considered as an ontology
(a formal specification of the shared conceptualization of the
experts of the federal office)structured in form of a triadic
context. Here, we use our knowledge discovery approach not
for discovering a shared conceptualization, but for analysing it.
Even though the manual is smaller than a typical folksonomy
resulting from a social bookmarking system, it is still by far too
large to be analyzed without technical support.

The core data of the manual forms a triadic context
(U, T, R, Y). We consider as objects U the 66 IT components, as
attributes T the 377 listed threats, and as conditions R the 912
safeguards. They are related by 5,680 triples.24

23 The online version of the manual is available at http://www.bsi.de/gshb/
24 See Refs. [19,70,76] for other analyses of this dataset.

R. J aschke et al. / Web Semantics: Science, Services and Agents on the World Wide Web 6 (2008) 3853

From this dataset, we have computed the iceberg concept
lattice for u = t = r = 3. Its visualization in Fig. 7 follows
the conventions introduced in Ref. [40]. The five nodes in the
middle are the five resulting frequent tri-concepts. The sets of
users, tags, and resources composing a tri-concept can be read
off the three sides of the triangle. There, three Hasse diagrams
display the three quasi-orders 
3 as introduced in
Section 2.4. The arrows guide the reader to the larger elements
of each quasi-order. Each node in a hierarchy represents the set
containing the labels attached to it plus all labels below. The
empty nodes are not part of the quasi-order. They are just used
to be able to place each label once only. In the IT components
hierarchy on the right, for instance, the leftmost node represents
the set {Computer Centres, Data Media Archives, Server Room,
Technical Infrastructure Room}.

2, and 

1, 

A node in the middle of the diagram represents then the triconcept consisting of the three components it projects to. The
left-most tri-concept, for instance, is the tri-concept ({Computer
Centres, Server Room, Data Media Archives, Technical Infrastructure Room}, {Unauthorized entry into a building, Theft,
Vandalism}, {Locked doors, Entry regulations and controls,
Closed windows and doors}).
The three corners of the inner triangle are not realized (as
there are no nodes on them). They stand for the tri-sets (, T, R),
(U,, R), and (U, T,), resp., and are only realized if the first,
second, or third threshold is set to zero.

The manual distinguishes seven classes of IT components,
like Networked Systems and Telecommunications. The fact that
all components that occur in the most frequent tri-concepts (i.e.,
the six components in the right-most hierarchy) are of the Infrastructure class indicates that this class was modeled with the
highest level of detail. Surprisingly it surpasses more typical IT
classes like the two mentioned above.
For having a closer look, we decrease the minimum thresh-
olds, e.g., to u = 3, t = r = 2. The resulting tri-lattice is
shown in Fig. 8. It contains the previous five tri-concepts plus
five new ones. We see that again the major contribution comes
from the Infrastructure class, which is now extended by Protective cabinets. Additionally some more of the combinations of
these components became frequent, indicated by the additional
nodes in the right hierarchy.

With the decreasing thresholds, the lower left hierarchy grew
as well. It contains now additionally four threats in two separated
nodes. These nodes are not comparable (in terms of set inclu-
sion) with the already existing nodes. The threats in the lower
one of themFailure of internal supply networks, Fireare
extending the list of threats against the Infrastructure class via
the IT component Building. The upper hierarchy shows the safeguards against these new threats: Hand-held fire extinguishers
and Adapted segmentation of circuits.

The threats in the uppermost isolated node of the lower left
hierarchyMisuse of administrator rights [. . .] and Unauthorized acquisition [. . .]belong to a new class of IT components,
as they are related to the new isolated node with three Windows
operating systems in the right diagram. The safeguards against
these threats are listed at the isolated node in the upper diagram.
The IT components that seem to be endangered secondmost are

thusafter IT infrastructure roomsWindows operating sys-
tems. At least they are modeled with greater detail as other
operating systems that show up when decreasing the thresholds
further.

If we decrease the minimum thresholds further, we can discover this way more and more details, until we finally reach with
u = t = r = 0 all 3,751 tri-concepts of this dataset.

4.3. Conceptual analysis of the BibSonomy publication
data

We conclude the list of applications with another social
resource sharing system. BibSonomy25 is a social bookmark and
publication management system that is run by the Knowledge
& Data Engineering Group at the University of Kassel. Beside
sharing bookmarks, BibSonomy enables the sharing of publication lists. It provides several output formats, including BibTEX,
formatted HTML, RTF, EndNote, XML, RDF, and RSS-Feeds.
BibSonomy can thus be used for generating reference lists for
scientific publications and annual reports, as well as for personal,
group, and project homepagessupporting researchers in their
everyday business. As a folksonomy offers the possibility to add
more than one tag to a resource, documents can be found following different search paths, unlike books in a library which
can only be placed in one physical location.

For our analysis we focused on the publication management
part of BibSonomy. We first made a snapshot of BibSonomys publication entries, including all publication posts made
until November 23, 2006 at 13:30 CET. From the snapshot
we excluded the publication posts from the DBLP computer
science bibliography26 since they are automatically inserted
and all owned by one user and all tagged with the same tag
(dblp). Therefore they do not provide meaningful information about shared conceptualizations. Similarly, we excluded
all tag assignments with the tag imported and all publication
posts which exclusively have this tag, because it is automatically assigned to all posts which were added by one of the
import functions. The resulting snapshot contains |Y| = 44, 944
tag assignments built by |U| = 262 users, containing |R| =
11, 101 publication references tagged with |T| = 5, 954 distinct
tags.27

The Trias algorithm needed 75 min on a 2 GHz AMD
Opteron machine to compute all 13,992 tri-concepts of this
dataset. Among those there are 12,659 tri-concepts which
contain only one user, representing the individual conceptualizations of the users. (These could be used to present personal
concept hierarchies by means of dyadic Hasse diagrams.) The
remaining 1,333 tri-concepts thus all contain at least two users
and therefore represent shared concepts. To further analyze these
concepts, we next take a closer look on the tri-concepts which
contain at least three users, two tags and two publication entries

25 http://www.bibsonomy.org
26 http://www.informatik.uni-trier.de/ley/db/
27 BibSonomy benchmark datasets are available for scientific purposes, see
http://www.bibsonomy.org/faq

Fig. 8. All frequent tri-concepts of the IT Baseline Security Manual for u = 3, t = r = 2.

Fig. 9. All frequent tri-concepts of the BibSonomy publications for u = 3, t = 2, r = 2.

R. J aschke et al. / Web Semantics: Science, Services and Agents on the World Wide Web 6 (2008) 3853

Table 2
The mapping of publication IDs to publication titles

Publication title

A Finite-State Model for On-Line Analytical Processing in Triadic Contexts
Annotation and Navigation in Semantic Wikis
A Semantic Wiki for Mathematical Knowledge Management
BibSonomy: A Social Bookmark and Publication Sharing System
Bringing the Wiki-Way to the Semantic Web with Rhizome
Building and Using the Semantic Web
Conceptual Clustering of Text Clusters
Content Aggregation on Knowledge Bases using Graph Clustering
Creating and using Semantic Web information with Makna
Emergent Semantics in BibSonomy
Explaining Text Clustering Results using Semantic Structures
Harvesting Wiki Consensus - Using Wikipedia Entries as Ontology Elements
Information Retrieval in Folksonomies: Search and Ranking
KAON  Towards a Large Scale Semantic Web
Kaukolu: Hub of the Semantic Corporate Intranet
Kollaboratives Wissensmanagement
Learning with Semantic Wikis
Mining Association Rules in Folksonomies
On Self-Regulated Swarms, Societal Memory, Speed and Dynamics
Ontologies improve text document clustering
Proceedings of the First Workshop on Semantic Wikis  From Wiki To Semantics
Proc. of the European Web Mining Forum 2005
Semantic Network Analysis of Ontologies
Semantic Resource Management for the Web: An ELearning Application.
Semantic Web Mining
Semantic Web Mining and the Representation, Analysis, and Evolution of Web Space
Semantic Web Mining for Building Information Portals (Position Paper)
Social Bookmarking Tools (I): A General Review
Social Bookmarking Tools (II). A Case Study  Connotea
Social Cognitive Maps, Swarm Collective Perception and Distributed Search on Dynamic Landscapes
SweetWiki : Semantic Web Enabled Technologies in Wiki
Text Clustering Based on Background Knowledge
The ABCDE Format Enabling Semantic Conference Proceedings
The Courseware Watchdog: an Ontology-based tool for Finding and Organizing Learning Material
Towards a Wiki Interchange Format (WIF)  Opening Semantic Wiki Content and Metadata
Towards Semantic Web Mining
TRIAS - An Algorithm for Mining Iceberg Tri-Lattices
Usage Mining for and on the Semantic Web (Book)
Usage Mining for and on the Semantic Web (Workshop)
Wege zur Entdeckung von Communities in Folksonomies
WordNet improves text document clustering

(i.e., with minimal support values u = 3, t = 2, r = 2). Each
of these 21 tri-concepts expresses the fact that all of its users
tagged all its publications with all its tags.

The diagram in Fig. 9 shows the triadic concept lattice of all
these 21 tri-concepts. The titles of the publications in the figure
are substituted by numbers for space reasons. The corresponding
titles can be found in Table 2, the full bibliographic information
was tagged in BibSonomy (after the evaluation) with the tag
trias example.28 As in Figs. 7 and 8, the 21 nodes in the center
of the triangle represent the 21 frequent tri-concepts. The sets of
users, tags, and resources composing a tri-concept can be read
off the three sides of the triangle.
For instance, the lower most node in the triangle represents
the tri-concept consisting of the set {jaeschke, schmitz, stumme}

28 http://www.bibsonomy.org/group/kde/trias example?items=50

of users, the set {fca, triadic} of tags, and the set {1, 37} of
resources. Similarly, the node in the user hierarchy labelled
brotkasting represents not only the user brotkasting but also
all users in nodes laying below this node. Therefore the users
jaeschke andsince it is located below both brotkasting and
jaeschkestumme also belong to this node. Note that it fulfills
thus the minimal support constraint u = 3 for the users.

A closer look on the tag hierarchy reveals the content of the
most central publications in the system. The tag social co-occurs
with most of the tags. On the level of generality defined by the 
thresholds, this tag is (together with the tags ai (meaning Artificial Intelligence), . . ., tags) assigned by the users lkl kss and yish
to the publications 19 and 30, (together with the tag bookmark-
ing) by the users hotho, jaeschke, stumme to the publications 4
and 28, and (again together with the tag bookmarking) by the
users brotkasting, jaeschke, stumme to the publications 28 and
29. The tags as well as the corresponding publication titles indi-

cate that the two sets of users {lkl kss, yish} and {brotkasting,
hotho, jaeschke, stumme} form two sub-communities which
both work on social phenomena in the Web 2.0, but from different perspectives.

A second topical group is spanned by the tag semantic, which
occurs in three different contexts. The first is on semantic wikis,
which correlates with the isolated group {2, . . ., 31, 12, 33, 35}
of publications, and theequally isolatedgroup {lysander07,
xamde, deynard, langec} of users. The second context in which
the tag semantic occurs is on Semantic Web Mining, being
connected by the users {grahl, hotho, stumme} with different
combinations of the additional tags web and mining to the publications 6, 14, 22, 25, 26, 27, 36, 38, and 39. These assignments
are witnessed by the three tri-concepts in the very middle of the
diagram. On the same line are two more tri-concepts, which indicate that these users are also interested in text clustering and in
nepomuk (the acronym of a European project). The third context
in which the tag semantic occurs is in combination with folkson-
omy. This provides a link to the group {2006, myown, nepomuk,
bibsonomy, folksonomy} of tags which are used by the authors
of this paper and by other researchers from the European project
Nepomuk29 to describe their own publications.

Two more topical groups can be found at the top and bottom
of the tags quasi-order. One is related to a Peer-to-Peer eLearning
application, and the other to triadic Formal Concept Analysis.
Since the diagram shows the frequent tri-concepts only, we
cannot deduce from the absence of a relationship that two objects
are not related at all. When the thresholds are lowered, links
between the topical islands discussed above will show up.

Concluding, we see that iceberg tri-concept lattices provide a
means for exploring the flat structure of folksonomiesjust as
iceberg concept lattices in the dyadic case. One may be surprised
by the relatively small numbers of frequent tri-concepts. This
showsjust as in the dyadic casethat the closeness condition
provides a strong criterion for pruning the result set without loss
of information.

5. Conclusion and outlook

In this paper, we have presented a formal definition of the
problem of mining all frequent tri-concepts, and have presented
an efficient algorithm for its solution. We have empirically studied the performance of the algorithm, and have presented two
real-world applications.

This work opens a series of challenging tasks for future
research. (i) An important issue for the presentation of the results
is the development of a visualization metaphor to display small,
medium, and large (frequent) concept tri-lattices, and to provide
efficient means for navigating and browsing them. (ii) Continuing the research on association rules, a natural next step would be
the development of triadic association rules, combining thus
the developments in triadic FCA and association rule mining.
(iii) The natural next step after discovering shared conceptualizations would be to formalize them in an ontology. We plan

29 http://nepomuk.semanticdesktop.org/

thus to extend our approach to an ontology learning applica-
tion. (iv) These steps together lead to a development which is
currently undertaken in the European project Nepomuk  The
Social Semantic Desktop: the exploitation of Trias for discovering and managing communities in a peer to peer network of
semantic desktops.

Acknowledgement

Part of this research was funded by the EU in the Nepomuk

project (FP6-027705).
