Web Semantics: Science, Services and Agents on the World Wide Web 6 (2008) 266273

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

Revyu: Linking reviews and ratings into the Web of Data
Tom Heath a,b,, Enrico Motta b

a Talis Information Limited, Knights Court, Solihull Parkway, Birmingham B37 7YB, United Kingdom
b Knowledge Media Institute, The Open University, Walton Hall, Milton Keynes MK7 6AA, United Kingdom

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 15 May 2008
Received in revised form 22 August 2008
Accepted 15 September 2008
Available online 23 October 2008

Keywords:
Semantic Web
Linked Data
Reviews
Ratings
Revyu

1. Introduction

Revyu is a live, publicly accessible reviewing and rating Web site, designed to be usable by humans whilst
transparently generating machine-readable RDF metadata for the Semantic Web, based on user input. The
site uses Semantic Web specifications such as RDF and SPARQL, and the latest Linked Data best practices
to create a major node in a potentially Web-wide ecosystem of reviews and related data. Throughout the
implementation of Revyu design decisions have been made that aim to minimize the burden on users, by
maximizing the reuse of external data sources, and allowing less structured human input (in the form of
Web 2.0-style tagging) from which stronger semantics can later be derived. Links to external sources such
as DBpedia are exploited to create human-oriented mashups at the HTML level, whilst links are also made
in RDF to ensure Revyu plays a first class role in the blossoming Web of Data. In this paper we document
design decisions made during the implementation of Revyu, discuss the techniques used for linking Revyu
data with external sources, and outline how data from the site is being used to infer the trustworthiness
of reviewers as sources of information and recommendations.

 2008 Elsevier B.V. All rights reserved.

Reviews and ratings are widely available on the Web and are one
major form of user-generated content that has become associated
with Web 2.0 [25]. However, despite the availability of reviews and
ratings through APIs such as the Amazon Associates Web Service
[2], this data remains largely isolated in silos, and described in
formats that hinder its integration and interlinking with data from
other sources. This presents considerable barriers to the aggregation of all reviews of a particular item from across the Web, as
an item reviewed in one silo cannot easily be associated with the
same item reviewed elsewhere. As has been recognised by previous authors [15,16], the Semantic Web, or Web of Data, provides a
technological platform with which to overcome this problem and
Revyu is a significant and concrete step towards realising a solu-
tion.

Revyu is a live, publicly usable and well used reviewing and
rating Web site, launched in November 2006 and available at
http://revyu.com/. The site combines an approachable interface
for the creation of reviews by human users with a range of APIs
through which Semantic Web applications can access machine-

 Corresponding author at: Talis Information Limited, Knights Court, Solihull
Parkway, Birmingham B37 7YB, United Kingdom. Fax: +44 870 400 5001.

E-mail addresses: tom.heath@talis.com (T. Heath), e.motta@open.ac.uk

(E. Motta).

1570-8268/$  see front matter  2008 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2008.09.003

readable data for reuse in third-party applications. The site has
been developed using Semantic Web technologies and standards
such as RDF [19] and SPARQL [26], and according to Linked Data
principles [5] and best practices [7]. These features enable Revyu
to readily consume data from external services for the creation
of human-oriented mashups while also seeding an ecosystem of
interlinked review and rating data on the Web that is helping to
bootstrap the Semantic Web as a whole. In the following sections
we will describe Revyu in more detail, examine these human- and
machine-oriented characteristics and discuss many of the underlying design decisions.

2. Revyu compared to conventional Web APIs

Revyu allows people to review and rate things simply by filling in a Web form. This style of interaction with the site will be
familiar to those who have written reviews on sites such as Epinions [12], Amazon [1] or TripAdvisor [28]. Whilst this functionality
is not especially novel, as a reviewing application Revyu improves
significantly over other work in the area in a number of ways.

First, Revyu is not a data silo that locks data away for safe keep-
ing. Instead, reviews and ratings created within Revyu are exposed
in a reusable, machine-readable data format, RDF. This contrasts
with sites that collect data from users but only republish it in HTML,
thereby masking the structure created by the author of the review
and no doubt still represented in the underlying database. The RDF
data model represents a more flexible mechanism for publishing

Fig. 1. The Revyu.com home page.

structured data than approaches such as microformats,1 which are
not supported by a common underlying data model and consequently present greater challenges for those wishing to parse and
consume published data.

Secondly, the data access mechanisms provided by Revyu
improve upon the APIs of sites such as Amazon. Publishing data
in RDF allows for easier merging of data from disparate sources,
as heterogeneous data can be combined in one document without
the document as a whole needing to conform to a single schema.
Golbecks FilmTrust [15] is noteworthy as one of the first applications to make review data available on the Web in RDF. However
it is limited to the domain of films and does not provide a query
interface to the underlying data via languages such as SPARQL. The
Revyu SPARQL endpoint provides developers with greater flexibility in querying the underlying data set than is generally possible
with conventional Web APIs.

Thirdly, Revyu takes a Linked Data [5] approach to publishing
reviews and ratings on the Web. The technical aspects of Revyu
as a Linked Data application will be described in detail in later
sectionsat this stage it is sufficient to outline the benefits of the
approach:

1. All entities within the Revyu site are addressable over the Web,
allowing these to be referenced from other online data sets. In
the context of Revyu, third parties may use this capability to indicate (dis-)agreement with a particular review, or where there
may be a conflict of interest that compromises the credibility

1 http://microformats.org/.

of a particular reviewer (as reported in [31]) this can be high-
lighted. Crucially, this additional information can be published
elsewhere on the Web in RDF, simply referencing the appropriate items on Revyu. This avoids the creation of a single silo in
which all information must be located.

2. Duplication of data across data providers is reduced. There is less
need for Revyu to maintain local copies of data about reviewed
items, and incur the associated data management overhead, as
RDF statements can be used to connect review data with richer
item descriptions in other locations on the Web. This has the
effect of encouraging data to remain published and managed by
the authoritative source.

3. Data integration can be performed once, and reused many times.
A data publisher need only expend the effort once to link entities
in their data with those in external data sets, and publish these
links as RDF statements for consumption by third parties. This
removes the need for each data consumer to perform their own
data integration, the results of which may be locked within application code used to create mashups and therefore not available
for reuse by others.

Lastly, Revyu takes an open world perspective on the reviewing process by not constraining users to reviewing items from a
fixed and pre-selected database. Anything a user can name can
be reviewed, and consequently reviewers are not restricted to
reviews and ratings in one domain. By supplying links related to
the item they are reviewing, users enable disambiguation and linking of reviewed items through inverse functional properties such
as foaf:homepage.

T. Heath, E. Motta / Web Semantics: Science, Services and Agents on the World Wide Web 6 (2008) 266273

3. A usable Semantic Web system

A major goal of Revyu was to create a Semantic Web application that could be used by non-specialist users, i.e. those with no
experience or knowledge of Semantic Web technologies. This was
achieved by making the creation and publication of RDF invisible
to the reviewer, enabling users to contribute data to the Semantic Web through a familiar, Web 2.0-style mode of interaction. The
Revyu home page is shown in Fig. 1.

As of May 2008 Revyu has attracted 837 reviews from 261
distinct reviewers. This corresponds to over 35,000 RDF triples publicly available on the Semantic Web. Whilst not a large figure by
many standards, it is significant that many of these triples have
been generated from direct user input, rather than by data min-
ing, extraction from natural language, or conversion of existing
databases.

3.1. Tagging in Revyu

When creating Revyu, a significant decision was taken to not
require users to classify the item they were reviewing, but instead
to associate keyword tags with the item. This decision was taken for
several reasons: firstly there was not seen to be a sufficiently comprehensive classification available of items that users may want
to review; secondly, requiring all users to subscribe to a single
classification scheme for reviewed items seemed unnecessarily
constraining and against the open-world spirit of the Semantic
Web; thirdly, providing a usable interface through which nonspecialists could classify items using arbitrary types discovered in
ontologies on the Semantic Web was seen as unfeasible; and lastly,
even the coverage provided by multiple ontologies readily available on the Web was deemed insufficient to describe all items that
might be reviewed, therefore potentially resulting in a more closed
world of reviewed items.

Despite the availability of large-scale ontologies such as Yago
[27], and their integration with DBpedia [3], we believe that these
issues remain unresolved. For example, the Yago class that should
be used to describe a relatively simple concept such as movie
remains unclear, and users cannot be expected to engage in such
issues during review creation.

We believe that tagging retains the appropriate balance of
usability whilst also providing data from which stronger semantics can be derived. At present we use tagging data in two ways: to
identify basic semantic relationships between tags, and to derive
type information about a reviewed item.

3.1.1. Identifying co-occurring tags

Tags that are frequently associated with the same item are
assumed to be related in some way. In the HTML pages about each
tag, tags that co-occur above a certain threshold are displayed to the
user. This threshold is set low for HTML output, as human readers of
the page are unlikely to infer erroneous information based on these
relationships. In contrast however, relationships exposed in RDF
descriptions of tags (using the skos:related property) are based
on a more conservative threshold, in order to avoid erroneous inferences based on these assertions. In the future these co-occurrence
relationships may also be described using the SCOT ontology.2

3.1.2. Deriving type information

We currently derive type information from tagging data in two
domains, books and films, relying on external data sources to help

2 http://scot-project.org/scot/spec.

ensure accurate results. Firstly, where items are tagged book we
parse Web links provided by the reviewer that relate to the item,
and attempt to extract ISBN numbers embedded in these links.
Where we are able to extract an ISBN number in this fashion we
conclude that the reviewed item is in fact a book, and add a corresponding rdf:type statement to the triplestore.

If an item has been tagged film or movie, we execute a query
against the DBpedia SPARQL endpoint in order to find any films
that have the same name as the reviewed item. If a match is found
then we conclude this item is in fact a film, and add an rdf:type
statement to this effect to the triplestore. These type statements
for both books and films are exposed in the RDF descriptions of
items on Revyu, and also serve as the basis for showing additional
relevant data in the HTML pages about an item, as detailed below.

4. Revyu architecture and implementation

Revyu is built on the same technologies that support many conventional Web applications  Apache, MySQL and PHP  but is
also fundamentally a Semantic Web application from the ground
upwards. Backend storage of RDF triples is provided by a denormalised MySQL database. The application layer uses the RDF
API for PHP (RAP) [24] for accessing, querying, manipulating and
serializing RDF data.

All site content  reviews, data about reviewers, data about
reviewed items and the tags reviewers assign to these  is published
on the site simultaneously in HTML and RDF/XML. These HTML and
RDF descriptions of resources are published as separate crawlable
documents on the Revyu site but interlinked using RDF Autodiscovery techniques. The site uses the Review [4], FOAF [9] and Tag [23]
ontologies to describe reviews, reviewers and tags respectively, as
well as properties and classes from RDFS and OWL.

4.1. Human-oriented vs. machine-oriented mashups

The data exposed in HTML and RDF descriptions of resources
is not always isomorphic. In the RDF descriptions of resources we
choose to simply expose data from Revyu, complemented by links
to additional data in external data sets. Data from external sources
is not republished in Revyu RDF output. In contrast, HTML pages
about items in Revyu do reproduce external data. This approach
could be described as using Semantic Web data to produce Web 2.0-
style mashups at the human-readable, HTML level, whilst simply
linking data at the RDF level.

The rationale for this design decision is as follows: humanoriented HTML documents need to present coherent and
comprehensive information to a user viewing that document with
a conventional Web browser, without requiring her to navigate to
many other pages unless she requires related information. There-
fore, the publisher of a human-oriented mashup may choose to
integrate data from various sources and provide a coherent view
to the user that somewhat masks the provenance of the data, as
the user can choose to trust the mashup (and its underlying data
sources) based on the extent to which they trust the site on which
it is published.

In contrast to this Web of Documents perspective, the Semantic Web is designed to enable data to be integrated from multiple
sources in potentially unanticipated ways. As a result, data publishers cannot make any assumptions about how the data in a single
RDF document will be viewed, as different Semantic Web applications will approach this in different ways. We argue that browsers
for the Web of Data should be able to follow RDF links between
related data sources, integrate this distributed data dynamically,
and present a unified, coherent view to the end user. In this sce-

nario, replicating RDF data from one source in a different location
is redundant and potentially obscures the origin of data, thereby
complicating the process of reasoning about and conveying data
provenance in user applications.

It should be noted that we do not claim that the Revyu Web
2.0-style mashups represent something that could not have been
achieved using conventional Web 2.0 approaches. However, to
clarify, the following features distinguish our approach: the simultaneous publishing of data-oriented and human-oriented mashups,
so that the data integration effort we have invested is not lost
but can be reused by other parties; the ability to easily integrate
additional heterogeneous sources using RDF; and the substantially
reduced development costs in producing human-oriented mashups
through use of Semantic Web technologies.

4.2. Programmatic access to Revyu data

Third parties can access Revyu data by performing HTTP GET
requests on the URIs of RDF documents on the Revyu site. In addi-
tion, data held within the site can be queried programmatically
via the Revyu SPARQL endpoint. The Revyu SPARQL endpoint uses
the RAP SPARQL engine, which operates against the same MySQLbased triplestore as the rest of the Web site. This SPARQL endpoint
allows third parties to access Revyu data for reuse in their own
applications. Whilst in some ways analogous to Web 2.0 APIs that
provide remote query capabilities, SPARQL endpoints afford many
advantages to the developer: for example, common libraries can
be used to query multiple RDF graphs yet return the results as
one resultset, effectively allowing joins over multiple data sources;
furthermore, developers are not limited to performing certain
pre-selected queries defined by an APIinstead queries can be performed to retrieve arbitrary elements of the underlying RDF graph.

5. Production and consumption of Linked Data

5.1. Linkable Data in Revyu

Rather than simply publishing islands of unconnected RDF data
on the Web, Revyu was designed from the outset to adhere to the
four principles of Linked Data, outlined by Berners-Lee [5]: using
URIs as names for things, using HTTP URIs so people can look up
those names, providing useful information when someone looks up
a URI, and linking to other URIs so more things can be discovered.
By following these principles and Linked Data best practices [7] the
site ensures that reviews it hosts can be fully connected into a Web
of Data.

All things represented on Revyu are assigned URIs: reviews, peo-
ple, reviewed things, tags assigned to things, and even the bundles
that represent tags assigned by one person at one point in time.
Providing URIs for all reviewers and reviewed things gives many
items a presence on the Semantic Web which they would not have
otherwise, and enables any third party to refer to these items in
other RDF statements. This linkable data creates the potential for
inward links to Revyu from other data sets.

All URIs in the Revyu URI-space can be dereferenced. Attempts
to dereference the URIs of non-information resources receive an
HTTP303 See Other response containing the URI of a document
that describes the resource. This adheres to the W3C Technical Architecture Groups finding on the httpRange-14 issue [30],
and serves to reinforce the distinction between a resource and
a description of that resource, as each has a distinct URI. Content negotiation is also performed on the URIs of non-information
resources, whereby the user agent receives a description of the
resource in either HTML or RDF depending on the value of the
Accept: header sent in the initial HTTP request.

5.2. Linking to other data sets

In addition to publishing data in a form that is amenable to
inward linking on the Semantic Web, Revyu also aims wherever
possible to create outward links from entities in the site to those in
external, related data sets, in order to create a Web of Data rather
than simply isolated islands of RDF.

At present there are outgoing links from Revyu to DBpedia [3],
the RDF Book Mashup [6], the Open Guide to Milton Keynes [13], the
Randomness Guide to London, papers from the 6th International
Semantic Web Conference, and papers from the Linked Data on
the Web (LDOW2008) workshop [8]. These links take the form of
owl:sameAs statements in RDF, to assert that two URIs identify
the same resource, and have been produced in two different ways,
retroactively and proactively.

5.2.1. Retroactive linking

Our initial approach to linking across data sets took items that
had already been reviewed in Revyu, and attempted to match these
with the same item represented in different data sets. This approach
has been used in the domains of books and films. As described
above, where an item has been tagged book and an ISBN can be
extracted from the related links provided by a reviewer, then an
owl:sameAs link is set to the corresponding item in the RDF Book
Mashup. Similarly, where a reviewed item has been tagged film
or movie and a match found via the DBpedia SPARQL endpoint,
an owl:sameAs link is set to that item in DBpedia. This approach
has met with some success, but has a number of disadvantages: the
book matching algorithm relies on users providing certain types of
links when they review an item, which we have found to not always
be a reliable assumption; the film matching algorithm is overly
reliant on string matching, and constrained by the lack of string
similarity functions in SPARQL; custom matching algorithms are
required for each type of reviewed item, which is not very scalable
when any type of item can be reviewed.

5.2.2. Proactive linking

In order to overcome the limitations of retroactive linking, we
have investigated a proactive approach based on priming Revyu
with skeleton descriptions of items that users may wish to review.
These skeleton records simply include a text label for the item, a
statement indicating the type of the item, a number of relevant keyword tags, and an owl:sameAs link to the same item in the external
source data set. Not only does this provide a foundation upon which
new reviews can be created, it also ensures that new reviews of
these items are instantly part of the Web of Data. Compared to
the retroactive approach, in this case linking becomes trivial and is
guaranteed to succeed, as the skeleton record for an item is created
based on data about an item whose URI in an external data set is
already known.

This skeleton record approach has been followed when linking
Revyu to data from the Open Guide to Milton Keynes and the Randomness Guide to London, both members of the Open Guides family
of wiki-based city guides that expose data in RDF. Taking the Open
Guide to Milton Keynes as an example, whilst some amenities in
the city, such as pubs and restaurants, were already reviewed on
Revyu, many more were listed in the Open Guide due to its longer
history. Therefore, after identifying items existing in both locations
and making the appropriate mappings to avoid duplication, we created skeleton records in Revyu for the remaining items, setting links
back to their Open Guide URIs.

This has enabled latitude and longitude data for many items to
be retrieved from RDF exposed by the Open Guide, and used to show
a Google Map of the items location (see Fig. 2 for an example). The

T. Heath, E. Motta / Web Semantics: Science, Services and Agents on the World Wide Web 6 (2008) 266273

Fig. 2. Location map of reviewed item using external geodata.

same approach can also be used to expose address, telephone, and
opening time information held in the Open Guide.

Our goal is to apply this proactive approach to many other
domains, such as books, restaurants, academic papers and films
(for which a set of 12,000 skeleton records has already been prepared based on DBpedia data). The major barrier to this approach
at present is not the availability of source data sets from which to
create skeleton records, but the ability of the existing infrastructure
to scale to very large numbers of triples.

Whilst the proactive approach has many benefits when compared to the retroactive linking method, the requirement for
manual preparation of skeleton data sets remains an issue. We
expect this to be somewhat mitigated by the inevitable increase in
the number of items semantically described on the Web, which can
then be automatically harvested and imported into Revyu. How-
ever, there will always remain a significant proportion of items that
are not described in this way, for which alternative methods will be
required. Additional issues to be resolved include management of
skeleton records related to items that frequently change, or those
that are removed from the external data sets from which skeleton
records were derived.

5.3. Consuming Linked Data to enhance the user experience

Once links are made between items in Revyu and those in external data sets, these are actively exploited to enhance the experience

of our users. This manifests itself in a number of ways, such as
using geodata from the Open Guides to provide show locations of
reviewed items on a map, as described above. In addition, where
owl:sameAs statements exist linking films on Revyu to their entry
in DBpedia, we retrieve additional information about the film, such
as the URI of the films promotional poster, and the name of the
director. This information is displayed on the Revyu HTML page
about the film (as shown in Fig. 3), thereby enhancing the value of
the site for users without requiring this information to be manually
entered into Revyu. Similarly we use owl:sameAs links between
Revyu and the RDF Book Mashup [6] as the basis for retrieving book
cover and author information which is also then displayed on the
Revyu HTML page about the book.

6. Reusing existing personal profiles

External data about reviewers contributing to the site is also
reused within Revyu. A common experience with existing Web
applications is that, on registration, the user must create a new
profile that duplicates profiles they have already created on other
sites. This can increase the burden on the user as they must manage
multiple redundant sets of personal information stored in different
locations. In addition to consuming external data about items that
have been reviewed on the site, Revyu aims to address this issue by
reusing existing profile information about reviewers, where this is
available on the Semantic Web.

Fig. 3. Profile page of The Prestige with DBpedia film data.

Consequently, people registering with the site are not required
to provide copious information to populate their user profile.
Instead, where they have an existing FOAF description in an external location they may provide its URI to Revyu. In such cases, Revyu
dereferences this URI and queries the resulting graph for relevant
information (such as a photo, location, home page URI, and inter-
ests), which is then displayed in the HTML version of their user
profile, as illustrated in Fig. 4.

In contrast to the HTML view, information from external FOAF
files is not republished in the RDF version of the reviewer profile.
Whilst this does introduce a disparity between the HTML and RDF
documents, in terms of what information is exposed, this decision
was taken in order to avoid duplicating RDF data that is already
available elsewhere on the Semantic Web. To enable Semantic Web
applications to locate this related RDF data rdfs:seeAlso links
are set between the RDF description on Revyu and the URI of the
reviewers external FOAF file. Where the user has assigned herself
a URI in her FOAF description, Revyu also sets owl:sameAs links
asserting that this URI identifies the same resource as her Revyu
URI.

One limitation of this approach is that users who are not familiar
with the Semantic Web may not know the location of existing FOAF
profiles published for them by sites such as MyOpera [22]. In cases
where a user has not listed a FOAF file URI in their Revyu profile,
we use two alternative methods to try and enrich their profile.

First, to locate additional profile data about a user we query with
SPARQL a store of FOAF data crawled from across the Web and stored

in the Talis Platform [20]. Where data is found about the user we
display this, however at present the provenance of the information is not communicated to the person viewing the profile, and no
reasoning is performed about the trustworthiness or relevance of
such information based on its provenance. We expect to address
this issue in ongoing work.

If querying the store of crawled FOAF data returns no information about the user, our second approach is to use the Sindice
Semantic Web index [29] and attempt to locate additional RDF documents on the Web that may describe the user, using the following
procedure: a SHA1 [11] hash of the users mailbox URI is generated
from his or her registered email address; using the FOAF property
mbox sha1sum, and the Inverse Functional Property lookup service
in Sindice, a list of URIs of documents that contain this predicate
and object is returned; the first of these URIs is dereferenced and
queried for relevant information about the user.

As the Sindice index is more comprehensive that our current
store of FOAF data, this has greater potential to return information a result. However, the service returns only links to documents
containing RDF data, however this data itself cannot be queried
without first retrieving the document. Therefore, at present, only
the first document in the Sindice results is queried for data
about the user, the result being that Revyu is dependent on relevance ranking within Sindice, rather than applying our own
relevance ranking algorithms. As with reasoning about trustworthiness based on provenance, we hope to address this issue in future
research.

T. Heath, E. Motta / Web Semantics: Science, Services and Agents on the World Wide Web 6 (2008) 266273

Fig. 4. User profile page, showing reuse of external FOAF data.

7. Inferring trust relationships from Revyu data

A broader goal of our research is to use knowledge held within
trusted social networks to support information-seeking tasks on
the Web. Data collected within Revyu forms a basis for this research,
as the reviews created by users, and the tags they apply to items,
enable us to infer trustworthiness relationships between people,
with regard to particular topics. The algorithms used to generate
metrics that represent these trust relationships are referred to as
the Hoonoh algorithms.

These algorithms generate experience, expertise and affinity
metrics, which represent respectively the predicted trustworthiness of an individual with regards to a topic, based on his or her
experience of and expertise in that topic, and the predicted trustworthiness of an individual based on the affinity relationship
between the information seeker and that individual. These factors
are derived from previous research into trust and source-selection
in information seeking activities [17].

A fundamental aspect of our approach in this area, based on
our previous research [17], is the principle that trust can be top-
ical; one person may be highly trusted for recommendations in
one domain but trusted very little in others. For example, one
may trust a friend who is a banker to give sound financial advice,
but never trust her film recommendations. This trust topicality
is supported by the experience and expertise algorithms, whilst
affinity captures a more universal trust relationship from one individual to another that is not topical in nature. Keyword tags used
in Revyu seed the list of topics in which individuals may have
experience or expertise, and also provide a basis for computing
measures of experience. Each keyword tag is taken to denote one
topic.

Broadly speaking the experience algorithm generates a metric
of a persons experience regarding a particular topic, by calculating
the proportion of all items tagged with a particular tag that person
has reviewed. The credibility algorithm computes person topic
credibility metrics by comparing the numerical rating component
of each review to the mean rating of that item across all users. A
mean is then taken of all a reviewers review-specific credibility
scores for items tagged with a particular tag, to produce a reviewers
credibility score for that topic. Whether or not an affinity exists
between two individuals is determined by a combination of the
following factors derived from the reviews they have submitted to
Revyu: the extent to which both parties have rated the same items
(i.e. the overlap in rated objects), and the consistency in the ratings
given by each party to items both have reviewed (this is referred
to as the rating overlap). A more detailed account of preliminary
versions of these algorithms is provided in [18].

Based on data generated with these algorithms, a Web-based
system, Hoonoh.com, has been implemented and deployed that
uses these metrics to support source-centric information-seeking
within an individuals social network. Hoonoh allows users to
search for people with knowledge of particular topics and rank
these potential information sources according to the experience,
expertise and affinity trust factors.

8. Collecting and exposing social network data

In addition to consuming data from existing, external FOAF pro-
files, Revyu enables users to state that they know other Revyu
reviewers. At this point the relationship is recorded in the triplestore using the foaf:knows property, and exposed (privacy settings
permitting) in the users RDF description on the Revyu site. This

ensures that social networking data created in Revyu is not automatically rendered inaccessible to other services, and can play a
first class role in a broader, Web-wide social graph. This FOAF data
from Revyu is one of many potential sources of social network information that can be used by Hoonoh to rank known individuals as
information sources.

grant number GR/N15764/01. OK is sponsored by the European
Commission as part of the Information Society Technologies (IST)
programme under grant number IST-2001-34038. The Open Guides
and DBpedia communities, and the RDF Book Mashup team deserve
our special thanks.

9. Future work and conclusions

In addition to encouraging further user participation in order
to increase the value delivered by the site, we plan to integrate
Revyu with a number of additional data sets, as discussed above. It
should be noted that our aim in linking to external datasets is not
to constrain, but merely to seed, users conceptions of what can be
reviewed. As we integrate further data sets we hope to develop
techniques for automated population of Revyu with data about
reviewable items, from the Semantic Web at large.

A medium-term goal for Revyu is to aggregate review and rating data from external sources, in order to provide a single point of
access for structured review data across the Web. An essential prerequisite for this development is more explicit licensing of review
data published on the Web, using licenses such Creative Commons
(for creative aspects of reviews) [10] or the Open Data Commons
Public Domain Dedication and License (for more factual data about
reviewed items) [21]. To enable the storage of vastly increased
amounts of data on which we can provide a wider range of ser-
vices, Revyu will also be rebuilt as an application on top of the Talis
Platform [20]. It is our hope that aggregation and search services
for review data will help encourage more extensive publication of
reviews and ratings in RDF.

As we consume increasing amounts of external data from the
Semantic Web at large, we expect that algorithms for reasoning
about the trustworthiness and relevance of data based on provenance will become increasingly important. Our aim is to investigate
these issues in ongoing research.

In order to provide more structured access to increasing numbers of reviews, we intend to migrate from keyword tagging to a
form of semantic tagging. For certain types of information, such
as the location of an item that has a physical presence, we plan
to introduce a tagging interface that allows users to pick specific
locations from a pre-assembled gazetteer, in which each location is
associated with a URI in data sets such as Geonames [14] or DBpe-
dia. The nature of the relationship between the reviewed item and
the tag could then be explicitly recorded in RDF, allowing users to
search for items by location.

In conclusion, in this paper we have described Revyu, a human
usable reviewing and rating Web site built on Semantic Web
technologies, and fundamentally designed to contribute to the
realization of a Web of Data. Whilst superficially not unique in
functionality, the site is rare in its status as a publicly available service in daily use that is oriented towards human users, yet also
embodies current best practices in developing for the Semantic
Web. Experience gained from the implementation of Revyu, and
reported here, provides valuable insights for others creating Linked
Data and Semantic Web applications.

Acknowledgements

This research was partially supported by the Advanced Knowledge Technologies (AKT) and OpenKnowledge (OK) projects. AKT
is an Interdisciplinary Research Collaboration (IRC) sponsored by
the UK Engineering and Physical Sciences Research Council under
