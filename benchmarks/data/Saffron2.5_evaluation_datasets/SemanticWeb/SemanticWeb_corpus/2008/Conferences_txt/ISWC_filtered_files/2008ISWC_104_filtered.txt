An Experimental Comparison of RDF Data

Management Approaches in a SPARQL

Benchmark Scenario

Michael Schmidt1,, Thomas Hornung1, Norbert K uchlin1, Georg Lausen1,

and Christoph Pinkel2

1 Freiburg University, Georges-K ohler-Allee 51, 79106 Freiburg, Germany
{mschmidt,hornungt,kuechlin,lausen}@informatik.uni-freiburg.de
2 MTC Infomedia OHG, Kaiserstr. 26, 66121 Saarbr ucken, Germany

c.pinkel@mtc-infomedia.de

Abstract. Efficient RDF data management is one of the cornerstones
in realizing the Semantic Web vision. In the past, different RDF storage
strategies have been proposed, ranging from simple triple stores to more
advanced techniques like clustering or vertical partitioning on the predi-
cates. We present an experimental comparison of existing storage strategies on top of the SP2Bench SPARQL performance benchmark suite and
put the results into context by comparing them to a purely relational
model of the benchmark scenario. We observe that (1) in terms of performance and scalability, a simple triple store built on top of a column-store
DBMS is competitive to the vertically partitioned approach when choosing a physical (predicate, subject, object) sort order, (2) in our scenario
with real-world queries, none of the approaches scales to documents containing tens of millions of RDF triples, and (3) none of the approaches
can compete with a purely relational model. We conclude that future
research is necessary to further bring forward RDF data management.

1 Introduction

The Resource Description Framework [1] (RDF) is a standard format for encoding machine-readable information in the Semantic Web. RDF databases are
collections of so-called triples of knowledge, where each triple is of the form
(subject,predicate,object) and models the binary relation predicate between the
subject and the object. For instance, the triple (Journal1,issued,1940) might
be used to encode that the entity Journal1 has been issued in year 1940. By
interpreting each triple as a graph edge from a subject to an object node with
label predicate, RDF databases can be seen as labeled directed graphs.

To facilitate RDF data access, the W3C has standardized the SPARQL [2]
query language, which bases upon a powerful graph pattern matching facility. Its
very basic construct are simple triple graph patterns, which, during query evalu-
ation, are matched against components in the RDF graph. In addition, different
SPARQL operators can be used to compose more advanced graph patterns.

 The work of this author was funded by DFG, grant GRK 806/2.

A. Sheth et al. (Eds.): ISWC 2008, LNCS 5318, pp. 8297, 2008.
c Springer-Verlag Berlin Heidelberg 2008
?

?

?
An efficient RDF storage scheme should support fast evaluation of such graph
patterns and scale to RDF databases comprising millions (or even billions) of
triples, as they are commonly encountered in todays RDF application scenarios (e.g., [3,4]). The straightforward relational implementation, namely a single
Triples relation with three columns subject, predicate, and object that holds all
RDF triples, seems not very promising: The basic problem with this approach is
that the evaluation of composed graph patterns typically requires a large amount
of expensive self-joins on this (possibly large) table. For instance, the query Re-
turn the year of publication of Journal1 (1940) might be expressed in SQL as
follows (for readability, we use shortened versions of the RDF URIs).

SELECT T3.object AS yr
FROM Triples T1 JOIN Triples T2 ON T1.subject=T2.subject

JOIN Triples T3 ON T1.subject=T3.subject

WHERE T1.predicate=type AND T1.object=Journal AND T2.predicate=title

AND T2.object=Journal 1 (1940) AND T3.predicate=issued

(1)

The Triples table access T1 and the associated Where-conditions extract
all Journal entities, T2 fixes the title, and T3 extracts the year of publication. We
observe that even this rather simple query requires two subject-subject self-joins
over the Triples table. Practical queries may involve much more self-joins.

To overcome this deficiency, other physical organization techniques for RDF
have been proposed [5,6,7,8,9,10,11]. One notable idea is to cluster RDF data,
i.e. to group entities that are similar in structure [9,10] and store them in flattened tables that contain all the shared properties. While this may significantly
reduce the amount of joins in queries, it works out only for well-structured data.
However, one strength of RDF is that it offers excellent support for scenarios
with poorly structured information, where clustering is not a feasible solution.
A conceptually simpler idea is to set up one table for each unique predicate in
the data [5,11], which can be seen as full vertical partitioning on the predicates.
Each such predicate table consists of two columns (subject, object) and contains
all subject-object pairs linked through the respective predicate. Data is then
distributed across several smaller tables and, when the predicate is fixed, joins
do not involve the whole set of triples. By physically sorting data on the subject
column, subject-subject joins between two tables, a very frequent operation, can
be realized in linear time (w.r.t. the size of the tables) by merging their subject
columns [11]. In such a scenario, the query from above might be formulated as,

SELECT DI.object AS yr
FROM type TY JOIN title TI ON TY.subject=DT.subject

JOIN issued IS ON TY.subject=IS.subject

WHERE TY.object=bench:Journal AND TI.object=Journal 1 (1940)

(2)

where type, title, and issued denote the corresponding predicates tables.
Predicate selection now is implicit by the choice of the predicate table (i.e.,
no longer encoded in the WHERE-clause) and, given that the subject-column is
sorted, both joins might be efficiently implemented as linear merge joins.

In the experiments in [11] on top of the Barton library data [12], vertical
partitioning turns out to be clearly favorable to the triple table scheme and

M. Schmidt et al.

always competitive to clustering. Although the scenario is a reasonable choice
that illustrates many advantages of vertical partitioning, several issues remain
open. One point is that, in the partitioned scenario, efficient subject-subject merge
joins on the predicate tables (which are possible whenever predicates are fixed)
are a key to performance. However, when physically sorting table Triples by
(predicate, subject, object), linear merge joins might also apply in a triple store.
A study of the Barton benchmark shows that one query (out of seven) requires
no join on the triple (resp., predicate) table(s), and each two involve (a) a single
subject-subject join, (b) two subject-subject joins, and (c) one subject-subject plus
one subject-object join. Thus, none involves more than two joins. The simplicity
of these join patterns to a certain degree contrasts with the Introduction of [11],
where the authors state that almost all interesting queries involve many self-
joins and motivate vertical partitioning using a five-way self-join query. We
agree that real-world queries often involve complex join-patterns and see an
urgent need for reevaluating the vertical approach in a more challenging scenario.
To this end, we present an experimental comparison of the triple and vertically
partitioned scheme on top of the the SP2Bench SPARQL benchmark [13]. The
SP2Bench queries implement meaningful requests in the DBLP scenario [14] and
have been designed to test challenging situations that may arise in the context
of SPARQL and Semantic Web data. In contrast to the Barton queries, they
contain no aggregation, due to missing SPARQL language support. But except
for this construct, they cover a much wider range of operator constellations, RDF
data access paths, join patterns, and advanced features (e.g., Optional clauses,
solution modifiers). The queries for the vertical and the triple store are obtained
from a methodical SPARQL-to-SQL translation and reflect these characteristics.
To put our analysis into context, we consider two more scenarios. First, we
test the Sesame SPARQL engine [15] as a representative SPARQL processor that
relies on a native RDF store. Second, we translate the SP2Bench scenario into
a purely relational scheme, thus comparing the current state-of-the-art in RDF
data management against established relational database technologies.
Contributions. Among others, our experiments show that (1) when triple tables are physically sorted by (predicate, subject, object), efficient merge joins can
be exploited (just like in the vertical scheme) and the triple table approach becomes more competitive, (2) for the challenging SP2Bench queries neither the
vertical nor the triple scheme shows a good overall performance, and (3) while
both schemes typically outperform the Sesame SPARQL engine, the purely relational encoding is almost always at least one order of magnitude faster. We
conclude that there is an urgent need for future research in this area.
Related Work. An experimental comparison of the triple table and a vertically
partitioned scheme has been provided in [5]. Among others, the authors note the
additional costs of predicate table unions in the vertical scenario, which will be
discussed later in this paper. Nevertheless, the setting in [5] differs in several
aspects, e.g. in the vertically partitioned scheme the RDF schema layer was
?

?

?
stored in separate tables and physical sorting on the subject-column (to allow
for subject-subject merge joins), a central topic in our analysis, was not tested.
We point the interested reader to the experimental comparison of the triple
and vertical storage scheme in [16]. This work has been developed independently
from us. It presents a reevaluation of the experiments from [11] and, in this line,
identifies situations where vertical partitioning is an insufficient solution. Several
findings there are similar to our results. While the latter experiments are carried
out in the Barton scenario (like the original experiments in [11]), we go one step
further, i.e. perform tests in a different scenario and put the results into context
by comparing them to a purely relational scheme, as well as a SPARQL engine.
The Berlin SPARQL Benchmark [17] is settled in an e-commerce scenario and
strictly use-case driven. In contrast, the language-specific SP2Bench suite used
in this work covers a broader range of SPARQL/RDF constructs and, for this
reason, is preferable for testing the generality of RDF storage schemes.
Structure. In the next section we summarize important characteristics of the
SP2Bench SPARQL performance benchmark [13], to facilitate the interpretation
of the benchmark results. In Section 3 we then sketch the tested storage schemes
and the methodical query translation into these scenarios. Finally, Section 4
contains the in-depth discussion of our experiments and a conclusion. In the
remainder, we assume the reader to be familiar with RDF [1] and SPARQL [2].

2 The SP2Bench Scenario

SP2Bench [13] is settled in the DBLP [14] bibliographic scenario. Central to the
benchmark is a data generator for creating DBLP-like RDF documents, which
mirror characteristics and relations found in the original DBLP data. It relies
on natural function families to capture social-world aspects encountered in the
DBLP data, e.g. the citation system is modeled by powerlaw distributions, while
limited growth functions approximate the number of publications per year. Sup-
plementary, the SP2Bench suite provides a set of meaningful SPARQL queries,
covering a variety of SPARQL operator constellations and data access patterns.
According to DBLP, the SP2Bench generator creates nine distinct types of
bibliographic entities, namely Article, Journal, Inproceedings, Proceed-
ings, Book, Incollection, PhDThesis, MastersThesis, and WWW doc-
uments, where each document is represented by a unique URI. In addition, there
are persons that act as authors or editors. They are modeled by blank nodes.

Each document (resp., person) is described by a set of properties, such as
dc:title, dc:creator (i.e., the author), or swrc:isbn. Outgoing citations are expressed
through predicate dcterms:references, which points to a blank node of type rdf:Bag
(a standard RDF container class) that links to the set of all document URIs referenced by the respective document. Attribute dcterms:partOf links inproceedings
to the proceedings they appeared in; similarly, swrc:journal connects articles to
journals. Several properties (e.g., dc:creator) are multi-valued.

The first part of Table 1 lists the number of document class instances of type
Inproceedings, Proceedings, Article, Journal, Incollection, and the

M. Schmidt et al.

Table 1. Key characteristics of documents generated by the SP2Bench generator

#triples #Inpr. #Proc. #Art. #Journ. #Inc. #Oth. #auth./#dist. #prop. file size year

10k
50k
250k
1M
5M
25M
?

?

?
1.4k
9.2k
43.5k
255.2k

4.0k
213 17.1k
903 56.9k
4.7k 207.8k
1.5M 24.4k 642.8k
?

?

?
1.4k

4.6k 1.4k
11.7k 4.5k

1.5k/0.9k 23+34 1.0MB 1955

6.8k/4.1k 23+34 5.1MB 1967

26MB 1979
?

?

?
151.0k/82.1k 23+44 106MB 1989
1.4k 898.0k/429.6k 23+52 533MB 2001
2.4k
5.4M/2.1M 25+52 2.7GB 2015

34.5k/20.0k 23+43

remaining types #Oth. (Book, Www, PhD- and MastersThesis) for generated documents up to 25M RDF triples. Article and Inproceedings documents clearly dominate. The total number of authors (i.e., triples with predicate
dc:creator) increases slightly super-linear to the total number of documents. This
reflects the increasing average number of authors per paper in DBLP over time.
The table also lists the number #prop. of distinct properties. This value x + y
splits into x standard attribute properties and y bag membership properties
rdf: 1, . . ., rdf: y, where y depends on the maximum-sized reference list in the
data. We observe that larger documents contain larger reference lists, and hence
more distinct properties. As discussed later, this might complicate data processing in the vertically partitioned scenario. Finally, we list the physical size of the
RDF file (in NTriples format) and the year up to which data was generated.

To support queries that access an author with fixed characteristics, the documents contain a special author, named after the mathematician Paul Erd os, who
gets assigned 10 publications and 2 editor activities in-between 19401996. As
an example, Q8 (Appendix A) extracts all persons with Erd os Number 1 or 2.1

3 The Benchmark Scenarios

We now describe the four benchmark scenarios in detail. The first system under
consideration is (1) the Sesame [15] SPARQL engine. Sesame constitutes a query
engine that, like the other three scenarios, relies on a physical DB backend. It
is among the fastest SPARQL engines that have been tested in the context of
the SP2Bench benchmark (cf. [13]) and has been chosen as a representative for
the class of SPARQL engines. The remaining scenarios are (2) the triple table approach, (3) the vertically partitioned approach as described in [11], and
(4) a purely relational DBLP model. They are all implemented on top of a relational DBMS. Accordingly, a translation of the SP2Bench SPARQL queries into
SQL is required. We will sketch the detailed settings and our methodical query
translation approaches for scenarios (2)-(4) in the remainder of this section. The
resulting SQL queries are available online2; still, to be self-contained we will
summarize their key characteristics when discussing the results in Section 4.

According to [11], to reach best performance all relational schemes should
be implemented on top of a column-store DBMS, which stores data physically

1 See http://www.oakland.edu/enp/.
2 http://dbis.informatik.uni-freiburg.de/index.php?project=SP2B/translations.html
?

?

?
by column rather than row (see [11] for the advantages of column-oriented systems in the RDF scenario). The C-Store research prototype [18] used in [11]
misses several SQL features that are essential for the SP2Bench queries (e.g. left
joins), so we fall back on the MonetDB [19] column-store, a complete, industrialstrength relational DBMS. We note that MonetDB differs from C-Store in several aspects. First, data processing in MonetDB is memory-based while it is
disk-based in C-Store. Moreover, C-Store exhibits a carefully optimized mergejoin implementation (on top of run-length encoded data) and makes heavy use
of this operation. Although we observe that MonetDB uses merge joins less
frequently (cf. Section 4), the system is known for its performance and has recently been shown to be competitive to C-Store in the Barton Library RDF
scenario [16].

3.1 The Triple Table Storage Scheme

In the triple table scheme a single table Triples(subject, predicate,object) holds
all RDF triples. Methodical translations of SPARQL into this scheme have been
proposed in [20,21,22]. The idea is to evaluate triple patterns separately against
table Triples, then combining them according to the SPARQL operators in the
query. Typically, SPARQL operator And is expressed by a relational join, Union
by a SQL union, Filter clauses result in Where-conditions, and Optional is
modeled by a left outer join. For instance, SPARQL query Q1 (Appendix A)
translates into query (1) from the Introduction (prefixes and data types are
omitted). Observe that Q1 connects three patterns through two And operators
(denoted as .), resulting in two SQL joins. The patterns are connected through
variable ?journal in subject position, so both are subject-subject joins. We emphasize that, although queries were translated manually, the scheme is very close
to the approaches used by SPARQL engines that build on the relational model.

Dictionary Encoding. URIs and Literals tend to be long strings; they might
blow up relational tables and make joins expensive. Therefore, we store integer keys instead of the string value, while keeping the key-value mapping in
a Dictionary(ID,val) table (cf. [15,23,24,11]). Note that dictionary encoding
implies additional joins with the Dictionary table in the translated queries.

Implementation. We sort data physically by (predicate, subject, object) rather
than (subject, predicate, object). While this contrasts with the experiments in [11],
we will show that this sort order makes the triple approach more competitive,
because fast linear merge joins across property tables in the vertical scenario can
now be realized by corresponding merge joins in the triple scenario.

We note that indexing in MonetDB differs from conventional DBMS; it interprets INDEX statements as advices, feeling free to ignore them and create its
own indices.3 Though, we issue a secondary BTree index for all remaining permutations of the subject, predicate, and object columns. The Dictionary table
is physically sorted by ID and we request a secondary index on column val.

3 See http://monetdb.cwi.nl/projects/monetdb/SQL/Documentation/Indexes.html.

M. Schmidt et al.

3.2 The Vertically Partitioned Storage Scheme

The vertically partitioned relational store maintains one two-column table with
schema (subject, object) for each unique predicate in the data. The query translation for the vertical scenario is similar to the triple table translation. The
translation of SPARQL query Q1 into this scenario is exemplarily shown in the
Introduction, query (2). Here, data is extracted from the predicate tables, so
predicate value restrictions in the Where-clause are no longer necessary.

One major problem in the vertical scheme arises when predicates in queries
are not fixed (i.e., when SPARQL variables occur in predicate position). Then,
information cannot be extracted from a single predicate table, but queries must
compute the union over all these tables. As discussed in Section 2 (Table 1),
in our scenario the number of distinct properties (and hence, predicate tables)
increases with document size. Consequently, such queries require more unions
on large documents. This illustrates a basic drawback of the vertical approach:
Query translation depends on the structure of the data and, what is even more
urgent, queries may require a large number of unions over the predicate tables.
Implementation. We sort the predicate tables physically on (subject, object)
and issue an additional secondary BTree index on columns (object, subject).
Dictionary encoding is implemented analogously to the triple scheme.

3.3 The Purely Relational Scheme

We started from scratch and developed an Entity Relationship Model (ERM) of
DBLP. Using ERM translation techniques, we end up with the following tables,
where primary keys are underlined and foreign keys are marked by prefix fk .

 Document(ID,address,booktitle,isbn,. . .,stringid,title,volume)
 Document_homepage(fk document,homepage)
 Document_seeAlso(fk document,seeAlso)
 Venue(ID,fk document,fk venue type)
 Publication(ID,chapter,fk document,fk publication type,fk venue,pages)
 Publication_cdrom(fk publication,cdrom)
 Abstract(fk publication,txt)
 PublicationType(ID,name) and VenueType(ID,name)
 Person(ID,name,stringid)
 Author(fk person,fk publication) and Editor(fk document,fk person)
 Reference(fk from,fk to)
The scheme distinguishes between venues (i.e., Journal and Proceedings)
and publications (such as Article, Inproceedings, or Book). The dictionary
tables PublicationType and VenueType contain integer IDs for the respective
venue and publication classes. Table Document constitutes a base table for both
document types, containing properties that are common to both venues and
publications. Supplementary, Venue and Publication store the properties that
are specific for the respective type. For instance, if a new Book document is
inserted, its base properties are stored in table Document, while publication-type
?

?

?
specific properties (e.g., chapter) are stored in table Publication. The entries
are linked through foreign key Publication.fk document; the type (in this case
Book) is fixed by linking Publication.fk publication type to the Book ID in
PublicationType. Properties foaf:homepage, rdf:seeAlso, and bench:cdrom are
multi-valued in the SP2Bench scenario, so they are stored in the separate tables
Document_homepage, Document_seeAlso, and Publication_cdrom. We use a
distinguished Abstract table for the larger-than-average abstract strings.

Finally, there is one table Person that stores person information, two tables
Author and Editor that store the author and editor activity of persons, and a
table Reference that contains all references between documents.
Implementation. The scheme was implemented in MonetDB exactly as described
above, using the specified PRIMARY and FOREIGN KEY constraints, without additional indices. In the sense of a relational schema we omit prefix definitions (such
as rdf:, dc:). The data was translated using a conversion script.

4 Experimental Results

Setting. The experiments were carried out on a Desktop PC running ubuntu
v7.10 gutsy Linux, with Intel Core2 Duo E6400 2.13GHz CPU and 3GB DDR2
667 MHz nonECC physical memory. We used a 250GB Hitachi P7K500 SATA-II
hard drive with 8MB Cache. The relational schemes were executed with MonetDB mserver v5.5.0, using the (more efficient) algebra frontend (flag -G).

As discussed in Section 3, we tested (1) the Sesame v2.0 engine SP (coupled
with its native storage layer, providing all possible combinations of indices) and
three MonetDB scenarios, namely (2) the triple store TR, (3) the vertically
partitioned store VP, and (4) the purely relational scheme RS. We report on
user (usr), system (sys), and elapsed time (total). While usr and sys were
extracted from the /proc file system, elapsed time was measured through a timer.
MonetDB follows a client-server architecture and we provide the sum of the usr
and sys times of the client and server processes. Note that the experiments were
run on a DuoCore CPU, where the linux kernel sums up usr and sys of the
individual processor units, so usr+sys might be greater than total.

For all scenarios we carried out three runs over all queries on documents of
10k, 50k, 250k, 1M, 5M, and 25M triples, setting a 30 minutes timeout and
2GB memory limit (using ulimit) per query. As our primary interest is the basic
performance of the approaches (rather than caching or learning strategies), we
performed cold runs, i.e. destroyed the database in-between each two consecutive
runs and always restarted it before evaluating a query. We provide average times
and omit the deviation from the average (which was always negligible).
Discussion of the Benchmark Results. All results were verified by comparing the outcome of the engines among each other (where possible). Table 2 summarizes the query result sizes and the physical DB sizes for each scenario on all
documents. The VP scheme requires less disk space than TR for large documents,
since predicates are not explicitly stored for each triple. For Sesame, indices

M. Schmidt et al.

Table 2. Query result sizes on documents up to 25M triples and physical DB size

Q1

Q2 Q3a Q3b Q3c

Q4 Q5a/b

Number of query results for individual queries

Phys. DB size (MB)
Q6 Q7 Q8 Q9 Q10 Q11 SP TR VP RS
?

?

?
3.6k

10k
?

?

?
50k
?

?

?
250k
6.2k 15.9k 127
1M 1 32.8k 52.7k 379
5M 1 248.7k 192.4k 1.3k
25M 1 1.9M 594.9k 4.1k
?

?

?
1.1k
1.8k
6.9k 12.1k

0 184
0 23.2k
2 264
0 104.7k
0 542.8k
62 332
0 2.6M 35.2k 62.8k 292 400
0 18.4M 210.7k 417.6k 1.2k 493

n/a 696.7k 1.9M 5.1k 493

4 166
4 307
4 452
4 572
4 656
4 656
?

?

?
10 277

10 1376 404 271 195
10 6928 2395 1168 913
?

?

?
s
d
n
o
c
e
s
 

n

i
 

e
m

i
t

s
d
n
o
c
e
s
 

n

i
 

e
m

i
t

s
d
n
o
c
e
s
 

n

i
 

e
m

i
t

s
d
n
o
c
e
s
 

n

i
 

e
m

i
t

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

Q1

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q2

usr+sys
sys
total

 

e
r
u
l
i
a

y
r
o
m
e

l
a
n
r
e
t
n

S1

S2

S3

S4

S5

S6

Q3b

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q4

usr+sys
sys
total

n
o
i
t
s
u
a
h
x

y
r
o
m
e

n
o
i
t
s
u
a
h
x

y
r
o
m
e

S1

S2

S3

S4

S5

S6

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

Q1

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q2

usr+sys
sys
total

t
u
o
e
m

i

S1

S2

S3

S4

S5

S6

Q3b

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q4

usr+sys
sys
total

 

e
r
u
l
i
a

y
r
o
m
e

l
a
n
r
e
t
n

t
u
o
e
m

i

S1

S2

S3

S4

S5

S6

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

Q1

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q2

usr+sys
sys
total

n
o
i
t
s
u
a
h
x

y
r
o
m
e

S1

S2

S3

S4

S5

S6

Q3b

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q4

usr+sys
sys
total

t
u
o
e
m

i

t
u
o
e
m

i

S1

S2

S3

S4

S5

S6

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

Q1

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q2

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q3b

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q4

S1

S2

S3

S4

S5

usr+sys
sys
total

n
o
i
t
s
u
a
h
x

y
r
o
m
e

S6

Fig. 1. Results on S1=10k, S2=50k, S3=250k, S4=1M, S5=5M, and S6=25M triples

occupy more than half of the required space. In RS there is no redundancy, no
dictionary encoding, and no prefixes are stored, so least space is required.

The query execution times are shown in Figures 1, 2, and 3 (the y-axes are

always in log scale). Please note that the individual plots scale differently.

Q1. Return the year of publication of Journal 1 (1940).
This simple query returns exactly one result on all documents. The TR and VP
translations are shown in the Introduction. The RS query joins tables Venue,
Document, and VenueType on the connecting foreign keys and then filters for
VenueType.name=Journal and Document.title=Journal 1 (1940).

We observe that both the TR and VP scenario scale well for documents up to
5M triples, but total time explodes for 25M triples. The gap between total and
usr+sys for 25M indicates that much time is spent in waiting for data being read
from or written to disk, which is caused by query execution plans (QEPs) that
?

?

?
s
d
n
o
c
e
s
 

n

i
 

e
m

i
t

s
d
n
o
c
e
s
 

n

i
 

e
m

i
t

s
d
n
o
c
e
s
 
n

i
 

e
m

i
t

s
d
n
o
c
e
s
 
n

i
 

e
m

i
t

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

Q5a

usr+sys
sys
total

n
o
i
t
s
u
a
h
x

y
r
o
m
e

S1

S2

S3

S4

S5

S6

Q5b

usr+sys
sys
total

n
o
i
t
s
u
a
h
x

y
r
o
m
e

S1

S2

S3

S4

S5

S6

Q6

usr+sys
sys
total

n
o
i
t
s
u
a
h
x

y
r
o
m
e

S1

S2

S3

S4

S5

S6

Q7

usr+sys
sys
total

n
o
i
t
s
u
a
h
x

y
r
o
m
e

n
o
i
t
s
u
a
h
x

y
r
o
m
e

S1

S2

S3

S4

S5

S6

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

Q5a

usr+sys
sys
total

t
u
o
e
m

i

S1

S2

S3

S4

S5

S6

Q5b

usr+sys
sys
total

 

e
r
u
l
i
a

y
r
o
m
e

l
a
n
r
e
t
n

S1

S2

S3

S4

S5

S6

Q6

usr+sys
sys
total

n
o
i
t
s
u
a
h
x

y
r
o
m
e

S1

S2

S3

S4

S5

S6

Q7

usr+sys
sys
total

t
u
o
e
m

i

S1

S2

S3

S4

S5

S6

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

Q5a

usr+sys
sys
total

t
u
o
e
m

i

t
u
o
e
m

i

t
u
o
e
m

i

t
u
o
e
m

i

S1

S2

S3

S4

S5

S6

Q5b

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q6

usr+sys
sys
total

t
u
o
e
m

i

t
u
o
e
m

i

t
u
o
e
m

i

t
u
o
e
m

i

S1

S2

S3

S4

S5

S6

Q7

usr+sys
sys
total

t
u
o
e
m

i

t
u
o
e
m

i

t
u
o
e
m

i

t
u
o
e
m

i

S1

S2

S3

S4

S5

S6

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

Q5a

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q5b

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q6

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q7

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Fig. 2. Results on S1=10k, S2=50k, S3=250k, S4=1M, S5=5M, and S6=25M triples

s
d
n
o
c
e
s
 
n

i
 

e
m

i
t

 0.1

 0.01

 0.001

s
d
n
o
c
e
s
 
n

i
 

e
m

i
t

s
d
n
o
c
e
s
 
n
i
 
e
m

i
t

s
d
n
o
c
e
s
 
n
i
 
e
m

i
t

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

Q8

usr+sys
sys
total

n
o
i
t
s
u
a
h
x

y
r
o
m
e

S1

S2

S3

S4

S5

S6

Q9

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q10

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q11

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

Q8

usr+sys
sys
total

t
u
o
e
m

i

S1

S2

S3

S4

S5

S6

Q9

usr+sys
sys
total

t
u
o
e
m

i

S1

S2

S3

S4

S5

S6

Q10

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q11

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

Q8

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q9

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q10

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q11

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

 0.1

 0.01

 0.001

Q8

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

(n/a)

Q10

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Q11

usr+sys
sys
total

S1

S2

S3

S4

S5

S6

Fig. 3. Results on S1=10k, S2=50k, S3=250k, S4=1M, S5=5M, and S6=25M triples

involve expensive fetch joins, instead of efficient subject-subject merge joins. We
claim that using merge joins would be more efficient here. Due to this deficiency,
both Sesame and the RS scenario outperform the TR and VP schemes.
