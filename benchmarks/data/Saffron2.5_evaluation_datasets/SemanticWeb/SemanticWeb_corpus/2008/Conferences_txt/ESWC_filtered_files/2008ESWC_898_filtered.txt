The Combination of Techniques for Automatic Semantic

Image Annotation Generation in the IMAGINATION

Application

Andreas Walter1 and Gabor Nagypal2

1 FZI Research Center for Information Technologies , Information Process Engineering,

Haid-und-Neu-Strae 10-14, 76131 Karlsruhe, Germany

2 disy Informationssysteme GmbH, Erbprinzenstr. 4-12, Eingang B, 76133 Karlsruhe, Germany

Andreas.Walter@fzi.de

nagypal@disy.net

Abstract. The IMAGINATION project provides image-based navigation for digital cultural and scientific resources. Users can click on parts of an image to find
other, interesting images to a given context. In this paper, we present the core parts
of the IMAGINATION application. To allow the navigation through images, this
application automatically generates high quality semantic metadata. Therefore it
combines automated processes for person and object detection, face detection and
identification in images together with text mining techniques that exploit domain
specific ontologies.

1 Introduction

State of the art systems for the navigation through images either assume that users
manually create semantic image annotations or they use automated processes for image
annotation creation in isolation. SemSpace [1] uses domain ontologies and allows the
semantic annotation of image parts. This application does not use automated processes
at all. Thus, the annotation of images is a time consuming task in this system. Riya [2]
uses a face detection algorithm. This reduces the annotation time for users, but leads
to new problems. The sole usage of face detection algorithm leads to the problem of
incorrectly generated annotations. E.g., so-called phantom faces may be generated.

The goal of IMAGINATION is to minimize the human effort to create high-quality
image annotations. First, the annotation time for the creation of semantic images has to
be reduced by automatic generation. Second, these generated artifacts must be of highquality to reduce the time needed for manual corrections. To achieve these goals, IMAGINATION combines different automated processes. Moreover, background knowledge
in a common domain ontology is also exploited to achieve best result.

In Section 2, we present the automated processes that are used in the IMAGINATION
application. In Section 3, we present a sample scenario to demonstrate the interaction
of the processes and how this interaction helps increase to quality of annotations.

 This work was co-funded by the European Commission within the project IMAGINATION.

S. Bechhofer et al.(Eds.): ESWC 2008, LNCS 5021, pp. 879883, 2008.
c Springer-Verlag Berlin Heidelberg 2008

A. Walter and G. Nagypal

2 Components of the IMAGINATION Application

In this section, we present the components of the IMAGINATION application. They
work together to automatically generate semantic image annotations of the highest possible quality.

2.1 ImageNotion - Collaborative Generation of Domain Ontologies

Domain ontologies used in IMAGINATION base on the ImageNotion concept [3]. Ontologies according to ImageNotion consist of imagenotions. An imagenotion (formed
from the words image and notion) graphically represents a semantic notion through
an image. Furthermore, similarly to many existing ontology formalisms, it is possible
to associate descriptive information, e.g. textual labels and date information with an
imagenotion. Further, it is possible to add links to related web pages for an imageno-
tion. Links can help text mining algorithms to gather background information from
web pages. In addition, relations between imagenotions are also supported. To achieve
maximal understandability, ImageNotion makes no distinction between concepts and
instances. Based on the ImageNotion methodology, users of the IMAGINATION system can collaboratively generate required domain ontologies. Also, it is possible to
import and extend existing ontologies, such as CIDOC-CRM ([4]). Semantic annotations can be created either for the whole image or for image parts. Fig. 1 shows an the
imagenotion for Manuel Barroso, the current president of the EU commission.

Fig. 1. Imagenotion for Manuel Barroso

2.2 Automated Processes

Most images contain text base image annotations. The text mining algorithms of JSI1
[5] allow the detection of semantic elements in such text based image annotations. They
can also new ontology elements. Especially for this task, the background texts that are
stored at imagenotions as links to external web pages are very useful.

1 Links to partner web pages can be found on the project web site:

http://www.imagination-project.org
?

?

?
Face detection and identification algorithms are provided by Fraunhofer IIS ([6]).
The face detection algorithm can detect parts on images that display faces. In addition,
gender-classification of a detected person is also possible. The face identification algorithm aims to detect the relevant person for a detected face. It returns a list of proposals
for the person and their corresponding relevance.

Person and object detection algorithms are provided by NTUA. Person detection
finds the image area showing a person or a part of it. Object detection algorithms can
identify objects, e.g. tanks, airplanes or cars.

2.3 Controller for the Generation of Automatically Generated Image

Annotations

The controller for the generation of automatically generated image annotations gets an
image as input. First, it loads available textual and manually created semantic annotations for the image. Then, it iteratively invokes the available automated processes one
by one. Each of the automated processes can read and change the available annotations
and image regions, and add new ones. This allows the correction or the refinement of
existing result. E.g., face detection algorithms may thoroughly examine areas for faces
that were detected as persons by the person detection algorithms. In addition, the text
mining results may help to eliminate wrong suggestions in the face identification step.
The controller stops the annotation process, when there are no further changes in an
iteration.

3 An Example Scenario for Using the IMAGINATION Application

In this section we present an example scenario for using the IMAGINATION appli-
cation. The input is an image showing the current president of the EU commission,
Manuel Barroso, together with the former president of the EU commission, Romano
Prodi.

First, the user uploads the image. Then, it is possible to create manual annotations.
In Fig. 2, a user has added the imagenotion Manuel Barrosso for the complete image
with a high rating.

In the next step, the user can start the automated annotation process. Fig. 3 shows
the result of the automated processes. In the first iteration, the text mining algorithm
has created the semantic annotations Romano Prodi and Manuel Barroso, based
on the textual title of the image: EU president Barroso meets Prodi. The person and
object detection algorithms have created two image annotations for the shapes of the
two persons. The face detection algorithm has created two image annotations for the
detected faces. The face identification has identified Manuel Barroso with a score of
80 percent and Guenther Verheugen with a score of 20 percent. Also, the gender of
the second face was detected as male. The controller now initiates another annotation
round. In this round, the person identification can use the results of the other automated
processes. For the second face, it creates a new image annotation Romano Prodi for
Prodis face with a score of 100 percent and sets the score of Guenther Verheugen
to zero, since the information of the text mining algorithm and the manual annotation

A. Walter and G. Nagypal

Fig. 2. Manual annotation of an image

Fig. 3. Results of the automated processes

states, that there must be the person Manuel Barroso. Also, it sets the score of the
detected areas for the persons to zero, since two faces were detected2. In the third iteration round, there are no more changes and the controller returns the result.

2 Our users prefer faces to body contours, when the size of the face is big enough.
?

?

?
Fig. 4. Resulting semantic image annotations for the image

Fig. 2 shows the final result of the annotation when a user searches for the image.
The result contains the detected annotation boxes of Manuel Barroso and Romano
Prodi. Thus, the combination of the automated processes with domain ontologies lead
to automatically created image annotations with a higher quality than using the automated processes in isolation.

The application is accessible at www.imagenotion.com
