Module Extraction and Incremental Classification:

A Pragmatic Approach for EL+

Ontologies

Boontawee Suntisrivaraporn

Theoretical Computer Science, TU Dresden, Germany

meng@tcs.inf.tu-dresden.de

Abstract. The description logic EL+ has recently proved practically
useful in the life science domain with presence of several large-scale
biomedical ontologies such as Snomed ct. To deal with ontologies of
this scale, standard reasoning of classification is essential but not suffi-
cient. The ability to extract relevant fragments from a large ontology and
to incrementally classify it has become more crucial to support ontology
design, maintenance and re-use. In this paper, we propose a pragmatic
approach to module extraction and incremental classification for EL+
ontologies and report on empirical evaluations of our algorithms which
have been implemented as an extension of the CEL reasoner.

1 Introduction
In the past few years, the EL family of description logics (DLs) has received
an increasing interest and been intensively studied (see, e.g., [1,2,3,8]). The attractiveness of the EL family is twofold: on the one hand, it is computationally
tractable, i.e., subsumption is decidable in polytime; on the other hand, it is sufficiently expressive to formulate many life science ontologies. Examples include
the Gene Ontology, the thesaurus of the US National Cancer Institute (Nci),
the Systematized Nomenclature of Medicine, Clinical Terms (Snomed ct), and
large part (more than 95%) of the Galen Medical Knowledge Base (Galen).
We lay emphasis on Snomed ct which comprises about four hundred thousand
axioms and is now a standardized clinical terminology adopted by health care
sectors in several countries [13].

Being a standard ontology, Snomed has been designed to comprehensively
cover a whole range of concepts in the medical and clinical domains. For this
reason, it is often the case that only a small part is actually needed in a specific application. The ability to automate extraction of meaningful sub-ontologies
that cover all relevant information is becoming important to support re-use of
typically comprehensive standardized ontologies. Several techniques for syntactic module extraction have been proposed [9,11,6], since semantic extraction is
highly complex [6]. Though (deductive) conservative extension could be used as
a sufficient condition for extracting a module, it is unfortunately too expensive

 Supported by DFG-Project under grant BA 1122/11-1 and EU-Project TONES.

S. Bechhofer et al.(Eds.): ESWC 2008, LNCS 5021, pp. 230244, 2008.
c Springer-Verlag Berlin Heidelberg 2008
?

?

?
(ExpTime-complete already in EL with GCIs [8]). In Section 3 of the present
paper, we define a new kind of module, called reachability-based modules, which
is motivated by a once-employed optimization technique in the CEL system and
which can be extracted in linear time. Also, we propose an algorithm for extracting modules of this kind and show some interesting properties.

Despite being classifiable by modern DL reasoners, design and maintenance
of large-scale ontologies like Snomed ct requires additional reasoning support.
This is due to the fact that an ontology under development evolves continuously,
and the developer often has to undergo the long process of full classification
after addition of a few new axioms. Though classification of Snomed requires
less than half an hour (see [2] or Table 1 in the present paper), the ontology
developer is not likely willing to wait that long for a single change. In the worst
case, she may end up not using automated reasoning support which could have
helped identify potential modeling errors at an early stage. In Section 4, we
propose a goal-directed variant of the EL+ classification algorithm developed in
[3] which can be used for testing subsumption queries prior to full classification.
Section 5 presents an extension of the algorithm in [3] to cater for two ontologies:
the permanent ontology Op which has been carefully modeled, and axioms of
which are not supposed to be modified; and, the temporary ontology Ot that
contains new axioms currently being authored. The extended algorithm reuses
information from the previous classification of Op and thus dispense with the
need of the full classification of OpOt. We call reasoning in this setting restricted
incremental classification.

All algorithms proposed in this paper have been implemented in the CEL
reasoner [2] and various experiments on realistic ontologies have been performed.
The experiments and their promising results are discussed in Section 6.

For interested readers, proofs omitted from the present paper can be found in

the associated technical report [12].

2 Preliminaries
The present paper focuses on the sub-Boolean DL EL+ [3], which is the underlying
logical formalism of the CEL reasoner [2]. Similar to other DLs, an EL+ signature
is the disjoint union S = CNRN of the sets of concept names and role names. EL+
concept descriptions (or complex concepts) can be defined inductively as follows:
each concept name A  CN and the top concept  are EL+ concept descriptions;
and, if C, D are EL+ concept descriptions and r  RN is a role name, then concept
conjunction C  D and existential restriction r.C are EL+ concept descriptions.
An EL+ ontology O is a finite set of general concept inclusion (GCI) axioms
C  D and role inclusion (RI) axioms r1    rn  s with C, D EL+ concept
descriptions and ri, s role names. Concept equivalences and (primitive) concept
definitions are expressible using GCIs, whereas RIs can be used to express various
role axioms, such as reflexivity (	  r), transitivity (r  r  r), right-identity
(r  s  r), and role hierarchy (r  s) axioms. Figure 1 illustrates an example
in the medical domain. For convenience, we write Sig(O) (resp., Sig(), Sig(C))

B. Suntisrivaraporn

Pericardium  Tissue  contained-in.Heart
Endocardium  Tissue  part-of.HeartValve
Pericarditis  Inflammation  has-location.Pericardium
Endocarditis  Inflammation  has-location.Endocardium
Inflammation  Disease  acts-on.Tissue

1
2
3
4
5
6 Disease  has-location.Heart  HeartDisease
7
8
9

has-location  contained-in  has-location

HeartDisease  has-state.NeedsTreatment

part-of  part-of  part-of

Fig. 1. An example EL+ ontology Oex
?

?

?
to denote the signature of the ontology O (resp., the axiom , the concept C),
(O) denote the set of
i.e., concept and role names occurring in it. Also, let CN
 and concept names occurring in O.
The main inference problem for concepts is subsumption query: given an ontology O and two concept descriptions C, D, check if C is subsumed by (i.e.,
more specific than) D w.r.t. O, written C O D. From our example ontology,
it is not difficult to draw that Pericarditis Oex
has-state.NeedsTreatment. The
identification of subsumption relationships between all pairs of concept names
occurring in O is known as ontology classification.
The semantics of EL+ ontologies, as well as of subsumption, is defined by
means of interpretations in the standard way, and we refer the reader to [12,1].

3 Modules Based on Connected Reachability

In this section, we introduce a new kind of module based on connected reachability,
and propose an algorithm for extracting the modules of this kind. We also show
that, in the DL EL+, our modules indeed correspond to modules based on syntactic
locality first introduced in [6]. We start by giving the general definition of module:
Definition 1 (Modules for an axiom and a signature). Let O be an EL+
ontology, and O a (possibly empty) set of axioms from O. We say that O is a
module in O for an axiom  (for short, -module in O ) if: O |=  iff O |= .
We say that O is a module for a signature S if, for every axiom  with
Sig()  S, we have that O is an -module in O.
Intuitively, a module of an ontology O is a subset O  O that preserves an
axiom of interest or the axioms over a signature of interest. Observe that this is
a very generic definition, in the sense that the whole ontology is itself a module.
In the following, we are interested in certain sufficient conditions that not only
help extract a module according to Definition 1 but also guarantee relevancy of
the extracted axioms. Note that if O |= , a justification (minimal axiom set
?

?

?
that has the consequence) is a minimal -module in O. A justification covers
one axiom, not the axioms over a signature, thus it is normally expensive to
obtain and involve standard inference reasoning, such as subsumption. For this
reason, various syntactic approaches to extracting ontology fragments have been
proposed in the literature [9,11,6]. In [6], Cuenca Grau et al. introduced a kind
of module based on so-called syntactic locality for SHOIQ. Though EL+ is not
a sublanguage of SHOIQ due to RIs, the definition from [6] can be straightforwardly adjusted to suit EL+ as shown below:
Definition 2 (Locality-based modules). Let O be an EL+ ontology, and S
a signature. The following grammar recursively defines Con

(S):

Con

(S) ::= A | (C  C) | (C  C

) | (r.C

) | (r.C)

with r is a role name, C a concept description, A, r  S, and C  Con
(S).
An EL+ axiom  is syntactically local w.r.t. S if it is one of the following
forms: (1) RI R  s where R is either a role name r  S or a role composition r1    rn with ri  S for some i  n, or (2) GCI C  C where
(S). We write local(S) to denote the collection of all EL+ axioms
C  Con
that are syntactically local w.r.t. S.
If O can be partitioned into O and O s.t. every axiom in O is syntactically
local w.r.t. S  Sig(O), then O is a locality-based module for S in O.
Now we consider the optimization techniques of reachability that are used
to heuristically determine obvious subsumption and non-subsumption relation-
ships. The reachability heuristic for non-subsumption can easily be exploited in
module extraction for EL+ ontologies. To obtain a more satisfactory module size,
however, we introduce a more appropriate (i.e., stronger) reachability notion and
develop an algorithm for extracting modules based on this notion.
Definition 3 (Strong/weak reachability). Let O be an EL+ ontology, and
A, B  CN
(O). The strong (weak) reachability graph Gs(O) (Gw(O)) for O is
(O)) and Es (Ew)
a tuple (Vs, Es) ((Vw, Ew)) with Vs = CN
the smallest set containing an edge (A, B) if B =  or A  D  O s.t. B is a
conjunct in D (if B =  or C  D  O s.t. A  Sig(C) and B  Sig(D)).
We say that B is strongly reachable ( weakly reachable) from A in O if there
is a path from A to B in Gs(O) (Gw(O)).
Observe that B is strongly reachable from A in O implies A O B, while A O B
implies that B is weakly reachable from A in O.
The weak reachability graph Gw(O) for O can be extended in a straightforward
way to cover all the symbols in O, i.e., also role names. Precisely, we define
w iff y =  or
the extension as G
there is an axiom L  R  O s.t. x  Sig(L) and y  Sig(R). A module
for S = {A} in an ontology O based on extended weak reachability can be
w(O), extract all the paths from A in Gw(O),
extracted as follows: construct G
and finally, accumulate axioms responsible for the edges in those paths. However,
this kind of module is relatively large, and many axioms are often irrelevant.

w(O) := (Sig(O)  {}, E

w) with (x, y)  E
?

?

?
(O) (Vw = CN
?

?

?
B. Suntisrivaraporn

For example, any GCIs with Disease appearing on the left-hand side, such as
Disease  has-location.Brain  BrainDisease, would be extracted as part of the
module for S = {Pericarditis}. This axiom is irrelevant since Pericarditis does not
refer to Brain and thus BrainDisease. Such a module would end up comprising the
definitions of all disease concepts. To rule out this kind of axioms, we make the
notion of reachability graph stronger as follows: All symbols appearing on the
left-hand side (e.g., Disease, has-location and Brain) are viewed as a connected
node in the graph, which has an edge to each symbol (e.g., BrainDisease) on
the right-hand side of the axiom. The connected node is reachable from x iff all
symbols participating in it are reachable from x. In our example, since Brain is
not reachable from Pericarditis, neither is BrainDisease. Therefore, the axiom is
not extracted as part of the refined module.
Definition 4 (Connected reachability and modules). Let O be an EL+
ontology, S  Sig(O) a signature, and x, y  Sig(O) concept or role names. We
say that x is connectedly reachable from S w.r.t. O (for short, S-reachable) iff
x  S or there is an axiom (either GCI or RI) L  R  O s.t. x  Sig(R)
and, for all y  Sig(L), y is reachable from S.
We say that an axiom L  R is connected reachable from S w.r.t. O (for
short, S-reachable) if, for all x  Sig(L), x is S-reachable. The reachabilitybased module for S in O, denoted by Oreach
, is the set of all S-reachable axioms.
Intuitively, x is connectedly reachable from {y} w.r.t. O means that y syntactically refers to x, either directly or indirectly via axioms in O. If x, y are concept names, then the reachability suggests a potential subsumption relationship
y O x. Note, in particular, that axioms of the forms   D and 	  r in O
are connectedly reachable from any signature because Sig() = Sig(	) = , and
therefore occur in every reachability-based module. In our example, Oreach
{Pericarditis}
contains axioms 1, 3, 57 and 9. We now show some properties of connected reachability and reachability-based modules that are essential for establishing the subsequent lemma and theorem:
). Let O be an EL+
Proposition 1 (Properties of reachability and Oreach
ontology, S, S1, S2  Sig(O) signatures, x, y, z symbols in Sig(O), and A, B concept names in CN(O). Then, the following properties hold:
1. If S1  S2, then Oreach
2. If x is {y}-reachable and y is {z}-reachable, then x is {z}-reachable.
3. If x is connected reachable from {y} w.r.t. O, then Oreach
{x}  Oreach
{y}
4. x  S  Sig(Oreach
5. If B is not connected reachable from {A} w.r.t. O, then A O B.
The converse of Point 5 is not true in general, for instance, Pericarditis involves
Tissue, but the corresponding subsumption does not follow from the ontology.
This suggests that we could use connected reachability as a heuristic for answering negative subsumption, in a similar but finer way as in weak reachability.
We outline our algorithm for extracting the reachability-based module given a
signature S and an ontology O in Algorithm 1. Similar to the technique developed

) if, and only if, x is S-reachable w.r.t. O.

S1

 Oreach
S2

.
?

?

?
Algorithm 1. extract-module
Input: O: EL+ ontology; S: signature
Output: OS: reachability-based module for S in O
1: OS  
2: queue  active-axioms(S)
3: while not empty(queue) do
(L  R)  fetch(queue)
4:
if Sig(L)  S  Sig(OS) then
5:
OS  OS  {L  R}
6:
queue  queue  (active-axioms(Sig(R)) \ OS)
7:
8: return OS
?

?

?
in [3], we view the input ontology O as a mapping active-axioms : Sig(O)  O
with active-axioms(x) comprising all and only axioms L  R  O such that
x occurs in L. The main differences, compared to the O mapping in [3] (also
used in Section 4), are that active-axioms does not assume the input ontology to
be in normal form, and that it is defined for both concept and role names. The
intuition is that every axiom   active-axioms(x) is active for x, in the sense
that y could be connectedly reachable via  from x for some y  Sig(O). For
convenience, we define active-axioms(S) :=
xS active-axioms(x) for a signature
S  Sig(O).
It is easy to see that each axiom Algorithm 1 extracts to OS is S-reachable.
The fact that all S-reachable axioms are extracted to OS can be proved by
induction on connected reachability.
Proposition 2 (Algorithm 1 produces Oreach
). Let O be an EL+ ontology
and S  Sig(O) a signature. Then, Algorithm 1 returns the reachability-based
module for S in O.
In fact, connected reachability can be reduced to propositional Horn clause im-
plication. The idea is to translate each EL+ axiom L  R into the Horn clause
l1lm  r1rn where li  Sig(L) and ri  Sig(R). Given a signature
S and a symbol x, x is S-reachable iff x is implied by
y w.r.t. the Horn
clauses. The Dowling-Gallier algorithm [4] can check this in linear time.

yS
?

?

?
In the following, we show a tight relationship between our reachability-based

is the minimal locality-based module). Let O be an
is the minimal locality-

modules and the (minimal) locality-based modules.
Theorem 1 (Oreach
EL+ ontology, and S  Sig(O) a signature. Then, Oreach
based module for S in O.
So, Algorithm 1 can be used to extract a locality-based module in an EL+
ontology. The main difference, in contrast to the algorithm used in [6,5], is that
our algorithm considers only active axioms for R when a new axiom L  R
is extracted. Also, testing whether an EL+ axiom  = (L  R) is non-local
w.r.t. a signature S  Sig(OS) boils down to testing S-reachability of , which
is a simpler operation of testing set inclusion Sig(L) ? S  Sig(OS). This

B. Suntisrivaraporn

is due to the fact that any concept description and role composition L, with
x  Sig(L) interpreted as the empty set, is itself interpreted as the empty set.
This observation could be used to optimize module extraction for ontologies in
expressive description logics.
It has been shown for SHOIQ that locality-based modules for S = {A} in O
preserves the subsumption A  B for any B  CN(O) [6]. This property could
have been transferred to our setting as a corollary of Theorem 1 if EL+ were a
sublanguage of SHOIQ. Despite this not being the case, it is not hard to show
that reachability-based modules in EL+ also enjoy the property:
Lemma 1 (Oreach
and Oreach
{A}
 = A  B with B  CN(O), O |=  iff Oreach

preserves A O B). Let O be an EL+ ontology, A  CN(O),
the reachability-based module for S = {A} in O. Then, for any

{A} |= .

4 Goal-Directed Subsumption Algorithm

In general, the techniques developed for module extraction have a number of potential applications, including optimization of standard reasoning, incremental
classification, explanation, and ontology re-use. An obvious way to exploit module extraction to speed up standard reasoning, such as subsumption  ?O , is
to first extract the module Oreach
{} for S = {} in O, and then query the subsumption  ?Oreach{}
, i.e., w.r.t. the module instead of the original ontology. Based on
the assumption that modules are relatively much smaller than the ontology, this
optimization should be highly effective. In this section, however, we argue that
module extraction actually does not help speed up standard reasoning in EL+.
This stems from the deterministic and goal-directed nature of the reasoning algorithm for deciding subsumption in EL+, which is in contrast to non-deterministic
tableau-based algorithms for expressive logics, such as SHOIQ.
In fact, with small modifications to the EL+ classification algorithm (first
introduced in [1] for EL++ and later refined for implementation in [3]), we obtain
a subsumption testing algorithm. The modified algorithm does not actually have
to perform steps irrelevant to the subsumption in question  the goal. We call
this variant the goal-directed subsumption algorithm.

Algorithm 2 outlines the modified core procedure goal-directed-process to replace process of Figure 3 in [3]. The procedure process-new-edge, as well as essential data structures, i.e., O, queue, R, S, remains intact. In particular, we view
the (normalized) input ontology O as a mapping O from concepts (appearing
on the left-hand side of some GCI) to sets of queue entries. Here, B denotes the
set of all concept names appearing in the conjunction B1    Bn.
The main difference is the initialization of S, thus of queue. Since we are interested in the particular subsumption   , we activate only  by initializing
S() with {,} and queue() with O()  O(). We activate a concept name
B only when it becomes the second component of a tuple added to some R(r)
and has not been activated previously (see lines 8-9 in goal-directed-process of
Algorithm 2). Thereby, S(B) and queue(B) are initialized accordingly. Queues
?

?

?
return positive

if goal-directed-process(A, X,   ) then

Algorithm 2. Goal-directed subsumption algorithm
Procedure subsumes(  )
Input: (  ): target subsumption
Output: positive or negative answer to the subsumption
1: activate()
2: while not empty(queue(A)) for some A  CN(O) do
3: X  fetch(queue(A))
4:
5:
6: return negative
Procedure goal-directed-process(A, X,   )
Input: A: concept name; X: queue entry; (  ): target subsumption
Output: positive or unknown answer to the subsumption
1: if X = B  B, B  S(A) and B  S(A) then
2:
3:
4:
5:
6:
7:
8: if X = r.B and (A, B)  R(r) then
9:
10:
11: return unknown

S(A) := S(A)  {B}
queue(A) := queue(A)  O(B)

for all concept names A
and role names r with (A
)  O(r.B)

) := queue(A

activate(B)
process-new-edge(A, r, B)

if A =  and B =  then

queue(A
?

?

?
return positive
?

?

?
, A)  R(r) do

are processed in the same fashion as before except that  and  are now being
monitored (Line 6), so that immediately after  is added to S(), the algorithm
terminates with the positive answer (Line 7). Otherwise, goal-directed-process terminates normally, and the next queue entry will be fetched (Line 3 in subsumes?
of Algorithm 2) and processed (Line 4). Unless positive is returned, queues processing is continued until they are all empty. In this case, the algorithm returns
negative.
It is important to note that the goal-directed algorithm activates only concept
names relevant to the target subsumption   , i.e., those reachable via R()
from . The subsumer sets of concept names that do not become activated are
not populated. Moreover, axioms that are involved in rule applications during
the computation of subsumes?(  ) are those from the reachability-based
{} in O. The following proposition states this correlation:
module Oreach
Proposition 3 (subsumes?(  ) only requires axioms in Oreach
be an ontology in EL+ normal form, and Oreach
S = {} in O. Then, subsumes?(  ) only requires axioms in Oreach
{} .
Intuitively, the proposition suggests that our goal-directed subsumption algorithm inherently takes into account the notion of connected reachability, i.e., it
applies rules only to relevant axioms in the reachability-based module. In fact,

). Let O
{} the reachability-based module for



B. Suntisrivaraporn

the preprocessing overhead of extracting the relevant module Oreach
{} for the subsumption query  ?O  makes the overall computation time for an individual
subsumption query longer. This has been empirically confirmed in our experiments (see the last paragraph of Section 6).

Despite what has been said, module extraction is still useful for, e.g., ontology

re-use, explanation, and full-fledged incremental reasoning [5].

5 Duo-Ontology Classification

ex

ex

Unlike tableau-based algorithms, the polynomial-time algorithm in [1,3] inherently classifies the input ontology by making all subsumptions between concept
names explicit. This algorithm can be used to query subsumption between concept names occurring in the ontology, but complex subsumptions, such as
Inflammationhas-location.Heart ?Oex HeartDiseasehas-state.NeedsTreatment
cannot be answered directly. First, the ontology Oex from Figure 1 has to be augex := Oex  {A  Inflammation  has-location.Heart, HeartDisease 
mented to O
has-state.NeedsTreatment  B} with A, B new concept names, and then the
subsumption test A ?O
B can be carried out to decide the original complex
subsumption. Since A, B are new names not occurring in Oex, our complex subsumption holds iff A O
B. This approach is effective but inefficient unless only
one such complex subsumption is queried for each ontology. Constructing and
normalizing the augmented ontology every time each subsumption is tested is
not likely to be acceptable in practice, especially when the background ontology
is large. For instance, normalization of Snomed ct takes more than one minute.
In this section, we propose an extension to the refined algorithm (henceforth
referred to as the original algorithm) developed in [3] to cater for a duo-ontology
O = (Op  Ot) with Op a permanent EL+ ontology and Ot a set of temporary
GCIs. Intuitively, Op is the input ontology of which axioms have been read in
and processed before, while Ot contains temporary GCIs that are asserted later.
The main purpose is to reuse the information made available by the preprocess and classification of Op. Once Op has been classified, the classification of
Op  Ot should not start from scratch but rather use the existing classification
information together with the new GCIs from Ot to do incremental classification.
In our extension, we use two sets of the core data structures O(), R(), S(), but
retain a single set of queues queue(). The mappings Op, Rp, Sp are initialized and
populated exactly as in the original algorithm, i.e., Op encodes axioms in Op, and
Rp, Sp store subsumption relationships inferred from Op. Similarly, the mapping
Ot encodes axioms in Ot, but Rt, St represent additional inferred subsumptions
drawn from Op  Ot that are not already present in Rp, Sp, respectively. The extended algorithm is based on the tenet that description logics are monotonic, i.e.,
Op |=  implies OpOt |= . There may be an additional consequence  such that
Op |=  but OpOt |= . Our algorithm stores such a consequence  in a separate
set of data structures, namely Rp, Sp. Analogously to the original algorithm, queue
?

?

?
Algorithm 3. Processing queue entries in duo-ontology classification
Procedure process-duo(A, X)
Input: A: concept name; X: queue entry;
1: if X = B  B, B  Sp(A)  St(A) and B  Sp(A)  St(A) then
2:
3:
4:
5:
6: if X = r.B and (A, B)  Rp(r)  Rt(r) then
7:

St(A) := St(A)  {B}
queue(A) := queue(A)  Op(B)  Ot(B)
for all A

, A)  Rp(r)  Rt(r) do

)  Op(r.B)  Ot(r.B)

and r with (A
?

?

?
) := queue(A

process-new-edge(A, r, B)

queue(A
?

?

?
Procedure process-new-edge-duo(A, r, B)
Input: A, B: concept names; r: role name;
1: for all role names s with r 
Rt(s) := Rt(s)  {(A, B)}
queue(A) := queue(A)  
2:
3:
for all concept name A
4:
(A

, A)  Rp(u)  Rt(u) and (A
process-new-edge-duo(A
, v, B)
?

?

?
Op s do
{B|BSp(B)St(B)}( Op(s.B
, B)  Rp(v)  Rt(v) do

))
 and role names u, v with u  s  v  Op and

)  Ot(s.B
?

?

?
5:
6:

7:

for all concept name B
(B, B

)  Rp(u)  Rt(u) and (A, B
?

?

?
)  Rp(v)  Rt(v) do

 and role names u, v with s  u  v  Op and

process-new-edge-duo(A, v, B

)
?

?

?
entries are repeatedly fetched and processed until all queues are empty. Instead
of the procedures process and process-new-edge, we use the extended versions for
duo-ontology classification as outlined in Algorithm 3.
The behavior of Algorithm 3 is identical to that of the original one [3] if Op
has not been classified before. In particular, Op()  Ot() here is equivalent to
O() in [3] given that O = (Op  Ot). Since no classification has taken place,
Sp(A) = Rp(r) =  for each concept name A and role name r. Initialization and
processing of queues are done in the same manner with the only difference that
inferred consequences are now put in Rt and St.
If Op has been classified (thus, Sp, Rp have been populated), then a proper
initialization has to be done w.r.t. the previously inferred consequences (i.e.,
Sp, Rp) and the new GCIs (i.e., Ot). To this end, we initialize the data structures
by setting:
 for each role name r  RN(O), Rt(r) := ;
 for each old concept name A  CN(Op), St(A) :=  and
{(A,B)Rp(r),XSp(B)} Ot(r.X);
 for each new concept name A  CN(Ot)\CN(Op), St(A) := {A,}

Ot(X)  

XSp(A)

queue(A) :=
queue(A) := Ot(A)  Ot().
?

?

?
After initialization, queue processing is carried out by Algorithm 3 until all
queues are empty. Observe the structural analogy between these procedures and
the original ones in [3]. Observe also the key difference: information is always

B. Suntisrivaraporn

retrieved from both sets of data structures, e.g., Sp(A)  St(A) in Line 1, while
modifications are only made to the temporary set of data structures, e.g., St(A) :=
St(A){B} in Line 2. The correctness of Algorithm 3 can be shown following the
correctness proofs structures of the original algorithm (see the submitted journal version of [3]) w.r.t. additional subsumption consequences obtained during
incremental classification.
Lemma 2 (Correctness of Algorithm 3). Let O = (Op  Ot) be a duo-
ontology, and Sp, Rp be the results after the original algorithm terminates on
Op. Then, the extended algorithm (Algorithm 3), applied to Ot, incrementally
classifies Ot against Op (i.e., classifies O) in time polynomial in the size of O.
That is, B  Sp(A)  St(A) iff A O B for all A, B  CN(O).
In our example, we may view Oex as the permanent ontology Op and the two new
GCIs as the temporary ontology Ot. We can then run the extended algorithm on
Op  Ot and reuse existing information in Sp and Rp, if any. After termination,
our complex subsumption boils down to the set membership test B ? Sp(A) 
St(A) = St(A). To decide subsequent subsumption queries, only Ot, Rt, St, and
queue need to be initialized, leaving the background ontology Op and possibly
its classification information Rt, St intact.
Interestingly, this algorithm can be used effectively in certain scenarios of
incremental classification. Consider Op as a well-developed, permanent ontology,
and Ot as a small set of temporary axioms currently being authored. Obviously, if
the permanent ontology is large, it would be impractical to reclassify from scratch
every time some new axioms are to be added. Algorithm 3 incrementally classifies
Ot against Op and its classification information. If the inferred consequences are
satisfactory, the temporary axioms can be committed to the permanent ontology
by merging the two sets of data structures. Otherwise, axioms in Ot and their
inferred consequences could be easily retracted, since these are segregated from
Op and its consequences. To be precise, we simply dump the values of Ot(), Rt()
and St(), when the temporary axioms are retracted.

6 Experiments and Empirical Results

This section describes the experiments and results of the three algorithms we
proposed in this paper: module extraction, goal-directed subsumption query,
and duo-ontology classification, which have been implemented and integrated as
new features into the CEL reasoner [2] version 1.0b. All the experiments have
been carried out on a standard PC: 2.40 GHz Pentium-4 processor and 1 GB of
physical memory. In order to show interesting characteristics of reachabilitybased modules and scalability of subsumption and incremental classification
in EL+, we have selected a number of large-scale medical ontologies. Our test
suite comprises Snomed ct, Nci, and the EL+ fragments1 of FullGalen and
1 FullGalen is precisely based on SHIF dispensed with negation, disjunction, and
value restriction. The DL EL+ can indeed express most of its axioms, namely 95.75%,
and we obtained this fragment for experimental purposes by dropping role inverse
and functionality axioms.
?

?

?
Table 1. EL+ ontology test suite

Ontologies Concepts/roles Concept/role axioms Class. time (sec) Positive subs. (%)
ONotGalen
OFullGalen
ONci
OSnomed

3 937 / 442
35 531 / 1 016
46 800 / 140
379 691 / 13

2 748 / 413
23 136 / 950
27 652 / 70
379 691 / 62

7.36
512.72
7.01
1 671.23

0.6013
0.1648
0.0441
0.0074

NotGalen, denoted respectively by OSnomed, ONci,OFullGalen, and ONotGalen.2
The FullGalen ontology shall not be confused with the original version of
Galen, the latter of which is almost 10 times smaller and commonly used in DL
benchmarking. The sizes of our test suite ontologies are shown in the second and
third columns of Table 1. The last but one column shows the time CEL needs to
classify each ontology, while the last presents in percentage the ratio of positive
subsumption relationships between concept names. Observe that all ontologies
have a very low ratio of positive subsumption (less than 1%); in particular, less
than a ten-thousandth of all potential subsumptions actually hold in OSnomed.
Modularization: For each ontology O in the test suite and each concept name
A  CN(O), we extracted the reachability-based module Oreach
A . Statistical data
concerning the sizes of modules and times required to extract them are presented
in Table 2. Observe that it took a tiny amount of time to extract a single module
based on connected reachability, with the maximum time less than four seconds.
However, extracting large the number of modules (i.e., one for each concept
name) required considerably more time and even longer than classification. This
was nevertheless the first implementation that was not highly optimized. Several optimization techniques could be employed in module extraction, especially
recursive extraction as suggested by Point 3 of Proposition 1 and the counting
techniques from [4]. To empirically support Theorem 1, we have compared our
modularization algorithm to that from [5,6]. As expected, the results of both
algorithms coincide w.r.t. ONotGalen and ONci, while we were unable to obtain
locality-based modularization results w.r.t. the other two ontologies.3
Interestingly, module extraction reveals important structural dependencies
that reflect complexity of the ontology. Though very large, concepts in ONci and
OSnomed are loosely connected w.r.t. reachability which makes it relatively easy
to classify. In contrast, OFullGalen contains more complex dependencies4, thus
is hard to classify.
Duo-ontology classification: As mentioned before, there are at least two applications of Algorithm 3, viz., complex subsumption query and (restricted)
2 Obtainable at http://lat.inf.tu-dresden.de/meng/toyont.html.
3 Due to memory exhaustion with 0.8 GB of Java heap space.
4 Based on the statistical data analysis, there are two clearly distinct groups of concepts in OFullGalen
: the first with module sizes between 0 and 523 (med. 39; avg.
59.29) and the second between 14 791 and 15 545 (med. 14 792; avg. 14 829). Surpris-
ingly, there is no module of size between those of these two groups.

B. Suntisrivaraporn

Table 2. Module extraction (time in second; size in number of axioms)

Ontologies
ONotGalen
OFullGalen
ONci
OSnomed

Extraction time

Module size (%)

median average maximum total
< 0.01  0.00
0.04
< 0.01  0.00
< 0.01  0.01

0.01

35 (1.27) 68.64 (2.50)

0.01 2.38
495 (18.00)
0.85 960 178 (0.77) 7092 (30.65) 15 545 (67.18)
436 (0.929)
0.17 3.43 12 (0.026) 28.97 (0.062)
3.83 3 744 18 (0.005) 30.31 (0.008)
262 (0.069)

median

average

maximum

Table 3. Incremental classification (in second)
ONotGalen

OFullGalen

ONci

OSnomed

C. time IC. time C. time IC. time C. time IC. time C. time IC. time
55.86
57.97
68.58
83.27
93.89

2.00 1 666.43
2.15 1 663.51
2.37 1 661.49
2.54 1 652.84
3.19 1 640.11

1.75 486.19
1.88 484.89
2.45 482.13
2.88 466.97
4.46 450.61

56.94
59.37
62.34
80.52
109.81

5.10
4.81
4.78
4.70
4.59

6.53
6.50
6.48
6.43
6.38

Temp. axioms

(|Ot|)
0.2%
0.4%
0.6%
0.8%
1.0%

incremental classification. For complex subsumption query, we have adopted
the activation idea from Algorithm 2 to quickly answer the query. To perform
meaningful experiments, it is inevitable to involve a domain expert to obtain
sensible test data. Though we have done so w.r.t. OSnomed, the numbers of complex subsumption queries and additional axioms are very small compared to the
ontology size.5 For this reason, we have developed our test strategy as follows:
for each ontology O and various numbers n, we have (i) partitioned O into Op
and Ot such that Ot contains n% of GCIs from O; (ii) classified Op normally;
finally, (iii) incrementally classified Ot against Op. The average computation
times for several runs of (ii) and (iii) are shown in the left and right columns of
each ontology in Table 3, respectively. It requires only 4% (resp., 15%, 35%, and
38%) of the total classification time for OSnomed (resp., for OFullGalen, ONci,
and ONotGalen) to incrementally classify up to 1% of all axioms, i.e., about
four-thousand axioms in the case of OSnomed.
Subsumption: To evaluate our goal-directed algorithm, we have run subsumption tests between random pairs of concept names without any heuristics.6
Average/maximum querying times (in second) are 0.09/1.51 for ONotGalen,
124.01/254.31 for OFullGalen, 0.0034/0.44 for ONci, and 0.0183/3.32 for OSnomed.
5 On average, a typical complex subsumption query against OSnomed
took 0.00153
milliseconds, while incremental classification of one axiom needed 48.74 seconds.
6 Since there are about 144 billion pairs of concept names in the case of OSnomed
and some subsumption queries against OFullGalen
took a few minutes, performing
subsumption queries between all pairs would not be feasible. Therefore, one thousand
random pairs of subsumption were tested against OFullGalen
, and one million random
pairs against each of the other ontologies.
?

?

?
Notice that subsumption requires a negligible amount of time and not much more
than extracting a module in the case of ONci and OSnomed. Observe also that
subsumption querying times are roughly proportional to module sizes, which
reflects the nature of the goal-directed algorithm as stated by Proposition 3.

7 Related Work

Recently, various techniques for extracting fragments of ontologies have been
proposed in the literature. An example is the algorithm proposed in [11] which
was developed specifically for Galen. The algorithm traverses in definitional order and into existential restrictions but does not take into account other de-
pendencies, e.g., role hierarchy and GCIs. If applied to our example ontology
Oex, the algorithm extracts only 1, 3 and 5 as its segmentation output for
Pericarditis. This is obviously not a module because we lose the subsumption
Pericarditis Oex HeartDisease. Another example is the Prompt-Factor tool [9]
which implements an algorithm that, given an ontology O and a signature S,
retrieves a subset O1  O by retrieving to O1 axioms that contain symbols in
S and extending S with Sig(O1) until a fixpoint is reached. This is similar to
our modules based on weak reachability, but it does not distinguish symbols occurring on lhs and rhs of axioms. In our example, the tool will return the whole
ontology as output for S = {Pericarditis}, even though several axioms are irrele-
vant. As we have shown, modules based on syntactic locality [6] are equivalent
to our reachability-based modules relative to EL+ ontologies. Since reachability
is much simpler to check, our algorithm has proved more efficient.

Incremental classification and reasoning have received much attention in the
recent years. In [7,10], the so-called model-caching techniques have been investigated for application scenarios that only ABox is modified. A technique for
incremental schema reasoning has recently been proposed in [5]: it utilizes modules to localize ramifications of changes and performs additional reasoning only
on affected modules. The framework supports full-fledged incremental reasoning
in the sense that arbitrary axioms can be retracted or modified, and as such it
is worthwhile to investigate how its techniques can be integrated into our duoontology classification algorithm. All above-mentioned works focus on expressive
languages. Here, however, we developed a very specific approach to (restricted)
incremental classification in EL+. Since the technique exploits the facts that the
original EL+ algorithm maintains completed subsumer sets, it is not obvious
how this may benefit tableau-based algorithms for expressive DLs.

8 Conclusion

In this paper, we have introduced a new kind of module (based on connected
reachability) and proposed an algorithm to extract them from EL+ ontologies.
We have shown that these are equivalent to locality-based modules w.r.t. EL+
ontologies and empirically demonstrated that modules can be extracted in reasonable time and are reasonably small. Also, we have proposed a goal-directed
variant of the algorithm in [3] for testing subsumption prior to classification

B. Suntisrivaraporn

and have extended this algorithm to cater for a duo-ontology which can be utilized to answer complex subsumption queries and to do (restricted) incremental
classification. Our empirical results have evidently confirmed that the proposed
algorithms are practically feasible in large-scale ontology applications.
Despite not being directly useful to speed up standard reasoning in EL+, modularization obviously benefits ontology re-use and explanation. As future work,
we shall study the effectiveness of using modules to optimize axiom pinpointing,
which is the cornerstone of explanation support.

Acknowledgement. The author would like to acknowledge Franz Baader and
Carsten Lutz for their valuable suggestions and Christian H.-Wiener for his willingness in comparing the two modularization approaches.
