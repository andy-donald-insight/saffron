Streaming SPARQL - Extending SPARQL to Process

Data Streams

Andre Bolles, Marco Grawunder, and Jonas Jacobi

University of Oldenburg, Germany,

Department for Computer Science, Information Systems and Databases


		

	
	
	

Abstract. A lot of work has been done in the area of data stream processing.
Most of the previous approaches regard only relational or XML based streams
but do not cover semantically richer RDF based stream elements. In our work,
we extend SPARQL, the W3C recommendation for an RDF query language, to
process RDF data streams. To describe the semantics of our enhancement, we
extended the logical SPARQL algebra for stream processing on the foundation
of a temporal relational algebra based on multi-sets and provide an algorithm to
transform SPARQL queries to the new extended algebra. For each logical algebra
operator, we define executable physical counterparts. To show the feasibility of
our approach, we implemented it within our O	 framework in the context
of wind power plant monitoring.

1 Introduction

Wind power plants are one promising way to reduce CO2 emissions and by this the
greenhouse eect. Large o-shore wind parks are capable of delivering electric power in
a constant and reliable way. These parks need high initial investments, so keeping maintenance costs low is indispensable. Monitoring and early problem detection is essen-
tial. The current approach to monitor wind parks are proprietary SCADA (Supervisory
Control and Data Acquisition) systems. This leads to the problem of missing interoperability between dierent wind power plant vendors and makes it dicult or even
impossible for customers to extend the system. In analogy to the application of database
management systems for many standard applications like personnel or warehouse man-
agement, we believe that data stream management systems (DSMS) [1] can help in
reducing initial wind parks costs and providing higher interoperability. The International Electrotechnical Commission has proposed a standard to monitor and communicate with wind parks [2]. IEC 61400-25 contains a standard data model and a common
information model. The standard determines no communication format. A common approach could be the usage of XML. In our work we analyze the use of RDF [3] as an
alternative, because RDF can be used to model IEC 61850 family and substandards like
61400-25 in future. Furthermore a triple contains all information needed to understand
the content therefore RDF is an ideal format for serialization and missing triples (e.g.
because of network failure) do not necessary corrupt the whole stream.

In DSMS continuous queries are used to determine stream information. SPARQL
is the W3C Recommendation for a query language over RDF. Unfortunately, this

S. Bechhofer et al.(Eds.): ESWC 2008, LNCS 5021, pp. 448462, 2008.
c Springer-Verlag Berlin Heidelberg 2008
?

?

?
approach is not applicable directly to RDF data streams. A sensor produces typically
unlimited datasets (e.g. an element every second). Some operators in SPARQL need the
whole dataset to process, like distinct, join or sort. A common approach for this problem is the use of window queries. Instead of regarding the whole stream, only subparts,
so called windows, are treated. Because recent data have typically higher relevance (e.g.
average wind speed in the last 10 minutes) this approach is applicable. We regard different kinds of windows. Time based windows define the window by a unit of time (e.g.
the last 10 minutes). These windows are called sliding windows, if they are moved for
each new point in time. If the windows are moved only after a distinct period, these
windows are called sliding  windows (e.g. move the window every 5 minutes over the
stream with the window size 10 minutes) [4]. Element based windows are defined by
the number of elements in the window (e.g. the last 100 statements). We model these
windows by defining temporal element validity, i.e. if an element is valid it is part of
the window.

In query processing we follow the usual approach of translating a descriptive query
into an internal representation (the logical plan) that can more easily be optimized and
transformed. This logical plan will then be translated into a set of physical plans, containing executable physical algebra operators. Finally, one of these plans will be se-
lected, e.g. by means of a cost model, and executed.

The contributions of this paper are:

 the extension of SPARQL to handle RDF based data streams,
 the precise definition of the semantics of this extension by extending the existing

SPARQL algebra,

 a transformation algorithm to map the language extension to the extended SPARQL

algebra and

 a set of physical algebra operators to execute the queries.

The remainder of this paper is as follows. The next section describes how we extended the SPARQL grammar to allow referencing data streams and defining windows
over these streams. After that we give a clear formal definition of what our data streams
are (Sec. 3) and, based on this definition, we show how we extended the SPARQL algebra (Sec. 4) and how SPARQL queries can be translated into that algebra (Sec. 5).
Because algebra operators are not executable we defined physical counterparts of each
logical operator (Sec. 6). Finally, we discuss related work (Sec. 7) and give an outlook
on future work.

2 Extending the SPARQL Grammar

SPARQL as defined in [5] is not sucient to define queries over data streams. One of
our main goals is to preserve the known syntax and semantics of SPARQL as much
as possible. We extend SPARQL with the capability to explicitly state data streams
and to define windows over them. Windows can be defined in the FROM part of a
SPARQL query to define a common window for the whole data stream. To allow a finer
granularity we also allow windows in graph patterns.

A. Bolles, M. Grawunder, and J. Jacobi

Table 1 shows the extended grammar production rules in EBNF. First are listed those
rules that are aected by our extensions1. Then new rules are listed. Extensions and
new rules are shown in bold. The other rules from [5] do not need to be modified for
processing data streams2. All nonterminals (underlined) that are not explained further
are identical to [5].

Table 1. Extended SPARQL Grammar (extract)

SelectQuery

:: SELECT ( DISTINCT  REDUCED )? ( Var  * )

(DatasetClause*  DatastreamClause*)
WhereClause SolutionModifier

:: NAMED SourceSelector
:: FROM (DefaultStreamClause  NamedStreamClause)

NamedGraphClause
DatastreamClause
DefaultStreamClause :: STREAM SourceSelector Window
NamedStreamClause :: NAMED STREAM SourceSelector Window
SourceSelector
GroupGraphPattern

:: IRIref
::  TriplesBlock? ((GraphPatternNotTriples  Filter) .?

Window

:: (SlidingDeltaWindow  SlidingTupelWindow 

TriplesBlock? )* (Window)? 

FixedWindow)

:: WINDOW RANGE ValSpec FIXED

SlidingDeltaWindow :: WINDOW RANGE ValSpec SLIDE (ValSpec)?
FixedWindow
SlidingTupelWindow :: WINDOW ELEMS INTEGER
ValSpec
INTEGER
Timeunit

:: INTEGER Timeunit?
:: [0-9]
:: (MS  S  MINUTE  HOUR  DAY  WEEK)

To state an input as a data stream the keyword STREAM followed by an IRI has to
be used. We allow dierent window types, which require specific language extensions.
If a window is defined in a query in the FROM and in the graph pattern parts, only the
more special window of the graph pattern is evaluated. We provide time based windows
and element based windows. Sliding -windows allow the definition of the window size
with the RANGE keyword whereas we assume milliseconds to be the default timeunit.
SLIDE defines the delay after which the window is moved. The value after SLIDE
can be omitted. In that case the size is 1 of the unit defined in the RANGE-part. If
SLIDE and RANGE contain the same values, we call this a fixed (or tumbling) window.
As syntactic sugar we also allow the definition of this window using FIXED. Finally,
ELEMS defines element based windows.

Listing 1.1 below gives an example of a query containing time and element based
windows in the FROM and in the optional graph pattern part. The idea of the query is
to return the number of starting a wind turbine in the last 30 minutes and, if available,
the number of stopping a wind turbine that has to be reported in the last 1500 elements
of the data stream.

1 For space reasons we omitted Construct, Describe and Ask queries which are defined similar

to Select.

2 Of course there are possibly dierent semantics when defining queries over data streams.
?

?

?
PREFIX w t u r :  h t t p :   i e c . o r g 61400 25  r o o t  l n  c l a s s e s WTUR#
SELECT ? x ? y ? z
FROM STREAM  h t t p :   i e c . o r g 61400 25  r o o t  t d . r d f 

WINDOW RANGE 30 MINUTE SLIDE

WHERE  ? x w t u r : S t r C n t ? y .

OPTIONAL  ? x w t u r : S t o p C n t ? z .
WINDOW ELEMS 1500  

Listing 1.1. SPARQL query over an RDF stream with windows

3 Defining Data Streams

Before we present our extended algebra we define the logical base of our algebra, the
data stream. Like [6] we distinguish between a raw data stream, representing the data
received by the DSMS, a physical data stream which can be processed by the operators
of the DSMS and finally a logical data stream over which the algebra and therefore
the semantics of the extensions can be defined. Many of the following definitions are
inspired by [6].

A raw data stream represents simply the data arriving at the DSMS. The data format
could be in dierent formats like XMLRDF or Turtle representation. A special access
operator can transform the statements to a unified representation. Because some sources
in data stream applications typically produce timestamped information (e.g. a sensor for
wind speed also transmits a timestamp for the measured value), we defined an RDF raw
data stream with timestamps, too.

The physical RDF data stream contains prepared elements that can be used as input
for physical data stream operators. This means especially that all elements are times-
tamped, defined either by the data source (raw data stream with timestamps) or by the
DSMS (raw data streams without timestamps). Let   (T ; ) be a discrete time domain as proposed by [7]3. Let 	 : [ts te)  T 
 T ts  te be the set of right open time
intervals:

Definition 1 (Physical RDF data stream). Let P
RDF be the set of all physical RDF
data streams. A physical RDF data stream S P
RDF 
(MP
RDF  
((s p o) [tS  tE))(s p o)   [tS  tE)  	 is an ordered
possibly unlimited sequence of pairs, consisting of an RDF statement and a right open
time interval. The order is defined by P
t :

RDF is defined as a pair S P

RDF  P

RDF  P

t ) where MP

xi x j   
 	 i j   i  j : xi P

t x j  xitS  x jtS

In SPARQL only the first operators typically handle RDF based data. E.g. a basic graph
pattern transforms RDF statements to SPARQL solutions  which are the input to the
following operators. To represent this in our algebra we define a set P
 of physical 
data streams analogous to P

RDF.

3 Without reducing generality, we allow only natural numbers for .

A. Bolles, M. Grawunder, and J. Jacobi

Logical algebra operators consume logical RDF streams. These logical streams are
not defined as sequences but as multi-sets. Because no elements are processed on the
logical level, it is only used for transformation and optimization; the order in the streams
is not relevant. The great advantage of defining logical streams on multi-set semantics
is to make it possible to base our algebra on the extended relational algebra [8]. Just
like there, duplicates are allowed and expressed by the number of occurrences.

Definition 2 (Logical RDF data stream). Let L
RDF be the set of all logical RDF data
streams. A logical RDF data stream is a possibly unlimited multi-set of triples: S L
RDF 
((s p o) t n)(s p o)   t   n  
0. The triple ((s p o) t n) expresses: The
RDF statement (s p o) is valid at time t and occurs n-times at this point in time.
((s p o) t n)  S L
means that subject, predicate and object of two statements are pairwise equal.

RDF : (s p o) RDF ( s p o)  t  t. RDF

RDF : (( s p o) t n)  S L

Analogously, we define the set of logical  data streams L
 , because not all logical
algebra operators can consume logical RDF data streams. We also define sequential
logical RDF and sequential logical  data streams to support sort operations. We will
use L

x if no distinction between RDF and  is necessary.

To relate physical and logical algebra operators, and thus defining the semantics of
the physical operators, we need to define transformations between the dierent stream
types. Thereby it is possible to assign plan transformations and optimizations on the
logical query level also to the physical level. Due to space limitations we need to omit
these transformations here.

4 Extending the SPARQL Algebra

Given the base definitions, we can now present some of the formal definitions of our
new or extended SPARQL algebra operators.

The first operator we introduce is needed to define windows over the logical stream
L
x. It takes parameters w   defining the width of the window and   w defining the
delay of window moving:

Definition 3 (Sliding -window). Let w   be the width of a sliding window and
  w   be a time span, by which the window is moved. Let t   be a point in time.
A sliding -window is a function slide
w

x 
  
  
   L

x , with:

: L

slide
w (S L

x  t) : (z t n)i   : (i 	 )  w  t  i 	  

x : Y   

Y  S L
Y  (z t n) max(i 	 )  w 0  t  t 
n  (ztn)Y n

The special case   1 defines a sliding window, the case   w defines a tumbling
window. Defining   w ensures not to miss elements by moving the window. The
second kind of window, called a sliding tuple window, is defined over the element count
in a stream. To define this operator we need to define a count function on logical data
streams, that gives the number of elements in a logical RDF or  stream (in the following
represented by x) until a point in time t [6]:
?

?

?
Definition 4 (Count function of logical x data streams). Let t   be a point in time.
The function m : L
x 
    calculates the number of all elements in the data stream
until t:

m(t S L

x ) : 

(z t nt  t

This definition is only valid for n  1, i.e. at every point in time only one element is
added to the stream. With this function a sliding tuple window can be defined as follows:

Definition 5 (Sliding tuple window). Let c   be the maximum size of a sliding
tuple window and t   a point in time. A sliding tuple window is a function count
:
L
x 
  
   L

x with:

c

count

c

(S L

x)  c 1  m(t S L

x )  m(t)

x  t) : (z t n)Y  S L
Y  (z t n)  S L
 n  (ztn)Y n

x : Y   
x maxm(t S L

Triple Pattern Matching. In SPARQL [5] no operator for the transformation from
RDF statements to SPARQL is defined. To be more general, we introduce the operator
 that filters statements from a (logical) RDF stream and transforms them to SPARQL
solutions. To cope with the problem of blank nodes we need to extend the definition for
an RDF instance mapping from [9]:

Definition 6 (Extended RDF instance mapping). Let  be the set of all extended RDF
instance mappings. An extended RDF instance mapping ext   is a function ext :
RDF-T  V  RDF-T  V using a function f : RDF-B  RDF-T:

ext(x) :
?

?

?
f (x)  RDF-T
x

if x  RDF-B
if x  I  RDF-L  V

We can then define the triple matching operator:

Definition 7 (Triple pattern matching). Let p  (x y z)   be a triple pattern in
the set of all triple patterns, S L
RDF a logical data stream and ext : RDF-T 
V  RDF-T  V an extended RDF instance mapping. The triple pattern matching
 : L

RDF  L

 is defined as follows:

RDF 
   L

p(S L

RDF) : ( t n)((s p o) t n)  S L

RDF : ext   :

ext(x)  RDF-T  ext(x)  s  ext(y)  RDF-T  ext(y)  p 
ext(z)  RDF-T  ext(z)  o  ext(x)  V  (ext(x))  s 
ext(y)  V  (ext(y))  p  ext(z)  V  (ext(z))  o

The triple pattern matching operator transforms a logical RDF stream into a logical 
data stream, i.e. it changes the schema of the contained elements. All the following
described operators consume logical  streams. Therefore, the triple pattern matching
operator must be placed in a plan before any of the following operators.

A. Bolles, M. Grawunder, and J. Jacobi

Filter. The filter operator evaluates the FILTER term of a SPARQL query. It selects
from a logical  stream those elements that satisfy a predicate p( t)  s from the set
of all SPARQL predicates.4

Definition 8 (Filter). Let p :  
   true f alse  s be a SPARQL predicate. A
filter operator fp is a function f : L

, defined as follows:

 
   L

fp(S L

) : ( t n)( t n)  S L

  p( t)

Union. The union of two logical  streams evaluates the UNION term of a SPARQL
query.

Definition 9 (Union of logical  data streams). The union  of two logical  data
streams is a function  : L

, defined as follows:

  L

 
 L

(S L

1 S L

2) : ( t n1  n2)
(( t n1)  S L
n1  n2  0

1  n1  0)  (( t n2)  S L

2  n2  0) 

The operator adds an element to the result stream if it occurs in one of the two streams.
Because  is a multi-set operator we need to sum the multiplicities [8].

Join. A join operator combines two compatible elements from two  data streams. Two
solutions are compatible [5] if:

1 	 2 : v1  dom(1) v2  dom(2) : v1  v2  1(v1)  2(v2)

1(v1)  2(v2) does also apply in this work, if v1 in 1 and v2 in 2 are unbound.
Further let merge :  
    be a mapping corresponding to the merge function
from [5] defined as follows:

merge(1 2)  merge : 1 	 2

with dom(merge)  dom(1)  dom(2) 
(v  dom(1)
dom(2) : merge(v)  1(v)) 
(v  dom(2)
dom(1) : merge(v)  2(v)) 
(v  dom(1)  dom(2) : merge(v)  1(v)  2(v))

We can then define the join as follows.

Definition 10 (Join). The join of two logical  data streams is a function : L
L
 with:

 
 L

 

 (S L

1 S L

2) : (merge(1 2) t n1 	 n2)(1 t n1)  S L

1 

(2 t n2)  S L

2  1 	 2

Only elements that are valid at the same point in time can be joined to a new element.

4 A SPARQL predicate is a boolean expression, consisting of operators from section 11.3 in [5]

with boolean return values whose operands are variables or RDF terms.
?

?

?
Basic Graph Pattern Matching. This operator is defined in the SPARQL algebra, too,
although it is a join over two or more triple pattern matchings. To assure that blank
nodes are handled correctly, the included triple pattern matchings must use the same
RDF instance mapping.
Definition 11 (Basic Graph Pattern matching). Let p1 p2   be two triple patterns
and S L
RDF be two logical RDF data streams. A basic graph pattern
matching is the mapping  : L

RDF2  L

RDF1 S L

, defined as follows:

RDF  L

RDF 
 L
RDF2) :  (p1(S L

(S L

RDF1 S L

RDF1) p2(S L

RDF2))

with ext1  ext2.

Left Join. In [5] a left join is used to evaluate an OPTIONAL term of a SPARQL query.
We combine the left join directly with a filter predicate to preserve the correct OPTIONAL semantics. Unfortunately, the formal definition and its full description in [5]
are inconsistent. According to the full description the left join does not deliver a result
if there is no right element to potentially join with, so we use the following definition
of a left join as opposed to the definition in [5]:
Definition 12 (W3C LeftJoin). Let p  s be a SPARQL predicate. A left join w3c is
a mapping w3c:  
   , evaluated as follows:

w3c (1 2) : merge(1 2)1  2  2  2  1 	 2  p(merge(1 2))

 11  1  2  2 : 1 	 2  p(merge(1 2))

Based on this modified left join we give our definition of the stream based left join:
Definition 13 (LeftJoin). Let p  s be a SPARQL predicate. A left join  is a mapping
: L

, defined as follows:

 
 L
 (S L

 
 s  L
1 S L

2) : (merge(1 2) t n1 	 n2)(1 t n1)  S L

1 

(1 t n2)  S L
(1 t n1)(1 t n1)  S L
 p(merge(1 2))

2 : 1 	 2  p(merge(1 2)) 

1  (2 t n2)  S L

2 : 1 	 2

Other Operators. In addition to the described operators we also defined tolist, order
by, duplicate elimination, duplicate reduction, slice, projection, construct, describe and
ask.

5 Query Translation

We are now able to show how we can translate SPARQL queries over data streams into
logical algebra plans. Most transformation rules from [5] can be applied directly, using our new algebra operators. Only the definition of windows over the data streams
and the new triple pattern operator need special rules. The triple pattern matching operator transforms RDF statements into SPARQL solutions. Listing1.2 shows a simple
SPARQL query without data streams. The transformation of this query can be found in
Figure 1.

A. Bolles, M. Grawunder, and J. Jacobi

SELECT ?w ? x ? y ? z
FROM  h t t p :   s r c . n e t  g r a p h . r d f 
WHERE  ?w my:name ? x  UNION  ? y my:power ? z 

Listing 1.2. Query 1

Fig. 1. Query plan for Query 1

Fig. 2. Query plan for Query 2

As you can see, the triple patterns  	
	  and  	  are
both transformed to one triple pattern matching operator. By this, the RDF statements
are filtered from the source and transformed into SPARQL solutions. Afterwards, the
union and project operators can process the triple pattern matching results.

Window definitions in the FROM parts of a query are placed directly before the
corresponding triple pattern matching operator as demonstrated in Query 2 in Listing
1.3 and Figure 2.

SELECT ?w ? x ? y ? z
FROM STREAM  h t t p :   s r c . n e t  g r a p h . r d f  WINDOW RANGE 1000 SLIDE
WHERE  ?w my:name ? x  UNION  ? y my:power ? z 

Listing 1.3. Query 2

Fig. 3. Query plan for query 1.1
?

?

?
Algorithm 1. Method AlgebraOp createPlan(clause, actStream, namedStreams,
win, graphVar)

AlgebraOp retVal  null;
List subplans  new List();
if clause instanceof GroupGraphPattern then

win  clause.getWindow();
foreach Subclause sc: clause.getSubclauses() do

subplans.add(createPlan(sc, actStream, namedStreams, win, graphVar));

retVal  createJoinHierarchyOverAll(subplans);
setLeftJoinInHierarchyIfRightInputIsOptional(retVal);

else if clause instanceof TriplesBlock then

foreach Subclause sc: clause.getSubclauses() do

subplans.add(createPlan(sc, actStream, namedStreams, win, graphVar));

retVal  createJoinHierarchyOverAll(subplans);

else if clause instanceof GroupOrUnionGraphPattern then

foreach Subclause sc: clause.getSubclauses() do

subplans.add(createPlan(sc, actStream, namedStreams, win, graphVar));

retVal  createUnionHierarchyOverAll(subplans);

else if clause instanceof Filter then

retVal  new Filter(clause.getExpression());

else if clause instanceof GraphGraphPattern then

if (uri  clause.getGraphClause().getURI())  null then

retVal  createPlan(clause.getSubclause(), namedStreams.get(uri),
namedStreams, win, null);

else

foreach s : namedStreams do

subplans.add(createPlan(clause.getSubclause(), s, namedStreams, win,
clause.getGraphVar()));

retVal  createUnionHierarchyOverAll(subplans);

else if clause instanceof Triple then

TriplePatternMatching tpm  new TriplePatternMatching(clause, graphVar);
if win  null then

win  actStream.getWindow();
retVal  tpm.withInput(win.withInput(createAccessOp(actStream.getURI())));

else

retVal  win.withInput(tpm.withInput(createAccessOp(actStream.getURI())));

return retVal;

Our complete transformation algorithm can be found in Algorithm 1. The basic idea
of this algorithm is to recursively run through the query starting at the WHERE-clause
and create operators for the serveral query parts (e. g. a left join operator for an optional
graph pattern). With the parameter 
 it is possible to determine whether to put a
window operator of a FROM-part or of a basic graph pattern part of a query into the
queryplan.

Finally, we present the translation result of the query in Listing 1.1 in Figure 3 in our

logical algebra.

A. Bolles, M. Grawunder, and J. Jacobi

6 Physical SPARQL Data Stream Algebra

The logical algebra is used to define the operator semantics and allow some static plan
optimizations. A logical algebra cannot be used to execute queries. For this a physical
algebra with executable operators is needed. In line with [6] we apply an interval based
approach for the physical algebra.

The set of operators is divided into two groups. Stateless operators do not need any
information about the stream history or stream future. Each stream element can be processed directly. Operators of this group are triple pattern matching, filter, union, project,
construct and our time based window operators. The other group contains stateful oper-
ators. These operators need further information to process an element, e.g. a sort operator needs to know all elements before it can sort the set. Join, left join, basic graph pattern matching, duplicate eliminationreduction, orderBy, slice, ask and element based
windows are stateful operators. They need a special data structure to process their input.
As in [6] a so called sweep area is used as this data structure. It is an abstract datatype
with methods to insert, replace or query elements. We will not further describe this data
structure but refer to [6].

We will present our implementation of the sliding -window (Algorithm 2 ) first: A
sliding  window has a width w   and a step size    to move the window over the
data stream. In the following, x is used to either describe the set of RDF statements or
the set of SPARQL solutions; z is an instance of this set.

xin  P

Algorithm 2. Sliding  window
Input: S P
x  w      w
Output: S P
S P
xout  ;
foreach e:(z [tS  tE)) 	 S RDFin do

xout  P
x

etE :  tS
e  S P

RDFout;

  	   w;

If a new element occurs in the stream, it will be read out and its end timestamp will
  	   w. Afterwards, the element will be written into the output

be set according to  tS
stream of the operator.

As stated above, a triple pattern matching transforms filtered statements of an RDF
input stream to SPARQL solutions. This operator is stateless and can be implemented
as in Algorithm 3.

The algorithm gets a triple pattern and an extended RDF instance mapping ext as
input. If the subject, predicate and object of the triple pattern match the subject, predicate and object of an RDF stream element, a SPARQL solution is generated, where
variables of the triple pattern are mapped to the corresponding terms in the RDF stream
statement. The SPARQL solution is written to the  output stream.

We present our solution for the LeftJoin operator in Algorithm 4 and 5.
?

?

?
RDFin  P
out  P

  p  (x y z)   ext  

Algorithm 3. Triple Pattern Matching
Input: S P
Output: S P
S P
out  ;
SPARQL Solution  : new SPARQL Solution();
foreach e:((s p o) [tS  tE)) 	 S RDFin do
?

?

?
if (x  V  ext(x)  es)  (y  V  ext(y)  ep)  (z  V  ext(z)  eo)
then

if x  V then

.add(x,s);

if y  V then

.add(y,p);

if z  V then

.add(z,o);

  S P

out;

Algorithm 4. LeftJoin
Input: S P
Output: S P
Let S P
foreach e : ( [tS  tE)) 	 S P

in1 be the left and S P

in1 S P
out  P

in2  P
?

?

?
if j  1 then

*Input from left input stream
doLeft(this);

else

*Input from right input stream
doRight(this);

mintS  min(tS ( [tS  tE))  S A1);
if mintS  null then
while H   do

  SweepAreas S A1 S A2 Min-Heap H p  s

in2 the right input stream;

in j j  1 2 do

top : (  [ tS   tE ))  top element of H;
if top. tS  mintS then

top  S P
Remove top from H;

out;

else

break;

*

*

7 Related Work

This work is based on the W3C Recommendation SPARQL [5], especially on the defined algebra and grammar. Also, possibilities for the serialization of RDF statements
in data streams have been described. Our work is based on [6]. In that work a schema
independent algebra for stream processing has been introduced. Because of some differences between the relational model and the RDF graph model, this algebra could not
completely be reused for RDF stream processing. But some ideas like the time instant
based approach for logical algebra operators and the interval based approach for physical
algebra operators oer advantages for the definition of algebra operators in this work.

A. Bolles, M. Grawunder, and J. Jacobi

Algorithm 5. doLeft(LeftJoin op) and doRight(LeftJoin op) of a LeftJoin
doLeft(LeftJoin op);
S A2.purgeElements(e);
e tE  etS ;
Iterator qualifies  S A2.query(e);
while qualifies.hasNext() do

e : ( [tS  tE ))  qualifies.next();
if e 	 e  p(merge( )) then

emerge : (merge( ) intersection([tS  tE) [tS  tE ));
if emergetS  e tE then

Insert ( [e tE  emergetS )) into H;

else

Insert emerge into H;
e tE  emergetE;

intersect : intersection([tS  tE ) [tS  tE ));
if intersect.tS  e tE then

Insert ( [e tE  intersecttS )) into H;
e tE  intersect.tS ;

S A1.insert(e);
doRight(LeftJoin op);
Iterator invalids  S A1.extractElements(e);
while invalids.hasNext() do

 e : invalids.next();
if  e tE   etE then

Insert ( e [ e tE   etE )) into H;

Iterator qualifies  S A1.query(e);
while qualifies.hasNext() do

e : ( [tS  tE ))  qualifies.next();
if e 	 e  p(merge( )) then

emerge : (merge( ) intersection([tS  tE) [tS  tE ));
if emergetS  e tE then

Insert ( [e tE  emergetS )) into H;

else

Insert emerge into H;
e tE  emergetE;

intersect  intersection([tS  tE) [tS  tE ));
if intersect.tS  e tE then

Insert ( [e tE  intersecttS )) into H;
e tE : intersecttS ;

S A2.insert(e);

Another approach for the expression of the validity of data stream elements is the
positive-negative tuple approach introduced in [10]. This approach allows for using so
called negative tuples, that mark the end of their positive counterparts. But this approach
has the disadvantage that at least twice the elements have to be processed in comparison
to the interval based approach of [6] and that all algebra operators have to distinguish
between dierent types of elements.

There are other approaches like [11,12] which also introduce stream processing lan-
guages. But the continuous query language CQL [11] uses the relational model in defining operators that transform a stream into a relation and vice versa. This is not useful
for SPARQL stream processing because of the dierences between the RDF and the relational models. It is the same with the extended XQuery language [12]. This language
provides many constructs for handling XML data. Indeed RDF can be serialized as
XML, but the extended XQuery constructs do not handle the RDF semantics correctly.
So a real RDF query language has to be extended for stream processing.
?

?

?
Extending SPARQL for stream processing window operators had to be integrated
into the SPARQL language. These operators have been introduced earlier (see [11, 12,
13, 14, 15]). Ideas for windows have been taken from these works, but also in this case
the interval based approach in [6] oer advantages in implementing the corresponding
physical algebra operators. So time based windows can be realized by calculating the
end of a validity interval and tuple based windows can be realized by using a sweep
area and setting the end of an earlier element to the start of a later element (see [6]).

8 Conclusions and Outlook

In this work we presented an extension to SPARQL to cope with window queries over
data streams. We extended the SPARQL language to allow the definition of time and
count based windows over data streams. We implemented the extended SPARQL processing in our O	 system, which is an enhancement of our DynaQuest [16] framework with the ability to process data streams. For the translation of SPARQL we used
the ARQ project5 and slightly extended their query translation process. We added to
this base our own query translation and execution framework and extended it with the
described logical and physical algebra operators. We showed that query processing over
RDF streams is possible. We now need to determine if this format is applicable for wind
park monitoring. We will do this in the context of the Alpha Ventus6 project, which creates an oshore test platform in the North Sea. Another application for our approach
might be in the context of mobile information systems as they are developed in the
C3World7 research group.

There are multiple possible extensions for this work. Predicate based windows [17]
define the boundaries using predicates over the stream content. We have already developed initial approaches but further research is necessary. Additionally, we are currently
extending SPARQL to support group by clauses and aggregation, which are necessary in
monitoring applications. Also alternatives to using windows like the positive-negative
tuple approach [10] will be evaluated in future work.
