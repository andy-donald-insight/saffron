Web Semantics: Science, Services and Agents

on the World Wide Web 2 (2004) 109130

A subscribable peer-to-peer RDF repository for distributed

metadata management


Min Cai

, Martin Frank, Baoshi Yan, Robert MacGregor

USC/Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA 90292, USA

Received 25 May 2004; received in revised form 14 August 2004; accepted 8 October 2004

Abstract

In this paper, we present a scalable peer-to-peer RDF repository, named RDFPeers, which stores each triple in a multiattribute addressable network by applying globally known hash functions. Queries can be efficiently routed to the nodes that
store matching triples. RDFPeers also enables users to selectively subscribe to RDF content. In RDFPeers, both the neighbors
per node and the routing hops for triple insertion, most query resolution and triple subscription are logarithmic to the network
size. Our experiments with real-world RDF data demonstrated that the triple-storing load among nodes differs by less than an
order of magnitude.
 2004 Elsevier B.V. All rights reserved.

Keywords: Semantic web; Peer-to-peer; Distributed RDF repositories; Distributed metadata management

1. Introduction

Metadata is the foundation for the semantic web, and
is also critical for Grid [13,40] and Peer-to-Peer (P2P)
systems [28]. RDF [1] metadata makes flexible statements about resources that are uniquely identified by
URIs. RDF statements are machine-processable, and
statements about the same resource can be distributed
on the Web and made by different users. RDF schemata
[2] are extensible and evolvable over time by using a


Corresponding author.
E-mail addresses: mcai@isi.edu (M. Cai), frank@isi.edu

(M. Frank), baoshi@isi.edu (B. Yan), macgregor@isi.edu
(R. MacGregor).

new base URI every time the schema is revised. The
possibility to distribute RDF statements provides great
flexibility for annotating resources.

However, distributed RDF documents on the Web
are hard to discover. Putting an RDF document on a
Web site does not mean that others can find it, much
less issue structured queries against it. One approach is
to crawl all possible Web pages and index all RDF documents in centralized search engines, RDF Google if
you wish, but this approach makes it difficult to keep the
indexed metadata up to date. For example, it currently
takes Google many days to index a newly created Web
page. Further, this approach has a large infrastructure
footprint for the organization providing the querying
service, and is a centralized approach on top of tech-

1570-8268/$  see front matter  2004 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2004.10.003

M. Cai et al. / Web Semantics: Science, Services and Agents on the World Wide Web 2 (2004) 109130

nologies (RDF, the Internet itself) that were intentionally designed for decentralized operation.

Also centralized RDF repositories are not well
suited for some semantic web applications in which
data is not owned by any participant and each participant is responsible for supporting the community.
When the community scales up, the data and query
load will be so large that no participant will be able
to afford the hosting cost. One example of such application is SciencePeers, a design for maintaining
shared views of scientific fields in which the participants are peers both in the scientific sense (peer re-
view) and in the technical sense (peer-to-peer tech-
nology). In this design, each member takes responsibility for a proportional fraction of the disk storage,
bandwidth, and computing cycles to support the com-
munity. Another example is Shared-HiKE, a collaborative hierarchical knowledge editor that lets users cre-
ate, organize, and share RDF data. In Shared-HiKE,
each participant has her local hierarchical knowledge
and also shares the external knowledge from other
participants.

Moreover, participants in the community want to
quickly be notified of specific new content, that is, they
have persistent queries expressing interest in certain
people, products, or topics that are constantly serviced.
For example, in addition to publishing and querying
the shared views, each participant in SciencePeers can
also subscribe to scientific topics of interest. In centralized RDF repositories without subscription support,
this could only be accomplished by constantly issuing
the queries of interest every few minutes, which will
generate much unnecessary query load on the server.
Also, it is difficult for centralized subscription schemes
to scale up to a large number of subscribers. Thus,
we argue that a distributed RDF infrastructure that can
scale to Internet size and support RDF metadata subscription is necessary for many semantic web applica-
tions, such as SciencePeers and Shared-HiKE.

One choice for non-centralized RDF repositories is
Edutella [28] that provides an RDF-based metadata infrastructure for P2P applications. It uses a Gnutella-like
[34] unstructured P2P network that has no centralized
index or predictable location for RDF triples. Instead,
RDF queries are flooded to the whole network and
each node processes every query. Measurement studies
[37,39] show that Gnutella-like unstructured P2P networks do not scale well to a large number of nodes.

This is because their flooding mechanism generates
a large amount of unnecessary traffic and processing
overhead on each node, unless a hop-count limit is set
for queriesbut then the queries cannot guarantee to
find results, even if these results exist in the network.
An Edutella successor [29] provides better scalability
by introducing super-peers and schema-based routing;
however, it requires up-front definition of schemas and
designation of super peers.

This paper presents a scalable P2P RDF repository
named RDFPeers that allows each node to store, query,
and subscribe to RDF statements. The nodes in RDFPeers self-organize into a cooperative structured P2P
network based on randomly chosen node identifiers.
When an RDF triple is inserted into the network, it
will be stored at three places by applying a globallyknown hash function to its subject, predicate, and object values. Both exact-match and range queries can be
efficiently routed to those nodes where the matching
triples are known to be stored if they exist. The subscriptions for RDF statements are also routed to and
stored on those nodes. Therefore, the subscribers will
be notified when matching triples are inserted into the
network. We implemented a prototype of RDFPeers
in Java and evaluated its preliminary performance and
scalability in a 16-nodes cluster. We also measured the
load balancing of real-world RDF data from the Open
Directory Project by inserting it into a simulated RDFPeers network, and found that the load balances to less
than an order of magnitude between the nodes when
using a certain successor probing technique.

2. RDFPeers architecture

Our distributed RDF repository consists of many
individual nodes called RDFPeers that self-organize
into a multi-attribute addressable network (MAAN)
[8]. MAAN extends Chord [41] to efficiently answer
multi-attribute and range queries. However, MAAN
only supported predetermined attribute schemata with a
fixed number of attributes. RDFPeers exploits MAAN
as the underlying network layer and extends it with
RDF-specific storage, retrieval, subscription, and load
balancing techniques. Fig. 1 shows the architecture
of RDFPeers. Each node in RDFPeers consists of six
components: MAAN network layer, RDF triple loader,
RDF subscriber API, local RDF triple and subscription

Fig. 1. The architecture of RDFPeers.

storage, native query resolver and RDQL-to-native-
query translator.

The underlying MAAN protocol contains four
classes of messages for (a) topology maintenance, (b)
storage, (c) query, and (d) subscription. The topology
maintenance messages are used for keeping the correct
neighbor pointers and routing tables. It includes JOIN,
KEEPALIVE, and other Chord stabilizing messages.
The STORE message inserts triples into the network
and the REMOVE message deletes the triples from the
network. The QUERY message visits the nodes where
the triples in question are known to be stored, and returns the matched triples to the requesting node. The
RDF triple loader reads an RDF document, parses it
into RDF triples, and uses MAANs STORE message
to store the triples into the RDFPeers network. When
an RDFPeer receives a STORE message, it stores the
triples into its local RDF triple/subscription storage
component such as a file or a relational database. The
native query resolver parses native RDFPeers queries
and uses MAANs QUERY message to resolve them.
There can be a multitude of higher-level query modules
on top of the native query resolver that map higher-level
user queries into RDFPeers native queries, such as
an RDQL to native query translator. Applications built
on top of RDFPeers can also subscribe to RDF triples
by calling the RDF subscriber API with a subscription
handler. The RDFPeers node then sends a SUBSCRIBE
message to the nodes that are responsible for storing
matching triples. When the RDF triples that match the

subscription are inserted into the network, the subscribing node will receive a NOTIFY message and notify the
application to handle the triples with the subscription
handler.

3. MAAN overview

MAAN [8] uses the same one-dimensional modulo2m circular identifier space as Chord, where m is the
number of bits in node identifiers and attribute hash
values. Every node in MAAN is assigned a unique m-
bit identifier, called the node ID, and all nodes selforganize into a ring topology based on their node IDs.
The node ID can be chosen locally, for example by applying a hash function to the nodes IP address and port
number. In MAAN, bundles of related attributevalue
pairs such as name: John, age: 27 are called re-
sources, a term we will avoid in this paper because of
its different meanings in RDF. Note that for RDFPeers
use of MAAN, a bundle of related attributevalue
pairs is always synonymous with an RDF triple.

Unlike Chord in which these bundles can only be
stored and looked up by one unique key, they can be
stored and looked up by any attribute value in MAAN.
Chord uses SHAl hashing [27] to assign each key a
unique m-bit identifier. MAAN uses the same hashing for string-valued attributes. However, for numeric
attributes MAAN uses locality preserving hash functions to assign each attribute value an identifier in the

M. Cai et al. / Web Semantics: Science, Services and Agents on the World Wide Web 2 (2004) 109130

Fig. 2. A 4-bit Chord network consisting of 8 nodes and 4 keys.

m-bit space. Here, we refer to the hashing image of
the key in Chord as well as to the hashing image of
the attribute value in MAAN as the key that is an
identifier in the circular m-bit space. Suppose we have
an attribute a with numeric values v [vmin, vmax]. In
RDFPeers, the only attributes that can have numeric
values are the objects, given that subjects and predicates are always non-numeric URIs in RDF. A simplistic locality preserving hash function we could use
is H(v) = (v vmin) (2m  1)/(vmax  vmin), where
v [vmin, vmax].

In Chord, key k is assigned to the first node whose
identifier is equal to or follows k in the identifier circle.
This node is called the successor node of key k, denoted by successor(k). Fig. 2 shows an 8-node Chord
network with 4-bit circular identifier space. Node N5
has the node ID of 5 and stores the key 3 and key 4.
Similar to Chord, each node in MAAN maintains two
sets of neighbors, the successor list and the finger table.
The nodes in the successor list immediately follow the
node in the identifier space, while the nodes in the finger table are spaced exponentially around the identifier

space. The finger table has at most m entries. The ith entry in the table for the node with ID n contains the identity of the first node s that succeeds n by at least 2i1 on
the identifier circle, i.e., s = successor(n + 2i1), where
1 i m and all arithmetic is modulo 2m . The finger
table contains more close nodes than far nodes at doubling distance. Thus, each node only needs to maintain
the state for O(log N) neighbors for a network with N
nodes. For example, the fingers of N6 in Fig. 2 are N10
and N14. MAAN uses Chords successor routing algorithm to forward a request of key k to its successor
node. If a node n receives a request with key k, the node
searches its successor list for the successor of k and forwards the request to it if possible. If it does not know
the successor of k, it forwards the request to the node
j whose identifier most immediately precedes k in its
finger table. By repeating this process, the request gets
closer and closer to the successor of k. For example,
if N14 in Fig. 2 issues a lookup request for Key11, it
sends the request to its finger N6 that is the closest one
to Key11 in the identifier space. N6 then forwards the
request to N10 that will forward it to N12. Since N12 is

the successor node of Key11, it looks up the resource
corresponding to Key11 locally and returns the result
to N14. Since the fingers on each node are spaced exponentially around the identifier space, each hop from
node n to the next node covers at least half the identifier
space (clockwise) between n and k. The average number of hops for this routing is O(log N) for a network
with N nodes.

MAAN stores each bundle of attributevalue pairs
on the successor nodes of the keys for all its attribute
values. Suppose each bundle has M pairs ai, vi and
Hi(v) is the hash function for attribute ai (Note that
M is always 3 in RDFPeers, a1 is always subject, a2
is always predicate, and a3 is always object). Each
bundle of attributevalue pairs will be stored at node
ni = successor(H(vi)) for each attribute value vi, where
1 i M. A STORE message for attribute value vi is
routed to its successor node using the above successor routing algorithm. M nodes store the same bundle
consisting of M attributevalue pairs, each by keying
on a different attribute. Thus, the routing hops for storing a bundle of attributevalue pairs is O(M log N) for
bundles with M attributes.

Since numeric attribute values in MAAN are
mapped to the m-bit identifier space using locality preserving hash function H, numerically close values for
the same attribute are stored on nearby nodes. Given a
range query [l, u], where l and u are the lower bound
and upper bound, respectively, nodes that contain attribute value v [l, u] must have an identifier equal to
or larger than successor(H(l)) and equal to or less than
successor(H(u)).
Suppose node n wants to search for bundles with attribute value v [l, u] for attribute a. Node n composes
a QUERY message and uses the successor routing algorithm to route it to node nl, the successor of H(l).
The query message has parameters k, a, R, and X. k is
the key used for successor routing, initially k = H(l). a
is the name of the attribute we are interested in, R is
the desired query range [l, u] and X is the list of bundles of attributevalue pairs discovered in the range.
Initially, X is empty. When node nl receives the query
message, it searches its local sets and appends those
sets that satisfy the range query for attribute a to X in
the message. Then it checks whether it is the successor
of H(u) also. If true, it sends back the query result in
X to the requesting node n. Otherwise, it forwards the
query message to its immediate successor ni. Node ni

repeats this process until the message reaches node nu,
the successor of H(u). Thus, routing the query message
to node nl via successor routing takes O(log N) hops for
N nodes. The next sequential forwarding from nl to nu
takes O(K), where K is the number of nodes between nl
and nu. So, there are total O(log N + K) routing hops to
resolve a range query for one attribute. Given that the
nodes are uniformly distributed in the m-bit identifier
space, K is N s, where s is the selectivity of the range
query and s = (l u)/(vmax  vmin).

MAAN supports multi-attribute and range queries
using a single-attribute-dominated query resolution ap-
proach. Suppose X are the bundles of attributevalue
pairs satisfying all sub-queries, and Xi are the bundles satisfying the sub-query on attribute ai, where
1 i M. So we have X =Xi and each Xi is a superset of X. This query resolution approach first computes
a Xk that satisfies one sub-query on attribute ak. Then
it applies the sub-queries for other attributes on these
candidate bundles and computes the intersection X that
satisfies all sub-queries. Here, we call attribute ak the
dominant attribute. In order to reduce the number of
the candidate sets that do not satisfy other sub-queries,
we carry all other sub-queries in the QUERY message,
and use them to filter out the unqualified bundles of
attributevalue pairs locally at the nodes visited. Since
this approach only needs to do one iteration around the
Chord identifier space for the dominant attribute ak,
it takes O(log N + N sk) routing hops to resolve the
query, where sk is the selectivity of the sub-query on
attribute ak. We can further minimize the routing hops
by choosing the attribute with minimum selectivity as
the dominant attribute, presuming, of course, that the
selectivity is known in advance; in that case, the routing
hops will be O(log N + N smin), where smin is the minimum range selectivity for all attributes in the query.

Although the simplistic locality preserving hash
function above keeps the locality of attribute values
it does not necessarily produce uniform distributions
of hashing values if the distribution of attribute values is not uniform. Consequently, the load balancing
of resource entries can be poor across the nodes. To
address this problem, we proposed a uniform locality preserving hashing function in MAAN that always
produces uniform distribution of hashing values if the
distribution function of input attribute values is continuous and if the distribution is known in advance.
The former condition is satisfied for many common

M. Cai et al. / Web Semantics: Science, Services and Agents on the World Wide Web 2 (2004) 109130

a string, we apply the SHA1 hash function to mapping
the subject value and predicate value to the m-bit identifier space in MAAN. However, the values of attribute
object can be URIs, plain literals or typed literals.
Both URIs and plain literals are strings and we apply
SHA1 hashing on them. The typed literal can be either
string types or numeric types, such as an enumeration
type or a positive integer, respectively. As discussed
above, we apply SHA1 hashing on string-typed literals and locality preserving hashing on numeric literals.
For example, to store the first triple above by subject,
RDFPeers would send the following message in which
the first attributevalue pair (subject, info:rdfpeers)
is the routing key pair, and key is the SHA1 hash value
of the subject value.

This triple will be stored at the node that is the successor node of key. Fig. 3 shows how the three triples
above are stored into an example RDFPeers network.
It also shows the finger tables of example nodes N6 and
N14 for illustration.

Most semantic web applications prefer high availability to strong consistency in the face of network
partitions. RDFPeers provides relaxed consistency by
leveraging soft state updates [7,12]. Each triple has
an expiration time, and the node that inserts the triple
needs to renew the triple before it expires. If the nodes
that store the triple do not receive any renewals, the
triple will be removed from their local storage. With
soft state updates, RDFPeers provides best effort consistency for triples indexed at three places.

To apply locality-preserving hashing on numeric
literals of RDF triples, we need to know their minimal and maximal values. We can leverage the datatype
information of the predicates provided by the RDF
schema definition. For example, the following schema
defines that the object values of triples whose predicate
is <foaf:age> are instances of <info:AgeType>.

distributions, such as Gaussian, Pareto, and Exponential distributions. Suppose attribute value v conforms
to a certain distribution with continuous and monotonically increasing distribution function D(v) and possibility function P(v) = dD(v)/dv and v [vmin, vmax]. We
can design a uniform locality preserving hashing function H(v) as follows: H(v) = D(v) (2m  1). This load
balance mechanism assumes that we know the distribution functions of attribute values in advance. However,
this prerequisite is not always true for many semantic
web applications. Section 8.5 discusses our approach
to dynamically balance load among nodes by probing
the load on multiple successors when new nodes join.

4. Storing RDF triples

RDF documents are composed of a set of RDF
triples. Each triple is in the form of subject, predi-
cate, object. The subject is the resource about which
the statement was made. The predicate is a resource
representing the specific property in the statement. The
object is the property value of the predicate in the state-
ment. The object is either a resource or a literal; a resource is identified by a URI; literals are either plain
or typed and have the lexical form of a unicode string.
Plain literals have a lexical form and optionally a language tag, while typed literals have a lexical form and a
datatype URI. The following triples show three different types of objects, resource, plain literal, and typed
literal, respectively.

In order to support efficient queries on distributed
RDF triples, we exploit the overlay structure of MAAN
to build a distributed index for these triples. In the
STORE message one of the three attribute values is designated as the destination of the routing, and we store
each triple three times, once each based on its sub-
ject, predicate, and object. Each triple will be stored at
the successor node of the hash key of the value of the
routing key attributevalue pair. Since the value of attribute subject and predicate must be a URI that is

Fig. 3. Storing three triples into an RDFPeers network of 8 nodes in an example 4-bit identifier space that could hold up to 16 nodes (in reality
a much larger identifier space is used, such as 128 bits).

Thus, the numeric literals have the minimal value 0
and maximal value 250 as defined by the XML schema
of <info:AgeType>. However, this approach assumes
that the datatypes of predicates are fixed and will not
change in the future. We solve this problem by only
allowing a schema to involve to a new version with
a different namespace rather than change the old ver-
sion; and applications are responsible for updating the
RDF statements with new schemas, which is always
necessary because of our soft state scheme.

Since nodes might fail and network connections
might break, triples stored on their corresponding successor nodes are replicated on their neighbors in the
Chord network. This can be done by setting the parameter Replica Factor in MAAN. Whenever a node
receives a triple storing request, it will not only store
the triple locally but also store it to as many of its immediate successors as the above parameter dictates. If

any node fails or its connection breaks, its immediate
successor and predecessor will detect it by checking
the KEEPALIVE messages. If the node does not come
back to life after a time-out period, nodes will repair the
ring structure using the Chord stabilization algorithm.
After stabilization, the immediate successor node of
the failed node will restore its replicas to its new pre-
decessor.

5. Native queries in RDFPeers

Based on the above triple-storing scheme, we define
a set of native queries that can be efficiently resolved
via MAANs multi-attribute range queries. These native queries include atomic triple queries, disjunctive and range queries, and conjunctive multi-predicate
queries.

M. Cai et al. / Web Semantics: Science, Services and Agents on the World Wide Web 2 (2004) 109130

Table 1
The eight possible atomic triple queries for exact matches

No.

Q1
Q2
Q3
Q4
Q5
Q6
Q7
Q8

Query pattern

(?s, ?p, ?o)
(?s, ?p, oi)
(?s, pi, ?o)
(?s, pi, oi)
(si, ?p, ?o)
(si, ?p, oi)
(si, pi, ?o)
(si, pi, oi)

Cost

O(N)
log N
log N
log N
log N
log N
log N
log N

Query semantics

Find all possible triples.
Given object oi of any predicate, find the subjects and predicates of matching triples.
Given predicate pi, find the subjects and objects of the triples having this predicate.
Given object oi of predicate pi, find the subjects of matching triples.
Given subject si, find all predicates and objects of the resource identified by si.
Given subject si, find its predicate that has object oi.
Given subject si, find its object of predicate pi.
Return this triple if it exists otherwise return nothing.

The cost is measured in the number of routing hops needed to resolve each query.

5.1. Atomic triple queries

An atomic query query is a triple pattern in which
the subject, predicate, or object can each either be a
variable or an exact value. The eight resulting possible
queries are shown in Table 1.

Q1 is the most general and most expensive query
that matches all triples. Since there is no restriction
whatsoever on this triple pattern, we have to propagate
this query to all nodes, which takes O(N) routing hops
for a network with N nodes.

We can use MAANs routing algorithm to resolve
queries Q2 through Q8 since we store each triple
three times based on its subject, predicate, and object hash values. In these seven query patterns, there
is always at least one value that is a constant, and
we resolve the query by routing it to the node responsible for storing that constant, that node then
matches these triples against the pattern locally and
returns them to the requesting node.1 For example, in
Fig. 3 if node N6 asks the native query (<info:mincai>,
<foaf:name>, ?name), we hash on info:mincai and
get the hash value 1. Then N6 routes it to the corresponding node N1 (via N14). N1 filters triples locally using this pattern, and sends back the matched
triple <info:mincai>, <foaf:name>, Min Cai to N6
(via N5).

5.2. Disjunctive and range queries

RDFPeers native queries support constraints on
variables in the triple patterns. Q9 extends the above

1 Note that we assume that the value is not overly popular, in

which case we would have to use O(n) messages, see Section 8.4.

atomic triple queries with a constraint list that limits
the domain of variables.

Variables can be either string-valued or numeric.
Constraints can limit the domain of string values by
enumerating a set of either allowed or forbidden con-
stants. Numeric variables can additionally be limited
to a set of disjunctive ranges.

As discussed in Section 3, MAAN can efficiently
resolve range queries by using locality-preserving
hashing.2 In addition to specifying a single range, Q9
can also specify a set of disjunctive ranges for attribute
values. For example, a user can submit a range query for
variable ?x and ?xd
i=1[li, ui]. Obviously, this kind of
disjunctive range query could simply be resolved by issuing one query for each contiguous range and by then
computing the union of the results. For a query with
d disjunctive ranges, this takes d O(log N + N s),
where s is the aggregate selectivity of the d ranges. So
the number of hops in the worst case increases linearly
with d and is not bounded by N. We can optimize this by

2 Note that this is the one case where RDFPeers would benefit
from up-front RDF Schema information: if say an integer-valued
object of some triples in reality only ever has values 110, RDFPeers
can use a hash function that yields better load balancing for these
triples.

using a range-ordering algorithm that sorts these disjunctive query ranges in ascending order. Given a list of
disjunctive ranges in ascending order, [li, ui], 1 i d
where li  lj and ui  uj, if i j, the query request will
be first routed to node nl1, the successor node of H(l1)
that is the key corresponding to the lower bound of
the first range. Node nl1 then sequentially forwards the
query to the successor node of the upper bound H(u1)
if it itself is not the successor node of H(u1). Then
node nu1 uses successor routing to forward the query
to node nl2, the successor node corresponding to the
lower bound of the next range [l2, u2], which in turn
forwards the query to the successor node of H(u2). This
process will be repeated until the query reaches the
successor node of H(ud). This optimized algorithm exploits the locality of numeric MAAN data on the Chord
ring and the ascending order of the ranges, reduces the
number of routing hops, especially for cases where d
is large, and bounds the routing hops to N. Disjunctive
exact-match queries such as ?c {Tom, John} present
a special case of the above disjunctive range queries
where both the lower bound and upper bound of the
range are equal to the exact-match value, and we use
the same algorithm to resolve them.

5.3. Conjunctive multi-predicate queries

In addition to atomic triple queries and disjunctive
range queries, RDFPeers handles conjunctive multipredicate queries that describe a non-leaf node in the
RDF graph by specifying a list of edges for this node.
They are expressed as a conjunction of atomic triple
queries or disjunctive range queries for the same subject
variable. Q10 consists of a conjunction of sub-queries
where all subject variables must be the same.

In Q10, we restrict the sub-query Q9 to be the Q3style triple pattern with constraints on the object vari-
able. Thus, Q10 describes a subject variable with a
list of restricting predicate, object or predicate, objectrange pairs.

To efficiently resolve these conjunctive multipredicate queries, we use a recursive query resolu-

tion algorithm that searches candidate subjects on each
predicate recursively and intersects the candidate subjects inside the network, before returning the query results to the query originator. The query request takes
the parameters q, R, C, and I, where q is the currently
active sub-query, R is a list of remaining sub-queries,
C is a set of candidate subjects matching current active
sub-query, and I is a set of intersected subjects matching all resolved sub-queries. Initially, q is the first subquery in this multi-predicate query, R contains all subqueries except q, C is empty and I is the whole set. Suppose the sub-query q for predicate pi is vli  oi  vui,
where vli and vui are the lower bound and upper bound
of the query range for the object variable oi, respec-
tively. When node n wants to issue a query request, it
first routes the request to node nli = successor(H(vli)).
The node nli receives the request, searches its local
triples corresponding to predicate pi, appends the subjects matching sub-query q to C, forwards this request
to its immediate successor nsi unless it is already the
successor(H(vui)). Node nsi repeats this process until
the query request reaches node nui = successor(H(vui)).
When node nui receives the request, it also searches
locally for the subjects matching sub-query q and appends them to C. It then intersects set I with set C, and
pops the first sub-query in R to q. If R or I is empty,
it sends the query response back with the subjects in I
as the result; otherwise, it resolves sub-query q. This
process will be repeated until no sub-queries remain or
I is empty.

algorithm
routing hops

recursive
i=1(log N + N  si)

takes
in the

worst case, where k is the number of sub-queries
and si is the selectivity of the sub-query on predicate pi. However, it intersects the query results on
different predicates in the network and will terminate
the query process before resolving the query on
all predicates if there are no matches left,
i.e., I
is empty. Thus, we can further reduce the average
number of expected routing hops by sorting the
sub-queries in ascending order of selectivity presuming the selectivity can be estimated in advance.
For example, in the above three-predicate query, the
sub-query on rdf:type might match many subjects,
while foaf:age matches far fewer and foaf:name
matches only a handful. After sorting the sub-queries,
we resolve foaf:name first, then rdf:age, and finally
rdf:type.

This

M. Cai et al. / Web Semantics: Science, Services and Agents on the World Wide Web 2 (2004) 109130

6. Resolving RDQL queries

RDQL [26] is a query language for RDF proposed
by the developers of the popular Jena Java RDF toolkit
[24]. RDQL operates at the RDF triple level, without
taking RDF schema information into account (like
RQL [22] does) and without providing inferencing ca-
pabilities. As such, it is the type of low-level RDF query
language that we want RDFPeers to support well. It is
our intuition that it is possible to translate all RDQL
queries into combinations of the native RDFPeers
queries above; however, we have not yet written such
a translator and it may be inefficient for some queries,
especially for joins. This section informally describes
how the example RDQL queries from the Jena tutorial
(http://www.hpl.hp.com/semweb/doc/tutorial/RDQL)
would be resolved.

Query (1) translates directly into Q4, so that it
can be resolved in log N routing hops in a network
of N nodes. Similarly, query (2) translates directly
into Q3, taking log N hops. To resolve query (3), we
first issue a Q4-style query and then use its query result as constraint to issue a Q9-style disjunctive query
with Q3-style triple patterns. Since all the predicate
values in the two triple patterns are known, these
two native queries can be resolved in 2 log N hops.
Query (4) is a typical Q9-style range query with the
constraint on the object value. Since its predicate
value is known, we can route the query to the node
that stores the triples with predicate inf:age in log N
hops.

Our native queries do not include join operations,
so that we decompose join queries into multiple native
queries. Query (5) can be resolved via two Q3-style
queries, and by then joining the first triple sets object with the second triples subject, 2 log N routing
hops. (However, note that these two Q3-style queries
might generate large-size messages if the predicates
vcard:N or vcard:Given are popular.) Query (6) can be
resolved by first issuing the same query as for the previous RDQL example for the first triple pattern. Then
we use the query result as a constraint for variable ?re-
source and resolve the second triple pattern as a Q9style disjunctive range query. Finally, we use the second
query result as a constraint for variable ?y and again resolve the third triple as a Q9-style query, which in the
aggregate takes 3 log N hops.

7. RDF subscription and notification

7.1. Subscribing to atomic queries

RDFPeers also already implements subscriptions
for atomic queries in which at least one of the triples
values is restricted to a constant. Our basic scheme for
subscriptions to these queries is that the subscription
request is routed to the same node that is responsible
for storing the triple with that value in that position.
Thus, the subscription request for (?person, ?predicate,
Min Cai) would be routed to node N10 in the example of Fig. 3. If there are multiple constants in the triple
pattern, absent a-priori knowledge of the frequency dis-
tribution, we heuristically bias to first use the subject,
then the object, then the predicate to route subscrip-
tions, based on our experience for which positions are
most likely to have overly popular values (see Section 8.4). Thus, the subscription request for (?person,
<foaf:age>, 28) would be routed to node N2 in our
running example.

Each node keeps a local list of subscriptions, which
consist of (1) a triple pattern, (2) a requested notification frequency, (3) the requested expiration date
of the subscription, and (4) the node identifier of the
subscriber. Each node internally maintains hash-based
access into this subscription list where the key is a
positionconstant pair. When a node stores or removes
a triple, it will also locally evaluate the matching subscription queries and (immediately or after collecting

several such matches) notify the subscribing node of the
matched triples. How often such notification messages
are sent is dictated by the larger duration of (a) the
requested notification frequency, and (b) a minimum
interval between updates that the subscription-hosting
node may impose. Given that we want both data and
subscriptions to survive the sudden death of any node,
we replicate the subscription list to the next replication
factor nodes in the identifier space, just as we do for
the triples themselves. The repair protocol for subscription data is identical to the repair protocol for triple data
described in Section 4. Conversely, it is possible that
subscriptions persist after the subscribing node has quit
the network. We deal with this issue via a maximum
subscription duration parameter. Each node will periodically purge its subscriptions list from older entries,
unless a subscribing node reissued the subscription request more recently, in which case it will reset the age
of the subscription to the latest request date.

7.2. Subscribing to disjunctive and range queries

In disjunctive and range queries, the object is restricted to be within one or more disjunctive enumeration domains or numeric ranges. The basic subscription
scheme for disjunctive and range queries is similar to
the one for constant queries, but the subscription request is stored by all nodes that fall within the hashed
identifiers of the minimum and maximum range value.
The routing of the subscription request is identical to
that for range queries described in Section 5.2, taking
O(log N + N s) routing hops, where s is the selectivity of the range query. For performance reasons, largeselectivity range query subscriptions are undesirable
because a large number of matches would be sent. In
practice, a query for common integer values, independent of a target predicate such as (a) likely, makes little
sense. However, subscriptions for a narrow date range
as in (b) or historical date ranges (the 12th century)
independent of predicate seems to be of practical value.

node in the series of nodes that would add it to its
subscription listcompute the estimated number of
nodes that would be involved (selectivity in percentage of the identifier space times estimated number of
participating nodes, the latter estimated from the size
of the nodes finger table), and reject it if it exceeds
that threshold. This technique would not prevent a node
from inserting a range request that did not exceed the
threshold at insertion time but does exceed it later because of network growth, but it would prevent the subscription from being re-inserted as-is into the larger network once the original subscription expires. At present,
we have not implemented such a rejection mechanism
for overly broad range subscriptions.

7.3. Subscribing to conjunctive multi-predicate
queries

These conjunctive multi-predicate queries look for
subjects that match multiple constant (or constant
range) predicateobject pairs. We have not implemented these subscriptions at time of writing. A possible scheme could initially route the subscription to the
node corresponding to the first clause, which would remove and store just this first clause, and would also
store the hash value of the next clause (not the identifier of the node that it currently maps to, given that
the clause will move as nodes appear and disappear).
Another node will then store the next clause, and route
the remaining clauses towards the hash value of the
next closest clause, and so on. The node storing the last
clause will store the node identifier of the node that
issued the original subscription request. Then, whenever the first clause match a new triple, the matching
triples will be forwarded to the second node in the
chain. The second and subsequent nodes will only further forward those triples that also match their local filtering criterion. There is a complication to this scheme
if range queries are involved. In these cases, in the subscription registration phase one would always propagate the subscription request to the next nearest node
involved.

Conceivably, the network could reject range subscription requests that span more than maximum range
subscription selectivity nodes (say, 20). For example,
this could be done by having the node to which the
minimum value hashes toand which, thus, is the first

7.4. Unsupported subscription types

We do not support subscriptions to the following

types of queries.

M. Cai et al. / Web Semantics: Science, Services and Agents on the World Wide Web 2 (2004) 109130

The first type is inherently not scalable to large net-
works, and we do not intend to ever support it. The
second type consists of a combination of disjunctive
and conjunctive sub-queries. It is our intuition that this
type of subscription could be supported by chaining the
techniques explained above within the network, with
the leaves of the query parse tree as the starting points.
The third type consists of joins. It is our intuition that
those joins could be supported for which (a) one of the
conjunctive clauses has a constant value and for which
(b) this clause by itself matches only a moderate number of triples (Example 3a). With the design of RDFPeers as described, it may not be possible to efficiently
resolve joins for which each clause by itself leads to
an overwhelming number of triples while the join between them leads to few (Example 3b). However, the
following slight variation may allow RDFPeers to handle those as well. Instead of prefixing URIs and values
with subject:, predicate:, and object: before applying SHA-1 hashing, as we do now for a slight load
balancing gain, we could instead not add that prefix
before hashing. In that case, the same URI hashes to
the same node regardless of position. At a high cost of
O(N) routing hops for first broadcasting the subscription to all nodes, each node can then locally search
for a match when it stores a new triple and notify the
subscriber.

7.5. Extension to support highly skewed
subscription patterns

In a real-world P2P application, e.g., of scientists
subscribing to each others Weblog-like communica-
tions, it is likely that the vast majority of scientists will
have few if any subscribers while a handful will attract nearly everybody. In the latter case, analogous
to IP multicasting for Internet video streaming, we
want to avoid having to originate a number of messages proportional to the number of subscribers from
the subscription-handling node, but rather want to construct something more akin to a real-life phone tree.
We propose the following possible extension: if a node
ends up with multiple identical subscription queries by
different subscribers, such as (<mailto:famous@ivy-

league.edu>, ?, ?), it will internally combine them
into a single entry in its subscription list, with multiple addresses to be notified. It will then designate the
node half-way across from it in identifier space as a
replicating node for the subscriptions if the number
of subscribers exceeds a certain threshold, then one a
quarter-way across if an-other threshold is exceeded,
and so on, adding up to log (N) repeater nodes analogous in structure to its finger table. In this case, it
will send the repeater nodes those subscriber identifiers that fall into their responsibility. The repeater
nodes can then themselves set up repeater nodes, and
so on. In the aggregate, this will take O(N) notification messages if all N nodes subscribe (the natural
lower bound), and additionally leads to the busiest
nodes having to send no more than O(log N) notification messages rather than the O(N) that need to be
sent from the subscription-handling node in the naive
approach.

8. Implementation and evaluation

We implemented a prototype of RDFPeers in Java
that extends our previous MAAN implementation.
RDFPeers is implemented as a Java library and exposes
the following API to applications:

The first two methods store and remove RDF triples
from the P2P network. The query method lets you retrieve triples from the network by specifying a triple
pattern that can restrict values to be constants or numeric ranges. The subscribe method lets you watch
for RDF content changes by passing a triple pattern to watch for, how long you would like this subscription to last (in ms), how frequently you want
to be notified, and a call-back object; you will then
be called back periodically with lists of added and

Fig. 4. The number of routing hops to resolve atomic triple patterns
Q2 through Q8.

Fig. 5. The number of routing hops to resolve disjunctive exactmatch queries in a network with 1000 nodes.

deleted triples that matched. All of these four methods throw a variety of exceptions not further described
here, such as ones for broken connections and response
time-outs.

We already measured the performance of MAAN
on a real-world network of up to 128 nodes in a previous paper [8]. We measured the number of neighbors
per node against the network size. Similar to Chord,
the number of neighbors at each node increases logarithmically with the network size, so that the node
state in MAAN scales well to a large number of nodes.
We also measured the number of routing hops against
the network size for both exact-match queries and for
range queries. The experiment results showed that for
exact-match queries, the number of routing hops in
the worst case is O(log N) and the average routing
hops is log N/2. However, for range queries whose selectivity si > %, meaning that they select more than
one node, the routing hops increase linearly with network size. This is optimal in the sense that si of total N nodes have to be visited by the search queries
presuming we want to evenly balance the load to the
nodes.

8.1. Routing hops to resolve native queries

The number of routing hops taken to resolve a
query is the dominant performance metric for P2P
systems. Fig. 4 shows our simulation result
for
atomic triple patterns from 1 node to 8192 nodes on

a logarithmic scale, which matches our theoretical
analysis.

We also compared two disjunctive range query resolution algorithms: the simple algorithm versus range
ordering algorithm. Fig. 5 shows the simulation result
for up to 1000 disjunctive exact-match values (si = %)
in a network with 1000 nodes.

Fig. 6 shows the result for up to 1000 disjunctive
ranges with 0.1% selectivity each in the same network.
From these two experiments, we can see that the range
ordering algorithm takes less routing hops to resolve
a range query than the simple algorithm, and that its
routing hops are indeed bounded by N.

Fig. 6. The number of routing hops to resolve disjunctive range
queries (0.1% selectivity) in a network with 1000 nodes.

M. Cai et al. / Web Semantics: Science, Services and Agents on the World Wide Web 2 (2004) 109130

Fig. 7. Aggregated throughput of triple storing increases with the number of concurrent clients in a 12-node network.

8.2. Throughput of triple storing and querying

In this section, we present throughput measurements
for triple storing operations and query operations in a
RDFPeers network deployed on a 16-node cluster. The
nodes in the cluster are all dual Pentium III 547 MHz
workstations with 1.5 GB memory, and connected with
a 1-Gigabit switch.

We first measured the aggregated throughput of
triple storing in a RDFPeers network with 12 nodes.
We increased the number of clients that concurrently
store triples into the network from 1 to 25. Fig. 7
shows that the number of triples stored/s of all clients
increases sublinearly with respect to the number of
clients. When there is only one client, it stores 10.74
triples/s. However, 25 clients can concurrently store
94.00 triples/s. When the number of clients is more
than 25, the throughput does not increase significantly
because of the computation and network limitation of
our fixed number of nodes.

We then measured the aggregated query throughput
for the same RDFPeers network that preload 10,000
and 100,000 triples, respectively, at the beginning of the
test. Each client performed 200 queries on one RDFPeers node simultaneously and the total rate of queries
is calculated. Fig. 8 shows that the query rates of two
configurations both increase sublinealy with respect to
the number of clients. When there is only one client,

the query rates are 11.08 and 11.47 queries/s, respec-
tively, for 10,000 and 100,000 preloaded triples. While
for 150 clients, the query rates are 214.38 and 233.20
queries/s, respectively for 10,000 and 100,000 triples.
Similarly to storing operations, the query throughput
also stops increasing significantly when there are more
than 120 clients. These results also show that the query
rate only drops slightly when the preloaded triples increase from 10,000 to 100,000.

These throughput results of storing and query operations are still preliminary and not enough for applications that care about high throughput for storing
and query triples. We will further do some performance
tuning for our RDFPeers implementation, such as using
asynchronous socket, customized message marshaling
and unmarshaling, and batched triple insertion.

8.3. Message traffic of subscription and
notification

We performed two experiments, running RDFPeers
on the same cluster, with up to 10 nodes per ma-
chine. In the first experiment, we set up a network
of N nodes, then inserted 1024 subscription requests
into the network (1 024/N subscriptions per node), followed by inserting 16,348 triples into the network (each
node inserts 16,348/N triples). Each triple matches
8 subscriptions. Fig. 9 shows that the subscription

Fig. 8. Aggregated query throughput increases with the number of concurrent clients in a 12-node network with 10,000 and 100,000 preloaded,
respectively.

messages needed grow logarithmically with the size
of the network, 1024 log (N), while the number of
notification messages needed approaches a constant,
16,348 triples 8 subscriptions each. It is less than
that constant for small networks because some subscriptions can be resolved within a single node. The
latter are bounded by that constant assuming that the
subscription-handling node can store the network address of the subscriber and open a direct connection

to notify it, as our implementation does, otherwise,
if Chord successor routing is used, the latter number
would grow logarithmically with network size as well.
Finally, as expected, the cost of inserting triples grows
logarithmically with network size, 16,348 triples 3
times each triple is indexed log N.

In the second experiment, we kept the number of
nodes in the network constant, but varied the percentage of topics that each node subscribes to. As expected,

Fig. 9. For a constant number of triple subscriptions and insertions, the cost of our subscription scheme in messages grows no more than
logarithmically with network size, 128 topics, 1024 subscriptions, and 16,384 triples.

M. Cai et al. / Web Semantics: Science, Services and Agents on the World Wide Web 2 (2004) 109130

Fig. 10. For a constant network size and load, registration and notification traffic grows linearly with the subscription rate, 128 topics, 64 nodes,
and 8192 triples.

Fig. 10 shows that the number of messages needed
grows linearly with the subscription rate, both for the
subscription traffic and for the notification traffic.

8.4. Dealing with overly popular URIs and literals

Even todays cheapest PCs have a surprising storage capacity, each can store well over 10 million RDF
triples by dedicating 10 GB of its typical 60 GB disk.
Nevertheless, some triples in RDF such as those with
the predicate rdf:type may occur so frequently that it
becomes impossible for any single node in the network
to store all of them. That is, in practice, triples may
not hash around the Chord identifier circle uniformly
due to the non-uniform frequency count distribution of
URIs and literals. Fig. 11 shows the frequency count
distribution of the URIs and literals in the RDF dump
of the Kids and Teens catalog of the Open Directory
Project (http://rdf.dmoz.org/). There are two RDF files
for this catalog: kt-structure, rdf.u8.gz and kt-content,
rdf.u8.gz. The former describes the tree structure of this
catalog and contains 19,550 triples. The latter describes
all the sites in this catalog and contains 123,222 triples.
Fig. 11 shows that only 1020 URIs and literals (less
than 0.1%) occur more than a thousand times.

Table 2 lists the URIs and literals that occur more
than 1000 times in kt-structure.rdf.u8.gz. For exam-
ple, since each URI as a predicate value will be stored

at only one node, this node has the global knowledge
about the frequency count of this predicate value.

We deal with predicate values that become overly
popular by simply no longer indexing triples on them.
Each node defines a Popular Threshold parameter
based on its local capacity and willingness (subject to
some minimum community expectation). Each node
keeps counting the frequency of each predicate value. If
a predicate value occurs more than Popular Threshold
times, the node will refuse to store it and internally
makes a note of that. If the node receives a search re-

Fig. 11. The frequency count distribution of URIs and literals in the
ODP Kids and Teens catalog.

Table 2
URIs and literals that occur more than one thousand times in kt-
structure.rdf.u8.gz

Frequency

URI or literal

rdf:type
dc:Title
http://dmoz.org/rdf/Topic
http://dmoz.org/rdf/catid
http://dmoz.org/rdf/lastUpdate
http://dmoz.org/rdf/narrow
http://dmoz.org/rdf/altlang
dc:Description

Type

Predicate
Object
Object
Predicate
Predicate
Predicate
Predicate
Object

quest with the overly popular value for the predicate,
it sends a refusal message back to the requesting node
and the requesting node must then find an alternative
way of resolving the query by navigating to the target triples through either the subject or object values.
This approach will add O(log N) to that nodes total
query cost in hops. We limit subject and object values
in the same way. We are aware that this still makes the
node with popular URIs a hotspot for query messages
that can be addressed by querying nodes caching which
queries were refused in the past. In essence, this means
that you cannot ask, e.g., which instances in the world
are the subclass of some class. However, these queries
are so general and would return so many triples that we
suspect they would rarely be of use in practice anyway
(in analogy to the English language, where the words
a and the occur frequently but provide little value
as search terms). For the above query, you could alternatively gather the class URIs for which you want to
look for instances for, then traverse to the instances via
that set of URIs by issuing a Q 4-style query.

Fig. 12 shows the minimum, average, and maximum
number of triples per node with Popular Threshold
from 500 to 32,000. In this experiment, we store
both ktstructure.rdf.u8.gz and ktcontent.rdf.u8.gz (to-
tal 142,772 triples) into a network of 100 physical nodes (and the standard Chord log (100) = 6
virtual nodes per physical node for
trading off
load balancing against routing hops). When Popular Threshold = 32,000, there are no overly popular
URIs or literals being removed and there is an average
of 4303 triples per node. However, the load is unevenly
balancedthe minimum number of triples per node is
700 while the maximum number of triples per node is
36,871. When Popular Threshold is set to 500, there

Fig. 12. The number of triples per node as a function of the threshold of popular triples (100 physical nodes with 6 virtual nodes per
physical node).

are 20 overly popular URIs and literals being removed
from indexing and there are an average of 2352 triples
per node. The minimum number of triples per node is
688 while the maximum number of triples per node
is reduced to 4900which we believe at less than an
order of magnitude difference is acceptable load bal-
ancing.

8.5. Load balancing via successor probing

Although limiting overly popular URIs and literals
greatly reduces the difference between the maximum
and minimum number of triples per node, the triples
are still not uniformly distributed around all nodes.
This is because the frequency count distribution of nonpopular URIs and literals remains non-uniform even
after removing overly popular values. We propose a
preliminary successor probing scheme inspired by the
probe-based node insertion techniques of [15] to further achieve a more balanced triple storage load on each
node. In Chord, the distribution of node identifiers is
uniform and independent of the data distribution. In
this successor-probing scheme, we use a sampling technique to generate a node identifier distribution adaptive
to the data distribution. When a node joins the network,
it will use SHAl hashing to generate Probing Factor
candidate identifiers. Then it uses Chords successor
routing algorithm to find the successors corresponding
to these identifiers. All the successors will return the

M. Cai et al. / Web Semantics: Science, Services and Agents on the World Wide Web 2 (2004) 109130

number of triples that would be migrated to the new
node if it joined there, and the new node will choose
the identifier that gives it the heaviest load. The cost
of this technique is that it increases the insertion time
of a triple from log N to Probing Factor log N. It is
our intuition that log N is a good setting for the probing
factor. Fig. 13 shows the minimum, average, and maximum number of triples per node with Probing Factor
from 1 to 9 in a network with 100 physical nodes. The
Popular Threshold is set to 1000 in this experiment.
If there is no successor probing, the most loaded node
has 7.2 times more triples than the least loaded node. If
each node probes 9 nodes when it joins, the node with
the heaviest load only has 2.6 times more triples than
the node with the lightest loadwhich further reduces
load imbalances to much less than an order of mag-
nitude. We can further improve load balancing with a
background virtual node migration scheme proposed in
[30], subject to the limitation that it cannot distribute
the load for a single overly popular value.

9. Example application: Shared-HiKE

Hierarchical Knowledge Editor lets users create and
organize RDF data. Unlike most other metadata creation tools, HiKE lets users enter instance data first,
and add an ontology for the data later, explicitly or
by inference when (possibly other) users create more

Fig. 13. The number of triples per node as a function of the number
of successor nodes probed (100 physical nodes, PopularThreshold =
1000).

data, refine their data, or align their data. Various external hierarchical structures can be imported whole
into HiKE, such as a file hierarchy or a tree hierarchy
of XML instance data. The whole HiKE hierarchy is
based on RDF. Each node in HiKE is a RDF resource
with the shown text being its label. Each node can have
some attributes that correspond to RDF triples with this
node as the subject. The node hierarchy is also represented with a list of RDF triples connecting various
resources. HiKE has been constantly used by us as a
semantic desktop. Being RDF-driven, HiKE seems a
natural application of RDFPeers. We have interfaced
HiKE to RDFPeers network and termed that combined
application Shared-HiKE, forming what we believe is
the first instance of a new class of Internet application
driven by RDF transmitted over a structured P2P net-
work. Shared-HiKE is written in Java and sits on top
of the API provided by RDFPeers. Fig. 14 shows a
screenshot of Shared-HiKE as currently implemented.
The left pane (My HiKE) contains all of the RDF
data, both this users and others. The My Shared
and the Active Users items are specially recognized,
and cannot be moved, deleted, or re-named. Content
under My Shared is inserted into the P2P network.
Conversely, opening nodes under Active Users will
fetch and display content shared by others via queries
to the underlying P2P network. Anybody can add to
others shared content. The tabs called My Shared,
Bob, MinCai, Baoshi, Sameer, and Martin
do not represent new content but are rather convenience
shortcuts into the My HiKE hierarchy. The middle
pane shows attribute data of the current selection (that
is, out-going arcs of that RDF node). At time of writing,
we are working on (a) color-coding content based on
who contributed it, on (b) using RDFPeers new subscription mechanism to monitor the network for users
going on- and off-line (rather than for the user having
to explicitly refresh the Active Users node), and
on (c) letting the user monitor specified URIs and keywords via RDFPeers subscriptions.

10. Related work

Our work on RDFPeers was inspired by a number of
research fields including RDF metadata management,
structured Peer-to-Peer systems, and publish/subscribe
systems.

Fig. 14. Shared-HiKE, a P2P knowledge editor built on top of subscribable RDFPeers.

10.1. RDF metadata management systems

Many centralized RDF repositories have been implemented to support storing, indexing, and querying RDF documents, such as RDFDB [36], Inkling
[25], RDFStore [3] and Jena [24]. These centralized
RDF repositories typically use in-memory or databasesupported processing, and files or a relational database
as the back-end RDF triple store. RDFDB supports a
SQL-like query language, while Inkling, RDFStore and
Jena all support SquishQL-style RDF query languages.
Centralized RDF repositories are very fast and can scale
up to many millions of triples. However, they have the
same limitations as other centralized approaches, such
as a single processing bottleneck and a single point of
failure.

To support integrated querying of distributed RDF
repositories, Stuckenschmidt et al. [42] extend the
Sesame system to a distributed architecture that introduces a RDF API implementation (Mediator SAIL) on
top of the distributed repositories. Their work focuses
on the index structure as well as query optimization
in the mediator SAIL implementation. This mediator
approach can support arbitrary complex queries and

works well for small size of data sources. However, it
is difficult for this approach to scale up to Internet size
of data sources. Edutella [28] and its successor superpeer based RDF P2P network [29] were discussed in
Section 1. Super-peers are often desirable in order to
place the load unevenly among heterogeneous nodes,
but our scheme can achieve the same effect more flexibly by nodes hosting more or fewer Chord virtual nodes
according to their capacity. REMINDIN [44] developed a lazy learning approach for the SWAP platform
[14] to efficiently route semantic queries based on social metaphors. However, it only learns how to forward
simple queries and lacks efficient algorithms for complex queries.

Much work in the semantic web and information integration literature has been emphasized on solving the
semantic interoperability problem among data sources
with heterogeneous ontologies. ChattyWeb [4] enables
the participating data sources to incrementally develop
global agreement in an evolutionary and completely
decentralized bottom-up process by learning the graph
of local mappings among schemas through gossiping.
Piazza [17] also eliminates the need for a global mediated schema by describing the mappings between

M. Cai et al. / Web Semantics: Science, Services and Agents on the World Wide Web 2 (2004) 109130

sets of XML and RDF source nodes and evaluating
those schema mappings transitively to answer queries.
These two systems forward queries to the peers based
on schema similarities, which is complementary to
RDFPeers that indexes instances of RDF statements.
It might be interesting to develop some hybrid systems
that leverage schema mapping on the top of RDFPeers.

10.2. Structured Peer-to-Peer systems

Recent structured P2P systems use message routing
instead of flooding by leveraging a structured overlay
network among peers. These systems typically support
distributed hash table (DHT) functionality and offer
the operation lookup (key), which returns the identity
of the node storing the object with the key [32]. Current
proposed DHT systems include Tapestry [45], Pastry
[35], Chord [41], CAN [31], Koorde [21], and so on.
These DHT systems provide scalable distributed
lookup for unique keys. However, they cannot support efficient search, such as keyword search and multidimensional range queries. Reynolds and Vahdat [33]
proposed an efficient distributed keyword search sys-
tem, which distributes an inverted index into a distributed hash table, such as Chord or Pastry. To minimize the bandwidth consumed by multi-keyword conjunctive searches, they use bloom filters to compress
the document ID sets by about one order of magnitude
and use caching to exploit temporal locality in the query
workload. For large sets of search results, they also use
streaming transfers and return only the desired number
of results. pSearch [6] is another peer-to-peer keyword
search system that distributes document indices into a
CAN network based on the document semantics generated by latent semantic indexing (LSI). It uses contentaware node bootstrapping to force the distribution of
nodes in the CAN to follow the distribution of indices.
Andrzejak and Xu [5] extend CAN for handling
range queries on single attributes by mapping onedimensional space to CANs multi-dimensional space
using Hibert Space Filling Curve as hash function.
However, this work did not address multi-attribute
range queries. In contrast
to Andrzejaks system,
Schmidt and Parashar [38] proposed a dimension reducing indexing scheme that efficiently maps the multidimensional information space into the one dimensional Chord identifier space by using Hibert Space
Filling Curve. This system can support complex queries

containing partial keywords, wildcards, and range
queries. PIER [18] focuses on designing a massively
distributed query engine based on DHT systems, especially for distributed equi-joins. Their join algorithms
are based on a multicast primitive that flood the query to
all nodes in the same namespace. However, PIER does
not support efficient range predicates because DHTs
are a hashing mechanism. Actually the work in PIER
is complementary to RDFPeers for supporting efficient
join operations.

10.3. Publish/subscribe systems

Besides RDFPeers,

there are several other distributed RDF metadata management systems that provide publish and subscribe mechanisms. MDV [23] is
a distributed RDF metadata management system based
on a 3-tier architecture and supports caching and replication in the middle-tier. It implemented a filter algorithm based on relational database technology that efficiently computes all subscribers for created, updated,
and deleted RDF data. Chirita et al. [11] proposed a
peer-to-peer RDF publish/subscribe system that was
based on a super-peer based RDF peer-to-peer network.
In contrast to RDFPeers, subscriptions in this approach
are selectively broadcast to other super-peers based on
their advertisements, while subscriptions in RDFPeers
are routed to and store on a particular node that is also
responsible for storing matching RDF statements.

Publish/subscribe systems have also been studied
extensively in the networking and distributed systems
literature [9,10,16,19,20]. However, those systems typically only support topic-based or type-based sub-
scriptions. In contrast, RDFPeers and other metadata
publish/subscribe systems allow more expressive subscriptions for metadata. Recent advance in distributed
hash tables also enables a new class of scalable pub-
lish/subscribe systems [10,43] that neither relies on any
centralized server nor subscription broadcasting.

11. Future work and conclusion

We would like to implement the RDQL to RDFPeers
native queries translator that we have only sketched in
this paper, and improve load balancing using a background virtual node migration scheme. We would also
like to take more measurements of the scalability of

our subscription design, such as throughput stress tests:
For what number of subscribers, subscribing to how
much content, does the scheme break, not just in terms
of abstract routing hops, but in reality for our actual
Java implementation?.

In conclusion, RDFPeers provides efficient distributed RDF metadata storage, query, and subscription in a structured P2P network. It avoids flooding
queries to the network and guarantees that query results will be found if they exist. RDFPeers can also balance the triple-storing load between the most and least
loaded nodes by using a successor-probing scheme. Its
state cost in neighborhood connections is logarithmic
to the number of nodes in the network, and so is its
processing cost in routing hops for all insertion, most
query, and subscription operations. RDFPeers offers
subscriptions that, assuming a fixed number of subscriptions per node, scale to networks of many nodes.
RDFPeers also preserves subscriptions as well as the
original data by replicating content to a fixed number of
nearby nodes so that the network can repair itself without data loss when a node suddenly dies. RDFPeers,
thus, enables fault-tolerant distributed RDF repositories of truly large numbers of participants. We hope it
can become the basis for new types of metadata-driven
and egalitarian community applications on the Internet.

Acknowledgements

The successor probing technique of Section 8.5
was inspired by discussions with Shahram Ghandeharizadeh and Antonios Daskos about load balancing
techniques. We are grateful to Ann Chervenak and Mats
Rynge for their support of our work on the Center
For Grid Technologies computing cluster. We thank
Sameer Maggon for implementing the GUI of Shared-
HiKE. We also gratefully acknowledge feedback from
the anonymous reviewers, Stefan Decker, and Geoff
Pike, and AFOSR funding under grant F49620-01-1-
0341.
