Semplore: An IR Approach to Scalable Hybrid

Query of Semantic Web Data

Lei Zhang1, QiaoLing Liu2, Jie Zhang2, HaoFen Wang2,

Yue Pan1, and Yong Yu2

1 IBM China Research Lab

Beijing, 100094, China

lzhangl,panyue@cn.ibm.com

2 Department of Computer Science & Engineering
Shanghai Jiao Tong University, Shanghai, 200240, China
{lql,zhangjie,whfcarter,yyu}@apex.sjtu.edu.cn

Abstract. As an extension to the current Web, Semantic Web will not
only contain structured data with machine understandable semantics but
also textual information. While structured queries can be used to find
information more precisely on the Semantic Web, keyword searches are
still needed to help exploit textual information. It thus becomes very
important that we can combine precise structured queries with imprecise keyword searches to have a hybrid query capability. In addition, due
to the huge volume of information on the Semantic Web, the hybrid
query must be processed in a very scalable way. In this paper, we define
such a hybrid query capability that combines unary tree-shaped structured queries with keyword searches. We show how existing information
retrieval (IR) index structures and functions can be reused to index semantic web data and its textual information, and how the hybrid query
is evaluated on the index structure using IR engines in an efficient and
scalable manner. We implemented this IR approach in an engine called
Semplore. Comprehensive experiments on its performance show that it
is a promising approach. It leads us to believe that it may be possible
to evolve current web search engines to query and search the Semantic Web. Finally, we breifly describe how Semplore is used for searching
Wikipedia and an IBM customers product information.

1 Introduction

With more and more structured and semantic information made avaiable on the
Semantic Web, structured queries such as SPARQL can be used to find information more precisely. At the same time, current web search is dominated by the
form of keyword searches. Although precise structured queries generally produce
far better results than imprecise keyword searches, keyword search capability is
still needed in Semantic Web because: (1) The huge amount of textual information in the (Semantic) Web will remain to be a valuable source of information
that need be exploited using keyword searches; (2) Users often have vague information needs that can hardly be expressed as formal queries; and (3) keyword

K. Aberer et al. (Eds.): ISWC/ASWC 2007, LNCS 4825, pp. 652665, 2007.
c Springer-Verlag Berlin Heidelberg 2007
?

?

?
searches are extremely simple to use. It thus becomes very important that we can
combine precise structured queries with imprecise keyword searches to have a
hybrid query capability. On the other hand, as an extension to the current Web,
Semantic Web will have an even larger volume of data and textual information.
Hybrid queries against such large volume of web-scale data must be evaluated
in a very scalable way.

Current research on searching or querying Semantic Web uses either an IRbased (e.g. [1,2,3]) or a DB-based (e.g. [4,5,6,7]) approach. The IR-based work
does not provide structured query capability and the DB-based work lacks support to keyword searches. Few work [8] tries to combine them to achieve hybrid
query capability. DB-based work pays more attention to the scalability of queryanswering and it relies on databases various indices and query optimization algorithms to support efficient evaluation of complex queries. However, taking DB
engines to support complex queries on web-scale data is still a big challenge. In
contrast, IR engine is a special-purpose engine supporting only keyword searches
but has proven to be able to scale to the size of the Web. Current web search
engines have developed scalable method to process keyword searches using classic IR techniques with distributed and parallel backend infrastructure [9]. This
inspires us to trade query capability for scalability and to try an IR approach
of indexing, querying and searching of semantic web data. The problem then
breaks down to the following points:
 What is the hybrid query capability ?
 How to index semantic web data using existing IR index structures which

are designed for textual information ?

 How to use IR engines to answer the hybrid queries and maintain the effi-

ciency and scalability ?

In this paper, we show how we tried to solve these problems and how we
implemented the solution in Semplore using a popular open-source IR engine 
Lucene. Our experiments show that the IR approach is promising and it leads us
to believe that it may be possible to evolve current web search engines powerful
backend IR infrastructure for querying and searching the Semantic Web and
ultimately evolve them to web-scale semantic web search engines.

The paper is organized as follows. Section 2 defines the hybrid query capa-
bility. Section 3 describes in detail the methods of indexing and querying of
semantic web data using IR index structure and engine. Section 4 then reports
the experiment results of Semplore and briefly describes its two applications. We
discuss related work in Section 5 and conclude the paper in Section 6.

2 Hybrid Query Capability

[10] introduced a DL-based formal conjunctive query language for Semantic Web.
Conjunctive queries are also the formal core of SPARQL query language [11].
We thus use conjunctive queries as the basis of the hybrid query. We then make
an extension to ordinary conjunctive queries to combine keyword search for

L. Zhang et al.

Film 

romantic

star

star

y2

Best Actor Academy

Award Winners

y3

Best Actress Academy

Award Winners

Director

x

directs

directs

y1

y4

Film  war

Fig. 1. An Example Query Graph

semantic web data as well. The idea is that we view the searched keywords as a
virtual concept called keyword concept W . An individual will be regarded as
an instance of a keyword concept W if the textual content of any of its datatype
properties contains the searched keywords in W (i.e., we adopt a boolean IR
model). This idea derives from our previous work in [8].

Based on that, we can formally define the hybrid query capability of Sem-
plore. A unary hybrid conjunctive query q over a knowledge base K is a query
expression of the form

q(x)  y .conj(x,y )

y are existentially quantified variables
where x is called the target variable,
called non-distinguished variables, and conj(x,y ) is a conjunction of terms of
the form C(z), R(z1, z2), or R(z1, z2). z, z1, z2 are individuals in K or variables
y . R is a role/relation name and C (or D) is a concept expression that
in x or
is a boolean combination of concept name A and keyword concept W :

C, D :=  |  | A | W | {i} | C  D | C  D | C

The answer to the query w.r.t K is the set defined by {a  O | K |= q[x/a]},
where O denotes the set of all individual names in K, and q[x/a] denotes the
query q with all occurrences of variable x substituted by the individual name a.
The above query can be depicted as a directed graph, where the nodes are variables or individual names and the edges are relations connecting them. Concept
expressions and relation names provide labels for nodes and edges respectively.1
Fig.1 shows an example of such a query graph and [10] has details about the
definition of a query graph.

In this paper, we restrict to queries whose graph patterns are trees, as in
[10]. We also restrict the query result to be unary (i.e., a single target variable
x in the query). These restrictions lead to a much more simplified and hence
efficient query evaluation procedure, while a large portion of information needs
can still be expressed. This is the major place where we trade query capability
for scalability.

The query capability of Semplore can then be defined primarily as unary
tree-shaped hybrid query. Its not hard to see that the unary tree-shaped hybrid
1 If the node is an individual i, the concept expression is {i}. If a node have no label
on it, we add the concept expression  as its label.
?

?

?
Table 1. Translating Semantic Web Data to Documents in IR

Document Field

concept C

relation R

individual i

subConOf
superConOf
text
subRelOf
superRelOf
text
type
subjOf
objOf
text

Term
super-concepts of C
sub-concepts of C
tokens in textual properties of C
super-relations of R
sub-relations of R
tokens in textual properties of R
concepts that i belongs to
all relations R that (i, R, ?) is a triple in data
all relations R that (?, R, i) is a triple in data
tokens in textual properties of i

queries without keyword concepts is a strict subset of SPARQL queries. In the
next section, we show that the hybrid query capability can be achieved using IR
engines on semantic web data.

3 Semplore Engine

3.1 Index Structure

IR indexing is based on the concepts of documents, fields(e.g. title, abstract,
etc.), and terms. Based on the classic inverted index structure, IR engines can
efficiently retrieve documents given a boolean combination of pairs of (field,
term) as a query. Current web search engine has implemented this technique on
the web scale.

Our intuition is that if we treat individuals as documents and their associated
concept names as terms, we can then retrieve all individuals of a given concept
by inputing the concept name as a query term into the IR engine. Extending this
intuition, we realize that we can answer many kinds of semantic queries using
IR engines if we translate semantic web data into documents, fields and terms
in a proper way as shown in Table 1. After the translation, IR engine can index
semantic web data in its inverted index structure and provide retrieval functions
over the data. In addition, in order to return inferred data in query result, we
require that the semantic web data be preprocessed by a reasoning engine to
contain all inferred data.

The idea of treating concepts as terms to index individuals is not new. Previous work [12] proposed and analyzed more complex labeling schemes for indexing
semantic web data. Whats new in our work, however, is on how to index relation instances (s, R, o). The index should enable us to find all the objects of
a relation with a given set of subjects (e.g. find all the films directed by some
Chinese director: {f | directs(d, f)  ChineseDirector(d)}) and vice versa.

We propose an approach called PosIdx to index a relation instance (s, R, o).
Recall that in the classic inverted index structure, for each term there is a posting
list of documents that contain the term. In addition, for each document in the

L. Zhang et al.

"example"

i1 i2

  

Term Index

C1

i1 i2

  

R1

i1 i2

  

Term Positions

i2 i3

  

i4 i5

  

Term Posting Lists

Triples to be indexed:

(i1, rdfs:label, example)
(i2, rdfs:comment, example)

(i1, rdf:type, C1)
(i2, rdf:type, C1)

(i1, R1, i2)
(i1, R1, i3)
(i2, R1, i4)
(i2, R1, i5)

Fig. 2. PosIdx Index Structure Example

posting list, there is also a list of positions showing where the term appears in
the document. In the PosIdx method, subject s is treated as a document with a
field named subjOf and a term R in the field. Object o is stored as a position
of the term R in the document s. We use the position list to store the objects
of relation R under subject s. An example index structure is depicted in Fig.2
(field information is omitted for brevity). The objOf field is a symmetric case of
subjOf and is also not shown in Fig.2. If we see subjOf as a field for indexing
instances of relation R, the objOf field can then be seen as indexing instances
of relation R.

As to the physical storage and access of the logical inverted index structure ,
it has been thoroughly studied in the IR field, which results in many optimized
methods, such as byte-aligned index compression [13] and self-indexing [14]. Fur-
thermore, in the proposed PosIdx method, relation objects enjoy the benefit of
spatial locality for fast access, because positions of a term are usually physically
stored together and continuously in modern IR engines. In fact, in our Semplore
implementation, we enjoy all the above-mentioned optimizations and benefits
because they are alreay built into the underlying IR engine Lucene.

The use of IR approach also enables us to leverage the heavy optimizations
on the architectures and algorithms for building index in IR field (e.g.[15]). In a
real (Semantic) Web search engine, advanced techniques such as MapReduce [16]
can be applied on a cluster of machines to speed up the index building process,
thanks to the simplicity of the IR index structure.

3.2 Query Evaluation

Based on the above index, Semplore reuses IR engines merge-sort based boolean
query evaluation method and extends it to answer the unary tree-shaped hybrid
query defined in Section 2. In the following, we first introduce and explain some
basic operations and their corresponding notations, then we describe the query
evaluation algorithm of Semplore.

Basic Operations. We generalize the notion of a posting list to an Ascending
Integer Stream (AIS) which can be accessed from the smallest integer to the
largest one. By adding additional indexing structures to the inverted index (e.g.,
self-indexing [14]), modern IR engines can supply a very efficient stream reader
for a posting list AIS.
?

?

?
(1) Basic retrieval: (f, t)

Given a field f and a term t, (f, t) retrieves the corresponding posting list from
inverted index. This is a standard IR operation. The output of this operation is
an AIS. For example, under Table 1s structure, (type, ChineseDirector) will
retrieve all individuals of the ChineseDirector concept as an AIS.

(2) Merge-sort: m(S1, op, S2)
S1 and S2 are two AISs and op is a binary operator which can be ,  or .
Merge-sort computes S1 op S2 and returns a new AIS. Merge-sort can be nested
to compute boolean combinations of multiple AISs. IR research has developed
efficient algorithms to do nested merge-sort on AISs.
(3) Concept expression evaluation: (C)

The input of this operation is a concept expression C as defined in Section 2
which is a boolean combination of concept name A and keyword concept W . The
output of this operation is an AIS containing all the IDs of the individuals of C.
This operation can be implemented using basic retrievals and nested merge-sort
operations, thus is also readily available in modern IR engines. For example, if
C is Film  war, the (C) operation can then be achieved through two basic
retrievals and one merge-sort: m( (type, Film), , (text, war) ).
(4) Relation expansion:  (S1, R, S2)

The input of the operation is a relation R and two AISs S1 and S2 that contain individual IDs. The operation computes the set {y | x : x  S1  (x, R, y)  y  S2}
and returns it as an AIS. For example,  ((ChineseDirector), directs,
(DocumentaryFilm)) can be used to find all documentary films directed by some
Chinese director. This operation is not available in a classic IR engine. We will
show later how it can be computed on the index structure we proposed.
Evaluation Algorithm. Based on the above four basic operations, Algorithm
1 shows how a unary tree-shaped hybrid query defined in Section 2 can be
evaluated. The algorithm can be visually imagined as traversing the query tree
in the depth-first order. It evaluates the concept expression of each vertex when
moving forward and uses results of children to constrain the results of parent
when moving backward. It will terminate in 2  E steps each of which is either
a (C) operation or a  (S1, R, S2) operation.

Taking Fig.1 as an example with target variable x, we first reach to leaf vertex y2 via x and y1, and compute their results S[x], S[y1], S[y2]. Then S[y1] =
, S[y1]) is computed when we move backward from y2 to y1. Sim-
(S[y2], star
ilarly, y3 is traversed and its result also adds constraint to result of its parent
, S[x]).
y1. Next, result of root vertex x is updated by S[x] = (S[y1], directs
Finally, y4 is traversed and the result of root x is updated again, which is the
final answer.

L. Zhang et al.

Algorithm 1. Query Evaluation Algorithm

Input : A unary tree-shaped hybrid query Q(t) with graph G = (V, E) and

target variable t on the vertex vt  V ; Each vertex u  V has a
concept expression Cu as its label and each edge (u, v)  E has a

relation R(u,v) as its label. (Note that R(u,v) is equal to R
(v,u). )

Output: An AIS containing the IDs of individuals in the answer set of Q(t)
foreach vertex u  V do

checked[u] = f alse; S[u] = null;

DF S(vt);
return S[vt]
?

?

?
Procedure DFS(u)
checked[u] = true;

S[u] = (Cu);

foreach vertex v such that (u, v)  E or (v, u)  E do
?

?

?
if (checked[v] == true) then continue v ;
DF S(v);
if ((v, u)  E) then S[u] = (S[v], R(v,u), S[u]);
else S[u] = (S[v], R


(u,v), S[u]);

Relation Expansion. Among the four basic operations used for query evalua-
tion, relation expansion  (S1, R, S2) is the one that is not directly supported by
current IR engines. However, it can be evaluated in four steps using additional
operations. Fig.3 shows how this is done on the PosIdx index structure.
First, we compute the valid subjects that have R relations: S = m(S1, ,
(subjOf, R)).2 Second, we find the objects for each valid subject s  S using an
operation called getObjects(s, R) which returns the object set {o | (s, R, o)} as
an AIS, given s and R. Third, we union all these object sets and sort the result
set to obtain a new AIS SO. This step is encapsulated in an operation called
massUnion(S, R) = SO =
sS getObjects(s, R). Finally, we do a merge-sort
m(SO,, S2) to obtain the final result. This final step can be integrated into
the massUnion operation as we will show later. In short, relation expansion can
be completed using basic retrieval, merge-sort and two additional operations:
getObjects and massUnion.
?

?

?
When the number of valid subjects in S is large, the massUnion(S, R) operation
becomes expensive because it has to union and sort a large number of sets stored on
disk, which is an I/O bound operation. In Fig.3, these sets are the shaded segments
in term Rs position list. If we still do a streaming merge-sort on all the sets to
obtain all the objects, it would incur a prohibitive I/O cost because it will lead
to a large number of back-and-forth disk seeks. One way to save I/O cost is to
selectively union a subset of all the sets that can still cover all the objects. However,
selecting such a subset is the Set-Cover problem which is NP hard [17].

2 If the relation is R



, replace subjOf with objOf. Similarly, in the following steps

getSubjects(o,R) is used instead of getObjects(s,R).
?

?

?
(subjOf, R)

Term Rs position list Final Result

S1
i3
i6
i9
i20


i1
i3
i4
i9
i10
i20


massUnion

i1
i6
i8
i9


S2
i1
i3
i8
i9
i10


i3
i8
i9
i1
i8
i5
i6
i9


getObjects(i20, R)

massUnion is an expensive

operation to union and sort possibly

a huge number of sets on disk.

Fig. 3. Relation Expansion on PosIdx

Algorithm 3. BVI for  (S1, R, S2)
?

?

?
Do a basic retrieval OR = (objOf, R); Let N = |OR| and T = 0;
Allocate two bit vectors B1 and B2 of size N and initialize them to all 0s;
Do m(OR,, S2). During the merge-sort, set B2[i] = 1 for the ith element in
OR that is also in S2. Let M be the number of 1 bits in B2;
foreach s  m(S1, (subjOf, R)) do

Os = getObjects(s, R) ;
foreach sequence number i  Os do

if

(B2[i] == 1) then
B2[i] = 0; T + +; B1[i] = 1;
(T == M ) then goto 10;
if

Construct the result AIS G from the OR stream using the filtering condition:
the ith element of OR is in G if B1[i] is 1;
return G as an AIS
?

?

?
We use a simple yet effective approach for the massUnion operation: read in
all the sets one by one using the getObjects(s, R) operation and use a bit vector
to track the union result. For convenience, we use sequence numbers to identify
the objects in the position list. Suppose the set of all distinct objects of relation
R is OR = {o | s : (s, R, o)} and N = |OR|. Sorting the set OR on object IDs
ascendingly gets a list of objects o1, o2, . . . , oN . The sequence number of object
oi is i under relation R. We thus can allocate a limited size bit vector to track
which object is in the result of the relation expansion. The algorithm is called
Bit Vector Intersection (BVI) and shown in Algorithm 3.
Note that N = |OR| in line 1 can be directly obtained from inverted index as
the document frequency of the term R without any computation at run time.
Line 4 and 5 can be implemented together on the PosIdx index very efficiently
using a sequential scan on the position list during merge-sort, with the help of
self-indexing [14].

L. Zhang et al.

The worst case time complexity of the algorithm is linear to the number of
all objects of valid subjects but it will stop when all the possible results have
been found in line 9. Meanwhile, because of the stop condition, the execution
time of the algorithm wont increase definitely with the size of the valid subjects
S = m(S1, , (subjOf, R)). In our experiments, we are surprised to find that
the time even decreases when the size of valid subjects |S| exceeds an threshold.
This is because in one disk I/O more Os sets (i.e, the shaded blocks in Fig. 3)
can be read in due to the increased locality of these sets when |S| becomes large.
It shows the benefit of the PosIdx index structure in which relation objects enjoy
the spatial locality for fast access.

The space requirement of Algorithm 3 is linear to N which may be quite large.
But in practice, a 256MB memory can already hold the two bit vectors for N
as large as 1 billion and the memory can be reused across multiple executions of
the algorithm.

3.3 Implementation

We implemented all the above index and query evaluation algorithms in the
Semplore engine. It uses the popular open source IR engine Lucene to do classic
inverted indexing and perform all the basic IR operations. V2.0.0 Java version
of Lucene is used which implements byte-aligned index compression and self-
indexing. We use the COLT package3 for fast bit vector operations in Semplore.

4 Experiment and Application
4.1 Experiment Setup

Both synthetic and real world semantic web data are used in our experiment.
We use LUBM [18] benchmark data sets, from LUBM(5,0) to LUBM(400,0),
to test Semplores scalability. To evaluate Semplores performance on hybrid
queries, we use Wikipedia content as the real world knowledge base because
it contains both rich textual properties and relationships between entities. We
combine TBox from YAGO [19] and ABox from DBpedia [20] as our Wikipedia
dataset. Some simple heuristic rules are used for data cleaning.

All the data sets are preprocessed by Minerva [7] to do reasoning. IBM DB2
v8.1.7 is used as the backend database of Minerva. Table 2 shows the number of
triples of each data set after reasoning. We then index the inferred data set in
Semplore, by extracting the triples from Minerva. The index time of Semplore
excludes the time of extracting triples from Minerva. Table 2 shows Semplores
index performance w.r.t different data sets using a single index thread. We can
see that both the index time and space of Semplore increase basically linearly
with the size of dataset. The following query evaluation experiments are carried
out on these indices. For Sesame [4], we used the 1.2.6 version with MySQL
5.0.21 as its backend RDBMS. All the experiments are conducted on a normal
3 http://dsd.lbl.gov/hoschek/colt/
?

?

?
Table 2. Datasets and Index Performance

Dataset

Triples After Reasoning Index Time(s) Index Space(MB)

LUBM(5,0)
LUBM(10,0)
LUBM(20,0)
LUBM(50,0)
LUBM(400,0)

Wikipedia

729,253
1,485,029
3,135,033
7,763,131
62,233,512
13,991,407
?

?

?
25.6
?

?

?
Table 3. Query Response Time for LUBM Datasets (ms) (Sem: Semplore, Min:
Minerva, Ses: Sesame; As in [21], we omit Sesames performance on LUBM(50) and
LUBM(400) due to its excessive loading time.)

Query

LUBM(5)

LUBM(10)

LUBM(20)

Sem Min Ses Sem Min Ses

Sem Min Ses

LUBM(50) LUBM(400)
Sem Min

Sem Min

BQ1
BQ3
BQ4
BQ5
BQ6
BQ7
BQ8
BQ10
BQ11
BQ12
BQ13
BQ14

NQ1
NQ2
?

?

?
156 218
109 1000
?

?

?
203 2781
?

?

?
234 1953

234 4468
?

?

?
156 1125
?

?

?
484 2968

1078 8874
?

?

?
109 2625

360 2672
?

?

?
453 4890
31 2625 281

78 1046 12594 156 2016 53468 360 5438 2938 67078
78 4688 609
406 17922 3297 523815

172 7094 532

desktop PC with Pentium 4 CPU of 3.2 GHz and 2G memory, running Microsoft
Windows Server 2003 with Sun Java JRE 1.5.0. The Wikipedia data set and the
test queries used in the following experiments are all available from our Semplore
web site4 which also contains live demos.

4.2 Query Evaluation

First, we consider the 14 LUBM benchmark queries(BQ) in [18]. Some modifications are applied to the queries due to the unary tree-shaped query capability
of Semplore. Queries with multiple target variables (BQ4, BQ7, BQ8, BQ12)
are modified to unary ones, in which we all choose x as target variable. We also
remove two cyclic queries (BQ2, BQ9). The remaining 12 queries are all path
queries and primarily designed to test reasoning capability. We therefore add
two new tree-shaped queries (NQ1, NQ2) to test Semplore.

4 http://apex.sjtu.edu.cn/apex wiki/Demos/Semplore

L. Zhang et al.

Table 4. Hybrid Queries and Their Response Time on Wikipedia Dataset (ms)

Query

Set
QS1

(TBox)

QS2

(ABox)

QS3

(ABox)

Set
Size

QS4

(ABox)

Pattern

Example Query

Ave
Time

Max
Time

node

node

path

ave len:2.3
max len:3

tree

ave dep:2.2
max dep:3

Find all concepts with label containing the
term chinese
Find documentary films about world war

Find films reaching Academy Award and
starring a James Bond actor;
Find artists origining from New York City
and having hip hop albums
Find directors who have directed roman-
tic films starring Best Actor Academy
Award Winners and Best Actress Academy
Award Winners and also films about war

We compare the query evaluation performance on pure structured queries of
Semplore with the DB-based ontology stores Minerva and Sesame. Table 3 shows
the response time of the three systems for all the 14 queries. The query time
includes traversing the whole result set of each query. All the three systems have
inferred data materialized and do not have run-time reasoning. Thanks to the
benefit of spatial locality for fast access using PosIdx index, Semplore achieves
very good scalability on all the 14 queries. Its maximal query processing time of
the 12 BQs is less than 0.25 second even for the largest LUBM(400) data set,
which is much better than that of Minerva. Considering the two NQs, although
Semplore needs more relation expansion operations, it manages to return answers within 4 seconds and still keeps orders of magnitude faster than Minerva
and Sesame. One important reason is that while Minerva and Sesame depends
on complex nested table joins, Semplore turns to relation expansions along the
edges of query graph, which are more lightweight operations. This advantage
comes from Semplores designed trade-off between query capability and scala-
bility. Certainly, we note that Minerva is well-designed to deal with reasoning,
whereas Semplore focuses more on indexing and querying. The comparison here
is somewhat unfair on this aspect, but it certainly shows that IR-based approach
is also promising for querying semantic web data.

What we test above is on queries without keyword searches. Since there are
no benchmarks for hybrid queries yet, we created four sets of queries for the
Wikipedia dataset with increasing complexity in query patterns, from node,
path to tree. The queries include 10 TBox queries and 40 ABox queries. All
the queries contain one or more keyword searches to express vague information
needs. The details of the hybrid queries are shown in Table 4.

The table also summarizes the response time of Semplore w.r.t the four query
sets. The query time includes traversing the whole result set of each query. By providing sub-second query respond time on the 1.3GB Wikipedia data set index , Semplore provides good scalability on hybrid queries as well. This mainly benefits from
its unified index method for both semantic information and textual information.
?

?

?
4.3 Applications

In this section, we very briefly describe two applications of the Semplore engine.
The first one is a search application for the Wikipedia data set we used in
the experiments. To provide both structured queries and keyword seaches in
the user interface (UI), we adopted and extended the faceted search paradigm
[22]. Users can mix browsing, querying, searching and discovering in the search
application easily. Users actions in the UI are translated to hybrid queries to the
Semplore engine. Our users reported that it improves access to the Wikipedias
rich structural and textual information. The application can be accessed from
our Semplore web site.

In another application, we exploit the use of semantic web technologies for
product information management (PIM) as reported in [23]. Modern enterprises
have very complex product information that contains a large variety of cate-
gories, attributes, relationships and rich textual descriptions. Hybrid query capability and easy-to-use UI is needed for the PIM user to browse, query and
search all the products. We modeled a real IBM customers product information
in OWL and converted a subset of the real data into RDF. We then use the
Semplore engine and the extended faceted search developed above to help user
browse, query and search the product information. Semplore successfully delivered answers to hybrid queries with sub-second performance on the 2GB index
of the RDF data set. It thus augments the semantic PIM system in [23] with a
powerful search engine.

5 Related Work

Existing work on querying and searching semantic web data can be roughly
divided into two categories: IR-based and DB-based.

Swoogle [3] is a crawler-based indexing and retrieval system for the Semantic
Web. It uses IR engine to index the crawled semantic web documents using
either n-gram or URIrefs as terms and computes a ranked list of these documents
given the search terms. [1] augments keyword search with semantic information
collected from different sources while [2] uses keyword search results as a seed to
do spread activation on semantic networks. These work takes a pure IR approach
and does not support structured queries on the semantic web data. [24] combines
keyword searches and structured queries but focuses on result ranking.

Most DB-based work such as [4,5,6,7] rely on relational database engines for
indexing and querying. The primary database schema used for storing triples is
a vertical schema with various optimizations. Query answering is achieved primarily through self-join on the vertical table. Indices are built on combinations
of subjects, predicates and objects. These DB-based approaches have no or weak
support to keyword searches. YARS [25] does not rely on a relational database
but uses similar index structures (i.e. B+ trees). Both YARS and Kowari5 support keyword searches but they use IR engine separately for that purpose only.

5 http://www.kowari.org

L. Zhang et al.

BigOWLIM6 is a scalable repository supporting structured queries but uses its
own proprietary storage and index format. LUBM [18] benchmark are developed
alongside those work to evaluate semantic web knowledge base systems [21].

Our work is certainly related to the cross field of DB and IR. Actually, the
integration of IR and DB is a long desired research goal in the information
management area. IR methods have been successfully borrowed to DB area for
many tasks such as keyword searches (e.g. [26]) and searching XML (e.g. [27]).
At the same time, work in IR area is also adding more structures and semantics
to the keyword search. [28] borrows XML Fragment query language to express
more semantic-rich queries for searching a semantically annotated text corpora.
These work does not address the hybrid query capability for semantic web data
(i.e. the RDF triples) but most of them supports ranking of results which is
currently lacking in our method.

6 Conclusion

Having hybrid query capability and scalable query evaluation algorithm is important in querying semantic web data. In this paper, we define such a hybrid
query capability that combines structured queries with keyword searches. Unlike
most of the current work that uses DB engines, our work uses existing IR index
structure and engine to support the hybrid query capability. Our work shows
that this IR approach not only is possible but also achieves good scalability due
to its trade-off on query capability and reuse of existing IR optimizations. It
leads us to believe that it may be possible to evolve current web search engines
powerful backend IR infrastructure for querying and searching the Semantic Web
and ultimately evolve them to web-scale semantic web search engines. Our future
work includes the evaluation of the effectiveness of the hybrid query capability
and the support of ranking of results.
