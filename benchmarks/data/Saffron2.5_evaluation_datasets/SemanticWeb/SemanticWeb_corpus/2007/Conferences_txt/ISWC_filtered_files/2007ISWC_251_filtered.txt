Discovering Simple Mappings Between

Relational Database Schemas and Ontologies

Wei Hu and Yuzhong Qu

School of Computer Science and Engineering, Southeast University,

Nanjing 210096, P.R. China
{whu,yzqu}@seu.edu.cn

Abstract. Ontologies proliferate with the growth of the Semantic Web.
However, most of data on the Web are still stored in relational databases.
Therefore, it is important to establish interoperability between relational
databases and ontologies for creating a Web of data. An effective way to
achieve interoperability is finding mappings between relational database
schemas and ontologies. In this paper, we propose a new approach to discovering simple mappings between a relational database schema and an
ontology. It exploits simple mappings based on virtual documents, and
eliminates incorrect mappings via validating mapping consistency. Ad-
ditionally, it also constructs a special type of semantic mappings, called
contextual mappings, which is useful for practical applications. Experimental results demonstrate that our approach performs well on several
data sets from real world domains.

1 Introduction

The popularity of ontologies is rapidly growing since the emergence of the Semantic Web. To date, the amount of available Web ontologies continues increasing
at a phenomenal rate. For example, Swoogle [10] has collected more than 10,000
ontologies so far. However, most of the worlds data today are still locked in data
stores and are not published as an open Web of inter-referring resources [4]. In
particular, as reported in [6], about 77.3% data on the current Web are stored
in relational databases (the so-called Deep Web). Therefore, it is necessary to
actualize interoperability between (Semantic) Web applications using relational
databases and ontologies.

In order to achieve such interoperability, an effective way is to discover mappings between relational database schemas and ontologies. Although relational
databases are based on closed-world assumption while ontologies use open-world
semantics, there usually exist some approximate correspondences between them.
For instance, an attribute in a relational database schema may correspond to a
property in an OWL ontology. In fact, relational databases can be formalized by
First Order Logic (FOL) [21]; while the logical foundation for OWL ontologies
is Description Logic (DL) [2], which is a subset of FOL. Thereupon, it is feasible
to construct mappings between relational database schemas and ontologies.

K. Aberer et al. (Eds.): ISWC/ASWC 2007, LNCS 4825, pp. 225238, 2007.
c Springer-Verlag Berlin Heidelberg 2007

W. Hu and Y. Qu

Discovering mappings between a relational database schema and an ontology
usually employs a two-phase paradigm: (i) searching simple mappings between
entities in the relational database schema and the ontology, and (ii) constructing
complex compositions based on simple mappings. Finding simple mappings is an
early and fundamental stage for constructing complex compositions [1]. In this
paper, we focus on the first problem, i.e., discovering simple mappings between
a relational database schema and an ontology.

Manually discovering such simple mappings is tedious and improbable at the
Web scale. Although many (semi-)automatic approaches have been proposed to
address this issue (e.g. [7,13,17]), pursuant to the results of our investigation,
they have not well considered the characteristics of relational database schemas
and ontologies, so the mappings they exploited are not accurate enough. Besides,
most of the present approaches cannot construct semantic mappings, which are
demonstrated to be useful in various practical applications (e.g. [8]).

In this paper, we propose a new approach to discovering simple mappings. It
constructs virtual documents for the entities in a relational database schema as
well as an ontology, so it can discover mappings from a semantic perspective, and
it validates mapping consistency, so it can eliminate certain incorrect mappings.
In addition, the approach constructs a special type of semantic mappings, called
contextual mappings [5], between relations in the relational database schema and
classes in the ontology. The contextual mappings can be transformed directly to
view-based mappings with selection conditions, which are useful for applications
from real world domains.

The remainder of this paper is organized as follows. Section 2 gives the definitions of discovering simple mappings between a relational database schema
and an ontology. Section 3 sketches out our approach. Section 4 describes the
approach in details. Section 5 evaluates the approach on several cases from real
world domains. Section 6 discusses some related works. Finally, Section 7 concludes the paper with future work.

2 Problem Statement

Followed by [19], a data model is a collection of high-level data description constructs that hide many low-level storage details. A description of data in terms
of a data model is called a schema.
Definition 1. A relational database schema, R, is a finite collection of relation
schemas. A relation schema consists of the name of the relation, the names of
the attributes in the relation along with their associated domains. A domain is
referred to in a relation schema by the domain name and has a set of associated
values. A relational database schema specifies a set of integrity constraints (ICs),
which restrict the data instances that can be stored in the database.
In our notation, R denotes a relation, and A denotes an attribute. type(A) gets
the domain name of A. rel(A) gets the relation which specifies A. pk(R) returns
the attributes appeared as the primary keys of R. ref(A) returns the attributes
?

?

?
tional database schemas.

Discovering Simple Mappings

An ontology is an explicit specification of a shared conceptualization [14]. In

this paper, we propose a simple definition based on [15,18].
Definition 2. An ontology, O, is a pair O = (S, A0), where S is the signature
describing the vocabulary, while A0 is a set of axioms specifying the intended
interpretation of the vocabulary in some domain of discourse. Further, S is the
disjoint union of sets of classes, properties and individuals in OWL DL.
Without explanation, ontologies used in this paper are expressed by OWL DL.
For notation, we use C to represent a class, and P to represent a property. Fur-
ther, PD denotes a datatype property and PO denotes an object property. d(P)
gets the domain(s) of P, and r(P) gets its range(s).

Similar to the definition in [23], we define discovering simple mappings be-

tween a relational schema and an ontology as follows.
Definition 3. Let R be a relational schema and O be an ontology, discovering
simple mappings between R and O gets a set of mappings M = {m}. A mapping
m is a 5-tuple: < id, u, v, t, f >, where id is a unique identifier; u is an entity in
{R}  {A}, and v is an entity in {C} {P}; t is a relationship (e.g. equivalence
(=), subsumption ()) holding between u and v; and f is a confidence measure
in the [0, 1] range.

A u t h o r 

  i d   :   i n t e g e r 

        n a m e   :   s t r i n g 
        e m a i l   :   s t r i n g 

P a p e r 

  i d   :   i n t e g e r 
        t i t l e   :   s t r i n g 
        t y p e   :   i n t e g e r 

w r i t e s 

a i d   :   i n t e g e r 
p i d   :   i n t e g e r 

h a s I D 

o w l : o n P r o p e r t y 

<1, writes, hasAuthor, =, 1.0>

r d f s : d o m a i n 

_ : g e n i d 

r d f s : s u b C l a s s O f 

h a s A u t h o r 

1 . 0 >

= ,

h a s I D ,

i d ,

< 2 ,

P a p e r 

r d f s : d o m a i n 

r d f s : s u b C l a s s O f 

r d f s : s u b C l a s s O f 

< 3 ,   P a p e r ,   J o u r n a l P a p e r , 

,   0 . 8 > 

J o u r n a l 
P a p e r 

C o n f e r e n c e 

P a p e r 

r d f s : r a n g e 

A u t h o r 

Fig. 1. A toy example

To help understanding, we illustrate a toy example here. Looking at the relational schema depicted in the left part of Fig. 1, it contains three relations:
Author, Paper, and writes. Each relation has a set of attributes, e.g., Author
has three attributes: id, name, and email. The underlined attribute, such as
id, indicates the primary key of the relation. The arrow represents a referential IC, e.g., the foreign key aid in writes references the key id in Author.
The ontology shown in the right part of Fig. 1 contains four classes, i.e., Author,
Paper, ConferencePaper and JournalPaper, and two properties, i.e., hasID and
hasAuthor. We could further recognize that hasID is a datatype property and

W. Hu and Y. Qu

hasAuthor is an object property. Besides, ConferencePaper and JournalPaper
are two subclasses of Paper. Paper and hasID are linked by a restriction con-
struct. If we match the relational schema with the ontology, we possibly obtain
some mappings (numbered 13 with dotted lines) in Fig. 1, where the first and
the second ones are two mappings holding the equivalence relationships respec-
tively, and the third is a mapping holding the subsumption relationship.

3 Overview of the Approach

The overview of our approach is illustrated in Fig. 2. In general, it starts with a
relational schema and an ontology, and after four processing stages, it outputs
a set of simple mappings.

 Phase 1: Classifying entity types. This phase is a preprocessing process. It
heuristically classifies entities in the relational schema and the ontology into
four different groups to limit the searching space of candidate mappings. Be-
sides, this phase coordinates different characteristics between the relational
schema and the ontology.

 Phase 2: Discovering simple mappings. This phase firstly constructs virtual
documents for the entities in the relational schema and the ontology to capture their implicit semantic information. Then, it discovers simple mappings
between entities by calculating the confidence measures between virtual documents via the TF/IDF model [22].

 Phase 3: Validating mapping consistency. This phase uses mappings between
relations and classes to validate the consistency of mappings between attributes and properties. It considers the compatibility between data types of
attributes and properties as well. In addition, some inference rules are also
integrated in this process.

r e l a t i o n a l 
s c h e m a 

o n t o l o g y 

P h a s e   1 

C l a s s i f y i n g 
e n t i t y   t y p e s 

P h a s e   2 

D i s c o v e r i n g 

s i m p l e 

m a p p i n g s 

P h a s e   3 

P h a s e   4 

V a l i d a t i n g 
m a p p i n g 

c o n s i s t e n c y 

C o n s t r u c t i n g 

c o n t e x t u a l 
m a p p i n g s 

s i m p l e     m a p p i n g s 

< 1 ,   R 1 ,   C 1 ,   = ,   1 . 0 > 

< 2 ,   R 2 ,   P 2 ,   = ,   0 . 5 > 

< 3 ,   A 3 ,   P 3 ,   = ,   0 . 8 > 

< 4 ,   R 4 ,   C 4 ,       ,   0 . 6 > 

Fig. 2. Overview of the approach

 Phase 4: Constructing contextual mappings. This phase operates on mappings between relations and classes found in the previous phases, and supplies them with sample instances. It constructs a set of contextual mappings,
which indicate the conditions how they could be transformed to view-based
mappings with selection conditions.
?

?

?
4 Details of the Approach

In this section, we describe each of the four processing stages in details.

4.1 Classifying Entity Types

A relation in a relational schema can be classified into four disjoint types based
on the properties of its primary keys: Strong Entity Relation (SER), Weak Entity
Relation (WER), Regular Relationship Relation (RRR), and Specific Relationship Relation (SRR). An attribute can be distinguished into two categories by
whether it is a foreign key: Foreign Key Attribute (FKA) and Non Foreign Key
Attribute (NFKA). Please refer to [9] for formal definitions.

Generally, a strong (or weak) entity relation would heuristically match a class
in an ontology; while a regular (or specific) relationship relation would heuristically match an object property. For example, the relation Author in Fig. 1 is a
strong entity relation, and matches the class Author; while the relation writes
is a regular relationship relation, and matches the object property hasAuthor.
Similarly, if an attribute is a foreign key attribute, it would match an object
property; otherwise, it would match either a datatype or an object property. One
exception needs to be noticed. If a relation is a regular (or specific) relationship
relation, all its attributes appeared as primary keys as well as foreign keys are
unnecessary to participate in the process of discovering mappings. For instance,
in Fig. 1, the relation writes is a regular relationship relation, so the attributes
aid and pid should not be considered anymore.

According to the heuristic classification, we partition entities in the relational

schema and the ontology into the following four groups.
 Group 1: {{SER}  {WER}}  {C}.
 Group 2: {{RRR}  {SRR}}  {PO}.
 Group 3: {FKA}  {PO}.
 Group 4: {NFKA}  {{PD}  {PO}}.
Besides, we consider some preprocessing steps to coordinate different characteristics between the relational schema and the ontology. As an example, a regular
(or weak) relationship relation should be copied so that it could match two object properties holding the inverseOf construct. As another example, an n-arity
relationship (n  3) should be reified as a group of binary relationships, because
OWL ontologies can only express unary and binary relationships [2]. Please note
that the heuristic rules above are not complete, but they are effective in a lot of
application scenarios.

4.2 Discovering Simple Mappings

Inspired by [20], we present a method in this paper, which considers the structures of both the relational schema and the ontology to exploit their semantic
information. The rationalities are as follows: the semantic information of a relational schema is characterized mainly by its ICs. For instance, a referential IC

W. Hu and Y. Qu

involves two relations and associates a group of attributes in one relation to the
keys of another relation. Likewise, an OWL ontology can be mapped to an RDF
graph [18], which also indicates the semantic information in its structure.

We construct virtual documents, denoted by V D(.), for the entities in both
the relational schema and the ontology to capture their structural information.
A virtual document represents a collection of weighted tokens, which are derived
not only from the description of the entity itself, but also from the descriptions
of its neighbors. The weights of the tokens indicate their importance, and could
then be viewed as a vector in the TF/IDF model [22].

The formulae in (1)(2) build virtual documents for relations and attributes
respectively. In general, for a relation, if it is a strong (or weak) entity relation,
then the virtual document is from its local description; otherwise, it is a regular
(or specific) relationship relation, then the virtual document is from its local description as well as the descriptions of the referenced relations. For an attribute,
if it is a foreign key attribute, besides involving the description itself, we further
consider the descriptions of its referenced relations; otherwise, we complement
its data type into account.

Des(R)
Des(R) +  

V D(R) = 

V D(A) = Des(A) +   (Des(rel(A)) +Aref(A) Des(rel(A
Des(A) +   Des(rel(A)) +   Des(type(A))

Aref(A)

Des(rel(A

Apk(R)

R  {SER}  {WER}
)) R  {RRR}  {SRR} ,

(1)

))) A  {FKA}

A  {NFKA} .
(2)

Analogously, the formulae in (3)(4) construct virtual documents for classes and
properties respectively. In brief, for a class, its virtual document is its local
description. For a property, we consider not only its local description, but also
the descriptions of its domain and range classes. Please note that if the property
is a datatype property, its range is actually its data type.

V D(C) = Des(C),

(3)

V D(P) = Des(P) +   (Cd(P) Des(C) +Cr(P) Des(C)) P  {PO}

Des(P) +  

Cd(P) Des(C) +   Des(r(P))

For simplicity, in this paper, we define Des(.) merely returns the name of an
entity as its local description.  and  are fixed rational numbers in [0, 1]. The
values should be configured with respect to practical cases. In our experience, 
should be a little larger than .

P  {PD} . (4)

As an example to explain the construction of virtual documents, let us see the
regular relationship relation writes in Fig. 1. Its local description only includes
write, and its two neighbors are Paper and Author. The virtual document of
writes is V D(writes) = {write,   paper,   author}.

We discover simple mappings by calculating the confidence measures between
entities. The confidence measure between any two entities is calculated by the
cosine value between two vectors Ni and Nj, corresponding to two virtual documents V Di and V Dj in the TF/IDF model:
?

?

?
conf idence(V Di, V Dj) = cosine(Ni, Nj) =
?

?

?
,

(5)

n2
jk

l
k=1
?

?

?
l
k=1
n2
ik

l
k=1

niknjk
?

?

?
where l is the dimension of the vector space, and nik (njk) is the component of
the vector. If the two virtual documents do not share any tokens, the confidence
measure would be 0.0. If all the token scores equal completely, it would be 1.0.

4.3 Validating Mapping Consistency

In a relational database, relations are the unique building structures while attributes are defined by relations within their local scopes, i.e., attributes cannot
stand alone without relations. In contrast, classes and properties in an OWL ontology are both first-class citizens. Nevertheless, the restriction construct in an
OWL ontology provides a way of specifying local domain and range constraints
on the classes [18].

In this paper, we use this kind of constraints between relations (classes) and
attributes (properties) to check the consistency between mappings. We firstly assume that the mappings between relations and classes are correct, and then we
utilize these mappings to validate the consistency of the candidate mappings between attributes and properties. Please note that some inference rules should be
considered as well. For example, in Fig. 1, the domains of the datatype property
hasID should include the classes JounalPaper and ConferencePaper. Besides,
we also check the compatibility of data types between non foreign key attributes
and datatype properties.

Considering the example shown in Fig. 1 again, we assume that the mapping
between the relation Paper and the class Paper has been discovered, then we
validate two candidate mappings: the mapping between the attribute id in Paper
and the property hasID, and the mapping between the attribute id in Author
and the property hasID. It is obvious that the latter one is inconsistent with the
mapping between the relation Paper and the class Paper.

4.4 Constructing Contextual Mappings

Data integration is a traditional application for matching [23]. As an important
infrastructure, query answering provides certain answers of queries over map-
pings. In [8], it has been proven that subsumption relationships are helpful for
the optimization of query answering. It inspires us to construct mappings holding
the subsumption relationships between a relational schema and an ontology.

A naive approach to construct such mappings holding the subsumption relationships is reusing the hierarchies of entities in a relational schema and an
ontology. For the ontology, the hierarchy of entities is explicitly specified by the
subClassOf constructs; while for the relational schema, the Reverse Engineering
techniques (e.g. [9]) could also help us recover such hierarchy. But the naive approach would suffer from finding too many mappings holding the subsumption
relationships, and most of them are not useful in practical applications.

W. Hu and Y. Qu

In this paper, we focus on searching a special type of mappings holding the
subsumption relationships, called contextual mappings. It can be directly translated to conditional mappings or view-based mappings [5]. Let us see the example
illustrated in Fig. 3. In the example, when the value of the attribute type in the
relation Paper equals to 1, the relation Paper matches the class JournalPaper;
and when the value equals to 2, it matches the class ConferencePaper. So the
contextual mappings not only hold the subsumption relationships, but also explain the conditions how they can be converted to the equivalence relationships.

w h e r e   t y p e   =   2 

P a p e r 

t i t l e 

t y p e 

    A   s u r v e y   o f   s c h e m a - b a s e d   m a t c h i n g   a p p r o a c h e s 
    B r i d i n g   t h e   g a p   b e t w e e n   O W L   a n d   r e l a t i o n a l   d a t a b a s e s 
    C r e a t i n g   a   s c i e n c e   o f   t h e   W e b 
    T o w a r d s   a   S e m a n t i c   W e b   o f   r e l a t i o n a l   d a t a b a s e s 
    I n f e r r i n g   c o m p l e x   s e m a n t i c   m a p p i n g s 
?

?

?
i d 
?

?

?
w h e r e   t y p e   =   1 

p i d _ 1 

h a s T i t l e 

P a p e r 

r d f s : s u b C l a s s O f 

r d f s : s u b C l a s s O f 

J o u r n a l 
P a p e r 

r d f : t y p e 

C o n f e r e n c e 

P a p e r 

r d f : t y p e 

r d f : t y p e 

p i d _ 3 

p i d _ 4 

h a s T i t l e 

h a s T i t l e 

C r e a t i n g   a   s c i e n c e 

T o w a r d s   a   S e m a n t i c   W e b 

o f   t h e   W e b 

o f   r e l a t i o n a l   d a t a b a s e 

I n f e r r i n g   c o m p l e x 
s e m a n t i c   m a p p i n g s 

Fig. 3. The toy example with instances

Constructing contextual mappings requires two preconditions: (i) certain input mappings, and (ii) sample instances for both the relational schema and the
ontology. To the first precondition, we have already found such mappings in the
previous subsections. To the second one, a database is a collection of data [19], so
it always contains instances; while according to the report by Swoogle [10], only
1.5% Semantic Web ontologies have few individuals. So it is possible to provide
some overlapped instances for both the relational schema and the ontology.

The algorithm ContextMatch is shown in Table 1. The input of the algorithm
is a relational schema with associated sample data, an ontology with associated
sample individuals, and a set of simple mappings found previously. The goal of
the algorithm is to assemble a collection of contextual mappings. To accomplish
this, the algorithm considers each input mapping between a relation and a class
in turn at line 1, and selects the data JR from the relation at line 2.

Next, in lines 35, the algorithm enumerates all the disjoint subclasses of
the class, and for each subclass, it selects its individuals I kC , and finds the
instances J kR from JR which match I kC by InstanceMatch. As a result, JR is
partitioned into some disjoint subsets corresponding to the subclasses. In our
current implementation, InstanceMatch is developed by comparing the values of
the instances through the input mappings between attributes and properties.
Please note that InstanceMatch is the most time-consuming routine throughout the whole algorithm, and its complexity is relevant to the sizes of sample
instances.

In lines 68, the algorithm repeatedly examines each attribute in the relation
whether it is a categorical attribute or not. If so, InformationGain computes the
information gain (IG) of the attribute on {J kR}. The attribute Al, which has the
?

?

?
Table 1. An algorithm for constructing contextual mappings

Algorithm. ContextMatch(S, O, J, I, M ).
Input: A relational schema S, with associated sample data J,

an ontology O, with associated sample individuals I,
and a set of simple mappings M .

Output: A set of contextual mappings M
?

?

?
.

1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.

for each m =< id, u, v, t, f > in M s.t. u is a relation and v is a class

JR := InstanceSelect(u, S, J);
for each Ck s.t. Ck is a subclass of v and disjoint with any other Ck

I kC := InstanceSelect(Ck, O, I);
J kR := InstanceMatch(JR, I kC , M );
igi := InfomationGain(Ai,{J kR});

for each Ai in u s.t. Ai is a categorical attribute

l := arg max(igi);
for each Ck s.t. igl > 
?

?

?
return M
?

?

?
;

  {< new id, u,Ck,Al = xxx, igl >};

:= M

maximal IG, is chosen as the best splitting attribute. Please note that computing
IG for classification (e.g. decision tree) has been widely studied in the fields of
Machine Learning and Data Mining. In the end, in lines 911, if the IG of Al is
larger than a given threshold , then we construct a new contextual mapping,
and add it to the set of contextual mappings as output.

5 Evaluation

We have implemented the proposed approach in Java, called Marson (Mapping
between relational schemas and ontologies). In this section, we report on some
results of an experimental study. Please note that all the test cases and experimental results are available at our website 1.

5.1 Case Study

In our evaluation, we choose the data sets used in [1], which can be downloaded
from the website 2. The data sets are obtained from a variety of real world do-
mains, and the relational database schema and the ontology in each data set are
developed independently. Volunteers are trained to set up reference mappings.
The statistical data of the data sets are listed in Table 2.

1 http://iws.seu.edu.cn/infores/tools/falcon-ao/marson.zip
2 http://www.cs.toronto.edu/yuana/research/maponto/relational/testData.html

W. Hu and Y. Qu

Table 2. Characteristics of data sets

ID R
?

?

?
OBSERVER
Country

 R  A O
?

?

?
Univ. CS
Conference
Bibliography
Bibliography
Factbook

 C
?

?

?
 P
?

?

?
Ref.
?

?

?
5.2 Experimental Methodology

Two experiments are designed to evaluate Marson. In the first experiment, we
measure the performance of Marson on discovering simple mappings (without
contextual mappings) between a relational schema and an ontology. Four approaches are set up for comparison: (a) a simple approach, denoted by Simple,
which only utilizes the local descriptions of the entities (i.e.  = 0,  = 0 in (1)
(4)) for calculating the confidence measures in the TF/IDF model, and does not
validate the consistency between mappings; (b) an approach, denoted by VDoc,
which discovers simple mappings by constructing virtual documents, but does
not check mapping consistency; (c) an approach, denoted by Valid, which only
validates the consistency between mappings found by the simple approach; and
(d) a simple version of an existing prototype Ronto [17]. We have implemented
it based on I-Sub [24] as its elementary matcher for calculating the confidence
measures between entities. Please refer to Section 6 for a detailed introduction.
The parameters of VDoc and Marson in (1)(4) are uniformly set as follows:
 = 0.2,  = 0.1. Please note that our tests also show that Marson is stable
with slight changes on  and .

In the above experiment, we use the well known F1-Measure (a combination
of precision and recall) to evaluate the performance of each approach. We have
tested a variety of cutoffs or thresholds for each approach, and selected the best
ones in our experiments. It seems fair to all the approaches.

In the second experiment, we evaluate the effectiveness of Marson on constructing contextual mappings. Some real instances are collected from the Web
corresponding to the relational schemas and ontologies in the first three data sets
(more than 50 instances for each relation and class). We look into the contextual
mappings found by our algorithm by comparing with the mappings established
by experienced volunteers.

5.3 Discussion on Experimental Results

The results on measuring the F1-Measures of Simple, VDoc, Valid and Marson are illustrated in Fig. 4(a). It shows that either VDoc or Valid performs
better than Simple, and Marson is dominant in most data sets. More specif-
ically, VDoc improves Simple in tests 1, 2, and 5, because it can discover the
mappings between the entities having little commonality in their local descrip-
tions. Valid enhances Simple in almost all the data sets, since it often occurs
?

?

?
that the relational schema in each data set has some attributes in different relations owning the same names such as id or name. But the mappings found
additionally by VDoc and Valid are not completely orthogonal, some of them
are overlapped. Based on the experiment, Marson is the best one on nearly all
the data sets except for a slight lag in test 4. It demonstrates that it is feasible
to integrate VDoc and Valid together and achieve a good result.

0.8

0.6

0.4

0.2

Simple

VDoc Valid Marson

0.8

0.6

0.4

0.2

Marson

Ronto

(a) Simple, VDoc, Valid and Marson

(b) Marson and Ronto

Fig. 4. Comparison of F1-Measure

The comparison results between Marson and Ronto are shown in Fig. 4(b).
It indicates that Marson performs better than Ronto in average F1-Measure.
The reason is that Marson can find additional correct mappings by VDoc, and
eliminate some inconsistent mappings by Valid.

Furthermore, it is valuable to mention that Marson is quite efficient in the
first experiment. Based on our environment (Intel Pentium IV 2.8GHz processor,
512MB memory, Windows XP Professional, and Java SE 6), it takes about 5
seconds to complete all the five tests (including the parsing time).

In the second experiment, the contextual mappings constructed by our algorithm are evaluated by experienced volunteers, and the results are exhibited
in Table 3. Marson constructs some interesting contextual mappings. For in-
stance, in test 2, Marson constructs a contextual mapping between the relation
Event and the class Conference. It points out that when the values of the attribute type in Event equals to Research Session or Industrial Session, the
subsumption relationship between Event and Conference can be converted to
the equivalence relationship. In most tests, our algorithm finds all the possible
contextual mappings. But in test 1, it misses the contextual mapping between
the relation academic staff and the subclasses of Faculty (e.g. Professor),
because without background knowledge, Marson cannot discover the mapping
between academic staff and Faculty.

6 Related Work

Discovering mappings between relational database schemas and ontologies is an
interdisciplinary research in both Database and Semantic Web communities. At

W. Hu and Y. Qu

Table 3. Evaluation of contextual mappings
?

?

?
Found

Existing Correct
?

?

?
an early stage, some works (e.g. [7]) try to implement visual toolkits in order to
help users specify mappings manually. This kind of approaches may succeed in
some specific scenarios, but they are impractical for the scale of the Web.

At present, many works focus on discovering mappings (semi-)automatically.
For example, Dragut and Lawrence [13] transform relational schemas and ontologies into directed labeled graphs respectively, and reuse the schema matching
tool COMA [11] to exploit simple mappings. Papapanagiotou et al. [17] develop
a plug-in named Ronto, which introduces six different strategies to discover
mappings by distinguishing the types of entities in relational schemas, and it is
similar to the Simple approach in this paper. However, all the approaches mentioned above disregard the structural differences in models, and do not validate
the consistency between mappings.

Furthermore, to the best of our knowledge, no existing work raises the issue
of constructing semantic mappings between relational schemas and ontologies.
In both Database and Semantic Web communities, more and more researchers
have been aware of the importance for constructing semantic mappings (e.g.
[5,8]), and we believe it is also necessary to consider semantic mappings between
relational schemas and ontologies. In this paper, we propose a novel algorithm
to find a special type of semantic mappings, called contextual mappings, which
can directly help query answering and data integration.

Besides, there exist some literatures addressing the problem from other direc-
tions. For example, Dou et al. [12] describe a general framework for integrating
databases with ontologies via a first-order ontology language Web-PDDL. Barrasa et al. [3] design a language R2O for expressing complex mappings. Motik
et al. [16] propose an extension of OWL with ICs that captures the intuition
behind ICs in relational databases. An et al. [1] develop a prototype MapOnto
for inferring complex semantic mappings formalized by Horn-Clauses between
relational tables and ontologies deriving from simple mappings. It is worthy of
note that our approach can provide such initial mappings.

7 Summary and Future Work

In summary, the main contributions of this paper are listed as follows. Firstly, we
have presented a new approach to discovering simple mappings between entities
in a relational database schema and an ontology. It captures semantic information contained in the structures of the entities based on virtual documents, and
eliminates incorrect mappings by validating mapping consistency.
?

?

?
Secondly, we have proposed a novel algorithm to construct contextual map-
pings. The algorithm reuse simple mappings and supplies additional sample instances for a relational database schemas and an ontology. Contextual mappings
specify the conditions for converting to view-based mappings with selection con-
ditions, which further help query answering and data integration.

Finally, we have experimentally evaluated our approach on several data sets
from real world domains. The results demonstrate that our approach performs
well as compared to some existing approaches in average F1-Measure. Besides,
the results also show that the contextual mappings constructed by our approach
are useful and meaningful.

In the future work, we look forward to comparing our approach with some
intermediate approaches which firstly convert one data model to the other, and
then reuse certain schema matching or ontology matching methods to discover
simple mappings. We also hope to consider some machine learning techniques for
mining some other interesting and useful semantic mappings. Finally, we would
like to integrate our approach into some existing data integration tools in order
to evaluate its effectiveness.

Acknowledgements

The work is supported in part by the NSFC under Grant 60573083, and in part
by the 973 Program of China under Grant 2003CB317004. We thank Dongdong
Zheng and Yuanyuan Zhao for their work in the experiments. We also appreciate
anonymous reviewers for their precious comments.
