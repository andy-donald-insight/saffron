Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 170183

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

journal homepage: www.elsevier.com/locate/websem

Contextualized ranking of entity types based on knowledge graphs
Alberto Tonon a,, Michele Catasta b, Roman Prokofyev a, Gianluca Demartini c,
Karl Aberer b, Philippe Cudre-Mauroux a
a eXascale Infolab, University of Fribourg, Switzerland
b EPFL, Lausanne, Switzerland
c Information School, University of Sheffield, UK

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 1 April 2015
Received in revised form
6 October 2015
Accepted 22 December 2015
Available online 6 January 2016

Keywords:
Entity typing
Ranking
Context
Crowdsourcing
Knowledge graphs

A large fraction of online queries targets entities. For this reason, Search Engine Result Pages (SERPs)
increasingly contain information about the searched entities such as pictures, short summaries, related
entities, and factual information. A key facet that is often displayed on the SERPs and that is instrumental
for many applications is the entity type. However, an entity is usually not associated to a single generic
type in the background knowledge graph but rather to a set of more specific types, which may be relevant
or not given the document context. For example, one can find on the Linked Open Data cloud the fact that
Tom Hanks is a person, an actor, and a person from Concord, California. All these types are correct but some
may be too general to be interesting (e.g., person), while other may be interesting but already known to
the user (e.g., actor), or may be irrelevant given the current browsing context (e.g., person from Concord,
California). In this paper, we define the new task of ranking entity types given an entity and its context.
We propose and evaluate new methods to find the most relevant entity type based on collection statistics
and on the knowledge graph structure interconnecting entities and types. An extensive experimental
evaluation over several document collections at different levels of granularity (e.g., sentences, paragraphs)
and different type hierarchies (including DBpedia, Freebase, and schema.org) shows that hierarchy-based
approaches provide more accurate results when picking entity types to be displayed to the end-user.

 2016 Elsevier B.V. All rights reserved.

1. Introduction

A large fraction of online queries targets entities [1]. Commercial search engines are increasingly returning rich Search Engine
Result Pages (SERPs) that contain not just ten blue links but also im-
ages, videos, news, etc. When searching for a specific entity, users
may be presented in the SERP with a summary of the entity itself taken from a background knowledge graph. This search task
is known as ad-hoc object retrieval [2,3], that is, finding an entity
described by a keyword query in a structured knowledge graph.
After correctly identifying the entity described by the user query,
the subsequent task is that of deciding what entity information
to present on the SERP among all potential pieces of information
available in the knowledge graph. It is possible, for example, to display pictures, a short textual description, and related entities.

 Corresponding author.

E-mail addresses: alberto.tonon@unifr.ch (A. Tonon), michele.catasta@epfl.ch

(M. Catasta), roman.prokofyev@unifr.ch (R. Prokofyev),
g.demartini@sheffield.ac.uk (G. Demartini), karl.aberer@epfl.ch (K. Aberer),
philippe.cudre-mauroux@unifr.ch (P. Cudre-Mauroux).

http://dx.doi.org/10.1016/j.websem.2015.12.005
1570-8268/ 2016 Elsevier B.V. All rights reserved.

One interesting entity facet which can be displayed in the
SERP is its type. In public knowledge graphs such as Freebase,
entities are associated with several types. For example, the
entity Peter Jackson in Freebase1 has 17 types, among which
Person, Ontology Instance, Film director, and Chivalric Order
Member can be found. When deciding what to show on the
SERP, it is important to select the few types the user would
find relevant only. Some types are in most cases not compelling
(e.g., Ontology Instance) while other types (e.g., Film director)
may be interesting for a user who does not know much about
the entity. Users who already know the entity but are looking for
some of its specific facets might be interested in less obvious types
(e.g., Chivalric Order Member, and its associated search results).
More than just for search, entity types can be displayed to Web
users while browsing and reading Web pages. In such a case, popups displaying contextual entity summaries (similar to the ones
displayed on SERPs like the Google Knowledge Panel) can be shown

1 http://www.freebase.com/edit/topic/en/peter_jackson.

to the users who want to know more about a given entity she is
reading about. In this case again, picking the types that are relevant
is critical and highly context-dependent.

A third example scenario is to use selected entity types to
summarize the content of Web pages or online articles. For
example, one might build a summary for a given news article by
extracting the most important entities in the article and listing
their most relevant types (e.g., this article is about two actors and
the president of Kenya).

In this paper, we focus on the novel task of ranking available
entity types based on their relevance given a context. We propose
several methods exploiting the entity type hierarchy (i.e., types and
their subtypes like person and politician), collection statistics
such as the popularity of the types or their co-occurrences,
and the graph structure connecting semantically related entities
(potentially through the type hierarchy).

We experimentally evaluate our different approaches using
crowdsourced judgements on real data and extracting different
contexts (e.g., word only, sentence, paragraph) for the entities.
Our experimental results show that approaches based on the type
hierarchy perform more effectively in selecting the entity types
to be displayed to the user. The combination of the proposed
ranking functions by means of learning to rank models yields
to the best effectiveness. We also assess the scalability of our
approach by designing and evaluating a Map/Reduce version of our
ranking process over a large sample of the CommonCrawl dataset2
exploiting existing schema.org annotations.
In summary, the main contributions of this paper are:
 The definition of the new task of entity type ranking, whose goal
is to select the most relevant types for an entity given some
context.
 Several type-hierarchy and graph-based approaches that exploit both schema and instance relations to select the most relevant entity types based on a query entity and the user browsing
context.
 An extensive experimental evaluation of the proposed entity
type ranking techniques over a Web collection and over
different entity type hierarchies including YAGO [4] and
Freebase by means of crowdsourced relevance judgements.
 A scalable version of our type ranking approach evaluated over
a large annotated Web crawl.
 The proposed techniques are available as an open-source
library3 as well as an online web service.4

The present work is based on our previous contribution on type
ranking [5]. However, we extend our previous article in several
different ways: We propose a new context-aware approach to rank
entity types that extends the notion of context in which an entity
appears to exploit the text surrounding it in addition to other
co-occurring entities (Section 6.4), and a new method that mixes
different features coming from both the knowledge base, including
entity popularity, and the type hierarchy (Section 6.5). We report
additional details on the methods we used to build our text
collection, including a pilot study we did in order to evaluate the
best task design to collect relevance judgements (Section 7). We
add a discussion on the relation among the features we take into
consideration and on the comparison between hierarchy based and
context-aware methods for ranking entity types (Section 9).

The rest of the paper is structured as follows. We start below
by describing related work from entity-search and ad-hoc object
retrieval. Then, we introduce the most important concepts in

the Web of Data (Section 3) to formally define our new type
ranking task in Section 4. In Section 5 we present the architecture
of our system, and in Section 6 propose a series of approaches
to solve it based on collection statistics, type hierarchies, and
entity graphs. Section 8 presents experimental results comparing
the effectiveness of our various entity ranking approaches over
different document collections and type hierarchies as well as a
scalability validation of our Map/Reduce implementation over a
large corpus. Finally, we conclude in Section 10.

2. Related work

Entity-centric data management is a re-emerging area of
research at the overlap of several fields including Databases,
Information Retrieval, and the Semantic Web. In this paper we
target the specific problem of assigning types to entities that have
been extracted from a Web page and correctly identified in a preexisting knowledge graph.
Named Entity Recognition and Ranking. Classic approaches to
Named Entity Recognition (NER) typically provide as output some
type information about the identified entities; In most cases, such
types consist of a very limited set of entities including Person,
Location, and Organization (see e.g., [6,7]). While this is useful for
applications that need to focus on one of those generic types, for
other applications such as entity-based faceted search it would be
much more valuable to provide specific types that are also relevant
to the users browsing context.

In the field of Information Retrieval, entity ranking has been
studied for a few years. Historically, the first entity-oriented task
being addressed was expert finding [8] where the focus is on one
specific entity type, that is, people. The goal is to find people who
are knowledgeable about the requested topic. After this, works
have looked at how to search for multiple entity types. Early
approaches on entity ranking focused on entities of different types
which are present in Wikipedia [9,10]. In the IR context, TREC5
organized an Entity Track where different entity-centric search
tasks have been studied: Four entity types were considered in
that context, i.e., people, products, organizations, and locations.
Type information can also be used for entity search tasks, e.g., by
matching the types of the entities in the query to the types of
the retrieved entities (see for instance [11]). Moreover, the IR
community has organized workshops on entity search topics at the
major research venue [12,13].

More recently, we have proposed a hybrid approach to rank
entity identifiers as answer to a Web search query [3]. We used
both standard IR methods based on inverted indexes as well as a
structured search approach that exploits the graph structure (also
including type information) connecting entities among each other
to improve search effectiveness. In [14] the authors show how the
number of entities used for the graph-based search step influences
search effectiveness. Related to this is the aggregation of all data
available about a specific entity [15], also including its types.

In the NLP field, entity extraction methods are continuously
being developed. Here also, the types that are considered are
typically rather limited. For example, in the method proposed
in [16] 18 types are considered. In [17,18], authors propose a NER
system to recognize 100 entity types using a supervised approach.
The starting point to define the 100 entity types is the BBN
linguistic collection6 which includes 12 top types and 64 subtypes.
Entity types. The Semantic Web community has been creating
large-scale knowledge graphs defining a multitude of entity types.

2 http://commoncrawl.org/.
3 https://github.com/MEM0R1ES/TRank.
4 http://trank.exascale.info.

5 http://trec.nist.gov.
6 http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2005T33.

A. Tonon et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 170183

Efforts such as YAGO [4] have assigned to LOD entities many
types by combining Wikipedia categories and WordNet senses.
More recently, projects such as DBpedia [19] and Freebase [20]
have collected large collections of structured representations of
entities along with their related types. Such knowledge graphs
hence represent extremely valuable resources when working on
entity type ranking as we do in this paper.

An early work about ranking entity types is [21] where authors
propose a method to select the best type of the result for a Web
search query. Similarly, in [22] authors propose methods to select
the best type given a query by exploiting the type hierarchy from
a background knowledge graph. As compared to this, we aim to
rank types assigned to entities mentioned on the Web and (as
pointed out in [22] as particularly challenging) to select the right
granularity of types from the background type hierarchy.

In a recent demo [23], the task of selecting the most relevant
types used to summarize an entity has been proposed. However,
the focus of this work was on generating an entity description of
a given size, while our focus is to select the most relevant types
given the context in which the entity is described. Similarly to
that work, we build our approaches using large knowledge graphs
such as YAGO and DBpedia. In Tipalo [24], the authors propose an
algorithm to extract entity types based on the natural language
description of the entity taken from Wikipedia. PEARL [25] is an
approach that selects the most appropriate type for an entity by
leveraging a background textual corpus of co-occurring entities
and performing fuzzy pattern matching for new entities. We also
rely on a background n-gram corpus to compute type probabilities
(see Section 6.4), however, the task the authors tackle is different
from ours: while their goal is to find the correct type of emerging
entities (that is, entities not yet present in a knowledge graph),
we rank the types of entities already contained in the knowledge
graph, assuming they are correct. Yao et al. also worked on
extracting entity types from text [26]; However, contrary to our
case, their approach is not bound to a fixed ontology and extracts
entity types coming from textual surface-form expressions (for
example, Jan Zamoyski, a magnate) without linking them to any
knowledge graph.
Related applications. Several applications of our techniques could
be based on existing work. For instance, entity-type ranking
could be applied on open-domain Question Answering [27],
where candidate answers are first generated and later on filtered based on the expected answer types. For systems like
Watson [28], identifying specific and relevant entity types could
potentially significantly improve effectiveness. Another application depending on high-quality entity types is entity resolution
over datasets of different entity types. In [29], the authors evaluate their approach on top of four entity types (that is, persons,
addresses, schools, and jobs). The availability of more specific entity types would probably be beneficial for this type of task as
well.

3. The knowledge graph

The task we address in this paper is based on the Linked Open
Data (LOD) cloud.7 This is a large collections of datasets describing
entities in structured format. Popular datasets in LOD include
DBpedia, Freebase, and GeoNames.

Each entity in these datasets is uniquely identified by an
http URI and is described by means of RDF triples, that is,
factual statements including a subject (i.e., an entity URI), a
predicate, and an object. Predicates are taken from a predefined

schema (i.e., an ontology) and objects may be either other entity
URIs (e.g., URI1 is_married_to URI2) or textual elements (e.g.,
URI1 has_name John Doe).

In this work we focus on a specific set of predicates in LOD
datasets that indicate entity type information. In detail, we look
at the object values of the set of triples containing as subject the
target entity URI and as predicate one of those indicating type
information. Such set of objects represents all correct types of the
target entity. The task we address in this paper is to produce a
ranked list of correct types with the goal of ranking first the most
relevant types for the entity also based on the textual context
where the entity appears.

4. Task definition

Given a knowledge graph containing semi-structured descriptions of entities and their types, we define the task of entity type
ranking for a given entity e appearing in a document d as the task
of ranking all the types Te = {t1, . . . , tn} associated to e based on
their relevance to its textual context ce from d. In RDFS/OWL, the
set Te is typically given by the objects that are related to the URI of
e via the <rdfs:type> predicate. Moreover, we take into consideration entities connected to e via a <owl:sameAs> to URIs
of other selected ontologies and we add to Te all the types directly attached to them. For example, <dp:Tom_Cruise>8 has
an <owl:sameAs> connection to <fb:Tom_Cruise> which
allows us to add the new type <fb:fashionmodels>.

The context ce of an entity e is defined as textual content
surrounding the entity taken from the document d in which e
is mentioned. This context can have a direct influence on the
rankings. For example, the entity Barack Obama can be mentioned
in a Gulf War context or in a golf tournament context. The most
relevant type for Barack Obama shall probably be different given
one or the other context. The different context types we consider
in this paper are: (i) three paragraphs around the entity reference
(one paragraph preceding, one following, and the paragraph
containing the entity); (ii) one paragraph only, containing the
entity mention; (iii) the sentence containing the entity reference;
and (iv) the entity mention itself with no further textual context.
To rank the types by their relevance given a context, we exploit
hierarchies of entity types. In RDFS/OWL, a type hierarchy is
typically defined based on the predicate <rdfs:subClassOf>.
For example, in DBpedia we observe that <dp:Politician>
is a subclass of <dp:Person>. Knowing the relations among
types and their depth in the hierarchy is often helpful when
automatically ranking entity types. For example, given a type
hierarchy related to a specific entity, we might prefer a more
specific type rather than a too general one.

We evaluate the quality of a given ranking (ti, . . . , tj) by using
ground truth relevance judgements assessing which types are most
relevant to an entity e given a context ce. We discuss rank-based
evaluation metrics in Section 8.
5. TRank++ system architecture

Our solution, TRank++, automatically selects the most appropriate entity types for an entity given its context and type infor-
mation. TRank++ implements several components to extract entities and automatically determine relevant types. First, given a Web
page (e.g., a news article), we identify entities mentioned in the

7 http://linkeddata.org.

8 In the rest of this article we refer to DBpedia resources with the namespace dp,
to DBpedia ontology entries with dpo, and to Freebase resources with fb.

Fig. 1. The TRank++ architecture.

Fig. 2. The integrated type hierarchy.

textual content of the document using state-of-the-art NER focusing on persons, locations, and organizations. Next, we use an inverted index constructed over DBpedia literals attached to entity
URIs, and use the extracted entity mention as a query to the index to select the best-matching URI for that entity.9 Then, given an
entity URI we retrieve (for example, thanks to a SPARQL query to a
knowledge graph) all the types attached to it. In this way, we obtain
types such as <owl:Thing>, <dpo:EFF_Pioneer_Award_
recipients> and <dpo:English_bloggers> for the entity
<dp:Tim_Berners-Lee>. Finally, our system produces a ranking of the resulting types based on evidences computed by using
different methods exploiting the textual context where the entity
is mentioned. A summary of the different steps involved in is depicted in Fig. 1.

We briefly describe the entity extraction and entity linking
components below. The focus of the rest of this paper will then be
on the definition and experimental comparison of different ranking
functions for entity types.
Entity extraction. The first component of the TRank++ pipeline
takes as input a document collection and performs NER, that is,
the identification of entity mentions in the text. Entities that can
be accurately identified are persons, locations, and organizations.
The current implementation of our system adopts a Conditional
Random Field approach to identify entities [31].
Entity linking. The following step is entity linking, which aims at
assigning a URI to an entity mention identified in the previous step.
The goal is to disambiguate an entity (e.g., Michael Jordan) by
uniquely identifying it (e.g., the former NBA basketball player). In
order to obtain a URI for the entity, we rank candidate URIs from
DBPedia 3.8 using an inverted index by TFIDF similarity on the
label. Note that the focus of this paper is not on improving the

9 This is the same baseline approach used in [30] for Entity Linking.

state-of-the-art in named entity recognition or linking, thus we
apply existing approaches for these steps.
Integrating different type hierarchies. For the purpose of our task,
we require a large, integrated collection of entity types to enable
fine-grained typing of entities. There are several large ontologies
available, both manually constructed [32] as well as based on
the widespread success of Wikipedia combined with information
extraction algorithms [19,4]. However, the lack of alignment
among such ontologies hinders the ability of comparing types
belonging to different collections.
In TRank++, we exploit pre-existing mappings provided by
DBpedia and PARIS [33] to build a coherent tree of 447,260 types,
rooted on <owl:Thing> and with a max depth of 19. The tree
is formed by all the <rdfs:subClassOf> relationships among
DBpedia, YAGO and schema.org types. To eliminate cycles and
to enhance coverage, we exploit <owl:equivalentClass> to
create <rdfs:subClassOf> edges pointing to the parent class
(in case one of the two classes does not have a direct parent).
Considering that the probabilistic approach employed by PARIS
does not provide a complete mapping between DBpedia and
Yago types, we have manually added 4 <rdfs:subClassOf>
relationships (reviewed by 4 domain experts) to obtain a single
type tree (rather than a forest of 5 trees).10 Fig. 2 shows a
visual representation of the integrated type hierarchy used by
TRank++.
Entity type retrieval and ranking. Finally, given the entity URI we
retrieve all its types (from a background RDF corpus or from a previously created inverted index) and rank them given a context. In
this paper, we use the Sindice-2011 RDF dataset11 [34] to retrieve
the types, which consists of about 11 billion RDF triples.

10 The such created type hierarchy is available in the form of a small inverted index
that provides for each type the path to the root and its depth in the hierarchy at
http://exascale.info/TRank.
11 http://data.sindice.com/trec2011/.

A. Tonon et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 170183

SELECT ?x
WHERE { ?x <dpo:wikilink> <e> .

?x <rdfs:type> <t_i>

For example, in Fig. 3(a) to rank types for the entity e we exploit the
fact that linked entities have also the type Actor to rank it first.

In a similar way, we exploit the knowledge graph by following
<owl:sameAs> connections and observing the types attached to
such URIs (SAMEAS):

SELECT ?x
WHERE { <e> <owl:sameAs> ?x .
?x <rdfs:type> <t_i>

Our next approach (LABEL) adopts text similarity methods. We
consider the label of e and measure its TFIDF similarity with other
labels appearing in the background knowledge graph in order to
find related entities.12 At this point, we inspect the types of the
most related entities to rank the types of e. More specifically, we
select the top-10 entities having the most similar labels to e and
rank types based on the frequency of ti  Te for those entities.

6.2. Hierarchy-based ranking approaches

Fig. 3.

(a) Entity-centric (b) Context-aware (c) Hierarchy-based type ranking.

6. Approaches to entity type ranking

The proposed approaches for entity type ranking can be
grouped in entity-centric, context-aware, and hierarchy-based.
Fig. 3 shows on which data such approaches are based. The
entity-centric approaches look at the relation of the entity e with
other entities in a background knowledge graph following edges
such as <dpo:wikiLink> and <owl:sameAs>. Context-aware
approaches exploit the co-occurrence of the entity e with other
entities in the same textual context. Hierarchy-based approaches
look at the structure of the type hierarchy and rank types of e based
on that. Finally, mixed approaches combine evidences of relevance
coming from all kinds of methods.

6.1. Entity-centric ranking approaches

We now turn to the description of several techniques to rank
entity types. The first group of approaches we describe only
considers background information about a given entity and its
types without taking into account the context in which the entity
appears.

Our first basic approach (FREQ) to rank entity types is
based solely on the frequency of those types in the background
knowledge graph ranking first the most frequent type of an entity.
For example, the type Person has a higher frequency (and thus is
more popular) than EnglishBlogger.

Our second approach (WIKILINK) exploits the relations existing
between the given entity and further entities in the background
knowledge graph. Hence, we count the number of neighboring
entities that share the same type. This can be for example be
performed by issuing the following SPARQL queries retrieving
connected entities from/to e:

SELECT ?x
WHERE { <e> <dpo:wikilink> ?x .

?x <rdfs:type> <t_i>

The more complex techniques described below make use of the
type hierarchy and measure the depth of an entity type ti attached
to e in order to assess its relevance. We define the DEPTH ranking
score of a type ti as the depth of ti in the type hierarchy. This
approach favors types that are more specific (i.e., deeper in the type
hierarchy).

In some cases, the depth of an entity type in the hierarchy may
not be enough. To detect the most relevant entity types, it might
also be useful to determine the branch in the type hierarchy where
the most compelling entity types are defined. In that context, we
define a method (ANCESTORS) that takes into consideration how
many ancestors of ti  Te are also type of e. That is, if Ancestors(ti)
is the set of ancestors of ti in the type hierarchy, then we define the
score of ti as the size of the set {tj|tj  Ancestors(ti)  tj  Te}. For
example, in Fig. 3(c) we rank first the type Actor because Person
is its ancestor and it is also a type of e. On the other hand, the
type Humanitarian Foundation has a bigger depth but no ancestor
which is also a type of e.

A variant of this approach (ANC_DEPTH) considers not just the

number of such ancestors of ti but also their depth. Thus,

depth(tj).

(1)

ANC_DEPTH(ti) = 

tjAncestor(ti)tjTe

6.3. Entity-based context-aware ranking approaches

We describe approaches leveraging the entity context below.
A first approach (SAMETYPE) taking into account the context ce in
which e appears is based on counting how many times each type
ti  Te appears in the co-occurring entities e  ce also mentioned
in the context. In this case, we consider a match whenever the same
type URI is used by e and e, or when the type of e has the same
label as the type from e. For example, in Fig. 3(b) we rank first the
type Actor for the entity e because it co-occurs with other entities
of type Actor in the same context.

12 This can be efficiently performed by means of an inverted index over entity
labels.

A slightly more complex approach (PATH) leverages both the
type hierarchy and the context in which e appears. Given all entities appearing in the context e  ce, the approach measures
how similar the types are based on the type hierarchy. We measure the degree of similarity by taking the intersection between the
paths from the root of the type hierarchy (i.e., <owl:Thing>) to
ti  Te and to tj  Te. For instance, when ranking types for the
entity Tom Hanks in a context where also Tom Cruise ap-
pears, we measure the similarity between the types by considering the common paths between the root of the type hierarchy
and both types, e.g., Thing-Agent-Person-Artist-Actor-American
TelevisionActors and Thing-Agent-Person-Artist-Actor-Actors
FromNewJersey would be considered as highly similar. On the
other hand, the Tom Hanks type path Thing-PhysicalEntity-
CausalAgent-Person-Intellectual-Scholar-Alumnus-CaliforniaState
University, SacramentoAlumni is not very similar with the previous Tom Cruise path. Hence, the approach ranks the AmericanTelevisionActors type higher given the context in which it appears.

6.4. Text-based context-aware approaches

We now propose two context-aware approaches that exploit
the textual context in which the considered entities appear.
Formally, we want to rank the types of an entity e, appearing in
a window of text (wk, wk+1, . . . , w0 = e, w1, . . . , wk), where
e is a mention of the entity occurring inside the window. In this
method, we rank types according to the probability of seeing an
entity of type t given the tokens wk, wk+1,..., w1, w1,..., wk.

We use the text of the Wikipedia Webpages in order to compute
relevant statistics for type ranking. More precisely, we extend the
user-annotated entities by using a state-of-the-art entity linking
method: DBpedia Spotlight [35]. All the linked entities are then
substituted by special tokens containing their entity types. For
example, if we suppose that an entity e having types t0 and t1
appears in a certain window of text  w, we replicate twice  w
where the first time we replace the entity with t0, and the second
time with t1. The resulting sequence of tokens is finally split
into n-grams, and aggregated counts are calculated. Formally, we
compute the probability of an entity type t given a window of text
 w by averaging the probability of finding an entity of type t in each
individual n-gram we can extract from  w. The probability of a type
t given an n-gram ng is computed as shown in Eq. (2), where T is
the set of all considered types.

Pr(t | ng) = Count(t | ng)
Count(tj | ng)


jT


(that is, we take two tokens before an entity type, and two tokens
after the entity type).

NGramScore(t | ng)

Score(t,  w) =

ngNGrams(  w)

|NGrams(  w)|

(3)

As one can notice, NGRAMS0 always prioritizes coarser types. In
order to mitigate this phenomenon, we devise a method drawing
inspiration from our recent work [37]. Our second text-based
context-aware approach, NGRAMS1, models the probability of
seeing an instance of a certain entity type given a window of text
as a flow crossing the type hierarchy starting from the root (with
probability 1) and descending the tree until either a leaf is reached
or the flow of probability is broken (that is, we reach a node that
does not transmit any probability to its children). Additionally, in
order to avoid cases in which deeper or coarser types are always
prioritized, when computing the score of an entity type we take
into consideration the entropy of its childrens probabilities, and
that of its siblings probabilities, too. For example, suppose that the
probability that flowed to dpo:Actor is scattered almost equally
among all its 465 children. In this case dpo:Actor should be
prioritized as it is more informative than each of its children.
The main idea supporting this decision is the fact that when the
probability mass of the current type in the hierarchy is scattered
among many of its children, this can give us clues about how
the current type should be ranked with respect to its children. In
Section 9, we give more details on the relation between entropy,
number of children, and relevance.

Despite using the same concepts, we cannot directly apply
the algorithm we proposed in our previous work since it was
designed to return only one type. What we propose instead is a
generalization of this approach using the probability of the current
node and the entropy of its children as features to assign a score to
an entity type. This is appropriate in our context as we can exploit
the labeled data of our testset (see Section 7 for more information).
Specifically, we use a decision tree [38] to assign a score to the
current type, given a certain window of text, by exploiting the
following features:
1. NGRAMS0, the score of the NGRAMS0 method, playing the role

of the type probability;

2. ratioParent, the ratio between the current type probability

and the probability of its parent;

3. nChildren, the number of children to which some probability

mass flows;

4. hChildren, the entropy of the probabilities of the children;
5. nSiblings, the number of siblings of the current node having

6. hSiblings, the entropy of the probabilities of the siblings.

(2)

some probability mass;

It is worth noting that, since every entity is an instance of the most
general type, the probability of <owl:Thing> given any text is
always 1. Unfortunately, as a consequence of the sparsity of natural
language data, we do not always have evidence of the occurrence
of all considered types, given a certain textual context. This is
exacerbated when the knowledge graph taken into consideration
contains many entity types. We address this issue using a popular
technique from statistical machine translation known as Stupid
Back-off smoothing [36], in which we fall back to estimating the
probability using (n  1)-grams if the original n-gram is not
contained in our background corpus. For unigrams, the probability
estimate is the probability of the given type.

Finally, the score that our first text-based context-aware
approach (NGRAMS0) assigns to a DBpedia type given a window of
text  w is computed as shown in Eq. (3). NGrams(  w, n) is a function
returning all the n-grams composing w. During our experimental
evaluation, we fix the length of the textual context  w to 5 tokens

Section 8 gives more technical details and reports on the
evaluation of NGRAMS0 and NGRAMS1; in addition, the relation
between the features we selected and relevance is discussed in
Section 9.

6.5. Mixed approaches

Below, we report on techniques that exploit several features to

rank entity types.
Mixing evidence from type hierarchy and knowledge base. The first
technique we propose, KB-HIER, uses decision trees [38] to combine features that come from the entity whose types are ranked,
from the type hierarchy and from the knowledge base. The features
we consider in that context are:
1. popularity of the entity in the knowledge base, measured by
computing the number of triples with the given entity as the
subject.

A. Tonon et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 170183

2. nTypes, that is, the number of types connected to the entity.
3. nChildren, typeDepth, nSiblings, the number of chil-
dren, depth in the type hierarchy, and number of siblings of the
entity type taken into consideration.

We focus on the interplay among those features as we believe that
it is the most interesting aspect of this approach.
Learning to rank entity types. Finally, since TRank++ ranking
approaches cover fairly different types of evidences (based on
the entity-graph, the context, or the type hierarchy) to assess the
relevance of a type, we also propose to combine our different
techniques by determining the best potential combinations using
a training set, as it is commonly carried out by commercial search
engines to decide how to rank Web pages (see for example [39]).
Specifically, we use decision trees [40] and linear regression
models to combine the ranking techniques described above into
new ranking functions. The decision tree method we used is
M5 [41], which is specifically designed for regression problems.

The effectiveness of these two approaches is discussed in
Section 8, while in Section 9 we discuss the relations between the
various features we use.

6.6. Scalable entity type ranking with MapReduce

Ranking types using the above methods for all the entities
identified in a large-scale corpus using a single machine and
SPARQL end-points is impractical, given the latency introduced
by the end-point and the intrinsic performance limitations of a
single node. Instead, we propose a self-sufficient and scalable
Map/Reduce architecture for TRank++, which does not require
to query any SPARQL end-point and which pre-computes and
distributes inverted indexes across the worker nodes to guarantee
fast lookups and ranking of entity type. More specifically, we build
an inverted index over the DBpedia 3.8 entity labels for the entity
linking step and an inverted index over the integrated TRank++
type hierarchy which provides, for each type URI, its depth in
the type hierarchy and the path to the root of the hierarchy. This
enables a fast computation of the hierarchy-based type ranking
methods proposed in Section 6.2.

7. Crowdsourced relevance judgements

To create the ground truth judgements for the best types
to be selected for an entity given a context we used paid
crowdsourcing.13 We decided to ask anonymous Web users rather
than creating the ground truth ourself as they are a real sample
of Web users who could benefit from the envisioned application.
Each task, which was assigned to 3 different workers from the US,
consists of asking the most relevant type for 5 different entities,
and was paid $0.10 for entities without context and $0.15 for
entities with context. Additionally, we allowed the workers to
annotate the entity as an error which could have happened either
at the extraction or linking level, and to add an additional type
if the proposed ones were not satisfactory. Overall, the relevance
judgement creation costed $190.

13 We run our tasks over the Amazon MTurk platform. The collected data and task
designs are available for others to reuse at http://exascale.info/TRank.

Table 1
Agreement rate among crowd assessors during the evaluation of the four
test collections.

Collection
Entity-only
Sentence
Paragraph
3-paragraphs

Fleiss 

7.1. Pilot study

In order to better understand how to obtain accurate relevance
judgements from the crowd, we ran a pilot study where we
compared three different task designs for the entity type relevance
judgement. In order to compare our task designs, we assigned each
different task to 10 workers for a total of 30 requests and a budget
of $6. The workers were requested to read a paragraph of text and
rank the types of 6 entities having, on average, 11 entity types each.
Two of the task designs we analyzed are based on the interface
depicted in Fig. 4 (left) but differ from the fact that in one the
workers could select multiple relevant types, while in the other
they could only select one relevant type (they had to explicitly
mark all the other types as irrelevant). The rationale behind this
choice was that having to express an opinion for each entity type
forces the worker to read all the type label, thus, reducing spam
(i.e., random selection of one type). The high frequency of yes
we recorded in the first task design (6.76 on average) led us to
understand that the workers misinterpreted the crowdsourced
task and signaled as relevant all the types that they know are
correct for the entity displayed (which was not the goal as clearly
explained in the task instructions), while the second task design
was not popular among the workers due to the high number of
clicks it required (only 7 workers out of 10 completed the task),
leading to potentially long delays to obtain judgements for all
our datasets.14 Finally, the interface of the third task design we
considered is similar to the one shown in Fig. 4 (right). In this case,
the users were still allowed to select only one relevant type for each
entity displayed, but only one click was needed to complete the
task.

Given the results of the pilot study, we selected our last task
design to generate the relevance judgements in our datasets since
it also simulates our target use case of showing one single entity
type to a user browsing the Web. Table 1 lists the inter-rater
agreement among workers in terms of Fleiss k computed on the
final relevance judgements for each test collection we made. We
observe that agreement increases with an increasing degree of
context. We argue that the context helps the worker in selecting
the right type for the entity; without much context, the worker
is prone to subjective interpretation of the entity, that is, he/she
associates to the entity the type that is the most relevant based on
his/her background knowledge.

8. Experiments

8.1. Experimental setting

We have created a ground truth of entity types mentioned in
128 news articles selected from the top news of each category

14 During the pilot study we monitored the main web forums (e.g., http://www/
mturkforum.com) where crowd workers exchange information about tasks and we
noticed that this task design was criticized as using mega-bubbles, a neologism
used to describe the presence of numerous radio buttons that must be clicked to
complete the task.

Fig. 4. Task design (left) and final version of the interface used by the crowd to generate relevance judgements for entity types (right).

from the New York Times website during the period 21 Feb7 Mar
2013. On average, each article contains 12 entities. After the entity
linking step, each entity is associated to an average of 10.2 types in
our Linked Data collection. We crowdsourced the selection of the
most relevant types by asking workers which types are the most
relevant given a specific textual context. To generate our ground
truth out of the crowdsourcing results we consider relevant each
type which has been selected by at least one worker to obtain
binary judgements, and we consider the number of workers who
selected the type as its relevance score in a graded relevance
setting.
Evaluation measures. As main evaluation measure for comparing
different entity type ranking methods we use Mean Average
Precision (MAP). Average Precision (AP) for the types Te of an entity
e is defined as


tiTe

rel(ti)  P@i
|Rel(Te)|

AP(Te) =

(4)

where rel(ti) is 1 if ti is a relevant type for the entity e and
0 otherwise, Rel(Te) is the set of relevant types for e, and P@i
indicates Precision at cutoff i. MAP is defined as the mean of AP over
all entities in the collection. MAP is a standard evaluation measure
for ranking tasks which considers binary relevance: A type ti is
either correct or wrong for an entity e.

Since the original relevance judgements are not binary
(i.e., more than one worker can vote for a type and thus have
a higher relevance value than a type with just one vote), we
also measure Normalize Discounted Cumulative Gain (NDCG) [42]
which is a standard evaluation measure for ranking tasks with nonbinary relevance judgements. NDCG is defined based on a gain

vector G, that is, a vector containing the relevance judgements at
each rank. Then, discounted cumulative gain measures the overall
gain obtained by reaching rank k putting more weight at the top of
the ranking:

G[j]/(log2(1 + j)).

(5)

DCG[k] = k

j=1

To obtain NDCG, we normalize it dividing DCG by its optimal
value obtained with the optimal gain vector which puts the most
relevant results first. This gives a measure in [0, 1] where 1 is
obtained with the best possible ranking.
types belonging to the integrated TRank++ hierarchy.

During the evaluation of our methods we only consider entity-

8.2. Dataset analysis

Out of the NYT articles we have crawled, we created four
different datasets to evaluate and compare approaches for the
entity type ranking task. First, we use a collection consisting
exclusively of entities and their types as extracted from the news
articles. This collection is composed by 770 distinct entities: out
of the original 990 extracted entities we consider only those with
at least two types to be ranked and we removed the errors in NER
and entity linking which were identified by the crowd during the
relevance judgements. Each entity has, on average, 10.2 types to be
ranked.
Sentence collection. We built a Sentence collection consisting of
all the sentences containing at least two entities. In this and the
following collections we asked the human assessor to judge the
relevance of a type in the given context (e.g., a sentence). Thus,

A. Tonon et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 170183

Table 2
Overlap of type relevance judgements run using
different entity contexts.

Context A
Sentence
Paragraph
3-paragraphs
Sentence
Sentence
Paragraph

Context B
Entity only
Entity only
Entity only
Paragraph
3-paragraphs
3-paragraphs

JudgOverlap

the assessor has to read the context and select the type that
best describes the entity given the presented text. This collection
contains 419 context elements composed of an average number of
32 words and 2.45 entities each.
Paragraph collection. We constructed a collection consisting of all
the paragraphs longer than one sentence and containing at least
two entities having more than two types. This collection contains
339 context elements composed of an average number of 66 words
and 2.72 entities each.
3-paragraphs collection. The last collection we have constructed
contains the largest context for an entity: the paragraph where
it appears together with the preceding and following paragraph
in the news article. As the paragraph collection, this collection
contains 339 context elements which are composed on average
of 165 words each. The entire context contains on average 11.8
entities which support the relevance of the entities appearing in
the mid paragraph.

We measured the similarity among relevance judgements run
displaying different entity contexts to the human judges. Specif-
ically, to compare the judgements over two contexts A and B we
measure
JudgOverlap(A, B) =

|sharedRelevant(A, B)|

min (|relevant(A)| ,|relevant(B)|)

(6)

Table 2 shows the similarity scores among judgements. We can observe that showing exclusively the entity to the human assessor
yields to somehow different judgements as compared to displaying some contextual information about the entity. No major differences can be observed among different sizes of contexts.
8.3. TRank++ effectiveness results

Evaluation over different contexts. Fig. 5 shows the evolution of MAP
and NDCG values by varying the number of types associated to an
entity. We can see that when an entity has many different types it is
more difficult to rank its types. Even for the simple approach FREQ
when few types are assigned to an entity we can obtain effective
results. On the right side of Fig. 5 we can see the robustness of DECTREE over an increasing number of types associated to the entity.
Fig. 6 shows the average effectiveness values for entities in
different sections of our NYT collection. We can see that the
most effective type ranking can be obtained on articles from
the Dealbook section which deals with merge, acquisitions, and
venture capital topics. Most challenging categories for finding the
correct entity type include Arts and Style. On the right side of Fig. 6
we can see the number of types associated to entities appearing in
a specific section of the NYT. We can see that the entities with most
types (16.9) appear in the Opinion section. The less types (8.7) are
associated to entities appearing in the Dealbook section which may
also explain the fact that their types can be ranked best.

Table 3 reports the results of the evaluation of all the methods
described in Section 6. We notice that, when we compare the
results obtained among the different collections (i.e., entity-only,
sentences, paragraph, and 3 paragraphs), the effectiveness values

Table 4
Examples of crowd-originated entity types.

Entity label

David
Glassberg

Fox

Bowie

Atlantic

Existing types
Alumnus, Resource,
Northwestern Uni.
Alumni,
US television journalists
Thing, Eukaryote
Minor league team,
Minor league sports team
Resource, Populated place

Crowd suggested type

New York City policeman

Television network

Musical artist

Ocean

European
Commission
Childress

Type of profession,
Landmark
Thing, Resource

Governmental organizations

Locality

is

the

that

obtained without context are generally higher supporting the
conclusion that the type ranking task for an entity without context
is somehow easier than when we need to consider the story in
which it is mentioned.

exploits

approach that

Among the entity centric approaches, in most of the cases
WIKILINK-OUT,
the
<dpo:wikiLink> edges, performs best. Among the contextaware approaches the NGRAMS1 method performs best while, as
expected, NGRAMS0 performs poorly, obtaining scores which are
similar to those of our baseline. Despite being conceptually sim-
ple, the hierarchy-based approaches clearly outperform most of
the other methods, showing scores similar to the most sophisticated context-aware approach. Even the simple DEPTH approach
performs effectively.

To evaluate NGRAMS1 and KB-HIER, we used 5-fold cross
validationover 4334, 6011, 5616, and 5620 data points in the four
different collections. We increased the number of splits when
evaluating the combination of all the approaches since we had
more data points: we ran 10-fold cross validation over 7884,
11,875, 11,279, and 11,240 data points. For this last approach,
out of the ranking approaches we have proposed, we selected
12 features which cover the different methodologies (i.e., entity-
centric, context-aware, and hierarchy-based) to train regression
models for entity type ranking. We can observe that the best
performing method is the one based on decision trees (DEC-
TREE), which outperforms all other approaches. KB-HIER, which
was initially designed to investigate how hierarchy-based features
interplay with features extracted from the knowledge base,
performs actually better than our linear regression approach (LIN-
REG) that combines scores coming from the other methods.
Crowd-powered entity type assignment. For some entities the
knowledge base may not contain good enough types. For example,
some entities have only <owl:Thing> and <rdfs:Resource>
attached to them. In such cases, we ask the crowd to suggest a type
for the entity they are judging. While it is not the focus of this
paper to extend existing LOD ontologies with additional schema,
we claim that this can be easily done by means of crowdsourc-
ing. Some example of crowd-originated entity types are listed in
Table 4.
8.4. TRank++ scalability

We run the MapReduce TRank++ pipeline over a sample of
CommonCrawl15 which contains schema.org annotations. At the
moment of writing this paper, CommonCrawl is formed by 177
valid crawling segments, accounting for 71 TB of compressed Web

15 http://commoncrawl.org/.

Fig. 5. MAP and NDCG of FREQ (top) and DEC-TREE (bottom) for entities with different number of types on the 3-paragraphs collection.

Fig. 6. Distribution of NDCG and MAP scores over article categories (top) and average number of types per entity over article categories (bottom).

Table 3
Type ranking effectiveness in terms of NDCG and MAP for different textual contexts.

Approach

Paragraph

0.7050*
0.7297*

WIKILINK-IN

WIKILINK-OUT

SAME-AS

SAMETYPE

NGRAMS0

NGRAMS1

ANCESTORS

ANC_DEPTH
0.5885*
KB-HIER
0.6279*
DEC-TREE
LIN-REG

* Statistically significant improvements (t-test p < 0.05) of the mixed approaches over the best ranking approach.

0.5966*
0.6535*

0.6233*
0.6618*

3-paragraphs

0.6759*
0.7003*

Entity-only

Sentence

0.6954*
0.7282*

content. We sampled uniformly 1TB of data over the 177 segments,
and kept only the HTML content with schema.org annotations.
This resulted in a corpus of 1,310,459 HTML pages, for a total of
23 GB (compressed).

Our MapReduce testbed is formed by 8 slave servers, each
with 12 cores at 2.33 GHz, 32 GB of RAM and 3 SATA disks. The
relatively small size of the 3 Lucene inverted indexes (600 MB)
used by the TRank++ pipeline allowed us to replicate the indexes
on each single server (transparently via HDFS). In this way, no
server represented a read hot-spot or, even worse, a single point
of failure-mandatory requirements for any architecture which
could be considered Web-scale ready. We argue that the good

performance of our MapReduce pipeline is majorly due to the
use of small, pre-computed inverted indexes instead of expensive
SPARQL queries.

Processing the corpus on such testbed takes 25 min on average,
that is to say each server runs the whole TRank++ pipeline on 72
documents per second. Table 5 shows a performance breakdown
for each component of the pipeline. The value reported for Type
Ranking refers to the implementation of ANCESTORS, but it is
comparable for all the other techniques presented in the paper
(except the ones based on the Learning to Rank approach, which
we did not test in MapReduce).

A. Tonon et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 170183

Table 5
Performance breakdown of the MapReduce pipeline.

Text extraction
18.9%

35.6%

Entity linking
29.5%

Type retrieval
9.8%

Type ranking
6.2%

Table 6
CommonCrawl sample statistics.

Domain

youtube.com
blogspot.com
over-blog.com
rhapsody.com
fotolog.com

% in corpus

Schema.org type

VideoObject
Product
Offer
Person
BlogPosting

% in corpus

Product

VideoObject

Schema.org Type

Table 7
Co-occurrences of Schema.org annotations with entity types.
top-3 most frequent TRank++ types
dp:GivenName
dp:Settlement
dp:Company
yago:InternetCompaniesOfTheUnitedStates
yago:PriceComparisonServices
dp:Settlement
yago:InternetCompaniesOfTheUnitedStates
yago:PriceComparisonServices
dp:Company
dp:GivenName
dp:Company
yago:FemalePornographicFilmActors
dp:GivenName
dp:Settlement
yago:StatesOfTheUnitedStates

BlogPosting

Person

Offer

The observed schema.org class distributions almost overlap

with the one previously found by [43] (see Table 6).16
Table 7 shows the most frequent entity types selected by
TRank++ for entities contained in Web pages annotated with the
top schema.org classes. We can observe how TRank++ types refer to specific entities mentioned in topic-specific pages as for ex-
ample, <yago:InternetCompaniesOfTheUnitedStates>
entities are contained in http://schema.org/Product Web pages.

Table 8 shows the entity types that most frequently co-occur
in our sample of CommonCrawl. Most frequent entity types
mentioned together are about actors.
Fig. 7 shows the diversity of entity types selected by TRank++
for Web pages annotated with different schema.org classes. We
can clearly see power low distribution where the top schema.org
classes contain very many different entity types while most of the
other have low diversity of entity types.

9. Discussion

In this section, we comment on the performance of the various
approaches we empirically evaluated. We focus particularly on the
new text-based approaches and on KB-HIER.

We begin by pointing the readers attention to the bottom part
of Fig. 8, as it illustrates where the relevant types are located in our
type hierarchy. As can be observed, most of the relevant types can
be found between the second and the fifth level of our tree, with a
remarkable peak at Type Depth = 4. We also notice that the greatest
number of leaves can be found at that depth level. This provides
a hint as of why DEPTH performs worse than other methods: as

16 More statistics can be found at http://exascale.info/TRank.

Fig. 7. Occurrences of distinct TRank++ types in CommonCrawl (log scale).

many of the relevant types have a depth of four, returning deeper
results is typically not optimal.

The upper part of the figure shows how some of the features
taken into consideration by NGRAMS1 behave. We can see that
both nSiblings and hSiblings are able to detect the peak of
relevant results at Type Depth = 4. These results suggest that
hSiblings and NGRAMS0 are good estimators of the relevance of
entity types.

As for the hChildren feature, the experimental results
depicted in Fig. 9 confirm that relevance is related to entropy.
As can be seen, nodes whose childrens entropy is lower have a
lower relevance score. Despite the interesting properties of the
metrics just described, the most predictive features for NGRAMS1
are, in order, NGRAMS0 (41%), ratioParent (15%), hSiblings
(14%), nSiblings (11%), hChildren (10%).17 Fig. 10 shows how
NGRAMS0, ratioParent and relevance relate to each other and
explains why the NGRAMS0 approach performs poorly: it can
easily detect the really few types which have the highest level of
relevance but fails in detecting irrelevant types, which are by far
more numerous. It is also interesting to notice that, on average,
the n-gram probability mass is scattered among very few nodes
at Type Depth = 5, . . . , 7, where most of the leaves are. This can
be due partly by the fact that the extension of the text window
we used is not big enough to catch the difference among deeper
types, thus not assigning any probability to types of those level, and
partly to the fact that in our testset there are fewer occurrences of
types having depth greater than 5. Finally, from Fig. 8 we postulate
that the learner possibly favored hSiblings over hChildren
because of its ability to detect the peak of relevant results occurring
at Type Depth = 4.

As for KB-HIER, surprisingly the most predictive feature
selected by the learner is nTypes (38%), followed by popularity
(20%), nSiblings (17%), nChildren (14%), and typeDepth
(11%).18 We studied the relation between nTypes, nSiblings,
and relevance. The results of our analysis are shown in Figs. 11
and 12. From the former figure we observe that, in general, with
small numbers of types to rank, those with fewer siblings are
more likely to be relevant, while as the number of types to be
ranked increases, types with fewer siblings get more relevant. The
latter figure suggests that popular entities have more types, thus
suggesting a connection between nTypes and popularity.

We conclude this section with a final remark about the
effectiveness of context-aware and context-unaware methods.

17 The reported numbers are computed on the Sentences Collection; a similar
trend was observed in the other datasets.
18 The reported numbers are computed on the Entity-only collection; a similar
trend was observed in the other datasets.

Table 8
Co-occurrences of entity types in the CommonCrawl sample.

Type

Type

yago:Actor109765278
dp:GivenName
dp:Settlement
yago:Actor109765278
dp:Person
dp:GivenName
yago:EnglishTelevisionActors
dp:GivenName
yago:StatesOfTheUnitedStates
yago:AmericanStageActors

yago:Actor109765278
dp:GivenName
dp:Settlement
yago:AmericanStageActors
yago:Actor109765278
dp:Settlement
yago:Actor109765278
yago:FirstName106337307
yago:StatesOfTheUnitedStates
yago:AmericanStageActors

Fig. 8. Distribution of NGRAMS1 features, number of leaves in the type hierarchy, and number of relevant results with varying a type depth.

Fig. 9. Relation between hChildren, hSiblings, and relevance. As can be
observed, there is an almost linear relation between hChildren and relevance.

Fig. 10. Relations between the two most predictive features of NGRAMS1 and
relevance.

We noticed that, in general, preferring deeper types has often
a positive effect on the final ranking of the types of a given
entity. This is highlighted by the high scores achieved by all
hierarchy based methods and by NGRAMS. However, there are
cases for which such a choice does not pay off and for which
context-based methods perform better. For instance, in document
P3-0146, Mali co-occurs with Paris, Greece, and Europe.

The top-3 results selected by ANCESTORS (context-unaware) are
LeastDevelopedCountries, LandlockedCountries, and FrenchspeakingCountries but they are all marked as non-relevant by
the Crowd since they were deemed too specific. In contrast,
the top-3 types selected by PATH (context-aware), namely,
PopulatedPlace,
In
this case, ANCESTORS obtained a low score since it favored the

Place, and Country, are all relevant.

A. Tonon et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 170183

the deployment of a browser plugin for contextual entity type dis-
play. An additional dimension we plan to investigate in the future
is the creation and display of supporting evidence for the selection
of the entity types. For example, a sentence or related entities may
be presented to motivate the fact that the selected type is not the
most popular type related to the entity (e.g., Tom Cruise is a vegetarian according to Freebase).
