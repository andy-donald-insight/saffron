Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 3652

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

journal homepage: www.elsevier.com/locate/websem

A rule-based agent-oriented approach for supporting
weakly-structured scientific workflows
Zhili Zhao a,, Adrian Paschke b, Ruisheng Zhang a

a School of Information Science & Engineering, Lanzhou University, 730000 Lanzhou, China
b Department of Computer Science, Freie Universitat Berlin, 14195 Berlin, Germany

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 27 June 2015
Received in revised form
21 January 2016
Accepted 29 February 2016
Available online 11 March 2016

Keywords:
Scientific workflows
Weakly-structured processes
Multi-agent systems
Logic programming
Semantic Web

Weakly-structured Scientific Workflows (WsSWFs) often contain goal-oriented tasks that are logical and
complicated, but they are vital for workflow results. They may involve interactions between multiple
participants or have complicated logic to express scientific policies and cater to dynamic execution
environments. In general, such WsSWFs not only need a rich process and (domain-specific) decision logic
specification, but also require a flexible execution and human interaction. In this paper, we propose a
Rule-based Agent-oriented Framework (RbAF) to support the WsSWF execution by combining rule-based
knowledge representation with agent technology. We describe workflows by messaging reaction rules,
which go beyond global Event-Condition-Action (ECA) rules and support performing complex actions
locally within certain contexts. We describe (domain-specific) decision logic in workflows by exploiting
the benefits of both Logic Programming (LP) and Description Logic (DL). Our evaluation results show that,
RbAF well supports the WsSWFs and has higher expressive power than other three considered scientific
workflow systems.

 2016 Elsevier B.V. All rights reserved.

1. Introduction

Scientific workflow has seen massive growth in recent years
as science becomes increasingly reliant on the analysis of massive data sets and the use of distributed resources [1]. They
assist scientists to perform data management, analysis and simulation of in silico experiments [2]. Compared with business workflows
which are already supported by competing specifications and Business Process Management (BPM) standards, scientific workflows
have not been widely adopted and supported yet. One significant
reason is that scientific workflows have extra requirements over
their counterparts in the business domain, such as explicit data/in-
formation flow, exact reproducibility, agility to quickly adapt to
changed knowledge and human/machine decisions, team cooperation for distributed problem solving and user friendly Graphical User Interface (GUI) tools [3,4]. To address such requirements,
existing business workflow technologies need to be thoroughly
adapted and extended [5]. Furthermore, existing solutions for business workflows as well as scientific workflows mainly focus on
structured compute-intensive and data-oriented tasks, instead of

 Corresponding author.

E-mail address: zhaozhl@lzu.edu.cn (Z. Zhao).

http://dx.doi.org/10.1016/j.websem.2016.02.002
1570-8268/ 2016 Elsevier B.V. All rights reserved.

decision-centric tasks that need the cooperation of scientists or
computer agents as a team supported by weakly-structured work-
flows.

A WsSWF is a process, in which there are complex decisioncentric tasks that require agile runtime decisions during their
execution; they may involve interactions between multiple participants or have complicated logic to express scientific policies and
cater to dynamic execution environments; they could be modeled
at a high abstract level with standard graphical workflow representation tools (e.g., Business Process Model and Notation (BPMN)),
but the inherent complex and flexible behavior during the task execution cannot be easily implemented. In the current state-of-the-
art, there are partial solutions that have been proposed for some
of the aforementioned issues, such as increasing the flexibility of
service composition [6,7], incorporating knowledge tasks and objects into workflow models [8]. Nevertheless, some core issues of
the WsSWFs are still unsolved. Compared with the structured computational scientific workflows, the WsSWFs focus on knowledgeintensive tasks and require:
 Rich process specification: the WsSWFs contain complex deci-
sion-centric tasks, which require processes to handle new and
exceptional situations. Besides simple control-flow descriptions (e.g., a task is enabled after the completion of a preceding task), it is also necessary to describe advanced process

logic, which needs dynamic recognition of operational as well
as knowledge-based states to implement intelligent routings at
runtime.
 Expressing domain-specific policies: the WsSWFs often involve
complex domain-specific policies, which regulate the behavior
of scientific applications. In order to automate the WsSWFs,
it is necessary to express such scientific policies and enable
machines to deal with them automatically.
 Flexibility: the structured processes suffer from limitations with
respect to dynamic evolution and adaptation at runtime. In
order to provide high flexibility, the WsSWFs should be allowed
to be easily modified according to individual situations.
 Human interaction: scientific workflow systems are often
designed to automate scientific processes and improve their
operational efficiency. However, human users still need to
perform manual tasks and steer the workflow execution to deal
with unforeseen problems at runtime.
 Exact reproducibility: provenance plays an important role in
verification, explanation, reproduction and informed reuse of
data used and produced by scientific workflows, especially
by the WsSWFs, which have non-deterministic decision logic
(However, provenance is a broad standalone topic and is out of
the scope of this work).
This paper mainly focuses on the execution phase of the
scientific workflow life cycle and proposes a rule-based, agentoriented framework, called RbAF, with the purpose of explicitly
supporting the WsSWF execution. On one hand, an agent-based
framework provides a flexible execution environment. On the
other hand, declarative rules provide a declarative programming
style to specify the agent behavior. The combination of them offers
a promising approach to support the WsSWFs.

The rest of this paper is organized as follows. Section 2
introduces the WsSWFs by means of two real-world use cases.
Section 3 presents the state-of-the-art on different solutions with
the purpose of improving the flexibility of both business workflows
and scientific workflows. Section 4 presents the design of the
conceptual workflow framework, RbAF. Section 5 introduces the
implementation of RbAF. Section 6 evaluates RbAF based on
control-flow and data patterns. Finally, we discuss and conclude
the work in Section 7.

2. Use cases

2.1. Treating a newly discovered ant

Fig. 1 presents a fictional but realistic process of identifying
a newly discovered ant (scientific name: formicidae). It is taken
from European Distributed Institute of Taxonomy (EDIT), which is
a network of excellence gathering 28 major institutions devoted
to knowing the living world better with the support of the
European Commission. The process involves collaboration of three
participants: fieldworker, taxonomist and curator.

The process is organized as follows. First, a fieldworker who
often works in countryside triggers the identification process.
He/She describes a newly discovered ant and then sends the ant
description to a taxonomist, who has experience and expertise
to perform the identification and treat it. Afterwards, a curator
archives the identification result. Finally, the corresponding
treatment schemes are then provided to the fieldworker. These
participants are often in different locations and collaborate on the
ant identification.

It is worth pointing out that the ant identification task itself
involves complicated domain-specific logic to distinguish an ant
from its homogeneous groups; it is represented as a sub-process
(with a + mark in the notation) in Fig. 1. The identification details
are shown as a process in Fig. 2.

Fig. 1. Process of treating a newly discovered ant.

Fig. 2. Process of ant identification.

The identification process starts with allocating the task to an
inference service acting on the taxonomist behalf in terms of the
location, where the ant is discovered. Afterwards, the ant is identified in terms of domain knowledge. Ants can differ widely in their
food requirements and behaviors, some pests even can cause a serious impact on crops. According to the Bayers ant identification
guide [9], the policies used to identify an ant include body features,
nest structure and habits (e.g., food preference). Likewise, the task
allocation and the ant treatment also need to be encoded with domain knowledge. In Fig. 2, these knowledge-intensive decisioncentric tasks are represented as rounded rectangles with small
table notations in them. There would be a case that the discovered ant is unusual and the inference service cannot identify it, this
happens because ant taxonomists may have different expertises in
a certain domain (or area). In this case, the inference service used
to identify the ant can forward the request to other services playing the same role for help. Moreover, if no service is available or
completes the identification, it might involve domain experts to
identify it manually. From a technical perspective, it is difficult to
implement this kind of knowledge-intensive decision-centric process by traditional Workflow Management System (WfMS)s.

2.2. Protein prediction result analysis

Fig. 3 shows a process used to analyze the precision of protein
prediction algorithms. Nair et al. declared that, proteins perform
most important tasks in organisms, such as catalysis of biochemical reactions, transport of nutrients, recognition and transmission
of signals [10]. In general, protein function can be thought of as,
anything that happens to or through a protein [11]. For the purpose of describing protein functions, the Gene Ontology Consortium [12] provides an ontology of protein functions based on a
dictionary of well-defined terms, also known as Gene Ontology
(GO) terms. Each GO term defines gene product properties as well
as the relationships with other terms. The protein prediction is often conducted by computational algorithms that generate one or
more GO terms indicating the functions that a protein may have.
The prediction is considered correct if the protein has some true
annotations (i.e., GO terms) that lie on a path in the gene ontology tree from the root to a leaf that visits the predicted annotation
(i.e., GO term) [13].

Z. Zhao et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 3652

Fig. 3. Protein prediction result analysis.

In order to automate the analysis task, it is necessary to check
if a target protein has some reliable GO terms that lie on a path
in the gene tree of the predicted GO term. Moreover, to improve
the robustness of the process, the workflow inputs given by users
need to be verified, i.e., the workflow inputs must be a valid
protein product ID and a valid GO term, as shown activities in
Fig. 3. These verification activities also involve decisions based
on domain knowledge and cannot be easily implemented by
traditional WfMSs.

3. Related work

With the development of the workflow technologies, more
and more efforts have been put into automating business and
scientific processes. However, workflow processes in practice
are complex and require a flexible design to represent their
process logic and decision logic. Moreover, although distributed
execution environments provide a huge amount of resources,
their uncertainty and heterogeneity also bring difficulties to an
effective workflow execution. To deal with these challenges, it is
necessary to provide not only an expressive workflow description
language, but also sophisticated mechanisms to handle dynamic
exceptions at runtime. This section surveys existing solutions with
the purpose of providing a flexible workflow composition and
supporting an adaptive workflow execution.

3.1. Agent-oriented workflow compositions

In computer science, an agent is a computer system that
is intelligent and autonomous. Communities of agents support
flexible cooperation and are usually used to solve problems that are
difficult or impossible for an individual agent to solve, also known
as a Multi-Agent System (MAS). In general, a MAS provides high
scalability and can scale via distributed process execution. With the
MAS framework, it is also possible to provide additional reasoning
intelligence inside an agent, which can be invoked by the agent as
decision procedures.

Buhler et al. [16] present an approach to specify a workflow as
a MAS, which can intelligently adapt to changing environmental
conditions. Specially, they present Business Process Execution
Language for Web Services (BPEL) that is used as a specification
language for the initial social order of a MAS. In other words, each
agent uses a passive Web service as its external behavior. Barker
et al. [6,17] capture scientific processes with Multi-Agent Protocol
(MAP), which allows typical
features of scientific workflow
requirements to be understood in terms of pure coordination
and to be executed in an agent-based, decentralized, peer-to-
peer architecture. Lam et al. state that an agent system could be
constructed to enact a set of given workflows while respecting the

Fig. 4. GO term ancestor chart.

For example, GO:0007167 is a GO term generated by a protein
prediction algorithm NetCoffee [14] to predict protein Q15653 of
human. Fig. 4 adapted from [15] shows the ancestor chart (i.e., gene
ontology tree) of GO term GO:0007167 in the context of its related
terms. The prediction is considered correct since protein Q15653
has a reliable GO term GO:0007165 (i.e., cell death) that lies on a
path in the ancestor chart of GO term GO:0007167 from the root
to a leaf (i.e., the predicted GO term GO:0007167 is a type of the
reliable GO term GO:0007165).

The process of Fig. 3 has two inputs: a protein (represented by
protein product ID) and a predicted GO term generated by a protein
prediction algorithm. It starts by retrieving GO terms associated
with the protein. This task is often done by querying Quick GO
database [15] with a protein name. The GO terms of Quick GO
are suggested by and solicited from members of the research and
annotation communities. They have evidence codes that indicate
how the description to a particular term is supported. In general,
only reliable GO terms are used to analyze the precision of protein
prediction algorithms. For example, in the analysis of protein
prediction results generated by NetCoffee, only the GO terms with
evidence codes IEA (inferred from electronic annotation) and ISS
(inferred from sequence or structural similarity) are considered as
unreliable terms [14]. The analysis process iteratively takes reliable
GO terms of the protein and checks if there is a reliable GO term
lying on a path in the gene ontology of the predicted GO term
(i.e., the predicted GO term is a type of the reliable GO term); the
analysis process terminates when one or no required reliable GO
term is found.

constraints of a given organization [18]. They use Semantic Web
languages (i.e., OWL-DL and Semantic Web Rule Language (SWRL))
to describe organizational and domain knowledge, and such
knowledge can be used by the agents to make intelligent decisions
at runtime. Moreover, they describe business organizations by
defining roles, role classification and norms together. AlfonsoCendon et al. [19] present a solution that integrates agents
into a generic architecture for context-awareness and activity
management in ambient intelligence systems. Complex decisions
and interactions in context-aware workflows are described by
multi-agent systems. The integration of MAS with workflows is
helpful in the declarative workflow description and facilitates the
definition of more complex workflows and automated reasoning
on them. Due to the limitation of centralized and hierarchical
structures of traditional process control system, Luo et al. [20]
propose an agent-based service-oriented integration architecture.
They focus on chemical process automation and employ agents
for dynamic service composition. In other words, the service
composition is directed by agents in terms of specific objectives.
Subject-oriented Business Process Management (SBPM) is a new
BPM methodology and provides a coherent procedural framework
to model an organizations business processes: its focus is the
cooperation of all stakeholders involved in the strategic, tactical,
and operational issues, sharing their knowledge in a networked
structure [21,22].

To sum up, these agent-oriented workflow composition efforts
demonstrate the advantages of agent-oriented architecture and
support flexible workflow composition from a workflow structure
perspective. They usually focus on coordination mechanisms, organizational environment modeling and norm specifications. How-
ever, most of them do not consider how to specify the internal
behavior of an agent. This is crucial if there are domain-specific
knowledge-intensive activities that are involved in a workflow.
Moreover, although there are benefits of the agent-oriented workflow composition, it loses the strengths of the centralized workflow execution, i.e., different services are composed efficiently
through a centralized flow.

3.2. Rule-based workflow languages

The rule-based approaches can also support flexible service
composition and model the process logic with declarative rule
languages. As an initial attempt on this topic, some efforts simply
combine existing standard business workflow languages with
declarative rules, i.e., separating complex decision-centric logic
from standard workflow logic in an aspect-oriented flavor. Paschke
et al. [23] propose a heterogeneous service-oriented integration
of rules (decision rules and complex event processing reaction
rules) with BPM to describe business processes. The decisioncentric activities can be semantically represented by declarative
rules and heterogeneously integrated into BPEL processes by
invoking and executing them as semantic inference services.
Choi [24] separates easily-changed business rules from main
business functions based on the aspect-oriented approach for more
efficient service system development. In the proposed approach,
variable business rules included in business processes are not
only separated from business functions, but also modularized
and maintained independently. This approach based on aspectoriented programming improves adaptability, reusability and
maintainability of business processes, and its spirit is also in line
with the approach proposed in [23]. Such approaches alleviate the
problem to some extent, but adaptations are only possible as long
as they concern the content of pre-identified business rules that fit
into the fixed workflow logic (e.g., BPEL) [25].

There are also efforts that dedicate to provide rule-based
workflow compositions. Lin et al. [26] propose a solution to

support interorganizational workflow execution based on process
agents and ECA rules. According to Lin et al., ECA rules are used
to control internal state transitions, and the process agents are
used to control external state transitions of tasks in the local
workflows [26]. Frincu et al. [7] look at scientific workflows
from a distributed system perspective and argue that the rulebased workflow composition has advantages in handling issues
with respect to scalability, failure tolerance, data integrity and
scheduling. They give an overview of typical workflow issues and
solutions, and present a simple ECA rule-based workflow language
intended for self-adaptation and auto-generation. Chen et al. [27]
also use ECA rules to realize the service composition. Besides
an ECA rule-based workflow formalization, an automatic event
composition algorithm is developed to ensure the correctness
and validness of service composition at design time. Compared
with [7], the ECA-based workflow in [27] is more sophisticated
and a graphical process modeling tool is given. Weigand et al. [25]
propose a declarative rule-driven framework FARAO for dynamic
service composition. That is, Condition Action (CA) rules describe
data dependencies between services involved in a workflow, and
each CA rule corresponds to a message sent by the orchestrator
to invoke a service. CA rules are also extended with business
rules to steer the decisions in a workflow. Compared with FARAO,
the task dependencies of scientific workflows in this paper
are described by messaging reaction rules [23,28], and domain
decision-centric policies are expressed by derivation rules that can
also access external Semantic Web data. In addition, this paper
combines agent technology with declarative rules and supports
not only structured service orchestration, but also peer-to-peer
conversation-based interactions between distributed participants.
Fernandez et al. state that,
rule-based computing models are
able to naturally express parallelism, distribution and autonomic
adaptation [29]. They see a computation as a set of chemical
reactions, which consume some molecules of data interacting
freely within a chemical solution and produce new ones (resulting
data). The proposed workflow management system can describe
a wide variety of workflow patterns both in a centralized and a
decentralized way. Compared with the service coordination driven
reaction rules, our work not only employs messaging reaction rules
to describe service interactions, but also uses derivation rules to
describe domain-specific decision logic.

Some efforts also strive to employ the MAS benefits into the
rule-based approaches. Rule Responder [30] is a framework for
specifying virtual organizations as a semantic MAS to support
collaborative teams. Human members of an organization are
assisted by autonomous rule-based agents, which use Semantic
Web rules to describe aspects of their owners derivation and
reaction logic. The solution presents a flexible and scalable
framework to accomplish complex goals and can also be seen as
a preliminary architecture of RbAF proposed in this paper.

To sum up, most existing efforts mentioned above employ ECA
rules to implement the workflow composition. ECA rules following
the form On Event If Condition Do Action provide active real-time
or just-in-time reactions to events and are right for detection
and reaction to events in dynamic computing environments.
Moreover, ECA rules are usually defined with a global scope [28]
and are suited to represent reactive systems that actively detect
or query internal and external events in a global context and
then trigger reactions. In contrast to these efforts, this paper
describes scientific workflows by messaging reaction rules, which
complement global ECA rules by describing reactive logic that is
available in certain local contexts (e.g., a workflow, conversation
protocol state or complex situation) and make it possible to
employ distributed agents to perform complex tasks. Moreover,
the combination of the process logic represented by messaging
reaction rules with the decision logic implemented in terms

Z. Zhao et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 3652

of derivation rules provides an expressive logic to describe the
WsSWFs. Compared to the classic workflow languages that provide
simple qualifying conditions, declarative rules are able to represent
complex conditional decisions, task (or goals) and reactions which
are needed in scientific workflows. However, it is worth noticing
that, although the rule-based workflow languages have advantages
in expressive workflow composition, they usually do not provide
good usability as other workflow languages supported by graphical
workflow designers.

3.3. Efforts on weakly-structured workflows

There are also few efforts trying to support complex weaklystructured workflows from different perspectives. Van Elst et al.
[31] state that weakly-structured workflows are incomplete
process models. Such workflows have exploratory knowledgeintensive activities and cannot be sufficiently modeled by classical static process models and workflows. To support these
workflows, they propose a process-oriented knowledge management approach that integrates process modeling and workflow
enactment and facilitates active information support in dynamic
changing environments. In this way, it is possible that knowledgeintensive processes are started with a partial model and are refined later during the execution. This approach can be regarded
as a variant of the standard case-based reasoning with reuse and
continuous adaptation of knowledge-intensive processes in an organization [31]. However, the knowledge-intensive tasks considered in this paper usually involve domain-specific decision logic,
and this paper describes and executes them by providing a flexible
rule-based agent-oriented framework.

[8]

Papavassiliou et al.

focus on the weakly-structured
knowledge-intensive business process modeling and present
an approach for integrating BPM and knowledge management.
They state that weakly-structured business processes are both
knowledge-intensive and weakly-structured. Such processes have
central decision steps that require personal judgement or access
to much specific information in files or forms. The sequence of processing steps of a process may vary for specific instances, and complex decisions are embedded into the processes as black boxes.
Also, they present a workflow modeling tool that can explicitly
incorporate knowledge tasks and objects into business process
models. However, their approach gives a theoretical framework to
enhance business process modeling with knowledge management
activities, and does not provide a proof-of-concept implementa-
tion.

DECLARE is a prototype of a WfMS that uses a constraint-based
process modeling language for the development of declarative
models describing loosely-structured processes [32]. DECLARE
defines constraints on the execution orders of loosely-structured
processes, which can be completed in any order that accords
with the constraints. Compared with an overspecified imperative
model,
the declarative model implicitly defines the controlflow as all possibilities that do not violate any of the given
constraints [32]. Based on Linear Temporal Logic (LTL), DECLARE
provides constraint templates to model constraints init, 1..*,
response,
responded existence and responded absence.
In addition, by combining YAWL with DECLARE, it is possible
to support
loosely-
structured and high-structured processes. In contrast to DECLARE,
which focuses on the constraint-based workflow structures, the
rule-based workflow specification of this paper focuses more
on describing the complex domain-specific decision logic and
conditional reactive logic of the WsSWFs, which determine
intelligent workflow routings at runtime. With the reactive event
messaging between distributed agents, both structured service
orchestration and peer-to-peer conversation-based interactions

large processes containing mixtures of

between distributed participants are supported. Moreover, LTL is
often used for abductive planning, while this paper focuses on the
execution of decision logic of the WsSWFs, i.e. deductive reasoning
with rules based on facts.

Case Management is another technique that can be used to deal
to non-recurrent knowledge-intensive processes [33]. Stavenko
et al. state that the case management technology focuses on
unstructured and ad-hoc business processes and allows the
modeling of cases in which a business goal
is achieved by
taking decisions in the context of documents and other content
objects [33]. With the focus on the information about the case,
dynamic case management supports not only structured tasks,
but also semi-structured and collaborative/unstructured tasks.
Minor et al. [34] present a case-based reasoning approach for
automated workflow adaptation from a different perspective.
Workflow adaptation cases describing problems and solutions are
used to adapt a workflow to changing circumstances dynamically.
As it can be noticed from the aforementioned efforts, weaklystructured processes are more complex than the structured
compute/data-intensive workflows. Existing efforts mainly focus
on declarative control-flow constraint representation and theoretical modeling, and do not consider (domain-specific) decision
logic in weakly-structured processes. Case management technique
focuses on the reuse of experience and can also be used to deal
with non-recurrent unstructured processes. However, this paper
considers the weakly-structured processes from the technical perspective and provides a rule-based workflow language not only for
flexible workflow composition, but also for expressive (domain-
specific) decision logic expression. Moreover, a distributed, multi-
agent-based execution environment is provided to support the
workflow execution.

4. Rule-based agent-oriented framework

This section presents a conceptual workflow framework, called
RbAF to support the WsSWFs. RbAF not only provides a declarative
rule-based workflow language combining messaging reaction
rules and derivation rules, but also employs multiple inference
agents as the workflow execution environment to support the
WsSWFs. On one hand, in computer science, besides the autonomy,
an agent also has abilities, like perceiving their environments
and automatically responding to changes (reactivity), starting
new actions on their own to pursue their own or given objects
(proactivity), and engaging in conversations with other agents
in cooperative ways (social ability) [35]. On the other hand,
the rule-based programming can not only describe the process
behavior in a declarative manner, but also support a compact and
comprehensive logical domain knowledge representation with
automated reasoning. One interesting application of the rulebased programming is that it can be directly used as the basis for
describing the agent behavior.

Fig. 5 shows the overall architecture of RbAF, which is
characterized as providing support to the WsSWFs in two levels:
 The workflow definition: a workflow is described via the
composition of a group of abstract tasks, each of which
describes certain scientific goal and is independent of any
specific implementation. A task can be either a primitive task
or a composite task that defines the execution order of a set of
sub-tasks (aka. a sub-workflow or sub-process).
 The workflow execution: during the workflow execution, each
abstract task is allocated to an agent, which decides on its
own to execute the task. The task execution can lead to one
or more results, and the agent may return the task results to
the original requester or send the results to other agents to
perform subsequent tasks. That is, such agents can negotiate
and collaborate with each other on performing complex tasks.

Fig. 5. Rule-based agent-oriented scientific workflow framework.

RbAF employs two main rule types to represent the WsSWFs:
messaging reaction rules and derivation rules. More precisely,
the workflow composition is described by messaging reaction
rules, which describe (abstract) processes in terms of messagedriven conversations between agents. In other words, the task
dependencies are described by the order of sending and receiving
messages between agents. Derivation rules, which are often used
for derivations of knowledge as conclusions from given knowledge,
are mainly used to describe knowledge-intensive decision-centric
steps in workflows.

For the purpose of enriching the workflow description with
semantics, an upper-level ontological workflow metadata model
(workflow ontology) is given to define general workflow concepts
and their relationships. For example, a task has inputs and outputs,
which are data; a task is performed by one or more agents which
play certain roles. The upper-level workflow ontology provides
a well-modularized schema and allows the general workflow
concepts to be further specialized with domain-specific ontologies.
With the workflow ontology, it is possible to automatically find
alternative resources (e.g., agents), thereby allowing the workflow
execution to resume if a resource is unavailable at runtime. In
addition, RbAF provides access to external Semantic Web data
(e.g., domain vocabularies and ontologies) and reduces the effort
required to achieve similar logic with declarative rules.

RbAF combines two ways of the workflow execution: orchestration and choreography. That is, a centralized workflow engine (also
an agent) takes control of the execution of a scientific workflow and
completes it via the composition of distributed agents, and the involved agents are not aware of the whole complex workflow (aka.
orchestration). Moreover, messaging reaction rules describe interactions between multiple participants, making it possible to build
choreography workflows which focus on collaboration and message
exchange between multiple participants. For example, in the use
case of ant treatment mentioned in Section 2.1, the interaction between the agents acting on fieldworker, taxonomist and curator
is maintained by the workflow engine in a centralized way. How-
ever, if an agent used to identify a newly discovered ant cannot
complete the identification, then it can forward the identification
request to other agents playing the same role for help via sending
and receiving messages. The interaction logic of such agents for the
ant identification is not centrally controlled.

Moreover, RbAF integrates human users into the WsSWFs. For
the tasks that need to be performed by human users, RbAF can
transfer the workflow control to human users who are responsible
for them (i.e, human tasks). To do so, a Human Agent (HA) manages
the life cycle of human tasks and provides a Web interface for
scientists to operate on human tasks, thereby supporting user
interaction in the workflow system.

RbAF also provides an escalated aspect-oriented, event-driven
exception handling at runtime. That is, the workflow exceptions
are usually handled separately by an Exception Handling Agent
(EHA) by replacing the failed sub-process dynamically. Once
an exception cannot be handled automatically by the EHA, the
exception can be escalated to human users to make a decision
or provide required resources. These exceptions handled by the
EHA and human users are also known as expected and unexpected
exceptions, respectively.

4.1. Declarative workflow specification

Existing efforts have shown that the control-flow dependencies
of a workflow can be described by rule-based languages, e.g., ECA
rules, which strictly follow the On Event If Condition Do Action
paradigm. ECA rules are typically defined in a global scope
and react on internal events of the reactive system, such as
changes (updates) in the active database [36,23], as shown in
Fig. 6(a). However, in a distributed environment with independent
system nodes, event processing not only requires notification
and communication mechanisms, but also needs to be done in a
local context, e.g., in a conversation or a workflow. In this paper,
RbAF describes workflow composition by messaging reaction
rules, which can not only describe (abstract) processes in terms
of message-driven conversations between multiple participants,
but also support performing complex actions locally with certain
contexts.

4.1.1. Reaction rules

Messaging reaction rules involve both receiving and sending
messages between distributed agents. This section describes how
reaction rules are used to detect external event messages.

Reaction rules are (behavioral or action) rules that react
to occurred events (external events or changed conditions) by

Z. Zhao et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 3652

(a) ECA rule-based workflows.

(b) Messaging reaction rule-based workflows.

Fig. 6. ECA rules vs. messaging reaction rules.

executing actions [37]. In RbAF, an agent follows the sense-
reason-act pattern of reaction rules and interacts with external
environment via conversation-based messaging reaction rules.

A reaction rules is a collection of reactive rules, which specify
and program reactive systems in a declarative manner, and the
most general form of a reaction rule consists of the following
parts [37]:
define reaction rule reaction_rule
on [event]
[condition]
if
then [conclusion]
do [action]
[postcondition]
after
else [elseconclusion]
elseDo [else/alternativeaction].

A reaction rule consists of parts of the event or situation
processing (e.g., detection, computation), condition verification,
action invocation and post-condition verification, where the condition and (especially) the post-condition parts are optional [37].
Depending on the parts of the general syntax, reaction rules can
be specialized into different types: derivation (deduction) rules (if-
then), production rules (if-do), trigger rules (on-do) and ECA rules
(on-if-do). More precisely, the condition and conclusion parts are
often used in derivation rules to derive new information from existing data (more details can be found in Section 4.2.1), and the
event and action parts are used in trigger rules or ECA rules to deal
with internal/external events. The elseconclusion and elseDo parts
are used to implement branching logic. They are executed if the
condition part and the event part are false, respectively. The post
part is a logical test that must be true just after the execution of
action.

In RbAF, the messages (events) passing between distributed
agents are associated with a conversation identifier to reflect the
process execution. This is crucial to keep all tasks of a process
instance running in one conversation, especially for processes that
involve the synchronization of tasks running in parallel.

The conversation identifier is also helpful to implement
advanced synchronization workflow patterns, which need to
distinguish different workflow instances. Besides the conversation
identifier, a message passing two agents also includes the following
information:

 Protocol defines the protocol of message passing.
 Sender and Receiver denote the source and destination of the
message, respectively.
 Performative describes the pragmatic context in which the
message is sent, e.g., FIPA Agent Communication Language
(ACL) [38]. The message context gives meaning to the message.
 Content denotes the payload of the message.
The action part of a reaction rules describes the procedure of
processing events (i.e., performing tasks). The actions of performing a task could be adding/retracting knowledge, variable assign-
ment, messaging activities (i.e., message sending and receiving),
and execution of (external) functions. In contrast to global ECA
rules, messaging reaction rules support performing complex actions locally within certain contexts. In other words, message sending and receiving activities can be embedded into the action part
of reaction rules to employ distributed agents to perform complex
tasks, making it possible to implement rule-based branching workflow logic and support distributed workflow execution, as shown
in Fig. 6(b).

4.1.2. Event-driven workflow execution

In RbAF, the agents act as hosts to distributed resources, and
the interactions between distributed agents are represented by
messaging reaction rules. That is, an agent receives a request
of performing a task, processes the request by using internal or
external resources, then returns the results to the requester or
sends the results to other agents to perform subsequent tasks. In
other words, the workflow execution is driven by sending and
receiving messages between agents, and thus RbAF can also be
referred to as an Event-Driven Architecture (EDA).

The event-driven RbAF is in line with the data-driven scientific
workflow execution. This is because EDA provides an appropriate
model for active data sharing based on the production and
consumption of events [39]. In RbAF, the data passing between
tasks is regarded as event messaging between agents. In other
words, the event messages carry data sharing between tasks.
Fig. 7 presents the event-driven workflow execution of an abstract
workflow. The first task Task1 of the workflow is triggered by
event e1, which carries the data required by Task1. After Task1
completes or generates required data, events e2 and e3 are sent to
trigger subsequent tasks Task2 and Task3, respectively. Task2 and

Fig. 7. Event-driven workflow execution.

Task3 run in parallel, which generate e4 and e5 to announce their
completions. The workflow completes when both Task2 and Task3
are completed.

In general, an event carries a list of primitive data types, such
as string, int and double. If the data passing between tasks is
large, a logical pointer indicating the way to access the data can be
delivered as an event. Before processing the data, the data receiver
needs to dereference the logical pointer and retrieve the actual
data identified by the logical pointer. This solution is also known
as a handle-oriented approach [40], which avoids unnecessary
transfers, especially when the workflow execution is controlled
by a third-party agent (e.g., the execution of two or more tasks is
controlled by a centralized workflow engine).

4.1.3. CEP-based workflow pattern modeling

Workflow patterns refer to recurring workflow processes. From
different perspectives, the Workflow Patterns Initiative [41] has
delivered four types of workflow patterns related to the development of workflow applications, i.e., control-flow patterns, data pat-
terns, resource patterns and exception handling patterns. This section presents how the rule-based Complex Event Processing (CEP)
technologies are used to represent the control-flow patterns.

In this paper, RbAF presents an event-driven workflow execution and models workflows by messaging reaction rules, which
specify and program reactive systems in a declarative manner. In
particular, they provide ability to reason over events, actions and
their effects, and allow detecting events and responding to them
automatically. The workflow modeling based on the event-driven
execution is also known as Event-driven Process Chains (EPCs),
which is a business process modeling language for the representation of temporal and logical dependencies between activities in
a business process [42].

Following EPCs, RbAF defines a process with a set of activities
that comprises three different types of elements connected by
control-flow edges: tasks, event messages and connectors, see Fig. 7
as an example. The tasks represent activities in a process. The
event messages are generated to trigger the task execution and the
connectors that control the flow of a process (aka. gateways). There
are three kinds of connectors: AND, XOR and OR, and they can be
used as either split (one incoming, multiple outgoing branches)
or join (multiple incoming, one outgoing branch) connectors.
Fig. 7 shows an AND split connector, which means after Task1 all
subsequent tasks Task2 and Task3 are triggered to be executed
concurrently, and an AND join connector, which means both Task2
and Task3 have to be completed.

As aforementioned, the detection of an event corresponds to
a reaction rule. An AND split connector can be implemented by
sending parallel messages and detecting them by corresponding
reaction rules later. Other complex split connectors (e.g., the XOR
split connector) can be implemented by imposing conditions on
reaction rules triggering subsequent tasks. The implementation
of the XOR split connector can be further used to implement the
Exclusive Choice pattern, which is one of the control-flow patterns
delivered by the Workflow Patterns Initiative. Similarly for the
implementation of the Multi-Choice pattern [43].

RbAF employs rule-based CEP technologies to implement the
join connectors. The rule-based CEP exploits reaction rules for

event processing and often supports situation detection, preand post-conditions, and (transactional) action logic (complex
actions) [44].
Instead of supporting the comprehensive CEP
operators of event algebras, RbAF does not impose real-time
constraint on reaction time (aka. an any-time reaction rule system),
and only supports a part of necessary CEP operators involved in
scientific workflows.

In RbAF, each composite event consisting of multiple base
events is usually described by an event pattern, which contains
event templates, relational operators and variables [45]. The
following are the relational CEP operators used by RbAF to define
complex event patterns:
 (e1e2)(t). The composite event defined by this operator occurs
when both e1 and e2 are detected; this pattern is also known as
a conjunction event pattern.
 (e1e2)(t). The composite event defined by this operator occurs
when either e1 or e2 is detected; this pattern is also known as a
disjunction event pattern.
 ANY (m, e1, e2, . . . , en)(t)(1 < m < n). The composite event
defined by this operator occurs when m events out of n are
detected.
Note that each base event ei in the complex event patterns
mentioned above could be either atomic event or composite event.
The detection of the conjunction event pattern can implement
the AND join connector, which requires all incoming branches to
be completed. The agent responsible for a subsequent task needs
to receive all base events indicating that the incoming tasks are
successfully executed. Fig. 8 shows the process of implementing
the AND join connector. Whenever a base event indicating the
completion of an incoming task occurs, it is firstly recorded as an
event fact in knowledge base and then checks if the conjunction
event pattern is detected or not. The reasoning if the conjunction
event pattern is detected is implemented by a derivation rule,
which is proved to be true when all base events are in knowledge
base. As soon as the complex event pattern is detected, the complex
event is triggered. After that, the base facts are removed from
knowledge base, as shown in Fig. 8.

Since the base event detection in this paper is event-driven,
this kind of complex event pattern detection is also known as
forward chaining event-driven reasoning. As a concrete example,
Fig. 9 shows a process of detecting a composite event e, which
requires all base events e1, e2 and e3 to be successfully proved, i.e., e
is e1e2e3. The detection of base events e1, e2, and e3 is described
by three reaction rules, as shown as follows.
define reactive rule detect_e1
on e1
do ins(e1),
define reactive rule detect_e2
on e2
do ins(e2),
define reactive rule detect_e3
on e3
do ins(e3),
check(e)  e1,
del(e1),

trigger(e),
del(e3).

e2,
e3,
del(e2),

check(e).

check(e).

check(e).

Derivation rule check(e) describes the detection of composite
event e and is evaluated whenever a base event occurs. Note that
consequent  antecedent is the basic form of derivation rules
(see Section 4.2.1 for more details). Suppose that e1 is detected
first, it is immediately recorded as an event fact in knowledge base.
Since e2, and e3 have not been detected, the execution of derivation
rule check(e) fails at the moment. The reasoning of derivation
rule check(e) for the second time is triggered when another base
event is detected. The dash lines in Fig. 9 denote that the second

Z. Zhao et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 3652

Fig. 8. Process of implementing the AND join connector.

Fig. 9. Example of an AND join connector implementation.

check(e) reasoning happens when any of e2 and e3 is detected,
rather than happens immediately. Derivation rule check(e) can only
succeed when all base events are detected, then composite event
e is triggered. After that, the base events are removed from the
knowledge base. The implementation of AND join connector can be
further used to implement the Synchronization pattern delivered by
the Workflow Patterns Initiative [43].

The detection of the disjunctive event pattern can implement
the XOR join connector. The XOR join connector can have either
local or non-local semantics [46]. The non-local XOR join connector
expects only one incoming task to be successfully executed. In
other words, the thread of control is passed to the subsequent
branch when the first task is completed, and the completion of
other tasks does not result in the thread of control being passed
on. On the contrary, the local XOR join connector propagates each
incoming process token without ever blocking. Depending on two
different situations, the non-local and local XOR join connectors
can be used to implement the Structured Discriminator pattern and
the Multiple Merge pattern delivered by the Workflow Patterns
Initiative [43], respectively.

The difference between the non-local and local XOR join
connectors lies in if the subsequent incoming branches are blocked
or not after the first incoming branch has been enabled. There
are two solutions to implement them. One solution is to control
the occurrence of a composite event. According to the occurrence
times of the composite event, the composite event can be triggered
once or more. The other solution is to control the consumption
of the composite event. The subsequent task can consume the
composite event once or multiple times. RbAF adopts the latter
to implement the XOR join connector. The implementation of
the XOR join connector has the same process as the AND join
connector, and the difference can be found in the derivation rules
that are used to detect the disjunctive event pattern, i.e., there are
multiple derivation rules used to describe different situations that
the disjunctive event pattern can be detected, one for each base
event.

The OR join connector usually has non-local semantics and
synchronizes all incoming branches that are active. In other words,

the non-local OR join connector needs to detect which branches
are still active, and which will never be active. But the detection is
usually difficult if the incoming branches involve cyclic processes
that could never be completed. RbAF addresses this issue by
attaching a timeout to the event pattern detection, which waits
for a pre-specified time and then consumes events that are there,
as shown in Fig. 10. The OR join connector is usually used to
implement the Structured Synchronizing Merge pattern delivered by
the Workflow Patterns Initiative [43].

The ANY event pattern can also be implemented in a similar way
as the XOR join connector implementation, and the only difference
can be found in the derivation rules that are used to detect the ANY
event pattern, i.e., the base events required to be detected must be
explicitly specified.

To sum up, RbAF employs the rule-based CEP technologies
to implement the control-flow patterns. Moreover, declarative
derivation rules provide ability to reason over events and make
it possible to implement advanced control-flow patterns. More
details about the workflow pattern-based evaluation can be found
in Section 6.

4.2. Domain decision-centric logic description

4.2.1. Derivation rules

Derivation rules follow an if (antecedent)-then (consequent) style
and can derive new information from existing data. They are
formulas of the form q  p, where p is antecedent specified, and q
is the conclusion deduced. The reasoning of derivation rules can be
both forward and backward (aka. forward and backward reasoning,
respectively). The forward reasoning starts with the available data
and uses inference rules to extract more data until a goal is reached.
An inference engine using forward chaining searches inference
rules until it finds one where the antecedent (if clause) is known
to be true  [47]. On the contrary, the backward reasoning starts
with a list of goals and works backwards to see if the data supports
any of these goals available. An inference engine using backward
chaining would search inference rules until it finds one which has
a consequent (then clause) that matches a desired goal [47].

Fig. 10. Process of implementing the OR join connector.

Fig. 11. Domain knowledge-intensive decision with derivation rules.

The common deductive computational model of logic programming uses the backward reasoning (goal-driven) resolution
to instantiate the program clauses via goals and uses unification to
determine the program clauses to be selected and the variables to
be substituted by terms [47]. RbAF also uses the backward reasoning to implement domain decision-centric activities, which are
usually represented as decision goals. For each decision goal, an
inference engine checks if this goal is satisfied or not. This way
of derivation is also known as backward chaining goal-driven rea-
soning. Different from the backward deductive derivation, the way
of complex event pattern detection introduced in Section 4.1.3 is
known as forward chaining event-driven reasoning. In other words,
a complex event pattern is detected as soon as base events required
for the pattern are detected.

Fig. 11 shows the derivation model adapted from [48]. The
domain logic consists of derivation rules and facts. The facts are
further classified into base facts that are given in a specific domain,
and derived facts that are created from existing ones. One can
use derivation rules and facts to drive implicit facts (i.e., the
derived facts). In RbAF, the facts describe information, including
events, (object-oriented) object instances, class individuals (of
ontology classes), constraints, states, conditions, actions, data
(e.g., relational, XML), etc. A derivation is either a mathematical
calculation that generates a derived fact according to a specified
mathematical algorithm or an inference that creates the derived
facts using logical induction.

Derivation rules focus on declarative problem representation
and go beyond typical restricted expressiveness of simple gateways in process execution models. They are more understandable
and allow domain experts to express complex scientific rules in
their own terms. Moreover, derivation rules support easy adapta-
tion, changes and extensions. Compared to imperative programs,
in which the logic is deeply buried, such declarative rules can be
easily adapted to other similar experiments.

4.2.2. Semantic web data query

Derivation rules are usually built on the facts that specify
propositions taken to be true in a domain. This section presents
how existing Semantic Web data can be reused in domain
knowledge representation.

Fig. 12. Semantic web data query.

Currently, there are many domain specific glossaries, taxonomies and Semantic Web ontologies available on the Internet
[49]. In particular, the applications of Semantic Web technologies
in life science domain have got good achievement and are one step
ahead of other research domains. Such Semantic Web data provides a common, comprehensible foundation for resources of different scientific domains, and it is wise to reuse it rather than waste
efforts to achieve similar logic by declarative rules from scratch.

Semantic Web data is usually in the form of vocabularies or on-
tologies. An ontology is an explicit specification of a conceptual-
ization, which represents a set of objects and their relations in a
domain. The vocabularies, ontologies and rules can all be employed
to represent domain-specific logic. Moreover, they are expressible
in each other to some extent. For example, derivation rules can express the concepts and relationships encoded by semantic vocabularies and ontologies, e.g., A  B in Web Ontology Language (OWL)
can be encoded as A(x)  B(x). However, although there are
overlaps between ontologies and rules, they cannot replace each
other. The ontology-based knowledge representation depends on
the expressiveness of DL. They are good at representing schema
level knowledge and even asserting the existence of unknown in-
dividuals, but they cannot specify arbitrary relationships between
instances (individuals). The rule-based knowledge representation
takes the perspective of LP and represents domain policies in a
clear logical way. However, declarative rules also have limitations,
e.g., they cannot express the existence of unknown/unnamed indi-
viduals. For the purpose of exploiting the benefits of both rules and
ontologies, there are efforts attempting to combine them as a unified logic, such as [50,51]. However, these efforts are still under the
way. Different from these efforts, RbAF adopts a lightweight solution to integrate existing Semantic Web data into declarative rules,
rather than providing domain experts with a complex unified logic.
That is, RbAF builds declarative rules on top of ontologies and enables rules to access existing Semantic Web data as external codes.
To do so, RbAF provides three ways to access domain data encoded
by Semantic Web technologies, as shown in Fig. 12.

Querying vocabularies with SPARQL. Resource Description
Framework (RDF) is a data model for the description of Web

Z. Zhao et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 3652

resources. The model denotes an RDF graph, where both data and
relationships are represented by URIs. In other words, an RDF graph
is a set of triples with a form of (subject, predicate, object). SPARQL
is the standard query language for this model. For example, the
following SPARQL query retrieves all proteins of fruit fly.

Listing 1: Example of SPARQL query
1 PREFIX up:<http :// purl.uniprot.org/core/>
2 SELECT ?protein
3 WHERE
4 {

9 }

?protein a up:Protein .
?protein up:organism ?organism .
?organism up:commonName ?name .
FILTER regex (?name , "Fruit fly", "i" )

However, SPARQL has some challenges [52]: (1) due to the open
world semantics of RDF, RDF databases are inherently incomplete;
(2) SPARQL cannot get complete answers when it queries
the vocabularies with predefined semantics (e.g., ontologies in
Resource Description Framework Schema (RDFS) or OWL); (3) the
normative SPARQL assumes that the RDF data resides in a single
repository and the queries have full access, but in reality, SPARQL
has to work at Web scale to accommodate Linked Data.

Incorporating Ontologies as Typed Rules. Compared with
RDF, RDFS is a simple ontology language that allows individuals
sharing properties to be classified into classes. The individuals
of a class are referred to as instances of that class. RDFS defines
the relationship between instances and classes with a special
URI rdf:type. For example, the triple <uniprot:Q15653 rdf:type
up:Protein> defines that Q15653 is a protein. (Note that the
namespace prefix bindings are omitted for clarity.) OWL extends
RDFS with more complex statements about individuals, classes
and properties. Both of them can describe a set of individual
objects sharing properties. However, users need to enumerate all
individuals of a class when they encode the knowledge represented
by the class with declarative rules. To overcome this problem,
RbAF incorporates domain ontologies (classes to be more precise)
as typed rules, i.e., the variables in rules can be typed with
the concepts defined in external ontologies. This solution greatly
reduces rules that need to be formulated and also improves the
flexibility and accuracy of domain knowledge representation. For
example, the inputs of the protein prediction analysis process must
be a valid protein and a valid GO term (see Section 2). However, for
a cell, there may be thousands of proteins and GO terms, and it
is impossible to validate them one by one with declarative rules.
With this solution, the only thing needed to be done is to declare
the type of two inputs as up:Protein and up:Concepts, respectively,
which are already defined in the UniProt core ontology [53].

Reasoning Ontologies with Reasoners. Besides incorporating
ontologies as typed rules, RbAF also can reason complex ontologies,
i.e., the ontologies specified by RDFS or OWL. In addition to
classes, RDFS defines restrictions on properties. For example,
rdfs:domain and rdfs:range restrict the domain of subject and the
range of object of a property, respectively. Especially, OWL further
extends RDFS with more expressiveness, including the definition of
class relations, constraints and cardinalities, equivalences between
classes, properties of properties, etc.

4.3. Human interaction

The HA manages the life cycle of human tasks. Typically the
process of performing a human task is triggered when the HA
receives a human task request on its interface from other agents.
The HA interface has an agent lifetime scope and is active while the
HA runs. Afterwards, the HA stores the tasks and sets their states as
pending. The human tasks in this paper have two statuses, namely
pending and done. They are initialized as pending when they are
received and updated to done after they are completed by human
users.

4.4. Exception handling

RbAF provides two ways to handle workflow exceptions at

runtime:

Dynamic exceptional activity replacement: the dynamic
replacement refers to treatments of an exception by dynamically
replacing an exceptional activity with an alternative owning
the same effect. Logic programming has inherent advantages
in specifying alternative execution paths in case a particular
execution path fails. Moreover, based on the workflow ontology, it
is also possible for the EHA to reallocate a task to alternative agents
with the same effect, and its successors know nothing about the
replacement. Since this strategy handles exceptions automatically,
it is also known as automatic exception handling and the exceptions
are referred to as expected exceptions.

Human interaction: Besides the expected exceptions, there
are exceptions that cannot be handled automatically by the
rule-based agents. For example, no resources available (e.g., no
agent is available to perform a task). Based on the asynchronous
user interaction, human users are allowed to handle these
exceptions by providing missing resources. Compared with the
automatic exception handling, this approach is also known manual
exception handling and the exceptions are referred to as unexpected
exceptions.

5. Proof-of-concepts

Based on the conceptual framework, RbAF, presented in Section 4, this section introduces a proof-of-concept implementation,
a Rule-based Agent Workflow System (RAWLS).

5.1. Prova

This paper employs Prova [54], both a Semantic Web rule
language and a distributed rule engine, to specify and execute
the WsSWFs. On one hand, Prova combines different rule types
and provides an expressive, hybrid, declarative and compact rule
programming language. Moreover, Prova combines imperative,
declarative and functional programming styles by using a Prolog syntax that allows calling external procedural attachments
(e.g., Java methods). Also, Prova follows the spirit of W3C Semantic Web initiative and allows using external ontologies as a type
system for declarative rules. With these combinations, Prova can
access external data sources via query languages, such as SQL,
SPARQL and XQuery. On the other hand, Prova is an economic and
efficient, JVM-based rule engine that supports the execution of
declarative decision rules, complex reaction rule-based workflows,
rule-based CEP in a runtime production environment.

RbAF allows human operations in the WsSWFs. For the tasks
that need to be performed by human users, a Human Agent
(HA) is employed to receive human task requests, process human
operations and then return the results to task requesters, as shown
in Fig. 5.

5.2. Mule ESB as communication middleware

Mule is a lightweight Java-based Enterprise Service Bus
(ESB) and integration platform that allows developers to connect
applications together quickly and easily, enabling them to

Fig. 13. Mule-based workflow architecture.

exchange data [55]. As an application integration platform, Mule
ESB allows deploying Prova agents as distributed rule inference
services and enables their coordination and cooperation. However,
for the purpose of providing an expressive, flexible workflow
specification, the interactions between Prova agents in RAWLS
are actually specified by declarative rules rather than the controlflows provided by Mule. Fig. 13 shows the Mule-based system
architecture of RAWLS.

Prova agents deployed on Mule ESB act as distributed inference
services, each of which runs a local rule base that implements reaction and decision logic of the agents. Such agents react to incoming
event messages in terms of the reaction rule-based workflow logic
and also provide access to external applications and data sources,
such as Web services, Java object representations, Semantic Web
data and relational databases. The communication between processes is implemented by the following Prova constructs of sending
and receiving one or more context-dependent event messages:

Listing 2: Prova Constructs of Messaging Reaction Rules
1 sendMsg(XID ,Protocol ,Agent ,Performative ,Payload)
2 rcvMsg(XID ,Protocol ,From ,Performative ,Payload)
3 rcvMult(XID ,Protocol ,From ,Performative ,Payload)

Here, XID is the conversation identifier of a message. Protocol
defines the communication protocol. In RAWLS, Java Message
Service (JMS) transport protocol is used for the communication
between distributed Prova agents, and Apache ActiveMQ [56],
which is an open source message broker, is used to manage JMS
messages. Agent and From denote the destination and source of
the message, respectively. Performative describes the pragmatic
context in which the message is sent. A standard nomenclature
of the performative is, e.g., the FIPA ACL [38]. Payload denotes the
actual content of the message.

The task dependencies of a workflow can be directly implemented by messaging reaction rules of Prova. There are two types
of Prova reaction rules: inline and global reaction rules. The inline
reaction rules usually locate in the body of a rule and act as its sub-
goals. They can be restricted to accept just one message, a specified number of messages, or be limited by a timeout, which can be

employed to implement the non-local XOR join connector, the local XOR join connector and the OR join connector, respectively (For
more details about such connectors, see Section 4.1.3). The semantics of global reaction rules are more aligned with message (event)-
driven reactive rules. A global reaction rule has a rule base lifetime
scope, i.e., it is active while the rule base runs on a Prova engine
(agent), and it is ready to receive any number of messages arriving
at the agent.

RAWLS employs a Web-based user client to manage workflow
applications. Users can inspect available workflows and invoke a
workflow by sending a request to the workflow engine. The user
client also hosts the HA which allows human users to perform
human tasks and deal with exceptions via the communication
with a HA proxy and the EHA, respectively. The HA proxy is also
a Prova agent that acts as an intermediary between human task
requesters and the HA. The workflow engine, the HA proxy and
the EHA are the agents that can communicate with the user client.
Besides a JMS endpoint to communicate with other Prova agents,
such agents also have an HTTP endpoint to interact with the user
client. Therefore, they are also known as public agents, and the
other agents are called internal agents, as shown in Fig. 13.

To communicate with the external user client, RAWLS employs
Reaction RuleML, the current de-facto standard language for
reactive Web rules, to represent messages passing between the
public agents and the user client. Reaction RuleML [57] is not
only a general, practical, compact and user-friendly XML-serialized
language, but also a rule interchange format for the family of
reaction rules [58,44]; it specifies knowledge in a way that is
understandable to non-computer domain experts. The translations
between Reaction RuleML and Prova messages are supported by
two translator services.

5.3. Domain logic expression in Prova

As an expressive rule language, Prova is capable of backwardreasoning logic programming to formalize decision logic in
terms of derivation rules. In particular, with the combination
of forward-directed messaging reaction rules, it is possible to
employ distributed agents to prove derivation rules. In addition,

Z. Zhao et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 3652

RbAF provides different ways of accessing domain-specific data
encoded by Semantic Web technologies and their implementation
is presented in this section.

In order to query RDF data, Prova provides SPARQL operators
based on OpenRDF Sesame [59], which is an open source Java
framework for storage and querying of RDF data. Sesame offers an
easy-to use Application Programming Interface (API) that supports
the leverage of RDF data in applications. In particular, it can run in
a standalone server mode with multiple applications connecting
to it. Based on the tight integration with Java, Prova embeds the
Sesame Java API into declarative rules and outsources storage and
querying of RDF data to a Sesame server. Such solution not only
reduces the complexity of Prova, but also improves the flexibility
of SPARQL querying. The Sesame employed by RAWLS is 2.7.9
published in December of 2013, which implements the SPARQL 1.1
specification.

Besides the SPARQL query, RAWLS also extends Prova to
implement SPARQL 1.1 Update [60], which is an extension to the
SPARQL query language. The Sesame update API is encapsulated
into Prova built-in predicate sparql_update/4. SPARQL update can
be used to update the status of Prova agents during the workflow
execution.

For the ontology reasoning, RAWLS extends Prova to incorporate SPARQL-DL query engine [61]. SPARQL-DL query language is
a subset of SPARQL and is explicitly tailored to ontology-specific
requests related to OWL; it uses SPARQL syntax and is more expressive than existing DL query languages by allowing mixed TBox,
RBox, and ABox queries [62]. Moreover, the SPARQL-DL query engine is settled on top of the OWL API and can be regarded as an
interface to every ontology reasoner supporting the OWL API [61].
In this work, RAWLS employs HermiT [63], which is a Java-based
OWL reasoner, to be a real reasoner behind the SPARQL-DL query
engine to reason domain ontologies. For example, in the use case
of protein prediction result analysis mentioned in Section 2.2, the
prediction of a protein is considered correct if the protein has some
reliable GO terms that lie on a path in the gene ontology tree from
the root to a leaf that visits the predicted GO term [13]. For each GO
term, the Gene Ontology Consortium provides an ontology to describe it and its relationships with other terms. Therefore, the protein prediction result analysis can be converted into a question: if
the predicted GO term is the subclass of any reliable GO term of the
protein, then the prediction is considered as correct. The question
can be represented as a SPARQL-DL query as follows (Lines 510).

Listing 3: SPARQL-DL Query in Prova

Onto = csw. DataProcessor .getOnto(PGOTerm),
sparqldl_create (Engine ,Onto),
element(GOTerm ,RGOTerms),
QueryString = 

1 analysis(RGOTerms ,PGOTerm ,Result ):-

PREFIX : <http :// www. geneontology.org/go#>
ASK {

askQuery(Engine ,QueryString ,Result ).

SubClassOf (: $PGOTerm ,: $RGOTerm)

13 analysis(RGOTerms ,PGOTerm ,Result ):-

Result = "no".

16 askQuery(Engine ,QueryString ,Result ):-

sparqldl_ask(Engine ,QueryString ,queryId),
sparqldl_results (queryId),
Result = "yes",
!.

22 askQuery(Engine ,QueryString ,Result ):-

Result = "no".

The SPARQL-DL query SubClassOf(:$PGOTerm, :$RGOTerm)
asks whether class PGOTerm (i.e., predicted Go term) is the subclass

of RGOTerm (i.e., reliable GO term) (Line 8). It is a TBox query
and returns true if PGOTerm is a child of RGOTerm or equivalent
to RGOTerm in the hierarchy tree. Note that Prova cannot directly
concatenate strings with variables by + operator, the variables
PGOTerm and RGOTerm are attached with $ at the beginning for
clarity.

In addition, Prova variables can be typed with concepts defined
in external ontologies. RAWLS implements the integration of
external ontologies as typed rules by the SPARQL-DL query engine.

6. Evaluation

6.1. Workflow pattern-based expressiveness evaluation

Workflow patterns are recurrent solutions in the development
of process-oriented applications. From different perspectives,
the Workflow Patterns Initiative [41] have delivered four types
of workflow patterns related to the development of workflow
applications, i.e., control-flow patterns, data patterns, resource
patterns and exception handling patterns. Such patterns are
the formal ways of describing workflow recurrent solutions
and provide a comprehensive benchmark to compare process
modeling languages. In terms of the control-flow and data patterns,
this section compares the rule-based workflow specification of
RAWLS with the workflow languages of other three prominent
scientific WfMSs: Kepler [40], Taverna [64], and Triana [65] to
evaluate the level of solving different types of tasks. Note that the
workflow patterns delivered by the Workflow Patterns Initiative
are originally for business workflows and this section only
considers the patterns that are important for scientific workflows.

6.1.1. Control-flow patterns

The Workflow Patterns Initiative [41] delivered original 20
Workflow Control-flow Patterns (WCPs) in 2003 [66]. In the latest release [43], the number of the control-flow patterns has been
increased to 43 for the purpose of describing more advanced sce-
narios. To make a clear comparison, the numbering and definition
of control-flow patterns in this section follows the Workflow Patterns Initiative.

This section does not consider the control-flow patterns that
involve cancellation and force completion of a workflow activity
(WCP-19, 20, 25, 26, 27, 29, 32, 35). This is because canceling a task
(a process) or rolling back to original states rarely happens in the
scientific workflow execution. Such workflow patterns are also not
supported by other three scientific WfMSs, i.e., Kepler, Taverna and
Triana.

The results of control-flow pattern-based evaluation are summarized in Table A.1, including the evaluation results regarding to
Kepler, Taverna and Triana from [67]. + denotes that a pattern
is directly supported. If a pattern is not supported, it is rated to
. The results show that RAWLS supports 26 patterns, which
are much more than Kepler which supports 18; Taverna which
supports 10 patterns; Triana which supports 13 patterns. To be
more specific, the rule-based workflow specification of RAWLS also
supports the basic workflow patterns (i.e., WCP-0105 in the ta-
ble) as Kepler, Taverna and Triana. With respect to the advanced
patterns, it has superiority over other three systems, especially
to advanced branching and synchronization patterns (i.e., WCP-
0609, 2833, 3738, 41, 42), state-based patterns (i.e., WCP-
1618, 3940) and trigger patterns (i.e., WCP-23 and 24). The
advanced branching and synchronization patterns characterize
more complex branching and merging concepts in workflows.
For example, Structured Discriminator (WCP-09) requires a join
connector to select one branch from two or more branches and
ignore others. None of Kepler, Taverna and Triana supports it, because they are not able to reset the join construct when exactly one

piece of data is received [67]. The state-based patterns are the ones,
in which decisions are made according to data associated with current execution, including the status of activities as well as processrelevant working data. RAWLS not only integrates human dynamic
decisions, but also provides an expressive decision logic descrip-
tion, thereby supporting the patterns WCP-16 and 18 that are not
supported by other three systems. Moreover, with the benefits of
Prova reactive event messaging, RAWLS supports two trigger pat-
terns: Transient Trigger (WCP-23) and Persistent Trigger(WCP-24).

6.1.2. Data patterns

Workflow Data Patterns (WDPs) aim to capture the various
ways in which data is represented and utilized in workflows [68].
Like the control-flow-based evaluation,
the numbering and
definition of data patterns in this section also follows the Workflow
Patterns Initiative for the clarity.

The results of data pattern-based evaluation are summarized
in Table B.2, including the evaluation results regarding to Kepler,
Taverna and Triana from [67]. + denotes that a pattern is directly
supported. If a pattern is not supported, it is rated to .

The evaluation considers all 40 data patterns delivered by
the Workflow Patterns Initiative. The results show that RAWLS
supports 33 patterns, which are much more than Kepler which
supports 19; Taverna which supports 18 patterns; Triana which
supports 19 patterns.

To be more specific, RAWLS employs messaging reaction rules
to describe the agent interactions by sending and receiving
messages, but the data local in a task or agent and the data shared
by a set of tasks cannot be defined. Therefore, the data visibility
patterns which involve data sharing between tasks or cases are
not supported (WDP-02, 03, 05, 06 and 07). Based on messaging
reaction rules, RAWLS supports all external data interaction
patterns, especially the ones which receive and respond to requests
for data elements from external environment (WDP-1725).
However, in Kepler, Taverna and Triana, since only the tasks of
a workflow can start a connection with external environment,
they are not reactive to support such patterns. Moreover, with
the agent-oriented execution framework and derivation rules,
it is possible to provide complex domain-specific preconditions
and postconditions to perform tasks, thereby supporting the
patterns WDP-3437. In addition, based on Mule ESB, two data
transformation patterns (WDP-32 and 33) are also supported by
RAWLS.

6.2. Discussion of the domain knowledge representation

RbAF exploits the benefits of both DL and LP to express (domain-
specific) decision logic in workflows, i.e., integrating existing
Semantic Web data into declarative rules (see Section 4.2). This
section evaluates the expressive power of the domain knowledge
representation in RbAF from both LP and DL perspectives in
Sections 6.2.1 and 6.2.2, respectively.

logic programs, but also supports Negation as Failure (NaF) and
provides a simple and practical formalism for expressing defaults
and exceptions, and other forms of non-monotonic reasoning.
Disjunctive normal logic programs extend normal logic programs
by adding disjunction in the rule heads. However, computing
answer sets of disjunctive normal logic programs are hard (Full
disjunctive logic programs under Stable Model Semantics (SMS)
is  1
1 -complete [69]) and there are also few solid and efficient
implementations. Extended logic programs support both NaF and
classical negation, however, the classical negation might lead to
logical conflicts between rules. Therefore, normal logic programs
have modest expressiveness to describe scientific policies and can
be regarded as general logic programs to specify (domain-specific)
decision logic in the WsSWFs.

However, there are two problems that need to be considered
when using normal logic programs: recursion-through-negation
and undecidability when using function symbols with no restrictions.
The former can be solved by checking if a logic program can
be stratified or not, and Prova can execute stratified programs
directly. Moreover, NaF is safe only when the test goal is ground.
This can be done by Prova bound built-in, which is capable of
testing if the arguments supplied to a rule are bound.

The other problem is that using function symbols in logic programs may make reasoning tasks undecidable in general cases. To
overcome this issue, there are solutions that have been proposed
to impose restrictions on the program syntax to guarantee the decidability of reasoning tasks [70]. A decidable fragment of normal
logic programs is nonrecursive logic programs [71]. However, the restriction (i.e., nonrecursive) is strong and causes a loss of expressive
power to express recursion relations. This paper follows the spirits
of  -restricted and FP2 programs [72,73] to guarantee the decidability of the decision logic in the WsSWFs. It is worth noticing that,
if a logic program is  -restricted or FP2, its reasoning is decidable.
However, not all decidable logic programs are either  -restricted or
FP2 logic programs. There are other decidable logic programs, but
they are out of the scope of this paper because they are more expressive and complicated and are not originally designed for normal logic programs.

6.2.2. DL-based knowledge representation

Domain ontologies involved in this work can be represented
in RDFS and OWL. The SPARQL-API query engine employed by
RAWLS is built on OWL API and fully aligned with the OWL 2. It
uses SPARQL syntax and is more expressive than existing DL query
languages by allowing mixed TBox, RBox and ABox queries (see
Section 5.3). Moreover, it acts as a SPARQL-DL interface to every
reasoner supporting OWL API 3, such as Pellet [74], RacerPro [75],
FaCT++ [76] and HermiT [63]. In other words, such reasoners can be
easily configured as a main ontology reasoner in terms of specific
requirements.

7. Conclusion and discussion

6.2.1. LP-based knowledge representation

Scientific knowledge representation usually involves nonmonotonic reasoning, i.e., propositions derived from a knowledge
base may be changed by adding or removing its clauses. Moreover,
scientific knowledge representation usually needs to describe
exceptions, which do not conform to general rules. Currently, there
are different types of logic programs: propositional logic programs,
Datalog logic programs, definite logic programs, stratified logic
programs, normal
logic programs, extended logic programs,
disjunctive logic programs and combinations of classes. Among
existing logic programs, the most suited for scientific knowledge
representation are normal logic programs. A normal logic program
not only inherits the expressiveness of propositional and finite

The main contribution of this paper is a rule-based, agentoriented framework that addresses the requirements of the WsS-
WFs. We provided a declarative rule-based scientific workflow
language combining messaging reaction rules and derivation rules.
With the combination of messaging reaction rules and derivation
rules, it is possible for the workflow engine to reason over events,
actions and their effects. Based on the workflow pattern-based
evaluation, RbAF shows higher expressive power than other three
considered scientific workflow systems. Moreover, we provided an
expressive (domain-specific) decision logic description combining
LP and DL: on one hand, RbAF represents domain-specific knowledge by derivation rules, which are more expressive than typical simple gateways. We employed normal logic programs, which

Z. Zhao et al. / Web Semantics: Science, Services and Agents on the World Wide Web 3738 (2016) 3652

Table A.1
Control-flow pattern-based comparison.

Control-flow Patterns
WCP-01. Sequence
WCP-02. Parallel split
WCP-03. Synchronization
WCP-04. Exclusive choice
WCP-05. Simple merge
WCP-06. Multi-choice
WCP-07. Structured synchronizing merge
WCP-08. Multi-merge
WCP-09. Structured discriminator
WCP-10. Arbitrary cycles
WCP-11. Implicit termination
WCP-12. Multiple instances without synchronization
WCP-13. Multiple instances with a priori design-time knowledge
WCP-14. Multiple instances with a priori runtime knowledge
WCP-15. Multiple instances without a priori runtime knowledge
WCP-16. Deferred choice
WCP-17. Interleaved parallel routing
WCP-18. Milestone
WCP-21. Structured loop
WCP-22. Recursion
WCP-23. Transient trigger
WCP-24. Persistent trigger
WCP-28. Blocking discriminator
WCP-30. Structured partial join
WCP-31. Blocking partial join
WCP-33. Generalized AND-join
WCP-34. Static partial join for multiple instances
WCP-36. Dynamic partial join for multiple instances
WCP-37. Local synchronizing merge
WCP-38. General synchronizing merge
WCP-39. Critical section
WCP-40. Interleaved routing
WCP-41. Thread merge
WCP-42. Thread split
WCP-43. Explicit termination

Kepler

Taverna

Triana

are more expressive than propositional and finite logic programs
to describe general (domain-specific) decision logic. On the other
hand, RbAF provides flexible ways to access domain data encoded
by Semantic Web technologies. Additionally, different exception
handling mechanisms and human interaction are supported during the workflow execution. Compared to existing workflow solu-
tions, this paper explicitly considers the WsSWFs from a technical
perspective and offers the following major features:
(i) Abstraction via a distributed multi-agent model reflecting
the semiotic structure of scientific teams in a distributed
choreography style of the workflow execution and distributed
problem-solving.

(ii) Complex decision logic via derivation rules and logical inference deductions beyond the typical restricted expressiveness
of simple gateways in process execution models.

(iii) Situation-awareness and behavioral dynamic reactions via the
rule-based CEP technologies leading to dynamic and agile
workflow reaction patterns.

(iv) Semantic workflow execution via domain models and information models represented as ontologies which are integrated
into the workflow execution semantically.

(v) Decoupled via event messages enabling asynchronous communication and parallel processing, non-deterministic execution branches of problem solving tasks in distributed agents.
(vi) Extending the range of workflow applications via combining the
benefits of both orchestration and choreography, i.e., maintaining the overall workflow execution in a centralized way,
while complex decision-centric tasks can be performed by a
group of collaborative agents sharing the same goal.

(vii) Asynchronous user interaction via the asynchronous communication enabling users to operate on manual tasks or handle
unexpected exceptions.

However, the rule-based workflow languages often suffer
from limitations with respect to usability. In general, scientific
workflows are composed by scientists themselves. They are
experts in their specific domains and are responsible for both
workflows modeling and domain decision expression. A solution
to this problem is providing graphical user interfaces to facilitate
domain experts to compose scientific workflows through dragging
and dropping workflow components. However, the flexibility and
expressive power of declarative rules are weakened in this way.
Another solution to the problem is reducing the complexity of rulebased workflow specifications by providing a powerful workflow
editor with advanced capabilities to ease the workflow definition,
such as syntax highlighting, context sensitive content assist, syntax
error indicator, code completion and template navigation. Since
this solution can keep the expressive power of declarative rules,
we will focus on improving our workflow editor by providing such
advanced capabilities in future.

Acknowledgment

This work is supported by the Fundamental Research Funds for

the Central Universities (Project No. lzujbky-2015-105).

Appendix A. Control-flow pattern-based comparison

See Table A.1.

Appendix B. Data pattern-based comparison

See Table B.2.

Table B.2
Data pattern-based comparison.

Data patterns
WDP-01. Task data
WDP-02. Block data
WDP-03. Scope data
WDP-04. Multiple instance data
WDP-05. Case data
WDP-06. Folder data
WDP-07. Workflow data
WDP-08. Environment data
WDP-09. Task to task
WDP-10. Block task to sub-workflow decomposition
WDP-11. Sub-workflow decomposition to block task
WDP-12. To multiple instance task
WDP-13. From multiple instance task
WDP-14. Case to case
WDP-15. Task to environmentpush-oriented
WDP-16. Environment to taskpull-oriented
WDP-17. Environment to taskpush-oriented
WDP-18. Task to environmentpull-oriented
WDP-19. Case to environmentpush-oriented
WDP-20. Environment to casepull-oriented
WDP-21. Environment to casepush-oriented
WDP-22. Case to environmentpull-oriented
WDP-23. Workflow to environmentpush-oriented
WDP-24. Environment to workflowpull-oriented
WDP-25. Environment to workflowpush-oriented
WDP-26. Workflow to environmentpull-oriented
WDP-27. Data transfer by valueincoming
WDP-28. Data transfer by valueoutgoing
WDP-29. Data transfercopy in/copy out
WDP-30. Data transfer by referenceunlocked
WDP-31. Data transfer by referencewith lock
WDP-32. Data transformationinput
WDP-33. Data transformationoutput
WDP-34. Task preconditiondata existence
WDP-35. Task preconditiondata value
WDP-36. Task postconditiondata existence
WDP-37. Task postconditiondata value
WDP-38. Event-based task trigger
WDP-39. Data-based task trigger
WDP-40. Data-based routing

Kepler

Taverna

