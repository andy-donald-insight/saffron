Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 1425

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

An adaptive ontology mapping approach with neural network based
constraint satisfaction
Ming Mao a,,3, Yefei Peng b,1,3, Michael Spring c,2

a SAP Labs, 3410 Hillview Ave, Palo Alto, CA 94306, USA
b Yahoo!, 701 First St, Sunnyvale, CA 94089, USA
c University of Pittsburgh, 135 N Bellefield Ave, Pittsburgh, PA 15260, USA

a r t i c l e

i n f o

a b s t r a c t

Ontology mapping seeks to find semantic correspondences between similar elements of different ontolo-
gies. It is a key challenge to achieve semantic interoperability in building the Semantic Web. This paper
proposes a new generic and adaptive ontology mapping approach, called the PRIOR+, based on propagation theory, information retrieval techniques and artificial intelligence. The approach consists of three
major modules, i.e., the IR-based similarity generator, the adaptive similarity filter and weighted similarity aggregator, and the neural network based constraint satisfaction solver. The approach first measures
both linguistic and structural similarity of ontologies in a vector space model, and then aggregates them
using an adaptive method based on their harmonies, which is defined as an estimator of performance
of similarity. Finally to improve mapping accuracy the interactive activation and competition neural
network is activated, if necessary, to search for a solution that can satisfy ontology constraints. The
experimental results show that harmony is a good estimator of f-measure; the harmony based adaptive
aggregation outperforms other aggregation methods; neural network approach significantly boosts the
performance in most cases. Our approach is competitive with top-ranked systems on benchmark tests
at OAEI campaign 2007, and performs the best on real cases in OAEI benchmark tests.

 2009 Elsevier B.V. All rights reserved.

Article history:
Received 22 January 2009
Received in revised form 3 November 2009
Accepted 12 November 2009
Available online 17 November 2009

JEL classification:
D.2.12 [Software Engineering]:
InteroperabilityData mapping
H.3.3 [Information Systems]: Information
Search and RetrievalRetrieval models
I.2.6 [Artificial Intelligence]:
LearningConnectionism and neural nets

Keywords:
Constraint satisfaction problem (CSP)
Harmony-based adaptive aggregation
Interactive activation and competition
(IAC) network
Ontology mapping
PRIOR+

1. Introduction

The World Wide Web (WWW) is widely used as a universal
medium for information exchange. Automatically exchanging data
and reusing the exchanged data in the WWW is limited due to
the heterogeneity problem existing in information resources, and
the non-semantic nature of HTML and URLs. Information heterogeneity occurs at three levels, i.e., syntax, structure and semantics
[38]. Syntactic heterogeneity is the simplest heterogeneity problem
caused by the usage of different data formats. To solve the syntactic

 This paper has been revised and extended from the authors previous work
[2325].
 Corresponding author. Tel.: +1 650 852 3868.
E-mail addresses: ming.mao@sap.com (M. Mao),

ypeng@yahoo-inc.com (Y. Peng), spring@sis.pitt.edu (M. Spring).

1 Tel.: +1 408 349 8446.
2 Tel.: +1 412 624 9429.
3 This work was done when the authors had affiliation with University of Pitts-

burgh.

1570-8268/$  see front matter  2009 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2009.11.002

heterogeneity, standardized formats such as XML,4 RDF/RDFS5 and
OWL6 have been widely used to describe data in a uniform way that
makes automatic processing of shared information easier. However
standardization cannot overcome structural heterogeneity which
occurs as a result of the way information is structured even in
homogeneous syntactic environments. For example, one source
might model trucks but only classify them into a few categories;
while the other source might make very fine-grained distinctions
between types of trucks based on their physical structure, weight,
purpose, etc. Manually encoded transformation rules as well as
some middleware components have been used to solve structural
heterogeneity problems [42]. Though sophisticated solutions to
syntactic and structural heterogeneity have been developed, the
problem of semantic heterogeneity is still only partially solved.
Semantic heterogeneity occurs whenever two contexts do not

4 http://www.w3.org/TR/2004/REC-xml-20040204.
5 http://www.w3.org/TR/rdf-schema/.
6 http://www.w3.org/TR/owl-features/.

share the same interpretation of information (e.g. homonyms and
synonyms). For example, the semantic search engine Swoogle
returns 346 documents when searching for spring.7 The top-ranked
results show that the same term has many different meanings, e.g.
one spring means the season, the other spring means the ground
water, etc. Though synonym sets, term networks, concept lattices,
features and constraints have been proposed as solutions for solving semantic heterogeneity among different information systems,
those approaches are not sufficient to solve the problem of semantic
heterogeneity in the WWW environment [38].

The vision of the Semantic Web [1] provides many new perspectives and technologies to overcome the limitation of the WWW.
Ontologies are a key component to solve the problem of semantic
heterogeneity, and thus enable semantic interoperability between
different web applications and services because of its ability to provide formal and explicit definitions of data and allow reasoning
over related concepts. Though ontologies are being used more and
more, no universal ontology exists for the WWW. Given the reality
of multiple ontologies over many domains, ontology mapping that
aims to find semantic correspondences between similar elements
of different ontologies has been the subject of research in various
domains and applications [32].

The following use cases show how ontology mapping can help
to achieve semantic correspondences in different scenarios, and
thus motivate our work in this area. First of all, ontology mapping
is important to the success of the Semantic Web. The pervasive
usage of agents or web services is a characteristic of the Semantic
Web. However agents or web services may use different protocols
that are independently designed, which means when agents or web
services meet, there is little chance for them to understand each
other without an interpreter. Therefore ontology mapping is a
necessary precondition to establish interoperability between agents or
services using different ontologies [7] (page 2). That is, the mapping
between ontologies provides the means for agents and services
to either translate their messages or integrate bridge axioms in
their own models. Secondly, ontology mapping is also widely used
to support data integration and information transformation. For
example, a web marketplace such as Amazon8 may need to combine products from multiple vendors catalogs into its own. A web
portal like NCSTRL9 may want to integrate documents from multiple library directories into its own. A company may want to
merge its service taxonomy with its partners. A researcher may
want to merge his/her bookmarks with those of his/her peers, etc.
Moreover, from the perspective of information retrieval, ontology
mapping can support semantic query processing across disparate
sources by expanding or rewriting the query using the corresponding information in multiple ontologies. For example, a user is
looking for the director of a movie, e.g., Star War, on the Web. In
one movie website, the name of movie is identified as moviename
and the name of its director is identified as director in its schema.
However in another movie website, those two concepts might be
identified as title and directorname, respectively in their schema.
Therefore to enable a federated search on those two websites, a
mapping between the schemas of those two websites will help us
rewrite queries according to different schemas.

Ontology mapping can be done either by hand or using automated tools. Manual mapping becomes impractical as the number,
size and complexity of ontologies increases. Automatic ontology
mapping has shown its importance in practical applications including the Semantic Web [1], information transformation and data

integration [6], query processing across disparate sources [14], to
name a few. Fully or semi-automated mapping approaches have
been examined in various research studies, e.g., analyzing linguistic information of elements in ontologies [20,34,39], utilizing
information retrieval techniques [21,22,36], treating ontologies as
structural graphs [28,31,41], using heuristic rules to look for specific
mapping patterns [15] and applying machine learning techniques
[5,26]. Comprehensive surveys of ontology mapping systems and
approaches can be found in [9,19,32].

Though the state of the art approaches have made significant
progresses in ontology mapping, they suffer from two limitations.
First, ontology mapping approaches that use multiple mapping
strategies meet the problem of aggregating multiple similarities.
Currently they either use some predefined experience numbers
to weight different similarities or tentatively set parameters in
aggregation functions (e.g. sigmoid). Manually setting parameters
is impractical due to its inability to adapting to different ontology mapping tasks. A second limitation is that most ontology
mapping approaches do not thoroughly deal with ontology constraints (e.g., the hierarchical relations in RDFS, the constraints
and axioms in OWL, and the rules in SWRL10). Most approaches
either ignore ontology constraints completely or deal with ontology constraints based on some heuristic rules [8,18,31]. To the best
of our knowledge, exceptions are GLUE [5], which adopts relaxation labeling to optimize mapping configurations by considering
ontology constraints, and RiMOM [39], which uses risk minimization to search for the optimal mappings from the results output by
multiple strategies. To overcome the limitations, in this paper we
propose a new weight assignment method to adaptively aggregate
different similarities and then adopt a neural network based constraint satisfaction model to improve overall mapping performance
from previously aggregated results. Actually our adaptive aggregation method can be integrated in most matching systems that
estimate multiple similarities. Though the neural network model
can be implemented independently from our adaptive aggregation
approach, the parameter (i.e. harmony) provides a good guidance
on where the neural network model should be activated or not.

Our contributions in this paper are twofold:

 We propose a measure harmony to estimate performance of similarities for ontology mapping, without given the ground truth.
Based on the estimation we adaptively aggregate various similarities and adjust our mapping strategies.
 We propose to use the interactive activation and competition
(IAC) neural network to search for a solution that best satisfies
ontology constraints.

To evaluate our approach, we adopt the benchmark tests from
OAEI ontology matching campaign 2007. We follow the evaluation
criteria of OAEI, calculating the precision, recall and f-measure of
each test case. Experimental results show that harmony has high
correlation with f-measure of individual similarity; the harmony
based adaptive aggregator outperforms all existing aggregation
methods; the IAC neural network boosts mapping performance sig-
nificantly. We also compare our approach with top-ranked systems
that participated in the campaign.

The rest of the paper is organized as follows. Section 2 illustrates
and defines ontology mapping problem with a simple example.
Section 3 explains our approach in details. Section 4 describes our
evaluation methodology and discusses experimental results. Section 5 reviews some related work followed by a summary and
future work at the end.

7 Based on the search results returned from http://swoogle.umbc.edu/ in July,

2007.

8 http://www.amazon.com/.
9 http://www.ncstrl.org/.

10 http://www.daml.org/2003/11/swrl/.

M. Mao et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 1425

Fig. 1. Two bibliographic ontologies.

2. Problem statement

Ontology is a formal, explicit specification of a shared conceptualization in terms of concepts (i.e., classes), properties and
relations [12]. Classes can be associated instances as well. Fig. 1
shows two sample ontologies in Bibliography area, in which the
ellipses indicate classes (e.g., Reference, Composite, Book and
Proceedings, etc.), the dashed rectangles indicate properties (e.g.,
Publisher, Editor, Organization, etc.), the lines with arrowhead indicate subClassof relation between two classes, and the
solid rectangle indicates an instance that is associated with the
class of Monograph (i.e., object-oriented data modeling published by the MIT Press at 2000). Each class and property has some
information to describe and restrict it. For example, the descriptive information of Book in the left ontology includes its ID, label,
comment and restrictions such as title, publisher, etc.

Ontology mapping aims to find semantic correspondences
between similar elements in two ontologies. In this paper, semantic correspondence refers to = relationship and elements refer
to classes and properties. The input of a mapping task is two
homogeneous ontologies, O1 and O2, expressed in formal ontology
languages. The output is a mapping, also called the mapping result,
between the input ontologies. Mapping can be represented in different ways such as queries [3], bridging axioms [6] or an instance in
a mapping ontology [14]. We define mapping results as a statement
4-tuple (as written in Eq. (1)), where m is a mapping that specifies a
specific element e1i in O1 corresponds to a certain element e2j in O2
with a relationship of r, and the mapping holds a confidence measure of s (also known as similarity), which is typically normalized
in a range [0. . .1].

m(e1 i, e2 j, r, s)

(1)

Candidate mappings in Fig. 1 include Reference and Compos-
ite, Book and Book, Monograph and Monogaphy, Collection
and Collection, Proceedings and Proc. They can be repre-
as: m(Reference,Composite = .11), m(Book,Book = 1),
sented
m(Monograph,Monography = .9),
m(Collection,Collection = 1),
m(Proceedings,Proc. = .36).

Fig. 2. The architecture of PRIOR+.

problem (CSP) in the context of ontology mapping. The architecture
of our approach is shown in Fig. 2, where H denotes the harmony
of similarities. The details of its three major modules, i.e., the IRbased Similarity Generator, the Adaptive Similarity Aggregator and
the Neural Network (i.e., the IAC neural network) based Constraint
Satisfaction Solver, are given in the following sections.

3. Our approach

3.1. IR-based similarity generator

Generally speaking, our approach, which we call PRIOR+, first
measures the similarities of both linguistic and structural information of ontology in a vector space model using classic information
retrieval technique. Next it adaptively aggregates different similarities according to their predicted performance and adjusts mapping
strategies based on the performance of final similarity. Finally it
utilizes the IAC neural network to solve the constraint satisfaction

In this section we briefly describe the generation of different similarities and refer interested readers to our previous work
[2022] for details. The input of the similarity generator is two
ontologies, which will be parsed by Jena11 and each element of

11 http://jena.sourceforge.net/.

which will be pre-processed by removing stop words, stemming,
and tokenizing. The outputs are three similarity matrixes that contain similarity scores for each pair of elements in ontologies.

3.1.1. Name similarity

The name similarity is calculated based on the edit distance
between the name (i.e., ID) of elements. The name-based similarity
is defined as Eq. (2), where EditDist(e1i, e2j) is Levenshtein distance
between elements e1i and e2j, l(e1i) and l(e2j) are the string length
of the name of e1i and e2j, respectively.
NameSim(e1 i, e2 j) = 1  EditDist(e1 i, e2 j)
max(l(e1 i), l(e2,j))

(2)

3.1.2. Profile similarity

The profile similarity is generated in three steps:

 Profile Enrichment. For each element in the ontology, we generate
a profile (i.e., a combination of the elements descriptive informa-
tion) to represent it and thus enrich its information. In particular,
the profile of a class = the classs ID + label + comments + other
restriction + its properties profiles + its instances profiles. The
profile of a property = the propertys ID + label + its domain + its
range. The profile of an instance = the instances ID + label + other
descriptive information. Then the tfidf weight is assigned for
each profile based on the whole collection of all profiles in the
ontology.
 Profile Propagation. To exploit the neighboring information of
each element, the profile of the elements ancestors, descendants
and siblings will be passed to that of the element with different
weights.
 Profile Mapping. Finally the cosine similarity between the profiles
of two elements of e1i and e2j is calculated in a vector space model
using Eq. (3), where Ve1i and Ve2j are two vectors representing the
profile of element e1i and e2j, respectively, n is the dimension of
the profile vectors, Vke1i and Vke2j are kth element in the profile
vector of element e1i and e2j, respectively, |Ve1i| and |Ve2j| are the
lengths of the two vectors, respectively.

k=1

(V e1 i

 V e2 j

(V el i

k )2

(3)

)2

(V e2 j

ProfileSim (e1 i, e2 j) =


Ve1 i
|Ve1 i

Ve2 j
||Ve2j

| =

3.1.3. Structural similarity

(5)

depth of the class from the root.

diff (e1 i, e2 j) = |sf (eli)  sf (e2j)|

max (sf (eli), sf (e2j))

Here we give an example of depth difference. Assume the max
depth of ontology O1 is 5, the max depth of ontology O2 is
6. depth(e1i) = 3, depth(e2j) = 4. We first normalize the depth as
sf(e1i) = 3/5 = .6, sf(e1i) = 4/6 = .67. Then calculate depth difference:
diff(e1i,e1i) =|.6-.67|/max(.6, .67) = .07/.67 = .10.

3.2. Harmony

In this section we introduce the term harmony to estimate the
importance and reliability of different similarities. Totally five individual harmonies (i.e., class name harmony, class profile harmony,
class structural harmony, property name harmony, and property
profile harmony) and two final harmony (i.e. class harmony, property harmony) will be estimated on the corresponding similarities.

3.2.1. The definition of harmony

As we stated in Section 1 that manually setting parameters to
aggregate different similarities is impractical due to its inability to
adapting to different ontology mapping tasks; meanwhile, the fact
that different similarities work well in different situations motivates us to investigate a new measure that can estimate the quality
of each similarity so that we can aggregate them according to their
individual characteristic (see the comparison of individual similarity in Section 4.2.1). Therefore we are looking for a measurement
that (1) can tell us which similarity is more reliable and trustful
so that we can give it a higher weight during aggregation and filter out false mappings that have low similarity; (2) can assist us
to adaptively adjust our mapping strategy, i.e., when to activate or
inactivate NN-based constraint satisfaction solver.

Ideally, for 1-1 mapping, the similarity score of two truly
mapped elements should be larger than that of all other pairs of
elements that share the same row/column with the two elements
in the similarity matrix, which implies that the two elements of this
pair mutually prefer each other. Given the rationale, we define the
harmony of the similarity matrix as Eq. (6), where #s max denotes
the number of the pair of elements that has the highest and the only
highest similarity in its corresponding row and column in the similarity matrix, and #ei denotes the number of elements in ontology
Oi.
h =

#s max

(6)

min (#e1, #e2)

3.2.2. A simple example of harmony estimation

Table 1 is the name similarity matrix for the example illustrated
in Fig. 1. The upper table lists the original similarity score between
each pair of elements. The lower table illustrates how the harmony
is calculated in this case, where  denotes the cell that has the
highest similarity score in each row, O denotes the cell that has
the highest similarity score in each column, and  denotes the
overlapped cell that has the highest similarity in both the row and
the column. The cells that have highest similarity score in each row
or column are indicated in bold in Table 1. Therefore the #s max in
Eq. (6) is the number of  in Table 1. In this case, #s max is 4 and
thus the harmony of the name similarity matrix is 4/5 = .8.

The structural similarity between two elements comes from
their structural features (e.g., the number of direct property of a
class). Structural similarity is considered for classes only. No structural similarity will be given to property and instance due to the lack
of hierarchical information. The structural similarity of the classes
in two ontologies is defined by Eq. (4), where e1i and e2j are two
class elements in ontology O1 and O2, respectively, n is the total
number of structure features, diffk(e1i,e2j) denotes the difference
for feature k.

(1  diffk(e1 i, e2 j))

StructSim (eli, e2j) =

k=1

(4)

3.3. Adaptive similarity aggregator

The diffk(e1i,e2j) is defined as Eq. (5), where sf(e1i) and sf(e2j) denote
the value of structure features of e1i and e2j, respectively. In our
approach sf(e1i) and sf(e2j) are one of the following values, i.e., the
number of the class direct properties, the number of the class
instances, the number of the class children, and the normalized

3.3.1. Similarity aggregation in the state-of-art ontology
mapping approaches

Aggregating different similarity is pervasive in ontology map-
for

ping systems that contain multiple individual matchers,

M. Mao et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 1425

Table 1
A sample of harmony calculation.

Composite

Book

Proc.

Monography

Collection
