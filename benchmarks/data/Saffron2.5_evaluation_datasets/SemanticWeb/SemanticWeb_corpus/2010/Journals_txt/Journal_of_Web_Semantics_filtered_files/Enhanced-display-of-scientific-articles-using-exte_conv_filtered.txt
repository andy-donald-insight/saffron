Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 190195

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

Invited paper
Enhanced display of scientific articles using extended metadata
Roderic D.M. Page

University of Glasgow, Glasgow G12 8QQ, UK

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 24 April 2009
Received in revised form 2 September 2009
Accepted 26 March 2010
Available online 3 April 2010

Keywords:
Data citation
Geotagging
Identifiers
Scientific publication
Biodiversity informatics
Elsevier Grand Challenge

Although the Web has transformed science publishing, scientific papers themselves are still essentially
black boxes, with much of their content intended for human readers only. Typically, computer-readable
metadata associated with an article is limited to bibliographic details. By expanding article metadata to
include taxonomic names, identifiers for cited material (e.g., publications, sequences, specimens, and
other data), and geographical coordinates, publishers could greatly increase the scientific value of their
digital content. At the same time this will provide novel ways for users to discover and navigate through
this content, beyond the relatively limited linkage provided by bibliographic citation.

As a proof of concept, my entry in the Elsevier Grand Challenge extracted extended metadata from
a set of articles from the journal Molecular Phylogeny and Evolution and used it to populate an entity-
attribute-value database. A simple web interface to this database enables an enhanced display of the
content of an article, including a map of localities mentioned either explicitly or implicitly (through
links to geotagged data), taxonomic coverage, and both data and citation links. Metadata extraction was
limited to information listed in tables in the articles, such as GenBank sequences and specimen codes. The
body of the article was not used, a restriction that was deliberate to demonstrate that making extended
metadata available does not require a journals publisher to make the full-text freely available (although
this is desirable for other reasons).

 2010 Elsevier B.V. All rights reserved.

1. Introduction

Scientific publishing is in transition. The classic model of publishers delivering human-only readable content, whether in print or
electronically, is being supplemented by machine-readable content
[29]. But machine-readable content is still a second-class citizen,
often limited to bibliographic metadata about the article. Hence,
most electronic publications are essentially opaque black boxes,
their digital content locked inside PDFs or HTML pages (Fig. 1a). In
order to make these documents findable, indexing and abstracting
services such as Google Scholar1 and PubMed2 make use of fragments of text (e.g., the abstract) or full-text indexing to help users
find relevant content (Fig. 1b).

Document findability would be significantly improved if indexing services could extract additional information, such as terms for
which we have a controlled vocabulary (e.g., taxonomic names of
organisms), database identifiers (such as macromolecular sequence
accession numbers, and museum specimen codes), and geographic
coordinates (latitude and longitude pairs) (Fig. 1c). For example,

 Tel.: +44 141 330 4778.
E-mail address: r.page@bio.gla.ac.uk.

1 http://scholar.google.com.
2 http://www.ncbi.nlm.nih.gov/pubmed/.

1570-8268/$  see front matter  2010 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2010.03.004

querying on the taxonomic name Aves (birds) should find all
papers on birds, even if those documents do not all include the term
Aves. Extracting identifiers enables the document to be linked to
external databases, leading to the development of metrics of data
citation, and making provenance traceable. Extracting geographical coordinates would enable publishers to provide interfaces that
query their journal content by geographic area (e.g., find all articles that include species living in Madagascar), or for a given article
provide a list of geographically proximate publications (e.g., find
other articles on species within 100 km of the centre-point of this
study).

Note that exposing these elements (terms, identifiers, and coor-
dinates) need not require the publisher to make available their
primary digital asset (the full text of the article). Additional metadata  beyond standard bibliographic details  could be readily
exposed, for exampling using Open Text Mining Interface,3 greatly
increasing a documents findability and usability.

1.1. Citation linking

Article interrelationships can include citation, bibliographic
coupling, and co-citation (Fig. 2). Establishing these links

3 http://opentextmining.org/wiki/Main Page.

Fig. 1. Increasing the findability of documents with more sophisticated indexing. (a) A raw document, such as a PDF file. (b) Indexing strings, such as keywords, facilitates
basic text searching. (c) Indexing terms from controlled vocabularies, database identifiers, and geographical coordinates enable more sophisticated queries.

1.2. Data citation

In data-rich subjects such as molecular biology, taxonomy, sys-
tematics, and ecology, a paper may contain a wealth of potential
links to data (such as DNA sequences, museum specimens, taxonomic names, ecological observations), many of which have a
digital presence. There may also be additional, implicit links. For
example, a paper in systematics may list DNA sequences from Gen-
Bank, but not the voucher specimens from which those sequences
were obtained. This potentially deprives natural history museums,
for example, from an opportunity to demonstrate the value of their
collections by being able to list publications that use (or cite) data
derived from material in their care. Similarly, some have argued
that failure to cite the authorities of taxonomic names contributes
to the relatively low impact factor of taxonomic publications ([31],
but see [9]).

An obvious extension to current publishing practice is to extend
linking beyond publications alone, thus embedding those publications in a broader web of biodiversity data [23,25]. Some publishers
have already made efforts in this direction. BioOne5 converts putative taxonomic names to links to ITIS,6 others provide a discount
on the cost of publication if authors use bibliographic software to
construct their list of references, and mandate that some data links
(e.g., GenBank accession numbers) are marked-up.

Extending this linking of resources to include museum spec-
imens, for example, would add an important extra dimension
to biodiversity publications, beyond providing provenance for
data [27]. In particular, many museum specimens have been
geo-referenced [10], providing a wealth of spatial data that has
been harvested globally by GBIF.7 Linking sequences and publications to geo-referenced specimens will enable spatial queries
to be performed, bringing an additional dimension to information
retrieval from scientific literature [1]. Many records in GenBank are
themselves geo-referenced, adding a further source of geographic
information.

However, there are significant obstacles to extending linking beyond bibliographic citation. The Digital Object Identifiers
(DOIs) used by publishers have an underlying technical and social

Fig. 2. Relationships between publications. One document may cite another. Two
documents (e.g., A and B) are bibliographically coupled if they both cite a third (C).
Similarly, co-citation occurs when two documents (e.g., A and B) are cited by a third
(C).

requires a mechanism to uniquely identify a publication, and tools
for finding appropriate identifiers from article metadata. These
services are provided by CrossRef,4 which not only stores basic
metadata about a publication (such as journal title, volume, starting
page number, first author), but can also store more comprehensive
metadata, including lists of cited references. This enables forward
linking, so that a publisher displaying paper B can tell the user that
B is cited by the more recent paper, A (Fig. 2). Metrics based on the
links between publications can be used to quantify the value of an
article (e.g., how many times it has been cited), which can be used
to measure the value of the journal publishing those articles (e.g.,
impact factor), or the impact that an author is having on their
field of research.

4 http://www.crossref.org.

5 http://www.bioone.org.
6 http://www.itis.gov.
7 http://www.gbif.org.

R.D.M. Page / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 190195

Fig. 3. Data model linking publications, authors, sequences, specimens, taxonomic names, and locations. Thick lines indicate relationships that have to be extracted from the
text of an article, or from PubMed, GenBank, or specimen records. Circled numbers indicate identifiers that can be obtained for the corresponding entity. These include (1)
DOIs, PubMed identifiers (PMIDs), Handles, or URLs for publications; (2) GenBank accession numbers (either listed in the publication, or obtained from NCBI); (3) specimen
codes (either listed in the publication, or in the GenBank record); and (4) uBio namebankIDs for taxonomic names.

infrastructure that supports their persistence. In contrast, many
resources that are identified by URLs in scientific papers lack this
infrastructure, and may disappear at a moments notice [6]. Hence,
publishers may be reluctant to populate their documents with
links that may break. There may also be significant amounts of
data (and/or links to data) in supplementary appendices (typically
stored in Word, Excel, or PDF files). While publishers have a stake
in maintaining the availability of the articles that they publish,
they currently have less incentive to maintain access to underlying data, as evidenced by the frequent failure to adequately archive
supplementary data [8].

Museum specimen records are more isolated digitally than
records in publication or genomic databases, in part because of
the lack of a simple, resolvable identifiers for museum specimens.
This is an obstacle to linking museum records to publications and
sequences. Furthermore, specimens are tagged with taxonomic
names, but not with any widely used identifiers associated with
those names (such as NCBI taxonomy ids).

1.3. Modeling the links

Combining information on publications, sequences, and speci-
mens, we arrive at a simple model that includes the key entities
of interest in biodiversity informatics (Fig. 3). Authors are linked to
publications, which may be linked to other publications via citation
links. Publications may cite nucleotide sequences and specimens
(typically listed in tables in the body of the text), and may also list
localities. Specimens may be listed in GenBank records, and either
of these records may be geo-referenced. The record for a specimen lists the name of the corresponding organism, and GenBank
records for parasites may list their host organism. Both of these

names can be assigned an identifier using webservices provided by
uBio.8

Note that any one source may provide only a partial set of
links. PubMed records do not always list the associated GenBank
sequences, and when they do they usually list only the sequences
that are newly published by that paper, which may be a small
fraction of the sequences actually analysed (phylogenetic studies typically build on previous work). GenBank records may omit
the names of voucher specimens, which may instead be found in
the publication. GenBank locations may be geo-referenced, but the
museum records for a specimen may lack this information, and vice
versa.

2. Challenge entry

My entry in the Elsevier Grand Challenge Knowledge Enhancement in the Life Sciences contest9 used the model shown in Fig. 3
as the framework for a database that was populated with content
from the journal Molecular Phylogenetics and Evolution. I extracted
citation links to both papers and data, such as GenBank sequences,
taxonomic names, and museum specimens, together with geotagged localities, and built a web of entities linked by typed
relationships.10 Assembling the entry was a three-step process,
involving harvesting, assembling, and displaying data.

8 http://www.ubio.org.
9 http://www.elseviergrandchallenge.com.
10 http://iphylo.org/ rpage/challenge/www.

Fig. 4. Screen shot showing basic bibliographic metadata being displayed for an article [30], enhanced with a map of localities linked to the article, a taxonomic summary as
a treemap, and lists of other articles that are related either through citation, geographic or taxonomic overlap. These related studies are discovered by harvesting identifiers
and geographical co-ordinates from the article.

2.1. Harvesting

The database was seeded with a full text collection of articles for Molecular Phylogenetics and Evolution. The XML documents
were converted into a summary document in JSON format using a
XSLT style sheet. The summary document listed basic bibliographic
metadata, the references cited, as well as the content of any tables.
Scripts written in PHP were used to extract identifiers and localities
from the tables, such as specimen codes, GenBank accession num-
bers, and latitude and longitude pairs. The body of the article was
not searched for these identifiers, partly to see how much could
be gleaned without using that text, and also because discovering
identifiers within the text itself can be problematic. For example,
in experiments with other documents, I discovered that a simple regular expression to extract GenBank identifiers also matched
UTM grid references (for example UTM grid reference DQ402119 in
[19] is also a GenBank sequence for human herpesvirus). For each
reference cited in a papers bibliography, the bioGUID OpenURL
resolver11[22] was used to search for available identifiers (such
as DOIs, PubMed numbers, Handles, or URLs). This service also
returned metadata for GenBank accession numbers and specimen
codes.

2.2. Assembling

Harvested metadata was stored in an Entity-Attribute-Value
(EAV) database [18,20] implemented in MySQL. Entity attributes

(metadata) were stored in typed attribute tables (i.e., there are
separate tables for dates, integers, real numbers, strings, and
large chunks of text). A separate table listed all available globally
unique identifiers (GUID) for each entity (e.g., DOIs, PMID, Han-
dles, GenBank accession numbers, etc.). For each entity a 32-digit
hexadecimal MD5 hash of the default GUID was used as the unique
internal identifier. To avoid duplication due to the same publication
being added from different sources (and having different GUIDs), a
Journal Article Citation Convention (JACC) identifier [5] was created
using the journal ISSN, volume, and starting pagetwo articles with
the same JACC were regarded as the same. Typed links between
entities were stored in a separate table. A table with a MySQL SPATIAL index was used to store localities, permitting basic spatial
queries. To support taxonomic queries a nested-sets representation
of the NCBI Taxonomy was created, following [24].

2.3. Display

Fig. 4 shows a screen shot of my entry12 displaying a typical
article [30]. Each object in the database, whether article, sequence,
specimen, taxon, or author has its own webpage that displays metadata about that object, as well as any links it may have to other
objects (Fig. 4). In addition to classical links between papers, such
as citation (Fig. 2), papers may be linked by shared data, that is,
they have links to one or more GenBank sequences or specimens
in common (analogous to bibliographic coupling, Fig. 2) [15]. These
shared links (if present) are listed in a section entitled Shares data

11 http://bioguid.info/openurl.

12 http://iphylo.org/ rpage/challenge/www/.

R.D.M. Page / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 190195

query language. RDF requires vocabularies to describe entities and
their relationships. For some classes of entity (such as publications)
there are several competing vocabularies in existence, whereas for
others there are none. SPARQL has considerable potential, but in
the context of the Challenge entry its use was not feasible as it does
not natively support the geospatial, full-text searching, and nested
sets queries needed to create the visualisations (e.g., Fig. 4).

The entry has merely scratched the surface of possible visu-
alisations. The original proposal [26] included the use of Google
Earth to display phylogenies. This is technically achievable,14 but
preliminary work found that automated extracting trees from
bitmap images in journal pages was more difficult than anticipated,
and I abandoned this task. However, the maps displayed on each
web page (Fig. 4) can be exported in KML and viewed in Google
Earth.

3. Conclusion and outlook

My challenge entry made very limited use of the full-text doc-
uments. This was partly not only to keep the task manageable, but
also to see what could be achieved without the publisher handing over its crown jewels (i.e., the full text) to the reader. Part of
the database created here could have been populated from sources
such as PubMed, without access to Molecular Phylogenetics and Evolution full text at all, although it would lack the citation links, and
many GenBank and museum links, as well as some locality informa-
tion. Some citation links could be recovered from PubMed, and for
some purposes (such as using citation links to improve information
retrieval [3]) incomplete citation data can still be useful [12].

The key point is that much of the information displayed in
the demonstration comes from a small fraction of the information in the journal articles. If for each article publishers were to
output metadata listing the papers cited, GenBank accession num-
bers, specimen codes, and any latitude-longitude pairs, then a
system like this entry could be created without requiring access
to the underlying text. The task facing the publisher, then, is to
extract the metadata and make it available. Given the potential for
errors when this process is automated, it would be desirable to
provide authors with simple tools to mark up their manuscripts,
for example, by flagging GenBank accessions, museum codes,
and latitudes and longitudes (the later being written in standard
format).

Given that making just a little more metadata available can significantly enhance what publishers (and their readers) could do
with an article, even without making the full text freely available,
one might wonder what is gained from moving to open access (in
the strict sense of enabling copying and repurposing of the published content [17]). Purely from the narrow point of this Challenge
entry, extracting identifiers and geotags is error-prone, and having the full text available would facilitate detecting and correcting
errors. Furthermore, papers themselves can contain errors. On several occasions in this study I found cases where GenBank accession
numbers were clearly incorrect. For example, [21] is a paper on
bryozoans, yet the demo linked this study to Homo sapiens. This is
a result of a table in the paper listing the incorrect GenBank accession numbers (AJ711044-50 should have been AJ971044-50). In the
same way, [14] is a study on birds, yet contains a stray fish sequence
due to an error in one of the tables.

The existing model of relying on authors detecting these errors
and arranging for errata to be published is inefficient, and means
that many errors in the scientific literature are likely to go undetected and uncorrected. One way forward is to treat a scientific

Fig. 5. Examples of different ways latitude and longitude are reported in four articles
[13,11,16,28] from the journal Molecular Phylogenetics and Evolution.

with (note that these papers need not directly cite, nor be cited by,
the current article).

Taxonomic information is displayed in a variety of ways. The
taxa in a study are listed on the article web page, and summarised in
a split layout treemap [7] populated with images of the taxa.13 The
size of each cell in the treemap is proportional to the number of taxa
in that group (typically a genus). Each taxon has its own separate
page, which lists papers referring to that taxon, and displays the
NCBI classification for that taxon using a PygmyBrowser [2].

Localities extracted from tables in the articles, or via objects that
are geo-referenced (e.g., GenBank sequences, or voucher specimens
for those sequences) are used to generate a map of all localities
linked to the article. The web page displays up to five studies whose
geographic coverage overlaps that of the article being displayed.

2.4. Obstacles and limitations

Automatic extraction of identifiers can run into problems. As
noted above, GenBank identifiers can be identical to UTM grid ref-
erences. Museum specimen codes are written in a variety of styles,
and there can be enormous variation in how latitude and longitudes are written, both individually, and when written as a pair of
co-ordinates. In addition, there is considerable variation in how
latitude and longitude pairs are reported in tables in Molecular
Phylogenetics and Evolution. Authors may include the (latitude, lon-
gitude) pair in a single column, split it between two columns, or
put one value under another. In some cases the individual values
include information on which hemisphere they refer to, in others
this information is in the table header (Fig. 5). Taken together this
makes parsing geo-references somewhat challenging, and is a good
argument for authors (and copy editors) adopting a standard way
to include this information in manuscripts.

Search is rather crudely implemented. Very simple full-text
searching is available for text, implemented using MySQLs FULLTEXT index. Spatial searching relies on MySQLs spatial extensions,
which have limited functionality in the current version of that
software. For example, the search for overlapping polygons is actually implemented as a search for overlapping minimum bounding
rectangles. Even if this issue was addressed, the use of bounding
polygons is in itself too crude to adequately represent a geographic distribution. The taxonomic search returns taxa within the
taxonomic span of the article. However (and analogously to the
bounding polygon), if a study includes a few disparate taxa, then the
list of taxa returned may be more diverse than the user anticipates.
An alternative approach to implementing the challenge entry
would have been using RDF and a triple store, with SPARQL as the

13 The images were obtained using Yahoos image search APIs and Flickr.

14 http://iphylo.blogspot.com/2007/06/google-earth-phylogenies.html.

article not as an immutable text, but rather as version 1.0 of a series
of annotated and edited versions. Supporting community revision
suggests a wiki-style interface, and may be yet another step in the
convergence of journals and databases [4].

Acknowledgements

I thank Anita de Ward and Noelle Gracy of Elsevier for facilitating access to full-text XML of Molecular Phylogenetics and Evolution,
Kehan Harman and Benjamin Good for comments on the entry, and
the three anonymous reviewers who provided helpful comments
on the manuscript.
