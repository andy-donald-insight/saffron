Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 5568

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

Anomalies in ontologies with rules
Joachim Baumeister, Dietmar Seipel

University of Wurzburg, Institute of Computer Science, Am Hubland, 97074 Wurzburg, Germany

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 18 January 2009
Received in revised form 4 August 2009
Accepted 17 December 2009
Available online 4 January 2010

Keywords:
Evaluation
Verification
Ontology engineering
Owl
Rif-Bld
Swrl

1. Introduction

For the development of practical semantic applications, ontologies are commonly used with rule exten-
sions. Prominent examples of semantic applications not only are Semantic Wikis, Semantic Desktops,
but also advanced Web Services and agents. The application of rules increases the expressiveness of the
underlying knowledge in many ways. Likewise, the integration not only creates new challenges for the
design process of such ontologies, but also existing evaluation methods have to cope with the extension
of ontologies by rules.

Since the verification of Owl ontologies with rule extensions is not tractable in general, we propose to
verify ontologies at the symbolic level by using a declarative approach: With the new language Datalog,
known anomalies can be easily specified and tested in a compact manner. We introduce supplements
to existing verification techniques to support the design of ontologies with rule enhancements, and we
focus on the detection of anomalies that especially occur due to the combined use of rules and ontological
definitions.

 2010 Elsevier B.V. All rights reserved.

The use of ontologies has shown its benefits in many applications of intelligent systems in the last years. Recent examples are
the development of Semantic Wikis, e.g., [7,28], and Semantic Desk-
tops, e.g., [27]. Most prominently, the Semantic Web initiative [35]
coordinates the specification and life cycle of ontology languages
in the context of the Semantic Web [1]. The semantic web stack,
e.g., see [16], describes the architecture of the Semantic Web at
a technical level including languages for ontologies and rules, but
also key technologies such as Unicode and encryption. Whereas, the
implementation of lower parts of the semantic web stack has successfully led to a standardization, the upper parts, especially rules
and the logic framework, are still heavily discussed in the research
community, see for example [16,19,26].

This insight has led to many proposals for rule languages compatible with the semantic web stack, e.g., the definition of Rif-Bld
(Basic Logic Dialect of the Rule Interchange Format [33]), Swrl
(semantic web rule language) which originates from RuleML, and
similar approaches [17]. It is generally agreed that the combination of ontologies with rule-based knowledge is essential for many
interesting semantic web tasks such as the realization of semantic web agents and services. Swrl allows for the combination of a
high-level abstract syntax for Horn-like rules with Owl, and a model

 Corresponding author.
E-mail addresses: joba@uni-wuerzburg.de (J. Baumeister),

seipel@informatik.uni-wuerzburg.de (D. Seipel).

1570-8268/$  see front matter  2010 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2009.12.003

theoretic semantics is given for the combination of Owl with Swrl
rules. The Xml syntax was derived from RuleML. With Rif-Bld an
analogous Xml serialization of rules is in the process of standard-
ization. Rif-Bld specifies an interchange format for rule languages
and proposes an integration with Rif-Bld/Owl languages.

However, with the increased expressiveness of such ontologies new demands for development and maintenance guidelines
arise. Thus, conventional approaches for evaluating and maintaining ontologies need to be extended and revised in the light of rules,
and new measures need to be defined to cover the implied aspects
of rules and their combination with conceptual knowledge in the
ontology.

Concerning the expressiveness of the ontology language, we
focus on the basic elements of Owl DL, which should make the
work transferable to ontology languages other than Owl, and we
mostly describe methods for the syntactic analysis of the considered ontology. We also focus on the basic features of rule languages
such as Swrl and Rif-Bld: they correspond to a rule language of
Horn clauses with class or property descriptions as literals with
equality and a standard first-order semantics.

1.1. Verification at the symbolic level

Due to the combination of Owl and rules, however, the general
detection of all anomalies is an undecidable task. Whereas for fragments of Rif-Bld or Swrl  such as Elp [19]  tractable reasoning can
be provided, the identification of redundant and deficient knowledge still requires syntactic methods that investigate the concepts
and rules at the symbolic level.

J. Baumeister, D. Seipel / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 5568

Here, the term verification denotes the syntactic analysis of
ontologies at the symbolic level for detecting anomalies. On the one
hand, the discussed issues of the presented work originate from
the evaluation of taxonomic structures in ontologies introduced
by Gomez-Perez [11]. On the other hand, in the context of rule
ontologies, classical work on the verification of rule-based knowledge  see for instance Preece and Shinghal [22,23]  has to be
reconsidered. In this work, the verification of ontologies (mostly
taxonomies) and rules (based on predicate logic), respectively, has
been investigated separately. However, the combination of taxonomic and other ontological knowledge with a rule extension leads
to new evaluation issues that can cause redundant or even inconsistent behavior. For example, a very obvious redundancy may be
due to the coexistence of the taxonomic relation subClassOf(A,
B) and the rule A  B.

One contribution of our work is the extension of classic measures by novel anomalies that result from the combination of
rule-based and ontological knowledge. Here, the concept of dependency graphs from deductive databases can be used [8].

Of course, the collection of possible anomalies presented in
this paper may always be incomplete, and additional elements
of the ontology language may also introduce new possibilities of
occurring anomalies. For this reason, we propose the declarative
specification of anomalies by Datalog, that allows for flexibly including new and application-relevant anomalies. Here, the
axioms of the ontology and the given rules are mapped to corresponding Datalog facts and rules, respectively. Thus, the anomaly
predicates described in the remainder of the paper can be directly
applied.

In detail, we investigate the implications and problems that
emerge from rule definitions in combination with some of the following ontological descriptions:

(i) class relations like subclass, complement, disjointness,
(ii) basic property characteristics like transitivity, symmetry, ranges

and domains, and cardinality restrictions.

We distinguish between the following categories of anomalies:

 Circularity in taxonomies and rule definitions.
 Redundancy due to duplicate or subsuming knowledge.
 Inconsistency because of contradicting definitions.
 Deficiency comprising subtle issues describing questionable
ontology design.

Since we mainly describe syntactic checks of ontologies, the
presented work is different from the evaluation of ontologies with
respect to the intended semantic meaning: the OntoClean methodology [14] is an example for semantic checks of taxonomic decisions
made in ontologies. We also do not consider common errors that
can be implemented due to the incorrect understanding of logical
implications of Owl descriptions, as described by Rector et al. [25].

1.2. Integration of verification methods

In general, the verification of ontologies with rules should not be
seen as an isolated task, but is understood as a subtask of the evaluation phase, that is proposed in almost all methodologies for ontology
development [12]. In the past, a variety of methodologies was
introduced, that structure the development and evolution process
into distinct phases, for example the On-To-Knowledge methodology [32], Methondology [12], and the extensive CommonKADS
methodology [29]. Here, the presented verification methods can
be integrated as a sub-task into the evaluation phase, and they are
used after every significant modification of the working ontology.

1.3. Structure of the paper

The paper is organized as follows: Section 2 gives basic
definitions and describes the expressiveness of the underlying
knowledge representation; in the context of this work a subset
of Owl DL is used. Then, the four main classes of anomalies are
discussed in more detail. In Section 3, we introduce anomalies
concerning the circularity of definitions. Anomalies uncovering
inconsistent knowledge are shown in Section 4. We deal with
redundancy in Section 5 and describe deficient knowledge in
Section 6. We present some technical details of the evaluation
mechanism of Datalog in Section 7. The paper is concluded with
a discussion.

2. Expressiveness and basic notions

For the analysis of ontologies with rules we restrict the considered constructs to a subset of Owl DL; in fact, many anomalies
can occur when using the simple profile Owl 2 El [13]: we investigate the implications of rules that are mixed with subclass relations
and/or the property characteristics transitivity, symmetry, cardi-
nality, complement, and disjointness.

For example, in a university domain there might exist classes
like Person, Student, and Professor, that are connected by properties such as
 subClassOf(Student, Person),
 subClassOf(Professor, Person),
 disjointClasses(Student, Professor).

Fig. 1 shows a graphical version of the class definitions.
Class atoms and property atoms. Given a class C and a property
P: when used in rules we call C(x) a class atom and P(x, y) a property
atom. For the following, it will be useful to extend the relations on
classes and properties to relations on class and property atoms.
), if both atoms have the
Given two atoms A, A
same argument tuple, and their predicate symbols are linked by a
 both are
relation , i.e., if A and A
 class atoms, such that A = C(x), A
 = C
 property atoms, such that A = P(x, y), A

(x), and (C, C
 = P

, we write (A, A

), or

(x, y), and (P, P

).

For example, the relation  can be subClassOf, disjoint-
) it
 are of the same type (either class or property

Classes, objectComplementOf, etc. From a relationship (A, A
follows that A and A
atoms).

2.1. Specification in Datalog

The detection of anomalies has been done using the Prolog
meta-interpreter Datalog, which we have implemented in Swi
Prolog [36]. Due to their compactness and conciseness, we give
the corresponding formal definitions in Datalog for the anomalies,

Fig. 1. A simple ontology example with a disjoint relation.

which are evaluated using a mixed bottom-up/top-down approach
based on Datalog and Prolog concepts, respectively.

An intuitive understanding of the presented, mixed rule sets is
possible without fully understanding the new inference method.
For the interested reader, we introduce technical details of the
evaluation mechanism of Datalog as well as some supporting
predicates in Section 7.

Variables such A, B, C, . . ., A, or Bi can be used for both class
atoms and property atoms, whereas As, Bs, . . ., denote sets of class
atoms and property atoms. The relationship subClassOf(A, A)
describes that A is a subclass of A.
Rules B1    Bn  A are represented as non-grounded
Datalog facts rule(Bs=>A) (with variable symbols), where Bs =
[B1, . . ., Bn] is the list of body atoms, A is the head atom, and =>
is a binary infix functor. Without loss of generality, we can assume
that the rule heads are atomic, since rules with conjunctive rule
heads can be split into several rules. In the bodies of Datalog and
Prolog rules, conjunction (and) is denoted by ,, disjunction (or)
is denoted by ;, and negation by not.

2.1.1. Incompatible classes: disjointness and complements

We use disjointClasses(C1, C2) to define the disjointness
between two Owl classes. The construct objectComplementOf
points to instances, that do not belong to a specified class. The disjointness relation between a class C1 and a class C2 is equivalent to
the relation subClassOf(C1, objectComplementOf(C2)).

Two classes C1 and C2 are incompatible, if there exists a disjointness or a complement relationship between them. This is described
by the following Prolog predicate used in Datalog:

incompatible(C1, C2) :-

(subClassOf(C1, objectComplementOf(C2))
; disjointClasses(C1, C2)).

For incompatible classes C1 and C2 there cannot exist an

instance x with C1(x) C2(x).

2.1.2. Taxonomic relationships and rules

An obvious equivalence exists between a transitive subclass
relationship subClassOf(B, A)  where A and B are both class
atoms or both property atoms with the same arguments  and the
rule B  A with a single body atom B, that has the same argument
as A. Thus, we combine them into the single formalism derives in
Datalog:

derives(C1, C2) :-

(subClassOf(C1, C2)
; rule([B]=>A),
B =.. [C1, X1], A =.. [C2, X2],
var(X1), X1 == X2)

Since such an equivalence is symmetrical, the predicate
derives always creates cyclic derivations of equivalent elements
with length 1.

We compute the transitive closure tc derives of derives

using the following standard Datalog scheme:

tc derives(E1, E2) :-

derives(E1, E2).

tc derives(E1, E3) :-

derives(E1, E2), tc derives(E2, E3).

The following Prolog predicates with calls to Datalog facts

generalize tc derives and incompatible to atoms:

tc derives atom(A1, A2) :-

A1 =.. [P1|Xs], A2 =.. [P2|Xs],
tc derives(P1, P2).

incompatible atoms(A1, A2) :-

A1 =.. [P1|Xs], A2 =.. [P2|Xs],
incompatible(P1, P2).

tc incompatible atoms(A1, A2) :-

A1 =.. [P1|Xs], A2 =.. [P2|Xs],
tc derives(P1, P3),
incompatible(P3, P4),
tc derives(P2, P4).

As described before, the binary built-in predicate =.. of Prolog splits given atoms Ai into their predicate symbol Pi and their
list Xs of arguments; using the same variable Xs for both atoms
requires the argument lists to be identical. We cannot evaluate
these rules using forward chaining, since =.. cannot be applied
if Xs is an unknown list.
For two (class or property) atoms A and B we say that A implies
B, if A = B or tc derives atom (A, B). The first of the following
supporting Prolog rules turns the transitive closure into a reflexive transitive closure; the second extends it to negated atoms, i.e.
literals, where  denotes negation:

implies(A, B) :-

(A = B ; tc derives atom(A, B)).

implies( A,  B) :-
implies(B, A).

2.1.3. Remark on examples

In the following we give examples for most of the described
anomalies. Here, we use the benchmark university domain LUBM
[15], because of its popularity and intuitive understanding. We use
the prefixes a: and b: for classes and properties in order to para-
phrase, that these elements are contained in the ontologies a and
b.

The Prolog call T =.. Xs splits a term T into a list Xs =
[F,X1,...,Xn] consisting of the functor F and the arguments
X1,...,Xn. Above, the functors C1 and C2 of the class atoms A and
B, respectively, are class names and both atoms have one argument.
The call var(X1), X1 == X2 tests, if these arguments X1 and X2
are bound to the same variable.
With the existence of equivalence definitions E1  E2 in an
ontology language, e.g., the Owl definitions equivalentClasses
and equivalentObjectProperties, we can further extend the
definition of derives: an element E1 is derived by an element E2, if
the elements are equivalent classes or properties. In Datalog, we
extend derives with the following Prolog rule:

derives(E1, E2) :-

(equivalentClasses(E1, E2)
; equivalentObjectProperties(E1, E2)).

3. Circularity

Circular definitions in the ontology have a severe impact on the
reasoning capabilities of the underlying knowledge. Here we distinguish circular definitions in the taxonomic structure of the ontology
as described by Gomez-Perez [11], circular dependencies in the rule
base as considered, e.g., by Preece and Shinghal [22], but also circular dependencies that can occur due to the mixture of taxonomic
and rule-based knowledge.

3.1. Circularity in taxonomy and rules

Circular definitions can occur in the taxonomy, in rules, and in

property relations.

J. Baumeister, D. Seipel / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 5568

The following Datalog predicate finds pairs [E,F] of subse-

3.1.1. Exact circularity in taxonomy and rules
quent elements E = Ei1 and F = Ei from a cyclic chain
E1, E2, . . . , En, En+1 = E1,
where Ei1 derives Ei, for 2  i  n + 1, such that all elements Ei of
the chain are either classes or properties.

anomaly(exact circularity, [E, F]) :-

derives(E, F), E \= F,
tc derives(F, E).

Cycles with n = 1 commonly occur due to the inclusion of equivalent classes and properties in the predicate derives. For the
subClassOf relation alone (included in derives), the described
circular relationships are commonly detected by existing tools.

Example. Consider two ontologies a and b with classes
 subClassOf(a:Professor, a:Person) and
 subClassOf(b:Employee, b:Person).

Then, the following incorrect alignments create an undesired

circularity in the taxonomy with n = 4:
 equivalentClasses(a:Professor, b:Person) and
 equivalentClasses(a:Person, b:Employee).

The example is depicted in Fig. 2, where the incorrect alignment
between the concepts of two ontologies a and b produce the circular
dependency.

3.1.2. Circularity between rules and taxonomy
A rule B1    Bn  A, such that the head atom A implies some
body atom B = Bi, leads to a circularity. The rule should be considered as a restricted subClassOf relation between A and B, which
may result in the detection of a misapplied taxonomic definition
between them.

The circularity can be found with the following Datalog pred-

icate:

anomaly(circularity, A-Bs) :-
rule(Bs=>A), member(B, Bs),
implies(A, B).

Example. Since subClassOf(Professor, Person), the following rule  defining a specific restriction on instances of classes
Person and Professor  creates a partially cyclic definition:

Person(X) Teacher(X,Y) 
University(Y) Professor(X).

Fig. 2. An example of a circular alignment of concepts of two different ontologies
due to the incorrect use of equivalence relations.

3.2. Circular properties

Property descriptions can also be the source of circularity, when

P2Pn1 Cn = C

a chain of properties Pi connects a class C by a chain
C = C1
of classes Ci, with n  2, to itself; at least one of the properties
should not be symmetric. We say that a property P connects two
PE, if there exists a property
classes it D and it E and denote this by D
, such that it D transitively derives or
between two classes D
is equal to D

 transitively derives or is equal to it E.

 and E

P1C2

 and E

Often such a circularity leads to infinite models of the ontology.
In pure description logic reasoners, various blocking methods [2,18]
ensure termination of the proof procedure in case of existentially
quantified cycles. However, the extension of ontologies by rules
requires new methods, and decidability is not guaranteed in the
general case. Typical sources of circularity are the incorrect use of
inverse and symmetrical properties during the matching of two
ontologies. In the general case however, a cyclic property chain may
sometimes be an intentional design decision in ontology modeling
and should be therefore not treated as an anomaly.

and

and

alignments:

Example. We consider two ontologies a and b with the following
classes
equivalentClasses(a:Lecture,
b:Course)
equivalentClasses(a:Professor,
b:Professor). The following further properties are defined
in the ontologies:
 lectures(a:Professor, a:Lecture) and
 teaches(b:Professor, b:Course).

If lectures and teaches are incorrectly aligned as inverse

properties, then a property cycle is created.

We consider common property and range restrictions and
further restrictions like the quantifiers someValuesFrom and all-
ValuesFrom. Circular properties are detected in Datalog as
follows.

anomaly(circular property, C, Ps) :-

tc connected classes(C, Ps, C),
member(P, Ps),
not(symmetricObjectProperty(P)).

The call anomaly(circular property, C, Ps) computes
classes C that are connected to themselves by a chain Ps of prop-
erties; the chain Ps is computed by using the Datalog predicate
tc connected classes, which will be given in Section 7. If at least
one of the properties is not symmetric, then we have found a circular chain.

4. Inconsistency

Contradictory knowledge contained in ontological knowledge
and rules often yields unintended and unexpected conclusions. In
the past, possible inconsistencies were investigated separately for
both taxonomic knowledge [11] and rule-based knowledge [22].
In the context of this paper, we focus on inconsistent knowledge
that can be detected at the symbolic level. In the common case, the
consistency of ontological knowledge with (general) rules cannot
be derived in a tractable manner.

Typical examples of inconsistencies are contradicting rule consequences for two rules with subsuming rule antecedents. For
taxonomic knowledge, the partition error, which is given by a subclass of two or more classes that are contained in a disjoint partition
(pairwise disjoint classes), is very common. In the following, we
additionally discuss inconsistencies that may occur due to the combined use of rules and ontology definitions.

a:Student) is defined. The following alignment rule would
introduce an incompatible rule antecedent:

a:Student(X) a:Teacher(X) =>b:TA(X)
The example is similar to the partition error shown in Fig. 3,
where the contradicting concept is inherited by two disjoint con-
cepts. In this example, the contradicting concept is derived by a rule
having incompatible concepts in the antecedent.

The following Datalog predicate detects incompatible rule

antecedents.

anomaly(incompatible antecedent, Bs=>A) :-
rule(Bs=>A), sub sequence([Bi, Bj], Bs),
tc incompatible atoms(Bi, Bj).

The basic Prolog predicate sub sequence selects a subsequence of (not necessarily consecutive) elements of a given list.
Note, that the call tc incompatible atoms instantiates the rule
Bs=>A.

An incompatible rule antecedent can also be considered to
be a redundancy, since it is responsible for an unused rule, that
never fires. However, we classify this anomaly as an inconsistency,
because the incompatible antecedent may very likely be the result
of a defective alignment of classes.

4.3. Self-contradicting rule

An anomaly similar to the incompatible rule antecedent is
described by the following: A rule is called self-contradicting, if there
exists an incompatibility relationship between the head atom A and
at least one body atom B, i.e., A and B are disjoint or complements.
Note that, according to our definitions this means that A = C(x) and
B = D(x) are class atoms with the same argument x, and that C and
D are disjoint or complements.

For two ontologies,

Example.
the relationship disjoint-
Classes(a:Teacher, b:Student) can be responsible for creating a self-contradicting rule,
for example b:Student(X)
b:Lecture(Y) b:teaches(X,Y) a:Teacher(X).

The following Datalog predicate derives instances of rules that

are self-contradicting:

anomaly(self contradicting rule, Bs=>A) :-

rule(Bs=>A), member(B, Bs),
tc incompatible atoms(A, B).

If a self-contradicting rule is activated, then the derived conse-

quent contradicts its antecedent.

4.4. Contradicting rules

Consider two instances r and r

 of rules, such that for every body
 implies
 are contradicting, if their head atoms A and A

 would fire, then also the more general rule r

atom B of r there exists a body atom B
B. The rules r and r
are contradicting. If r
would fire, which derives contradicting conclusions.

, such that B

 of r

Example.
For two ontologies a and b, the incorrect equivalence relationship between the properties a:lectures and
b:inLecture will cause the following rules to be contradicting:
 a:Per(X) a:Lec(Y) a:lectures(X,Y) a:Teacher(X),
 b:Per(X) b:Lec(Y) b:inLecture(X,Y) b:Student(X),

Person

and

are

where
Per
relationship disjointand Lec,
and
equivalence
Classes(a:Teacher, b:Student)
relationships between the corresponding classes Person and

respectively, with the

abbreviated

Lecture

the

by

Fig. 3. An example of a partition error, where the concept TA (Teaching Assistent)
inherits from the disjoint concepts Teacher and Student.

4.1. Partition error in taxonomy

The partition error [10] is commonly created due to the incorrect
combination of disjoint and derives relations: There exists a partition error on the class level, when a class C is the subclass of two
disjoint classes Ci, Cj. Similarly, a partition error on the instance
level occurs, when an instance X was created from two disjoint
classes.

Example. Consider the ontology a with a class Person having two
disjoint subclasses Teacher and Student:
 subClassOf(a:Teacher, a:Person),
 subClassOf(a:Student, a:Person), and
 disjointClasses(a:Teacher, a:Student).

The alignment of the class b:TA (TeachingAssistent) of the ontology b as a subclass of both a:Teacher and a:Student would
introduce a partition error, see for example Fig. 3.

The following Datalog predicate detects partition errors,
where X is either a subclass or an instance of the disjoint classes
C1 and C2:

anomaly(partition error, X-[C1, C2]) :-

incompatible(C1, C2),
((derives(X, C1), derives(X, C2))
; (classAssertion(C1, X),
classAssertion(C2, X))).

The Prolog term X-[C1, C2] is used as a syntactic data structure for X and the group of the disjoint classes C1 and C2. Since
Owl 2, it is also possible to define disjointness between properties,
asserting that a given collection of properties is pairwise exclusive.
A partition error for properties can be defined analogously to the
Datalog predicate given above.

4.2. Incompatible rule antecedent

A rule B1    Bn  A has an incompatible antecedent, if there
exists an incompatibility relationship between two body atoms
Bi and Bj, e.g., a disjoint or complement relationship. Note that,
according to our definitions this means that Bi = Ci(x) and Bj = Cj(x)
are class atoms with the same argument it x, and that Ci and Cj are
disjoint or complements.

Example.
Teacher and Student,

Consider the ontology a with two disjoint classes
i.e., disjointClasses(a:Teacher,

J. Baumeister, D. Seipel / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 5568

The described anomaly can be generalized to two (not necessarily disjoint) sets of rules that derive two semantically contradicting
conclusions. However, this generalized type of anomaly cannot be
detected in a purely syntactic manner.

4.5. Multiple functional properties

Functional properties are not allowed to have more than one
value for each individual. Therefore, the functional definition of
a property can be canonically translated to a property with a
minimum cardinality restriction  0 and a maximum cardinality
restriction  1.

For this reason, we can easily detect a semantic error, if a functional property has a maximum cardinality restriction greater than
1. Please note, that a property which transitively derives a functional property is also functional.

The detection of an inconsistently defined maximum cardinality

restriction can be done in Datalog as follows:

anomaly(multiple functionality, Q) :-

functionalObjectProperty(Q),
(P = Q ; tc derives(P, Q)),
max cardinality restriction(C, P, X), X > 1.

With the introduction of Owl 2, also qualified cardinality restrictions are allowed; thus, an additional predicate can be introduced
to check, if particular instances of a property exceed a corresponding qualified restriction. An inconsistent property restriction may
be the result of an incorrectly performed ontology integration, e.g.,
the wrong alignment of functional and non-functional properties.

5. Redundancy

Redundant knowledge is created by ontological definitions and
rules that can be removed from the knowledge base without changing the intended semantics. In most cases, redundancies can be
clearly identified. Typical redundancies for ontologies like identical concepts have already been discussed, for example in [11]. Also,
a separate discussion of rule-based redundancies like subsuming
rules can be found for instance in [23].

In the following, we introduce further redundancies that can
occur due to the combination of ontological definitions and
rules.

5.1. Identity

We call identical formal definitions of classes, properties or
rules, that can be only discriminated by their different names,
identity errors. They can occur if some implied knowledge is not
explicitly stated in the ontology, thus uncovering an incompleteness error.

For example, identical classes may be distinguished by the
developer by the introduction of an additional property for one of
the identical classes. Also identity of classes or rules can be created
by the integration of overlapping ontologies that share (partially)
identical concepts.

5.2. Redundancy by repetitive taxonomic definition

The redundant definition of taxonomic knowledge of classes and
properties was already described by Gomez-Perez [11]. Let X, Y be
either two classes or two properties.

We distinguish two types of repetition:

Fig. 4. An example of the incorrect alignment of the properties lectures and
inLecture resulting in contradicting rules.

Lecture in the ontologies a and b. The example is depicted in
Fig. 4.

Contradicting rule instances can be detected based on a suitable subsumption relation  for clauses, which we will also use for
detecting rule subsumption in a later section. Therefore, we extend
the relation implies from atoms to negative literals: A implies B,
if B implies A. Moreover, we call the disjunction   = B1  . . .  Bn
the body clause of a rule r = B1    Bn  A.
Definition 1 (Subsumption). Given two disjunctions   = L1   
Ln and  = K1    Km of arbitrary (positive or negative) literals
Li and Kj.    , if there exists a substitution 
, such that for all Li
there exists a Kj, where Li
 implies Kj.

In comparison, the standard subsumption relation would

require Li
 = Kj instead of Li
 implies Kj.

The following Datalog rule derives instances of rules that con-

tradict each other:

anomaly(contradicting rules, [R1, R2]) :-

rule(R1), rule(R2),
contradicting rules(R1, R2).

This Datalog rule is supported by the following Prolog rule:

contradicting rules(Bs1=>A1, Bs2=>A2) :-

negate atoms(Bs1, Cs1),
negate atoms(Bs2, Cs2),
clause subsumes(Cs1, Cs2),
tc incompatible atoms(A1, A2).

The Prolog predicate negate atoms transforms a list [B1,
. . ., Bn] of atoms into a list [ B1, . . ., Bn] of negated atoms. The
rule is further supported by the following Prolog predicates
clause subsumes:

clause subsumes(Cs1, Cs2) :-

checklist(implies, Cs1, Cs2).

In case of subsumption, the body of the more general rule r1
always fires when the body of r2 fires. Note that, based on the call of
the Prolog predicate clause subsumes, the predicate above computes instances of r1 and r2, such that the body of the instance of r1
subsumes the body of the instance of r2.1
The consequences A1 = C1(x) and A2 = C2(x) are contradicting, if
the corresponding classes C1 and C2 are incompatible, i.e., disjoint
or complements.

1 If we replace the call to the Prolog goal G = contradicting rules(R1, R2)
by not(not(G)) in the body of the anomaly rule above, then we would check for
subsumption without creating instances.

 direct repetition, where subClassOf(X, Y) is defined more than
once in the ontology;

hand, the rule defines an additional restricted subsumption if the
rule body not only contains B but further atoms. Therefore, the
anomaly may also point to an inconsistent mapping between A
and (an ancestor of) B. For B A, the equivalence may be incorrectly assigned, since the rule condition denotes a restriction on
the implication. This error is similar to circularity between rules and
taxonomy, but with an inverse subclass relation.

rule

With the introduction of Property Chain Inclusion (Object-
PropertyChain) in Owl 2,
it similarly becomes possible to
redundantly derive a property chain by a rule. For instance,
worksFor(Person,Lab) locatedIn(Lab, Org)
the
 . . . worksFor(Person,Org) describes a redundant impliif the following property chain was already defined:
cation,
(ObjectPropertyChain(worksFor locatedIn) worksFor).
When the rule contains additional atoms in the rule body, the
detection of this anomaly points to an incorrectly defined Object-
Property-Chain, since the additional atoms may define a more
restricted constraint on the particular inclusion.

5.5. Redundant implication of transitivity or symmetry

The following two anomalies can be interpreted as special cases

of a rule subsumption.

Transitivity. A rule of the form
r = P(x, y)  Q (y, z)    R(x, z)

with a transitive property R in the head is redundant, if the properties P, Q , and R are equivalent. The reason is that in this situation
the more general rule rt = P(x, y)  Q (y, z)  R(x, z) without  can
be derived by the Owl reasoner. We always assume a property P to
be equivalent to itself.

Example.
For a transitive property sub, which should abbreviate sub-Organization-Of, the following rule redundantly repeats
the transitive definition:
sub(X, Y)  sub(Y, Z)  . . . sub(X, Z).

A redundant definition of a transitive property can be detected

using the following Datalog predicate:

anomaly(redundant transitivity hb, Rule) :-

rule(Rule),
head predicate(Rule, R),
rule transitivity(Rule, R, Rule t),
rule subsumes check(Rule t, Rule).

If Rule is the Datalog representation of an arbitrary rule r
with the head predicate R, then the supporting Prolog predicate rule transitivity/3, cf. Section 7, tests if R is transitive
and constructs the Datalog representation Rule t of the rule
rt = P(x, y)  Q (y, z)  R(x, z), such that P, Q , and R are equivalent.
Then, we can check if rt subsumes r; this depends on the
arguments of the predicates P, Q , and R in r. For example, rt subsumes the rule r from above, but it does not subsume the rule
 = P(x, y)  Q (y, z)    R(z, x).

Symmetry. An analogous anomaly can occur for symmetrical
properties R in rule heads: if R is equivalent to the property P, then
the rule
r = P(x, y)    R(y, x)
is redundant, since the more general rule rs = P(x, y)  R(y, x)
without  can be derived by the Owl reasoner. In Datalog we

Fig. 5. An example for a rule redundantly deriving an already known parent.

 indirect repetition, where subClassOf(X, Y) is defined, but this
relation can also be derived by a chain subClassOf(X, Y1), sub-
ClassOf(X1, X2), . . .subClassOf(Xn, Y) with n  1.

Direct and indirect repetition corresponding to the instantiation
of classes and properties can also be defined on instance-of instead
of subclass relations. A repetitive definition can easily occur due to
the (correct) alignment of two classes or properties. In such cases,
repetitions are not an undesirable redundancy, but an intended
behavior.

5.3. Rule subsumption

, for short r  r

alent disjunction clause(r) = B1  . . .  Bn  A.
We say that a rule r subsumes another rule r
clause(r)  clause(r
head A
 with respect to the same substitution 
.

A rule r = B1    Bn  A, can be mapped to a logically equiv-
, if
). This means, that the head A of r subsumes the
, and the body clause of r subsumes the body clause of
 can be removed without changing the
semantics of the ontology. Subsuming rules can be detected by
the following Datalog predicate, where the Prolog predicate
rule subsumes check, which we do not list here, is used for checking subsumption:

 of r

A subsumed rule r

anomaly(subsumed rule, [R1, R2]) :-

rule(R1), rule(R2),
rule subsumes check(R1, R2),
not(rule subsumes check(R2, R1)).

5.4. Redundant implication

A rule r (over class or property atoms) has a redundant implication of a parent, if some body atom B implies the head atom
A.
This can be seen as a special case of rule subsumption, since the
implication can be seen as a rule B  A, which subsumes the rule r.
Example. Given the subclass relation subClassOf(Professor,
Teacher), the following rule redundantly derives the parent
Teacher:
Professor(X) Lecture(Y) teaches(X,Y) Teacher(X).
The example is depicted in Fig. 5.
In Datalog, such a redundancy can be defined as follows:

anomaly(implication of superclass, Bs=>A) :-

rule(Bs=>A), member(B, Bs),
implies(B, A).

Besides the obviously redundant

inclusion of B in the
antecedent, this anomaly might also point to an incorrectly
assigned subsumption relation between A and B. On the one hand,
there exists a separate subsumption between A and B. On the other

J. Baumeister, D. Seipel / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 5568

detect such a redundancy as follows:

anomaly(redundant symmetry hb, Rule) :-

rule(Rule),
head predicate(Rule, R),
rule symmetry(Rule, R, Rule s),
rule subsumes check(Rule s, Rule).

If Rule is the Datalog representation of an arbitrary rule r
with the head predicate R, then the supporting Prolog predicate rule symmetry/3, cf. Section 7, tests if R is transitive and
constructs the Datalog representation Rule s of the rule rs =
P(x, y)  R(y, x), such that P and R are equivalent. Then, we can
check if rs subsumes r, which again depends on the arguments of
the predicates P and R in r.

Often such redundancies can be explained by an erroneous
assumption of the transitivity or symmetry during an ontology
matching process. Then, the rules define a more restrictive condition of transitivity and symmetry, respectively, if the conjunctions
 are not empty.

For this reason, the anomalies may be either classified as inconsistent mappings of the properties, or as incorrect alignments of
transitivity and symmetry.

6. The

Fig.
a:worksWith(X,Y) b:collaborates(Y,X) b:E(Y).

redundantly uses

rule

symmetrical property:

a:P(X)

In Datalog  with a supporting Prolog rule this can be

detected using the Prolog predicate clause subsumes check:

anomaly(redundant transitivity b, Rule) :-

rule(Rule),
body predicate(Rule, R),
rule transitivity(
Rule, R, [Pxy, Qyz]=>Rxz),
rule to clause(Rule, [ |Cs]),
clause subsumes check(
[ Pxy,  Qyz,  Rxz], Cs).

5.6. Redundancy in the antecedent of a rule

Redundancy in the antecedent may occur because of redundant
derivations of classes or properties, or because of already defined
property relations.

We first construct three atoms Rxz, Pxy, and Qyz for equivalent
properties, where R is a transitive property that occurs in the body
of a rule Rule together with P and Q. Then, we form a clause from
the negations of the three atoms and check if it subsumes the body
clause Cs of Rule. The body clause Cs is obtained by applying the
predicate rule to clause and omitting the first element of the
result, which is the head of Rule.

5.6.1. Redundant derivation in the antecedent
A redundancy in the antecedent of a rule occurs in a rule B1 
  Bn  A, if some body atom Bi implies another body atom Bj.
Here, Bj is redundant in the rule body and may be removed.

The

Example.
subClas-
sOf(TeachingAssistant, Person) makes the atom Person(X)
redundant in the following rule:

Person(X) TeachingAssistant(X)  . . . Employee(X)

relationship

subclass

The Datalog implementation for finding the anomaly is as fol-

lows:

anomaly(redundant derivation, Bs=>A) :-

rule(Bs=>A), sub sequence([Bi, Bj], Bs),
(implies(Bi, Bj)
; implies(Bj, Bi)).

As a special case, this form of redundancy can occur in the ontol-
ogy, if Bi  Bj, e.g., due to the definition of equivalence relations. The
anomaly may alternatively point to an incorrect mapping between
the elements Bi and Bj, when these two elements were aligned from
different ontologies.

5.6.2. Redundant use of transitivity and symmetry

With the definition of special property characteristics in Owl,
further anomalies may occur. For equivalent properties P, Q, R,
there may exist the following redundancies:

 A rule P(x, y)  Q (y, z)  R(x, z)    A has a redundant body
atom R(x, z), if the properties P, Q, R, are transitive.
 A rule P(x, y)  Q (y, x)    A has a redundant body atom
Q (x, y), if the properties P and Q are equivalent and symmetric.

anomaly(redundant symmetry b, Rule) :-

rule(Rule),
body predicate(Rule, Q),
rule symmetry(Rule, Q, [Pxy]=>Qyx),
rule to clause(Rule, [ |Cs]),
clause subsumes check([ Pxy,  Qyx], Cs).

We construct two atoms Pxy and Qyx for equivalent properties,
where P is a symmetric property that occurs in the body of a rule
Rule together with Q. Then, we form a clause from the negations of
the two atoms, and we check if it subsumes the body clause Cs of
Rule.

Example. For two ontologies a and b, the symmetric properties
 a:worksWith(a:Person, a:Person) and
 b:collaborates(b:Person, b:Employee)

were defined to be equivalent. With the alignment equiv-
alentClasses(a:Person, b:Person) and the relationship
subClassOf(b:Employee, b:Person),
a:P(X)
a:worksWith(X,Y) b:colla-borates(Y,X) b:E(Y), where
Person and Employee are abbreviated by P and E, respectively,
redundantly includes one of the two symmetric properties; either
the use of worksWith or collaborates is redundant. In Fig. 6 the
concepts and properties together with their alignments are shown.

rule

the

Like the redundant definitions of transitivity and symmetry as
described in Section 5.5, these anomalies can point to an incorrect
mapping of properties during an ontology alignment process.

5.7. Unsupported rule condition

A rule r has an unsupported condition, if at least one of its
body atoms B neither unifies with an input atom (e.g., a given
instantiation of the ontological concepts) nor with the consequent

of another rule. The corresponding Datalog predicate is shown
below:

The restriction is redundant, because the functionality of a prop-

erty requires its uniqueness for the entire ontology.

anomaly(unsupported condition, Bs=>A) :-

rule(Bs=>A), member(B, Bs),
not(call(B)), not(rule( =>B)).

The following Datalog predicate detects redundant max-

cardinality restrictions:

The rule even checks if some call of the atom B is successful.

5.8. Unsatisfiable rule condition

An unsatisfiable condition can occur due to the rich semantics
of Owl, for instance, if complement or disjoint descriptions are
incorrectly aligned. The rule antecedent is unsatisfiable, if two body
literals Bi = Ci(x) and Bj = Cj(x) are incompatible.

The definition of an unsatisfiable condition is given in Datalog

as follows:

anomaly(unsatisfiable condition, Bs=>A) :-
rule(Bs=>A), sub sequence([Bi, Bj], Bs),
tc incompatible atoms(Bi, Bj).

The anomaly was also described as the inconsistency incompatible rule antecedent in Section 4.2, because the occurrence of
such a rule in a (merged) ontology may also point to an incorrect
alignment of a disjoint or complement description.

5.9. Redundant cardinalities

When using properties to define relations between classes,
the relation can be further specialized by cardinality restric-
tions. However, sometimes the cardinalities are redundant due
to the semantics of some special properties in Owl. One example is the use of the minimal cardinality  0, since all instances
of a property have a link to zero or more individuals in its
domain definition. The detection of a redundant min-cardinality
restriction can simply be done using the following Datalog pred-
icate:

anomaly(redundant mincardinality 0, Q) :-

min cardinality restriction(C, P, 0).

Example.
redundant cardinality restriction, that can be omitted.

The property teaches(Person, Person) defines a

<owl:Restriction>

<owl:onProperty rdf:resource=#teaches/>
<owl:minCardinality

rdf:datatype=&xsd;nonNegativeInteger>
0 </owl:minCardinality>

</owl:Restriction>

Another example for redundant cardinality restrictions is a
max-cardinality restriction  1 for functional properties.
If a
super-property of the property is functional, then the cardinality
restriction is also redundant.

For

Example.
hasID(Organization,
&xsd;string), a max-cardinality restriction with  1 is defined. If
the property is also functional, then the restriction can be omitted.

property

<owl:Restriction>

<owl:onProperty rdf:resource=#hasID />
<owl:maxCardinality

rdf:datatype=&xsd;nonNegativeInteger>

1 </owl:maxCardinality>
</owl:Restriction>

anomaly(subsumed maxcardinality 1, Q) :-

functionalObjectProperty(Q),
(P = Q ; tc derives(P, Q)),
max cardinality restriction(C, P, 1).

Since a functionality definition is intuitively well-defined, this
concept should be preferred when compared to a max-cardinality
restriction.

6. Deficiency

Deficiency is more subtle than the previously presented categories of anomalies. The following anomalies consider the
completeness, understandability and maintainability of ontologies.
Possible sources of such anomalies are imprecision during the manual development of (large) ontologies, effects of the evolution of
ontologies, e.g., [31], and erroneous side-effects of the integration
of ontologies.

Since deficiencies mostly detect areas in an ontology with
problematic design, we also call them design anomalies. The identification of such an anomaly is the starting point of a refactoring.
Refactoring methods describe procedures to eliminate the corresponding design anomaly without changing the meaning of the
remaining knowledge.

Originally, design anomalies had been identified and invesIn the last years, software
tigated for relational databases.
engineering research has coined the term bad smells for parts of
the source code that do not produce false behavior, but are badly
designed and should be improved for better maintainability, cf.
[21,9]. Recently, some approaches were presented to transfer this
idea to the conceptual properties of different knowledge representations [3,6] and Owl ontologies [4,5].

In the following, we present a set of possible anomalies that
affect the design of an ontology. However, these can be only seen
as indicators for an actual anomaly. In any case the user has to
decide whether and how to remove the possible issue. The presented design anomalies mainly focus on the detection of badly
designed ontology concepts. For some anomalies their use in rules
is taken into account, whereas other anomalies can occur independent of the existence of rule-based knowledge.

6.1. Lazy class/property

The usage of a class or property is often a good indicator for its
actual utility. We call a class or a property of an ontology lazy, if it
is never or rarely used in real-world applications. More precisely,
an element is possibly lazy when

 the element represents a leaf in the hierarchy, and
 no rules use this element, and
 there exist no instances of the element, and
 no other element uses this element as a property.

There exist a number of reasons for the occurrence of this
anomaly: Lazy elements may occur due to the integration of ontologies (including terms that are not useful or relevant any more), or
due to the evolution of an ontology (previously useful concepts
were replaced by specializations or generalizations).

J. Baumeister, D. Seipel / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 5568

In Datalog, a possibly lazy element E can be detected as follows:

anomaly(lazy element, E) :-

element(E),
not(subClassOf( , E)),
not(rule predicate(E)),
not(instance( , E)).

The supporting predicate element is defined in Prolog:

element(E) :-

(class(E)
; objectProperty(E)
; datatypeProperty(E)
; transitiveObjectProperty(E)
; symmetricObjectProperty(E)
; functionalObjectProperty(E)
; inverseObjectProperties(E, )).

The constraints stated above can be relaxed by checking for very
few rules with the considered element in their head or body. Then,
these rules have to be inspected by the user and marked as not
useful.

6.2. Chains of inheritance

The hierarchy of classes and properties define the backbone
of every ontology. Simple subclass relations are used to describe
the inheritance of concepts and property relations. During the
evolution of (manually built) ontologies or due to the imprecise
integration of ontologies, the intended subclass structure of classes
and properties can degenerate to subclass cascades in some parts
of the hierarchy.

A taxonomic chain

C1, C2, . . . , Cn

of pairwise different classes Ci, where Ci1 is a subclass of Ci, for
2  i  n, is called a chain of inheritance, if all intermediate classes
C2, . . . , Cn1 are not participating in any other subclass relations
except the ones in the chain (isolated subClassOf), see Fig. 7.

Fig. 7. A chain of inheritance of classes C1, . . . Cn.

Fig. 8. Lonely disjointa distant class C disjoint to a collection of siblings C1, . . . Cn.

The intermediate elements Ci may be not useful for applications,

when

(i) there exist no or very few individuals for the elements Ci and
(ii) the elements Ci are not (extensively) used in ontological defi-

nitions, e.g., restrictions, or in rules.

A maximal chain of inheritance can be detected in Datalog as

follows.

anomaly(chain of inheritance, Cs) :-

maximal simple path(
isolated subClassOf, Cs).

isolated subClassOf(C1, C2) :-

subClassOf(C1, C2),
not((subClassOf(C1, C), C \= C2)),
not((subClassOf(C, C2), C \= C1)).

The Prolog predicate maximal simple path from a graph
library computes simple paths, which at both ends cannot be
extended by an isolated subClassOf.

If the user has decided to eliminate the useless elements of the
chain, then the particular elements have to be removed separately
by the refactoring collapse hierarchy [5].

6.3. Lonely disjoint class

We call a class a lonely disjoint, if this class is not disjoint with any
of its siblings, but it is disjoint with classes that are mutual siblings
in another branch of the taxonomy. See Fig. 8 for an example, where
class C is a lonely disjoint, since C is disjoint to the classes C1, . . . , Cn,
that are siblings but not a sibling of C. It is worth noticing that the
class C does not need to be disjoint to all Ci in the disjoint partition,
but to a sufficiently large number of classes Ci (in Fig. 8, class Cn+1
is not disjoint with C).

The Datalog implementation of this anomaly is as follows:

anomaly(lonely disjoint, C) :-

class(C), siblings(Cs),
checklist(disjointClasses(C), Cs).
not((sibling(C, M),
disjointClasses(C, M))).

The Prolog meta-predicate checklist/2 calls disjoint-
Classes(C, D) for all members D of the list Cs to determine,
whether C and D (the C is always the same) are disjoint. The rule is
supported by two Prolog rules for sibling and siblings, respec-
tively, including aggregation, which we will see in Section 7.

A lonely disjoint class is often created by the manual modification of the ontology: a class is moved to another branch of the
taxonomy, but the attached disjointness descriptions are not realigned appropriately. Furthermore, the anomaly can also occur
due to incorrect alignments during an ontology integration task.
The existence of a lonely disjoint class can cause unintended reasoning results or even errors. The developer of the ontology has to
decide manually about detected lonely disjoints. The elimination
of an actual anomaly is quite simple: the disjointness property is
just removed from the lonely disjoint class.

tions or rules. A detailed example of this refactoring is shown in
[5].

It is worth noticing that the elimination of an over-specific property range can introduce new redundancies or even inconsistencies.
For example, redundant rules are commonly produced when there
exist equivalent rules with values that were coarsened to a single
value. Inconsistent rules can occur due to a semantically inconsistent mapping function. In consequence, after the elimination of
an anomaly, it is reasonable to undergo a subsequent check for
redundant or inconsistent definitions.

6.4. Over-specific property range

6.5. Property clump

Sometimes the developers of an ontology tend to be very specific
when defining value ranges for properties. During the practical use
of the ontology, it often turns out that the values are too specific
and that a coarser range with less values would fit the considered
domain much better.

The

value

range

= {high

Rtemp = {veryhigh, high
Example.
normal, low, verylow} of a property temp (for
temperature)
may contain five possible values, but
the actual application of
the property uncovers that a more general range
} with three values would work much

temp
better. A typical example for this situation is the alignment of two
ontologies, where the value range of a specific concept is shrunk
in order to match with a foreign concept. A further example is the
planned use of the developed system by human operators: here, a
smaller and more comprehensible range of values is less prone to
errors caused by manual data entry.

, normal, low

If rules are defined containing this property, then the anomaly
can be identified by the existence of many analogous rules for the
particular values. In our example, rules for the values high and very
high could be present.

In such cases, the refactoring coarsen value range [5] forms

 = {high, very high} and low

groups of equivalent values, e.g., high
{low, very low}.

The following Datalog predicate detects over-specific property ranges by determining pairs of rules that have variants
has value(P, Vi) in their antecedent (with i = 1, 2). This type
of rule pair is found by deleting the variants from the rule bodies
and subsequently testing for their equality.

anomaly(over specific,

[R1, R2, has value(P,[V1,V2])]) :-
rule(R1), rule(R2),
R1 = Bs1=>A, R2 = Bs2=>A, R1 \= R2,
delete(has value(P, V1), Bs1, Bs),
delete(has value(P, V2), Bs2, Bs).

An analogous Datalog predicate can be defined for overspecific property ranges in rule consequences. The anomaly is
removed by replacing the original values of the property with the
aggregated ones in every ontological definition, e.g., in restric-

In ontologies, properties are commonly used to define relations
and attributes between classes and individuals, respectively. The
repeated and identical use of a collection of properties in many
classes is a deficiency called property clump. A property clump is
comparable to the repeated use of code fragments in traditional
software, so-called clones.
For ontologies, a property clump PC = (C,P) is formed by a set C =
{C1, . . . , Cn} of at least two classes, that all share the same set P =
{P1, . . . , Pm} of properties; these properties can describe data type
properties and object properties. Such an unintentionally repeated
definition of properties in different classes can occur due to the
manual development and evolution of an ontology.

The following Datalog rules find all maximal sets Cs of classes

that have the same set Ps of properties in common:

anomaly(property clump, [Cs, Ps]) :-

setof(C, class has properties(C, Ps), Cs),
length(Cs, N), N > 1.

class has properties(C, Ps) :-

setof(P, class has property(C, P), Ps).

We used two nested aggregations based on the powerful Prolog meta-predicate setof/3. The inner aggregation computes a
class and its properties. The outer aggregation computes all classes
having the same set of properties.
The repeated use of properties of a clump PC = (C,P) can be
caught by a new class CP, which gets the properties inP. The original
classes C C are linked to CP instead of linking them to the properties P. For ontologies with rules, we have to change all rules with
property atoms P(x, y) for P P in their antecedent or consequent.
The definition of such an abstract property class CP may increase
the compactness and the maintainability (with respect to changes,
extensions, fixes) of the ontology.
An example of a property clump P = {P1, P2, P3, P4} used by
three classes C1, C2, and C3 is depicted in Fig. 9 (left); the refactored design using an abstract property class CP is shown at the
right of the figure.

The introduction of a new class, that captures related aspects
of another class, is also discussed in the ontology design pattern
n-ary relations [20], where a new class is created in order to link
the instances of n individuals to an instance of a single class. With

Fig. 9. Refactoring a property clump to an n-ary relation with the abstract property class P.

J. Baumeister, D. Seipel / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 5568

the identification of a property clump, incorrectly modeled n-ary
relations may be uncovered. The extraction of such repetitions into
a single data structure is a common refactoring, which improves
the compactness and maintainability of the implementation.

7. Implementation in Datalog

The introduced anomalies have also been defined by an implementation in the new language Datalog. Using this language, we
have developed a new approach that extends the Datalog paradigm
and mixes it with Prolog. The analysis can be run using the system
DisLog Developers Kit (DDK) [30]. This toolkit provides a module including the presented implementation of Datalog and the
anomaly predicates as well as the shown examples.

For the interested reader, we introduce some technical details
of the evaluation mechanisms of Datalog in the following. For the
detection of anomalies a number of further Datalog and Prolog
predicates were used. We describe their implementation in Sections 7.3 and 7.4.

7.1. Mixing Datalog and Prolog: forward and backward
chaining

The detection of anomalies in rule ontologies could not be formulated using Prologs backward chaining or Datalogs forward
chaining alone, since we need recursion on cyclic data, function
symbols (mainly for representing lists), non-grounded facts, dis-
junction, negation, and aggregation (using meta-predicates) in rule
bodies, and stratification.

Datalog and Prolog. We distinguish between Datalog rules
and Prolog rules: Datalog rules are forward chaining rules that
may contain function symbols (in rule heads and bodies) as well
as negation, disjunction, and Prolog predicates in rule bodies.
Datalog rules are evaluated bottom-up, and all possible conclusions are derived.

The supporting Prolog rules are evaluated top-down, and  for
efficiency reasons  only on demand, and they can refer to Datalog
facts. The Prolog rules are also necessary for expressivity reasons:
they are used for some computations on complex terms, and  more
importantly  for computing very general aggregations of Datalog
facts.

Forward and backward chaining. Datalog rules cannot be evaluated in Prolog or Datalog alone for the following reasons:
Current Datalog engines cannot handle function symbols and
non-grounded facts, and they do not allow for the embedded computations (arbitrary built-in predicates), which we need here in this
work. Standard Prolog systems cannot easily handle recursion with
cycles, because of non-termination, and are inefficient, because of
subqueries that are posed and answered multiply. Thus, they have
to be extended by some Datalog facilities (our approach) or mem-
oing/tabling facilities (the approach of the Prolog extension Xsb
[24]). Since the embedding system, the DDK [30], is developed in
Swi-Prolog, we have implemented a new inference machine that
can handle mixed, stratified Datalog /Prolog rule systems.

The evaluation of Datalog programs mixes forward-chained
evaluation of Datalog with SLD-resolution of Prolog, see Fig. 10.
A Datalog rule A  B1    Bn can contain atoms Bi which are
evaluated backward in Prolog.

7.2. Stratified evaluation of Datalog

For the ontology evaluation we have implemented two layers

(strata) D1 and D2 of Datalog rules:
 The upper layer D2 consists of the rules for the predicate
anomaly/2 and some Datalog rules that are stated together with
them.

Fig. 10. Mixing forward and backward chaining.

 The lower layer D1 consists of all other Datalog rules. For exam-
ple, the rules for predicates derives and tc derives are in D1.

D1 is applied to the Datalog facts for the following basic pred-
icates, which have to be derived from the underlying ontology
document:

rule, class, sub-Class-Of,
object-Complement-Of, incompatible,
equivalentObjectProperties,
equivalentClasses,
transitive/symmetricObjectProperty,
min/max cardinality restriction,
property restriction,
class has property.
The resulting Datalog facts are the input for D2. The stratification into two layers is necessary, because D2 refers to D1 through
negation and aggregation. Most Prolog predicates in this paper support the layer D2.

7.3. Further Datalog predicates

The following Datalog predicate computes a chain Ps of prop-

erties that connect two classes C and D using transitive closure:

tc connected classes(C, [P], D) :-

connected classes(C, P, D).

tc connected classes(C, [P|Ps], D) :-

connected classes(C, P, E),
tc connected classes(E, Ps, D),
not(member(P, Ps)).

connected classes(C, P, D) :-

tc derives(C, C ),
property restriction(C , P, D ),
tc derives(D , D).

7.4. Further supporting Prolog predicates

Head and body. The head and body predicates of a rule can be

determined using the following pure Prolog predicates:

head predicate( =>A, P) :-

functor(A, P, ).

body predicate(Bs=> , P) :-

member(B, Bs), functor(B, P, ).

rule predicate(E) :-

rule(Rule),
(head predicate(Rule, E)
; body predicate(Rule, E)).

Siblings. The following Prolog rules define siblings and aggregate
the siblings Z of a class X to a list Xs using the Prolog meta-predicate

setof/3, respectively:

sibling(X, Y) :-

subClassOf(X, Z),
subClassOf(Y, Z), X = Y.

siblings(Zs) :-

setof(Z, sibling(X, Z), Zs).

These rules could also be evaluated in Datalog using forward
chaining. But, since we need siblings only for certain lists Zs, this
would be far too inefficient. The call to setof/3 above succeeds
for every class X having siblings, and it computes the list Zs of all
siblings Z of X. On backtracking, the siblings of the other classes X
are computed. This means, setof/3 does a grouping on the variable
X. Within setof/3, the call sibling(X, Z) computes one class X
and its siblings Z.

Transitivity. Given a Datalog rule Rule and a predicate R, the
following Prolog rule tests if R is transitive and then constructs
three atoms Rxz, Pxy, and Qyz, where P and Q are body predicates
of Rule that are equivalent to R. Finally, it forms a Datalog rule
Rule t from the three atoms.

rule transitivity(Rule, R, Rule t) :-

transitiveObjectProperty(R),
body predicate(Rule, P),
equivalentObjectProperties(R, P),
body predicate(Rule, Q),
equivalentObjectProperties(R, Q),
Pxy =.. [P,X,Y], Qyz =.. [Q,Y,Z],
Rxz =.. [R,X,Z],
Rule t = [Pxy, Qyz]=>Rxz.

Symmetry. Given a Datalog rule Rule and a predicate R, the
following Prolog rule tests if R is symmetric and then constructs
two atoms Pxy and Ryx, where P is a body predicate of Rule that
is equivalent to R. Finally, it forms a Datalog rule Rule s from the
two atoms.

rule symmetry(Rule, R, Rule s) :-

symmetricObjectProperty(R),
body predicate(Rule, P),
equivalentObjectProperties(R, P),
Pxy =.. [P,X,Y], Ryx =.. [R,Y,X],
Rule s = [Pxy]=>Ryx.

8. Discussion

For the last couple of years, ontologies have played a major
role for building intelligent systems. Currently, the standard ontology language Owl is extended by rule-based elements using, e.g.,
the rule interchange format Rif or the semantic web rule language
Swrl. With the introduction of Owl 2 Rl a profile of Owl is defined,
that is especially useful for the interchange with rule-based knowl-
edge. We have shown, that with the increased expressiveness of
ontologies  now also including rules  a number of new evaluation issues has to be considered. In this paper, we have presented
a collection of typical anomalies that arise during practical ontology development, especially when aligning and integrating existing
ontologies.

When reviewing the described anomalies, we see that most
issues only depend on Owl axioms with a low expressivity, i.e.,
many anomalies can occur even when using the simple Owl 2
El profile [13,34]. Only the following anomalies take advantage
of more expressive Owl axioms requiring the profiles Owl 2 Ql
or Owl 2 Rl: Circular Properties (Section 3.2), Multiple Functional
Properties (Section 4.5), Redundant Implication of Transitivity or
Symmetry (Section 5.5), Redundant Use of Transitivity and Symmetry (Section 5.6.2), and Redundant Cardinalities (Section 5.9).
About a half of the issues required the existence of rules in
the knowledge base. Of course, the presented anomalies only

gave a brief insight into the collection of possible verification
issues.

Anomalies were considered concerning the basic elements of
the ontology language. When using built-ins, the detection of
anomalies becomes a difficult task, since the semantics of builtins can rarely be evaluated at the symbolic level. Simple problems
occurring with built-ins are easily detectable, especially the definition of identical knowledge. For instance, the assessment of the
body-mass-index (BMI) in two medical ontologies a and b is redundant given the rules
op:num-greater-than(W,25)
a:hasBMI(P,W)
a:overweight(P)

and the rule
b:calBMI(P,W)
b:heavy(P)

op:num-greater-than(W,25)

where a:hasBMI and b:calBMI are defined as equivalent, and

a:overweight and b:heavy are equivalent, respectively.

Here, easily detectable inconsistencies can be identified; for
example, when the numeric threshold is specified differently in
the above rules. The analysis of more complex definitions, however,
becomes much more difficult, when the semantics of the built-ins
cannot be mapped to the symbolic level.

For all discussed anomalies, we have introduced a declarative
approach using Datalog for implementing the anomaly checks for
ontology verification. Due to its declarative nature, new methods
for anomaly detection can be easily added to the existing work.
From our point of view, this is crucial, because of the incompleteness of the presented anomalies: in principle, giving a complete
overview of possible anomalies is not feasible, since the number of
anomalies depends on the expressiveness of the ontology and the
rule representation, respectively, that should be verified.

The actual frequency of the introduced anomalies is an interesting issue. However, only a small number of ontologies (mostly toy
examples) is available that make use of a rule extension. A sound
review of anomaly occurrences would require a reasonable number
of practical ontologies with a significant size.

Furthermore, larger systems may also include parts of a nonmonotonic rule base. Here, some work has been done on the
verification of non-monotonic rule bases [37,38], that has to be
re-considered in the presence of an ontological layer.
