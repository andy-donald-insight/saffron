Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 241254

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

Modeling and querying graphical representations of statistical data
Michel Dumontier a,c, Leo Ferres b,, Natalia Villanueva-Rosales c

a Department of Biology, Carleton University, Ottawa, Canada
b Department of Computer Science, University of Concepcion, Concepcion, Chile
c School of Computer Science, Carleton University, Ottawa, Canada

a r t i c l e

i n f o

a b s t r a c t

Although pictorial renditions of statistical data are ubiquitous, few techniques and standards exist
to exchange, search and query these graphical representations. We present several improvements to
humangraph interaction including (i) a new approach to manage statistical graph knowledge by semantic annotation of graphs that bridges the gap between Web 2.0 social tagging and formal, logic-based
approaches, (ii) knowledge management and discovery across a non-trivial graph knowledge base and
(iii) sophisticated question answering that requires background knowledge.

 2009 Elsevier B.V. All rights reserved.

Article history:
Received 9 December 2008
Received in revised form
16 December 2009
Accepted 18 December 2009
Available online 4 January 2010

Keywords:
Charts and graphs
Statistics
Semantic Web
Ontology
Accessibility

1. Introduction

Since their first appearance in print in the early nineteenth century (see [47], referenced in [36]), line graphs, bar graphs, pie charts,
and the rest of the so-called statistical graphs [36], have become
the de facto representational medium to communicate knowledge
originally stored in simple numerical datasets. Government agen-
cies, businesses, and academia publish countless statistical graphs
every day about an incredibly wide variety of topics. Their ubiquity
notwithstanding, finding, exchanging, integrating, and in general
computing [3] with these representations in the World Wide Web
is becoming more and more of a challenge. The aim of this work
is to make statistical graphs available as highly structured representations that can be queried, exchanged, integrated and whose
structure can be extended using Semantic Web (SW) technology.
In particular, we concentrate on n-variable line graphs appearing
in Statistics Canadas online publication, The Daily [52].

Graphical representations of numerical data serve two fundamentally different purposes: data exploration and data communication [36]. Graphs falling in the former category (exploratory
graphs) are usually quickly put together for private analy-
sis. They contain most of the available data and are geared
towards discovering patterns in them. These graphs are usually discarded after analysis. By contrast, by being geared towards mass

 Corresponding author. Tel.: +56 41 220 3573; fax: +56 41 222 1770.
E-mail address: leo@inf.udec.cl (L. Ferres).

1570-8268/$  see front matter  2009 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2009.12.002

dissemination and consumption, graphs falling in the latter category (communicative graphs) usually involve less data, the message
they contain is clearer and when finally published, they have a
more permanent presence. In this paper we deal with the latter
kind.

By far, the most common practice is to create (communicative)
statistical graphs using technologies that produce raster images
(e.g. gif, or jpg). Statistics Canada produces and publishes hundreds of graphs a week about all aspects of Canadian and world
socio-economic issues, including an average of two graphs per day
in our target publication, The Daily. Graphs in The Daily are
currently published only in gif format, along with some restricted
access to the underlying database. If we consider the total repository of graphs published since the first digital edition of The Daily
in 1995, there is a total of 5575 unstructured graphs.

While unstructured formats may be enough to communicate a
graphs content in certain situations (e.g. discussing a graph during
a business meeting or embedding it in a paper report), they pose
serious challenges for more involved tasks. First, even the simplest
tasks such as obtaining the precise information encoded in them is
either not possible or too complicated for the occasional user. In the
case of The Daily, for instance, if a graph consumer needs to find
the precise value of just one point in a published graph he or she
will have to use the Structured Query Language (SQL) to query the
cansim database, a large, multidimensional database to find just
this one value. This can be done, but it is far from ideal. Instead,
the user could simply querying the local representation of the
graph.

M. Dumontier et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 241254

Second, graphs are much more than the numerical tables that
give rise to them, and, therefore, querying graphs provides richer
answers than querying the numerical dataset. In creating graphs
for publishing and mass consumption, graph authors or graph composers as they are known in Statistics Canada, always have a very
distinct communicative purpose in mind; e.g. to show how employment has declined in the first few months of 2008, or to show the
upwards trend in investment in non-residential building construc-
tion. These graph composers have all the graphing applications
drawing power at their disposal, but they have to settle for only
a few characteristics to put into the graph: its size, how steep the
lines will look, the general geometry of the graph, the number of
categories to show and points to plot, the colors, etc. Since the
success of graphs as representations of numerical data relies, for
the most part, on the human ability to recognize and remember
visual patterns [34,36], then the composer is in fact determining
what information the user will be able to obtain from the graph.
This activity acts as a summarization of all the data into potentially
interesting or important data. In short, graphs may be thought
of as value-added representations of some underlying numerical
dataset, and therefore querying graphs taking into account how
they look and what they are about is a world apart from querying
a database of numbers.

In addition, it has become apparent that statistical agencies may
want to exchange graphs, instead of only the numerical DBs they
are based on. However, this poses many problems for graphs as
unstructured, or semi-structured representations. Suppose a composer has decided to use quarters as the primary category in the
x-axis of a graph. These categories, without semantics, would be
misleading. For instance, the Canadian and United States quarters
span different time periods. Saying that employment increases in
the first quarter in Canada is saying that employment increases
between April and June, while in the United States it will be
understood as increasing between October and December. Without
deeper understanding of the semantics of this regional terminol-
ogy, this knowledge is simply not available or may result in using
false information during vital decision-making.

Third, given the nature of the domain, there is always the need
to add information besides that which comes formally embedded
in graphs. We have thus attempted to make the graph model extensible by mixing Web 2.0 approaches and Semantic Web technology.
Briefly, we provide the ability to tag graphs with alternative information that may be used for a task not previously contemplated. As
such, a tag may be simply provided with some textual description
associated to it, or it may be more or less ontologically committed.
This has the advantage of making the base formalization extensible
with alternative semantics.

Finally, by structuring and providing semantics to digital graphical representations, there is the possibility of translating graphical
information into several other modalities such as sound, or speech
or force-feedback mice to provide universal access to knowledge.
The work reported in this paper has in fact been inspired by issues
of accessibility to statistical data by blind and visually impaired
internet users [18]. Governments are striving to make their websites as accessible as possible, an activity even sanctioned as a
law in the United States (see Section 5081) and strongly pursued in Canada as laws that prohibit discrimination of any kind
(see the Canadian Charter of Rights and Freedoms2). We believe
Semantic Web technologies to be ideal for this purpose, and the
potential that particular communities tag graphs with their own
view of the world is a very attractive effect of the proposed
methodology.

1 http://www.section508.gov/.
2 http://lois.justice.gc.ca/en/charter/.

In summary, the representation of statistical graphs in an
unstructured format has several important drawbacks, including,
(i) the inability to obtain precise information about the graph (e.g.
what is the exact value of the datapoint for January 2005 of Graph
1 in Fig. 4, on page 10?), (ii) the inability to exchange or merge
complementary graphs (such as integrating the complementary
information in Graphs 3 and 4 in Fig. 4), (iii) the inability to retrieve
graphs having particular content, given particular visual cues or
that require deeper knowledge of a graphs general purpose (such
as returning those graphs that are about all kinds of sales except car
sales), (iv) the impossibility of extending the representation with
alternative knowledge and (v) the inability to present them in other
modalities (such as sound or speech) to make them accessible to
audiences with special needs.

We sought to solve these problems by (a) analyzing a repository of graphs in all their visual detail and automatically mining
them from graphing applications such as MS Excel, (b) providing a novel, clean methodology that allows semantic annotation of
graphs and bridges the gap between Web 2.0 social tagging and
Semantic Web ontologies, (c) demonstrating knowledge management and discovery across a non-trivial graph knowledge base and
(d) demonstrating sophisticated question answering that requires
background knowledge. This work marks an important milestone
towards the creation of annotated graphs that are machine under-
standable, compatible with Semantic Web technologies, and that
can be queried with precise semantics.

The paper is organized as follows: in the next section we review
the literature and systems most closely related to our work. Section
3 deals with the automatic mining and curation of a half a years
worth of statistical graphs obtained in their original format after
they were published online by Statistics Canada. In Section 4 we
provide a formal model of graphs using the Web Ontology Language (OWL), which allows several types of expressive queries to
the representation (Section 5). Finally, we conclude by discussing
the main results of this work and provide directions for future work.

2. Related work

There has not been much work on semantic annotation of statistical graphs or using tools to (automatically) reason with them.
In fact, this paper has benefited greatly from work in such areas
as diverse as Graphics Design, Psychology, and HumanComputer
Interaction, besides, of course, Computer Science.

A significant amount of the research which has been performed
in the statistical graph domain has come from the Graphics Design
literature in the pioneering work of Bertin [5], Tufte [57] and, intersecting Graphics Design and Psychology, the work by Cleveland
[9]. These authors research has focused on defining some of the
visual properties of graphs, including a taxonomical categorization of them based on their function given these visual properties,
defining the vocabulary that should be used to talk about the
different objects composing a graph, or suggesting forms of presentation of those elements to maximize human understanding.
The main drawback of this work for our purposes is its focus on
breadth rather than depth, and its lack of thorough formalization,
a sine qua non of ontological engineering. This notwithstanding,
our graph terminology has been inspired to a large extent by
Bertins a priori classifications, and their subsequent experimental testing by Cleveland, to whom, together with [36], we owe the
adoption of the general word graph to denote these representa-
tions.

Similarly, there has been work on the cognitive and perceptual basis of understanding these graphs [34,46,37,38,6,55] and
the nature of the graph representation in terms of computational (in the cognitive sense) and informational equivalence with
propositional representations [35]. Two studies in particular have

been central to our research. First, Kosslyn [34] gave a thorough
toolset for analyzing graphs in terms of their constituents, and how
these constituents syntax, semantics and pragmatics affect human
graph-processing abilities. In point of fact, we have published
a mini-ontology that maps the final vocabulary of the Statistical Graph Ontology presented here and that used by Kosslyn in
his work.3 Second, Cheng et al. [7], provide what they call an
ontological framework, GraphRep, to analyze the roles of several
dimensions in the creation and interpretation of Cartesian graphs.
The authors have carried out a detailed analysis of how quantities and magnitudes are mapped onto the visual and conceptual
properties of graphs, the latter by reusing EngMath, an ontology
for engineering mathematics [22]. However, as may be expected,
this work and indeed the rest of the psychological literature, in
virtue of their level of discourse, is not detailed enough for our
domain-modeling purposes in certain areas (e.g. the nature of the
relationship between a point and its category axis), while it is much
more detailed in others (e.g. the encoding of spatial information of a
graphs constituents, or the rules of interpretation of these graphs).
Therefore, not unlike the work in Graphics Design, it lacks in-depth
formalism at the lowest level, which had to be supplied, while still
some other pieces of useful information had to be left out for future
sematic annotation work, either manual or automatic.

Computationally, we can distinguish research on standards of
representation of graphs in some formal language, and reasoning
over visual representations. Thus, on the one hand, graph data have
been structured and exchanged using a common format, usually
either a proprietary language as in the case of [32,33,48,21], or using
a specialization of XML, such as OpenXML (commonly referred to
as OOXML or Office Open XML [30]) or Open Document Format
[45] or the SPSS format [62]. These are all rich formalizations, but
geared towards graph creation rather than their querying and thus
important information about their semantics, particularly the relation among the different constituents, is not encoded. Therefore,
any querying in these formats would have to be done syntacti-
cally, or by knowing the implicit hierarchical relations in the XML
tree. On the other hand, diagrammatic, and in particular the spatial
and temporal literature research has focused mostly on detailed
representations and reasoning over simple diagrams that are only
indirectly relevant to graphs [1,13,24]. Some work has also been
done on statistical graph retrieval through visual cues [8] and on
querying over a relational database of diagrammatic information
using a specialized version of SQL (Diagrammatic SQL) [3].

Similarly, the visualization literature has investigated some of
the issues addressed here, including querying and tagging. In [26],
the authors use timeboxes to interact with visual representations
of time series data. In [25], a system is described for asynchronous
collaboration where images become enriched by tags as other social
spaces. Finally, Polaris [53] and the ManyEyes4 system provide
querying, analysis, tagging and visualization of datasets contained
in relational databases. However, these approaches are generally
geared towards data exploration using graphs, rather than clean-
ing, exchanging or integrating a repository of already published
ones, in which the communicative meaning is clear. For instance,
most of the graphs analyzed in these papers do not have a title,
let alone a subtitle. The representational languages used are pro-
prietary, meaning that the representations cannot be exchanged
across platforms or even applications, making multi-modal presentation more difficult. Some of these richer representations can
be exported into XML, but there is no explicit semantics to XML
elements as there is in other more complete knowledge representation languages (i.e. no obvious way to relate titles with their

subtitles, for instance). Perhaps most important is that these sys-
tems/approaches work on raw datasets, or draw graphs according
to best practices. We work with graphs that have been created
for/with a purpose by some expert human being who has then published them (probably on the web), and under the hypothesis that
this expertise is valuable.

In more general terms, as far as we know, no research has been
carried out over a sizable dataset of real statistical graphs (c.f. [19]).
Some research has indeed been done on real graphs, but they are
mostly exploratory case studies of only one complex graph. As well,
there has not been work on using Semantic Web technologies to
encode the structure and knowledge encoded visually in graphs.
Although the EngMath ontology can indeed be found online, it is
not directly relevant to our domain and has been written in the
Knowledge Interchange Format,5 a superset of first order predicate
calculus. Instead, our modeling language, OWL-DL, is a tractable
and decidable subset of FOL. Thus, unless some ad hoc changes are
made, information will be lost in the translation from KIF to OWL.
There are no available formal ontologies of the statistical graph
domain, or the line graph domain in particular.

Summarizing, our work concentrates on cleaning and providing
semantics to a large repository of semi-structured statistical graphs
(particularly line graphs) and on the testing of technologies such as
OWL, Description Logics and DL Querying that provide alternatives
to either proprietary representational languages or the relational
database approach. As well, we place more emphasis on graphs
as a visual object and on the potential of distributed approaches to
semantic tagging, including social and game-based tagging [61,60],
for which we lay the grounds in this paper.

3. Data sources and data cleaning

The data source used is the collection of a half-years worth of
statistical graphs produced for The Daily, Statistics Canadas main
online publication. Graphs for The Daily are designed in spreadsheet applications such as Microsoft Excel. When finished, graphs
are converted into the Graphics Interchange Format (gif), embedded into html pages, and ultimately published online. In turn, the
files containing the graphs in their native object models are normally discarded. For the work reported here, we have obtained 368
files containing 367 graphs in their native applications format. Of
these, 96 were n-variable (n  1) line graphs in English, on which
this paper is based.

Two separate steps were necessary before assigning semantic
structure to the graphs in the corpus. First, the graphs had to be
mined out of their native application and abstracted from their
proprietary object models. Second, they had to be curated from
syntactic malformations such as the lack of recognizable titles, or a
missing category in the x-axis.

Since Statistics Canada uses MS Excel to design the graphs, the
mining step was achieved by implementing an MS Excel 2003
plug-in that queried the model of the graph object (chart object,
in Microsoft parlance) via its Application Programming Interface
(API). This process attempted to extract a minimal and common set
of information pieces which account for only a part of the objects
and relations in the OWL representation discussed later (see Section
4). This information is used to abstract from proprietary data mod-
els, and could be used in relation to many other applications such as
SPSS or GNUPlot, to name just two. The complete formal syntax of
this abstract (i.e. not application-specific) representation of a graph,
in Extended Backus-Naur Form (EBNF), is given in Fig. 1. Only elements contentBoxes/box and geometry/plotArea are perhaps without

3 http://www.inf.udec.cl/leo/ontologies/kosslyn.owl.
4 http://manyeyes.alphaworks.ibm.com/manyeyes.

5 http://ksl.stanford.edu/knowledge-sharing/papers/engmath-tree.html.

M. Dumontier et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 241254

Fig. 1. EBNF syntax of the application-independent graph object model.

any obvious utility. Their use is discussed in the next paragraph and
in Section 5.2 (in relation to Equation 1), respectively.6

Since graphs are usually composed for visual consumption
rather than their structured archiving, the plug-in was not always
able to correctly identify the function of all the elements and
properties. The resulting representations had to go through a curation stage. A few examples will help illustrate this point. The first
one concerns the lack of recognizable titles. Although visually the
graphs did have titles (see Fig. 4), these were normally encoded
using the freedom of text boxes, rather than the available title
property in the graphing application. When extracting the different pieces of graph information, titles were added to the list of
elements of type box in contentBoxes, together with other types of
information also present in text boxes. Thus, there was no information as to the title of the graph. Relatedly, some types of titles
are not present at all, since some of these titles are obvious to a
human given the context (e.g. years for the categories 1990,
1991, . . . in the horizontal axis). Finally, the last example concerns the absence or underspecification of categories. Although
years (1990, 1991, . . .) are shown in the horizontal axis, there
are graphs with n datapoints per category. In general terms this is
not a problem for visually inspecting a graph, since the human analyst will visually coindex a segment of the axis to the given year.
However, it is usually the case that there is no one-to-one correspondence between category and value in the underlying data sheet.
That is, instead of writing the category and the value in the data
sheet, as shown in Fig. 2(a), the former are left implicit as in Fig. 2(b).
Several other common syntactic problems had to be addressed during the curation stage (see [19] for a detailed treatment of these
issues).

The curation of mined graphs was achieved through a set of
specialized algorithms that attempted to reconcile a first raw representation obtained from the graphing application  which could
contain missing information  with the mandatory information

6 This

grammar was

implemented in the

format
guage Document
http://www.inf.udec.cl/leo/jws01/linegraph.dtd.

Type Definition

EXtended Markup Lan-
at

available

(XML DTD),

Fig. 2. A comparison between explicit and implicit data sources in the data sheet
underlying graphs in MS Excel. (a) Available categories and (b) missing categories.

required by the graph grammar. For example, recognizing titles by
the relative position and font of text boxes (e.g. the main title was
always in bold font, or there was never a title within the plot area),
counting empty category elements between two or more specified
ones and heuristically finding the missing ones, etc. Once all the
obligatory elements of the graph were recognized and instantiated
into their correct position, an XML structure, now fully satisfying
the grammar (DTD) in Fig. 1 was generated. This XML was subsequently used to populate the ontology described in the next section
by means of an XML stylesheet.7

4. The Statistical Graph Ontology in OWL

We have divided the present section into three subsections. The
first subsection briefly discusses the choice of the word graph to
denote the object of our modeling efforts  a topic of some contention  and lays out the notational conventions used throughout
the paper to help with the exposition. The second subsection deals
with the requirement specifications gathering stage for the Statistical Graph Ontology (SGO, for short), following the methodology
described in [44] and the results of our own previous work on the
subject [16,11,10]. In this subsection, we also discuss some of the
validation methods used to evaluate the comprehensiveness and

7 http://semanticscience.org/ontology/igraph-mapping.xsl.

correctness of the SGO. The third and final subsection analyzes the
SGO ontology in detail.

4.1. Preliminaries

Before embarking on the definitional task of the domain at hand,
a few notes on terminology and notation are in order. In this paper,
we deal with objects which are called graphs or charts almost
interchangeably. We have followed [36] in calling these objects
statistical graphs, but we also use line graphs, or bar graphs to
specify their type or just graphs to mean all statistical graphs. We
are painfully aware of the ambiguity of the word graph, which is
used to mean charts, diagrams, a data structure in computer science and the mathematical construct. However, we have decided
to continue using graph, instead of the possibly less ambiguous
chart, because we have found that, first, empirical studies show
that advanced students and professionals of Graphic Design categorize the objects of interest as graphs, rather than charts. In point
of fact, they have a different set of representative images for the
latter (e.g. a Gantt chart is a time chart) [39]. Second, researchers
and authors of a large body of scientific literature dealing with the
human perception and cognition of these objects tend to call them
graphs, rather than charts [46,50]. At times, they even go to
the extent of making their difference quite explicit (see p. 186 in
[34]).

With regards to notation, this paper follows a simple set of typographical rules that will hopefully make exposition clearer and text
flow better, while also retaining a degree of technical detail for
those interested in them. We have adopted the Manchester OWL
Syntax [27] for presentation purposes, plus the usual conventions
of using the Serif font and capitalizing content words in predicates,
as in DescriptionPredicates, and using third-person verbs in lower
case and bold font to denote relations, as in hasRole. Ontologies are
denoted in small-monospaced-font, individuals in Times bold
font and datatypes also in monospaced-font with a suffix denoting the type, as in 2.5float. Finally, we will use the symbol 
to mean the end or running of a query, and the symbol  to mean
the end of an explanation of how a query reached the result.

4.2. Ontology design

The Statistical Graph Ontology (SGO) was designed following
semantic web best practices [23,58,44,11,16]. The scope of the SGO
was to model the entities and relations that will essentially constitute a statistical graph. Specifically, we looked at all multi-variable
line graphs published by Statistics Canadas main online publica-
tion, The Daily. However, besides LineGraph, the ontology also
provides classes for other kinds of graphs to make extensions eas-
ier. These other graph classes are Histogram, HorizontalBarGraph,
LineBarGraph, StackedBarGraph, VerticalBarGraph which are subclasses of BarGraph, and PieGraph and ScatterGraph. As discussed,
we only have instantiated individuals in the LineGraph class.

By providing these representations with rich semantic informa-
tion, we enable a multiplicity of applications including exchanging
information with other statistical agencies in the world, providing
accessibility to blind and visually impaired people, and allowing
universal access by portable media such as phones and Personal
Assistant Devices.

Determining the essential concepts of the SGO and evaluating
them was done in several stages. First, a set of more than 3000
line graphs available in previous publications of The Daily were
analyzed visually and a set of graph components were identified.
The primitive layers of the ontology (the taxonomy of terms, see the
Three Layer Approach (TLA) discussed below [11]) were created in
this manner after iteratively categorizing the classes.

Second, we carried out a requirements gathering session with
a professional statistician and a professional statistical communicator from Statistics Canada. Their task was to describe, in natural
language, a set of carefully chosen graphs to an audience consisting
of three legally blind people and four sighted people, all experienced in dealing with statistical graphs (either working at Statistics
Canada or with higher education degrees in Psychology and the Sci-
ences). The participants were instructed to listen to the description
and replicate the graph by drawing it on a blank piece of paper.8
Their conversations were recorded and the transcripts later analyzed [17]. The stimulus graphs, in turn, were selected from the
The Daily corpus and made to conform to the following criteria:
an equal number of line- and bar graphs were sought with (1) one
or two series, (2) positive values only or with positive as well as
negative values, and (3) with, as well as without, trend lines. These
criteria insured a reasonably varied stimulus set. For this paper, we
only take the line graphs subset into consideration. New terms were
identified and, in this case, so were relations mentioned by the pro-
fessionals. These relations were later added to the more complex
layers of the ontology. The resulting vocabulary was the union of
terms identified through visual inspection with those identified in
the descriptions.

Finally, the graph data structures defined in both the OOXML and
the ODF were correlated to the available set of terms and relations
to ensure a comprehensive coverage. A range of available ontologies were reused for this purpose. Some of them include the Basic
Relations Ontology (BRO), an ontology of countries, of time (Time
Interval) and others, which we discuss below.

Summarizing, the terminology for the SGO was obtained and
cross-evaluated in different ways: (i) by surveying the cognitive
psychology and design literature, (ii) by our own visual inspection of 3000 line graphs from the Statistics Canada website, (iii) by
analyzing the vocabularies of published formal representations of
graphs for specific applications (SPSS, OOXML, and ODF) and finally
(iv) by a semi-controlled requirements specifications study with
professionals in the statistical domain. This insured both depth and
breadth of the SGO.

4.3. The Statistical Graph Ontology (SGO)

To paraphrase a well-known saying, an image is worth a thousand logic propositions. Even assuming a structured input, giving
formal semantics to visual representations is a challenging task [35].
We have adopted a TLA to ontology design, contributing to the
modularity and extensibility of the resulting model, while keeping
application-specific commitments to a minimum [11].

and the

Protege version 4 [51] with the embedded Fact++ reasoner [56] was used to create and check the consistency of
three OWL ontologies [64]: statistical-graph-primitive,
statistical-graph-complex,
application-specific
statistical-graph-igraph. The first of these, statistical-
graph-primitive, contains the complete graph vocabulary
without any class restrictions: 74 classes,9 19 object properties
and six data type properties.
In turn, statistical-graph-
complex adds general class restrictions that are considered to
be universally true about graphs (e.g. StatisticalGraph always
hasPart Plot, with primitive relations such as hasPart being defined
in yet another ontology, the Basic Relation Ontology, or BRO, for
short10). Finally, the statistical-graph-igraph ontology, the
application layer, constrains the document with elements and

8 Including the blind participants, who told us they would be able to do so.
9 All
available

supporting

software

ontologies

and

is

at

http://semanticscience.org/ontology, except where otherwise stated.
10 http://semanticscience.org/ontology/bro-primitive.

M. Dumontier et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 241254

time-interval-primitive ontology for time and date.11 Briefly,
this ontology covers time intervals from Second to Millenia, including obviously Quarter (FirstQuarter, SecondQuarter, ThirdQuarter, and
FourthQuarter), Month, from January to December and Year from
1900 until 2009. Instances of these classes are related through
the hasPart (or its inverse,
isPartOf) and four time relations:
precedes (and its inverse, precededBy) and immediatelyPrecedes
(isImmediatelyPrecededBy). For instance, in graph c080219b in
the KB in Fig. 4, the instance I 2004 is asserted as a FirstQuarter
that isPartOf 2004, which isA Year, immediatelyPrecedes II 2004
and precedes III 2004 and IV 2004. Conversely, 2004, which isA
Year, immediatelyPrecedes 2005, isImmediatelyPrecededBy 2003
and precedes 2006, 2007, . . . and hasPart I 2004, II 2004, . . . which
are of class Quarter.

A more complex, two-step inference which will be used repeatedly proceeds as follows: step (1) since III 2003 isPartOf 2003,
2003 precedes 2005, therefore III 2003 precedes 2005, and step (2)
since III 2003 precedes 2005, January 2005 isPartOf 2005, therefore III 2003 precedes January 2005. The reader may want to go
back to Fig. 3 and attempt to visualize the instances in Quarter discussed here as x0, x1, . . . and the ones in Year as xx0, xx1, . . . The
next paragraph explains how exactly the time-interval and the
graph-complex ontologies are integrated.

As mentioned at the beginning of this section, assigning deep
semantics to visual representations is not a simple task. Not unlike
the basic idea of the Semantic Web in general, there will always
be other dimensions of information to be added in order to enrich
the base representation for a particular purpose. Thus, instead of
assuming that the three authors of this paper have developed a
comprehensive model of the statistical graph domain all by them-
selves, the efforts have been geared towards providing a more
scalable and distributed approach, attempting to seize the benefits of ideas such as social tagging, formal ontologies designed by
domain experts and Semantic Web technology. For this purpose,
we have introduced a set of object properties (hasTag /isTagOf) that
can be used with minimal ontological commitment. In the weakest
case, graphs can be related to a generic instance of some unknown
category, being identified by some Uniform Resource Identifier
(URI) and having some human readable label (rdfs:label). A
stronger commitment can be made by making this an instance
(rdf:type) of some class defined in some RDF/OWL document,
thus providing the ability to reason about its class membership. This
object property approach is therefore more flexible than the alternative of datatype annotation alone, which could only be subject to
syntactic matching. Another valuable aspect of this approach is that
we can discover graphs having components that are semantically
annotated. To infer that graphs having semantically annotated parts
are themselves semantically annotated, we use the object property
chain inclusion axiom, asserting that the function composition of
hasPart and hasTag is a subproperty of hasTag (hasPart hasTag
hasTag). Thus, graphs can be queried directly with tags. Semantic
annotations based on keywords or controlled vocabularies can later
be mapped to ontologies for enhanced question answering about
graph contents. This happens, for instance, with CategoryData,
where x0 in graph c080219b hasTag January 2004 that isA January,
and isPartOf 2004, which isA Year. Likewise, xx0 an instance of
SecondaryCategoryAxis, hasTag2004, instance of Year. The different objects composing graphs are therefore tagged with further

11 http://semanticscience.org/ontology/time-interval-primitive.owl. Notice that
we reused our own ontology for time because we wanted to link the individuals and
reason across intervals of time. The best alternative, http://www.w3.org/TR/owl-
time/, could be more appropriate if OWL reasoners supported datatype reasoning,
which they currently do not. That is, in the absence of datatype reasoning, the only
questions we have been able to ask are those about containment and ordering.

Fig. 3. Diagrammatic representation of some of the relations holding between the
different object instances of graph c080219b from Fig. 4. Arcs stand for the hasPart
relation, except where noted (hasValue). x0, x1, . . . , xx0, xx1, . . . are instances of
CategoryData, while y0 series0 is an instance of ValueData. The classes of the other
instances should be inferable by their name.

relationships that do not carry a strong ontological commitment
per se, but that are required for specific tasks at the application
level [18].

The following definition of the StatisticalGraph object proceeds mostly in a path from the outer to the inner objects
composing these graphs and in a loosely depth-first manner.
Briefly, a StatisticalGraph may hasTitle one PrimaryTitle and some
SecondaryTitle. To prevent the visual and analytical impossibility
of a SecondaryTitle appearing on its own, SecondaryTitle isPartOf
some Graph that hasPart some PrimaryTitle. A StatisticalGraph must
always hasPart exactly one Plot, which, in general terms may
hasPart some Series and hasPart some CoordinateAxis (XAxis.
YAxis and ZAxis). CoordinateAxis may hasPart one or more
CategoryAxis (PrimaryCategoryAxis and SecondaryCategoryAxis) and
one or more ValueAxis (LeftValueAxis or RightValueAxis). By asser-
tion, CategoryAxis hasPart CategoryData and, more specifically, by
inference, PrimaryCategoryAxis hasPart PrimaryCategoryData and
SecondaryCategoryAxis hasPart SecondaryCategoryData. ValueAxis
is usually used to represent continuously varying numerical data
(ValueData, which isPartOf some ValueAxis) and may be scaled
(ScaledValueAxis isSubClassOf ValueAxis and LinearValueAxis,
LogarithmicValueAxis and SemiLogarithmicValueAxis are all subclasses of ScaledValueAxis). Finally, a Series hasPart two or
more DataPoint, that hasPart Data to be plotted from the set of
CoordinateAxis. Data, or more specifically, CategoryData or ValueData
hasValue a concrete numerical data type (e.g. int, float, real or
double). For a diagrammatic view of part of the model described
above using graph c080219b from Fig. 4 as example, see Fig. 3.

Line graphs normally display functions from time to values.
All the line graphs in our KB have years, quarters, or months
in the category axis. As well, more than one time unit may be
present at once and the graph may have a primary category axis
holding months or quarters, and a secondary category axis holding years (see e.g. graphs c080219b and 080313a, respectively,
in Fig. 4). Given the importance of temporal knowledge for the
querying of statistical line graphs, we have reused an available

Fig. 4. Sample Knowledge Base of graphs appearing in The Daily. The names are the dates of publication, denoted by the following expression: cYYMMDD[az], where c
identifies the graph as the English version (rather than the French version, which is labeled with a g), YY are the last two digits of the year, MM of the month and DD of the
day. The next character denotes the order of appearance in the publication (a is the first graph in that publication, b is the second, and so on). In keeping with our hypothesis,
we have also kept the real (and diverse) dimensions/aspect ration of the graphs. This is important for our purposes and will be explained in Section 5.2 below.

information, rather than, for instance, asserting that x0 or xx0
are months or years themselves, which would be, philosophically
speaking, an ontological stretch. All graph components may have
any number of tags, and the hasTag relation could be potentially
specialized, an issue we have not tackled in this paper.

5. Graph querying

Two general types of queries may be asked of graphs: (1)
queries about the objects composing a single graph (intra-graphical
queries), and (2) queries that are asked to a graph KB (inter-
graphical queries) [2]. Queries of type (2) can be further subdivided
into those that (i) integrate graphs, (ii) differentiate graphs or (iii)
span graphs in terms of all their constituting objects.

We will demonstrate graph querying using a KB built with four
line graphs out of the 96 in our original corpus (see Fig. 4). The
results apply to the full KB without any intended loss of general-
ity. All queries, like the descriptions in Section 4.3, are specified
in Manchester Syntax [28]. The Manchester OWL Syntax is a more
intuitive syntax for OWL descriptions. We use the same typographical conventions discussed in 4.1. The only new constructs we use

here are the keywords and, and that, which denote the logical
operator and, where both conjuncts have to be true for the condition to hold; or, which denotes the logical inclusive or, where just
one or both disjuncts must be true for the condition to hold, and
finally some, which stands for the existence quantifier (at least
one). A simple example is Graph that hasTitle someTitle, meaning
return all those graphs that have at least one title. In order to
make exposition clearer, however, we have slightly abused the
notation of Manchester Syntax. However, in the interest of com-
prehensiveness, we have decided to include an appendix with the
fully formalized queries, should the reader wish to execute them
him/herself.

5.1. Intra-graphical queries

The following are some instances of possible intra-graphical
queries, using graph c080219b in Fig. 4 as example.12 These queries

12 The URL for this OWL file is http://semanticscience.org/ontology/tinyKB-
c080219b.owl.

M. Dumontier et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 241254

return relatively simple answers when compared to the answers
at the inter-graphical level. However, they do show interesting
properties of the model, mostly exemplifying a line graphs direct
relationship with the time ontology by adding semantics to the
graphs tagged parts. These queries are obviously vital at the application level as well, where graphs will have to be recreated in one
of many possible modalities.

Query 1. ValueData that isPartOf some (DataPoint that hasTag
value May 2006) 

Query 1 returns the individuals holding the value for the
month of May 2006 in both series0 (y28 Series0 hasValue
1.8float and series1 (y28 Series1 hasValue2.8float) of
graph c080219b in Fig. 4, with reasoning proceeding along the following lines:

Result explanation. Individual y28 Series0 is of type ValueData
and datapoint28 Series0 hasPart y28 Series0. Since the relation
isPartOf is the inverse of hasPart, therefore y28 Series0 isPartOf
datapoint28 Series0. Also, datapoint28 Series0 hasPart x28,
which hasTag May 2006. By role inclusion [29], (hasPart hasTag)
hasTag, it is inferred that datapoint28 Series0 hasTagMay 2006.

Queries about points are perhaps the simplest, yet the most
common questions external applications (and users) will ask about
graphs. These types of queries are important since visual inspection of a graph rarely yields the precise value of a single point, and
graph readers will normally want to be precise. Visual inspection
is what graphs are primarily made for, but obtaining precise information during policy making decisions at the governmental level
is vital, and graphs are also used for this task. Next we return a set
of months whose datapoints have values greater than 2.6. Thus,

Query 2. Month and isTagOf some (DataPoint that hasPart some
(hasValue some float [> 2.6])) 

returns the set of individuals September 2005, January 2006,
and May 2006, which are difficult to guess just by visually inspecting the graph. Not unlike the reasoning for Query 1, the reasoning
for Query 2 proceeds along the following lines, this time using
datatype and subsumption reasoning, with September 2005 as
example:

Result explanation. Individual datapoint20 Series1 is of type
DataPoint and hasParty20 Series1, which in turn hasValue
3.2float, a floating point number greater than 2.6. The
individual datapoint20 Series1 also hasPart x20, which hasTag
September 2005, which is of type September, which is of type
Month, and by the role inclusion axiom and the inverse of hasTag
(i.e. isTagOf), September 2005 isTagOf datapoint20 Series1.

All graphs that have months as categories in the horizontal axis
can also be queried with respect to quarters. Interestingly, countries
have different fiscal year definitions. For instance, Canadas first
quarter starts in April, while the United States starts in October.
Thus, if someone from the US asks for values in some third quarter,
he or she will probably mean the US definition of third quarter or
the definition of a calendar one, starting in January, rather than the
Canadian one. In any case, graphical representations are exchanged
with other statistical agencies in the world, themselves with different quarter definitions, and the proposed level of articulation is
highly desirable.

In the time-interval-complex layer, each Month class contains the restrictions of the Quarters it corresponds to according to
the definition of such quarter. For instance, January isPartOf the calendar FirstQuarter and isPartOf the fiscal fourth quarter in Canada
and also isPartOf the fiscal SecondQuarter in the United States.
These axioms are asserted as necessary conditions as follows:
January is a subClassOf some isPartOf some CalendarFirstQuarter
and isPartOf some FiscalFourthQuarter CAD and isPartOf some

FiscalSecondQuarter USA. The following query makes use of the
descriptions discussed above.

Query 3.
isTagOf some (DataPoint that (hasTag some (isPartOf
some FiscalFirstQuarter CAD)) and (hasPart some (hasValue some
float [>2.5]))) 
returns May 2006. The same query, using FiscalFirstQuarter USA
would have returned October 2005 instead, with reasoning proceeding similarly to that for Query 2 above: Result explanation.
datapoint28 Series1 is the only DataPoint individual that satisfies the conjunction of (1) hasPart some hasValue greater than
2.5 (2.8float, through having part y28 Series1) and (2) has
a tag (May 2006, through x28, of type PrimaryCategoryData) that
isPartOf a Canadian fiscal first quarter (May 2006 is of type May and
May isPartOf FiscalFirstQuarter CAD). Finally, datapoint28 Series1
hasTag May 2006, the individual returned.

The reader will have noticed that Query 3 starts with isTagOf,
rather than, for instance, Month that isTagOf, which would have
returned the same individual given this KB. Although this KB only
has the tag May 2006 associated to the PrimaryCategoryData individual x28, part of the ultimate goal of this work is to allow social
tagging of the different components of graphs, as discussed in the
previous section. Given this, we may assume that there will be any
number of tags associated to the different objects. If so, unless we
specifically need to return months (and in so doing ignoring other
category data that may be part of a fiscal first quarter of any kind),
the query should be left as general as possible, returning all possible
tags and thus fostering knowledge exploration.

5.2. Inter-graphical queries

Inter-graphical queries are those asked to a set of graphs, rather
than to a single one. At their simplest, inter-graphical queries use
the same vocabulary and resources as intra-graphical ones. All
queries discussed in the preceding section will return the same
answers, and, for instance, they can be extended simply (but mean-
ingfully) by wrapping them in the formulas [StatisticalGraph that
hasTag some ()] and [StatisticalGraph that hasPart some ()] to
return the statistical graph objects for which these descriptions
hold. However, having a variety of graphs permits the extension
of the statistical graph formalization in interesting ways; allow-
ing, for instance, queries which would have been less informative
if asked intra-graphically. These include the integration of complementary information from different physical graphs, the merging
of incomplete series, and other similar tasks. We have extended the
original graph model in two ways. First, we extracted and analyzed
the titles and the series of the graphs in the full KB and provided
semantics for what the graphs are about. Second, we enriched
the representations in order to allow a simple but powerful query
language based on a few visual properties of graphs. We deal with
each of these issues below.

In order to integrate knowledge contained in different graphs,
it was necessary to analyze the semantics of those objects that
held topical information about the graph (e.g. titles, or text boxes).
A systematic and comprehensive linguistic and conceptual investigation of the text associated to titles and series in the graphs
in the KB was carried out. This investigation involved creating
potential tags using a mixture of n-gram approaches, the C-value,
as reported in [20] and manual tagging.13 A tagging algorithm was
developed to automatically analyze all text associated to titles and
series and assign the pre-defined tags. These tags were later used to
instantiate individuals in the most specific category or categories

13 The complete tag ontology for titles and series in this KB can be found in
http://semanticscience.org/ontology/iGraph-tag-individuals.

old motor vehicle sales,

of either already available ontologies or specially created ones. We
have reused the ISO 3166 Code List of countries14, for instance,
to provide deeper semantics to countries (Canada, UnitedStates
and Chile), their regions (Saskatchewan, Ohio) and their relations
(dependentTerritoryOf).15 Sixty-five different individuals belonging directly or by subsumption to eighty-one classes were found
in these titles and series. For instance, there were graphs involving
different kinds of sales: manufacturing sales, motor vehicle sales,
new motor vehicle sales,
retail sales,
wholesale sale and pure sales, which is left unspecified. Thus,
while graphs with the title Improved manufacturing sales contribute to a drop in the inventory-to-sales ratio (graph c080416c,
in the full knowledge base) were tagged as manufacturing sales in
the ManufactoringSales class subsumed by the Sales class, graphs
such as c080520a, with the title Sales soar in Saskatchewan were
tagged as belonging only to the super-category Sales. Notice that,
in virtue of the word ratio appearing in its title, graph c080416c
in Fig. 4 will also be tagged with a ratio unit tag, an instance of
RatioUnit and, by subsumption to Unit. Moreover, in virtue of the
word Saskatchewan appearing in the title of c080416c, queries
asking for sales in Canada would return this graph in virtue of the
countries ontology.

Query 4 is an example of an inter-graphical query using the new
information given in tags.16 It asks the KB to return those datapoints
that (i) belong to a graph that contains information about Sales
after January 2005 and before May 2008 and (ii) have a value lower
than 41 or greater than 48.

Query 4. DataPoint that (isPartOf some (Series that hasTag
some Sales)) and (hasTag some (Month and (precededBy value
January 2005) and (precedes value May 2008))) and (hasPart
some ((hasValue some float [< 41.0]) or (hasValue some float
[> 48.0])))) 

The result includes datapoints from graphs c080418b and
c080619f in Fig. 4. Notice that only these graphs have series that
contain information about Sales, asserted using the hasTag prop-
erty, which demonstrates integration among the graphs in the KB.
Datapoints from series that do not contain this tag are not included
in the result. Also, these two graphs contain data corresponding to the range required, demonstrating both integration and
spanning, since the result of the query integrates datapoints that
span two different graphs, e.g. c080418b:datapoint1 Series2 corresponding to March 2005 that is only part of graph c080418b and
c080619f:datapoint36 Series2 which corresponds to April 2008
and is part only of graph c080619f.17

Result explanation. c080418b:datapoint1 Series2 is a DataPoint
individual that satisfies the conjunction of (1) isPartOf some
(through Series2 that
Series that has a tag some Sales,
hasTag sales, of type Sales), (2) hasPart some hasValue less
than 41 (40.694float, through having part y1 Series2)
and (3) hasTag some Month that is precededBy January 2005
and precedes May 2008 (through c080418b:x1 that hasTag
March 2005, precededBy January 2005 and precedes May 2008)

14 http://www.iso.org/iso/english country names and code elements.
15 http://www.bpiresearch.com/BPMO/2004/03/03/cdl/Countries.
16 The reader is encouraged to experiment with the KB by loading it from:
http://semanticscience.org/ontology/tinyKB-all.owl.
17 Although for intra-graphical queries it was not necessary (all queries were about
a single graph), in order to get the name of the set of graphs for which the description
holds, the qualified names option (qnames, in Protege) was used. However, to aid
readability, we have abused notation slightly and the query and the explanation are
both presented without explicit qnames.

5.3. Visual queries

Previous queries were based primarily on concepts and relations
which hold over numerical data, categories and identified content
tags in the analyzed graphs. However, graphs derive their representational success from being primarily visual objects. As such,
people usually rely on visual predicates when explaining and informally querying these objects. We have implemented two kinds of
visual tags that exemplify a simple but non-trivial way to query
graphs using a language based on the visual properties of the lines
present in those graphs. The first kind is querying by slope event,
the second is querying by slope quality. By slope we mean the visual
slope  rather than the mathematical slope  of a line between any
two points in a series. The difference lies in that the visual slope is
calculated taking into account a graphs relative measurements. We
obtain geometrical information from the graphs native application
object model (see the geometry /plotArea path in Fig. 1). In this case,
such measurements are given in points, where a point is equal to
1/72nd of an inch. Thus, the visual slope (denoted Sv) for any two
(subsequent) datapoints yi and yi+1 in a given series is calculated
by the following formula:
Sv(yi, yi+1) = arctan

(1)

(h/r)y
(w/|C|)

where h is the height and w the width of the plot area (obtained in
points from the path graph/geometry/plotArea [height] and [width],
respectively), r is the difference between the minimum and maximum values of the y-axis (from graph/axis/valueAxis [startsAt] and
[endsAt], respectively), y is the difference between the values of
yi+1 minus yi (graph/series/valueSet/value [id], 0  x), and |C| is the
number of primary categories in the x-axis. Strictly speaking, we
simply could have used the mathematical slope of a line  simply
y, since by virtue of being adjacent points the denominator of the
change will always be one  rather than the visual slope to calculate slope direction. However, for reasons that will be discussed
below, it was important to maintain information about how the
graph was visually presented. If we imagine a graph and were asked
to increase its width without locking its aspect ratio, the angle of all
segments of the line in the graph will decrease, appearing flatter.
The mathematical slope is insensitive to this manipulation and will
remain the same no matter how much the visual presentation is
modified.

The first kind of visual queries, by slope event, has to do with
the direction of slopes; i.e. whether they go up, down or stay
unchanged.18 We have empirically identified dozens of slope event
predicates that hold over one or several segments and that are regularly used by professional statisticians, at least pre-theoretically,
since they make use of qualitative guidelines. A few examples include AcceleratingSlope, PlummetingSlope, AdvancingSlope,
EdgingUpSlope, etc. The qualitative definition for advance in the
Statistics Canada style guide reads [Advance has] a crisp, confident feel: not tentative, not leaping and bounding ahead. Armies
advance slowly, surely, in step. Especially good for long-term
growth trends., for accelerate, it reads use[d] only to describe
a series of increases where each is greater than the last. We
have formalized all these predicates appearing in a corpus of texts
describing graphs. For instance, AcceleratingSlope is a predicate that
holds over the (visual) slope of many subsequent lines (a line lk is a
an ordered pair of the values of two points yk, yk+1 in the graph), and
where Sv(l0) < Sv(l1) < . . . < Sv(n). In other words, for an accelerat-

18 There has been at least some work along these lines. See, for instance,
http://cardioshare.icapture.ubc.ca/ for a system that answers queries about slope
events (increase, decrease) in the domain of creatine levels (an organic acid that
supplies energy for muscle contraction).

M. Dumontier et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 241254

ing slope to happen, the slope of a line must be greater than the one
immediately preceding it, usually for some empirically derived  
(left undefined in the style guide) such that [(Sv(li+1)  Sv(li))   ],
and where   stands for psychophysical constants in human angle
perception [40,43]. These complex predicates notwithstanding, the
most frequent line predicates occurring naturally are IncreasingLine,
DecreasingLine, and PlateauingLine. All other predicates for slope
events are specializations of the latter three predicates. The following query makes use of this new tag set by asking the small KB
to return those months of June 2005, 2006 or 2007 in which there
are decreases in series tagged with (any kind of) sales:

June that isPartOf some (2005 or 2006 or 2007) and
Query 5.
isTagOf some (isStartPointOf some DecreasingLine and isPartOf
some (Series that hasTag some Sales)) 

The result includes two individuals: June 2005, and June 2007,

for which the description holds.

Result explanation. Series1 and Series2 in graph c080418b
hasTag sales, which
both
hasPartline 4 5 Series1 and line 4 5 Series2. These two lines,
asserted as DecreasingLines, have x4 as their starting point, which
in turn hasTag June 2005, an instance of June. It works in the same
way for June 2007. 

belongs

they

Sale

to

and

The second kind of visual queries, by slope quality, has to do with
the angle of a slope, i.e. using predicates such as ModerateSlope,
SharpSlope, SubtleSlope, or SlightSlope, to name but a few exam-
ples. This general type of predicate is perhaps more complex than
slope events, depending heavily on human factors such as human
angle perception and on a highly context-dependent calculation of
what the graph content is generally representing (a subtle increase
in salary is not the same as a subtle increase in mortality rate,
for instance). These difficulties notwithstanding, vague predicates
are a common tool for professional statistical communicators due
probably to their summarizing power.

To shed some light on the issue of angle perception in graphs, an
experiment was carried out in which twenty students were asked
to read a caption over a graph using 20 words derived from a corpus
of graph descriptions (i.e. slight increase, the independent vari-
able) and modify the angle of a line (the dependent variable) using
a sliderbar. Ordering the words by the average angle and plotting
them results in a curve well-fitted by a cubic function (R2 = .92),
suggesting a three-way differentiation. However, it was empirically difficult to provide cut-off points in the function for all vague
slope-quality predicates (the difference between a slight increase
angle and a subtle increase angle is itself subtle, and the standard
deviation was usually quite high) [41,42].

Given the results of the experiment and the information
encoded in the graphs themselves, we have defined tags to deal
with these vague predicates in three different, complementary
ways. First, based on the evidence of the experiment, we have
partitioned the space into the three broad categories SmallSlope,
ModerateSlope and SharpSlope. These concepts were the highest
frequency words that describe slopes qualitatively in our corpus.
The second solution was to analyze titles of graphs for any occurrence of the words for qualitative slope description and, if any are
found, subsequently tag the whole graph object with that quality.
Thus, graph c080407b (in the larger database) whose title is Value
of non-residential permits decrease sharply is tagged as a graph
containing a sharp slope, for instance. Finally, we do allow tags
from users or analysts that may be willing to annotate the graph as
to the qualitative nature of some slope in them.

The following query uses most of the apparatus developed so
far to query the fullKB19 ontology (i.e. that KB with all the graphs)

19 http://semanticscience.org/ontology/fullKB.owl.

for those months that belong to the first Canadian quarter, in which
there are decreases in employment but sharp increases in sales.

Query 6. Month that (isPartOf some FiscalFirstQuarter CAD) and
(isTagOf some (IncreasingLine that ((hasTag some SharpSlope) and
(isPartOf some (Graph that hasTag some Sales)))) and (isTagOf
some (DecreasingLine that isPartOf some (Graph that hasTag some
Employment))) 
are

the
description: April 2005,
June 2005, April 2006, May 2006,
June 2006 April 2007, May 2007, June 2007, and May 2008. We
explain the reasoners output using May 2007 arbitrarily. All other
individuals could be explained in the same way.

individuals

returned

fulfilling

There

nine

which
and

c080516a:x33,

c080516a:line 32 33 Series1

isTagOf
c080516a:line 32 33 Series1,
isTagOf

Result explanation. May 2007 isPartOf FiscalFirstQuarter CAD.
May 2007
in
turn
therefore
isPartOf
May 2007
as well.
c080516a:line 32 33 Series1 is an instance of
IncreasingLine
and hasTag sharp slope, which is an instance of SharpSlope.
c080516a:line 32 33 Series1 isPartOf c080516a:graph c080516a
which hasTag sales, an instance of Sales. In turn, May 2007 isTagOf
c080711c:x28, which isPartOf
c080711c:line 27 28 Series0,
and therefore May 2007 isTagOf c080711c:line 27 28 Series0.
c080711c:line 27 28 Series0 is an instance of DecreasingLine and
isPartOf c080711c:graph c080711c which hasTag employment,
an instance of Employment. 

This is a more complex query than any of the ones we have discussed so far, drawing on the whole conceptual apparatus defined
in this paper. It demonstrates the power of the model by gathering
information across different graphs and integrating it into a single
result, ultimately discovering months that, for some reason, have
the peculiarity of people buying more even though the job market
is declining. In the next section we will discuss some general properties of the system we have presented, together with the general
advantage of the approach.

6. General discussion

In the previous sections we have discussed a rich ontologydriven knowledge management system which uses RDF/OWL to
formally express and query heterogeneous graphical representations of statistical data. We will now discuss in greater detail some
general features, lessons learned, and remaining challenges of the
domain.

In general terms, OWL proved expressive enough to encode
a wealth of information about graphical representations of statistical data. It was certainly enough to solve the problems we
set out to solve. Querying the graph KB through the SGO now
allows us to obtain precise information about a given graph (e.g.
the exact value of January 2005 in Graph 1 Fig. 4), integrate information which belongs to different physical graphs (see Query 4),
retrieve graphs having particular content such as all kinds of sales,
Graph that hasTag some Sales, retrieving c080619f and c080418b,
since wholesale is a kind of sale, but not the other two graphs
in the KB illustrated in Fig. 4, visual properties such as increases
and decreases (see, e.g. Query 5) and their qualitative visual slope
(see, e.g. Query 6). All this coupled with the possibility of extending the representation quite easily (by tags and by the structure
design of the ontology, see discussion below about the Three Layer
Approach), means that the SGO is much richer than the table of
numbers or database that gave rise to the graph.

In fact, perhaps one of the most important lessons of this investigation is that, given the domain and target users of the graph
KB, the choice of a Semantic Web approach, rather than a Relational Database System approach, proves to be the most natural
one. In our domain, the usual issues of Relational DataBase Sys-

semantic tagging, it makes the default monotonic reasoning and
inference approach of the SW preferable to the non-monotonic
approach. Consider a user adding some new information, let us
say, the individual puny title and the funny linegraph, the latter
specified as of type LineGraph. This user also adds the fact that
funny linegraph hasTitle puny title. Besides the discussed complexity of writing and updating RDB records derived from some O/R
mapping patterns, RDBSs will simply reject this particular update.
The reason is that there is a constraint violation: the range of the
relation hasTitle in the SGO is Title, but puny title does not belong
to the class Title (Closed World Assumption). In the SW approach,
given the range restriction, the ontology reasoner will simply infer
that puny title is a Title.20 Notice that, after classification, query
answering over the SGO will also retrieve implicitly derived facts.
That is, querying for all Title instances will return puny title. These
bits of underspecified information (e.g. puny title belonging to Thing)
are present all the time in our domain: partly because the visual
nature of the object allows many dimensions of description of the
information they contain, and partly because no one person knows
all that information about the domain at a given time, demanding
a distributed, scalable and extensible system like SW.

The work reported in these pages grew from the need to provide
deep semantics to graphical representations of statistical graphs
primarily in order to make these graphs accessible to blind and
visually impaired people [18] and, if possible, to a more general
audience that could also benefit from such a model. However, it
was also clear that a general model of (statistical) graphs would be
too underspecified for our assistive technology, while too specialized a model would become less useful for other potential users of
it (other statistical organizations, business intelligence technology,
etc.). Adopting a Three Layer Approach (TLA) to ontology design
(see [11] for a discussion, and [59] for a successful application of
the TLA to a biological subdomain) allowed us to overcome these
issues by designing the ontology in subsequent levels of special-
ization, from a pure taxonomy of terms with no relations other
than the is-a hierarchy (statistical-graph-primitive), to a
fully application-specific layer that we do not discuss in this paper
(statistical-graph-igraph, see [15]). In general, the TLA provides support for ontology reuse, extensibility, and maintainability.
In further tagging the graphs in the KB, users may choose to contribute non-disjoint classes in the taxonomy, additional implicit
graph knowledge, more instances at different levels of ontological
commitment or take the complete SGO and taylor it to their particular application needs. Thus, even though the ontologies adhering
to the TLA become slightly more numerous (see Fig. 6), they are
less monolithic, more modular and, in a way, easier to adopt and
extend, since a user has three documents to choose from, rather
than rejecting a model based simply, for instance, on the restrictions the modeler has put on the domain. Interestingly, beside
the casual tagger of a graph, we foresee the potentiality of meta-
taggers, users who will find shallow tags and assign them a place in
the most specific category of a relevant ontology, a simple extension
of the role of Web 2.0 users.

Having rich structure and semantics is an essential characteristic
of digital information if they are to be useful in the realm of assistive
technologies and universal accessibility. Statistical graphs are a fundamental tool for science, engineering, and businesses and would
definitely benefit from having rich semantics. In the case of Assistive Technologies (ATs), there have been successful efforts in taking

20 We owe these examples to a set of very helpful slides by I. Horrocks, available
at
http://www.comlab.ox.ac.uk/people/ian.horrocks/Seminars/download/onto-
db.ppt. The literature on Close World Assumption/Open World Assumption,
Monotonicity and Unique Name Assumption and their alleged better fit for the SW
is sparse and difficult to find.

Fig. 5. A subgraph of the Statistical Graph Ontology (SGO). The arrow denotes the
isSubClassOf relation.

tems (RDBSs) derived from both the Relational/Object Impedance
Mismatch [12] such as extensibility, economy of representational
space, and query expressivity on the one hand, and Open World
Assumption, Unique Name Assumption and implicit information
on the other, become highly relevant. Thus, although in principle
the Statistical Graph OWL KB TBox could be translated into a RDB
schema using known design patterns that map objects to tables
[31], the resulting RDB system would become either hard to main-
tain, poor in polymorphic read, write and/or update performance,
or space consuming due to some redundancy of data, even without considering the related problem of multiple inheritance or the
mapping of roles (or relations, or object properties). If we take as
example the simplified Graph subgraph (in the mathematical sense)
of the SGO depicted in Fig. 5, it will become clear that, depending
on the DB design pattern chosen, mapping the SGO onto a Relational model will be either (i) space inefficient for deep ontologies
with multiple inheritance and with heavy use of (transitive) object
properties and role inclusion axioms like the SGO, (ii) costly in
adding instances, since for LineBarGraph, for example, there will
be the need to access at least five tables and updating one or more
Object Identifiers for each superclass of it, holding write locks on
all tables belonging to the hierarchy, and thus with a heavy DB
load on root tables (e.g. thing), or (iii) difficult to query by inexperienced users, since to retrieve instances of classes with multiple
inheritance they will often require SQL joins over several tables
(e.g. scatter graph	line graph	line bar graph), while querying
the graph KB with Manchester Syntax, would be expressed simply
as ScatterGraph, a substantially simpler query.

Moreover, our approach relies on the extensibility of the domain
by tagging graphs with new information by expert statisticians and
non-experts in the domain (such as high-school students) alike.
This is obviously possible in a database system, but adding information to a DB by adding tables, views and the such is considerably
more costly and involved than adding information to an ontology,
where the inherent modularity and structure on the fly nature of
ontology creation and extension contrasts sharply with the structure upfront methodology of RDBMSs. By the same token, the
Open-World-Assumption in Semantic Web technologies naturally
deals with the possibly incomplete information of the visual repre-
sentations, since, as we said above, we do not necessarily know all
the facts about a given graph a priori, and there is always the need to
have some degree of underspecification (cf. the next paragraph). In
short, RDBMS representations are not as easily extensible as ontologies are. In a domain such as the statistical graphs domain, with so
many possible description dimensions by mostly naive users, this
characteristic is vital.

Given the complex nature of translating visual objects into
logical propositions, the formalization of the interplay between
propositionalized visual objects with more traditional objects
of logic such as linguistic expressions (e.g. the titles of the axes
or the main title, footnotes, etc.) and the dynamic nature of

M. Dumontier et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 241254

Fig. 6. Graphical representation of the imports in the ontologies used, where if a  b, then aimports b. The white node in the middle stands for the fullKB ontology, the
equivalent to an ontological entry-point (or any subset of it, such as the tinyKB discussed in Section 5.1). G1, G2, . . ., Gn are the graphs in the knowledge base.

these SW representations and providing summarization and navigation for them. Screen-readers could potentially query the SGO
and speak out aspects of the graph to a blind student, for instance.
Intra-graphical queries are a very important subset of queries for
ATs, since by querying the semantics of one graph may allow the
addition of restrictions to navigate the graph at different levels
of detail. For instance, instead of point-by-point, navigation could
be done text-by-text, or by exploring text with a certain semantic function (e.g. legends, x-axis titles, etc.). Likewise, in universal
accessibility, having rich semantics and the ability to ask queries
of a single graph means being able to translate graphs into the
restricted space of a PDAs small screen (by, for instance, redrawing what is more important, rather than rescaling the gif image),
and, potentially, also querying it for more detail. Implementing this
with a RDBS backend, Object DBs or even Datalog would be much
more complicated, particularly in the case of mobile technology,
with very limited resources. A SW approach is more intuitive in
this domain and with these demographics.

7. Conclusions and future work

A major goal of the Semantic Web is to assign semantics to, and
therefore enrich, web content [4]. In this paper we have significantly expanded a knowledge representation of statistical graphs
such that their semantic annotation is compatible with Web 2.0
tagging but can be extended to take advantage of the formalism
afforded by the OWL-DL Semantic Web language. We demonstrate
question answering and knowledge discovery across an example
graph knowledge base that involves recent and highly expressive
elements of the OWL language. Our work generates new opportunities for building semantically annotated statistical graphs that can
be used beyond their communicative intent and may have a direct
role in the newly evolving semantic science.

A few issues, of course, remain outstanding and some others
could be significantly improved with various degrees of effort. An

important issue is still with the performance of reasoners. It currently takes about one hour to classify the fullKB knowledge base,
and less than a minute for the more difficult queries to be answered,
on a desktop PC with 2 GB of RAM and a Pentium 4 CPU at 3.5 GHz.
This is less than optimal in an application for domains such as
research, policy making or business decisions. Since we expect to
be adding two graphs per day on average, we will reach the reasoner engine limits quite quickly. There are always alternatives to
improve performance, both at the ontology level and at the application level. At the application level, the hybrid model of instance
stores (iS), which use ontologies to reason with many instances
stored in some database [63], OWL 2 profiles [65], or caching frequent queries, or parallelizing the system over several servers, etc.
could be all used. At the ontology level, we may simplify the granularity of the ontology by pruning classes and instances which are
rarely asked for.

Much more work could be done to improve the richness of the
semantics of graphs in the KB. For example, there are always problems with using string matching to analyze textual information
in graphs such as titles, footnotes, legends, etc. We could probably obtain better results by using both shallow and deep parsing
Natural Language Processing (NLP) technology instead of simply
finding strings. For the purposes of this paper, the string matching approach was arguably enough, since it demonstrated how a
naive analysis gave large returns on investment. This notwithstand-
ing, this approach would likely not scale well in complex graphs or
maybe in graphs other than line graphs. Using NLP technology, with
resources such as WordNet [14] and new interesting approaches
combining large terminology banks such as WordNet and KBs such
as Wikipedia (to name but two well-known examples), as in YAGO
[54], should definitely improve knowledge discovery.

With respect to querying, other improvements could be made.
Description Logic queries such as the ones we have discussed have
been up to the task for all the purposes of this paper. We think
that, given the domain, these queries are far from trivial. However,

it could be interesting to experiment with other query languages
such as SPARQL [49], or Jena.21 Fuzzy DL could be used to model
vague predicates such as slight or moderate or indeed the fullrange of the identified slope quality predicates. Relatedly, we have
formalized slope events, but have not yet translated them into any
machine understandable formalism such as OWL. This will allow
queries such as return all graphs that have a moderate advance
between February and March 2007, which are interesting in that
the predicate in fact ranges over a set of lines, not just one segment
as Increase, Decrease and Plateau.

We do not claim that we have dealt with all possible graphs. In
fact, we deal only with line graphs, and those published by Statistics
Canada, which are relatively constrained in their artistry. In fact,
even this dataset had to be thoroughly processed before assigning
semantics to it. However, we are currently publishing all graphs
that Statistics Canada produces every day with a delay of a few
hours fully automatically, which is indicative of the feasibility of the
methodology of building an empirically based, extensible, graph
domain model using Semantic Web methodology and tools.

Acknowledgements

This work was supported by a National Science and Engineering
Research Council of Canada and Cognos, Inc. Collaborative Research
and Development grant (NSERC CRD 346381-06) and a Proyecto de
Insercion Postdoctoral PSD 57 del Programa Bicentenario de Ciencia
y Tecnologia, CONICYT, Chile, to L. Ferres; and by an NSERC Discovery Grant to M. Dumontier. The authors would like to thank
L. Boucher and M. Lachance at Statistics Canada for their constant
support. This project was not funded by FONDECYT Chile.

Appendix A.

Runnable Queries in Manchester Syntax:

Query 1. ss:ValueData that ss:isPartOf some
(ss:DataPoint that ss:hasTag value ss:May 2006)

ss:Month and ss:isTagOf some (ss:DataPoint

Query 2.
that ss:hasPart some (ss:hasValue some float[>
2.6]))

Query 3. ss:isTagOf some (ss:DataPoint that
(ss:hasTag some (ss:isPartOf some
ss:FiscalFirstQuarter CAD)) and (ss:hasPart some
(ss:hasValue some float [>2.5])))

Query 4. ss:June that ss:isPartOf some (ss: 2005 or
ss: 2006 or ss: 2007) and ss:isTagOf some
(ss:isStartPointOf some ss:DecreasingLine and
ss:isPartOf some (ss:Series that ss:hasTag some
ss:Sales))

Query 5. ss:June that ss:isPartOf some (ss: 2005 or
ss: 2006 or ss: 2007) and ss:isTagOf some
(ss:isStartPointOf some ss:DecreasingLine and
ss:isPartOf some (ss:Series that ss:hasTag some
ss:Sales))

Query 6. ss:Month that (ss:isPartOf some
ss:FiscalFirstQuarter CAD) and (ss:isTagOf
some (ss:IncreasingLine that ((ss:hasTag some
ss:SharpSlope) and (ss:isPartOf some (ss:Graph that
ss:hasTag some ss:Sales))))) and (ss:isTagOf some
(ss:DecreasingLine that ss:isPartOf some (ss:Graph
that ss:hasTag some ss:Employment)))

21 http://jena.sourceforge.net/.
