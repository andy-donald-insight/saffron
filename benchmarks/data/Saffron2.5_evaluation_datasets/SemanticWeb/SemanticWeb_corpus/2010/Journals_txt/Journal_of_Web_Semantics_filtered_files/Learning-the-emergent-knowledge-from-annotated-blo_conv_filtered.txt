Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 329339

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

Learning the emergent knowledge from annotated blog postings
Tae-Gil Noh, Seong-Bae Park, Se-Young Park, Sang-Jo Lee

Department of Computer Engineering, Kyungpook National University, 1370 Sankyuk-dong, Buk-gu, 702-701 Daegu, Republic of Korea

a r t i c l e

i n f o

a b s t r a c t

Emergent knowledge does not come from a particular document or a particular knowledge source, but
comes from a collection of documents or knowledge sources. This paper proposes a system which combines social web content and semantic web technology to process the emergent knowledge from the
blogosphere. The proposed system regards blog postings as experiences of people on particular topics.
By annotating postings in the selected domains with ontology vocabularies, the system collects experiences from various people into an ontology about people and experiences. The system processes this
ontology with semantic rules to find the emergent knowledge. Users can access previously unavailable
facts, concepts and trends which are emerging from social web content by using the proposed system.

 2010 Elsevier B.V. All rights reserved.

Article history:
Received 8 November 2009
Received in revised form 8 May 2010
Accepted 10 May 2010
Available online 15 May 2010

Keywords:
Emergent knowledge
Social web
Ontology
Semantic search
Ontology learning

1. Introduction

With the recent growth of the Web 2.0, it has become easier than
ever to publish and share ideas and experiences over the web. It is
estimated that blog postings now have more incoming traffic than
traditional main stream web sites [18].

The power of the social web comes from a large number of content generators, the normal users. Thus, some information that is
unavailable from other sources like magazine sites or company web
sites is often available in user-generated content. The users are both
the consumer and the provider of the information in the social web
environment.

While the social web is a great success as it is, there is still a lot
of information in the social web content which is not accessible by
current search engines. For example, let us consider these questions
(or queries):

 What was the most hotly debated political issue in the blogo-

sphere last year?

 What kinds of books were popular among female bloggers in the

west coast area?

 What other games are being talked about recently by people who

liked the game, Prince of Persia?

 Where do they go for their summer vacation? Especially those

who are similar to me.

 This paper is a revised and extended version of [14].
 Corresponding author. Tel.: +82 53 950 7574.
E-mail address: sbpark@sejong.knu.ac.kr (S.-B. Park).

1570-8268/$  see front matter  2010 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2010.05.001

This kind of knowledge can not be gained from just one doc-
ument. Rather, it emerges from collections of user postings. For
example, although it will take a lot of time and energy, a human
being can answer the above questions by reading a large number
of related blogs and forum postings. Such knowledge is missing
from the current social web and can not be searched by the current
generation of search engines. This type of knowledge was called by
Gruber as Emergent Knowledge [7]. He argued that if a system is to
be truly named as a system of c ollective intelligence, it should be
able to process the emergent knowledge.

To build a system which finds the emergent knowledge and
allows its users to explicitly ask the emergent knowledge, there
are several challenges to overcome.

 Knowledge contained in user-generated content is not accessible

by machines.

 How can machines find the emergent knowledge that is mean-

ingful to users?

 How can users access such emergent knowledge without know-

ing details about the knowledge base?

 How to harmonize what humans do well and what machines do

well?

In this paper, a social web search system enhanced by the
semantic web technology is proposed to answer the above chal-
lenges. The purpose of the system is to find and access emergent
knowledge from real world blog postings.

The system regards blog postings as expressions of various experiences of the users. A simple ontology about experience is devised
to capture the experiences in a machine-understandable format.

T.-G. Noh et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 329339

The ontology is called event ontology in this paper. It provides the
semantic vocabulary to annotate blog postings. A semi-automatic
semantic annotator is devised and implemented to annotate each
blog posting. This annotator is embedded both in a semantic blog
system and in a blog data collecting tool for gathering semantic
annotations from real world blog postings. The collected annotations then become the instances of the event ontology.

In the proposed system, a rule-based concept extraction is
adopted to find and access previously unavailable knowledge. Rules
are submitted by advanced users, and then the system applies
these rules to find instances of the event ontology which satisfy the
rules. Then these instances are labeled with corresponding semantic labels. With the semantic labels, even casual users can access
newly found facts and values which were not directly available in
the ontology.

The system provides a few types of query methods. It accepts
SPARQL queries for advanced users, and also has a keyword-based
query method and a natural language interface which translates
user queries into formal queries.

With the resulting system, users can reveal and access information from social web content which is not available by the
traditional search engines. Details of the methods used in the system are described in the following sections. In Section 2, related
works are given. In Section 3, the design of the ontology and the
semi-automatic semantic annotation method are described. In Section 4, rule-based inferences and semantic rules are explained.
In Section 5, the implemented system and its environments are
shown. The system is evaluated in Section 6. Finally the paper is
concluded in Section 7.

2. Related works

In this section, related works are given in two parts. The first
part contains related works about semantic annotations and search
enhancements. The second part reviews recent works about combining social web with semantic web.

The simplest form of utilizing additional information which
emerges from a collection of user contributes might be average
scores or rankings of items which can be found on shopping sites
and movie rating sites. However, a machine has limited kinds of
such information without some structured data. Thus, there have
been many previous work to obtain structured data.

Annotating web contents is one of such examples. Systems like
OpenCalais [20] and Zemanta [12] automatically annotate the text
part of the blog postings with the help of entity name extractor and other natural language processing tools. The problem of
the automatic text annotation is that automatic annotation over
unstructured text is as difficult as natural language understanding.
Cayzer first proposed and implemented a blog with semantic
annotations [4]. SemBlog [10] is also a similar semantic publishing
platform based on open-source tools. SIOC [2] is a meta-data model
for user-generated contents. It enables users to search through different types of forums and blogs with the same structured data. The
models like SIOC mainly address the problem of data portability
between social web services. FOAF [3] is a practical project which
is similar to SIOC. It tries to unify the way of representing personal
information and social information in the structured data.

Structured data can be used in a search enhancement. One of
such enhancements is the faceted search [25] which continuously
narrows the query to find results satisfying the conditions of the
query. The structured data such as SIOC or FOAF can work as additional features or conditions to narrow search space.

The idea of combining semantic web and social web gets more
interests from the research community. One of such approach is
to build emergent semantics from social web which aims to over-

Fig. 1. Overview of the ontology.

come the knowledge acquisition bottleneck. In [13,24], it has been
shown that light weight ontologies can be constructed from the
social tagging behaviors.

In [7], a collective knowledge system is defined as the system
which enables computation and inference over the collected infor-
mation, leading to answers, discoveries, or other results that are
not found in the human contributions. Such new discoveries and
answers are called as the emergent knowledge. In [7], a travel social
web system with a recommendation facility was given as an example of such system. The system infers the preferences of users from
the users postings and connections among locations, users and
tags. The similar efforts of processing and finding collective knowledge from social web content with semantic web technologies can
be found in [22] (a recommendation system) and [21] (a tutor sys-
tem). However, such systems utilize the findings only to solve the
pre-defined problems. Therefore, the users are not able to query
the emergent knowledge directly.

3. The event ontology and the semantic annotation

3.1. Event ontology and domain ontologies

The event ontology is designed to express simple events of
everyday life such as dining, shopping, reading books, or making
a trip. The ontology is used as a vocabulary for semantic annotation
of each blog posting.

Compared to more sophisticated event models like LODE [17]
or F-model [16], the event ontology of this paper is much sim-
pler. F-model is a complex ontology that can express not only time
and space, but also correlational or casual relationships between
events. LODE is an event model that is designed to inter-operate
between various linked data such as museum data or historical
events. Unlike LODE or F-model, term event in this paper means
personal event, and the ontology is also reflecting it.

The outline of the ontology is shown in Fig. 1. The ontology
is designed as simple as possible, since it is believed that simple semantics and lots of annotated instances are far better than
richly-annotated few instances. Instances with complex semantics
are rich in knowledge, but it is generally more difficult or often
impractical to obtain richly-annotated data. Moreover, even with
simple semantics, a lot of new information which are not directly
available in the ontology can be found by the rule processing.

In Table 1, all predicates of the event ontology are listed. The
predicate e vent:subject links to the subject of the event which
is a FOAF instance. There are two predicates related to time
information, e vent:beginTime and event:endTime. The predicate e
vent:object holds the topic item of the event, which is an instance
of the domain ontology. The predicate event:rating holds the rating
value of the event.

To capture various events of the blogs, the existence of proper
domain ontologies is essential since the domain ontologies provide

Table 1
Predicates of the event ontology.

Name

event:subject
event:object
event:beginTime
event:endTime
event:withWhom
event:postingURL
event:eventType
event:rating

Table 2
Information in topic domain.

Domain

Book ontology

IT ontology

Location ontology

Detail

Agent of event, a blogger (FOAF inst.)
Topic of event, a domain ontology inst.
Starting time of event
Ending time of event (optional)
Additional agent of event (optional)
URL of the blog posting
Activity type of the event
User rating of the event (optional)

Information for each instance

Title, author, translator, publisher, publish
date, genre, ISBN, picture URL
Name, alternative names, manufacturing date,
maker, weight, available colors, picture URL,
device type, supported file types, capability
codes
Name, alternative names, feature code,
address, latitude, longitude

the t opics of the events. In this paper, three domains are covered in
data gathering. They are domains of Books, Travel locations, and IT
devices. A book ontology in [1] is adopted and slightly modified to
fit Korean books. GeoNames ontology [23] with minor modification
is adopted for travel locations. Lastly, the IT ontology of [5] is used
as a domain ontology of the IT devices.

The instances of domain ontologies are connected to event
instances by predicate event:object as topic items of the events.
For example, if a blog posting is about a book reading, the e
vent:eventType predicate of the event has the value of  bookread-
ing, and the topic item of the posting is an instance of the book
ontology which is connected by event:object predicate. If a posting
is about an IT device, the topic item of the posting is an instance of
IT ontology. The information which are explicitly available in the
domain ontologies are listed in Table 2. Table 3 shows the personal
information recorded for each blogger.

Previous semantic blog of [10] and SIOC publish metadata of the
blog itself in semantic form. Blogs have a lot of metadata that can
be beneficial when published: user interactions between bloggers,
dates of posting and interaction, attached data and links, etc. How-
ever, the ontology used in this paper does not try to model metadata
of blogs. It only tries to capture the experiences expressed in the
blog contents. In a way, the event instance of this paper can be
regarded as a semantic version of tags that is attached by the
bloggers.

3.2. Semi-automatic semantic annotation

In the proposed system, each blog posting is treated as an event.
Each posting becomes an instance of the event ontology. The annotation is actually the determination of the topic item of the posting
(event:object), the experiencer (event:subject), and the rating of the
experience (event:rating).

A semi-automatic semantic annotator is implemented to obtain
such semantic annotations from the real world blog data. Automatic
annotation of a blog posting is yet a difficult task, since the posting

Table 3
Information in personal data.

Domain

Blogger info. (in FOAF)

Information for each instance

Name, nickname, blog URL, age (birth
date), address, gender

is a free text. There are various automatic annotation work in the
literature [26,11,19], but the accuracy of automatic annotations is
still far from 100%. Thus, a semi-automatic annotation method is
adopted in the proposed system.

The annotator module in the system reads a blog text and
extracts words and phrases that can be the topic item of the blog
posting. The extracted words and phrases are compared with the
labels of instances in the ontology. The annotator module returns
relevant instances of the domain in a ranked list. The semantic blog
shows the list to the user. From this list, the user can select the topic
of the posting.

This semi-automatic annotation module is used in two ways.
The first is a blog system with semantic annotation capability. A
screen-shot of the blog is shown in Fig. 2. After a blogger posts
an article, the blog interface asks the domain of the posting. After
getting the domain from the user, the semi-automatic annotator
processes the text in real-time and lists all seemingly possible topic
items in the list. This is shown in Fig. 2(a). In this figure, the listed
topic items are book titles. If there is a relevant topic item, the blogger selects it from a drop-down box. If the list does not include a
proper topic item, the blogger can input the name of the topic item
as literal, or can search other instances by typing an instance name.
Other fields are also shown to the user with default values. For
example, the time of the event is presented to the user as of today,
and the rating of the item is given to the user as a blank. If the blogger wants to change the date or the rating, she can do so with a
few clicks. Fig. 2(b) shows the complete annotation, after the blogger finishes the posting. It shows the domain, topic item, time and
rating of the blog posting. Fig. 2(c)) shows (part of) the same annotation written in OWL. The assumption behind this semantic blog
is that bloggers will tag their content with semantic annotations if
the process is easy enough (for the case, a few clicks).

The second way of using the semi-automatic annotation module is the annotation collecting tool. The tool is designed to collect
a large set of annotations from existing blogs, since the number of
users of the new semantic blog is yet too few to form a large collection of events. The following process was used to collect annotated
blog postings from conventional blogs.

(i) Select some domain instances.
(ii) For each instance, search blog postings with conventional
search engine, with labels and names of the domain instances.
(iii) Gather the resulting blog postings. Process each posting with

semi-automatic annotator.

(iv) A human annotator selects the topic item from the ranked list.
The human annotator fills in other information like rating and
date according to the posting. Unrelated or noisy postings are
discarded by the human annotator.

4. Accessing emergent knowledge

In this paper, it is assumed that the new relations can be found by
finding meaningful connections between event participants (sub-
jects and objects). For example, the fact that a user has connections
with 10 different books (by events of book-reading) does not reveal
any new findings. However, if all 10 books have one same genre
field (say, Sci-fi), then a new connection can be drawn between
the user and the genre (say, the user is a sci-fi lover). Likewise, if
those who regularly post about sci-fi books also post often about
books of fantasy genre, a new connection between two genres can
be drawn. If it can be assumed that the blogosphere reflects the
real life, these findings can be regarded as knowledge about what
people do usually.

From the event data collection, an expert might be able to mine
such knowledge with various methods. However, the goal of the

T.-G. Noh et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 329339

Fig. 2. The semantic blog with semi-automatic semantic annotation. (a) Selecting a topic item. (b) The annotation seen to the user, as a collection of domain, topic, date and
rating. (c) The annotation captured in an RDF/XML file.

proposed system is to build a system that automatically tracks such
findings and let those findings explicitly available to casual users.
The methods adopted to make them available are described in the
following subsections.

4.1. Semantic rules

In this paper, a rule-based method is devised for finding meaningful connections between items and people. The rules are called S

Table 4
Examples of semantic rules.

Label part

Sci-Fi lover

Hot devices

Early adopters

Best sellers (of year N)

Steady Seller

Antecedent part

Who posts more than 10 Sci-Fi book
postings within a year OR who has more
than 20 book postings and at least 20% of
them are Sci-Fi.
Ratio (number of postings about the item
within last 3 months, number of postings
of the domain within 3 months) >0.05.
Who has posted more than 10 reviews
about IT devices that are launched in less
than 3 months at the time of each posting.
Top 50 most discussed books in the given
year N.
Best seller for more than 3 years.

Table 5
Examples of alias keywords.

Alias name

(age group) 20s

published in last n year

Bookworm

last year

SPARQL clause
SELECT ?x WHERE {?x
foaf:birthday ?y FILTER
(current-date ? y > 20 &&
current-date ? y < 30)}
SELECT ?x WHERE { ?x rdf:type
book. ?x book:publishdate ?date
FILTER (?date < current-date 
000n-00-00) }
SELECT ?x WHERE {?x tyl:slabel
bookworm}
SELECT ?x WHERE { ?x
event:beginTime ?y FILTER (?y >
current-date  0001-00-00 && ?y
< current-date.year-01-01) }

Role

emantic Rules, and they are pre-defined rules which describe certain patterns. When some instances satisfy one of the rules, they
will acquire an additional property.

Each semantic rule consists of two parts. One is an antecedent
part in which the condition to be satisfied is described. The other is
a label part which is assigned to items satisfying the condition. The
labels are usually words or phrases that are meaningful to human.
Table 4 shows some examples of semantic rules. Note that rules can
reuse other semantic rules in them. For example, a rule for steady
seller can be defined with best seller. Defining semantic rules
can be regarded as defining higher level concepts with relatively
lower level event descriptions.

In the proposed system, SPARQL is used as the rule description.
Although SPARQL is a query language, it can be successfully
used as rule language [15]. In this paper, it is used as a description
of conditions to match. The semantic rule has only two parts;
the condition part and the label part. If an instance satisfies the
condition, it will have the label as its new property.

Two additional functionalities have been added to effectively

use SPARQL as the rule description.

 SPARQL lacks a method to update the ontology. The RDF store
used for the system did not support SPARQL 1.1 nor SPARQL-
update. Thus, in the proposed system, the modification of the
ontology is done by the external rule-processor. The ruleprocessor looks up the semantic rule table and labels the
instances which satisfy the rules.

 SPARQL does not have some important functions such as count-
ing, accessing date of today, or calculating of ratios.1 Thus, these
functions are provided externally to be used with SPARQL. The
functions are implemented in JAVA.

The rule-processor checks all semantic rules in a daily basis. One
reason for daily process is time complexity of rule processing. Some
rules can not be processed in real time, and thus must be processed
before the query time. For example, if a rule for light weight mp3
device is defined as top 20% of light weight mp3 devices, the
rule-processor has to check all instances of mp3 devices. Then, it
takes a few minutes to process this rule.

The other reason of the daily processing is that some rules
depend on time. For example, if a rule for book worm is defined
as a person who posted more than 30 book articles in the last 12
months, the rule has to be re-evaluated at least monthly. Since the
ontology of the proposed system is about human events, temporal
information is an essential part and many rules are related with

1 Most of these functions are overlapping with SPARQL aggregation functions of

SPARQL working group.

time or durations. Therefore, a periodic rule processing is required
for the ontology.

The role of the semantic rules is important in the proposed
system. Semantic rules add new properties to the subjects (FOAF
instances, bloggers) and objects (domain ontology instances, topic
items of blog postings) of the ontologies. Added labels act as bridges
that link the low-level event data and high-level concepts that are
meaningful to the users. These additional labels make the ontology richer. For example, the concepts like early adopter, apple
lovers, top 10 books of this year, and southern area do not exist
in the ontology as a direct form, and can not be queried directly.
With semantic rules, those items or bloggers can be explicitly
expressed and can be selected. Thus, providing enough semantic
rules makes the ontology richer and more meaningful to the human
users.

Semantics labels are connected to ontology instances by the

predicate of tyl:slabel. All attached semantic labels are literals.

4.2. Methods of querying

In addition to SPARQL, two other query methods are designed for
casual users. The first is the keyword-based queries. For keyword
based queries, alias keywords are defined. In Table 5, some alias
keywords are listed. Alias keywords are natural language keywords
that will be translated into SPARQL phrases by a pre-defined table
look-up. For the proposed system, about 500 alias keywords are
defined.

Each alias has a predefined role: object (O), subject (S) or event
(E). For example, an alias of 20s has a role of S, which implies
that this alias is always translated into a restriction to a subject
of an event. On the other hand, published in last year is marked
with O and translated into a restriction to an object of an event.
Thus, a set of keywords like books, published in last year, favored
by 20s, favored by bookworm, can be translated into a proper
SPARQL query by matching and connecting clauses and their role
markers.

To form complex queries with more than one Subject-Event-
Object pattern, users have to explicitly use parentheses with role
markers. For example, books favored by teens can be described
without parentheses by books, favored by 10s. Then, bloggers who
have read books favored by teens can be queried by (people, read,
(books, favored by 10s)O)S.

Matching a natural language keyword with an ontology instance
can be ambiguous. For example, keyword devicename:iPod can be
matched to more than one IT device instance, since many models of
mp3-players are called iPod. In the proposed system, ambiguity
resolution is not attempted at the query processing time and the
query result will contain all instances with the name or alternate
name of iPod. The users can make a stricter query by using URIs.

T.-G. Noh et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 329339

In the proposed system, the users can click an item in the search
result to copy the instances URI.

There is also a natural language (NL) query module. The module
translates NL queries into SPARQL queries. The method for this is
described in detail in [8].

4.3. Enriching the search result

The result of a SPARQL query is just a set of instance URIs which
satisfies the query. For example, if the user query was about light
weight mp3 devices, the raw search result of equivalent SPARQL
query is a list of domain ontology instances like device0031,
device1097, . . .. This result must be enriched before being presented to the users.

The search engine decides the additional information needed
for each search result according to the type of the search target.
If the query result is a set of travel locations, the search engine
will prepare a travel location result page, and it will make additional queries to the ontologies for obtaining additional information
about locations. Name, address and picture URL of each location
is queried. To prepare a map in the search result, the engine also
queries longitude and latitude.

For books, information of each book is added: author, publisher,
date of publish, genre, translator and picture URL. For the search
results on people, a social network among people is drawn from
their FOAF friends and reply/trackback links. For all result pages,
the labels of the semantic rules (semantic labels) attached to the
search results are given with a frequency. With this frequency, a UI
(user interface) module draws tag clouds of the semantic labels.

The search engine returns this enriched search result in a XML
format. Processing and visualizing the search result is the role of an
UI. Our UI implementation is described in Section 5.

4.4. Scenario-based analysis

With the semantic labels, users can ask relations which did not
explicitly exist in the domain ontology nor in the event ontology.
However, this search method is still a kind of faceted search over
the ontology instances. It finds the subjects or objects of event collections which satisfy the given query condition. Thus, it can not
answer questions such as What are the major differences between
mobile phones released in this year and mobile phones released in
last year?, What is the common point between these two groups
of people?, and How the available colors of mp3 devices have
been changed for last five years?

Fig. 3. System overview, data collection part.

A scenario-based analysis is devised to address information
needs like this. The analysis module processes pre-defined types
of analysis requests described below.

 Common points: What are the most notable common points

between two instances or two groups of instances?

 Differences: What are the most notable differences between two

instances or two groups of instances?

 Changes over time: How properties of an instance or properties of

a group of instances have changed over time?

 Connections between two: If a user has an event, how likely the

same user will have another specific event in the future?

For the scenarios of common points and differences, a simple
vector model is used to measure similarities or dissimilarities.
Two groups to be compared are first represented as two vectors.
Properties of the instances, connected instances and properties of
connected instances are used as elements of the two vectors. After
calculating the similarity between two vectors, the elements which
mostly contribute the similarity are then extracted. For example,
if two items represented in the vectors have enough similarity,
the analysis module declares that two items are quite similar and
extracts top n elements of the vectors as common points.

The scenario changes over time tracks the changes happening to
a group of instances. The scenario module plots the frequency of
various properties (semantic labels, genres, age group of subjects,
etc) in the time graph. It also points out the properties which have
been greatly changed.

The scenario connections between two is based on a simple fre-
quency. It simply counts the co-occurrences of two event topics
in the event ontology. The co-occurrence is calculated by count-

Fig. 4. System overview, search and analysis part.

Fig. 5. An example of search result.

ing number of people who have experienced both topics. If the
frequency is higher than the average expectation between two random topics, the scenario module reports that two event topics have
a possible relation. It also reports bloggers who have posted both
events as evidences.

5. Experience search system: architecture and
implementation

Figs. 3 and 4 show the overview of the system architecture. Fig. 3
depicts the data collecting part: the semantic blog and the annotation collecting tool. The blog is implemented by modifying an open
source blog system.2 The user interface of the semantic annotation
was written in PHP, and the semi-automatic annotation module
was written in Java. Both PHP and Java run on a web-server. The
annotation tool is a local Java application. It uses the same semiautomatic annotation module with the semantic blog. However,
for the annotation tool, the annotation module runs with the blog
postings collected from commercial blog search engines. Two local
Korean blog search engines were used to collect blog postings of
the given domains.3.

The semi-automatic annotation module needs domain ontology
for its topic item listings. Access to the domain ontology is handled
by a RDF store. In our implementation, Allegrograph [6] is used
as the RDF store. Allegrograph provides its own Java client-server
query method and a Sesame-based query method. In the system,
the Java client-server method was used. Both the semantic blog and
the annotation tool output OWL files as their results. Each OWL file
is an event instance that represents the corresponding blog posting.
The semantic blog also provides the FOAF instance of the user. With

2 Textcube, http://www.textcube.org/.
3 Aladdin blogs

(http://blog.aladdin.co.kr/)

for books and Egloos blogs
(http://egloos.com/) for IT devices and travel. Note that the category of the
blog postings (book, IT device, or travel) are explicitly set by the blog users in those
blog systems.

this setup, more than 100,000 blog postings were annotated and
collected in the event ontology.

Fig. 4 shows the search and analysis part. In this figure, the
search module and the analysis module lies in the center of the sys-
tem. All modules of this part including UI are written in JAVA. Again,
Allegrograph is used as the RDF store. All ontologies including FOAF
and domain ontologies are stored in one RDF store due to the speed
issue. The search module accepts SPARQL, keyword queries, and
natural language queries. A SPARQL query is directly processed by
the RDF store, while keyword and natural language queries are first
translated into a SPARQL query before being queried upon the RDF
store. To answer the query in real-time, SPARQL LIMIT for each
query is set to a fixed number (20). With additional request from
the user, the search module will get next 20 results. To enrich the
search result, the search module requests additional information
to the RDF store, as described in Section 4.3. With the added infor-
mation, the search module outputs the final result in a XML format.
The XML file is then transferred to the UI module.

The UI module is implemented with the Prefuse visualization
library [9]. The UI renders XML files into human readable results.
Fig. 5 shows a search result UI. The query is 20s, women, favored
books, published within 1 year. The result screen is split into 4
sections. The upper left section lists the books which satisfy the
query. That is, the books are listed which are published within 1
year and rated as more than 3 by women in their 20s. By clicking each book in the list, a user can access the original postings
of the query subjects. The graph shown in upper right section is
a subject-gender graph of the books. By clicking on this compo-
nent, other graphs such as subject-ages, distribution of semantic
labels, object-genres and object-publishers can be shown. The
lower right section shows a social network of items. Each node in
this graph is an item (in this case, a book). Thus, the connected
nodes in the graph imply that someone reviewed both items. The
size of a node is decided by the social network measure of the
centrality.

Fig. 6 shows an analysis result page. In this figure, two groups
of people are compared to find their differences. The first group is

T.-G. Noh et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 329339

Fig. 6. An example of analysis page.

Apple lovers, and the second group is Samsung lovers. In the
upper part, the bloggers from each group are listed. In the lower
part, various values and properties which are most distinct between
two groups are listed in descending order. Only the first two differences are shown in this figure. The system finds that two groups are
quite different, and points out that the first group (Apple lovers)
is more royal to the company and it has significantly more women
as its members.

6. Evaluation

6.1. Setup and procedure

A user evaluation was set up to assess the usability of the search
and analysis system. The evaluation was designed to evaluate following points.

 Is it easy for normal users who know nothing about SPARQL and

ontology to understand the semantic labels?

 Can normal users easily search and analyze with the semantic

labels?

 Is it easy for the users to understand the search and analysis
result? Are they able to navigate within the search result easily?
 After accessing the result, will they trust the system output?
What would be their impression on the system, comparing to
the current commercial services?

Fifteen participants took part in the evaluation. They were
recruited by acquaintance. Three of them are women, and the
rest are men. Their age ranges from 20 to 38. Most of them are
undergraduate students, while some of them are researchers and
graduate students. To make sure they can represent normal users,
only those who know nothing about ontologies and Semantic Web
are accepted as participants.

Among three available search methods, alias-keyword based
query was selected for the evaluation. SPARQL has been ruled out

since no participant knew it. NL query module has also been ruled
out due to its limited domain.4

Fourteen tasks were prepared for the participants. The test was
done individually. At arrival, the participants were introduced to
the system and the purpose of the evaluation. First, they were told
the main features of the system, and then the participants familiarized themselves with the system with first four training tasks.
During the training, the participants could ask for an explanation
or support. They were then asked to carry out another 10 tasks on
their own. These tasks were slightly more complicated than the
trainings.

The instruction of each task describes the information needs and
the required actions to attain the goal. However, the instructions
do not specify how the actions should be taken.

For example, let us consider the instruction of task #5: We
need to find more than two romance novel authors who are
favored by female bloggers. First, find romance novels favored by
female bloggers. Then, report the names of the authors. In this
task, users have to compose a query with semantic labels (i.e.
[genre:romance][books][favored by][woman]), and user need to
look for the name of authors in the result list. Some tasks were
more complex than others. For example, task #7 requires users to
form two consecutive queries, and task #11 needs queries with role
markers. The complete list of tasks used in the evaluation can be
found in Appendix A.

Except task #13 and #14, the participants reported the result
verbally at the end of each task. We checked correctness of the
result and response time. The number of navigational interactions
on the UI was also captured by counting the number of clicks that
had changed the view panels of UI. The final two tasks are free tasks.
Task #13 asks users to try any query that he or she feels like to ask.
Task #14 asks users to pick any two of the previous tasks and try

4 At the time of evaluation, it cannot handle queries about travel locations and IT

devices.

Table 6
Average time on task, average number of query and interaction (time in s, amount of action in percentage compared to minimum required actions).

Min. time

Max. time

Mean. time

Std. dev.

Avg. query amnt.

Avg. interact. amnt.

Num. correct answer

Task #5
Task #6
Task #7
Task #8
Task #9
Task #10
Task #11
Task #12

150%
200%
105%
120%
130%
130%
190%
200%

180%
175%
135%
140%
155%
118%
290%
280%

14/15
14/15
13/15
15/15
13/15
14/15
11/15
12/15

to fulfill the information need with any other search system. They
were given 30 min to solve all predefined tasks from task #5 to #12.
At the end of evaluation, the participants were requested to fill in
a questionnaire composed of 21 open and closed questions. Closed
questions are on a 5-point scale and address the system overall:
overall impression, its learnability, semantic label, search result and
analysis result. Open questions are about positive aspects and negative aspects of the system, and what they have learned in task #13
and #14.

6.2. Result and analysis

6.2.1. Time and accuracy

Table 6 shows the average time and amount of interaction taken
for each task. It also holds the number of correct answers from the
participants. Minimum time for each task shows the response time
of the fastest participant for each task. Maximum time shows the
slowest response for the task, and mean time shows the average
time taken for the task among the 15 participants. Average amount
of query and interaction show relative numbers of queries and
interactions in percentage compared to the best case for each task.
Performance varies greatly from task to task and from participant to participant. Seven participants successfully answered all
predefined tasks. Five participants missed only one task. The lowest performing participant only answered 4 out of 8 tasks correctly.
Users response time also varies greatly from 30 s to several min-
utes. This reflects that combining semantic labels was not easy for
some participants.

Task #5 and #12 are tasks that need only single query and one
interaction. The average time for the two tasks is 166 s. Even the
fastest participant took around 50 s. The participants spent most of
the time reading the list of semantic labels to find a proper label.

The difficulty of task #5 and task #12 is roughly same in terms
of query complexity and the number of interactions. Task #5 is
the first task of their own and task #12 is the last task. However,
the participants could not solve task #12 faster. The query of task
#12 needed a new semantic label which was not seen previously
to the participants. It is a semantic label about fans of an author,
and its form is [author name] fan. However, there are other alias
keywords that are different in forms, like booktitle:[title] and
author:[name]. The participants were generally confused and
tried to find a form like fan:[author name], or fanof:[author
name]. They could finally find the correct form, but not before
they looked through all the list of related semantic labels.

Most of the participants could answer the tasks correctly within
given time. Average accuracy was 88%. Considering some tasks
need logically complex queries, this is not a bad result. The most
difficult query for the participants was the query of task #11. In
this task, the participants are needed to use parentheses and an
explicit role-marker to form the corresponding query. Although the
usage of parentheses and role-markers are explained in the training
task #3, some participants failed to understand the notation. Even
the participants who understood the notation complained that the
notation was not very intuitive.

6.2.2. User satisfaction

The closed questions are grouped into five sets: overall system
issues, semantic labels, search results, analysis results and learn-
ability. Overall the participants opinion was positive. The system in
general was judged satisfying (86.7%) and very stimulating (100%).
However, the participants responses were neutral on easiness of
the system usage (46.7% positive and 20% negative). On speed and
reliability issue, only 47.7% judged the system as fast (vs. 33.3%
negative) and 40% judged the system as reliable (vs. 26.7% negative).
In the proposed system, it is not difficult to form a query that
needs a long response time (for example, combining several labels
that use SPARQL FILTERs). Even though the system limits the search
results to 15 by SPARQL LIMITS, it is still possible to form a query
that needs more than 1 min to process. The correct queries of
the prepared tasks generally do not need that much time (at most,
around 10 s).

Low reliability of the system is also caused by the slow response
time. Current RDF store of the system does not support canceling an ongoing query. Thus, from a users point of view, the system
client reports nothing after processing a slow query. After some sec-
onds, the impatient user restarts the program, and then it suddenly
works slower than before since the RDF store is still processing previous query. This generally gave the feeling of unreliable to our
participants.

Most of the participants felt that the semantic labels were
not difficult to understand (only 6.7% negative, 60% positive), but
remained neutral about easiness of forming complex queries with
semantic labels (46.7% neutral, negative and positive both 26.7%).
The participants replied that understanding of search result was
easy (93.3%) and navigating search result was also easy (66.7% positive and 26.7% neutral). Nearly all participants judged the search
result was satisfying (93.3%) and stimulating (93.3%).

The participants found the analysis result was easy to understand (80%), and navigate (60% positive and 13.3% negative). They
marked the analysis result was good (80%) and stimulating (93.3%).
Last two closed questions are about learnability. About half of the
participants judged the system was easy to learn (53.3%), while 20%
remained neutral and 26.7% judged it was not easy. The participants
generally agreed that the system was intuitive once mastered its
usage (66.7%), but 20% of the participants still felt it is not intuitive
even after completing all the tasks.

For open questions, the participants replied what were the most
positive and negative issues of the system, and what they thought
about the system compared to their favorite blog search services.
Besides the already mentioned problems of speed and composing
queries, the participants noted that UI was not tidy enough. They
also pointed the inconsistencies of the UI behaviors.

Some participants also wanted to see an additional method to
confirm that they got the intended query. Experts can judge that by
looking at the generated SPARQL, but normal users have no way to
check the meaning of the query other than the query itself.

Among the given tasks, the participants picked the results of
task #4 (comparing books read by men and women) and task #10
(finding out when people usually take trips to mountains) as their

T.-G. Noh et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 329339

favorites. The participants generally liked rich additional information given to them in forms of maps, graphs and networks. They
also liked the links to blog postings provided as evidences, so they
could visit and read the blog postings to check that the system was
not lying.

When comparing the proposed system with their own favorite
search engines, the participants generally responded that the systems capability to analysis and query with conditions was unique
and preferable.

6.2.3. Overall result

The participants generally regarded the system as interesting
and useful. Even the participants who criticized the query methods
and speed issues highly praised the system output (100% stimulating and 86.7% satisfying). This is partly because the system
sometimes gives us unexpected and surprising results.

For example, with task #4, casual users can find the statement
men read horrors, women read romances is only half-true. It
shows that women do frequently read romances and male bloggers rarely read romance novels. However, female bloggers who
read horror novels also outnumber male bloggers who read the
same genre. From the result of the system, the statement can be
rewritten into something like Women often read, Men rarely read.
Romance novels? Men just dont.

Task #10 tests a Korean saying, Beaches at summer. Mountains
at autumn. But the system tells us that this is hardly true at least
in Blogosphere. Time-event graph of the search result shows that
postings about mountains dramatically increase in July and August,
while postings about beaches does not have distinctive increase and
they are being visited through all seasons.

Finding such unexpected answers is indeed the goal of our sys-
tem: a system that enables users to acquire emergent knowledge
that is scattered behind social web content. Though the proposed
system is yet far from perfect, the evaluation session could draw
positive responses from general users. It has shown that a new type
of search is possible and promising.

7. Conclusions and future work

In this paper, a novel system has been proposed which enables
its users to access the emergent knowledge from the social web
data. The proposed system considers blog postings as experiences
of various users. Thus, the blog postings are converted into machine
readable events by a semi-automatic semantic annotation. The system draws previously unavailable information from the collected
events through rule-based labeling and scenario-based analysis.
With the system, the users can ask several types of queries which
can not be processed by legacy search engines.

Many works are left for the proposed system. Our future work
will be focused on practicality of the system including improving the annotation method (more accurate, automated semantic
annotation), speeding up the search process, processing of other
types of events (some popular categories like music, movies and
sports), additional analysis with more sophisticated methods, and
web interfaces for the search/analysis UI.

A more thorough evaluation is also future work. The paper
showed the effectiveness of the proposed system with a group of
users. It will be interesting to compare the system directly with
traditional search engines like Google or Naver. To design such an
evaluation, a well-balanced test set and a new evaluation measure might be needed. For example, if the tasks described in the
appendix were tested on traditional search engines, they would
have scored far lower than the proposed system since the tasks
were designed to test the ability of the proposed system. Measuring emergent findings is also an issue: it is still unclear that

the traditional Precision/Recall measure is a good measurement for
such knowledge findings. In this paper, the test group was a small
group recruited by acquaintance. By preparing a web version of
the system, it would be possible to evaluate the system by a larger
group of independent testees. Evaluating the effectiveness of query
interfaces themselves (NL, SPARQL and keywords), other than the
system output, is also another future work.

Processing, counting and labeling of events with rules are what
machines (the semantic web technologies) do well. Clarifying and
discriminating what is meaningful and what is not are what human
beings (the social web users) do well. The proposed system is
a feasible attempt to combine their merits to process emergent
knowledge from the vast content of social web.

Acknowledgment

This work was supported by the IT R&D program of MKE/IITA:
Development of a Cognitive Planning and Learning Model for
Mobile Platforms.

Appendix A. Tasks used in the evaluation

Task definitions and their best queries are given in this section.
Actual task instructions are in Korean. The text listed here is a direct
translation.

(diff)

[people][read][genre:horror][book],

([person][read][book][bookauthor:Yu Hong-Jun])S

 Task #1: Find more than three mp3-players that are favored by
20s.
 Query: [mp3-player][favored by][20s]
 Min. num. of needed interactions: 1
 Task #2: Find blog postings about mp3-players from Apple. Find
any mp3-player made by Apple. Find more than two blog postings
related to that item.
 Query: [maker:Apple][mp3-player]
 Min. num. of needed interactions: 4
 Task #3: Yu Hong-Jun is a famous author of a travel book. Where
are the travel locations people those who have read his book
travel to?
 Query:
[traveled] [travel location]
 Min. num. of needed interactions: 1
 Task #4: They say Men read horrors, Women read romances.
Check out this is true in blogs. Compare differences of two groups;
who have read horror novels and who have read romance novels.
 Query:
[peo-
ple][read][genre:romance][book]
 Min. num. of needed interactions: 1
 Task #5: We need to find more than two romance novel authors
who are favored by female bloggers. First find romance novels favored by female bloggers. Then, report the names of the
authors.
 Query: [genre:romance][book][favored by][women]
 Min. num. of needed interactions: 1
 Task #6: What products from Apple, that is favored by women,
20s, is also favored by 40s? First find the products from Apple
favored by women 20s. Then, check each product to find which
has been mostly referred to by 40s.
 Query: [device] [maker:Apple] [favored by] [20s] [women]
 Min. num. of needed interactions: 4
 Task #7: Lets find a book that is published in 2003, and that
is commonly loved by women of age-group 20s and 30s. First
compare common points between two groups: women in 20s
and women in 30s. Find the most commonly loved author. Then,
find the books written by him or her in 2003.
 Query1: (common) [women][20s], [women][30s]

 Query2: [books] [author:Murakami Haruki] [published in
2003]
 Min. num. of needed interactions: 2
 Task #8: Find the most commonly talked mp3-player among
mp3-players favored by early-adopters. What age-group is referring to the device mostly?
 Query: [mp3-player][favored by][early-adopter]
 Min. num. of needed interactions: 2
 Task #9: Search steady-seller books. Pick any steady-seller
author, and report books written by the author.
 Query1: [Steady-seller][book]
 Query2: [book][author:xxxx]
 Min. num. of needed interactions: 2
 Task #10: Find mountains that 20s often travels to. Tries to find
when the places are usually visited in terms of months or seasons.
Report the seasons or months and point the evidence.
 Query: [mountains][often visited by][20s]
 Min. num. of needed interactions: 5
 Task #11: Gong Ji-Young is a famous author who have wrote
several influential novels. What books are recently read by those
who have read books of Gong Ji-Young? This can be a complex
query. Report the name of the books.
 Query:
[recently][read][book]
 Min. num. of needed interactions: 1
 Task #12: Find foreign novels that are favored by fans of Paul
Auster.
 Query: [genre:foreign novel][Paul Auster Fan][favored by]
 Min. num. of needed interactions: 1

([person][read][book][author:Gong

Ji-Young])S
