Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 110124

Contents lists available at ScienceDirect

Web Semantics: Science, Services and Agents

on the World Wide Web

j o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / w e b s e m

Automatic construction of a large-scale situation ontology by mining how-to
instructions from the web
Yuchul Jung, Jihee Ryu, Kyung-min Kim, Sung-Hyon Myaeng

KAIST Computer Science Department, 335 Gwahak-ro, Yuseong-gu, Daejeon, South Korea

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 11 October 2009
Received in revised form 31 March 2010
Accepted 9 April 2010
Available online 18 April 2010

Keywords:
Automatic ontology construction
Situation ontology
Action mining
How-to instruction
Service recommendation
Automatic service composition

With the growing interests in semantic web services and context-aware computing, the importance
of ontologies, which enable us to perform context-aware reasoning, has been accepted widely. While
domain-specific and general-purpose ontologies have been developed, few attempts have been made for
a situation ontology that can be employed directly to support activity-oriented context-aware services.
In this paper, we propose an approach to automatically constructing a large-scale situation ontology by
mining large-scale web resources, eHow and wikiHow, which contain an enormous amount of how-to
instructions (e.g., How to install a car amplifier). The construction process is guided by a situation model
derived from the procedural knowledge available in the web resources. Two major steps involved are:
(1) action mining that extracts pairs of a verb and its ingredient (i.e., objects, location, and time) from
individual instructional steps (e.g., <disconnect, ground cable>) and forms goal-oriented situation cases
using the results and (2) normalization and integration of situation cases to form the situation ontology.
For validation, we measure accuracy of the action mining method and show how our situation ontology
compares in terms of coverage with existing large-scale ontology-like resources constructed manually.
Furthermore, we show how it can be utilized for two applications: service recommendation and service
composition.

 2010 Elsevier B.V. All rights reserved.

1. Introduction

Ontological knowledge has become a main vehicle for semantically and conceptually oriented techniques and applications such
as word sense disambiguation, searching, classification, question
answering, entity resolution, and context/situation-aware reasoning for personalized services. However, currently available
large-scale ontologies often fail to deal with diverse task situations
that may arise in the real world because they lack in understanding the dynamic nature of daily lives of people and the associated
activities. For example, automatically built ontologies like YAGO
[12] driven by WordNet [40] and Wikipedia [39] do not have a sufficient coverage of contextual instances to reason about situations
and activities arising from different domains. There is no consideration about such activities of daily living as shopping, driving,
wedding, etc., for which the context variables like actions, location,
and time should be made available. Without a situation ontology of
this kind, it would not be possible to infer what activity the user is
engaged in and what actions are likely to be taken from the current

situation, which can be characterized with context variables like
the current location, objects used, and time.

As a novel solution to the problem, we attempt to build a huge
situation knowledge base of human activities by means of text mining techniques that exploit the structure of the how-to descriptions,
which is essential for context/situation-aware services. Action level
knowledge is extracted from eHow1 and wikiHow2, freely accessible websites currently storing more than one million articles on
how to do things step by step, which collectively cover almost every
domain of daily lives including business, cars, computers, educa-
tion, health, travel, weddings, etc. An article can be converted into
an instance of a situation ontology model that consists of a goal,
action sequence, and contextual ingredient that includes location,
time, and objects. To organize such knowledge, we have defined a
situation ontology specification that includes six ontology classes,
topic, goal, action, object, time, and location, and six types of semantic relations, hasTopic, hasAction, hasNextAction, hasObject, hasTime,
and hasLocation, all of which are derived from the eHow articles, as
in Fig. 2.

 Corresponding author. Tel.: +82 42 350 6149; fax: +82 42 350 6222.
E-mail addresses: enthusia77@kaist.ac.kr (Y. Jung), zzihee5@kaist.ac.kr (J. Ryu),

kimdarwin@kaist.ac.kr (K.-m. Kim), myaeng@kaist.ac.kr (S.-H. Myaeng).

1 http://www.ehow.com/.
2 http://www.wikihow.com/.

1570-8268/$  see front matter  2010 Elsevier B.V. All rights reserved.
doi:10.1016/j.websem.2010.04.006

We crawled the entire set of articles from the eHow and the
wikiHow websites and applied natural language processing (NLP)
techniques to obtain a highly refined situation ontology, which can
help detecting the current situation of a user in a daily life and suggesting a solution suitable for the problem at hand if any. The task
of the employed NLP techniques is to extract actions expressed in a
verb form and associated contextual ingredient items from the goal
and subsequent action sequences expressed in natural language in
an article. In order to put the linguistic constituents in an ontological form,3 we designed four additional steps: goal normalization,
action normalization, action transition probability calculation, and
ingredient resolution.

To assess the utility of the proposed method and its outcome, we
measured accuracy and coverage of the automatically constructed
ontology. Accuracy was measured by taking a random sample of
the situation instances converted from the corresponding articles.
We checked whether or not those instances were clear without
ambiguity and well-formed. For coverage of the resulting ontology,
it was compared for verbs against existing large-scale ontology-like
resources: WordNet and OMICS [27].

In this paper, an automatic situation ontology construction
based on action mining from the Web is presented to build a
large-scale situation ontology that is required to reason about user
intentions (or situations) and provide relevant recommendations in
a given context. Its main contribution is to show that an automatic
methodology can be employed to construct a large-scale situation ontology for the situation model with high precision. Given
the dynamic nature of knowledge in peoples daily activities, it
is critical to devise an automatic method for constructing situation ontologies. Through the application scenarios, we also show
that the ontology constructed as such can be of practical value
for context-aware applications. We advocate that the high accuracy of the method and the sheer size and utility of the situation
ontology lend themselves to further research and development in
context-aware applications involving unconstrained daily lives.

Section 2 describes the main features and drawbacks of previous work concerning situation-awareness, situation ontology, and
automatic ontology construction to set the stage for our work.
In Section 3, we introduce our situation ontology model and the
resources from which the current situation ontology is constructed.
Section 4 explains the details of our situation ontology construction
process focusing action mining and normalization. In Section 5, we
present an evaluation of the constructed ontology for its accuracy
and comparison to other ontology-like resources. Section 6 shows
how the newly constructed situation ontology can be utilized in
situation-aware recommendation and semantic web service com-
position. In Section 7, we give our conclusion and discuss future
directions.

2. Related work

The notion of context-awareness in ubiquitous computing was
proposed in 1990s to address the interaction between computer
systems and environments [5]. Situation-awareness has also been
used to refer to the same meaning [13]. The notion has received a
great deal of attention because it is a basis for improving the quality
of decisions in a heterogeneous, highly dynamic environment [26].
The meaning of information about the perceived objects can be
correctly determined when the situation or context is taken into
account.

3 To focus on the construction process and utility of the ontology in this article,
we define a situation model and the corresponding ontological structure, without
representing them in a language like OWL.

Ontologies have been proposed to provide a support for
situation awareness. In particular upper ontologies serve as a
common vocabulary for collaborating agents and information
sources [6,13,25,26,36]. Although those efforts succeeded in deriving design requirements [25,26] and developing domain specific
models [13], there are few attempts to build a large-scale situation ontology that can handle diverse situations in daily lives.
Context/situation-aware systems are still at an infant stage as far
as knowledge support is concerned. To the best of our knowl-
edge, there has been no explicit effort to automatically construct a
large-scale knowledge base for understanding user situations and
activities of daily living in various domains.

While not directly concerned about situation awareness, there
have been some attempts to extract semantic relations among concepts or entities that exist in a corpus, which are often simply words
and phrases. A study [21] used a set of lexico-syntactic patterns
that occur frequently to extract a lexical relation of interest from
a large text corpus. It is an early attempt to extend WordNet for
hyponyms. Another study [10] introduced an automatic method
to enrich WordNet by using the web. To overcome the limitations
of WordNet, such as lack of relations between topically related
concepts and proliferation of word senses, it linked document collections from the web to concepts in WordNet. It was shown that
the Web resource could be practically used to collect lists of words
that are topically related to the concept (called as topic signature)
and to discriminate different word senses by clustering the concepts that lexicalize them.

In the same context, attribute extraction has been the subject
of recent investigations within the information extraction commu-
nity. Extracted attributes are considered relations between entities
(or objects or values). Several studies [9,17,28,35] attempted
to acquire attributes, possibly along with corresponding values,
from Web documents. The method proposed [20] employs lexicosyntactic patterns for unstructured text in a small collection of
Web documents. More recently, weakly supervised approaches
[17,18,35] for unstructured Web documents were introduced to
deal with a large number of classes and extract attributes which
are not restricted to any pre-defined pattern types (e.g., X-of Y pat-
terns). While related, they do not deal with situations in general
nor actions and ingredients in particular.

There have been more explicit efforts to build an ontology
automatically using a single resource for background knowledge
(e.g., WordNet or Wikipedia) or multiple resources. For example,
YAGO ontology [12], a large ontology extracted from Wikipedia
and WordNet, is known to have high quality, over 95% accuracy.
It comprises not only concepts in the style of WordNet, but also
named entities like people, organizations, geographic locations,
books, songs, products, etc. They are related among themselves
with various relations such as what-is-located-where, who-was-
born-when, who-has-won-which-prize, etc. Because of the high
quality and large quantity of the data in the reusable RDF format,
it can be used to enhance the performance of existing applications and to facilitate creations of new application for semantic
web. Similar to YAGO, DBpedia [7] aims to extract structured information from Wikipedia (especially, semi-structured templates of
Wikipedia) and uses RDF to represent the extracted information. It
allows users to query relationships and properties with Wikipedia
resources. In addition, the dataset is interlinked on RDF level
with various other open datasets on the Web including: Freebase,
OpenCyc, UMBEL, GeoNames, and DBLP. However, YAGO and DBpedia can hardly support reasoning about diverse cases people are
situated in because they were obtained mainly by excavating characteristics (or properties) of existing named entities in Wikipedia.
Our work is unique in that we do not deal with an arbitrary
natural language corpus that is difficult and inefficient to process
using todays technology. Rather we deal with special-purpose web

Y. Jung et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 110124

Fig. 1. Our situation model.

resources where sentences are in a special format, namely instruc-
tions. Besides, since the content was constructed by people with
a specific goal in mind, it contains its own characteristics in lexi-
cal, syntactic, and semantic aspects. This sublanguage aspect of the
resources makes it more amenable to apply relatively efficient NLP
techniques and produce more reliable results than dealing with
arbitrarily complex sentences. Moreover, there has been no other
attempt, to the best of our knowledge, to automatically construct a
situation ontology of this scale for such a wide variety of goals and
actions, thereby enabling context-awareness of daily lives. Needless to say, the relations connecting them are not IS-A that has been
the focus of most automatic ontology construction efforts.

3. Situation ontology

In this section, we introduce our situation model and situation
ontology specification that are driven by the content how-to knowl-
edge, eHow and wikiHow. The model is intended to hold the action
knowledge available in the resources, instead of taking a prescriptive approach for general purposes. In addition, the details of the
knowledge sources are presented.

3.1. Situation ontology model and its specification

The notion of situation can be defined narrowly from a systems
perspective as a set of relevant context values that are frequently
associated with a behavior pattern of a mobile device user in a
context-aware service domain [3]. More broadly, it can be categorized into an atomic situation, a logical composition situation, or
a temporal situation, each of which has a collection of contexts and
corresponding services [37]. Regardless of the ways situations are
defined, context/situation-aware systems often fail to effectively
evolve to accommodate dynamically changing service requirements that are strongly connected with diverse situations, mainly
due to the lack of sufficient coverage of situations in daily lives.
If we were to avoid prohibitive efforts of manually constructing a
large-scale, computable knowledge base for daily living, however, it
becomes obvious that we need to resort to existing and/or evolving

human-generated resources that describe daily human activities. In
an effort to utilize such resources, we design a simple yet practical situation model amenable for the action knowledge available in
eHow and wikiHow articles.

Our situation model consists of three components (Goal, Action
sequences to achieve the goal, and Ingredients that contains context variables). While a goal represents a desired state that one
may want to pursue, its action sequence contains actual steps
to reach to the state. The ingredient component consists of context variables (e.g., objects, location, time, etc.) associated with an
action. While a triple <Goal, Action Sequences, Ingredients> can
be regarded as an independent situation, we can imagine a more
complex environment where multiple situations or goals are interwound by various activities of people in a daily life. For example, as
a goal gets satisfied, it may trigger a set of new desires, hence new
goals.4 This phenomenon can be expressed as a goal graph in the
model in which goals are connected when there is a common action
they share. This indirect relationship among goals, represented as
undirected edges, can be obtained more reliably than causal relationships that should be obtained from other resources. Note also
that a general form of an action sequence is a network since an
action can have branches. This goal-oriented structure of the situation model is a vehicle with which we represent the existing
large-scale how-to knowledge. Fig. 1 depicts a schematic diagram
for the situation model.

Our situation ontology based on the situation model takes the
form as in Fig. 2. Each goal is connected to a topical category
(i.e., topic in Fig. 2) which can be found in the eHow hierarchy.
A hasTopic relation elucidates the context and background where
a goal is found. In addition, each goal has several action steps with
a hasAction relation, which are required to reach the goal state. To
represent the order among the actions, hasNextAction relation is
used between two consecutive actions. Each action can have one
or more of hasObject, one hasTime, and one hasLocation relations
according to its subordinating collateral circumstances.

4 The terms, goal, desire, and intention are used interchangeably in this paper.

Fig. 2. Situation ontology specification (left) and real example (right).

3.2. Sources for our situation ontology

There are two quite similar resources for how-to knowledge,
eHow and wikiHow, available on the web with the same creators
and the same primary goals. The main difference is that while
eHow allows for individual contributions independently of others and hence already contains more than one million articles,
wikiHow guarantees its high quality by ensuring only one article exists for a goal and allowing a community of volunteers to
update it if necessary in a way Wikipedia is constructed and main-
tained. Due to wikiHows short history, its quantity is much smaller
than that of eHow, but the contents are maintained very carefully,
avoiding duplicates. The two knowledge resources are used in a
complementary fashion in our effort to build a situation ontol-
ogy.

3.2.1. eHow

It is a free online community (www.eHow.com) dedicated
to providing visitors an ability to research, share, and discuss
instructional solutions that help complete day-to-day tasks. It
covers a wide variety of topics organized into a hierarchy of
categories, such as automotive, college, real estate, health, and
weddings because the content is created by both professional
experts and amateur members. Each eHow article contains the
practical knowledge of everyday to help people discuss, plan,
and complete things like how to handle health insurance if
you lose your job, how to eat well for less, how to format a
hard drive with windows XP, etc. The site has over 10-year history of running it as a way of sharing knowledge on the web;
especially within Linux communities it has been very successful
[15].

It currently contains more than one million articles and 160,000
high-quality videos, and the numbers are still growing. Table 1
shows some statistics for different topic categories. Owing to its
evolving nature and the growing number of interactions among

users, the content is expected to be more accurate, highly achievable and easy to understand in the future, making them a solid basis
for a situation model and ontology. As such, our effort to construct
an ontology out of this resource is by no means an one-time effort;
the methodology and its feasibility to automatically construct a situation ontology are of utmost importance. As improvements are
made to the content and the methodologies, the quality of the
resulting ontologies will be enhanced, too.

Table 1
Statistics about eHow content (as of 08/26/2009).

Category

# content

Percentage

Arts & entertainment
Business
Careers & work
Cars
Computers
Culture & society
Education
Electronics
Fashion. style & personal care
Food & drink
Health
Hobbies. games & toys
Holidays & celebrations
Home & garden
Internet
Legal
Parenting
Parties & entertaining
Personal finance
Pets
Relationships& family
Sports & fitness
Travel
Weddings

6.7%
3.1%
3.9%
3.1%
4.7%
2.6%
3.0%
1.9%
4.9%
7.5%
12.1%
7.3%

10.2%
2.5%
1.0%
1.9%
0.9%
4.1%
3.0%
2.5%
7.4%
2.9%
0.8%

Total

1,012,773

100.0%

Y. Jung et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 110124

Table 2
Statistics about wikiHow content (as of 10/07/2009).

Category

# Content

Percentage

Arts & entertainment
Cars & other vehicles
Computers & electronics
Education & communications
Family life
Finance, business & legal
Food & entertaining
Health
Hobbies & crafts
Holidays & traditions
Home & garden
Personal care & style
Pets & animals
Philosophy & religion
Relationships
Sports & fitness
Travel
Work world
Youth

5.4%
1.9%
16.0%
6.1%
1.9%
1.9%
11.3%
6.3%
10.8%
1.3%
5.2%
5.6%
3.8%
1.2%
4.1%
7.0%
1.1%
1.4%
7.7%

Total

100.0%

3.2.2. wikiHow

It is a community-based web site with an extensive database
of how-to instructions. It started as an extension of the already
existing eHow website and has evolved to host over 56,000 howto articles with a mission to build the worlds largest and highest
quality how-to manual. Table 2 shows some statistics for 19 topic
categories. The history of wikiHow goes back to January 2005.
The two owners of eHow started wikiHowa collaborative writing
project striving to build the worlds largest how-to manual. eHow
was sold in 2006, and wikiHow was launched as an independent
site (www.wikihow.com). Although the number of articles is much
smaller than that of eHow, its quality is highly guaranteed with the
help of registered contributors. Fig. 3 shows an example of goals
of a wikiHow article with multiple eHow articles that correspond
to it. Compared with wikiHow, there exist similar and redundant
goals in eHow. The mappings are done automatically as in Section
4.2.2.

4. Situation ontology construction: goal-action mining

The goal of our ontology construction process is to derive an
explicit specification of goals and associated actions from how-to
instructions people created so that they can serve as conceptualization of situations that arise in daily lives. As depicted in Fig. 4, there
are two main sub-processes. The how-to articles from the eHow

Fig. 4. Steps for situation ontology construction.

and wikiHow sites are first processed with both a syntactic pattern
based method and a probabilistic method so that actions (in the
form of verbs) and associated ingredients are extracted with high
coverage, and then the results go through a sequence of refinement
steps to form an ontology. Since the eHow site has many duplicated
goals, we used the goals of the wikiHow as a basis for integrating
the two. Detailed explanations are found below.

4.1. Verb and ingredient extraction

A unique characteristic of how-to articles is that many of the
sentences in the instructions are in the form of imperative sentences starting with a base form of a verb. We found that about
56% of all the instruction step sentences in the entire data in eHow
have this form. We also found that the instructions usually start
with a practically doable action, and details are followed by the
first sentence from general to specific as in Fig. 5.

Other remaining sentences are usually an explanation of the
status like You are almost done or background knowledge like
Caffeine can interfere with sleep up to 12 hours after it is con-
sumed. Nonetheless, some non-imperative sentences can contain
instructional actions as in You should take your private transport.
In addition, the ingredient on an instruction may have a form of
noun phrase modified by a preposition phrase, but we limit the
ingredient to be only a noun phrase without a preposition phrase.
In order to detect an action (a pair of verb and associated
ingredient) from a sentence, we employ a combination of a syntactic pattern-based approach and a probabilistic approach with
conditional random fields (CRF) [14]. Each approach has its own
customized cut-off value (or threshold) to achieve high perfor-

Fig. 3. Corresponding goals between wikiHow and eHow.

Fig. 5. An example how-to article.

Fig. 6. Applying two different extraction modules.

Fig. 7. Preprocessing.

mance in recall and precision. We combined the two different
modules sequentially, applying the high-precision module first and
then more tolerant module. More detailed steps are shown in Fig. 6.
While the syntactic pattern-based approach can detect actions
and ingredients with high precision, the CRF-based method is
employed to complement rigidness of the pattern-based approach
and increase recall. Given a sentence like You should visit a hospital or Turn off the engine, applicable syntactic rules are first
searched from the rule base. If there is a matching rule, the verb
and ingredient are extracted directly. If there is no matching rule,
however, the CRF module kicks in, identifies the best matching situation model, and computes the probability. If the probability value
is greater than the threshold (T, heuristically measured T is 0.9), it
becomes a legitimate result.

4.1.1. Preprocessing

To apply an automatic extraction algorithm, we firstly apply a
set of NLP tasks as shown in Fig. 7. The first step detects sentences
from a how-to article, which are parsed with Stanford Parser5 after
an artificial subject is added to an imperative sentence as the parser
usually makes a mistake of treating the first word as the subject of
sentence. A sentence parse tree is converted into the corresponding typed dependencies by using an inherent printTree function
of TreePrint class in the Stanford Parser library6 so that we obtain

5 http://nlp.stanford.edu/software/lex-parser.shtml.
6 http://nlp.stanford.edu/software/dependencies manual.pdf.

Fig. 8. Pattern generation process.

a much higher coverage rate than using original parse tree pat-
terns. From the parsing result, meaningless adverbial phrases and
determiners are pruned to group into the same parse tree cluster.

4.1.2. Syntactic pattern-based approach

For the syntactic pattern-based method, a set of prominent
pattern rules must be generated from the instruction sentences.
We developed an unsupervised learning method based on simple
heuristics that an action verb and its ingredient item(s) occur as
a predicate in the form of a verb phrase connecting a verb and its
object(s) (e.g., find a car).

As shown in Fig. 8, a skeletal pattern is generated by replacing
every word into a slot variable. Having generated sentences with
skeletal syntactic patterns, they were sorted to collapse the same
patterns into a unique one so that we could count the frequency of
each unique pattern. Since it is too time-consuming to tag all the
generated skeletal syntactic patterns, we selected most frequently
occurring top 300 patterns among more than 14,000 patterns. An
expert annotator manually tagged the verb and the ingredient for
the patterns.

From those tagged skeletal patterns we generate two association rules respectively by recognizing a VP and its components
based on tagged information. A dependency pattern with verb and
ingredient annotations can be easily transformed into two association rules using unsupervised association rule mining method [19].
For obtaining more accurate pattern rules, we tested each pattern
with a test collection. Some pattern recorded low accuracy, so we
took only 184 patterns having higher than 85% confidence value as
final syntactic patterns.

4.1.3. Probabilistic CRF-based approach

Although the pattern-based approach achieves high-level accu-
racy, its coverage is limited to the patterns constructed manually
based on the sentences that were analyzed. Thus, there are sentences that fell through the patterns yet contain legitimate actions.
To catch them, we adopt a more lenient method  conditional random fields (CRFs) based open information extraction (OIE), named
as O-CRF [23,24]  to deal with the sentences not covered by the
association rules.

CRFs are undirected graph models used to calculate the conditional probability of values on designated output nodes given
values assigned to other designated output nodes. It allows some
transitions to vote more strongly than others in computing state
sequence probabilities. It is a general and expressive modeling
technique, considering a whole sequence rather than per-state nor-
malization. In the special case in which the output nodes of the
graphical model are linked by edges in a linear chain, CRFs make

Y. Jung et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 110124

Fig. 9. Action extraction as sequence labeling.

a first-order Markov independence assumption, and thus can be
understood as conditionally trained finite state machines (FSMs).
Fig. 9 shows an example of action extraction modeled as sequence
labeling, where the verb remove and ingredient timing belt are iden-
tified.

Assumptions and considerations in the CRF model are as fol-
lows. Let X = <x1, x2, . . ., xt> be an observed input data sequence,
such as a sequence of words in text. Furthermore, let Y be a set
of states of a finite state machine (FSM), each of which is associated with a label, l L and Y = <y1, y2, . . ., yt> be a sequence of
states. By HammersleyClifford theorem, CRF defines the conditional probability of a state sequence given an input sequence to be

PCRF(Y|X) = 1
Z0

exp

t=1

kfk(yt1, yt, X, t)

where Z0 is a normalization factor over all state sequences, fk(yt1,
yt, X, t) is an arbitrary feature function over its arguments, and k is
a learned weight for each feature function. Higher  weights make

their corresponding FSM translations more likely. CRFs define the
conditional probability of a label sequence based on total probability over the state sequences, PCRF(l|X) =
x:l(x)=1PCRF(Y|X), where
l(x) is the sequence of labels corresponding to the labels of the state
in sequences.

Once a model structure has been selected, the transition and
emission parameters need to be estimated from the training data.
We used L-BFGS, for finding a set of parameters  ={1, . . ., k} on
an exponential model which maximizes its log likelihood because
L-BFGS is a quasi-Newton method. This is significantly more efficient than the traditional iterative scaling and even conjugate
gradient [31]. In addition, a Gaussian prior over parameters was
used for smoothing as a way to cope with data sparseness (or
unseen data) in the training data.

We used the CRF implementation provided by MALLET [22], as
well as part-of-speech tagging and phrase-chunking tools available
from Stanford Parser. In addition, we used the Viterbi algorithm
which can be correspondingly modified from its HMM form to find
the most likely state sequence given the observation sequence.
A CRF model was learned with the 210 action patterns manually
tagged previously. Although we used the same 210 patterns as the
training data, the CRF model was able to cover more sentences
with reasonable accuracy. The accuracy was 95.5% when we set
the threshold (T) to 0.9 under our 10-fold cross validation.

4.2. Ontology construction

Having extracted verbs and associated ingredients from imperative sentences in how-to articles, which are descriptions of action
steps to achieve goal instances, the next step in the ontology construction process is to generate an integrated whole. It consists
of three sub-processes: Action Normalization, Goal Normalization,

Fig. 10. Action normalization.

and Action Transition Probability Calculation. At the end, we apply
a method for ingredient resolution.

4.2.1. Action normalization

This process identifies the same actions found in different articles and collapses them into a unique normalized action by using
Resolvers clustering algorithm [7], a greedy agglomerative clustering method. To compute similarity among actions, we use three
methods: a string similarity matching method that was used in the
resolvers clustering algorithm, a semantic distance using WordNet,
and an action sequence model that we propose.

We illustrate the normalization method using an example in
Fig. 10. Two similar goals have pump as the first verb in the
sequence of actions, but they have different objects brake pedal
and brake foot pedal, respectively. By applying the string similarity model [4], however, they are considered the same action. We
use the MongeElkan string similarity function for objects and the
Levenshtein string edit-distance function for relations.

Fig. 10(c) shows the lexically different cases, (jack up, car) and
(raise, vehicle), that essentially refer to the same action. This problem can be resolved with a semantic distance algorithm using
WordNet. Because WordNet contains a large number of synsets and
their relations such as synonyms, hyper/hyponyms, troponyms,
we assume that the same actions expressed in different words
are identical when they are connected by one of the relations.
For example, you can get hypernyms of a concept from WordNet using PointerUtils.getHypernymTree() function provided by
WordNet API. We used JiangConrath measure [1] to determine the
semantic distance between two concepts. However, we adopted the
measurement only when two concepts have a direct parentchild
relationship of the above types, excluding siblings.

For the case in Fig. 10(b), (take, spare tire) and (check, equip-
ments) can be seen as playing a similar role even though they are
different, since the associated goals and the two other actions are
similar, respectively. To determine two actions refer to the same
thing, we construct action clusters using the preceding and succeeding actions of a given action in an action sequence. When they
are found in the same cluster, they are assumed to refer to the same
action. The most dominant action determined by frequency is chosen from the cluster to replace the two actions. The probability that
two actions ai and aj are included in the same cluster is computed

Table 3
Result of action normalization.

Domain

# of extracted action instances

# of unique actions

# of actions after
normalization

Avg. # of unique
actions for each
normalized action

Arts & entertainment
Careers & work
Cars
Education
Fashion, style & personal care
Health
Hobbies, games & toys
Holidays & celebrations
Home & garden
Pets
Sports & fitness
Travel

Total

as follows:

2,293,156

|sim(ai1, aj1), sim(ai+1, aj+1))

P(Rt
i,j
=   sim(ai1, aj1) +  sim(ai+1, aj+1) + 1

  +  + 

where Ri,j is the random variable for the event that ai and aj are
related (i.e., refer to the same action cluster). Rt
i,j denotes the event
is true, and Rf
i,j denotes the event that it is false. The similarity
function is a combination of the string similarity model and the
WordNet distance model described above. The action sequence
model sets the probability of a1 co-referring with a2 to a smoothed
version of the similarity. The particular choice of   and  make little
difference to our results, so long as they are chosen such that the
resulting probability can never be one or zero. In our system, we
set the parameter values as follows:   = 10,  = 10 and  = 5.

We combine the three pieces of evidence and cluster the actions
with the Resolvers clustering algorithm [4]. For each potential
co-reference relationship Ri,j, there are now three pieces of probabilistic evidence. Let Es
i,j be the evidence for the string similarity
model, Ew
i,j for the action
sequence model. Making an Naive Bayes assumption that a piece
of evidence is conditionally independent among each other, we
can find the probability of a co-reference relationship by applying Bayes Rule to both sides (we omit the i, j indices for brevity):

i,j for the WordNet distance model, Ea

P(Rt|Es, Ew, Ea) =

P(Rt|Es)P(Rt|Ew)P(Rt|Ea)(1  P(Rt))
i (t,f)P(Ri|Es)P(Ri|Ew)P(Ri|Ea)(1  P(Ri))

Table 4
Result of goal normalization.

1,051,705

The clustering algorithm requires a threshold parameter to determine which scores are suitable for merging. In this paper, we chose
a threshold of 0.6 empirically, which appeared to work well for our
data.

As a result, the actions, verbs and ingredients, are clustered as
in Table 3. Each action cluster was labeled with the most frequent
expression of verb and ingredient for normalization. In other words,
a representative expression is selected for labeling their equivalence class to construct compact vocabulary. The second column
shows the number of extracted raw action instances, from which
the numbers under third column was generated by collapsing the
identical actions. The fourth column shows the number of actions
after normalization. The last column indicates how many unique
actions were reduced to a single normalized action on average.

4.2.2. Goal normalization

There exist multiple articles in eHow, which describe the action
steps for the same goal. Besides, the two resources, eHow and wikiHow have different characteristics as described in Section 3.2. In
wikiHow, the articles are refined by numerous users collaborative
work to result in articles with distinct goals. On the other hand,
each article in eHow is written independently by individual users.
While they usually provide correct action steps on their own right
to achieve the goals, two articles with the same goal often provide
somewhat different action steps. Based on these characteristics, we
decided to use the wikiHow articles as a backbone of goal classes
and eHow articles as a source of action instances to enrich goal
classes.

We first gather a set of candidate goals of each goal class, from
eHow, by using a search technique. The titles of the wikiHow arti-

Domain

# of goal classes

Avg. # of articles in goal classes

Avg. # of action instances in goal classes

Arts & entertainment
Careers & work
Cars
Education
Fashion, style & personal care
Health
Hobbies, games & toys
Holidays & celebrations
Home & garden
Pets
Sports & fitness
Travel

Total

Y. Jung et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 110124

Table 5
Number of instances in our situation ontology.

Domain

# of goal

# of action

# of object

# of time

# of location

Arts & entertainment
Careers & work
Cars
Education
Fashion, style & personal care
Health
Hobbies, games & toys
Holidays & celebrations
Home & garden
Pets
Sports & fitness
Travel

Total

cles are used as queries to retrieve the candidate goals from eHow,
among which top 20 are selected. We used Lucene7 to index and
to retrieve eHow articles. In the next step, we measure similarity between the action steps of the query and each of the retrieved
candidate goals to filter out the errors at the search stage and select
sufficiently relevant goals. We use the MongeElkan string similarity function to compare two sequences of action steps. We labeled
each goal class with the title of the wikiHow article used as the
query.

As a result, we obtained 40,976 goal classes from the whole
dataset (12 domains) as in Table 4. An average of 3.92 articles was
mapped to a goal class. We evaluated precision of the classification result with a random sample of 100 goals and obtained 97% of
sample goals that were classified into proper goal classes.

4.2.3. Action transition probability calculation

Assuming that a goal can be achieved by a set of action
sequences, there should be a temporal order among actions in
general. Such orders can be expressed with hasNextAction and
hasPreviousAction (inverse of the hasNextAction) in our situation
ontology. In the action normalization process, action sequences
appearing in different articles are collapsed into one. That is, a normalized action sequence can have a weight that corresponds to the
number of times it appeared before normalization, which indicates
the strength of the occurrence of next/previous actions. We count
the number of times an action occurs in the entire database and
convert it into a probability value. The probability of hasNextAction
between a pair of normalized actions, for a given goal G is calculated
as follows:

W G

Ai,Aj

isNextStep(aa, ab|g)

G  g

Ai

 aa

 ab

Aj

P(hasNextAction(Ai, Aj)|G) =

All actions in G

W G
i,j

ak

W G
i,k

where isNextStep() is a binary function whose value is 1 when
there is an event that a unnormalized action ab occurs after another
unnormalized action aa within a particular goal in a given normalized goal G. Otherwise, its value is 0. W G
is an weight
within a normalized action sequence calculated by summing up
isNextStep(). The probability of hasNextAction is calculated by normalizing W G
with the sum of the weights of the all possible next
actions within a given normalized goal G. The probability of hasPreviousAction is calculated in a similar way. A normalized action stays

Ai,Aj

Ai,Aj

in the ontology if the probability is above a threshold value, which
is empirically set to 0.2.

4.2.4. Ingredient resolution

To excavate relevant entities that can be connected to
actions with hasLocation and hasTime, we employ three different
strategies: rule-based, dictionary-based, and NER (named entity
recognition)-based extractions. First, we extract ingredient items
from preposition phrases and adverbial phrases in action sen-
tences. The rule-based extraction method deals mostly with date
and time information such as on June 5th, at five thirty, and
yyyy/mm/dd. Second, to detect these patterns and extract time
and place information, we constructed rules in regular expres-
sions. The second method is to use time and location terms in
a dictionary, such as Sunday and morning, which were collected by exploring the hyponyms of time and location classes
like clock time and time period of WordNet. Location classes
include location, structure, way, and land. Third, the NERbased extraction method identifies the ingredient items by means
of a named entity tagger. We employed a Java-implemented NER
tagger [2] based on Conditional Random Field. The tagger is trained
with Web-augmented lexicons using a technique called WebListing whose result can be replaced with GoogleSets.8 By employing
this tagger, we were able to recognize named organization, loca-
tion, time, date such as Hawaii, Montana Avenue, Sports Day
and their semantic classes.

5. Evaluation

In order to validate our effort for automatically constructing a
situation ontology, we first show the statistics of the result and
discuss about the experiment we ran for extraction accuracy and
its result for both the syntactic pattern-based and the CRF-based
methods. To put the result in perspective, we compare the coverage of the resulting situation ontology with other ontology-like
resources, WordNet and OMICS, in terms of actions covered.

5.1. Overall statistics and accuracy

Table 5 shows the statics for the numbers of goals, actions,
objects, time items, and locations in the automatically constructed
situation ontology. The last line shows the total across all the 12
domains. On average, about ten actions and three objects were
identified for a goal whereas the numbers of time items and location items for an action are only slightly greater than 1.1 and 1.9,
respectively. As expected, the average numbers of instances per

7 http://lucene.apache.org.

8 http://labs.google.com/sets.

Table 6
Accuracy of the extraction methods.

Domain

# of all sentences # of imperative sentences # processed by patterns Accuracy of patterns # processed by CRF Accuracy of CRF

Arts & entertainment
Careers & work
Cars
Education
Fashion, style & personal care
Health
Hobbies, games & toys
Holidays & celebrations
Home & garden
Pets
Sports & fitness
Travel

Total

5,657,541

3,214,438

1,785,940

94%
93%
97%
95%
96%
94%
96%
96%
97%
95%
96%
94%

95%

3,177,915

81%
79%
94%
84%
85%
82%
89%
87%
87%
82%
83%
80%

84%

goal for different ingredient items and actions differ from domain to
domain with the ranges of 0.126.9 (ingredient items) and 6.329.7
(actions), respectively It is interesting to note, for example, that the
average number of location items for the travel domain is exceedingly high (greater than 26) compared to other the other domains.
Table 6 shows accuracy for each of the two methods: the
syntactic pattern-based method and the CRF-based method. A production rate indicates the percentage of sentences handled by one
of the methods whereas accuracy measures the ratio of accurately
extracted actions and ingredients over all those extracted. Accuracy was measured based on a random sample of 100 sentences.
The syntactic pattern-based method gave 55.6% production rate
and 95% accuracy since it is a rather conservative approach. On the
other hand, the CRF method gave a very high production rate of
98.9% and decent accuracy of 84%.

The two methods were combined to produce the final result as
in Table 7. We applied the pattern-based method first because it is
more precision-oriented and the CRF-based method for those sentences not processed by the first method. We varied the threshold
T to obtain different pairs of values. It should be noted that a weight
in MALLET was adjusted with a pilot experiment to obtain the high
recall and reasonable precision values for the CRF-based method
before the combination was performed although higher precision
could have been obtained at the expense of rapidly dropping recall
values.

5.2. Coverage

Since the wide coverage is an important feature of the situation
ontology we constructed, we compared its coverage with those of
other ontology-like resources: WordNet and OMICS. We analyzed
OMICS data [27] because its goal and nature are partially similar
to those of the situation ontology. While OMICS contains different
types of knowledge, such as uses, causes, desires, locations, prox-
imity, paraphrase, etc., it contains several hundreds of tasks and
associated actions expressed as imperative sentences for indoor
home services. A task description, like making coffee or answering the phone, captures the steps required to accomplish its task,
and each step contains a verb and objects. That is, it follows the
form of how-to steps, except for its conciseness. We applied the
same action mining method described in Section 4.1 to the OMICS
data set. For our ontology, the raw verbs extracted before action
normalization were used.

Table 7
Performance of the combined method with different threshold values.

Domain

T = 0.90

T = 0.92

T = 0.94

T = 0.96

T = 0.98

Production rate
Accuracy rate

75.14%
95.5%

71.34%
96.0%

65.66%
96.5%

58.73%
96.0%

55.63%
97.0%

It would be an over-generalization to just compare two ontologies in terms of the size and coverage because ontologies differ
in their structure, entity types, axioms, relation types, domains,
quality, etc. However, such comparisons give an idea about how
extensive the situation ontology is. As in Table 8, the actions in our
situation ontology cover 55% of all the verbs and 77% of all the root
verbs in WordNet. Given that a large proportion of English verbs
are state verbs and that rarely occurring verbs are not often used
to represent real-life actions in daily lives, the coverage is considered very high. In comparison with the verbs covered by OMICS,
our ontology has significantly higher coverage (55% vs. 11%). At the
same time, 93% of the OMICS verbs are covered by the situation
ontology. The Home & Garden domain has the highest coverage
(84%, which is tied with the Health domain) of the OMICS verbs
since it is the closest to the domain of OMICS. However, the coverage of other domains is also high. This indicates that the same
set of action verbs are used across different domains. The last column shows the coverage in terms of root verbs in WordNet. This
was computed by using a function9 available in WordNet, which
converts a verb to one of 294 verbs at the top level.

5.3. Discussion

We have shown that the methodology described in this paper
has generated a large-scale situation ontology of moderate qual-
ity. With a growing number of sites that collect valuable data from
user participations, it is important to be able to extract ontological knowledge in an automatic way to the extent that the result is
usable and the process is efficient. This kind of efforts is in line with
the web 2.0 idea that encourages user participations and allows for
ambiguities and uncertainties of the data. While carefully handcrafted ontologies are more amenable for formal reasoning and
systems requiring high precision results, large-scale ontologies that
are less formal would be valuable for domain-independent applications requiring common sense and situation-awareness.

Nonetheless, our work has some limitations that should be
addressed. Most notably, the situation ontology is not designed to
be linked with formal ontologies described in a language like OWLS
or RDFS. While the format can be changed without much difficulty,
it does not represent knowledge formally. The actions and ingredient items have been neither disambiguated nor linked to real
concepts (e.g., there is no URI). While the current version can be
utilized for a variety of applications involving daily activities that
tolerate inexactness and impreciseness like recommendation ser-
vices, the ontology would serve as glue to many existing ontologies
when it can be expressed more formally.

9 PointerUtils.getHypernymTree().getRootNode(): JWNL, WordNet Java API.

Y. Jung et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 110124

Table 8
Action coverage.

Domain

WordNet 2.1
OMICS (indoor domain)

eHowTo + wikiHow (12 domains)

Arts & entertainment
Careers & work
Cars
Education
Fashion, style & personal care
Health
Hobbies, games & toys
Holidays & celebrations
Home & garden
Pets
Sports & fitness
Travel

#WordNet verbs covered

#OMICS verbs covered

WordNet root verbs covered

6321 ()
694 (11%)

3499 (55%)
1909 (30%)
1485 (23%)
1242 (20%)
1459 (23%)
1611 (25%)
1957 (31%)
2105 (33%)
1497 (24%)
2062 (33%)
1513 (24%)
1889 (30%)
1536 (24%)

694 (100%)
694 ()

645 (93%)
566 (82%)
526 (76%)
496 (71%)
526 (76%)
530 (76%)
585 (84%)
584 (84%)
527 (76%)
585 (84%)
533 (77%)
567 (82%)
524 (76%)

294 ()
122 (41%)

226 (77%)
176 (60%)
170 (58%)
146 (50%)
168 (57%)
153 (52%)
181 (62%)
175 (60%)
153 (52%)
170 (58%)
155 (53%)
177 (60%)
163 (55%)

While we achieved a moderate level of accuracy with the combination of the syntactic pattern-based and CRF-based methods for
action and ingredient mining, there is a room for further improve-
ments. Other types of machine learning techniques should be
investigated for increased efficiency and accuracy. Furthermore, we
need to consider some linguistic constructs like preposition phrases
that were ignored in the current result. This will lead to a richer
representation of situation knowledge.

This paper introduces a new method and result for using the web
resources that contain valuable knowledge in daily lives. The ontology can and should be expanded to include additional situations,
goals, and associated actions and ingredients as the two resources
we used are expanding everyday to accumulate more and more
knowledge. While the method we used for the how-to knowledge
is specialized for the sub-language, it can be further extended to
cover more general descriptions of how-to knowledge in web pages
and blog posts. The difficulty of handling less constrained language
can be reduced with the use of the situation ontology that has been
constructed already.

6. Applications

To demonstrate the applicability of the situation ontology, we
introduce two application scenarios where it can play a key role:
situation-aware service recommendation and semantic web service composition. In the first application, the system attempts to
infer users current situation through identification of the goal that
can be revealed by contextual information including users cur-

rent location, actions taken, and objects used for the actions. Since
the ontology currently contains about 160,000 situation instances
(40,976 goals 3.92 articles per goal on average) across 12 topic
categories of daily lives, this functionality of situation prediction
followed by providing a recommendation for a problematic situation is not limited to a small domain. The wide coverage and utility
make it possible to eliminate or minimize much of the effort to
handcraft domain-specific ontologies or knowledge bases. In the
second application, we describe how our situation ontology can be
employed in composing a sequence of semantic Web services for
required functionality. Availability of the situation ontology makes
it possible to compose semantic web services comprising Input,
Output, Precondition, and Effect (IOPE) even when the last two
elements, Precondition and Effect, are not available.

6.1. Situation-aware service recommendation

We can identify the goal of a user from the context by looking up the situation ontology. In other words, the actions taken by
the user are mapped to the situation ontology to identify the associated goal. Fig. 11 shows the overall flow of the processes in the
situation-aware service recommendation system. Given a situation
query out of the current context, Situation Predictor consults the
situation ontology to generate possible situations. Obtaining the
user feedback, i.e., a selected item, Service Recommender provides
a list of services by looking up the Service Pool database. The right
side of the figure shows the result after executing each step.

Fig. 11. Service recommendation flow.

Table 9
Overall results for the five situations.

No.

Description

Location

Airport

Youve arrived at J.F.K.
International Airport while on
a business trip.
Highway

You are driving a car on a
highway. Suddenly one tire is
blown out.
Railroad
station

You are on a business trip to
Busan. You are now arriving at
the Busan Railroad Station.
Beach

You are enjoying your vacation
on Haeundae Beach. You have
sunburn while tanning.
Hotel

You sleep in a resort hotel. The
fire alarm is waking you up.

Context
ingredients

Ticket, departure
board

Most frequently
selected situations

Make airport
check-in fast and
safe

Spare tire, trunk

Change a flat tire

Ticket, luggage

Book train travel

Most frequently
selected services

ATM, bus station

AAA (American
Automobile
Association)

Ticket vending
machine, waiting
room

Swim-suit, sun
block

Enjoy vacation at
beach

First-aid

Emergency exit,
fire extinguisher

Be safe from fire

Situation Query. A situation query is constructed based on the
behavioral context detected by several sensors in the ubiquitous
environment. We assume that the context variables are identified
from the real situation, so that they are used as an input to the
situation predictor. For example, we present location, place and
schedule information as behavioral context. Fig. 11(a) shows a situation query built with a users context.

Situation Predictor. The main function of Situation Predictor (SP)
is to find a likely situation from the situation ontology. Given an
input situation query, SP retrieves matching goals that are deemed
potentially pertinent situations for the user. In essence, SP maps
indicative actions and user context to the goals in the case base by
retrieving relevant cases with the case-based retrieval method [29].
Relevance is computed using the weighted Euclidian distance as in
the Pythagoras theorem in n dimensions. While there is usually one
situation that is pertinent to the real situation, others may provide
an opportunity to discover a serendipitous service that would take
some effort to find by going through the service pool. For the implementation of the situation predictor, has Action, hasGoal, hasObject,
hasLocation, and hasTime in the situation ontology are used.

Given the predictions ranked by the system, the user has an
option to select a situation that best suits the users context and
preference as in Fig. 11(b) where the part in bold type is the one
selected. While the situation case base is general-purpose and its
size is large, it is by no means complete. In addition, the situation query may not be sufficient to rank the correct situation at
the top. This is the reason why the system accepts a user feedback
for the most relevant situation. The correct situation, confirmed by
the user, is stored together with the context variables for future
decisions.

Service Recommender. The Service Recommender module plays
the role of finding useful services among those provided by Service
Provider based on the subordinate actions/ingredients of the predicted situations. The services are chosen based on the process of
matching the ingredient items and the actions against the service
descriptions. It is conceivable that this matching can be done more

accurately when there is a separate service ontology where service
capability descriptions are available. The situation ontology plays
a useful role in reducing uncertainties when the system attempts
to understand the user context with insufficient senor data and
infer appropriate services required in the context. This inference
made possible by the situation ontology can provide opportunistic
services.

Fig. 11(c) shows the list of recommended services where the
numbers in parentheses correspond to situation ids in the predicted
situation list. The left side of the table represents the list of recommended services before the user selects a particular situation
title. The various services associated with the predicted situation
are recommended. Even when the user does not see a service that
perfectly fits the users real situation, s/he can select the most suitable situation title that can reduce the search space of the service
pool. Upon selecting a situation title (e.g., Use the Airtrain), the list
of recommended services are automatically changed to the services
corresponding to the selected situation.

6.1.1. Prototype

To evaluate the performance of situation-aware service recom-
mendation, we designed an experiment with the implemented
prototype and five different simulated contexts in a variety of
domains. The five situations were chosen among frequently happening human activities of daily living. In our prototype, a situation
query generated automatically from the recognition of the current
context looks up the situation ontology. We implemented Situation
Predictor using Lucene, a search engine library,10 which enables
indexing and retrieval of text elements using well-known information retrieval algorithms. We used the default settings of Lucene,
while separating indexing fields as Goal, Action, and Ingredient.
Upon recognition of a matching situation, possible actions are identified and services can be recommended.

10 Apache Lucene: http://lucene.apache.org.

Y. Jung et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 110124

Fig. 12. Recommended services relevance for each situation.

6.1.2. Settings for evaluation

We built a simulated testing environment on top of the prototype by showing five real photos describing different situation (or
scenes) to a group of evaluators, consisting of 20 graduate students.
For each scene, they were asked to select an appropriate goal they
would want to achieve in that situation among those retrieved from
the situation ontology. For a selected goal, a service was manually
selected by each evaluator from the how-to articles corresponding
to the given situation. This resulted in five possibly different <goal,
service> pairs to be compared against the systems choice. In other
words, the systems choice was supposed to be compared against
each of the 20 human-selected answers for a given situation. Table 9
shows the most frequent choice of services and the most frequently
chosen situation label for each set of contexts with its description.
More precisely, once the simulated environment was set up
for five different contexts (scenes), each participant was asked to
choose a goal that would arise as well as a service that would satisfy
him/her among the alternatives the system provides. For the airport context, for example, a participant would choose Check-in at
an airport as his/her goal among several possible goals retrieved
from the context information. Then he/she selected airline ticket
among a list of services like ATM, bank, Airtrain, and bus station
that represent a set of possible services. The system predicted the
situation and recommendation based on the simulated user context information (sensed user actions, location, time, special user
preference detected, etc.).

6.1.3. Evaluation and discussion

The performance of service recommendations was judged for
relevance and newness by the participants as in Fig. 12. The
participants were asked to assess a recommendation as rele-
vant/irrelevant and expected/unexpected. When Arrived at JFK
Airport was selected as the situation, for example, AirTrain was
considered as an unexpected service. The graphs on the left side
show the results of service recommendations without user feed-
back. Of the service recommendations for all the situations, 18% was
irrelevant on average. The rest were considered relevant services.
About 46.4% of recommended services were relevant and new.

The graphs on the right are the results of service recommendations after applying user feedback. Only 3.3% was irrelevant,
which happened in a single situation (i.e., situation 5). About 47.5%
of recommended services were relevant and new. The difference

between the two cases, with and without user feedback, lies in
the change in the proportion of the relevant & already known recommendations as well as in the decrease of irrelevant ones. User
feedback not only ensures the recommendations are relevant but
also tend to recommend the services that meet the user expecta-
tions.

The experimental result implies that the situation ontology is
useful in detecting the situations correctly in that only a small
proportion of the recommendations are irrelevant. This is particularly valuable and encouraging because relatively simple context
information was used under a simple user situation model without
resorting to complex rule-based reasoning. The user feedback case
indicates that the situation ontology rarely makes the system fail
in making recommendations since at least one of the recommendations is relevant in most cases.

Compared to other work on context-aware situation detection
and service recommendations, our approach is unique with the
sheer size and scale of the situation case base. It provides a substantial ground knowledge base that serves as a user situation model
without prior learning or rule generation. Better yet, the user situation case base can evolve with user feedback so as to improve the
recommendation quality in a personalized manner.

6.2. Assisting automatic web service compositions

There is a growing need for automatic service compositions as
the number of web services increases and users requests for new
services diversify [8]. Our situation ontology can be adopted to help
building composite web services that support high-level business
processes over and above what web service recommendations can
do. Because automatic web service composition is still a challenging
area, we here only discuss possible uses of our situation ontology in
terms of automatic web service compositions without experiments.
A recently introduced approach to automatic composition of
web services is to use a domain ontology and semantic descriptions of services using service description languages such as OWL-S
[33], WSMO [38], and SAWSDL [32]. In a semantic description, a
users request is represented by means of specifications of Inputs,
Outputs, Preconditions and Effects (IOPE), which are the basis for
automatic composition of web services [16]. Considering that two
services with identical IOPEs are functionally identical, a composite
web service satisfying the IOPE of a user request can be chosen. This

Fig. 13. Service composition using the situation ontology.

method may fail in generating composite web services that suit the
user intention, however, when services or user requests do not have
a complete specification, for example, with missing pre-conditions
and effects. To overcome this drawback of the approach, a web service composition work based on a hierarchical task network (HTN)
[11] considered functional semantics of services. However, it is
almost impossible to find out the functionality of every service and
the composition or decomposition relations between whole ser-
vices. The work in [8] used the functional semantics of a service,
which define what a service actually does that is represented by a
pair of its action and the object of the action.

The functionality semantics is congruent with actions in our situation ontology in that the latter specifies actions to be taken to
accomplish a goal. In addition to the availability goals and actions
that can be converted into functional semantics, the wide coverage
of our situation ontology can provide an added benefit especially
when a service has to be specified with multiple operations for its
multiple functionalities as is the case in general.

More specifically, our situation ontology can provide the follow-

ing benefits to semantic service compositions:

(1) Given a goal to be achieved by service composition (e.g., Enjoy
a vacation in Scandinavia in Fig. 13), actions to be taken to
achieve the goal can be obtained from the situation ontology.
These actions can be converted into functions to be executed
in the composed service, which can be searched in the service
registry. However, if those services need to be in the form of
RESTful [30] APIs or SOAP [34] APIs, they should be registered
with the input, output, and functionality.

(2) In an ad hoc environment where the users goal may change
frequently, new goals can be identified easily by just mapping
user actions to the situation ontology to provide flexibility in
detecting goal transitions.

(3) The situation ontology can be used to check completeness of a
semantic web service repository and make a recommendation
for what should be developed further. This is possible because
the ontology contains a wide variety of goals and step-by-step

actions to accomplish the goals. Each situation instance in the
ontology can be seen as an abstract workflow that both humans
and programs can use for the purpose.

7. Conclusion and future work

We presented an automatic approach to constructing a largescale situation ontology by means of action mining from the web
resources. Especially, in order to aggregate situation knowledge
from evolving web resources, such as eHow.com and wikiHow.com,
we have defined a situation ontology model consisting of user goals,
action sequences, and their context information such as objects,
locations, and times, all of which are derived from the how-to
instructions in natural language.

The ontology construction method consists of the two major
steps: verb & ingredient extractions and instance normalizations
for goals, actions, and ingredients (locations, objects, and times).
We devised a method based on syntactic patterns and CRFs, which
were applied sequentially, for the first step and goal and action
normalizations for the second, resulting in more than 30,000 goals
across twelve topic categories, 317,000 actions and 89,400 objects.
A sampled evaluation shows 95.5% accuracy.

We believe that the wide coverage and fine-granularity of the
situation ontology will help accelerating research and development
in real-life situation-aware applications. To show the feasibility,
we included two system scenarios: situation-aware service recommendation and automatic web service composition. We are
confident that our attempt and result help reducing brittleness
of intelligent systems in an open domain by providing domainsensitive situation-awareness. When the current work is extended
further for experience mining from blogs, for which the situation
ontology will play a critical role, we will be one step closer to seamless context-aware services.

One of the issues related to this work is how often the ontology has to be updated as the data published on Web 2.0 platforms
undergo frequent alterations and updates (i.e., Wikipedia pages).
The changes are necessary to meet a communitys consensus and

Y. Jung et al. / Web Semantics: Science, Services and Agents on the World Wide Web 8 (2010) 110124

improve the quality. In order for an automatically built ontology to
evolve, it would be best to include a link to the original source or
information pertaining to its vital data (e.g., the recording of who
created the how-to, the date and time the data was extracted, etc.).
This kind of provenance information would serve as a clue for the
update intervals and benefit an end system in making the ontology
up-to-date and the end user in deciding what to trust. However,
the lack of such provenance information with the two resources,
unlike Wikipedia, makes it difficult to come up with an update policy although the number of new articles can be a good clue to make
such a decision. A careful examination of this issue is left for future
work.

Acknowledgements

Support for this research came from the Ministry of Knowledge Economy, Korea, under the Information Technology Research
Center support program supervised by the National IT Industry Promotion Agency; NIPA-2009-(C1090-0903-0008). Financial support
for this work also came from a grant from the strategic technology
development program 2008-F-047-02 of the Ministry of Knowledge Economy.
