Towards a Commercial Adoption of Linked Open Data for

Online Content Providers

Wolfgang Halb


Alexander Stocker

Harald Mayer

Helmut Mulner

Ilir Ademi

JOANNEUM RESEARCH

Institute of Information Systems

Graz, Austria

firstname.lastname@joanneum.at

ABSTRACT
Descriptive case studies for a successful commercial adoption of Linked Data are still rare. Little has been said by
the Linked Data community concerning the business potential of Linked Data and the challenges lying ahead for all
enterprises, intending to use Linked Data in their professional production environments. Motivated from this lack
of research and driven by the requirements of commercial
content providers, we present a first version of our proto-
type, aiming to support professional online editors in producing valuable online content, enriched with (multimedia)
information from Linked Data sources. We also include a
preliminary evaluation of our prototype and a comparison
of the prototype against other systems for semantic content
enrichement. Though presenting ongoing research, this paper contributes to the current discussion on business aspects
related to the provision or consumption of Linked Data.

Categories and Subject Descriptors
H.4.m [Information Systems]: Miscellaneous

General Terms
Design, Theory, Economics, Performance

Keywords
Linked Data, commercial adoption, business aspects

1.

INTRODUCTION AND MOTIVATION

This section provides a short introduction into the online
content industry and motivates the needs of online editors

Alexander Stocker also works for Know-Center,

Inf-

feldgasse 21a, Graz, Austria

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
I-SEMANTICS 2010, September 1-3, 2010 Graz, Austria
Copyright 2010 ACM 978-1-4503-0014-8/10/09 ...$10.00.

for a new technology supporting their online editorial pro-
cess.

The current business model of commercial content pro-
viders, e.g. online newspapers, is comparatively transpar-
ent: Content providers aim to produce useful contents, publish these contents on their portals and indirectly monetize
them by serving advertisements. Hence, revenues of online
providers largely depend on the number of users consuming online content (their reach) and indirectly also on their
session length. The two most common advertising pricing
models are the cost per impression (CPI) and the cost per
click (CPC) model. Advertisements are either served directly by the content provider or by third party services.
For a more detailed discussion on business models, cf. e.g.
[12] or [14].

Valuable online content, which is suitable for monetarization through advertisement,
is in practice created by
a specialist, the online editor. An online editor usually
investigates upcoming topics, aggregates (online) content
from various sources, including user generated content taken
from blogs, or professional content from press agencies, and
merges all these small junks together shaping a fascinating
story, capable of drawing the attention of the user. Needless to say, online editors require a good nose for how to
create such content, which is preferably consumed by people on the Web. Unlike any other role in the online content
industry, professional online editors depend and rely more
on Web technology. Research has shown that people on the
web are rather scanning content than reading everything in
detail which is contradictory to readers of classical newspapers [7]. Though, very little is known about the needs of
people regarding nature, structure and presentation of online content, and we may just imagine, what differs good
online content from bad.
In practice, the amount of revenue generated from advertisements may serve as indicator,
determining quality and appropriateness of online content.
Human resources are always scarce, which implies that
they have to be utilized efficiently and effectively. From
talks with commercial online content providers we learned
that professional online editors spend most of their time investigating interesting and suitable material, which may enrich their editorial content to become more fascinating and
valuable to their audience and/or enables them to produce
editorial content quicker, enriched with multimedia objects


third party content will play an important role. Accurately
considering these aspects may increase the attention of existing content consumers, keeping them on site for a longer
period as well as attracting new consumers, positively affecting the amount of revenues gained from ads embedded
in the content. Anyway, to prove these hypotheses is not
the goal of our current paper.

Our research problem may be outlined as follows: Professional online editors are facing at least two business chal-
lenges:

 They need to be very efficient in their core business,
i.e. developing their editorial content and getting it
published instantly on the Web.

 They have to produce up to date (multimedia) con-
tent, particularly capable of drawing the attention of
humans.

We investigated current Web technology, foremost Linked
Data, to support online editors in creating professional online content. The next section takes a detailed look into
our approach discussing the potentials of Linked Data for
business and transforming them to our specific situation.

2. TOWARDS A TECHNOLOGY-ORIENTED

SOLUTION

In this section we will motivate Linked Data as a proper
technology-oriented solution for business, capable of dealing
with both introduced challenges. As a subtopic of the Semantic Web, Linked Data, based on four simple rules, has
gained much attention in research. In a nutshell, the vision
of the Linked Data community is to first facilitate the generation of semantically enriched Data (Linked Data) and as a
result of this data-supply others will come and build intelligent applications on top of it. Such a strategy is supposed to
be a very pragmatic solution for the well-known chicken-egg
problem of the Semantic Web.

We find that as a current Semantic Web technology, Linked
Data is capable of generating benefits in at least three different business scenarios:

1. Enterprises may adopt Linked Data to interlink their
increasing its accessibility for humans

own content,
and machines.

2. Enterprises may adopt Linked Data to integrate third
party content into their own portals, as the Web may
know more than they do.

3. Enterprises may adopt Linked Data to prepare their
own content for third party adoption, enhancing its
reusability and visibility.

These three general benefits will especially affect commercial content providers, as they are dealing with huge amounts
of data usually stored in data silos. A data store is called a
data silo if it is so tightly dependent on a specific environment that it is impossible to reciprocally use and share information with other information management systems within
or across organizational boundaries (cf. [8]). The so-called
silo effect is also currently popular in the business and
organizational communities to describe a lack of communication and common goals between departments in an or-
ganization. Experts agree that these silos (whether on an

organizational or information technology level) greatly reduce efficiency and should be reduced, whereas cooperation
should instead be fostered wherever possible (cf. [3]).

As a result of this siloing, content providers usually find
themselves again in at least one of the following scenarios:

1. They may operate more than one content portal, facing
the need to better integrate and interlink their data
to achieve better accessibility, i.e. to allow enhanced
search and retrieval across portals.

2. They may want to integrate third party data to enrich their own editorial content with open structured
data, choose open - instead of licensed - content to
reduce costs, and develop valuable intelligent applications based on open data.

3. They may provide their own content to be used by
third parties, thereby achieving a significant increase
in visibility and reach, raising the general reusability of
their own content, and leading to third party adoption
coming along with search-engine related benefits.

Figure 1 depicts how online content providers may use Linked
(Open) Data and benefit from it.

Figure 1: Three scenarios for the use of Linked Data.

From this it follows that adopting Linked Data may definitively result in a paradigm shift for the professional editing
business: Online editors may benefit much from Linked Data
as this new technology will enable them to perform better
and to create more valuable content. Specifically, Linked
Data delivers the following benefits to online editors:

 With Linked Data it is easy to integrate own or third
party data to generate appropriate and up-to-date content on the one hand, and

 there is already a plethora of different Linked Data
sources available, that provides information ranging
from geographical to statistical data which is ready
for integration.

Whenever an enterprise is dealing with Linked data, the
question arises, whether Linked Data has more value to the
human end user, than ordinary data. The Linked Data
Value Chain as pictured in Figure 2 provides a lightweight

123Data providerData consumerEnterprise(Portal)Benefit for EnterpriseIncreased visibility of own content Increased reusability of own content due to consistent data structureSearch Engine OptimizationEnterprise(Portal)Enterprise(Portal 1)Enriching own content with open structured dataUtilizing free data instead of fee-based dataDevelop intelligent application based on open dataEnterprise(Portal X)Increase accessability of own contentAllow structured exchange of data between isolated portalsAllow search and retrieval across different domainsact as Raw Data Providers. Mentionable exceptions are the
BBC [9] and the New York Times [10]. Linked Data technology will enable enterprises to act as Linked Data Providers,
providing Linked Data for third parties, and to act as Linked
Data Application providers, consuming data from third parties and providing more valuable Human-Readable-Data on
top of it for the human enduser.

Based on the illustrated initial situation of commercial
content providers, the current business challenges of online
editors and the concept of the Linked Data Value Chain,
we developed a first prototype, serving professional content
providers.

3. PROTOTYPE

Motivated by the findings stated in Section 2 a prototype
has been developed that is intended to support editors at
online content providers but can also be used as a generalpurpose tool in other domains. It enriches editorial content
with further information from Linked Data sources and also
generates a Linked Data version of the editorial content. A
distinguishing feature of the tool is that it supports multilingual content which poses additional challenges in the
context of the Web of Data where English is still the predominant language. Currently the prototype is being tested
at a cooperating content provider.
3.1 Use Case

The primary use case of the developed prototype is to
support the editorial process at online content providers.
In order to meet the needs of the industry we collaborated
closely with one of the major content providers in Austria.
The tool can be integrated in a providers content management system and while an editor creates an article, the text
is analyzed for interesting terms and the tool automatically
suggests further information from the Web of Data. This
includes data from various Linked Data sources such as textual content, links, images, or video. The editor instantaneously receives additional information about the article she
is writing and can then decide which external content should
be included in the article. This manual decision step has
been introduced following feedback from editors and content providers as they prefer to have more control over the
published content. It further allows to improve content suggestions based on previous selections and preferences. As an
added benefit the final article is enriched with more exciting content and provides the reader with further information
without having to leave the providers pages. This increases
the attractiveness of the content provider with further potential positive effects on visit durations, returning users, as
well as page and ad impressions leading to higher ad revenues for the content provider.
3.2 Modules

The tool consists of three different modules that work
together as a unified solution that can be integrated into
an existing content management system as a service or can
be used as a stand-alone web application. The term extraction and classification module identifies interesting and
relevant terms which act as an input for the Linked Data
consumption & interlinking module where additional information from Linked Data sources is collected. The Linked
Data Provision module makes the discovered information
available as Linked Data to the public.

Figure 2: The Linked Data Value Chain [11]

model, to conceptualize the business perspective of Linked
Data and to make the value adding process to the data trans-
parent.

The Linked Data Value chain [11] comprises three different concepts, Participating Entities, Linked Data Roles,
and Types of Data. Participating entities are persons, enter-
prises, associations, and research institutes owning at least
one of the following roles:

 Raw Data Providers provide any kind of data.
 Linked Data Providers provide any kind of data in a
Linked Data format. They consume Raw Data provided by Raw Data Providers and transform it into
Linked Data.

 Linked Data Application Providers provide Linked Data
Applications. They consume Linked Data provided by
Linked Data Providers, process it within their applications and transform it into Human-Readable-Data.
 End users are humans who (like to) consume Human-
Readable-Data, which is a human-readable presentation of Linked Data provided by Linked Data Application Providers.

The Linked Data Value Chain distinguishes between three
types of Data, Raw Data, Linked Data und Human Readable Data. According to this concept, the value of the data
increases with every data transformation step and human
readable data has the highest value for the human enduser.
 Raw Data is any kind of structured or unstructured
data that has not yet been converted into Linked Data
 Linked Data is any data in a Resource Description
Framework (RDF)1 format interlinked with other RDF
data.

 Human-Readable-Data is any kind of data which is

prepared for the consumption of humans.

With respect to the introduced Linked Data Value Chain,
online content providers currently and almost exclusively

1http://www.w3.org/RDF/


The term extraction and classification module that has
been developed is targeted at German-language content as
the cooperating content provider produces the majority of
its content in German. Even though there exist several term
extraction solutions for the English language (which can also
be plugged in and used in the prototype) there is still a
lack of well-performing, generally available tools for German.
Through its modular structure the prototype can support
term extraction solutions for any language that are available
from third-party providers.

In the current stage the term extraction and classification

module combines the following approaches:

 Blacklist: All terms and possible word formations
that occur in a general dictionary are removed from
the text. As a result this step delivers interesting
words such as names, toponyms, and domain-specific
terms. All possible morphological formations have to
be considered and compounds are also a special challenge in the German language that may lead to false
positives and negatives. A detailed discussion of the
approach is out of scope of this paper.

 Whitelist: Further a whitelist with relevant terms
from Linked Data sources is applied, with the most
important datasets being DBpedia2 and GeoNames3
for general news articles.

 Rules: With a rule-based approach also person and
company names are identified (e.g. first name followed
by noun  person name).

3.2.2 Linked Data consumption & interlinking
The Linked Data consumption & interlinking module retrieves additional information about the identified terms and
creates interlinks to Linked Data sources. Disambiguation
between different concepts that share the same label is one
of the biggest challenges. The term Obama can for instance refer to the American president, his wife, or a city in
Japan.

The general workflow of the module starts with a search
for potentially relevant information in external data sources.
In the first phase this is done via a query to DBpedia and
GeoNames, two datasets that already contain a lot of general
knowledge and geographic information. Even though the
use of further datasets is easily possible, this first step aims
at identifying relevant concepts for the found terms where
these two Linked Data hubs already provide sufficient information for general news articles. The query is based on the
extracted term and takes the original documents language
into account as well as textual similarity measures.

In many cases it is not possible to find only one distinct
concept but rather many potential matches are found and
thus disambiguation needs to be done. In the current use
case there is almost no information about the term available directly as it is simply part of a news article. The
information about the category of the article (e.g. politics,
local news, etc.) can aid in narrowing potential concepts
though. Subsequently this implies that link discovery and
resolution approaches that have been proposed for Linked

2http://dbpedia.org/About
3http://www.geonames.org/

1 < body about = " http :// test . j o a n n e u m . at / news / xyz " >
2 < h1 p r o p e r t y = " dc : title " > Von Graz aus ... </ h1 >
3 ...
4 < div r e s o u r c e =

" http :// dbpedia . org / r e s o u r c e / Larnaca "
rel = " dcterms : r e l a t i o n " >
5 < span p r o p e r t y = " rdfs : label "

xml : lang = " de " > Larnaka </ span >
6 < span p r o p e r t y = " dbpprop : a b s t r a c t "

xml : lang = " de " > Larnaka , auch Larnaca ,
g r i e c h i s c h Larnaka ... </ span >

7 ...
8 </ div >
9 < div

r e s o u r c e = " http :// sws . g e o n a m e s . org / 1 4 6 4 0 0 / "
rel = " dcterms : r e l a t i o n " >

10 ...
11 </ div >

Listing 1: RDFa snippets of an exemplary Linked
Data output

Data sources such as SILK [17], the Co-reference Resolution
System (CRS) [5], KnoFuss [13], or LD-Mapper [16] cannot
be used in this context. These approaches rely on further
information about a resource that can be compared in two
different datasets, i.e. there needs to be some overlap between the source and target datasets which is not the case
in our scenario where the source dataset contains no more
information about a concept than its label.

Information that is available and can be exploited is the
co-occurrence of terms in one article. By looking at all potential concepts for all extracted terms contained in one document it is possible to construct what we call a Linked Data
Entity Space. All relations between the concepts are modeled which allows to identify concepts that are most closely
related, i.e. that have the shortest conceptual distance. For
toponyms geographic distance metrics are also taken into
account. Toponym disambiguation based on geographic distances is extremely powerful for certain categories such as
local news.

Once the concept has been identified it is possible to retrieve further information from different data sources. The
information gained from Linked Data sources can also be
extremely useful for queries to other repositories containing
for instance user contributed multimedia content. It is possible to find more appropriate matches as the query can be
enhanced with more metadata for finding relevant images
and videos. Especially for concepts related to geographical
locations it is possible to supply coordinates that have been
retrieved from DBpedia or GeoNames in the query when
searching for images on Flickr or videos on Youtube.
3.2.3 Linked Data provision
The final article contains related information from Linked
Data sources as well as image and video content from Flickr4
and Youtube5. It also includes an RDF representation that
is embedded in the webpage via RDFa [1], a practice for
building linked data for both humans and machines as described in [6]. Some exemplary snippets of this output are
shown in Listing 1 where a machine processable description of the article,
its relations with further information
sources and additional information is provided along with
4http://www.flickr.com/
5http://www.youtube.com/


cently added support of RDFa content by important global
search engine providers such as Yahoo!6 and Google7 [2]
underlines the industrys appreciation of this approach. For
further processing by applications an RDF/XML version is
also provided.
3.3 In Use

The prototype can be used in a standalone web application or it can be integrated in a content management system.
In Figure 3 a screenshot of the demonstrator web application is shown.
In the text editor area the original text is
inserted, the panel on the right side then automatically suggests further information from Linked Data sources that the
editor can simply select with a single click. The information
will be integrated in the final online news article and RDF
describing the news article as well as links to other resources
is also supplied.

4. EVALUATION

Although our intention was to investigate paradigms of
the commercial adoption of Linked Data, and even though
our prototype is still under development, we have conducted
a preliminary evaluation and included a benchmark against
other systems for semantic content enrichement. These early
tests already indicate that the achieved performance of our
our prototype is superior compared to similar systems that
aim at enhancing (editorial) content. The most distinguishing features of our solution are the support of the German
language, recommendation of multimedia content and the
relationship of the recommended objects to concepts extracted from the text.

One goal of our evalation was to benchmark our prototype against three popular applications for semantic enrichment as listed in Table 1 where demonstrators are publicly
available on the Web: Calais8, Ontos API9, and Zemanta10.
However, as can be seen from the comparison table, some
tools have restrictions which resulted in a limited evalua-
tion: We found out that Calais currently does not support
German-language content at all. Using a translation service
as an intermediary step and processing the translated output
- an English version of the German-language article - might
at the first glance solve the language problem. As this would
indirectly result in an evaluation of the translation service
within our evaluation, we decided not to include Calais at all
as its functionality does not match with our requirements.
We furthermore learned that Ontos API is currently in fact
capable of extracting terms, but does not provide any content enrichment which resulted in a drop-out of Ontos API,
too. As only Zemanta provides all required functionality for
a valid comparison, we are limited to benchmark our prototype with Zemanta.

We developed a six-step procedure for our preliminary

evaluation:

1. In the first step we selected a set of German-language
articles from a local commercial news provider. Our

6http://www.yahoo.com
7http://www.google.com
8http://viewer.opencalais.com/
9http://try.ontos.com/
10http://www.zemanta.com/demo/

Figure 4: Recall and precision for all terms

preliminary evaluation contained only ten articles, including articles in the domains of politics, business,
sports, and culture. For a more comprehensive future
evaluation we have access to more than 3,000 articles
from the news paper.

2. We manually extracted persons, places, and organizations from each article. Furthermore, we extracted
terms which are important for a particular article as
they describe the content.

3. Thereafter, we processed the content of each article
with our prototype as well as with Zemanta. This
resulted in an automatic extraction of terms which we
evaluate in the next step.

4. We did a quantitative comparison between manually
and automatically extracted terms for both applica-
tions, our prototype and Zemanta.

5. We manually analyzed quantity and quality of the content recommended from both applications. Thereby,
we especially wanted to explore whether and how recommended objects relate to the terms (concepts) extracted from the articles.

6. We compared the recommendation-ability of our prototype to the results of Zemanta. As the ability to
suggest content for enrichement differs in various as-
pects, this evaluation is mainly done qualitatively.

In the following, we present the lessons learned from our
preliminary evaluation. Figures 4 and 5 present the quantitative results of the term extraction evaluation (step 1 - 4):
From our investigation we learned that our prototype generated satisfactorily results. The recall of all relevant terms
(cf. Figure 4) is considerably higher in our prototype and
even though Zemanta has identified less relevant terms the
precision values are comparable. This shows that our prototype is capable of retrieving more correct relevant terms
which allows online editors to be more flexible when enriching their content with content from third party sources.

Figure 5 shows the recall values for places, people, and
organizations. Our prototype outperforms Zemanta when
extracting people and places: In this context it is important
to mention that Zemanta can extract internationally known

 60%70%80%90%100%10%20%30%40%50%60%70%80%90%100%Our prototypeZemanta0%10%20%30%40%50%60%70%80%90%100%RecallPrecisionOur prototypeZemantaFigure 3: Screenshot of the prototype

Our prototype
Calais
Zemanta
Ontos API

English language
support
via extensions
yes
yes
yes

German language
support
yes

limited
yes

Categorizations

Integration of external content

yes
yes

yes

yes (Linked Data, multimedia content)

yes (select sources)

Table 1: Comparison of different systems for semantic enrichment

Font Name and SizeFont Style Undo/RedoAlignmentParagraph StyleIndenting and ListsInsert ItemAnalyzebody < p#MailActi...BerlinBonnGrazLarnacaWikipediaName: LarnakaBeschreibung:Larnaka, auch Larnaca, griechisch Larnaka(, veraltet ), turkisch Larnaka, ist eineHafenstadt im Sudosten der Mittelmeerinsel Zypern mit77.000 Einwohnern (Stand 31. Dezember 2004) undHauptort des gleichnamigen Bezirkes. [siehe Wikipedia]Referenzen:http//www.larnaka.comGeonamesFlickrYou TubeLondon StanstedMallorcaPaphosStanstedRyanairWikipediaFlickr    Article Recommandations:Place (8)Organisation (1) Von Graz aus zu uber 60 DestinationenDer Flughafen Graz stellte am Mittwoch seinen Sommerflugplan vor. Mit dabei einige Neuheiten.Am 28.03.2010 tritt der Sommerflugplan des Flughafen Graz in Kraft. Zirka 60 Destinationen inrund 20 Landern stehen auf dem Programm, darunter auch einige Neuheiten. Ende Mai bisAnfang September kann man mit Blagus und Niki nach Irland (Shannon) fliegen. Auch Zypernsteht heuer auf dem Programm: Moser-Reisen bietet Fluge nach Paphos. Ein weiteres Ziel aufZypern ist in diesem Sommer naturlich auch wieder Larnaca. Schon seit einiger Zeit alsDreiecksflug im Programm  jetzt geht es mit dem Reiseveranstalter ETI auch direkt von Grazins agyptische Sharm el Sheikh am Roten Meer. Auch Stadtereisende kommen im Sommer aufihre Kosten: Ab 1. Mai fliegt Air Berlin funf Mal pro Woche (taglich auer Dienstag undDonnerstag) von Graz zum Flughafen Berlin/Tegel.Mit Beginn des Sommerflugplans ubernimmt auerdem die Welcome Air die DestinationKoln/Bonn von der Air Berlin. Die Flugtage sind Dienstag, Donnerstag und Sonntag. Weiterhinim Programm ist auch der London-Stansted-Flug der Ryanair. In Grobritanniens Hauptstadtgeht es immer Montag, Mittwoch, Freitag und Sonntag. Und was ware ein Sommer ohne Flugenach Palma de Mallorca: Niki fliegt sechs Mal in die Urlaubshochburg.Semantic Text Analysis and InterlinkingSemTex EditorArial13NormalVon Graz aus zu uber 60 DestinationenDer Flughafen Graz stellte am Mittwoch seinen Sommerflugplan vor. Mit dabei einige Neuheiten.Am 2803.2010 tritt der Sommerflugplan des Flughafen Graz in Kraft. Zirka 60 Destinationen inrund 20 Landern stehen auf dem Programm, darunter auch einige Neuheiten. Ende Mai bisAnfang September kann man mit Blagus und Niki nach Irland (Shannon) fliegen. Auch Zypernsteht heuer auf dem Programm: Moser-Reisen bietet Fluge nach Paphos. Ein weiteres Ziel aufZypern ist in diesem Sommer naturlich auch wieder Larnaca. Schon seit einiger Zeit alsDreiecksflug im Programm  jetzt geht es mit dem Reiseveranstalter ETI auch direkt von Grazins agyptische Sharm el Sheikh am Roten Meer. Auch Stadtereisende kommen im Sommer aufihre Kosten: Ab 1. Mai fliegt Air Berlin funf Mal pro Woche (taglich auer Dienstag undDonnerstag) von Graz zum Flughafen Berlin/Tegel.   the Web without having to care about own infrastructure
the downside is that one becomes dependent on the data
providers infrastructure. Response times for queries depend
on server load and it could happen that a resource is unavailable for any (technical) reason that cannot be influenced by
the data consumer. One of the solutions to this issue is hosting a copy of relevant Linked Data on infrastructure that is
under ones own control - which in turn creates the need for
getting informed about dataset changes where different approaches exist and a commonly agreed strategy still needs to
evolve12. From a business perspective one could also identify
the need for Linked Data providers/consolidators that offer
Service Level Agreements that contractually guarantee the
availability of relevant Linked Data for professional users.

Data quality: For professional users the quality of data
can be an important issue that should be taken into account
by data publishers if they want their data to be reused.

Legal issues: Dataset publishers should be explicit about
licensing terms of their data to protect their rights or make
the data legally safely useable by others (cf. [4]).

Even though further challenges in the context of Linked
Data (such as provenance, trust, archiving, etc.) would be
worthwhile dealing with it seems that solving the issues presented above could foster an even greater acceptance of solutions based on Linked Data for professional use.

6. CONCLUSIONS AND FUTURE WORK
From recent discussions with online editors we learned
much about the nature of their business, quick but professional production of valuable and up-to-date online content
as outlined in Section 1. We drove our motivation to investigate the adoption of Linked Data for commercial content providers from the requirements of online editors. The
business opportunities underlying Linked Data may fulfill
their requirements as discussed in Section 2. Our prototype,
which we comprehensively presented in Section 3, is aimed at
supporting online editors during their editorial process and
beyond. Results of a preliminary evaluation are presented
in Section 4 and showed that our prototype is already able
to outperform other solutions. When implementing our first
prototype, we learned much about challenges impairing a
successful adoption of Linked Data for professional production environments, which we briefly outlined in Section 5.

Our paper already includes a preliminary evaluation of
our prototype as well as a comparison against other systems
for semantic content enrichement. In a next step, we will
rigorously evaluate our first prototype with professional online editors as probands, deriving further requirements for
technical improvement. Second, we aim to integrate the
next version of our prototype into the content managemement system of a major Austrian content provider enabling
us to perform a test of the tentative hypothesis as shown
in Figure 6 that embedding Linked Data positively affects
the number of page visits and session length and thus has a
positive effect on content providers revenues.

7. ACKNOWLEDGMENTS

The research reported in this paper was partially supported by the Austrian Federal Ministry for Transport, Innovation and Technology (bmvit).

12see http://esw.w3.org/topic/DatasetDynamic for a list
of proposals to describe Linked Data updates and changes

Figure 5: Recall of entities by category

persons very well, but struggles when trying to extract local
politicians or businessmen. When it comes to extracting
organizations, our prototype is on a comparable level with
Zemanta.

Evaluating the ability of our prototype to suggest text,
pictures and videos for content enrichement (step 5 - 6) is
more challgenging, especially as it differs from those of Zemanta in various aspects: While our prototype links suitable
data for any of the selected terms using Wikipedia, Geon-
ames, Flickr, and Youtube, Zemanta only recommends content for the entire article. Therefore, data recommended by
our prototype is of finer granularity and of higher seman-
tics. This aspect makes it almost impossible to compare the
quality of content linked by our prototype against the content Zemanta recommends. From the requirements of online
editors, we learned that content should preferably be linked
to the terms (concepts) in the text and not to the entire
article. Evaluating the quantity of content linked, we found
out that our prototype suggests a plethora of media and
text objects compared to Zemanta. However, both quantity
and quality of content can be further improved: We noticed,
that mainly pictures from Flickr and videos from Youtube
did not always match with extracted concepts.

5. CHALLENGES

Over the past months Linked Data technology has ma-
tured, various applications have been created, and new data
is constantly being added. However, during the development
of the prototype we have identified three important challenges that still need attention and should be addressed to
make Linked Data applications competitive and allow their
use in professional production environments. It has to be
noted that most of the issues do not only apply to Linked
Data but the Web in general.

Distributed infrastructure: One of the advantages of
Linked Data is that it can be accessed via HTTP URIs and
queries on remote SPARQL [15] endpoints that are made
available by the data providers themselves or Linked Data
consolidators (such as the Virtuoso instance hosting Linked
Open Data11). Even though it is appealing to use data from

11http://lod.openlinksw.com/

 0%10%20%30%40%50%60%70%80%90%100%PlacesPeopleOrganizationsOur prototypeZemanta[12] K. Lyons, C. Playford, P. R. Messinger, R. H. Niu,
and E. Stroulia. Business models in emerging online
services. In M. L. Nelson, M. J. Shaw, and T. J.
Strader, editors, Value Creation in E-Business
Management. 15th Americas Conference on
Information Systems, AMCIS 2009, SIGeBIZ track.
Selected Papers, volume 36 of Lecture Notes in
Business Information Processing, pages 4455, San
Francisco, CA, USA, 2009. Springer Berlin Heidelberg.

[13] A. Nikolov, V. Uren, E. Motta, and A. de Roeck.
Integration of semantically annotated data by the
KnoFuss architecture. In 16th International
Conference on Knowledge Engineering and Knowledge
Management (EKAW 2008), Acitrezza, Italy, 2008.

[14] A. Osterwalder and Y. Pigneur. An e-business model

ontology for modeling e-business. In Proceedings of
15th Bled Electronic Commerce Conference. e-Reality:
Constructing the e-Economy, Bled, Slovenia, 2002.

[15] E. Prudhommeaux and A. Seaborne. SPARQL query

language for RDF. W3C recommendation.
http://www.w3.org/TR/rdf-sparql-query/, Jan
2008.

[16] Y. Raimond, C. Sutton, and M. Sandler. Automatic

interlinking of music datasets on the semantic web. In
Proceedings of the Linked Data on the Web Workshop
(LDOW2008), Beijing, China, 2008.

[17] J. Volz, C. Bizer, M. Gaedke, and G. Kobilarov. Silk 

a link discovery framework for the web of data. In
Proceedings of the Linked Data on the Web Workshop
(LDOW2009), Madrid, Spain, 2009.

Figure 6: Tentative hypothesis of positive Linked
Data effects
