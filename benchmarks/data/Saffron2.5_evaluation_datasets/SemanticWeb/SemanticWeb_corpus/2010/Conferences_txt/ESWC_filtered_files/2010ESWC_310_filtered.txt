Combining Query Translation with Query
Answering for Efficient Keyword Search

G unter Ladwig and Thanh Tran

Institute AIFB, Karlsruhe Institute of Technology, Germany

{guenter.ladwig,duchthanh.tran}@kit.edu

Abstract. Keyword search has been regarded as an intuitive paradigm
for searching not only documents but also data, especially when the users
are not familiar with the data and the query language. Two types of approaches can be distinguished. Answers to keywords can be computed by
searching for matching subgraphs directly in the data. The alternative to
this is keyword translation, which is based on searching the data schema
for matching join graphs, which are then translated to queries. Answering
these queries is performed in the later stage. While clear advantages have
been shown for the approaches based on query translation, we observe
that processing done during query translation has some overlaps with the
processing needed for query answering. We propose a tight integration of
query translation with query answering. Instead of using the schema, we
employ a bisimulation-based structure index graph. Searching this index
for matching subgraphs results not only in queries, but also candidate
answers. We propose a set of algorithms which allow for an incremental
process, where intermediate results computed during query translation
can be reused for query answering. In experiments, we show that this
integrated approach consistently outperforms the state of the art.

1 Introduction

Graph structured data has attracted much attention recently, which is partly due
to the massive availability of RDF. There are billions of freely available RDF
triples, hosted by data providers involved in the LOD project. This number is
increasing, just like the amount of RDFa data associated with Web pages.

In this paper, we present an approach for keyword search on graph structured
data. Keyword search has been regarded as an intuitive paradigm for exploring
and searching for data, especially in the case where the users are not familiar with
the data and the query language. Approaches for computing structured answers
from keywords exist for different data models, including relational, XML and
graph structured data such as RDF [2,3,12,9,10,14,11].

State of the Art. Two different types of approaches can be distinguished. With
direct keyword query answering, answers to keywords are computed by searching
for matching subgraphs directly in the data, i.e. subgraphs which connect the
data elements matching the keywords [3,12,9]. Implementing such an approach

L. Aroyo et al. (Eds.): ESWC 2010, Part II, LNCS 6089, pp. 288303, 2010.
c Springer-Verlag Berlin Heidelberg 2010
?

?

?
amounts to building a native engine for keyword search. Specific indexes and
storage mechanisms have to be provided.

Alternatively, keyword search can be supported by computing translations
in the form of queries, which can then be processed using an existing database
engine. We refer to this as keyword query translation. Examples of database
extensions for keyword search include DBXplorer [2] and Discover [11]. These
systems are based on finding candidate networks, basically join expressions constructed using information found in the schema. These candidate networks are
used to instantiate a number of SQL queries. Similarly, [18] extracts a schema
from the RDF data graph. During online processing, this schema is augmented
with elements matching the user keywords. Keyword translation is performed
by finding matching subgraphs in this augmented schema representing possible
queries. Processing the queries derived from them is finally performed using the
underlying RDF store.

Keyword search based on translation has several advantages [18]. The produced queries can be presented to the user, thereby facilitating comprehension
of the results and in particular, enabling query refinement. Moreover, keyword
search can be performed efficiently: keyword translation is relatively fast, as exploration for subgraphs is performed on the schema. Since this is much smaller
than the actual data, exploration for queries is much faster than exploration
for answers in the data graph. For query answering, optimization capabilities of
the database engine can be leveraged. For keyword search on RDF, it has been
shown in [18] that combining fast query translation with state of the art query
answering is faster than direct keyword query answering [3,12,9].

While clear advantages have been shown for translation-based approaches, we
observe that processing done during query translation has overlaps with processing needed for query answering. We propose a tight integration of query
translation with query answering. The main contributions of our approach are:

 We propose a novel process which tightly combines query translation with
query answering. This is based on the observation that for query translation,
keywords are matched against the data. Then, possible join graphs between
these keyword matching elements are obtained. These operations are similar
to data retrieval and join operations performed during query answering.

 Instead of a schema, we employ a bisimulation-based structure index. Searching this index for join graphs results not only in queries, but also candidate
answers. This allows for an incremental process, where intermediate results
computed during query translation can be reused for query answering.

 For efficient and incremental processing, we elaborate on new algorithms for
all step in this process. We propose the decomposition keyword queries into
segments such that search using these segments result in entities that can be
further processed during query answering. The algorithm proposed for join
graph search leverages existing strategies for exploration, but computes both
join graphs and candidate answers. A special query answering algorithm is
proposed for processing join graphs, which takes candidate answers as inputs.

G. Ladwig and T. Tran

In experiments, we show that this integrated and incremental process for keyword
search consistently outperforms the state of the art.
Outline. We start with a problem definition in Section 2. A brief overview of our
approach is presented in Section 3. In Sections 4, 5 and 6, we describe the major
steps keyword mapping, query translation and answering. Evaluation results are
provided in Section 8. We conclude with a summary in Section 9.

2 Problem

In this section, we present models for the data and queries. Then, we define the
problem that we elaborate on.

Data Model. We deal with general graph structured data defined as follows:
Definition 1. A data graph is an RDF graph G = (V = VE  VD, L =
LR  LA, E) where VE are entities (RDF resources), VD are data values (RDF
literals), LR and LA are drawn from the set of object properties (relations) and
data properties (attributes) labels, and E represent edge instances.

Query Model. Two different types of queries are distinguished in this setting:
(1) the system query qs, which is the one finally used by the query engine to
retrieve answers and (2) the user query qu, which is the one actually entered by
the user. System queries qs are conjunctive queries of the following type:
Definition 2. A conjunctive query q is an expression of the form p1  . . .  pn,
where pn  P are query atoms of the form p(n1, n2) with n1, n2 being variables
or constants otherwise, and pn are called predicates. We distinguish between
relation query atoms pr  LR and attribute query atoms pa  LA.
Regarded as the basic block for querying graph structured data (RDF), these
queries have been the focus of recent work on RDF query processing [1,19,15].
The user query qu is a keyword query, i.e. qu = {k1, ..., kn} where each ki is
a keyword. Users enter keyword queries because they are not familiar with the
formal query language, the schema or the data. Fig. 1 shows a data graph and
example queries.

Conjunctive Query Answering. Fig. 1c illustrates that since variables can
interact in an arbitrary way, qs is essentially a graph pattern qs = (Vvar 
Vcon, L, E) consisting of a set of triple patterns p(v1, v2). As usual, query answering amounts to graph pattern matching:

s of a query qs on a graph G is a homomorphic mapDefinition 3. A match qm
ping s from the variables of qs to vertices of G such that the according substitution of variables in the graph pattern would yield a subgraph of G.
Query Translation. Translating qu means to find the queries qs representing
possible interpretations of qu. The focus lies on finding interpretations qs that
have non empty results. In order for some graph pattern matches to exist for qs,
?

?

?
Fig. 1. a) A data graph, b) its structure index c) a query graph, d) a keyword query

predicates and constants of qs must correspond to some elements of G. Thus, we
denote the space representing all possible interpretations of qu as Gq, a graph
constructed using elements of G. An interpretation can be defined as a keyword
pattern matching on Gq:
Definition 4. An interpretation qs for qu is a subgraph of Gq(Vq, Lq, Eq) connecting the keyword matching elements n  Nk  Vq, where n is obtained via a
mapping u from keywords of qu to elements in the set Vq  Lq.

3 Overview

We propose a tight integration of query translation and query answering to obtain an incremental process such that intermediate results obtained via the first
step can be reused in the second step. This is based on the observation that
query translation is very similar to query answering. For query answering, triple
patterns are matched against the data to obtain matching triples. The entire
query graph is processed by performing joins on the matching triples along the
query edges. During query translation, a similar matching is needed in order
to obtain keyword matching elements. Exploration for matching subgraphs connecting these keyword elements is similar to join processing  with the difference
that there are no query edges that can be used to guide this process.

The overall process is as follows: We firstly decompose the initial keyword
query into segments, and map them to entities and relation labels of G. This
step operates on two indexes built for G, one containing all relation labels LR
of G, called relation label index, and another one containing all attribute edges
G(V, LA, E) called entity index. The exploration for queries and search for candidate answers is combined in one step called join graph search. For this we
employ a query search space Gq constructed from a bisimulation-based struc-
, which represents the different edge-labeled structures that
ture index graph G

G. Ladwig and T. Tran

can be found in the data graph. Nodes of Gq represent extensions which stand
for entities in the data graph that are similar in structure. During join graph
search, we explore Gq for matching subgraphs from which candidate queries are
derived. Because of the way the structure index graph is built from the data
graph, these matching subgraphs are also candidate answers. That is, answers
to the query are contained in the nodes (extensions) of the matching subgraphs
and no other data has to be considered for query answering. Candidate answers
in these extensions are refined in the subsequent query answering process. For
this, the actual data graph edges have to be retrieved for elements in the exten-
sions, using the relation index G(VE, LR, E), and joined along the edges of the
matching subgraphs in the last step.

Comparison to Related Work. The general top-k subgraph exploration procedure proposed in [18] is adopted for join graph search. For brevity, we do not
consider scoring models, while their use for top-k and ranking as discussed in
[18] is equally applicable to join graph search.

Different from work on direct keyword query answering [3,12,9], our approach
aims to compute answers as well as queries that can be presented to the user.
The exploration for subgraphs takes place on the structure index constructed
from the data graph, instead of using the data graph itself.

So far, query translation has been performed independently from query answering [2,11,18]. Through the tight integration of these steps, we aim to minimize redundant processing by leveraging intermediate results. For this, we propose new algorithms for every major step of the integrated process: we decompose the keyword query into segments, from which the first initial result set of
entities can be obtained. This is different to keyword mapping in previous approaches [2,11,18,3,9], where the aim is to find some matching elements (instead
of entities). We propose the use of a structure index. As opposed to using the
schema [2,11,18], exploring the structure index results in a set of join graphs,
which represent queries and at the same time, contain candidate answers that
can be refined in the subsequent step. We propose a novel query answering pro-
cedure, which, as opposed to existing approaches [1,19,15], accepts entities and
the candidate answers contained in the join graphs as inputs.

4 Keyword Mapping = Entity Search

The first step to keyword search is keyword mapping, where the aim is to obtain a
set of keyword matching elements. In direct keyword query answering, these elements are data elements, i.e. tuples or nodes of a data graph [3,9]. For translation,
keywords k are mapped against the query search space Gq(Vq, Lq, Eq) to obtain
query elements (predicates and constants), i.e.  : k  VqLq [2,11,18]. Since we
are interested in queries with non-empty results, the computed query elements
must match some elements of the data graph G(V, L, E). In other words, query
elements (and thus keywords) are assumed to be drawn from data graph element
labels such that keyword mapping amounts to  : k  V L. Thus, results of this
?

?

?
mapping might comprise entities ve  VE  V , data values vd  VD  V and
edge labels l  L. Keywords are matched against labels using standard IR-style
keyword matching.
In the interest of computing not only queries but also answers, we propose
an alternative mapping  : k  GE  LR, where k might not be a keyword,
but a keyword segment ks  qu. Such a segment refers to entity descriptions
GE or relation labels LR and thus, are called entity keyword query and relation
keyword query respectively:
Definition 5. A description of an entity ve  VE is a subgraph GE(Ve, Le, Ee)
of G comprising all the edges l(ve, vd)  E, where vd  VD (and thus l  LA).
A keyword k denotes an entity e if there is a mapping  : k  GE, where GE
are descriptions of entities e  E.

kKe GEk

An entity keyword query is a set of keywords Ke, where the intersection of
=  with
the matching elements of all keywords is not empty, i.e.
GEk being the matching descriptions and e  E being the matching elements for
a keyword k.
A keyword k denotes a relation r if there is a mapping  : k  LR. Analo-

gously, a relation keyword query is a set of keywords Kr, where the intersection
kKr Rk =  with
of the matching relations of all keywords is not empty, i.e.
Rk being the matching relation labels for keyword k.
In other words, we map keywords to entities and relation labels. For this, the
keyword query q = K is decomposed into a set of entity keyword queries KE =
Ke1, . . . , Ken and relation keyword queries KR = Kr1, . . . , Krn. In particular, we
are interested in partitions of the keywords, i.e. each keyword occurs in exactly
one segment and there is no overlap between segments.
?

?

?
To create these partitions, we first generate segments of K with non-empty
results, i.e. matching segments. For this, the algorithm iterates through all subsets S of K in a bottom-up fashion, starting with single-element segments. The
level corresponds to segment size such that at level 1, segments are of size 1. At
every level, a segment sn  S is added to the set of matching segments Sm, if
the following conditions are satisfied: its subsegment sn1 containing the keywords {k1, . . . , kn1} has results (this is the case if sn1  Sm); the additional
keyword kn  sn has a result; and the intersection of these two sets of results is
not empty. The final result, i.e. all valid combinations of keyword segments, is
obtained via an algorithm to generate all partitions of the set K [5], using the
valid segments in Sm.

Example 1. For the keyword query in Fig. 1d, we start with segments with
length 1, to see that all of them match some elements in G. At level 2, we find
that only the combination researcher, tran is valid: (researcher)  (tran) =
{p1}. Based on these valid segments, two partitions of the query are com-
puted, i.e. {{researcher, tran},{KIT},{ICDE},{supervises},{author}} and
{{researcher},{tran},{KIT},{ICDE},{supervises},{author}}.

G. Ladwig and T. Tran

5 Query Translation = Join Graph Search

5.1 Structure Index for Graph Structured Data

Structure indexes have been widely used for semi-structured and XML data
[4,13,16]. A well-known concept for this is the dataguide [7], which basically
is a structural description for rooted data graphs. Similar to this concept, a
structure index has been proposed for general data graphs [17]. Nodes of this
structure index stand for groups of data elements that have equal structural
neighborhood, where equal structural neighborhood is defined by the wellknown notion of bisimulation. According to this notion, two graph nodes v1, v2
are bisimilar (written: v1  v2) if they cannot be distinguished by looking only
at their outgoing or incoming edge-labeled trees. Pairwise bisimilar nodes form
an extension. Applying the bisimulation  to the subgraph G(VE, LR, E) of our
data graph that contains relation edges only, results in a set of such extensions
{[v] : v  VE} with [v] := {w  VE : v  w}. These extensions form a
complete partition of the entity nodes VE of the data graph, i.e. form a family
P of pairwise disjoint sets whose union is VE.
 of G(VE, LR, E)
can be defined in terms of extensions and relations between them. In particular,
extensions from the partition P form the vertices of G
. An edge with label l
links two extensions E1, E2  P of G
 exactly if G contains at least one lr-edge
linking an element in the extension E1 to some element in the extension E2.
Example 2. The data graph shown in Fig. 1a can be partitioned into 8 ex-
tensions, shown as nodes of the index graph in Fig. 1b. Nodes p1 and p3
are grouped into extension E2 as they are bisimilar, i.e. both have incoming
supervise and knows edges and both have the same outgoing edgs paths knows,
(worksAt, partOf) and (authorOf, conf erence).

Based on this notion of bisimulation, the structure index G

Note that similar to the structure index, a schema also represents a structural
description of the data. However, a structure index is a description of the structures actually exhibited by the data, constructed from the data. In particular,
it has the following property [17]:

Property 1. Whenever there is a match of a query graph q on a data graph G

(homomorphism from q into G) the query also matches on the index graph G
). Moreover, nodes of the index graph matches
(homomorphism from q into G
will contain all data graph matches, i.e. the bindings to query variables.

5.2 Construction of Query Search Space

As opposed to direct keyword query answering, keyword query translation does
not operate on the actual data G(V, L, E), but on a query search space Gq.
Essentially, this search space consists of two parts, (1) the keyword matching
elements and (2) the structures that might connect these elements. Recall that
in order for the computed queries qs to produce non empty results, all predicates
?

?

?
and constants of qs must match elements of G. Hence, the query search space
shall be constructed from elements in G. Recall that keyword matching elements
comprise edge labels l  LR and entities e  VE  V . Typically, the schema is
used to represent the possible structures [2,11,18]. Instead, we propose the use
of a structure index to obtain the following query search space:
Definition 6. Given the set of keyword matching elements n  N k  (LR 
VE) and the data graph G, the query search space Gq is defined as the index
) of G, extended with a special type of edges of the form
graph G
contains([v], n) iff n  VE and n is in the extension [v]  V
The query search space is thus the structure index graph, extended with keyword
matching entity nodes. Since all different edge-labelled structures found in the
data are represented in the structure index, all possible structures of queries
with non empty results are completely captured by the proposed query search
space. This result follows directly from Property 1 of the structure index:

(V

.

, L

, E





Theorem 1. Whenever a query graph pattern q matches a data graph G (ho-
momorphism from q into G), there are some subgraphs of Gq that match q (ho-
momorphism from q into Gq).
Compared to the schema-based search space, the one proposed here is more
appropriate for investigating possible translations. Since the schema does not
necessarily represent actual structures in the data, many queries found through
schema exploration might have empty results.

Example 3. Fig. 2a shows an example query search space, consisting of the structure index in Fig. 1b extended with the keyword matching entities p1, u1, c1.

Fig. 2. a) Query space consisting of structure index, extended with keyword matching
elements p1, u1, c1, join graph found in this query space is highlighted, b) structured
query corresponding to the join graph and c) the data retrieved and joined during join
graph processing, join paths are highlighted.

5.3 Search for Join Graphs

During this step, we explore the query search space for subgraphs connecting
the keyword elements. More precisely, these subgraphs called join graphs are
formalized as follows:

G. Ladwig and T. Tran

Definition 7. Let Gq = (Vq, Lq, Eq) be the query search space, K =
{k1, . . . , kn} be the set of keyword segments and let f : K  Vq  Lq be a
function that maps keyword segments to sets of corresponding graph elements.
 Vq
A K-matching join graph of Gq is a graph Gm
and Lm
q
 for every k  K, f(k)  (V m

q = (V m
q , Lm
q ) = , i.e. Gm

q contains at least one

 Lq such that

q ) with V m

 Lm

q , Em

q

q

representative keyword matching element for every keyword from K, and

is connected such that there exists a path from every graph element to

 Gm
q

every other graph element from Gm
q .

In our approach, we search for graphs, which contain the keyword matching
edges l  LR, and additionally, can be used to join the keyword matching entities
e  VE. Such join graphs are constructed using edges e([e1], [e2])  E
 of the
structure index part of the query search space Gq. As several keyword matching
elements might be contained in the same extension, we firstly compute the sets
of extensions for every keyword segment k, which we use as starting points for
the exploration.

We use the top-k exploration algorithm as described in [18], to which we refer for an in-depth discussion of the algorithm. The algorithm is based on the
concept of cursors, which represent an exploration path from a start element
to some node in the structure index graph. Initially, each cursor is associated
with a keyword segment and the corresponding extensions previously computed
as starting elements. At each step, the cursor with the lowest cost (e.g. path
length, but other metrics are also possible) is chosen for expansion. Also, the
element at the end of the current cursor is examined to check whether it was
explored by other cursors, so that all keyword segments are covered. If this is the
case, the corresponding cursors are merged to form a subgraph. The exploration
terminates when the top-k subgraphs are found or the maximum exploration
distance is encountered for all cursors. Discovered subgraphs that are isomorphic are aggregated to obtain one single query for those representing the same
interpretations of the keywords.

is

the

example

about finding

join graph Gm
q

=
Example 4. This
{supervises(E1, E2), worksAt(E2, E3), partOf(E3, E5), authorOf(E2, E4),
conf erence(E4, E6)} as highlighted in Fig. 2. To obtain this, we iterate
through N k = {{p1},{u1},{c1},{supervise},{author}} to find the starting
extensions Sk = {{E2},{E5},{E6},{supervise},{author}}. At the beginning,
all cursors created for these start elements have equal
length. Thus, we
might start with any element from Sk. For instance, we pop the cursor
c(E2, E2,, 1) and add it to E2.CE2 to mark that E2 has been visited.
Then, new cursors are created for neighbors {supervises,authorOf,worksAt,
contains} of E2. At the next iterations, remaining cursors of
length 1
are taken from the queue and processed in the same manner. This proceeds until neighbor elements within distance of 4 have been explored
for elements in Sk. Then, we find that E2 contains cursors to all other
elements, i.e. E2.({c(E2, E6,authorOf, 4)}, {c(E2,supervises,supervises, 1)},
?

?

?
{c(E2,authorOf,authorOf, 1)}, {c(E2,E5,worksAt, 4)}). Paths represented by
these cursors are merged to obtain the join graph Gm
q . Further exploration does
not yield any results not isomorphic to Gm
q .

Complexity. As shown in [18], the time needed for join graph search is bounded
by |Gq|kmax where Gq is the query search space and kmax is the maximum path
length of query atoms considered for query translation. When compared to direct
keyword query answering based on exploring the data graph [3,12,9], this makes
up a crucial difference in time complexity. In our approach, |Gq| corresponds to
the size of the structure index, which is bigger than the schema, but typically,
is order of magnitudes smaller than the data graph [17].

6 Query Answering = Join Graph Processing

Instead of retrieving triples and joining them along the query, as done in standard
query processing, we propose query answering to be tightly coupled with query
translation, such that the computed entities and join graphs corresponding to
the user queries can be leveraged.
Recall that the join graphs Gm

q computed during translation are subgraphs of
the structure index. Every node of such a graph represents an extension, i.e. a
set of entities. Due to Property 1, we can infer that the structure index enables
us performing query translation and answering in an incremental way:

Theorem 2. Extensions of a join graph Gm
derived, contain all the bindings to variables of q.

q , from which the query q has been

Proof 1. Query translation is performed based on the isomorphism from Gm
q
q is a match of q, i.e. homomorphism from q into Gq. Since the
into q. Thus, Gm
 part of Gq is the one used for the exploration, Gm
structure index G
is in fact
, i.e. it is an index graph match. By Property
a homomorphism from q into G
1, Gm

q contains all the bindings to q.

q

Intuitively speaking, not only queries but also candidate answers were computed
q . Thus, it suffices to focus
during translation. These answers are contained in Gm
on elements in the extensions of Gm
q . More precisely, we can focus on the keyword
matching entities in these extensions.

The query answering algorithm leveraging these intermediate results is shown
including the keyword matching elements
in Alg. 1. Given the join graph Gm
e  N k contained in some nodes [e] of Gm
q
(i.e. e is connected with [e] via
contains([e], e)), it computes all matches of this pattern on the data graph
G = (V, L, E). These matches are stored as tuples in the result table R. Just
like standard query processing on graph structured data [1,19,15], edges of the
q ) from the data graph
query pattern Gm
q ([e1], [e2]). However, if given results exist, i.e. there are
matching the edge lm
keyword matching entities contained in [e1] or [e2] such that [e1].N k or
[e2].N k is not empty, they are used for further processing. Otherwise, triples

q are processed by retrieving triples E(lm

q

G. Ladwig and T. Tran

Algorithm 1. Join Graph Processing
Input: Join graph Gm

q ); Keyword matching entity nodes N k  VE;
Subgraph G(VE, LR, E) of the data graph G containing only entity nodes
and relation edges.

q (V m

q , Lm

q , Em

q (e1, e2)  E(lm

q ) matching join graph edge lm
q ;

Data: Sets of data graph edges lm

The keyword matching entities [e1].N k contained in [e1].

Result: Table R of answers where each row represents a match of Gm
foreach lm

q do

q onto G

if [e1].N k =   [e2].N k =  then

q (e1, e2)  E|e1  [e1].N k, e2  [e2].N k};
q (e1, e2)  E|e1  [e1], e2  [e2]};

E(lm

q ([e1], [e2])  Em
q )  {lm
q )  {lm
end
R  R  E(lm
q );

E(lm

else

end
return R;

are

the

along

joined

triples

the
and

translated

processing
retrieved

shown
edges Lm
q

q (e1, e2) are retrieved from G. Due to the use of the structure index, only triples
lm
with e1  [e1] and e2  [e2] have to be retrieved. This number of triples might
q .
be considerably lower than all the triples with label lm
in Fig.
Example 5. For
query
q
2b,
the
=
{supervise, worksAt, authorOf, partOf, conf erence} of
corresponding
join graph g shown in Fig. 2a. If we start with supervise(E1, E2) for instance,
we found that E2.N k = p1. Thus, E(lm
q ) = supervises(p2, p1), i.e. only one edge
with p1 is retrieved. In this example, either [e1].N k or [e2].N k is always = .
Join graph processing for this example and the result R = {supervises(p2, p1),
worksAt(p1, i1), partOf(i1, u1), conf erence(a1, c1)} is illustrated in Fig. 2c.
| edges, the time
Complexity. As shown in [17], for a join graph with |Em
|Em
q |)
and space for computing the answer table R is bounded by O(edgemax
q )|, with lm
where edgemax is |E(lm
q being the label instantiated by the largest
number of edges. This complexity result holds also for existing query answering approaches, where |E(lm
q )| is derived from size of the tables built for
edge labels l  L. The crucial difference lies in this factor. In our approach,
q ([e1], [e2]))| amounts to max{|[e1].N k|,|[e2].N k|}, i.e. the number of
|E(lm
entities computed during query mapping, which are contained in the join graph
nodes [e1] and [e2]. If no entities have been obtained for either one of these
nodes, |E(lm
q ([e1], [e2]))| amounts to max{|[e2]|,|[e2]|}, i.e. the size of the
join graph nodes.

q

7 Evaluation

Through the experiments, we aim to compare performance of our approach
against the state of the art.
?

?

?
Systems. For implementing the underlying indexes, we use a standard technique
for indexing graph structured data. In particular, we use inverted indexes, as
elaborated in [6]. We use an IR engine1 for managing these indexes. This engine is
also leveraged for mapping keywords to relation edge labels and entities (keyword
mapping), as well as for the retrieval of relations (join graph processing). We
compare our system against the keyword translation approach elaborated in [18].
It has been shown that the time for query translation achieved through [18], plus
the time for query answering is lower than the time for the state of the art system
based on direct keyword query answering [3,12,9]. For a detailed comparison
with the state of the art approaches on direct keyword query answering, we refer
to [18].

We have implemented this translation approach (QT) on top of a system for
query answering (QA) based on vertical partitioning [1] and compared it against
the implementation of our integrated approach (IQTQA). All implementations
rely on the same engine for indexing and retrieval.

Datasets. The following datasets are used for the benchmark: DBLP captures
bibliographic information about the field of Computer Science. It has been a
standard dataset for evaluating keyword search [9,18]. LUBM is the Lehigh
University benchmark, a synthetic dataset used extensively in the Semantic Web
community for evaluating knowledge base systems and RDF stores [8]. We used
the data generator proposed for the LUBM benchmark to create datasets for 1,
5, 10 and 50 imaginary universities.

Table 1. Statistics for the data graphs and indexes

Data [#Edges] Data [MB] EntityIdx

12,920,826

LUBM1 100,577
LUBM50 6,654,596

2,084

1,132

[MB]
?

?

?
RelIdx
[MB]
?

?

?
1,037

StrucIdx
[KB]
?

?

?
Schema
[KB]
?

?

?
For these datasets, the size and number of edges are shown in Table 1. Also,
the size of the associated entity index, relation index, structure index and schema
is provided. One can see that the structure index is consistently bigger than the
schema, but is of magnitudes smaller than the data graph. Further, its size is
not dependent on the size of the data graph, but the structures contained in it.

Queries. In order to study the behavior of the proposed algorithms in a principled way, test queries are generated by random sampling from the data. Keyword
queries are derived from generated structured queries.

Setting. We carried out the experiments on a Linux machine with two Intel
Xeon Dual Core 2.33 GHz processors and 48GB of main memory, of which 2GB
were allocated to the Java VM. All data and indexes were stored on a RAID
1 http://lucene.apache.org/

G. Ladwig and T. Tran

array. All times presented are the average of 10 runs of 25 generated queries for
each dataset. Between queries, we explicitly clear the operating system cache
and internal caches.

Total Processing Time. We have measured the average processing time
needed for QTQA and our approach IQTQA. For QTQA, we take the translation time + the query answering time for one query, the time needed for answering the first query output by query translation. For IQTQA, we consider
query answering time needed for processing the first join graph, as well as the
time needed for processing all join graphs output by query translation. As shown
in Fig. 3a, query translation constitutes the greater share. Especially in our ap-
proach, query translation makes up for more than 90% of the total processing
time. This is because we have chosen a generous value for kmax, resulting in a
relatively large neighborhood to be explored and a large number of candidate
interpretations to be computed. Consistently for all datasets, query translation
using QTQA is faster than our approach IQTQA. The difference between these
two approaches is greater for the LUBM datasets, where QTQA is up to 20
percent faster w.r.t query translation. This advantage of QTQA over IQTQA is
however outweighed by the worse performance in query answering. While query
answering takes almost half of the total time for QTQA, it makes up only a
small fraction of the total time for IQTQA. This holds for all datasets. This
even holds when not only the first join graph, but all join graphs are processed
for IQTQA, i.e. query translation + computing answers for all computed queries
using IQTQA is faster than query translation + computing answers for only one
query using QTQA, w.r.t all datasets. It seems that most of the work has been
done already during query translation such that the computation of answers for
all computed queries consume only a small fraction of additional time.

Effect of Data Size. We have measured total time for LUBM of different
data sizes. As illustrated in Fig. 3a, query translation time in both QTQA and
IQTQA increases linearly with the size of the data. Further decomposition of
this time into its two main components tells that this increase is mainly due to
query mapping, while the time for join graph search remains relatively constant.
This is consistent with our complexity analysis. The time for join graph search
depends on the structure index. Since the size of the structure indexes (and
schemas) is relatively constant in our experiments, this part of query translation
is not affected by the changes in data size. However, query mapping time is
partly determined by the number of mappings that can be retrieved from the
data. Larger data sizes lead to larger number of mappings, which in turn, result
in higher mapping time. Also query answering time increases linearly with the
size of the data, for both QTQA and IQTQA. This is not surprising, as this time
component is determined by the number of triples that can be retrieved for a
query atom. Larger data size results in larger number of matching triples.

Effect of Keyword Query Complexity. We have run experiments with keyword queries of different complexity, as measured by the number of keywords.
The query translation time for QTQA and IQTQA is illustrated in Fig. 3c for
?

?

?
Fig. 3. Evaluation results

DBLP and LUBM50. Query translation time increases with the number of key-
words. This is because the number of keywords has an influence on the complexity of both keyword mapping and join graph search. When the number of
keywords increase, a larger number of mappings needs to be retrieved, a larger
number of segments require to be tested and potentially, a larger number of
starting elements have to be considered during join graph search. Compared
with QTQA, the increase exhibited by IQTQA is slightly stronger. This can be
explained by the larger search space employed by IQTQA, i.e. the structure index is bigger than the schema. The negative effect of a larger number of starting
elements exacerbate, when the search space is larger in size.

Effect of Maximum Neighborhood Distance. This problem is more evident when looking at the maximum neighborhood size kmax used for join graph
search. We illustrate the effect of this factor in Fig. 3b. The increase of query
translation time with greater kmax is consistently stronger for IQTQA, especially
w.r.t LUBM50. A greater kmax means simply means a greater portion of the
search space will be searched, thus resulting in higher translation time.

Effect of Structured Query Complexity. The negative effect due to the
larger search space is overcompensated by the gain in query answering perfor-
mance. In Fig. 3d, we illustrate the relation between query answering time and
query complexity, where complexity is represented by the number of query edges.
While time for QTQA increases linearly, time for IQTQA remains relatively con-
stant. Here the result for QTQA is better than worst case performance because
in many instances, retrieved data comes in sorted order, thus enabling fast joins.

G. Ladwig and T. Tran

Query times for IQTQA do not increase with the number of query edges because
for most cases, intermediate results from translation have been leveraged such
that only a small number of data elements are actually involved in the join.

8 Conclusion

We have proposed an approach for keyword search, which combines query translation with structured query answering to obtain an integrated process. Results
produced during translation are reused to improve the efficiency of subsequent
query answering. For this, we break down the overall process into two similar
pattern matching problems: one is to match the keywords against a query search
space to obtain a query, and the other is to match the query against the data.
By constructing the query search space based on the data, i.e. the entities and
the structures connecting them as represented by a structure index, the result of
the first matching can greatly improve the efficiency of the second matching. We
propose algorithms to perform these two matching tasks in an efficient and incremental way. We have established complexity bounds for these algorithms and
compare these theoretical results with related work. In the benchmark against
the state of the art, we show that our approach outperforms the state of the art.

Acknowledgements. Research reported in this paper was supported by the
German Federal Ministry of Education and Research (BMBF) under the iGreen
project (grant 01IA08005K).
