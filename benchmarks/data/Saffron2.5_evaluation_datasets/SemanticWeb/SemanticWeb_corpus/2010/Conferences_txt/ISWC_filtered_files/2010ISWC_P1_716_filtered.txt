Query Strategy for Sequential Ontology Debugging

Kostyantyn Shchekotykhin and Gerhard Friedrich

Universitaet Klagenfurt
Universitaetsstrasse 65-67
9020 Klagenfurt, Austria

{firstname.lastname}@ifit.uni-klu.ac.at

Abstract. Debugging is an important prerequisite for the wide-spread application of ontologies, especially in areas that rely upon everyday users to create and
maintain knowledge bases, such as the Semantic Web. Most recent approaches
use diagnosis methods to identify sources of inconsistency. However, in most debugging cases these methods return many alternative diagnoses, thus placing the
burden of fault localization on the user. This paper demonstrates how the target
diagnosis can be identified by performing a sequence of observations, that is, by
querying an oracle about entailments of the target ontology. We exploit probabilities of typical user errors to formulate information theoretic concepts for query
selection. Our evaluation showed that the suggested method reduces the number
of required observations compared to myopic strategies.

1 Introduction

The application of semantic systems, including the Semantic Web technology, is largely
based on the assumption that the development of ontologies can be accomplished efficiently even by every day users. However, studies in cognitive psychology, like [1],
discovered that humans make systematic errors while formulating or interpreting logical descriptions. Results presented in [10,12] confirmed these observations regarding
ontology development. Therefore it is essential to create methods that can identify and
correct erroneous ontological definitions. Ontology debugging tools simplify the development of ontologies by localizing a set of axioms that should be modified in order to
formulate the intended target ontology.

To debug an ontology a user must specify some requirements such as coherence
and/or consistency. Additionally, one can provide test cases [3] which must be fulfilled
by the target ontology Ot. A number of ontology diagnosis methods have been developed [13,6,3] to pinpoint alternative sets of possibly faulty axioms (called a set of
diagnoses). A user has to change at least all of the axioms of one diagnosis in order to
satisfy all of the requirements and test cases.

However, the diagnosis methods can return many alternative diagnoses for a given
set of test cases and requirements. A sample study of real-world inconsistent ontologies
presented in Table 1 shows that even a small number of irreducible sets of axioms that
are together inconsistent/incoherent (conflict sets) can be a source of a large number
of diagnoses. For instance only 8 conflict sets in the Economy ontology resulted in

 The research project is funded by grants of the Austrian Science Fund (Project V-Know, con-

tract 19996).

P.F. Patel-Schneider et al. (Eds.): ISWC 2010, Part I, LNCS 6496, pp. 696712, 2010.
c Springer-Verlag Berlin Heidelberg 2010
?

?

?
Table 1. Dianosis results for some real-world ontologies presented in [6]. #C/#P/#I are the numbers of concepts, properties, and individuals in an ontology. #CS/min/max are the number of
conflict sets, their minimum and maximum cardinality. The same notation is used for diagnoses
#D/min/max. These ontologies are available upon request.

Ontology
1. Chemical
2. Sweet-JPL
3. University
4. Tambis
5. Economy
6. Transport

Axioms
?

?

?
#C/#P/#I
48/20/0

1537/121/50

30/12/4
395/100/0
339/53/482
445/93/183

#CS/min/max

#D/min/max Domain

6/5/6
8/1/13
4/3/5
7/3/9
8/3/4
9/2/6

6/1/3
13/8/8
90/3/4
147/3/7
864/4/9
1782/6/9

Chemical elements
Earthscience
Training
Biological science
Mid-level
Mid-level

864 diagnoses. In the case of Transportation ontology the diagnosis method was able
to identify 1782 diagnoses. In such situations simple visualization of all alternative
changes of the ontology is ineffective.

A possible solution would be to introduce an ordering using some preference criteria.
For instance, Kalyanpur et al. [7] suggest measures to rank the axioms of a diagnosis
depending on their structure, occurrence in test cases, etc. Only the top ranking diagnoses
are then presented to the user. Of course this set of diagnoses will contain the target one
only in the case when a faulty ontology, the given requirements and test cases, provide
sufficient data to appropriate heuristics. However, in most debugging sessions a user has
to provide additional information (e.g. in the form of tests) to identify the target diagnosis.
In this paper we present an approach to acquisition of additional information by generating a sequence of queries, which should be answered by some oracle such as a user,
an information extraction system, etc. Our method uses each answer to a query to reduce
the set of diagnoses until finally it identifies the target diagnosis. In order to construct
queries we exploit the property that different diagnoses imply unequal sets of axioms.
Consequently, we can differentiate between diagnoses by asking the oracle if the target
ontology should imply an axiom or not. These axioms can be generated by classification and realization services provided in description logic reasoning systems [15,4].
In particular, the classification process computes a subsumption hierarchy (sometimes
also called inheritance hierarchy of parents and children) for each concept name mentioned in a TBox. For each individual mentioned in an ABox, realization computes the
atomic concepts (or concept names) of which the individual is an instance [15].

In order to generate the most informative query we exploit the fact that some diagnoses are more likely than others because of typical user errors. The probabilities of
these errors can be used to estimate the change in entropy of the set of diagnoses if a
particular query is answered. We select those queries which minimize the expected en-
tropy, i.e. maximize the information gain. An oracle should answer these queries until
a diagnosis is identified whose probability is significantly higher than those of all other
diagnoses. This diagnosis is the most likely to be the target one.

We compare our entropy-based method with a greedy approach that selects those
queries which try to cut the number of diagnoses in half as well as with a random
strategy when the algorithm selects queries to be asked completely randomly. The evaluation was performed using the set of ontologies presented in Table 1 and generated

K. Shchekotykhin and G. Friedrich

examples. Its results show that on average the suggested entropy-based approach is at
least 50% better than the greedy one.

The remainder of the paper is organized as follows: Section 2 presents two introductory examples as well as the basic concepts. The details of the entropy-based query
selection method are given in Section 3. Section 4 describes the implementation of the
approach and is followed by evaluation results in Section 5. The paper concludes with
an overview of related work.

2 Motivating Examples and Basic Concepts

In order to explain the fundamentals of our approach let us introduce two examples.
Example 1. Consider a simple ontology O with the terminology T :

ax 1 : A  B

ax 2 : B  C

ax 3 : C  Q

ax 4 : Q  R

and the background theory A : {A(w),R(w)}. Let the user explicitly define that the
two assertional axioms should be considered as correct.
The ontology O is inconsistent and the only irreducible set of axioms (minimal conflict set) that preserves the inconsistency is CS : {ax 1, ax 2, ax 3, ax 4}. That is one
has to modify or remove the axioms of at least one diagnosis:

D1 : [ax 1] D2 : [ax 2] D3 : [ax 3] D4 : [ax 4]

to restore the consistency of the ontology. However it is unclear, which diagnosis from
the set D : {D1 . . .D4} corresponds to the target one.

In order to focus on the essentials of our approach we employ the following simplified definition of diagnosis without limiting its generality. A more detailed version can
be found in [3].
?

?

?
O, B, T

where O is an ontology, B
|= a set of logical sentences which must be implied by the target
A diagnosis is a set of axioms D  O such that the set of axioms O \ D can be
|=  T
|=

We allow the user to define a background theory (represented as a set of axioms)
which is considered to be correct, a set of logical sentences which must be implied by
the target ontology and a set of logical sentences which must not be implied by the
target ontology. Following the standard definition of the diagnosis [11,8], we assume
that each axiom ax j  Di is faulty whereas each axiom ax k / Di is correct.
Definition 1. Given a diagnosis problem
a background theory, T
ontology Ot, and T
extended by a logical description EX and (O \ D)  B  EX |= t
and (O \ D)  B  EX |= t
A diagnosis D is minimal if there is no proper subset of the faulty axioms D  D such
that D
is a diagnosis. The following proposition allows us to characterize diagnoses
without the extension EX. The idea is to use the sentences which must be implied to
approximate EX.

|= a set of logical sentences which must not be implied by Ot.

|= for all t

|= for all t

|=  T

|=.

|=, T

|=
?

?

?
O, B, T

|=}  t

, a set of axioms D  O is a

|=

|=, T
|= consistent for all t

|=  T

|=.

diagnosis iff (O \ D)  B  {

Corollary 1. Given a diagnosis problem
t|=T |= t
?

?

?
|=, T

|=

t|=T |= t

|=  T

|=}t

O, B, T
|= and CSB{

In the following we assume that a diagnosis always exists under the (reasonable) con-
|= and the negation
dition that the background theory together with the axioms in T

|= are mutually consistent. For the computation of diagnoses the set of
of axioms in T
conflicts is usually employed.
, a conflict set CS  O is a
Definition 2. Given a diagnosis problem
|= is inconsistent.
set of axioms s.t. there is a t
A conflict is the part of the ontology that preserves the inconsistency/incoherency. A
minimal conflict CS has no proper subset which is a conflict. D is a (minimal) diagnosis
iff D is a (minimal) hitting set of all (minimal) conflict sets [11].
In order to differentiate between the minimal diagnoses {D1 . . .D4} an oracle can
be queried for information about the entailments of the target ontology. For instance,
in our example the ontologies Oi = O \ Di have the following entailments O1 : ,
O2 : {B(w)}, O3 : {B(w), C(w)}, and O4 : {B(w), C(w), Q(w)} provided by the
realization of the ontology. Based on these entailments we can ask the oracle whether
the target ontology has to entail Q(w) or not (Ot |= Q(w)). If the answer is yes (which
|= and D4 is the target
we model with the boolean value 1), then Q(w) is added to T
diagnosis. All other diagnoses are rejected because (O \ Di)  B  {Q(w)} for i =
1, 2, 3 is inconsistent. If the answer is no (which we model with the boolean value
|= and D4 is rejected as (O \ D4)  B |= Q(w) (rsp.

0), then Q(w) is added to T
(O \D4) B Q(w) is inconsistent) and we have to ask the oracle another question.
, a set of diagnoses D, and a
Property 1. Given a diagnosis problem
set of logical sentences X representing the query Ot |= X :
If the oracle gives the answer 1 then every diagnosis Di  D is a diagnosis for
|=.
If the oracle gives the answer 0 then every diagnosis Di  D is a diagnosis for

|=  X iff (O \Di) B {
|=  {X} iff (O \ Di)  B  {

|=}  X is consistent.

O, B, T

|= is consistent for all t

|=}{X}t

|=  T

|=, T

|=

t|=T |= t

t|=T |= t

Note, a set X corresponds to a logical sentence where all elements of X are connected
by . This defines the semantic of X.

As possible queries we consider sets of entailed concept definitions provided by a
classification service and sets of individual assertions provided by realization. In fact,
the intention of classification is that a model for a specific application domain can be
verified by exploiting the subsumption hierarchy [2].

One can use different methods to select the best query in order to minimize the
number of questions asked to the oracle. Split-in-half heuristic is one of such methods
that prefers queries which remove half of the diagnoses from the set D. To apply this
heuristic it is essential to compute the set of diagnoses that can be rejected depending
on the query outcome. For a query X the set of diagnoses D can be partitioned in sets
of diagnoses DX, DX and D

 for each Di  DX it holds that (O \ Di)  B  {
 for each Di  DX it holds that (O \ Di)  B  {

 D = D \ (DX  DX)
Given a diagnosis problem we say that the diagnoses in DX predict 1 as a result of the
query X, diagnoses in DX predict 0, and diagnoses in D
do not make any predictions.

|=} |= X
|=} |= X

t|=T |= t
t|=T |= t

where

K. Shchekotykhin and G. Friedrich

O, B, T
?

?

?
|=, T

|=

.

If the oracle gives the answer 0 then the set of rejected diagnoses is DX and the set

, a set of diagnoses D, and a
If the oracle gives the answer 1 then the set of rejected diagnoses is DX and the set

Property 2. Given a diagnosis problem
query X:
of remaining diagnoses is DX  D
.
of remaining diagnoses is DX  D
For our first example let us consider three possible queries X1, X2 and X3 (see Table 2).
For each query we can partition a set of diagnoses D into three sets DX, DX and D
.
Using this data and the heuristic given above we can determine that asking the oracle if
Ot |= C(w) is the best query, as two diagnoses from the set D are removed regardless
of the answer.
Let us assume that D1 is the target diagnosis, then an oracle will answer 0 to our
question (i.e. Ot |= C(w)). Given this feedback we can decide that Ot |= B(w) is
the next best query, which is also answered with 0 by the oracle. Consequently, we
identified that D1 is the only remaining minimal diagnosis. More generally, if n is the
number of diagnoses and we can split the set of diagnoses in half by each query then
the minimum number of queries is log2n. However, if the probabilities of diagnoses
are known we can reduce this number of queries by using two effects: (1) We can
exploit diagnoses probabilities to asses the probabilities of answers and the change in
information content after an answer is given. (2) Even if there are multiple diagnoses in
the set of remaining diagnoses we can stop further query generation if one diagnosis is
highly probable and all other remaining diagnoses are highly improbable.

Table 2. Possible queries in Example 1

Query

X

{D1}
{D1,D2}
{D1,D2,D3}
Example 2. Consider an ontology O with the terminology T :

{D2,D3,D4}
{D3,D4}
{D4}

X1 : {B(w)}
X2 : {C(w)}
X3 : {Q(w)}







ax 1 : A1  A2 " M1 " M2
ax 2 : A2  s.M3 " s.M2
ax 3 : M1  A " B

ax 4 : M2  s.A " C
ax 5 : M3  B # C

and the background theory A : {A1(w), A1(u), s(u, w)}. The ontology is inconsistent
and includes two minimal conflict sets: {ax 1, ax 3, ax 4 , ax 1, ax 2, ax 3, ax 5}. To
restore consistency, the user should modify all axioms of at least one minimal diagnosis:

D1 : [ax 1] D2 : [ax 3] D3 : [ax 4, ax 5] D4 : [ax 4, ax 2]

Following the same approach as in the first example, we compute entailments for each
ontology Oi = O\Di for all minimal diagnoses Di  D. To construct a query we select
a DX  D and determine the common set X of concept instantiations and concept
subsumption axioms, which are entailed by each Oi = O \ Di, where Di  DX. If the
set X is empty, the query is rejected. For each accepted query the remaining diagnoses
Dj  D \ DX are partitioned into three sets DX, DX, and D
as defined above. If
?

?

?
Table 3. Possible queries in Example 2

Query
X1 : {B  M3}
X2 : {B(w)}
X3 : {M1  B}
X4 : {M1(w), M2(u)}
X5 : {A(w)}
X6 : {M2  D}
X7 : {M3(u)}

{D1,D2,D4}
{D3,D4}
{D1,D3,D4}
{D2,D3,D4}
{D2}
{D1,D2}
{D4}

X

{D3}
{D2}
{D2}
{D1}
{D3,D4}






{D1}


{D1}
{D3, D4}
{D1, D2, D3}

the the ontology Oj = O \ Dj is inconsistent with X then we add Dj to the set DX.
In the case when Oj  {X} is inconsistent Dj is added to DX. Otherwise we add Dj
to the set D
For instance, ontologies Oi = O \ Di obtained for diagnoses D2, D3 and D4 have

.

the following set of common entailments:
?

?

?
4 : {A1  A2, A1  M1, A1  M2, A2(u), M1(u), M2(u), A2(w), M1(w)} (1)
?

?

?
4 is not empty it is considered as the query and the set DX includes
Since the set X
three elements {D2,D3,D4}. The ontology O \ D1  {X
4} is inconsistent therefore

the set DX = {D1} and the set D = . However, a query need not include all
partitions the set of diagnoses into DX, DX and D
of these axioms. If a query X
and there exists an irreducible set X  X
which preserves the partition then it is

4 can be reduced to its subset X4 :
sufficient to query X. In our example, the set X
{M1(w), M2(u)}. If there are multiple subsets that preserve the partition we select one
with minimal cardinality. For query generation we investigate all possible subsets of D.
This is feasible since we consider only the n most probable minimal diagnoses (e.g.
n = 12) during query generation and selection.

The possible queries presented in Table 3 partition the set of diagnoses D in a way
that makes the application of myopic strategies, such as split-in-half, inefficient. A
greedy algorithm based on such a heuristic would select the first query X1 as the next
query, since there is no query that cuts the set of diagnoses in half. If D4 is the target
diagnosis then X1 will be positively evaluated by an oracle (see Fig. 1). On the next
iteration the algorithm would also choose a suboptimal query since there is no partition that divides the diagnoses D1, D2, and D4 into two equal groups. Consequently,

{D1,D2,D3,D4} : X1

$HHHHH

zvvvvv
{D1,D2,D4} : X2
$HHHHH
{D1,D2} : X3
$HHHHH
zvvvvv

{D3}

ujjjjjjjj
{D1,D4} : X4
$HHHHH
zvvvvv

{D4}

{D1}

{D1}

{D2}

Fig. 1. Greedy algorithm

z
$
z
$
u
$
$
z

K. Shchekotykhin and G. Friedrich

it selects the first untried query X2. The oracle answers positively, and the algorithm
identifies query X4 to differentiate between D1 and D4.

However, in real-world settings the assumption that all axioms fail with the same
probability is rarely the case. For example, Roussey et al. [12] present a list of anti-
patterns. Each anti-pattern is a set of axioms, like {C1  R.C2, C1  R.C3, C2 
C3}, that correspond to a minimal conflict set. The study performed by the authors
shows that such conflict sets occur often in practice and therefore can be used to compute probabilities of diagnoses.

The approach that we follow in this paper was suggested by Rector at al. [10] and
considers the syntax of the description logics, such as quantifiers, conjunction, negation,
etc., rather than axioms to describe a failure pattern. For instance, if a user modifies a
quantifier of one of the roles to restore coherency, then we can assume that axioms
including universal quantifier are more probable to fail than the other ones. In [10] the
authors report that in most cases inconsistent ontologies were created because users (a)
mix up r.S and r.S, (b) mix up r.S and r.S, (c) mix up # and ", (d) wrongly
assume that classes are disjoint by default or overuse disjointness, (e) wrongly apply
negation. Observing that misuses of quantifiers are more likely than other failure patterns one might find that the axioms ax 2 and ax 4 are more likely to be faulty than ax 3
(because of the use of quantifiers), whereas ax 3 is more likely to be faulty than ax 5 and
ax 1 (because of the use of negation). Therefore, diagnosis D2 is the most probable one,
followed closely by D4 although it is a double fault diagnosis. D1 and D3 are significantly less probable because ax 1 and ax 5 have a significantly lower fault probability
than ax 3. A detailed justification based on probability is given in the next section.

Taking into account the information about user faults provided in [10], it is almost
useless to ask query X1 because it is highly probable that the target diagnosis is either
D2 or D4 and therefore it is highly probable that the oracle will respond with 1. Instead,
asking X3 is more informative because given any possible answer we can exclude one
of the highly probable diagnoses, i.e. either D2 or D4. If the oracle responds to X3
with 0 then D2 is the only remaining diagnosis. However, if the oracle responds with 1,
diagnoses D4, D3, and D1 remain, where D4 is significantly more probable compared
to diagnoses D3 and D1. We can stop, since the difference between the probabilities
of the diagnoses is high enough such that D1 can be accepted as the target diagnosis.
In other situations additional questions may be required. This strategy can lead to a
substantial reduction in the number of queries compared to myopic approaches as we
will show in our evaluation.

Note that in real-world application scenarios failure patterns and their probabilities can
be discovered by analyzing actions of a user in an ontology editor, like Prot eg e, while
debugging an ontology or just repairing an inconsistency/incoherency. In this case it is
possible to personalize the debugging algorithm such that it will prefer user-specific
faults.

3 Entropy-Based Query Selection

To select the best query we make the assumption that knowledge is available about the
a-priori failure probabilities in specifying axioms. Such probabilities can be estimated
either by studies such as [10,12] or can be personalized by observing the typical failures
?

?

?
of specific users working with an ontology development tool. In the last case an ontology editor should just save logs of debugging sessions, as well as user actions taken to
restore the consistency/coherency of an ontology. Such observations can be then used to
identify typical failures of a particular user. Using observations about failure patterns,
for instance obtained from an ontology editor as described above, we can calculate the
initial probability of each axiom p(ax i) containing a failure. If no information about
failures is available then the debugger can initialize all probabilities p(ax i) with some
small number.
Given the failure probabilities p(ax i) of axioms, the diagnosis algorithm first calculates the a-priori probability p(Dj) that Dj is the target diagnosis. Since all axioms fail
independently, this probability can be computed as [8]:
?

?

?
p(Dj) =

p(ax n)

ax n Dj

ax m Dj

1  p(ax m)

(2)

The prior probabilities for diagnoses are then used to initialize an iterative algorithm that
includes two main steps: (a) selection of the best query and (b) update of the diagnoses
probabilities given the query feedback.

According to information theory the best query is the one that, given the answer of
an oracle, minimizes the expected entropy of a the set of diagnoses [8]. Let p(Xi = vik)
where vi0 = 0 and vi1 = 1 be the probability that query Xi is answered with either 0
or 1. Let p(Dj|Xi = vik) be the probability of diagnosis Dj after the oracle answers
Xi = vik. The expected entropy after querying Xi is:

He(Xi) =

p(Xi = vik)  

p(Dj|Xi = vik) log2 p(Dj|Xi = vik)
?

?

?
DjD

1

k=0

The query which minimizes the expected entropy is the best one based on a one-step-
look-ahead information theoretic measure. This formula can be simplified to the following score function [8] which we use to evaluate all available queries and select the
one with the minimum score to maximize information gain:

sc(Xi) =

p(Xi = vik) log2 p(Xi = vik) + p(D

i ) + 1

(3)

1

k=0

where D
i is the set of diagnoses which do not make any predictions for the query Xi.
p(D
i ) is the total probability of the diagnoses that predict no value for the query Xi.
Since, for a query Xi the set of diagnoses D can be partitioned into the sets DXi, DXi
and D
i , the probability that an oracle will answer a query Xi with either 1 or 0 can be
computed as:

p(Xi = vik) = p(Sik) + p(D

i )/2

(4)
where Sik corresponds to the set of diagnoses that predicts the outcome of a query, e.g.
Si0 = DXi for Xi = 0 and Si1 = DXi in the other case. Under the assumption
that both outcomes are equally likely the probability that a set of diagnoses D
i predicts
Xi = vik is p(D
Since by Definition 1 each diagnosis is a unique partition of all axioms in an ontology O into correct and faulty, we consider all diagnoses as mutually exclusive events.

i )/2.

K. Shchekotykhin and G. Friedrich

Therefore the probabilities of their sets can be calculated as:

p(D

i ) =

p(Dj)

p(Sik) =

p(Dj)
?

?

?
DjSik
?

?

?
DjD

i

Given the feedback v of an oracle to the selected query Xs, i.e. Xs = v we have to
update the probabilities of the diagnoses to take the new information into account. The
update is made using Bayes rule for each Dj  D:

p(Dj|Xs = v) = p(Xs = v|Dj)p(Dj)

p(Xs = v)

(5)

where the denominator p(Xs = v) is known from the query selection step (Equation 4)
and p(Dj) is either a prior probability (Equation 2) or is a probability calculated using
Equation 5 during the previous iteration of the debugging algorithm. We assign p(Xs =
v|Dj) as follows:

1,

0,

2 ,

p(Xs = v|Dj) =

if Dj predicted Xs = v;
if Dj is rejected by Xs = v;
if Dj  D

s

Example 1 (continued). Suppose that the debugger is not provided with any information about possible failures and therefore it assumes that all axioms fail with the
same probability p(ax i) = 0.01. Using Equation 2 we can calculate probabilities for
each diagnosis. For instance, D1 suggests that only one axiom ax 1 should be modified by the user. Hence, we can calculate the probability of diagnosis D1 as follows
p(D1) = p(ax 1)(1  p(ax 2))(1  p(ax 3))(1  p(ax 4)) = 0.0097. All other minimal
diagnoses have the same probability, since every other minimal diagnosis suggests the
modification of one axiom. To simplify the discussion we only consider minimal diagnoses for the query selection. Therefore, the prior probabilities of the diagnoses can be
normalized to p(Dj) = p(Dj)/
?

?

?
DjD p(Dj) and are equal to 0.25.

Given the prior probabilities of the diagnoses and a set of queries (see Table 2)
we evaluate the score function (Equation 3) for each query. E.g. for the first query
X1 : {B(w)} the probability p(D) = 0 and the probabilities of both the positive
and negative outcomes are: p(X1 = 1) = p(D2) + p(D3) + p(D4) = 0.75 and
p(X1 = 0) = p(D1) = 0.25. Therefore the query score is sc(X1) = 0.1887.
The scores computed during the initial stage (see Table 4) suggest that X2 is the best
query. Taking into account that D1 is the target diagnosis the oracle answers 0 to the

Table 4. Expected scores
(p(ax i) = 0.01)

for queries

Query
X1 : {B(w)}
X2 : {C(w)}
X3 : {Q(w)}

Initial score X2 = 1

0.1887

0.1887
?

?

?
Table 5. Expected scores
for queries
(p(ax 1) = 0.025, p(ax 2) = p(ax 3) =
p(ax 4) = 0.01)

Query
X1 : {B(w)}
X2 : {C(w)}
X3 : {Q(w)}

Initial score

0.250
0.408
0.629
?

?

?
Table 6. Probabilities of diagnoses after answers

Answers
Prior
X3 = 1
X3 = 1, X4 = 1
X3 = 1, X4 = 1, X1 = 1

D1
0.0970
0.2352
?

?

?
D2
0.5874
?

?

?
D3
0.0026
0.0063
0.0082

D4
0.3130
0.7585
0.9918

Table 7. Expected scores for queries

Queries
X1 : {B  M3}
X2 : {B(w)}
X3 : {M1  B}
X4 : {M1(w), M2(u)}
X5 : {A(w)}
X6 : {M2  D}
X7 : {M3(u)}

Initial
0.974
0.151
0.022
0.540
0.151
0.686
0.759

X3 = 1
0.945
0.713

0.213
0.713
0.805
0.710

X3 = 1, X4 = 1

0.931
?

?

?
0.970

query. The additional information obtained from the answer is then used to update the
probabilities of diagnoses using the Equation 5. Since D1 and D2 predicted this answer,
their probabilities are updated, p(D1) = p(D2) = 1/p(X2 = 1) = 0.5. The probabilities of diagnoses D3 and D4 which are rejected by the outcome are also updated,
p(D3) = p(D4) = 0.

On the next iteration the algorithm recomputes the scores using the updated proba-
bilities. The results show that X1 is the best query. The other two queries X2 and X3 are
irrelevant since no information will be gained if they are performed. Given the negative
feedback of an oracle to X1, we update the probabilities p(D1) = 1 and p(D2) = 0. In
this case the target diagnosis D1 was identified using the same number of steps as the
split-in-half heuristic.
However, if the first axiom is more likely to fail, e.g. p(ax 1) = 0.025, then the first
query will be X1 : {B(w)} (see Table 5). The recalculation of the probabilities given
the negative outcome X1 = 0 sets p(D1) = 1 and p(D2) = p(D3) = p(D4) = 0.
Therefore the debugger identifies the target diagnosis only in one step.
Example 2 (continued). Suppose that in ax 4 the user specified s.A instead of s.A
and s.M3 instead of s.M3 in ax 2. Therefore D4 is the target diagnosis. More-
over, the debugger is provided with observations of three types of failures: (1) conjunc-
tion/disjunction occurs with probability p1 = 0.001, (2) negation p2 = 0.01, and (3)
restrictions p3 = 0.05. Using the probability addition rule for non-mutually exclusive
events we can calculate the probability of the axioms containing an error: p(ax 1) =
0.0019, p(ax 2) = 0.1074, p(ax 3) = 0.012, p(ax 4) = 0.051, and p(ax 5) = 0.001.
These probabilities are exploited to calculate the prior probabilities of the diagnoses
(see Table 6) and to initialize the query selection process.
On the first iteration the algorithm determines that X3 is the best query and asks an
oracle whether Ot |= M1  B is true or not (see Table 7). The obtained information is
then used to recalculate the probabilities of the diagnoses and to compute the next best

D  getDiagnoses(HS-Tree(O, B  T
DS  computeDataSet(DS, D);
DP  computePriors(D, F P );

DP  uptateProbablities(DP, DS, T
s  getMinimalScore(DS, DP );
X, DX, D
if getAnswer(Ot |= X) then T
|=  T
else T

  selectQuery(DS, s);

|=  X;

|=  T

X

|=  X;

|=, T

|=, n));

|=, T

|=);

K. Shchekotykhin and G. Friedrich

Algorithm 1. Ontology debugging algorithm
Input: ontology O, set of background axioms B, set of fault probabilities for axioms F P ,
maximum number of most probable minimal diagnoses n, acceptance threshold 
Output: a diagnosis D
1 DP  ; DS  ; T
2 while belowThreshold(DP, )  s = 1 do

|=  ; D  ; s  0;

|=  ; T

11 return mostProbableDiagnosis(D, DP );
query X4, and so on. The query process stops after the third query, since D4 is the only
diagnosis that has the probability p(D4) > 0.
Given the feedback of the oracle X4 = 1 for the second query, the updated probabilities of the diagnoses show that the target diagnosis has a probability of p(D4) = 0.9918
whereas p(D3) is only 0.0082. In order to reduce the number of queries a user can specify a threshold, e.g.  = 0.95. If the probability of some diagnosis is greater than this
threshold, the query process stops and returns the most probable diagnosis. Note, that
even after the first answer X3 = 1 the most probable diagnosis D3 is three times more
likely than the second most probable diagnosis D1. Given such a great difference we
could suggest to stop the query process after the first answer. Thus, in this example the
debugger requires less queries than the split-in-half heuristic.

4 Implementation Details
The ontology debugger (Algorithm 1) takes an ontology O as input. Optionally, a user
can provide a set of axioms B that are known to be correct, a set F P of fault probabilities for axioms ax i  O, a maximum number n of most probable minimal diagnoses
that should be considered by the algorithm, and a diagnosis acceptance threshold .
The fault probabilities of axioms are computed as described by exploiting knowledge
about typical user errors. Parameters n and  are used to speed up the computations. In
Algorithm 1 we approximate the set of the n most probable diagnoses with the set of
the n most probable minimal diagnoses, i.e. we neglect non-minimal diagnoses which
are more probable than some minimal ones. This approximation is correct, under a
reasonable assumption that probability of each axiom p(ax i) < 0.5. In this case for
every non-minimal diagnosis N D, a minimal diagnosis D  N D exists which from
Equation 2 is more probable than N D. Consequently the query selection algorithm operates on the set of minimal diagnoses instead of all diagnoses (including non-minimal
ones). However, the algorithm can be adapted with moderate effort to also consider
non-minimal diagnoses.
?

?

?
We implemented the computation of diagnoses following the approach proposed by
Friedrich et al. [3]. The authors employ the combination of two algorithms, QUICKXPLAIN [5] and HS-TREE [11]. The latter is a search algorithm that takes an ontology
O, a set of correct axioms, a set of axioms T
|= which must not be implied by the target
ontology, and the maximal number of most probable minimal diagnoses n as an input.
HS-TREE implements a breadth-first search strategy to compute a set of minimal hitting sets from the set of all minimal conflicts in O. As suggested in [3] it ignores all
branches of the search tree that correspond to hitting sets inconsistent with at least one
|=. HS-TREE terminates if either it identifies the n most probable minimal
element of T
diagnoses or there are no further diagnoses which are more probable than the already
computed ones. Note, HS-TREE often calculates only a small number of minimal conflict sets in order to generate the n most probable minimal hitting sets (i.e. minimal
diagnoses), since only a subset of all minimal diagnoses is required.

The search algorithm computes minimal conflicts using QUICKXPLAIN. This algo-
rithm, given a set of axioms AX and a set of correct axioms B returns a minimal conflict
set CS  AX, or  if axioms AX  B are consistent. Minimal conflicts are computed
on-demand by HS-TREE while exploring the search space. The set of minimal hitting
sets returned by HS-TREE is used by GETDIAGNOSES to create a set D with at most n
minimal diagnoses.
At the beginning of the main loop the algorithm calls COMPUTEDATASET function
to generate a set of ontologies O : {Oi} for each diagnosis Di  D by removing all
elements of a diagnosis from O. The algorithm uses this set to generate data sets like
the ones presented in Tables 2 and 3. For each ontology Oi  O the algorithm gets a set
of entailments from the reasoner and associates them with the corresponding diagnosis
Di. The algorithm uses the set of diagnoses/entailments pairs to compute the set of
queries. For each query Xi it partitions the set D into DXi, DXi and D
i , as defined
in Section 2. Then Xi is iteratively reduced by applying QUICKXPLAIN such that sets
DXi and DXi are preserved.

In the next step COMPUTEPRIORS computes prior probabilities for a set of diagnoses
given the fault probabilities of the axioms contained in F P . To take past answers into
account the algorithm updates the prior probabilities of the diagnoses by evaluating
Equation 5 for each diagnosis in D (UPDATEPROBABILITIES). All data required for the
update is stored in sets DS, T

|=, and T

|=.

The function GETMINIMALSCORE evaluates the scoring function (Equation 3) for

each element of DS and returns the minimal score.

X, DX, DX

In the query-selection phase the algorithm selects a set of axioms that should be

evaluated by an oracle. SELECTQUERY retrieves a triple
corresponds to the best (minimal) score s. The set of axioms X is then presented to the
oracle. If there are multiple queries with a minimal score SELECTQUERY returns the
triple where X has the smallest cardinality in order to reduce the answering effort.
|= or T
|=.
This is done to exclude corresponding diagnoses from the results of HS-TREE in further
iterations. Note, the algorithm can be easily extended to allow the oracle to reject a
query if the answer is unknown. In this case the algorithm proceeds with the next best
query until no further queries are available.

Depending on the answer of the oracle, the algorithm extends either set T
?

?

?
  DS that

K. Shchekotykhin and G. Friedrich

The algorithm stops if there is a diagnosis probability above the acceptance threshold
 or if no query can be used to differentiate between the remaining diagnoses (i.e. all
scores are 1). The most probable diagnosis is then returned to the user. If it is impossible
to differentiate between a number of highly probable minimal diagnoses, the algorithm
returns a set that includes all of them.

5 Evaluation

The evaluation of our approach was performed using generated examples and realworld ontologies presented in Table 1. We employed generated examples to perform
controlled experiments where the number of minimal diagnoses and their cardinality
could be varied to make the identification of the target diagnosis more difficult. The
main goal of the experiment using ontologies is to demonstrate applicability of our
approach in the real-world settings.

For the first test we created a generator which takes a consistent and coherent on-
tology, a set of fault patterns together with their probabilities, the minimum number
of minimal diagnoses m, and the required minimum cardinality of these minimal diagnoses |Dt| as inputs. The output was an alteration of the input ontology for which
at least the given number of minimal diagnoses with the required cardinality exist. In
order to introduce inconsistencies and incoherences, the generator applied fault patterns
randomly to the input ontology depending on their probabilities.

In this experiment we took five fault patterns from a case study reported by Rector at
al. [10] and assigned fault probabilities according to their observations of typical user
errors. Thus we assumed that in cases (a) and (b) (see Section 2, when an axiom includes
some roles (i.e. property assertions), axiom descriptions are faulty with a probability of
0.025, in cases (c) and (d) 0.01 and in case (e) 0.001. In each iteration the generator
randomly selected an axiom to be altered and applied a fault pattern to this axiom. Next
it selected another axiom using the concept taxonomy and altered it correspondingly to
introduce an incoherency/inconsistency. The fault patterns were randomly selected in
each step using the probabilities given above.
For instance, given the description of a randomly selected concept A and the fault
pattern misuse of negation, we added the construct "X to the description of A,
where X is a new concept name. Next, we randomly selected concepts B and S such
that S  A and S  B and added "X to the description of B. During the generation process, we applied the HS-TREE algorithm after each introduction of a in-
coherency/inconsistency to control two parameters: the minimum number of minimal
diagnoses in the ontology and their minimum cardinality. The generator continued to introduce incoherences/inconsistencies until the specified parameter values were reached.
For instance, if the minimum number of minimal diagnoses equals to m = 6 and their
cardinality to |Dt| = 4, then the generated ontology will include at least 6 diagnoses of
cardinality 4 and some additional number of diagnoses of higher cardinalities.

The resulting faulty ontology as well as the fault patterns and their probabilities
were inputs for the ontology debugger. The acceptance threshold  was set to 0.95 and
the number of most probable minimal diagnoses n was set to 12. One of the minimal
diagnoses with the required cardinality was randomly selected as the target diagnosis.
?

?

?
s
e
i
r
e
u
q
d
e
r
i
u
q
e
?

?

?
Required number of minimal diagnoses in a faulty ontology 

Entropy-based: 

Random
|Dt|=2                |Dt|=4              

Split-in-half

|Dt|=8

Fig. 2. Number of queries required to select the target diagnosis Dt with threshold  = 0.95.
Random and split-in-half are shown for the cardinality of minimal diagnoses |Dt| = 2.

Note, the target ontology is not equal to the original ontology, but rather is a corrected
version of the altered one, in which the faulty axioms were repaired by replacing them
with their original (correct) versions according to the target diagnosis. The tests were
done on ontologies bike2 to bike9, bcs3, galen and galen2 from Racers benchmark
suite1.

The average results of the evaluation performed on each test suite (depicted in Fig. 2)
show that the entropy-based approach outperforms the split-in-half method described
in Section 2 as well as random query selection by more than 50% for the |Dt| = 2 case
due to its ability to estimate the probabilities of diagnoses. On average the algorithm
required 8 seconds to generate a query. Figure 2 also shows that the cardinality of the
target diagnosis increases as the number of required queries increases. This holds for the
random and split-in-half methods (not depicted) as well. However, the entropy-based
approach is still better than the split-in-half method even for diagnoses with increasing
cardinality. The approach required more queries to discriminate between high cardinality diagnoses because the prior probabilities of these diagnoses tend to converge.

In the tests performed on the real-world ontologies we initialized the input parameters
n and  of Algorithm 1 with the same values as in the test with generated examples.
Also we used the same five fault patterns together with their probabilities as given above.
Before the experiment each ontology was analyzed by the HS-TREE algorithm and all
minimal diagnoses of these ontologies were identified. In each test for a given ontology
we selected randomly one of its minimal diagnoses as the target one and applied our
approach using both split-in-half and entropy-based strategies. The evaluation of queries
was done automatically by verifying if a query is also entailed by the target ontology
obtained by removing all axioms of the target diagnosis from the input ontology. For

1 http://www.racer-systems.com/products/download/benchmark.phtml

K. Shchekotykhin and G. Friedrich

Table 8. Number of queries required to identify a target diagnosis

Split-in-half

Entropy-based

Ontology
1. Chemical
2.
Sweet-JPL
3. University
4. Tambis
5. Economy
6. Transport

min max
?

?

?
avg min max
?

?

?
avg
?

?

?
Table 9. Time in seconds required to calculate 12 first and all minimal diagnoses as well as an
average time used to generate a query

Ontology

Diagnoses
all

1,39
0,97
36,47
Sweet-JPL 31,97
0,27
0,61
286,11
80,29
55,70
8,33
6,70
99,02

1. Chemical
2.
3. University
4. Tambis
5. Economy
6. Transport

Query
avg
1,50
5,48
1,12
3,91
1,87
2,39

each ontology we performed 20 tests and on each iteration the target diagnosis was
randomly reselected.

The results of this experiment are presented in Tables 8 and 9 and show that in terms
of queries, the entropy-based approach outperformed split-in-half. As the number of
diagnoses grew we observed that the difference between the two strategies increased.
In the best case for the entropy-based strategy, when the target diagnoses were assigned
a high a-priori fault probability, the number of queries was usually twice as low as
required by the split-in-half strategy. Also in the worst case, when the target diagnoses
were assigned a low a-priori fault probability, the entropy-based strategy performed
better than split-in-half, because it was able to adapt the a-posteriori fault probabilities
using Bayes rule and the oracles feedback to queries. In this case the entropy-based
strategy corresponds to active learning [14] applied to learn fault probabilities which
is not exploited in the split-in-half strategy. The more queries are asked, the better the
entropy-based method can predict the target diagnosis.

6 Related Work

To the best of our knowledge no sequential ontology debugging methods (neither employing split-in-half nor entropy-based methods) have been proposed to debug faulty
ontologies so far. Diagnosis methods for ontologies are introduced in [13,6,3]. Ranking
of diagnoses and proposing a target diagnosis is presented in [7]. This method uses a
number of measures such as: (a) the frequency with which an axiom appears in conflict
sets, (b) impact on an ontology in terms of its lost entailments when some axiom is
modified or removed, (c) ranking of test cases, (d) provenance information about the
?

?

?
axiom, and (e) syntactic relevance. All these measures are evaluated for each axiom in
a conflict set. The scores are then combined in a rank value which is associated with the
corresponding axiom. These ranks are then used by a modified HS-TREE algorithm that
identifies diagnoses with a minimal rank. In this work no query generation and selection
strategy is proposed if the target diagnosis cannot be determined reliably with the given
a-priori knowledge. In our work additional information is acquired until the target diagnosis can be identified with confidence. In general, the work of [7] can be combined
with the one presented in this paper as axiom ranks can be taken into account together
with other observations while calculating the prior probabilities of the diagnoses.

The idea of selecting the next best query based on the expected entropy was exploited
in the generation of decisions trees [9] and further refined for selecting measurements in
the model-based diagnosis of circuits [8]. We extended these methods to query selection
in the domain of ontology debugging.

7 Conclusions

In this paper we presented an approach to the sequential diagnosis of ontologies. We
showed that the axioms generated by classification and realization can be used to build
queries which differentiate between diagnoses. To rank the utility of these queries we
employ knowledge about typical user errors in ontology axioms. Based on the likelihood
of an ontology axi om containing an error we predict the information gain produced by a
query result, enabling us to select the next best query according to a one-step-lookahead
entropy-based scoring function. We outlined the implementation of a sequential debugging algorithm and compared our proposed method with a split-in-half strategy. Our
experiments showed a significant reduction in the number of queries required to identify the target diagnosis.
