ISReal: An Open Platform for Semantic-Based

3D Simulations in the 3D Internet

Patrick Kapahnke, Pascal Liedtke, Stefan Nesbigall,

Stefan Warwas, and Matthias Klusch

German Research Center for Artificial Intelligence, Saarbr ucken, Germany

firstname.surname@dfki.de

Abstract. We present the first open and cross-disciplinary 3D Internet
research platform, called ISReal, for intelligent 3D simulation of real-
ities. Its core innovation is the comprehensively integrated application
of semantic Web technologies, semantic services, intelligent agents, verification and 3D graphics for this purpose. In this paper, we focus on
the interplay between its components for semantic XML3D scene query
processing and semantic 3D animation service handling, as well as the
semantic-based perception and action planning with coupled semantic
service composition by agent-controlled avatars in a virtual world. We
demonstrate the use of the implemented platform for semantic-based 3D
simulations in a small virtual world example with an intelligent user
avatar and discuss results of the platform performance evaluation.

1 Introduction

In the Internet of today, navigation and display of content mostly remains two-
dimensional. On the other hand, the proliferation of advanced 3D graphics for
multi-player online games, affordable networked high-definition display and augmented reality devices let Internet users increasingly become accustomed to and
expect high-quality 3D imagery and immersive online experience. The 3D Internet (3DI) is the set of 3D virtual and mixed reality worlds in the Internet
that users can immersively experience, use and share with others for various
applications [25,5,2,31].

As of today, the 3DI offers, for example, various alternative worlds like SecondLife (2L)1, questville, Croquet and WorldOfWarcraft, and mirror worlds like
Twinity2. Applications include socializing and business collaboration in 3D meeting spaces, the 3D exploration of virtual cities, the participation in cross-media
edutainment events like concerts and lectures, the trading of real and virtual
assets, the functional 3D simulation of production lines and architecture at design time, as well as advanced visual 3D information search by using 3D Web

 The work presented in this paper has been partially funded by the German Ministry

for Education and Research (BMB+F) under project grant 01IWO8005 (ISReal).

1 http://secondlife.com
2 http://www.twinity.com

P.F. Patel-Schneider et al.(Eds.): ISWC 2010, Part II, LNCS 6497, pp. 161176, 2010.
c Springer-Verlag Berlin Heidelberg 2010

P. Kapahnke et al.

browsers such as SpaceTime and ExitReality. In such virtual worlds, the user
is usually represented by and driving the behavior of an avatar as her digital
alter-ego.

Major challenges of the 3DI are (a) the more realistic, standard-based 3D
graphical display in 3D Web browsers, and (b) the making of user avatars behave more intelligent in their 3D environment. For example, the intelligence
of most avatars in virtual worlds today is either restricted to direct execution
of non-verbal user commands, or rather simple event-rule-based but resourceoptimized means of AI planning with massive volumes of action scripts in online
games. Besides, in most cases, avatars are not even capable of understanding the
semantics of their perceived 3D environment due to the lack of standard-based
semantic annotations of 3D scenes and reasoning upon them or do not exploit
3D scene semantics for intelligent action planning in a virtual world they are
involved in.

To address these challenges, we developed the first open, cross-disciplinary
3DI research platform, called ISReal, that integrates semantic Web, semantic
services, agents and 3D graphics for intelligent 3D simulation of realities. In this
paper, we describe the innovative interplay between its components with focus
on semantic 3D scene annotation and query processing, and the semantic-based
action planning of intelligent agent-controlled avatars together with a discussion
of our experimental performance evaluation of the platform in a simple virtual
3D world. To the best of our knowledge, there is no other such integrated 3DI
platform available yet.3

The remainder of the paper is structured as follows. Section 2 provides an
overview of the ISReal platform while sections 3 and 4 describe the global semantics and intelligent agents for semantic-based 3D simulation. Section 5 demonstrates the use of the platform for a simple use case, followed by performance
evaluation results and comments on related work in Sections 7 and 8.

2 ISReal Platform: Overview

Virtual world descriptions in XML3D. The ISReal platform can be used to
develop and simulate virtual worlds in XML3D4 which is a 3D graphics-oriented
extension of HTML4. A virtual world scene is graphically described in form of
a single XML3D scene graph that includes all objects of the 3D scene to be
displayed as its nodes. In contrast to X3D5, XML3D scene descriptions can be
directly embedded into a standard HTML page such that every scene object
becomes part of and accessible in the standard HTML-DOM (Document Object
Model) by any XML3D-compliant Web browser capable of rendering the scene
without any specific viewer plug-in required. Graphical changes in the virtual

3 Major barriers of an 3DI uptake by people today refer to its potential physio-
cognitive, social and economic impacts on individual users of virtual worlds which
discussion is outside the scope of this paper.

4 http://www.xml3d.org
5 http://www.web3d.org/x3d/specifications/
?

?

?
Fig. 1. ISReal platform components

world during its simulation such as user interactions with the scene and 3D object
animation in the browser correspond to changes of its XML3D scene graph in
the Web page of the virtual world scene which is loaded and processed by the
ISReal client. In the following, we give an overview of the platform components
and its communication architecture for virtual 3D world simulations.
Platform Components. The ISReal platform consists of five groups of components that are the user interface, the global semantics, 3D graphics, intelligent agents and verification environment (see Fig. 1). The graphics environment
maintains the given set of XML3D scene graphs of virtual worlds by its internal
RTSG-2 (real-time scene graph) system [24] and renders them by a pluged-in
3D rendering engine for high-quality 3D display such as our world-fastest raytracer RTFact [9] at run time. For immersive 3D interaction with simulated
virtual worlds, it additionally provides an open, immersive VR (virtual reality)
system. The global semantics environment (GSE) is responsible for managing
global scene ontologies each of which describing the semantics of a virtual world
in its application domain as well as the execution handling of globally registered
semantic services which groundings have an effect on these ontologies such as
the change of the position of some object in the scene by the respective 3D
animation in the graphics environment (cf. Section 3). The verification environment manages and composes hybrid automata that describe spatial and temporal
properties of scene objects and their interactions and verifies them against given
safety requirements at design time; for reasons of space, we omit a description of
this platform component. The semantic world model of the platform is the set of
semantically annotated 3D scene graphs with references to the global semantics
and the verification component. The agent environment manages the avatarcontrolling intelligent agents capable of scene perception, local scene ontology
management and semantic-based action planning to accomplish its tasks given

P. Kapahnke et al.

Fig. 2. ISReal v1.1 communication architecture for virtual 3D world simulations

by the user or other agents (cf. Section 4). Finally, the user can interact with a 3D
simulated virtual world scene by alternative means of 3D Web-based or immersive 3D virtual reality system-based user interface of the platform. The interface
is either of both XML3D-compliant versions of Google Chrome and Mozilla Firefox browsers or an immersive VR environment based on the open VR system
Lightning (which we connected with multi-touch display, space mouse, tracking
system and iPhone as 3D input devices). A user can (non-verbally) query the
semantics of marked single objects in the simulated scene with or without her
avatar, and to command her avatar to answer complex semantic queries and to
pursue given tasks in the scene.
Communication Architecture for Virtual 3D World Simulation. The
client-server-based communication architecture of the ISReal platform 1.1 for
single-user virtual 3D world simulation is shown in Figure 2.

The ISReal client is exclusively responsible for maintaining and rendering
the complete virtual world scene with its embedded 3D graphics environment,
and communicates with the ISReal server hosting all other components (and
a Web server, in case of XML3D browser as ISReal client) for intelligent sim-
ulation. Asynchronous and bidirectional client-server communication is impemented by use of the WebSockets API6. Once the initial world scene page in
HTML/XML3D is loaded by the ISReal client from the ISReal server, the client
connects to server-sided components, triggers the scene-relevant configuration of

6 http://dev.w3.org/html5/websockets/
?

?

?
semantics and agents at the server, and is responsible for user-interaction-based
updates and rendering of the XML3D scene graph (Web-based or immersive
3D).7 The open ISReal platform in its current version 1.1 has been fully implemented in Java and JavaScript.

3 ISReal Global Semantics

Semantic-based 3D simulation of virtual worlds is a key feature of the ISReal
platform. In this section, we describe the semantic annotation of 3D scene objects
and the global semantics environment of the platform in more detail.

3.1 Semantic 3D Scene Object Annotation

The semantic world model of the platform is the set of all semantically annotated
XML3D scene graphs for simulated virtual worlds. Any 3D scene object in a
virtual world is represented as a node of the XML3D scene graph that graphically
describes this world. The semantics of a 3D scene object can be described by
annotating its XML3D scene graph node by use of standard RDFa8 with links
to (a) the uniquely assigned object in a given global scene ontology described in
(the OWL-Horst fragment of) standard OWL2 that represents the conceptual
and assertional knowledge about the scene and application domain, (b) semantic
services in OWL-S that describe the operational functionality of the scene object
and are grounded in respective 3D animation scripts, and (c) hybrid automata
that describe object properties with respect to continuous time and space in
FOL linear arithmetics.

Figure 3 shows an example of semantic annotation of a virtual worlds scene
object, that is a door connecting room A with room B. The representation
of this object in the XML3D scene graph refers to a node labeled doorAB
that includes its graphical description and semantic annotation. The first case
refers to the 3D geometry (mesh) data required for rendering the scene object doorAB as defined in its respective subnode. The semantic annotation of
the doorAB node is in RDFa with references to (a) an uniquely assigned object doorAB which semantics is defined in a given global scene ontology, (b)
a set of semantic services describing the opening and closing of doorAB each
of which grounded with an appropriate 3D animation script to be executed by
the graphics environment, and (c) a hybrid automaton describing the temporalspatial property that doorAB can be opened and closed with angular speed of
10 degrees per second, which is not possible to encode and reason upon in OWL2.
Both the given global ontology and semantic object services are maintained in
the global semantics environment of the ISReal platform.

7 We are working on a multi-user/server architecture where the ISReal server maintains the global scene graph and provides multiple clients with only update instructions of how to change and render their local views on the scene based on user
interaction events.

8 The same principle of semantic annotation can be applied to X3D scene graphs as

well. For a discussion of the benefits of XML3D over X3D, we refer to [27].

P. Kapahnke et al.

Fig. 3. Example of semantic annotation of a XML3D scene graph object with RDFa

3.2 Global Semantics Environment

Architecture. The global semantics environment (GSE) consists of two components as shown in Figure 4, that are the global ontology management system
(OMS) and the semantic service handler (SemSH). The OMS maintains a given
set of global ontologies each of which describing the conceptual (TBox) and factual (ABox, fact base) knowledge about one simulated virtual world in OWL2. It
handles the processing of different types of semantic queries issued by the user or
agents against the global ontology of the actually simulated virtual world9. We
assume that the TBox of the global ontology, in contrast to its ABox, does not
change during simulation. The selected global scene ontology is materialized in,
updated and queried through a selected RDF store of the OMS as usual. Other
semantic queries (which answering is not possible by triple stores) are routed
by the OMS query decider to the appropriate semantic reasoner(s) depending
on its type or indicated by the user. The SemSH maintains the global semantic
service repository that is assumed to contain all services in OWL-S which are
related to the global scene ontology in terms of having either a precondition to
be checked against its fact base, a grounding that may update the fact base as
an effect, or both.

9 In the following, we focus on the global ontology of one virtual world.
?

?

?
Fig. 4. Architecture of the global semantics environment (GSE)

Implementation. The implemented GSE has two architectural key features.
First, its OMS has an open plug-in (API) architecture for using any RDF/S store
and semantic reasoner as appropriate and is realized with the LarKC platform10.
The OMS query decider routes semantic queries to OMS plug-ins available for
the RDF triple stores SwiftOLIM (with RDF materialization of OWL2 under
OWL-Horst semantics) and AllegroGraph, the semantic OWL-DL reasoner Pellet11 with internal Jena RDF store, and the RDF relational reasoner STAR[14].
Second, semantic query answering and service handling by the GSE is upon
request only, in particular, the GSE does not actively communicate semantic
updates of the global ontology to other components; this avoids communication
bottleneck and supports the paradigm of perception-based knowledge for BDI
agents (cf. Section 4).
Semantic 3D Scene Query Processing. As a result of its open plug-in ar-
chitecture, the types of semantic queries the OMS is capable of answering depends on the respective functionality of its plug-ins for triple stores and semantic
reasoners. For example, the OMS can (a) efficiently answer object (and OWLHorst concept) queries with its RDF store SwiftOWLIM using SPARQL, (b)
more complex (OWL2-DL) concept queries with Pellet using SPARQL-DL, and
(c) relational object queries with STAR. For example, a relational object query
like How are scene objects doorAB, doorBC and roomC related ? is processed
by STAR by reduction to the corresponding NP-hard Steiner-Tree problem for
the RDF graph of the materialized global ontology followed by the polynomial
computation of an approximated solution in O(nlogn) in terms of minimal RDF

10 http://www.larkc.eu/resources/
11 http://clarkparsia.com/pellet
