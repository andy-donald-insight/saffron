A Case Study of Linked Enterprise Data

Bo Hu1 and Glenn Svensson2

1 SAP Research

2 BTS EMEA, SAP AG

{bo01.hu,glenn.svensson}@sap.com

Abstract. Even though its adoption in the enterprise environment lags
behind the public domain, semantic (web) technologies, more recently
the linked data initiative, started to penetrate into business domain with
more and more people recognising the benefit of such technologies. An
evident advantage of leveraging semantic technologies is the integration
of distributed data sets that benefit companies with a great return of
value. Enterprise data, however, present significantly different characteristics from public data on the Internet. These differences are evident in
both technical and managerial perspectives. This paper reports a pilot
study, carried out in an international organisation, aiming to provide a
collaborative workspace for fast and low-overhead data sharing and inte-
gration. We believe that the design considerations, study outcomes, and
learnt lessons can help making decisions of whether and how one should
adopt semantic technologies in similar contexts.

1 Introduction

Thus far, the Linked Data (LD) initiative has demonstrated its value through a
variety of projects aiming at improving data accessibility for primarily public and
academic users [2]. The success stories certainly have not slipped the attention of
large enterprises. Cautious attempts were made to experiment the LD principles
and to evaluate the benefits, leading to the so-called linked enterprise data
paradigm, the counterpart of LD in the business domain [14].

The motivation behind linking enterprise data is evident. Nowadays, with the
deepening of globalisation, more and more non-mission-critical businesses are
outsourced away from the home countries to for example design teams in Eu-
rope, manufacturers in China and service support in India. Fluctuation and risk
in local markets, especially volatile ones, therefore becomes more manifested at
the global level. This phenomenon has drawn more attention to business agility
and continuity, a common ingredient of both being the easy access to data facilitating coordination and collaboration across different geographical locations.
Businesses must be able to optimise their internal enterprise data landscape
and explore such a landscape at the speed of thought so as to react to the
rapidly changing market. Executives must be timely and comprehensively informed so that they can make decisions to counteract the threats to business
revenue. More importantly, everyone needs to have ready and immediate access
to information/data that enable her to carry out the allocated tasks.

P.F. Patel-Schneider et al.(Eds.): ISWC 2010, Part II, LNCS 6497, pp. 129144, 2010.
c Springer-Verlag Berlin Heidelberg 2010

B. Hu and G. Svensson

Accessing data in an enterprise context, though not a new research area, is
not a topic that we can comfortably mark as solved [10]. Enterprise data management has become a prevalent challenge with the rapidly plummeted storage
and digitising cost resulting in an unprecedent amount of artefacts available
in electronic form1. Linked Data initiative was proposed to deal with exactly
this problem in the public domain, i.e. removing the barriers to data access
and sharing. Intuitively, it seemed that we can just borrow the concepts having been so successfully implemented and recreate the stories in the enterprise
environment. Our experience, however, prove otherwise. Indeed, enterprise data
has many characteristics that resemble the data from public domains [6]. It, at
the same time, presents unique requirements that put into test the principles
and assumptions that are widely enjoyed when linking public data sets. The
differences are demonstrated in the following aspects. Firstly, enterprise data
is normally tied closely with the business processes. Peeling off the contexts
wherein the use of such data takes place might render the data linking effort less
fruitful. Secondly, it becomes increasingly important to link to data sets outside
organisational boundaries. This is evident in use cases such as supply chain management and pre-sale where data from public domain significantly enrich internal
data sets. We, therefore, see a mixture of public, partner, and proprietary data
complicating data transparency and accessibility. To our best knowledge, none
of the existing efforts have addressed the process driven requirement unique to
enterprise data.

Inspired by the misalignment between the requirements of enterprise data and
existing LD efforts, we carry out studies with real users to investigate how the
linked data principles and concepts can assist customer account executives and
team members when they need comprehensive and real-time access to internal
and external data sets. We first elaborate on the differences (Section 2) between
enterprise data and public data. Bearing these differences in mind, we discuss
certain design considerations and the system architecture in the context of a
customer information portal (CIP) project (Section 3). This is followed by three
real-life use cases demonstrating the value of CIP (Section 4). We then discuss
the lessons learnt (Section 5) and conclude the paper in Section 6.

2 Why Corporate Data Is Different?

As a collaborative and international effort, Linked Data has gained good publicity in the academic and to some extent the public sector communities [2].
With all the exciting success stories of massive development effort in linked data
projects, we now face the question regarding the applicability of linked data
principles in the corporate sub-domain.

It is evident that enterprise data lend themselves as both an opportunity and
a challenge. On the one hand, enterprise data have well-defined boundaries with
rigid protocols regulating the transition across the boundaries. They present
less heterogeneity and diversity comparing with public data from the Internet.

1 http://www.thegoldensource.com/component/attachments/download/36
?

?

?
Furthermore, even though divided into different departments focusing on different areas, modern enterprise normally reinforces a common corporate culture,
which fosters a common, shared corporate language, i.e. domain vocabulary.
In many cases, this vocabulary may even impinge on communities beyond corporate boundaries. A good example is the jargons and acronyms used by the
global SAP customer network. Finally, enterprise data are normally well documented and preserved either formally as white-papers, official publications, etc.
or informally in e-mails, task log data, wiki pages, etc. Different from public data
from the Internet, enterprise data are normally subject to internal review, for
the purpose of auditing and quality control, or, at minimum, created with good
intentions to fellow workers. We can therefore enjoy a much smaller amount of
noise compared to general public data.

On the other hand, enterprise data still present significant research challenges.
Simply connecting different islands together in an archipelagic data landscape
will not be convincing enough. Process-driven is a unique feature that one has
to bear in mind when migrating the LD concepts into the enterprise environment.
Meanwhile, the relatively small size and homogeneous nature of enterprise data
suggest that superficial connection of in-house data may not generate a good
enough business value. In many cases, internal data alone is not sufficiently rich
to satisfy diverse business requirements and thus incorporating external data
sources is inevitable. How and what data should be exploited, however, can only
stem from real-life scenarios. It is, therefore, salient to align with end users to
understand and demonstrate the return of value of linking enterprise data. We
will discuss these points further in this section.

2.1 Process-Driven

Currently, there are roughly two approaches to fulfill the LD vision, namely datadriven and community-driven. Data-driven starts with a set of core data and tries
to establish connections with as many relevant data sets as possible to emerge
patterns not possible to individual data sets alone, while community-driven tries
to fulfill the data request of a community, e.g. movie fans, gene researchers, etc.
Both approaches may find themselves struggling in the enterprise environments.
Data management in an enterprise environment always has one ultimate pur-
pose: improving the efficiency of a companys core business. However, linking
data together does not necessarily mean that the implications, with which data
are generated and leveraged, automatically become explicit to those linked in.
The business implications can only be understood when we situate data into their
original business processes. Therefore, different from the dominant data-driven
nature when linking data from the Internet, linking enterprise data demonstrates
a strong process-driven characteristic. That is the connections among data can
and should only be revealed within the context of business processes where such
data are consumed. Similarly, links among data should not be arbitrarily created
independent from business processes. Aligned with companies mission-critical
businesses, linking enterprise data from both inside and outside a company can
be rightfully leveraged in decision making.

B. Hu and G. Svensson

We would also argue that the successful community-driven approach (c.f. [16])
is not strictly applicable in the enterprise environments. Such communities are
normally self-organised by common interests and loosely regulated, mainly self-
disciplined. Misconduct and inappropriate behaviours do not result in the same
consequence as in enterprise environments. Meanwhile, members of the community are organised in a rather flat structure with equal access to resources, which
is a freedom that is not valid in companies. To the best interests of employees,
taking a process-driven approach to data linking therefore can guarantee the
alignment between personal interests and organisational policies.

2.2 External Data

At the beginning of the CIP project, our intuition was that in an international
organisation, the internal data alone should present enough challenges and offer
sufficient business value for the LD paradigm. This was proved partially wrong
during the discussion with end users. Internal data, although distributed across a
large geographical region, are well-regulated and to some extent aligned attribute
to common corporate cultures and operational regulations. Making internal data
compliant with LD principles is more an organisational and motivational effort
than a technical challenge.

The real challenge comes from defining good scenarios that can meaningfully link data together to satisfy needs of everyday businesses. For such a pur-
pose, internal data can only tell part of the story. Very frequently, employees
refer to external data sets for essential information that is not available from
within the corporate boundaries. For example, the latest volcanical ash disturbance resulted in changes of project execution, project management decisions,
and customer relationship management; natural disasters (e.g. the earthquake
in SiChuan Province, China) can lead to major changes in supply chain man-
agement. The importance of such external data will not be fully demonstrated
if they are not combined with internal enterprise data and consumed in realtime business decision making. The linking of public, partner and proprietary
data should conform to the following guidance. External data should not interfere with internal ones. Where conflict observed, organisational protocols should
be consulted to resolve the inconsistences. Meanwhile, it should follow existing
organisational policies: this again points back to the process-driven aspect.

2.3 Personal Space

The most controversial argument that we would like to put forward, which can
be deemed against the total openness of the LD initiative, is that when linking enterprise data, the personal comfortable zone in data sharing should be
respected. For organisations of different sizes, cultures, and structures, there is a
long standing tendency of information disintegration attribute to a lack of trust
in fellow workers, feeling of insecurity, and fear of disgrace [12]. We did not plan
to deal with such motivational issues. Rather we acknowledge the existence of
?

?

?
such barriers and try to accommodate user requirements that stem therefrom.
Obsering such a requirement allows users to more comfortably position themselves in data sharing initiatives. This is, however, done at the price of sacrificing
fundamental LD principles to a certain extent.

3 Customer Information Portal

The concept of linked enterprise data is materialised in a pilot study that is
meant to facilitate data integration and data sharing in a geographically distributed international organisation. When a company operates in more than one
locations, it is not surprised to find different regional representatives approaching the same customer with different stories. The representatives sometimes are
caught totally unprepared with questions regarding latest business and technical development and, even worse, regarding technical proposals and sales offers
made from other units or even within the same units. A simple and effective
remedy to such a problem is to create a portal for all the data concerning a
customer. It can serve as a briefing tool for any one working on a customer so
as to avoid the aforementioned embarrassment. We take advantage of the CIP
project as a platform for understanding benefits and constraints of applying LD
concepts in the enterprise environment.

3.1 Design Decisions

During the definition of this pilot project, we try to address the unique characteristics of enterprise data (as discussed in previous sections).

Process-driven is given particular emphasis. Projected on design decisions,
this implies the ability to answer what data should be accessed by whom at
what stage?. Based on business processes, one is prescribed to navigate the
internal resources, employee profiles, and external data only specified in the
business processes. Doing so will ensure that enterprise data are linked in line
with organisational policies and strategies. Business processes can be standard
ones or created for personal needs using predefined building blocks. We provide
a list of exemplary business processes that are modelled and executed using
in-house software (e.g. SAP Netweaver BPM) due to practical considerations.
The in-house software is well understood by all the end users that reduces the
learning curve. Meanwhile, in order to ensure a smooth integration with internal
data sets, we try to avoid unnecessary disturbance to the platforms wherein
such data sets are used. The in-house business process management system offers
adapters compliant with J2EE Connector Architecture2 and thus can seamlessly
integrate with Java-based semantic systems.

The privacy concerns are addressed by maintaining a clear separation between
data sets that are available to everyone and those that are only visible to the selected few. When creating an online article, a new business process, or uploading

2 http://java.sun.com/j2ee/connector/

B. Hu and G. Svensson

a document, people can opt-in to share or not share such resources. Effectively
this is tantamount to linking private data space with the public one. Regardless of whether or not the resources are made public, an excerpt is produced to
inform others of the contents.

We try to accommodate the general LD principles as followings. Using URI for
resource identification can be easily satisfiedall internal resources (including
documents and people) are uniquely identifiable through URIs. When this is not
the case, we annotate data sets with uniquely identifiable labels based on RDFcoded ontologies. Links among internal resources are implemented as ontology
properties among annotated resources. For internal data, syntactic and semantic mismatch does not present as a problem due to the existence of well-defined
common vocabularies normally exercised by large organisations. Semantic interoperability becomes more of an issue when linking to external data sets. We
adopt a simple but effective solution: embedding a Wikipedia link in concept
definition. For instance, the Course Wikipedia article (URI) is introduced as
a super-concept of concept Training Course. The benefit is seen in two aspects:
explanation and alignment. With links pointing to Wikipedia articles, we can
easily extract the natural language based explanation of a concept. This is, in
many cases, the first paragraph of the article. This explanation can be displayed
to human readers for better understanding of the concept. Nearly all end users
find this helpful. On the other hand, Wikipedia serves as a good reference point
for aligning external resources with internal ones, for instance, through DBPe-
dia. For those that are not currently covered by DBPedia, we leverage existing
ontology mapping tools [7].

RDF representation is used exclusively in the background. We would argue
that any efforts to make the underlying RDF representation transparent to the
end users are likely to create more questions than answers in an enterprise envi-
ronment. The following observations underpin our contentions. A majority of the
corporate users are not semantic-web minded. More precisely, they do not care
whether the data provision is facilitated by traditional technologies or semantic technologies, as long as data are provided in a timely and accurate manner.
Such end users are for instance executives, sales and pre-sale personnel, service
support and human resource. Understanding semantic technologies is certainly
not a competence that they intent to develop. Ironically, the end users who will
benefit from linked enterprise data is likely to enjoy such benefits only when the
semantic technologies totally disappear from the user interface. A direct design
consequence is that we had to improve user experience through good visualisation techniques (c.f. [4]) and RDF adaptors for conventional programming
languages (c.f. [15]) for intuitive RDF data manipulation.

3.2 System Architecture

CIP is a multiple-layered data/information integration platform (see Figure 1).
At the bottom, there is the Data Layer. We clearly distinguish data sources
that are only available to internal users and those in the public domain due to
?

?

?
Fig. 1. Customer Information Portal Architecture

data safety and privacy concerns. We also differentiate data that are properly
structured (e.g. databases), semi-structured (e.g. wiki pages, calendars, to-do
lists, etc.), and un-structured (e.g. e-mails, blogs, and legacy documents).

Structured data from internal sources are mapped directly to the ontologies
via for example manually/semi-automatically crafted D2RQ scripts3. Note that
semi-automatically identifying correspondences between database schemata and
ontologies is not a disadvantage. In our case, the internal databases are specialised for managing certain types of mission-critical data where consistence
and stability is observed. We do not expect the schemata to be frequently up-
dated/upgraded. Therefore, the DB2RDF mapping, once defined, has a knockon effect on data migration. On the other hand, data stored in such databases
capture critical information of the companys core business. In order to support
sensible and accurate decision making, such data have to be faithfully presented.
We evaluated several automatic database to ontology mapping toolkits and none
of them produced satisfactory results. Human intervention and verification is inevitable and, we believe, is more cost-effective if introduced in the early stage
of mapping. String similarity was leveraged to produce recommendations and
based on our experience string similarity or a combination of its variants is by
far the most effective method. We leverage DBpedia to align structured data

3 http://www4.wiwiss.fu-berlin.de/bizer/D2RQ/spec/

B. Hu and G. Svensson

Fig. 2. User landing page

from public domain. At this stage, structured public data exploited in CIP is
mainly Wikipedia infobox presenting basic facts of key customers, the partners
and competitors. Wikipedia can also provide semantic enhanced applications
(c.f. [5]). We plan to investigate the applicability of such technologies in the
next phase of this pilot.

Semi-structured data from both internal and external sources are processed
in two stages. First, the structured part is extracted. For instance, the dates,
locations and priority levels in Calenders are used to populate the ontology.
The free-text contents of such semi-structured data sets are feed into a keyword
extractor for shallow natural language processing. We use Gate [3] to create such
extractors.

Processed data are stored in a semantic repository and are consumed by a
business process management system residing in the integration layer. End users
of the CIP do not assume equal privilege of internal as well as external data sets.
What data sets should be linked is entirely decided by use cases and thus essentially driven by the business processes associated with the use cases. For
instance, if the use case is to establish new sales opportunities, one needs to access potentially full customer engagement history in the Customer Relationship
Management (CRM) data. On the other hand, if the use case is cost reduction,
one focuses on product life-cycle management data, supply-chain management
data, etc. Process driven is facilitated by providing predefined use cases at the
personal landing page (Figure 2) of the CIP tuned against ones profile (role,
area of working, professional responsibilities, etc.).

4 Use Cases

The value of linked enterprise data can only be fully appreciated if it supports
the real needs from end users. In the context of the CIP project, we carried out
workshops with different stake-holders to elicit their requests. Out of the discussion with end users, we identify a list of interesting web mashing up scenarios.
In this section, we elaborate on three exemplary ones.
?

?

?
4.1 Meeting the Customers

Nearly all the modern sales 101 courses emphasise on focusing on the prospects
point of view. Meeting with the prospects is always the best way to establish
mutual trust and to understand their needs. The information portal facilitates
this through linking external and internal data showing major events that the
prospect is likely to participate and how events overlay with internal events (from
e.g. internal event calendars).

Finding the prospects events presents a technical challenge. We tackled this in
the following steps. Firstly, we extract event information from the prospects home
page. Such pages can be easily found since almost all large enterprises maintain
event calendars of various details. With little variants, entries in the event calendars are normally in the form of Date, Type, (Location), Description and
can be easily processed with text analysis tools. The second data source is the recurrent past events identifiable in the internal customer engagement record. This
shows where positive contacts were established before and are likely to happen
in the future. Keywords from the past events (e.g. titles) are used to search and
retrieve the date and location of the next event in the series from the Internet.
We also identified several event portals as auxiliary data sources. Such portals are
domain specific and can only be identified on a per customer basis. For pharmaceutical industries, exemplary web portals include pharmiweb.com, pharmaceutical-
int.com, etc.

Data from the above three sources are used to create instances of the CIP
domain ontology. We define seven different event types, namely conferences, ex-
hibitions, trade fairs/expos, media/press events, training courses, unconferences,
and the unspecified, while Unspecified is used to collect those of unknown or unconcerned types. Equation 1 is fragments of event type Training Course: where
Coursewpd refers to the corresponding Wikipedia article via its URL. Denoted
in Turtle notation4, an event instance is as follows:

<http://www.***.com/EventsCalendar.mvc/EventDetail/32831>

rdf:type #Training_Course ;
rdfs:label "GCP"^^xsd:string ;
#starts "07/06/2010"^^xsd:string ;
#ends "07/09/2010"^^xsd:string ;
#location "Costa Mesa"^^xsd:string ;
#participants #NovoNordisk , ... , #Pfizer ;
...

Training Course  Event  Coursewpd =1 starts.xs:date =1 ends.xs:date

 =1 location.xs:string
 participants.Organisation  . . .

(1)

We used simple domain heuristics to recognise types of events. In majority of the
cases, types of events are either explicitly specified (e.g. in AstraZeneca event

4 http://www.w3.org/TeamSubmission/turtle/
