Summary Models for Routing Keywords to

Linked Data Sources

Thanh Tran, Lei Zhang, and Rudi Studer

Institute AIFB, Karlsruhe Institute of Technology, Germany

{dtr,lzh,studer}@kit.edu

Abstract. The proliferation of linked data on the Web paves the way
to a new generation of applications that exploit heterogeneous data from
different sources. However, because this Web of data is large and continuously evolving, it is non-trivial to identify the relevant link data sources
and to express some given information needs as structured queries against
these sources. In this work, we allow users to express needs in terms of
simple keywords. Given the keywords, we define the problem of finding
the relevant sources as the one of keyword query routing. As a solu-
tion, we present a family of summary models, which compactly represents the Web of linked data and allows to quickly find relevant sources.
The proposed models capture information at different levels, representing summaries of varying granularity. They represent different trade-offs
between effectiveness and efficiency. We provide a theoretical analysis
of these trade-offs and also, verify them in experiments carried out in a
real-world setting using more than 150 publicly available datasets.

1 Introduction

The Web is no longer only a collection of textual documents but also a Web of
linked data. One prominent project which largely contributes to this development
is the Linking Open Data project. Collectively, linked data comprises hundreds
of sources containing over 13.1 billions RDF triples, which are connected by 142
millions links (November 2009, http://linkeddata.org/).

This development offers new opportunities for addressing complex information
needs. Instead of documents, complex results ranging over different sources of
linked data can be returned to Web users. To exploit this, users can specify
complex queries using structured query languages such as SPARQL1. While
such a query language is powerful, it requires users to know not only the query
syntax and semantics but also the schema as well as the underlying data.
Problem. So far, these requirements have proven to be a large burden. Given
the amount of linked data is large and continuously evolving, it is inherently
difficult to know what is in there (i.e., the data and the schema) and to formulate the corresponding structured queries for addressing some given information
needs. Hence, it is desirable to have a mechanism, which allows users to express

http://www.w3.org/TR/rdf-sparql-query/

P.F. Patel-Schneider et al. (Eds.): ISWC 2010, Part I, LNCS 6496, pp. 781797, 2010.
c Springer-Verlag Berlin Heidelberg 2010

T. Tran, L. Zhang, and R. Studer

information needs in their own words. Another aspect of dealing with the large
Web of linked data is scalability. Processing the needs against the entire Web
might be too time consuming and not needed, especially when users are interested in and want to choose some particular sources of information. Processing
against a relevant subset of linked data identified by the user is more scalable
and possibly the only practical solution for the large Web of linked data. Concerning these problems, the question we deal with is given the needs expressed
by users as sets of keywords, are there corresponding answers in linked data and
what combination of data sources shall be used to produce them?.
Existing Work. In the Semantic Web community, there exists a large body
of work on processing queries against RDF and linked data. Given structured
queries, RDF stores such as RDF-3X [5] and YAR2 [3] can compute structured
results and in the context of linked data query processing [2], can also identify
relevant sources. They however do not apply when the information need is provided as keywords. While keyword search is supported by some Semantic Web
search engines such as SWSE [1] and Sig.ma [9], they are limited to processing
simple list of keywords that refer to entities. This work deals with complex information needs, which may involve complex results providing information about
sets of entities and relations between them, i.e., result tuples that may form
graphs. Further, the aim is not to directly compute results but to quickly identify and let users and system focus on the combination of sources that produce
non-empty results.

To this end, work in information retrieval (IR) and database research dealing
with keyword search constitutes the starting point. Keyword search has become
the most widely used IR paradigm on the Web, enabling lay users without knowledge of the schema and data to search for a priori unknown documents. This
kind of schema-agnostic search is not limited to textual data but can also be used
for querying structured data. In database research, solutions have been proposed
that allow for the retrieval of the most relevant, possibly graph-structured results [4,6,7]. Unlike IR approaches, which consider only keywords for finding
matching documents (we called keyword coverage), database approaches also
use structure information. Possible join sequences in the data are explored to
ensure that matching result tuples not only contain the keywords but also,
represent meaningful connections between these keywords (called structure cov-
erage). Given the data graph in Fig. 1a and the query Stanford, John, Award
for instance, an IR-style approach might return none (AND-semantics) or all the
entities uni1, per2, ... in the graph because they all partially match the keyword
query (OR-semantics) whereas the DB approach would return the subgraph that
connects uni1 with per2, per1, per3 and prize1. However, computing complex results in this way is expensive, especially in a multi-source setting like the linked
data Web. Authors of state-of-the-art work explicitly considered only the setting
where number of databases that can be dealt with is up to the tens [6].

Thus, database researchers started to look at a problem we consider most re-
lated, namely the of finding the single most relevant databases [11,10]. They recognized the fact that the computational complexity resulting from a large-scale
?

?

?
setting can be partially addressed when allowing users to choose and retrieve
answers from only some particular databases. Given a set of keywords, the goal
is to find and rank the single most relevant databases that contain the answers.
Following this line, we propose specific solutions for the linked data context.
The differences to this work called database selection will be discussed in detail
throughout the paper.
Contributions. While existing approaches select single databases, we deal with
the Web of linked data where results are not bounded by a single source but
may encompass several linked data sources. Instead of computing the most relevant single sources, we extend the work in [11,10] to compute the most relevant
combinations of sources. The goal is to produce keyword routing plans which
capture combinations of sources that contain non-empty results. This novel keyword query routing problem raises additional challenges. Most notably, query
keywords may be covered by several linked sources, resulting in a large search
space. The size of this search space grow exponentially with the number of
sources and their associated links. Targeting this problem of scale, we report the
following contributions in this paper:

 We propose solutions for keyword query routing which enable the exploitation of linked data. Without putting any burden on the users, this kind
of approaches help to find relevant sources containing complex answers to
ad-hoc information needs in the large and evolving Web of linked data.

 We propose a multi-level relationship graph to capture the search space of the
keyword query routing problem. Based on this, we elaborate on a family of
summary models, which compactly represent the Web of linked data. These
models capture information at different levels, representing summaries of
different granularities. In a theoretical analysis, we prove that finer grained
models can improve the result quality. This however, comes at the expense
of higher complexity. Thus, the models represent different trade-offs between
effectiveness and efficiency.

 In the experiments, we investigate these trade-offs by analyzing the precision and the processing time needed using different models. The experiments were carried out in a real-world setting using more than 150 publicly
available datasets, and an open-source implementation we made available at
http://code.google.com/p/rdfstores/. Results of using summaries are
promising. While the best one shall be determined w.r.t a concrete appli-
cation, there is one model that seems to represent the most practical trade-
off: the D-KERG model, which summarizes elements according to sources,
produces results in less than 10ms, out of which every second is a valid one.

Outline. Section 2 introduces the readers to the concepts of linked data and keyword query routing. The search space and its summary models are presented in
Section 3. Strategies for computing routing plans using these models and ramifications for result quality and performance are discussed in Section 4. Evaluation
results are provided in Section 5 before we conclude in Section 6.

T. Tran, L. Zhang, and R. Studer

2 Preliminary

In this section, we discuss the underlying data and problem.

2.1 Web of Linked Data

Linked data can be conceived as a set of data graphs, each represents a particular
source. As a working definition, we present a simple graph-based model of linked
data called the Web graph. In that model, we distinguish between the Web data
graph representing relationships between individual data elements, the Web
schema graph, which captures information about group of elements, and the
Web source graph that contains information at the level of data sources.

n
i=1

N 

n
i=1

,M

,N 

2,E
j,N 

2),. . . , gn(N 
j  N 

i,N 

1), g2(N 
i, nj  N 
,N 

1,E
i, M = {m(ni, nj)|ni  N 
E
,M

Definition 1 (Web Graph). The Web of linked data is modeled as a Web
Graph W(G
,E) where G denotes the set of data graphs, M is
the set of edges also called mappings or links, which establish connections be-

tween elements of two different graphs, N  is the set of all nodes and E is

the set of all edges, i.e., G = {g1(N 
n)},
n,E
, i = j}
N  =
and E =
i  M. We use W(G,M,N ,E) to distinguish the Web data
graph from the Web schema graph W(G
,E) and the Web source graph
,E). We have n  N representing a data element, n
W(N 
  N  stands for a
  N  denotes a data source. For simplicity, we use
group of elements, and n
n  n
 to denote that an element n belongs to the group n
 and n, n
 to
. Elements in N
 belongs to the source n
assert the element n and the group n
and N  are labeled, i.e., there is a function label : N  N  ! 2V that associates
an element with a set of labels drawn from V, the vocabulary of words. We have
j)  M iff there is m(ni, nj)  M where ni  n
i and nj  n
?

?

?
j. Analo-
m(n
j )  E iff there is m(n
 n
j)  M where n
?

?

?
gously, e(n
j .
i and n
i, n
,N 
,E) to refer to the union set of elements
We use the Web graph W(G
i
of the Web data graph, the Web schema graph and the Web source graph.

  n

,M

 n
?

?

?
j
?

?

?
i, n
?

?

?
i , n

This is a simple model of linked data that omits details not necessary for this
work. In particular, data elements may correspond to RDF resources, blank
nodes or literals. Schema elements might stand for classes or data types. For
keyword query routing, these distinctions are not relevant but the fact that the
elements can be recognized via their labels. While different kinds of links can be
established, the ones frequently found are sameAs links, which denote that two
RDF resources or two classes are the same. There is also no need to distinguish
the types of links. Only the fact that sources can be reached via some kinds of
link m  M matters. An example of this model is illustrated in Figs. 1.

2.2 Keyword Query Routing

Given the need expressed as keywords, we aim to identify sources containing
results. A DB-style result to a keyword query is typically a Steiner graph, which
in the linked data scenario, may combine data from several sources:
?

?

?
Fig. 1. (a) A Web data graph (left) and (b) its Web schema graph (right)

K  NK  N with a label that matches ki (N M

Definition 2 (Keyword Query Result). A Web data graph W(G,M,N ,E)
contains a result for a query K = {k1, k2, . . . , k|K|} if there is subgraph also
called Steiner graph WK(GK,MK,NK,EK), where for all ki  K, there is an
K  N M

K is called the set of
n
keyword elements), and there is path ni  nj for all ni, nj  N M
K . In a d-max
Steiner graph, the length of the paths ni  nj is d-max or less.
Typical for keyword search is the pragmatic assumption that users are only interested in compact results such that a threshold dmax can be used to constrain the
connections to be considered. Thus, instead of general Steiner graphs, keyword
search solutions proposed so far and the work presented here consider d-max
Steiner graphs as results. For our example query Stanford, John, Award, we
K = {uni1, per2, per1, per3, prize1}; the subgraph that connects these
have N M
keyword elements is a 1-Steiner graph because the maximum distance between
keyword elements is 1; and since there are no other elements between keyword
elements, N M
Definition 3 (Keyword Routing Plan). Given the Web data graph W =
(G,M,N ,E) and a set of keyword queries SK, the mapping  : SK ! 2G that
associates a query with a set of data graphs is called a keyword routing plan
RP. A plan RP = {g1, . . . , g|K|} for a query K  SK is considered valid when
there is a combination of data graphs gi  RP that produces non-empty results
for K.
A valid plan in our example is RP = {F reebase, DBLP, DBP edia}. Note that
validity does not imply relevance. That is, a valid plan ensures that results can
be produced, but for the users, these results may differ in relevance. A proper
account of relevance and the ranking of routing plans based on the relevance of
their results go beyond the scope of this paper, which is focused on efficiency
aspects of computing valid plans. We assume a fixed ranking function, which
equally applies to all summaries discussed in this paper. We refer the interested
readers to our report [8], which discusses relevance and the ranking function.

K = NK.

T. Tran, L. Zhang, and R. Studer

3 Summary Models for Keyword Query Routing

We now discuss the most related work in detail and introduce the models we use
for keyword query routing.

3.1 Keyword Query Routing Search Space

For database selection, the search space is composed of a set of databases. The
idea behind previous work [11,10] is to model every database using a keyword
relationship model. A keyword relationship ki, kj is a pair of keywords, which
can be connected via a sequence of join operations, i.e., there exists two data
elements ni  nj that contain ki and kj. For instance, Stanf ord, Award is a
keyword relationship because there is a path between F B:uni1 and DBP :prize1
in Fig. 1a. The state-of-the-art [10] employs a keyword relationship graph (KRG),
with keywords being nodes and keyword relationships being edges. A database
is relevant when all pairs of query keywords match some edges of the KRG.

In

our

have

the

example, we

keyword pairs

(Stanf ord, John),
(Stanf ord, Award) and (John, Award). It is clear that when using keyword relationships in every source to form separate KRGs, none of them
matches all the 3 keyword pairs. To match the pair (Stanf ord, Award), relationships across sources from F reebase to DBP edia have to be incorporated
into in the model. In keyword query routing, the search space does not comprise
single databases but constitutes one integrated Web data graph. Instead of
computing a set of summary models, this problem requires the construction of
one integrated summary model. It shall allow for answers capturing relationships
across sources. Thus, not only single sources but also combinations of sources
might be relevant. Another aspect not addressed by current work is efficiency.
Instead of capturing all possible relationships, we aim to use a more compact
representations of the search space.

We conceive the search space as a multi-level inter-relationship graph (MIRG),
as illustrated in Fig. 2. For clarity, this figure does not show the labels and also,
omits some data and schema elements of our running example. At the lowest
level, it models relationships between keywords. In the upper-levels, there is the
Web data graph W followed by W and W. Elements and relationships at the
upper level represent sets of elements and sets of relationships at the lower level:
a node at the source level represents a set of schema elements; every schema node
represents a set of data elements; and every data element n is composed of a set
of keywords K. We say k  K is mentioned in n, denoted mentionedIn(k, n).

3.2 Summary Models

Thus, MIRG provides different perspectives on the search space and different
views on the data. The lower levels capture more fine-grained views of the data.
In order to extend the KRG [10] to deal with keyword query routing, the keyword
level and keyword relationships at this level that also capture links between
sources have to be taken into account. We will now discuss such an extension of
?

?

?
SOURCE

SCHEMA

type

ELEMENT

containedIn

containedIn

type

type

type

type

mentionedIn mentionedIn
KEYWORD

mentionedIn

mentionedIn mentionedIn

John

McCarthy

University

Turing

Stanford

Award

Fig. 2. Multi-level inter-relationship graph

the KRG, and introduce further summary models that capture relationships at
different levels of granularity. Examples of the models are shown in Fig. 3.

,N 

k

,M

,E) is W KSK = N KSK , where N KSK

Definition 4 (Keyword Sets). The keyword sets (KS) of a Web graph
W(G
stands for all the keywords
that are mentioned in elements of the graphs G. Every nKS
 N KSK is in fact a
tuple (k,Gk) that represents a keyword k and the graphs Gk  G mentioning k.
This is a simple model that contains only keywords but no relationships between
them. It captures all nodes at the keyword level of MIRG.

,N 

,M

Definition 5 (Element-level KERG). An element-level keyword-element
relationship graph (E-KERG) of a Web graph W(G
,E) is a tuple WK = (N K,EK). Every keyword-element nK  NK is a tuple (n, g,K)
where n  N is the corresponding element node it represents, g  G  G
is the data graph containing n, and K is the set of all keywords that are
mentioned in n, i.e., K = {k|mentionedIn(k, n)}. There is a relationship
eK = (ki, nKi(ni, gi, Ki),kj , nKj(nj, gj, Kj))  EK, iff mentionedIn(ki, ni),
mentionedIn(kj, nj), and ni  nj.
This can be seen as an extension of the KRG because it captures all keywords
and relationships. As shown in Fig. 3a, it also represents the data elements in
which the keywords are mentioned. Hence, we use keyword-element to make
clear that a node captures both the data element and its keywords. This model
captures elements at the keyword and element level of the MIRG.

Definition 6 (Schema-level KERG). A schema-level keyword-element rela-
K,EK). It captures elements
tionship graph (S-KERG) is a tuple W

K = (N 

T. Tran, L. Zhang, and R. Studer

Fig. 3. (a)The 1-E-KERG (top left), (b) the 1-S-KERG (bottom left), (c) the 1-D-
KERG (top right) and the (d) KS for our running example.
?

?

?
at the keyword and schema level of the MIRG. For a keyword-element node
, g,K)  N K, we have n
  N  being a schema-level node, g  G  G

K(n
n
, and K comprises keywords that are menis the schema graph containing n
, mentionedIn(k, n)}.
, i.e., K = {k|n  n
tioned in the elements n  n

K = (ki, n
j, gj, Kj))  EK,
i, gi, Ki),kj , n
?

?

?
There is a relationship e
Kj (n
Ki(n
iff mentionedIn(ki, ni), mentionedIn(kj, nj), ni  n
i, nj  n
?

?

?
j, and ni  nj.

As opposed to E-KERG, this one is indeed a summary model because it clusters two element-level relationships (ki, nKi(ni, gi, Ki),kj , nKj (nj, gj, Kj))
and (kv, nKv(nv, gv, Kv),kw, nKw(nw, gw, Kw)) to one schema-level relationship when they capture the same keyword relationships (i.e., ki =

kv and kj = kw) between the same classes (i.e, n
j =
w). For instance, (John, (P erson, DBP edia,{Smith, John, M cCarthy}),

n
Award,
(P rize, DBP edia, {M usic, Award, T uring})) in Fig. 3b is an
aggregation of the relationships (John, (per4,DBP edia,{Smith, John}),
Award,
(prize2,DBP edia,{M usic, Award})) and (John,(per3,DBP edia,
{M cCarthy, John}),Award,(prize1,DBP edia,{T uring, Award})) in Fig. 3a.
These E-KERG relationships are aggregated because they represent the same relationships (John, Award) between the classes (P erson, P rize).
?

?

?
v and n
?

?

?
i = n

K = (N 

Definition 7 (Source-level KERG). A source-level keyword-element rela-
K,EK). For a keyword-element
tionship graph (D-KERG) is a tuple W
  N  being a source-level node, i.e., a graph,
node n
and K is the set of all keywords that are mentioned in elements of the graph n
.
j , Kj))  EK, iff ki is
?

?

?
There is a relationship e
Ki(n

mentioned in some elements ni of the graph n
i , kj mentioned in some elements
nj of the graph n

,K)  N K, we have n
K = (ki, n
?

?

?
j , and ni  nj.

i , Ki), kj, n
?

?

?
K(n
?

?

?
Kj (n
?

?

?
Thus, this model is conceptually similar to S-KERG but aggregate elements at
the level of sources. It combines schema-level relationships when they capture the
same keyword relationships between the same sources. As shown in Fig. 3b, there
are only distinct keyword relationships in S-KERG. Thus, no further aggregation
is needed in this case.

As keyword search results, we consider d-max Steiner graphs where paths between keyword elements are of length dmax or less. Accordingly, we actually employ
a dmax-KERG versions where the maximum distance to be considered between
ni and nj is dmax (ni dmax nj). Note that the summaries illustrated in Figs.
3 resemble the structure of the underlying data and schema graphs because relationships in the summaries in fact correspond to graph edges, i.e., only paths with
length 1 are considered such that dmax = 1 (1-KERG models). Clearly, a higher
value for dmax would result in a blowup of paths. In particular, the E-KERG model
would contain much more relationships than there are edges in the data graph.
Hence, summarizing relationships is essential for efficient keyword query routing.

3.3 Computing Summary Models
The computation of dmax-KERG models is performed in three steps. Firstly,
the relationships between entities are computed for various distances within a
threshold dmax. Then, connected term pairs are extracted based on the computed
relationships. They are used for computing E-KERG. For computing S-KERG
and D-KERG, term pairs are further grouped according to schema and sourcelevel elements, respectively.

All information are finally stored in an specialized index that enables the
lookup of keyword-element relationships, given a pair of keywords. In par-
ticular, for (ki, kj), we have (1) IEKERG returning the relationships eK =
(ki, nKi,kj , nKj), (2) ISKERG returning e
K = (ki, n
) and (3)

). Also, we construct a KS model

IDKERG returning e
Kj
based on keywords extracted from the data graphs and build the index (4) IKS,
which returns the elements nKS

, given the keyword k.

K = (ki, n
?

?

?
,kj , n
?

?

?
Ki

,kj, n
?

?

?
Kj
?

?

?
Ki

k

4 Computing Keyword Routing Plans

For computing valid query routing plans, the idea behind existing work on keyword search [4,6,7] and database selection [11,10] applies: we search for Steiner
graphs to discover sources that produce answers. Recall that a Steiner graph
is basically a graph that connects keyword elements. The existence of such a
graph indicates that there are answers to the keyword query. In our approach,
the search is not performed directly on the Web data graph but on the summary
models. Specifically, we search for Steiner graphs in either (1) W ksK , (2) WK, (3)
W
K or (4) W
K. Since KS (1) do not capture relationships, the results that can
be derived from it do not completely adhere to the notion of Steiner graph. Also
for the KERG models (2-4), Steiner graphs that can be computed are different
in granularities. We will now elaborate on strategies for searching Steiner graphs
using different summaries.

T. Tran, L. Zhang, and R. Studer

4.1 Routing Plan Computation Using KS

Using the KS model and its index, routing plans can be computed as follows:
 Given the keyword query K = {k1, k2, . . . , ki}, retrieve the elements
retrieved before, put the sources Gki that is associated with

ki (ki,Gki) for every ki  K using the IKS index.
nKS

nKS
ki

into the set of relevant sources GK.

 For every nKS
ki
 Compute all |K|-combinations for the set GK.
 Output these combinations as the set of routing plans SRP.
Intuitively speaking, this procedure simply retrieves sources that cover the keywords and in order to cover all |K| query keywords, it uses |K|-combinations of
these sources as routing plans.

4.2 Routing Plan Computation Using KERGs

Since KERG models capture relationships, we retrieve data for pair of keywords
(ki, kj), instead of single keywords. Retrieved data are joined to compute Steiner
graphs. It is necessary to ensure that all keyword elements in a Steiner graph
are pairwise connected through a path of length dmax or less. Thus, it is necessary to join all possible keyword pairs. Given a query with three keywords
k1, k2, k3 for instance, we need to retrieve keyword elements and perform the
joins (k1, k2) k2 (k2, k3) k3,k1 (k1, k3) to verify that (1) the elements n2
matching k2 are connected with both n1 that match k1 and n3 that match k3
over a distance of dmax or less (by means of the first join ((k1, k2) k2 (k2, k3)
on k2), (2) the elements n3 just found to be connected with n2, are also connected with n1 (by means of the second join on k3), and (3) the n1 found to be
connected with n2, is also connected with n3 (by means of the third join on k1).
The complete procedure can be summarized as follows:
 Given the keyword query K = {k1, k2, . . . , ki}, compute all 2-combinations
of K to get all possible keyword pairs, resulting in a total of N = |K|(|K| 
1)/2 different pairs. Subsequently, retrieve relationships for these pairs and
perform joins according to a random2 or alternatively, optimized order.

 In particular, inputs for every keyword pair are obtained using the underlying
index. Given (k1, k2) and IEKERG for instance, relationships of the form
eK = (k1, nK1(n1, g1, K1),k2, nK2(n2, g2, K2)) are retrieved. Joining this
with the next inputs retrieved for (k2, k3) for instance, ensures that n2 is
connected with both n1 and n3.

 Processing the entire join sequence of keyword pairs yields a set of graphs.
Depending on the underlying summary model, these graphs capture Steiner
graphs at the source, schema or element level.

2 For this work, we omit the aspect of join order optimization and simply generate a

random order for joining keyword pairs.
?

?

?
 Some resulting graphs might be indistinguishable in terms of the sources and
connections between sources they represent. Keep only one of those because
the other does not contain additional information.
of sources, i.e., the routing plans RP.

 Extract sources associated with elements of the graphs to obtain combination

This procedure is the same for all KERGs. Given that the underlying data
contain results, we provide proofs in the report [8] to show that applying this
procedure on the S-KERG summary will yield routing plans, i.e., when Steiner
graphs can be found for K in the data, then there will be corresponding graphs
that can be found in the summary. Thus, given K, the procedure will output a
non-empty set of RP if W contains a result for K. In the same manner, it is
straightforward to show that E-KERG and D-KERG can provide this guarantee.
However, we show formally in [8] that the other way around is not true, i.e.,
the graphs derived from the summary are not necessarily valid such that there
might be no corresponding Steiner graph in the data. Thus, the fact that a
routing plan can be derived from the summaries does not guarantee there exists
a result for K. This formal result is interesting because it makes clear that while
the use of summaries might be required to obtain the desired performance, it
has consequences on the result validity. In particular, it implies that the more
compact the summary, the more likely that plans computed from it are not valid.
We will now discuss the intuition behind this formal result.

4.3 Result Validity

max = ddata

max-E-KERG is used, ddata

A graph derived from a summary does not always have a corresponding Steiner
graph in the data, unless we use E-KERG. This model makes a difference because it in fact captures all nodes and paths in the Web data graph. In particular,
max-Steiner graphs are keyword query answers,
when a dsum
max, then E-KERG captures all the paths in the data that are reland dsum
evant for Steiner graph computation, i.e., all paths up to length dsum
max. For every
path ni dmax nj in the data, there is a one-to-one corresponding relationship
eK = (ki, nKi(ni, gi, Ki),kj , nKj (nj, gj, Kj)) in E-KERG. This one-to-one
correspondence of paths constitutes the base argument, which can be extended
inductively to show that there is also a one-to-one correspondence of graphs such
that a graph derived from E-KERG always has a corresponding Steiner graph
in the data, and vice versa.
?

?

?
Kj (n

A S-KERG however, combines

single
j, gj, Kj)) iff ni1 , ni2
?

?

?
two edges e(ni1 , nj1) and e(ni2 , nj2)

=
in
(paths)
data

(ki, n
 n
i, gi, Ki),kj , n
?

?

?
j,
Ki(n
ni1 , ni2 mention ki, and nj1 , nj2 mention kj. Thus, for an element in the data,
there is always a counterpart in S-KERG, which is however a grouping of
elements, constituting a one-to-many correspondence. Through this grouping,
we loose detailed information about elements in the group. That is, for the
pair of keyword (ki, kj), S-KERG captures the corresponding connection from

the element group n
j but can no longer tell for instance, whether this

relationship
 n
?

?

?
i, nj1 , nj2
?

?

?
i to n

the

graph

to

one

e

T. Tran, L. Zhang, and R. Studer

represents a connection between ni1 to nj1 or ni1 to nj2. In other words, it can
be inferred from S-KERG that ni1 is connected with nj2 even though such a
connection does not exist in the data. With respect to our example, a graph can
be derived from S-KERG that covers the keywords Stanf ord, John and M usic.
It is clear from Fig. 3a that there is no Steiner graph corresponding to this.
The problem here is that S-KERG does not distinguish the John McCarthy
connected with Stanford from the John Smith connected with Music. Thus,
it incorrectly infers the connection Stanford and Music.

 n
?

?

?
i and nj1 , nj2

The same arguments can be applied to D-KERG. The difference is that
the grouping in D-KERG is even more coarse-grained. Two edges e(ni1 , nj1)
e(ni2 , nj2) are aggregated to one single relationship in D-KERG, when ni1 and
ni2 mention the same keyword ki, nj1 and nj2 mention kj, and they belong to the

same data source, i.e., ni1 , ni2
j . Note that with S-KERG,
the incorrect inference mentioned before would not occur when John Smith is in
a different class than John McCarthy. They would not have been aggregated to
one single node in S-KERG. This however happens with D-KERG. No matter
the classes they belong to, these elements would be aggregated to one single node
when they are in the same data source. With respect to our example, D-KERG
makes one additional false inference: it does not distinguish the person John
connected with Stanford from yet another John connected with Music,
which is an article (see that John as an article and John as a person in Fig. 3b
is aggregated to one element in Fig. 3c).

 n

Compared to the KERG models, KS does not capture relationships between
keywords at all. Given two keywords ki, kj, the sources which cover these key-
?

?

?
words can be derived from KS, e.g. the graphs n
j . However, this does not
i , n
i and nj  n
imply there exist two elements ni  n
?

?

?
j , and ni  nj. More gener-
ally, a combination of sources derived from KS covers all keywords but does not
ensure that elements matching these keywords are connected, and thus, does not
necessarily correspond to a Steiner graph.

In summary, the percentage of valid plans for D-KERG is less or equal that
max value
for S-KERG, which in turn is less or equal that for E-KERG. When dsum
of E-KERG is sufficiently large to cover all paths relevant for Steiner graph
computation, i.e., dsum
max, this percentage is 100 for E-KERG. By chance,
the percentage of valid plans for KS might be higher than that for the summary
models but in general, is expected to be less (because relationships between
elements are not considered).

max = ddata

4.4 Complexity

|K|1
max ), where inputmax denotes the largest
Using KS, complexity is O(input
number of elements that can be obtained for a keyword ki. This is because for
computing the combination of sources for a 2-keyword query K = {ki, kj}, we
have to union every element retrieved for ki with every other retrieved for kj
(Cartesian product), thus requiring |inputi||inputj| time and space. For queries
with |K| keywords, we have to combine elements retrieved for one keyword ki
?

?

?
with elements retrieved for every other keyword kj  K, kj = ki. Thus, |K|  1
combinations of input sets of maximum size inputmax have to be performed.

With KERG models, retrieved elements have to be joined. While in practice,
this operation can be performed more efficiently using special indexes and join
implementation, this operation in worst case, also requires |inputi|  |inputj|
time and space. Inputs are retrieved not for every ki but for all possible pair
of keywords. This results in complexity O(inputC(K,2)1
), where inputmax here
refers to the largest number of relationships that can be obtained for a keyword
pair, and C(K, 2) is the number of 2-combinations of the set K, denoting the
number of joins that have to be processed.

max

While the number of operations are same for all KERG models, the size
of inputmax varies. Clearly, the more coarse-grained the grouping, i.e., the
higher the number of elements aggregated to one group at the summary level,
the smaller will be inputmax. In particular, we have inputmax(D-KERG) 
inputmax(S-KERG)  inputmax(E-KERG). How much smaller a KERG summary is compared to one other depends on the data. In the extreme case where
every data element mentions only distinct terms, i.e., does not share terms with
one other, all KERG models are actually equal in size.
While KERG models require joins on input sets to be performed C(K, 2)  1
times, KS only needs |K|1 combinations of input sets. However, the advantage
of using KERG is that the size of the input sets that have to be processed is
expected to be smaller. This is not only due to the effect of summarization. For
all KERG models, inputs are retrieved for keyword pair while for KS, inputs
are retrieved using single keywords. Two keywords are more selective than one
keyword, thus more likely result in smaller input.

5 Evaluation

We implemented our approach for keyword query routing in Java using JDK
1.6 on top of MySQL 5.1. The experiments were conducted on a commodity
PC with 2.5GHz Intel Core, 4GB of RAM and 500GB HDD SATA II 7200rpm,
running on Windows 7. As discussed, while KRG [10] is limited to the problem
of database selection, E-KERG can be seen as an extension that captures the
ideas behind KRG. KS represents a naive baseline. The goal was to assess the
performance of routing plan computation and the validity of results that can be
achieved with S-KERG and D-KERG, compared to the baselines E-KERG and
KS.

5.1 Data Preprocessing

We employed a chunk of RDF data part of the Billion Triple Challenge dataset3.
It contains about 10M RDF triples that are from 154 different data sources,
linked via 500K mappings.

http://vmlion25.deri.ie/index.html

T. Tran, L. Zhang, and R. Studer

In total, the number of distinct terms extracted from all sources was 121,434.
We measured the number of elements in KS and the number of KERG relation-
ships. This was done for different settings of dmax to investigate the changes
in the number of relationships as longer distances are considered. KS contains
804,528 elements. For dmax = 0, 1, 2, 3, 4, E-KERG contains 2.4M, 7.7M, 364M,
616M and 889M relationships, S-KERG contains 1.8M, 5.1M, 144M, 215M and
312M relationships and D-KERG contains 1.7M, 4.7M, 141M, 203M and 279M
relationships. Clearly, there were more relationships in KERG models than elements in KS. The number of relationships increases with dmax. The increase was
particularly sharp (one order of magnitude) when changing dmax from 1 to 2.

Similar results were obtained for index size. The E-KERG index was the
largest. As an average over different settings for dmax, S-KERG was about 36%,
D-KERG was about 32% and KS was less than 1% the size of E-KERG. For
dmax = 2 for instance, the sizes for E-KERG, S-KERG, D-KERG and KS were
8694MB, 3438MB, 3279MB and 22 MB, respectively.

Larger indexes required more building times. The times for building the S-
KERG indexes for dmax = 4, 3, 2, 1 for instance, were 846 Min, 583 Min, 339
Min and 27 Min, respectively.

Our report [8] provides a breakdown of the results into 6 categories of datasets
that vary in size. According to these results, both index size and building time
increased with the size of the dataset. However, there is no strict correlation
because there are cases where relatively small datasets resulted in large indexes.
Rather, structural density was the dominant factor. Large index and high building costs were obtained for datasets which exhibit large number of links to other
datasets, and contain nodes with large in- and outdegree.

5.2 Query Processing

For the experiment, we used a set of 30 keyword queries. All queries are valid,
i.e., they produce non-empty keyword answers (4-Steiner graphs to be precise).
For each query, at least two data sources contribute to the answers. One example
submitted by participants is Rudi AIFB ISWC2008. The sources containing
partial answers to this are uni-karlsruhe.de and semanticweb.org. Other examples are Town River America, Markus Denny Semantic Wikis and Beijing
Conference Database 2007. All queries can be found in our report [8].

Validity of Routing Plans. To investigate the validity, we use precision at k
(P @k) to measure the percentage of plans that are valid out of the top-k plans
returned by the system. For instance, P @10 is 1 when every plan in the top-10
list returned by the system, produces at least one keyword query result.

Fig. 4a shows P @5 for the settings dmax = 0, 1, 2, 3, 4. These values represent
the average computed for all 30 queries. Using E-KERG, precision was up to
100 percent, i.e., for dsum
max = 4. With P @5 being always above 0.6 when
dmax > 1, S-KERG and D-KERG also achieved relatively good results. P @5
for KS was only 6%. Clearly, dmax had a positive effect. More valid plans were

max = ddata
?

?

?
E(cid:882)KERG
E(cid:882)KERG
D(cid:882)KERG
D(cid:882)KERG
S(cid:882)KERG
S(cid:882)KERG
?

?

?
@
@
?

?

?
1,0
1,0
0,9
0,9
0,8
0,8
0,7
0,7
0,6
0,6
0,5
0,5
0,4
0,4
0,3
0,2
0,1
0,0

dmax
?

?

?
@
@
?

?

?
1,0
1,0
0,9
0,9
0,8
0,8
0,7
0,7
0,6
0,6
0,5
0,5
0,4
0,4
0,3
0,2
0,1
0,0

E(cid:882)KERG
E(cid:882)KERG

S(cid:882)KERG
S(cid:882)KERG

D(cid:882)KERG
D(cid:882)KERG
?

?

?
1,0
1,0
0,9
0,9
0,8
0,8
0,7
0,7
0,6
0,6
0,5
0,5
0,4
0,4
0 3
0,3
0,2
0,1
0,0

E(cid:882)KERG
E(cid:882)KERG
S(cid:882)KERG
S(cid:882)KERG

D(cid:882)KERG
D(cid:882)KERG
?

?

?
(a) P@k at various dmax

|K|

(b) P@k at various |K|

k

(c) P at various k

Fig. 4. Validity of the plans measured using P @k

computed when a higher value was used for dmax. However, using dmax = 4
instead of 3 did not yield clear improvement.
Fig. 4b shows the effect of query length |K|. Quite clear, queries with larger
number of keywords resulted in lower precision. It dropped as low as 0.23 when
using D-KERG for queries with 5 keywords.

Fig. 4c shows that as more results from the system were taken into account
(larger k), precision decreased. The decrease is small for k values larger than 3.
Experimental results thus correspond to the analysis we presented before: KS
is the model that produces only very few valid plans. This result was improved
by one order of magnitude when relationships between keywords were used.
The more fine-grained a model captures the relationships, the larger was the
percentage of valid plans. Even a summary at the level of sources produced
reasonably high quality results, i.e., every second plan was a valid one.

Performance. Performance is measured as the average response time for computing routing plans. Fig. 5a shows the performance for queries at various settings using different values for dmax. This parameter had no effect on the KSs
results but clearly influenced the performance achieved with KERG summaries.
Times increased with higher values for dmax. While this increase was sharp for
E-KERG and S-KERG, time performance of D-KERG was relatively stable. In
particular, time required by D-KERG was no more than 10ms on average.

Expectedly, more time was needed when the number of query keywords in-
creases, as illustrated in Fig. 5b. It seems that all the other models had poor
performance w.r.t complex queries but D-KERG. In particular, E-KERG is no
longer affordable for queries with more than 2 keywords because it needed more
than 100s to produce results. While the times shown are the actual times obtained for the other models, only the lower bound was shown for E-KERG. This
is because we applied a timeout of 6min. Fig. 5c shows the exact times obtained for E-KERG and the queries that had to be aborted due to timeout. For
dmax = 4 for instance, 1 out of every three queries was aborted.

Less expected, Fig. 5a+ 5b show that KS did not achieve good performance.

It needed more than 30s on average, up to 100s for queries with 5 keywords.

This can be explained using the theoretical result achieved in the previous sec-
tion. Namely, the poor performance of KS indicates that the number of elements
(see inputmax in Section 4.4) retrieved for single keywords must have been much

T. Tran, L. Zhang, and R. Studer

)
)
s
s

m
m
?

?

?
i
i

(
(
?

?

?
e
e
m
m
?

?

?
g
g
n
n
i
i
s
s
s
s
e
e
c
c
o
r

y
r
e
u
?

?

?
1000000
1000000

100000
100000
?

?

?
E(cid:882)KERG
E(cid:882)KERG
S(cid:882)KERG
S(cid:882)KERG
D(cid:882)KERG
D(cid:882)KERG

dmax

(a) Times at var. dmax

1000000
1000000

)
)
s
s

m
m
?

?

?
i
i

(
(
?

?

?
e
e
m
m
?

?

?
g
g
n
n
i
i
s
s
s
s
e
e
c
c
o
r

y
r
e
u
?

?

?
100000
100000
?

?

?
E(cid:882)KERG
E(cid:882)KERG

S(cid:882)KERG
S(cid:882)KERG

D(cid:882)KERG
D(cid:882)KERG
?

?

?
|K|

(b) Times at var. |K|
?

?

?
k
k
(cid:882)
(cid:882)
?

?

?
i
i

e
e
m
m
?

?

?
g
g
n
n
i
i
s
s
s
s
e
e
c
c
o
r

y
r
e
u
?

?

?
1000000
1000000

100000
100000
?

?

?
)
)
s
s

m
m

(
(
?

?

?
dmax=0
dmax=0

dmax=1
dmax=1

dmax=2
dmax=2

dmax=3
dmax=3

dmax=4

Q1 Q3 Q5 Q7 Q9 Q11 Q13 Q15 Q17 Q19 Q21 Q23 Q25 Q27 Q29

Queries

(c) Times for E-KERG at var. dmax

Fig. 5. Processing times

larger than for two keywords. In other words, keyword pairs proved to be the
much more selective queries. Considering relationships between keywords thus
did not only improve result validity but also performance.

6 Conclusion

We presented a solution to the novel problem of keyword query routing. It helps
users without knowledge of the evolving linked data and schema to find combination of sources that contain answers corresponding to their needs. This solution
also partially addresses the aspect of efficiency as queries can be then evaluated
against the relevant sources identified by the user, instead of using the entire
Web of linked data.

We have proposed a family of summary models. Through theoretical and
experimental analysis, we showed that it is important to capture keyword rela-
tionships. Compared to the KS model representing the naive baseline that stores
only single keywords, the KERG models relying on relationships could produce
a much larger number of valid results, i.e., improved precision by more than one
order of magnitude when compared to the naive baseline represented by KS. Fur-
ther, finding out which relationships are covered as opposed to single keywords
resulted in less intermediate results to be processed. Thus, using relationships
also has a positive effect on performance.

We could also show that summarizing relationships is essential for dealing with
the large-scale linked data Web. Using a fine-grained E-KERG model representing an extension of work in database selection that captures all relationships
in the data, precision was up to 100%, but response time was too high. While
specific requirements shall determine what is the best model, it seems that
D-KERG which summarizes at the level of sources represents the most practical
trade-off. It produced results in less than 10ms out of which every second one
was valid.

As future work, we will combine the proposed work on query routing with
query processing to obtain a scalable procedure for computing relevant sources
as well as retrieving the final answers from them.
?

?

?
Acknowledgements. Research reported in this paper was supported by the
German Federal Ministry of Education and Research (BMBF) under the iGreen
(grant 01A08005) and CollabCloud project (grant 01IS0937A-E).
