Maximal Incrementality in Linear Categorial Deduction 
Mark Hepple
Dept . of Computer Science
University of Sheffield
Regent Court , Portobello Street
Sheffield S14 DP , UK
hepple?dcs , hef.ac.uk
Abstract
Recent work has seen the emergence of a common framework for parsing categorial grammar  ( CG ) formalisms that fall within the ' type-logical ' tradition  ( such as the
Lambek calculus and related systems ) , whereby some method of linear logic theorem proving is used in combination with a system of labelling that ensures only deductions appropriate to the relevant grammaticalogic are allowed  . The approaches realising this framework , however , have not so far addressed the task of incremental parsing--a key issue in earlier work with ' flexible ' categorial grammars  . In this paper , the approach of ( Hepple ,  1996 ) is modified to yield a linear deduction system that does allow flexible deduction and hence incremental processing  , but that hence also suffers the problem of ' spurious ambiguity '  . 
This problem is avoided via normalisation.
1 Introduction
A key attraction of the class of formalisms known as ' flexible ' categorial grammars is their compatibility with an incremental style of processing  , in allowing sentences to be assigned analyses that are fully or primarily left-branching  . Such analyses designate many initial substrings of a sentence as interpretable constituents  , allowing its interpretation to be generated ' online ' as it is presented  . Incremental interpretation has been argued to provide for efficient language processing  , by allowing early filtering of implausible readings  .   1 This paper is concerned with the parsing of categorial formalisms that fall within the ' type -logical '  1Within the categorial field , the significance of incrementality has been emphasised most notably in the work of Steedman  , e . g . ( Steedman , 1989) . 
tradition , whose most familiar representative is the associative Lambek calculus  ( Lambek ,  1958) . Recent work has seen proposals for a range of such systems  , differing in their resource sensitivity ( and hence , implicitly , their underlying notion of ' linguistic structure  '  )  , in some cases combining differing resource sensitivities in one system  .   2 Many of these proposals employ a ' labelled deductive system ' methodology  ( Gabbay ,  1996) , whereby types in proofs are associated with labels which record proof information for use in ensuring correct inferencing  . 
A common framework is emerging for parsing type -logical formalisms  , which exploits the labelled deduction idea . Approaches within this framework employ a theorem proving method that is appropriate for use with linear logic  , and combine it with a labelling system that restricts admitted deductions to be those of a weaker system  . Crucially , linear logic stands above all of the type-logical formalisms proposed in the hierarchy of substructural logics  , and hence linear logic deduction methods can provide a common basis for parsing all of these systems  . For example , Moortgat ( 1992 ) combines a linear proofnet method with labelling to provide deduction for several categorial systems  . Morrill ( 1995 ) shows how types of the associative Lambek calculus may be translated to labelled implicational linear types  , with deduction implemented via a version of SLD resolution  . Hepple ( 1996 ) introduces a linear deduction method , involving compilation to first order formulae , which can be combined with various labelling disciplines  . These approaches , however , are not dir-ected toward incremental processing . 
In what follows , we show how the method of ( Hepple ,  1996 ) can be modified to allow processing which has a high degree of incrementality  . These modifications , however , give a system which suffers 2See , for example , the formalisms developed in ( Moortgat & Morrill ,  1991) , ( Moortgat & Oehrle ,  1994) , ( Morrill ,  1994) , ( Hepple ,  1995) . 
344 the problem of ' derivational equivalence ' , also called's purious ambiguity ' , i . e . allowing multiple proofs which assign the same reading for some combination  , a fact which threatens processing efficiency . We show how this problem is solved via normalisation  . 
2 Implicational Linear Logic
Linear logic is an example of a " resource -sensitive " logic  , requiring that each assumption ( ' resource ' ) is used precisely once in any deduction . For the implic-ational fragment , the set of formulae ~ are defined by 5 r : := A\[~'o-~- ( with A a nonempty set of atomic types )  . A natural deduction formulation requires the elimination and introduction rules in  ( 1 )  , which correspond semantically to steps of functional application and abstraction  , respectively . 
(1) Ao-B:aB:bIS:v\]o-EA : a
A : ( ab)o-I
Ao-B : Av . a
The proof ( 2 )   ( which omits lambda terms ) illustrates that ' hypothetical reasoning ' in proofs  ( i . e . the use of additional assumptions that are later discharged or cancelled  , such as Zhere ) is driven by the presence of higher-order formulae  ( such as Xo- ( yc-z ) here )  . 
(2) Xo-(Yo--Z ) Yo-WWo--Z\[Z\]




Various type-logical categorial formalisms ( or strictly their implicational fragments ) differ from the above system only in imposing further restrictions on resource usage  . For example , the associ-ative Lambek calculus imposes a linear order over formulae  , in which context , implication divides into two cases ,   ( usually written \ and / ) depending on whether the argumentype appears to the left or right of the functor  . Then , formulae may combine only if they are adjacent and in the appropriate left-right order  . The non-associative Lambek calculus ( Lambek ,  1961 ) sets the further requirement that types combine under some fixed initial brack-etting  . Such weaker systems can be implemented by combining implicational linear logic with a labelling system whose labels are structured objects that record relevant resource information  , i . e . of sequencing and/or bracketting , and then using this information in restricting permitted inferences to only those that satisfy the resource requirements of the weaker logic  . 
3 First-order Compilation
The first-order formulae are those with only atomic argument types  ( i . e . ~": := AI . ~ oA ) . 
Hepple ( 1996 ) shows how deductions in implicational linear logic can be recast as deductions involving only first-order formulae  .   3 The method involves compiling the original formulae to indexed first-order formulae  , where a higher-order initial formula yields multiple compiled formulae  , e . g .   ( omitting indices ) Xo- ( yo--Z ) would yield Xo-Y and Z , i . e . with the subformula relevant o hypothetical reasoning  ( Z ) effectively excised from the initial formulae , to be treated as a separate assumption , leaving a first-order residue . Indexing is used in ensuring generaline aruse of resources  , but also notably to ensure proper use of excised subformulae  , i . e . so that Z , in our example , must be used in deriving the argument of Xo-Y , and not elsewhere ( otherwise invalid deductions would be derivable )  . 
The approach is best explained by example . In proving Xo-(Yo--Z ) , Yo-W , Wo--Z = ~ X , compilation of the premise formulae yields the indexed formulae that form the assumptions of  ( 3 )  , where formulae ( i ) and ( iv ) both derive from Xo-- ( Yo-Z )  . 
(Note in ( 3 ) that the lambda terms of assumptions are written below their indexed types  , simply to help the prooffit in the column . ) Combination is allowed by the single inference rule  ( 4 )  . 
(3 )   ( i )   ( ii )   ( iii )   ( iv ) i : Xo- ( Y : j ) k : Yo- ( W:0 ) l : Wo -- ( Z:0 ) j : Z ) ~ t . x()tz . t )) ~ u . yuAv . wvzj , l:W : w zj , k , l:Y : y(wz)i , j , k , l:X : x()tz . y(wz )) (4) ?: Ao--(B:~):Av . a ?: B:blr = ? t~?r:A:a\[b//vl Each assumption i  ( 3 ) is associated with a set containing a single index  , which serves as the unique 3The point of this manoeuvre ( i . e . compiling to first-order formulae ) is to create a deduction method which , like chart parsing for phrase-structure grammar , avoids the need to recompute intermediater sults when searching exhaustively for all possible analyses  , i . e . where any combination of types contributes to more than one over all analysis  , it need only be computed once . The incremental system to be developed in this paper is similarly compatible with a ' chart-like ' processing approach  , although this issue will not be further addressed with in this paper  . For earlier work on chart-parsing type-logical formalisms  , pecifically the associative Lambek calculus , see KSnig (1990) , Hepple (1992) , K5 nig (1994) . 
345 identifier for that assumption . The index sets of a derived formula identify precisely those assumptions from which it is derived  . The rule (4) ensures appropriate indexation , i . e . via the condition r r = ?~? , where t ~ stands for disjoint union ( ensuring linear usage )  . The common origin of assumptions ( i ) and ( iv )   ( i . e . from Xo-- ( Yo-Z ) ) is recorded by the fact that ( i ) 's argument is marked with ( iv ) 's index ( j )  . 
The condition a C~b of ( 4 ) ensures that ( iv ) must contribute to the derivation of ( i ) 's argument ( which is needed to ensure correct inferencing )  . Finally , observe that the semantics of ( 4 ) is handled not by simple application , but rather by direct substitution for the variable of a lambda expression  , employing a special variant of substitution , notated_\[_//_\](e . g . 
t\[s // v \] to indicate substitution of s for v in t  )  , which specifically does not act to avoid accidental binding  . 
In the final inference of (3) , this method allows the variable zt of all within the scope of an abstraction over z  , and so become bound . Recall that introduction inferences of the original formulation are associated with abstraction steps  . In this approach , these inferences are no longer required , their effects having been compiled into the semantics  . See ( Hepple , 1996) for more details , including a precise statement of the compilation procedure  . 
4 Flexible Deduction
The approach just outlined is unsuited to incremental processing  . Its single inference rule allows only a rigid style of combining formulae  , where order of combination is completely determined by the argument order of functors  . The formulae of (3) , for example , must combine precisely as shown . It is not possible , say , to combine assumptions ( i ) and ( if ) together first as part of a derivation . To overcome this limitation , we might generalise the combination rule to allow composition of functions  , i . e . combinations akin to e . g . Xo-Y , Yo--W ==> Xo-W . However , the treatment of indexation in the above system is one that does not readily adapt to flexible combination  . 
We will transform these indexed formulae to another form which better suits our needs  , using the compilation procedure (5) . This procedure returns a modified formula plus a set of equations that specify constraints on its indexation  . For example , the assumptions ( i-iv ) of ( 3 ) yield the results ( 6 )   ( ignoring semantic terms , which remain unchanged ) . Each atomic formula is partnered with an index set  ( or typically a variable over such )  , which corresponds to the full set of indices to be associated with the complete object of that category  , e . g . in(i ) we have ( X+?) , plus the equation ? = i Wrr which tells us that X ' sindex set ? includes the argument formula Y's index set rr plus its own index i  . The further constraint equation ? = it ~ rr indicates that the argument's index set should include j  ( c . f . the conditions for using the original indexed formula  )  . 
(5) 0 . (?: x : t ) = (( x + ?) : t , 0) where X atomic 0 . (?: Xo-Y:t ) = ( Z:t,C ) where 0 . 1(?, Xo--Y ) = ( Z , C ) 0 . 1(? , x ) = (( x + 7) , 7=?) where X atomic , 7 a fresh variable 0 . 1 (? , Xl?-(Y : 7r )) = ( X2o--(Y+7) , C ') where 6 , 7 fresh variables ,  6 := ?~7 0"1(6 , X 1 ) = ( X2 , C )
C '= Cu ~ rc7 ( unless ~ r = 0 , when C =  C ') (6) i . old formula : i : Xo-- ( Y : j ) new formula: ( X + C ) o- ( Y + Tr ) constraints : ?= i ~ r r , jC 7 rif . old formula:k : Yo- ( W : O ) new formula: ( V + a ) o- ( W%3 ) constraints : a = k ~ / ~ i ii . old formula : l : Wo- ( Z : O ) new formula: ( W + 7 ) o- ( Z + ~ ) constraints : 7= lt~iv . old formula:j : Znew formula: ( Z+j ) constraints : 0 ( 7 ) Ac--B:Av . a B : b
A : a\[bllv\]
The previous inference rule (4) modifies to (7) , which is simpler since indexation constraints are now handled by the separate constraint equations  . We leave implicit the fact that use of the rule involves unification of the index variables associated with the two occurrences of " B "  ( in the standard manner )  . 
The constraint equations for the result of the combination are simply the sum of those for the formulae combined  ( as affected by the unification step )  . For example , combination of the formulae from ( iii ) and ( iv ) of ( 6 ) requires unification of the index set expressions  6 and j , yielding the result formula ( W + 7 ) plus the single constraint equation V = ltgj , which is obviously satisfiable ( with 3'= j , l ) . A combination is not allowed if it results in an unsatisfiable set of constraints  . The modified approach sone atly moves indexation requirements off into the constraint equation domain that we shall henceforth drop all consideration of them  , assuming them to be appropriately managed in the background  . 

We can now state a generalised composition rule as in  ( 8 )  . The inference is marked as \[ m , n \] , where m is the argument position of the ' functor  '   ( always the lefthand premise ) that is involved in the combination , and n indicates the number of arguments inherited from the ' argument '  ( righthand premise )  . 
The notation " o--Zn . . . o--Zl " indicates a sequence of n arguments , where n may be zero , e . g . the case\[1 , 0\] corresponds precisely to the rule (7) . Rule ( 8 ) allows the non-applicative derivation ( 9 ) over the formulae from ( 6 )   ( c . f . the earlier derivation (3)) . 
(8) Xo-Y . . . . o--Y1Y mo-Z . . . . o'-Zl
Ayl . ..y , , . a Azl . . . z ~. b\[m,n\]
Xo-Z .... o-Zlo-Y ,,_1-. o-Y 1
Ayl . . . ym-1Zl . . . z , . a\[b//ym\](9)(ii ) ( iii ) ( iv)
X c-Y Yo-W Wo-ZZ
At . x(Az.t ) Au.yu Av . wvz
Xo-W : Au . x(kz . yu)\[1,11\[1,1\]xo-z:~v . x(~z . y(wv )) x : x ( , ~ z . y ( wz )   )   \[1   21   5 Incremental Derivation As noted earlier , the relevance of flexible CGs to incremental processing relates to their ability to assign highly left-branching analyses to sentences  , so that many initial substrings are treated as interpretable constituents  . Although we have adap-ted the ( Hepple , 1996) approach to allow flexibility in deduction , the applicability of the notion ' left-branching ' is not clear since it describes the form of structures builtin proof systems where formulae are placed in a linear order  , with combination dependent on adjacency . Linear deduction methods , on the other hand , work with unordered collections of formulae . Of course , the system of labelling that is in use--where the constraints of the ' real'grammatical logic reside--may well import word order information that limits combination possibilities  , but in designing a general parsing method for linear categorial formalisms  , these constraints must remain with the labelling system  . 
This is not to say that there is no order information available to be considered in distinguishing incremental and nonincremental nalyses  . In an incremental processing context , the words of a sentence are delivered to the parser one-by-one  , in ' left-to-right'order . Given lexicalook-up , there will then bean ' order of delivery ' of lexical formulae to the parser  . Consequently , we can characterise an incremental analysis as being one that at any stage includes the maximal amount of ' contentful ' combin-ation of the formulae  ( and hence also lexical meanings ) so far delivered , within the limits of possible combination that the proof system allows  . Note that we have not in these comments reintroduced an ordered proof system of the familiar kind by the backdoor  . In particular , we do not require formulae to combine under any notion of ' adjacency '  , but simply ' as soon as possible ' . 
For example , if the order of arrival of the formulae in ( 9 ) were ( i , iv ) -< ( ii ) -< ( iii ) ( recall that ( i , iv ) origin-ate from the same initial formula , and so must arrive together ) , then the proof ( 9 ) would be an incremental analysis . However , if the order instead was ( ii ) -< ( iii ) -< ( i , iv ) , then (9) would not be incremental , since at the stage when only ( ii ) and ( iii ) had arrived , they could combine ( as part of an equivalent alternative analysis )  , but are not so combined in (9) . 
6 Derivational Equivalence,
Dependency &: Normalisation
It seems we have achieved our aim of a linear deduction method that allows incremental analysis quite easily  , i . e . simply by generalising the combination rule as in  ( 8 )  , having modified indexed formulae using (5) . However , without further work , this ' achievement ' is of little value , because the resulting system will be very computationally expensive due to the problem of ' derivational equivalence ' or ' spurious ambiguity '  , i . e . the existence of multiple distinct proofs which assign the same reading  . For example , in addition to the proof (9) , we have also the equivalent proof (10) . 
(10) ( i ) ( ii ) ( iii ) ( iv)
Xo--YYo-WWo-ZZ
At . x(Az.t ) Au.yu Av . wvz
Yo--Z :) ~ v.y(wv)\[1,1\]
Y : y(wz)x:z(azy(wz ))\[1 , 0\] \[1 , 0\] The solution to this problem involves pecifying a normal form for deductions  , and allowing that only normal form proofs are constructed  ) Our route to specifying a normal form for proofs exploits a correspondence between proofs and dependency structures  . 
Dependency grammar ( DG ) takes as fundamental ~ This approach of ' normal form parsing ' has been applied to the associative Lambek calculus in  ( K 6 nig ,  1989) , ( Hepple ,  1990) , ( Hendriks ,  1992) , and to Combinatory Categorial Grammar in ( Hepple & Morrill ,  1989) , ( Eisner ,  1996) . 
347 the notions of head and dependent . An analogy is often drawn between CG and DG based on equating categorial functors with heads  , whereby the arguments sought by a functor are seen as its dependents  . 
The two approaches have some obvious differences.
Firstly , the argument requirements of a categorial functor are ordered  . Secondly , arguments in CG are phrasal , whereas in DG dependencies are between words . However , to identify the dependency relations entailed by a proof  , we may simply ignore argument ordering , and we can trace through the proof to identify those initial assumptions  ( ' words ' ) that are related as head and dependent by each combination of the proof  . This simple idea unfortunately runs into complications  , due to the presence of higher order functions . For example , in the proof (2) , since the higher order functor's argument category  ( i . e . 
Yo--Z ) has subformuiae corresponding to components of both of the other two assumptions  , Yo-W and Wo--Z , it is not clear whether we should view the higher order functor as having a dependency relation only to the ' functionally dominant'assumption Yo-W  , i . e . with dependencies a in ( lla ) , or to both the assumptions Yo-W and Wo-Z , i . e . with dependencies as perhaps in either ( llb ) or ( llc )  . 
The compilation approach , however , lacks this problem , since we have only first order formulae , amongst which the dependencies are clear , e . g . as in (12) . 
(11) ( a ) ~ f ~
Xo-(Yo-Z ) Yo-WWo-Z ? Xo-(Yo-Z ) Yo-WWo-Z
Xo-(Yo-Z ) Yo-WWo-Z(12) #-5
Xo--YYo-WWo-ZZ
Some preliminaries . We assume that proof assumptions explicitly record ' order of delivery ' information  , marked by a natural number , and so take the form : nxNF urther , we require the ordering to go beyond simple ' order of deliver y ' in relatively ordering first order assumptions that derive from the same original higher-order formula  .   ( This move simply introduce some extra arbitrary bias as a basis for distinguishing proofs  . ) It is convenient o have a ' linear ' notation for writing proofs  . We will write ( n/X\[a\] ) for an assumption ( such as that just shown )  , and ( XY/Z\[m , n \] ) for a combination of subproofs X and Y to give result formula Z by inference \[ m  , n \] . 
(13) dep((XY/Z\[m , n \])) = ( i , j , k ) where gov(m , X ) = ( i , k ) , fun ( Y ) = j ( 14 ) dep * ( (n/X \[ a \] ) ) -- 0 dep* ( (X Y / Z \[ re , n \] ) ) = ~ U dep* ( X ) Udep * ( Y ) where 5= dep ( ( XY/Z\[m , n \])) The procedure dep , defined in (13) , identifies the dependency relation established by any combination  , i . e . for any subproof P = ( XY/Z\[m , n \]) , dep(P ) returns a triple ( i , j , k ) , where i , j identify the head and dependent assumptions for the combination  , and k indicates the argument position of the head assumption that is involved  ( which has now been inherited to be argument m of the functor of the combination  )  . The procedure dep * , defined in (14) , returns the set of dependencies stablished within a subproof  . Note that depemploys the procedures gov ( which traces the relevant argument back to its source assumption -- the head  ) and fun ( which finds the functionally dominant assumption within the argument subproof -- the dependent  )  . 
(15) gov(i , ( n/x\[a \])) = ( n , i ) go v(i , ( xY/z\[m , n \])) = gov((i-m+1) , Y ) where to < i < ( m + n ) go v(i , ( XY/Z\[m , n \])) = gov(i , X ) where i < m go v(i , ( XY/Z\[m , n \])) = gov((i-n+1) , X ) where ( m + n ) < i ( 16 ) fun ( (n/X \[ a \] ) ) = n fun ( (X Y / Z \[ re , n \])) = fun(X ) From earlier discussion , it should be clear that an ' incremental nalys is ' is one in which any dependency to be established is established as soon as possible in terms of the order of delivery of assumptions  . 
The relation << of ( 17 ) orders dependencies in terms of which can be established earlier on  , i . e .   6  <<  7 if the later-arriving assumption of 6 arrives before the later-arriving assumption of 7- Note however that 6  , 7 may have the same later arriving assumption ( i . e . if this assumption is involved in more than one dependency  )  . In this case , < < arbitrarily gives precedence to the dependency whose two assumptions occur closer together in delivery order  . 
348 (17) 5 < < 7 ( where h = ( i , j , k ) , 7 = ( x , y , z )) if \]( max (/ , j ) < max(x , y)V ( max (/ , j ) = max(x , y ) Amin(i , \]1> rain(x , y ) ) ) We can use << to define an incremental normal form for proofs  , i . e . an incremental proof is one that is well-ordered with respect o < < in the sense that every combination  ( XY/Z\[m , n \] ) within it establishes a dependency 5 which follows under < < every dependency 5' established within the sub-proofs X and Y it combines  , i . e . 5' <<5 for each 5'6 dep*(X ) tJ dep*(Y) . This normal form is useful only if we can show that every proof has an equivalent normal form  . For present purposes , we can take two proofs to be equivalent if \] they establish identical sets of dependency relations  . 5 (18) trace(/ , j , ( i/X\[a \])) = jtrace(/ , j , ( XY/Z\[m , n \] ) ) =  ( m+k-1 ) where i 6 assure ( Y ) trace ( i , j , Y ) = ktrace(i , j , ( XY/Z\[m , n \])) = k where i 6 assure(X ) trace(i , j , X ) = k , k < mtrace(i , j , ( XY/Z\[m , hi ) ) =  ( k+n-1 ) where i 6 assure ( X ) trace ( i , j , X ) = k , k > m ( 19 ) assum ( (i / x \[ a \] ) ) =  i  assum ( (X Y / Z fro , n \] ) ) = assum ( X ) U assum ( Y ) We can specify a method such that given a set of dependency relations : D we can construct a corresponding proof  . The process works with a set of subproofs7) , which are initially just the set of assumptions ( i . e . each of the form ( n/F\[a \])) , and proceeds by combining pairs of subproofs together  , until finally just a single proof remains . Each step involve selecting a dependency 5 ( 5 =  ( i , j , k ) ) from / )   ( setting D := D-5 for subsequent purposes )  , removing the subproofs P , Q from 7) which contain the assumption si , j ( respectively ) , combining P , Q ( with P as functor ) to give a new subpro of R which 5This criterion turns out to be equivalento one stated in terms of the lambda terms that proofs generate  , i . e . two proofs will yield identical sets of dependency relations iff they yield proof terms that are fly-equivalent  . 
This observation should not be surprising , since the set of ' dependency relations ' returned for a proof is in essence just a rather unstructured summary of its functional relations  . 
is added to 7) ( i . e . P := (7)-P,Q)uR) . It is important to get the right value form in the combin-ation fro  , n \] used to combine P , Q , so that the correct argument of the assumption i ( as now inherited to the end-type of P ) is involved . This value is given by m = trace(i , k , P ) ( with trace as defined in (18)) . 
The process of proof construction is nondeterministic  , in the order of selection of dependencies for incorporation  , and so a single set of dependences can yield multiple distinct  , but equivalent , proofs ( as we would expect ) . 
To build normal form proofs , we only need to limit the order of selection of dependencies using < <  , i . e . 
requiring that the minimal element under < < is selected at each stage  . Note that this ordering restriction makes the selection process deterministic  , from which it follows that normal forms are unique  . Putting the above methods together , we have a complete normal form method for proofs of the first-order linear deduction system  , i . e . for any proof P , we can extract its dependency relations and use these to construct a unique  , maximally incremental , alternative proof -- the normal form of P . 
7 Proof Reduction and
Normalisation
The above normalisation approach is somewhat nonstandard  . We shall next briefly sketch how normalisation could instead be handled via the standard method of proof reduction  . This method involves defining a contraction relation  ( t > l ) between proofs , which is typically stated as a number of contraction rules of the form X t > lY  , where Xistermed are dex and Y its contractum . Each rule allows that a proof containing a redex be transformed into one where that occurrence is replaced by its contractum  . A proof is in normal form if \] it contains no redexes  . 
The contraction relation generates a reduction relation  ( t > ) such that X reduces to Y ( X\[>Y ) if \] Y is obtained from X by a finite series ( possibly zero ) of contractions . A term Y is a normal form of X iff ? is a normal form and X\[>Y  . 
We again require the ordering relation << defined in  ( 17 )  . A redex is any subproof whose final step is a combination of two well-ordered subproofs  , which establishes a dependency that undermines well-orderedness  . A contraction step modifies the proof to swap this final combination with the final one of an immediate subproof  , so that the dependencies the two combinations establish are now appropriately ordered with respect o each other  . The possibilities for reordering combination steps divide into four cases  , which are shown in Figure 1 . This re-

Y Z X Z Y \[ m,n \] ~ is , t\]
V where s < m1 :> V'\[8 , t\]\[(m+t-1) , n \]
WW
Yz X Y Z
Ira , n\]--\[(s-m+1), t\]
V where m_<s I>V'\[s , t\]--Ira , (n+t-1)\]Ws<(m+n ) Wx
XYZXZY ~\[ m,n\]~\[(s--n+1), t\]
V where s_>(re+n ) DV'\[~, t\]Ira,~\]
Ww
Y Z X Y Z
Ira , n\]--\[8, ( t-n+:)\]
Vt > V'--\[s , t\]\[(m+s-1), n\]
WW
Figure 1: Local Reordering of Combination Steps : the four cases duction system can be shown to exhibit the property  ( called strong normalisation ) that every reduction is finite , from which it follows that every proof has a normal form  .   6   8 Normal form parsing The technique of normal form parsing involves ensuring that only normal form proofs are construc-ted by the parser  , avoiding the unnecessary work of building all the nonnormal form proofs  . At any stage , all subproof so far constructed are in normal form  , and the result of any combination is admitted only provided it is in normal form  , otherwise it is discarded . The result of a combination is recognised as nonnormal form if it establishes a dependency that is out of order with respect to that of the final combination of at least one of the two subproofs combined  ( which is an adequate criterion since the subproofs are well-ordered  )  . The procedures defined above can be used to identify these dependencies  . 
9 The Degree of Incrementality
Let us next consider the degree of incrementality that the above system allows  , and the sense in which 6To prove strong normalisation , it is sufficient o give a metric which assigns to each proof a finite nonnegative integer score  , and under which every contraction reduces a proof 's score by a nonzero amount  . The following metrict t can be shown to suffice :   ( a ) for P = ( nIX\[a\] )  , #( P ) = 0 , ( b ) for P = ( XY/Z\[m , n \]) , whose final step establishes a dependency a , #( P ) = it(X ) + ~ u(Y ) + D , where D is the number of dependencies 5' such that < < a ' , which are established in X and Y , i . e . D =\[ A\]whereA=5'\]5' edep , ( X ) Udep , ( Y)A5<<5' . 
it might be considered maximal . Clearly , the system does not allow full ' word-by-word ' incrementality  , i . e . where the words that have been delivered at any stage in incremental processing are combined to give a single result formula  , with combinations to incorporate each new lexical formula as it arrives/For example  , in incremental processing of Today Johnsang , the first two words might yield ( after compil-ation ) the first-order formulaeso-s and np , which will not combine under the rule (8) . sInstead , the above system will allow precisely those combinations that establish functional relations that are marked out in lexical type structure  ( i . e . subcategorisation ) , which , given the parMlel-is m of syntax and semantics , corresponds to allowing those combinations that establish semantically relevant functional relations amongst lexical meanings  . Thus , we believe the above system to exhibit maximal incrementality in relation to allowing ' semantically content ful'combinations  . In dependency terms , the system allows any set of initial formulae to combine to a single result iff they form a connected graph under the dependency relations that obtain amongs them  . 
Note that the extent of incrementality allowed by using ' generalised composition ' in the compiled first-order system should not be equated with that which  7For an example of a system allowing word-by-word incrementality  , see ( Milward ,  1995) . 
S Note that this is not to say that the system is unable to combine these two types  , e . g . a combination so--s , np = ~ so-(so-np ) is derivable , with appropriate compilation . The point rather is that such a combination will typically not happen as a component in a proof of some other overall deduction  . 
3 50 would be allowed by such a rule in the original ( non-compiled ) system . We can illustrate this point using the following type combination  , which is not an instance of even ' generalised ' composition  . 
Xo-(Yo-Z ), Yo--W=~Xo-(Wo-Z)
Compilation of the higher-order assumption would yield Xo--Yplus Z  , of which the first formula can compose with the second assumption Yo-W to give Xo-W  , thereby achieving some semantically contentful combination of their associated meanings  , which would not be allowed by composition over the original formulae  .   9   10 Conclusion We have shown how the linear categorial deduction method of  ( Hepple ,  1996 ) can be modified to allow incremental derivation , and specified an incremental normal form for proofs of the system  . These results provide for an efficient incremental linear deduction method that can be used with various labelling disciplines as a basis for parsing a range of type-logical formalisms  . 

Jason Eisner 1996 . ' Efficient Normal-Form Parsing for Combinatory Categorial Grammar  . ' Proc . o /

Dov M . Gabbay . 1996. Labelle deductive systems.
Volume 1. Oxford University Press.
Herman Hendriks .  1992 . ' Lambek Semantics : normalisation , spurious ambiguity , partial deduction and proofnets ' , Proc . of Eighth Amsterdam Colloquium , ILLI , University of Amsterdam . 
Mark Hepple .  1990 . ' Normal form theorem proving for the Lambek calculus '  . Proc . of COLING90 . 
Mark Hepple .  1992 . ' Chart Parsing Lambek Grammars : Modal Extensions and Incrementality '  , 
Proc . of COLING-92.
Mark Hepple .  1995 . ' Mixing Modes of Linguistic Description in Categorial Grammar '  . Proceedings
EACL-7, Dublin.
Mark Hepple .  1996 . ' A Compilation-Chart Method for Linear Categorial Deduction '  . Proc . of
COLING96, Copenhagen.
9This combination corresponds to what in a directional system Wittenburg  ( 1987 ) haster meda'predict-ive combinator ' , e . g . such as X/(Y/Z ), Y/W = vW/Z . 
Indeed , the semantic result for the combination i the first-order system corresponds closely to that which would be produced under Wittenburg's rule  . 
Mark Hepple & Glyn Morrill .  1989 . ' Parsing and derivational equivalence . ' Proc . of EACL4 . 
Esther K Snig .  1989 . ' Parsing as natural deduction ' . 
Proc . of ACL-2Z
Esther K Snig .  1990 . ' The complexity of parsing with extended categorial grammars ' Proc  . of

Esther K Snig .  1994 . ' A Hypothetical Reasoning Algorithm for Linguistic Analysis  . ' Journal of Logic and Computation , Vol . 4, No1, ppl-19 . 
Joachim Lambek .  1958 . ' The mathematics of sentence structure . ' American Mathematical
Monthly , 65, pp 154-170.
Joachim Lambek .  1961 . ' On the calculus of syntactic types . ' R . Jakobson ( Ed) , Structure of Language and its Mathematical Aspects  , Proceedings of the Symposia in Applied Mathematics XII  , 
American Mathematical Society.
David Milward .  1995 . ' Incremental Interpretation of Categorial Grammar  . ' Proceedings EACL-7,

Michael Moortgat .  1992 . ' Labelled deductive systems for categorial theorem proving '  . Proc . of Eighth Amsterdam Colloquium , ILLI , University of Amsterdam . 
Michael Moortgat & Richard T . Oehrle .  1994 . ' Ad-jacency , dependency and order ' . Proc . of Ninth
Amsterdam Colloquium.
Michael Moortgat & Glyn Morrill .  1991 . ' Heads and Phrases : Type Calculus for Dependency and Constituency  . ' To appear : Journal of Language,
Logic and Information.
Glyn Morrill .  1994 . Type Logical Grammar : Categorial Logic of Signs . Kluwer Academic Publishers , Dordrecht . 
Glyn Morrill .  1995 . ' Higher-order Linear Logic Programming of Categorial Deduction '  . Proc . of
EACL-7, Dublin.
Mark J . Steedman .  1989 . ' Grammar , interpretation and processing from the lexicon . 'In Marslen-Wilson , W . ( Ed ) , Lexical Representation ad Process , MIT Press , Cambridge , MA . 
Kent Wittenburg .  1987 . ' Predictive Combinators : A method for efficient parsing of Combinatory Categorial Grammars  . ' Proc . of ACL-25 . 

