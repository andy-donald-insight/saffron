Rich Prior Knowledge in
Learning for NLP
Gregory Druck , Kuzman Ganchev , Jo?o Gra?a
Why Incorporate Prior Knowledge?
have : unlabeled data
option : hire
linguist
annotators
Why Incorporate Prior Knowledge?
have : unlabeled data
option : hire
linguist
annotators
This approach does not
scale to every task and
domain of interest.
However , we already
know a lot about most
problems of interest.
Example : Document Classification
?
Prior Knowledge:
?
labeled features : information about the label
distribution when word w is present
--- --- -----
-- -- --- ----
--- --- --- ---
-- ---------
------- ---- --
--- --- -----
-- -- --- ----
--- --- --- ---
-- ---------
------- ---- --
--- --- -----
-- -- --- ----
--- --- --- ---
-- ---------
------- ---- --
--- --- -----
-- -- --- ----
--- --- --- ---
-- ---------
------- ---- --
--- --- -----
-- -- --- ----
--- --- --- ---
-- ---------
------- ---- --
--- --- -----
-- -- --- ----
--- --- --- ---
-- ---------
------- ---- --
Documents
Labels
newsgroups classification
baseball Mac politics
...
hit Apple senate
...
Braves Macintosh taxes
...
runs Powerbook liberal
...
sentiment polarity
positive negative
memorable terrible
perfect boring
exciting mess
Example : Information Extraction
?
Prior Knowledge:
?
labeled features:
?
the word ACM should be labeled either journal or
booktitle most of the time
?
non-Markov ( long-range ) dependencies:
?
each reference has at most one segment of each type W . H . Enright . Improving the efficiency of matrix operations in the numerical solution of stiff ordinary differential equations . ACM Trans . Math . Softw ., 4(2), 127-136, June 1978.
extraction from research papers:
Example : Part-of-speech Induction ?
Prior Knowledge : ? linguistic knowledge : each sentence should have a verb ? posterior sparsity : the total number of different POS tags assigned to each word type should be small
Tags
A career with the European institutions must become more attractive . Too many young , new...
Text
Example : Dependency Grammar Induction ?
Prior Knowledge : ? linguistic rules : nouns are usually dependents of verbs ? noisy labeled data : target language parses should be similar to aligned parses in a resource-rich source language
Example : Word Alignment ?
Prior Knowledge : ?
Bijectivity : alignment should be mostly one-to-one ? Symmetry : source?target and target?source alignments should agree A career with the European institutions must become more attractive.
Uma carreira nas institui??es europeias t?m de se tornar mais atractiva.
This Tutorial
In general , how can we leverage such knowledge and an unannotated corpus during learning?
Notation & Models input variables ( documents , sentences ): structured output variables ( parses , sequences ): unstructured output variables ( labels ): input / output variables for entire corpus : probabilistic model parameters : generative models : discriminative models : model feature function : p ?( y|x ) p?(x,y ) x y ? f(x , y)
X Y y
Learning Scenarios ?
Unsupervised : ? unlabeled data + prior knowledge ?
Lightly Supervised : ? unlabeled data + ? informative ? prior knowledge ? i.e . provides specific information about labels ?
Semi-Supervised : ? labeled data + unlabeled data + prior knowledge
Running Example #1:
Document Classification ? model : Maximum Entropy Classifier ( Logistic Regression ) ? setting : lightly supervised ; no labeled data ? prior knowledge : ? labeled features : information about the label distribution when word w is present ? label is often hockey or baseball when game is present p?(y|x ) = exp (? ? f(x , y))
Running Example #2:
Word Alignment ? model : first-order Hidden Markov Model ( HMM ) ? setting : unsupervised ? prior knowledge : ? Bijectivity : alignment should be mostly one-to-one 1 1 2 3 we know the way sabemos el camino null 1 2 3 0 p?(y,x ) = p?(y0)
N ? i=1 p?(yi|yi?1)p ?( x i|yi)
Problem ?
This output does not agree with prior knowledge ! ? six target words align to source word animada ? five source words do not align with any target word gameconvivialvery,animatedanwasit cordialmuyyanimadamaneraunadejugaban model data output x
Limited Approach : Labeling Data limitation : Often unclear how to do conversion ? Example #1: often ( not always ) game ? { hockey,baseball } ? Example #2: alignment should be mostly one-to-one prior knowledge --- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- -- approach : Convert prior knowledge to labeled data.
Prototypes (+ cluster features ): ? [ Haghighi & Klein 06]
Others : ? [ Raghavan & Allan 07] ? [ Schapire et al 02]
Limited Approach : Bayesian Approach approach : Encode prior knowledge with a prior on parameters.
limitation : Our prior knowledge is not about parameters ! Parameters are difficult to interpret ; hard to get desired effect.
?
Example #1: often ( not always ) game ? { hockey,baseball } ? Example #2: alignment should be mostly one-to-one natural : ? should be small ( or sparse )?? ( informative prior ) possible : ? should be close to ?? i ?? i p (?) specifying x [ Dayanik et al 06] [ Johnson 07], among many others
Limited Approach : Augmenting Model limitation : can be difficult to get desired effect ? Example #1: often ( not always ) game ? { hockey,baseball } limitation : may make exact inference intractable ? Example #2: Bijectivity makes inference # P-complete x additional variables and dependencies.
This Tutorial develop : ? a language for directly encoding prior knowledge ? methods for learning with knowledge in this language ? ( approximations to modeling this language directly ) ? ( loosely ) these methods perform mappings for us : ? encoded prior knowledge parameters ? encoded prior knowledge labeling ? --- -------- -- ----- ------- --- ------ -------- -- ----- ------- --- ------ -------- -- ----- ------- --- ---? ? A Language for Encoding Prior Knowledge Our prior knowledge is about distributions over latent output variables . ( output variables are interpretable ) Specifically , we know some properties of this distribution : ? Example #1: often ( not always ) game?{hockey,baseball } Formulation : know about the expectations of some functions under distribution over latent output variables
Constraint Features ? constraint feature function : ?
Example #1: ? for document x , returns a vector with a 1 in the lth position if y is the lth label and the word w is in x ?
Example #2: ? returns a vector with mth value = number of target words in sentence x that align with source word m ?( x , y ) ? w(x , y ) = 1 ( y = l )1( w ? x ) ?( x,y ) =
N ? i=1 1(yi = m)
Expectations of Constraint Features ?
Example #1: Corpus expectation : ? vector with expected distribution over labels for documents that contain w ( is the count of w ) ?
Example #2: Per-example expectation : ? vector with mth value = expected number of target words that align with source word m
Ep ? [?( X,Y )] = ? x ? y p?(y|x)?w(x , y)
E p ? [?( x,y )] = ? y p?(y|x)?(x,y ) c w
Expressing Preferences ? express preferences using target values : ?
Example #1: ? label distribution for game is close to [40% 40% 20%] ?
Example #2: ? expected number of target words that align with each source word is at most one ??
E p ? [? w ( X , Y )] ? ??
E p ? [?( x , y )] ? ??
Preview : Labeled Features
User Experiments [ Druck et al 08] 0 100 200 300 400 500 600 700 8000.4 0.5 0.6 0.7 0.8 0.9 tes ting ac cur acy
GEER ~2 minutes , 100 features labeled ( or skipped ): 82% accuracy ~15 minutes , 100 documents labeled ( or skipped ): 78% accuracy
PC vs . Mac complete set of labeled features
PC Mac dos mac ibm apple hp quadra dx targets set with simple heuristic : majority label gets 90% of mass
Preview : Word Alignment [ Gra?a et al 10] 77.5 86.25
HMM HMM + Bijectivity Constraint
Overview of the Frameworks
Running Example
Model Family : conditional exponential models are model features p?(Y|X ) = exp ( ? ? f(X,Y))
Z(X)
Z(X ) = ?
Y e x p ( ? ? f(X , Y )) f ( X , Y ) Choosing parameters Model Family : conditional exponential models Objective : maximize observed data likelihood
Note : Frameworks also suitable for generative models ( no labeled data necessary ) ? p?(Y|X ) = exp ( ? ? f(X,Y))
Z(X ) max ? log p ?( Y L | X L ) + log p (?) d e f = L (?; D L )
Visual Example : Maximum Likelihood
Model:
Objective : -+ oo o o o o o o max ? log p ?( Y L | X L )? 0. 1??? p(Y|X ) = ? i exp ( y i x i ? ?)
Z ( x i)
A language for prior information
The expectations of user-defined constraint features are close to some value ?( X , Y ) ??
E [?( X , Y )] ? ??
Running Example:
Want to ensure that 25% of unlabeled documents are about politics ? constraint features ? preferred expected value ?
Expectation w.r.t . unlabeled data ?( x , y ) = ? 1 if y is ? politics ? 0 otherwise ?? = 0 . 25
Constraint-Driven Learning
Motivation : Hard EM algorithm with preferences
Hard EM:
Constraint Driven Learning:
M - Step : set ? = arg max ? log p ?( ? Y | X )
E-Step : set ? Y = argmax
Y log p ?( Y | X )? penalty ( Y )
M - Step : set ? = arg max ? log p ?( ? Y | X )
E-Step : set ? Y = argmax
Y log p ?( Y | X )
M . Chang , L . Ratinov , D . Roth (2007).
Constraint-Driven Learning
Motivation : Hard EM algorithm with preferences
Constraint Driven Learning : ? penalties encode similar information as * more on this later * ?
E-Step can be hard ; use beam search
E-Step : set ? Y = argmax
Y log p ?( Y | X )? penalty ( Y )
M - Step : set ? = arg max ? log p ?( ? Y | X )
E [ ? ] ? ??
Visual Example : Constraint Driven Learning where are ? imagined ? labels and ? Y -+ oo o o o o o o ?[ ? Y ] = count (+ , ? Y ) max ?, Y ? log p ?( Y L | X L )? 0. 1??? ? Y ) = 2
Posterior Regularization
Motivation : EM algorithm with sane posteriors
EM:
Constrained EM:
E-Step : set q ( Y ) = argmin q
D KL ( q ( Y )|| p ?( Y | X ))
M-Step : set ? = argmax ?
E q ( Y ) [ p ?( Y | X )]
E-Step : set q ( Y ) = argmin q ? Q
D KL ( q ( Y )|| p?(y|x))
M-Step : set ? = argmax ?
E q ( Y )[ p ?( Y | X )]
J . Gra?a , K . Ganchev , B . Taskar (2007).
Posterior Regularization
Motivation : EM algorithm with sane posteriors Idea : provide constraints
Objective:
E [ ? ] ? ?? define Q : set of q such that E q [?] ? ?? m ax ?
L (? ; D L )? D KL ( Q || p ?( Y | X )) run EM-like procedure but use proposal q ? Q where
D KL is KullbackLeibler divergence
X = D U are the input variables for unlabeled corpus
Y is label for entire unlabeled corpus
Posterior Regularization
Hard constraints:
Soft constraints : max ?
L (?; D L ) ? min q ? Q
D KL ( q ( Y )|| p ?( Y | X ))
Q = ? q ( Y ) : ? ? ? E q [?( Y )] = ?? ? ? ? ? ? ? max ?
L(?;D L ) ? min q ?
D KL ( q ( Y )|| p ?( Y | X )) + ? ? ? ? E q [?( Y )] = ?? ? ? ? ? Visual Example : Posterior Regularization where : -+ oo o o o o o o max ? log p ?( Y L | X L )? 0. 1???
D KL ( Q || p ?) = min q
D KL ( q || p ?) s.t . E q [?] = 2
Generalized Expectation Constraints
Motivation : augment loglikelihood with cost for ? bad ? posteriors.
Objective : where is shorthand
Optimization : gradient descent on max ?
L (?; D L )? ? ? ? E p ? ( Y | X ) [?] ? ?? ? ? ? ?
E p ? ( Y | X ) [?] = E p ? ( Y | X ) [?( X , Y )] = ?
Y p ?( Y | X )?( X , Y ) ?
G . Mann , A . McCallum (2007).
A visual comparison of the frameworks
Objective : Generalized Expectation Constraints -+ oo o o o o o o max ? log p ?( Y L | X L ) ? 0. 1???
Types of constraints
Constraint Driven Learning : Penalized Viterbi ? Easy if decompose as the model.
and ?
Otherwise : ?
Beam search ?
Integer linear program p ( Y | X ) = ? c p c ( y c | X ) argmax
Y log p ?( Y | X ) ? ??( X , Y )? ???? ??( X , Y )? ???? ??( X , Y )? ???? = ? c ? c ( X , y c )
Types of constraints
Posterior Regularization : KL projection ? Usually easy if decompose as the model : and ? Otherwise : Sample ( e.g . K . Bellare , G . Druck , and A . McCallum , 2009) ?( Y , X ) p ( Y | X ) = ? c p c ( y c | X ) q ( Y | X ) = ? c q c ( y c | X ) ?( X , Y ) = ? c ? c ( X , y c ) ? min q D KL ( q || p ?) s.t . ? E q [?] ? ???? ? ?
Types of constraints
Generalized Expectation Constraints : Direct gradient ?
Usually easy if : ? decomposes as the model ? Can compute * more on this later * ?
Unstructured ?
Sequence , Grammar ( semiring trick ) ?
Otherwise : sample or approximate the gradient.
?( Y , X ) max ?
L (?; D L )? ? ? ? E p ? ( Y | X ) [?] ? ?? ? ? ? ? ?( X , Y ) = ? c ? c ( X , y c )
E [ ?? f ]
A Bayesian View : Measurements
Objective : mode of given observations
X L ? X
Y L Y ?( X , Y ) b
Figure 4.1: The model used by Liang et al [2009], using our notation . We have separated treatment of the labeled data ( XL,YL ) from treatment of the unlabeled data X.
and produce some value ?( X,Y ), which is never observed directly . Instead , we observe some noisy version b ? ?( X,Y ). The measured values b are distributed according to some noise model pN(b|?(X,Y )). Liang et al [2009] note that the optimization is convex for log-concave noise and use box noise in their experiments , giving b uniform probability in some range near ?( X,Y).
In the Bayesian setting , the model parameters ? as well as the observed measurement values b are random variables . Liang et al [2009] use the mode of p(?|XL,YL,X,b ) as a point estimate for ?: argmax ? p(?|XL,YL,X,b ) = argmax ? ?
Y p(?,Y,b|X,XL,YL ), (4.6) with equality because p(?|XL,YL,X,b ) ? p(?,b|XL,YL,X ) = ? Y p(?,Y,b|X,XL,YL ). Liang et al [2009] focus on computing p(?,Y,b|X,XL,YL).
They define their model for this quantity as follows : p(?,Y,b|X,XL,YL ) = p(?|XL,YL ) p?(Y|X ) pN(b|?(X,Y )) (4.7) where the Y and X are particular instantiations of the random variables in the entire unlabeled corpusX . Equation 4.7 is a product of three terms : a prior on ?, the model probability p?(Y|X ), and a noise model pN(b |?). The noise model is the probability that we observe a value , b , of the measurement features ?, given that its actual value was ?( X,Y ). The idea is that we model errors in the estimation of the posterior probabilities as noise in the measurement process . Liang et al [2009] use a uniform distribution over ?( X,Y ) ? ?, which they call ? box noise ?. Under this model , observing b farther than ? from ?( X,Y ) has zero probability . In log space , the exact MAP objective , becomes : max ?
L (?) + logEp?(Y|X ) ? pN(b|?(X,Y )) ? . (4.8) ? l og p (?) + ? ( x , y ) ? D L l og p ?( y | x ) = L (? ; D L ) ?
P . Liang , M . Jordan , D . Klein (2009)
Objective : mode of given observations
A Bayesian View : Measurements
X L ? X
Y L Y ?( X , Y ) b
Figure 4.1: The model used by Liang et l . [2009], using our notation . We have separated treatment of the labeled data ( XL,YL ) from treatment of the unlabeled data X.
and produce some value ?( X,Y ), which is never observed directly . Instead , we observe some noisy version b ? ?( X,Y ). The measured values b are distributed according to some noise model pN(b|?(X,Y )). Liang et al [2009] note that the optimization is convex for log-concave noise and use box noise in their experiments , giving b uniform probability in some range near ?( X,Y).
In the Bayesian setting , the model parameters ? as well as the observed measurement values b are random variables . Liang et al [2009] use the mode of p(?|XL,YL,X,b ) as a point estimate for ?: argmax ? p(?|XL,YL,X,b ) = argmax ? ?
Y p(?,Y,b|X,XL,YL ), (4.6) with equality because p(?|XL,YL,X,b ) ? p(?,b|XL,YL,X ) = ? Y p(?,Y,b|X,XL,YL ). Liang et al [2009] focus on computing p(?,Y,b|X,XL,YL).
They define their model for this quantity as follows : p(?,Y,b|X,XL,YL ) = p(?|XL,YL ) p?(Y|X ) pN(b|?(X,Y )) (4.7) where the Y and X are particular instantiations of the random variables in the entire unlabeled corpusX . Equation 4.7 is a product of three terms : a prior on ?, the model probability p?(Y|X ), and a noise model pN(b |?). The noise model is the probability that we observe a value , b , of the measurement features ?, given that its actual value was ?( X,Y ). The idea is that we model errors in the estimation of the posterior probabilities as noise in the measurement process . Liang et al [2009] use a uniform distribution over ?( X,Y ) ? ?, which they call ? box noise ?. Under this model , observing b farther than ? from ?( X,Y ) has zero probability . In log space , the exact MAP objective , becomes : max ?
L (?) + logEp?(Y|X ) ? pN(b|?(X,Y )) ? . (4.8) ?
L (?; D L ) + log E p ? ( Y | X ) ? p (??|?( X , Y )) ? ?
What's wrong with this picture?
Objective : mode of given observations Example : Exactly 25% of articles are ? politics ? What is the probability exactly 25% of the articles are labeled `` politics ''? How do we optimize this with respect to ? max ?
L (? ; D L ) + log E p ?( Y | X ) ? p (??|?( X , Y )) ? ? ? p (??|?( X , Y )) = 1 ? ?? = ?( X , Y ) ?
E p ?( Y | X ) ? 1 (?? = ?( X , Y )) ?
What's wrong with this picture?
Example : Compute prob : 25% of docs are ? politics?.
Naively : in this case we can use a DP , but if there are many constraints , that doesn?t work.
Easier : What is the expected number of ? politics ? articles?
Article p(?politics ?) 1 0.2 2 0.4 3 0.1 4 0.6 0 . 2 + 0 . 4 + 0 . 1 + 0 . 6 0 . 2 ? (1 ? 0 . 4) ? (1 ? 0 . 1) ? (1 ? 0 . 6) + . . . + +(1 ? 0 . 2) ? (1 ? 0 . 4) ? (1 ? 0 . 1) ? 0 . 6
Probabilities and Expectations difficult to compute expectations of arbitrary functions but...
Usually : decomposes as a sum e.g . 25% of articles are ? politics?
Idea : approximate ?( X , Y ) ?( X , Y ) = ? instances ?( x , y )
E p ?( Y | X ) ? p ? ?? | ?( X , Y ) ?? ? p ? ?? | E p ?( Y | X ) [?( X , Y )] ?
Probabilities and Expectations
Approximation:
Objective:
Example : is Gaussian is so for appropriate this is identical to GE!
E p ? ( Y | X ) ? p ? ?? | ? ?? ? p ? ?? | E p ? ( Y | X ) [ ? ] ? max ?
L (?; D L ) + log p ? ?? | E p ?( Y | X ) [?] ? l og p ? ?? | E [?] ? ? p ? ?? | E [ ? ] ? l og p ? ?? | E [ ? ] ? ? ? ? ? E [ ? ] ? ?? ? ? ?
Optimizing GE objective
GE Objective : ?
Gradient involves covariance this can be hard because and the usual dynamic programs ( inside outside , forward backward ) can?t compute this.
C ov ( ? , f ) = E [ ?? f ] ? E [ ? ] ? E [ f ]
E [?? f ] = ?
Y p ( Y )?( Y )? f ( Y )
O GE = max ?
L (? ; D L )? ? ? ? E p ?( Y | X ) [ ?( X , Y )] ? ?? ? ? ? ?
Optimizing GE Objective
Maintaining both and in the DP is expensive * Semiring trick can help for some problems * x1 x2 x3 x3 y1 y2 y3 y4
E [?? f ] = ?
Y p ( Y )?( Y )? f ( Y ) ?( Y )? f ( Y ) = ? ? i ?( yi ) ? ? ? ? ? j f ( y j ) ? ? yi y j E.g . if inference is a hypergraph problem.
A Variational Approximation
GE Objective : ?
Can be hard to compute in gradient.
Idea : use variational approximation * Note : this is the PR objective * q ( Y ) ? p ?( Y | X ) max ? , q ( Y ) L (?; D L )? D KL ? q ( Y ) || p ?( Y | X ) ? ? ? ? ? E q [?( X , Y )] ? ?? ? ? ? ?
C ov ( ? , f )
O GE = max ?
L (? ; D L )? ? ? ???? E p ?( Y|X ) [ ?( X , Y )] ? ? ? ?
Approximating with the mode
PR Objective : sometimes minimizing the KL is hard.
Idea : use hard assignment : ? becomes ? becomes ? use EM-like procedure to optimize
Constraint Driven Learning Objective : max ? , q ( Y ) L (?; D L )? D KL ? q ( Y ) || p ?( Y | X ) ? ? ? ? ? E q [?( X , Y )] ? ?? ? ? ? ? q ( Y ) ? 1 ( Y = ? Y ) ? ? ? E q [?( X , Y )] ? ?? ? ? ? ? l og p ( ? Y ) D KL ? q ( Y ) || p ?( Y | X ) ? l og p (?? | ?( X , ? Y )) m ax ?, ? Y
L (? ; D L ) + log p ?( ? Y ) + log p (??|?( X , ? Y ))
Visual Summary
Measurements
Generalized
Expectation
Distribution
Matching
Posterior
Regularization
Coupled Semi-
Supervised
Learning
Constraint
Driven
Learning variational approximation;
Jensen?s inequality variational approximation
MAP approximation
MAP approximation logE [ p N (??|?)] ? log p N (??| E[?])
Applications ?
Unstructured problems : ?
Document Classification ?
Sequence problems : ?
Information Extraction ?
Pos-Induction ?
Word Alignment ?
Tree problems : ?
Grammar Induction
Document Classification ?
Model : Max . Entropy Classifier ( Logistic Regression ) ? Challenge : What if we have no labeled data ? ? cannot use standard unsupervised learning : --- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- --
Documents
Labels p ?( y|x ) = exp (? ? f(x , y )) ? y exp (? ? f(x , y )) ? y p ?( y | x )= 1
Labeled Features ? often we can still provide some light supervision ? prior knowledge : labeled features ? formally : have an estimate of the distribution over labels for documents that contain word w : ?? w newsgroups classification baseball Mac politics ...
hit Apple senate ...
Braves Macintosh taxes ...
runs Powerbook liberal ...
sentiment polarity positive negative memorable terrible perfect boring exciting mess
Leveraging Labeled Features with GE [ Mann & McCallum 07], [ Druck et al 08] ? constraint feature : ? for a document x , returns a vector with a 1 in the lth position if y is the lth label and the word w is in x ? expectation : label distribution for docs that contain w ? GE penalty : KL divergence from target distribution ? w ( x , y ) = 1 ( y = l )1( w ? x ) ? x
E p ? ( y | x ) [ ? w(x , y)]
D KL ? ?? w || ? x
Ep?(y | x)[?w(x , y )] ?
User Experiments with Labeled Features [ Druck et al 08] 0 100 200 300 400 500 600 700 8000.4 0.5 0.6 0.7 0.8 0.9 tes ting ac cur acy
GEER ~2 minutes , 100 features labeled ( or skipped ): 82% accuracy ~15 minutes , 100 documents labeled ( or skipped ): 78% accuracy
PC vs . Mac complete set of labeled features
PC Mac dos mac ibm apple hp quadra dx targets set with simple heuristic : majority label gets 90% of mass
Experiments with Labeled Features [ Druck et al 08] GE ( model contains only labeled features ) GE ( model also contains unlabeled features ) 15x 3.5x 6.5x learning about ? unlabeled features ? through covariance improves generalization estimated speedup over labeling documents
Information Extraction : Example Tasks ? citation extraction : ? apartment listing extraction : Detached single family house . 3 bedrooms 1 1/2 baths . Almost 1000 square feet in living area . 1 car garage . New pergo floor and tile kitchen floor . New interior/exterior paint . Close to shopping mall and bus stop . Near 101/280. Available July 1, 2004. If you are interested , email for more details.
Cousot , P . and Cousot , R . 1978. Static determination of dynamic properties of recursive procedures . In Proceedings of the IFIP Conference on Programming Concepts , E . Neuhold,
Ed . North-Holland Pub . Co ., 237-277.
Information Extraction : Markov Models ? models for sequence labeling based IE ?
Hidden Markov Model ( HMM ): ?
Conditional Random Field ( CRF ): p?(y,x ) = p?(y0)
N ? i=1 p?(yi|yi?1)p ?( x i|yi ) p?(y|x ) = exp(
N ? i =1 ? ? f ( x , yi ? 1 , yi )) expectation : label distribution when q is true model : Linear Chain CRF note : Semiring trick makes GE
O(L [ Mann & McCallum 08]
Information Extraction : Labeled Features [ Mann & McCallum 08], [ Liang et al 09]
ROOMMATES respectful
CONTACT * phone*
FEATURES laundry apartments example labeled features : ? x ? i
E p?(yi | x )[? q(x , yi , i )] constraint features : vector with a 1 in the lth position if y is the lth label and predicate q is true ( i.e . w is present at i ) ? q ( x , yi , i ) = 1 ( y i = l)q(x , i ) Information Extraction : Labeled Features [ Haghighi & Klein 06], [ Mann & McCallum 08], [ Liang et al 09] apartment listing extraction
Prototype
GE ( KL)
Measurements/PR supervised CRF (100) [ MM08] ? accurate with constraints alone ? outperform fully supervised with constraints and labeled data
Limitations of Markov Models ? predicted : ? prediction has two author and two title segments : ? error #1: Neuhold , Ed . should be editor ? error #2: North-Holland Pub . Co ., should be publisher ? A Markov model cannot represent that at most one segment of each type appears in each reference.
Cousot , P . and Cousot , R . 1978. Static determination of dynamic properties of recursive procedures . In Proceedings of the IFIP Conference on Programming Concepts , E . Neuhold,
Ed . North-Holland Pub . Co ., 237-277.
LongRange Constraints [ Chang et al 07] [ Bellare et al 09] ? ? Each field is a contiguous sequence of tokens and appears at most once in a citation .? ? constraint feature : counts the number of segments of each type ? constrained to be ? 1 using PR or CODL ? additional constraints : 10 labeled features such as : ? pages?pages ? proc.?booktitle
LongRange Constraints [ Chang et al 07] [ Bellare et al 09] constraints improve both
CRF ( PR ) and HMM ( CODL )
CRF CRF + PR
HMM HMM + CODL citation model method description [ Mann et al 07] MaxEnt GE constraints on label marginals [ Druck et al 09] CRF GE actively labeled features [ Bellare &
McCallum 09] alignment
CRF
GE labeled features [ Singh et al 10] semi-Markov
CRF
PR labeled gazetteers [ Druck et al 10] HMM PR constraints derived from labeled data
Other Applications in
Information Extraction
Pos Induction
Low Tag Ambiguity [ Gra?a et al 09]
JJ
VB
NN car object romantic offensive being
E[degree ] = 1.5E[degree ] = 10000 0 2 4 6 8 10 0 200 400 600 800 1000 1200 1400 1600 1800L 1L ! rank of word by L1L!SupervisedHMMDistribution of word ambiguity
N V ADJ Prep ADV 0.9 0.1 0 0 0 0.7 0.1 0.1 0 0.1 0.1 0.3 0 0.6 0 0.3 0.6 0 0 0.1 0.3 0.7 0 0 0 ?
Pick a particular word type : run ?
Stack all occurrences ?
Calculate posterior probability ?
Take the maximum for each tag ?
Sum the maxes a run into town.
of the mile run.
run gold.
run errands.
run for mayor.
Sum 0.9 0.7 0.1 0.6 0.2
Max
Sum 2.5
Measuring Tag Ambiguity [ Gra?a et al 09] ? wti : Word type w has hidden state t at occurrence i m i n cwt
E q ( y ) [? wti ] ? c wt ?1 / ?? = ? w t c w t
Tag Sparsity [ Gra?a et al 09] 2.5 3.75
A m b i g u i t y d i f f e r e n c e
HMM L1LMax
Average ambiguity difference 0 2 4 6 8 10 0 200 400 600 800 1000 1200 1400 1600 1800L 1L ! rank of word by L1L!SupervisedHMMHMM+SpDistribution of word ambiguity
Results [ Gra?a et al 09]
HMM HMM+Sp 3.8 6.7 7.4 7.6 9.6 3.8 6.5 % Average Improvement
Word Alignments [ Gra?a et al 10] ?
Bijectivity constraints : ?
Each word should align to at most one other word ?
Symmetry constraints : ?
Directional models should agree
Bijectivity Constraints [ Gra?a et al 10]
Bijective Constraints 0 1 2 3 4 5 6 7 8 0 ? ? ? ? ? ? ? ? ? jugaban ? ? 1 1 ? ? ? ? ? ? ? ? ? de ? ? 1 2 ? ? ? ? ? ? ? ? ? una ? ? 1 3 ? ? ? ? ? ? ? ? ? manera ? ? 1 4 ? ? ? ? ? ? ? ? ? animada ? ? 1 5 ? ? ? ? ? ? ? ? ? y ? ? 1 6 ? ? ? ? ? ? ? ? ? muy ? ? 1 7 ? ? ? ? ? ? ? ? ? cordial ? ? 1 8 ? ? ? ? ? ? ? ? ?. ? ? 1 it was an animated , very convivial game .
50 / 74
Bijective Constraints - After projection 0 1 2 3 4 5 6 7 8 0 ? ? ? ? ? ? ? ? ? jugaban ? ? 1 1 ? ? ? ? ? ? ? ? ? de ? ? 1 2 ? ? ? ? ? ? ? ? ? una ? ? 1 3 ? ? ? ? ? ? ? ? ? manera ? ? 1 4 ? ? ? ? ? ? ? ? ? animada ? ? 1 5 ? ? ? ? ? ? ? ? ? y ? ? 1 6 ? ? ? ? ? ? ? ? ? muy ? ? 1 7 ? ? ? ? ? ? ? ? ? cordial ? ? 1 8 ? ? ? ? ? ? ? ? ? . ? ? 1 it was an animated , very convivial game .
51 / 74Feature:
Constraint : ?( x,y ) =
N ? i=1 1(yi = m)
E q [?( x , y )] ? 1
Symmetry Constraints [ Gra?a et al 10]
Feature:
Constraint:
Sym metric - Original posteriors 0 1 2 3 4 ?? p ? t ( z | x ) 0 ? ? ? ? ? no 1 ? ? ? ? ? hay 2 ? ? ? ? ? estad??sticas 3 ? ? ? ? ?.
0 1 2 3 4 ?? p ? t ( z | x ) 0 ? ? ? ? ? no 1 ? ? ? ? ? hay 2 ? ? ? ? ? estad??sticas 3 ? ? ? ? ?.
no statistical data exists .
p ? t q ?? p ? t ?? p ? t 55 / 74
Eq [ ?( x , y )] = 0 ?( x , y ) = ? ?? ?? + 1 y ? ?? y and ?? y i = j ? 1 y ? ?? y and ?? y j = i 0 otherwise ?? p ?( y | ) ?? p ?( y )
Symmetry Constraints [ Gra?a et al 10]
Before projection : After projection:
Symmetric - After projection
E-Step qs(z ) = arg min q(z )? Q s
KL [ qs(z ) || p?t ( z | xs )] 0 1 2 3 4 ?? p ? t ( z | x ) 0 ? ? ? ? ? no 1 ? ? ? ? ? hay 2 ? ? ? ? ? estad??sticas 3 ? ? ? ? ?.
0 1 2 3 4 ?? p ? t ( z | x ) 0 ? ? ? ? ? no 1 ? ? ? ? ? hay 2 ? ? ? ? ? estad??sticas 3 ? ? ? ? ?.
no statistical data exists .
0 1 2 3 4 0 ? ? ? ? ? no ?? q ( z)1 ? ? ? ? ? hay 2 ? ? ? ? ? estad??sticas 3 ? ? ? ? ?.
0 1 2 3 4 0 ? ? ? ? ? no ?? q ( z)1 ? ? ? ? ? hay 2 ? ? ? ? ? estad??sticas 3 ? ? ? ? ?.
no statistical data exists .
M-Step Does not change 56 / 74 ?? p ?( y | x ) ?? p ?( y | x ? q ( y ) ? q ( y )
Results [ Gra?a et al 10] 50 60 70 80 90 100 1000 10000 100000 1e+06precision size S-HMMB-HMMHMM 50 60 70 80 90 100 1000 10000 100000 1e+06precision size S-HMMB-HMMHMM Evolution with data size 50 60 70 80 90 100 1000 10000 100000 1e+06precision size S-HMMB-HMMM4HMM 50 60 70 80 90 100 1000 10000 100000 1e+06precision size S-HMMB-HMMM4HMM ? Specially useful for low data situations 6 1 / 74 Evolution with data size 50 60 70 80 90 100 1000 10000 100000 1e+06precision size S-HMMB-HMMM4HMM 50 60 70 80 90 100 1000 10000 100000 1e+06precision size S-HMMB-HMMM4HMM ? Specially useful for low data situations 6 1 / 74
Results [ Gra?a et al 10] 60 65 70 75 80 85 90 95 En-Pt Pt-En Pt-Fr Fr-Pt EnEs EsEn Es-Fr Fr-Es Pt-Es Es-Pt EnFr Fr-EnLanguagesHMM70.5 67.5 73.0 77.6 75.7 74.9 80.9 84.0 82.4 79.8 76.3 78.3
BHMM 85.0 74.4 71.3 86.3 88.4 87.2 87.2 86.5 82.5 90.1 90.8 91.6
SHMM 86.2 85.0 82.4 87.9 82.7 84.6 89.1 88.9 84.6 91.8 93.4 9 4.6
Dependency Parsing
DMV Model [ Gra?a et al 04]
Dependency model with valence ( Klein and Manning , ACL 2004) x y
Regularization
N creates
V sparse
ADJ grammars
N p?(x , y ) = ? root(V ) ? ? stop(nostop|V , right,false ) ? ? child(N|V , right ) ? ? stop(stop|V , right,true ) ? ? stop(nostop|V , left,false ) ? ? child(N|V , left ) . . .
3/9
Dependency Parsing ?
Transfer annotations from another language ? [ Ganchev et al 09] ?
Constrain the number of child/parent relations ? [ Gillenwater et al 11] ?
Use linguistic rules ? [ Druck et al 09] [ Naseem et al 10]
Dependency Parsing
Transfer annotations [ Ganchev et al 09] ?
Use information from a resource rich language ?
Make the annotation transfer robust ?
Preserve n % of the edges
Dependency Parsing
Transfer annotations [ Ganchev et al 09]
E q [?( x,y )] = x | ? y ? C x q ( y|x)
E q [ ?( x,y )] ? b
Dependency Parsing
Transfer annotations [ Ganchev et al 09]
DMV PR-Transfer
Dependency Parsing
Posterior Sparsity [ Gra?a et al 10] ?
ML learns very ambiguous grammars ? all productions have some probability ? constrain the number of possible productions
Dependency Parsing
Posterior Sparsity [ Gillenwater et al 11] Measuring ambiguity on distributions over trees
N ?
N
V ?
N
AD
J ?
N
N ?
V
V ?
V
AD
J ?
V
N ?
AD
J
V ?
AD
J
AD
J ?
AD
J
SparsityN isV workingV 0.40.6 0 1 0
SparsityN isV workingV 0.4 0.6 .4 .6 0
UseV goodADJ grammarsN 0.70.3 0 .7 .3
UseV goodADJ grammarsN 0.40.6 .4 .6 0 max ? sum = 3.3 ? 0 1 .3 .4 .6 0 .4 .6 0 7/9
Dependency Parsing
Posterior Sparsity [ Gillenwater et al 11] GILLENWATER , GANCHEV , GRA?A , PEREIRA , TASKAR
Una d papelera nc es vs un d objeto nc civilizadoaq
Una d papelera nc es vs un d objeto nc civilizadoaq 1.00 1.00 1.000.49 0.51 1.00 0.57 0.43
Una d papelera nc es vs un d objeto nc civilizadoaq 1.00 0.83 0.75 0.990.92 0.35 0.48 Figure 14: Posterior edge probabilities for an example sentence from the Spanish test corpus . Top is Gold , middle is EM , and bottom is PR.
since then it does not have to pay the cost of assigning a parent with a new tag to cover each noun that does not come with a determiner.
Table 4 contrasts the most frequent types of errors EM , SDP , and PR make on several test sets where PR does well . The ? acc ? column is accuracy and the ? errs ? column is the absolute number of errors of the key type . Accuracy for the key ? parent POS truth/guess ? child POS ? is computed as a function of the true relation . So , if the key is pt / p g ? c , then accuracy is : acc = # of pt ? c in Viterbi parses # of pt ? c in gold parses . (25) In the following subsections we provide some analysis of the results from Table 4.
7.1 English Corrections
Considering English first , there are several notable differences between EM and PR errors . Similar to the example for Spanish , the direction of the noun-determiner relation is corrected by PR . This is reflected by the VB/DT ? NN key , the NN/VBZ ? DT key , the NN/IN ? DT key , the IN/DT ? NN key , the NN/VBD ? DT key , the NN/VBP ? DT key , and the NN/VB ? DT key , which for EM and SDP have accuracy 0. PR corrects these errors.
A second correction PR makes is reflected in the VB/TO ? VB key . One explanation for the reason PR is able to correctly identify VBs as the parents of other VBs instead of mistakenly making TO the parent of VBs is that ? VB CC VB ? is a frequently occurring sequence . For example , ? build and hold ? and ? panic and bail ? are two instances of the ? VB CC VB ? pattern from the test corpus.
Presented with such scenarios , where there is no TO present to be the parent of VB , PR chooses the first VB as the parent of the second . It maintains this preference for making the first VB a parent of the second when encountered with ? VB TO VB ? sequences , such as ? used to eliminate ?, because it would have to pay an additional penalty to make TO the parent of the second VB . In this manner , PR corrects the VB/TO ? VB key error of EM and SDP.
26
Gold:
DVM:
DMV+Sparsity:
Dependency Parsing
Posterior Sparsity [ Gillenwater t al . 11]
DMV DMV+Sparsity
Dependency Parsing
Linguistic Rules [ Naseem et al 10]
Using Universal Linguistic Knowledge to Guide Grammar Induction Tahira Naseem , Harr Chen , Regina Barzilay Computer Science and Artificial Intelligence Laboratory
Massachusetts Institute of Technology { tahira , harr , regina } @ csail.mit.edu
Mark Johnson
Department of Computing
Macquarie University mark.johnson@mq.edu.au
Abstract
We present an approach to grammar induction that utilizes syntactic universals to improve dependency parsing across a range of languages . Our method uses a single set of manually-specified language-independent rules that identify syntactic dependencies between pairs of syntactic categories that commonly occur across languages . During inference of the probabilistic model , we use posterior expectation constraints to require that a minimum proportion of the dependencies we infer be instances of these rules . We also automatically refine the syntactic categories given in our coarsely tagged input . Across six languages our approach outperforms state-of-the-art unsupervised methods by a significant mar-gin.1 1 Introduction Despite surface differences , human languages exhibit striking similarities in many fundamental aspects of syntactic structure . These structural correspondences , referred to as syntactic universals , have been extensively studied in linguistics ( Baker , 2001; Carnie , 2002; White , 2003; Newmeyer , 2005) and underlie many approaches in multilingual parsing.
In fact , much recent work has demonstrated that learning crosslingual correspondences from corpus data greatly reduces the ambiguity inherent in syntactic analysis ( Kuhn , 2004; Burkett and Klein , 2008; Cohen and Smith , 2009a ; Snyder et al , 2009;
Berg-Kirkpatrick and Klein , 2010).
1The source code for the work presented in this paper is available at http://groups.csail.mit.edu/rbg/code/dependency/
Root ? Auxiliary Noun ? Adjective
Root ? Verb Noun ? Article
Verb ? Noun Noun ? Noun
Verb ? Pronoun Noun ? Numeral
Verb ? Adverb Preposition ? Noun
Verb ? Verb Adjective ? Adverb
Auxiliary ? Verb
Table 1: The manually-specified universal dependency rules used in our experiments . These rules specify head-dependent relationships between coarse ( i.e ., unsplit ) syntactic categories . An explanation of the ruleset is provided in Section 5.
In this paper , we present an alternative grammar induction approach that exploits these structural correspondences by declaratively encoding a small set of universal dependency rules . As input to the model , we assume a corpus annotated with coarse syntactic categories ( i.e ., high-level part-of-speech tags ) and a set of universal rules defined over these categories , such as those in Table 1. These rules incorporate the definitional properties of syntactic categories in terms of their interdependencies and thus are universal across languages . They can potentially help disambiguate structural ambiguities that are difficult to learn from data alone ? for example , our rules prefer analyses in which verbs are dependents of auxiliaries , even though analyzing auxiliaries as dependents of verbs is also consistent with the data . Leveraging these universal rules has the potential to improve parsing performance for a large number of human languages ; this is particularly relevant to the processing of low-resource
Small set of universal rules = 1 if edge in rule set
E q [ ?( x,y )] ? b ?( x , y)
Dependency Parsing
Linguistic Rules [ Nas em et al 10]
DMV DMV+Rules
Dependency Parsing:
Applications using Other Models ?
Tree CRF ? [ Druck et al 09] ?
MST Parser ? [ Ganchev et al 09]
Other Applications ?
Multi view learning : ? [ Ganchev et al 08] ?
Relation extraction : ? [ Chen et al 11]
Implementation Tips and Tricks
Off-the-Shelf Tools : MALLET http://mallet.cs.umass.edu ? off-the-shelf support for labeled features ? models : MaxEnt Classifier , Linear Chain CRF ( one and two label constraints ) ? methods : GE and PR ? constraints on label distributions for input features ? GE penalties : KL divergence , (+ soft inequalities ) ? PR penalties : (+ soft inequalities ) ? in development : Tree CRF , and other penalties ? ? ?1
Off-the-Shelf Tools : MALLET http://mallet.cs.umass.edu ? import data in SVMLight-like or CoNLL03-like formats ? import constraints in a simple text format : ? easily specify method options ( i.e . SimpleTagger ): positive interesting:2 film:1 ...
negative tired:1 sequel:1 ...
positive best:1 recommend:2 ...
U.N . NNP BNP B-ORG official NN INP O heads VBZ BVP O tired negative:0.8 positive:0.2 best positive:0.9 negative:0.1
U.N . B-ORG:0.7,0.9
BVP O:0.95, java cc.mallet.fst.semi_supervised.tui.SemiSupSimpleTagger \ -- train true -- test lab -- loss l2 -- learning ge \ unlabeled.txt test.txt constraints.txt
New GE Constraints : MALLET http://mallet.cs.umass.edu ? Java Interfaces for implementing new GE constraints ? covariance computation implemented ( MaxEnt , CRF ) ? primarily need to write methods to : ? restriction : constraints must factor with model ? restriction : GE objective must be differentiable compute constraint features and expectations compute GE objective value compute GE objective gradient ( but not covariance)
New PR Constraints : MALLET http://mallet.cs.umass.edu ? Java Interfaces for implementing new PR constraints ? inference algorithms implemented ( MaxEnt , CRF ) ? primarily need to write methods for E-step ( projection ): ? restriction : constraints must factor with model compute constraint features and expectations compute scores under q for E-step compute objective function for E-step compute gradient for E-step
GE Implementation Advice ? computing covariance ( required for gradient ): ? trick : compute cov . of composite constraint feature ? example : penalty : ? result : only need to store vectors of size in computation , rather than covariance matrix ? trick : efficient gradient computation in hypergraphs ? use semiring algorithms of [ Li & Eisner 09] ? result : same time complexity as supervised ( w . both ) ? c ( x , y ) = ? ? 2( ??? E [?])?( x , y)?22 d i m ( f )
GE Implementation Advice ? parameter regularization : ? regularization encourages bootstrapping by penalizing very large parameter values : ? optimization : nonconvex ? usually LBFGS still preferable ( use ? restart trick ?) ? zero initialization usually works well ? other init : supervised , MaxEnt , GE in simpler model ? >
Off-the-Shelf Tools : PR Toolkit http://code.google.com/p/pr-toolkit / ? off-the-shelf support for PR ? models : ?
MaxEnt Classifier , HMM,DMV ? applications : ? Word Alignment , Pos Induction , Grammar Induction ? constraints : posterior sparsity , bijectivity , agreement ?
No command line mode ?
Smaller support base
PR Implementation example:
Word Alignment - Bijectivity ?
Learning : EM , PR ? void eStep(counts , lattices ); ? void mStep(counts ); ? lattice constraint.project(lattice ); ?
Model : HMM ? lattice computePosteriors(lattice ); ? void addCount(lattice , counts ); ? void updateParameters(counts ); ?
Constraints : Bijectivity ? lattice project(lattice);
PR Implementation example:
EM class EM { model ; void em(n ){ lattices = model.getLattices (); counts = model.counts (); for(i=0; i < n ; i ++) { eStep(counts , lattices ); mStep(counts ); } } void eStep(counts , lattices ) { counts.clear (); for(l : lattices ) { model.computePosterior(l ); model.addCount(l,counts ); } } void mStep(counts ) { model.updateParameters(counts ); } ......
}
PR Implementation example:
PR class PR { model ; constraint ; void em(n ){ lattices = model.getLattices (); counts = model.counts (); for(i=0; i < n ; i ++) { eStep(counts , lattices ); mStep(counts ); } } void eStep(counts , lattices ) { counts.clear (); for(l : lattices ){ model.computePosterior(l ); constraint.project(l ); model.addCount(l,counts ); } } void mStep(counts ) { model.updateParameters(counts ); } ......
}
PR Implementation example:
HMM class HMM { obsProb , transProbs,initProbs ; lattice computerPosteriors(lattice ){ ? Run forward backward ? } void addCount(lattice,counts ){ ? Add posteriors to count table ? } void updateParams(counts ){ ? Normalize counts ? ? Copy counts to params table ? } void getCounts (){ ? return copy of params structures ? } void getLattices (){ ? return structure of all lattices in the corpus ? } ......
}
PR Implementation example:
Bijective constraints ?
Constraint : returns a vector with mth value = number of target words in sentence x that align with source word m ?( x,y ) =
N ? i=1 1(yi = m ) Q = { q : E q [?( x,y )] ? 1} ?
Primal : Hard
D KL ( Q | p ?) = arg min q
D KL ( q | p ?) ?
Dual : Easy arg max ?? 0 ? b T ? ?? l og Z (?)? ||?|| 2
Z (?) = ? y p ?( y | x ) exp (?? ? ?( x , y ))
PR Implementation example:
Bijective Constraints class BijectiveConstraints { model ; lattice project(lattice ){ obj = BijectiveObj(model,lattice ); Optimizer.optimize(obj ); } } class BijectiveObj { lattice ; void updateModel(newLambda ){ lattice_ = lattice*exp(newLambda ); computerPosteriors(lattice ) } double getObj (){ obj = - dot(lambda,b ); obj -= lattice.likelihood ; obj -= l2Norm(lambda ); } double [] getGrad (){ grad = lattice.posteriors - b ; grad -= norm(lambda ); return grad ; }
Other Software Packages ?
Learning Based Java : ? http://cogcomp.cs.illinois.edu/page/software_view/11 ? support for Constraint-Driven Learning ?
Factorie : ? http://code.google.com/p/factorie / ? support for GE and PR in development Rich Prior Knowledge in Learning for Natural
Language Processing
Bibliography
For a more up-to-date bibliography as well as additional information about these methods , point your browser to : http://sideinfo.wikkii.com / 1 Constraint-Driven Learning Constraint driven learning ( CoDL ) was first introduced in Chang et al [2007], and has been used also in Chang et al [2008]. A further paper on the topic is in submission [ Chang et al , 2010].
2 Generalized Expectation
Generalized Expectation ( GE ) constraints were first introduced by Mann and McCallum [2007] 1 and were used to incorporate prior knowledge about the label distribution into semisupervised classification . GE constraints have also been used to leverage ? labeled features ? in document classification [ Druck et al , 2008] and information extraction [ Mann and McCallum , 2008, Druck et al , 2009b , Bellare and McCallum , 2009], and to incorporate linguistic prior knowledge into dependency grammar induction [ Druck et al , 2009a].
3 Posterior Regularization
The most clearly written overview of Posterior Regularization ( PR ) is Ganchev et al [2010]. PR was first introduced in Graca et al [2008], and has been applied to dependency grammar induction [ Ganchev et al , 2009, Gillenwater et al , 2009, 2011, Naseem et al , 2010], part of speech induction [ Grac?a et al , 2009a ], multiview learning [ Ganchev et al , 2008], word alignment [ Graca et al , 2008, Ganchev et al , 2009, Grac?a et al , 2009b ], and crosslingual semantic alignment [ Platt et al , 2010]. The framework was independently discovered by Bellare et al [2009] as an approximation to GE constraints , under the name Alternating Projections , and used under that name also by Singh et al [2010] and Druck and McCallum [2010] for information extraction . The framework was also independently discovered by Liang et al [2009] as an approximation to 1In Mann and McCallum [2007] the method was called Expectation Regularization.
a Bayesian model motivated by modeling prior information as measurements , and applied to information extraction.
4 Closely related frameworks
Quadrianto et al [2009] introduce a distribution matching framework very closely related to GE constraints , with the idea that the model should predict the same feature expectations on labeled and undlabeled data for a set of features , formalized as a kernel.
Carlson et al [2010] introduce a framework for semisupervised learning based on constraints , and trained with an iterative update algorithm very similar to CoDL , but introducing only confident constraints as the algorithm progresses.
Gupta and Sarawagi [2011] introduce a framework for agreement that is closely related to the PR-based work in Ganchev et al [2008], with a slightly different objective and a different training algorithm.
References
K . Bellare , G . Druck , and A . McCallum . Alternating projections for learning with expectation constraints . In Proc . UAI , 2009.
Kedar Bellare and Andrew McCallum . Generalized expectation criteria for bootstrapping extractors using record-text alignment . In EMNLP , pages 131?140, 2009.
Andrew Carlson , Justin Betteridge , Richard C . Wang , Estevam R . Hruschka Jr ., and Tom M . Mitchell . Coupled Semi-Supervised Learning for Information Extraction . In Proceedings of the Third ACM International Conference on Web Search and Data Mining ( WSDM ), 2010.
M . Chang , L . Ratinov , and D . Roth . Guiding semisupervision with constraint-driven learning . In Proc . ACL , 2007.
Ming-Wei Chang , Lev Ratinov , and Dan Roth . Structured learning with constrained conditional models . 2010. In submission.
M.W . Chang , L . Ratinov , N . Rizzolo , and D . Roth . Learning and inference with constraints . In Proceedings of the National Conference on Artificial
Intelligence ( AAAI ). AAAI , 2008.
G . Druck , G . Mann , and A . McCallum . Learning from labeled features using generalized expectation criteria . In Proc . SIGIR , 2008.
G . Druck , G . Mann , and A . McCallum . Semisupervised learning of dependency parsers using generalized expectation criteria . In Proc . ACL-IJCNLP , 2009a.
Gregory Druck and Andrew McCallum . High-performance semisupervised learning using discriminatively constrained generative models . In Proceedings of the International Conference on Machine Learning ( ICML 2010), pages 319?326, 2010.
Gregory Druck , Burr Settles , and Andrew McCallum . Active learning by labeling features . In EMNLP , pages 81?90, 2009b.
K . Ganchev , J . Grac?a , J . Blitzer , and B . Taskar . Multiview learning over structured and nonidentical outputs . In Proc . UAI , 2008.
K . Ganchev , J . Gillenwater , and B . Taskar . Dependency grammar induction via bitext projection constraints . In Proc . ACL-IJCNLP , 2009.
Kuzman Ganchev , Joo Graa , Jennifer Gillenwater , and Ben Taskar . Posterior sparsity in unsupervised dependency parsing . Journal of Machine Learning Research , 11:2001?2049, July 2010. URL http://jmlr.csail.mit.edu / papers/v11/ganchev10a.html.
Jennifer Gillenwater , Kuzman Ganchev , Joo Graa , Ben Taskar , and Fernando Pereira . Sparsity in grammar induction . In NIPS Workshop on Grammar Induction , Representation of Language and Language Learning , 2009.
Jennifer Gillenwater , Kuzman Ganchev , Joo Graa , Fernando Pereira , and Ben Taskar . Posterior sparsity in unsupervised dependency parsing . Journal of Machine Learning Research , 12:455?490, February 2011. URL http://jmlr.
csail.mit.edu/papers/v12/gillenwater11a.html.
Joao Graca , Kuzman Ganchev , and Ben Taskar . Expectation maximization and posterior constraints . In J.C . Platt , D . Koller , Y . Singer , and S . Roweis , editors , Advances in Neural Information Processing Systems 20, pages 569? 576. MIT Press , Cambridge , MA , 2008.
J . Grac?a , K . Ganchev , F . Pereira , and B . Taskar . Parameter vs . posterior sparisty in latent variable models . In Proc . NIPS , 2009a.
J . Grac?a , K . Ganchev , and B . Taskar . Postcat - posterior constrained alignment toolkit . In The Third Machine Translation Marathon , 2009b.
Rahul Gupta and Sunita Sarawagi . Joint training for open-domain extraction on the web : exploiting overlap when supervision is limited . In Proceedings of the Fourth ACM International Conference on Web Search and Data Mining ( WSDM ), 2011.
P . Liang , M . I . Jordan , and D . Klein . Learning from measurements in exponential families . In Proc . ICML , 2009.
G . S . Mann and A . McCallum . Simple , robust , scalable semisupervised learning via expectation regularization . In Proc . ICML , 2007.
G . S . Mann and A . McCallum . Generalized expectation criteria for semisupervised learning of conditional random fields . In Proc . ACL , 2008.
Tahira Naseem , Harr Chen , Regina Barzilay , and Mark Johnson . Using universal linguistic knowledge to guide grammar induction . In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing , pages 1234?1244, Cambridge , MA , October 2010. Association for Computational Linguistics . URL http://www.aclweb.org/anthology/D10-1120.
John Platt , Kristina Toutanova , and Wentau Yih . Translingual document representations from discriminative projections . In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing , pages 251?261, Cambridge , MA , October 2010. Association for Computational Linguistics.
URL http://www.aclweb.org/anthology/D10-1025.
Novi Quadrianto , James Petterson , and Alex Smola . Distribution matching for transduction . In Y . Bengio , D . Schuurmans , J . Lafferty , C . K . I . Williams , and A . Culotta , editors , Advances in Neural Information Processing Systems 22, pages 1500?1508. MIT Press , 2009.
Sameer Singh , Dustin Hillard , and Chris Leggetter . Minimally-supervised extraction of entities from text advertisements . In Human Language Technologies : The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics , pages 73?81, Los Angeles , California , June 2010. Association for Computational Linguistics . URL http://www.aclweb.org/anthology/N10-1009.
