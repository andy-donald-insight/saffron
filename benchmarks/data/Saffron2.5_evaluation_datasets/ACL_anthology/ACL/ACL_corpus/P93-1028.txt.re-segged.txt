ALOGICAL SEMANTICS
FORNON MONOTONICSORTS
Abstract
Suppose we have a feature system , and we wish
to add default values in a well-defined way . We might start with Kasper-Rounds logic , and use Reiter's example to form it into a default logic  . 
Giving a node a default value would be equivalent to saying " if it is consistent for this node to have that value  , then it does . " Then we could use default theories to describe feature structures  . The particular feature structure described would be the structure that supports the extension of the default theory  . This is , in effect , what the theory of nonmonotonic sorts gives you . This paper describes how that theory derives from what is described above  . 
Mark A . Young & ~ Bill Rounds
Artificial Intelligence Laboratory
The University of Michigan 1101 Beal Ave.
Ann Arbor , MI 48109 marky , rounds ? engin , umich , edu The original presentation of nonmonotonic sorts provided only a description of their operation and an informal description of their meaning  . In this paper , we present a logical basis for NSs and non -monotonically sorted feature structures  ( NSFSs )  . 
NSFSs are shown to be equivalent to default theories of default logic  ( Reiter 1980 )  . In particular , we show how nonmonotonics or tunification is equivalent to finding the smallest default theory that describes both NSFSs  ; and also how taking a solution for a NSFS is the same as finding an extension for that theory  . 

There have been many suggestions for incorporating defaults into unification-based grammar formalisms  ( Bouma 1990 ; Bouma 1992 ; Carpenter 1991 ; Kaplan 1987 ; Russell et al 1992 ; Shieber 1986 ; Shieber 1987) . Each of these proposes a non-commutative , non-associative default unification operation that combines one structure representing strict information with a not here present-ing default information  . When presented with a set of structures , the result depends on the order in which the structures are combined  . This runs very much agains the unification tradition  , in which any set has a unique most general satisfier  ( if a satisfier exists at all )  . 
A method that is free of these ordering effects was presented in  ( Young 1992 )  . The method of nonmonotonic sorts ( NSs ) allows default labels to be assigned at any time , and used only in the absence of conflicting information  . NSs replace the more traditional labels on feature structures to given on monotonically sorted feature structures  ( NS-FSs )  . These structures can be combined by an associative and commutative unification operation  . FSs are rederived from NSFSs by taking a solution -- an operation defined in terms of information present in the NSFS  . 
FEATURESYSTEMS
Unification-based grammar formalisms use formal objects called feature structures to encode linguistic information  . We use a variant of the standard definition . Each structure has a sort ( drawn from a finite set 8 )  , and a ( possibly empty ) set of attributes ( drawn from a finite set ~ )  . 
Definition 1 A feature structure is a tuple ( Q , r ,  6 , O ) where ? Q is a finite set of nodes , ? rEQ is the root node ,  ?  6 : QxY r ---+ Q is a partial feature value function that gives the edges and their labels  , and ? ( 9 : Q ~ S is a sorting function that gives the labels of the nodes  . 
This structure must be connected.
It is not unusual to require that these structures also be acyclic  . For some systems O is defined only for sink nodes  ( PATR-II , for example ) . Fig .   1 shows a standard textual representation for a FS . 
We sometimes want to refer to substructures of a FS  . If . A is a feature structure as described above , we write . A/f for the feature structure rooted at 6(q , f ) . This feature structure is defined by Q~c_Q , the set of nodes that can be reached from 6(r , f ) . 
We will use the letter p ( possibly subscripted ) to represent paths ( that is , finite sequences from . T '*) . 
We will also extend ~ to have paths in its second < subjagrnumber > is a singular < subjagr >= < predagr > < predactor >= < subj > < predrep > is a sleep < pred tense > is a present Figure  1: Textual Feature Structure : " Uther sleeps . "

FALSEa where a ESpl -" P2 where each PiEJ ~* f : ? where fE~- and ? E FML ?^? ? v ? Figure  2: SFML : the domain of sorted logical formulas . 
1 . A2 . A3 .   . 4 4  .  ,4 5 . A 6 . A7 .   . 4 position , with the notion of iterated application of 5 . 
We will assume that there is a partial order ,  -~ , defined on S . This ordering is such that the greatest lower bound of any two sorts is unique  , if it exists . In other words , ( SU_1_ , - q ) is a meet-semilattice ( where_l_represents in consistency or failure )  . This allows us to define the most general unifier of two sorts as their greatest lower bound  , which write as a Asb . We also assume that there is a most general sort , T , called top . The structure ( S , -g ) is called the sort hierarchy . 
KASPER-ROUND SLOGIC ( Kasper 1988 ) provides a logic for describing feature structures  . Fig . 2 shows the domain of these logical formulas . We use the standard notion of satisfaction . Let A = ( Q,r , 5, O) . 
= TRUE always ;-FALSE never ;= a ~ O(r)__ . a ;= pl --' p~-:- , > 5(r , pl ) = 5 ( r , p ~) ; = f : ?? = ~ A/f is defined and A/f ~? ; = ? A ? ? === ~ A ~? and . A ~? ; = ? V ??---~ A ~? or A~?Note that item 3 is different han K asper's original formulation . Kasper was working with a flats ort hierarchy and a version of FSs that allowed sorts only on sink nodes  . The revised version allows for order-sorted hierarchies and internal sorted nodes  . 
NONMONOTONICSORTS
Figure 3 shows a lexical inheritance hierarchy for a subset of German verbs  . The hierarchy specifies
VERB template < past tense suffix > default+te < past participle prefix > is age+<past participle suffix > default + tspiellex VERB 
MIDDLE-VERB template VERB < past participle suffix > is a + enmahllex MIDDLE-VERB 
STRONG-VERB template MIDDLE-VERB < pastense suffix > is a  0 zwinglex STRONG-VERB < past tense stem > is a zwang < past participle stem > is a zwung Figure  3: Example Lexicon with Defaults strict ( is a ) and default ( default ) values for various suffixes . If we ignore the difference between strict and default values  , we find that the information specified for the past participle of mahlis inconsistent  . The MIDDLE-VERB template gives + en as the suffix  , while VERB gives + t . The declaration of the latter as a default tells the system that it should be dropped in favour of the former  . The method of nonmonotonic sorts formalizes this notion of separating strict from default information  . 
Definition 2 A nonmonotonic sort is a pair ( s , A/wheres ES , and ACS such that for each dEA , d-4 s . 
The first element , s , represents the strict information . The default sorts are gathered together in A . 
We write Af for the set of nonmonotonic sorts.
Given a pair of nonmonotonic sorts , we can unify them to get a third NS that represents their combined information  . 
Definition 3 The nonmonotonics or tunifier of nonmonotonic sorts  ( sl , Az ) and ( s2 , As ) is the nonmonotonic sort(s , A ) where ? S~81 As s2 , and ? A = dAssIdEAzUA2A(dAss)-~s . 
The nonmonotonic sort unifier is undefined if saAss2 is undefined . We write nzA~n2 for the NS unifier of nl and n2 . 
The method strengthens consistent defaults while eliminating redundant and inconsistent ones  . It should be clear from this definition that NS unification is both commutative and associative  . Thus we may speak of the NS unifier of a set of NSs  , without regard to the order those NSs appear . Looking back to our German verbs example , the past participle suffix in VERB is ( T , + t ) , while that of MIDDLE-VERB is (+ en ,  ) . The lexical entry for mahl gets their nonmonotonics or tunifier  , which is (+ en ,  ) . If + tAs + en had been defined , and equal (+ en , ) would have been (+ an , + ten . 
Once we have nonmonotonic sorts , we can create nonmonotonically sorted feature structures  ( NS-FSs ) by replacing the function 0 : Q~S by a function ~: Q~A f . The nodes of the graph are thus labeled by NSs instead of the usual sorts  . 
NSFSs may be unified by the same procedures as before  , only replacing sort unification at the nodes with nonmonotonics or tunification  . NSF Sunification , written with the symbol rlN , is associative and commutative . 
NSFSs allow us to carry around default sorts , but has so far given us no way to apply them . When we are done collecting information , we will want to return to the original system of FSs  , using all and only the applicable defaults . To do that , we introduce the notions of explanation and solution  . 
Definition 4 A sort t is said to be explained by a nonmonotonic sort  ( s , A if there is a DCA such that t = S^s(AsD ) . If t is a maximally specific explained sort , lhen ~ is called a solution of n . 
The solutions for + en , )) and T , + t ) are + en and + t respectively . The latter NS also explains T . 
Note that , while D is maximal , it's not necessarily the case that D =  A . If we have mutually inconsistent defaults in A , then we will have more than one maximal consistent set of defaults  , and thus more than one solution . On the other hand , strict information can eliminate defaults during unification  . That means that a particular template can inherit conflicting defaults and still have a unique solution -- provided that enough strict information is given to disambiguate  . 
NSFS solutions are defined in much the same way as NS solutions  . 
Definition 5 AFS(Q , r , ~ , O ) is said to be explained by a NSFS(Q , r ,  8 , Q ) if for each node qEQ we have ~2 ( q ) explains O ( q )  . If . A is a maximally specific explained FS , then A is called a solution . 
If we look again at our German verbs example , we can see that the solution we get formahlis the FS that we want  . The inconsistent default suffix + t has been eliminated by the strict+en  , and the sole remaining default must be applied . 
For the generic way we have defined feature structures  , a NSFS solution can be obtained simply by taking NS solutions at each node  . More restricted versions of FSs may require more care  . 
For instance , if sorts are not allowed on internal nodes , then defining an attribute for a node will eliminate any default sorts assigned to that node  . 
Another example where care must be taken is with typed feature structures  ( Carpenter 1992 )  . Here the application of a default at one node can add strict information at another  ( possibly making a default at the other node inconsistent  )  . The definition of NSFS solution handles both of these cases  ( and others ) by requiring that the solution beaFS as the original system defines them  . In both of these cases , however , the work can be ( at least partially ) delegated to the unification routine ( in the former by Mlowing labels with only defaults to be removed when attributes are defined  , and in the latter by propagating type restrictions on strict sorts  )  . 
What is done in other systems in one step has been here broken into two steps -- gathering information and taking a solution  . It is important hat the second step be carried out appropriately  , since it re-introduces the nonmonotonicity that we've taken out of the first step  . For a lexicon , templates exist in order to organize information about words  . 
Thus it is appropriate to take the solution of a lexical entry  ( which corresponds to a word ) but not of a higher template ( which does not )  . If the lexicon were queried for the lexical entry formahl  , then , it would collect the information from all appropriate templates using NSF Sunification  , and return the solution of that NSFS as the result  . 
DEF AULTLOGIC
The semantics for nonmonotonic sorts is motivated by default logic  ( Reiter 1980 )  . What we want a default sort to mean is : " if it is consistent for this node to have that sort  , then it does . " But where Reiter based his DL on a first order language  , we want to base ours on K as per-P ~ ounds logic . This will require some minor alterations to lZeiter's formalism  . 
A default theory is a pair ( D , W ) where D is a set of default inferences and W is a set of sentences from the underlying logic  . The default inferences are triples , written in the form ~: Mp Each of the greek letters here represent sawff from the logic  . The meaning of the default inference is that if ~ is believed and it is consistent o assume  t5  , then 7 can be believed . 
Given a default theory ( D , W ) , we are interested in knowing what can we believe . Such a set of beliefs , cM led an extension , is a closure of W under the usual rules of inference combined with the default rules of inference given in D  . An extension E is a minimal closed set containing W and such that if c ~: M f l  /7 is a default , and if ~ EE and consistent with E then 7EE ( that is , if we believe ~ x and fl is consistent with what we believe  , then we also believe 7) . 
l ~ eiter can test a formula for consistency by testing for the absence of its negation  . Since Kasper-Rounds logic does not have negation , we will not be able to do that . Fortunately , we have do have our lasis consistent if it is satisfiable  . Testing a set of K asper-Rounds formulas for consistency thus simply reduces to finding a satisfier for that set  . 
Formally , we encode our logic as an information system ( Scott 1982 )  . An information system ( IS ) is a triple ( A , C , b ) where A is a countable set of " atoms , " C is a class of finite subsets of A , and t-is a binary relation between subsets of A and elements of A  . A set X is said to be consistent if every finite subset of X is an element of C  . A set G is closed if for every X_CG such that X l-a  , we have a EG . 
Following the style used for information systems , we will write G for the closure of G . 
In our case , A is the wffs of SFML ( except FALSE ) , and C is the class of satisfiable sets . The entailment relation encodes the semantics of the particular unification system we are using  . That is , we have
FI-I ~ if VF . F ~ AF ~ F ~ fl.
For instance,
Pl ":- P2 ,   P2  - -  P3 I-Pl-- P3 represents the transitivity of path equations . 
DEF AUL TKAS PER-ROUNDS

In the previous section we described the generic form of default logic  . We will not need the full generality to describe default sorts  . We will restrict our attention to closed precondition-free normal defaults  . That is , all of our defaults will be of the form : : M ~ We will write DE as an abbreviation for this default inference  . Here fl stands for a generic wff from the base language  . Even this is more general than we truly need , since we are really only interested in default sorts  . Nevertheless , we will prove things in the more general form . 
Note that our default inferences are closed and normal  . This means that we will always have an extension and that the extension  ( s ) will be consistent if and only if W is consistent  . These follow from our equivalents of Reiter's theorem  3  . 1 and corollaries 2 . 2 and 2 . 3 . 
Let's consider now how we would represent he information in Fig  . 3 in terms of Kasper-Rounds default logic . The strict statements become normal KR formulas in W  . For instance , the information for MIDDLE-VERBs ( not counting the inheritance information ) is represented as follows: (  , past : participle : suffix : + en )   ) The information for VERB will clearly involve some defaults  . In particular , we have two paths leading to default sorts . We interprethese statements as saying that the path exists  , and that it has the value indicated by default . Thus were present the VERB template as:
D = D past : tenae : suyfix : + te,
Dpast : partieiple:su\]\]ix:+t),
W = past : tense : suffix : T , past : participle : suffix : - I- , past : participle : prefix : ge + Inheritance is done simply by pairwise set union of ancestors in the hierarchy  . Since the entry for mahl contains no local information  , the full description for it is simply the union of the two sets above  . 
D = D past : tense : suy$i ~ : :+ te,
Opast : partieiple : , uLfix :+ t,
W = past : tense : suffix : - l- , past : participle : suffix : T , past : participle : prefix : ge + , past : participle : suffix : + enWe can then find an extension for that default theory and take the most general satisfier for that formula  . It is easy to see that the only extension for raahl is the closure of : past : tense : suffix : + te  , past : participle : suffix : + en , past : participle : prefix:ge + The default suffix+t is not applicable for the past participle due to the presence of + en  . The suffix + reisapplicable and so appears in the extension  . 
DKRL AND NON MONOTONIC

In the previous section we defined how to get the right answers from a system using default sorts  . In this section we will show that the method of nonmonotonic sorts gives us the same answers  . First we formalize the relation between NSFSs and default logic  . 
Definition 6 Let 79 = ( Q , r ,  5 ,  ~ ) be a nonmono-tonically sorted feature structure . The default theory of D is DT ( 79 )  =  ( Dp : tI~2 ( 5 ( r , p )) = ( s , A ) At 6A , Pl , P2 I5(r , PQ----5(r , p2) up : sI~(5(r , p )) = ( s , A ) ) ) The default part of DT ( 79 ) encodes the default sorts , while the strict part encodes the path equations and strict sorts  . 
Theorem 1 The FS . 4 is a solution for the NSFS 7) if and only if ?1 . 4 ~? is an extension of


Because we are dealing with closed normal default theories  , we can form extension simply by taking maximal consistent sets of defaults  . This , of course , is also how we form solutions , so the the solution of a NSFS is an extension of its default theory  . 
We now need to show that NSF Sunification behaves properly  . That is , we must show that nonmonotonics or tunification doesn't create or destroy extensions  . We will write ( D1 , W1) = zx(D2 , I4/2) to indicate that ( O1 , W1) and ( D2 , W2) have the same set of extensions . We will do this by combining a number of intermediater sults  . 
Theorem 2 Let ( D , W ) be a closed normal default theory . 
1 . / fc~A/3?*7 , then ( D , Wto4^/3) = a(D , W to 7) -2 . /fWU/3 is inconsistent , then ( Dt^DE , W ) = A(D , W ) . 
3. If W~-/3, then ( DUDE , W ) = A(D , W).
4 . If W~-~anda ^/3 ?: ~7 , then ( DtODE , W ) = A(DtOD . y , W ) . 
The formulas ~ and /3 represent he ( path prefixed ) sorts to be unified , and 7 their ( path prefixed ) greatest lower bound . The first part deals with strict sort unification  , and is a simple consequence of the fact that ( D , W ) has the same extensions as ( D , W ) . The next two deal within consistent and redundant default sorts  . They are similar to theorems proved in ( Delgrande and Jackson 1991 ) : inconsistent defaults are never applicable ; while necessary ones are always applicable . The last part allows for strengthening of default sorts  . 
It follows from the previous three . Together they show that nonmonotonic unification preserves the information present in the NSFSs being unified  . 
Theorem 3 Let 791 and 792 be NSFSs . Then DT ( 79 ZRN 792 ) = zxDT ( 791 ) to DT ( 792 )   ( using pairwise set union )  . 

Most treatments of default unification to date have been presented very informally  . ( Bouma 1992) and ( Russell et al 1992) , however , provide very thorough treatments of their respective methods  . 
Bouma's is more traditional in that it relies on " subtracting " inconsistent information from the default side of the unification  . The method given in this paper is similar to Russell's method in that it relies on consistency to decide whether default information should be added  . 
Briefly , Boum a defines a default unification operation AU ! B =  ( A-B ) IIB , where A-B is derived from A by eliminating any path that either gets a label or shares a value in B  . In the lexicon , each template has both " strict " and " default " information  . The default information is combined
A template < f > is a a < g > default b
B template < f > default c < g > is ad
ClexAB
Figure 4: Multiple Default Inheritance with the inherited information by the usual unification  . This information is then combined ( using El ! ) with the strict information to derive the FS associated with the template  . This FS is then inherited by any children of the template  . 
Note that the division into " strict " and " default " for Bouma is only local to the template  . At the next level in the hierarchy , what was strict becomes default . Thus " defaultness " is not a property of the information itself  , as it is with NSs , but rather a relation one piece of information has to another  . 
The method described in ( Russell et al 1992 ) also divides templates into strict and default parts  1  . Here , though , the definitions of strict and default are closer to our own  . Each lexical entry inherits from a list of templates  , which are scanned in order . Starting from the lexical entry , at each template the strict information is added , and then all consistent defaults are applied . 
The list of templates that the lexical entry inherits from is generated by a topological sort of the inheritance hierarchy  . Thus the same set may give two different results based on two different orderings  . This approach to multiple inheritance allows for conflicts between defaults to be resolved  . Note , however , that if template A gets scanned before template B  , then A must not contain any defaults that conflict with the strict information in template B  . Otherwise we will get a unification failure , as the default in A will already have been applied when we reach B  . With NSs , the strict information will always over ride the default  , regardless of the order information is received . 
The treatment of default information with NSs allows strict and default information to be inherited from multiple parents  . Consider Fig .  4 . Assuming that the sorts do not combine at all , the resulting
FS for lexical entry C should be \[ , a \] gdThe two methods mentioned above would fail to get any answer for  6': one default or the other would l'I'here may actually be multiple strict parts  , which are treated as disjuncts , but that is not pertinent to the comparison . 
2 13 be applied before the other template was even considered  . In order to handle this example correctly , they would have to state C's properties directly . 
One advantage of both Bouma and Russellis that exceptions to exceptions are allowed  . With nonmonotonic sorts as we have presented them here  , we would get conflicting defaults and thus multiple answers  . However , it is straightforward to add priorities to defaults  . Each solution has a unique set of defaults it uses  , and so we can compare the priorities of various olutions to choose the most preferred one  . The priority scheme can be any partial order , though one that mirrored the lexical inheritance hierarchy would be most natural  . 
Another advantage that both might claim is that they deal with more than just default sorts  . However , the theorems we proved above were proved for generic wits of K as per-Rounds logic  . Thus any formula could be used as a default , and the only question is how best to represent the information  . 
Nonmonotonic sorts are a concise and correct implementation of the kind of default inheritance we have defined here  . 

This paper has shown how the method of nonmono -tonic sorts is grounded in the well-established theories of Kasper-Rounds logic and Reiter's default logic  . This is , to our knowledge , the first attempt to combine Reiter's theory with feature systems  . 
Most previous attempts to fuse defaults with feature structures have relied on procedural code -- a state of affairs that is highly inconsistent with the declarative nature of feature systems  . Methods that do not rely on procedures still suffer from the necessity to specify what order information is received in  . 
It seems to us that the major problem that has plagued attempts to add defaults to feature systems is the failure to recognize the difference in kind between strict and default information  . The statement that the present participle suffix for English is '+ ing ' is a very different sort of statement than that the past participle suffix is '+ ed'by default  . 
The former is unassailable information . The latter merely describes a convention -- that you should use '+ ed'unless you ' retold otherwise  . The method of nonmonotonic sorts makes this important distinction between strict and default information  . The price of this method is in the need to find solutions to NSFSs  . But much of the cost of finding solutions is dissipated through the unification process  ( through the elimination of inconsistent and redundant defaults  )  . In a properly designed lexicon there will be only one solution  , and that can be found simply by unifying all the defaults present  ( getting a unification failure here means that there is more than one solution -- a situation that should indicates an error  )  . 
The semantics given for NSs can be extended in a number of ways  . In particular , it suggests a semantics for one kind of default unification  . It is possible to say that two values are by default equal by giving the formula Dp-  p2  . This would be useful in our German verbs example to specify that the past tense root is by default equal to the present tense root  . This would fill in roots for spiel and mahl without confounding zwing  . Another extension is to use a prioritize default logic to allow for resolution of conflicts between defaults  . The natural prioritization would be parallel to the lexicon structure  , but others could be imposed if they made more sense in the context  . 
References
Bouma , Gosse 1990 . Defaults in unification grammar . In Proceedings of the 1990 Conference of the Association for Computational Linguistics  .  165-172 . 
Bouma , Gosse 1992 . Feature structures and nonmonotonicity . Computational Linguistics 18(2):183-203 . 
Carpenter , Bob 1991 . Skeptical and credulous default unification with applications to templates and inheritance  . In Default Inheritance Within Unification-Based Approaches to the Lexicon  . 
Carpenter , Bob 1992 . The Logic of Typed Feature Structures . Cambridge University Press . 
Delgrande , James P and Jackson , WKen 1991.
Default logic revisited . In Proceedings of the Second International Conference on the Principles of Knowledge Representation and Reasoning  .  118-127 . 
Kaplan , Ronald 1987 . Three seductions of computational linguistics . In Linguistic Theory and Computer Applications . Academic Press , London . 

Kasper , Bob 1988 . Feature Structures : A Logical Theory with Applications to Language Analysis  . 
Ph.D . Dissertation , University of Michigan , Ann

Reiter , Ray 1980. A logic for default reasoning.
Artificial Intelligence 13:81-132.
Russell , Graham ; Ballim , Afzal ; Carroll , John ; and Warwick-Armstrong , Susan 1992 . A practical approach to multiple default inheritance for unification-based lexicons  . Computational Linguistics 18(3): 311-337 . 
Scott , Dana 1982 . Domains for Denotational Semantics , volume 140 of Lecture Notes in Computer

Shieber , Stuart 1986 . An Introduction to Unification-Based Approaches to Grammar  , volume 4 of CSLI Lecture Notes . University of
Chicago Press , Chicago.

Shieber , Stuart 1987 . Separating linguistic analyses from linguistic theories  . In Linguistic Theory and Computer Applications . Academic Press,
London . 136.
Young , Mark 1992 . Nonmonotonic sorts for feature structures . In National Conference on Artificial Intelligence  , San Jose , California .  596-601 . 

