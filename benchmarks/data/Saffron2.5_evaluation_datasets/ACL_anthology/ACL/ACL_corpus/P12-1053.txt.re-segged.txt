Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics , pages 506?515,
Jeju , Republic of Korea , 814 July 2012. c?2012 Association for Computational Linguistics
Strong Lexicalization of Tree Adjoining Grammars
Andreas Maletti?
IMS , Universita?t Stuttgart
Pfaffenwaldring 5b
70569 Stuttgart , Germany
maletti@ims.uni-stuttgart.de
Joost Engelfriet
LIACS , Leiden University
P.O . Box 9512
2300 RA Leiden , The Netherlands
engelfri@liacs.nl
Abstract
Recently , it was shown ( KUHLMANN , SATTA : Tree-adjoining grammars are not closed under strong lexicalization . Comput . Linguist ., 2012) that finitely ambiguous tree adjoining grammars cannot be transformed into a normal form ( preserving the generated tree language ), in which each production contains a lexical symbol . A more powerful model , the simple contextfree tree grammar , admits such a normal form . It can be effectively constructed and the maximal rank of the nonterminals only increases by 1. Thus , simple contextfree tree grammars strongly lexicalize tree adjoining grammars and themselves.
1 Introduction
Tree adjoining grammars [ TAG ] ( Joshi et al , 1969; Joshi et al , 1975) are a mildly context-sensitive grammar formalism that can handle certain nonlocal dependencies ( Kuhlmann and Mohl , 2006), which occur in several natural languages . A good overview on TAG , their formal properties , their linguistic motivation , and their applications is presented by Joshi and Schabes (1992) and Joshi and Schabes (1997), in which also strong lexicalization is discussed . In general , lexicalization is the process of transforming a grammar into an equivalent one ( potentially expressed in another formalism ) such that each production contains a lexical item ( or anchor ). Each production can then be viewed as lexical information on its anchor . It demonstrates a syntactical construction in which the anchor can occur . Since a lexical item is a letter of the string ? Financially supported by the German Research Foundation ( DFG ) grant MA 4959 / 11.
alphabet , each production of a lexicalized grammar produces at least one letter of the generated string . Consequently , lexicalized grammars offer significant parsing benefits ( Schabes et al , 1988) as the number of applications of productions ( i.e ., derivation steps ) is clearly bounded by the length of the input string . In addition , the lexical items in the productions guide the production selection in a derivation , which works especially well in scenarios with large alphabets.1 The GREIBACH normal form ( Hopcroft et al , 2001; Blum and Koch , 1999) offers those benefits for contextfree grammars [ CFG ], but it changes the parse trees . Thus , we distinguish between two notions of equivalence : Weak equivalence ( Bar-Hillel et al , 1960) only requires that the generated string languages coincide , whereas strong equivalence ( Chomsky , 1963) requires that even the generated tree languages coincide . Correspondingly , we obtain weak and strong lexicalization based on the required equivalence.
The GREIBACH normal form shows that CFG can weakly lexicalize themselves , but they cannot strongly lexicalize themselves ( Schabes , 1990). It is a prominent feature of tree adjoining grammars that they can strongly lexicalize CFG ( Schabes , 1990),2 and it was claimed and widely believed that they can strongly lexicalize themselves . Recently , Kuhlmann and Satta (2012) proved that TAG actually cannot strongly lexicalize themselves . In fact , they prove that TAG cannot even strongly lexicalize the weaker tree insertion grammars ( Schabes and Waters , 1995). However , TAG can weakly lexicalize themselves ( Fujiyoshi , 2005).
1Chen (2001) presents a detailed account.
2Good algorithmic properties and the good coverage of linguistic phenomena are other prominent features.
506
Simple ( i.e ., linear and nondeleting ) contextfree tree grammars [ CFTG ] ( Rounds , 1969; Rounds , 1970) are a more powerful grammar formalism than TAG ( Mo?nnich , 1997). However , the monadic variant is strongly equivalent to a slightly extended version of TAG , which is called non-strict TAG ( Kepser and Rogers , 2011). A GREIBACH normal form for a superclass of CFTG ( viz ., second-order abstract categorial grammars ) was discussed by Kanazawa and Yoshinaka (2005) and Yoshinaka (2006). In particular , they also demonstrate that monadic CFTG can strongly lexicalize regular tree grammars ( Ge?cseg and Steinby , 1984; Ge?cseg and Steinby , 1997).
CFTG are weakly equivalent to the simple macro grammars of Fischer (1968), which are a notational variant of the well-nested linear contextfree rewriting systems ( LCFRS ) of Vijay-Shanker et al (1987) and the well-nested multiple contextfree grammars ( MCFG ) of Seki et al (1991).3 Thus , CFTG are mildly context-sensitive since their generated string languages are semilinear and can be parsed in polynomial time ( Go?mez-Rodr??guez et al , 2010).
In this contribution , we show that CFTG can strongly lexicalize TAG and also themselves , thus answering the second question in the conclusion of Kuhlmann and Satta (2012). This is achieved by a series of normalization steps ( see Section 4) and a final lexicalization step ( see Section 5), in which a lexical item is guessed for each production that does not already contain one . This item is then transported in an additional argument until it is exchanged for the same item in a terminal production . The lexicalization is effective and increases the maximal rank ( number of arguments ) of the nonterminals by at most 1. In contrast to a transformation into GREIBACH normal form , our lexicalization does not radically change the structure of the derivations . Overall , our result shows that if we consider only lexicalization , then CFTG are a more natural generalization of CFG than TAG.
2 Notation
We write [ k ] for the set { i ? N | 1 ? i ? k }, where N denotes the set of nonnegative integers . We use a fixed countably infinite set X = { x1, x2, . . . } 3Kuhlmann (2010), Mo?nnich (2010), and Kanazawa (2009) discuss well-nestedness.
of ( mutually distinguishable ) variables , and we let Xk = { xi | i ? [ k ]} be the first k variables from X for every k ? N . As usual , an alphabet ? is a finite set of symbols , and a ranked alphabet (?, rk ) adds a ranking rk : ? ? N . We let ? k = {? | rk (?) = k } be the set of k-ary symbols . Moreover , we just write ? for the ranked alphabet (?, rk).4 We build trees over the ranked alphabet ? such that the nodes are labeled by elements of ? and the rank of the node label determines the number of its children . In addition , elements of X can label leaves . Formally , the set T?(X ) of ?- trees indexed by X is the smallest set T such that X ? T and ?( t1, . . . , tk ) ? T for all k ? N , ? ? ? k , and t1, . . . , tk ? T .5 We use positions to address the nodes of a tree . A position is a sequence of nonnegative integers indicating successively in which subtree the addressed node is . More precisely , the root is at position ? and the position ip with i ? N and p ? N ? refers to the position p in the ith direct subtree . Formally , the set pos(t ) ? N ? of positions of a tree t ? T?(X ) is defined by pos(x ) = {?} for x ? X and pos(?(t1, . . . , tk )) = {?} ? { ip | i ? [ k ], p ? pos(ti )} for all symbols ? ? ? k and t1, . . . , tk ? T?(X).
The positions are indicated as superscripts of the labels in the tree of Figure 1. The subtree of t at position p ? pos(t ) is denoted by t|p , and the label of t at position p by t(p ). Moreover , t[u]p denotes the tree obtained from t by replacing the subtree at p by the tree u ? T?(X ). For every label set S ? ?, we let posS(t ) = { p ? pos(t ) | t(p ) ? S } be the S-labeled positions of t . For every ? ? ?, we let pos?(t ) = pos{?}(t ). The set C?(Xk ) contains all trees t of T?(X ), in which every x ? Xk occurs exactly once and posX\Xk(t ) = ?. Given u1, . . . , uk ? T?(X ), the first-order substitution t[u1, . . . , uk ] is inductively defined by xi[u1, . . . , uk ] = { ui if i ? [ k ] xi otherwise t[u1, . . . , uk ] = ? ( t1[u1, . . . , uk ], . . . , tk[u1, . . . , uk ] ) for every i ? N and t = ?( t1, . . . , tk ) with ? ? ? k and t1, . . . , tk ? T?(X ). First-order substitution is illustrated in Figure 1.
4We often decorate a symbol ? with its rank k [ e.g . ?( k)].
5We will often drop quantifications like ? for all k ? N?.
507 ?[?] ?[1] ?[11] x[12]2 ?[2] x[21]1 ?[22] [ ? ? , x1 ] = ? ? ? x1 ? ? ? ? Figure 1: Tree in C?(X2) ? T?(X ) with indicated positions , where ? = {?, ?, ?} with rk (?) = 2, rk (?) = 1, and rk (?) = 0, and an example first-order substitution.
In first-order substitution we replace leaves ( elements of X ), whereas in second-order substitution we replace an internal node ( labeled by a symbol of ?). Let p ? pos(t ) be such that t(p ) ? ? k , and let u ? C?(Xk ) be a tree in which the variables Xk occur exactly once . The second-order substitution t[p ? u ] replaces the subtree at position p by the tree u into which the children of p are ( first-order ) substituted . In essence , u is ? folded ? into t at position p . Formally , t[p ? u ] = t [ u[t|1, . . . , t|k ] ] p.
Given P ? pos?(t ) with ? ? ? k , we let t[P ? u ] be t[p1 ? u ] ? ? ? [ pn ? u ], where P = { p1, . . . , pn } and p1 > ? ? ? > pn in the lexicographic order.
Second-order substitution is illustrated in Figure 2.
Ge?cseg and Steinby (1997) present a detailed introduction to trees and tree languages.
3 Context-free tree grammars
In this section , we recall linear and nondeleting contextfree tree grammars [ CFTG ] ( Rounds , 1969; Rounds , 1970). The property ? linear and nondeleting ? is often called ? simple ?. The nonterminals of regular tree grammars only occur at the leaves and are replaced using first-order substitution . In contrast , the nonterminals of a CFTG are ranked symbols , can occur anywhere in a tree , and are replaced using second-order substitution.6 Consequently , the nonterminals N of a CFTG form a ranked alphabet . In the lefthand sides of productions we write A(x1, . . . , xk ) for a nonterminal A ? Nk to indicate the variables that hold the direct subtrees of a particular occurrence of A.
Definition 1. A ( simple ) contextfree tree grammar [ CFTG ] is a system ( N ,?, S , P ) such that ? N is a ranked alphabet of nonterminal symbols , ? ? is a ranked alphabet of terminal symbols,7 6see Sections 6 and 15 of ( Ge?cseg and Steinby , 1997) 7We assume that ? ? N = ?.
? ? ? ? ? [ ?? ? ? ? x2 ? x1 ? ] = ? ? ? ? ? ? ? ? ? Figure 2: Example second-order substitution , in which the boxed symbol ? is replaced.
? S ? N0 is the start nonterminal of rank 0, and ? P is a finite set of productions of the form A(x1, . . . , xk ) ? r , where r ? CN??(Xk ) and A ? Nk.
The components ` and r are called left - and righthand side of the production ` ? r in P . We say that it is an A-production if ` = A(x1, . . . , xk ). The righthand side is simply a tree using terminal and nonterminal symbols according to their rank . Moreover , it contains all the variables ofXk exactly once.
Let us illustrate the syntax on an example CFTG . We use an abstract language for simplicity and clarity.
We use lowercase Greek letters for terminal symbols and uppercase Latin letters for nonterminals.
Example 2. As a running example , we consider the CFTG Gex = ({ S(0), A(2)},?, S , P ) where ? ? = {?(2), ?(0), ?(0)} and ? P contains the productions ( see Figure 3):8
S ? A (?, ?) | A (?, ?) | ?(?, ?)
A(x1, x2)? A(?(x1, S ), ?( x2, S )) | ?( x1, x2) .
We recall the ( term ) rewrite semantics ( Baader and Nipkow , 1998) of the CFTG G = ( N ,?, S , P ).
Since G is simple , the actual rewriting strategy is irrelevant . The sentential forms of G are simply SF(G ) = TN??(X ). This is slightly more general than necessary ( for the semantics of G ), but the presence of variables in sentential forms will be useful in the next section because it allows us to treat righthand sides as sentential forms . In essence in a rewrite step we just select a nonterminal A ? N and an A-production ? ? P . Then we replace an occurrence of A in the sentential form by the righthand side of ? using second-order substitution.
Definition 3. Let ?, ? ? SF(G ) be sentential forms.
Given an A-production ? = ` ? r in P and an 8We separate several righthand sides with ?|?.
508
S ?
A ? ?
S ? ? ? ?
S ?
A ? ?
A x1 x2 ?
A ? x1 S ? x2 S
A x1 x2 ? ? x1 x2
Figure 3: Productions of Example 2.
A-labeled position p ? posA (?) in ?, we write ? ??, pG ?[ p ? r ]. If there exist ? ? P and p ? pos (?) such that ? ??, pG ?, then ? ? G ?.
9 The semantics JGK of G is { t ? T ? | S ?? G t }, where ?? G is the reflexive , transitive closure of?G.
Two CFTGG1 andG2 are ( strongly ) equivalent if JG1K = JG2K . In this contribution we are only concerned with strong equivalence ( Chomsky , 1963).
Although we recall the string corresponding to a tree later on ( via its yield ), we will not investigate weak equivalence ( Bar-Hillel et al , 1960).
Example 4. Reconsider the CFTG Gex of Example 2. A derivation to a tree of T ? is illustrated in Figure 4. It demonstrates that the final tree in that derivation is in the language JGexK generated byGex.
Finally , let us recall the relation between CFTG and tree adjoining grammars [ TAG ] ( Joshi et al , 1969; Joshi et al , 1975). Joshi et al (1975) show that TAG are special footed CFTG ( Kepser and Rogers , 2011), which are weakly equivalent to monadic CFTG , i.e ., CFTG whose nonterminals have rank at most 1 ( Mo?nnich , 1997; Fujiyoshi and Kasai , 2000). Kepser and Rogers (2011) show the strong equivalence of those CFTG to non-strict TAG , which are slightly more powerful than traditional TAG . In general , TAG are a natural formalism to describe the syntax of natural language.10 4 Normal forms In this section , we first recall an existing normal form for CFTG . Then we introduce the property of finite ambiguity in the spirit of ( Schabes , 1990; Joshi and Schabes , 1992; Kuhlmann and Satta , 2012), which allows us to normalize our CFTG even further . A major tool is a simple production elimination 9For all k ? N and ? ? G ? we note that ? ? CN??(Xk ) if and only if ? ? CN??(Xk).
10XTAG Research Group (2001) wrote a TAG for English.
scheme , which we present in detail . From now on , let G = ( N ,?, S , P ) be the considered CFTG.
The CFTG G is start-separated if posS(r ) = ? for every production `? r ? P . In other words , the start nonterminal S is not allowed in the righthand sides of the productions . It is clear that each CFTG can be transformed into an equivalent start-separated CFTG . In such a CFTG we call each production of the form S ? r initial . From now on , we assume , without loss of generality , that G is start-separated.
Example 5. Let Gex = ( N ,?, S , P ) be the CFTG of Example 2. An equivalent start-separated CFTG is G?ex = ({ S ?(0)} ? N ,?, S ?, P ? { S ? ? S}).
We start with the growing normal form of Stamer and Otto (2007) and Stamer (2009). It requires that the righthand side of each non-initial production contains at least two terminal or nonterminal symbols . In particular , it eliminates projection productions A(x1) ? x1 and unit productions , in which the righthand side has the same shape as the lefthand side ( potentially with a different root symbol and a different order of the variables).
Definition 6. A production ` ? r is growing if | posN??(r )| ? 2. The CFTG G is growing if all of its non-initial productions are growing.
The next theorem is Proposition 2 of ( Stamer and Otto , 2007). Stamer (2009) provides a full proof.
Theorem 7. For every start-separated CFTG there exists an equivalent start-separated , growing CFTG.
Example 8. Let us transform the CFTG G?ex of Example 5 into growing normal form . We obtain the
CFTG G??ex = ({ S ?(0), S(0), A(2)},?, S ?, P ??) where P ?? contains S ? ? S and for each ? ? {?, ?}
S ? A (?, ?) | ?(?, ?) | ?(?, ?) (1)
A(x1, x2)? A(?(x1, S ), ?( x2, S )) (2)
A(x1, x2)? ?(?( x1, S ), ?( x2, S )) .
From now on , we assume thatG is growing . Next , we recall the notion of finite ambiguity from ( Schabes , 1990; Joshi and Schabes , 1992; Kuhlmann and Satta , 2012).11 We distinguish a subset ? ? ?0 of lexical symbols , which are the symbols that are preserved by the yield mapping . The yield of a tree is 11It should not be confused with the notion of ? finite ambiguity ? of ( Goldstine et al , 1992; Klimann et al , 2004).
509
S ? G
A ? ? ? G
A ? ? S ? ? S ? G
A ? ? A ? ? ? ? S ? G
A ? ? A ? ? ? ? ? ? ? ?? G ? ? ? ? ? ? ? ? ? ? ? Figure 4: Derivation using the CFTG Gex of Example 2. The selected positions are boxed.
a string of lexical symbols . All other symbols are simply dropped ( in a preorder traversal ). Formally , yd ? : T ? ? ? ? is such that for all t = ?( t1, . . . , tk ) with ? ? ? k and t1, . . . , tk ? T ? yd?(t ) = { ? yd?(t1) ? ? ? yd?(tk ) if ? ? ? yd?(t1) ? ? ? yd?(tk ) otherwise.
Definition 9. The tree language L ? T ? has finite ?- ambiguity if { t ? L | yd?(t ) = w } is finite for every w ? ??.
Roughly speaking , we can say that the set L has finite ?- ambiguity if eachw ? ?? has finitely many parses in L ( where t is a parse of w if yd?(t ) = w).
Our example CFTG Gex is such that JGexK has finite {?, ?}- ambiguity ( because ?1 = ?).
In this contribution , we want to ( strongly ) lexicalize CFTG , which means that for each CFTG G such that JGK has finite ?- ambiguity , we want to construct an equivalent CFTG such that each non-initial production contains at least one lexical symbol.
This is typically called strong lexicalization ( Schabes , 1990; Joshi and Schabes , 1992; Kuhlmann and Satta , 2012) because we require strong equiva-lence.12 Let us formalize our lexicalization property.
Definition 10. The production ` ? r is ?- lexicalized if pos?(r ) 6= ?. The CFTG G is ?- lexicalized if all its non-initial productions are ?- lexicalized.
Note that the CFTG G??ex of Example 8 is not yet {?, ?}- lexicalized . We will lexicalize it in the next section . To do this in general , we need some auxiliary normal forms . First , we define our simple production elimination scheme , which we will use in the following . Roughly speaking , a non-initial A-production such that A does not occur in its righthand side can be eliminated fromG by applying it in 12The corresponding notion for weak equivalence is called weak lexicalization ( Joshi and Schabes , 1992).
all possible ways to occurrences in righthand sides of the remaining productions.
Definition 11. Let ? = A(x1, . . . , xk ) ? r in P be a non-initial production such that posA(r ) = ?.
For every other production ?? = `? ? r ? in P and
J ? posA(r ?), let ?? J = ` ? ? r?[J ? r ]. The CFTG Elim(G , ?) = ( N ,?, S , P ?) is such that
P ? = ? ??=`?? r??P \{?} {?? J | J ? posA(r ?)} .
In particular , ??? = ? ? for every production ??, so every production besides the eliminated production ? is preserved . We obtained the CFTG G??ex of Example 8 as Elim(G?ex , A(x1, x2) ? ?( x1, x2)) from G?ex of Example 5.
Lemma 12. The CFTG G and G ?? = Elim(G , ?) are equivalent for every non-initial A-production ? = `? r in P such that posA(r ) = ?.
Proof . Clearly , every single derivation step of G ?? can be simulated by a derivation of G using potentially several steps . Conversely , a derivation of G can be simulated directly by G ?? except for derivation steps ??, pG using the eliminated production ?.
Since S 6= A , we know that the nonterminal at position p was generated by another production ??. In the given derivation of G we examine which nonterminals in the righthand side of the instance of ?? were replaced using ?. Let J be the set of positions corresponding to those nonterminals ( thus p ? J).
Then instead of applying ?? and potentially several times ?, we equivalently apply ?? J of G ? ?.
In the next normalization step we use our production elimination scheme . The goal is to make sure that non-initial monic productions ( i.e ., productions of which the righthand side contains at most one nonterminal ) contain at least one lexical symbol . We define the relevant property and then present is monic if | posN (?)| ? 1. The set of all monic sentential forms is denoted by SF?1(G ). A production ` ? r is monic if r is monic . The next construction is similar to the simultaneous removal of epsilon-productions A ? ? and unit productions A ? B for contextfree grammars ( Hopcroft et al , 2001). Instead of computing the closure under those productions , we compute a closure under non-?-lexicalized productions.
Theorem 13. If JGK has finite ?- ambiguity , then there exists an equivalent CFTG such that all its non-initial monic productions are ?- lexicalized.
Proof . Without loss of generality , we assume that G is start-separated and growing by Theorem 7.
Moreover , we assume that each nonterminal is useful . For every A ? N with A 6= S , we compute all monic sentential forms without a lexical symbol that are reachable from A(x1, . . . , xk ), where k = rk(A ). Formally , let ? A = {? ? SF?1(G ) | A(x1, . . . , xk )? +
G ? ?} , where?+G ? is the transitive closure of?G ? and the CFTG G ? = ( N ,?, S , P ?) is such that P ? contains exactly the non-?-lexicalized productions of P .
The set ? A is finite since only finitely many non-?-lexicalized productions can be used due to the finite ?- ambiguity of JGK . Moreover , no sentential form in ? A contains A for the same reason and the fact that G is growing . We construct the
CFTG G1 = ( N ,?, S , P ? P1) such that
P1 = { A(x1, . . . , xk )? ? | A ? Nk , ? ? ? A } .
Clearly , G and G1 are equivalent . Next , we eliminate all productions of P1 from G1 using Lemma 12 to obtain an equivalent CFTG G2 with the productions P2. In the final step , we drop all non-?-lexicalized monic productions of P2 to obtain the CFTG G , in which all monic productions are ?- lexicalized . It is easy to see that G is growing , start-separated , and equivalent to G2.
The CFTG G??ex only has {?, ?}- lexicalized non-initial monic productions , so we use a new example.
Example 14. Let ({ S(0), A(1), B(1)},?, S , P ) be the CFTG such that ? = {?(2), ?(0), ?(0)} and
A x1 ? G ? ? ? B x1 ? G ? ? ? ? x1 ?
B x1 ? G ? ? x1 ?
Figure 5: The relevant derivations using only productions that are not ?- lexicalized ( see Example 14).
P contains the productions
A(x1)? ?(?, B(x1)) B(x1)? ?( x1, ?) (3)
B(x1)? ?(?, A(x1)) S ? A (?) .
This CFTG Gex2 is start-separated and growing.
Moreover , all its productions are monic , and JGex2K is finitely ?- ambiguous for the set ? = {?} of lexical symbols . Then the productions (3) are non-initial and not ?- lexicalized . So we can run the construction in the proof of Theorem 13. The relevant derivations using only non-?-lexicalized productions are shown in Figure 5. We observe that |? A | = 2 and |? B | = 1, so we obtain the CFTG ({ S(0), B(1)},?, S , P ?), where P ? contains13
S ? ?(?, B (?)) | ?(?, ?(?, ?))
B(x1)? ?(?, ?(?, B(x1)))
B(x1)? ?(?, ?(?, ?( x1, ?))) . (4)
We now do one more normalization step before we present our lexicalization . We call a production ` ? r terminal if r ? T?(X ); i.e ., it does not contain nonterminal symbols . Next , we show that for each CFTG G such that JGK has finite ?- ambiguity we can require that each non-initial terminal production contains at least two occurrences of ?- symbols.
Theorem 15. If JGK has finite ?- ambiguity , then there exists an equivalent CFTG ( N ,?, S , P ?) such that | pos?(r )| ? 2 for all its non-initial terminal productions `? r ? P ?.
Proof . Without loss of generality , we assume that G is start-separated and growing by Theorem 7.
Moreover , we assume that each nonterminal is useful and that each of its non-initial monic productions is ?- lexicalized by Theorem 13. We obtain the desired CFTG by simply eliminating each non-initial terminal production ` ? r ? P such that | pos?(r )| = 1. By Lemma 12 the obtained CFTG 13The nonterminal A became useless , so we just removed it.
511
Ax1 x2 ?
A ? x1 S ? x2 S ? A ,?? x1 x2 x3 ? ? A ,?? ? x1 S ? x2 S x3 ? A ,?? x1 x2 x3 ? ? A ,?? ? x1 ? S , ?? ? ? x2 S x3 Figure 6: Production ? = `? r of (2) [ left ], a corresponding production ?? of P ? [ middle ] with righthand side r?,2, and a corresponding production of P ??? [ right ] with righthand side ( r?,2)? ( see Theorem 17).
is equivalent to G . The elimination process terminates because a new terminal production can only be constructed from a monic production and a terminal production or several terminal productions , but those combinations already contain two occurrences of ?- symbols since non-initial monic productions are already ?- lexicalized.
Example 16. Reconsider the CFTG obtained in Example 14. Recall that ? = {?}. Production (4) is the only non-initial terminal production that violates the requirement of Theorem 15. We eliminate it and obtain the CFTG with the productions
S ? ?(?, B (?)) | ?(?, ?(?, ?))
S ? ?(?, ?(?, ?(?, ?(?, ?))))
B(x1)? ?(?, ?(?, B(x1)))
B(x1)? ?(?, ?(?, ?(?, ?(?, ?( x1, ?))))) .
5 Lexicalization
In this section , we present the main lexicalization step , which lexicalizes non-monic productions . We assume that JGK has finite ?- ambiguity and is normalized according to the results of Section 4: no useless nonterminals , start-separated , growing ( see Theorem 7), non-initial monic productions are ?- lexicalized ( see Theorem 13), and non-initial terminal productions contain at least two occurrences of ?- symbols ( see Theorem 15).
The basic idea of the construction is that we guess a lexical symbol for each non-?-lexicalized production . The guessed symbol is put into a new parameter of a nonterminal . It will be kept in the parameter until we reach a terminal production , where we exchange the same lexical symbol by the parameter . This is the reason why we made sure that we have two occurrences of lexical symbols in the terminal productions . After we exchanged one for a parameter , the resulting terminal production is still ?- lexicalized . Lexical items that are guessed for distinct ( occurrences of ) productions are transported to distinct ( occurrences of ) terminal productions [ cf . Section 3 of ( Potthoff and Thomas , 1993) and page 346 of ( Hoogeboom and ten Pas , 1997)].
Theorem 17. For every CFTG G such that JGK has finite ?- ambiguity there exists an equivalent ?- lexicalized CFTG.
Proof . We can assume that G = ( N ,?, S , P ) has the properties mentioned before the theorem without loss of generality . We let N ? = N ?? be a new set of nonterminals such that rk(?A , ??) = rk(A ) + 1 for every A ? N and ? ? ?. Intuitively , ? A , ?? represents the nonterminal A , which has the lexical symbol ? in its last ( new ) parameter . This parameter is handed to the ( lexicographically ) first nonterminal in the righthand side until it is resolved in a terminal production . Formally , for each righthand side r ? TN?N ???( X ) such that posN ( r ) 6= ? ( i.e ., it contains an original nonterminal ), each k ? N , and each ? ? ?, let r?,k and r ? be such that r?,k = r[?B , ??( r1, . . . , rn , xk+1)]p r ? = r[?B , ??( r1, . . . , rn , ?)] p , where p is the lexicographically smallest element of posN ( r ) and r|p = B(r1, . . . , rn ) with B ? N and r1, . . . , rn ? TN?N ???( X ). For each nonterminal A-production ? = `? r in P let ?? = ? A , ??( x1, . . . , xk+1)? r?,k , where k = rk(A ). This construction is illustrated in Figure 6. Roughly speaking , we select the lexicographically smallest occurrence of a nonterminal in the righthand side and pass the lexical symbol ? in the extra parameter to it . The extra parameter is used in terminal productions , so let ? = `? r in P ? ? ? ? S , ?? x1 ? ? x1 ? Figure 7: Original terminal production ? from (1) [ left ] and the production ? ( see Theorem 17).
be a terminal A-production . Then we define ? = ? A , r(p)?(x1, . . . , xk+1)? r[xk+1]p , where p is the lexicographically smallest element of pos?(r ) and k = rk(A ). This construction is illustrated in Figure 7. With these productions we obtain the CFTG G ? = ( N ? N ?,?, S , P ), where
P = P ? P ? ? P ?? and
P ? = ? ?=`? r?P 6`=S,posN ( r)6=? {?? | ? ? ?} P ?? = ? ?=`? r?P 6`=S,posN ( r )=? {?} .
It is easy to prove that those new productions manage the desired transport of the extra parameter if it holds the value indicated in the nonterminal.
Finally , we replace each non-initial non-?-lexi-calized production in G ? by new productions that guess a lexical symbol and add it to the new parameter of the ( lexicographically ) first nonterminal of N in the righthand side . Formally , we let P nil = {`? r ? P | ` 6= S , pos?(r ) = ?} P ??? = {`? r ? | `? r ? P nil , ? ? ?} , of which P ??? is added to the productions . Note that each production ` ? r ? P nil contains at least one occurrence of a nonterminal ofN ( because all monic productions of G are ?- lexicalized ). Now all non-initial non-?-lexicalized productions from P can be removed , so we obtain the CFTGG ??, which is given by ( N ? N ?,?, S,R ) with R = ( P ? P ???) \ P nil . It can be verified that G ?? is ?- lexicalized and equivalent to G ( using the provided argumentation).
Instead of taking the lexicographically smallest element of posN ( r ) or pos?(r ) in the previous proof , we can take any fixed element of that set . In the definition of P ? we can change posN ( r ) 6= ? to | pos?(r )| ? 1, and simultaneously in the definition of P ?? change posN ( r ) = ? to | pos?(r )| ? 2.
With the latter changes the guessed lexical item is only transported until it is resolved in a production with at least two lexical items.
Example 18. For the last time , we consider the CFTG G??ex of Example 8. We already illustrated the parts of the construction of Theorem 17 in Figures 6 and 7. The obtained {?, ?}- lexicalized CFTG has the following 25 productions for all ?, ?? ? {?, ?}:
S ? ? S
S ? A (?, ?) | ?(?, ?) | ?(?, ?)
S?(x1)? A ?(? ?, ??, x1) | ?( x1, ?)
S?(x1)? ?( x1, ?)
A(x1, x2)? A?(?(x1, S ), ?( x2, S ), ?) (5)
A?(x1, x2, x3)? A?(?(x1, S ??(? ?)), ?( x2, S ), x3)
A(x1, x2)? ?(?( x1, S ?(?)), ?( x2, S))
A?(x1, x2, x3)? ?(?( x1, S?(x3)), ?( x2, S ??(? ?))) , where A ? = ? A , ?? and S ? = ? S , ??.
If we change the lexicalization construction as indicated before this example , then all the productions S?(x1) ? A ?(??, ??, x1) are replaced by the productions S?(x1) ? A(x1, ?). Moreover , the productions (5) can be replaced by the productions A(x1, x2) ? A(?(x1, S ?(?)), ?( x2, S )), and then the nonterminalsA ? and their productions can be removed , which leaves only 15 productions.
Conclusion
For k ? N , let CFTG(k ) be the set of those CFTG whose nonterminals have rank at most k . Since the normal form constructions preserve the nonterminal rank , the proof of Theorem 17 shows that CFTG(k ) are strongly lexicalized by CFTG(k+1). Kepser and Rogers (2011) show that non-strict TAG are strongly equivalent to CFTG(1). Hence , non-strict TAG are strongly lexicalized by CFTG(2).
It follows from Section 6 of Engelfriet et al (1980) that the classes CFTG(k ) with k ? N induce an infinite hierarchy of string languages , but it remains an open problem whether the rank increase in our lexicalization construction is necessary.
Go?mez-Rodr??guez et al (2010) show that well-nested LCFRS of maximal fanout k can be parsed in time O(n2k+2), where n is the length of the input string w ? ??. From this result we conclude that CFTG(k ) can be parsed in time O(n2k+4), in the sense that we can produce a parse tree t that is generated by the CFTG with yd?(t ) = w . It is not clear yet whether lexicalized CFTG(k ) can be parsed more efficiently in practice.
513
References
Franz Baader and Tobias Nipkow . 1998. Term Rewriting and All That . Cambridge University Press.
Yehoshua Bar-Hillel , Haim Gaifman , and Eli Shamir.
1960. On categorial and phrase-structure grammars.
Bulletin of the Research Council of Israel , 9F(1):1?16.
Norbert Blum and Robert Koch . 1999. Greibach normal form transformation revisited . Inform . and Comput ., 150(1):112?118.
John Chen . 2001. Towards Efficient Statistical Parsing using Lexicalized Grammatical Information . Ph.D.
thesis , University of Delaware , Newark , USA.
Noam Chomsky . 1963. Formal properties of grammar . In R . Duncan Luce , Robert R . Bush , and Eugene Galanter , editors , Handbook of Mathematical Psychology , volume 2, pages 323?418. John Wiley and Sons,
Inc.
Joost Engelfriet , Grzegorz Rozenberg , and Giora Slutzki.
1980. Tree transducers , L systems , and two-way machines . J . Comput . System Sci ., 20(2):150?202.
Michael J . Fischer . 1968. Grammars with macro-like productions . In Proc . 9th Ann . Symp . Switching and Automata Theory , pages 131?142. IEEE Computer
Society.
Akio Fujiyoshi . 2005. Epsilon-free grammars and lexicalized grammars that generate the class of the mildly context-sensitive languages . In Proc . 7th Int.
Workshop Tree Adjoining Grammar and Related Formalisms , pages 16?23.
Akio Fujiyoshi and Takumi Kasai . 2000. Spinal-formed contextfree tree grammars . Theory Comput . Syst ., 33(1):59?83.
Ferenc Ge?cseg and Magnus Steinby . 1984. Tree Automata . Akade?miai Kiado ?, Budapest.
Ferenc Ge?cseg and Magnus Steinby . 1997. Tree languages . In Grzegorz Rozenberg and Arto Salomaa , editors , Handbook of Formal Languages , volume 3, chapter 1, pages 1?68. Springer.
Jonathan Goldstine , Hing Leung , and Detlef Wotschke.
1992. On the relation between ambiguity and nondeterminism in finite automata . Inform . and Comput ., 100(2):261?270.
Carlos Go?mez-Rodr??guez , Marco Kuhlmann , and Giorgio Satta . 2010. Efficient parsing of well-nested linear contextfree rewriting systems . In Proc . Ann . Conf.
North American Chapter of the ACL , pages 276?284.
Association for Computational Linguistics.
Hendrik Jan Hoogeboom and Paulien ten Pas . 1997.
Monadic second-order definable text languages . Theory Comput . Syst ., 30(4):335?354.
John E . Hopcroft , Rajeev Motwani , and Jeffrey D . Ullman . 2001. Introduction to automata theory , languages , and computation . Addison-Wesley series in computer science . Addison Wesley , 2nd edition.
Aravind K . Joshi , S . Rao Kosaraju , and H . Yamada.
1969. String adjunct grammars . In Proc . 10th Ann.
Symp . Switching and Automata Theory , pages 245? 262. IEEE Computer Society.
Aravind K . Joshi , Leon S . Levy , and Masako Takahashi.
1975. Tree adjunct grammars . J . Comput . System Sci ., 10(1):136?163.
Aravind K . Joshi and Yves Schabes . 1992. Tree-adjoining grammars and lexicalized grammars . In Maurice Nivat and Andreas Podelski , editors , Tree Automata and Languages . North-Holland.
Aravind K . Joshi and Yves Schabes . 1997. Tree-adjoining grammars . In Grzegorz Rozenberg and Arto Salomaa , editors , Beyond Words , volume 3 of Handbook of Formal Languages , pages 69?123. Springer.
Makoto Kanazawa . 2009. The convergence of well-nested mildly context-sensitive grammar formalisms.
Invited talk at the 14th Int . Conf . Formal Grammar . slides available at : research.nii.ac.jp / ? kanazawa.
Makoto Kanazawa and Ryo Yoshinaka . 2005. Lexicalization of second-order ACGs . Technical Report NII-2005-012E , National Institute of Informatics , Tokyo,
Japan.
Stephan Kepser and James Rogers . 2011. The equivalence of tree adjoining grammars and monadic linear contextfree tree grammars . J . Log . Lang . Inf ., 20(3):361?384.
Ines Klimann , Sylvain Lombardy , Jean Mairesse , and Christophe Prieur . 2004. Deciding unambiguity and sequentiality from a finitely ambiguous max-plus automaton . Theoret . Comput . Sci ., 327(3):349?373.
Marco Kuhlmann . 2010. Dependency Structures and Lexicalized Grammars : An Algebraic Approach , volume 6270 of LNAI . Springer.
Marco Kuhlmann and Mathias Mohl . 2006. Extended cross-serial dependencies in tree adjoining grammars.
In Proc . 8th Int . Workshop Tree Adjoining Grammars and Related Formalisms , pages 121?126. ACL.
Marco Kuhlmann and Giorgio Satta . 2012. Tree-adjoining grammars are not closed under strong lexicalization . Comput . Linguist . available at : dx.doi.
org/10.1162/COLI_a_00090.
Uwe Mo?nnich . 1997. Adjunction as substitution : An algebraic formulation of regular , contextfree and tree adjoining languages . In Proc . 3rd Int . Conf . Formal Grammar , pages 169?178. Universite ? de Provence , France . available at : arxiv.org/abs/cmp-lg / 9707012v1.
Uwe Mo?nnich . 2010. Well-nested tree languages and attributed tree transducers . In Proc . 10th Int . Conf . Tree Adjoining Grammars and Related Formalisms . Yale University . available at : www2.research.att.
com/?srini/TAG+10/papers/uwe.pdf.
514
Andreas Potthoff and Wolfgang Thomas . 1993. Regular tree languages without unary symbols are star-free . In Proc . 9th Int . Symp . Fundamentals of Computation Theory , volume 710 of LNCS , pages 396?405.
Springer.
William C . Rounds . 1969. Context-free grammars on trees . In Proc . 1st ACM Symp . Theory of Comput ., pages 143?148. ACM.
William C . Rounds . 1970. Tree-oriented proofs of some theorems on contextfree and indexed languages . In Proc . 2nd ACM Symp . Theory of Comput ., pages 109? 116. ACM.
Yves Schabes . 1990. Mathematical and Computational Aspects of Lexicalized Grammars . Ph.D . thesis , University of Pennsylvania , Philadelphia , USA.
Yves Schabes , Anne Abeille ?, and Aravind K . Joshi.
1988. Parsing strategies with ? lexicalized ? grammars : Application to tree adjoining grammars . In Proc . 12th Int . Conf . Computational Linguistics , pages 578?583.
John von Neumann Society for Computing Sciences,
Budapest.
Yves Schabes and Richard C . Waters . 1995. Tree insertion grammar : A cubic-time parsable formalism that lexicalizes contextfree grammars without changing the trees produced . Comput . Linguist ., 21(4):479? 513.
Hiroyuki Seki , Takashi Matsumura , Mamoru Fujii , and Tadao Kasami . 1991. On multiple contextfree grammars . Theoret . Comput . Sci ., 88(2):191?229.
Heiko Stamer . 2009. Restarting Tree Automata : Formal Properties and Possible Variations . Ph.D . thesis , University of Kassel , Germany.
Heiko Stamer and Friedrich Otto . 2007. Restarting tree automata and linear contextfree tree languages . In Proc . 2nd Int . Conf . Algebraic Informatics , volume 4728 of LNCS , pages 275?289. Springer.
K . Vijay-Shanker , David J . Weir , and Aravind K . Joshi.
1987. Characterizing structural descriptions produced by various grammatical formalisms . In Proc . 25th Ann . Meeting of the Association for Computational Linguistics , pages 104?111. Association for Computational Linguistics.
XTAG Research Group . 2001. A lexicalized tree adjoining grammar for English . Technical Report IRCS-01-03, University of Pennsylvania , Philadelphia , USA.
Ryo Yoshinaka . 2006. Extensions and Restrictions of Abstract Categorial Grammars . Ph.D . thesis , University of Tokyo.
515
