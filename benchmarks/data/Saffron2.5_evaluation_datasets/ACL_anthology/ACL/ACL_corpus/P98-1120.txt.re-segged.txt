SOLVING ANALOGIES ONWORDS : ANALGORITHM
Yves Lepage
ATR Interpreting Telecommunications Research Labs,
Hikaridai22 , Seika-ty S , SSraku-gun , KySto619-0288 , Japan
lepage@itl , atr.co.jp
Introduction
To introduce the algorithm presented in this paper  , we take a path that is inverse to the historical development of the idea of analogy  ( see ( Hoffman 95 ) ) . This is necessary , because a certain in comprehension is faced when speaking about linguistic analogy  , i . e . , it is generally given a broader and more psychological definition  . Also , with our proposal being computational , it is impossible to ignore works about analogy in computer science  , which has come to mean artificial intelligence . 
1 A Survey of Works on Analogy
This paper is not intended to be an exhaustive study  . For a more comprehensive study on the subject , see ( Hoffman 95) . 
1 . 1 Metaphors , or Implicit Analogies Beginning with works in psychology and artificial intelligence  ,   ( Gentner 83 ) is a milestone study of a possible modeling of analogie such as  , " anatom is like the solar system " adequate for artificial intelligence  . In these analogies , two domains are mapped , one onto the other , thus modeling of the domain becomes necessary . 
Ysun-, nucleus planet-~Yelectron
In addition , properties ( expressed by clauses , formulae , etc . ) are transferred from one domain onto the other , and their number somehow determines the quality of the analogy  . 
aZZ racts ( sun , J ~ aZZ racZs ( nucleus , plane Z ) elec Zron ) more massive ( sun , -~ f more massive ( nucleus , planet ) elec Zron ) However , Gentner's explicit description of sentences as " an A is like a B"as analogies is subject to criticism  . Others ( e . g . 
(Steinhart 94 ) ) prefer to call these sentences metaphors 1 , the validity of which rests on sentences of the kind  , " A is to B as C is to D " , for which the name analogy 2 is reserved . In other words , some metaphors are supported by analogies . For instance , the metaphor , " anatom is like the solar system " , relies on the analogy , " an electron is to the nucleus , as a planet is to the sun " . 3 The answer of the AI community is complex because they have headed irectly to more complex problems  . For them , in analogies or metaphors ( Hall 89 ) : two different domains appear for both domains , modeling of a knowledge base is necessary mapping of objects and transfer of properties are different operations the quality of analogies has to be evaluated as a function of the strength  ( number , truth , etc . ) of properties transferred . 
We must drastically simplify all this and enunciate a simpler problem  ( whose resolution may not necessarily be simple )  . This can be acl fieved by simphfying data types , and consequently the characteristics of the problem  . 
alf the fact that properties are carried over characterise such sentences  , then etymologically they are metaphors : In Greek  , pherein : to carry ; meta-:between , among , with , after . " Metaphor " means to transfer , to carry over . 
2In Greek , logos , -logio:ratio , proportion , reason , discourse ; an n-:top down , again , a new . " Analog 3 , " means the same proportions , similar ratios . 
3 This complies with Aristotle's definitions in the

728 1 . 2 Mul t ip l ic i ty vs Unic i ty of Domains In the field of natural anguage processing  , there have been plenty of works on pronunciation of English by analogy  , some being very much concerned with reproducing human behavior  ( see ( Damper & Eastmond 96 ) ) . Here is an illustration of the task from ( Pirelli & Federici 94 ) : vaneA/vejn / , ~ g . Lhsane 1-~ x =/ sejn/Similarly to AI approaches , two domains appear ( graphemic and phonemic ) . Consequently , the functions f , g and h are of differentypes because their domains and ranges are of different data types  . 
Similarly to AI again , a common feature in such pronouncing systems is the use of databases of written and phonetic forms  . Regarding his own model , ( Yv on 94) comments that : The\[ . . . \] model crucially relies upon the existence of numerous paradigmatic rela-fionsh  . ips in lexical databases . 
Paradigmatic relationships being relationships in which four words intervene  , they are in fact morphological nalogies : " reaction is to reactor  , as faction is to factor " . 
reactor / - ~ reactio . n ? L glg factor ~ faction Contrasting sharply with AI approaches  , morphological nalogies apply in only one domain , that of words . As a consequence , the number of relationships between analogical terms decreases from three  ( f , g and h ) to two ( f and g ) . Moreover , because all four terms intervening in the analogy are from the same domain  , the domains and ranges of f and g are identical . Finally , morphological nalogies can be regarded as simple equations independent of any knowledge about the language in which they are written  . This standpoint eliminates the need for any knowledge base or dictionary  . 
\] reactor --, reaction ~ g ~ g factor ~ x ? 1 . 3 Unic i ty vs Mult ip l ic i ty of Changes Solving morphological analogies remains difficult because several simultaneous changes may be required to transform one word into a second  ( for instance , doer --- , undo requires the deletion of the suffix-er and the insertion of the prefix un-  )  . This problem has yet to be solved satisfactorily . For example , in ( Yvon 94) , only one change at a time is allowed , and multiple changes are captured by successive applications of morphological analogies  ( cascade model )  . However , there are cases in the morphology of some languages where multiple changes at the same time a remandatory  , for instance in semitic languages . 
" One change at a time " , is also found in ( Nagao 84 ) for a translation method , called translation by analogy , where the translation of an input sentence is an adaptation of translations of similar sentences retrieved from a database  . 
The difficulty of handling multiple changes is remedied by feeding the system with new examples differing by only one word commutation at a time  .   ( Sadler and Vendelmans 90 ) proposed a different solution with an algebra on trees : differences on strings are reflected by adding or subtracting trees  . Although this seems a more convincing answer , the use of databases would resume , as would the multiplicity of domains . 
Our goal is a true analogy-solver , i . e . , an algorithm which , on receiving three words as input , outputs a word , analogical to the input . For that , we thus have to answer the hard problem of : ( 1 ) performing multiple changes ( 2 ) using a unique data type ( words )   ( 3 ) without dictionary nor any external knowledge . 
1.4 Analogies on Words
We have finished our review of the problem and ended up with what was the starting point of our work  . In linguistic works , analogy is defined by Saussure , after Humboldt and Baudoin de Courtenay , as the operation by which , given two forms of a given word , and only one form of a second word , the missing form is coined 4 , " honoristo hon6rem as 6r6tor is to 6rSt6rem " noted 6r~t6rem  :  6rdtor  =  hon6rem : honor . 
This is the same definition as the one given by Aristotle himself  , " A is to B as C is to D " , postulating identity of types for A , B , C , and D . 
4 Latin : 6rd to r(orator , speaker ) and honor ( honour ) nominative singular , 5 rat6 rern and honfremaccusative singular . 

However , while analogy has been mentioned and used , algorithmic ways to solve analogies seem to have never been proposed  , may be because the operation , isso " intuitive " . We ( Lepage & Ando 96 ) recently gave a tentative computational explanation which was not always valid because false analogies were captured  . It did not constitute an algorithm either . 
The only work on solving analogies on words seems to be Copy cat  ( ( Hofstadter et al 94 ) and ( Hoffman 95 ) ) , which solves such puzzles as : abc:abbccc = ijk : x  . Unfortunately it does not seem to use a truly dedicated algorithm  , rather , following the AI approach , it uses a for lnalisation of the domain with such functions as  , " previous in a Zphabe'c " , " rank in a Zphabel : " , etc . 
2 Foundations of the Algorithm 2 . 1 The First Term as an Axis ( Itkonen and Haukioja 97 ) give a program in Prolog to solve analogies in sentences  , as a refutation of Chomsky , according to whom analogy would not be operational in syntax  , because it dehvers non-gralnmatical sentences . That analogy would apply also to syntax , was advocated decades a goby Hermann Paul and Bloomfield  . 
Chomsky's claim is unfair , because it supposes that analogy applies only on the symbolevel  . 
It konen and Haukioja show that analogy , when controlled by some structural level , does deliver perfectly grammatical sentences . What is of interestous , is the essence of their method , which is the seed for our algorithm :
Sentence D is formed by going through sentences B and Cone element at a time and inspecting the relations of each element to the structure of sentence A  ( plus the part of sentence D that is ready )  . 
Hence , sentence A is the axis against which sentences B and C are compared  , and by opposition to which output sentence D is built  . 
rext der : u_~n readoble=d " - oer : x~x = un~able The method will thus be:  ( a ) look for those parts which are not common to A and Bononeh and  , and not common to A and C on the other and ( b ) put them together in the right order . 
2.2 Common Subsequenees
Looking for common subsequences of A and B ( resp . A and C ) solves problem ( a ) by complementation .   ( Wagner & Fischer 74 ) is a method to find longest common subsequences by computing edit distance matrices  , yielding the minimal number of edit operations ( insertion , deletion , substitution ) necessary to transform one string into another . 
For instance , the following matrices give the distance between like and unlike on one hand  , and between like and known on the other hand , in their right bottom cells : dist(like , unlike ) = 2 and dist(Iike , known )  =  5 unlike known ! 1   2   2   3   4   5 l 1   2   3   4   5 i 2   2   3   2   3   4 i 2   2   3   4   5 k 3   3   3   3   2   3 k 2   3   3   4   5 e 4   4   4   4   3   2 e 3   3   4   4   5   2  . 3 Simi l i tude between Words We call simi l i tude between A and B the length of their longest common subsequence  . It is also equal to the length of A , minus the number of its characters deleted or replaced to produce B  . 
This number we caUp dist(A , B ) , because it is a pseudo-distance , which can be computed exactly as the edit distances  , except that insertions cost 0 . 
sire(A,B ) = IA\[-pdist(A,B )
For instance , pdist(unlike , like ) = 2 , while pdist(like , unlike ) = O . 
like u 1   1   1   1 unliken 2   2   2   2 l 2   2   2   2 I 1   1   0   0   0   0 i 3   2   2   2 i 2   2   1   0   0   0 k 4   3   2   2 k 3   3   2   1   0   0 e 5   4   3   2 e 4   4   3   2   1   0 Characters inserted into B or C may be left aside  , precisely because they are those characters of B and C  , absent from A , that we want to assemble into the solution , D . 
As A is the axis in the resolution of analogy , graphically we make it the vertical axis around which the computation of pseudo-distances takes place  . For instance , for like : unlike = k , ' r ~ OW ~ : X , nwonkun 1 ike 1 III iI 1 I 0   0   0   0   2   2   2   2   2 i 2   2   1   0   0   0   2   2   2   2   2 k 3   3   2   1   0   0   3   3   3   3   3 e 4   4   3   2 i 0 It is easy to verify that there is no solution to an analogy if some characters of A appearn either in Bnor in C  . The contrapositive says that , for an analogy to hold , any character of A has to appear in either B or C  . Hence , the sum of the similititudes of A with B and C must be greater than or equal to its length : sim  ( A , B ) + sire(A , C ) >_IAI , or , equivalently , 
IdI~pdist(d,B ) + pdist(d,C)
When the length of A is greater than the sum of the pseudo-distances  , some subsequences of A are common to all strings in the same order  . 
Such subsequences have to be copied into the solution D  . We call com(A , B , C , D ) the sum of the length of such subsequences . The delicate point is that this sum depends precisely on the solution D being currently built by the algorithn LTo summarise  , for analogy A : B = C : D to hold , the following constraint must be verified : IAI = p dist  ( A , B ) + pdist(A , C ) + com(A , B , C , D ) 3 The Algorithm 3 . 1 Computat ion of Mat r i ces Our method relies on the computation of two pseudo-distance matrices between the three first terms of the analogy  . A result by ( Ukkonen 85 ) says that it is sufficient o compute a diagonal b and plus two extrab and s on each of its sides in the edit distance matrix  , in order to get the exact distance , if the value of the overall distance is known to be less than some given threshold  . This result applies to pseudo-distances , and is used to reduce the computation of the two pseudo-distance matrices  . The width of the extrab and s is obtained by trying to satisfy the coverage constraint with the value of the current pseudo-distance in the other matrix  . 
proccompute_matrices(A , B , C , pdAB , pdAc ) compute pseudo-distances matrices with extra bands of  pdAB/2 and pdAc/2 if \[ dl >_p dist ( d , B ) + pdist(A , C ) main component else compute . an atrices ( A , B , C , max(\[AI-pdist(d , C ) , pdAB+1) , xnax ( IAI-pdist(A , B ) , pdac+x )) end if end procCOlnpute_matrices3 . 2 Ma in Component Once enough in the matrices has been computed  , the principle of the algorithm is to follow the paths along which longest common subsequences are found  , simultaneously in both matrices , copying characters into the solution accordingly . At each time , the positions in both matrices must be on the same horizontal line  , i . e . at a same position in A , in order to ensure a right order while building the solution  , D . 
Determining the paths is done by comparing the current cell in the matrix with its three previous ones  ( horizontal , vertical or diagonal ) , according to the technique in ( Wagner & Fischer 74 )  . As a consequence , paths are followed from the end of words down to their beginning  . The nine possible combinations ( three directions in two matrices ) can be divided into two groups : either the directions are the same in both matrices  , or they are different . 
The following sketches the algorithm , corn(A , B , C , D ) has been initialised to : IAI-(pdist(d , B ) + pdist(d , C )) , iA , is and ic are the current positions in A , B and C . dir AB ( resp . dir Ac ) is the direction of the path in matrix AxB ( resp . A ? C ) from the current position . " copy " means to copy a character from a word at the beginning of D and to move to the previous character in that word  . 
if constraint ( iA , iB , ic , corn(A , B , C , D ) ) case : dirAB = dirAc = diagonal i f A\[iA \] = B \[iB \] = C\[ic \] decrement corn  ( A , B , C , D ) end if copy B\[iB\]+C\[ic\]-A\[iA\]~case : dirAB = dirAC = horizontal copy charb/min  ( pdist ( A\[1 . .iA \], B\[1 . .iB \]), pdist ( A\[1 . .iA \], C\[1 . .ic \] )   ) case : dirAB = dirAc = vertical move only in A ( change horizontal line ) case : dir AB  #dir Acif dir AB = horizontal copy B\[iB \] a In this case  , we move in tile three words at the same time . Also , the character arithmetics factors , in view of generalisations , different operations : if the three current characters in A  , B and C are equal , copy this character , otherwise copy that character fomB or C that is different from the one in A  . If all current characters are different , his is a failure . 
b The word with less similitude with A is chosen , so as to make up for its delay . 
731 e\] . se?f dirAB = vertical move in A and C e1$? same thing by exchanging B and C end ? f end if 3  . 3 Early Termination in Case of

Complete computation of both matrices is not necessary to detect a failure  . It is obvious when a letter in A does not appear in B or C  . This may already be detected before any matrix computation  . 
Also , checking the coverage constraint allows the algorithm to stop as soon as non-satisfying moves have been performed  . 
3.4 An Example
We will show how the analogy like : unlike = known : x is solved by the algorithm  . 
The algorithm first verifies that all letters of l ikea represent either in unlike or known  . 
Then , the minimum computation is done for the pseudo -distances matrices  , i . e . only the minimal diagonal band is computed . 
ekiln uknown 0   1   1   1   1   1   0   1   2 i 2   2   0   1   2 k 3   3   0   1   2 e 4   4 As the coverage constraint is verified , the main component is called . It follows the paths noted by values in circles in the matrices  . 
eki1nu known ? ? i ? ?12i2 ~ ) The succession of moves triggers the following copies into the solution : dir AB diagonal diagonal diagonal diagonal horizontal horizontal horizontal dir Accopy diagonal n diagon alw diagonalo diagonal n horizon talk diagonal n diagonal uAt each step  , the coverage constraint being verified , finally , the solution x = unknown is oup tut . 
4 Properties and Coverage 4 . 1 Trivial Cases , Mirroring Trivial cases of analogies are , of course , solved by the algorithm , like : A : A = A : x = ~ x =
A or A : A = C : x ~ x = C . Also , by construction , A : B = C : x and A : C = B : x deliver the same solution  . 
With this construction , mirring poses no problem . If we note A the mirror of word A , then A : B = C : D ? ~ A : B = C:D . 
4.2 Prefixing , Suffixing , Parallel
In fixing
Appendix A lists a number of examples , actually solved by the algorithm , from simple to complex , which illustrate the algorithm's performance . 
4 . 3 Redup l i ca t ion and Permutat ion The previous form of the algorithm does not produce redupl ication  . This would be necessary if we wanted to obtain , for example , plurals in Indonesian S:orang:orang = burung : x = vx = burung-burung  . In this case , our algorithm delivers , x = orang-burung , because preference is given to leave prefixes unchanged  . However , the algorithm may be easily modified so that it applies repeatedly so as to obtain the desired solution  6  . 
Permutation is not captured by the algorithm . An example ( q with a and u ) in Proto-semitic is : yaqtilu:yuqtiIu = qatal : qutaI  . 
4 . 4 Language - independence/Code-dependence Because the present algorithm performs compu-ration only on a symbolevel  , it may be applied to any language . It is thus language independent . This is fortunate , as analogy in linguistics certainly derives from a more general psychological operation  ( ( Gentner 83 )  , ( Itk one n 94)) , which seems to be universal among human beings . Examples in Section A illustrate the language independence of the algorithm  . 
Conversely , the symbols determine the granularity of the analogies computed  . Consequently , a commutation not reflected in the coding system will not be captured  . This may be illustrated by a Japanes example in three different Sorang  ( human being ) singular , orang-orang plural , burung ( bird ) . 
SSi , nilarly , it is easy to apply the algorithm in a transducer -like way so that it modifies  , by analogy , parts of an input string . 
732 codings : the native writing system , the Hep-burn transcription and the official , strict rec-omlnendation ( kunrei ) . 
Kanji/Kana : ~-9:~#~~-9-=~<: x
Hepburn : matsu : mae himasu = hataraku : xKunrei :matu:matimasu = hataraku : xx = hatarak imasu The algorithm does not solve the first two analogies  ( solutions : ~- ~$ # , hatarokimasu ) because it does not solve the elementary analogies  , -9:~=<: ~ and tsu:chi=ku:ki , which are beyond the symbolevel r . 
More generally speaking , the interaction of analogy with coding seems the basis of a frequent reasoning principle : f  ( A ) : f ( B ) = f ( C ) : x~A : B ==_ C:f-t ( x ) Only the first analogy holds on the symbolevel and  , as is , is solved by our algorithm , f is an encoding function for which an inverse exists  . 
A striking application of this principle is the resolution of some Copy cat puzzles  , like:abc:abd=ijk:x => x=ijIUsing a binary ASCII representation  , which reflects sequence in the alphabet , our algorithm produces : 011000010110001001100011  :  011000010110001001100100  ---~  011010010110101001101011 : X = : ~ X ~ 011010010110101001101100 ~ ijlSet in this way , even analogies of geometrical type can be solved under a convenient representation  . 
An adequate description ( or coding ) , with no reduplication , is : obj(bia ) & . obj ( ~maU ) Cobj ( big ) _obj ( big ) ~: xobj = circle " ~: obj = circle-obj = square This is actually solved by our algorithm : obj  (   ,   . U ) cobj ( bia ) x = & obj = square ~ One could imagine extending the algorithm by parametrising it with such predefined analogical relations  . 
In other words , coding is the key to many analogies . More generally we follow ( Itkonen and Haukioja 97 ) when they claim that analogy is an operation against which formal representations should also be assessed  . But for that , of course , we needed an automatic analogy-solver . 
Conclusion
We have proposed an algorithm which solves analogies on words  , i . e . when possible it coins a fourth word when given three words  . It relies on the computation of pseudo-distances between strings  . The verification of a constraint , relevant for analogy , limits the computation of matrix cells , and permits early termination in case of failure . 
This algorithm has been proved to handle many different cases in many different languages  . In particular , it handles parallel infix-ing , a property necessary for the morphological description of semitic languages  . Reduplication is an easy extension . 
This algorithm is independent of any language , but not coding-independent : it constitutes a trial at inspecting how much can be achieved using only pure computation on symbols  , without any external knowledge . We are inclined to advocate that much in the matter of usual analogies  , is a question of symbolic representation , i . e . a question of encoding into a form solvable by a purely symbolic algorithm like the one we proposed  . 
AExamples
The following examples how actual resolution of analogies by the algorithm  . They illustrate what the algorithm achieves on real linguistic examples  . 
A . 1 Inser t ion or de let ion of pref ixes or suffixes Latin : or a torem : or a tor = ho nor em : xx = honor French : rd pression : rdp  . ressionnaire = rd action : xx = rdactionnai reMalay:tinggal:ketinggalan=d~tduk: x x = k e d u d u k a n 
Chinese : ~: 4~: ~$ ~= ~: x x = ~
English : wolf : wolves = leaf : xx = leaves Malay : kawan : mengawani = keliting : xx = mengeliling i 
Malay : keras:menger askan=ke na:x
X - - - - 17 zengefla\]zal ~
Polish : wyszed teg : wyszIa . 4 = poszedted:xx = posztad
A.3 Infixing and umlaut
Japanese : ~: ~@ Y ~= ~7 o : x x = , ~@ ~
German : lang:Idngste=scharf:xx=schdrfste German : fliehen : erfloh=schlie~en : xx- ersehloflPolish:zgubiony:zgubieni = zmartwiony:xx = zmartwieniAkkadian : uka ~  . ~ad : uktanaggad=ugak . ~ ad:xx = u . ?tanakgad
A.4 Parallel in fixing
Proto-semitic : yasriqu:sariq = yanqinm : xx = naqim 
Arabic : huziht:huzdI = sudi'a:xx = sud ( ~' Arabic : arsaIa : mursitun = asIama : xx = m . usIimun

Robert I . Damper & John E . G . Eastman
Pronouncing Text by Analogy
Proceedings of COLING96, Copenhagen,
August 1996, pp . 268-269.
Dedre Gentner
Structure Mapping : A Theoretical Model for

Cognitive Science , 1983, vol . 7, no 2, pp .  155-170 . 
Rogers P . Hall
Computational Approaches to Analogical
Reasoning : A Comparative Analysis
Artificial Intelligence , Vol . 39, No . 1, May 1989, pp .  39-120 . 
Douglas Hofstadter and the Fluid Analogies Research Group Fluid Cbncepts and Crexttive Analogies 
Basic Books , New York , 1994.
Robert R . Hoffman
Monster Analogies
AI Magazinc , Fall 1995, vol . 11, pp 1135.
Esa Itkonen
Iconicity , analogy , and universal grammar Journal of Pragmatics ,  1994 , vol . 22, pp .  37-53 . 
Esa Itkonen and Jussi Haukioja
A rehabilitation of analogy in syntax ( and elsewhere ) in Andr OsKert ~ sz ( ed . ) Metalinguistikim
Wandeh die kognitive Wendein W is -senschafls theorie und Linguistik Frankfurta/M  , Peter Lang ,  1997 , pp .  131-177 . 
Yves Lepage & Ando Shin-Ichi
Saussurian analogy : a theoretical account and its application 
Precedings of COLING96, Copenhagen,
August 1996, pp . 717-722.
Nagao Makoto
A Framework of a Mechanical Translation between Japanese and English by Analogy Principle in Artificial ~ Human Intelligence  , Alick Elithorn and Ranan Banerjieds . , Elsevier
Science Publishers , NATO 1984.
Vito Pirelli & Stefano Federici " Derivational " paradigms in morphonology Proceedings of  COLING94  , Kyoto , August 1994 , Vol . I , pp 234-240 . 
Victor Sadler and Ronald Vendelmans
Pilot implementation of a bilingual knowledge bank Proceedings of  COLING90  , Helsinki ,  1990 , vol 3 , pp .  449-451 . 
Eric Steinhart
Analogical Truth Conditions for Metaphors Metaphor and Symbolic Activity  ,  1994 ,  9(3) , pp 161-178 . 
Esko Ukkonen
Algorithms for Approximate String Matching h ~formation and Control  ,  64 ,  1985 , pp .  100-118 . 
Robert A . Wagner and Michael J . Fischer
The String-to-String Correction Problem
Journal for the Association of Computing Machinery  , Vol . 21, No . 1, January 1974, pp . 

Frangois Yvon
Paradigmatic Cascades : a Linguistically
Sound Model of Pronunciation by Analogy
Proceedings of ACL-EACL-97 , Madrid ,  1994 , pp 428-435 . 

