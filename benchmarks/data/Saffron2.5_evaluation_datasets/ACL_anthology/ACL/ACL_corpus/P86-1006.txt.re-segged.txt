COMPUTATION ALCOMPLEXITY OF CURRENT GPSG THEORY
Eric Sven Ristad
MIT Artificial Intelligence Lab Thinking Machines Corporation 
545 Technology Square and 245 First Street
Cambridge , MA 02139 Cambridge , MA 02142

An important goal of computational linguistics has been to use linguistic theory to guide the construction of computationally efficient realworld natural language processing systems  . At first glance , generalized phrase structure grammar ( GPSG ) appears to be ablessing on two counts . First , the precise formalisms of GPSG might be a direct and fransparent guide for parser design and implementation  . Second , since GPSG has weak contextfree generative power and contextfree languages can be parsed in O  ( n  ~ ) by a wide range of algorithms , GPSG parsers would appear to run in polynomial time  . This widely-assumed GPSG " efficient parsability " result is misleading : here we prove that the universal recognition problem for current GPSG theory is exponential-polynomialt mehard  , and assuredly intractable . 
The paper pinpoint sources of complexity ( e . g . metarules and the theory of syntactic features ) in the current GPSG theory and concludes with some linguistically and computationally motivated restrictions on GPSG  . 
1 Introduction
An important goal of computational linguistics has been to use linguistic theory to guide the construction of computationally efficient realworld natural anguage processing systems  . Generalized Phrase Structure Grammar ( GPSG ) linguistic theory holds out considerable promise as an aid in this task  . The precise formalisms of GPSG offer the prospect of a direct and transparent guide for parser design and implementation  . Furthermore , and more importantly , GPSG's weak contextfree generative power suggests an efficiency advantage for GPSG-based parsers  . Since contextfree languages can be parsed in polynomial time  , it seems plausible that GPSGs can also be parsed in polynomial time  . This would in turn seem to provide " the beginnings of an explanation for the obvious  , but largely ignored , fact that l humans process the utterances they hear very rapidly  ( Gazdar , 198\] :155) . "  1 In this paper I argue that the expectations of the informal complexity argument from weak contextfree generative power are not in fact met  . I begin by examining the computational complexity of metarules and the feature system of GPSG and show that these systems can lead to computational intractabil-~See also Joshi  , " Tree Adjoining Grammars ~ p . 226, in Natural Language Parsing (1985) ed . by D . Dowty , L . Karttunen , and A . Zwicky , Cambridge University Press : Cambridge , and a Except lons to the Rule , ~ Science News 128:314-315 . 
ity . Next I prove that the universal recognition problem for current GPSG theory is Exp-Poly hard  , and assuredly intractable . 2 That is , the problem of determining for an arbitrary GPSG G and input string z whether x is in the language L  ( G ) generated by G , is exponential polynomial time hard . This result puts GPSG-Recognition ia complexity class occupied by few natural problems : GPSG -Recognition is harder than the traveling salesman problem  , context-sensitive language recognition , or winning the game of Chesson an nxn board . The complexity classification shows that the fastest recognition algorithm for GPSGs must take exponential time or worse  . One role of a computational analysis is to provide formal insights into linguistic theory  . To this end , this paper pinpoint sources of complexity in the current GPSG theory and concludes with some linguistically and computationally motivated restrictions  . 
2 Complexity of GPSG Components
A generalized phrase structure grammar contains five language-particular components -- immediate dominance  ( ID ) rules , metarules , linear precedence ( LP ) statements , feature cooccurrence restrictions ( FCRs ) , and feature specification defaults ( FSDs ) -- and four universal components -- a theory of syntactic features  , principles of universal feature instantiation , principles of semantic interpretation , and formal relationships among various components of the grammar  , s Syntactic ategories are partial functions from features to atomic feature values and syntactic ategories  . They encode subcategorization , agreement , unbounded dependency , and other significant syntactic information . The set K of syntacticate-gories is inductively specified by listing the set F of features  , the set A of atomic feature values , the function po that defines the range of each atomic-valued feature  , and a set R of restrictive predicates on categories  ( FCRs )  . 
The set of ID rules obtained by taking the finite closure of the metarules on the ID rules is mapped into local phrase structure trees  , subject to principles of universal feature instantiation  , FSDs , FCRs , and LP statements . Finally , local trees are 2We use the universal problem to more accurately explore the power of a grammatical formalism  ( see section 3 . 1 below for support ) . Ris-tad ( 1985 ) has previously proven that the universal recognition problem for the GPSG's of Gazdar  ( 1981 ) is NP-hard and likely to be intractable , venunder severe metarule restrictions . 
3This work is based on current GPSG theory as presented in Gazdar et  . 
al . (1985), hereafter GKPS . The reader is urged to consul that work for a formal presentation adthorough exposition of current GPSG theory  . 
30 assembled to form phrase structure trees , which are terminated by lexical elements . 
To identify sources of complexity in GPSG theory , we consider the isolated complexity of the finite metarule closure Ol > - station and the rule to tree mapping  , using the finite closure membership and category membership problems  , respectively . 
Informally , the finite closure membership problem is to determine if an ID rule is in the finite closure of a set of metarules M on a set of ID rules R  . The category membership problem is to determine if a category or Coralegal extension of C is in the set K of all categories based the function p and the sets A  , F and R . Note that both problems must be solved by any GPSG-based parsing system when computing the ID rule to local tree mapping  . 
The major results are that finite closure membership is NP-hard and category memberships PSPACE-hard  . Barton ( 1985 ) has previously shown that the recognition problem for ID/LP grammars is NP-hard  . The components of GPSG theory are computationally complex  , as is the theory as a whole . 
Assumptions . In the following problem definitions , we allow syntactic categories to be based on arbitrary sets of features and feature values  . In actuality , GPSG syntactic categories are based on fixed sets and a fixed function p  . As such , the set K of permissible categories is finite , and a large table containing K could , in principe , be given . 4 We ( uncontroversially ) generalize to arbitrary sets and an arbitrary function p to prevent such a solution while preserving GPSG's theory of syntactic features  , s No other modifications to the theory are made . 
An ambiguity in GKPS is how the FCRs actually apply to embedded categories  . 6 Following Ivan Sag ( personal communication ) , I make the natural assumption here that FCRs apply toplevel and to embedded categories equally  . 
4 This suggestion is of no practical significance , because the actual number of GPSG syntactic a tegories i extremely large  . The total number of categories , given the 25 atomic features and 4 category-valued features , is : JK = K'I = 32 s ( (1 +32s ) C ( 1+32s ) ( ( 1 ?32~ ) (1 +32s ) ~ ) 2 ) s ) " ~_32 s ( 1 + 32~ ) s4>3le2~>10TM Seep age 10 for details . Many of these categories will be linguistically meaningless  , but all GPSGs will generate all of them and then filter someout in consideration of FCRs  , FSDs , universal feature instantiation , and the other admissible local trees and lexical entries in the GPSG  . While the FCRs in some grammars may reduce the number of categories  , FCRs are a language-particular component of the grammar  . The vast number of categories cited above is inherent in the GPSG framework  . 
SOur goal is to identify sources of complexity in GPSG theory  . The generalization to arbitrary sets allows a finegrained study of one component of GPSG theory  ( the theory of syntactic features ) with the tools of computational complexity theory  . Similarly , the chessboard is uncontroverslally generalized to size n ? a in order to study the computational complexity of chess  . 
eA category C that is defined for a feature \] , fE(F-Atom)nDON(C ) ( e . g . f = SLASH ) , contains an embedded category C ~ , where C(f)---C ~ . 
GKPS does not explain whether FCR's must be true of C ~ as well as C  . 
2.1 Metarules
The complete set of ID rules in a GPSG is the maximal set that can be arrived at by taking each metarule and applying it to the set of rules that have not themselves arisen as a result of the application of that metarule  . This maximal set is called the finite closure ( FC ) of a set R of lexical ID rules under a set M of metarules  . 
The cleanest possible complexity proof for metarule finite closure would fix the GPSG  ( with the exception of metarules ) for a given problem , and then construct metarules dependent on the problem instance that is being reduced  . Unfortunately , metarules cannot be cleanly removed from the GPSG system  . 
Metarules take ID rules as input , and produce other ID rules as their output . If we were to separate metarules from their inputs and outputs  , there would be nothing left to study . 
The best complexity proof for metarules , then , would fix the GPSG modulo the metarules and their input  . We ensure the input is not inadvertently performing some computation by requiring the one ID rule R allowed in the reduction to be fully specified  , with only one 0-1evel category on the lefthand side and one unanalyzable terminal symbol on the righthand side  . 
Furthermore , no FCRs , FSDs , or principles of universal feature instantiation are allowed to apply  . These are exceedingly severe constraints . The ID rules generated by this formal system will be the finite closure of the lone ID ruleR under the set M of metarules  . 
The ( strict , resp . ) finite closure membership roblem for GPSG metarules is : Given an ID rule r and sets of metarules M and ID rules R  , determine if 3 resuch that rI~r(rI = r , resp . ) and rI?FC(M,R ) . 
Theorem 1: Finite Closure Membership is NP-hard Proof : On input  3-CNF formula F of length n using them variables zl .   .   . x , ~ , reduce 3SAT , a known NP-complete problem , to Metarule-Membership in polynomial time . 
The set of ID rules consists of the one ID rule R , whose mother category represents the formula variables and clauses  , and a set of metarules Ms . t . an extension of the ID rule A is in the finite closure of M over R iff F is satisfiable  . The metarules generate possible truth assignments for the formula variables  , and then compute the truth value of F in the context of those truth assignments  . 
Let w be the string of formula literals in F , and let wl denote the ith symbol in the string w . 
1. The ID rules R , A
A : where < satisfiable > < satisfiability >

F --* < satisfiability >\[\[ STAGE 3\]\]-~<satisfiable > is a terminal symbol is a terminal symbol \[ y , 0\]: l<i<mulc , o \] : I < i < ~
U\[STAGEI\]2 . Construct he metarules ( a ) mmeta rules to generate all possible assignments othe variables 
V i , 1 < i < m\[yi0\] , \[STAGEI \]-* W(i)\[YiI\] , \[ STAGE1\]~W ( b ) one metarule to stop the assignment generation process\[STAGE  1\]  ) - ~ W ( 2 ) \[ STAGE2\]--*W ( c ) I w \[ metarules to verify assignments V i , j , k1 < i < 1 ~ j , l <_j <_m , O < k < 2 , if wsi-k : xj , then construct he metarule \[ yi1\] , \[ ei0\] , \[ STAGE2\])--+W(3)\[yji\] , \[ ci1\] , \[ STAGE2\]--'W
V i , j , kl < i < ~-1 , l <_j <_m , O<k<_2 , if wsi-k = ~ , then construct he metarule \[ yj0\] , \[ cl0\] , \[ STAGE2\]-*W(4)\[yjO\] , \[ ci1\] , \[ STAGE2\]--- , W ( d ) Let the category C =\[ ci1\]:1<i<l ~ J . Construct the metarule
C\[STAGE 2\] - ~ W\[STAGE 3\] --* < satisfiable > ( 5 ) The reduction constructs O ( I w l ) metarules of size log ( Iw\[ )  , and clearly may be performed in polynomial time : the reduction time is essentially the number of symbols needed to write the GPSG down  . Note that the strict finite closure membership problem is also NP-hard  . One need only add a polynomial number of metarules to " change " the feature values of the mother node C to some canonical value when C  ( STAGE ) = 3--all 0 , for example , with the exception of STAGE . Let F =\[ Yi0\]:l<i<mU\[c , O\]:l<i < ~ . Then A would be A:F\[STAGE 3\] -~< satisfiable >

The major source of intractability is the finite closure operation itself  . Informally , each metarule can more than double the number of ID rules  , hence by chaining metarules ( i . e . by applying the output of a metarule to the input of the next metarule  ) finite closure can increase the number of ID rules exponentially ff  2  . 2 A Theory o f Syntact i c Features Here we show that the complex feature system employed by GPSG leads to computational intractability  . The underlying insight for the following complexity proof is the almost direct equivalence between Alternating Turing Machines  ( ATMs ) and syntactic categories in GPSG . The nodes of an ATM computation correspond to 0-level syntactic ategories , and the ATM computation tree corresponds to a full  , n-level syntacticate-gory . The finite feature closure restriction on categories  , which limits the depth of category nesting , will limit the depth of the corresponding ATM computation tree  . Finite feature closure constrains us to specifying  ( at most ) a polynomially deep , polynomially branching tree in polynomial time . This is exactly equivalent to a polynomial time ATM computation  , and by Chandra and Stockmeyer (1976) , also equivalent to a deterministic polynomial space-bounded'luring Machine computation  . 
As a consequence of the above insight , one would expect the GPSG Category-Membership problem to be PSPACE-hard  . 
The actual proof is considerably simpler when framed as a reduction from the Quantified Boolean Formula  ( QBF ) problem , a known PSPACE-complete problem . 
Let a specification of K be the arbitrary sets of features F  , atomic features Atom , atomic feature values A , and feature cooccurrence restrictions R and let p be an arbitrary function  , all equivalent to those defined in chapter 2 of GKPS . 
The category membership problem is : Given a category C and a specification of a set K of syntactic ategories  , determine if 3CIs . t . CI~C and CIEK . 
The QBF problem is QIF1 Qzyz . . . Qmy , nF ( yh YZ, . . . , y , n)IQ i6V ,  3 , where they i are boolean variables , F is a boolean formula of length n in conjunctive normal form with exactly ~ More precisely  , the metarule finite closure operation can increase the size of a GPSGG worse than exponentially : from IGi to O  ( \] G\[2 ~ )  . Given a set of ID rules R of symbol size n , and a set M of m metarule , each of size p , the symbol size of FC(M , R ) is O(nz ~) = O(IGIZ ~) . Each met~ule can match the productions in RO ( n ) different ways , inducing O ( n + p ) new symbols permatch : each metarule can therefore square the ID rule grammar size  . There aremmeta rules , of inite closure can create an ID rule grammar with O  ( n2  ~ ) symbols . 
32 three variables per clause (3-CNF ) , and the quantified formula is true . 
Theorem 2: GPSG Category-Membership is PSPACE-hard Proof : By reduction from QBF  . On input formula fl = QlylQ2 y2 .   .   . QmymF(yl , y2, .   .   .   , y , ~ ) we construct an instance P of the Category -Membership problem in polynomial time  , such that f ~ EQB F if and only if P is true . 
Consider the QBF as a strictly balanced binary tree  , where the ith quantifier Qi represents pairs of subtree s < T t  , T !> such that ( 1 ) T t and T ! each immediately dominate pairs of subtrees representing the quantifiers Qi+l  . . . Qra , and ( 2 ) the ith variable y i is true in T ~ and false in Tf  . All nodes at leveliin the whole tree correspond to the quantifier Qi  . The leaves of the tree are different instantiations of the formula F  , corresponding to the quantifier-determined truth assignment so them variables  . A leaf node is labeled true if the instantiated formula F that it represents is true  . An internal node in the tree at level i is labeled true if  1  . Q i="3" and either daughter is labeled true , or 2 . Qi -= " V " and both daughters are labeled true . 
Otherwise , the node is labeled false.
Similarly , categories can be_understood as trees , where the features in the domain of a category constitute a node in the tree  , and a category C immediately dominates all categories C ~ such that S f e  (   ( r-Atom ) ADON ( C ) ) \ [ C ( f ) = C'\] . 
In the QBF reduction , the atomic-valued features are used to represent hemvariables  , the clauses of F , the quantifier the category represents , and the truth label of the category . 
The category-valued features represent the quantifiers -- two category-valued features q k  , q t k represent he subtree pairs < T t , TI > for the quantifier Qk . FCRs maintain quantifier-imposed variable truth assignments " down the tree " and calculate the truth labeling of all leaves  , according to F , and internal nodes , according to quantifier meaning . 
Details . Let w be the string of formula literals in F , and w ~ denote the ith symbol in the string w . We specify a set K of permissible categories based on A  , F , p ,  . and the set of FCRsRs . t . the category \[\[ LABEL 1\]\] or an extension of it is an element of K iff ~ is true  . 
First we define the set of possible 0-level categories , which encode the formula F and truth assignments to the formula variables  . The feature wi represents the formula literal wi in w  , yj represents the variable yj in f2 , and ci represents the truth value of the ith clause in F  . 
Atom = LEVEL , LABE Luw , : 1 < i < l wluy : - : 1 < j < muc ~ : 1 < ; < ~
F-Atom = qk , q ~ : l < k < mp ? ( LEVEL ) = k : l < k < mA-1po ( f )  = 0 , 1 Vf E Atom -  LEVEL  FCR's are included to constrain both the form and content of the guesses :  1  . FCR's to create strictly balanced binary trees :
Vk , l < k < m , \]LEVEL k\]=\[qk\[\[Yk 1\]\[LEVEL k + 1\]\]\]& \[ ql\[\[Vk 0\]\[LEVEL k + 1\]\]\]   2  . FCR's to ensure all 0-level categories are fully specified :
V i , 1 < i < m\[c , \]=\[ w3 , - ~\]&\[~3~-l\]&\[~~3 , \]\]LABEL\]--=\[cl\]
Vk , 1<k<m ,\[ LABEL\]--=\[yk\]3 . FCR's to label internal nodes with truth values determined by quantifier meaning : 
Vk , l < k < rn , if Qk = " V " , then include :\[ LEVEL k\]&\[LABEL 1\] ------\[ qk\[\[LABELll\]\]&\[q ~\[\[ LABEL 1\]\]1 \[LEVEL k\]&\[LABELO\]-----\[qk\[\[LABEL 0\]\]\] V\[q ~\[\[ LABEL 0\]\]1 otherwise Qk = "3"  , and include :\[ LEVEL k\]&\[LABEL 1\] --\[ qk\[\[LABEL 11\]\] Y\[q~\[\[LABELI\]\]\]\[LEVELk\]&\[LABEL O\]--\[qk\[\[LABEL  0\]\]\]&Iq ~\[\[ LABEL 0\]\]\] The category-valued features qk and q~represent the quantifier Qk  . In the category value of qk , the formula variable y k = 1 everywhere , while in the category value of q ~ , 
Yk = 0 everywhere.
4 . one FCR to guarantee that only satisfiable assignments are permitted : \[ LEVEL  1\] ~ILABEL 1\]   5  . FCR's to ensure that quantifier assignments are preserved " down the tree ": 
V i , kl <_i < k < m , \[ Yi 1\] D\[qk\[\[Yi 1\]\]\]&\[q ~\[\[ Yi 1\]\]\]  \[~ , O\]~\[q~\[\[y ~ o\]\]\]&\[qi\[\[y ~ 0\]\]\] 

V i , kl < i < lw\[and1 < k < m , if wi = Yk , then include :\[ Yk11 D\[w , 11\[~ko\]D\[~o \] else if wi = Y - ~ , then include : \[ y , ~:\] D\[~ , o \]\[ ~ , ~ , o \] DN ,  1\] 7 . FCR's to verify the guessed variable assignments in leaf nodes : 
Vil < i < ~,
It , o \]_=\[~ s , -2o \] ~\ [ ~ , _  , o \] ~\ [ ~ , o\]\[ci1\]--\[ws , - ~1\] V\[ws , _I1\]V\[ws , 1\]\[LEVEL rn+l\]&\[c ,   0\] D\[LABEL 0\] \[LEVELm + 1\]d~\[Cx   1\]&:\[c2 l \]& . . . & \[c~ol/31 \] D\[LABEL 11 The reduction constructs O ( 1~1 ) features and O ( m  ~ ) FCRs of size O ( logm ) in a simple manner , and consequently may be seen to be polynomial time  .  0 . ~ . P The primary source of intractability in the theory of syntactic features is the large number of possible syntacticate-gories  ( arising from finite feature closure ) in combination with the computational power of feature cooccurrence rstrictions  , FCRs of the " disjunctive consequence " form\[f v\]D\[flvl\]V  .   .   . V\[fnvn\]compute the direct analogue of Satisfiability : when used in conjunction with other FCRs  , the GPSG effectively must try all n feature-value combinations  . 
3 Complex i ty o f GPSG-Recogn i t ion Two isolated membership problems for GPSG's component formal devices were considered above in an attempt to isolate sources of complexity in GPSG theory  . In this section the recognition problem ( RP ) for GPSG theory as a whole is considered . 
I begin by arguing that the linguistically and computationally relevant recognition problem is the universal recognition problem  , as opposed to the fixed language recognition problem  . I then show that the former problem is exponential-polynomial  ( Exp-Poly ) time-hard . 
SFinite feature closure admits a surprisingly large number of possible categories  . Given a specification ( F , Atom , A , R , p ) of K , let a = lAteral and b = IF-Atom I . Assume that all atomic features are binary : a feature may be +  , - , or undefined and there are 3 a 0-1evel categories . The b category-valued features may each assume O ( 3 ~ ) possible values in a 1-1evel category , so I/f'I = O(3 = (3") b) . More generally , IK = K'I-O(3~'~C ~ or r~- , =) = O(3~?''~C:o o , ~) = O(~*" . ) = O(3o . '') where E~=onvergestoe ~2 . 7 very rapidly and a , b = O(IGI ); a = 25 , b = 4 in GKPS . The smallest category in K will be 1 symbol ( null set )  , and the largest , maximally-specified , category wilt be of symbol-slzelog IKI = oca . b !) . 
3 . 1 Def in ing the Recogn i t ion Prob lem The universal recognition problem is : given a grammar G and input string x  , is zCL(G ) ? . Alternately , the recognition problem for a class of grammars may be defined as the family of questions in one unkown  . This fized language recognition problem is : given an input string x  , is zEL for some fixed language L ? . For the fixed language RP , it does not matter which grammar is chosen to generate L--typically  , the fastest grammar is picked . 
It seems reasonable clear that the universal RP is of greater linguistic and engineering interest han the fixed language RP  . 
The grammars licensed by linguistic theory assign structural descriptions to utterances  , which are used to query and update databases , be interpreted semantically , translated into other human languages , and so on . The universal recognition problem--unlike the fixed language problem--determines membership with respecto a grammar  , and therefore more accurately models the parsing problem  , which must use a grammar to assign structural descriptions  . 
The universal RP also bears most directly on issues of natural language acquisition  . The language learner evidently possesses a mechanism for selecting grammmars from the class of learnable natural anguage grammars / ~ a on the basis of linguistic inputs  . The more fundamental question for linguistic theory  , then , is " what is the recognition complexity of the class / ~ c ? "  . 
If this problem should prove computationally intractable  , then the ( potential ) tractability of the problem for each language generated by a G in the class is only a partial answer to the linguistic questions raised  . 
Finally , complexity considerations favor the universal RP . 
The goal of a complexity analysis is to characterize the amount of computational resources  ( e . g . time , space ) needed to solve the problem in terms of all computationally relevent inputs on some standard machine model  ( typically , a multitape deterministic Turing machine ) . We know that both input string length and grammar size and structure affect the complexity of the recognition problem  . Hence , excluding either input from complexity consideration would not advance our understanding  .   9 Linguistics and computer science are primarily interested in the universal recognition problem because both disciplines are concerned with the formal power of a family of grammars  . Linguistic competence and performance must be considered in the larger context of efficient language acquisition  , while computational considerations demand that the recognition problem be characterized in terms of both input string and grammar size  . 
Excluding grammar size from complexity consideration i order ST his ~ consider all relevant inputs ~ methodology is universally assumed in the formal language and computational complexity literature  . For example , Hopcraft and Ullman ( 1979:139 ) define the contextfree grammar recognition problem as : " Given a CFG G =  ( V , T , P , $) and a string z in Y ' , is x in L(G ) ? . " . Garey and Johnson ( 1979 ) is a standard reference work in the field of computational complexity  . All 10 automat and language recognition problems covered in the book  ( pp . 265-271) are universal , i . e . 
of the form " Given an instance of a machine /grammar and an input  , does the machine/grammar accep the input7 ~ The complexity of these recognition problems is alt #ays calculated in terms of grammar and input size  . 
3 4 to argue that the recognition problem for a family of grammars is tractable is akin to fixing the size of the chessboard in order to argue that winning the game of chess is tractable : neither claim advances our scientific understanding of chessor natural language  . 
3 . 2 GPSG-Recogn i t ion is Exp-Po ly hard Theorem 3: GPSG-Recognition is Exp-Polytime-hard Proof 3: By direct simulation of a polynomial space bounded alternating Turing Machine Monin put w  . 
Let S(n ) be a polynomial in n . Then , on input M , aS ( n ) space-bounded one tape alternating Turing Machine  ( ATM )  , and string w , we construct a GPSGG in polynomial time such that wEL  ( M ) iff $0 wll w22 . . . w,~n$n ? lEL(G ) . 
By Chandra and Stockmeyer (1976),
ASPACE ( S ( n ) ) = U DTIM ~ cs ( " ) ) c:>0 where ASPACE ( S ( n ) ) is the class of problems olvable in space Sin ) on an ATM , and DTIME ( F ( n ) ) is the class of problems solvable in time F ( n ) on a deterministic Turing Machine . 
As a consequence of this result and our following proof  , we have the immediate result that GPSG -Recognition is DTIME  ( cS ( n ) ) - hard , for all constants c , or Exp-Polytime-hard . 
An alternating Turing Machine is like a nondeterministic TM  , except that some subset of its states will be referred to as universal states  , and the remainder as existential states . A nondeterministic TM is an alternating TM with no universal states  .   10 The nodes of the ATM computation tree are represented by syntactic ategories in K?--one feature for every tapes quare  , plus three features to encode the ATM tape head positions and the current state  . The reduction is limited to specifying a polynomial number of features in polynomial time  ; since these features are used to encode the ATM tape  , the reduction may only specify polynomial space bounded ATM computations  . 
The ID rules encode the ATMNextM () relation , i . e . C---*Next M(C ) for a universal configuration C . The reduction constructs an ID rule for every combination of possible head position  , machine state , and symbol on the scanned tapes quare . 
Principles of universal feature instantiation transfer the rest of the instantaneous description  ( i . e . contents of the tape ) from mother to daughters in ID rules . 
1?Our ATM definition is taken from Chandra nd Stockmeyer  ( 1976 )  , with the restriction that the work tapes are one -way in finite  , instead of two-way infinite . Without loss of generality , we use a 1-tape ATM , so C(Qxr ) ? ( Q?rk?(L , Rx(L , R )) Let Next M(C)----C0 , Cl ,   .   .   . , Ck . If C is a universal configuration , then we construct an ID rule of the form c ~ Co , Cl ,   .   .   .   , ck (6) Otherwise , C is an existential coi ~ figuration ad we construct the k +  1 ID rules c - - , c ~ v i , 0 < i < k ( 7 ) A universal ATM configuration is labeled accepting if and only if it has halted and accepted  , or if all of its daughters are labeled accepting . We reproduce this with the ID rules in 6( or 8) , which will be admissible only if all subtrees rooted by the RHS nodes are also admissible  . 
An existential ATM configuration is labeled accepting if and only if it has halted and accepted  , or if one of its daughters is labeled accepting . We reproduce this with the ID rules in 7( or 9) , which will be admissible only if one subtree rooted by a 
RHS node is admissible.
All features that represent tapes quares are declared to be in the HEAD feature set  , and all daughter categories in the constructed ID rules are head daughters  , thus ensuring that the Head Feature Convention ( HFC ) will transfer the tape contents of the mother to the daughter  ( s )  , modulo the tape writing activity specified by the next move relation  . 
Details.

Result 0 M(i , a , d ) =\[\[ HEAD0i + ll , \[ ia \] , \[A1\]\] if d = R\[\[HEAD0i-1\] , \[ ia \] , \[ A1\]\] if d = L
Result lM(j , c , p , d ) =\[\[ HEAD1j+l\] , \[ rfc\]\[STATEp\]\] if d = R\[\[ HEAD1 j-l\] , \[ ric\]\[STATEpl\]if d=LTransM(q , a , b ) = (( p , c , dl , d2) : (( q , a , b ) , ( p ; c , dl , d2 > ) eB where a is the read-only ( R/O ) tape symbol currently being scanned b is the read -write  ( R/W ) tape symbol currently being scanned dl is the R/O tape direction  d2 is the R/W tape direction
The GPSGG contains : 1 . Feature definition station tree , where the features in A tomen code the ATM configuration  . Labeling is performed by ID rules . 
( a ) definition of F , Atom , A
F : A to m =
A = STATE , HEADO , HEAD1 , Aui : O<i<\[wl+luri:1_<j_<S ( I w l ) 
QUEUr ; as defined earlier ( b ) definition of p0p ? ( A )  = 1 , 2 , 3 p?(STATE ) = Q ; the ATM states et p ? ( HEADO ) : j : 1 < j <- I~1 p ? ( HEAD1 ) = i:1 < i < S ( I ~ I ) vf ? ; : o < ; < 1~1+1po(f ) = ZU $ ; the ATM input alphabet
Vf?ry:1 < j<s(l~l)pO(f ) = F ; the ATM tape alphabet ( c ) definition of HEAD feature set HEAD = i : 0_ < ; -< M+lurj . : 1_<j_<S ( l~l )   ( d ) FCRs to ensure full specification of all categories except null ones  . 
Vf . feAtom ,\[ STATE\]D\[f\]2 . Grammatical rules Vi , j , q , a , b : 1</< lwl , 1 < J-<S(I~I) , qcQ , ae Z , bet if TransM(q , a , b ) #@ , construct he following ID rules . 
( a ) if q ? U ( universal state)\[HEADOi\] , \[ ia \] , \[ HEAD1j\] , Jr ; b \] , \[ STATEq\] , \[AI\]--*ResultOM(i , a , dlk ) U Result1M(j , ck , Pk , d2k ) : ( Pk , ck , dlk , d2k)eTransM(q , a , b )   ( s ) where all categories on the RHS are heads . 
( b ) otherwise q ? Q-U ( existential state ) V ( pk , ck , dlk , d2~)E TransM(q , a , b ) , \[ HEADOi\] , \[ ia \] , \[ HEAD1j\] , \[ rjb\] , \[ STATEq\] , \[AI\]---+ResultOM ( , a , dlk ) U Result1M(\] , ck , pk , d2k )   ( 9 ) where all categories on the RHS are heads . 
( c ) One ID rule to terminate accepting states , using null-transitions . 
\[ STATE h\] , \[1Y\]--*~ ( 10 )   ( d ) Two ID rules to read input strings and begin the ATM simulation  . The A feature is used to separate functionally distinct components of the grammar  . \[ A 1\] categories participate in the direct ATM simulation  , \[ A 2\] categories are involved in reading the input string  , and the\[A 3\] category connects the read input string with the ATM simulation start state  . 
START---*\[A1\] , \[A21(11)\[a2\]--~\[A2\] , \[ A2\] where all daughters are head daughters , and where START:\[HEAD01\] , \[ HEAD1I\] , \[ STATEs\] , \[ A3\]u\[rj#1:1_<j_<s ( M )   ( e ) the lexical rules , 
V a , iacE , l < i < l w l ,  < ~; , \[ A2\] , \[; ~\] > (12) vio_<i < lwl+1 , <$ i , \[ A2\] , \[ i$\]> The reduction plainly may be performed in polynomial time in the size of the simulated ATM  , by inspection . 
Nometa rules or LP statements are needed , although recta-rules could have been used instead of the Head Feature Convention  . Both devices are capable of transferring the contents of the ATM tape from the mother to the daughter  ( s )  . One metarule would be needed for each tapes quare /tape symbol combination in the ATM  . 
GKPS Definition 5 . 1 4 of Admissibility guarantees that admissible trees must be terminated  , nBy the construction above--see especially the ID rule  10 -- an\[A 1\] node can be terminated only if it is an accepting configuration  ( i . e . it has halted and printed Y on its first square ) . This means the only admissible trees are accepting ones whose yield is the input string followed by a very long empty string  . P . C . P ** The admissibility of nonlocal trees is defined as follows  ( GKPS , p . 104):
Definition : Admissibility
Let R be a set of ID rules . Then a treet is admissible from R if and only if  1  . tisterminated , and 2 . every local subtree in . t is either terminated or locally admissible from somer  6 R . 
36 3 . 3 Sources o f In t rac tab i l i ty The two sources Of intractability in GPSG theory spotlighted by this reduction are null -transitions in ID rules  ( see the ID rule 10 above )  , and universal feature instantiation ( in this case , the Head Feature Convention ) . 
Grammars with unrestricted null-transitions can assign elaborate phrase structure to the empty string  , which is linguistically undesirable and computationally costly  . The reduction must construct a GPSGG and input string x in polynomial time such that xEL  ( G ) iff wEL ( M )  , where M is a PSPACE-bounded ATM within put w . The ' polynomial time ' constraint prevents us from making either x or G too big  . Null-transitions allow the grammar to simulate the PSPACE ATM computation  ( and an Exp-PolyTM computation indirectly ) with an enormously long derivation string and thene rase the string  . If the GPSGG were unable to erase the derivation string  , G would only accept strings which were exponentially larger than M and w  , i . e . too big to write down in polynomial time . 
The Head Feature Condition transfers HEAD feature values from the mother to the head daughters just in case they don't conflict  . In the reduction we use HEAD ' features to encode the ATM tape  , and thereby use the HFC to transfer the tape contents from one " ATM configuration C  ( represented by them other ) to its immediate successors Co ,  . . . , Cn(the head daughters . The configurations C,C0, .   .   .   , Ca have identical tapes , with the critical exception of one tapes quare . If the HFC enforced absolute agreement between the HEAD features of the mother and head daughters  , we would be unable to simulate the PSPACE ATM computation in this manner  . 
4 Interpreting the Result 4 . 1 Generat ive Power and Computat iona l Com-p lex i ty At first glance  , a proof that GPSG-Recognition is Exp-Poly hard appears to contradic the fact that contextfree languages can be recognized in O  ( ns ) time by a wide range of algorithms . To see why there is no contradiction , we must first explicitly state the argument from weak contextfree generative power  , which we dub the efficient parsability ( EP ) argument . 
The EP argument states that any GPSG can be converted into a weakly equivalent contextfree grammar  ( CFG )  , and that CFG-Recognition is polynomial time ; therefore , GPSG-Recognition must also be polynomial time . The EP argument continues : if the conversion is fast  , then GPSG-Recognition is fast , but even if the conversion is slow , recognition using the " compiled " CFG will still be fast  , and we may justifiably lose interest in recognition using the original  , slow , GPSG . 
The EP argument is misleading because it ignores both the effect conversion has on grammar size  , and the effect grammar size has on recognition speed  . Crucially , grammar size affects recognition time in all known algorithms  , and the only grammars directly usable by contextfree parsers  , i . e . with the same complexity as a CFG , are those composed of contextfree productions with atomic nonterminal symbols  . For GPSG , this is the set of admissible local trees , and this set is astronomical : o((3m ~' , '+') ( Iz ) in a GPSG G of size m . \] ~ Context-free parsers like the Earley algorithm run in time O  ( IG'j2 . n3 ) where IG'I is the size of the CFG G ' and n the input string length  , so a GP SGG of size m will be recognized in time
O(3=. m!m=~+'.~3) (14)
The hyper-exponential term will dominate the Earley algo-rithm complexity in the reduction above because m is a function of the size of the ATM we are simulating  . Even if the GPSG is held constant , the stunning derived grammar size in formula 13 turns up as an equally stunning ' constant ' multiplicative factor in  14  , which in turn will dominate the real world performance of the Earley algorithm for all expected inputs  ( i . e . any that can be written down in the universe ) , every time we use the derived grammar . iSPullum ( 1985 ) has suggested that " examination of a suitable ' typical ' GPSG description reveals a ratio of only  4 to I between expanded and unexpanded grammar statements  , " strongly implying that GPSG is efficiently processable as a consequence  .   14 But this " expanded grammar " is not adequately expanded  , i . e . 
it is not composed of contextfree productions with  unanalyz-12As we saw above , the metarule finite closure operation can increase the ID rule grammar size from IRI = O  ( IGI ) to O ( m2~ ) in a GPSG G of size m . We ignore the effects of ID/LP format on the number of admissible local trees here  , and note that if we expanded out all admissible linear precedence possibilities in FC  ( M , R , the resultant ' ordered ' ID rule grammar would be of size O  ( rn2'~7 )  . In the worst case , every symbol in FC(M , R ) is underspecified , and every category in K extends every symbol in the FC  ( M , R grammar . Since there are o(s-- , ') possible syntactic categories , and O(mTM ) symbols in FU(M , R ) , the number of admissible local trees ( = atomic contextfree productions in Giso ( (3~ . ~,), , , , ') = o(s ~ , , , , , ~*') i . e . astronomical . Ristad ( 1986 ) argues that the minimal set of admissible local trees in GKPS'GPSG for English is considerably smaller  , yet still contains more than 10z ? local trees . 
la The compiled grammar recognition problem is at least as intractable as the uncompiled one  . Even worse , Barton 1985 ) shows how the grammar expansion increases both the space and time costs of recognltlon  , when compared to the cost of using the grammar directly  . 
1 4Thls ubstantive argument is somewhats range coming from a coauthor of a book which advocates the purely formal investigation of linguistics : " The universalism \[ of natural anguage  1 is , ultimately , intended to been tirely embodied in the formal system  , not expressed by statements made in it . 'GKPS(4) . It is difficult to respond precisely to the claims made in Pul-Ium  ( 1985 )  , since the abstract is ( necessarily ) brief and consists of assertions unsupported by factual documentation or clarifying assumptions  . 
37 able nonterminal symbols .   15 These informal tractability arguments are a particular instance of the more general EP argument and are equally misleading  . 
The preceding discussion of how intractability arises when converting a GPSG into a weakly equivalent CFG does not in principle preclude the existence of an efficient compilation step  . 
If the compiled grammar is truly fast and assigns the same structural descriptions as the uncompiled GPSG  , and it is possible to compile the GPSG in practice  , then the complexity of the universal recognition problem would not accurately reflect the real cost of parsing  . 16 But until such a suggestion is forthcoming , we must assume that it does not exist .  1~ , 1 siS , Expanded grammar " appears to refer to the output of metarule finite closure  ( i . e . ID rules ) , and this expanded grammar is tra , = table only if the grammar is directly usable by the Earley algorithm exactly as contextfree productions are : all no a terminals in the contextfree productions must be unanalyzable  . But the categories and ID rules of the metarule finite closure grammar do not have this property  . Nonterminals in GPSG are decomposable into a complex set of feature specifications and cannot be made atomic j in part because not all extensions of ID rule categories a relegal  . For example , the categories - OO01Vl~\[-tCF1g ~PA$\] and VP\[+INV , VFOI~FIN\]are not legal extensions of VP in English  , while VP\[?INV , + AUX . 
VFORI~FINI is . FCRs , FSDs , LP statements , and principles of universal feature instantiation -- all of which contribute to GPSG's intractability -- must all still apply to the rules of this expanded grammar  . 
Even if we ignore the significant computational complexity introduced by the machinerymentioned in the previous paragraph  ( i . e . theory of syntactic features , FCRs , FSDs , ID/LP format , null-transitions , and metarules ) , GPSG will still not obtain an e . fficient parsability result . This is because the Head Feature Convention alone ensures that the universal recognition problem for GPSGs will be NP-hard and likely to be intractable  . Ristad (1986) contains a proof . This result should not be surprising , given that ( 1 ) principles of universal feature instant\]ation in current GPSG theory replace the metarules of earlier versions of GPSG theory  , and ( 2 ) metarules are known to cause intractability in GPSG  . 
~ 6The xistence or nonexistence of efficient compilation functions does not affect either our scientific interest in the universal grammar recognition problem or the power and relevance of a complexity analysis  . If complexity theory classifies a problem as intractable  , we learn that something more must be said to obtain tractability  , and that any efficient compilation step , if it exists at all , must itself be costly . 
1 7Note that the GPSG we constructed in the preceding reduction will actually accept any input x of length less than or equal to I wl if and only if the ATMM accepts it using S  ( \] wl ) space . We prepare an input string $ for the GPSG by converting it to the string  $0xl   lx22  . ., xn nSr~-1 e . g . 
shades is accepted by the ATM if and only if the string $  Oalb2a3d4e5e657 is accepted by the GPSG . Trivial changes in the grammar allows us to permute and " spread " the characters of ? across an infinite class of strings in an unbounded number of ways  , e . g . $ O'~x~i ' ~2 .   .   . ~ zll'y b .   .   . ? ~$ a?l where each ~ is a string over an alphabet which is distinct from the ~ i alphabet  . Although the flexibility of this construction results in a more complicated GPSG  , it argues powerfully agains the existence of any efficient compilation procedure for GPSGs  . Any efficient compilation procedure must perform more than an exponential polynomial amount of work  ( GPSG-Recognition takes at least Exp-Polytime ) on at least an exponential number of inputs ( all inputs that fit in the twt space of the ATM 's read-only tape  )  . More importantly , the required compilation procedure will convert say exponential-polynomialt me bounded Turing Machine into a polynomial * time TM for the class inputs whose membership can be determined within a arbitrary  ( fixed ) exp-polytime bound . Simply listing the accepted inputs will not work because both the GPSG and TM may accept an in finite class of inputs  . Such a compilation procedure would be extremely powerful  . 
lSNote that compilation illegitimately assumes that the compilation step  4  . 2 Complex i ty and Succ inc tness The major complexity result of this paper proves that the fastest algorithm for GPSG-Recognition must take more than exponential time  . The immediately preceding section demonstrates x -actly how a particular algorithm for GPSG -Recognition  ( the EP argument ) comes to grief : weak contextfree generative power does noten surefficient parsability because a GPSG G is weakly equivalent to a very large CFG G ~  , and CFG size affects recognition time . The rebuttal does not suggest hat computational complexity arises from representational succinctness  , either here or in general . 
Complexity results characterize the amount of resources needed to solve instances of a problem  , while succinctness results measure the space reduction gained by one representation ver another  , equivalent , representation . 
There is no casual connection between computational complexity and representational succinctness  , either in practice or principle . In practice , converting one grammar into a more succinct one can either increase or decrease the recognition cost  . 
For example , converting an instance of contextfree recognition  ( known to be polynomial time ) into an instance of context-sensitive recognition  ( known to be PSPACE-complete and likely to be intractable  ) can significantly speed the recognition problem if the conversion decreases the size of the CFG logarithmically or better  . Even more strangely , increasing ambiguity in a CFG can speed recognition time if the succinctness gain is large enough  , or slow it down otherwise--unambiguous CFGs can be recognized in linear time  , while ambiguous ones require cubic time . 
In principle , tractable problems may involv ~ succinct representations  . For example , the iterating coordination schema ( ICS ) of GPSG is an unbeatably succinct encoding of an in finite set of contextfree rules  ; from a computational complexity viewpoint , the ICS is utterly trivial using a slightly modified Earley algorithm  .   19 Tractable problems may also be verbosely represented : consider a random finite language  , which may be recognized in essentially constant ime on a typical computer  ( using a hash table )  , yet whose elements must be individually listed . Similarly , intractable problems may be represented both succinctly and nonsuccinctly  . As is well known , the Turing machine for any arbitrary r . e . set may be either extremely small or monstrously big  . Winning the game of chess when played on an nxn board is likely to be computation Mly intractable  , yet the chessboard is not intended to be an encoding of another representation  , succinct or otherwise . 
is free . There is one theory of primitive language l arning and use : conjecture a grammar and use it  . For this procedure to work , grammars should be easy to test on small inputs . The overall complexity of learning , testing , and speech must be considered . Compilation speeds up the speech component at the expense of greater complexity in the other two components  . 
For this linguistic reason the compilation argument is suspect  . 
X ~ A more extrem example of the unrelatedness of succinctness and complexity is the absolute succinctness with which the dense language ~" may be represented--whether by a regular expression  , CFG , or even Taring machine--yet members of E?may be recognized in constant time  ( i . e . 
always accept).

Tractable problems may involve succinctor nonsuccinct representations  , as may intractable problems . The reductions in this paper show that GPSGs are not merely succinct encodings of some contextfree grammars  ; they are inherently complex grammars for some contextfree languages  . The heart of the matter is that GPSG's formal devices are computationally complex and can encode provably intractable problems  . 
4.3 Relevance of the Result
In this paper , we argued that there is nothing in the GPSG formal framework that guarantees computational tractability : proponents of GPSG must look elsewhere for an explanation of efficient parsability  , if one is to be given at all . The crux of the matter is that the complex components of GPSG theory interact in intractable ways  , and that weak contextfree generative power does not guarantee tractability when grammar size is taken into account  . A faithful implementation f the GPSG formalisms of GKPS will provably be intractable  ; expectations computational linguistics might have held in this regard are not fulfilled by current GPSG theory  . 
This formal property of GPSGs is straightforwardly interesting to GPSG linguists  . As outlined by GKPS , " an important goal of the GPSG approach to linguistics\[is ! the construction of theories of the structure of sentences under which significant properties of grammars and languages f all out as theorems as opposed to being stipulated as axioms  ( p . 4) . " The role of a computation alnalysis of the sort provided here is fundamentally positive : it can offer significant formal insights into linguistic theory and human language  , and suggest improvements in linguistic theory and realworld parsers  . 
The insights gained may be used to revise the linguistic theory so that it is both stronger linguistically and weaker formally  . 
Work on revising GPSG is in progress . Briefly , some proposed change suggested by the preceding reductions are : unit feature closure  , no FCRs or FSDs , no null-transitions in ID rules , metarule unit closure , and no problematic feature specifications in the principles of universal feature instantiation  . Not only do these restrictions alleviate most of GPSG's computational intractability  , but they increase the theory's linguistic constraint and reduce the number of nonnatural language grammars licensed by the theory  . Unfortunately , there is insufficient space to discuss these proposed revisions here--the reader is referred to Ristad  ( 1986 ) for a complete discussion . 
Acknowledgments . Robert Berwick , Jim Higginbotham , and Richard Larson greatly assisted the author in writing this paper  . 
The author is also indebted to Sandiway Fong and David Waltz for their help  , and to the MIT Artificial Intelligence Lab and Thinking Machines Corporation for supporting this research  . 
Barton , G . E .  (1985) . " On the Complexity of ID/LP Parsing , " Computational Linguistics ,  11(4): 205-218 . 
Chandra , A . and L . Stockmeyer (1976) . " Alternation , "  17 th Annual Symposium on Foundations of Computer Science  , : 98-108 . 
Gazdar , G .  (1981) . " Unbounded Dependencies and Coordinate Structure  , " Linguistic Inquiry 12:155-184 . 
Gazdar , G . , E . Klein , G . Pullum , and I . Sag (1985) . Generalized Phrase Structure Grammar . Oxford , England : Basil

Garey , M , and D . Johnson (1979) . Computers and Intractabil-ity . San Francisco : W . H . Freeman and Co . 
Hopcroft , J . E . , and J . D . Ullman (1979) . Introduction to Automata Theory , Languages , and Computation . Reading,
MA : Addison-Wesley.
Pullum , G . K .  (1985) . " The Computational Tractability of GPSG , " Abstracts of the 60th Annual Meeting of the Linguistics Society of America  , Seattle , WA:36 . 
Ristad , E . S .  (1985) . "GPSG-Recognition is NP-hard , " A . I . 
Memo No . 837, Cambridge , MA : M . I . T . Artificial Intelligence Laboratory . 
Ristad , E . S .  (1986) . " Complexity of Linguistic Models : A Computational Analysis and Reconstruction of Generalized Phrase Structure Grammar  , " S . M . Thesis , MIT Department of Electrical Engineering and Computer Science  . ( In progress ) . 
5 References
