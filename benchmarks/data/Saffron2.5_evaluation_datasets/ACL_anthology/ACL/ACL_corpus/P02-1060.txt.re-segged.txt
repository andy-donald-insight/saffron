Named Entity Recognition using an HMM-based Chunk Tagger 

GuoDong Zhou Jian Su
Laboratories for Information Technology
21 Heng Mui Keng Terrace
Singapore 119613
zhougd@lit.org.sgsujian@lit.org.sg


This paper proposes a Hidden Markov
Model ( HMM ) and an HMM-based chunk tagger , from which a named entity ( NE ) recognition ( NER ) system is built to recognize and classify names , times and numerical quantities . Through the HMM , our system is able to apply and integrate four types of internal and external evidences :  1  ) simple deterministic internal feature of the words  , such as capitalization and digitalization ;  2 ) internal semantic feature of important triggers ; 3) internal gazetteer feature ; 4) external macro context feature . In this way , the NER problem can be resolved effectively . Evaluation of our system on MUC6 and MUC7 English NE tasks achieves Fmeasures of 96  . 6% and 94 . 1% respectively . It shows that the performance is significantly better than reported by any other machine learning system  . Moreover , the performance is even consistently better than those based on handcrafted rules  . 
1 Introduction
Named Entity ( NE ) Recognition ( NER ) is to classify every word in a document into some predefined categories and " none-of-the-above "  . In the taxonomy of computational linguistics tasks  , it falls under the domain of " information extraction "  , which extracts specific kinds of information from documents as opposed to the more general task of " document management " which seeks to extract all of the information found in a document  . 
Since entity names form the main content of a document  , NER is a very important step toward more intelligent information extraction and management  . The atomic elements of information extraction -- indeed  , of language as a whole--could be considered as the " who "  , " where " and " how much " in a sentence . NER performs what is known as surface parsing , delimiting sequences of tokens that answer these important questions  . NER can also be used as the first step in a chain of processors : a next level of processing could relate two or more NEs  , or perhaps even give semantics to that relationship using a verb  . In this way , further processing could discover the " what " and " how " of a sentence or body of text  . 
While NER is relatively simple and it is fairly easy to build a system with reasonable performance  , there are still a large number of ambiguous cases that make it difficult to attain human performance  . 
There has been a considerable amount of work on NER problem  , which aims to address many of these ambiguity , robustness and portability issues . During last decade , NER has drawn more and more attention from the NE tasks [  Chinchor95a  ] [  Chinchor98a ] in MUCs [ MUC6]  [  MUC7]  , where person names , location names , organization names , dates , times , percentages and money amounts are to be delimited in text using SGML markups  . 
Previous approaches have typically used manually constructed finite state patterns  , which attempt to match against a sequence of words in much the same way as a general regular expression matcher  . Typical systems are Univ . of Sheffield's LaSIE-II [ Humphreys+98] , ISOQuest's NetOwl [ Aone+98]  [  Krupha+98] and Univ . of Edinburgh's LTG [ Mikheev+98]  [  Mikheev+99] for English NER . These systems are mainly rule-based . 
However , rule-based approaches lack the ability of coping with the problems of robustness and portability  . Each new source of text requires significant tweaking of rules to maintain optimal performance and the maintenance costs could be quite steep  . 
The current trend in NER is to use the machine learning approach  , which is more Computational Linguistics ( ACL ) , Philadelphia , July 2002 , pp .  473-480 . 
Proceedings of the 40th Annual Meeting of the Association for attractive in that it is trainable and adaptable and the maintenance of a machine learning system is much cheaper than that of a rule-based one  . The representative machine learning approaches used in NER are HMM  ( BBN's IdentiFinder in [ Miller+98]  [  Bikel+99] and KRDL's system [ Yu+98] for Chinese NER . ), Maximum Entropy ( New York Univ . 's MEME in [ Borthwick+98] [ Borthwich99] ) and Decision Tree ( New York Univ . 's system in [ Sekine98] and SRA's system in [ Bennett+97]  )  . 
Besides , a variant of Eric Brill's transformation based rules [  Brill95] has been applied to the problem [ Aberdeen+95]  . Among these approaches , the evaluation performance of HMM is higher than those of others  . The main reason may be due to its better ability of capturing the locality of phenomena  , which indicates names in text . Moreover , HMM seems more and more used in NE recognition because of the efficiency of the Viterbi algorithm [  Viterbi67] used in decoding the NE-class state sequence . However , the performance of a machine learning system is always poorer than that of a rule-based one by about  2%  [  Chinchor95b  ] [  Chinchor98b  ] . This may be because current machine learning approaches capture important evidence behind NER problem much less effectively than human experts who handcraft the rules  , although machine learning approaches always provide important statistical information that is not available to human experts  . 
As defined in [ McDonald96] , there are two kinds of evidences that can be used in NER to solve the ambiguity  , robustness and portability problems described above  . The first is the internal evidence found within the word and/or word string itself while the second is the external evidence gathered from its context  . In order to effectively apply and integrate internal and external evidences  , we present a NER system using a HMM . The approach behind our NER system is based on the HMM-based chunk tagger in text chunking  , which was ranked the best individual system [ Zhou+00a  ] [  Zhou+00b ] in CoNLL'2000  [  Tjong+00]  . Here , a NE is regarded as a chunk , named " NE-Chunk " . To date , our system has been successfully trained and applied in English NER  . To our knowledge , our system outperforms any published machine learning systems  . Moreover , our system even outperforms any published rule -based systems  . 
The layout of this paper is as follows . Section 2 gives a description of the HMM and its application in NER : HMM-based chunk tagger  . Section 3 explains the word feature used to capture both the internal and external evidences  . Section 4 describes the backoff schemes used to tackle the sparseness problem  . Section 5 gives the experimental results of our system . Section 6 contains our remarks and possible extensions of the proposed work  . 
2 HMM-based Chunk Tagger 2.1 HMM Modeling
Given a token sequence nngggGL 211 = , the goal of NER is to find a stochastic optimal tag sequence n n t t t T  L211 = that maximizes ( 21 )   ) ( ) (  )  , ( log ) ( log ) ( log 111n nn nn nn nn


TPGTP ? +=
The second item in ( 21 ) is the mutual information between nT1 and nG1 . In order to simplify the computation of this item  , we assume mutual information independence : ? = = nininnGtMIGTMI ?= ?=? ninininnn 



GTP 11),(log )()(), ( log(23)
Applying it to equation (2 . 1), we have : ?? = = + ? = ninini in nn
GtPtPTP GTP ) ( log ) ( log ) (log ) (log ( 24 ) The basic premise of this model is to consider the raw text  , encountered when decoding , as though it had passed through a noisy channel , where it had been originally marked with NE tags . The job of our generative model is to directly generate the original NE tags from the output words of the noisy channel  . 
It is obvious that our generative model is reverse to the generative model of traditional  HMM1  , as used 1In traditional HMM to maximise ) ( log 11 nn GTP , first we apply Bayes ' rule : )() , ( ) (11 n n n n n


GTP = and have : in BBN's IdentiFinder , which models the original process that generates the NE-class annotated words from the original NE tags  . Another difference is that our model assumes mutual information independence  ( 22 ) while traditional
HMM assumes conditional probability independence ( I 1 )  . Assumption ( 22 ) is much looser than assumption ( I 1 ) because assumption ( I 1 ) has the same effect with the sum of assumptions ( 22 ) and ( I-3 ) 2 . In this way , our model can apply more context information to determine the tag of current token  . 
From equation (24) , we can see that : 1 ) The first item can be computed by applying chain rules  . In ngram modeling , each tag is assumed to be probabilistically dependent on the 
N1 previous tags.
2 ) The second item is the summation of log probabilities of all the individual tags  . 
3 ) The third item corresponds to the " lexical " component of the tagger  . 
We will not discuss both the first and second items further in this paper  . This paper will focus on the third item ? = n in iG tP difference between our tagger and other traditional HMM-based taggers  , as used in BBN's IdentiFinder . 
Ideally , it can be estimated by using the forwardbackward algorithm [  Rabiner89] recursively for the 1st-order  [  Rabiner89] or 2nd -order HMMs [ Watson+92]  . However , an alternative backoff modeling approach is applied instead in this paper  ( more details in section 4 )  . 
2 . 2 HMM-based Chunk Tagger ) ) ( log ) ( ( logmax arg ) ( logmaxarg nnn
Tnn


GTP +=
Then we assume conditional probability independence : ?= = n ii in ntgPTGP and have :   ) ) ( log ) (log ( maxarg ) ( logmaxarg i ii
Tnn


GTP += ?= ( I 2 ) 2 We can obtain equation ( I 2 ) from ( 2 . 4) by assuming )( log ) ( log 1 iinitgPGtP = ( I3)
For NE-chunk tagging , we have token >= < iii wfg ,   , where n n w w w W L211 = is the word sequence and nnfffF L211 = is the word-feature sequence . In the meantime , NE-chunk tag it is structural and consists of three parts :  1  ) Boundary Category : BC = 0 ,  1 ,  2 ,  3 . Here 0 means that current word is a whole entity and 1/2/3 means that current word is at the beginning/in the middle/at the end of an entity  . 
2) Entity Category : EC . This is used to denote the class of the entity name  . 
3) Word Feature : WF . Because of the limited number of boundary and entity categories  , the word feature is added into the structural tag to represent more accurate models  . 
Obviously , there exist some constraints between 1?it and it on the boundary and entity categories , as shown in Table 1 , where " valid "/" invalid " means the tag sequence i it t  1? is valid/invalid while " valid on " means ii tt  1? is valid with an additional condition ii ECEC =?1   . Such constraints have been used in Viterbi decoding algorithm to ensure valid 
NE chunking.
0  1   2   3   0 Valid Valid Invalid Invalid 1 Invalid Invalid Valid on Valid on 2 Invalid Invalid Valid Valid 3 Valid Valid Invalid Invalid Table 1: Constraints between 1?it and it ( Column : 1 ? iBC in 1 ? it ; Row : iBC in it ) 3 Determining Word Feature As stated above , token is denoted as ordered pairs of word-feature and word itself :>= < iii wfg  ,   . 
Here , the word-feature is a simple deterministic computation performed on the word and/or word string with appropriate consideration of context as looked up in the lexicon or added to the context  . 
In our model , each word-feature consists of several subfeatures  , which can be classified into internal subfeatures and external subfeatures  . The internal subfeatures are found within the word and/or word string itself to capture internal evidence while external subfeatures are derived within the context to capture external evidence  . 
3.1 Internal Sub-Features
Our model captures three types of internal subfeatures :  1  )   1f : simple deterministic internal feature of the words  , such as capitalization and digitalization ;  2 )   2f : internal semantic feature of important triggers  ; 3) 3 f : internal gazetteer feature . 
1 )   1f is the basic subfeature exploited in this model , as shown in Table 2 with the descending order of priority . For example , in the case of non-disjoint feature classes such as 
Contains Digit And Alpha and
Contains Digit And Dash , the former will take precedence . The first eleven features arise from the need to distinguish and annotate monetary amounts  , percentages , times and dates . The rest of the features distinguish types of capitalization and all other words such as punctuation marks  . 
In particular , the First Word feature arises from the fact that if a word is capitalized and is the first word of the sentence  , we have no good information as to why it is capitalized  ( but note that All Caps and CapPeriod are computed before First Word  , and take precedence . ) This subfeature is language dependent . Fortunately , the feature computation is an extremely small part of the implementation  . This kind of internal subfeature has been widely used in machine learning systems  , such as BBN's IdendiFinder and New York Univ . 's MENE . The rationale behind this subfeature is clear : a  ) capitalization gives good evidence of NEs in Roman languages  ; b ) Numeric symbols can automatically be grouped into categories  . 
2 )   2f is the semantic classification of important triggers  , as seen in Table 3 , and is unique to our system . It is based on the intuitions that important triggers are useful for NER and can be classified according to their semantics  . This subfeature applies to both single word and multiple words  . This set of triggers is collected semiautomatically from the NEs and their local context of the training data  . 
3) Sub-feature 3f , as shown in Table 4 , is the internal gazetteer feature , gathered from the lookup gazetteers : lists of names of persons  , organizations , locations and other kinds of named entities . This subfeature can be determined by finding a match in the gazetteer of the corresponding NE type where n  ( in Table 4 ) represents the word number in the matched word string  . Instead of collecting gazetteer lists from training data  , we collect a list of 20 public holidays in several countries , a list of 5 , 000 locations from websites such as GeoHive 3 , a list of 10 , 0 00 organization names from websites such as Yahoo4 and a list of 10  , 0 00 famous people from websites such as Scope Systems5  . Gazetters have been widely used in NER systems to improve performance  . 
3.2 External Sub-Features
For external evidence , only one external macro context feature 4 f , as shown in Table 5 , is captured in our model .   4f is about whether and how the encountered NE candidate is occurred in the list of NEs already recognized from the document  , as shown in Table 5 ( n is the word number in the matched NE from the recognized NE list and m is the matched word number between the word string and the matched NE with the corresponding NE type  . ) . This subfeature is unique to our system . The intuition behind this is the phenomena of name alias  . 
During decoding , the NEs already recognized from the document are stored in a list  . When the system encounters a NE candidate , a name alias algorithm is invoked to dynamically determine its relationship with the NEs in the recognized list  . 
Initially , we also consider part-of-speech ( POS ) subfeature . However , the experimental result is disappointing that incorporation of POS even decreases the performance by  2%  . This may be because capitalization information of a word is submerged in the muddy of several POS tags and the performance of POS tagging is not satisfactory  , especially for unknown capitalized words ( since many of NEs include unknown capitalized words  . ) . 
Therefore , POS is discarded.
3 http://www . geohive . com / 4http://www . yahoo . com / 5http://www . scopesys . com/Sub-Feature1 f Example Explanation/Intuition
One Digit Num 9 Digital Number
Two Digit Num 90 Two-Digit year
Four Digit Num 1990 Four-Digit year
Year Decade 1990s Year Decade
Contains Digit And Alpha A 8956-67 Product Code
Contains Digit And Dash 09-99 Date
Contains Digit And One Slash 3/4 Fraction or Date Contains Digit And Two Slashs 19/9/1999 DATE
Contains Digit And Comma 19, 000 Money
Contains Digit And Period 1 . 00 Money , Percentage Other Contains Digit 123 124 Other Number
All Caps IBM Organization
Cap Period M . Person Name Initial
Cap Other Period St . Abbreviation
Cap Periods N.Y . Abbreviation
First Word First word of sentence No useful capitalization information 
Initial Cap Microsoft Capitalized Word
Lower Case Will Un-capitalized Word
Other $ All other words
Table 2: Sub-Feature 1f : the Simple Deterministic Internal Feature of the Words NE Type  ( No of Triggers ) Sub-Feature 2f Example Explanation/Intuition PERCENT ( 5 ) Suffix PERCENT % Percentage Suffix Prefix MONEY $ Money Prefix MONEY  ( 298 ) 
Suffix MONEY Dollars Money Suffix
Suffix DATE Day Date Suffix
Week DATE Monday Week Date
Month DATE July Month Date
Season DATE Summer Season Date
Period DATE1 Month Period Date
Period DATE2 Quarter Quarter/Half of Year
End DATE Weekend Date End
DATE (52)
Modifier DATE Fiscal Modifier of Date
Suffix TIME a.m . Time Suffix TIME (15)
Period Time Morning Time Period
Prefix PERSON 1Mr . Person Title
Prefix PERSON2 President Person Designation
PERSON (179)
First Name PERSON Micheal Person First Name LOC ( 36 ) Suffix LOC River Location Suffix ORG ( 177 ) Suffix ORG Ltd Organization Suffix Others ( 148 ) Cardinal , Ordinal , etc . Six , , Sixth Cardinal and Ordinal Numbers Table 3: Sub-Feature 2f : the Semantic Classification of Important Triggers NE Type  ( Size of Gazetteer ) Sub-Feature 3 f Example DATE ( 20 ) DATEnGn Christmas Day : DATE2G2PERSON ( 10 , 000) PERSON nGn Bill Gates : PERSON 2G 2
LOC (5,000) LOC nGn Beijing : LOC 1G1
ORG (10 , 000 ) ORG nGn United Nation: ORG2G2 Table 4: Sub-Feature 3f : the Internal Gazetteer Feature ( Gmeans Global gazetteer ) 
NE Type Sub-Feature Example
PERSON PERSON nLm Gates : PERSON 2L1 ( " Bill Gates " already recognized as a person name  ) LOCLOCnLmN . J . : LOC 2L2 ( " New Jersey " already recognized as a location name  ) ORGORG nLmUN : ORG2L2 ( " United Nation " already recognized as a org name  ) Table 5: Sub-feature 4f : the External Macro Context Feature ( Lmeans Local document )   4 Backoff Modeling Given the model in section 2 and word feature in section 3  , the main problem is how to compute ? = nini GtP sufficient training data for every event whose conditional probability we wish to calculate  . 
Unfortunately , there is rarely enough training data to compute accurate probabilities when decoding on new data  , especially considering the complex word feature described above  . In order to resolve the sparseness problem , two levels of backoff modeling are applied to approximate  ) / ( 1 niGtP : 1 ) First level backoff scheme is based on different contexts of word features and words themselves  , and nG1 in ) / (   1 niGtP is approximated in the descending order of i i i i w f f f  12  ??  , 21 ++ i i i iff wf , i i i w f f 1? , 1 + i i if w f , i i if wf 11? ? , 11 ++ ii iwff , i i if ff 12 ? ? , 21++ ii ifff , i i w f , i i if ff 12 ? ? , 1 + i iff and if . 
2 ) The second level backoff scheme is based on different combinations of the four subfeatures described in section  3  , and kf is approximated in the descending order of  4321 k k k kffff , 5 Experimental Results In this section , we will report the experimental results of our system for English NER on  MUC6 and MUC7 NE shared tasks , as shown in Table 6 , and then for the impact of training data size on performance using  MUC7 training data . For each experiment , we have the MUC dry run data as the held out development data and the MUC formal test data as the heldout test data  . 
For both MUC6 and MUC7 NE tasks , Table 7 shows the performance of our system using MUC evaluation while Figure  1 gives the comparisons of our system with others . Here , the precision ( P ) measures the number of correct NEs in the answer file over the total number of NEs in the answer file and the recall  ( R ) measures the number of correct NEs in the answer file over the total number of NEs in the key file while Fmeasure is the weighted harmonic mean of precision and recall : 

RPF++=22)1 ( ? ? with 2? = 1 . It shows that the performance is significantly better than reported by any other machine learning system  . Moreover , the performance is consistently better than those based on handcrafted rules  . 
Statistics ( KB )


Dry Run

Formal Test

MUC 613 3012 1124
MUC 7708 156 561
Table 6: Statistics of Data from MUC6 and MUC7 NET asks FPR
MUC6 96.6 96.3 96.9
MUC7 94.1 93.7 94.5
Table 7: Performance of our System on MUC6 and MUC7 NET asks
Composition FP R1 ff = 77 . 6 81 . 0 74 . 121 fff = 87 . 4 88 . 6 86 . 1321 ffff = 89 . 3 90 . 5 88 . 2421 ffff = 92 . 9 92 . 6 93 . 14321 ffffff=94 . 1 93 . 7 94 . 5 Table 8: Impact of Different Sub-Features With any learning technique  , one important question is how much training data is required to achieve acceptable performance  . More generally how does the performance vary as the training data size changes ? The result is shown in Figure  2 for MUC7 NE task . It shows that 200KB of training data would have given the performance of  90% while reducing to 100KB would have had a significant decrease in the performance  . It also shows that our system still has some room for performance improvement  . This may be because of the complex word feature and the corresponding sparseness problem existing in our system  . 
Figure 1: Comparison of our system with others on MUC6 and MUC7 NE tasks
Precision Our MUC6 System
Our MUC7 System
Other MUC6 Systems
Other MUC7 Syetems
Figure 2: Impact of Various Training Data on Performance
Training Data Size ( KB )
Fmeasure

Another important question is about the effect of different subfeatures  . Table 8 answers the question on MUC7NE task : 1 ) Applying only 1f gives our system the performance of 77  . 6% . 
2 )   2f is very useful for NER and increases the performance further by  10% to 87  . 4% . 
3) 4f is impressive too with another 5 . 5% performance improvement . 
4) However , 3f contributes only further 1 . 2% to the performance . This may be because information included in 3f has already been captured by 2f and 4f   . Actually , the experiments show that the contribution of 3f comes from where there is no explicit indicator information in/around the NE and there is no reference to other NEs in the macro context of the document  . The NEs contributed by 3f are always wellknow nones , e . g . Microsoft , IBM and Bach ( a composer) , which are introduced in texts without much helpful context  . 
6 Conclusion
This paper proposes a HMM in that a new generative model  , based on the mutual information independence assumption  ( 23 ) instead of the conditional probability independence assumption  ( I 1 ) after Bayes ' rule , is applied . Moreover , it shows that the HMM-based chunk tagger can effectively apply and integrate four different kinds of subfeatures  , ranging from internal word information to semantic information to NE gazetteers to macro context of the document  , to capture internal and external evidences for NER problem  . It also shows that our NER system can reach " near human performance "  . To our knowledge , our NER system outperforms any published machine learning system and any published rule -based system  . 
While the experimental results have been impressive  , there is still much that can be done potentially to improve the performance  . In the near feature , we would like to incorporate the following into our system : ? List of domain and application dependent person  , organization and location names . 
? More effective name alias algorithm.
? More effective strategy to the backoff modeling and smoothing  . 
References [ Aberdeen+95] J . Aberdeen , D . Day , L . 
Hirschman , P . Robinson and M . Vilain . MITRE : Description of the Alembic System Used for 
MUC6. MUC6. Pages 141-155. Columbia,
Maryland . 1995.
[Aone+98] C . Aone , L . Halverson , T . Hampton , M . Ramos-Santacruz . SRA : Description of the IE2 System Used for MUC7 . MUC7 . Fairfax , Virginia . 

[Bennett+96] S.W . Bennett , C . Aone and C.
Lovell . Learning to Tag Multilingual Texts Through Observation  . EMNLP'1996 . Pages 109-116 . 
Providence , Rhode Island . 1996.
[Bikel+99] Daniel M . Bikel , Richard Schwartz and Ralph M . Weischedel . An Algorithm that Learns What's in a Name . Machine Learning ( Special Issue on NLP ) .  1999 . 
[Borthwick+98] A.Borthwick , J . Sterling , E.
Agichtein , R . Grishman . NYU : Description of the MENE Named Entity System as Used in  MUC7  . 
MUC7. Fairfax , Virginia . 1998.
[Borthwick99] Andrew Borthwick . A Maximum Entropy Approach to Named Entity Recognition  . 
Ph . D . Thesis . New York University . September , 1999 . 
[Brill95] Eric Brill . Transform-based
Error-Driven Learning and Natural Language Processing : A Case Study in Part-of-speech Tagging  . Computational Linguistics 21 (4) . 
Pages 543-565.1995.
[Chinchor95a]Nancy Chinchor . MUC6 Named Entity Task Definition ( Version 2 . 1) . MUC6 . 
Columbia , Maryland . 1995.
[Chinchor 95b]Nancy Chinchor . Statistical Significance of MUC6 Results . MUC6 . Columbia,
Maryland . 1995.
[Chinchor98a]Nancy Chinchor . MUC7 Named Entity Task Definition ( Version 3 . 5) . MUC7 . 
Fairfax , Virginia . 1998.
[Chinchor98b]Nancy Chinchor . Statistical Significance of MUC7 Results . MUC7 . Fairfax,
Virginia . 1998.
[ Humphreys+98] K . Humphreys , R . Gaizauskas , S . Azzam , C . Huyck , B . Mitchell , H . Cunningham , Y . Wilks . Univ . of Sheffield : Description of the LaSIE-II System as Used for  MUC7  . MUC7 . 
Fairfax , Virginia . 1998.
[Krupka+98] G.R . Krupka , K . Hausman.
IsoQuest Inc . : Description of the NetOwl TM Extractor System as Used for  MUC7  . MUC7 . 
Fairfax , Virginia . 1998.
[McDonald96] D . McDonald . Internal and
External Evidence in the Identification and Semantic Categorization of Proper Names  . In B . 
Boguraev and J . Pustejovsky editors : Corpus Processing for Lexical Acquisition  . Pages 21-39 . 
MIT Press . Cambridge , MA . 1996.
[ Miller+98] S . Miller , M . Crystal , H . Fox , L . 
Ramshaw , R . Schwartz , R . Stone , R . Weischedel , and the Annotation Group . BBN : Description of the SIFT System as Used for MUC7  . MUC7 . Fairfax,
Virginia . 1998.
[Mikheev+98] A.Mikheev , C . Grover , M.
Moens . Description of the LTG System Used for MUC7 . MUC7 . Fairfax , Virginia .  1998 . 
[Mikheev+99] A.Mikheev , M . Moens , and C.
Grover . Named entity recognition without gazeteers . 
EACL'1999. Pages 1-8. Bergen , Norway . 1999.
[MUC6] Morgan Kaufmann Publishers , Inc.
Proceedings of the Sixth Message Understanding Conference  ( MUC6 )  . Columbia , Maryland .  1995 . 
[MUC7] Morgan Kaufmann Publishers , Inc.
Proceedings of the Seventh Message Understanding Conference  ( MUC7 )  . Fairfax , Virginia .  1998 . 
[Rabiner89] L . Rabiner . A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition ?  . IEEE 77 (2) . Pages 257-285 . 

[Sekine98] Satoshi Sekine . Description of the Japanese NE System Used for MET2  . MUC7 . 
Fairfax , Virginia . 1998.
[ Tjong+00] Erik F . Tjong Kim Sang and Sabine Buchholz . Introduction to the CoNLL2000 Shared Task : Chunking . CoNLL'2000 . Pages 127-132 . 
Lisbon , Portugal . 1114 Sept 2000.
[ Viterbi 67] A . J . Viterbi . Error Bounds for Convolutional Codes and an Asymptotically Optimum Decoding Algorithm  . IEEE Transactions on Information Theory . IT (13) . Pages 260-269,
April 1967.
[Watson+92] B . Watson and Tsoi A Chunk.
Second Order Hidden Markov Models for Speech Recognition ?  . Proceeding of 4th Australian International Conference on Speech Science and 
Technology . Pages 146-151.1992.
[Yu+98] Yu Shihong , Bai Shuanhu and Wu
Paul . Description of the Kent Ridge Digital Labs System Used for  MUC7  . MUC7 . Fairfax , Virginia . 

[Zhou+00] Zhou GuoDong , Su Jian and Tey Tong Guan . Hybrid Text Chunking . CoNLL'2000 . 
Pages 163-166. Lisbon , Portugal , 1114 Sept 2000.
[Zhou+00b]Zhou GuoDong and Su Jian,
Error-driven HMM-based Chunk Tagger with Context -dependent Lexicon  . EMNLP/VLC'2000 . 
Hong Kong , 78 Oct 2000.
