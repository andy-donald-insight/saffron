A Method for Word Sense Disambiguation of Unrestr icted Text 
Rada Mihalcea and Dan I . Moldovan
Department of Computer Science and Engineering
Southern Methodist University
Dallas , Texas , 75275-0122

Abstract
Selecting the most appropriate sense for an ambiguous word in a sentence is a central problem in Natural Language Processing  . In this paper , we present a method that attempts to disambiguate all the nouns  , verbs , adverbs and adjectives in a text , using the senses provided in WordNet . The senses are ranked using two sources of information :  ( 1 ) the Internet for gathering statistics for word word cooccurrences and  ( 2 ) WordNet for measuring the semantic density for a pair of words  . We report an average accuracy of 80% for the first ranked sense , and 91% for the first two ranked senses . 
Extensions of this method for larger windows of more than two words are considered  . 
1 Introduction
Word Sense Disambiguation ( WSD ) is an open problem in Natural Language Processing  . Its solution impacts other tasks such as discourse  , reference resolution , coherence , inference and others . WSD methods can be broadly classified into three types :  1  . WSD that make use of the information provided by machine readable dictionaries  ( Cowie et al ,  1992) , ( Miller et al ,  1994) , ( Agirre and Rigau ,  1995) , ( Li et al ,  1995) , ( McRoy ,  1992); 2 . WSD that use information gathered from training on a corpus that has already been semantically disambiguated  ( supervised training methods )   ( Gale et al ,  1992) , ( Ng and Lee ,  1996); 3 . WSD that use information gathered from raw corpora  ( unsupervised training methods )   ( Yarowsky , 1995) ( Resnik ,  1997) . 
There are also hybrid methods that combine several sources of knowledge such as lexicon information  , heuristics , collocations and others ( McRoy , 1992) ( Bruce and Wiebe , 1994) ( Ng and Lee , 1996) ( Rigau et al ,  1997) . 
Statistical methods produce high accuracy results for small number of preselected words  . A lack of widely available semantically tagged corpora almost exclude supervised learning methods  . A possible solution for automatic acquisition of sense tagged corpora has been presented in  ( Mihalcea and Moldovan ,  1999) , but the corpora acquired with this method has not been yet tested for statistical disambiguation f words  . On the other hand , the disambiguation using unsupervised methods has the disadvantage that the senses are not well defined  . None of the statistical methods disambiguate adjectives or adverb so far  . 
In this paper , we introduce a method that attempts to disambiguate all the nouns  , verbs , adjectives and adverbs in a text , using the senses provided in WordNet ( Fellbaum ,  1998) . To our knowledge , there is only one other method , recently reported , that disambiguates unrestricted words in texts ( Stetina et al ,  1998) . 
2 A word word dependency approach
The method presented here takes advantage of the sentence context  . The words are paired and an attempt is made to disambiguate one word within the context of the other word  . This is done by searching on Internet with queries formed using different senses of one word  , while keeping the other word fixed . The senses are ranked simply by the order provided by the number of hits  . A good accuracy is obtained , perhaps because the number of texts on the Internet is so large  . In this way , all the words are the ranking of senses to curb the computational complexity in the step that follows  . Only the most promising senses are kept . 
The next step is to refine the ordering of senses by using a completely different method  , namely the semantic density . This is measured by the number of common words that are within a semantic distance of two or more words  . The closer the semantic relationship between two words the higher the semantic density between them  . We introduce the semantic density because it is relatively easy to measure it on a MRD like WordNet  . A metric is introduced in this sense which when applied to all possible combinations of the senses of two or more words it ranks them  . 
An essential aspect of the WSD method presented here is that it provides a raking of possible associations between words instead of a binary yes/no decision for each possible sense combination  . This allows for a controllable precision as other modules may be able to distinguish later the correct sense association from such a small pool  . 
3 Contextua l rank ing o f word senses Since the Internet contains the largest collection of texts electronically stored  , we use the Internet as a source of corpora for ranking the senses of the words  . 
3.1 Algorithm 1
For a better explanation of this algorithm , we provide the steps below with an example . We considered the verb-noun pair " investigate report "  ; in order to make easier the understanding of these examples  , we took into consideration only the first two senses of the noun report  . These two senses , as defined in WordNet , appear in the synsets : ( report  #l , study and report #2 , news report , story , account , write up . 
INPUT : semantically untagged word1-word2 pair ( W1-W2 ) OUTPUT : ranking the senses of one word

STEP1 . Form a similarity list \] or each sense of one of the words  . Pick one of the words , say W2 , and using WordNet , form a similarity list for each sense of that word  . For this , use the words from the synset of each sense and the words from the hypernym synsets  . Consider , for example , that W2 has m senses , thus W2 appears in m similarity lists : . . . , ( wL (', . . . , where W1,Wff, . . . , W ~ n are the senses of W2 , and W2 ( s ) represents the synonym numbers of the sense W ~ as defined in WordNet  . 
Example The similarity lists for the first two senses of the noun report are :  ( report , study ) ( report , news report , story , account , write up ) STEP2 . For mW1-W2(s ) pairs . The pairs that may be formed are : - w ,  - (1) ,  -  . . . , wl-(Wl--W2, Wl-W22(1), Wi-W2(2), . . . , Wl - W : ( k2)) ( Wl - W2 n , Wl-W2n (1) , Wl-W2m (2) ,   . . . , Wi - W ~ ( k in ) ) Example The pairs formed with the verb investigate and the words in the similarity lists of the noun report are:  ( investigate-report , investigate-study ) ( investigate-report , investigate-news report , investigate-story , investigate-account , ivestigate-write up ) STEP3 . Search the Internet and rank the senses W~(s) . A search performed on the Internet for each set of pairs as defined above  , results in a value indicating the frequency of occurrences for W l and the sense of  W2  . In our experiments we used ( Altavista ,  1996 ) since it is one of the most powerful search engines currently available  . Using the operators provided by Alta Vista , query-forms are defined for each W1-W2 ( s ) set above: ( a )   ( " w , oR " wloRoR .   .   . 
OR"W1W ~ ( k  ~ ) ' )   ( b )   ( ( W ~ NEAR W ~ ) OR ( W1NEARW ~ ( 1 ) ) OR ( W1NEARW ~ ( 2 ) ) OR . . . OR(W ~ NEARW ~( k '))) for all 1 < i < m . Using one of these queries , we get the number of hits for each sense i of W2 and this provides a ranking of them senses of
W2 as they relate with 1411.
Example The types of query that can be formed using the verb investigate and the similarity lists of the noun report  , are shown below . After each query , we indicate the number of hits obtained by a search on the Internet  , using Alta Vista . 
( a )   ( " investigaterport " OR " investigate study " )   ( 478 )   ( " investigaterport " OR " investigate news report " OR " investigate story " OR " investigate account " OR " investigate write up  "  )   ( ~81 )   ( b )   ( ( investigate NEAR report ) OR ( investigate NEAR study ) )  ( 34880 )   ( ( investigate NEAR report ) OR ( investigate NEAR news report ) OR ( investigate NEAR story ) OR ( investigate NEAR account ) OR ( investigate NEAR write up ) )  ( 15ss4 ) A similar algorithm is used to rank the senses of  W1 while keeping W2 constant ( un-disambiguated )  . Since these two procedures are done over a large corpora  ( the Internet )  , and with the help of similarity lists , there is little correlation between the results produced by the two procedures  . 
3.1.1 Procedure Evaluation
This method was tested on 384 pairs : 200 verb-noun ( file br-a01 , br-a02) , 127 adjective-noun ( filebr-a01) , and 57 adverb-verb ( filebr-a01) , extracted from SemCor 1 . 6 of the Brown corpus . 
Using query form ( a ) on Alta Vista , we obtained the results shown in Table 1 . The table indicates the percentages of correct senses  ( as given by SemCor ) ranked by us in top 1 , top 2 , top 3 , and top 4 of our list . We concluded that by keeping the top four choices for verbs and nouns and the top two choices for adjectives and adverbs  , we cover with high percentage ( mid and upper 90's ) all relevant senses . Looking from a different point of view , the meaning of the procedure so far is that it excludes the senses that do not apply  , and this can save a considerable amount of computation time as many words are highly polysemous  . 
top 1 top 2 top 3 top 4 noun 76%   83~   86~   98% verb 60%   68%   86%   87% adjective 79  . 8%  93% adverb 87%   97% Table 1: Statistics gather from the Internet for 384 word pairs . 
We also used the query form ( b ) , but the results obtained were similar ; using , the operator NEAR , a larger number of hits is reported , but the sense ranking remains more or less the same  . 
3 . 2 Conceptua l dens i ty a lgor i thm A measure of the relatedness between words can be a knowledge source for several decisions in NLP applications  . The approach we take here is to construct a linguistic on text for each sense of the verb and noun  , and to measure the number of the common nouns shared by the verb and the noun contexts  . In WordNet each concept has a gloss that acts as a micro context for that concept  . This is a rich source of linguistic information that we found useful in determining conceptual density between words  . 
3.2.1 Algorithm 2
INPUT : semantically untagged verb-noun pair and a ranking of noun senses  ( as determined by
Algorithm 1)
OUTPUT : sense tagged verb-noun pair
PaOCEDURE :
STEP1 . Given a verb-noun pair V-N , denote with < vl , v2 ,   . . . , Vh > and < nl , n2, . . . , nt > the possible senses of the verb and the noun using 

STEP2 . Using Algorithm 1 , the senses of the noun are ranked . Only the first t possible senses indicated by this ranking will be considered  . 
The rest are dropped to reduce the computational complexity  . 
STEP3 . For each possible pair vi-nj , the conceptual density is computed as follows : ( a ) Extract all the glosses from the subhierarchy including vi  ( the rationale for selecting the subhierarchy is explained below  )   ( b ) Determine the nouns from these glosses . 
These constitute the noun-context of the verb.
Each such noun is stored together with a weight w that indicates the level in the subhierarchy of the verb concept in whose gloss the noun was found  . 
( c ) Determine the nouns from the noun subhierarchy including nj  . 
( d ) Determine the conceptual density Cij of common concepts between the nouns obtained at  ( b ) and the nouns obtained at ( c ) using the metric :
Icdijlk
Cij = log ( descendents j )   ( 1 ) where : ? I cdljl is the number of common concepts between the hierarchies of vl and nj verb vi ? descendents j is the total number of words within the hierarchy of noun njSTEP  4  . Vii ranks each pair vi-nj , for all i and j . 
Rationale 1 . In WordNet , a gloss explains a concept and provides one or more examples with typical usage of that concept  . In order to determine the most appropriate noun and verb hierarchies  , we performed some experiments using SemCor and concluded that the noun subhierarchy should include all the nouns in the class of nj  . The subhierarchy of verb vi is taken as the hierarchy of the highest hypernym hi of the verb vi  . It is necessary to consider a larger hierarchy then just the one provided by synonyms and direct hyponyms  . As we replaced the role of a corpora with glosses  , better results are achieved if more glosses are considered  . Still , we do not want to enlarge the contextoo much . 
2 . As the nouns with a big hierarchy tend to have a larger value for Icdij\[  , the weighted sum of common concepts is normalized with respect to the dimension of the noun hierarchy  . 
Since the size of a hierarchy grows exponentially with its depth  , we used the logarithm of the total number of descendants in the hierarchy  , i . e . 
log(descendentsj).
3 . We also took into consideration and have experimented with a few other metrics  . But after running the program on several examples  , the formula from Algorithm 2 provided the best results . 
4 An Example
As an example , let us consider the verb-noun collocation revise law  . The verb revise has two possible senses in WordNet  1  . 6 and the noun law ? has seven senses . Figure 1 presents the synsets in which the different meanings of this verb and noun appear  . 
First , Algorithm 1 was applied and search the Internet using Alta Vista  , for all possible pairs VN that may be created using revise and the words from the similarity lists of law  . The following ranking of senses was obtained : Iaw#2  ( 2829 )  , law #3 (648) , law #4 (640) , law #6 (397) , law #1 (224) , law #5 (37) , law #7 ( O ) , " REVISE 1 . revise  #l => rewrite 2 . retool , revise #2=> reorganize , shake up
LAW 1 . law#I , jur is prudence => collection , aggregation , accumulation , assemblage 2 . law#2=> rule , prescript\] . . . 
3 . law #3 , natural aw =>\[ concept , conception , abstract \] 4 . law #4 , law of nature =>\[ concept , conception , abstract \] 5 . juris prudence , law #5 , legalphilosophy=>\[philosophy 6 . law #6 , practice of law =>\[ learned profession 7 . police , police force , constabulary , law #7=> force , personnel Figure 1: Synsets and hypernyms for the different meanings , as defined in WordNet where the numbers in parentheses indicate the number of hits  . By setting the threshold at t = 2 , we keep only sense #2 and #3 . 
Next , Algorithm 2 is applied to rank the four possible combinations  ( two for the verb times two for the noun )  . The results are summarized in Table 2: ( 1 ) \[ cdij\[-the number of common concepts between the verb and noun hierarchies  ;   ( 2 ) descendants j the total number of nouns within the hierarchy of each sense n j  ; and ( 3 ) the conceptual density Cij for each pair ni-vj derived using the formula presented above  . 
ladijI descendant sjCij n2   n3   1"$2   I"$3   n2   1"$3   5   4   975   1265   0  . 30 0 . 2 8   0   0   975   1265   0   0 Table 2: Values used in computing the conceptual density and the conceptual density Cij The largest conceptual density  C12  =  0  . 3 0 corresponds to V 1  --  n2 : rev ise#l~2 - l aw#2/5   ( the notation  #i/n means sense i out of n pos -tion 
Cor , senses given by WordNet) . This combina-of verb-noun senses also appears in Sem-file  br-a01  . 
5 Eva luat ion and compar i son w i th o ther methods  5  . 1 Tests against SemCor The method was tested on 384 pairs selected from the first two tagged files of SemCor  1  . 6 ( filebr-a01, br-a02) . From these , there are 200 verb-noun pairs , 127 adjective-noun pairs and 57 adverb-verb pairs . 
In Table 3, we present a summary of the results.
top 1 top 2 top 3 top 4 noun 86 . 5% 96% 97% 98% verb 67% 79% 86% 87% adjective 79 . 8%  93% adverb 87%   97% Table 3: Final results obtained for 384 word pairs using both algorithms . 
Table 3 shows the results obtained using both algorithms ; for nouns and verbs , these results are improved with respect othose shown in Table  1  , where only the first algorithm was applied . The results for adjectives and adverbs are the same in both these tables  ; this is because the second algorithm is not used with adjectives and adverbs  , as words having this part of speech are not structured in hierarchies in WordNet  , but in clusters ; the small size of the clusters limits the applicability of the second algorithm  . 
Discussion of results When evaluating these results  , one should take into consideration that : 1 . Using the glosses as a base for calculating the conceptual density has the advantage of eliminating the use of a large corpus  . But a disadvantage that comes from the use of glosses is that they are not part-of-speech tagged  , like some corpora are ( i . e . Treebank ) . For this reason , when determining the nouns from the verb glosses , an error rate is introduced , as some verbs ( like make , have , go , do ) are lexically ambiguous having a noun representation in WordNet as well  . We believe that future work on part-of-speech tagging the glosses of WordNet will improve our results  . 
2 . The determination of senses in SemCor was done of course within a larger context  , the context of sentence and discourse . By working only with a pair of words we do not take advantage of such a broader context  . For example , when disambiguating the pair protect court our method picked the court meaning " a room in which a law courts its " which seems reasonable given only two words  , whereas SemCor gives the court meaning " an assembly to conduct judicial business " which results from the sentence context  ( this was our second choice )  . In the next section we extend our method to more than two words disambiguated at the same time  . 
5 . 2 Compar i son wi th o ther methods As indicated in  ( Resnik and Yarowsky ,  1997) , it is difficult to compare the WSD methods , as long as distinctions reside in the approach considered  ( MRD based methods , supervised or unsupervised statistical methods ) , and in the words that are disambiguated . A method that disambiguates unrestricted nouns , verbs , adverbs and adjectives in texts is presented in ( Stetina et al ,  1998) ; it attempts to exploit sentential and discourse contexts and is based on the idea of semantic distance between words  , and lexical relations . It uses WordNet and it was tested on SemCor . 
Table 4 presents the accuracy obtained by other WSD methods  . The baseline of this comparison is considered to be the simplest method for WSD  , in which each word is tagged with its most common sense  , i . e . the first sense as defined in WordNet . 
Base Stetina Yarowsky Our line method noun 80 . 3% 85 . 7% 93 . 9% 86 . 5% verb 62 . 5% 63 . 9% 67% adjective 81 . 8% 83 . 6% 79 . 8 adverb 84 . 3% 86 . 5% 87%
AVERAOEI 77% I 80% I 180.1% 1
Table 4: A comparison with other WSD methods.
As it can be seen from this table , ( Stetina et al . , 1998) reported an average accuracy of 85 . 7% for nouns , 63 . 9% for verbs , 83 . 6% for adjectives and 86 . 5% for adverbs , slightly less than our results . Moreover , for applications such as information retrieval we can use more than one sense combination  ; if we take the top 2 ranked combinations our average accuracy is 91  . 5% ( from
Table 3).
Other methods that were reported in the lit-word ( i . e . nouns ) , or in the case of purely statistical methods focus on very limited number of words  . Some of the best results were reported in ( Yarowsky , 1995) who uses a large training corpus . For the noun drug Yarowsky obtains 91 . 4% correct performance and when considering the restriction " one sense per discourse " the accuracy increases to  93  . 9% , result represented in the third column in Table 4 . 
6 Extensions 6 . 1 Noun-noun and verb-verb pairs The method presented here can be applied in a similar way to determine the conceptual density within noun-noun pairs  , or verb-verb pairs ( in these cases , the NEAR operator should be used for the first step of this algorithm  )  . 
6.2 Larger window size
We have extended the disambiguation method to more than two words cooccurrences  . Consider for example : The bombs caused amage but no injuries  . 
The sense specified in SemCor , are : la . bomb ( #1~3 ) cause ( #1//2 ) damage ( #1~5 ) iujury ( #1/4  ) For each word X , we considered all possible combinations with the other words Y from the sentence  , two at a time . The conceptual density C was computed for the combinations X-Y as a summation of the conceptual densities between the sense i of the word X and all the senses of the words Y  . The results are shown in the tables below where the conceptual density calculated for the sense # i of word X is presented in the column denoted by C#i: 
X-YC #10 #2 C#3 bomb-cause 0 . 5700 bomb-damage 5 . 09 0 . 130 bomb-injury 2 . 69 0 . 15 0
SCORE 8.35 0.280
By selecting the largest values for the conceptual density  , the words are tagged with their senses as follows : lb  . bomb(#1/3) cause(#1/2) damage(#1~5)iuju , ( #e/4)
XY cause-bomb cause-damage cause-injury
SCOREc#I 5.161 2.831 2.633 0.62
C  #21.34 2.64 1.75 5.73
X-Y C#1 damage-bomb 5 . 60 damage-cause 1 . 73 damage-injury 9 . 87
SCORE 17.20 c #22.1 42.6 32.5 77.34
C#3 C#4 C#51 . 95 0 . 88 2 . 16 0 . 17 0 . 16 3 . 80 3 . 24 1 . 56 7 . 59 5 . 36 2 . 60 13 . 5 5 Note that the senses for word injury differ from la  . to lb . ; the one determined by our method ( #2/4 ) is described in WordNet as " an accident that results in physical damage or hurt "  ( hypernym : accident )  , and the sense provided in SemCor ( #1/4 ) is defined as " any physical damage ' ( hypernym : health problem )  . 
This is a typical example of a mismatch caused by the fine granularity of senses in WordNet which translates into a human judgment that is not a clearcut  . We think that the sense selection provided by our method is justified  , as both damage and injury are objects of the same verb cause  ; the relatedness of dam-age ( #1/5 ) and injury ( #2/~ ) is larger , as both are of the same class noun . event as opposed to injury ( #1~4 ) which is of class noun . state . 
Some other randomly selected examples considered were:  2a   . Thete , ~ orists(#l/1) bombed(#l/S ) the embassies(#1~1) . 
2b . terrorist(#1~1)bomb(#1~3) embassy(#1~1)3 a . A car-bomb ( #1~1 ) exploded ( #2/ lO ) in \] rout of PRC ( #I/1 ) embassy ( #1/1 )  . 
3b . car-bomb (#1/1) explode (#2/ lO)
PRC(#I/1) embassy(#1~1)4 a . The bombs ( #1~3 ) broke ( #23~27 ) windows ( #l/4 ) and destroyed ( #2~4 ) the two vehicles ( #1~2 )  . 
4b . bomb ( #1/3 ) break ( #3/27 ) window ( #1/4 ) destroy ( #2/4 ) vehicle (  #l/2 ) where sentences 2a , 3 a and 4 a are extracted from SemCor , with the associated senses for each word , and sentences 2b ,   3b and 4b show the verbs and the nouns tagged with their senses by our method  . The only discrepancy is for the injury-bomb2 . 35 5 . 35 0 . 41 2 . 28 injury-cause 04 . 48 0 . 05 0 . 01 in jury-damage 5 . 05 10 . 40 0 . 81 9 . 69
SCORE7 . 40 20 . 23 1 . 27 11 . 9 8 word broke and perhaps this is due to the large number of its senses  . The other word with a large number of senses explode was tagged correctly  , which was encouraging . 
7 Conclusion
WordNet is a finegrain MRD and this makes it more difficult to pinpoin the correct sense combination since there are many to choose from and many are semantically close  . For applications such as machine translation , finegrain disambiguation works well but for information extraction and some other applications this is an overkill  , and some senses may be lumped together . The ranking of senses is useful for many applications  . 
References
E . Agirre and G . Rigau .  1995 . A proposal for word sense disambiguation using conceptual distance  . In Proceedings of the First International Conference on Recent Advances in Natural Language Processing  , Veling rad . 
Altavista .  1996 . Digital equipment corporation . " http://www . altavista . com" . 
R . Bruce and J . Wiebe .  1994 . Word sense disambiguation using decomposable models  . 
In Proceedings of the Thirty Second Annual Meeting of the Association for Computational Linguistics  ( ACL-9~ )  , pages 139-146 , 
Las Cruces , NM , June.
J . Cowie , L . Guthrie , and J . Guthrie . 1992.
Lexical disambiguation using simulated annealing . In Proceedings of the Fifth International Conference on Computational Linguistics  COLING-92  , pages 157-161 . 
C . Fellbaum . 1998. WordNet , An Electronic
Lexical Database . The MIT Press.
W . Gale , K . Church , and D . Yarowsky . 1992.
One sense per discourse . In Proceedings of the DARPA Speech and Natural Language Workshop  , Harriman , New York . 
X . Li , S . Szpakowicz , and M . Matwin . 1995.
A wordnetbased algorithm for word semantic sense disambiguation  . In Proceedings of the Forteen International Joint Conference on Artificial Intelligence  IJCAI-95  , Montreal , 

S . McRoy .  1992 . Using multiple knowledge sources for word sense disambiguation  . Computational Linguistics , 18(1):1-30 . 
R . Mihalcea and D . I . Moldovan .  1999 . An automatic method for generating sense tagged corpora  . In Proceedings of AAAI99, Orlando , FL , July . ( to appear) . 
G . Miller , M . Chodorow , S . Landes , C . Leacock , and R . Thomas .  1994 . Using a semantic on-cordance for sense identification  . In Proceedings of the ARPA Human Language Technology Workshop  , pages 240-243 . 
H . T . Ng and H . B . Lee .  1996 . Integrating multiple knowledge sources to disambiguate word sense : An examplar-based approach  . In Proceedings of the Thirtyfour Annual Meeting of the Association for Computational Linguistics  ( ACL-96 )  , Santa Cruz . 
P . Resnik and D . Yarowsky .  1997 . A perspective on word sense disambiguation methods and their evaluation  . In Proceedings of ACL Siglex Workshop on Tagging Text with Lexical Semantics  , Why , What and How ? , Washington DC , April . 
P . Resnik .  1997 . Selectional preference and sense disambiguation . In Proceedings of ACL Siglex Workshop on Tagging Text with Lexical Semantics  , Why , What and How ? , Washington DC , April . 
G . Rigau , J . Atserias , and E . Agirre . 1997.
Combining unsupervised lexical knowledge methods for word sense disambiguation  . 
Computational Linguistics.
J . Stetina , S . Kurohashi , and M . Nagao .  1998 . 
General word sense disambiguation method based on a full sentential context  . In Usage of WordNet in Natural Language Processing  , Proceedings of COLING-ACL Workshop , 
Montreal , Canada , July.
D . Yarowsky .  1995 . Unsupervised word sense disambiguation rivaling supervised methods  . 
In Proceedings of the Thirtythird Association of Computational Linguistics  . 

