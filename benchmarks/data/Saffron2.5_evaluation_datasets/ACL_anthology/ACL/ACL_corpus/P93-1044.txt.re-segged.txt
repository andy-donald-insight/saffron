Guiding an HPSG Parser using Semantic and Pragmatic Expectations 
Jim Skon
Computer and Information Science Department
The Ohio State University
Columbus , OH 43210, USA
Internet : skon@c is . ohio-state.edu
Abstract 1
Efficient natural language generation has been successfully demonstrated using highly compiled knowledge about speech acts and their related social actions  . A design and prototype implementation fa parser which utilizes this same pragmatic knowledge to efficiently guide parsing is presented  . Such guidance is shown to prune the search space and thus avoid needless processing of pragmatically unlikely constituent structures  . 

The use of purely syntactic knowledge during the parse phase of natural language understanding yields considerable local ambiguity  ( consideration of impossible sube on stituents ) as well global ambiguity ( construction f syntactically valid parses not applicable to the socio-pragmatic context  )  . 
This research investigates bringing socio -pragmatic knowledge to bear during the parse  , while maintaining a domain independent grammar and parser  . The particular technique explored uses knowledge about hepragmatic context to order the consideration of proposed parse constituents  , thus guiding the parser to consider the best ( wrt the expectations ) solutions first . Such a search may be classified as a bestfirst search  . 
The theoretical models used to represent the pragmatic knowledge in this study are based on Halliday's Systemic Grammar and a model of the pragmatics of conversation  . The model used to represent the syntax and domain independent semantic knowledge is HPSG-Head -driven Phrase Structure 


Patten , Geis and Becker ( 1992 ) demonstrate the application of knowledge compilation to achieve the rapid generation of natural language  . Their mechanism is based on Halliday'systemic networks  , and on Geis'theory of the pragmatics of conversation  . A model of conversation using principled compilation of pragmatic knowledge and other linguistic knowledge is used to permit the application of pragmatic inference without expensive computation  . A pragmatic component is used to model social action  , including speech acts , and utilize conventions of us . g involving such features of context such as politeness  , ~ e~gister , and stylistic features . These politeness features are critiqdl to the account of indirect speech acts  . This pragmatic knovCledge is compiled into course -grained knowledge in the form of a classification hierarchy  . A planner component uses knowledge about conditions which need to be satisfied  ( discourse goals ) to produce a set of pragmatic features which characterize a desired utterance  . These features are mapped into the systemicl Research Funded by The Ohio State Center for Cognitive Science and The Ohio State Departments of Computer and 
Information Science and Linguistics grammar ( using compiled knowledge ) which is then used to realize the actual utterance  . 
The syntactic/semantic component used in this study is a parser based on the HPSG  ( Head Driven Phrase Structure Grammar ) theory of grammar ( Pollard and Sag ,  1992) . HPSG models all linguistic constituents in terms of part/a/information structures called feature structures  . 
Linguistic signs incorporate simultaneous representation f phonological  , syntactic , and semantic attributes of grammatical constituents  . HPSG is a lexiealized theory , with the lexical definitions , rather then phrase structure rules , specifying most configurational constraints . Control ( such as subcategorization , for example ) is asserted by the use of HPSG constraints - partially filled in feature structures called feature descriptions  , which constrain possible HPSG feature structures by asserting specific attributes and/or labels  . 
A HPSG based chart parser , under development a the author's university , was used for the implementation part of this study  . 
FEATUREM APPING
Planning & generation of coherent " speech " in a conversation require some understanding of the " hearer's " perspective  . Thus the speaker naturally has some ( limited ) knowledge about possible responses from the hearer  . This knowledge can be given to the same planner used for generation  , producing a partial set of pragmatic features or expectations  . These pragmatic expectations can then be mapped into the systemic grammar  , producing a set of semantic and syntactic expectations about what other participants in the conversation will say  . 
The technique explored here is to bring such expectations to bear during the parse process  , guiding the parser to the most likely solution in a bestfirst manner  . It is thus necessary that the generated expectations be mapped into a form which can be directly compared with constituents proposed within the HPSG parse  . 
Consider the sentence " Robin promised to come at no on "  , with the following context : S and y : " I guess we should get started  , what time did they say they would be here ?"
Kim : " Robin promised to come at no on "
A set of plausible partial expectations generated by the pragmatic and systemi components in anticipation of Kim's response might be:  ( ( S )   ( UN MARKED-DECL ARATIVE ) )  ( ( S SUBJECT )   ( PROPER ) )  ( ( S BETA )   ( NONFINITEPRED ) )  ( ( S PREDICATOR )   ( PROMISED ) )  ( ( S BETA TEMPORAL )   ( PP ) )  ( ( S BETA PREDICATOR )   ( ARRIVAL ) ) In these xpectations the first list of each pair  ( e . g .   ( SBETA ) ) represents a functional role within the expected sentence  . The expected features for the associated functional roles  . These expected features assert expectations which are both semantic  ( e . g . PROMISED ) and syntactic ( e . g .   ( ( S BETA TEMPORAL )   ( PP ) ) asserts both the existance and location of a temporal adjunct PP  )  . 
Note that in these expectations the temporal adjunct " at noon " should modify the embedded clause " to come "  , as would be expected in the specified context . 
Next consider the possible HPSG parses of the example sentence  . Figures 1 and 2 below illustrate two semantically distinct parses generated by our HPSG parser  . 
SHs//H/vP
NP VV VPP
Robin promised to come at no on
Figure 1.
SH//,V--vr\
NP VV VPP
Robin promised to come at no on
Figure 2.
Mapping expected features into HPSG constraints : Features generated from pragmatic expectations can be mapped into constraints on HPSG structures  , tated in terms of feature descriptions . Below are the HPSG feature descriptions corresponding to the pragmatically generated features PP and UNMARKED-DECLARATIVE  . 
PP = SYNSEMILOCICATHEAD prep . \[ MARKING unmarked\]\] phrase cat '
Figure 3.
UN MARKED-DECLARATIVE =
FDTRSIHEAD-DTRISYNSEM v_E phrase LSU ~ -DTRISYNSEMILOCICATIHEAD__ 
Figure 4.

Mapping expected functional roles into HPSG constituent structure : Pragmatic expectations are expected with in certain functional roles  , such a SUBJECT , PREDICATOR , BETA ( the embedded clause ) etc . This structural information must be used to assert the constraints into the relevant HPSG substructures  . This mapping is not as straightforward as the feature mapping technique  , as the structure induced by the systemic grammar is " flatter " than the structure produced by 

Consider the following pragmatically generated expectation :  ( ( S TEMPORAL )   ( PP ) ) Such an expectation may be realized by great variety of 
HPSG structural realizations , e . g . : 1 . Kimran at noon 2 . Kim could run home at no on 3 . K . im could have been running home at no on 4 . Kimraneas tatnoon . 
In these xamples modal verb operators ( 13 ) and multiple adjuncts ( 4 ) vary the actual structural depth of the temporal PP within the HPSG model  . Thus a given systemic role path may have numerous HI~G constituent path realizations  . One possible mapping technique is to generate constraints expressing all possible HPSG structural variants  . This , however would lead in many cases to a combinatorial explosion of constraints  . The techniquemployed by this study was to add a new clause attribute to verbal HPSG signs  , and use this attribute to embed within the signs a " clausally flattened " structures  . Each HPSG verbal sign in the same clause structure shares the same clausal value  . The clause value is a structure with labels for each system ic role  , where each label points to the constituent which fills that role in the given verbal clause  . A clausal boundry is said to exist between distinct clausal domains  . A clausal structure is illustrated in figure 5: ~" ~ vPIF~IVI~v\[r ~" I\]V/-/~%P\[ \[~\] P 
R?bin promlised " E"H\[~H // ~ pv\[N\]II come at no on\[CFPREDICATORV\[pr?mised\]\] \]\[\] LAUSE SUBJECTNP\[Robin\]=-BETA VP\[to come at no on\]\] rEI~LAUS ErPREDICATORV \[ come\]LTEMPORALPP\[atnoon\]\]\]\]I = 
Figure 5.
The current mapping only considers the mapping of roles within verbal signs  . Similar role structures may exist for other constituent types  , such as for noun phrase . Thus farthever bal clause boundary definition has been adequate for other phrasal structures  . 
GUIDING THE HPSG PARSE
The guidance strategy employed is to evaluate all proposed edges  ( i . e . complete and partially complete constituents ) against the expectations , ranking each based on the relative similarity with the expectations  . These edges are removed from the agend and included in the partial parse in a bestfirst order  . 
Critical to the success of a bestfirst algorithm is the heuristic evaluation function used to order the proposed constituents  . 
The heuristic evaluation function :
The heuristic evaluation function is based on three specific types of tests : I  . Role match-does a constituent match a role's set of expected features ? II  . Role path match - is a constituent role path compatible with the roles of its children ? III  . Clausal completeness - are all clausal roles expected for this constituent present ? Tests II and III above require that constituents under consideration have roles already assigned to them  . For example , in the case of II , the test requires roles for both the new constituent and the propose daughters of the constituent  . 
But since the parse strategy employeed is bottom -up  , role paths cannot be anchored to a root , and thus fully known , until parse completion . The solution to this dilemma is to hypothesis e a constituent's role using a process similar to abduction  . Two types of knowledge are exploited in this process  . First , roles with features which subsume or are consistant with a proposed constituent are considered good candidate roles  . Also , roles may also be inferred by projecting up from the roles already hypothesized for the children  . By intersecting these two sources of role evidence  , the list of hypothesized roles can be refined ( by ruling out roles without both types of evidence  )  . In this manner the hypothesized roles of later constituents can be refined from descendant constituents  . In the case of roles projected from daughters , clausal boundary knowledge must be applied to correctly infer the parent role  . 
EVALUATION & TESTING
The techniques described here have been used successfully to guide the parsing of several sentences taken from real conversations  . The pragmatic and semantic knowledge already existed from Patten's research  ( Patten , 1992) to generate these sentences . A subset of this knowledge , judged to represent the partial knowledge available to a listener  , was used to generate expectations in the form described above  . 
The parser used in this study by default produced all possible parses  . The modified version attempts to converge on the " expected " parse first  , and terminate . For each sentence tested the parser converges on the correct parse first  . When the expectations are modified to expect a different parse  , a different ( and correct ) parse is found first . The results in terms of speedup vary considerably depending on the level of ambiguity present in the sentence  . The most complex sentence parsed thus far exhibits considerable speedup  . When unguided , the parser produces 24 parses , and considers a total of 252 distinct constituents . In the guided case , the parser only considers 39 constituents , and converges on the one " correct " parse first . 
Within the current esting environment , this guidence results in a greater then tenfold speedup in terms of CPU time  . 

Pragmatic knowledge about language usage in routine conversational contexts can be highly compiled  . This knowledge can be used to produce semantic and syntactic expectations about next turns in conversation  , especially of next turns that are second members of adjacency pairs  ( Schegloff & Sacks 1973 )  . By mapping expected features into HPSG constraints  , and by augmenting HPSG sign structures to model the role structure of systemic grammar  , these expectations can be used as constraints on possible constituent structures of a HPSG constituent  . Given this mapping , the expectations may then be used to order the parse process  , guiding the parse , and avoiding the consideration of pragmatically unlikely constructions  . This process reduces the number of constituents considere during parsing  , reducing parse time and permitting the parser to correctly select the parse most like the pragmatic expectations  , This solution closely follows a classical A . I . search technique called a bestfirst search . The heuristic evaluation function used to classify the proposed constituents for bestfirst ordering uses inference similar to abductive reasoning  . 
One benefit of this solution is that it retains the modularity of the syntactic and semantic omponents  , not requiring a specialized grammar for each contextual domain  . In additional , as the coverage of the grammar increases , the search space will also increase , and thus possible benefits increase . 
Work is continuing on this study . Currently the heuristic is being enhanced to consider the specificity of an expectation match  , ordering those edges which match the most specific features first  . In addition , work is in progress to extend the coverage of the grammar and mapping to include the conversation domain utilized in Patten  , Geis & Becker 1992 . 

Geis , Mike . L . and Harlow , L . " Politeness Strategies in French and English : Implications for Second Language 

MacGregor , R . , " LOOM Users Manual " , University of Southern California , lnformations Sciences Institute ,  1991 . 
Patten , Terry . ; Geis , Mike . and Becker , Barbara . , " Toward a Theory of Compilation for Natural -l_anguage Gneration  , " Computation all ntelligence 8(1) ,  1992 , pp77-101 . 
Pollard , Carl and Sag , Ivan A . , " Head-Driven Phrase Structure Grammar " , unpublished manuscript draft ,  1992 . 
Pollard , Carl . and Sag , Ivan A . , " Information-Based Syntax and Semantics : Volume  1  , Fundamentals " , Center for the Study of Language and Information ,  1987 . 
Schegloff , E . A . and Sacks , H . Opening up closings . 
Semiotica , 7, 4:289-387, 1973.
Winograd , Terry .  1983 . " Language as a Cognitive Process ",
Addison-Wesley , Menlo Park , CA.

