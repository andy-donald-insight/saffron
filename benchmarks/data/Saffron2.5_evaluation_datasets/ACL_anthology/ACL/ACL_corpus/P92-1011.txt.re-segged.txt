COMPARING TWOGRAMMAR-BASED GENERATION
ACASESTUDY
Miroslav Martinovic and Tomek Strzalkowski
Courant Institute of Mathematical Sciences
New York University
715 Broadway , rm . 704
New York , N.Y ., 10003


In this paper we compare two grammar-based generation algorithms : the Semantic-Head-Driven Generation Algorithm  ( SHDGA )  , and the Essential Arguments Algorithm ( EAA) . Both algorithms have successfully addressed several outstanding problems in grammar-based generation  , including dealing with non-mono-tonic compositionality of representation  , left-recursion , deadlock-prone rules , and nondeterminism . We concentrate here on the comparison of selected properties : generality  , efficiency , and determinism . We show that EAA's traversals of the analysis tree for a given language construct  , include also the one taken on by SHDGA . We also demonstrate specific and common situations in which SHDGA will invariably run into serious in efficiency and nondeterminism  , and which EAA will handle in an efficient and deterministic manner  . We also point out that only EAA allows to treat he underly in grammar in a truly multidirectional manner  . 
1. INTRODUCTION
Recently , two important new algorithms have been published ( \[SNMP89\] , \[ SNMP90\] , \[ S90 a\] , \[S90b\]and\[$91\] ) that address the problem of automated generation of natural language x pressions from a structured representation fmeaning  . Both algorithms follow the same general principle : given a grammar  , and a structured representation fmeaning , produce one or more corresponding surface strings  , and do so with a minimal possible f for t . In this paper we limit our analysis of the two algorithms to unification-based formalisms  . 
The first algorithm , which we call here the Seman-tic-Head-Driven Generation Algorithm  ( SHDGA )  , uses information about semantic heads ~ in grammar rules to obtain the best possible traversal of the generation tree  , using a mixed top-down/bottom-up strategy . 
The semantic head of a rule is the literal on the right hand side that shares the semantics with the literal on the left  . 
The second algorithm , which we call the Essential Arguments Algorithm ( EAA )  , rearranges grammar productions at compile time in such a way that a simple topdown left-to-right evaluation will follow an optimal path  . 
Both algorithms have resolved several outstanding problems in dealing with natural language grammars  , including handling of left recursive rules , non-mono-tonic compositionality of representation  , and deadlock-prone rules 2 . In this paper we attempt to compare these two algorithms along their generality and efficiency lines  . Throughout this paper we follow the notation used in\[  SNMP90\]  . 
2. MAIN CHAR ACTERISTICS OF SHDGA'S
ANDEAA'STRAVERSALS
SHDGA traverses the derivation tree in the seman -tic-head-first fashion  . Starting from the goal predicate node ( called the root )  , containing a structured representation ( semantics ) from which to generate , it selects a production whose leg-hand side semantics unifies with the semantics of the root  . If the selected production passes the semantics unchanged from the left to some nonterminal on the right  ( the socalled chain rule )  , this later nonterminal becomes the new root and the algorithm is applied recursively  . On the other hand , if no right hand side literal has the same semantics as the root  ( the socalled non-chain rule )  , the production is expanded , and the algorithm is reeursively applied to every literal on its right hand side  . When the evaluation of a non-chain rule is completed  , SHDGA connects its lefthand side literal ( called the pivot ) to the initial root using ( in a backward manner ) a series of appropriate chain rules . At this time , all remaining literals in the chain rules are expanded in a fixed order  ( left-to-right )  . 
8 1   2 Deadlock-prone rules are rules in which the order of the expansion of right hand side literals cannot be determined locally  ( i . e . using only information available in this rule ) . 
Since SHDGA traverses the derivation tree hathe fashion described above  , this traversal is neither topdown (' I'D ) , nor bottom-up ( BU ) , nor left-to-right ( LR ) globally , with respect otheentire tree . However , it is LR locally , when the siblings of the semantic head literal are selected for expansion on the righthand side of a chain rule  , or when a non-chain rule is evaluated . 
In fact the overall traversal strategy combines both the TD mode  ( non-chain rule application ) and the BU mode ( backward application of chain rules )  . 
EAA takes a unification grammar ( usually Prolog-coded ) and normalizes it by rewriting certain left recursive rules and altering the order of right hand side nonterminals in other rules  . It reorders literals hathe original grammar ( both locally within each rule , and globally between different rules ) ha such a way that the optimal traversal order is achieved for a given evaluation strategy  ( eg . topdown left-to-righ 0 . This restructuring is done at compile time , so in effect a new executable grammar is produced  . The resulting parser or generator is TD but not LR with respect to the original grammar  , however , the new grammar is evaluated TD and LR(i . e . , using a standard Prolog interpreter) . 
As a part of the node reordering process EAA calculates the minimal sets of essential arguments  ( msea's ) for all literals hathegrammar , which in turn will allow to project an optimal evaluation order  . The optimal evaluation order is achieved by expanding only those literals which are ready at any given moment  , i . e . , those that have at least one of their mseas instantiated  . The following example illustrates the traversal strategies of both algorithms  . The grammar is taken from \[ SNMP 90\] , and normalized to remove deadlock-prone rules in order to simplify the exposition ?  ( 0 ) sentence/deel ( S ) --> s ( f'mite ) /S . 
(1) sentence/imp(S)-->vp(nonfmite , \[np(_)/you\])


(2) s(Form)/S->Subj , vp(Form,\[Subj/S.

(3) v p(Form , Subcat)/S-->v(Form , Z)/S , vpl(Form , Z)/Subcat . 
(4) vpl ( Form , \[Compl\[Z\])/Ar-->vpl(Form , Z)/Ar , 

(5) vpl(Form , Ar)/Ar.
(6) v p(Form , \[Subj\])/S-->v(Form , \[ Subj\])/VP , anx ( Form , \[ Subj\] , VP)/S . 
(7) an x(Form ,\[ Subjl , S)/S.
(8) aux ( Form , \[Subjl , A)/Z-->adv(A)/B , aux ( Form\[Subj\] , B)/Z . 

(9) v ( finite , \[np(_)/O , np(3-sing)lS\])llove(S , O ) -->\[ loves\] . 
(10) v ( f ' mite , \[ np(_)/O , p/up , np(3-sing)/S\])/ call_up(S , O ) -->\[ calls\] . 
(11) v ( fmite , \[ np(3-sing)/S\])/leave(S)-->\[leaves\] . 
.....?(12) np(3-sing)/john-->\[john\].
(13) np(3-pl)/friends-->\[friends\].
(14) adv(VP)/often(VP)-->\[often\].
The analysis tree for both algorithms i presented on the next page  . ( Figure 1 . ) . The input semantics i given as decl ( call_up ~ ohn friends ) ) . The output string becomes john calls up friends . The difference lists for each step are also provided  . They are separated from the rest of the predicate by the symbol I-The different orders in which the two algorithms expand the branches of the derivation tree and generate the terminal nodes are marked  , haitalics for SHDGA , and in roman case for EAA . The rules that were applied at each level are also given  . 
If EAA is rerun for alternative solutions , it will produce the same output string , but the order in which nodes vpl ( finite , \[p/up , np(3-sing)/john\])/\[Subj\]/Sl_S2 , and np ( . .)/~ends/S2__l \] ( level 4) , and also , vp1 ( finite , \[np(3-sing)/john\])/\[Subj\]/S1_S12 , and p/up/S12_S2 , at the level below , are visited , will be reversed . This happens because both literals in both pairs are ready for the expansion at the moment when the selection is to be made  . Note that the traversal made by SHDGA and the first traversal taken by EAA actually generate the terminal nodes hathesame order  . This property is formally defined below . 
Definition . Two traversals T ' and T " of a tree T are said to be the same-to-a-subtree  ( stas )  , if the follow-hag claim holds : Let N be any node of the tree T  , and S ~ . . . . . S all subtrees rooted at N . If the order in which the subtrees will be taken on for the traversal by T ' is S ?  . . . . . S . n and by T " S . t . . . . . S . ", then SJ = SJ . . . . . S . "=S . " . 
ss . 1 Jl . Itj ( S~is one of the subtrees rooted at N , for any k , and 1 ) Stasho we ver does not imply that the order in which the nodes are visited will necessarily be the same  . 
3 EAA eliminates such rules using lobal node reordering  ( \[$91\] )  . 
82 sentence/decl(call . _up 0 ohn , frieds )) IString_\[ls(ftnite)/callup(john , friends ) I String . _\[\]
SubJl String_SOn pO-slng ) /john I String_SOnp ( 3-sing ) /john I Uohnl S0 LS 010/Rule ( 12 ) john/VIV q ) (rmJte , ISubjl)/caUup(john , trien ~) IS0_\[\]v(finite , Z)/call_up0ohn , friends ) ISOSIvpl(nnlte , Z)/lSubjlISl\[1v(finite , \[ np()/friends , p/up , np(3-~ng)/john\])/vpl(finite , \[ npO/friends , p/up , n(3-sing)/john\])/i~t\]l_up(john , friends ) Il calls \[ SII . _Sl\[SubjllSl_ . \[\]
SRule(lO)callsvpl(finite , \[ p/up , ni ) (3-singJIjohn\])/\[Subj\]IIS 2
II $ 6RU le (4) vpl(flnite , \[ np(3-sing)/john)/\[Subj\]\[SI . _S 12 p/uplSl2_S2 lo/upll ~ l~l_S 247 RU le ( S ) 6Isv'pl ( fln~ , \[ np(3-slng)/john\])/\[np(3-si~ljohn\]lSl_Sl
Hup U
Rule ~0)
Rule (1)

Sule ~ up ( _ ) / rr ~ lS2_\[lnp ( 3-pl ) /frlends l\[~lIll 819 Rule ( 13 )   11I friends III FIGURE 1: EAA's and SHDGA's Traversals of An Analysis Tree . 
3. GENERALITY-WISE SUPERIORITYOF
EAAOVERSHDGA
The traversals by SHDGA and EAA as marked on the graph are stas  . This means that the order in which the terminals were produced  ( the leaves were visited ) is the same ( in this case : calls up friends john )  . As noted previously , EAA can make other traversals to produce the same output string  , and the order in which the terminals are generated will be different in each case  . 
(This should not be confused with the order of the terminals in the output string  , which is always the same ) . 
The orders in which terminals are generated during alternative EAA traversals are : up calls friends john  , friends calls up john , friends up calls john . In general , EAA can be forced to make a traversal corresponding to any permutation of ready literals in the right hand side of a rule  . 
We should notice that in the above example SHDGA happened to make all the right moves  , i . e . , it always expanded a literal whose msea happened to be instantiated  . As we will see in the following sections , this will not always be the case for SHDGA and will become a source of serious efficiency problems  . On the other hand , whenever SHDGA indeed follows an optimal traversal  , EAA will have a traversal that is same-to-a -subtree with it  . 
The previous discussion can be summarized by the next theorem  . 

Theorem : If the SHDGA , at each particular step during its implicit traversal of the analysis tree  , visits only the vertices representing literals that have at least one of their sets of essential arguments instantiated at the moment of the visit  , then the traversal taken by the SHDGA is the same -to-a-subtree  ( stas ) as one of the traversals taken by EAA . 
The claim of the theorem is an immediate consequence of two facts  . The first is that the EAA always selects for the expansion one of the literals with a msea currently instantiated  . The other is the definition of traversals being same-to-a-subtree  ( always choosing the same subtree for the next traversal  )  . 
The following simple extract from a grammar , defining a wh-question , illustrates the forementioned ( see
Figure 2 . below): .   .   .   .   .   .   .   .   . ? (1) wh ques/WhSem-->wh subj(Num)/WhSubj , whpred(Num , Tense , \[ Wh Subj , WhObj \]) / WhSem , whobj/WhObj . 
o . o . . . . . .
.  .   .   .   .   .   .  ,  . ? (2) wh subj(_ . )/ who-->\[who\] . 
(3) wh subj (__)/ what-->\[what\].
??  .   .   .   .   .   .   , ? (4) wh pred(sing , perf , \[ Subj , Obj\])/wrote(Subj , Obj)->\[wrote\] . 
...?.,,,?,(5) whobj/this-->\[this\].
?? oo , ooo ??
The input semantics for this example is wrote ( who , this ) , and the output string who wrote this . 
The numbering for the edges taken by the SHDGA is given in italics  , and for the EAA in roman case . Both algorithm ~ expand the middle subtree first , then the left , and finally the right one . 
Each of the three subtrees has only one path , therefore the choices of their subtrees are unique  , and therefore both algorithms agree on that , too . However , the way they actually traverse these subtrees i different  . 
For example , the middle subtree is traversed bottom-up by SHDGA and topdown by EAA  . wh pred is expanded first by SI-IDGA ( because it shares the semantics with the root , and there is an applicable non-chain rule ) , and also by EAA ( because it is the only literal on the right hand side of the rule  ( 1 ) that has one of its msea's instantiated ( its semantics ) ) . 
After the middle subtree is completely expanded , both sibling literals for the whpred have their semantics instantiated and thus they are both ready for expansion  . 
We must note that SHDGA will always electhe leftmost literal  ( in this case , whsubj ) , whether it is ready or not . EAA will selec the same in the first pass , but it will expand whobj first , and then wh subj , if we force a second pass . In the first pass , the terminals are generated in the order wrote who this  , while in the second pass the order is wrote this who  . The first traversal for EAA , and the only one for SHDGA are same-to-a-subtree . 
4. EFFICIENCY-WISE SUPERIORITYOF
EAAOVERSHDGA
The following example is a simplified fragment of a parser-oriented grammar for yes or no questions  . Using this fragment we will illustrate some deficiencies of 

o . ? o . o o o . .
(1) sentence/ques(askif(S )) --> yes noq/askif(S).
(2i " ye's'noq/asldf(S ) --> aux verb(Num , Pers , Form)/Aux , subj(Num , Pers)/Subj , main verb ( Form , \[ Subj , Obj\])/V erb , obj(_ , J/Obj , adj ( \[ Verb\])/S . 
wb,p~wr~e(wko . a , ~)\[ Q , m_U whs ~ bj ( Num)/WhSJjl(~ , esRI whpred(Num , Form , \[ Wh Subj , Wh Obj D/w role ( who , this ) IR IR2 wl ~ bj/Wh Obj I~_11   1   2 wrote 1 I 3   3   ~4   4 w ~ thh
Hll~ill ! I!~TJ , t * O ) su  ~ 4er3   1 II ~" 11 FIGURE 2: EAA's and SHDGA's STAST raversals of Who Question 's Analysis Tree  . 
84(3) aux verb ( sing , one , pres__perf)/laave(pres__perf , sing ) -->\[ have \] . 
(4) aux_verb ( sing , one , pres_cont)/be(pres_cont , sing-l)-->\[am\] . 
(5) aux verb ( sing , one , pres)/do(pres , sing-1)-->\[do\] . 
(6) aux_verb ( sing , two , pres)/do(pres , sing-2)-->\[do\] . 
(7) aux_verb ( sing , three , pres)/do(pres , sing-3)-->\[does\] . 
(8) aux_verb(pl , one , pres)/do(pres , pl-1)-->\[do\] . 
(9) subj(Num , Pers)/Subj-->np(Num , Pers , su)/Subj . 
(10) obj(Num , Pers)/Obj-->np(Num , Pers,ob)/Obj.
(11) np(Num , Pers , Case)/NP-->noun(Num , Pers , Case)/NP . 
(12) np(Num , Pers , Case)/NP-->p noun(Num , Pers , Case)/NP . 
(13) pnoun(sing , two , su)/you-->\[you\].
(14) pnoun(sing , three , ob)/him-->\[him\].
(15) main_verb(pres , \[Subj , Obj\])/see(Subj , Obj)-->\[see\] . 
(15 a ) main_verb(pres__perf , \[ Subj , Obj\])/seen(Subj , Obj)-->\[seen\] . 
(15b ) main verb ( perf , \[ Subj , Obj\])/ saw(Subj , Oj ) -->\[ saw\] . 
(16) adj(\[Verb\])/often(Verb)-->\[often\].
The analysis tree ( given on Figure 3 . ) for the input semantics ques ( ask if ( often ( see ( you , him )   )   )   )   ( the output string being do you see him often ) is presented below . 
Both algorithms start with the rule (1) . SHDGA selects ( 1 ) because it has the lefthand side nonterminal with the same semantics as the root  , and it is a non-chain rule . EAA selects ( 1 ) because its lefthand side unifies with the initial query  ( -?- sentence ( OutString__G ) /ques ( askif ( often ( see ( you , him )))) . 
Next , rule(2) is selected by both algorithms . Again , by SHDGA , because it has the lefthand side nonterminal with the same semantics as the current root  ( yes noq/ask if . . . ) , and it is a non-chain rule ; and by EAA , because the yesnoq/ask if . . , is the only nonterminal on the righthand side of the previously chosen rule and it has an instantiated msea  ( its semantics )  . The crucial difference takes place when the right hand side of rule  ( 2 ) is processed . EAA deterministically selects adj for expansion , because it is the only rhsliteral with an instantiated msea's  . As a result of expanding adj , the main verb semantics becomes instantiated , and therefore main__verb is the next literal selected for expansion  . After processing of main_verb is completed , Subject , Object , and Tense variables are instantiated , so that both subj and obj become ready . Also , the tense argument for aux_verb is instantiated ( Form in rule ( 2 ) ) . After subj , sentee ~ e/ques(askifl often ( see ( yoo , him ) ) ) ) \] String_\[\] ' I 1 yesnoqlaskiffonenlsee ( you , him )))\[ String_\[\]
Ru ~( z)
Ruleaux_verb(sing , two , pres)/do ( pres , sing-2)\[IdolROI_R0
Rule(o ) 113 do
V1s obj ( sing , two)/main_verb(pres , \[ you , him \]) / obj(sing , three ) you I\[youlRl\]RI see(you , him ) \]\[ see\[R2\]_R2him\[\[him\]R3\]_R3
Role (9) Rule (15) Rule (10) 5647810 np(sing , two , su)/seen p(sing , three , ob ) / you I\[you IRI \]_RI 1I   II1 him I\[him\[ R3\]_R3 
Rule . z )\ [ Rule(l , ) I 6599 p noun(sing , two , su)/p noun(slng , three , ob ) / you I\[you\[RI\]RIhiml\[himIR3LR3
Rule ( 13 ) \] Rule ( 14 ) I74108 you himll I//IV/V adj ( \[see ( you , him )\])/ often ( see ( you , him )) I\[one ~ I\[ILl
Rule (16) I311 often
IV
FIGURE 3: EAA's and SHDGA's Traversals of If Question's Analysis Tree  . 
85 and obj are expanded ( in any order ) , Num , and Pers for aux_verb are bound , and finally aux_verb is ready , too . 
In contrast , the SHDGA will proceed by selecting the leftmost literal  ( aux verb ( Num , Pers , Form )/ Aux ) of the rule (2) . At this moment , none of its arguments i instantiated and any attempt to unify with an auxiliary verb in a lexicon will succeed  . Suppose then that have is returned and unified with aux_verb with pres  . _perfas Tense and sing_lasNumber . This restricts further choices of subj and main_verb  . However , obj will still be completely randomly chosen , and then adj will reject all previous choices . The decision for rejecting them will come when the literal adj is expanded  , because its semantics is often ( see ( you , him )) as inherited from yes no q , but it does not match the previous choices for aux_verb  , subj , main_verb , and obj . Thus we are forced to backtrack repeatedly , and it may be a while before the correct choices are made  . 
In fact the same problem will occur whenever SHDGA selects a rule for expansion such that its leftmost right hand side literal  ( first to be processed ) is not ready . 
Since SHDGA does not check for readiness before expanding a predicate  , other examples similar to the one discussed above can be found easily  . We may also point out that the fragment used in the previous example is extracted from an actual computer grammar for English  ( Sager's String Grammar )  , and therefore , it is not an artificial problem . 
The only way to avoid such problems with SHDGA would be to rewrite the underly in grammar  , so that the choice of the most instantiated literal on the right hand side of a rule is forced  . This could be done by changing rule ( 2 ) in the example above into several rules which use metanon terminals Aux  , Subj , Main_Verb , and Obj in place of literals att x verb , subj , main verb , and obj respectively , as shown below: .   .   .   .   .  ?  .   .   .   . 
yes noq/askif(S)-->askif/S.
ask if/S-->
Aux , Subj , Main Verb , Obj , adj ( \[ Verb\] , \[Aux , S-ubj , Main_Verb , Obj\])IS . 

Since Aux , Subj , Main_Verb , and Obj are uninstantiated variables , we are forced to go directly to adj first . 
After adj is expanded the nonterminals to the left of it will become properly instantiated for expansion  , so in effect heir expansion has been delayed . 
However , this solution seems to put additional burden on the grammar writer  , who need not be aware of the evaluation strategy to be used for its grammar  . 
Both algorithms handle left recursion satisfactorily  . 
SHDGA processes recursive chain rules rules in a constrained bottom-up fashion  , and this also includes dead-lock prone rules . EAA gets rid of left recursive rules during the grammar normalization process that takes place at compile-time  , thus avoiding the runtime overhead . 
5. MULTI-DIRECTIONALITY
Another property of EAA regarded as superior over the SHDGA is its mult-direcfionality  . EAA can be used for parsing as well as for generation  . The algorithm will simply recognize that the top level m sea is now the string  , and will adjus to the new situation . Moreover , EAA can be run in any direction paved by the predicates ' mseas as they become instantiated at the time a rule is taken up for expansion  . 
In contrast , SHDGA can only be guaranteed to work in one direction  , given any particular grammar , although the same architecture can apparently be used for both generation  , \[ SNMP90\] , and parsing , \[ K90\] , \[N89\] . 
The point is that some grammars ( as shown in the example above ) need to be rewritten for parsing or generation , or else they must be constructed in such a ways o as to avoid indeterminacy  . While it is possible to rewrite grammars in a form appropriate for head-first computation  , there are real grammars which will not evaluate fficiently with SHDGA  , even though EAA can handle such grammars with no problems  . 
6. CONCLUSION
In this paper we discussed several aspects of two natural language generation algorithms : SHDGA and EAA  . 
Both algorithms operate under the same general set of conditions  , that is , given a grammar , and a structured representation fmeaning , they attempt to produce one or more corresponding surface strings  , and do so with a minimal possible effort . We analyzed the performance of each algorithm in a few specific situations  , and concluded that EAA is both more general and more efficient algorithm than SHDGA  . Where EAA enforces the optimal traversal of the derivation tree by precomputing all possible orderings for nonterminal expansion  , SHDGA can be guaranteed to display a compa -designed  , and the semantic heads are carefully assigned ( manually )  . With other grammars SHDGA will follow non-optimal generation paths which may lead to extreme in efficiency  . 
In addition , EAA is a truly multidirection all go-rithm , while SHDGA is not , which is a simple consequence of the restricted form of grammar that SHDGA can safely accept  . 
This comparison can be broadened in several directions  . For example , an interesting problem that remains to be worked out is a formal characterization f the grammars for which each of the two generation algorithms is guaranteed to produce a finite and/or optimal search tree  . Moreover , while we showed that SHDGA will work properly only on a subset of EAA's grammars  , there may be legitimate g ~ that neither algorithm can handle  . 
7. ACKNOWLED GEMENTS
This paper is based upon work supported by the Defense Advanced Research Project Agency under Contract  N00014-90-J-1851 from the Office of Naval Research , the National Science Foundation under Grant IRI-89-02304  , and the Canadian Institute for Robotics and Intelligent Systems  ( IRIS )  . 
REFERENCES\[C78\] COLMERAUER,A .  1978 . " Metamor-phosis Grammars . "In Natural Language Communication with Computers  , Edited by L . Bole . Lecture Notes in Computer Science , 63 . Springer-Verlag , New
York , NY , pp . 133-189.
\[ D90 a\]DY MET MAN , M .  1990 . " A Generalized Greibach Normal Form for DCG's . " CCRIT , Laval , Quebec : Ministere des Communications Canada . 
\[ D90 b\]DY MET MAN , M .  1990 . " Left-Re-cursion Elimination , Guiding , and Bi directionality in
Lexical Grammars . " To Appear.
\[DA84\]DAHL , V ., and ABRAMSON , H.
1984 . " On Gapping Grammars . " Proceedings of the Second International Conference on Logic Programming  . Uppsala , Sweden , pp .  77-88 . 
\[ DI88\]DY MET MAN , M ., and ISA BELLE,
P .  1988 . " Reversible Logic Grammars for Machine Translation  . " Proceedings of the 2nd International Conference on Theoretical nd Methodological Issues in Machine Translation of Natural Languages  . Car-negie-Mellon University , Pittsburgh , PA . 
\[ DIP90\] DY MET MAN , M . , ISABELLE , P . , and PERRAULT , F .  1991 . " A Symmetrical Approach to Parsing and Generation  . " Proceedings of the 13th International Conference on Computational Linguistics  ( COLING90 )  . Helsinki , Finland , Vol .  3 . , pp .  90-96 . 
\[GM89\]GAZDAR , G ., and MELLISH , C.
1989 . Natural ? zmguage Processing in Prolog . Addison-
Wesley , Reading , MA.
\[K90\] KAY , M .  1990 . " Head-Driven Parsing . " In M . Tomita ( ed . ) , Current Issues in Parsing Technology , Kluwer Academic Publishers , Dordrecht , the Netherlands . 
\[K84\]KAY , M .  1984 . " Functional Unification Grammar : A Formalism for Machine Translation  . " Proceedings of the lOth International Conference on Computational Linguistics  ( COLING-84 )  . Stanford
University , Stanford , CA ., pp . 75-78.
\[N89\] VANNOORD , G .  1989 . ~ An Overview of Head-Driven Bottom-Up Generation  . " In Proceedings of the Second European Workshop on Natural Language Generation  . Edinburgh , Scotland . 
\[PS90\]PENG , P ., and STRZALKOWSKI , T.
1990 . " An Implementation fA Reversible Grammar . " Proceedings of the 8th Conference of the Catmdian Society for the Computational Studies of Intelligence  ( CSCS 1-90 )  . University of Ottawa , Ottawa , Ontario , pp .  121-127 . 
\[S90 a\]STRZAL KOWSKI , T . 1990." Howto
Invert A Natural Language Parser into An Efficient Generator : An Algorithm for Logic Grammars  . " Proceedings of the 13th International Conference on Computational Linguistics  ( COLING90 )  . Helsinki , Finland,
Vol . 2., pp . 90-96.
\[S90b\]STRZALKOWSKI,T .  1990 . "Revers-ible Logic Grammars for Natural Language Parsing and Generation  . " Computational Intelligence Journal,
Volume 6., pp . 145-171.
87\[$91\] STRZAL KOWSKI , T .  1991 . " A General Computational Method for Grammar Inversion  . " Proceedingsera Workshop Sponsored by the Special Interest Groups on Generation and Parsing of the ACL  . 
Berkeley , CA ., pp . 9199.
\[SNMP89\] SHIEBER , S.M ., VANNOORD,
G . , MOORE , R . C . , and PEREIRA , F . C . N .  1989 . " A Semantic-Head-Driven Geration Algorithm for Uni-fication-Based Formalisms  . " Proceedings of the 27th Meeting of the ACL . Vancouver , B . C . , pp .  717 . 
\[SNMP90\]SHIEBER , S.M ., VANNOORD,
G ., MOORE , R.C ., and PEREIRA , F.C.N . 1990.
" Semantic-Head-Driven Geration . " Computational
Linguistics , Volume 16, Number 1.
\[ W88\]WEDEKIND , J .  1988 . " Generation as Structure Driven Derivation . * Proceedings of the 12th International Conference on Computational Linguistics  ( COL1NG-88 )  . Budapest , Hungary , pp .  732-737 . 

