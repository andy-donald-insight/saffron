Towards a Self-Extending Lexicon *
Uri Zernik
Michael G . Dyer
Artificial Intelligence Laboratory
Computer Science Department
3531 Boelt ~ rHall
University of t Mifomis
Los Angeles , California 90024
Abstract
The problem of manually modifying the lexicon appears with any natural language processing program  . 
Ideally , a program should be able to acquire new lexieal entries from context  , the way people learn . We address the problem of acquiring entire phrases  , specifically Jigurative phr~es , through augmenting a phr ~ a lezico ~ Facilitating such a self-extending lexicon involves  ( a ) disambiguation ~ seection of the intended phrase from a set of matching phrases  ,   ( b ) robust pars in ~- comprehension of partially -matching phrases  , and ( c ) error analysis --- use of errors in forming hypotheses about new phrases  . We have designed and implemented a program called RINA which uses demons to implement funetional- ~rammar principles  . RINA receives new figurative phrases in context and through the application of a sequence of failure-driven rules  , creates and refines both the patterns and the concepts which hold syntactic and semantic information about phrases  . 
David vs . Goliath







Remember the s~ory of David and Goliath ?
David took on Goliath.
David took Golt Lthsons , here ?
No . David took on Goliath.
He took on him . Heyon the fight ?
No . He took him on.
David attacked him.
He ~ okhimon.
He accepted She challenge ?



Hereinannt , her story.
John took on the third exam question.
He took on a hard problem.
Another dialogue involves put one's foot do ~- a . Again , the phrase is unknown while its constituents are known : 
Going Punk 1. Introduction
A language understanding program should be able to acquire new lexical items from context  , forming for novel phrases their linguistic patterns and figuring out their conceptual meanings  . The lexicon of a learning program should satisfy three requirements : Each lexical entry should  ( 1 ) be learnable , (2) facilitate conceptual analysis , and (3) facilitate generation . In this paper we focus on the first two aspects . 
1.1 The Task Domain
Two examples , which will be used throughout his paper , are given below . In the first dialogue the learner is introduced to an unknown phrase : take on  . The words take and on are familiar to the learner  , who also remembers the biblical story of David and Goliath  . The program , modeling a language learner , interacts with a native speaker , as follows : * This work w~s made possible in part by sgrant from the Keck 





Jennyvant , ed ~ ogo punk , but , her father put , histoot dovu . 
He moved his footd or a ?
It , doennot , mike sense.
No . He put his foot , dora.
He put his foot dovu.
He refused to lether go punk.
A figurative phrase such as put one's foocdown is a linguistic pattern whose associated meaning cannot be produced from the composition of its constituents  . 
Indeed , an interpretation of the phrasebased on the meanings of its constituents often exists  , but it carries a different meaning . The fact that this literal interpretation of the figurative phrase exists is a misleading clue in learning  . Furthermore , the learner may not even notice that a novel phrase has been introduced sinces he is fam-iliar with dram as well as with foot  . Becker\[ Becker?5\] has described a space of phrases ranging in generality from fixed proverbs such as charity begsns at  , home through idioms such as Xay dovet , hetar and phrasal verbs such as put , uprich one's spouse and look up the name , to literal verb phrases such as sit , on she chair . 
He suggested employing a phrasa lexicon to capture this entire range o  ( language structures . 
284 1.2 Issues in Phrase Aequ Lsition
Three issues must be addressed when learning phrases in context  . 
( I ) Detecting failures : What are the indications that the initial interpretation of the phrase take himon as " to take a person to a location " is incorrect ? Since all the words in the sentence are known  , the problem is detected both as a conceptual discrepancy  ( why would he take his ene my anywhere ? ) and as a syntactic failure ( the expected location of the assunied physical transfer is missing  )  . 
(2 ) Determining scope and generality of patterns : The linguistic pattern of a phrase may be perceived by the learner at various levels of general it ~ l  . For example , in the second dialogue , incorrect generalizations could yield patterns accepting sentence such as : Her boss put his left foot down  . 
He moved his foot dora.
He put down his foot .
He put dovn his leg.

A decision is also required about the scope of the pattern  ( i . e . , the tokens included in the pattern ) . 
For instance , the scope of the pattern in John put up with Mary could be  ( I ) ? x : per soaput : verb up where with is associated with l'lmry or  ( 2 ) ? x : persos put : verb up with ? y : persou , where with is associated with put up . 
Finding appropriate meanings : The conceptual meaning of the phrase must be extracted from the context which contains many concepts  , both appropriate and inappropriate for hypothesis formation  . Thus there must be strategies for focusing on appropriat elements in the context  . 
1.3 The Program
RINA\[ Dyer85\] is a computer program designed to learn English phrases  . It takes as input English sentences which may include unknown phrases and conveys as output its hypotheses about novel phrases  . The pro~am consists of four components : ( l ) Phrasal lexicon : This is a list of phrases where each phrase is a declarative pattern-concept air \[ Wilensky Sl\]  . 
(2) Case frame parser : In the parsing process , case frame expectations are handled by spawning demons\[  Dyer83\]  . The parser detects comprehension failures which are used in learning  . 
(3 ) Pattern Constructor : Learning of phrase patterns is accomplished by analyzing parsing failures  . Each failure situation is associated with a pattern-modification action  . 
(4 ) Concept Constructor : Learning of phrase concepts is accomplished by a set of strategies which are selected according to the context  . 
Schematically , the program receives a sequence of sentence /contezt pairs from which it refines its current pattern/concept air  . The pattern is derived from the sentence and the concept is derived from the coL text  . 
However , the two processes are not independent since the context influences construction of patterns while linguistic clues in the sentence influence formation of concepts  . 
2 . Phrasal Representation of the Lexicon Parsing in RINA is central since learning is evaluated in terms of parsing ability before and after phrases are acquired  . Moreover , learning is accomplished through parsing . 
2.1 The Background
RINA combines elements of the following two approaches to language processing : Phra~-bued pattern matching : In the implementation of UC\ [   Wilensky84\]  , an intelligent help system for UNIX users , both PHRAN\[AJ'ens82 l , the conceptual analyzer , and PHRED\[Jacobs85\] the generator , shareaphrasallepton . As outlined by Wilensky Wilensky81\] this lexicon provides a declarative database , being modu-larly separated from the control part of the system which carries out parsing and generation  . This development in representation of linguistic knowledge is paralleled by theories of functional grammars  Kay79\[  , and lezical-functional grammars \[ Bresnan 78\] . 
Ca~ , -b , ,- , ,ed demon pmming : Boris \[ DyerS3 I modeled reading and understanding stories in depth  . Its conceptual analyzer employed demon-based templates for parsing and for generation  . Demons are used in parsing for two purposes : ( 1 ) to implement syntactic and semantic expectations \[   Riesbeck74\] and ( 2 ) to implement memory operation such as search , match and update . 
This approach implements Schank's\[ Schank77\] theory of representation of concepts , and follows case-grammar\[ Fillmore681 principles . 
RINA uses a declarative phrasal lexicon as suggested by Wilensky\[  Wilensky82\]  , where a lexical phrase is a pattern-concept pair . The pattern notation is described below and the concept notation is Dyer's\[  Dyer83\] i-link notation . 
285 2.2 The Pattern Notation
To span English sentences , RINA uses two kinds of patterns : lezical patterns and ordering patterns\[  Arens82\]  . In Figure I we show sample lexical patterns ( patterns of lexical phrases )  . Such patterns are viewed as the generic linguistic forms of their corresponding phrases  . 
I . ? x : ( animate . a ~ ent ) nibble:verb < on?y:food > 2 . ? z : C pernou . Lgent ) tLke:verb on ? y:p , tlent3 . ? x : ( person . a~ent ) < put:verbfoot:body-part do ~ m >
Figure h The Pattern Notation
The notation is explained below : ( t ) A token is a literal unless otherwise specified . For example , on is a literal in the patterns above . 
(2) ? x : sort denotes a variable called . ~ x of a semantic types or t . ? y : food above is a variable which stands for references to objects of the semantic lass food  . 
(3) Act . verb denotes any form of the verbs ! lntactic class with the root act  .   nibble:vet6 above stands for expression such as : nibbled , hms never nibbled , etc . 
(4) By default , a pattern sequence does not specify the order of its tokens  . 
(5 ) Tokens delimited by < and > are restricted to their specified order  . In Pattern I above , on must directly precede ? y : food . 
Ordering patterns pertain to language word-order conventions in general  . Some sample ordering patterns are : active : < ? x : agenr  . ? y : ( verb . ~tive ) > passive : < ? x : pattent ? y : ( verb . p~, . s?ve ) >*< by ? Z : agent > infinitive : < to ? x : verb . active > " ? y:Iq~ent
Figure 2: Ordering Patterns
The additional notation introduced here is : ( 6 ) An * preceding a term , such as *< by ? z : ~ ent > in the first pattern above indicates that the term is optional  . 
(7)* denotes an omitted term . The concept for Ty in the third example above is extracted from the agent of the pattern including the current pattern  . 
(8) By convention , the agent is the case frame which precedes the verb in the lexical pattern  . Notice that the notion of agent is necessary since  ( a ) the agent is not necessarily the subject ( i . e . , she vu taken ) and b ) the agent is not necessarily the actor i . e . , she rece ived the book , he took ablo ~) , and ( c ) in the infinitive form , the agent must be referred to since the agent is omitted from the pattern in the lexicon  . 
(9 ) Uni/ieation\[ Kay79\] accounts for the interaction of lexical patterns with ordering patterns in matching input sentences  . 
So far , we have given a declarative definition of our grammar  , a definition which is neutral with respect to either parsing or generation  . The parsing procedure which is derived from the definitions above still has to be given  . 
2.3 Parsing Objectives
Three main tasks in phrasal parsing may be identified  , ordered by degree of difficulty . 
(1 ) Phrased laambiguation : When more than one lexi -cat phrase matches the input sentence  , the parser must select the phrase intended by the speaker  . For example , the input the vorker u took to the streets could mean either " they demonstrated " or " they were fond of the streets '  . In this case , the first phrase is selected according to the principle of pattern speci\]icit  9  \[  Arens821  . The pattern ? X:person taXe:verb < to the streets > is more specific then ? x : person take : verb < to?y:thing > However  , in terms of our pattern notation , how do we define pattern specificity ?2 ) Ill-formed input comprehension : Even when an input sentence is not well phrased according to textbook grammar  , it may be comprehensible by people and so must be comprehensible to the parser  . For example , John took Nary school is telegraphic , but comprehensible , while John took Nzry to conveys only a partial concept  . Partially matching sentences ( or " near misses ' ) are not handled well by syntax-driven pattern mate hers  . A deviation in a function word ( such as the word to above ) might inhibit the detection of the phrase which could be detected by a semantics-driven parser  . 
(3 ) Error-detection : when the hypothesized phrase does not match the input sentence/context pair  , the parser is required to detect the failure and return with an indication of its nature  . Error analysis requires that pattern tokens be assigned a case-significance  , as shown in Section 4 . 
Compounding requirements -- disambiguation plus error-analysis capability -- complicate the design of the parser  . On one hand , analysis of " near misses " ( they bury a hatchet instead of they buried the hatchet  ) can presence of a single phrase only . On the other hand , in the presence of multiple candidate phrases , disambigua-finn could be made efficient by organizing sequences of pattern tokens into a discrimination net  . However , attempting to perform both disambiguation and " near miss " recognition and analysis simultaneously presents a difficult problem  . The discrimination netorganization would not enable comparing the input sentence  , the " near miss " , with existing phrases . 
The solution is to organize the discrimination sequence by order of generality from the general to the specific  . According to this principle , verb phrases are matched by conceptual features first and by syntactic features only later on  . For example , consider three initial erroneous hypotheses : ( a ) bury a hatchet ( b ) bury the gun , and ( c ) bury the hash . On hearing the words " bury the hatchet ' , the first hypothesis would be the easiest to analyze  ( it differs only by a function word while the second differs by a content-holding word  ) and the third one would be the hardest ( as opposed to the second , huh does not have a common concept with hlttchet ) . 
2.4 Case-Frames
Since these requirements are not facilitated by the representation of patterns as given above  , we slightly modify our view of patterns . An entire pattern is constructed from a set of case-/tames where each case frame is constructed of single tokens : words and concepts  . 
Each frame has several slots containing information about the case and pertaining to:  ( a ) its syntactic appearance ( b ) its semantic oncept and ( c ) its phrase role : agent , patient . Variable identifiers ( e . g . , ? x . ? y ) are used for unification of phrase patterns with their corresponding phrase concepts  . Two example patterns are given below : The first example pattern denotes a simple literal verb phrase : id : ? x class : person role : agent  ( take : verb )   ( id : ? y class : person role : patient id : ? z class : location marker : to Figure  3: CueFrmmes for " He took her to school " Both the agent and the patient are of the class person  ; the indirect object is a location marked by the preposition co  . The second phrase is figurative : id : ? x class : person role : agent  ) take : verb ( marker : to determiner : the word : streets Figure 4: Case Frames for " He took to the streets " The third case frame in Figure  4 above , the indirect object , does not have any corresponding concept . Rather it is represented as a sequence of words . However the words in the sequence are designated as the marker  , the determiner and the word itself . 
Using this view of patterns enables the recognition of " near misses " and facilitate rror-analysis n parsing  . 
3. Demons Make Patterns Operational
So far , we have described only the linguistic notation and indicated that unification \[  Kay79\] accounts for production of sentences from patterns  . However , it is not obvious how to make pattern unification operational in parsing  . One approach \ [ Arens82\] is to generate word sequences and to compare generated sequences with the input sentence  . Another approach IPereiraS01 is to implement unification using PROLOG . Since our task is to provide lenient parsing , namely also ill-formed sentences must be handled by the parser  , these two approaches are not suitable . In our approach , parsing is carried out by converting patterns into demons  . 
Conceptual analysis is the process which involves reading input words left to right  , matching them with existing linguistic patterns and instantiating or modifying in memory the associated conceptual meanings  . For example , assume that these are the phrases for take : in the lexicon : ? x:person take:verb?y:person?z :locale 
John took her to Boston.
? x : person take : verb ? y : phys-obj
He took the book.
? x : person take : verb off ? y : attire
He took off his coaL.
? x : person take:verb on ? y:person
David took on Goliath.
? x : person take : verb a bow
The actor took a boy.
? x : thing take : verb a blow
The vail took a blov.
? x : person take : verb ~ to the streets ~
The vorker n~okt , othestreets.
The juvenile took t , othee ~ ree Cs.
Figure 5: A Variety of Phrases for TAKE where variables ? x  , : y and ? z also appear in correspond-in & concepts  ( not shown here )  . How are these patterns 3 . 1 Interact ion of Lexlcal and Order ing Pat terns Token order in the lexical patterns themselves  ( Figure 5 ) supports the derivation of simple active-voice sentences only  . Sentences such as:
Msryvas ~, zken on by John.
Aveak contender David might , have left , alone , bu ~ Goliath he book on . 
David dec?ded to take on Gol'tath.
Figure 6: A Variety of Word Orders cannot be derived directly by the given hxical patterns  . 
These sentences deviate from the order given by the corresponding lexical patterns and require interaction with language convention such as passive voice and infinitive  . Ordering patterns are used to span a wider range of sentences in the language  . Ordering patterns such as the one's given in Figure  2 depict the word order involving verb phrases . In each pattern the case frame preceding the verb is specified  . ( In active voice , the agent appear simediately before the verb , while in the passive it is the patient hat precedes the verb  . ) 3 . 2 How Does It All Work ? Ordering patterns are compiled into demons  . For example , DAGENT , the demonanticipating the agent of the phrase is generated by the patterns in Figure  2  . rt has three clauses :
If the verb is in active form then the agent is immediately be/ore the verb 
If the verb is in passive form then the agent may appear  , preceded by by . 
If the verb is in infinitive then the agent is omitted  . 
Its concept is obtained from the function verb.
Figure T : The Conatruction of D_AGENT
In parsing , this demon is spawned when a verb is encountered . For example , consider the process in parsing the sentence Da . v~ . dec ' ideal ~ bakeon ~, o\] . ?ath . 
Through identifying the verbs and their forms , the pro-tess is : decided ( active , simple ) Search for the agent before the verb , anticipate an infinitive form . 
talc , ( active , infinitive )
Do not anticipate the agent . The actor of the " take on " concept which is the agent  , is extracted from the agent of " decide ' . 
4 . Failure-Driven Pattern Construction Learning of phrases in RINA is an iterative pro-tess  . The input is a sequence of sentence-context pairs  , through which the program refines its current hypothesis about the new phrase  . The hypothesis pertains to both the pattern and the concept of the phrase  . 
4.2 The Learning Cycle
The basic cycle in the process is: ( a ) A sentence is parsed on the background of a conceptual context  . 
( b ) Using the current hypothesis , either the sentence is comprehended smoothly , or a failure is detected . 
( c ) If a failure is detected then the current hypothesis is updated  . 
The crucial point in this scheme is to obtain from the parser an intelligible analysis of failures  . As an example , consider this part of the first dialog : . 
1 Program : tie took on him . Hevon ~ he fight ? 2User : . No . He took him on . Dav '\[ dLt , ta , cked him . 
3 Program : He took him on.
He accepted the challenge ?
The first hypothesis i shown in Figure 8.
pattern : concept : ? x:person take:verb don?y : person ~ ? x w in the conflict with ? y 
Figure 8: First Hypothesis
Notice that the preposition on is attached to the object ? y  , thus assuming that the phrase is similar to He looked at  Iqaar7 which cannot produce the following sentence : H . 
look . dher at . This hypothesis underlies Sentence 1 which is erroneous in both its form and its meaning  . 
Two observations should be made by comparing this pattern to Sentence  2: The object is not preceded by the preposition on . 
The preposition on does not precede any object.
These comments direct the construction of the new hypothesis : concept : ? x:person take:verbon ? y : person ? x w in the conflict with ? y 
Figure 9: Second Hypothesis where the preposition on is taken as a modifier of the verb itself  , thus correctly generating Sentence 3 . In Figure 9 the conceptual hypothesis is still incorrect and must itself be modified  . 
4.3 Learning Strategies
A subset of RINA's learning strategies , the ones used for the David and Oolia Ch Dialog ( Section 1 . 1) are described in this section . In our exposition of failures and actions we will illustrate the situations involved in the dialogues above  , where each situation is specified by the following five ingredients :  ( 1 ) the input sentence ( Sentence )  , (2) the context ( not shown explicitly here ) ,   ( 3 the active pattern : either the pattern under construction  , or the best matching pattern if this is the first sentence in the dialogue  ( Patternl )   . 
(4 ) the failures detected in the current situation ( Failures )  ,   ( 5 ) the pattern resulting from the application of the action to the current pattern  ( Pattern 2 )  . 
Creating a New Phrase
A case . role mismatch occurs when the input sentence can only be partially matched by the active pattern  . A 9oal mismatch occurs when the concept instan-tinted by the selected pattern does not match the goals i -tuation in the context  . 

Patternt :


David took on Goliath.
? x:person take:verb?y:person?z:location
Pattern and goal mismatch ? x : person take : verb David's physically transferring Goliath to a location fails since  1  ) alocation is not found and ( 2 ) the action does not match David's goals . If these two failures are encountered , then a new phrase is created . In absence of a better alternative , RINA initially generates
David Cookhim some vhere.
Discriminating a Pattern by Freezing a Prepoab tional Phrase Ap repoMtional mismatch occurs when a preposition P matches in neither the active pattern nor in one of the lexical prepositional phrases  , such as : < on ? x : platform > ( indicating a spatial relation ) < on ? x:time-unit > ( indicating a time of action ) < on ? x : location > ( indicating a place ) 

Patternl :


David took on Goliath.
? x : person take : verb
Prepositional mismatch ? x : person take : verb < on ? y : person > The preposition on is not part of the active pattern  . Neither does it match any of the prepositional phrases which currently exist for on  . Therefore , since it cannot be interpreted in any other way , the ordering of the subexpression < on ? y , : peraoa > is frozen in the larger pattern , using < and > . 
Two-word verbs present a di~culty to language learners\[  Ulm75\] who tend to ignore the separated verb-particle form  , generating : take on him instead of cake himo , s . In the situation above , the learner produced this typical error . 
Relaxing an Under generalized Pattern
Two failures involving on : ( 1 ) case-role mismatch ( on ? y : p , r6 o a is not found ) and ( 2 ) prepositional mismatch ( on appears unmatched at the end of the sentence ) are encountered in the situation below :




David took him on.
? x : person take : verb < on ? y ' person
Prepositional and case-role mismatch.
? x : person take:verb on ? y:person
The combination of these two failures indicate that the pattern is too restrictive  . Therefore , the < and > freezing delimiters are removed , and the pattern may now account for two-word verbs  . In this case on can be separated from ?, & ke . 
Generaiising a Semantic Restriction A semantic mismatch is marked when the semantic class of a variable in the pattern does not subsume the class of the corresponding concept in the sentence  . 
Sentence:
Patternt :


John took on the third question.
? x : person take:verb on ? y:person
Semantic mismatch ? x : person take : verb on ? y : task As a result  , the type of ? y in the pattern is generalized to include both cases  . 

Freezing a Reference Which Relates to a Metaphor An unrelated reference is marked when a reference in the sentence does not relate to the context  , but rather it relates to a metaphor ( see elaboration in \[ Zernik85\] )  . 
The reference h is fooc cannot be resolved in the context  , rather it is resolved by a metaphoric gesture . 


Failures :
Pattern 2:
Her father put his foot down.
? x : person put : verb down ? y : phys-obj
Goal mismatch and unrelated reference ? x : person put : verb downfoot : body-partSince  ,   ( I ) putting his foot on the floor does not match any of the goals of Jenny's father and  ( 2 ) the reference his foot is related to the domain of metaphor-icgestures rather than to the context  . Therefore , foot becomes frozen in the pattern . This method is similar to a method suggested by Fuss and Wilks\[  Fuss83\]  . In their method , a metaphor is analyzed when an apparently ill -formed input is detected  , e . g . : the card rankffilot of gas . 
4.4 Concept Constructor
Each pattern has an associated concept which is specified using Dyer's\[  Dyer83\] i-link notation . The concept of a new phrase is extracted from the context  , which may contain more than one element . For example , in the first dialogue above , the given context contains some salients to W points\[  Wilensky82\] which are indexed in episodic memory as two violated expectations : ? David w on the fight in spite of Goliath's physical superiority  . 
? David accepted the challenge in spite of the risk involved  . 
The program extracts meanings from the given set of points  . Concept hypothesis construction is further discussed in \[  Zernik85\]  . 
5 . Previous Work in Language Learning In RINA , the stimulus for learning is comprehension failure  . In previous models language learning was , ~ lsodriven by detection of failures . 
PST\[ Reeker76\] learned grammar by acting upon dilfer cnces detected between the input sentence and internally generated sentences  . Six types of differences were classified , and the detection of a difference which belonged to a class caused the associated alteration of the grammar  . 
FOUL-UP\[ Granger771 learned meanings of single words when an unknown word was encountered  . The meaning was extracted from the script\[ Schank77\] which was given as the context . A typical learning situation was The cf firvas driving on Hvy  66  , vhen it care ened off the road . The meaning of the unknown verb care . ned was guessed from the SACCIDENT script . 
POLITICS\[CarbonellTO\] , which modeled comprehension of text involving political concepts  , initiated learning when semantic on straints were violated  . 
Constraints were generalized by analyzing underlying metaphors  . 
AMBER\[ Langley82\] modeled learning of basic sentence structure . The process of learning was directed by mismatches between input sentences and sentences generated by the program  . Learning involved recovery from both errors of omission  ( omitting a function word such as theor is in d add y bouncing ball  ) and errors of commission ( producing d add y is liking dinner )  . 
Thus , some programs acquired linguistic patterns and some programs acquired meanings from context  , but none of the above programs acquired new phrases  . Acquisition of phrases involves two parallel processes : the formation of the pattern from the given set of example sentences  , and the construction of the meaning from the context  . These two processes are not independent since the construction of the conceptual meaning utilizes linguistic clues while the selection of pattern elements of new figurative phrases bears on concepts in the context  . 
6. Current and Future Work
Currently , RINA can learn a variety of phrasal verbs and idioms  . For example , RINA implements the behavior of the learner in vf fivtd vs  . c , oliffich and in Go-?ng Punk in Section 1 . Modifications of lexicM entries are driven by analysis of failures  . This analysis is similar to analysis of ill -formed input  , however , detection of failures may result in the augmentation of the lexicon  . Failures appear as semantic discrepancies ( e . g . , goal-plan mismatch , or syntactic discrepancies ( e . g . , case-role mismatch ) . Finally , references in figurative phrases are resolved by metaphor mapping  . 
Currently our efforts are focussed on learning the conceptual elements of phrases  . We attemp to develop strategies for generalizing and refining acquired concepts  . 
For example , it is desirable to refine the concept for " take on " by this sequence of examples : 
David toak on Goliath.
The\[t , kers took on ~ he Celtics.
I took on a , bard ~ ffi , , . k.
I took on a , hey Job.
In selecting ~ henaae ? TQvard 8a . Self-Ez Cending Le Xi COne . Yet , 43 olcOU in old nK me . 

The first three examples " deciding to fight someone '  , " playing against someone " and " accepting a challenge " could be generalized into the same concept  , but the last two examples deviate in their meanings from that developed concept  . The problem is to determine the desired level of generality  . Clearly , the phrases in the following examples : ~ sd ce on a menemy 
Lakeos an old name ~ a ~ e on the shape of a essd ce deserve separatentries in the phrasal lexicon  . The question is , at what stage is the advantage of further generalization diminished ? 

We wish to thank Erik Muelhr and Mike Gasser for their in cisive comments on drafts of this paper  . 
References ArensS2J  \[  Becker75\]  \[  Bresnan78\]  \[  Carbonel179\] 
Areas , Y ., " The Context Model:
Language Understanding in a Context , " in Proceedings Fourth Annual Conference of the Cofnitive Science Society  , Ann Arbor , Michigan (1982 . 
Bucker , Joseph D . , " The Phrasal Lexicon , " pp .   70-73 in Proceedings Interdisciplinary Workshop on Theoretical Is  . 
sues in Natural Lanfaage Processing,
Cambridge , Massachusets ( June 1975).
Bresnan , Joan , " A Realistic Transformational Grammar , " pp . 1-59 in
Linguistic Theory and Psychological
Reality , ed . M . Halle J . Bresnan G.
Miller , MIT Press , Harvard , Massachusets (1978) . 
Carbonell , J . G ., " Towards a Sell'-
Extending Parser , " pp .   37 in Proceedings 17th Annual Meeting of the Association for Computational Linfaistics  , La
Jolla , California (1070).
\[ Dyer83\]\[Dyer8S\]
Dyer , Michael G . , In-Depth Understanding : A Computer Model of Integrated Processing for Narrative 
Comprehension , MIT Press , Cambridge , MA (1983).
Dyer , Michael G . and Uri Zernik , " Parsing Paradignm and Language
Learning , " in Proceedings AI-85, Long
Beach , California ( May 1085).
\ [Fasss3l  \[  Fillmore681  \[  Granger77\]  \[  Jacobs85\]  \[  Kay791  \[  Langley82\[  \[  PereiraS01  \[  Reeker76\]  \[  Riesbeck74\[  \[  Schank77\] 
Fans , Dan and Yorick Wilks , " Preference Semantics , Ilb Formedness and
Metaphor , " American Journal of Computational Linguistics 0 ( 3-4 )  , pp . 178-1s 7 ( zoo ) . 
Fillmore , C ., " The Case for Case , " pp.
l-g0 in Universals in Linguistic Theory , ed . E . Bach R . Harms , Holt , Reinhart and Winston , Chicago (1988) . 
Granger , R . H . , " FOUL-UP : A Program That Figures Out Meanings of 
Words from Context , " pp . 172-178 in
Proceedings Fifth\[JCAI , Cambridge,
Massachusets ( August 1977).
Jaeobs , Paul S . , " PHRED : A Generator for Natural Language Interfaces  , "
UCB/CSD85/108, . Computer Science
Division , University of California
Berkeley , Berkeley , California ( January 1985).
Kay , Martin , " Functional Grammar . " pp .   142-158 in Proceedings 5th Annual Meeting of the Berkeley Linguistic Society  , Berkeley , California (1979) . 
Langley , Pat , " Language Acquisition
Through Error Recovery , " Cognition and Brain Theory ~; (3) , pp . 211-255 I082) . 
Pereira , F . C . N . and David H . D . Warren , " Definite Clause Grammars for
Language Analysis - A Survey of the
Formalism and a Comparison with
Augmented Transition Networks."
Artificial Intelligence 13, pp . 231-278 ( i ~ o).
Reeker , L.H ., " The Computational
Study of Language Learning , " in . Advances in Computers , ed . M . Yovits M . 
Rubinoff , Academic Press , New York (1976).
Riesbeck , C.K ., " Computational
Understanding : Analysis of Sentences and Context , " Memo238 , AILaboratory (1974) . 
Schank , Roger and Robert Abe Lson,
Scripts Plans Goals and Understanding,
Lawrence Erlbaum Associates , Hillsdale , New Jersey (1977) . 
2 91  "   Ulm751  \[  Wilensky81\]  \[  Wilensky82\]  \[  Wilensky84\]  \[  Zernik85\] 
Ulm , Susan C ., " The Separation
Phenomenoni English Phrasal Verbs,
Doubletrouble , "601, University of
California Los Angeles (1975). M.A.

Wilensky , R ., " A Knowledge-Ba~ed
Approach to Natural Language Pro-eessing : . A progress Report , " in Proceedings Seventh International Joint Conference on Artificial Intelligence  , 
Vancouver , Canada (1981).
Wilensky , R ., " Points : A Theory of
Structure of Stories in Memory , " pp.
345-375 in Strategies for Natural
Lanfaage Processing , ed . W.G.
Lehnert M . H . Ringle , Laurence Erl-banm Associates , New Jersey (1982) . 
Wilensky , R . , Y . Arens , and D . Chin , " Talking to UNIX in English : an Overview of UC , " Communications of the
ACM2T (6), pp . 574.-593 ( June 1984).
Zernik , Uri and Michael G . Dyer,
Failure-Driven Aquisition of Fifarative
Phraseaby Second Language Speakers , 1985 . ( submitted to publication ) . 

