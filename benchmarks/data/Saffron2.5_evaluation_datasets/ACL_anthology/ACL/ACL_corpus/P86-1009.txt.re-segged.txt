COMPUTATION ALCOMPLEXITYINT WO-LEVEL

G . Edward Barton , Jr.
M.I.T . Artificial Intelligence Laboratory
545 Technology Square
Cambridge , MA 02139

Morphological analysis must take into account the spelling-change processes of a language as well as its possible configurations of stems  , affixes , and inflectional markings . The computational difficulty of the task can be clarified by investigating specific models of morphological processing  . The use of finite-state machinery in the " two -level " model by Kimmo Koskennie migives it the appearance of computational efficiency  , but closer examination shows the model does not guarantee efficient processing  . 
Reductions of the satisfiability problem show that finding the proper lexical/surface correspondence in a two-level generation or recognition problem can be computationally difficult  . The difficulty increases if unrestricted deletions  ( null characters ) are allowed . 

The " dictionary lookup " stage in a natural language system can involve much more than simple retrieval  . Inflectional endings , prefixes , suffixes , spelling-change processes , reduplication , on-concatenative morphology , and clitics may cause familiar words to show up in heavily disguised form  , requiring substantial morphological nalys is . 
Superficially , it seems that word recognition might potentially be complicated and difficult  . 
This paper examines the question more formally by investigating the computational characteristics of the " two-level " model of morphological processes  . Given the kinds of constraints that can be encoded in two-level systems  , how difficult could it be to translate between lexical and surface forms ? Although the use of finite-state machinery in the two-level model gives it the appearance of computational efficiency  , the model itself does not guarantee efficient processing  . Taking the Kimmo system ( Karttunen , 1983) for concreteness , it will be shown that the general problem of mapping between \] exical and surface forms in two-level systems is computationally difficult in the worst case  ; extensive backtracking is possible . If null characters are excluded , the generation and recognition problems are NP -complete in the worst case  . If null characters are completely unrestricted , the problems is PSPACE-complete , thus probably even harder . The fundamental difficulty of the problems does not seem to be a precompi-lation effect  . 
In addition to knowing the stems , affixes , and cooccurrence restrictions of a language , a successful morphological analyzer must take into account he spelling-change processes that often accompany affixation  . In English , the program must expect love+ing to appear as loving  , fly+s as flies , lie+ing as lying , and big+er as bigger . 
Its knowledge must be sufficiently sophisticated to distinguish such surface forms a shopped and hoped  . Crosslinguistically , spelllng-change processes may span either a limited or a more extended range of characters  , and the material that triggers a change may occur either before or after the character that is affected  . ( Reduplication , a complex copying process that may also be found , will not be considered here . ) The K immo system described by Karttunen ( 1 983 is attractive for putting morphological knowledge to use in processing  . Kimmo is an implementation of the " two-level " model of morphology that Kimmo Koskenniemi proposed and developed in his Ph  . D . thesis . IA system of lexicons in the dictionary component regulates the sequence of roots and affixes at the lexical level  , while several finite-state transducers in the automaton component -- ~  20 transducers for Finnish , for instance--mediate the correspondence between lexical and surface forms  . Null characters allow the automata to handle insertion and deletion processes  . 
The overall system can be used either for generation or for recognition  . 
The finite-state transducers of the automaton component serve to implement spelling changes  , which may be triggered by either left or right context and which may ignore irrelevant intervening characters  . As an example , the following automaton describes a simplified " Y-change " process that changes y to ibefore suffixes : I University of Helsinki  , Finland , circa Fall 1983 . 
53 " Y-Change "55 yy*s = ( lexical characters ) i y = s = ( surface characters ) state 1:24111 ( normal state ) state 2 . 00300 ( require * s ) state 3 .  0 0 0 1 0  ( requires ) state 4:24811 ( for bid+s ) state S : 24101 ( for bids ) The details of this notation will not be explained here  ; basic familiarity with the Kimmo system is assumed  . For further introduction , see Barton (1985) , Karttunen (1983) , and references cited therein . 
THESEEDS
OF COMPLEXITY
At first glance , the finite-state machines of the two-level model appear to promise unfailing computational efficiency  . Both recognition and generation are built on the simple process of stepping the machines through the input  . 
Lexical lookup is also fast , interleaved character by character with the quick left-to-right steps of the automata  . The fundamental efficiency of finite-state machines promises to make the speed of Kimmo processing largely independent of the nature of the constraint shat the automata encode : The most important technical feature of Kosken-niemi 's and our implementation f the Two-level model is that morphological rules are represented in the processor as automata  , more specifically , as finite state transducers .   .   .   . One important consequence of compiling \[ the gramma rules into automata \] is that the complexity of the linguistic description of a language has no significant effect on the speed at which the forms of that language can be recognized or generated  . This is due to the fact that finite state machines are very fast to operate because of their simplicity  .   .   .   . Although Finnish , for example , is morphologically a much more complicated language than English  , there is no difference of the same magnitude in the processing times for the two languages  .   .   .   . \[ This fact \] has some psy-cholinguistie nterest because of the common sense observation that we talk about " simple " and " complex " languages but not about " fast " and " slow " ones  . ( Karttunen , 1983:166 f ) For this kind of interest in the model to be sustained  , it must be the model itself that wipes out processing difficulty  , rather than some accidental property of the encoded morphological constraints  . 
Examined in detail , the runtime complexity of Kimmo processing can be traced to three main sources  . The recognizer and generator must both run the finite-state machines of the automaton component  ; in addition , the recognizer must descend the letter trees that make up a lexicon  . 
The recognizer must also decide which suffix lexicon to explore at the end of an entry  . Finally , both the recognizer and the generator must discover the correct lexical-surface correspondence  . 
All these aspects of runtime processing are apparent in traces of implemented Kimmo recognition  , for instance when the recognizer analyzes the English surface forms piel  ( in 61 steps ) according to Karttunen and Witten-burg's ( 1983 ) analysis ( Figure 1 )  . The stepping of transducers and letter-trees i ubiquitous  . The search for the lexical-surface or respondence is also clearly displayed  ; for example , before backtracking to discover the correct lexical entry spiel  , the recognizer considers the lexical strings py + with y surfacing as i and + as e  . Finally , after finding the put at a tive root spy the recognizer must decide whether to search the lexicon I that contains the zero verbal ending of the present indicative  , the lexicon AG storing the agentive suffix * er , or one of several other lexicons inhabited by inflection alending such as + ed  . 
The finite-state framework makes it easy to step the automata  ; the letter-trees are likewise computationally well-behaved  . It is more troublesome to navigate through the lexicons of the dictionary component  , and the current implementation spends considerable time wandering about  . However , changing the implementation f the dictionary component can sharply reduce this source of complexity  ; a merged dictionary with bit vectors reduces the number of choices among alternative lxicons by allowing several to be searched at once  ( Barton ,  1985) . 
Moreominous with respecto worst-case behavior is the backtracking that results from local ambiguity in the construction of the lexical -surface correspondence  . Even if only one possibility is globally compatible with the constraints imposed by the lexicon and the automata  , there may not be enough evidence at every point in processing to choose the correct lexical -surface pair  . Search behavior results . 
In English examples , misguided search subtrees are necessarily shallow because the relevant spelling-change processes are local in character  . Since long-distance harmony processes are also possible  , the recan potentially be a long interval before the acceptability of a lexical-surfaee pair is ultimately determined  . For instance , when vowel alternations within a verb stem are conditioned by the occurrence of particular tense suffixes  , the recognizer must sometimes see the end of the word before making final decisions about the stem  . 

Recognizing surface form " spiel " .
1 s1 . 4  . 1  . 2  . 1  . 12 sp 1 . 1  . 1  . 2  . 1  . 13 spy 1 . 3  . 4  . 3  . 1  . 14" spy " ends , newlelXlCOnN 5"0" ends . new lexicon C16 spy X X X extra input 7 ( 5 ) spy+1 . 5 . 16 . 4 . 1 . 18 spy + X X X 9 (5) spy + 1 . 8 . 1 . 4 . 1 . 110 spy + X X X 11 (4) " spy " ends , new lext con1 12 spy X X X extratn put 13 ( 4 ) " spy " ends , new lexicon P314 spy+1 . 6 . 1 . 4 . 1 . 115 spy+XXX 16 (14) spy+1,8 . 18 . 4  . 1  . 117 spy+XXX 18 (4) " spy " ends , new lext conPS19 spy+1 . 6 . 1 . 4 . 1 . 120 spy+e1 . 1 . 1 . 1 . 4 . 1
Zlspy + eX X X 22 (20) spy ? e1 . 1  . 4  . 1  . 3  . 123 spy+eXXX 24 (19) spy+1 . 8 . 16 . 4 . 1 . 125 spy+eXXX Epen the sls26 (4) " spy " ends , new lexicon PP27 spy+1 . 6 . 1 . 4 . 1 . 128 spy+e1 . 1 . 1 . 1 . 4 . 1 zgspy + eXXX 30 (28) spy+e1 . 1 . 4 . 1 . 3 . 131 spy+eXXX 32 (27) spy+1 . 8 . 18 . 4 . 1 . 133 spy+eXXX Epen the sts34 (4) " spy " ends . new lexicon PR35 spy+1 . 6  . 1  . 4, 1, 136 spy+XXX 37 (38) spy+1 . 8 . 16 . 4 . 1 . 138 spy+XXX 39 (4) " spy " ends . new lext conAG40 spy+1 . 6  . 1  . 4  . 1  . I41 spy+e1 . 1 . 1 . 1 . 4 . 142 spy+eXXX 43 (41) spy+e1 . 1  . 4 ,1  . 3, 144 spy+eXXX 45 (40) spy+1 . 8 . 16 . 4 . 1 . 146 spy+eXXX Epenthests 47 (4) " spy " ends . new lext conAB 48 spy+1,8 . 1 . 4 . 1 . 149 spy+XXX 50 (48) Spy+1, 5 . 18  . 4  . 1  . 151 spy ? X X X 52 (3) spt 1 . 1  . 4  . 1  . 2  . 853 spte 1 . 1 . 16 . 1 . 6 . 154 spteXXX 58 (53) sple 1 . 1 . 16 . 1 . 5 . 656 spiel 1 . 1 . 16 . 2, I . I57"spiel " ends . new lext conN58"0" ends . new lexicon Cl59"spiel "*** result 60 ( 58 ) spiel+1 . 1 . 18 . 1 . 1 . 1  61 spiel+XXX"--+--'+---+ ILL+LLL+III+-~ -+ xxx+l---+XXX + 


LLL ? - - - + X X X ? - ~ - + X X X +
LLL + ---+-*-+ XXX+_l_+xxx?-o-+AAA+
LLL + - - - + - - - + X X X + ! : i : : , x , .
LLL + - - - + X X X + -!- + X X X +

I---?XlX+---+---+XXX +
I---+---+LLL+LLL +**-?
I - - - + X X X +
Key to tree nodes : --- normal treversal
LLL new lexicon
AAA blocking by automata
XXX no lexl cal-surface pairs compatible with surface char and dictionary 
III blocking by left over input *'* analysis found  ( (" spiel " ( NSG ) ) ) Figure \]: These traces show the steps that the KIMMO recognizer for English goes through while analyzing the surface forms piel  . Each llne of the table oil the left shows the le\ ] d calstring and automaton states at the end of a step  . If some autoz , mton blocked , the automaton states axe replaced by ~ , X X I entry . An X X X entry with no auton m to , , n:une indicates that the \] exical string could not bc extended becau  , ~ethe surface c\] , a racter . ' tn dh , xical letter tree together ruh ' dout , -dlfeasible p , 'drs . 
After xnXXX or *** entry , the recognizer backtracks and picks up from a previous choice point  . 
indicated by the paxenthesized step l*l U , zl ) er before the lexical . ~tring . The tree Ol , the right depicts the search graphically , reading from left to right and top t . \]) ottoln with vertir ; db ; trs linking the choices at each choice point The flhntres were generated witl  , a \] ( IMM ( ) hnplen * entation written i , an ; I . llgll*t , llter version of MACI , ISI'I , t , sed initiMly on Kltrttllnel *' , ,? (1983:182ff ) ; dg or ith ni description ; the diction ; n'ym . lantom at on cont pouents for E , glish were taken front1 . ;artt , ne , and Wittenlmrg (1983) with minor (' llikllg CS . ThisiJz * ple*l*Vl*tatio*)se;u'?h( . sdel . th-tlr , ~ ta , sKmttu , en's does , but explores the Mternatives at a giwm depth in a different order from Karttttnen's  . 
55 ? I
Ignoring the problem of choosing among alternative lexicons  , it is easy to see that the use of finite-state machinery helps control only one of the two remaining sources of complexity  . Stepping the automata should be fast , but the finite-state framework does not guarantee speed in the task of guessing the correct lexical -surface or respondence  . 
The search required to find the correspondence may predominate  . In fact , the Kim more cognition and generation problems bear an uncomfortabler semblance to problems in the computational class NP  . Informally , problems in NP have solutions that may be hard to guess but are easy to verify -- just the situation that might hold in the discovery of a Kimmo lexical-surface correspondence  , since the automata can verify an acceptable correspondence quickly but may need search to discover one  . 
THE COMPLEXITY

TWO-LEVE LMOR PHOLOGY
The Kimmo algorithms contain the seeds of complexity  , for local evidence does not always show how to construct a lexical-surface correspondence that will satisfy the constraints expressed in a set of two-level automata  . 
These seeds can be exploited in mathematical reductions to show that two-level automata can describe computationally difficult problems in a very natural way  . It follows that the finite-state two-level framework itself cannot guarantee computational efficiency  . If the words of natural languages are easy to analyze  , the efficiency of processing must result from some additional property that natural languages have  , beyond those that are captured in the two-level model  . Otherwise , computationally difficult problems might turn up in the two-level automata for some natural language  , just as they do in the artificially constructed languages here  . In fact , the reductions are abstractly modeled on the Kimmo treatment of harmony processes and other long-distance dependencies in natural anguages  . 
The reductions use the computationally difficult Boolean satisfiability problems SAT and  3SAT   , which involve deciding whether a CNF formula has a satisfying truth-assignment  . It is easy to encode an arbitrary SAT problem as a Kimmo generation problem  , hence the general problem of mapping from lexical to surface forms in Kimmo systems iNP-complete  . 2 Given a CNF formula ~ , first construct a string o by notational translation : use a minussign for negation  , a comma for conjunction , and no explicit operator for disjunction . Then theo corresponding to the formula ( ~vy ) & ( ~ vz ) & ( xvyvz ) is-xy . - yz . xyz . 
2Membership in NP is also required for this conclusion  . A later section ( " The Effect of Nulls ~ ) shows membership in NP by sketching how a nondeterministic machine could quickly solve Kimmo generation and recognition problems  . 
The notation is unambiguous without parentheses because is required to be in CNF  . Second , construct a Kimmo automaton component A in three parts  .   ( A varies from formulato formula only when the formulas involve different sets of variables  . ) The alphabet specification should list the variables in a together with the special characters T  , F , minussign , and comma ; the equals sign should be declared as the Kimmo wildcard character  , as usual . The consistency automata , one for each variable in a , should be constructed on the following model : " x-consistency "  3   3 xx = ( lezical characters ) 
TF = ( surface characters 1:231 ( x undecided 2:202 ( xtrue3:033 ( x fals c The consistency automaton for variable x constrains the mapping from variables in the lexical string to truth-values in the surface string  , ensuring that whatever value is assigned to x in one occurrence must be assigned to x in every occurrence  . Finally , use the following satisfaction automaton , which does not vary from formula to formula : " satisfaction "  3   4  = =  , ( lexical characters
TF , ( surface characters 1 .  2 1 3 0  ( no true seen in this group )  2: 2 2 2 1  ( true seen in this group 3 .  1 2 0 0  ( -F counts as true ) The satisfaction automaton determines whether the truth-values assigned to the variables cause the formula to come out true  . Since the formula is in CNF , the requirement is that the groups between commas must all contain at least one true value  . 
The net result of the constraints imposed by the consistency and satisfaction automata is that some surface string can be generated from a just in case the original formula has a satisfying truth-assignment  . Furthermore , A and o can be constructed in time polynomial in the length of ~  ; thus SAT is polynomial-time reduced to the Kimmo generation problem  , and the general case of Kimmo generation is at least as hard as SAT  . Incidentally , note that it is local rather than global ambiguity that causes trouble  ; the generator system in the reduction can go through quite a bit of search even when there is just one final answer  . Figure 2 traces the operation of the Kimmo generation algorithm on a  ( uniquely ) satisfiable formula . 
Like the generator , the Kim more cognizer can also be used to solve computationally difficult problems  . One easy reduction treats 3 SAT rather than SAT , uses negated alphabet symbols instead of a negation sign  , and replaces the satisfaction automaton with constraints from the dictionary component  ; see Barton (1985) for details . 

Generating from lexical form "- xy . - yz . -y-z , xyz " 11, 1 . 1  , 3  38  +  12  +  15  +  18 + lg 20  +  31  +  34 +- FF-FF , -FF , -- FF , -T-FF , -F-FF , -FF-FF , -FF . 
-FF , -FF , -FF , -FF , -FF , -FF , -FF-FF , -FF-FF , -FF-FF , -FF-FF , -F F-F F-F F-F F-F F-F F-F F-F F-F F -F F-F F-F F-F F-F F-F F-F F-F F-F F -FF  3   , 1  , 1  , 23 g 3 . 3 ,1 ,2 40 (3) 3 ,3 ,1  . 1 41 3 ,3 ,1 ,3 42
X X Xy-con .  43 3,3,1 ,2 44 + 3,3 ,3 ,2 45 3 ,3  . 3, 146-3, 3, 3, 347 (45) - TXX Xy-con . 48-F3 , 3  , 3  , 249-F-3 , 3  , 3  , 250-FT X X Xz-con . 51 +- FF 3,3,3,252 - F-F , 3, 3 . 3, 153-FF,-F-F,T X X X x-con . 54+-FF , -F-F , F3 , 3  , 3  , 155-FF , -F-F , FTX X Xy-con . 56(2)-FF , -F-F , FF3 , 3 , 3 , 157-FF , -F-F , FFT X X Xz-con . 58-FF , -F-F , FFF3 , 3 , 3 , 15 g(57) - FF , -F-F , FFF X X X satis , nf . 60-FT 3 , 3  , 2  , 261-FT ,  3 , 3 , 2 , 162-FT , - 3  , 3  , 2  , 363 +- FT , - TX X Xy-con . 64-FT , - F3 , 3  , 2  , 265-FT , - F-3 , 3  , 2  , 266 (64) - FT , -F-FX X Xz-con . 67-FT,-F-T 3,3,2,268 - FT,-F-T . 3, 3, 2, 16g-FT,-F-T,TXXXx-con . 70+-FT , -F-T , F3 , 3 , 2 , 171-FT , -F-T , FTX X Xy-con . 72-FT , -F-T , FF3 , 3 , 2 , 173+-FT , -F-T , FFF X X Xz-con . 74-FF , -FT , -F-T , FFT3 , 3 , 2 , 2"-FF , -FT , -F-T , FFT "*** result-FT-FT , -FT , --FT , -F-FT , -T-FT-TF-FT-TF , -FT-TT-FT-TT , -FT-TT , -- FT-TT , -F-FT-TT , -T-FT-TT , -T--FT-TT , -T-F-FT-TT , -T-T-FT-TT , -T-T , -T-TF-TF , -TT-TT-TT--TT-F-TT-T-TT-TF-TT -TF  , -TT-TT-TT-TT . 
-TT-TT , -- TT-TT , -F-TT-TT , -T-TT-TT , -T--TT-TT , -T-F-TT-TT . -T-T-TT-TT,-T-T , 3, 2, 1, 2, 1, 13, 2, 1, 3
X X Xy-con.

X X X satis.

X X Xy-con.

X X X z-con.

X X Xsaris.

X X Xsaris.

X X Xy-con.

X X Xsaris.

X X Xy-con.



X X X satis.
("-FF,-FT,-F-T , FFT ")
Figure 2: The generator system for deciding the satisfiability of Boolean formulas in x  , y , and z goes through these steps when applied to the encoded version of the  ( satisfiable ) formula ( 5 Vy ) & ( ~ Vz ) & ( ~ V  ~ ) & ( zVyVz )  . Though only one truth-assignment will satisfy the formula  , it takes quite a bit of backtracking to find it . The notation used here for describin generator actions is similar to that used to describe recognizer actions in Figure ??  , but a surface rather than a lexical string is the goal  . A*-entry in the backtracking column indicates backtracking from an immediate failure in the preceding step  , which does not require the full backtracking mechanism to be invoked  . 
THEEFFECT
OF PRECOMPILATION
Since the above reductions require both the language description and the input string to vary with the  SAT/3SAT problem to be solved , there arises the question of whether some computationally intensive form of precompilation could blunt the force of the reduction  , paying a large compilation cost once and allowing Kimmor un-time for a fixed grammar to be uniformly fast thereafter  . 
This section considers four aspects of the precompilation question  . 
First , the external description of a Kimmo automator or lexicon is not the same as the form used at runtime  . Instead , the external descriptions are converted to internal forms : RMACHINE and GMACHINE forms for automata  , letter trees for lexicons ( Gajek et al ,  1983) . Hence the complexity implied by the reduction might actually apply to the construction of these internal forms  ; the complexity of the generation problem ( for instance ) might be concentrated in the construction of the " feasible-pair list " and the GMACHINE  . This possibility can be disposed of by reformulating the reduction so that the formal problems and the construction specify machines in terms of their internal forms rather than their external descriptions  . The GMACHINEs for the class of machines created in the construction have a regular structure  , and it is easy to build them directly instead of building descriptions in external " format  . As traces of recognizer operation suggest , it is runtime processing that makes translated SAT problems difficult for a Kimmosystem to solve  . 
Second , there is another kind of preprocessing that might be expected to help  . It is possible to compile a set of Kimmo automata into a single large automaton  ( a BIGMACHINE ) that will run faster than the original set . 
The system will usually run faster with one large automaton than with several small ones  , since it has only one machine to step and the speed of stepping a machine is largely independent of its size  . Since it can take exponential time to build the BIGMACHINE for a translated SAT problem  , the reduction formally allows the possibility that BIGMACHINE precompilation could make runtime pro-MACH\]NE precompilation step does not help runtime processing enough to change the fundamental complexity of the algorithms  . Recall that the maining redients of Kimmor untime complexity are the mechanical operation of the automata  , the difficulty of finding the right lexical -surface correspondence  , and the necessity of choosing among alternative lexicons  . BIGMACHINE precompilation will speedup the mechanical operation of the automata  , but it will not help in the difficult task of deciding which lexical-surface pair will be globally acceptable  . Precompilation oils the machinery , but accomplishes no radical changes . 
Third , BIGMACHINE precompilation also sheds light on another precompilation question  . Though B\]G MA-CHINE precompilation ivolves exponential bow up in the worst case  ( for example , with the SAT automata ) , in practice the size of the BIGMACHINE varies -- thus naturally raising the question of what distinguishes the " explosive " sets of automata from those with more civilized behavior  . It is sometimes suggested that the degree of interaction among constraints determines the amount of BIG-MACHINE blow up  . Since the computational difficulty of SAT problems results in large measure from their " global " character  , the size of the BIGMACHINE for the SAT system comes as no surprise under the interaction theory  . 
However , a slight change in the SAT automata demonstrates that BIGMACHINE size is not a good measure of interaction among constraints  . Eliminate the satisfaction automaton from the generator system  , leaving only the consistency automata for the variables  . Then the system will not search for a satisfying truth-assignment  , but merely for one that is internally consistent . This change entirely eliminates interactions among the automata  ; yet the BIGMACHINE must still be exponentially larger than the collection of individual automata  , for its states must distinguish all the possible truth-assignments to the variables in order to enforce consistency  . In fact , the lack of interactions can actually increase the size of the BIGMA-CHINE  , since interactions constrain the set of reachable state-combinations  . 
Finally , it is worth considering whether the nondeter -minism involved in constructing the lexical -surface correspondence can be removed by standard determinization techniques  . Every nondeterministic fnite-state machine has a deterministic counterpart that is equivalent in the weak sense that it accepts the same language  ; aren't Kimmo automata just ordinary finite-state machines operating over an alphabet that consists of pairs of ordinary characters ? Ignoring subtleties associated with null characters  , Kimmo automata can indeed be viewed in this way when they are used to verify or reject hypothesized pairs of lexical and surface strings  . However , in this use they do not need determinizing , for each cell of an automaton description already lists just one state  . In the cases of primary interest--generation and recognition -- the machines are used as genuine transducers rather than acceptors  . 
The determinizing algorithms that apply to finite -state acceptors will not work on transducers  , and in fact many finite-state transducers are not determinizable at all  . Upon seeing the first occurrence of a variable in a SAT problem  , a deterministic transducer cannot know in general whether to output T or F  . It also cannot wait and output a truth-value later  , since the variable might occur an unbounded number of times before there was sufficient evidence to assign the truth-value  . A finite-state transducer would not be able in general to remember how many outputs had been deferred  . 
THEEFFECTOFNULLS
Since Kimmo systems can encode NP-complete problems  , the general Kimmo generation and recognition problems are at least as hard as the difficult problems in NP  . 
But could they be even harder ? The answer depends on whether null characters are allowed  . If nulls are completely forbidden , the problems are in NP , hence ( given the previous result ) NP-complete . If nulls are completely unrestricted , the problems are PSPACE-complete , thus probably even harder than . the problems in NP . However , the full power of unrestricted null characters i not needed for linguistically relevant processing  . 
If null characters are disallowed , the generation problem for Kim mosy stems can be solved quickly on a nondeterministic machine  . Given a set of automat and a lexical string , the basic nondeterminism of the machine can be used to guess the lexical-surface or respondence  , which the automata can then quickly verify . Since nulls are not permitted , the size of the guess cannot get out of hand ; the lexical and surface strings will have the same length  . 
The recognition problem can be solved in the same way except that the machine must also guess a path through the dictionary  . 
If null characters are completely unrestricted , the above argument fails ; the lexical and surface strings may differ so radically in length that the lexical-surface correspondence annot be proposed or verified in time polynomial in input length  . The problem becomes PSPACE-complete--as hard as checking for a forced w in from certain NxN Goconfigurations  , for instance , and probably even harder than NP-complete problems  ( cf . Garey and Johnson , 1979:171ff) . The proof involve showing that Kim mosy stems with unrestricted nulls can easily be induced to work out  , in the space between two input characters , a solution to the difficult FiniteState Automata
Intersection problem.

The PSPACE-completeness reduction shows that if two-level morphology is formally characterized in a way that leaves null characters completely unrestricted  , it can be very hard for the recognizer to reconstruct the superficially null characters that may lexically intervene between two surface characters  . However , unrestricted nulls surely are not needed for linguistically relevant Kimmo systems  . 
Processing complexity can be reduced by any restriction that prevents the number of nulls between surface characters from getting too large  . As a crude approximation to a reasonable constraint  , he PSPACE-completeness reduction could be ruled out by forbidding entire lexicon entries from being deleted on the surface  . A suitable restriction would make the general Kim more cognition problems only 

Both of the reductions remind us that problems involving finite-state machines can be hard  . Determining membership in a finite-state language may be easy  , but using finite-state machines for different asks such as parsing or transduction can lead to problems that are computationally more difficult  . 

Barton , E .  (1985) . " The Computational Complexity of Two-Level Morphology  , " A . I . Memo No . 856, M . I . T . 
Artificial Intelligence Laboratory , Cambridge , Mass . 
Gajek , O . , H . Beck , D . Elder , and G . Whittemore (1983) . 
" LISP Implementation \[ of the KIMMO system \] , " Texas
Linguistic Forum 22:187-202.
Garey , M . , and D . Johnson (1979) . Computers and In-tractability . San Francisco : W . H . Freeman and Co . 
Karttunen , L .  (1983) . "KIMMO : A Two-Level Morpho-?logical Analyzer , " Texas Linguistic Forum 22:165-186 . 
Karttunen , L . , and K . Wittenburg (1983) . " A Two-Level Morphological Analysis of English , " Texas Linguistic
Forum 22:217-228.

This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology  . Support for the Laboratory's artificial intelligence research has been provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract  N00014-80-C-0505  . A version of this paper was presented to the Workshop on Finite State Morphology  , Center for the Study of Language and Information , Stanford University , July 2930 ,  1985 ; the author is grateful to Lauri Karttunen for making that presentation possible  . This research has benefited from guidance and commentary from Bob Berwick  , and Bonnie Dorr and Eric Grims on have also helped improve the paper  . 

