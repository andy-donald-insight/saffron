Parsing
w . A . Martin
Laboratory for Computcr Science
Massachusetts Institute of Technology
Cambridge , Massachu . ~ tts 02139
\[ . ooking at the Proceedings of last year's Annual Meeting  , one sccs that the session most closely parallcling this one was entitled Language Structure and Par~ing  . \ [ navcry nice prescnu ~ fion , Mart in Kay was able to unite the papers of that scssion uud crasingle theme  . Ash c stated it . 
" Illcre has been a shift of emphasis away from highly ~ tmctured systems of complex rules as the principal repository of infi~mmtion about the syntax of a language towards a view in which the responsibility is distributed among the Icxicoo  . semantic parts of the linguistic description , aod a cognitive or strategic component . Concomitantly , interest hasshiRed from al!lorithms for syntactic analysis and generation  , in which the central stnlctor c and the exact seqtlencc of events are paramount  , to systems iu which a heavier burden is carried by the data stlucture and in wilich the order of  , : vents is a m ,  . ~ter of strategy . 
\[' his y car . the papers of the session represent a greater diversity of rescan : h directions  . The paper by Hayes . and thcpaper by Wilcnsky and Aren ~ arc both examples of what Kayhad in mind  . but the paper I ) y Church , with r cgard to the question of algorithms , is quite the opposite . He tolds that once the full range uf constraints dcscribing pc~plc's processing behavior has been captul'ed  , the best parsing strategies will be rather straightforwarc L and easily cx plain cd as algorithms  . 
Perilaps the seven papers in this year ' session can best be introdue cd by briefly citing ~ mc of the achiev cm cqts and problems reported in the works they refcrence  , Inthclate i960"s Woods tweeds70\] capped an cf Tort by several people to d cv ch ) pNI ' N parsing . ' lll is wellknown technique applies a smdghtforward topdown  , left CO right ` d cp th fic ~ t pat . ~ing algorithm to a syntactic grammar . 
I-:~pcci aliy in the compiled fi ) rm produced by Ilorton\[Bnrton 76 ~ , \] . the parser was able to produce the first parse in good time  . but without ~ mantic constraints , numcroosyn ~ ictic analyses could be and ~ , mctim cs were fou . nd , especially in scntenccs with conjunctions . A strength of the system was the ATN grammar , which can be dc ~ ribc das as ct of contextfrec production rules whose righthand sides arc finite statc machincs and who  . ~ U'ansition arcs have bccn augmented with functions able to read and set registers  , and also able to block a transition on their an : . Many people have found this a convenient fonnulism in which m develop grammars of Engtish  . 
The Woods ATN parser was a great success and attempts were made to exploit it  ( a ) as a modc\[of human processing and ( b ) as a tool for writing grammars . At the same time it was recognized to havc limim doos  . It was n ' tolerant of errors , and it couldn't handle unknown words or constructions  ( there were n ~' tny syntactic constmcd on s which it didn't know  )  . In addidon , the question answering system fed by the parser had a weak notion of word and phrase  . ~ emantics and it was not always able to handle quantific rs properly  . It is not ct carthcs ? components could have supported a stronger interaction with syntactic parsing  , hadWoods chosen to a ~ cmpti . 
On the successide . Kaplan \ [ Kaplan72\] was inspired to claim that the ATN parser provided a good model tbr some aspects of human processing  . Some aspects which might bcmodeled are :
Linnuistic Phenomenon
Prefcrred readings of
Ambiguous Sentences
Garden ~th Sentences
Perceived Complexity

Center Embedding Pounds
A'r N Comnntadonal Mechanism
Ordcred Trying of
Alternative Arcs

Hold List Costing
Counting Total Transitions
None\[none study , most p cople got the a ) reading of 1) . One can try to explain desl ) Th cy told the girl that Bill liked the story . 
la ) They told the girl\[that\[Billiked the scoryJs\]  . 
lb ) Th ~ told\[the girl that Bill liked l NP the story  . 
by ordering the arcs leaving the state where the head noun of ' an NP has been ~' ccpccd:aIx  ) pam ( tcr minuting the NP ) is tried before an an : accepting a modifying relative clause  . \]-h)w cver , Ricil\[ Rich75\] puims out that df is an : ordering solution would seem to have diltlculd cs with  2  )  . This sentence is often nutperacived 2 ) They told the girl that Bill liked that he would beat the loath  ; all game . 
as requiring backup , yet if the arcs an : ordered as for I ) , it does require backup . 
There is no doubt that whatever is going on . the awareness of backup in 3 ) is so much stronger than in 2 ) that it seems like a different phenom cnoo . To resolve this , 3) The horse raced past the b , ' u ' n fell . 
one could claim that perceived backup is some fimction of ' the length of the actual b~kup  , or may be of the degree of commiunent to the original path  ( althooghitisnt clear what this would mean in ATN terms  )  . 
In this session . Ferrari and Stock will turn the a reordering game around and describe  , for actual tex ~ the probability that a given arc is the correct exitan : from a node  . given the an : by wiuch the parser arrived at the node  . \[t will be intcr ~ ting to look at their distributions  . \[ n the speech project at IBM War , sou Laboratories \ [ Baker75\] it was discovered some time a go that , for a given text , the syntactic classer a word could be predicted correctly over  90% of the umo given only the syntactic lass of the preceding word ` Interestingly  , the correctness of ' predictions fell offless than  10% wh cn only the current word w ~ used . One wonders if this same level of skewncs sholds across texts  , or ( what we will hear ) for the continuation of phrases . These results should be helpful in discussing the whole issue of arc orderiog " Implicit in any al ~ordering strategy is the assumption that not all parses of a sentence will be fi  ) und . Having the " best " path , the pars cr will stop w benit gets an acceptable analysis  . Arcordering helps find that " best'path . Marcus\[Man:us7g\] , agreed with the idea of following only a best path  , but he claimed that the reason there is nope ~ eived backup in  2  ) is that the human parser is able to look ahead a few constituent siostead of just ones ~ ate and one eoil stitu cnt in making au ' ansition  . He claims this makes a more accurate model of human garden path behavior  , but it doesn't address the issue of unlimited stuck depth  . Here , Church will describe a parser similar in design coM arcus '  , except that it conserves memory . This allows Church to address psychological facLS not add rc~qed by either Marcus or the ATN models  . Church claims that exploiting stack size constraints will in cn : ase the cimnces of building a good best path parser  . 

Besides psychological modeling , thcre is also an interest m using th cATN ft ) nnalism for writing and teach in grammars . Paramoun there ise :; planation , both of the grammar and its appiicatinn to a particu ! ar sentence  . The papcr by Kchler and Woods reports on this . We is chcd clpicks a particular problem , responding to an input which the ATN can't handle  . Hea ~ , ' xi at csa list of diagnostic couditions and actions with each state  . When no pur . x c is found , the parser find stile last store on the path which progressed the thnhcs td  ) rong h the input string and executes its diagnostic conditions and actions  . When a parser uses , rely syutactic on straints " one cxpects it to find a lut of parses  . Usuu Jly the number of parses grows marc than t in carly with sentence length  . Thus , for a ~ tirly COmlflete grammar and moderate to king sentences  , one would expect that the cast of no parses ( handled by Wei . % hedcl ) would be rare in comparison with the oilier two cases  ( not handled ) where file set of parses doesn't include the correct one  , or where the grammar has been mistakenly , written to allow undesired pa ! ~ s " Success of the above eflol'ts to folin w only the best path would clearly be relevant here  . No doubtW cischc del's proeedure can help find a lot of bugs if diet~t examples are chosen with a little care  . I htt there is sdll interesting work to be done on grammar and parser explanation  , and Weise hcd clison c of those who intends to explore it The remaining three paper stem from three separate traditions which reject the strict syntactic ATN formalism  , each for its own reasons . They are : i ) Semantic Grammars -- the Davidson and
Kaplan paper ii ) Scmantic Structure Driven Parsing -
Wilcnsky and Arenspaperiii ) Multiple knowledge Source Parsing -- Hayespaper Each of these systems claims some advantage over the more widely known and accepted ATN  . 
The som and cgrammar parser can be viewed as a variation of the ATN which attempts to cope with the ATN's lack of semantics  . Kapian's work builds on workstancd by Burton\[ Burton76b \] and picked up by Hcndrix et al\[ ltendrtx78J   . The semantic grammar parser uses semanuc in . ; t cad of syntactic arc categories . " l'h is collapse syntax and semantics into a single structure  . 
When an ATN parsing strategy is used the result is  actuall7 ~flexible than a syntactic ATN , but it is faster because syntactic possibilities are el in '* in  ; tted by the semantics of the domain . " Ilm strategy is justified m terms of the pcrfum '* anccofactual running systems  . Kaplan also calls on a speed criteria in suggest , og ( hat when an unkuown word is cn countcred the system as som call possibilities which will let parsing prncccd  . The o if more than one possibility leads to a successful parse  , the system should attempt to rt , ~ olve the word fi . trth cr by file search or user query . 
As Kaplan points nut . d ) is trick is not limited to semantic grammars , but only to systems having enough constraints . It would hc interesting to know hOW w (: . it woutdwork for systems using Oshcrs on's\[ Oshcrson78\] prcdicahility criterion . 
instead of troth for their scmanocs . Oshcrs on distinguishes between " green idea " , which he says is silly and " marricd bachelor " which he say ~ is just raise  . 
H cilotes that " idea i so at green " is no better , but " bac\[~ehlr is not married " is fine . Prc dicability is a looser constrain * than Kaplan uses  , aud if it would still be cuough to limit database search this wo  . " lbcint crcv ; ng , because prcdicability is easier to implement across a broad domain  . 
Wilen ~ ky is a former stu , : tent of Schank's and thus COlt'*usffoma tradition which emphastzessent at mcs over syutax  . He~s right in emphasizing Ore importance of phrases cmantics  . The grammarians Quirkaud Grcenhaum \ [ Quirk731 poiut outtile syntactic , ll '* d semantic import aucc of verb phrases over verbs  . -inhngut stms , lhesnan\[ Ih'csnang0l is developing a theory of Icxical phrases which phenomena explained by the old transfomtational grammar  . : or example . 
given 4 ) There were reported to have been lionssighted . 
a typical ATN parser would attempt by register manipulations to make " lions " the suhject  . Using a phrase approach , " there belions sighted " can be taken as meaning " exist lionssighted  . " wl ) erc " lions " is an object and " sighted " an object complement " There " is related to the " be " m " by a series of relationships between the argument S of semantic structures  . Wilensky appears to have suppressed syntax into his semantic component  , and so it will be in rct ~ ting to sechow he handles the traditional syntactic phenom cna of  4  )  , like passive and verb forms . 
Final b , the paper by Hayes shows the influence of the speech recognition projects where bad input gave the Woods A'r N great dim cnlty  . Text input is much better than speech input . However , examination of actual input \[ Malhotra75\] does show sentences like: 5  ) What would have profits have been ? Fortunately , these cases are rare . Much more likely is clips is and the omission of syntax when the semantics are clear  . For example , the missing commas in 6 ) Giveratios of manufacturing costs to sales for plants  1   2   3 and 4 for 72 and 73  . 
Examples like these show that errors and omissions are not random phenomena and that there can be something to the study of errors and how to deal with diem  . 
In summary , it can be seen ~ at while much progress has been made in consmtcting u ~ bic parsers  , the basici ~ ues , such as the division of syntax . 
semantics " and pragmatics both in representation and in urd cruf processing  , are still up for grabs . ' l ' be problem has plenty of structure , so there is good fun to be had . 
References\[ Ikukcr751  \[  llresnang0\]  \[  Burton76aj  \[  Burmn76bl  \[  Hcndrix73\] 
Baker . J . K . " Stochastic Modeling for
Automatic Speech Understanding , " Sneech
Rceoeuition . " lnvi\[~Pap ~ r ~ ~ ~ IEEE
SvmnosiurTLReddy,D.R.(E'kt .),\] 975.
Bresnan . Joan . " Polyadicity : Part I of a
Theory of l . exical Rules and
Rcprese flmtions , " MI'\["Department of
Linguistics ( January 1980).
Burton . Richard R . and Woods , William A.
" A Compiling System fnr Augmented
Transition Networks , " COLING 76.
Burton . Richard R . " Semantic Grammar : An Engineering Technique \ [ or Constructing Natural I~mguage Und cr~tanding Systems  , "
BBN Report 3453, Bolt . Beranek , and
Newman , Boston , Ma . ( December D 76).
Hendrix , Gary G . Sacerdoa , E.D.,
Sagalowicz . D . . and Slocum . J . " l ) cveloping a Natural I . anguage Interface to Complexl ') at a , " ACM l " rans , ~ Dqf . a hase Systems . vo \ [ . 
3, no . 2 ( June 1978). pp . 105-147.
\ [Kaplan72\]  \[  Malhotra751  \[  Marcus7Sl  \[  O~erson7Sl  \[  Quirk731 
I Rich 751\[Woods 70 l
Kaplan , Ronald M . " Augmented Transition
Networks as Psychological Models of
Sentence Comprehension , " Artificial
Int cllieenee , 3(October 1972). pp . 77-100.
Malhotra . Ashok . " l ) esign Critcria for a Knowlcdgc-Based English Language System for Management : An Experimental 
Analysis , " MIT/LCS/rR-1.46, MIT,
Laboratory for Computer Science,
Cambridge . Ma . ( February 1975).
Marcus`Mitchell . " A Theory of Syntactic Recognition for Naturall . 'mguages , " Ph . D . 
thesis . MIT Dept . of Electrical Engineering and Computer Science , Cambridge , Ma . ( to be published by MrT Press ) . 
Oshcrson , Danicl N . " Three Conditions on Conceptual Naturalness . " Cognition , 6(197g ), pp .  263-289 . 
Quirk . R . and Greenbaum . S . A Concise
Grammaro ~ Ctmiemnor arv F . nnlisll , Harcourt
Brace Jovanovich . New York ( L973).
Rich , Charles . " On the Psychological Reality of Augmented Transition Network Models of 
Sentence Cumprehension , " unpublished paper , MIT Artilicial Intelligence I . aboratory,
Cambridge , Ma . ( July\[97S).
Woods . William A . " Transition Network
Grammars for Natural Language Analysis "
CACM 13.10 ( October 1970), pp . 591-602.

