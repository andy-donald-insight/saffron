Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers , pages 141?146,
Portland , Oregon , June 1924, 2011. c?2011 Association for Computational Linguistics
A Corpus of Scope-disambiguated English Text
Mehdi Manshadi , James Allen , Mary Swift Department of Computer Science , University of Rochester Rochester , NY , 14627, USA { mehdih,james,swift}@cs.rochester.edu
Abstract
Previous work on quantifier scope annotation focuses on scoping sentences with only two quantified noun phrases ( NPs ), where the quantifiers are restricted to a predefined list . It also ignores negation , modal/logical operators , and other sentential adverbials . We present a comprehensive scope annotation scheme . We annotate the scope interaction between all scopal terms in the sentence from quantifiers to scopal adverbials , without putting any restriction on the number of scopal terms in a sentence . In addition , all NPs , explicitly quantified or not , with no restriction on the type of quantification , are investigated for possible scope interactions . 1 Introduction Since the early days of natural language understanding ( NLU ), quantifier scope disambiguation has been an extremely hard task . Therefore , early NLU systems either devised some mechanism for leaving the semantic representation underspecified ( Woods 1978, Hobbs and Shieber 1987), or tried to assign scoping to sentences based on heuristics ( VanLehn 1978, Moran 1988, Alshawi 1992). There has been a lot of work since then on developing frameworks for scope-underspecified semantic representations ( Alshawi and Crouch 1992, Bos 1996, Copestake et al , 2001, Egg et al , 2001). The motivation of most recent formalisms is to develop a constraint-based framework where you can incrementally add constraints to filter out unwanted scopings . However , almost all of these formalisms are based on hard constraints , which have to be satisfied in every reading of the sentence . It seems that the story is different in practice . Most of the constraints one can hope for ( imposed by discourse , pragmatics , word knowledge , etc .) are soft constraints , that is they define a preference over the possible readings of a sentence . As a result , statistical methods seem to be well suited for scope disambiguation . Surprisingly enough , after two decades of extensive work on statistical techniques in natural language processing , there has not been much work on scope disambiguation ( see section 6 for a review ). In addition , as discussed later , this work is very restricted . It considers sentences with only two quantifiers , where the quantifiers are picked from a predefined list . For example , it ignores definites , bare singulars/plurals , and proper nouns , as well as negations and other scopal operators . A major reason for the lack of work on statistical scope disambiguation is the lack of a comprehensive scope-disambiguated corpus . In fact , there is not even a standard test set for evaluation purposes . The reason behind this latter fact is simple . Scope disambiguation is very hard even for humans . In fact , our own early effort to annotate part of the Penn Treebank with full scope information soon proved to be too ambitious . Instead , we have picked a domain that covers many challenging phenomena in scope disambiguation , while keeping the scope disambiguation fairly intuitive . This helps us to build the first moderately sized corpus of natural language text with full scope information . By fully scoping a sentence , we mean to label the scope interaction between every two scopal elements in that sen-using command-line editors and regular expressions exist . Sentences were manually extracted from examples and exercises in these tutorials . ? Computer science graduate students : These are the sentences provided by CS graduate students describing some of the routine text editing tasks they often do . The sentences have been provided by both native and nonnative English speakers . 3.2 Expanding corpus with crowd sourcing The core corpus was used to get more sentences using crowd sourcing . We provided input/output ( I/O ) examples for each task in the core corpus , and asked the workers on Mechanical Turk to provide the description of the task based on the I/O example(s ). Figure (2) shows an example of two I/O pairs given to the workers in order to get the description of a single task . The reason for using two I/O pairs ( instead of only one ) is that there is almost always a trivial description for a single I/O pair . Even with two I/O pairs , we sometimes get the description of a different task , which happens to work for the both pairs . For example the original description for the task given in figure (2) is : 1. Sort all the lines by their second field . The following descriptions are provided by three workers based on the given input/output texts : 2. Sort the lines alphabetically by the values in the 2nd column . 3. Sort the lines by the first group of letters . 4. Alphabetize each line using the first letter of each word in the second column . (3) gives the description of a different task , but it works for the given I/O pairs . This is not a problem for us , but actually a case that we would prefer to happen , because this way , we not only get a variety of sentences defining the same task , but also obtain descriptions of new tasks . We can add these new tasks to the core corpus , label them with new I/O 1. Find an occurrence of the word " TBA " in every line and remove it from the line . 2. Print a list of the lines that do not start with a digit or end with a letter . 3. Replace every string " anti " possibly followed by a hyphen with " not ". Figure 1. Some examples from the core corpus INPUT OUTPUT 1000 NY April 3000 HU August 4000 OR May 4000 AL June 4000 AL June 3000 HU August 1000 NY April 4000 OR May c josh 21 a adams 23 d sam 26 b john 25 a adams 23 b john 25 c josh 21 d sam 26 Figure 2. Two I/O pairs given for a single task are allowed to cascade constraints to form a more concise representation ( see Figure 3). 4.1 Logical equivalence vs . intuitive scoping Our early experiments showed that a main source of interannotator disagreement are pairs of chunks for which , both orderings are logically equivalent ( e.g . two existentials or two universals ), but an annotator may label them with outscoping constraints based on his/her intuition . It turns out that the annotators ? intuitions are not consistent in these cases . Even a single annotator does not remain consistent throughout the data in such cases . Although it does not make any difference in logic , this shows up as interannotator disagreement . In order to prevent this , annotators were asked to recognize these cases and leave them unscoped . 4.2 Plurals Plurals , in general , introduce a major source of complexity both in formal and computational semantics ( Link 1997). From a scope?disambiguation point of view , the main issue with plurals come from the fact that they carry two possible kinds of readings : collective vs . distributive . We treat plurals as a set of individuals and assume that the index of a plural NP refers to the set ( collective reading ). However , we also assume that every plural potentially carries an implicit universal quantifier ranging over all elements in the set . We represent this implicit universal with id (? d ? for distributive ) where i is the index of the plural NP . It is important to notice that while most theoretical papers talk about the collectivity vs . distributivity distinction at the sentence level , for us the right treatment is to make this distinction at the constraint level . That is , a plural may have a collective reading in one constraint but a distributive reading in another , as shown in example 2 in figure (3).
1. Find [1/ an instance ] of [2/ the word " TBA "] in [3/ every line ] and remove [4/ it ] from [5/ the line ]. (3>1 ; 3=5 ; 1=4) // concise form : (5=3>1=4) 2. Print [1/ a list ] of [2/ the lines ] that do [ N1/ not ] start with [3/ a digit ] [ O1/ or ] end with [4/ a letter ]. (2>1 ; 2d>N1>3,4 ; N1>O1) // ( i>j,k ) ? ( i>j ; i>k ) 3. Replace [1/ every string " anti "] [ O1/ possibly ] followed by [2/ a hyphen ] with [3/ " not "]. (1>O1>2 ; 1>3) Figure 3. Chunked sentences labeled with scopings We represent each scoping using a directed graph over the chunk indices . For every outscoping relation i>j , node i is connected to node j by the directed edge ( i,j ). For example , figure (4a ) represents the scoping in (5). 5. Delete [1/ the first character ] of [2/ every word ] and [3/ the first word ] of [4/ every line ] in [5/ the file ]. (5>2>1 ; 5>4>3) Note that the directed graph must be a DAG ( directed acyclic graph ), otherwise the scoping is not valid . In order to be able to measure the similarity of two DAGs corresponding to two different scopings of a single sentence , we borrow the notion of transitive closure from graph theory . The transitive closure ( TC ) of a directed graph G=(V,E ) is the graph G+=(V,E +), where E + is defined as follows : 6. E+={(i,j ) | i,j ? V and i reaches j using a non-null directed path in G } Given the TC graph of a scoping , every pair ( i,j ), where i precedes j in the sentence , has one of the following three labels : ? WS ( i outscopes j ): ( i,j ) ? E + ? NS ( j outscopes i ): ( j,i ) ? E + ? NI ( no interaction ): ( i,j ) ? E + ? ( j,i ) ? E + A pair is considered a match between two scopings , if it has the same label in both . We define the metrics at two levels , constraint level and sentence level . At constraint level , every pair of chunks in every sentence is considered one instance . At sentence level , every sentence is treated as an in-Type of NP chunk Percentage NPs with explicit quantifiers ( including indefinite A ) 35% Definites 27% Bare singulars/plurals 25% Pronouns 7% Proper names ( files , variables , etc .) 6% Table 1. Corpus statistics ( a ) ( b ) Figure 4. DAG of scoping in (5) and its TC the first quantifier has wide scope . A major problem with this data is that the sentences are artificially constructed for the LSAT and GRE tests . In a recent work Srinivasan and Yates (2009) study the usage of pragmatic knowledge in finding the intended scoping of a sentence . Their labeled data set consists of 46 sentences , extracted from Web1Tgram ( from Google , Inc ) and hence is open-domain . The corpus consists of short sentences with two specific quantifiers : Every and A . All sentences share the same syntactic structure , an active voice English sentence of the form ( S ( NP ( V ( NP | PP )))). In fact , they try to isolate the effect of pragmatic knowledge on scope disambiguation . 7 Summary and future work We have constructed a comprehensive scope?disambiguated corpus of English text within the domain of editing plain text files . The domain carries many scope interactions . Our work does not put any restriction on the type or the number of scope-bearing elements in the sentence . We achieve the IAA of 75% on this task . Previous work focuses on annotating the relative scope of two NPs per sentence , while ignoring the complex scope-bearing NPs such as definites and indefinites , and achieves the IAA of 52%. The current corpus contains 2500 sentences , out of which 500 sentences have already been annotated . Our goal is to expand the corpus up to twice in size . 20% of the corpus will be annotated and the rest will be left for the purpose of semisupervised learning . Since world knowledge plays a major role in scope disambiguation , we believe that leveraging unlabeled domain specific data in order to extract lexical information is a promising approach for scope disambiguation . We hope that availability of this corpus motivates more research on statistical scope disambiguation . Acknowledgments This work was supported in part by grants from the National Science Foundation ( IIS-1012205) and The Office of Naval Research ( N000141110417).
Constraint-level Sentence-level ? 75.0% 66% ?- EZ 92.3% 89% Table 2. Interannotator agreement
