Proceedings of the ACL 2010 Conference Short Papers , pages 74?79,
Uppsala , Sweden , 1116 July 2010. c?2010 Association for Computational Linguistics
Correcting Errors in a Treebank Based on
Synchronous Tree Substitution Grammar
Yoshihide Kato1 and Shigeki Matsubara2
1Information Technology Center , Nagoya University
2Graduate School of Information Science , Nagoya University
Furo-cho , Chikusa-ku , Nagoya , 464-8601 Japan
yosihide@el.itc.nagoya-u.ac.jp
Abstract
This paper proposes a method of correcting annotation errors in a treebank . By using a synchronous grammar , the method transforms parse trees containing annotation errors into the ones whose errors are corrected . The synchronous grammar is automatically induced from the treebank.
We report an experimental result of applying our method to the Penn Treebank . The result demonstrates that our method corrects syntactic annotation errors with high precision.
1 Introduction
Annotated corpora play an important role in the fields such as theoretical linguistic researches or the development of NLP systems . However , they often contain annotation errors which are caused by a manual or semimanual markup process.
These errors are problematic for corpus-based researches.
To solve this problem , several error detection and correction methods have been proposed so far ( Eskin , 2000; Nakagawa and Matsumoto , 2002; Dickinson and Meurers , 2003a ; Dickinson and Meurers , 2003b ; Ule and Simov , 2004; Murata et al , 2005; Dickinson and Meurers , 2005; Boyd et al , 2008). These methods detect corpus positions which are marked up incorrectly , and find the correct labels ( e.g . postags ) for those positions . However , the methods cannot correct errors in structural annotation . This means that they are insufficient to correct annotation errors in a treebank.
This paper proposes a method of correcting errors in structural annotation . Our method is based on a synchronous grammar formalism , called synchronous tree substitution grammar ( STSG ) ( Eisner , 2003), which defines a tree-to-tree transformation . By using an STSG , our method transforms parse trees containing errors into the ones whose errors are corrected . The grammar is automatically induced from the treebank . To select STSG rules which are useful for error correction , we define a score function based on the occurrence frequencies of the rules . An experimental result shows that the selected rules archive high precision.
This paper is organized as follows : Section 2 gives an overview of previous work . Section 3 explains our method of correcting errors in a treebank . Section 4 reports an experimental result using the Penn Treebank.
2 Previous Work
This section summarizes previous methods for correcting errors in corpus annotation and discusses their problem.
Some research addresses the detection of errors in pos-annotation ( Nakagawa andMatsumoto , 2002; Dickinson and Meurers , 2003a ), syntactic annotation ( Dickinson and Meurers , 2003b ; Ule and Simov , 2004; Dickinson and Meurers , 2005), and dependency annotation ( Boyd et al , 2008).
These methods only detect corpus positions where errors occur . It is unclear how we can correct the errors.
Several methods can correct annotation errors ( Eskin , 2000; Murata et al , 2005). These methods are to correct tag-annotation errors , that is , they simply suggest a candidate tag for each position where an error is detected . The methods cannot correct syntactic annotation errors , because syntactic annotation is structural . There is no approach to correct structural annotation errors.
To clarify the problem , let us consider an example . Figure 1 depicts two parse trees annotated according to the Penn Treebank annotation 1. The 10 and * T * are null elements.
74
SNP VP . DTThat PRNS , NP VPPRPthey VBPsay SBAR-NONE - S-NONE-0 * T * , ,, MDwill VPVBbe ADJPJJgood PPINfor NPNNSbonds .
SNP VP . DTThat PRNS , NP VPPRPthey VBPsay SBAR-NONE - S-NONE-0 * T * , ,, MDwill VPVBbe ADJPJJgood PPINfor NPNNSbonds .
(a ) incorrect parse tree ( b ) correct parse tree Figure 1: An example of a treebank error parse tree ( a ) contains errors and the parse tree ( b ) is the corrected version . In the parse tree ( a ), the positions of the two subtrees (, ,) are erroneous . To correct the errors , we need to move the subtrees to the positions which are directly dominated by the node PRN . This example demonstrates that we need a framework of transforming tree structures to correct structural annotation errors.
3 Correcting Errors by Using
Synchronous Grammar
To solve the problem described in Section 2, this section proposes a method of correcting structural annotation errors by using a synchronous tree substitution grammar ( STSG ) ( Eisner , 2003). An STSG defines a tree-to-tree transformation . Our method induces an STSG which transforms parse trees containing errors into the ones whose errors are corrected.
3.1 Synchronous Tree Substitution Grammar First of all , we describe the STSG formalism . An STSG defines a set of tree pairs . An STSG can be treated as a tree transducer which takes a tree as input and produces a tree as output . Each grammar rule consists of the following elements : ? a pair of trees called elementary trees
PRNS,1 NP2 VP3 ,4
PRNS,1 NP2 VP3 ,4 source target
Figure 2: An example of an STSG rule ? a one-to-one alignment between nodes in the elementary trees For a tree pair ? t , t ??, the tree t and t ? are called source and target , respectively . The nonterminal leaves of elementary trees are called frontier nodes . There exists a one-to-one alignment between the frontier nodes in t and t ?. The rule means that the structure which matches the source elementary tree is transformed into the structure which is represented by the target elementary tree.
Figure 2 shows an example of an STSG rule . The subscripts indicate the alignment . This rule can correct the errors in the parse tree ( a ) depicted in
Figure 1.
An STSG derives tree pairs . Any derivation process starts with the pair of nodes labeled with special symbols called start symbols . A derivation proceeds in the following steps : 1. Choose a pair of frontier nodes ??, ??? for which there exists an alignment.
2. Choose a rule ? t , t ?? s.t . label (?) = root(t ) and label (??) = root(t ?) where label (?) is the label of ? and root(t ) is the root label of t.
3. Substitute t and t ? into ? and ??, respectively.
Figure 3 shows a derivation process in an STSG.
In the rest of the paper , we focus on the rules in which the source elementary tree is not identical to its target , since such identical rules cannot contribute to error correction.
3.2 Inducing an STSG for Error Correction This section describes a method of inducing an STSG for error correction . The basic idea of our method is similar to the method presented by Dickinson andMeurers (2003b ). Their method detects errors by seeking word sequences satisfying the following conditions : ? The word sequence occurs more than once in the corpus.
75
S SSNP VPPRN . SNP VPPRN . DT DTThat ThatSNP VPPRN . SNP VPPRN . DT DTThat ThatS , NP VP , S , NP VP , SNP VPPRN . SNP VPPRN . DT DTThat ThatS , NP VP , S , NP VP ,, , PRPthey PRPthey ( a)(b ) ( c ) ( d ) Figure 3: A derivation process of tree pairs in an
STSG ? Different syntactic labels are assigned to the occurrences of the word sequence.
Unlike their method , our method seeks word sequences whose occurrences have different partial parse trees . We call a collection of these word sequences with partial parse trees pseudo parallel corpus . Moreover , our method extracts STSG rules which transform the one partial tree into the other.
3.2.1 Constructing a Pseudo Parallel Corpus Our method firstly constructs a pseudo parallel corpus which represents a correspondence between parse trees containing errors and the ones whose errors are corrected . The procedure is as follows : Let T be the set of the parse trees occurring in the corpus . We write Sub (?) for the set which consists of the partial parse trees included in the parse tree ?. A pseudo parallel corpus Para(T ) is constructed as follows:
Para(T ) = {??, ? ?? | ?, ? ? ? ? ?? T
Sub (?) ? ? ?= ? ? ? yield (?) = yield (? ?) ? root (?) = root (? ?)} PRNS,1 NP2 VP4PRP3they VBP5say SBAR6-NONE-7 S8-NONE-90 * T * , ,10, PRNS,1 NP2 VP4PRP3they VBP5say SBAR6-NONE-7 S8-NONE-90 * T * , ,10, Figure 4: An example of a partial parse tree pair in a pseudo parallel corpusSNP VP . DTThat PRNS , NP VPPRPthey VBPsay SBAR-NONE - S-NONE-0 * T * , ,, VBDwill ADJP PPINof NPPRP$his NNSabilities . JJproud Figure 5: Another example of a parse tree containing a word sequence ?, they say ,? where yield (?) is the word sequence dominated by ? .
Let us consider an example . If the parse trees depicted in Figure 1 exist in the treebank T , the pair of partial parse trees depicted in Figure 4 is an element of Para(T ). We also obtain this pair in the case where there exists not the parse tree ( b ) depicted in Figure 1 but the parse tree depicted in Figure 5, which contains the word sequence ?, they say ,?.
3.2.2 Inducing a Grammar from a Pseudo
Parallel Corpus
Our method induces an STSG from the pseudo parallel corpus according to the method proposed by Cohn and Lapata (2009). Cohn and Lapata?s method can induce an STSG which represents a correspondence in a parallel corpus . Their method firstly determine an alignment of nodes between pairs of trees in the parallel corpus and extracts STSG rules according to the alignments.
For partial parse trees ? and ? ?, we define a node alignment C (?, ? ?) as follows:
C (?, ? ?) = {??, ??? | ? ? Node (?) ? ?? ? Node (? ?) ? ? is not the root of ? ? label (?) = label (??) ? yield (?) = yield (??)} where Node (?) is the set of the nodes in ? , and yield (?) is the word sequence dominated by ?.
Figure 4 shows an example of a node alignment.
The subscripts indicate the alignment.
An STSG rule is extracted by deleting nodes in a partial parse tree pair ??, ? ?? ? Para(T ). The procedure is as follows : ? For each ??, ??? ? C (?, ? ?), delete the descendants of ? and ??.
For example , the rule shown in Figure 2 is extracted from the pair shown in Figure 4.
3.3 Rule Selection
Some rules extracted by the procedure in Section 3.2 are not useful for error correction , since the pseudo parallel corpus contains tree pairs whose source tree is correct or whose target tree is incorrect . The rules which are extracted from such pairs can be harmful . To select rules which are useful for error correction , we define a score function which is based on the occurrence frequencies of elementary trees in the treebank . The score function is defined as follows:
Score(?t , t ??) = f(t ?) f(t ) + f(t ?) where f (?) is the occurrence frequency in the treebank . The score function ranges from 0 to 1. We assume that the occurrence frequency of an elementary tree matching incorrect parse trees is very low . According to this assumption , the score function Score(?t , t ??) is high when the source elementary tree t matches incorrect parse trees and the target elementary tree t ? matches correct parse trees . Therefore , STSG rules with high scores are regarded to be useful for error correction.
4 An Experiment
To evaluate the effectiveness of our method , we conducted an experiment using the Penn Treebank ( Marcus et al , 1993).
We used 49208 sentences in Wall Street Journal sections . We induced STSG rules by applying our method to the corpus . We obtained 8776 rules . We
PRN , SNP ,
PRN SNPNP VP
SNP VP
NPNP NPIN NP
NPNP PPIN NP (1) (2) (4) source target
VP , S , NP VP(3) PPIN NNSDT PPIN NPDT NNS Figure 6: Examples of error correction rules induced from the Penn Treebank measured the precision of the rules . The precision is defined as follows : precision = # of the positions where an error is corrected # of the positions to which some rule is applied We manually checked whether each rule application corrected an error , because the corrected treebank does not exist2. Furthermore , we only evaluated the first 100 rules which are ordered by the score function described in Section 3.3, since it is time-consuming and expensive to evaluate all of the rules . These 100 rules were applied at 331 positions . The precision of the rules is 71.9%. For each rule , we measured the precision of it . 70 rules achieved 100% precision . These results demonstrate that our method can correct syntactic annotation errors with high precision . Moreover , 30 rules of the 70 rules transformed bracketed structures . This fact shows that the treebank contains structural errors which cannot be dealt with by the previous methods.
Figure 6 depicts examples of error correction rules which achieved 100% precision . Rule (1), (2) and (3) are rules which transform bracketed structures . Rule (4) simply replaces a node label . Rule (1) corrects an erroneous position of a comma ( see Figure 7 ( a )). Rule (2) deletes a useless node NP in a subject position ( see Figure 7 ( b )). Rule (3) inserts a node NP ( see Figure 7 ( c)).
Rule (4) replaces a node label NP with the correct label PP ( see Figure 7 ( d )). These examples demonstrate that our method can correct syntactic annotation errors.
Figure 8 depicts an example where our method detected an annotation error but could not correct it . To correct the error , we need to attach the node 2This also means that we cannot measure the recall of the rules.
77
PRN , SNP , VPI think
PRN , SNP , VPI think NP
NP S VPis one good oneall you need
NP S VPis one good oneall you need
IN PP NNSof DTthe respondents IN
PP
NNSof DTthe respondents
NP
NP NP NP the U.S.only two or three other major banks
IN NPin
NP NP PP the U.S.only two or three other major banks
IN NPin ( a ) ( b ) ( c ) ( d)
Figure 7: Examples of correcting syntactic annotation errors
SPP SBAR,INAt NPNPCD10:33 , SPP SBAR,INAt NPCD10:33 , when ... when ...
Figure 8: An example where our method detected an annotation error but could not correct it SBAR under the node NP . We found that 22 of the rule applications were of this type.
Figure 9 depicts a false positive example where our method mistakenly transformed a correct syntactic structure . The score of the rule is very high , since the source elementary tree ( TOP ( NP NP VP .)) is less frequent . This example shows that our method has a risk of changing correct annotations of less frequent syntactic structures.
5 Conclusion
This paper proposes a method of correcting errors in a treebank by using a synchronous tree substitution grammar . Our method constructs a pseudo parallel corpus from the treebank and extracts STSG rules from the parallel corpus . The experimental result demonstrates that we can obtain error correction rules with high precision.
TOP
NP . VP based on quotations atfive major banksThe average of interbank offered rates
NP
TOP
NP . VP based on quotations atfive major banksThe average of interbank offered rates
S
Figure 9: A false positive example where a correct syntactic structure was mistakenly transformed In future work , we will explore a method of increasing the recall of error correction by constructing a wide-coverage STSG.
Acknowledgements
This research is partially supported by the Grant-in-Aid for Scientific Research ( B ) ( No . 22300051) of JSPS and by the Kayamori Foundation of Informational Science Advancement.
78
References
Adriane Boyd , Markus Dickinson , and Detmar Meurers . 2008. On detecting errors in dependency treebanks . Research on Language and Computation , 6(2):113?137.
Trevor Cohn and Mirella Lapata . 2009. Sentence compression as tree transduction . Journal of Artificial
Intelligence Research , 34(1):637?674.
Markus Dickinson and Detmar Meurers . 2003a . Detecting errors in part-of-speech annotation . In Proceedings of the 10th Conference of the European Chapter of the Association for Computational Linguistics , pages 107?114.
Markus Dickinson and Detmar Meurers . 2003b . Detecting inconsistencies in treebanks . In Proceedings of the SecondWorkshop on Treebanks and Linguistic
Theories.
Markus Dickinson and W . Detmar Meurers . 2005.
Prune diseased branches to get healthy trees ! how to find erroneous local trees in a treebank and why it matters . In Proceedings of the 4th Workshop on
Treebanks and Linguistic Theories.
Jason Eisner . 2003. Learning non-isomorphic tree mappings for machine translation . In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics , Companion Volume , pages 205?208.
Eleazar Eskin . 2000. Detecting errors within a corpus using anomaly detection . In Proceedings of the 1st North American chapter of the Association for Computational Linguistics Conference , pages 148?153.
Mitchell P . Marcus , Beatrice Santorini , and Mary Ann Marcinkiewicz . 1993. Building a large annotated corpus of English : the Penn Treebank . Computational Linguistics , 19(2):310?330.
Masaki Murata , Masao Utiyama , Kiyotaka Uchimoto , Hitoshi Isahara , and Qing Ma . 2005. Correction of errors in a verb modality corpus for machine translation with a machinelearning method . ACM Transactions on Asian Language Information Processing , 4(1):18?37.
Tetsuji Nakagawa and Yuji Matsumoto . 2002. Detecting errors in corpora using support vector machines.
In Proceedings of the 19th Internatinal Conference on Computatinal Linguistics , pages 709?715.
Tylman Ule and Kiril Simov . 2004. Unexpected productions may well be errors . In Proceedings of 4th International Conference on Language Resources and Evaluation , pages 1795?1798.
79
