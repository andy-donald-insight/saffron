ALGORITHM SFORGENERATION INLAMBEK
THEOREM PROVING
Erik-Jan van der Linden *
Guido Minnen
Institute for Language Technology and Artificial Intelligence 
Tilburg University
PO Box 90153, 5000 LE Tilburg , The Netherlands
E-mai hvdlin den Okub.nl

We discuss algorithms for generation within the Lambek Theorem Proving Framework  . Efficient algorithms for generation it his framework take a semantics-driven strategy  . This strategy can be modeled by means of rules in the calculus that are geared to generation  , or by means of an algorithm for the Theorem Prover  . The latter possibility enables processing of a bidirectional calculus  . Therefore Lambek Theorem Proving is a natural candidate for a ' uniform ' architecture for natural anguage parsing and generation  . 
Keywords : generation algorithm ; natural language generation ; theorem proving ; bidirection-ality ; categorial grammar . 
1 INTRODUCTION
Algorithms for tactical generation are becoming an increasingly important subject of research in computational linguistics  ( Shieber , 1988; Shieber et al , 1989; Calder et al ,  1989) . In this paper , we will discuss generation algorithms within the Lambek Theorem Proving  ( LTP ) framework ( Moortgat , 1988; Lambek , 1958; van Benthem ,  1988) . In section ( 2 ) we give an introduction to a categorial calculus that is extended towards bidirectionality  . The naive topdown control strategy in this section does not suit the needs of efficient generation  . Next , we discuss two ways to implement a semantics -driven strategy  . Firstly , we add inference rules and cut rules geared to generation to the calculus  ( 3 )  . Secondly , since these changes in the calculus do not support bidirectionality  , we * We would llke to thank Gosse Bouma , Wietske Si~tsma and Marianne Sanders for their comments on an earlier draft of the paper  . 
2 20 introduce a second implementation : a bottom-up algorithm for the theorem prover  ( 4 )  . 
2EXTENDING THECAL-

Natural Language Processing as deduction The architectures in this paper resemble the uniform architecture in Shieber  ( 1988 ) because language processing is viewed as logical deduction  , in analysis and generation : " The generation of strings matching some criteria can equally well be thought of as a deductive process  , namely a process of constructive proof of the existence of a string that matches the criteria  . " ( Shieber , 1988, p .  614) . 
In the LTP framework a categorial reduction system is viewed as a logical calculus where parsing a syntagm is an attempto show that it follows from a set of axioms and inference rules  . These inference rules describe what he processor does in assembling a semantic representation  ( representational non-autonomy : Crain and Steedman  , 1982; Ades and Steedman ,  1982) . Derivation trees represent a particular parse process  ( Bouma ,  1989) . 
These rules thus seem to be nondeclarative , and this raises the question whether they can be used for generation  . The answer to this question will emerge throughout this paper  . 
Lexical information As in any categorial grammar , linguistic information iLTP is for the larger part represented with the signs in the lexicon and not with the rules of the calculus  ( signs are denoted by prosody : syntax : semantlcs )  . A generator using a categorial grammar needs lexical information about the syntactic form of a functor that is connected to some semantic func -totin order to syntactically correctly generate the semantic arguments of this functor  . For a parser , the reverse is true . In order to fulfil both needs , lexical information is made available to the theorem prover in the form of  in~t6aces of o ~ ionu . IAxioms then truely represent what should be axiomatic in a lexicalist description of a language : the\]exical items  , the connections between form and meaning .  2
I * sliaination rules */( U , \[Pros_Fu:X/Y:Functor\] , \[TIR\] , V ) =>\[ Z\]<-\[Pros_Fu:X/Y:Functor\]=>\[Pros_Fu : X/Y : Functor\]k\[TIR\]=>\[ProsArg:Y : Ar ~ k  ( U , \[(Pros_Fu*l~os_Arg):X:Functor@Arg\] , V ) =>\[ z\] . 
(U , \[T\[R\] , \[Pros_Fu:Y\X:Functor\] , V ) =>\[Z\]<-\[Pros_Fu:Y\X:Functor\]=>\[ Pros_Fu:Y\X:Functor\]k\[TIR\]=>\[Pros_arg : Y : krg\]k  ( U , \[(Pros_krg*Pros_Fu):X:FunctorQArg\] , V ) =>\[ z\] . 
Rules Whenever inference rules are applied , an attempt is made to axiomatize the functor that participates in the inference by the first subsequent of the elimination rules  . This way , lexical information is retrieved from the lexicon . 
/* introduction rulss*/\[T\[R\]=>\[Pros:Y\X : Var_Y'Tsra_X\]<-nogs nvar  ( Y\X ) k ( \[ id:Y:Var_Y\] , \[T\[R\])=>\[(id*Pros):X:Tarm_X\] . 
A prosodic operator connects prosodic elements . A prosodic identity element , i d , is necessary because introduction rules are prosodical \] yvacuous  . In order to avoid unwanted matching between axioms and id-elements  , one special ax-iota is added for id-elements . Meta-logical checks are included in the rules in order to avoid vsri-ables occuring in the final derivation  , no genv , 2r reeursively checks whether any part of an expression is a variable  . 
A sequent in the calculus is denoted with P => T , where P , called the antecedent , and T , the succedent , are finite sequences of signs . The calculus is presented in (1) . In what follows , X and ? are categories ; T and Z , are signs ; R , U and V are possibly empty sequences of signs ; @denotes functional application , a care t denotes ~- abstraction , s ( i ) /* axioms*/\[Pros:X:?\]=>\[Pros:X:Y\]<-\ [ Pros:l:Y\]=i >\[ Pros:X:Y\]k true  . 
\[ Pros:X:Y\]=>\[Pros:X:Y\]<-(nossnvar(X) , nonvar(Y )) k1; rue . 
\[TIR\]=>\[Pros:X/Y : Var_Y'T srm_X\]<- nogs nvar  ( X/Y ) k ( \[ T\[R\] , Cid:Y:Var_Y\])->\[(Pros*id):l:Term_X\] . 
/* axiom for prosodicid-element*/\[id:X:Y\]= i >\[ id:X:Y \] <- is vs  . r(Y) . 
/* lexicon , lexioms*/\[john:np:john\] =1> \ [ john:np:john\] . 
\[ mary:np:mexy\]=1>\[maxy:np:maxy\].
\[ loves: ( np\s ) /np:lovn\]=1>\[loves: ( np\s ) /np : lows\] . 
In order to initiate analysis , the theorem prover is presented with sequents like  ( 2 )  . Inference rules are applied recursively to the antecedent of the sequent until axioms are found  . This regime can be called topdown from the point of view of prob-\]em solving and bottom-up from a " parsing " point of view  . For generation , a sequent like ( 3 ) is presented to the theorem prover . Both analysis and generation result in a derivation like  ( 4 )  . Note that generation ot only results in a sequence of lexical signs  , but also in a peosodic pl ~ rasing that could be helpful for speech generation  . 
(2 ) l Vemder Linden and Minnen ( submitted ) contains a more elaborate comparison of the extended cu\]tm with the origins \] calculus as proposed in Moortgat  ( 1988 )  . 
2A suggestion similar to this proposal was made by K ~ nig  ( 1989 ) who stated that lexics I items are to be seen as axioms  , but did not include them as such in her description of the L-calculus  . 
SThroughout this paper we will use a Prolog notation because the architectures presented here depend partly on the Prologun\[i ~ cstlon mechanism  . 
221\[john:A:B , lovss:C:D , msxy:E:F\]=>\[Pros:s:Ssm\](3)
U =>\[ Pros:s:loves@maryQjohn\]
Although both (2) and (3) result (4) , in the case of generation ,   ( 4 ) does not represent he ( 4 ) john:np:john1 or*s : ( np\s ) /np:lovesma ~ ry:np:mary=>john* ( loves * mary ) : s:lovesQaary@john<-loves: ( np\s ) /np : loves=>loves: ( np\s ) /np : 1 oves <- loves: ( np\s ) / np : loves = I > loves: ( np\s ) / np :1oves <-true aary:np:aary=>aary:np:aary<- ms  . ry:np:aa~ry=I > aary:np:aary<-truejohn : np:Jolm loves*mary:np\s:lovea@aary=>j ohn *  ( loves * mary ) : s:loves@aary@jolm<-loves*aary:np\s: loves@mary=>loves*aary:np\s:loves@mary<- true john:np:john=>john:np:john<-john:np : john  -1> john:np:john<-truejohn* ( loves * aary ) : s:lovss@aaryQjohn=>john* ( loves * mary ) : s:loves@aary@john:<-true exact proceedings of the theorem prover  . It starts applying rules , matching them with the antecedent , without making use of the original semantic information  , and thus resulting in an inefficient and nondeterministic generation process : all possible derivations including all hxical items are generated until some derivation is found that results in the succedent  .   4 We conclude that the algorithm normally used for parsing in LTP is inefficient with respect o generation  . 
3 CALCULIDE SIGNED
FORGENERATION
A solution to the ei ~ ciency problem raised in the previous section is to start from the origi-hal semantics  . In this section we discuss calculit hat make explicit use of the original semantics  . 
Firstly , we present Lambek-like rules especially designed for generation  . Secondly , we introduce a Cut-rule for generation with sets of categorial reduction rules  . Both entail a variant of the crucial starting -point of the semantic-he~d-driven algorithms described in Calder et al  ( 1989 ) and Shieber et al ( 1989 ) : if the functor of a semantic representation can be identified  , and can be re-fated to a lexical representation containing syntactic information  , it is possible to generate the arguments yntactically  . The efficiency of this strategy stems from the fact that it is guided by the known semantic and syntactic information  , and lexical information is retrieved as soon as possible  . 
In contras to the semantic-head-driven al>-proach , our semantic representations do not allow for immediate recognition of semantic heads : these can only be identified after all arguments  4ef   . Shleber et el . (1989) on topdown generation algorithms .   2   2   2 have been stripped of the functor recursively ( loves@mary@john=:>loves@mary=>loves )  . 
Calder et al conjecture that their algorithm "( . . . ) extends naturally to the rules of composition , division and permutation of Combinatory Categorial Grammar  ( Steedman ,  1987 ) and the Lambek Calculus ( 1958 ) "  ( Calder et al ,  1989 , p . 

This conjecture should be handled with care . As we have stated before , inference rules in LTP describe ho ~ a processor operates  . An important difference with the categorial reduction rules of Calder et al is that inference  . rules in LTP implicitly initiate the recursion of the parsing and generation process  . Technically speaking , Lambek rules cannot be arguments of the rule -predicate of Calder et al  ( 1989 , p .  237) . The gist of our strategy is similar to theirs , but the algorithms dilTer . 
Lambek-llke generation Rules are presented in ( 5 ) that explicitly start from the known information during generation : the syntax and semantics of the succedent  . Literally , the inference rule states that a sequent consisting of an antecedent that unifies with two sequences of signs U and Y  , and a succedent that unifies with a sign with semantics Sem_FuQSem_Arg is a theorem of the calculus if Y reduces to a syntactic functor looking for an argument on its left side with the functor-meaning of the original semantics  , and U reduces to its argument . This rule is an equivalent of the second elimination rule in  ( I )  . 
(5) /* el ~ ination rule */ ~ , v \] =>\[ ( Pros_krg * Pros_Fu ) : X : Sem_Fu@Sea_krg\]<-
V =>\[ Pros_Fu:Y\X:Sen_Fu\]t
U =>\[ Pros_Arg:Y:Sen_krg\].
/* introduction-rule*/\[T\[R\]=>\[Pros:Y\l : Var_Y ' Tera_X\]<-nogen vsr  ( Y\X ) k ( CC id:Y : V nur_Y\]\] , CTIR\]) =>\[( id*Pros):X : Tora_l\] . 
4 ACOMBINED BOT-


In this section , we describe an algorithm for the theorem prover that proceeds in a combined bottom-up/top-down fashion from the problem solving point of view  . It maintains the same semantics-driven strategy , and enables efficient generation with the bidirectional calculus in  ( I )  . 
The algorithm results in derivations like (4) , in the same theorem prover architecture , be it along another path . 
A Cut-rule for generation A Cut-rule is a structural rule that can be used within the L -calculus to include partial proofs derived with categorial reduction rules into other proofs  . In ( 6 ) a generation Cut-rule is presented together with the AB-system  . 
(6) /* Cut-rule for generation */\ [ U . V\]=>\[Pros_Z:Z:Su_Z\]<-\[Pros_X:X:Sem_X , Pros_Y:Y : Sem_Y\]=*>\[Pros_g:z:sem_Z\]
U =>\[ Pros_Z:X:Sem_Z\]
Vffi >\[ Proe_Y:Y : Sem_Y\].
/* reduction rules , system AB*/\[Pros_Fu:X/Y:Functor . lhcos_Arg:Y:lrg\]=*> ( Pros_FU * Pros_Arg ) :X:Functor@Arg\] . 
\[ Pros_Arg:Y : Arg , Pros_Fu:Y\l:Functor \] =*> ( Pros . Arg*Pros_Fu):X:Functor@ArS\] . 
The generator regimes presented in this section are semantics-driven : they start from a semantic representation  , assume that it is part of the uppermost sequent within a derivation  , and work towards the lexical items , axioms , with the recursive application of inference rules  . From the point of view of theorem proving , this process should be described as a topdown problem solving strategy  . The rules in this section are , however , geared towards generation . Use of these rules for parsing would result in massive nondeterminism  . El-ficient parsing and generation require different rules : the calculus is not bidirectioaal  .   223 Bidirectionality There are two reasons to avoid duplication of grammars for generation and interpretation  . Firstly , it is theoretically more elegant and simple to make use of one grammar  . 
Secondly , for any language processing system , human or machine , it is more economic ( Bunt ,  1987 , p .  333) . Scholars in the area of language generation have therefore pleaded in favour of the bidirectional it ~ of linguistic descriptions  ( Appelt ,  1987) . 
Bidirectionality might in the first place be implemented by using one grammar and two separate algorithms for analysis and generation  ( Jacobs , 1985; Calder et el . , 1989) . However , apart from the desirability to make use of one and the same grammar for generation and analysis  , it would be attractive to have one and the same processiag architecture for both analysis and generation  . Although attempts to find such architectures ( Shieber ,  1988 ) have been termed " looking for the fountain of youth '  , s it is a stimulating question to what ext it is possible to use the same architecture for both tasks  . 
Example An example will illustrate how our algorithm proceeds  . In order to generate from a sign , the theorem prover assumes that it is the succedent of one of the subsequeats of one of the inference rules  ( 7-1/2 )  .   ( In case of an introduction rule the sign is matched with the succedent of the head seq ~ en ~  ; this implies a topdown step . ) If unification with one of these subse-quents can be established  , the other subsequents and the head sequent can be partly instantiated  . 
These sequents can then serve as starting points for further bottom-up processing  . Firstly , the head sequent is subjected to bottom-up rocess -SR on Kaplan during discussion of the $ hieber presentation at Coling  1988  . 
Generation of noun phrase ~ he ~ abie . Start with sequent
P =>\[ Pros:np:the@table\]l-Assume suecedent is part of an axiom : \[ Pros:np:  the0t able\]=>\[Pros:np:the@table\] 2- Matchaxiom with last subsequent of an inference rule:  ( U , \[ Pros_Fu : X/Y : Functor\] , \[ T\[I  ~ , V ) =>\[Z\]<-\[Pros_Fu:X/Y:Functor\]=>\[ Pros_Fu:X/Y:Functor\]&\[T\[R\]=>\[ Pros_krg:Y : Arg\]&  ( U , \[( Pros_Fu * Pros_Arg ): X : Functor@~g\] , V ) =>\[ Z\] . 
Z = Pros:np:the@table ; Functor : the ; Arg = table ; X = np ; U =\[\] ; V =\[\] . 
3- Derive instantiated head sequent : \[ Pros_Fu : np/Y:the\]  , \[ T\[R\]=>\[Pros:rip: the0table  \]  4- No more applications in head sequent : Prove ( bottom-up ) first instantiated subsequent :\[ Pros_Fu : np/Y : the\]  , ,> \[ Pros_Fu : np/Y : the \] Unifies with the axiom for " the ": Pros_Fu = the  ; Y = n . 
5-Prove ( bottom-up ) second instantiated subsequent : \[ T\[R\]=> \[ Pros_Arg:n:"~able\]Unifies with axiom for " table ": Pros_Arg = table  ; T = table:n:table ; R =\[\] 6-Prove ( bottum-up ) last subsequent : is a nonlexical ax/om . 
\[  ( the * table ) : np : the@table\]=>\[ ( the * table ) : np : the Q table\] . 
7- Final derivation : the : np / n : the tab le : n : tab le => the*table:np  . the@table<-the:np/n:the=>the:np/n : the <- the:np/n:the  =1> the:np/n:the<-truetable:n:table = > table:n:table<-table:n:table=i > tabls:n:table<-true the*table:np:the@table = > the*table:np:the@table<-true as soon as possible  . Bottom-u processing stops when no more application operators can be elim-insted from the head sequent  ( 7-4 )  . Secondly , working topdown , the other subsequents ( 7-4/5 ) are made subject obottom-up rocessing , and at last the last subsequent (7-6) . (7) presents generation of a noun phrsse , the ~ able . 
Non-determinism A source for non-determin-is min the semantics-driven strategy is the fact that the theorem proverforms hypotheses about the direction a functor seeks its arguments  , and then checks these agains the lexicon . A possibility here would be to use a calculus where dora-inance and precedence are taken apart  . We will pursuer ids suggestioni future research . 
5 CONCLUDING

Implementation The algorithms and calculi presented here have been implemented with the use of modified versions of the categorial calculi interpreter described in Moortgat  ( 1988 )  . 
Conclusion Efl\]cient , bidirectional use of categorial calculi is possible if extensions are made with respect o the calculus  , and ifs combined bottom-up/top-down algorithm is used for generation  . Analysis and generation take place within the same processing architecture  , with the same linguistics descriptions , be it with the use of different algorithms . LTP thus serves as a natural candidate for a uniform architecture of parsing and generation  . 
Semantic non-monotonieity A constraint on grammar formalisms that can be dealt within current generation systems is semantic monotonicity  ( Shieber , 1988; but cf . Shieber et al , 1989) . The algorithm in Calder et al ( 1989 ) requires an even stricter constaint . Firstly , in van der Linden and Minnen ( submitted ) we describe how the addition of a unification -based semantics to the calculus described here enables processing of nonmonotonic phenomena such as noncompositional verb particles and idioms  . Identity semantics ( cf . Calder et alp . 235) should be no problem in this respect . Secondly , unary rules and typeraising ( ibid . ) are part of the L-calculus , and are neither fundamental problems . 
Inverse E-reduction A problem that exists for all generation systems that include some form of ~- semantics is that generation ecessitates the inverse operation of ~- reduction  . Although we have implemented algorithms for inverse E-reduction  , these are not computationally tractable , A way out could be the inclusion of a unification based semantics  . 7 SBunt ( 1987 ) states that an expression with n constants results in  2 n - 1 possible inverse ~- reduct lons . 
7As proposed in van der Linden and Minnen ( submit-ted ) for the calculus in ( 2 )  . 2256 REFERENCES Ades , A . , and Steedman , M . , 1982 On the order of words . Linguistics and Pkilosoph ~/, 4, pp .  517-558 . 
Appelt , D . E . ,  1987 Bidirectional Grammars and the Design of Natural Language Systems  . In Wilks , Y . ( Ed . ) , Theoretical Issues in Natural Language Processing  . Las Cruces , New Mexico : New Mexico State University , January 79 , pp . 

Van Benthem , J ., 1988 Categorial Grammar.
Chapter 7 in Van Benthem , J . , Essays in Logical Semantics . Reidel , Dordrecht . 
Boums , G . ,  1989 Emcient Processing of Flexible Categorial Grammar  . In Proceedings of the
EACL 1989, Manchester . pp . 1926.
Bunt , H . ,  1987 Utterance generation from semantic representations augmented with pragmatic information  . In Kempen 1987 . 
Calder , J . , Reape M . , and Zeevat , H . ,  1989 An algorithm for generation in Unification Categorial Grammar  . In Proceedings of the EACL 1989,
Manchester . pp . 233-240.
Crain , S . , and Steedman , M . , 1982 On not being led up the garden path . In Dowry , Karttunen and Zwicky ( Eds . ) Natu ~ l language pQrsing . Cambridge : Cambridge University Press . 
Jacobs , P . , 1985 PHRED , A generator for Natural Language Interfaces . Computational Linguistics 11, 4, pp .  219-242 . 
Kempen , G . , ( Ed . )  1987 Natural language generation : new results in artificial intelligence  , pay . 
ct to logy and linouiatics . Dordrecht : Nijhoff.
K 6nig , E . , 1989 Parsing as nature deduction . In Proceedings of the ACL 1989, Vancouver . 
Lsmbek , J . , 1958 The mathematics of sentence structure . Am . Math Monthly , 85, 154-169 . 
Linden , E . vander , and Minnen , G . ,  ( submitted ) An account of Non-monotonous phenomena in bidirectional Lambek Theorem Proving  . 
Moortgat , M ., 1988 Categorial Inueatigetions.
Logical and Hnguistic ? apects of the Lambek calculus  . Disseration , University of Amsterdam . 
Shieber , S . ,  1988 A uniform architecture for Parsing and Generation  . In Proceedings of Coling 1988, Budapest , pp .  614-619 . 
Shieber , S . , van Noord , G . , Moore , R . , and Pereira , P . ,  1989 A semantic-Head-Driven Generation Algorithm for Unification-Based For-malls ms  . In Proceedings of ACL 1989 Vancouver . 
Steedman , M . ,  1987 Combinatory Grammars and Parasitic Gaps Natural Language and Linguistic 
Theory , 5, pp . 403-439.

