A Unified Statistical Model for the Identification of English 

Endong Xun
Microsoft Research China
No . 49 Zhichun Road Haidian District
100080, China,

Ming Zhou
Microsoft Research China
No . 49 Zhichun Road Haidian District
100080, China,

Changning Huang
Microsoft Research China
No . 49 Zhichun Road Haidian District
100080, China,


This paper presents a novel statistical
model for automatic identification of
English base NP . It uses two steps : the N -
bestPart-Of-Speech ( POS ) tagging and
base NP identification given the Nbest
POS-sequences . Unlike the other
approaches where the two steps are
separated , we integrate them into a unified
statistical framework . Our model also
integrates lexical information . Finally,
Viterbi algorithm is applied to make
global search in the entire sentence,
allowing us to obtain linear complexity for
the entire process . Compared with other
methods using the same testing set , our
approach achieves 92 . 3% in precision and 93 . 2% in recall . The result is comparable with or better than the previously reported results  . 
1 Introduction
Finding simple and nonrecursive base Noun Phrase ( base NP ) is an important subtask for many natural language processing applications  , such as partial parsing , information retrieval and machine translation . A base NP is a simple noun phrase that does not contain other noun phrase recursively  , for example , the elements with in [ . . . ] in the following example are base NPs , where NNS , INVB Getcare part-of-speech tags [ as defined in M  . Marcus 1993] . 
[Measures/NNS]of/IN [ manufacturing/VBG activity /NN]fell/VBD more/RBR than/IN [ the/DT over all /JJ measures/NNS]  . / . 
Figure 1: An example sentence with base NP brackets A number of researchers have dealt with the problem of base NP identification  ( Church 1988 ; Bourigault 1992 ; Voutilainen 1993 ; Justeson & Katz 1995) . Recently some researchers have made experiments with the same test corpus extracted from the  20th section of the Penn Treebank Wall Street Journal ( Penn Treebank )  . 
Ramshaw & Markus ( 1998 ) applied transform-based error-driven algorithm ( Brill 1995 ) to learn a set of transformation rules , and using those rules to locally updates the bracket positions  . Argamon , Dagan & Krymolowski ( 1998 ) introduced a memory-based sequences learning method  , the training examples are stored and generalization is performed at application time by comparing subsequence of the new text to positive and negative evidence  . 
Cardie & Pierce ( 1998 1999 ) devised error driven pruning approach trained on Penn Treebank  . It extracts base NP rules from the training corpus and prune some bad base NP by incremental training  , and then apply the pruned rules to identify base NP through maximum length matching  ( or dynamic program algorithm )  . 
Most of the prior work treats POS tagging and base NP identification as two separate procedures  . However , uncertainty is involved in both steps . Using the result of the first step as if they are certain will lead to more errors in the second step  . A better approach is to consider the two steps together such that the final output takes the uncertainty in both steps together  . The approaches proposed by Ramshaw & Markus and Cardie & Pierce are deterministic and local  , while Argamon , Dagan & Krymolowski consider the problem globally and assigned a score to each possible base NP structures  . 
However , they did not consider any lexical information . 
This paper presents a novel statistical approach to base NP identification  , which considers both steps together within a unified statistical framework  . It also takes lexical information into account . In addition , in order to make the best choice for the entire sentence  , Viterbi algorithm is applied . Our tests with the Penn Treebank showed that our integrated approach achieves  92  . 3% in precision and 93 . 2% in recall . The result is comparable or better that the current state of the art  . 
In the following sections , we will describe the detail for the algorithm , parameter estimation and search algorithms in section  2  . The experiment results are given in section 3 . In section 4 we make further analysis and comparison . In the final section we give some conclusions . 
2 The statistical approach
In this section , we will describe the two-pass statistical model , parameters training and Viterbi algorithm for the search of the best sequences of POS tagging and base NP identification  . Before describing our algorithm , we introduce some notations we will use 2 . 1 Notation Let us express an input sentence E as a word sequence and a sequence of POS respectively as follows : n n w w w w E  121   . . . ? = nnttttT 121 . . .  ?=
Where n is the number of words in the sentence , it is the POS tag of the word iw . 
Given E , the result of the base NP identification is assumed to be a sequence  , in which some words are grouped into base NP as follows  . . . ] . . . [ . . .   111 + + ? j j i i i i i i i w w w w The corresponding tag sequence is as follows:  ( a ) m j j i i j j i i i n n n t b t t t t t B . . . . . . . . . . . .] . . . [ . . .  211 , 1111 == + ? + + + ? In which jib , corresponds to the tag sequence of a base NP :] . . . [1 ji it tt + . jib , may also be thought of as a base NP rule . Therefore B is a sequence of both POS tags and base NP rules  . 
Thus ??? in nm , 1 ( POS tagset ? base NP rules set) , This is the first expression of a sentence with base NP annotated  . Sometime , we also use the following equivalent form : ( b ) n j j j j j i i i i i i i i i i i i i i i m t b m t b m t b m t b m t Q . . . ) . . . ,(),() . . . ,(),(), . . . (  21111111 = = + + + + ? ? Where each POS tag it is associated with its positional information ibm with respect to base NPs  . The positional information is one of ,, ,, SOEIF . F , E and I mean respectively that the word is the left boundary  , right boundary of a base NP , or at another position inside a base NP . O means that the word is outside a base NP . Smarks a single word base NP . This second expression is similar to that used in [ Marcus  1995]  . 
For example , the two expressions of the example given in Figure  1 are as follows: ( a ) B = [ NNS]IN[VBGNN]VBDRBRIN[DTJJNNS ]   ( b ) Q = ( NNSS )   ( INO )   ( VBGF )   ( NNE )   ( VB DO )   ( RBR
O ) ( INO ) ( DTF)(JJI ) ( NNSE)( . O ) 2 . 2 An ? integrated ? two-pass procedure The principle of our approach is as follows  . The most probable base NP sequence * B may be expressed generally as follows:  ) ) ( ( maxarg * EBpB
B =
We separate the whole procedure into two passes , i . e . :)),()(( maxarg * ETBPETPB
B??(1)
In order to reduce the search space and computational complexity  , we only consider the
Nbest POS tagging of E , i.e.
))(( maxarg ) ( , . . ., 1

NTTT == ?(2)
Therefore , we have :)), ( )(( maxarg , ...,,*
NTTTB ??= (3)
Correspondingly , the algorithm is composed of two steps : determining the Nbest POS tagging using Equation  ( 2 )  . And then determining the best base NP sequence from those POS sequences using Equation  ( 3 )  . One can see that the two steps are integrated together  , rather that separated as in the other approaches . Let us no we xamine the two steps more closely . 
2 . 3 Determining the N best POS sequences The goal of the algorithm in the  1st pass is to search for the Nbest POS-sequences within the search space  ( POS lattice )  . According to Bayes ?
Rule , we have )()()()(

TPTEPETP ? =
Since ) ( EP does not affect the maximizing procedure of ) ( ETP , equation (2) becomes ))()(( maxarg ))(( maxarg )( ,  . . . ,, . . . , 11

NNTTTTTT ?==?== (4)
We now assume that the words in E are independent . Thus ? = ? niiit wPTEP (5)
We then use a trigram model as an approximation of  ) ( TP , i . e . : ? = ? ? ? n i ii iit t tPTP
Finally we have ))(( maxarg ) (, . . ., 1

NTTT == ?)),( )(( maxarg 121, . . . , 1 ? ? = = ? = ? i i i n i i i
TTTt ttP twP
N (7)
In Viterbi algorithm of Nbest search ,   ) ( ii twP is called lexical generation ( or output ) probability , and ) , (  12 ? ? iiitttP is called transition probability in Hidden Markov Model  . 
2.3.1 Determining the base NPs
As mentioned before , the goal of the 2nd pass is to search the best base NP-sequence given the Nbest POS-sequences  . 
Considering E , T and B as random variables , according to Bayes ? Rule , we have )() , ()() , (

TBEPTBPETBP ? =
Since )( )( )( )(

BPBTPTBP ?= we have , )( )( )(), (

BPBTPTBEPETBP ? ? ?= (8)
Because we search for the best base NP sequence for each possible POS-sequence of the given sentence E  , so constTEPTPTEP = ?=?)()()( , Furthermore from the definition of B , during each search procedure , we have ? = == nijijibttPBTP1) ,  . . . ,()(  . Therefore , equation (3) becomes )), ( )(( maxarg, . . . ,, *
NTTTB ?==))()(( maxarg , ...,,1

NTTTB ??== (9) using the independence assumption , we have ? = ? niiii  bmtwPTBEP ( 10 ) With trigram approximation of ) ( BP , we have : ? = ? ? ? mi ii in nnPBP
Finally , we obtain )) , () , ()(( maxarg , 1 * = ? ? = = ? ?= m i i i i n i i i i
TTTB nnnP tbmwPETPB
N   12  
To summarize , In the first step , Viterbi Nbest searching algorithm is applied in the POS tagging procedure  , It determines a path probability tf for each POS sequence calculated as follows : ? = ? ? ? = n i i i i i i i i t t t t p t w p f  , 1 12 ) , ()(  . 
In the second step , for each possible POS tagging result , Viterbi algorithm is applied again to search for the best base NP sequence  . Every base NP sequence found in this pass is also asssociated with a path probability ?? = ?? = ? = m i i i i i i i i i i i i i b n n  n p b m t w p f  , 1 ) , () , (  . 
The integrated probability of a base NP sequence is determined by btff ??  , where ? is a normalization coefficient (?4 . 2= in our experiments ) . When we determine the best base NP sequence for the given sentence E  , we also determine the best POS sequence of E , which corresponds to the best base NP of E . 
Now let us illustrate the whole process through an example : ? stock was down  9  . 1 points yesterday morning . ? . In the first pass , one of the Nbest POS tagging result of the sentence is : T = 
NN VB DRB CD NNS NN NN . For this POS sequence , the 2nd pass will try to determine the base NPs as shown in Figure  2  . The details of the path in the dash line are given in Figure  3  , Its probability calculated in the second pass is as follows  ( ? is pseudovariable ) :  )  , () , () , () , () , ( BCDNUMBER pORB down pOVBD was pSNN stock pETBP ???=) . ,( . ) , () , () , int(OpENN morning pBNN yesterdaypENNS spop ????) , ]([)] , [(])[ , () , ]([RB VBDNNSCD pVBDNNRB pNNVBD pNN p ? ??????]) [] , [( . ])[ , ] ( [ NN NN NN NS CD p NN SCD RB NN NN Np ?? Figure 2: All possible brackets of " stock was down 9  . 1 points yesterday morning " Figure 3: the transformed form of the path with dash line for the second pass processing  2  . 4 The statistical parameter training In this work , the training and testing data were derived from the  25 sections of Penn Treebank . 
We divided the whole Penn Treebank data into two sections  , one for training and the other for testing . 
As required in our statistical model , we have to calculate the following four probabilities :  ( 1 )   )  , (12 ?? ii it ttP , (2)) ( i it wP , (3)) (12 ? ? ii in nnP and (4)) , ( iiibmt wP . The first and the third parameters are trigrams of T and B respectively  . The second and the fourth are lexical generation probabilities  . Probabilities ( 1 ) and ( 2 ) can be calculated from POS tagged data with following formula e : ? ? ? ? ? ? ? = j j i i i ii ii ii ttt count ttt count tttp  ) (  ) ( )  , (  ) (  ) ( ) ( i ii ii tcount ttagwithwcount twp = ( 14 ) As each sentence in the training set has both POS tags and base NP boundary tags  , it can be converted to the two sequences as B ( a ) and Q ( b ) described in the last section . Using these sequences , parameters (3) and (4) can be calculated , The calculation formulas are similar with equations  ( 13 ) and ( 14 ) respectively . 
Before training trigram model (3) , all possible base NP rules should be extracted from the training corpus  . For instance , the following three sequences are among the base NP rules extracted  . 
There are more than 6 , 000 base NP rules in the Penn Treebank . When training trigram model (3) , we treat those base NP rules in two ways .   ( 1 ) Each base NP rule is assigned a unique identifier ( UID )  . This means that the algorithm considers the corresponding structure of each base NP rule  . 
(2 ) All of those rules are assigned to the same identifier  ( SID )  . In this case , those rules are grouped into the same class . Nevertheless , the identifiers of base NP rules are still different from the identifiers assigned to POS tags  . 
We used the approach of Katz ( Katz . 1987) for parameter smoothing , and build a trigram model to predict the probabilities of parameter  ( 1 ) and ( 3 )  . In the case that unknown words are encountered during base NP identification  , we calculate parameter ( 2 ) and ( 4 ) in the following way : 2 ) ) , (( max ) , () , ( ijj ii iii tbmcount tbmcount tbmwp = ( 15 )  2 ) ) ( ( max ) ( ) ( jj i ii tcount tcount twp = ( 16 ) Here , jbm indicates all possible base NP labels attached to it  , and jt is a POS tagguessed for the unknown word iw  . 
3 Experiment result
We designed five experiments as shown in Table 1 . ? UID ? and ? SID ? mean respectively that an identifier is assigned to each base NP rule or the same identifier is assigned to all the base NP rules  .   ?+1? and ?+4? denote the number of beat POS sequences retained in the first step  . And ? UID+R ? means the POS tagging result of the given sentence is totally correct for the  2nd step . 
This provides an ideal upper bound for the system . The reason why we choose N=4 for the Nbest POS tagging can be explained in Figure  4  , which shows how the precision of POS tagging changes with the number N  . 
96 .  95 97 .  00 97 .  05 97 .  10 97 .  15 97 .  20 97 .  25 97 .  30 97 .  35 97 .  40 97 .   45   1   2   3   4   5   6 Figure 4: POS tagging precision with respect to different number of Nbest In the experiments  , the training and testing sets are derived from the  25 sections of Wall Street Journal distributed with the Penn Treebank II  , and the definition of base NP is the same as Ramshaw?s  , Table 1 summarizes the average performance on both base NP tagging and POS tagging  , each section of the whole Penn Treebank was used as the testing data and the other  24 sections as the training data , in this way we have done the crossvalidation experiments  25 times . 
Precision ( base NP %)
Recall ( base NP %)
FMeasure ( base NP %) 2
RP+(base NP %)
Precision(POS %)
UID +192.75 93.30 93.02 93.02 97.06
UID +492.80 93.33 93.07 93.06 97.02
SID+18 6.999 0.148 8.548 8.569 7.06
SID+4 86.99 90.16 88.55 88.58 97.13
UID+R 93.44 93.95 93.69 93.70 100
Table 1 The average performance of the five experiments 88  .  00 88 .  50 89 .  00 89 .  50 90 .  00 90 .  50 91 .  00 91 .  50 92 .  00 92 .  50 93 .  00 1 2 3 4 5 6
UID+1
UID +4
UID + R
Figure 5: Precision under different training sets and different POS tagging results  91  .  60 91 .  80 92 .  00 92 .  20 92 .  40 92 .  60 92 .  80 93 .  00 93 .  20 93 .  40 93 .  60 1 2 3 4 5 6
UID+1
UID +4
UID + R
Figure 6: Recall under different training sets and different POS tagging results  96  .  80 96 .  85 96 .  90 96 .  95 97 .  00 97 .  05 97 .  10 97 .  15 97 .  20 1 2 3 4 5 6
Viterbi
UID +4
SID +4
Figure 7: POS tagging precision under different training sets Figure  5   -7 summarize the outcomes of our statistical model on various size of the training data  , x-coordinate denotes the size of the training set  , where "1" indicates that the training set is from section 0-8th of Penn Treebank ,   "2" corresponds to the corpus that add additional three sections  9-11th into "1" and so on . In this way the size of the training data becomes larger and larger  . In those cases the testing data is always section  20   ( which is excluded from the training data )  . 
From Figure 7 , we learned that the POS tagging and base NP identification are influenced each other  . We conducted two experiments to study whether the POS tagging process can make use of base NP information  . One is UID +4 , in which the precision of POS tagging dropped slightly with respect to the standard POS tagging with 
Trigram Viterbi search . In the second experiment SID+4 , the precision of POS tagging has increase slightly  . This result shows that POS tagging can benefit from base NP information  . 
Whether or not the base NP information can improve the precision of POS tagging in our approach is determined by the identifier assignment of the base NP rules when training trigram model of  )  , (12 ?? ii in nnP . In the future , we will further study optimal base NP rules clustering to further improve the performances of both base NP identification and 
POS tagging.
4 Comparison with other approaches
To our knowledge , three other approaches to base NP identification have been evaluated using 
Penn Treebank-Ramshaw & Marcus?s transformation based chunker  , Argamon et al?s MBSL , and Cardie?s Treebank_lex in Table 2 , we give a comparison of our method with other these three  . In this experiment , we use the testing data prepared by Ramshaw ( available at http://www . cs . biu . ac . il / ~ yuvalk/MBSL ) , the training data is selected from the 24 sections of Penn Treebank ( excluding the section 20 )  . We can see that our method achieves better result than the others  . 
Transformation-Based ( Training data : 200k)
Treebank_LexMBSL Unified Statistical
Precision (%) 91.8 89.0 91.6 92.3
Recall (%) 92.3 90.9 91.6 93.2
FMeasure (%) 92.0 89.9 91.6 92.7
Table 2: The comparison of our statistical method with three other approaches Transforamtion-Based Treebank_LexMBSL Unified Statistical 
Unifying POS & base NPNONONOYES
Lexical Information YESYES NOYES
Global Searching NONOYESYES
Context YES NOY ESYES
Table 3: The comparison of some characteristics of our statistical method with three other approaches Table  3 summarizes some interesting aspects of our approach and the three other methods  . Our statistical model unifies base NP identification and POS tagging through tracing Nbest sequences of POS tagging in the pass of base NP recognition  , while other methods use POS tagging as a preprocessing procedure  . From Table 1 , if we reviewed 4best output of POS tagging , rather that only one , the Fmeasure of base NP identification is improved from  93  . 02% to 93 . 07% . After considering base NP information , the error ratio of POS tagging is reduced by 2 . 4% ( comparing SID+4 with

The transformation based method ( R&M 95 ) identifies base NP within a local windows of sentence by matching transformation rules  . 
Similarly to MBSL , the 2nd pass of our algorithm traces all possible base NP brackets  , and makes global decision through Viterbi searching  . On the other hand , unlike MSBL we take lexical information into account  . The experiments show that lexical information is very helpful to improve both precision and recall of base NP recognition  . If we neglect the probability of ? = n i iii bmtwP the precision/recall ratios are reduced to  90  . 0/92 . 4% from 92 . 3/93 . 2% . Cardie?s approach to Treebank rule pruning may be regarded as the special case of our statistical model  , since the maximum-matching algorithm of base NP rules is only a simplified processing version of our statistical model  . Compared with this rule pruning method , all base NP rules are kept in our model . Therefore in principle we have less likelihood of failing to recognize base NP types As to the complexity of algorithm  , our approach is determined by the Viterbi algorithm approach  , or ) ( nO , linear with the length . 
5 Conclusions
This paper presented a unified statistical model to identify base NP in English text  . Compared with other methods , our approach has following characteristics : ( 1 ) base NP identification is implemented in two related stages : Nbest POS taggings are first determined  , then base NPs are identified given the Nbest POS -sequences  . Unlike other approaches that use POS tagging as preprocessing  , our approach is not dependant on perfect POS tagging  , Moreover , we can apply base NP information to further increase the precision of POS tagging can be improved  . 
These experiments triggered an interesting future research challenge : how to cluster certain base NP rules into certain identifiers so as to improve the precision of both base NP and POS tagging  . This is one of our further research topics . 
(2 ) Our statistical model makes use of more lexical information than other approaches  . Every word in the sentence is taken into account during base NP identification  . 
(3 ) Viterbi algorithm is applied to make global search at the sentence level  . 
Experiment with the same testing data used by the other methods showed that the precision is  92  . 3% and the recall is 93 . 2% . To our knowledge , these results are comparable with or better than all previously reported results  . 

Eric Brill and Grace Ngai . (1999) Man vs . machine : A case study in base NP learning . In Proceedings of the 18th International Conference on Computational
Linguistics , pp . 65-72. ACL?99
S . Argamon , I . Dagan , and Y . Krymolowski ( 1998 ) A memory-based approach to learning shallow language patterns  . In Proceedings of the 17th International Conference on Computational
Linguistics , pp . 67-73. COLING-ACL?98
Cardie and D . Pierce ( 1998 ) Error-driven pruning of treebank grammas for base NP identification  . In Proceedings of the 36th International Conference on Computational Linguistics  , pp . 218-224 . 

Lance A . Ramshaw and Michael P . Marcus ( In Press) . Text chunking using transformationbased learning . In Natural Language Processing Using Very large Corpora  . Kluwer . Originally appeared in The second workshop on very large corpora 
WVLC?95, pp . 82-94.
Viterbi , A . J .   ( 1967 ) Error bounds for convolution codes and asymptotically optimum decoding algorithm  . IEEE Transactions on Information Theory IT-13 ( 2 ) : pp . 260-269, April , 1967 S . M . Katz . (1987 ) Estimation of probabilities from sparse data for the language model component of speech recognize  . IEEE Transactions on Acoustics , Speech and Signal Processing . Volume ASSP-35, pp . 400-401, March 1987 Church , Kenneth .   ( 1988 ) A stochastic parts program and noun phrase parser for unrestricted text  . In Proceedings of the Second Conference on Applied Natural Language Processing  , pages 136143 . 
Association of Computational Linguistics.
M . Marcus , M . Marcinkiewicx , and B . Santorini ( 1993 ) Building a large annotated corpus of English : the Penn Treebank  . Computational
Linguistics , 19(2):313-330
