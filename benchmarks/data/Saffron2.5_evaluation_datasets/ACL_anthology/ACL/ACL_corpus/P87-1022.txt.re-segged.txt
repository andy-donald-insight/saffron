ACENTERING APPROACH TO PRONOUNS
Susan E . Brennan , Marilyn W . Friedman , Carl J . Pollard
Hewlett-Packard Laboratories
1501 Page Mill Road
Palo Alto , CA 94304, USA
Abstract
In this paper we present a formalization of the centering approach to modeling attentional structure in discourse and use it as the basis for an algorithm to track discourse context and bind pronouns  . As described in \[ GJW 86\] , the process of centering attention on entities in the discourse gives rise to the intersentential transitional states of continuing  , re ~ aining and shifting . We propose an extension to these states which handles some additional cases of multiple ambiguous pronouns  . The algorithm has been implemented in an HPSG natural language system which serves as the interface to a database query application  . 
1 Introduction
In the approach to discourse structure developed in\[  Sid83\] and \[ GJW86\]  , a discours exhibits both global and local coherence  . On this view , a key element of local coherence is centering , a system of rules and constraints that govern the relationship between what the discourse is about and some of the linguistic choices made by the discourse participants  , e . g . choice of grammatical function , syntactic structure , and type of referring expression ( proper noun , definite or in definite description , reflexive or personal pronoun , etc . ) . Pronominalization i particular serves to focus attention on what is being talked about  ; inappropriate use or failure to use pronouns causes communication to be less fluent  . For instance , it takes longer for hearers to process a pronominalized noun phrase that is no ~ in focus than one that is  , while it takes longer to process a non -pronominalized noun phrase that is in focus than one that is not\[  Gui85\]  . 
The\[ GJW86\] centering model is based on the following assumptions  . A discourse segment consists of a sequence of utterances  U1   .   .   .   .   . U , ~ . With each utterance U a is associated a list of forward  . looking cen-~ers , C f(U , ) , consisting of those discourse entities that are directly realized or realized I by linguistic expressions in the utterance  . Ranking of an entity on this list corresponds roughly to the likelihood that it will be the primary focus of subsequent discourse  ; the first entity on this list is the preferred cen~er  , C p(U , O . 
U , ~actually centers , or is " about " , only one entity at a time , the backward-looking cen~er , Cb(U =) . The backward center is a confirmation of an entity that has already been introduced into the discourse  ; more specifically , it must be realized in the immediately preceding utterance  , Un-1 . There are several distinct types of transitions from one utterance to the next  . 
The typology of transitions is based on two factors : whether or not the center of attention  , Cb , is the same from Un-1 to Un , and whether or not this entity coincides with the preferred center of U  , ~ . Definitions of these transition types appear in figure  1  . 
These transitions describe how utterances are linked together in a coherent local segment of discourse  . If a speaker has a number of propositions to express  , on every simple way to do this coherently is to express all the propositions about a given entity  ( continuing ) before introducing a related entity 1U directly realizes c if U is an utterance ( of some phrase , not necessarily a full clause ) for which c is the semantic interpretation , and U realizes c if either c is an element of the situation described by the utterance U or c is directly realized by some subpart of U  . Realizes is thus a generalization of irectly realizes \[ G  JW86\]  . 
155 cK ~) = cM ~) cKu .)  #cv(~.)
Cb(U .) = Cb(U._,)Cb(U.)#Cb(U._,)



Figure 1: Transition States ( retaining ) and then shifting the center to this new entity . See figure 2 . Retaining may be a way to signal an intention to shift  . While we do not claim that speakers really behave in such an orderly fashion  , an algorithm that expects this kind of behavior is more successful than those which depend solely on recency or parallelism of grammatical function  . The interaction of centering with global focusing mechanisms and with other factors such as intentional structure  , semantic selectional restrictions , verb tense and aspect , modality , intonation and pitch accent are topics for furthere search  . 
Note that these transitions are more specific than focus movement as described in \[  Sid83\]  . The extension we propose makes them more specific still  . Note also that the Cb of \[ GJW86\] corresponds roughly to Sidner's discourse focus and the Cf to her potential foci  . 
The formal system of constraints and rules for centering  , as we have interpreted them from \[ GJW86\] , are as follows . For each \[7, in \[71, . . . , U , n : ? CONSTRAINTS 1 . There is precisely one Cb . 
2 . Every element of Cf(Un ) must be realized in U, . 
3. Cb(Un ) is the highestranked element of
Cf(U , -1) that is realized in U , .
? RULES 1 . If some element of Cf(U , -1) is realized as a pronoun in U , , then so is Cb(U , ) . 
2 . Continuing is preferred over retaining which is preferred over shifting  . 
As is evident in constraint 3 , ranking of the items on the forward center list , Cf , is crucial . We rank the items in Cf by obliqueness of grammatical relation of the subcategorized functions of the main verb : that is  , first the subject , object , and object 2 , followed by other subcategorized functions , and finally , adjuncts . 
This captures the idea in \[ GJW86\] that subjecthood contributes strongly to the priority of an item on the 


Un+l : Carlworks att IP on the Natural Language

Cb:\[POLLARD:Carl\]
Of : ( \[POLLARD:Carl\]\[HP:HP\]\[NATLANG : Natural Language Project \]  ) 

U , +2: Hemanages Lyn.
Cb:\[POLLARD:Carl\]
CI:(\[POLLARD:A1\][FRIEDMAN : Lyn\])
He = Carl

Un+3: He promised together araise.
Cb:\[POLLARD:A1\]el: ( \[POLLARD:A2\][FRIED MAN:A3\]\[I~AISE : Xl\] ) 
He = Carl , her = Lyn

\[/,+4: She doesn't believe him.
Cb:\[POLLARD:A2\]
Cf:(\[FRIED MAN:A4\]\[POLLARD:AS\])
She=Lyn , him =  Carl
Figure 2
We are aware that this ranking usually coincides with surface constituent order in English  . It would be of interesto examine data from languages with relatively freer constituent order  ( e . g . German ) to determine the influence of constituent order upon centering when the grammatical functions are held constant  . In addition , languages that provide an identifiable topic function  ( e . g . Japanese ) suggest that topic takes precedence over subject . 
The part of the HPSG system that uses the centering algorithm for pronoun binding is called the ule called the semantics processor  , which computes representations of intrasentential anaphoric relations  , ( among other things ) . The semantics processor has access to information such as the surface syntactic structure of the utterance  . It provides the pragmatics processor with representations which include of a set of reference markers  . Each reference marker is contra indexed ~ with expressions with which it cannot co-specify  3  . Reference markers also carry information about agreement and grammatical function  . 
Each pronominal reference marker has a unique index from Ax  ,   .   .   .   , An and is displayed in the figures in the form \ [   POLLARD:A1 L where POLLARD is the semantic representation f the co-specifier  . For nonpronominal reference markers the surface string is used as the index  . Indices for indefinites are generated from XI, .   .   . , X , ~ . 
2 Extension
The constraints proposed by \[ GJW86\] fail in certain examples like the following ( read with pronouns de-stressed ) :
Brennan drives an Alfa Romeo.
She drives to of ast.
Friedman races her on weekends.
She often beats her.
This example is characterized by its multiple ambiguous pronouns and by the fact that the final utterance achieves a shift  ( see figure 4 )  . A shift is inevitable because of constraint 3 , which states that the Cb(U , ~) must equal the C p(U , -I )   ( since the C p ( Un-x ) is directly realized by the subject of Un , " Friedman ") . However the constraints and rules from \[ GJW86\] would fail to make a choice here between the cospecification possibilities for the pronouns in U  ,  . 
Given that the transition is a shift , there seem to be more and less coherent ways to shi ~  . Note that the three items being examined in order to characterize the transition between each pair of anchors  4 are the = See\[ BP80\] and \[ Cho80\] for conditions on coreference 3 See\[ Sid83\] for definition and discussion of cospecification . 
Note that this use of cospecification is not the saxneas that used in \[  Se185\]   4An anchor is a < Cb , Of > pair for an utterance
Cb(U , , ) = cpW.)
Cb(V , ,) #cp(u.)
CbW .) = cb(~z._~)cbw.)#CbW,,_,)




Figure 3: Extended Transition States
Cb of U ,,-1, the Cb of U , ~, and the Cp of Un . By\[ GJW86\] a shift occurs whenever successive Cb's are not the same  . This definition of shifting does not consider whether the Cb of U  , and the Cp of Un are equal . It seems that the status of the Cp of Un should be as important in this case as it is in determining the retaining/continuing distinction  . 
Therefore , we propose the following extension which handles ome additional cases containing multiple ambiguous pronouns : we have extended rule  2 so that there are two kinds of shifts . A transition for Unisranked more highly if Cb ( Un ) = Cp ( U , ) ; this state we call shifting-1 and it represents a more coherent way to shift . The preferred ranking is continuing >- retaining >-   shifting-1 ~ shifting ( see figure 3 )  . This extension enables us to successfully bind the " she " in the final utterance of the example in figure  4 to " Friedman . " The appendix illustrates the application of the algorithm to figure  4  . 
Kameyama \ [ Kam86\] has proposed another extension to the \[ G:JW86\] theory-a property-sharing constraint which attempts to enforce a parallellism between entities in successive utterances  . She considers two properties : SUBJ and IDENT . With her extension , subject pronouns prefer subject antecedents and non subject pronouns prefer non subject antecedents  . 
However , structural parallelism is a consequence of our ordering the Cf list by grammatical function and the preference for continuing over retaining  . Furthermore , the constraint suggested in \[ GJW86\] succeed in many cases without invoking an independent sruc-tural parallelism constraint  , due to the distinction between continuing and retaining  , which Kamey ama fails to consider . Her example which we reproduce in figure 5 can also be accounted for using the contin-
U ,,+ I : Brenn and rives an Alfa Romeo.
Cb:\[BRENNAN : Brennan \]
Cf:(\[BRENNAN:Brennan\]\[X2:Alfa Komeo\])

U ,,+2: She drives too fast.
Cb:\[BRENNAN : Brennan \]
Cf:(\[BRENNAN:AT\])
She=Brennan

U , ~+ s : Friedman races her on weekends.
Cb:\[BRENNAN:A7\]
Cf : ( \[FRIEDMAN : Friedman \]\[ BI~ENNAN:A8\]  \[  WEEKEND:X3\]  ) her=Brennan

Un+4: She often beats her.
Cb:\[FRIEDMAN : Friedman \]
Of:(\[FRIED MAN:A9\]\[BRENNAN:A10\])
She=Friedman , her=Brennan
Figure 4

U , ~+ I : Who is Maxwaiting for ?
Cb:\[PLANCK:Max\]
Of : (\[ PLANCK:Max\])

Un+2: He is waiting for Fred.
Cb:\[PLANCK:Max\]
C.f:(\[PLANCK:A1\]\[FLINTSTONE : Fred\])
He = Max

U,~+3: He invited him to dinner.
Cb:\[PLANCK:A1\]of: ( \[ PLANCK:A2\]\[FLINTSTONE : A3\] ) 
He-Max , him=Fred
Figure 5 uing / retaining distinctions . The third utterance in this example has two interpretations which are both consistent with the centering rules and constraints  . 
Because of rule 2 , the interpretation i figure 5 is preferred over the one in figure 6  . 
3 Algorithm for centering and pronoun binding There are three basic phases to this algorithm  . 
First the proposed anchors are constructed , then they are filtered , and finally , they are classified and ranked . The proposed anchors represent all the cospecification relationships available for this utterance  . 
Each step is discussed and illustrated in figure 7 . 
It would be possible to classify and rank the proposed anchors before filtering them without any other changes to the algorithm  . In fact , using this strategy 5It seems that property sharing of I'DENT is still necessary to account for logophoric use of pronouns in Japanese  . 

U , ~+ ~: Who is Maxwaiting for ?
Cb:\[PLANCK:Max\]el:(\[PLANCK:Max\])

U , ~+ 2: He is waiting for Fred.
Cb:\[PLANCK:Max \] el: ( \[ PLANCK:A1\]\[FLINTSTONE : Fred\] ) he = Max

Ur=+3: He invited him to dinner.
Cb:\[PLANCK:A1\]el: ( \[FLINTSTONE : A3\][PLANCK:A2\] ) 
He = Fred , him = Max
Figure 6 ( a ) Create set of referring expressions ( RE's )  . 
(b ) Order KE's by grammatical relation.
( c ) Create set of possible forward center ( Cf ) lists . Expand each element of ( b ) according to whether it is a pronoun or a proper name  . Expand pronouns into set with entry for each discourse entity which matches its agreement features and expand proper nouns into a set with an entry for each possible referent  . These expansions are a way of encoding a disjunction of possibilities  . 
( d ) Create list of possible backward centers ( Cb's )  . This is taken as the entities f ~ omCf(U , -1 ) plus an additional entry of NIL to allow the possibility that we will not find a Cb for the current utterance  . 
( e ) Create the proposed anchors . ( Cb-O . f combinations from the crossproduct of the previous two steps  )  2 . FILTER THE PROPOSED ANCHORS For each anchor in our list of proposed anchors we apply the following three filters  . If it passes each filter then it is still a possible anchor for the current utterance  . 
( a ) Filter by contra indices . That is , if we have proposed the same antecedent for two contraindexed pronouns or if we have proposed an antecedent for a pronoun which it is contra indexed with  , eliminate this anchor from consideration . 
( b ) Go through Cf(U , _ , ) keeping ( in order ) those which appear in the proposed Cf list of the anchor  . If the proposed Cb of the anchor does not equal the first element of this constructed list then eliminate this anchor  . 
This guarantees that the Cb will be the highest ranked element of the Cf  ( U , -t ) realized in the current utterance .   ( This corresponds to constraint 3 given in section t )   ( c ) If none of the entities realized as pronouns in the proposed C\[list equals the proposed Cb then eliminate this anchor  . This guarantees that if any element is realized as a pronoun then the Cb is realized as a pronoun  . 
(If there are no pronouns in the proposed C \[ list then the anchor passes this filter  . This corresponds ' to rule 1 in section 1) . This rule could be implemented as a preference strategy rather than a strict filter  . 
3. CLASSIFY and BANK
EXAMPLE : She doesn't believe him . ( U , +4 from figure 2) = (\[ A4\]\[AS\]) = t ,   ( \[ A4\]\[AS\] )  =~  ( \[FRIED MAN:A4\]\[POLLARD:A5\] )  =>  ( \[POLLARD:A2\][FKIED MAN:A3\]\[KAISE:XI\]NIL )  . 
= ~ There are four possible < Cb , Cf > pairs for this utterance . 
i . <\[ POLLARD : A2\] , (\['FRIED MAN:A4\]\[POLLARD:A5\])>ii . <\[FRIEDMAN : A3\] , (\[FRIED MAN:A4\][POLLARD:A5\])> iii . <\[KAISE : X1\] , (\[FRIED MAN:A4\][POLLARD:A$\])>iv . < NIL ,   ( \[FRIED MAN:A4\][POLLARD:A5\] ) >= ~ This filter doesn't eliminate any of the proposed anchors in this example  . Even though \[ A4\] and \[ A5\] are contraindexed we have not proposed the same co-specifier due to agreement  . 
= ~ This filter eliminates proposed anchors ii , iii , iv . 
= ~ This filter doesn't eliminate any of the proposed anchors  . 
The proposed Cb was realized as a pronoun.
( a ) Classify each anchor on the list of proposed anchors by = ~ Anchori is classified as a retention based on tim transition the transitions as described in section  1 taking U , ~- t to state definition . 
be the previous utterance and U , to be the one we are currently working on . 
( b ) Rank each proposed anchor using the extended rank -=~ Anchor i is the most highly ranked anchor  ( trivially )  . 
ing in section 2 . Set Cb ( Un ) to the proposed Cb and Cf ( Un ) to proposed Cf of the most highly ranked anchor . 
Figure 7: Algorithm and Example the filters , or if the next highest did , etc . The three filters in the filtering phase may be done in parallel  . 
The example we use to illustrate the algorithm is in figure  2  . 
4 Discussion 4 . 1 Discussion of the algor i thm The goal of the current algorithm design was conceptual clarity rather than efficiency  . The hope is that the structure provided will allow easy addition of further constraints and preferences  . It would be simple to change the control structure of the algorithm so that it first proposed all the continuing or retaining anchors and then the shifting ones  , thus avoiding a precomputation fall possible anchors  . 
\ [GJW86\] states that a realization may contribute more than one entity to the Cf  ( U )  . This is true in cases when a partially specified semantic description is consistent with more than one interpretation  . There is no need to enumerate x plicitly all the possible interpretations when constructing possible Cf  ( U ) ' s 6 , as long as the associated semantic theory allows partially specified interpretations  . This also holds for entities not directly realized in an utterance  . On our view , after referring to " a house " in U , , , a reference to " the door " in U , ~+ I might be got ten via inference from the representation for '% house " in Cf  ( Un )  . Thus when the proposed anchors are constructed there is no possibility of having an infinite number of potential Cf's for an utterance of finite length  . 
Another question is whether the preference ordering of transitions in constraint  3 should always be the same . For some examples , particularly where U , ~ contains a single pronoun and U , ~- I is a retention , some informant seem to have a preference for shifting  , whereas the centering algorithm chooses a continuation  ( see figure 8 )  . Many of our informants have no strong preference as to the cospecification of the unstressed " She " in  Un+4  . Speakers can avoid ambiguity by stressing a pronoun with respect o its phonological environment  . A computational system 6 Barbara Grosz , personal communication , ad\[GJW 86\]

Ur , +1: Brennan drives an Alfa P~omeo.
Cb:\[BRENNAN : Brennan \] el: ( \[BRENNAN : Brennan \]\[ ALFA:X1\] ) 

U,~+2: She drives too fast.
Cb:\[B1LENNAN : Brennan \]
Cf:(\[BRENNAN:A7\])
She-Brennan

Un+3: Friedman races her on weekends.
Cb:\[BB . ENNAN:A7\]
C , f : ( \[FRIEDMAN : Friedman \]\[ BRENNAN : A8\] ) \[ WEEKEND:X3\] ) her -- Brennan

U,~+4: She goes to Laguna Seca.
Cb:\[BI~ENNAN : A8\]
Cf:(\[BRENNAN:A9\]\[LAG-SEC:Laguna

She-Brennan ??
Figure 8 for understanding may need to explicitly acknowledge this ambiguity  . 
A computational system for generation would try to plan a retention as a signal of an impending shift  , so that after a retention , a shift would be preferred rather than a continuation  . 
4.2 Future Research
Of course the local approach described here does not provide all the necessary information for interpreting pronouns  ; constraints are also imposed by world knowledge , pragmatics , emantics and phonology . 
There are other interesting questions concerning the centering algorithm  . How should the centering algorithm interact with an inferencing mechanism ? Should it make choices when there is more than one proposed anchor with the same ranking ? In a database query system  , how should answers be in-tering interact with a treatment of definite/indefinite 
NP's and quantifiers ?
We are exploring ideas for these and other extensions to the centering approach for modeling reference in local discourse  . 
5 Acknowledgements
We would like to thank the following people for their help and insight : Hewlett Packard Lab's Natural Language group  , CSLI's DIA group , Candy Sid-net , Dan Flickinger , Mark Gawron , : John Nerbonne , Tom Wasow , Barry Arons , Martha Pollack , Aravind : Joshi , two anonymous referees , and especially Barbara Grosz . 
6 Appendix
This illustrates the extension in the same detail as the example we used in the algorithm  . The numbering here corresponds to the numbered steps in the algorithm figure  7  . The example is the last utterance from figure 4 . 
EXAMPLE : She often beats her.
I . CONSTRUCTTHEPROPOSEDAN-
CHORS ( a )   ( \[Ag\]\[A10\] )   ( b )   ( \[ A9\][A10\] )   ( c )   ( (\[ FRIEDMAN:A9\] [ FRIEDMAN:A10\] )   ( \[FRIED MAN:A9\]\[BRENNAN:A10\] )   ( \[BRENNAN:A9\][BRENNAN:A10\] )   ( \[BRENNAN:A9\][FRIED MAN:A10\] ) )  ( d )   ( \[FRIEDMAN : Friedman \]\[ BRENNAN:A8\]  \[  WEEKEND:X3\] NIL )   ( e ) There are 16 possible < Cb , Cf > pairs for this utterance . 
i . <\[FRIEDMAN : Friedman \] , (\[FRIEDMAN : Ag\][FRIEDMAN : A10\])> ii . <\[FRIEDMAN : Friedman \] , (\[FRIED MAN:A9\][BRENNAN:A10\])> iii . <\[FRIEDMAN : Friedman \] , (\[BRENNAN:A9\]\[FRIEDMAN:A10\])>iv . <\[FRiEDMAN : Friedmaa \] , (\[BRENNAN:A9\]\[BRENNAN:A10\])>v . <\[BRENNAN : A8\] , (\[FRIEDMAN : Ag\][FRIEDMAN : A10\])> vi . <\[BRENNAN : A8\] , (\[FRIEDMAN : Ag\][BRENNAN : A10\])> vii . <\[BRENNAN : A8\] , (\[BBRENNAN:A9\]\[FRIEDMAN:A10\])> viii . <\[BRENNAN : A8\] , (\[BRENNAN:A9\]\[BRENNAN:A10\])>ix . <\[ WEEKEND:X3\] , (\[FRIEDMAN : Ag\][FRIEDMAN : A10\])> x . <\[ WEEKEND:X3\] , (\[FRIEDMAN : Ag\][BRENNAN : A10\])> xi . <\[ WEEKEND:X3\] , (\[BBRENNAN : Ag\]\[FRIEDMAN : A10\])> xii . <\[ WEEKEND:X3\] , (\[BRENNAN:A9\]\[BRENNAN:A10\])> xiii . < NIL , (\[FRIEDMAN:Ag\][FRIEDMAN : A10\])>xiv . < NIL,(\[FRIED MAN:A9\][BRENNAN:A10\])>xv . < NIL , (\[BBRENNAN : Ag\]\[FRIEDMAN : A10\]) > xvi . < NIL,(\[RENNAN:A9\]\[BRENNAN:A10\]) > 2 . FILTER THE PROPOSED ANCHORS ( a ) Filter by contra indices . Anchorsi , iv , v , viii , iz , zii , ziii , zvi are eliminated since\[ A9\] and \[ A10\] are contraindexed . 
( b ) Constraint 3 filter eliminates proposed anchors vii , ix through zvi . 
( c ) Rule 1 filter eliminates proposed anchors iz through zvi . 
3 . CLASSIF Yarid RANK ( a ) After filtering there are only two anchors left . 
ii:<\[FRIEDMAN : Friedman \] ,   ( \[FRIEDMAN : Ag\][BRENNAN : A10\] ) > iii:<\[FRIEDMAN : Friedman \] ,   ( \[BRENNAN:A9\]\[FRIED MAN:A10\] ) > Anchor ii is classified as shifting-1 whereas anchor i ii is classified as shifting . 
(b ) Anchor ii is more highly ranked.

References\[ BPS0\]  \[  Cho80\]  \[  GJW83\]  \[  GJw861  \[  Gs85\]  \[  Gui85\]  \[  Kam86\]  \[  Se185\]  \[  SH841  \[  Sid81\] 
E . Bach and B . H . Partee . Anaphor and semantic structure . In J . Kreiman and A . 
Ojeda , editors , Papers from the Parases.
sion on Pronouns and Anaphora , pages 128 , CLS , Chicago , IL ,  1980 . 
N . Chomsky . On binding . Linguistic Inquiry , 11: pp .  1-46, 1980 . 
B.J . Grosz , A.K . Joshi , and S . Weinstein.
Providing a unified account of definite noun phrases in discourse  . In Proc . , Blst Annual Meeting of the ACL , Association of Computational Linguistics , pages 44-50 , Cambridge , MA ,  1983 . 
B.J . Grosz , A.K . Joshi , and S . Weinstein.
Towards a computational theory of discourse interpretation  . Preliminary draft , 1986 . 
B.J . Gross and C.L . Sidner . The Strnc.
ture of Discourse Structure . Technical Report CSLI-85-39 , Center for the Study of Language and Information , Stanford , CA ,  1985 . 
R . Guindon . Anaphora resolution : shortterm memory and focusing  . In Proc . , 238t Annual Meeting of the ACL , Association of Computational Linguistics , pages pp . 218--227, Chicago , IL , 1985 . 
M . Kameyama . A property-sharing constraint in centering . In Proc . , 24st Annual Meeting of the A CL , Association of Computational Linguistics , pages pp .  200-206,
New York , NY , 1986.
P . Sells . Coreference and bound anaphora : a restatement of the facts  . In Choe Berman and McDonough , editors , Proceedings of \] gELS 16 , GLSA , University of Massachusetts ,  1985 . 
I . Sag and J . Hankamer . Towards a theory of anaphoric processing . Linguistics and
Philosophy , 7: pp . 325-345, 1984.
C . L . Sidner . Focusing for interpretation f pronouns . American Journal of Computational Linguistics , 7(4): pp .  217-231, 1981 . 
\[Sid83\]C . L . Sidner . Focusing in the comprehension of definite anaphora  . In M . Brady and R . C . Berwick , editors , Computational
Models of Discourse , MIT Press , 1983.

