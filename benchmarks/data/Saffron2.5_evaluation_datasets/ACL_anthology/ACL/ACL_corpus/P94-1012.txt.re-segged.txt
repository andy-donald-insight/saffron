ALIGNING A PARALLEL ENGLISH-CHINE SECORPUS
STATISTICALLY WITHLEXICAL CRITERIA
Dekai Wu

Department of Computer Science
University of Science &: Technology
Clear Water Bay , Hong Kong
Internet : dekai ? cs.ust.hk
Abstract
We describe our experience with automatic alignment of sentences in parallel EnglishChinese texts  . Our report concerns three related topics : ( 1 ) progress on the HKUST EnglishChinese Parallel Bilingual Corpus  ;   ( 2 ) experiments addressing the applicability of Gale ~Church's  ( 1991 ) length-based statistical method to the task of alignment involving a non-Indo-European language  ; and ( 3 ) an improved statistical method that also incorporates domain-specific lexical cues  . 

Recently , a number of automatic techniques for aligning sentences in parallel bilingual corpora have been proposed  ( Kay & R Sscheisen 1988 ; Catizonee ~ al .  1989 ; Gale & Church 1991 ; Brown et al 1991 ; Chen 1993) , and coarser approaches when sentences are difficult to identify have also been advanced  ( Church 1993 ; Dagane ~ al .  1993) . 
Such corpora contain the same material that has been translated by human experts into two languages  . The goal of alignment is to identify matching sentences between the languages  . Alignment is the first stage in extracting structural information and statistical parameters from bilingual corpora  . 
The problem is made more difficult because as en -tence in one language may correspond to multiple sentences in the other  ; worse yet , ? sometimes several sentences ' content is distributed across multiple translated sentences  . 
Approaches to alignment fall into two main classes : lexical and statistical  . Le?ically-based techniques use extensive online bilingua lexicons to match sentences  . In contrast , statistical techniques require almost no prior knowledge and are based solely on the lengths of sentences  . The empirical results to date suggest hat statistical methods yield performance superior to that of currently available lexical techniques  . 
However , as far as we know , the literature on automatic alignment has been restricted to alphabetic Indo-European languages  . This methodological flaw weakens the arguments in favor of either approach  , since it is unclear to what extent a technique's superiority depends on the similarity between related languages  . The work reported here in moves towards addressing this problem  . 1 In this paper , we describe our experience with automatic alignment of sentences in parallel EnglishChinese txts  , which was performed as part of the SILC machine translation project  . Our report concerns three related topics . In the first of the following sections , we describe the objectives of the HKUST English Chinese Parallel Bilingual Corpus  , and our progress . The subsequent sections report experiments addressing the applicability of a suitably modified version of Gale & Church's  ( 1991 ) length-based statistical method to the task of aligning English with Chinese  . In the final section , we describe an improved statistical method that also permits domain-specific lexical cues to be incorporated probabilistically  . 
THEENGLISH-CHINESE

The dearth of work on non-Indo-European languages can partly be attributed to a lack of the prequisite bilingual corpora  . As a step toward remedying this , we are in the process of constructing a suitable English Chinese corpus  . To be included , materials must contain primarily tight , literal sentence translations . This rules out most fiction and literary material . 
We have been concentrating on the Hong
Kong Hansard , which are the parliamentary proceedings of the Legislative Council  ( Leg Co )  . Analogously to the bilingual texts of the Canadian Hansard  ( Gale & Church 1991 )  , Leg Cotran scripts are kept in full translation i both English  1Some newer methods are also intended to be applied to non-Indo-European languages in the future  ( Fung $ z Church 1994 )  . 
80 and Cantonese . 2 However , unlike the Canadian Hansard , the Hong Kong Hansard has not previously been available in machine-readable form  . 
We have obtained and converted these materials by special arrangement  . 
The materials contain high-quality literal translation  . Statements in LegCo may be made using either English or Cantonese  , and are transcribed in the original language . A translation to the other language is made later to yield complete parallel texts  , with annotation specifying the source language used by each speaker  . Most sentences are translated 1-for-1 . A small proportion are 1-for-2 or 2-for-2 , and on rare occasion 1-for-3 , 3-for -3 , or other configurations . Samples of the English and Chinese texts can be seen in figures  3 and 4  .   3 Because of the obscure format of the original data  , it has been necessary to employ a substantial amount of automatic on version and ref-ormatting  . Sentences are identified automatically using heuristics that depend on punctuation and spacing  . Segmentation errors occur occasionally , due either to typographical errors in the original data  , or to inadequacies of our automatic on ver-sion heuristics  . This simply results in incorrectly placed delimiters  ; it does not remove any text from the corpus . 
Although the emphasis is is on clean text so that markup is minimal  , paragraphs and sentences are marked following TEI -conformant SGML  ( Sperberg-McQueen & Burnard 1992 )  . We use the term " sentence " in a generalized sense including lines in itemized lists  , headings , and other non-sentential segment smaller than a paragraph  . 
The corpus currently contains about 60Mb of raw data , of which we have been concentrating on approximately  3  . 2Mb . Of this , 2 . 1M b is text comprised of approximately 0 . 35 million English words , with the corresponding Chinese translation occupying the remaining  1  . 1Mb . 
STATISTICALLY-BASED
ALIGNMENT
The statistical approach to alignment can be summarized as follows : choose the alignment hat maximizes the probability over all possible alignments  , given a pair of parallel texts . Formally ,   2Cantonese is one of the four major Han Chinese languages . Formal written Cantones employs the same characters as Mandarin  , with some additions . 
Though there are grammatical ndusage differences between the Chinese languages  , as between German and Swiss German , the written forms can be read by all . 
3 For further description see also Fung&:Wu ( 1994 )  . 
choose (1) argm~xPr(AVT1, if-2) where . A is an alignment , and ~ and " T2 are the English and Chinese texts , respectively . An alignment . A is a set consisting of L1 ~ L ~ pairs where each L1 or L2 is an English or Chinese passage . 
This formulation is so extremely general that it is difficult to argue against its pure form  . More controversial rethe approximations that must be made to obtain a tractable version  . 
The first commonly made approximation is that the probabilities of the individual aligned pairs within an alignment are independent  , i . e . , Pr(A\[TI , ' T2) ~ HPr(Li~--L2\[~,9-2) ( LI . ~-L~ ) EA The other common approximation is that each Pr ( L1~-L217-t , 7-2) depends not on the entire texts , but only on the contents of the specific passages within the alignment : 
Pr(AI~'T2) ~ HPr(L1~--L~IL1 , L ~)( LI~---L2)E , A Maximization of this approximation to the alignment probabilities is easily converted into a minimum-sumproblem :  ( 2 ) argrn AaxPr (  . AI ~, ~ r ~) ~ . argm~xHVr(L1 = L21L1,L2)(Lt . ~--L2)E . A = argn~nE-logPr(L1~-~L2IL1,L2)(Lt~L2)E . A The minimization can be implemented using a dynamic programming strategy  . 
Further approximations vary according to the specific method being used  . Below , we first discuss a pure length-based approximation  , then a method with lexical extensions . 
APPLICABILITY OFLENGTH-
BASED METHODS TO CHINESE
Length-based alignment methods are based on the following approximation to equation  ( 2 ) :  ( 3 ) Pr ( /1 ~- L2\[LI , L2) ~ er(L1~--L~lll , l ~) where 11 = length(L1) and l~=length(L2) , measured in number of characters . In other words , the only feature of Lt and L2 that affects their alignment probability is their length  . Note that there are other length-based alignment methods of characters  ( Brown et al 1991 )  . However , since Chinese text consists of an unsegmented characters tream without marked word boundaries  , it would not be possible to count the number of words in a sentence without first parsing it  . 
Although it has been suggested that length-based methods are language-independent  ( Gale & Church 1991 ; Brown et al 1991) , they may in fact rely to some extent on length correlations arising from the historical relationships of the languages being aligned  . If translated sentence share cognates , then the characterlengths of those cognates are of course correlated  . Grammatical similarities between related languages may also produce correlations in sentence lengths  . 
Moreover , the combinatorics of non-Indo-European languages can depart greatly from Indo-European languages  . In Chinese , the majority of words are just one or two characters long  ( though collocations up to four characters are also common  )  . At the same time , there are several thousand characters in daily use  , as in conversation or newspaper text . Such lexical differences make it even less obvious whether pure sentence-length criteria are adequately discriminating for statistical alignment  . 
Our first goal , therefore , is to test whether purely length-based alignment results can be replicated for English and Chinese  , languages from unrelated families . However , before length-based methods can be applied to Chinese  , it is first necessary to generalize the notion of " number of characters " to Chinese strings  , because most Chinese text ( including our corpus ) includes occasional English proper names and abbreviations  , as well as punctuation marks . Our approach is to count each Chinese character as having length  2  , and each English or punctuation character as having length  1  . This corresponds to the byte count for text stored in the hybrid EnglishChinesen cod-ing system known as Big  5  . 
Gale & Church's ( 1991 ) length-based alignment method is based on the model that each English character in  L1 is responsible for generating some number of characters in  L2  . This model leads to a further approximation which encapsulates the dependence to a single parameter  6 that is a function of 11 and 1s : Pr ( L1 = L2IL 1 , L2) . ~ Pr(L1~--L216 (11 , 12)) However , it is much easier to estimate the distributions for the inverted form obtained by applying 
Bayes ' Rule:
Pr(L1=L216) = Pr(6\]L1~L2) Pr(nl~-n2)
Pr ( 6 ) where Pr ( 6 ) is a normalizing constant hat can be ignored during minimization  . The other two distributions are estimated as follows  . 
First we choose a function for 6(11, 12) . To do this we look at the relation between 11 and 12 under the generative model . Figure 1 shows a plot of English versus Chinese sentence lengths for a hand-aligned sample of  142 sentences . If the sentence lengths were perfectly correlated  , the points would lie on a diagonal through the origin  . 
We estimate the slope of this idealized diagonal c = E  ( r ) = E ( 12/ll ) by averaging over the training corpus of hand -aligned  L1  ~-  L2 pairs , weighting by the length of L1 . In fact this plot display sub-stantially greater scatter than the English-French data of Gale & Church  ( 1991 )  .   4 The mean number of Chinese characters generated by each English character is c =  0  . 506, with a standard deviation ~ r = 0 . 166 . 
We now assume that 12 -llc is normally distributed , following Gale & Church (1991) , and transform it into a new gaussian variable of standard form  ( i . e . , with mean 0 and variance 1 ) by appropriate normalization : 12-11c ( 4 ) x / ~ ltr 2 This is the quantity that we choose to define as 6  ( /1 , 12) . Consequently , for any two pairs in a proposed alignment , Pr ( 6\[Lt ~- L ~ ) can be estimated according to the gaussian assumption  . 
To check how accurate the gaussian assumption is , we can use equation ( 4 ) to transform the same training points from figure  1 and produce a histogram . The result is shown in figure 2 . Again , the distribution deviates from a gaussian distribution substantially more than Gale & Church  ( 1991 ) report for French/German/English . Moreover , the distribution does not resemble ally smooth distribution at all  , including the logarithmic normal used by Brown el al  .  (1991) , raising doubts about the potential performance of pure length-based alignment  . 
Continuing nevertheless , to estimate the other term Pr(L1~L2) , a prior over six classes is constructed , where the classes are defined by then mn-ber of passages included within  L1 and L2  . Table 1 shows the probabilities used . These probabilities are taken directly from Gale & Church  ( 1991 )  ; slightly improved performance might be obtained by estimating these probabilities from our corpus  . 
The aligned results using this model were evaluated by hand for the entire contents of a  ran-4The difference is also partly due to the fact that Gale & Church  ( 1991 ) plot paragraph lengths instead of sentence l ngths  . We have chosen to plot sentence lengths because that is what the algorithm is based on  . 
82 1 . ? MRFREDLI ( in Cantonese ): J2 . I would like to talk about public assistance . J 3 . I notice from your address that under the Public Assistance Scheme  , the basic rate of $825 a month ~ ra ~825~950 ~ , ~ 15%o \] single adult will be increased by 15% to $950 a month . 
l4 . However , do you know that the revised rate plus all other grants will give each recipient no more than  $2000 a month ? On average , each recipient will receive $1600 to $1700 a month .  \] 5 . In view of Hong Kong's prosperity and highliving cost  , this figure is very ironical . J 6 . May I have your views and that of the Government ? \]   7  . Do you think that a comprehensiver view should be conducted on the method of calculating public assistance ?\]  8  . Since the basic rate is so low , it will still be far below the current level of living even if it is further increased by  20% to 30%  . If no comprehensiver view is carried out in this aspect  , this " safetynet " cannot provide any assistance at all for those who are really in need  . J 9 . I hope MrG over nor will give this question a serious response  . J 10 . ? THEGOVERNOR : J 11 . It is not in any way to be little the importance of the point that the Honourable Member has made to say that  , when at the outset of our discussions I said that I did not think that the Government would be regarded for long as having been extravagant yesterday  , I did not realize that the criticisms would begin quite as rapidly as they have  .  \] 12 . The proposals that we make on public assistance , both the increase in scale rates , and the relaxation of the absence rule , are substantial steps forward in Hong Kong which will  , I think , be very widely welcomed . J 13 . But I know that there will always be those who , I amsure for very good reason , will say you should have gone further , you should have clone more . J 14 . Societies customarily make advances in social welfare because there are members of the community who develop that sort of case very often with eloquence and verve  .  \]
N,~B~1600~N1700~o\]
N ~ ~ ~ ~ ? J
N ~ N ~ , A ~ 2o % ~3o %, ~~ ~ ~ ~ ~ N ~ oJ
AE~~N ~ , A ~ #~ ~ ~ ~ o ~ ~ ~ , ~ ~ D ~ ~ ~ ~ ,  ~ ~  , ~N ~ --~ , ~ ~ ~ oJ ~ , ~ ~ X - - ~ , ~~- -~ , ~ ~ - ~  , ~ ~ ~$ ~ ~ oJ Figure 3: A sample of length-based alignment output . 
domly selected pair of English and Chinese files corresponding to a complete session  , comprising 506 English sentences and 505 Chinese sentences . 
Figure 3 shows an excerpt from this output . Most of the true 1-for-1 pairs are aligned correctly . In (4) , two English sentences are correctly aligned with a single Chinese sentence  . However , the English sentences in (6 ,  7 ) are incorrectly aligned 1-for  -  1 instead of 2-for  -  1  . Also ,  (11 , 12) shows an example of a 3-for-l ,   1-for-1 sequence that the model has no choice but to align as  2-for-2  , 2-for -2 . 
Judging relative to a manual alignment of the English and Chinese files  , a total of 86 . 4% of the true L1 ~- L~pairs were correctly identified by the length-based method  . However , many of the errors occurred within the introductory session header  , whose format is domain-specific ( dis-
SQ4, ? em ? = o ? ~" gOLii*mxam . ll "? Figure 1: English versus Chinese sentence lengths . 

I0e?i?i " ioi " " iio , * o *** o 0   1   2   3   4 Figure 2: English versus Chinese sentence lengths . 
cussed below ) . If the introduction is discarded , then the proportion of correctly aligned pairs rises to  95  . 2% , a respectable rate especially in view of the drastic inaccuracies in the distributions assumed  . A detailed breakdown of the results is shown in Table  2  . For reference , results reported for English/French generally fall between  96% and 98%  . However , all of these number should be interpreted as highly domain dependent  , with very small sample size . 
The above rates are for Type I errors . The alternative measure of accuracy on Type II errors is useful for machine translation applications  , where the objective is to extract only 1-for-1 sentence pairs , and to discard all others . In this case , we are interested in the proportion of 1-for-1 output pairs that are true 1-for-1 pairs . ( In information retrieval terminology , this measures precision whereas the above measures recall  . ) In the test session , 4381-for-1 pairs were output , of which 377 , or 86 . 1%, were true matches . Again , however , by discarding the introduction , the accuracy rises to a surprising 96 . 3% . 

L1L201 101 112 2122
Pr(L1~L2) 0.0099 0.0099 0.89 0.089 0.011
Table 1: Priors for Pr(L1~--L2).
The introductory session header exemplifies a weakness of the pure length-based strategy  , namely , its susceptibility to long stretches of passages with roughly similar lengths  . In our data this arises from the list of council members present and absent at each session  ( figure 4 )  , but similar stretches can arise in many other domains  . In such a situation , two slight perturbations may cause the entire stretch of passages between the perturbations to be misaligned  . These perturbations can easily arise from a number of causes  , including slight omissions or mismatches in the original parallel texts  , a 1-for-2 translation pair preceding or following the stretch of passages  , or errors in the heuristic segmentation preprocessing  . Substantial penalties may occur at the beginning and ending boundaries of them is aligned region  , where the perturbations lie , but them is alignment between those boundaries incurs little penalty  , because the mismatched passages have apparently matching lengths  . This problem is apparently exacerbated by the non -alphabetic nature of Chinese  . Because Chinese text contains fewer characters , characterleng this a less discriminating feature  , varying over a range of fewer possible discrete values than the corresponding English  . The next section discusses a solution to this problem  . 
In summary , we have found that the statistical correlation of sentence lengths has a far greater variance for our EnglishChinese materials than with the Indo -European materials used by Gale & Church  ( 1991 )  . Despite this , the pure length-based method performs surprisingly well  , except for its weakness in handling long stretches of sentences with close lengths  . 
STATISTICALIN CORPORATION
OFLEXICAL CUES
To obtain further improvement in alignment accuracy requires matching the passages ' lexical content  , rather than using pure length criteria . This is particularly relevant for the type of long mismatched stretches described above  . 
Previous work on alignment has employed ei-

Incorrect % Correct 11   12   21   22   13   31   33   433   20   21   2   1   1   1   361   17   20   0   0   0   0   11   3   1   2   1   1   1   87  . 1 85 . 0 95 . 2 0 . 0 0 . 0 0 . 0 0 . 0 Table 2: Detailed breakdown of length-based alignment results  . 
1 . ? THEDEPUTY PRESIDENT THEHONOUR ABLE ?~~ J--J  : : -~   , K . B . E . , L . V . O . , J . P . JJOHNJOSE PHSWAINE , C . B . E . , Q . C . , J . P . J2 . ? THECHIEFSECRETARY THEHONOURABLESIRDAVID ROBERTFORD  , K . B . E . , L . V . O . , J . P . J 3 . ? THEFINANCIAL SECRETARY THE
HONOURABLEN A THANIEL WILLIAM HAMISH
MACLEOD , C . B . E . , J . P . Ji 37 misaligned matchings omitted 41 . ? THEHONOUR ALBEMANS AI-CHEONGJ 42 . ? THEHONOURABLESTEVENPOONKWOK-
LIMTHEHONOURABLEHEN RYTANGYING-
YEN , J . P .  \] 43 . ? THEHONOURABLETIKCHI-YUENJ ?~~ : N~iN,C . B . E . , J . P . J ? ~ N , . ~g  ~, C . M . G . , J . P . Jj Figure 4: A sample of misalignment using pure length criteria  . 
ther solely lexical or solely statistical ength criteria  . In contrast , we wish to incorporate lexical criteria without giving up the statistical approach  , which provides a high baseline performance . 
Our method replaces equation ( 3 ) with the following approximation :
Pr(La~---L21 L1,L2)
Pr(LI~-L2 111,12,vl,Wl .   .   .   .   , vn , Wn ) where vi =  #occurrences ( English cue i , L1) and wi=#occurrences ( Chinese cui , L2) . Again , the dependence is encapsulated within difference parameters & as follows: 
Pr(L1 ~ L2\[L1, L2)
Pr(L1 = L2~0(~l,~2),(~l(V1, Wl), .   .   . , ~ n(Vrt , Wn ))
Bayes ' Rule now yields
Pr(L1 . - ~ L2 160,61,62, .  ? . , 6n ) o ? Pr((f0, 61, . . .   , 5 , ~1 L1~--L2 ) Pr ( L1 = L2 ) The prior Pr ( L1 ~ L2 ) is evaluated as before . We assume all 6i values are approximately independent , giving (5) nPr (60 ,   .   .   , nlL1 = 1-IPr ( , lL1 = L2 )   i=0 The same dynamic programming optimization can then be used  . However , the computation and memory costs grow linearly with the number of lexical cues  . This may not seem expensive until one considers that the pure length-based method only uses resources equivalent to that of a single lexical cue  . It is in fact important ochoose as few lexical cues as possible to achieve the desired accuracy  . 
Given the need to minimize the number of lexical cues chosen  , two factors become important . 
First , a lexical cue should be highly reliable , so that violations , which waste the additional computation , happen only rarely . Second , the chosen lexical cues should occur frequently , since computing the optimization over many zero counts is not useful  . In general , these factors are quite domain-specific , so lexical cues must be chosen for the particular corpus at hand  . Note further that when these conditions are met , the exact probability distribution for the lexical  6/ parameters does not have much influence on the preferred alignment  . 
The bilingual correspondence lexicons we have employed are shown in figure  5  . These lexical items are quite common in the Leg Co domain  . 
Items like " C . B . E . " stand for honorific titles such as " Commander of the British Empire "  ; the other cues are self-explanatory . The cues nearly always appear 14o-1 and the differences 6/therefore have
C.B.E.C.B.E.
J.B.E.J.B.E.
L.V.O.L.V.O.








C.M.G.C.M.G.I.S.O.I.S.O.
J.P.J.P.K.B.E.K.B.E.
O.B.E.M.B.E.















Figure 5: Lexicons employed for paragraph ( top ) and sentence ( bottom ) alignment . 
a mean of zero . Given the relative unimportance of the exact distributions  , all were simply assumed to be normally distributed with a variance of  0  . 07 instead of sampling each parameter individually . 
This variance is fairly sharp , but nonetheless , conservatively reflects a lower reliability than most of the cues actually possess  . 
Using the lexical cue extensions , the Type I results on the same test file rise to 92  . 1% of true L1~L2 pairs correctly identified , as compared to 86 . 4% for the pure length-based method . The improvement is entirely in the introductory session header  . Without the header , the rate is 95 . 0% as compared to 95 . 2% earlier ( the discrepancy is insignificant and is due to somewhat arbitrary decisions made on anomolous regions  )  . Again , caution should be exercised in interpreting these percentages  . 
By the alternative Type II measure , 96 . 1% of the output 1-for-1 pairs were true matches , compared to 86 . 1% using the pure length-based method . Again , there is an insignificant drop when the header is discarded  , in this case from 96 . 3% down to 95 . 8% . 

Of our raw corpus data , we have currently aligned approximately 3 . 5Mb of combined English and Chinese texts . This has yielded 10 , 423 pairs clas-sifted as 1-for-l , which we are using to extract more refined information  . This data represents over 0 . 217 million English words ( about 1 . 269 Mb ) plus the corresponding Chinese text (0 . 659Mb) . 
To our knowledge , this is the first largescale empirical demonstration that a pure length-based method can yield high accuracy sentence alignments between parallel texts in Indo-European and entirely dissimilar non-alphabetic  , non-Indo-European languages . We are encouraged by the results and plan to expand our program in this direction  . 
We have also obtained highly promising improvements by hybridizing lexical and length -based alignment methods within a common statistical framework  . Though they are particularly useful for non -alphabetic languages where character length is not as discriminating a feature  , we believe improvements will result even when applied to alphabetic languages  . 

I am indebted to Bill Gale for helpful clarifying discussions  , Xuanyin Xia and Wing Hong Chan for assistance with conversion of corpus materials  , as well as Graeme Hirst and Linda Peto . 

BROWN , PETERF ., JENNIFERC . LAI , ~5
ROBERTL . MERCER .  1991 . Aligning sentences in parallel corpora . In Proceedings of the 29lh Annual Conference of the Association for Computational Linguistics  ,  169-176 , 

CATIZONE , ROBERTA , GRAH AMRUSSELL ,  ~ , 5 SU-SANWARWICK .  1989 . Deriving translation data from bilingual texts . In Proceedings of the First International Acquisition Workshop  , 

CHEN , STANLEYF .  1993 . Aligning sentences in bilingual corpora using lexical information  . 
In Proceedings of the 31st Annual Conference of the Association for Computational Linguistics  ,  916 , Columbus , OH . 
CHURCH , KENNETHW .  1993 . Char-align : A program for aligning parallel texts at the characterlevel  . In Proceedings of the 31st Annual Conference of the Association for Computational Linguistics  ,  18 , Columbus , OH . 

DAGAN , IDO , KENNETHW . CHURCH,
WILLIAMA . GALE .  1993 . Robust bilingual word alignment for machine aided translation  . 
In Proceedings of the Workshop on Very Large
Corpora , 18, Columbus , OH.
FUNG , PASCALE ~ KENNETHW . CHURCH . 1994.
Kvec : A new approach for aligning parallel texts . In Proceedings of the Fifteenth International Conference on Computational Linguistics  , Kyoto . To appear . 
FUNG , PASCALE & DEKAIWU .  1994 . Statistical augmentation fa Chinese machine -readable dictionary  . In Proceedings of the Second Annual Workshop on Very Large Corpora  , Kyoto . To appear . 
GALE , WILLIAMA . L:KENNETHW . CHURCH.
1991 . A program for aligning sentences in bilingual corpora  . In Proceedings of the 29th Annual Conference of the Association for Computational Linguistics  ,  177-184 , Berkeley . 
KAY , MARTIN&M . RSSCHE1 SEN .  1988 . Text-translation alignment . Technical Report P90-00143 , Xerox Palo Alto Research Center . 
SPER nERG-MCQUEEN , C . M . & LouBURNARD , 1992 . Guidelines for electronic text encoding and interchange  . Version 2 draft . 

