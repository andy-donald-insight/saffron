THE COMPUTATION ALDIFFICULTYOFID/LP

G . Edward Barton , Jr.
M.I.T . Artificial Intelligence Laboratory
545 Technology Square
Caanbridge , MA 02139

.\lodern linguistic theory attributes urface complexity to interacting snb systems of constraints  . \[" or instance , the IDLP gr , ' unmar formalism separates constraints on immediate dominance from those on linear order  . 
5 hieber's(t983) ID/I . Pparsing algorithm shows how to use ID and LP constraints directly in language processing  , without expandiqg them into an int crmrdiate " object gammar  . " However , Shieber's purported O(:,Gi2 . n  ~ ) runtime bound underestimates the tlillic nlty of ID/LP parsing  . 
ID/LP parsing is actually NP-complete , antithe worst-case runtime of Shieber's algorithm is actually exponential in grammar size  . The growth of parser data structures causes the difficulty  . So ) tiect ) m putational nd linguistic implications follow : in particular  , it is important to note that despite its poteutial for combinatorial explosion  , Shieber's algorithm remains better thau the alternative of parsing an expanded object gr ~anmar  . 

Recent linguistic theories derive surface complexity fr~ml modular subsystems of constraints  ; Chotusky ( 1981:5 ) proposes separate theories of bounding , government , O-marking , and so forth , while G , ' xzdar and\['ullum's GPSGfi ) rmalism ( Shieber . 1983: 2ff ) use-immediate-donfinance ?\[ D ) rules , linear-precedence ( l , P ) constraints , and , netarules . When modular ctmstraints , x reinvolved , rule systems that multiply out their surface effects are large and clums y  ( see Barton . 1984a ) . "\[' he expanded contextfree % bj eet grammar " that nmltiplies outtile constraints in a typical  (  , PSG system would contain trillions of rules ( Silieber ,  1983:1) . 
5 bicher ( 198:1 ) thus leads it : a welconte direction by ,  . hw . vinghow(D,\[ . P grammars can be parsed " directly , " with our the combinatorially explosive step of nmltiplying mtt the effects of the \[ D and LP constraints  . Shieber's ? dqorithm applies ID and LP constraints one step at a  ; ime .  ; , sneeded , t to wever , some doubts about computa-tion ; d complexity remain . ~ hieber (198 . 3:15 ) argates that his algorithm is identical to Earley 's in time complexity  , but this result seems almost too much to hope for  . Anll)/f . I ) grammar G can be much smalh rth ; man equivalent contextfreegr , ' umnar G '; for example , if Gt contains only the rule , 5 ~ to abc de , the corresponding G~t contains 5!~-120 rules . If Shieber's algorithm has the same time complexity ~ Earley's  . this brevity of exprd~slon comes free ( up to a constant )  . 5 hieber ~ ays little to ; dlay possible doubts : W , , will t . , rproq , ntarigor . .s ( h . lllOtlstr'~ . .li?)t ) of I'llnP c'(,mpt,'xlty . I . , t~t . I . , . idb ~, ch . .tr fr . mtiwoh, . ', , rc . lation h, . tw , ', . n)hel , rt , , , vtlt(',l ; tl ~, nthm ; rodE . rt< . y ' ~ that the ('+, t . ph'xityIs ) h ; d of Earh . y '>; tig , ) rltl~tlt\[IIt . l . + worst , ' . :+,, . wh , , retl . . I . I " rnh ' . ; d w : t y : . + p , ' (' ffy ; ttllli(llll " or dor-t; , ~l'-rt !+( . ri~i~t-imll d:~+'(',, l'<,v < . " yID rtih . , thel)i'('r ~' tlte~l ; d . , ; , with ; ' . r , , , In . " v . , t . + E , trh'y , ; tl~t ) rll hlll ~ qin, . +, ~ ivon ) h,' .   . : ramm . tr . vht . rkm ~: I .   . LI ) rnh . : . ; t ; Lk ( . . . , Cl ) ll + ' r + liillt time . 
rh , , . thin . c ,) IJHd , , ' . ": ity ,, I it .   . pre > ented : d ~ . , rltht . i . . . , ideo-tw ; dt()E . ri( . y '+ . That i: . . it ts ( i t (,' '2 . ' t :; ) . wht . ro : ('; : t >) 1 . , qzt ' , , f thv gramt , ~ arim , ml , vr , , f \[ D ruh ' . ~) and ni . ~tilt'h'ngth <) f the input . (: i , If ) Among other questions , it is nn clear why a + ituation of maximal constraints houhl represent the worst case  . Mtrd-real constraint may mean that there are more possibilities to consider  . 
.q . h ; eber's algorithm does have a time advantage over thense of garley's algorithm on the expanded CF 'G  . but it blows up in tile worst case ; tile el ; din of (9(G " . r(~) time complexity is nustaken . A reduction of the vertex-cover l > rt ) blenl shows that ID/LP parsing is actually NI ) -comph . te:hence ti , is bh ) wuparises from the inherent difficulty of ID , ' LP parsing ratlter than a defect in $ hieber's algorithm  ( unlessg ' = A2 )   . Tile following ~ ections explain aud discuss this result  . LP constraints are neglected because it is the ID r  . les that make parsing dilficult Atte ) ~ tion focuses on unordered contest-free 9 rammar ~ ( I ~ ( ' F (  ; s ; essentially , ll )/ l , Pgram , oarsaans LIt ) . AUCFG rule ; slike a standard C\[:G rule except that when use ( tmaderivati , , n , it may have the symbols , ) fits ex\[~ansiol twritten in any order . 
SHIEBER'SALGOIIITHM
Shiel ) ergeneralizes Earley's algorithm by generalizing the dotted-rule representation that Earley uses to track progress thro  , ghrule expansions . AUCI rG rule differs from a CFG rule only in that its right hand side is unordered  ; hence successive accumulation of set elements replaces linear ad-  . mcement through a sequence . Obvious interpretations follow for the operations that the Earley par  . , er performs on dotted rules : X- .   . A , B , C is a X -- A , B , C . is at ~' pical completed state ; Z--- . W . a , X , Y predicts terminal a and nontermi-nail X , Y ; and X--A . B , C , C should be advanced to X- . A , C . B , C after the predicted C is located , t Except for these changes , Shieber's algorithm is identical to Earley's . 
As Shieber hoped , direct parsing is better than using Earley's algorithm on an expanded gr  , -mlmar . If Shieber's parser is used to parse abcde according to Ct  , the state sets of the parser remain small . The first state set contains only iS-- . a , b , c , d , e , OI , the second state set contains only \[ S--a . b , c , d , e , Oi , , ' rodso forth . The state sets growl nuch larger if the Earley parser is used to parse the string according to G ' t  with its  120 rules . After the first terminal a has been processed , the second state set of the Earley parser contain  ,   . 1! - 2 . t stales spelling out all possible orders in which the renmiaing symbols b  , e , d , e may appear : ; S ~ a . bcde , O ! , ; S-,,, . c c d b . Oi and so on . 
Shieber's parser should be faster , since both parsers work by successively processing all of tile states in tile state sets  . 
Similar example show that tile 5hieber parser can have , -marbitrarily large advantage over the tlse of the Earley parser on tile object gr  , 'unmar . 
Shieber's parser does not always enjoy such a large advantage  ; in fact it can blowtip in the presence of ambiguity  . 
Derive G ~ . by modifying G t in two ways . First , introduce dummy categories A . tl , C , D , E so that A~a and so forth , with S-+ABC DE . Second , !et z be ambiguously in any of the categories A , B , C , D , E so that the rule for A becomes A~a ~ , z and so on . What happens when the string zzza is parsed according to G ~  . ? After the first three occurrences of z , the state set of the parser will reflect the possibility that any three of the phrases A  , /3 , C , D , E might have been seen , ' rod any two of then might remain to be parsed . There will be ( ~ )  =  t0 states reflecting progress through the rule expanding S  ; iS ~ A , B , C . D , E , 0\] will be in the state set , a . swill'S ~ A,C,E . B , D , OI , etc . There will also be 15 states reflecting the completion and prediction of phrases  . In cases like this , $ hieber's algorithm enumerates all of the combinations of k elements taken i at a tine  , where k is the rule length and i is the number of elements already processed  . Thus it can be combinatorially explosive . Note , however , that Shieber's algorithm is still better than parsing the object grammar  . 
With the Earley parser , the state set would reflect the same possibilities  , but encoded in a less concise representation . 
In place ot the state involving S~A , 13, C . D , E , for instance , there would be 3! . 2! = 12 states involving S~ABC . DE , S~13 CA . ED , and so forth . 2 his end IF or mor ~ . dl . rail ~~- e Barton (198, 1bi ~ ldShi , . hPr (1983 . Shieber ' . ~ rel , re ~, ent ; ttion , lilfers in . ~mleways from tilt . reprr . ' ~ , n latioll de . .
.a'ribt . ,\[ lit . re , witellW ~ . ~, h . vehpedillth'pt , ndeutly by tilt , author . 
The dilft , r, . ncestuft . i ~ ell Prldly iut . ~ . ' ~ eutiid , but . ~ eetote 2 . 
llne on trP . . . .t ? tit tlt . r r ) r r r 4 . ntztl . ion . i lht . .4tr;tled here . : ?, : ieber ' . ., rt . v . 
?P . ~Wl'llt+l+liOllH'?ll ; Idly . ~ ulfl . r . ~toPOIlI("eXtt'tltflOlllTilt+Y . ; tlllelf\[lil-of a total of 25 states , the Earley state set would contain 135  =  12  ?  10  -+-  15 states . 
With G ~ . , the parser could not be sure of the categorial identities of the phrases parsed  , but at least it was certain of the number , 'tadeztent of the phrases . The situation gets worse if there is uncertainty in those areas ~ well  . Derive G3 by replacing every z in G , . with the empty stringe so that , an A , for instance , can be either a or nothing . Before any input has been read , state set S , in $ hieber's parser must reflect the possibility that the correct parse may include any of the  2  ~ =  32 possible subsets of A , B , C , D , ~' empty initial constituents . For example , So must include \[ . . q - -  A , \]3,C , D , E . , 0i because the input might turn out to be the null string  . Similarly , S . must include : S ~ A , C , El . ~3, Dt , O ~ because the input might beb dord b . Counting all possible subsets in addition to other states having to do with predictions  , conpieions , and the parser start symbol that some it p\ [ ententatio as introduce  , there will be . 14 states in ?, .   ( There are 3:~8 states ill the corresponding state when the object gra  , atuar G ~ is used . )  low call : Shieber's algorithm be exponeatial in grant-Inar size despite its similarity to Earh :y's algorithm  , which is polynontiMingratn ln~tr size7 The answer is that Shieber's algorithm involves a leech larger bouad on the number of states in a state set  . Since the Eariey parser successively processes all of the states in each state set  ( Earley ,  1970:97) , an explosion in the size of the state set skills any small runtime bound  . 
Consider the Earley parser . Resulting from each rule X~At .   .   .   . 4 ~ in a gramoar G , , there are only k - t possible dotted rules . The number of possible dotted rules is thus bounded by the au ~' uber of synibo is that it takes to write G  , down , i . e . by : G , , t . Since an Eariey state just pairs a dotted rule with an interword position ranging front  0 to the length n of the input string , there are only O('~C ~ ; ? n ) possible states : hence no state set may contain more than O  ( Gai'n )   ( distinct ) states . By an argument due to Eartey , this limit allows an O(:G ~: . nz ) bound to be placed on Earley-parser runti , ne . In contrast , the state sets of Shieber's parser may growt tuch larger relative to gr~nmar size  . A rule X ~ A t .   .   . A ~ in a UCFG G ~ yields not k + I ordinary dotted rules  , but but 2 ~ possible dotted UCFC rules tracking accumulation of set elements  . \[ n the worst ca . ,e the gr , ' uutttar contains only one rule and kison the order of G  , ,:: hence a bound on the mt , nber of possible dotted UCFG rules is not given by O  ( G , , . ), but by 0 (2el , ) .   ( Recall tile exponential blow up illustrated for granmmr  /5:  . ) The parser some ti , ,tes blows up because there are exponentially more possible ways to to progress through an : reordered rule expansion than an through an ordered one  . in ID/LP parsing , the emits case occurs lem .   . qhivher 1083:10um . ~, ~ tordered seq t . , nrein . ~tead of a mld-tim . thv foretil t . do t : ? ou . ~ equently . in plltco of the . ., tate invov ing S ~  A . B . (: . D . E , Sltiei , er wouh J have tilt , : E = 6~t ; ttt . .~ itl-vtdving S -- ~ t . D . E , where o ~ range * overlte six per nlutlxtion 8 of

77 aeeb
I\["' delI ,, e2./e3
Figure 1: This graph illustrates a trivial inst , ance of the vertex cover problem . The set c , d is a vertex cover of size 2 . 
when the LP constraints force a unique ordering for every rule expansion  . Given sufficiently strong constraints , Shieber's parser reduces to Earley's as Shieber thought  , but strong constraint represents the best case computationally rather than the worst caze  . 

The worst-case time complexity of Shieber's algorithm is exponential in grammar size rather than quadratic  , 'm Shieber (1983:15 believed , l ) id Shieber choose a poor algorithm , or is ID/LP parsing inherently difficult ? In fact  , the simpler problem of recoyn ~ zzn 9 sentences according to a UCFG is NP-complete . Thus , unless P = 3/P , no ID/LP parsing algorithm can always run in trine polynomial in the combined size of grammar and input  . The proof is a reduction of the vertex cover problem  ( Garey and Johnson ,  1979: , 16) , which involves finding a small set of vertices in a graph such that every edge of the graph has an endpoint in the set  . Figure 1 gives a trivial example . 
To make the parser decide whether the graph in Figure I has a vertex cover of size  2  , take the vertex names a , b , c , and d as the alphabet . Take Ht through H4 as special symbols , one per edge ; also take U and D as dummy symbols . Next , encode the edges of the graph : for instance , edge el runs from a to c , so include the rules it ll --- , a and Ht ~ c . Rules for the dummy symbols are also needed . 
Dummy symbol D will be used to so a kup excess input symbols  , so D ~ a through D ~ d should be rules . 
Dummy symbol U will also soakup excess input symbols  , but U will be allowed to match only when there are four occurrences in a row of the same symbol one occurrence for each edge  )  . Take U ~ aaaa , U - - . bbbb , and U-- . cccc , and U---, ddd das the rules expanding U . 
Now , what does it take for the graph to have a vertex cover of size k =  2? One way to get a vertex cover is to go through the list of edges and underline one endpoint of each edge  . If the vertex cover is to be of size 2 , then mler lining must be done in such a way that only two distinct vertices axe ever touched in the process  . Alternatively , since there axe 4 vertices in all , the vertex cover will be of size 2 if there are 4  -  2  =  2 vertices left untouched in the underlining . 
This method of finding a vertex cover can be translated 
START-~Hit I2H3H 4UUDDDD
Hl-.-.a Ic

H3--.cl , ~

U---, aaaa ! bbbbtccccIdddd
D ~ alblcld
Figure 2: For k = 2 , the construction described in the text transforms the vertex-cover problem of Figure  1 into this UCFG . A parse exists for the string a aa abbbbeccc dddd iff the graph in the previous figure has a vertex cover of size  <2  . 
into an initial rule for the UCFG ,, as follows:
START-.HiII2H~II4UUDDDD
Each / /- symbol will match one of the endpoints of the corresponding edge  , each / . r-symbol will correspond to a vertex that was left untouclted by the H-matching  , and the D-symbols are just for bookkeeping .   ( Note that this is the only ~ ule in the construction that makes essential use of the unordered nat  , reofrule right hand sides . Figure 2 shows the complete gr , ' unmar that encodes the vertex-cover problem , , f Figure I . 
To make all of this work properly , take a = aaa abbbb bcccc dddd as the input string to be parsed  . ( For every vertex name z , include in a a contiguous run of occurrences of z  , one for each edge in the graph . ) The gramnlar encodes the underlining procedure by requiring each //- symbol to match one of its endpoints in a  . Since the expansion of the START rx , le is unordered ,   , an H-symbol can match anywhere in a , hence can match any vertex name ( subject to interference from previously matched rules  )  . Furthermore , since there is one occurrence of each vertex name for every edge  , it's impossible to run out of vertex-name occurrences  . The grammar will allow either endpoint of an edge to be " underlined "-- that is  , included in the vertex cover--so the parser must figure out which vertex cover to select  . However , the gr , -mtmar also requires two occurrences of U to match  . U can only match four contiguous identical input symbols that have not been matched in any other way  ; thus if the parser chooses to o iarge a vertex cover  , the U-symbols will not match and the parse will fail  . The proper number of D-symbols equals the length of the input string  , minust , e number of edges in the graph ( to ~ count for the // , -matches ) , minusk times the number of edges ( to account for the U-matches ) : in this case ,  16 - 4 - (2 ? 4) = 4 , as illustrated in the START rule . 
The result of this construction is that in order to decide whether a is in the language generated by the UCFG  , the
UUHt//2H3D//4DDD
A/IIIIIIII aaa abbbb bcccc dddd Figure  3: The grammar of Figure 2  , which encodes the vertex-cover problem of Figure I  , generates the string a = aaa abbbb ccccc ddddd accordin g to this parse tree  . The vertex cover c , d can be read off from the parse tree a ~ the set of elements domi  , ~ated by //- symbols . 
parser nmst search for a vertex cover of size 2 or less . 3If a parse exists , an appropriate vertex cover can be read off from beneath the //- symbols in the parse tree  ; conversely , if an appropriate vertex cover exists , it shows how to construct a parse . Figure 3 shows the parse tree that encodes a solution to the vertex-cover problem of Figure  1  . The construction thus reduces Vertex Coverto UCFG recognition  , and since the c , ~nstruction can be carried out in polynomial time , it follows that UCFG recognition and the more general ta  . sk of ID/LP parsing nmst be computationally difficult  . For a more detailed treatment of the reduction , see Barton (1984b ) . 
IMPLICATIONS
The reduction of Vertex Cover shows that the\[D /LP parsing problem is YP-complete  ; unless P = ~/ P , its time complexity is not bounded by , ' mypolynomial in the size ' of the grammar and input  . Ilence complexity analysis must be done carefully : despites intilarity to Earley's algorithm  , Shieber's algorithm does not have complexity O ( IG\[2 . n3) , but can sometimes undergo exponential growth of its internal structures  . Other computational , and linguistic on-sequences alzo follow . 
Although Shieber's parser sometimes blows up , it remains better than the alternative of , ~arsing an expanded " object ~ arnmar . " The NP-completeness result shows that the general c~e of ID/LP parsing is inherently difficult  ; hence it is not surprising that Shieber's ID/LP parser sometimes suffers from co  , n binatorial explosion . It is more important onote that parsing with the expanded CFG blows upine a ~ vc~es  . It should not beh~d to parse the lan-~lf the v  #rtexer  , veri . ~t , mallertll all expected , the D- . ~y , nbo ~ will up the extraeonti ~ muntrm that could have been matrhed I ~' more  ( f-symbols . 
guage that consists of a H permutations of the string abode  , but in so doing , the Earley parser can use 24 states or more to encode what the Shieber parser encodes in only one  ( recall Gl )  . Tile significant fact is not that the Shieber parser can blow up  ; it is that the use of the object grammar blows up unnecessarily  . 
The construction that reduces the Vertex Cover problem to ID/LPP  , x rsing involves a grammar and input string that both depend on the problem instance  ; hence it leaves it open that a clever programmer , night concentrate most of the contputational dilliculty of ID/LF'parsing into an of ll_ine grammar-precompilation stage independent of the input--under optimistic hopes  , perhaps reducing the time required for parsing ; minput ( after precompilation ) to a polynomial function of grammar size and inpt , t length . 
Shieber's algorithm has no precompilation step , ~ so the present complexity results apply with full force  ;   , ' my possible precompilation phase remains hyl ~othetical  . Moreover , it is not clear that a clever preco , npilation step is even possible . For example , if nenters into the true complexity of ID/LI ~ parsing  , ~ a factor multiplying an exponential ,   , an inpnt-indepemtent precompilation phase cannot help enough to make the parsing phase always run in polynomial time  . On a related note, . ~uppo , e the precom-pilation step is conversiol , to CF ( . ; farm ? md the runtime algorithm is the Earley parser  . Ah hough the precompila-tion step does a potentially exponent i  ; damount of work in producing G ' from G , another expoaential factor shows up at runtime because G ' in the complexity bound  G'2n ~ is exponentially larger than the original G ' . 
The NP-completeness result would be strengthened if the reduction used the same grammar for all vertex-cover problems  , for it woold follow that precompilation could not bring runtime down to polynomial time  . However , unless , ~= & P , there can be no such reduction . Since gr . ' Jannlar size would not count as a parameter of a fixed-gramm~tr\[D/LP parsing problem  , the l , se of the Earley parser on the object gr , -ulzmar would already constitute a polynomial-time algorithm for solving it  . ( See the next section for discussion . ) The Vertex Cover reduction also helps pin down the computational power of UCFGs  . AsG ,   , ' tadG't illustrated , a UCFG ( or an ID/LP gr , ' uumar ) is sometimes tnttch smaller than an equivalent CFG  . The NP-complete-ness result illumin at , _'s this property in three ways . First , th'e reduction shows that enough brevity is gained so that an instance of any problem in  . ~  . ~ can be stated in a UCFG that is only polyno , nially larger than the original problem instance . In contrast , the current polynomial-timer duc-tion could not be carried out with a CFG instead of a UCFG  , since the necessity of spelling out all the orders in which symbol slltight appear couhl make the CFG exponentially larger than the instance  . Second , the reduction shows that this brevity of expression is not free  . CFG'Shieber 1983:15n . 6) ment mn . ~ a possible precompilation step . but it i ~ concerned ~ , , , it l the ,  \[ , Pr ~' hL rum rather tha . '* tlt~rID rtth . -~ . 
7 9 recognition can be solved in cubic time or less , but unless P = . ~' P , general UCFG recognition cannot be solved in polynomial time  . Third , the reduction shows that only one essential use of the power to permute rule expansions is necessary to make the parsing problem NP -comphte  , though the rule in question may need to be arbitrarily long  . 
Finally , the ID/LP parsing problem illustrates how weakness of constraint c  , -mmake a problem computationally difficult . One might perhaps think that weak constraints would make a probleme mier since weak constraints ound easy to verify  , but it often takes ~ trong constraints to reduce the number of possibilities that an algorithm nmst consider  . In the present case , the removal of constraints on constituent order causes the dependence of the runtme boundong r  , ' unmar size to grow from IGI ~ to

The key factors that cause difficuhy in ID/LP parsing are familiar to linguistic theory  . GB-theory amt GPSG both permit the existence of constituents that are empty on the surface  , and thus in principle they both allow the kind of pathology illustrated by G ~  , subject to , -uueliora-tion by additional constraints . Similarly , every current theory acknowledges lexical ambiguity  , a key ingredient of the vertex-cover reduction . Though the reduction illumi-nates the power of certain u  , echanisms and formal devices , the direct intplications of the NP-completeness result for grammatical theory are few  . 
The reduction does expose the weakness of attempts to link contextfree generative power directly to efficient parsability  . Consider , for inst , ' mce , Gazdar's ( 1981:155 ) claim that the use of a formalism with only contextfree power can help explain the rapidity of human sentence processing : Suppose  . . . that the permitted class of genera-live gl ' an llllal'S constituted  , ts , b ~ ct-ft . h ~ J s c phrase structure gramni ; tr sc ; qmbl conly of generating con-text-freelungages . Such ; tmove w , mld have two iz , lportantue tath coretical conseqoences , one having to do with lear , mbility , the other with process-ability .   .   . We wenhi have the beginnings of an ex-plan:tti ~: u for the obvious  , but larg ~ . ly ignored , fact thltIhll:llD . ns process the ~ ttterance ~ they hear very rapidly  .   . " ~ cnll+llCe+cf ; tco;O . exl-frecI ; tngu ; tgeare I+r , val > lyl;ar ~; tl~h:in ; tl . ill n ' ~ that i > ~ i > r , ,l>ot'tionitl to the ct , bc , , f the lezlgl h of the ~ entenee or less . 
As previously remarked , the use of Earley's algorithm on the expanded object grant mar constitutes a parsing method for the IL xed-grammar  ( D/LP parsing problem that is indeed no worse than cubic in sentence length  . However , the most important , aspect of this possibility is that it is devoid of practical significance  . The object ~ , ' mmtar could contain trillions of rules in practical cases  ( Shieber ,  1983:4) . 
If IG '~, z . n ~ complexity is too slow , then it rentains too slow when ! G'I : is regarded as a constant  . Thus it is impossible to sustain this particular argument for the advantages of such formalisms  , as GPSG over other linguistic theories ; instead , GPSG and other modern theories seem to be ( very roughly ) in the same boat with respect to complexity . In such a situation , the linguistic merits of various theories are more important hancomplexity results  . ( See Berwick (1982) , Berwick and Weinberg (1984) , a JadRistad (1985) for further discussion . ) The reduction does not rule out the use of formalisms that decouple ID and LP constraints  ; note that Shieber's direct parsing algorithm wins out over the use of the object grammar  . However , if we assume that natural languages , x reefficiently parsable ( EP ) , then computational difFi cul-ties in parsing a formalism do indicate that the formalism itself fl ~ ils to capture whatever constraints are responsible for making natural languages EP  . If the linquistically rel . 
evant ID/LP grammars are EP but the general ID/LP gramu  , ars ~ e not , there must be additional factors that guarantee , say , a certain amount of constraint from the LP retation J  ( Constraints beyond the bare ID , LP formalism are reqt , ired on linguistic grounds , as well . ) The subset prtn ciple , ff language acqoisition ( cf . \[h , rwick and Wen-berg , 198 . 1:233 ) wouht lead the language learner to initially hypothesize strong order constraints  , to be weakened only in response to positive evidence  . 
l lowever , there are other potential ways to guarantee that languages will be EP  . It is possible that the principles of grammatical theory permit lunge  , ages that are not EP in the worst c , ' tse , just as ~ , ' uumatical theory allows sentences that are deeply center-embedded  ( Miller and Chomsky ,  1963 . Difficuh languages or sentences still wouhl not turn up in general use  , precisely because they wot , ht be difficult to process . ~ The factors making languages EP would not be part of grammatical theory because they would represent extragrammatical fctors  , i . e . the resource limitations of the language processing mechanisms  . In the same way , the limitations of language acquisition mechanisms might make hard-to-parse lunge  , age smaccesst ble to the langam gele , ' u ' nerin spite of satisfying ~ ammatical constraints  . However , these " easy explanations " are not tenable without a detailed account of processing mechanisms  ; correctore dictions are necessary about which constructions will be easy to parse  . 

This report describes research done at the Artificial Intelligence Laboratory of the Ma  . ssachusetts Institute of ~ a the ( ; B-fr ~ une work of Chom . -ky (1981) . for in ~ tance , the , ~ yn-tactic expre ~ . . , ionfunnrdered 0-grids attire X level i ' ~ constrained by tile principlv  . ~ of C . ' ~ eth ~ ry , gn do centrieity is a not lmr . ~ ignifi-cant constraint . See a L~o Berwick's (1982 discu . - , ,- , ionf constraints that could be pl ; wedml another gr ; unmatie' , d form , ' dism--lexic , ' d-fimetional grammar-to avoid as mfil . ' u " intr , ' u ' tability result . 
nit is often an or dotally remarked that lain rouges that allow relatively fre ~ word order '  . end to m ', tke heavy u . - . e of inf h ~' tions . Arichiattec-timln . l system can . -upply parsing constraints that make up for the hack of ordering e  . ,strai , * s : thu ~ tile situation we do not find is the computationa/lydill cult cnse~ff weak cmm craint  . 

Technology . Support for the Laboratory's artificial intelligence research as been provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract  N00014-80-C-0505  . During a portion of this research the author's graduate studies were supported by the Fannie and John Hertz Foundation  . Useful guidance and commentary during this research were provided by Bob Berwick  , Michael
Sipser , and Joyce Friedman.

Barton , E . (1984a ) . "Toweda Principle-Based Parser , " A . I . Menlo No . 788, M . I . T . Artificial Intelligence Laboratory , Cambridge , Mass . 
Barton , E . (198, 1b ) . " On the Complexity of ID/LP Parsing , " A . I . Menlo No . 812, M . I . T . Artificial Intelligence
Laboratory , Cambridge , Mass.
Berwick , R .  (1982) . " Computational Comphxity and Lexical-Functional Grammar  , " American Journal of Compu : ational Linguistica 8 . 3-4:97-109 . 
Berwick , R . , and A . Wcinberg (1984) . The Grammatical Basi ~ of Linguistic Performance . Cambridge , Mass . :
M.I.T . Press.
Chomsky , N .  (1981) . Lecture 8 on Government and Bind . 
ing . Dordrecht , toll and : Foris Publications.
Earley , J .  (1970) . " An Ef Ficient Context Free Parsing Algorithm , " Comm . ACM 13 . 2:94-102 . 
Gaxey , M . , and D . Johnson (1979) . Computer ~ and In-tractability . San Francisco : W . H . Freeman and Co . 
Gazdar , Gerald (1981) . " Unbounded Dependencies and Coordinate Structure  , " Linguistic Inquiry 12 . 2:155-184 . 
Miller , G . , and N . Chomsky (1963) . " Finitary Models of Language Users . " in R . D . Luce , R . R . Bush , and E . 
Galanter , eds . , Handbook of Mathematical Psychology , vol . II , 419-492 . New York : John Wiley and Sons , Inc . 
Ristad , E .  (1985) . "GPSG-Recognition is NP-Ilard , " A . I . 
Memo No . 837, M . I . T . Artificial Intelligence Laboratory , Cambridge , M , xss . , forthcoming . 
Shieber , S .  (1983) . "Direct Parsing of ! D/LP Grammars . " Technical Report 291 R , SRI International , Menlo Park , California . Also appears in Lingui~tic ~ and Philosophy 7: 2 . 

