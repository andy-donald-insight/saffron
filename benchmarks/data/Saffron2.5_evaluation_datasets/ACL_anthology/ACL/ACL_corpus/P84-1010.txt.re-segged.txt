DENOR MALIZATION AND CROSS REFERENCING IN THEORETICALLEXICOGRAPHY 
Joseph E . Grimes
DMLL , Morrill Hall , Cornell University
Ithaca N Ylh 853 USA
Summer Institute of Linguistics
7500 West Camp Wisdom Road
Dallas TX 75236 USA

A computational vehicle for lexicography was designed to keep to the constraints of meaning -text theory : sets of lexical correlates  , limits on the form of definitions , and argument relations similar to lexical -function algrA--~-r  . 
Relational databases look like a natural framework for this  . But linguists operate with a non-normalized view . Mappings between semantic actants and grammatical relations do not fitactant fields uniquely  . Lexical correlates and examples are poly-valent , hence denormalized . 
Cross referencing routines help the lexicographer work toward a closure state in which every term of a definition traces back to zero level terms defined extralinguistically or circularly  . 
Dummy entries produced from defining terms ensure no trace is overlooked  . Values of lexical correlates lead to other word senses  . Cross references for glosses produce an indexed unilingual dictionary  , the start of a fully bilingual one . 
To assist field work a small structured editor for a systematically denormalized database was implemented in PTP under  RT-11  ; Mumps would now be easier to implement on small machines  . It allowed fields to be repeated and nonatomic strings included  , and produced cross reference entries . It served for a monograph on a language of Mexico ? and for student projects from Africa and Asia  . -
ILEXICOGRAPHY
Natural language dictionaries seem like obvious candidates for information management in data baseform  , at least until you try to do one . Then it appears as if the better the dictionary in terms of lexicographic theory  , the more awkward it is to fit relational constraints  . Vest pocket tourist dictionaries are a snap ; Webster's Collegiate and parser dictionaries require careful thought  ; the Mel'chuk style of explanatory-combinatory dictionary forces us out of the strategies that work on ordinary databases  . 
In designing a tool to manage lexicographic field work under the constraints of Mel'chuk's meaning -text model  , the most fully specified one available for detailed lexicography  , Ilaid down specifications in four areas . First , it must handle all lexical correlates of the head word  . Lexical correlates relate to the head in ways that have numerous parallels within the language  . In English , for example , we have nouns that denote the doer of an action . Some , such as driver , writ-er , builder , are morphologically transparent . 
Others like pilot ( from fly ) and cook ( from cook ) are not ; yet they relate to the corresponding verbs in the same way as the transparent ones do  . Mel'-chuk and associates have identified about fifty such types  , or lexical functions , of which S_ , the habitual first substantive Just illustrated , is one . 
These types appear to have analogous meanings in different languages  , though not all types are necessarily used in every language  , and the relative popularity of each differs from one language to another  , as does the extent to which each is grammat -icalized  . For example , English has a rich vocabulary of values for a relation called Ma~n  ( from Latin magnus ) that denotes the superlative degree of its argument : Magn  ( sit ) = ti 6ht , Magn(black ) = Jet , pitch , coal , Magn(left ) = hard , Magn---~ay ) = for all you ' reworth , and on and on . On the other hand Huichol , a Uto-Azte can language of Mexico I have been working on since  1952  , has no such vocabulary ; it uses the simple intensive syeme and va~c ~ a for all this  , and 2 pick supits lexical richness in other areas . 
Second , a theoretically sound definition uses words that are themselves defined through as long a chain as possible back to zero level words that can be defined only in one of two ways : by accepting that some definitions -- as fe was possible -- may be circular  , or by defining the zero level via extralinguistic experiences  . Some dictionaries defines weet circularly in terms of sugar and vice versa  ; but one could also begin bypassing the sug-ar bowl and thus break the circularity  . The tool must help trace the use of defining words  . 
Third , the arguments in the semantic representation of a word have to relate explicitly to grammatical elements like subjects and objects and possessors : his projection of the budget and  1 NSF grant BNS-79060hl funded some of this work . 
2 Huichol transcription follows Spanish except high back unrounded  , ' glottal stop , ? hight one , Wlong syllable , ~ rhythmbreak , ~ voiced retro-flexal veopal at alfricative , ~ retrof lexflap , cuV labiove larstop . 
3 8 please turn out the li6ht each involve two arguments to the main operative word  ( him and budget , you and li6ht ) , but the relationship is handled in different grammatical frames  . 
Finally , the tool must run on the smallest , most portable machine available , if necessary trading processing time for memory and external space  . 
IIRELATIONS
Relations were proposed by Codd and elaborated on by Fagin  , Ullman , and many others . They are unordered sets of tuples , each of which contains an ordered set of fields . Each field has a value taken from a domain -- semantically  , from a particular kind of information . In lexicography the tuples correspond , not to entries in a dictionary , but to subentries , each with a particular sense . Each tuple contains fields for various aspects of the form  , meaning , meaning-to-form mapping , and use of that sense . 
For the update and retrieval operations defined on relations to work right  , the information stored in a relation is normalized  . Each field is restricted to an atomic value ~ it says only one thing  , not a series of different things . No field appears more than once in a tuple . Beyond these formal constraints are conceptual constraints based on the fact that the information in some fields determines what can be in other fields  ; Ullman spells out the main kinds of such dependency  . 
It is possible , as Shu and associates show , to normalize nearly any information structure by partitioning it into a set of normal form relations  . 
It can be presented to the user , however , in a view that draws on all these relations but is not itself in normal form  . 
Reconstituting a subentry from normal form tuples was beyond the capacity of the equipment that could be used in the field  ; it would have been cripplingly slow . Before sealed Winchester disks came out , floppies were unreliable intropical hu-midity where the work was to be done  , and only small digital tape cartridges were thoroughly reliable  . So the organization had to be managed by sequential merges across a series of small  (  . 25M ) tapes without random access . 
The requirements of normal form came to be an issue in three areas  . First , the prosaic matter of examples violates normal form  . Nearly any field in a dictionary can take any number of illustrative examples  . 
Second , the actants or arguments at the level of semantic representation that corresponds to the definition are in a theoretical status that is not yet clear  . Mel'chnk ( 1981 ) simply numbers the act-ants in a way that allows them to map to grammatical relations in as general away as possible  . 
Others , ~' self included , find recurring components of definitions on the order of Fillmore's cases  ( 1968 ) that are at least as consistently motivated as are the lexical functions  , and that map as sets of actants to sets of grammatical relations  . Rather than load the dice at this uncertain stage by designating either numbered or labeled actants as distinct field types  , it furthers discussion to be able to have Actant as a single field type that is repeatable  , and whose value in each instance is a link between an actant number  , a prcposed case , and even possibly a conceptual dependency category for comparison  ( Schank and Abelson ,  1977 . 11-17) . 
Third , lexical correlates are inherently many-to-one . For example , Huichol ~ u~i ' house ' in its sense labeled 1 . 1' where a person lives ' has sever -= taa . cuaaal antonyms : Ant ( ~ u ~ i1 . 1)+' space in .   . ~ of ront of a house ', ~ ull . ru ' aa ' space behlnda the house ', tel . cuarle ' space outside the fence ' , and Janadverbial use of taa . cuaa ' outdoors ' ( Grimes , 1981 . 88) . 
One could normalize the cases of all three types . But both lexicographers and users expect the information to be in nonnormal form  . Furthermore , we can make a realistic assumption that relational operations on a field are satisfied when there is one instance of that field that satisfies them  . 
This is probably fatal for Joins like " get me the Huichol word for ' travel '  , then merge its definition with the definitions of all other words whose agent and patient are inherently coreferential and involve motion '  . But that kind of capability is beyond a small implementation anyway  ; the lexicographer who makes that kind of pass needs a large scale  , fully normalized system . The kinds of selections one usually does can be aimed at any instance of a field  , and projections can produce all instances of a field  , quite happily for most work , and at an order of magnitude lower cost . 
The important thing is to denormalize systematically so that normal form can be recovered when it is needed  . Actants denormalize to fields repeated in a specified order  . Examples denormalize to strings of examples appended to whatever field they illustrate  . Lexical correlates denormalize to strings of values of particular functions  , as in the antonym example Just given . The functions themselves are ordered by a conventional list that groups similar functions together  ( Grimes 1981 . 288-291) . 
IIICROSSREFERENCING
To build a dictionary consistently along the lines chosen  , a computational tool needs to incorporate cross referencing  . This means that for each field that is built , dummy entries are created for all or most of the words in the field  . 
For example , the definition for ' opossum ' , y~u-xu , includes clauses like ca+u . ~ u + urime Ucu ~' aaw ' eats things that are not green ' and pUcu ~ i  . m~e-s_~e'it stail is bare ' . From these notes are generated that guarantee that each word used in the definition will ultimately either get defined itself or will be tagged yuun ~ itGmep ~ im~ate'e very body knows it ' to identify it as a zero level form that is undefinable  . Each note tells what subentry its own head word is taken out of  , and what field ; this information is merged into a repeatable Notes field in the new entry  . Under the stem ~ ruuri B ' be ? Jor Mnep Ucua ' aa ' eatsthlngs that are not green '  . 
This is a reminder to the lexicographer , first that there needs to be an entry for yuuri in sense B  , and second that it needs to account at the very least for the way that stem is used in the definition  ( d ) field of the entry for yeuxu . 
Cross referencing to guarantee full coverage of all words that are used in definitions backs up a theoretical claim about definitional closure : the state where no matter how many words are added to the dictionary  , all the words used to define them are themselves already defined  , back to a finite set of zero level defining vocabulary  . There is no clai , r that such a set is the only one possible ; only that at least one such set is l ~ Ossible . To reach closure even on a single set is such an ~--  , ense task -- I spent eight months full time on Huichol lexicography and didn't get even a twentieth of the everyday vocabulary defined -- that it can be approached only by some such systematic means  . 
There are sets of conformable definitions that share most parts of their definitions  , yet are not synonyms . Related species and groups of als ~ mals and plants have conformable definitions that are largely identical  , but have differentiating parts as well ( Grimes 1980 )  . The same is true of sets of verb sllkeca/tel ' besitting somewhere '  , ve/'u ' hestanding somewhere ' , ma/mane ' be spread out somewhere ' , and caa/hee'be laid out straight somewhere ' ( the slash separate gunitary and multiple reference stems  )  , which all share as part of their ? . ?, J ? . defl nltlon see . p~reu . teevl X-s ~ ecayup at at U?xa ~ . -s~e'spend an extended time at X without changing to another location '  , but differ regarding the spatial orientation of what is at X  . Cross referencing of words in definitions helps identify these cases  . 
Values of lexical functions are not always completely specified by the lexical function and the head word  , so they are always cross referenced to create the opportunity for saying more about them  . 
Qu  ~ i1 . 1 ' house ' in the sense of ' habitation of hu -mans'--~ersus ' stable ' or ' lair ' or ' hangar '   1  . 2 and ' ranch'1 . 3) is pretty well defined by the function S_ , substantive of the second actant , plus the head v ~ rbca/tel1 . 2' live in a house ' ( versus ' besitting somewhere ' ,  1 , 1 and ' live in a locality '1 . 3) . Nevertheless it ha~fifteen lexical functions of its own  , includin@the antonym set given earlier , and only one of those functions matches one of the nine that are associated with ca/tel  1  . 2:S . ( ca/tei1 . 2) = S2(~u~i1 . 1) = ~ u ~' inhab-itant , householder ' . 
Stepping outside the theoretical constraints of lexicography proper  , the same cross referencing mechanism helps setup bilingual dictionaries  . Definitions are always in the language of the entries  , but it is useful in many situations to gloss the definitions in some language of scientific discourse or trade  , then cross reference on the glos-ses by adding a tag that puts the notes from them into a separate section  . I have done this both for Spanish , the national language of the country where Huicholisspoken  , and for Latin , the language of the Linnean names of life forms . What results is not really a bilingual dictionary  , because it explains nothing at all about the second or third language -- no definitions  , no mapping between grammatical relations and actants  , no lexical functions for that language . It simply gives examples of counterparts of glosses  . As such , however , it is no less useful than some bilingual dictionaries  . To be consistent , the entries on the second language side would have to be as full as the first language entries  , and some mechanism would have to be introduced for distinguishing translation equivalents rather than Just senses in each language  . As it is , cross referencing the glosses gives what is properly called an indexed unilingual dictionary as a handy intermediate stage  . 
IVIMPLEMENTATION
Because of the field situation far which the computational tool was required  , it was implemented first in 1979 on an 8080 microcomputer with 32/  ( of memor ~ and two 130K sequentially accessible tape cartridges as an experimental package  , later moved to an LSI-11/2 under RT-11 with . 25M tapes . The language used was Simons's PTP (198h) , designed for perspicuous handling of linguistic data  . Data management was done record by record to maintain integrity  , but the normal form constraints on at-omicity and singularity of fields were dropped  . 
Functions were implemented as subtypes of a single field type  , ordered with reference to a special list . 
Because dictionary users expect ordered records , that constraint was added , with provision for mapping non-ASCII sort sequences to an ASCII sort key that controlled merging  . 
Data entry and merging both put new instances of fields after existing instances of the same field  , but this order of inclusion could be modified by the editor  . Furthermore , multiple instances of a field could be collapsed into a single non-atomic value with separator symbols in it  , or such a string value could be returned to multiple instances  , both by the editor . Transformations between repeated fields , strings of atomic values , and various normal forms were worked out with Gary 
Simons but not implemented.
Cross referencing was done in two ways : automatically for values of lexical functions  , and by means of tags written in while editing for any field  . Tags directed the processor to build across reference note for a full word  , prefix , stem , or suffix , and to file it in the first , second , or third language part . In every case the lexicographer had opportunity to edit in order to remove irrelevant material and to associate the correct name form  . 
Besides the major project in Huichol , the system was used by students for original lexicographic work in Dinka of the Sudan  , Korean , and Isnag of the Philippines . If I were to rebuild the system now , I would probably use the University of California at Davis's CP/M version of Mumps on a portable Winchester machine in order to have total ta management  , however , would remain the same , as it fits the application area well . I suspect , but have not proved , that full normalization capability provided by random access would still turn out unacceptably slow on a small machine  . 
VDISCUSSION
Investigation of a language centers around four collections of information that computationally are like databases : field notes  , text collection with glosses and translations , grammar , and dictionary . The first two fit the relational paradigm easily , and are especially useful when supplemented with functions that display glosses in-terlinearly  . 
The grammar and dictionary , however , require de-normalization in order to handle multiple examples  , and dictionaries require the other kinds of denorm-alization that are presented here  . Ideally those examples come out of the field notes and texts  , where they are discovered by an automatic parsing component of the grammar that is used by the selection algorithm  , and they are attached to the appropriate spots in the grammar and dictionary by relational join operations  .  ~-
VIRE FERENCES
Codd , E . F .  1970 . A relational model for large shared databanks . Communications of the ACM 13:6 . 377-387 . 
Fagin ~ R .  1979 . A normal form for relational databases that is based on domains and keys  . IBM
Research Report RJ 2520.
Fillmore , Charles J .  1968 . The case for case . In ~ m ~ on Bach and Robert T . Harms , eds . , Univers-als in linguistic theory , New York : Holt , Rine-hart and Winston ,  1-88 . 
Grimes , Joseph E .  1980 . Huichollife form classification I : Animals . Anthropological Linguistics 22:5 . 187-200 . II : Plants . Anthropological
Linguistics 22:6.264-27h.
W .   . . . . .   .  1981 .   E1 huiehol : a puntes so breellexlco \ [ Huichol : notes on the lexicon \]  , with P . de la Cruz , J . Carrillo , F . Dzaz , R . Dlaz , and A . de la Rosa . ERIC document ED 210901, microfiche . 
Kaplan , Ronald M . and Joan Bresnan .  1982 . Lexical-functional grammar : a formal system for grammatical representation  . In Joan Bresnan , ed . 
The mental representation of grammatical relations  , Cambridge : The MIT Press ,  173-281 . 
Mel'chuk , Igor A .  1981 . Meaning-text models : a recent trend in Sovi et linguistics  . Annual Review of Anthropology 10:27-62 . 
. . . . . , A . K . Zholkovsky , and Ju . D . Apresyan . in press . Tolkovo-kombinatorny Jslovar'russkogojazyka ( with English introduction )  . Vienna:
Wiener Slawistischer Almanach.
Schank , Roger C . and Robert P . Abels on . 1977.
Scripts , plans , goals and understanding : an inquiry into hnma ~ knowledge structures  . Hillsdale
NJ : Lawrence Erlbaum Associates.
Simons , Gary F . 198 h . Powerful ideas for text processing . Dallas : Summer Institute of Linguistics . 
Ullman , Jeffrey D .  1980 . Principles of database systems . Rockville MD : Computer Science Press . 
Wong , H . K . T . and N . C . Shu .  1980 . An approach to relational database scheme design  . IBM Computer
Science Research Report RJ 2688.

