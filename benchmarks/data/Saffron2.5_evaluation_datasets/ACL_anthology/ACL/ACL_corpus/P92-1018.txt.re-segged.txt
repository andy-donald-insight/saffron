Linear ContextFree Rewriting Systems and Deterministic Tree-Walking 

David J . Weir
School of Cognitive and Computing Sciences
University of Sussex
Falmer , Bright on BN 19 QH
david w@cogs.sussex , ac.uk
Abstract
We show that the class of string languages generated by linear contextfreer writing systems is equal to the class of output languages of deterministic tree-walking transducers  . From equivalences that have previously been established we know that this class of languages is also equal to the string languages generated by contextfree hypergraph grammars  , multicomponent tree-adjoining grammars , and multiple contextfree grammars and to the class of yields of images of the regular tree languages under finite-copying topdown tree transducers  . 
Introduction
In \[9\] a comparison was made of the generative capacity of a number of grammar formalisms  . Several were found to share a number of characteristics  ( described below ) and the class of such formalisms was called linear contextfreer writing systems  . This paper shows how the class of string languages generated by linear contextfreer writing systems relates to a number of other systems that have been studied by formal language theorists  . In particular , we show that the class of string languages generated by linear contextfree rewriting systems is equal to the class of output languages of deterministic tree-walking transducers  \[1\]  . 
A number of other equivalences have already been established  . In \[10\] it was shown that linear contextfree rewriting systems and multicomponent tree adjoining grammars  \[6\] generate the same string languages . The multiple contextfree grammars of \[7\] are equivalent to linear contextfree systems . This follows * I would like to thank Joost Engelfriet for drawing my attention to contextfree hypergraph grammars and their relationship to deterministic tree-walking automata  . 
from the fact that multiple contextfree grammars are exactly that subclass of the linear contextfreer writing systems in which the objects generated by the grammar are tuples of strings  . The class of output languages of deterministic tree-walking transducers i known to be equal to the class of yields of images of the regular tree languages under finite-copying topdown tree transducers  \[4\] and in \[3\] it was shown that it also equal to the string languages generated by contextfree hypergraph grammars  \[2  ,  5\] . 
We therefore have a number of Characterizations of the same class of languages and results that have been established for the class of languages associated with one system carry over to the others  . This is particularly fruitful in this case since the output languages of deterministic tree -walking transducers have been well studied  ( see\[4\] )  . 
In the remainder of the paper we describe linear contextfreer writing systems and deterministic tree-walking transducers and outline the equivalence proof  . 
We then describe contextfree hypergraph grammars and observe that they are a contextfree r writing system  . 
Linear Context-Free Rewriting Systems Linear contextfree rewriting systems arose from the observation that a number of grammatical formalisms share two properties  . 
1 . Their derivation tree sets can be generated by a contextfree grammar  . 
2 . Their composition operations are size-preserving , i . e . , when two or more substructures are combined only a bounded amount of structure is added or deleted  . 

Examples of formalisms that . satisfy these conditions are head grammars \[8\] , tree adjoining grammars \[6\] , multicomponent tree adjoining grammars \[6\] and contextfree hypergraph grammars . It was shown \[9\] that a system satisfying the above conditions generates languages that are semiline ar and can be recognized in polynomial time  . The definition of linear contextfree rewriting systems is deliberately not specific about the kinds of structures being manipulated  . In the case of head grammars these are pairs of strings whereas tree adjoining grammars manipulate trees and contextfree hypergraph grammars manipulate graphs  . 
In \[9\] size-preserving operations are defined for arbitrary structures in terms of properties of the corresponding functions over the terminal yield of the structures involved  . The yield is taken to be a tuple of terminal strings  . We call the function associated with a composition operation the yield function of that operation  . The yield function of Of of a composition operation f gives the yield of the structure f  ( cl , l dots , cn ) based on the yield of the structures el ,  ? ?  . , am . 
Let ~ be an alphabet of terminal symbols , f is an nary linear regular operation over tuples of strings in ~ if it can be defined with an equation of the form f  ( (xl , 1 ,  .   .   . , xl , k ,), . .  . , ( ran , l, . . . , xn , k , ,)) - ---( tl, .   .   .   , tk ) where each ki > O , n >_0 and each t i is a string of variables ( x's ) and symbols in ~ and where the equation is regular  ( all the variables appearing on oneside appear on the other  ) and linear ( the variables appear only once on the left and right  )  . 
For example , the operations of head grammars can be define with the  equations1: wrap (   ( Xl ,  ~2) , ( Yl , Y2)): ( XlYl , Y2X2) concl((xl , x2) , ( Yl , Y2)) = ( xx , x2 y , y2) C0n?2(( , ~1 , X2) , ( Yl , Y2)) = (2?IX2Yl , Y2)
Thus , we have wrap (( ab , ca ) , ( ac , bc )) = ( abac , bcca ) concl((ab , ca ) , ( ac , bc )) = ( ab , caa ebc ) conc2(ab , ca ) , ( ac , be )) = ( abcaac , be ) A generalized context-free grammar ( g c f g ) \[8\] is denoted G = ( VN , S , F , P ) where 1These operations differ from ( but are equivalent to ) those used in \[8\] VN is a finite set of nonterminal symbols , 
S is a distinguished member of VN,
F is a finite set of function symbols and P is a finite set of productions of the form 
A--+ f(A1, .   .   . , A , ) where n > 0, fCF , and A , AI, .   .   . , AmCVN . 
With a grammatical formalism we associate an in-te r p retation function m that maps symbols in F onto the formalism's composition operations  . For example , in a typical head grammar the set F might include W  , el , C2 where re(W ) = wrap , m(Cl ) = conclandre(C2) = conc2 . 
A formalism is a linear context-free rewrit ing system  ( lefts ) if every grammar can be expressed as a gcfg and its interpretation function m maps symbols onto operations whose yield functions are linear regular operations  . 
In order to simplify the remaining discussion we assume that m maps directly onto the yield functions themselves  . 
The language L(G ) generated by a gcfgG = ( VN , S , F , P ) with associated interpretation function mis defined as 
L ( G ) = where * A = := Vre ( f ) G if A--~f0EP*A~m (  /  )   ( tl ,   .   .   . , tn )
G if A--*f(A1, ..., An ) EP and
Ai ~-- ~ ti(l < i < n).

We denote the class of all languages generated by lefrs as LCFRL  . 
Deterministic Tree-Walking Transduc-ers A deterministic tree-walking transducer is an automaton whose inputs a rederivation trees of some contextfree grammar  . The automaton moves around the tree starting at the root  . At each point in the computation , depending on the label of the current node and the state of the finite state control  , the automaton moves string . The computation ends when the machine tries to move to the parent of the root node  . 
We denote a deterministic tree-walking t rans-ducer  ( d t w t ) by M- ( Q , G , A ,  6 , q0 , F ) where
Q is a finite set of states,
G = ( VN , VT , S , P ) is a contextfree grammar withoute-rules , 
A is a finite set of output symbols , 6: Q ? ( VNU VT ) ---+ Q?D ? A * is the transition function where
D = stay , upOd(k)\[k > 1 , q0EQ is the initial state and
FC_Q is the set of final states.
A configuration of M is a 4-tuple ( q ,  7 , r / , w ) where qEQ is the current state ,   7 is the derivation tree of G under consideration , r / is a node in 7 or T ( where 1" can be thought of as the parent of the root of T )  , and wEA * is the output string produced up to that point in the computation  . We have ( q ,  7 , r / , w)\['-M(q t ,  "\[ , r / , , WW /) if the label of r / is X , ~ f(q , X ) = ( q' , d , w ') such that when d = stay then T/'=r/ , when d = d ( i ) then 7/' is the ith child of r/ ( if it exists )  , and when d = up then r /' is the parent of r/ ( T if r / is the root of 7 )  . 
The output language OUT ( M ) of M is the set of strings : we A * I ( q0 , 7 , r/r , e)b~/(qf ,  7 , T , w ) , qlEF and 7 is a derivation tree of G with root r/r where F - ~ is the reflexive transitive closure of \['- M " We denote the class of all languages OUT  ( M ) where
Misadtwtas OUT ( DTWT).
Consider the dtwt
M = ( qo , ql , q2 , q3 , G , a , b , c , d , ~ f , qo , q3) where G = ( S , e , S , S -* A , A - ~ A , A -* e ) and the relevant component of 6 is defined as follows . 
6(q0 , s ) = ( q0 , d(1) , e ) 6( q0 , A ) = ( q0 , d(1) , a ) 6( ql , S ) = ( q2 , d(1) , e ) 6( q2 , A ) = ( q2 , d(1) , c ) 6 ( q3 , 5') -~( q 3 , up , e ) 6( q o , e ) = ( ql , up , e ) 6( q z , A ) = ( qz , up , b ) ~ f(q ~ , e ) = ( q3 , up , e ) 6( q3 , A ) = ( q3 , up , d ) It can be seen that OUT ( M ) = an bnc'~d ' ~ In > 1 . 
Equivalence
In this section we outline a two part proof that
OUT ( DTWT ) = LCFRL.
OUT(DTWT ) C_LCFRL
Consider adt wtM = ( Q , E , G , A ,  6 , qo , F ) where G = ( VN , VT , S , P ) . For convenience we assume that M is adtwt without stay moves  ( see Lemma 5 . 1 in\[3\] for proof that this can be done ) . 
Given a derivation tree of G , and a node r / in this tree , we record the strings contributed to the output between the first and last visit to nodes in the subtree rooted at r/  . These contributed terminal strings can be viewed as a k tuple where k is the number of times that the transducer enters and then leaves the subtree  . 
For each production X--*X1 .   .   . Xn in P and each pEQ we call C((X , p, . ) - . +( X1, e , 0) .   .   . ( Xn , ?, 0)) C((A,p, . ) ( XI , e , 0) .   .   . ( Xn , e ,  0 ) ) simulates all subcomputations of M that start in state pata node labelled X that has been expanded using the production X --*  X1   .   .   . X n . The node labelled A may be visited several times , but each time the machine must be in a different state  ( otherwise , being deterministic , it would loop indefinitely ) . The sequence of visits is recorded as a string of states  . The component of the rule that is underlined indicates which of the children or parent is currently being visited  . The call C((X,a,?)-~(Xl , al , il) .   .   . ( Xn , an , in ) ) is made when a computation is being simulated in which the node labelled A has been visited \] a\ [ times  ( \[ a\[denotes the length of a ) such that on the ith visit the machine was in the state indicated by the ith symbol in a  . al , .   .   .   , an are used in a similar way to encode the state of the machine during visits to each child node  . ? is a string of terms that is used to encode the output produced between the first and last visit to the subtree rooted at the node labelled A  . Ultimately , it has the form . tl .   .   .   . - tk . where each tien codes the composition of the ith component of the tuple  . The notation used for each ti is identical to that used in the equations used to define lefts composition operations given earlier  , i . e . , each t i is a string of output symbols and x's . i l , .   .   .   , in are used to encode the number of times that a given child has been visited from above  . This gives the number of times the subtree rooted at that node has been visited and  , hence , encodes which component of the tuple was completed most recently  . Thus , for each j , 1_<j_<n , the simulation has moved from the parent to the j th child ij ponent of the tuple derived from the jth node should contribute to the parent's current component  . When a move is made from the parent node to the j th child we add the variable xj  , /~+ x to the term currently being constructed for the parent node  . In other words , the next component of the parent output is the ij + lth component of its jth child  . 
The call
C((X , a , ?) --* ( X1, oq , ix) . . . ( Xj , aj , ij ) .   .   . ( Xn , an , in ) ) sumulates the machine visiting the j th child of a node expanded using the rule X--~  X1   . .  . X n . 
From M the gcfgG ' is constructed such that G ' =   ( V  ~ ,  5" , F , P ') where vk = S'u(X , a ) lXeVNUVT and non-repeating a eQ * and the procedure C determines P ' and F where for each production A - ~  X1   .   .   . Xn in P and each pEQ we call C((A , p, . )--*( Xx , c , 0) .   .   . ( X  ~ , e , 0)) In addition , for each a EVT and each pEQ we call
C((a , p , .)) - ~
C is defined as follows.
Case 1.
C((X , ap , ?) ---* ( X1, oq , ix) . .  . ( Xn , an , in )) Note that if n = 0 then XEVT , otherwise , XEVN . 
If 6(p , X ) = ( q , up , w ) then ( X , ap)--~ f((Xl ,  ~1)  ,   .   .   .   , ( Xn , otn ) ) E P ' for a new function f E F where re ( f ) is defined by f ( ( xl ,   .   .   . , mix ), . .  . , ( xl , . :  . , mi ,)) '= ( tl, .   .   . , tk ) where Cw .  = 41 "  .   .   . " tk ' . (note that when ij = 0 for some j then ( Xl, .   .   .   , xij ) will appearase ) , in addition , for each p ' in Q that does not appear in apcall C  ( ( X , o~pp ' , ew . ) ---*( Xl , ~1, i1) .   .   . ( Xn , O~n , in )) Note that ? has been placed after ew . This indicates that we have finished with the current component of the tuple  . 
Otherwise , if 6(p , X ) = ( q , d(j ) , w ) and 1_< j < n then call c((x , ap , ? w = j , ~ j + x )( xt , oq , it ) .   .   . ( xj , ajq , #+1) . . . (Xn , o~ , ~ , i , O ) Note that if XjEVT then it is not possible for the machine to move down the tree any further  . 
Case 2.
c((x , ?) --.
( X1,(~1, il) .   .   . ( Xj , ajp , ij ) .   .   . ( Xn , an , in))
If 6(p , Xj ) = ( q , up , w ) then call ( Xl , al , i l ) .   .   . ( Xj , ajp , ij ) .   .   . ( Xn , an , in )) Note that ? will end with xj , ii and the ijth compoent of the yield at As . will end in w . 
Otherwise , if 6(p , Xj ) = ( q , d(k ) , w ) then if XjEVN for each p ' in Q and not in ai P call c  ( ( x , a ,  ?) - -  . 
( Xl , ot\], it) .   .   . ( Xj , % pp ', ij ) .   . . ( Xn , an , in ) ) This simulates the next visit to this node ( which must be from below ) in the ( guessed ) state p ' . 
In addition to the productions added by C , include in P ~ the production S~--- . ( S , qoot q ! ) for each qiEF and a EQ * such that a ootqi is non-repeating and/f  ( q , S ) = ( qI , up , w ) for somewwhere q is the last symbol in q0 a . 
A complete proof would establish that the following equivalence holds  . 
( Aa ) ~( wt, .   .   .   , w ,   ) if and only if there is a derivation tree 7 of G with root ~? r labelled A such that a = at .   .   . an for some al , .   .   .   , an EQ + and for each i(1 < i < n ) 7 ,  7 , f , where ai = pia\[=a\['qi for some c ~ , a ~' EQ * . 
Consider the application of this construction to example the dtw t given earlier  . The grammar contains the following productions ( where productions containing useless nonterminals have been omitted  )  . 
( S , qoqlq3)--~A((A , qoq lq2 q3)) ( A , qoq lq2 qa ) --* f2((A , qoq lq2 qa )) = ( A , qoq lq2 q3)--~ f3((e , qoq2)) where = ( e , qoq2) ~ f40 where 140 = ( e , e ) . 
By renaming nonterminal we get the four productions 
S--*fl(A)A-.f2(A)
A---*f3(e)e---*f 40
LCFRLC_OUT ( DTWT)
Consider the gcfgG--(VN , S , F , P ) and mapping m that interprets the symbols in F . Without loss of generality we assume that no nonterminal appears more than once on the right of a production and that for each AEVN there is some rank  ( A ) = k such that only k-tuples are derived from A . 
We define adt wtM = ( Q ,  ~ , G  ~ , liT ,  6 , qo , F ) where G ~ is a contextfree grammar that generates derivation trees of G in the following way  . A derivation involving the use of a production zr will here presented by a tree whose root is labelled by z r = A--*f  ( A 1 ,   .   .   .   , Am ) with n subtrees encoding the derivations from A1 ,   .   .   . , An . 
The roots of these subtrees will be labelled by then productions used to rewrite the  A1   ,   .   .   . , An . Let lhs(~r ) = A and rhs(~r ) = AI, .   .   . , An . 
The dtwtM walks around a derivation tree 7 of G ' in such a way that it outputs the yield of  7  . Each subtree of 7 rooted at a node ~/ labelled by the production ~ r will be visited on k = rank  ( lhs Or ) ) occasions by M . During the ith visit to the subtree M will output the ith component of the tuple  . We therefore include in Qk states 1, .   .   .   , k that are used to keep track of which tuple is being considered  . This will generally involve visiting children of y as determined by the equation used to define function used in  7r   . Additional states in Q are used to keep track of these visits as follows  . When the lth child of T/has finish edits ruth component  , M will move back up to y in state ( A z , m ) . Since no nonterminal appears twice on the right of a production it is possible for M to determine the value of l from At while at y  . 
For each production ~ r = A--*f(A1, .   .   .   , A n ) EP where f is interpreted as the function defined by the equation f  (   ( xX , 1  ,   .  -  . , Xl , kl), .  -  . , ( Xnj, .   . -, Xn , k ,)) = ( tl, .   .   .   , t k ) we include the following components in the definition of  6  . 
For each i(1 < i < k ) ? if t i = w x l , m ? , where w is a possibly empty terminal string then let  6  ( i , ~) = ( m , down(O , w ) ? if ti = w ( in which case it is time to move up the tree ) let 6 ( i , ~ r ) = (( lhs(Ir ) , i ) , up , w ) For each BE rhs(~r ) and each m , 1 <_m <_ rank(B ) , let 6(( B , m ) , 7 r ) = ( q , move , w ) where ( q , move , w ) is determined as follows . For some unique I we know that B is the lth nonterminal on the right hand side of  7r   . There is a unique ti such that ti = ? lXZ , m w?2 where w is a possibly empty string of terminals . 
Case 1: ?2 is empty
In this case the ith component of the current node is complete  . Thus , q = ( lhs(r ), i ) and move = up . 
Case 2: ?2 begins with the variable xv , m , In this case the machine M must find them ' th component of the /' th child  . Thus , q = m ' and move = d(l') . 
It should be clear that the start state q0 should be 1 and the set of final states F = ( S , rank(S )) . 
A complete proof would involve verifying that the following equivalence holds  . 
( Aa)~(wl, .   .   .   , W n ) if and only if there is a derivation tree 7 of G ' with root ~ r labelled 7r such that lhs ( lr ) = A and for each i ( 1 < i < n )   ( i ,  7 , ~/ r , e)t-~4((A , i ) ,  7 , t , w  ~ ) We apply the construction to the grammar produced in the illustration of the first construction  . 
First , we name the productions of the grammar 7rl = S--~fl ( A ) ~ r2 = A--*f2 ( A ) The construction gives a machine in which the function  5 is defined as follows . 
di(1 , r l ) = (1 , d(1) , e ) & (1 , ~ r2) = (1 , d(1) , a ) 5 (2 ,  ~2) = (2 , d(1) , e ) 5 (1 , 7 rz ) = (1 , d(1) , a ) 5 (2 , r3) = (2 , d(1) , c ) 5 (1 , ~ r4) = (( e ,  1) , up , e ) 5 (2 ,  ~ , ) = fie ,  2) , up , ~) 6((A ,  1) , r l ) = (2 , d(1) , e ) 6(( A ,  2) , 7 rl ) : (( S ,  1) , up , e ) 6(( A ,  1) , r ~) = (( A ,  1) , up , b ) 5((A ,  2) , 7 r2) = (( A ,  2) , up , d ) 5((e ,  1) , 7 rz ) = (( A ,  1) , up , b ) 5((e ,  2) , r3) = (( A ,  2) , up , d ) The contextfree grammar whose derivation trees are to be transduced has the following productions  . 
";l'l " ~71"27l'1-"+7r3
We denote a hypergraph as a five tuple H(V , E ,  ~ , incident , label ) where
V is a finite set of nodes,
E is a finite set of edges,
E is a finite set of edge labels , incident : E --* V * is the incidence function and label : E --+ ~ is the edge labelling function 
For example , in the above graph
V = v l , v2 , vz , v4 , E = el , e2 , e3 , = a , b , c , incident(el ) = ( v2 , vl , v4) , i ,   , cide . t(e2) = ( v4 , vl ) , incident(e3) = ( v3) , label ( e , ) = a , label(e2)-b and label(e3)--c . 
A string can be encoded with a string hyper-g raph  \[5\]  . The string bcaab is encoded with the following graph  . 
71"2~71"271"2~71"371"3~7i'4
Context-Free Hypergraph Grammars
In this section we describe contextfree hypergraph gramars since they are an example of alcfrs involving the manipulation of graphs  , z The class of string languages generated by contextfree hypergraph grammars is equal to OUT  ( DT WT )   \[3\] and the above result shows that they are also equal to LCFRS  . 
A directed hypergraph is similar to a standard graph excep that its  ( hyper ) edges need not simply go from one node to another but may be incident with any number of nodes  . If an edge is incident with n nodes then it is a n-edge  . Then nodes that are incident to some edge are linearly ordered  . For example , in the figure below , dots denote nodes and labelled square boxes are edges  . The edge labelle da is a 3-edge , the edge labelled b is a 2-edge and the edge labelled c is a 1-edge   . When the number of nodes incidento an edge exceeds  2  , numbered tentacles are used to indicate the nodes that are incident to the edge  . The numbers associated with the tentacles coming from an edge indicate the linear order of the nodes that are incident to that edge  .   2-edges are shown in the standard way and 1-edges can be used as a way of associating labels with nodes as shown  . 

We denote a context-free hypergraph grammar ( cf hg ) as four tuple G = ( VN , VT , S , P ) where
VN is a finite nonterminal alphabet,
VT is a finite terminal alphabet,
SEVN is the initial nonterminal and
P is a finite set of productions e-*H where
H = ( V , E , VNO VT , incident , label ) is a hypergraph and eEE is a nonterminal edge in H  , i . e . , label(e ) EVN . 
Consider the application of a production e --* H to a graph H ~ at a no deep in H ~ with the same nonterminal label as e  . The resulting graph is obtained from H~by replacing e ~ by the graph H with e removed from it  . This involves merging of nodes . In particular , the ith node incident with e is merged with the ith node incident with e ~  . We require that all edges with the same label have the same number of incident nodes  . A derivation begins with a graph containing a single edge labelled S and no edges  . A derivation is completed when there are no nonterminal nodes in the graph  . 
The string language associated with a cf hgG is denoted STR  ( G )  . The class of languages generated by all cf hg is denoted STR  ( CFHG )  . 
Due to lack of space , rather than a complete formal definition of cf hg derivations  , we present an illustrative example . Consider the three production shown below . Note that the edge on the left-hand-side of the production is indicated with a double box  . 

Below we show the steps in a derivation of the string a abbccdd involving these productions  . Note that the set of graphs derived corresponds to the string language anbncndnIn >  0   . 
Dadabj ? ~ t
Cdab1
Cdaa ? b " ~..~?
Cdd
It is clear from their definition that cf hg satisfy the conditions for being alcfrs given earlier  . As has been observed \[3\] it is possible to represent the set of derivations of a given cf hg with a set of trees that can be generated by a contextfree grammar  . The composition operation of cf hg in which a node is replaced by a graph is clearly size-preserving since it does not involve duplication or deletion of an unbounded number of nodes or edges  . 
Additional Remarks
We end by elaborating on the relationship between lcfrs  , dtwt and cf hg in terms of the following complexity measures  . 
? The maximum of rank ( A ) nonterminals A of a gcfg . Let LCFRLk be the class of languages generated by g cfg of some lcfrs whose nonterminals have rank k or less  , i . e . , derive at most k tuples . 
? The crossing number of adtwtM . This is the maximum number of times that it visits any given subtree of an input tree  . Let OUT ( DT WTk ) be the class of languages output by dtwt whose crossing number does not exceed k  . 
? The maximum number oftentacles of the nonterminals of a cf h g  . Let STR ( CFI-IGk ) be the class of languages associated with cf hg whose nonterminals have at most k tentacles  . 
It has been shown ( Theorem 6 . 1 in\[3\]) that OUT(DTWTk ) = STR(CFHG g . k ) = STR ( CFHG2k+I ) It can be seen from the above constructions that
LCFRL k=OUT ( DT WTk ) = STR ( CFHG2k ) = STR ( CFHG2k+I ) 
References\[1\]A . V . Aho and J . D . Ullman . Translations on a contextfree grammar . Inf . Control , 19:439-475, 1971 . 
\[2\] M . Bauderon and B . Courcelle . Graph expressions and graph rewritings . Math . Syst . Theory , 20:83-127, 1987 . 
\[3\] J . Engelfriet and L . Heyker . The string generating power of contextfree hypergraph grammars  . 
J . Comput . Syst . Sci ., 43:328-360, 1991.
142\[4\]J . Engelfriet , G . Rozenburg , and G . Slutzki . Tree transducers , I systems , and two-way machines . J
Comput . Syst . Sci ., 20:150-202, 1980.
\[5\]A . Habel and H . Kreowski . Some structural aspects of hypergraph languages generated by hyperedge replacement  . In STACS , 1987 . 
\[6\]A . K . Joshi , L . S . Levy , and M . Takahashi . Tree adjunct grammars . J . Comput . Syst . Sci . , 10(1), 1975 . 
\[7\]T . Kasami , H . Seki , and M . Fujii . Generalized contextfree grammars , multiple contextfree grammars and head grammars . Technical report , Department of Information and Computer Science , Osaka University , Osaka , Japan ,  1988 . 
\[8\]C . Pollard . Generalized Phrase Structure Grammars , Head Grammars and Natural Language . 
PhD thesis , Stanford University , 1984.
\[9\]K . Vijay-Shanker , D . J . Weir , and A . K . Joshi . 
Characterizing structural descriptions produced by various grammatical formalisms  . In 25th meeting Assoc . Comput . Ling . , 1987 . 
\[10\]D . J . Weir . Characterizing Mildly Context-Sensitive Grammar Formalisms  . PhD thesis , University of Pennsylvania , Philadelphia , PA ,  1988 . 

