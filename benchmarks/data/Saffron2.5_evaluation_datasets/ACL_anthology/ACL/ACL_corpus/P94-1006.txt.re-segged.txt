INTENTIONS AND INFOR MATION IN DISCOURSE
Nicholas Asher
IRIT , Universit 4 Paul Sabatier,
118 Route de Narbonne,
31062 Toulouse , CEDEX,

asher@irit , fr
Alex Lascarides
Department of Linguistics,
Stanford University,
Stanford,
Ca 94305-2150,

alex ~ csli , stanford , edu

This paper is about the flow of inference between communicative intentions  , discourse structure and the domain during discourse processing  . We augment a theory of discourse interpretation with a theory of distinct mental attitudes and reasoning about them  , in order to provide an account of how the attitudes interact with reasoning about discourse structure  . 

The flow of inference between communicative intentions and domain information is often essential to discourse processing  . It is well reflected in this discourse from
Moore and Pollack (1992): (1) a . George Bush supports big business . 
b . He's sure tove to House Bill 1711.
There are at least three different interpretations  . Consider Context 1: in this context the interpreter I believes that the author A wants to convince him that  ( lb ) is true . For example , the context is one in which I has already uttered Bushwon'tve to any more bills  . 
I reasons that A's linguistic behavior was intentional  , and therefore that A believes that by saying ( la ) he will convince I that Bush will ve to the bill . Even if I believed nothing about the bill , he now infers it's bad for big business . So we have witnessed an inference from premises that involve the desires and beliefs of A  ( Moore and Pollack's " intentional structure " )  , as well as his linguistic behavior , to a conclusion about domain information ( Moore and Pollack's " informational structure " )  . 
Now consider Context 2: in this context I knows that A wants to convince him of  ( la )  . As in Context 1 , I may infer that the bill is bad for big business  . But now , ( lb ) is used to support ( la ) . 
Finally , consider Context 3: in this context I knows that House Bill 1711 is bad for big business , but doesn't know A's communicative desires prior to witnessing his linguistic behaviour  . From his beliefs about tile domain , he infers that supporting big business would cause Bush tove to this bill  . So , A must . have uttered ( la ) to support ( lb ) . Hence I realises that A wan~ed him to believe ( lb )  . So in contrasto Contexts 1 and 2 , we have a flow of inference from informational structure to intentional structure  . 
This story makes two main points . First , we agree with Moore and Pollack that we must represent both the intentional import and the informational import of a discourse  . As they show , this is a problem for current formulations of Rhetorical Structure Theory  ( RST )   ( Thompson and Mann ,  1987) . Second , we go further than Moore and Pollack , and argue that reasoning about beliefs and desires exploits different rules and axioms from those used to infer rhetorical relations  . 
Thus , we should represent intentional structure and discourse structure separately  . But we postulate rhetorical relations that express the discourse function of the constituents in the communicative plan of the author  , and we permit interaction between reasoning about rhetorical relations and reasoning about beliefs and desires  . 
This paper provides the first steps towards a formal analysis of the interaction between intentional structure and informational structure  . Our framework for discourse structure analysis is SDRT  ( Asher 1993 )  . The basic representational structures of that theory may be used to characterise cognitive states  . We will extend the logical engine used to infer rhetorical relations -- DiCE  ( Lascarides and Asher 1991 , 1993a , 1993b , Lascarides and Oberlander 1993 ) -- to model inferences about intentional structure and its interaction with informational structure  . 
BUSH'SREQUIREMENTS
We must represent both the intentional import and the informational import of a discourse simultaneously  . 
So we need a theory of discourse structure where discourse relations central to intentional import and to informational import can hold simultaneously between the same constituents  . A logical framework in which all those plausible relations between constituents that are consistent with each other are inferred  , such as a nonmonotonic logic like that in DICE ( Lascarides and Asher , 1993a ) , would achieve this . So conceivably , a similar nonmonotonic logic for RST might solve the problem of keeping track of the intentional and informational But this would work only if the various discourse relations about intentions and information could simultaneously hold in a consistent knowledge base  ( KB )  . Moore and Pollack ( 1992 ) show via discourse ( 2 ) that the current commitment to the nucleus -satellite distinction in 
RST precludes this.
(2) a . Let's go home by 5.
b . Then we can get to the hardware store before it closes  . 
c . That way we can finish the books helvest onight . 
From an intentional perspective , (2b ) is a satellite to (2a ) via Motivation . From an informational perspective , (2a ) is a satellite to (2b ) via Condition . These two structures are incompatible . So augmenting rtsT with a nonmonotonic logic for inferring rhetorical relations would not yield a representation of  ( 2 ) on multiple levels in which both intentional and informational relations are represented  . In SDRT , on the other hand , not all discourse relations induce subordination , and so there is more scope for different discourse relations holding simultaneously in a consistent KB  . 
Grosz and Sidner's ( 1986 ) model of discourse interpretation is one where the same discours elements are related simultaneously on the informational and intentional levels  . But using their framework to model ( 1 ) is not straightforward . As Grosz and Sidner ( 1990 ) point out : " any model ( or theory ) of the communication situation must distinguish among beliefs and intentions of different agents  , " but theirs does not . They represent intentional structure as a stack of propositions  , and different attitudes aren't distinguished . The informal analysis of ( 1 ) above demand such distinctions , however . For example , analysing ( 1 ) under Context 3 requires a representation f the following statement : since A has provided a reason why  ( lb ) is true , he must want I to believe that ( lb ) is true . It's unclear how Grosz and Sidner would represent this  . SDRT(hsher ,  1993 ) is in a good position to be integrated with a theory of cognitive states  , because it uses the same basic structures ( discourse representation structures or DRSs ) that have been used in Discourse Representation Theory  ( DRT ) to represent different attitudes like beliefs and desires  ( Kamp 1981 , Asher 1986 ,  1987 , Kamp 1991 , Asher and
Singh , 1993).
ABRIEFINTRODUCTION TO
SDRTANDDICE
In SDRT ( Asher ,  1993) , an NL text is represented by a segmented DRS ( SDRS )  , which is a pair of sets containing : the DRSS or SDRSs representing respectively sentences and text segments  , and discourse relations between them . Discourse relations , modelled after those proposed by Hobbs (1985) , Polanyi (1985) and Thompson and Mann (1987) , link together the constituents of an SDRS . We will mention three : Narration , Result and

? SDRSS have a hierarchical configuration , and SDRT predicts points of attachment in a discourse structure for new information  . Using DICE we infer from the reader's knowledge resources which discourse relation should be used to do attachment  . 
Lascarides and Asher ( 1991 ) introduce default rules representing the role of Gricean pragmatic maxims and domain knowledge in calculating the value of the update function  ( r , a , fl ) , which means " the representation fl of the current sentence is to be attached to a with a discourse relation  , where a is an open node in the representation r of the text so far "  . Defaults are represented by a conditional--?> ? means'if ?  , then normally ? . 
For example , Narration says that by default Narration relates elements in a text  . 
? Narration : ( v , c  ~ , /3) > garration(c ~ , /3 ) Associated axioms show how Narration affects the temporal order of the events described : Narration and the corresponding temporal axioms on Narration predict that normally the textual order of events matches their temporal order  . 
The logic on which DICE rests is Asher and Mor -reau's  ( 1991 ) Common sense Entailment ( CE )  . Two patterns of nonmonotonic inference are particularly relevant here  . The first is Defeasible Modus Pont Es : if one default rule has its antecedent verified  , then the consequent is nonmonotonically inferred . The second is the Penguin Principle : if there are conflicting default rules that apply  , and their antecedents are in logical entailment relations  , then the consequent of the rule with the most specific antecedent is inferred  . Lascarides and Asher ( 1991 ) use DICE to yield the discourse structures and temporal structures for simple discourses  . 
But the theory has so far ignored how A's intentional structure -- or more accurately  , I's model of A's intentional structure - -influences I ' inferences about the domain and the discourse structure  . 
ADDING INTENTIONS
To discuss intentional structure , we develop a language which can express beliefs , intentions and desires . Foblowing Bratman ( forthcoming ) and Asher and Singh ( 1993 )  , we think of the objects of attitudes either as plans or as propositions  . For example , the colloquial intention to do something -- like wash the dishes--will be expressed as an intention toward a plan  , whereas the intention that Suebe happy is an intention toward a proposition  . Plans will just consist of sequences of basic action sal  ; a2 ;   .   .   . ; an . Two operators --7~ for about to do or doing , and 7: ) for having done--will convert actions into propositions  . The attitudes we assume in our model are believes  ( BA ? means ' A believes ?' )  , wants ( WA ? means ' A wants ?') , and intends ( ZA ? means ' A intends ?') . All of this takes place in a modal , dynamic logic , where the propositional attitudes are supplied with a modal semantics  . To this we add the modal conditional operator > , upon Which the logic of DICE is Let's take a closer look at  ( 1 ) in Context 1 . Let the logical forms of the sentences ( la ) and ( lb ) be respectively a and /3 . In Context 1 , I believes that A wants to convince him of/3 and thinks that he doesn't believe already . Following the DRT analysis of attitudes , we assume I's cognitive state has embedded in it a model of A's cognitive state  , which in turn has a representation of I's cognitive state  . So ) ' VABI/3 and BA~BI/3 hold in I's KB . Furthermore , ( v ,  (~ , /3) AInfo(c ~ , /3) holds in I's KB , where Info(a , /3 ) is a gloss for the semantic content of a and / ~ that I knows about  ) I must now reason about what A intended by his particular discourse action  . I is thus presented with a classical reasoning problem about attitudes : how to derive what a person believes  , from a knowledge of what he wants and an observation of his behaviour  . The classic means of constructing such a derivation uses the practical syllogism  , a form of reasoning about action familiar since Aristotle  . It expresses the following maxim : Act so as to realize your goals ceter is paribus  . 
The practical syllogism is a rule of defeasible reasoning  , expressible in CE by means of the nonmonotonic consequence rlation ~  . The consequence rlation 0~? can be stated directly in the object language of CE by a formula which we abbreviate as ~?  , ?) ( Asher 1993) . 
We use 2_(?, ?) to state the practical syllogism . First , we define the notion that the KS and ? , but not the KB alone , nonmonotonically yield ?:* Definition : ? ) I ( KBA ? , ?)^ I(KB ,  ? ) The Practical Syllogism says that if ( a ) A wants ? but believes it's not true , and ( b ) he knows that if g , were added to his KB it would by default make ? true eventually  , then by default A intends ? . 
* The Practical Syllogism: ( a )   ( WA ( ? ) A ( b ) B A ( 3Cb ( ? , even fually ( ? ) ) ) ) >  ( c ) The Practical Syllogismenables . I to reason about A's cognitive state . In Context 1 , when substituting in the Practical Syllogism BI/3 for ? , and ( r , c  ~ , /3) AInfo(oqj3) for ? , we find that clause ( a ) of the antecedent to the Practical Syllogism is verified  . The conclusion ( c ) is also verified , because I assumes that A's discourse act was intentional  . This assumption could be expressed explicitly as a >- rule  , but we will not do so here . 
Now , abduction ( i . e . , explanatory reasoning ) as well as nonmonotonic deduction is permitted on the Practical Syllogism  . So from knowing ( a ) and ( c) , I can conclude the premise ( b ) . We can state in cE an ' abductive ' rule based on the Practical Syllogism :* The hbductive Practical Syllogism I  ( APS l )   ( / ~\] A ( ? ) A ~ A ( ~? ) A ~' A ( ? ) ) >
BA(:1 ? b(? , even Lually ( ? ) ) )   1This doesn't necessarily include that House Bill 1711 is bad for big business . 
hPsl allows us to conclude ( b ) when ( a ) and ( c ) of the Practical Syllogism hold . So , the intended action ? must be one that A believes will eventually make ? true  . 
When we make the same substitutions for ? and !/' in APS las before  , I will infer the conclusion of APS1 via Defeasible Modus Ponens : BA ( J . kb((r,0~,/3)^Info(cq/3), eventually(B1~3))) . That is , I infers that A believes that , by uttering what he did , I will come to believe/3 . 
In general , there may be a variety of alternatives that we could use to substitute for ? and ? in APS l  , in a given situation . For usually , there are choices on what can be abduced . The problem of choice is one that Hobbse ~ hi . (1990) address by a complex weighting mechanism . We could adopt this approacher e . 
The Practical Syllogism and APS 1 differ in two important ways from the DICE axioms concerning discourse relations  . First ,   APS1 is motivated by an abductive line of reasoning on a pattern of defeasible reasoning involving cognitive states  . The DICE axioms are not . 
Secondly , both the Practical Syllogism and hPsl don't include the discourse update function  ( r , c  ~ , /3 ) together with some information about the semantic ontent of a  and/3 in the antecedent , while this is a standard feature of the DICE axioms for inferring discourse structure  . 
These two differences distinguish reasoning about intentional structures and discourse structures  . But discourse structure is linked to intentional structure in the following way  . The above reasoning with A's cognitive state has led I to conclusions about the discourse function of ~  . Intuitively , a was uttered to support/3 , or a ' intentionally supports '/3 . This idea of intentional support is defined in DICE as follows : * Intends to Support : I support  ( c  ~ , fl ) ~-* ( WA(B , ~3) ABA (-~13 , ~) ABA(~bh((r ,  ~ , /3)hInfo(~ , /3) , even * ually(B1/3))) In words , a intentionally supports \]3 if and only if A wants I to believe /3 and doesn't think he does so already , and he also believes that by uttering a and /3 together , so that I is forced to reason about how they should be attached with a rhetorical relation  , I will come to believe/3 . 
Isupport(a , /3 ) defines a relationship between a and/3 at the discourse structural level , in terms of I's and A's cognitive states . With it we infer further information about the particular discourse relation that I should use to attach  /3 to c ~ . I support ( ot , /3 ) provides the link between reasoning about cognitive states and reasoning about discourse structure  . 
Let us now return to the interpretation of ( 1 ) under Context 1 . I concludes I support ( o ~ , /3) , because the right hand side of the *-*- condition in Intends to Support is satisfied  . So I passes from a problem of reasoning about A's intentional structure to one of reasoning about discourse structure  . Now , I should check to see whether o " actually does lead him to  believe/3  . This is a check on the coherence of discourse ; in order for an SDRS r to constituents must be satisfiable  . 2 Here , this amounts to justifying A's belief that given the discourse context and I's background beliefs of which A is aware  , I will arrive at the desired conclusion -- that he believes ft  . So , I must be able to infer a particular discourse relation R between a and fl that has what we will call the Belief Property :  ( BinAR ( a , fl )) >/ ~1fl . That is , R must be a relation that would indeed license I 's concluding fl from a  . 
We concentrate here for illustrative purposes on two discourse relations with the Belief Property : Result  ( a , fl ) and Evidence(a , fl ); or in other words , a results in f l , or a is evidence for f t . 
* Relations with the Belief Property : ( B , c ~ A Evidence ( a , fl )) > ~ . ~I ~ ( t3 1a ^ Result(a , fl ) ) > & fl The following axiom of Cooperation captures the above reasoning on I's part : if a I supports f l  , then it must be possible to infer from the semantic content  , that either Result ( a , fl ) or Evidence ( a , fl ) hold : ? Cooperation : (: l & . b((r , a , fl)A\[nfo(a , fl ) , Resull ( a , f l )) V ~ b((r , a , fl ) AInfo(a , fl ) , Evidence ( a , fl ) ) ) The intentional structure of A that I has inferred has restricted the candidate set of discourse relations that I can use to attach fl to a : he must use Result or Evidence  , or both . If I can't accommodate A's intentions by doing this  , then the discourse will be incoherent . 
We ' ll shortly show how Cooperation contributes to the explanation of why  ( 3 ) is incoherent . 
(3) a . George Bush is a weak-willed president.
b . ? He's sure tove to House Bill 1711.
FROMINTENTIONSTO

CONTEXTS 1AND 2
The axioms above allow I to use his knowledge of A 's cognitive state  , and the behaviour of At hathe observes , to ( a ) infer information about A's communicative intentions  , and ( b ) consequently to restrict the set of candidate discourse relations that are permitted between the constituents  . According to Cooperation , I must infer that one of the permitted discourse relations does indeed hold  . When clue words are lacking , the semantic content of the constituents must be exploited  . In certain cases , it's also necessary to infer further information that was n't explicitly mentioned in the discourse  , 2 Asher ( 1993 ) discusses this point in relation to Contrast : the discourse marker but is used coherently only if the semantic ontent of the constituents it connects do indeed form a contrast : compare Mary ' shair is black but here yes are blue  , with ? Mary's hair is black but John's hairi . ~ black . 
in order to sanction the discourse relation . For example , in (1) in Contexts 1 and 2 , I infers the bill is bad for big business . 
Consider again discourse (1) in Context 1 . Intuitively , the reason we can infer Result ( a , fl ) in the analysis of ( 1 ) is because ( i ) a entails a generic ( Bushvetoes bills that are bad for big business )  , and ( ii ) this generic makes fl true , as long as we assume that House Bill 1711 is bad for big business . 
To define the Result Rule below that captures this reasoning for discourse attachment  , we first define this generic-instancer lationship : instance  ( e ,  ? ) holds just in case ? is ( Vx ) (A ( x ) > B ( x ) ) and ? is A\[x/a~AB\[x/a~ . 
For example , bird ( tweety ) Afly ( tweety )   ( Tweety is a bird and Tweety flies ) is an instance of Vx ( bird ( x ) > fly ( x ) )  ( Birdsfly )  . 
The Result Rule says that if ( a ) fl is to be attached to a , and a was intended to support fl , and ( b ) a entails a generic , of which fland 6 form an instance , and ( c ) 6 is consistent with what A and I believe , 3 then normally , 6 and Result ( a , fl ) are inferred . 
? The Result Rule : ( a ) (( r , a , fl ) AI support ( a , fl ) A(b)~b^T ( a , ?)^~ b ^~^ ~( fl , ?)^ instance ( e , ?)^( c ) co , sistent ( KBiU ~ BAU6)) > ( Res . tt(a , fl ) ^6) The Result Rule does two things . First , it allows us to infer one discourse relation ( Result ) from those permitted by Cooperation . Second , it allows us to infer a new piece of information 6  , in virtue of which Result ( a , fl ) is true . 
We might want further constraints on 6 than that in ( c )  ; we might add that 6 shouldn't violate expectations generated by the text  . But note that the Result Rule doesn't choose between different tfs that verify clauses  ( b ) and ( c )  . As we've mentioned , the theory needs to be extended to deal with the problem of choice  , and it may be necessary to adopt strategies for choosing among alternatives  , which take factors other than logical structure into account  . 
We have a similar rule for inferring Evidence ( fl , a ) (" fl is evidence for a ") . The Evidence rule resembles the Result Rule , except that the textual order of the discourse constituents  , and the direction of intentional support changes :* The Evidence Rule:  ( a )   ( if , a , fl ) ^ Isuppo~t(fl , a ) ^( b ) ~ , b ^ , ( a , ?)^~ b ^~^ ~( ~ , ~)^ instance ( e , ~)^( c ) consistent ( Ks ~ UKSAU6))>(E , idence(Z , a )  ^ 6 ) We have seen that clause ( a ) of the Result Rule is satisfied in the analysis of  ( 1 ) in Context 1 . Now , let 6 be the proposition that the House Bill 1711 is bad for big 3Or   , more accurately , ~ i must be consistent with what I himself believes  , and what he believes that A believes . In other words , KBA is I '$ model of A's KB . 
37 business ( written as bad (1711)) . This is consistent with KBIUKBA , and so clause ( c ) is satisfied . Clause(b ) is also satisfied , because ( i ) a entails Bush vetoes bills that are bad for big business--i  . e . , : l~B^r(a , ?) holds , where ? is Vx((bill(x)A bad(z )) > veto(bush , x )); ( it ) fl ^/ i is bill (1711) Aveto ( bush , 1711) Abad(1711); and so(iii ) instance(? , flA/i ) and IKB^T^~(fl , flA6) both hold . 
So , when interpreting (1) in Context 1 , two rules apply : Narration and the Result Rule . But the consequent of Narration already conflicts with what is known  ; that the discourse relation between a and fl must satisfy the Belief Property  . So the consequent of the Result Rule is inferred :/ i  ( i . e . , House Bill 1711 is bad for big business ) and Result ( a , fl ) . 4 These rules show how ( 1 ) can make the knowledge that the house bill is bad for big businessmoot  . ; one does not need to know that the house bill is bad for big business prior to attempting discourse attachment  . 
One can inferit at the time when discourse attachment is attempted  . 
Now suppose that we start from different premises , as provided by Context2: BABIfl , BA~BI a and )/ VABI a . 
That is , I thinks A believes that I believes Bush will ve to the bill  , and I also thinks that A wants to convince him that Bush supports big business  . Then the ' intentional ' line of reasoning yields different results from the same observed behaviour -- A's utterance of  ( 1 )  . Using APS laga in , but substituting Bia for ? instead of B1fl , I concludes BA(I-kb((r , a , f l ) AI fo(a , fl ) , evet any(Ba )) . SoIsvVot(fl , a ) holds . 
Now the antecedent to Cooperation is verified , and so in the monotoni component of cE , we infer that a and fl must be connected by a discourse relation R ' such that  ( B1flAR ' ( a , fl )) > Bla . As before , tiffs restricts the set of permitted discourse relations for attaching / ? to a  . But unlike before , the textual order of a and fl , and their direction of intentional support mismatch  . 
The rule that applies this time is the Evidence Rule  . 
Consequently , a different discourse relation is inferred , although the same information/i--that House Bill  1711 is bad for big business--supports the discourse relation  , and is also be inferred . 
In contrast , the antecedents of the Result and Evidence Rules aren't verified in  ( 3 )  . Assuming I knows about the legislative process , he knows that if George Bush is a weak willed president  , then normally , he won'tve to bills . Consequently , there is no / i that is consistent with his KB , and sanctions the Evidence or Resull relation . Since I cannot infer which of the permitted discourse relations holds  , and so by contraposing the axiom Cooperation , a doesn't I support ft . And so I has failed to conclude what A intended by his discourse action  . It can no longer be a belief that it will eventually  4We could have a similar rule to the Result Rule for inferring Evidence  ( a , fl ) in this discourse contextoo . 
S Given the new KB , the antecedent of APSl would no longer be verified if we substituted ? with Blfl  . 
lead to I believing fl , because otherwise I support ( a , fl ) would be true via the rule Intends To Support . Consequently , I cannot infer what discourse relation to use in attachment  , yielding incoherence . 
FROMINFOR MATION TO

CONTEXT3
Consider the interpretation of ( 1 ) in Context 3: I has no knowledge of A's communicative intentions prior to witnessing his linguistic behaviour  , but he does know that the House Bill 1711 is bad for big business . I has sufficient information about the semantic ontent of a and fl to infer Result  ( a , fl ) , via a rule given in Lascarides and Asher ( 1991 ) : ? Result ( if , a , fl ) ^ fl )) > ResetS(a , fl ) Resull(a , fl ) has the Belief Property , and I reasons that from believing a , he will now come to believeft . Having used the information structure to infer discourse structure  , I must now come to some conclusions about A's cognitive state  . 
Now suppose that BABI a is in I's KS . Then the following principle of Charity allows I to assume that A was aware that I would come to believe fl too  , through doing the discourse attachment he did : ? Charity : BI ? > BABI ? This is because I has inferred Result  ( a , fl ) , and since Result has the belief property , I will come to believe fl through believing a ; so substituting fl for ? in Charity ,   BAI3Ifl will become part of I's KB via Defeasible Modus Ponens  . So , the following is now part of I'sKB : BA ( \[-kb ( ( V , a , fl ) ^ Info(a , f l )) , eventually ( Blfl )) . Furthermore , the assumption that A's discourse behaviour was intentional again yields the following as part of I'sKm  7A  ( ( V , a , fl ) AInfo(a , f l )) . So , substituting BIfl and ( r , a , fl ) AInfo(a , fl ) respectively for ? and ? into the Practical Syllogism  , we find that clause ( b ) of the premises , and the conclusion are verified . Explanatory reasoning on the Practical Syllogism this time permits us to infer clause  ( a ) : A's communicative goals were to convince I of fl  , as required . 
The inferential mechanisms going from discourse structure to intentional structure are much less well understood  . One needs to be able to make some suppositions about the beliefs of A before one can infer anything about his desires to communicate  , and this requires a general theory of common sense belief attribution on tile basis of beliefs that one has  . 
IMPERATIVE SAND
PLANUPDATES
The revision of intentional structures exploits modes of speech other than the assertoric  . For instance , consider another discourse from Moore and Pollack  ( 1992 ) : b . Then we can get to the hardware store before it closes  . 
c . That way we can finish the books helvest onight . 
Here , one exploits how the imperative mode affects reasoning about intentions  . Since reOrdering captures the intuition that if A orders a  , then normally he wants a to be true ; and Wanting and Doing captures the intuition that if A wants a to be true  , and doesn'think that it's impossible to bring a about  , then by defaul the intends to ensure that c~is brought about  , either by doing it himself , or getting someone lse to do it ( cf . 
Cohen and Levesque , 1990a).
* Since reOrdering :> ? Wanting and Doing: ( ~ VA ~ A ~ BA ~ eventually ( 7~ ) ) > ZA ( ~ ) These rules about A's intentional structure help us analyse  ( 2 )  . Let the logical forms of ( 2a-c ) be respectively or ,   /3 and 7- Suppose that we have inferred by the linguistic clues that Result  ( o~ , 13) holds . That is , the action a(i . e . , going home by 5 pro ), results in /3 ( i . e . , the ability to go to the hardware store before it closes  )  . Since ( ~ is an imperative , Defeasible Modus Po-nens on Since reOrdering yields the inference that  ) /VAc ~ is true . Now let us assume that the interpreter I believes that the author A doesn't believe that c~'s being brought about is impossible  . Then we may use Defea-sible Modus Ponens again on Wanting and Doing  , to infer ZA ( Tia ) . Just how the interpreter comes to the belief , that the author believes c ~ is possible , is a complex matter . More than likely , we would have to encode within the extension of DiCE we have made  , principles that are familiar from autoepistemic reasoning  . We will postpone this exercise , however , for another time . 
Now , to connect intentions and plans with discourse structure  , we propose a rule that takes an author's use of a particular discourse structure to be prima facie evidence that the author has a particular intention  . The rule Plan Apprehension below , states that if ~ is a plan that A intends to do , or get someone lse to do , and he states that 6 is possible as a Result of this action c ~ , then the interpreter may normally take the author A to imply that he intends  6 as well . 
? Plan Apprehension : ( nesult ( ~ , t3) AZA(~)A/3=can (6)) > ZA(r-(~ ; 6)) We call this rule Plan Apprehension , to make clear that it furnishes one way for the interpreter of a verbal message  , to form an idea of the author's intentions , on the basis of that message's discourse structure  . 
Plan Apprehension uses discourse structure to attribute complex plans to A  . And when attaching/3 to ~ , having inferred Result ( a ,  13) , this rule's antecedent is verified , and so we infer that 6--which in this case is to go to the hardware store before it closes -- as part of A's plan  , which he intends to bring about , either himself , or by getting another agent to do it . 
Now , we process 7- That way in 3' invokes an anaphoric reference to a complex plan . By the accessibility constraints in SDRT , its antecedent must\[a ; 6\] , because this is the only plan in the accessible discourse context  . So 7 must be the DKS below : as a result of doing this plan  , finishing the books helves ( which we have labelle de ) is possible: ( 7 ) Result ( \[ a ; Now , substituting \[ c ~ ; ~\] and efora and fl into the Plan Apprehension Rule  , we find that the antecedent to this rule is verified again  , and so its consequent is non-monotonically inferred : Za  ( T~ ( a ;  6 ; e )) . Again , I has used discourse structure to attribute plans to A  . 
Moore and Pollack ( 1992 ) also discuss one of I's possible responses to ( 2 ) :  ( 4 ) We don't need to go to the hardware store . 
Ibor rowed a saw from Jane.
Why does I respond with ( 4 ) ? I has inferred the existence of the plan\[~r ;  6 ; elvia Plan Apprehension ; so he takes the overall goal of A to be e ( to finish the book-shelves this evening )  . Intuitively , he fills in A's plan with the reason why going to the hardware store is a subgoal : I needs a saw  . SoA's plan is augmented with another subgoal ~ , where ~ is to buy a saw , as follows : Za (7 ~ . \[ c ~; 6; ~; e\]) . But since ~ holds , he says this and assumes that this means that A does not have to do c ~ and  6 to achieve ~ . To think about this formally , we need to not only reason about intentions but also how agents update their intentions or revise them when presented with new information  . Asher and Koons ( 1993 ) argue that the following schema captures part of the logic which underlies updating intentions : ? Vpdate Za  ( n\[al ;  . . . ; Z )( al ; .   .   . ; aS ) In other words , if you're updating your intentions to do actions alto ~  ,   , and altocU are already done , then the new intentions are to doot j+t to an , and you no longer intend to do alto aj . 
The question is now : how does this interact with discourse structure ? I is attempting to be helpful to A  ; he is trying to help realize A's goal . We need axioms to model this . Some key tools for doing this have been developed in the past couple of decades -- belief revision  , intention and plan revision -- and the long term aim would be to enable form M theories of discourse structure to interact with these formal theories of attitudes and attitude revision  . But since a clear understanding of how intentions are revised is yet to emerge  , any speculation on the revision of intentions in a particular discourse context seems premature  . 

CONCLUSIONSAND
FURTHER WORK
We have argued that it is important to separate reasoning about mental states from reasoning about discourse structure  , and we have suggested how to integrate a formal theory of discourse attachment with common sense reasoning about the discourse participants ' cognitive states and actions  . 
We exploited a classic principle of common sense reasoning about action  , the Practical Syllogism , to model I's inferences about A's cognitive state during discourse processing  . We also showed how axioms could be defined , so as to enable information to mediate between the domain  , discourse structure and communicative intentions . 
Reasoning about intentional structure took a different form from reasoning about discourse attachment  , in that explanatory reasoning or abduction was permitted for the former but not the latter  ( but cf . Hobbs et al 1990) . This , we argued , was a principled reason for maintaining separate representations of intentional structure and discourse structure  , but preserving close links between them via axioms like Cooperation  . Cooperation enabled I to use A's communicative intentions to reason about discourse relations  . 
This paper provides an analysis of only very simple discourses  , and we realise that although we have introduced distinctions among the attitudes  , which we have exploite during discourse processing  , this is only a small part of the story . 
Though DICE has used domain specific information to infer discourse relations  , the rules relate domain structure to discourse structure in at best an indirect way  . Implicitly , the use of the discourse update fimction ( v , c  ~ ,  ~ ) in the DICE rules reflects the intuitively obvious fact that domain information is filtered through the cognitive state of A  . To make this explicit , the discourse community should integrate work on speech acts and attitudes  ( Perrault 1990 , Cohen and Levesque 1990 a , 1990b ) with theories of discourse structure . In future work , we will investigate discourses where other axioms linking the different attitudes and discourse structure are important  . 

Asher , Nicholas ( 1986 ) Belief in Discourse Representation Theory , Journal of Philosophical Logic ,  15 ,  127-189 . 
Asher , Nicholas (1987) A Typology for Attitude Verbs , Linguistics and Philosophy ,  10 , pp 125-197 . 
Asher , Nicholas ( 1993 ) Reference to Abstract Objects in Discourse , Kluwer Academic Publishers , Dordrecht , 

Asher , Nicholas and Koons , Robert ( 1993 ) The Revision of Beliefs and Intentions in a Changing World  , in Precedings of the hal Spring Symposium Series : Reasoning about Mental States : Formal Theories and Applications  . 
Asher , Nicholas and Morreau , Michael ( 1991 ) Common Sense Entailment : A Modal Theory of Nonmono-tonic Reasoning  , in Proceedings to the 12th International Joint Conference on Artificial Intelligence  , Sydney Australia , August 1991 . 
Asher , Nicholas and Singh , Munindar ( 1993 ) A Logic of Intentions and Beliefs , Journal of Philosophical
Logic , 225, pp 513-544.
Bratman , Michael ( forthcoming ) Intentions , Plans and Practical Reason , Harvard University Press , Cambridge , Mass . 
Cohen , Phillip R . and Levesque , Hector J . (1990a ) Persistence , Intention , and Commitment , In Philip R . 
Cohen , Jerry Morgan and Martha E . Pollack ( editors ) Intentions in Communication , pp 33-69 . Cambridge,
Massachusetts : Bradford/MIT Press.
Cohen , Phillip R . and Levesque , Hector J .   ( 1990b ) Rational Interaction and the Basis for Communication  , In Philip R . Cohen , Jerry Morgan and Martha E . 
Pollack ( editors ) Intentions in Communication , pp 221-256 . Cambridge , Massachusetts : Bradford/MIT Press . 
Grosz , Barbara J . and Sidner , Candice L . (1986) Attention , Intentions and the Structure of Discourse . 
Computational Linguistics , 12, 175-204.
Grosz , Barbara J . and Sidner , Candice L . (1990) Plans for Discourse . In Philip R . Cohen , Jerry Morgan and Martha E . Pollack ( editors ) Intentions in Communication , pp 417-444 . Cambridge , Massachusetts :
Bradford/MIT Press.
Hobbs , Jerry R .   ( 1985 ) On the Coherence and Structure of Discourse . Report No : CSLI-85-37 , Center for the Study of Language and Information , October 1985 . 
Kamp , tlans ( 1981 ) A Theory of Truth and Semantic Representation , i Groenen dijk , J . A . G . , Janssen , T . 
M . V . , and Stokhof , M . B . J . ( eds . ) Formal Methods in the Study of Language ,  277-332 . 
Kamp , Hans ( 1991 ) Procedural and Cognitive Aspects of Propositional Attitude Contexts  , Lecture Notes from the Third European Summer School in Language  , Logic and Information , Saarbriicken , Germany . 
Lascarides , Alex and Asher , Nicholas ( 1991 ) Discourse Relations and Defeasible Knowledge , in Proceedings of the ? o9th Annual Meeting of Computational Linguistics ,  55-63 , Berkeley California , USA , June 1991 . 
Lascarides , Alex and Asher , Nicholas (1993a ) Temporal Interpretation , Discourse Relations and Common sense Entailment , in Linguistics and Philosophy ,  16 , pp 437-493 . 
Lascarides , Alex and Asher , Nicholas ( 1993b ) A Semantics and Pragmatics for the Pluperfect , in Proceedings of the European Chapter of the Association for Computational Linguistics  ( EACL93 )  , pp 250-259 , 
Utrecht , The Netherlands.
Lascarides , Alex , Asher , Nicholas and Oberlander , Jon ( 1992 ) Inferring Discourse Relations in Context , in Proceedings of the 30th Annual Meeting of the Asso-
USA , June 1992.
Lascarides , Alex and Oberlander , Jon ( 1993 ) Temporal Connectives in a Discourse Context , in Proceedings of the European Chapter of the Association for Computational Linguistics  ( EACL93 )  , pp 260-268 , Utrecht , 
The Netherlands.
Moore , Johanna and Pollack , Martha ( 1992 ) A Problem for RST : The Need for Multi-Level Discourse Analysis Computational Linguistics  ,  18 4 , pp 537-544 . 
Perrault , C . Ray ( 1990 ) An Application of Default Logic to Speech Act Theory  , in Philip R . Cohen , Jerry Morgan and Martha E . Pollack ( editors ) h~ten-tions in Communication , pp 161-185 . Cambridge , Massachusetts : Bradford/MIT Press . 
Polanyi , Livia ( 1985 ) A Theory of Discourse Structure and Discourse Coherence  , in Eil for , W . It . , Kroe-bet , P . D . , and Peterson , K . L . , ( eds ) , Papers from the General Session at he Twenty -First Regional Meeting of the Chicago Linguistics Society  , Chicago , April 2527 ,  1985 . 
Thompson , Sandra and Mann , William ( 1987 ) Rhetorical Structure Theory : A Framework for the Analysis of Texts  . In IPRA Papers in Pragrnatics , 1, 79-105 . 

