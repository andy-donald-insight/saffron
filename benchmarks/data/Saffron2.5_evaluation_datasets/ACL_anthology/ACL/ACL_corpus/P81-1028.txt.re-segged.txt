PROBLEM SINLOGICAL FORM
Robert C . Moore
SRI International , Menlo Park , CA 94025
IINTRODUCTION
Decomposition of the problem of " language understanding " into manageable subproblems has always posed a major challenge to the deve lopment theories of  , and systems for , natural-language processing . More or less distinct components are conventionally proposed for handling syntax  , semantics , pragmatics , and inference . 
While disagreement exists as to what phenomena properly belong in each area  , and how much or what kinds of interaction there are among these components  , there is fairly widespread concurrence as to the overall organization of linguistic processing  . 
Central to this approach is the idea that the processing of an utterance involves producing an expression or structure that is in some sense a representation of the literal meaning of the utterance  . 
It is often maintained that understanding what an utterance literally means consists in being able to recover this representation  . In philosophy and linguistics this sort of representation is usually said to display the ~form of an utterance  , so we will refer ( somewhat loosely-~--to the representations themselves as " logical forms  , " This paper surveys what we at SRI vie was some of the key problems encountered in defining a system of representation for the logical forms of English sentences  , and suggests possible approaches to their solution  . We will first look at some general issues related to the notion of logical form  , and then discuss a number of problems associated with the way information involving certain key concepts is expressed in English  . 
Although our main concern here is with theoretical issues rather than with system performance  , this paper is not merely speculative . The DIALOGIC system currently under development in the SKI Artificial Intelligence Center parses English sentences and translates them into logical forms embodying many of the ideas presented here  . 
IITHENATUREOFLOGICALFORM pieces of the logical form of the utterance that constitute referring expressions  . Having logical forms be semantically compositional is the ultimate expression of this kind of decomposability  , as it render sev , ery wellformed subexpression alocus of mean lng- - and therefore a potential locus of meanlng -dependent processing  . This is probably a more telling argument for semantic composlt lonality in designing language processing systems than in analyzing human language  , but it can be reasonably argued that such design principles must be followed by any system  , whether natural or artificial , that has to adapt to a complex environment ( see\[Simon ,  1969\] , especially Chapter 4) . ILogical form , therefore , is proposed as a level of representation distinct from surface-syntact lcform  , because there is apparently no direct way to semantically interpret natural language sentences in a compositional fashion  . Some linguists and philosophers have challenged this assumption \[ Montague  , 1974 a \]\[ Barwlse and Cooper ,  1981\] , but the complexity of their proposed systems and the limited range of syntactic forms they consider leaveserlous doubt that the logical -form level can be completely by passed  . 2 Beyond being co ~ positiouel , it is desirable -- though perhaps not essent ial--that the meaning of a logical form also be independent of the context in which the associated utterance occurs  .   ( The meaning of an expression in natural language , of course , is often context-dependent . ) A languageprocessing system must eventually produce a context-independent representation of what the speaker means by an utterance because the content of the utterance will normally be subjected to further process lnE after the original context has been lost  . In the many cases in which the speaker's intended meaning is simply the literal meaning  , a context-independent logical form would give us the representation we need  . There is little doubt that some representation of this sort is required  . For example , much of our general knowledge of the world is derived from simple assertions of fact in natural language  , but our situation would be hopeless if , for every fact we knew , we had to remember the context in which it was obtained before we could use it appropriately  . Imagine trying to decide what to do with a tax refund by having to recall whether the topic of conversation was rivers or financial institutions the first time one heard that banks were good places in which to keep money  . 
The first question to ask is , why even have a level of logical form ? After all  , sentences of natural languages are themselves conveyers of meaning  ; that is what natural languages are for . The reason for having logical foznns is to present the literal meanings of sentences more perspicuously than do the sentences themselves  . It is sometimes said that natural language sentences do not ' ~ eartheir meanings on their sleeves "  ; logical forms are intended to do exactly that . 
From this perspective , the main desideratum for a system of logical form is that its semantics be compositional  . That is , the meaning of a complex expression should depend only on the meaning of its subexpress lons  . This is needed for mean lnE-dependent cou ~ utational processes to cope with logical forms of arbitrary complexity  . If there is to be any hope of maintaining an intellectual grasp of what these processes are doing  , they must be decomposable into smaller and smaller meanlng-dependent subprocesses operating on smaller and smaller meaningful pieces of a logical form  . For instance , if identifying the entities referred to by an utterance is a subprocess of inferring the speaker's intentions  , there must be identifiable As this example suggests  , context independence is closely related to the resolution of ambiguity  . For any given ambiguity , it is possible to find a case in which the information needed tO resolve it is derived from the context of an utterance  . Therefore , if the mean lnEs of logical forms are to be context-lndependent  , the system of logical forms must provide distinct  , unambiguous representations for all possible readings of an ambiguous utterance  . The question remains whether logical form should also provide ambiguous representations to handle cases in which the dlsamblguatlng information is obtained later or is simply general world knowledge  . The pros and cons of such an approach are far from clear  , so we will generally assume only unemb IEuous logical forms  . 
Although it is sometimes assumed that a context -independent representation of the literal meaning of a sentence can be derived by using syntact i c and semantic knowledge only  , some pragmatic factors must also be taken into account  . To take a concrete example , suppose the request " Please llst the Nobel Prize winners in physics  , " is followed by the question ' ~ dho are the Americans ? " The phrase " the Americans " in the second utterance should almost certainly be interpreted as physics  , rather than all inhabitants or citizens of the United States  , as It might be understood in isolation . 
If the logical form of the utterance is to reflect the intended interpretation  , processes that are normally assigned to praSmatl cs must be used to derive it  . 
One could attempt to avoid thls consequence by representing " the Americans " at the level of logical form as literally meaning all Americans  , and have later pragmatic processing restrict the interpretation coAmeri can winners of the Nobel Prize in physics  . There are other cases , however , for which thls sort of move is not available . Consider more carefully the adjective " American  . " American people could be either in habi tants or citizens of the United States  ; American cars could be either manufactured or driven in the United States  ; American food could be food produced or consumed in or prepared in a style in d igenous Cothe United States  . In short , the meaning of " American " seems to be no more than " bearing some contextually determined relation to the United States  . " Thus , there is n~odefl nltecontext-independent mesnlng for sentences containing modifier sllke " American  . " The same is true for many uses of " have , "" of , " possessives , locative prepositions \[ Herskovits , 1980\] and compound nominals . The only way to hold fast to the position that the construction of logl cal-form precedes all pragmatic processing seems to be to put in " dummy '* symbols for the unknown relations : This m@y in fact be very useful in building an actual system  , ~ but It is hard to imagine that such a level of representation would bear much theoretical weight  . 
We will chum assume that a theoretically interes ting level of logical form will have resolved contextually dependent definite re ferences  , as well as the ocher " local " pragmatic ln determinacies mentioned  . 
An important consequence of this view is that sentences per se do not have logical fo rms ~ only sentences in context ~  . ~-~ f we speak loosely of the logical formo fa sentence  , this is how It should be interpreted . 
If we got hlsfar , why not say that all pragma Clc processing Cakes place before the logical form is constructed ? That is  , why make any distinction at all between what the speaker intends the hearer to infer from an utterance and what the utterance literally means ? There are two answers coth is  . The first is that , while the pragmatic factors we have in t roduced into the derivation of logical fo rms of a rare rather narrowly circums cr ibed  ( e . g . , resolving definitely determined noun phrases ) , the inference of speaker intentions is completely open-ended  . The problem confronting the hearer is to answer the question  , ' Why would the speaker say that in this situation ? " Practically any relevant knowledge chat the speaker and hearer mutually possess\[ Clark and Marshall  , 1981\]\[Cohen and Perrault ,   1981\] may be brought to bear in answering thlsquest ion  . Proma purely ~ echodologica ! standpoint , then , one would hope to define some more restricted notion of meaning as an intermediate step in deve loping the broader theory  . 
Even putting aside this methodological concern  , it seems doubtful chata theory of intended meaning can be co~trucCed without a concomitant thaor ? of literal meaning  , because the latter notion appears to play an explanatory role in the former theory  . Specifically , the literal meaning of an utterance is one of chose things from which hearers infer speakers " intentions  . 
For instance , in the appropriate context , " I'm getting cold " could be a request to close a window  . The only way for the hearer to understand thi s as a request  , however , is to recover the literal content of the utterance  , i . e . , that the speaker is getting cold , and to infer from this chat the speaker would llke him codo something about It  . 
In summary , the notion of logical form we wish to capture is essentially that of a representation of the " literal meaning in context " of an utterance  . To facilitate further processing , it is virtually essential that the meaning of Iogl cal-form expressions be compositional and  , at the same time , it is highly desirable that they be conCext -ln dependenc  . The latter condition requires that a system of logical form furnish distinct representations for the dlfferenc readings of ambiguous natural language expressions  . It also requires chat some limited amount of prag ~ atlc processing be involved in produc ing those representations  . Finally , we note that not all pragmatic factors in the use of language can be reflected in the logical form of an utterance  , because some of those factors are dependent on information that the logical form itself prov ides  . 
IIIFORMAND CONTENTINK NOWLED GEP . EP&ESENTJtTION Developing a theory of the loglcal form of English sentences is as much an exercise in knowledge representation as in linguistics  , butic differs from most work in arclfi clal intelligence on knowledge representation in one key respect  . Knowledge representation schemes are usually intended by their designers to be as general as possible and to avoid com ~ aitment to any particular concepts  . The essential problem for a theory of logical form  , however , is core present specific concepts chat natural languages have special features for expressing information about  . 
Concepts that fall in chlscategory include :* Events  , actions , and procesmes * Time and space * Collective entities and substances * Propositional attitudes and modalltles  . 
A theory of logical form of natural language expressions  , therefore , is primarily concerned with the content ra ther than the form of representation  . Logic , semantic networks , frames , scripts , and production systems are all different forms of representation  . But to say merely that one has adopted one of these forms is to say nothing about content  , i . e . , what is represented . 
The representation used in this paper , of course , takes a particular form ( higher-order logic with intensional operators  ) but relatively little will be said about developing or refining chatform  . Rather , we will be concerned with the question of what particular predicates  , functions , operators , and the like are needed to represent the content of English expressions involving concepts in the are as listed above  . This project might thus be better described as knowledge encodln  6 to distinguish It from knowledge representation , as it is usually understood in arclflcial intelligence  . 
IVAFRAME WORK FOR LOGICAL FORM
As mentioned previously , the basic fr-me work we will use to represent the logical form of English sentences is higher-order logic  ( i . d .   , higher-order predicate calculus ) , augmented by intensional operators . 
At a purely notational level , all well-formed expressions will be in " Cambridge Polish " form  , as in the programming language LZSP ; thus , the logical form of " John likes Mary " wi ll be simply  ( LIKE JOHN MARY )  . 
Despite our firm belief in the principle of semantic compositional t  t7   , we will not attempt cogive a formal semantics for the logical forms we propose  . Hence , our
I 18 ? adherence Co that principle is a good-falth intention rather than a demsn strated fact  . It should be noted , though , that virtually all the kinds of lo~t cal constructs used here are drawn from more formal work of logicians and philosophers in which r igorous semantic treatments are provided  . 
The only place in which our logical language differs sigulfl can cly from more familiar syscezs is In the treatment of quantiflers  . Normally the English determiners " every " and " some " are translated as logical quantlfiers that bind a single variable in an arbitrary formula  . This requires using an appropriate logical connective cocombine the contents of the noun phrase governed by the determiner with the contents of the rest of the sentence  . Thus ' ~ very Pisq " becomes ( EVERY X ( IMPLIES ( PX )   ( qX ) ) )  , and " Some P is Q '* becomes ( SOMEX ( AND ( eX )   ( qX ) ) ) It seems somewhat in elegant to have to used i fferent connectives to Join  ( PX ) and ( ~ X ) in the two cases , but semantically it works . 
In an extremely interesting paper , Barwise and Cooper\[1981\] point out ( and , in fact , prove ) that there are : any determiners in English fo r which this approach does not work  . The transformations employed in standard log ic coh and le " every " and " some " depend on the fact that any statement about every P or some P is logically equivalent to as ta tement about everything or something  ; for example , "Some P is Q " is equivalent to " Something is P and Q  . " What Barwlse and Cooper show is that there is no such transformation for determiners like " msst " or " more than half  . " That iS , statements about most P's or more than half the P's cannot be rephrased as statements about most things or more than half of all th ings  . 
Barvise and Cooper incorporate this insight in to a rather elaborate system modeled after Montague's  , so that , among other things , they can assign a denotation to arbitrary noun phrases out of context  . Adopting a more conservative modification of standard logical notation  , we will simply insist that all quanti fied formulas have an additional element expressing the restriction of the quantifier  . ' ~ ost P's are Q " will thus be represented by ( HOSTX ( FX )   ( qX ) ) . 
Following thls convention gives us a uniform t reatment for determined noun phrases : " Most menare mortal " " Some manis mortal " " Every manIsmortal " " The mani Smortal "" Threemen a remortal " 
Note that we treat ( MOST X ( 4 X )   ( MORTAL X ) )  ( SOMEX ( MANX )   ( MORTAL X ) )  ( EVERY X ( MANX )   ( MORTAL X ) )  ( THEX ( MANX )   ( MORTAL X ) )  ( 3x ( HA . X ) ( MORTJU . X )) " the " as a quantifier , on a parwlth " some " and " every . " " The " is often treated formally as an operator chat produces a complex singular term  , but thls has the disadvantage of not indicating clearly the scope of the expression  . 
A final point about our basic framework Is that most common nouns will be interpreted as relations rather than functions in logical form  . That is , even If we know that a person has only one height  , we will represent " John's height is 6feet " as ( HEIGE'?JOHN ( FEET6 ) ) ra ther than ( EQ ( HEIGHTJOHN )   ( FEET6 ) )  5 There are two reasons for this : one is the desire for " syntactic uniformity  ; the other is cohave a variable available for use in complex predicates  . Consider " John's height is more than 5 feet and less than 6 feet . " If height is a relation , we can say ( THEL ( HEIGHTJOHNL )   ( AND ( GTL ( FEET5 ) )  ( LTL ( FEET6 ) ) ) ) , whereas , if length is a function , we would say ( AND ( GT ( HEIGHTJOHN )   ( FT5 ) )  ( LT ( HEIGHTJOHN )   ( FT6 ) ) ) The second variant may look simpler , but it has the disadvantage that ( HEIGHTJOHN ) appears twice . This is not only syntactically unmotivated , since " John's height " occurs only once in the original English but  , what is worse , it may lead Coredundant prucass lns later on . Let us suppose Chat we want to test whether the assertion is true and that determining John ' sheight requires some expensive operation  , such as accessing an external database . To avoid doing the computation twice , the evaluation procedure must be much more complex if the second representation is used rather than the first  . 
VEVENTS , ACTIONS , ANDPROCESSES
The source of many problems in this area is the question of whether the treatment of sentences that describe events  ( " John is going to New York " ) should differ in any fundamental way from that of sentences chat describe statics i tuations  ( *' John is tn New York " )   . 
In a very influential paper , Davidson\[1967\] argues that , while simple predicate/argument notation , such as ( LOCJOHNmY ) , may be adequate for the latter , event sentences require explicit re ference to the event as an object  . Davldson's proposal would have us represent " John is going to New York " as if It were somsthing like " There is an event wh/~hIs agoing of Johnco New 
York ": ( so MEE ( EVENTE )   ( GOEJOHN mY ) ) Dav idson ' s a rguments fo r th i s ana lys i s are that  ( 1 ) many adverbial modifiers such as " quick ly " are best regarded as predicates of the events and that  42  ) it is possible corefer to the event expli citly in subsequent discourse  . (" John is going coNew York . Th . . . ~etrip will take four hours .  "  ) The problem wlth Davidson's proposal is that for sentences in which these phenomena do not arise  , the representation becomes unnecessarily complex  . We therefore suggest introducing an event abstraction operator  , EVABS , chat will allow us to introduce event var iables when we need them :  ( PXl . . . X . ) <-> ( SOMEE(EVENTE ) (( gVABSF ) Exl .   .   . xn ) ) In simple cases we can use the more straightforward form  . The logical form of " John is kissing Mary " would simply be  ( KISSJOHN MARY )  . The logical form of " John is gently kiss ing Mary  , " however , would be ( SOMEZ ( EVENTE )   ( AND ( ( EWSS KZSS ) ZJoHN ~ Y )   ( GENTLEE ) ) ) )  ( represented by LAMBDA expressions )   , we can handle other problems as well . Consider the sentence " Being a parent caused John's nervous break down  . "" Parent " Is a relational noun ; thus , if John is a parent , hemus the the parent of someone , but if John has several children we don't want to heforced into asserting chatbe in S the parent of any particular one of them caused the break down  . If we had PARENTI as them on a dicproperry of be in Saparent  , however , we could say ( SOMEE ( EVENTE )   ( Am )   ( ( EVABS PARENTL ) EJOHN )   ( CAUSEE " John's nervous breakdown " ) ) ) We don't need tO introduce PARENTI explic itly  , however , if we simply substitute for It the expression  , ( LAMBDAX(SOMEY(PERSONY ) ( PARENTXY))) , which would give us ( SOMEE ( EVENTE )   ( AND ( ( EVANS ( LAMBDAX ( SOMEY ( PERSONY )   ( PARZ NT x z ) ) ) )

JOHN )   ( CAUSEE " John's nervous breakdown " ) ) ) Another important question is whether actions - - - chat is  , events wlt hagents -- should be treated d if ferently from events without agents and  , if so , should the agent be specially indicated ? The po in t is that  , if Johnkissed Mary , that?s some thln She did , but not necessarily something sh . . . .~e did . Zt is not clear whether this distinction should be represented at the level of logical form or is rather an inference based on world knowledge  .   . 
Finally , most AS work on actions and events assumes that they can be decomposed into discretes teps  , and that their effects can be defined in terms of S final state  . Neither of these assumptions is appropriate for continuous processes  ; e . g .   , " The flow of water continued to flood the basement  . " What the logical form for such statements hould look like seems cobe a completely open question  .  6
VITIME AND SPACE
We believe that information about time is best represented primarily by sencential operators  , so that the logical form of a sentence like " John is in New Yorkat  2:00" would be some thlnSlikm ( AT2:00 ( LOt JOHN NY ) ) . There are two main reasons for following chls approach  . First , current time can be indicated simply by the lack of any operator  ; e , g .   , " John owns Fido " becomes simply ( OWNSJOHNFIDO ) o This is especially advantageous in basl csily static dowalns in which tlme plays a minimal role  , so we do not have to put some Chln S into the logical form of a sentence chat will besys temetically ignored by lower-level p rocessing  . The other advantage of this approach is that temporal operators can apply Coawhole sentence  , rather than Just to a verb . For instance , in the preferred reading of " The President ha8 lived in the White House since 1800  , "the referent of " the President " changes wi th the time contexts involved in evaluat in S the truth of the sentence  . The other reading can be obtained by allowing the quancl fier " the " in " the President " to assume a wider scope than that of the temporal operator  . 
Although we do not strongly dlstln sulshac tion verbs from stative verbs semantical ly  , there are before tense can be mapped into time correctly  . Stative verbs express present time by means of the simple present tense  , while action verbs use the present progress ive  . Compare : John kisses Mary ( normally habitual ) John is kissln8 Mary ( normally present time ) Johnowns Pido ( normally present time ) Johnisowning Fido ( unacceptable ) This is why ( KISSJOHN MARY ) represents " John is klsslns Mary , " rather than " Johnkisses Mary , " which would nor ~ slly receive a disposit ional or habitual interpretation  . 
What temporal operators will be needed ? We will use the operator AT to assert that a certain condition holds at a certain time  . PAST and FUTURE will be predicates on poin ts in time  . Sinq ~ le past tense statements with sCaCive verbs  , such a 8" John was in New York , " could mean either that John was in New York a t some unspecified time In the past or at a coutexcua/lyspecific time in the past :  ( SOMET ( PASTT )   ( ATT ( LOt JOHN NY ) ) )   ( TMET ( PASTT )   ( ATT ( LOCJOHNNY ) ) )   ( For the second expression to be an " offic ial " lo~t cal-form representation  , the incomplete definite reference would have to be resolved  .   ) Simple future-tense statements with sCaCive verbs are parallel  , with PUTI ~ replacing PAST . Explicit temporal modifiers are genera lly treated as additional restrict ions on the time referred to  . " John was in New York on Tuesday " a right be ( on at least one interpretation )  :  ( SOMET ( AND ( PASTT )   ( DURINGTTUESDAY ) )  ( AT ~ ( C0CJ oHN ~ ) )  )   ) For action verbs we get representations of tk ts  8o ft for past and future progressive tenses ; e . g .   , " John was kissing Mary " becomes ( THET ( PASTT )   ( ATT ( KISSJOHN ~ . lY )   )   ) When we use event abstraction to introduce individual events  , the interactions with time become somewhat r ick y  . Since ( KISSJO HN MAEY ) means " John is ( presently ) klns?ns Mary , " so must ( SOMEE ( EVENTE )   ( ( EVABS KZSS ) EJOHNMAEY ) ) S ince log ica l ly th i s formal express ion means something llke " There is  ( presently ) an event which is a kissing of Mary by John , " we will interpret the prnd ? caCeEVENT as be ing true at s particular time of the events in progress at that time  . To tie all this together , " John was kissing Mary gently '' would be represmnced by  ( THET ( PASTT )   ( ATT ( so MEE ( EVY ~ TE )   ( AND ( ( EVABS KISS )  ~ . JoHNM Alt Y )   ( GENTLEE ) ) ) ) ) Thamajo run solved problem relecing to time seams to be recouc-tliu statemancs chatre fercopoints in time with those that refe r co intervals -- for instance  , " The colpany earned $5m4111 on in March . " This csrtain Iy does not moan that stevery point in time during March the company earned  $5 au Llliou . One could invent are preesucaciou for sentences about intervals with no particular rele tiou Co the representation for sentences about points  , but then we would have the difficult task of constantly having to decide which represent at ion is approprlace  . This Is further complicated by the fact that the same event  , e . S . the American Rmvolutlon , could be viewed as dofin/J ~ either apo int in time or an interval  , depending on the time scale being cons idered  . 7(" At the time of the American Revolution , France was a --' monarchy , " compared wlth " During the American Revolution , England suffered a decllne in trade . " ) One would hope that there exist systematic relationships between statements about points in time and statements about intervals that can be exploited in develop in Balogical fo rm for tensed sentences  . There is a substantial literature in phi losophical logic devoted to " tense logic "\ [Rescher and Urquhart  , 1971\]\[McCawley ,  1981\ ]  , but almost all of thls work sees : to be concerned wlth evaluating the truth of sentences at points  , which , as we have seen , cannot be immediately extended to handle sentences about intervals  . 
We include space under the same heading as tlme because a major question about space Is the extent to which Its treatment should parallel that of time  . From an objective standpoint , it is often convenient to view physical space and time together as a four-dlmens lonal Euclidean space  . Furthermore , there are natural language constructions that seem best interpreted as asserting that a certain condition holds in a particular place  ( "In California it is legal to make ar ight turn on a red light "  )   , Just as time expressions often assert that a condition holds at a particular t ime  . The question is how farth is analogy between space and time can be pushed  . 
VlICOLLECTIVE ENTITIES AND SUBSTANCES
Most representation schemes are designed to express information about such discrete  , well-individuated objects as people , chairs , or books . Not all objects are so distinct , however ; collections and substances seem to pose special difficulties  , Collections are often indicated by conjoined noun phrases  . If we say " Newell and Simon wrote Human Problem Solving  , " we do not mean that they each did it individually  ( cf . 
" Newell and Simon have PhDs . "), rather we mean that they did it as a unit . Furthermore , if we want the treatment of this sentence to be parallel to chat of " ~ ulne wrote Word and Ob ject  , " we need an explicit representation of the unit " Newell and Simon  , " so that It can play the same role the individual " ~ ulne " plays in the latter sentence  . These considerations create difficulties in sentence interpretation because of the possibility of ambiguities between collective and distributed readings  . 
Thus , " Newell and Simon have written many papers , " might mean that individually each has written many papers or that they have jointly coauthored many papers  . The problems associated with conjoined noun phrases also arise with plural noun phrases and singular noun phrases that are inherently col lective  . " John , Bill , Joe , and Sam , "" the Jones boys , " and " the Jones String Quartet " may all refer to the same collective entity  , so that an adequate logical-form represent at ion needs to treat them as much a like as possible  . These is s , --S are treated in detail by Webber\[1978\] . 
The most obvious approach to handling collec tive entities is to treat them as sets  , but standard set theory does not provide qui te the right logic  . The interpretation of " and " in " the Jones boys and the Smith girls " would be the un ion of two sets  , but in " John and Mary " the interpretation would be constructing a set out of two indiv iduals  . Also , the distinction made in set theory between an individual  , on one hand , and the singletons at containing the indiv idual  , on the other , semas totally artificial in thls context . We need a " flatter " kind of structure than is provided by standard set theory  . The usual formal treatment of strings is a useful model  ; there is no distinction made between a character and a string Just one characterlens  ; moreover , string concatenation applies equally to st rings of one character or more than one  . Collective entities have these features in common with strings  , but share with sets the properties of being uoordered and not having repeated elements  . 
The set theory we propose has a set formation operator COMBC hat takes any number of a rguments  . The arguments of COMB may be individuals or sets of individuals  , and the value of COMB is the set chat contains all the individual arguments and all the elements of the set arguments  ; thus ,   ( COMBAiSCDEFC ) = ASCDEFG ( The notation using braces is NOT part of the logical-form language  ; this example is Just an attempt to illus tratewhat COMB means in terms of more conventional concepts  . ) If A is an individual , ( COMBA ) is elmply A . 
We need one other special operator to handle definitely determined plural noun phrases  , e . g . , " the American ships . " The problem is that in context this may re fer to some particular set of Americansh i ps  ; hence , we need to recognize it as a definite re ference that has to be resolved  . Following Weber\[1978\] , We will use the notation ( SET XP ) to express a predicate on sets that is satis fied by any set  , all of whose members satisfy ( LAMBDAXP )   . Then " the P's " would be the contextually determined set  , all of whose members are P's : ( THES ( ( SET X ( PX ) ) S )   . . . ) It might seem that , to properly capture the meaning of plurals , we would have to limit the extension of ( SET XP ) to sets of two or more elements . This is not always appropriate , however . Although " There are ships in the Med , " might seex to mean " The set of ships in the Med has at least two members  , " the question " Are there any ships in the Med ?" does not mean " Does the set of ships in the Mad have at least two members ? " The answer to the former question is yes  , even if there is only oneship in the Medi terranean  . This suggests Chatany presupposition the p lural carries to the effect that more than one object is involved may be a matter of Gr ice an lmplicature  ( " If heknew there was only one , why did n ' the says o ? " ) rather than semantics . Similarly , the plural marking on verbs seams to be Just a syntactic reflex  , rather than any sort of plural operator . On the latter approach we would have to take " Whokilled Cock Robin ?" as ambl Buous between a singular and plural reading  , sinces in Bular and plural verb forms would be semantically distinct  . 
To illustrate the use of our notation , we will represent " Everyone of the men who defeated Hannibal was brave  . "Since no one defeated Hannibal individual ly  , this mast be attributed to a collection of men :  ( so HET ( PASTT )   ( ATT ( EVERY X ( THES ( AND ( ( SET Y ( MANY ) ) S )   ( DEFEATSHANNIBAL ) )  ( MzMB xs ) )  ( EEAVE x )   ) ) ) Note Chat we can replace the plural noun phrase " the men who defeated Hannibal " by the singular collective noun phrase  , " the Roman army , " as in " Everyone in the Romeoarmy was brave ": ( SOMET ( PASTT )   ( ATT ( EVERY X ( THES ( AND ( ARMYS )   ( ROMANS ) )  ( Mz~xs ) )  ( BRAVEX ) ) ) ) chat IX QUESTIONS AND IMFERATIVE3 ( AND ( ( SET Y ( MANY ) ) S )   ( DEFEATS ~ NIBAL )   ) is replaced by ( AND ( ARMYS )   ( RO  ~ . ~NS )) . 
Collective entities are not the only ob jects that are difficult to represent  . Artificial intelligence representation schemes have notoriously shied away from mass quencitie ? and substances  . (\[ Hayes , 1978\]Is a notable exception . ) In a sentence like " All Eastern coal contains so masul fur  , " it see ,  . " tb ?\[" coal " and " sulfur " refer to properties of samples or pieces of " stuff  . "We might paraphrase thls sentence as " All pieces of stuff that are Eastern coal contain soue stuff that Issul fur  . " If we take this approach , then , In interpreting a sentence like " The Un iverseIrel and Is carrying  00   , 000 barrels of Saudilight crude , " we need coindicate that the " piece of stu ff " being described is the maximal " piece " of Saudllight crude the shlp is carrying  . In other cases , substances seem to be more llke abstract individuals  , e . g . , " Copper is the twenty-ninth element in the periodic table  . " Nouns that refer Co substances can also function as do plural noun phrases in their ~ eneric use : " Copperis\[antelopes are \] abundant in the Americans outhwest  . " Vlll PROPOSITIONAL ATTITUDES AND MODALITIES Propositional attitudes and modal it ies are discussed together  , because they are both normally treated as in tensional sentential operators  . For instance , to represent " John believes Chat the Fox is in Naples  , " we would have an operator BELIEVE that takes " John " as its first argunmnt and the representation of " The Fox is in Naples " as I ts second argument  . 
S ? ,   , tlarly , to represent '* the Fox might be in Naples , " we could apply an " operator POSSIBLE to the representation of " The Fox is in Naples  . " This approach works particularly well on a number of problems involving quan Cifiers  . For example , " John believes someone is in the basements ' possesses an ambiguity that is revealed by the two par ? phrases  , " John believes there is someone in the basement " and " There is someone John bel ieves Cobe in the basement  . " Aschess paraphrases suggest , thls distinction is represented by dif ferent relative scopes of the belief operator and the existential quantifier introduced by the indefinite pronoun " someone ":  ( BELIEVEJOHN ( SOMEX ( PERSONX )   ( LOCXBASEMENT ) ) )   ( SOMEX ( PERSONX )   ( BELIEVEJOHN ( LOCX ~ N~S ~ IENT ) ) ) This approach works very well up to a point , but there ? recases It does not handle . For exanple , sometimes verbs like " believe " do not take a sentenc ? a ? ? n ? rs ~ menc  , but rather a description of a sentence , e . g . , " John believes Gold bach's conjecture . " TF we were to make " believe " a predicate rather than a sentence operator to handle thi stype of ~ m?le  , the elegant semantics chat has been worked ou C for " quanc ? fylngIn " would completely break down  . Another alternative is to introduce a pred icate TIUE co maps description of a sentence into ? sentence that necessarily has the smset ruth value  . Than " John believes Cold bach's conjecture " is treated?s If It were " John belleves of Coldbach's conjecture that I tist rue  . " This is dlsc?n Sulshed inch ~ usu alwayf rom " John believes that Cold bach's--~-c ~n Jecture  ( whatever It may be ) is true " by reversing the scope of the descr iption " Gold bach's conjecture " and the operator " believe  . " The only types of utterances we have tr ied Core present in logical form to this po intare assertions  , but of course there are other speech acts as we ll  . The only twove will consider ? request ions and imperatives  ( commands )   . Since performatives ( promises , bets , declarations , etc .   ) have the ? ate syntactic form?s assert ions  , it appears that they raise no new problems . 
We will also concern ourselves only wich the literal speech act expressed by an utterance  . Dealing wlth indirect speech acts does no c seem to change the range of representations needed  ; sometimes , for example , we may simply need to represent what is lite rally an assertion as so machlnglnc?nded as a command  . 
For question ? , we would like to have a uniform treatment of both the yes/no and WH forms  . The simplest approach is coregard the semant ic content of a WH question to be a predicate whose extension is being sought  . This does no caddress the issue of what is a satisfactory answer to ? question  , but we regard that as part of the theory of speech acts proper  , rather than a question of logical form . We will introduce the operator WHAT for const ructlng complex set descriptions  , which , for the sake of uniformity , we will give the same four-parts t ructure veu?e for quantlflers  . The represent ? tlon of ' ~ hat Americanships are in the Med ? " would roughly be as fol lows :  ( WHATX ( AND ( SHIPX )  ~ . MERICANX ) )  ( LOCx ~ zD ) ) WHAT i s conven ient ly mnemonic , since we can represent " who " as ( WHATX ( PERSONX )   . . . . ), " when " as ( WHAT X ( TZHZ X ) .   .   .   . ), and so forth . " How many " questions will be treated a ? questioning the quantifier  . 
' ~ lov many men ? remortal ?" would be represented a ?  ( WHATN ( Nb ~ mZRN )   ( NX ( MANX )   ( MOZTAL X ) ) ) Yes/no questions can be handled?s ? degenerate case of WH questions by treating a proposition ? saO-ary predicate  . Since the exC ? ueion of ? nn-stypred icate is a set of n-tuples  , the extension of a proposition would be a set of  0 - ~ uples . There is only one 0-tuple , the e~ty top is , so there ? reonly two po?slbles ? ts of O-~uple ?  . Th?se are the single to ~ set containing the empty top is  , and the empty set , which we can identify wlth the truth values TRUE and FALSE  . The logical form of a yes/no question wl th Che proposition P as its S'mantic content would be  ( WHAT (   ) TEUEP )   , or more simply P . 
With regard to imperatives , It is less clear what type of semantic ob jectChair content should be  . We might propose that Itl ? a proposition , but vethen have Coaccount for the fact that not ? ll propositions are acceptable as commands  . For instance , John cannot be commanded " Bill go to New York . " The respon?e that a person can only be " commanded some chlng " he has control over is not adequate  , because any proposition can be converted in to a command by the verb " sake "-- e  . g . , " Make
Bill So Co New York . "
The awkwer dn as ? of the phrasing " command someone so mathlng " suggests another approach  . One cmm and ssos'one Cod . ~ o something , and the thinks that are done are actions . If actions are treated as objects , we c and ? fl nea relation DO chat map ? ? n agent sad an action into a proposition  ( See\[Moore ,  1980\ ] )  . " John is going CoNew York " would then be represented by  ( DOJO~h ~ ( GO~f )   )   . Actions are no vavailable to be the semant ic content of imperatives  . The problem with this approach is that we now have to pack into actions all the semant ic complexities Chat can ? rise in comms nds - above as predicates on events  ( " Co quickly " )  , quantiflers (" Go to every room in the house ") , and negation (" Don'tgo") . 
A third approach , which we feel is actually the most promising , is to treat the semantic content of an imperative as being a unary predlcace  . The force of an imperative 18 that the person to whom the command is directed is supposed to satisfy the predl caCe  . 
According to this theory the role of " make " is clear--it converts any proposition into a unary predicate  . If the assertion " John Ismaking glllgo CoNOw York " is represented as  ( MAKEJOHN ( GOBILL MY ) ) , we can form a unary predicate by LAMBDA abstraction :  ( LAMBDAX ( MAKEX ( GOgILLmY ) ) , which would be the semantic content of the command " Make 
Billgoto New York."
This approach does away wlth the problem concerning adverbial modifiers or quant lf lersIn commands  ; they can simply be part of the proposition f rom which the predicate is formed  . A final piece of evidence favoring thls approach over a theory based on the notion of a c tion is that some imperatives have nothing a t all to do wlth actions directly  . The semantic content of command sllke " Be good " or " Don't be a fool " really does seem to consist exclusively of a pred icate  . 
XCONCLUSION
In a paper that covers such a wide range of di sparate topics  , it is hard to reach any sweeping general conc lusions  , but perhaps a few remarks about the nature and current status of the research program are in order  . First , it should be clear from the issues di scussed that at least as many problems remain in the quest for logical form as have al ready been resolved  . 
Considering the amount of effort that has been expended upon natural language semantics  , this is somewhat surprising . The reason may be that relatlvely few researchers have worked in thls area for its own sake  . 
Davl deon's ideason action sentences , for instance , raised some very interesting points about logical form -- but the major debate Ic provoked in the philosophicalll cerature was about the metaphysics of the concept of action  , no cab out the semantics of action sentences . 
Even when semantics is a major concern , as in the work of Montague , the emphasis is often on showing chat relatively well-understood subareas of semantics  ( e . g . , quantificaclon ) can be done in a parClcular way , rather than on attempting to take on really new problems  . 
An additional difficulty is that so much work has been done in a fragmentary fashion  . It is clear that the concept of action is closely related to the concept of time  , but it is hard to find any work on either concept that takes the other one seriously  . To build a language-processlng system or a theory of language processing  , however , requires an integrated theory of logical form , not Just a set of incompatible fragmentary theories  . Our conclusion , then , is chacif real progress is to be made on understanding the logical form of natural language utterances  , it must be studied in a unified way and treated as an important research problem in its own right  . 

The ideas in this paper are the collective result of the efforts of a large number of people at SRI  , particularly Barbara Grosz , SC an Rosenscheln , and Gary dendrix . Jane Robinson , Jerry Hobbs , Paul Martin , and Norman Haas are chiefly responsible for the implement a Clon of the DIALOGIC system  , building on earlier systems cowhich Ann Robins on and Bill Paxcon made major contributions  . This research was supported by the Defense Advanced Research Projects Agency under Contracts  N00039-80-C-0645 and N00039-80-C-0575 with the
Naval Electronic Systems Command.

I Although our immediate aim is to construct a theory of natural-language processing ra ther than truth-conditional semantics  , It is worth noting that a system of logical form wlth a well-deflned semantics constitutes a bridge between the two projects  . If we have a processing theory that associa tes English sentences with their logical forms  , and if those loKical forms have a truth- ~ondltional semantics  , then we will have specified the semantics of the English sentences as well  . 
2 In other papers ( e . g . , \[ Montague , 1974b \]) , Montague himself uses an intenslonal logic in exactly the role we propose for logical form -- and for much the same reason : ' We could  . . . introduce the semantics of our fraKment\[of English \] directly  ; but It It Is probably mere per spicuous to proceed indirectly by  ( I ) setting up a certain simple artific i allanguage  , that often sed Intenslonal logic , (2) giving the semantics of that language , and ( 3 ) interpreting English indirectly by showing in a rigorous way how to translate it into the artificial language  . This Is the procedure we shall adopt; . . . "\[ Montague , 1974b , p . 256\] . 
3 The DIALOGIC system does build such a representation  , or at least components of one , as an intermediate step in deriving the logical form of a sentence  . 
4 This suggests chac our logical forms are representations of what David Kaplan  , in his famous unpublished paper on demonstratives \[Kaplan  ,  1977\] , calls the content of a sentence , as opposed to Its character . Kaplan introduces the content/character distinction to sort out puzzles connected wlth the use of demonstratives and Indaxl cals  . He notes that there are at least two different notions of " the meaning of a sentence " that conflict when indexical expressions are used  . If A says to B , " I am hungry , " and g says to A , " ~ amhungry , " they have used the same words , but in one sense they mean different things . After all , it may be the case that what A said is true and what B said is false  . If A says to g , " ~ amhungry , " and B says to A , "You are hungry , " they have used different words , but mean the same thing , that A is hungry . This notion of " meaning different things " or " meaning the same thing " is one kind of meaning  , which Kaplan calls " content . " There Is another sense , though , In which A and g both use the words " I am hungry " with the same mean lng  , namely , that the same rules apply to determine , in context , what content is expressed . For thls notion of meaning , Kaplan uses the term " character . " Kaplan's notion , therefore , is that the rules of the language determine the character of a sentence--whlch  , in turn , together wlth the context of utterance , determines the content . If ~ broaden the scope of Kaplan's theory to include the local pragmatic indeterml nacles we have discussed  , it seems Checthe way they depend on context would also be part of the character of a sentence and Chatour logical form is thus a representation of the content of the sentence-ln -context  . 
5 It should be obvious from the example that nouns referring to unlCs of measure -- e  . g . , " feet " -- are an exception coth e general rule . We treat types of quan Citles , such as distance , weight , volume , time Following Hayes \[1979\] , unlCs such as feet , pounds , gallons , and hours are considered to be functions from numbers  , to quantities . Thus ( FEET3 ) and ( YARDS l ) denote the same distance . Halation sllke length , weight , size , and duration hold between an entity and a quantity of an appropriate type  . Where a word llke " welghc " serves in English to refer coboth the rela Clon and the quantity  , we must be careful Codls Clngulsh between chem . To see the dlscincCion , note Chac length , beam , and draft are all relaclons between as hip and a quanClcy of the same type  , discance . We treat comparative sllke " greater than " as molcidomain relaclons  , working with any two quanci Cles of the same type ( or wich pure numbers , for chacmatter ) . 
6 Hendrix\[1973\] , Rieger\[1975\] , Hayes \[1978\] , and McDermott \[1981\] have all dealt with conClnuous processes co some extent  , buc none of them has considered specifically how language expresses information about processes  . 
7This point was impressed upon meby Pat Hayes.

Barwise , J . and R . Cooper \[1981\] " Generalized Quantifiers and Natural Language , " Lln~uls Clcsan . ~d Philosophy , Vol . 4, No . 2, pp .  159-219 (1981) . 
Clark , H . and C . Marshall \[1981\] "Deflnl Ce Reference and Mutual Knowledge , " in Elements of Discourse Understanding : Proceedings of E Workshop o~n Com~uta Clonal Aspects of Lin~ulst lc Structure and Discourse SeCt in ~  , A . K . Joshi , LA . Sag , and B . L . Webber , ads . ( Cambridge Unlversicy Press,
Cambridge , England , 1981).
Cohen , P . and C . R . Perraulc\[1981\]"InaccurateReference , " in Elements of Discourse Understanding : Proceedln~s of ~ Workshop on Computational Aspects of Linguistic Structure and Discourse Setting  , A . K . Joshi , I . A . Sag , and 8 . L . Webber , eds . 
( Cambridge University Press , Cambridge , England ,  1981) . 
Davidson , D . \[1967\]" The Logical Form of Acclon Sentences , " in The Lo61 C of Decision and Action , N . Rescher , ed . , pp . 81-95 ( University of Pittsburgh Press , Pittsburgh , Pennsylvania ,  1967) . 
Hayes , P . J . \[1978\]" Naive Physics : Ontology of Liquids , " Workin ~ Papers , Inscl Cute of Semantic and Cognitive Studies , Geneva , Switzerland , ( August 1978) . 
Hayes , P . J . \[1979\]" The Naive Physics Manifes to , " in Expert S~scems in the Micro-electronic A~e , D . Michle , ed . , pp . 242-270 ( Edinburgh Universlcy
Press , Edinburgh , Scotland , 1979).
Hendrix , G .   \[1973\] ' ~ odellng Slmul can eoue Actions and Conclnuous Processes  , " Arciflclal In Celllgence , Vol . 4, Nos . 3, 4, pp . 145-180 ( Winter 1973) . 
Herskovi Cs , A . \[1980\] " On the Spatial Uses of Prepositions , " in Proceed lnss of the 18th Annual Meecln ~ of the Association for Computational Philadelphia  , Pennsylvania , pp . i-5 (1922 June 1980) . 
Kaplan , D . \[1977\]" Demons Cratlves , An Essay on the Semon Cics , Logic , He Caphysics and Epis Cemology of Demons Cratlves and OCher Indexlcals  , " unpublished manus crlpc ( March 1977) . 
McCawley , J . D .   \[1981\] Everything chac Llnsuiscs Have Alwa Ts Wanted co Know Abou C~bu  .   .   . ~C Were A shamed to Ask ( Unlversl Cy of Chicago Press , Chicago , 
Illinois , 1981).
MoDermocc , D . V .   \[1981\] " A Temporal Logic for Reasoning about Processes and Plans  , " keearch Keporc 196 , Yale University , Department of Compu Cer Science , 
New Haven , Connecticut ( March 1981).
Moncague , R . \[1974a \]" English as a Formal Language , " in Formal Philosophy , Selected Papers of Richard Monca Sue , R . H . Thomason , ed . , pp . 18~21('-~al ~ University Press , New Haven , Connecticut , and
London , England , 1974).
Moncague , R .   \[1974b \]' The Proper Tree--nO of quanclfica clon in Ordinary English  , " in Formal Philosophy , Selected Papers of Richard Moncasue . 
R . H . Thomaaon , ed . , pp . 188-22i ( Yale Unlversicy Press , New Haven , Connecclcu C , and London , England ,  1974) . 
Moore , R . C . \[1980\] " Rmaeon?ng About Knowledge and Action , " Artificial Intelligence Can Cer Technical Note  191  , SRI International , Menlo Park , Califor ~ La ( October 1980) . 
Heather , N . and A . Urquharc , \[1971\] Temporal Losic ( Springer-Verlag , Vienna , Austria ,  1971) . 
Rieger , C .   \[1975\] " The Coumonseuse Algorl Chaasa Basis for Computer Models of Human Memor T  , Inference , Belief and Contextual Language Comprehension , " in Proceed ln~s , Theorecl cal Issues in Natural Language Processing  , Cambridge , Massachusetts , pp . 180-195 ( LO-13 June 1975) . 
Simon , H . A . \[1969\] The Sciences of the Artificial ( The HIT Press , Cambridge , Mass J ": hux CCs ,  1969) . 
Webber , B . L .   \[1978\] " A Formal Approach coDis course Anaphora , " Haporc No . 3761, Bolehranek and Newman , Inc . , Cambridge , Massachusetts ( May 1978) . 
