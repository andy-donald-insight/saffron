Memoisation for Glue Language Deduction and Categorial Parsing 
Mark Hepple
Department of Computer Science
University of Sheffield
Regent Court , 211 Portobello Street
Sheffield S14 DP , UK
hepple@dcs , hef.ac.uk
Abstract
The multiplicative fragment of linear logic has found a number of applications in computational linguistics : in the " glue language " approach to LFG semantics  , and in the formulation and parsing of various categorial grammars  . These applications call for efficient deduction methods  . Although a number of deduction methods for multiplicative linear logic are known  , none of them are tabular methods , which bring a substantial efficiency gain by avoiding redundant computation  ( c . f . chart methods in CFG parsing ) : this paper presents such a method , and discusses its use in relation to the above applications  . 
1 Introduction
The multiplicative fragment of linear logic , which includes just the linear implication ( o- ) and multiplicative ( ? ) operators , has found a number of applications within linguistics and computational linguistics  . Firstly , it can be used in combination with some system of labelling  ( after the ' labelled deduction ' methodology of ( Gabbay ,  1996 ) ) as a general method for formulating various categorial grammar systems  . Linear deduction methods provide a common basis for parsing categorial systems formulated in this way  . Secondly , the multiplicative fragment forms the core of the system used in work by Dalrymple and colleagues for handling the semantics of LFG derivations  , providing a ' glue language ' for assembling the meanings of sentences from those of words and phrases  . 
Although there are a number of deduction methods for multiplicative linear logic  , there is a notable absence of tabular methods , which , like chart parsing for CFGs , avoid redundant computation . Hepple ( 1996 ) presents a compilation method which allows for tabular deduction for implicational linear logic  ( i . e . the fragment with only o--) . This paper develops that method to cover the fragmen that includes the multiplic-ative  . The use of this method for the applications mentioned above is discussed  . 
2 Multiplicative Linear Logic
Linear logic is a ' resource-sensitive ' logic : in any deduction  , each assumption ( ' resource ' ) is used precisely once ? The formulae of the multiplicat-ive fragment of  ( intuitionistic ) linear logic are defined by ~": := AI~'o-~" J  9 v ? ~ ( A a nonempty set of atomic types )  . The following rules provide a natural deduction formulation : 
Ao--B:a B : bo-E
A : ( ab)\[B : v\]
A : ao--I
Ao-B :), v.a\[B:x\],\[C:y\]B?C:b
A : a A : a B : b ? E ? I
A"@?E ., ~( b , a ) A ? B : ( a ? b)
The elimination ( E ) and introduction ( I ) rules for o--correspond to steps of functional application and abstraction  , respectively , as the term labelling reveals . The o--I rule discharges precisely one assumption  ( B ) within the proof to which it applies . The ? I rule pairs together the premise terms , whereas ? E has a substitution like meaning . 1 Proofs that Wo--(Xo--Z ) , Xo--Y , Yo--Z=~W and that
Xo-Yo-Z , Y@Z = vX follow:
Wo-(Xo-Z ): wXo-Y:xYo-Z:y\[Z:z\]
Y : ( yz)x:
Xo--Z : Az . x ( y  z ) w : 1The meaning is more obvious in the notation of ( Benton et al , 1992): ( let bbex ~ yina) . 

Xo-Yo-Z:x\[Z:z\]\[Y:y\]Y ? Z:w
Xo-Y : ( zz)
X : ( zzu)xE~,,(w , (= z ~))
The differential status of the assumptions and goal of a deduction  ( i . e . between F and A in F = vA ) is addressed in terms of polarity : assumptions are deemed to have positive polarity  , and goals negative polarity . Each Sub-formula also has a polarity , which is determined by the polarity of the immediately containing  ( sub ) formula , ccording to the following schemata ( where 15 is the opposite polarity top ) :  ( i )   ( X po--Y ~ ) P ( ii )   ( X p?Y p ) pFor example , the leftmost assumption of the first proof above has the polarity pattern  ( W + o- ( X-o-Z + ) -  ) + . The proofs illustrate the phenomenon of ' hypothetical reasoning '  , where additional assumptions ( called ' hypothet-icals ' ) are used , which are later discharged . The need for hypothetical reasoning in a proof is driven by the types of the assumptions and goal : the hypotheticals correspond to positive polarity subformulae of the assumptions/goal that occur in the following subformula contexts : i  )   ( X-o--Y + ) -  ( giving hypothetical Y ) ii )   ( X + ? Y + ) +  ( giving hypo'sX and Y ) The subformula ( Xo-Z ) of Wo-- ( Xo-Z ) in the proof above is an instance of context ( i )  , so a hypothetical Z results . Subformulae that are instances of patterns ( i , ii ) may nest within other such instances ( e . g . in((A?B ) ? C)o-D , both ( ( A?B ) @ C ) and ( A ? B ) are instances of ( ii ) ) . 
In such cases , we can focus on the maximal pattern instances ( i . e . not contained within any other ) , and then examine the hypotheticals produced for whether they in turn license hypothetical reasoning  . This approach makes explicit the patterns of dependency amongst hypothetical elements  . 
3 First-order Compilation for
Implicational Linear Logic
Hepple ( 1996 ) shows how deductions in implic-ational linear logic can be recast as deductions involving only first-order formulae  , using only a single inference rule ( a variant of o-E )  . The method involves compiling the original formulae to indexed first-order formulae  , where a higher-order 2 initial formula yields multiple compiled formulae  , e . g .   ( omitting indices ) Xo-- ( Yo--Z ) would yield Xo--Y and Z , i . e . with the subformula Z , relevant o hypothetical reasoning , being excised to be treated as a separate assumption  , leaving a first-or de residue .   3 Indexing is used to ensure generaline aruse of resources  , but also notably to ensure proper use of excised subformulae  , i . e . so that Z , in our example , must be used in deriving the argument of Xo-Y , or otherwise invalid deductions would result ) . Simplifying Xo-- ( Yo--Z ) to Xo--Y removes the need for a no--I inference , but the effect of such a step is not lost , since it is compiled into the semantics of the formula  . 
The approach is best explained by example.
In proving Xo--(Yo--Z ) , Yo-W , Wo--Z = vX , the premise formulae compile to the indexed formulae  ( 14 ) shown in the proof below . Each of these formulae ( 14 ) is associated with a set containing a single index  , which serves as a unique identifier for that assumption  . 

2. j:Z : z2.k:Yo--(W:0):Au.yu4.
5 . j , 1: W : wz 6 . j , k , l:Y : y(wz ) 7 . i , j , k , l:X:x(z . y ( wz ) ) \[2+4\] \[3+5\] \[1+6\] The formulae ( 57 ) arise under combination , allowed by the single rule below . The index sets of these formulae identify precisely the assumptions from which they are derived  , with appropriate indexation being ensured by the condition  7r = ?~? of the rule ( where t2 stands for disjoint union , which enforces linear usage ) . 
?:Ao--(B:a):)~v . a ?: B : b 7r = ?~? rr:A:a\[b//v\] 2The key division here is between higher-order formulae  , which are are functors that seek at least one argument that bears a a functional type  ( e . g . Wo--(Xo--Z )) , and first-order formulae , which seek no such argument . 
3This ' excision ' step has parallels to the ' emit ' step used in the chart-parsing approaches for the associative Lambek calculus of  ( KS nig , 1994) and ( Hepple ,  1992) , although the latters differs in that there is no removal of the relevant subformula  , i . e . the ' emitting formula ' is not simplified , remaining higher-order . 

Assumptions (1) and (4) both come from
Xo- ( Yo--Z ) : note how ( 1 ) 's argument is marked with ( 4 ) 's index ( j )  . The condition c~C ? of the rule ensures that ( 4 ) must contribute to the derivation of ( 1 ) 's argument . Finally , observe that the rule's semantics involves not simple application  , but rather by direct substitution for the variable of a lambda expression  , employing a special variant of substitution , notated_\[_//_\] , which specifically does not act to avoid accidental binding  . Hence , in the final inference of the proof , the variable z falls within the scope of an abstraction over z  , becoming bound . The abstraction over z corresponds to a no-I step that is compiled into the semantics  , o that an explicit inference is no longer required  . See ( Hepple , 1996) for more details , including a precise statement of the compilation procedure  . 
4 F i r s t - o rder Compi la t ion for Mu l t ip l i ca t ive L inear Log ic In extending the above approach to the multiplicative  , we will address the ? I and @ E rules as separate problems  . The need for an ? I use within a proof is driven by the type of either some assumption or the proof's overall goal  , e . g . to build the argument of an assumption such as Ao-  ( B@C )  . For this specific example , we might try to avoid the need for an explicit @ I use by transforming the assumption to the form Ao-Bc-C  ( note that the two formulae are interderivable )  . This line of exploration , however , leads to incompleteness , ince the manoeuvre results in proof structures that lack a node corresponding to the result of the ? I inference  ( which is present in the natural deduction proof )  , and this node may be needed as the locus of some other inference  .   4 This problem can be overcome by the use of goal atoms  , which are unique pseudo-type atoms , that are introduced into types by compilation ( in the parlance of l is p , they are ' gensymmed ' atoms ) . An assumption Ao- ( B@C ) would compile to Ao--G plus Go-Bo-C , where G is the unique goal at om(gl , perhaps ) . A proof using these types does contain a node corresponding to  ( what would be ) the result of the @ inference in the natural 4Specifically   , the node must be presento allow for steps corresponding to @ E inferences  . The expert reader should be able to convince themselves of this fact by considering an example such as 
Xo-((Y?U ) ~-( Z?U )), Yo-Z ~ X.
deduction proof , namely that bearing type G , the result of combining Go--Bo-C with its arguments  . 
This method can be used in combination with the existing compilation approach  . For example , an initial assumption Ao- ( (B?C ) o--D ) would yield a hypothetical D , leaving the residue Ao-(B@C ) , which would become Ac~-G plus Go--Bo-C , as just discussed . This method of uniquely-generated ' goal atoms ' can also be used in dealing with deductions having complex types for their intended overall result  ( which may license hypotheticals , by virtue of realising the polarity contexts discussed in section  2  )  . Thus , we can replace an initial deduction F = ~ A with Co--A  , F  ~ G , making the goal A part of the lefthand side . The new premise Go---A can be compiled just like any other  . Since the new goal formula G is atomic , it requires no compilation . For example , a goal type Xo-Y would become an extra premise Go --  ( Xo--Y )  , which would compile to formulae Go-X plus Y . 
Turning next to ? E , the rule involves hypothetical reasoning , so compilation of a maximal positive polarity subformula B ? C will add hy-potheticals B  , C . No further compilation of B?C itself is then required : whatever is needed for hypothetical reasoning with respect to the internal structure of its subformulae will arise elsewhere by compilation of the hypotheticals B  , C . Assume that these latter hypotheticals have identifying indices i  , j and semantic variables x , y respectively . A rule for ? E might combine B?C ( with term t , say ) with any other formula A ( with terms , say ) provided that the latter has a disjoint index set that includes i  , j , to give a result that is also of type A , that is assigned semantics E~y(t , s ) . To be able to construct this semantics , the rule would need to be able to access the identities of the variables x  , y . The need to explicitly annotate this identity information might be avoided by ' raising ' the semantics of the multiplicative formula at compilation time to be a function over the other term  , e . g . t might be raised to Au . E ~ y(t , u) . A usable inference rule might then take the following form  ( where the identifying indices of the hypotheticals have been marked on the product type  ) :  ( ? , A , s )? , ( B?C):i , j , Au . t)i,j ? ? ~ r = ? w ?
Gr , A , t\[sllu\] ) quire that the type A of the minor premise is atomic  . This is possible since firstly , the first-order compilation context ensures that the arguments required by a functor to yield an atomic result are always present  ( with respect o completing a valid deduction )  , and secondly , the alternatives of combining a functor with a multiplicative under the rule either before or after supplying its arguments are equivalent  . 5In fact , we do not need the rule above , as we can instead achieve the same effects using only the single  ( o-- ) inference rule that we already have , by allowing a very restricted use of type polymorphism  . Thus , since the above rule's conclusion and minor premise are the same atomic type  , we can in the compilation simply replace a formula X NY  , with an implic-ation . Ao---( . A : i , j ) , where , 4 is a variable over atomic types ( and i , j the identifying indices of the two hypotheticals generated by compil-ation  )  . The semantics provided for this functor is of the ' raised'k ind discussed above  . However , this approach to handling ? E inferences within the compiled system has an undesirable characteristic  ( which would also arise using the inference rule discussed above  )  , which is that it will allow multiple derivations that assign equivalent proof terms for a given type combination  . 
This is due to nondeterminism for the stage at which a type such as Ao---  ( A : i , j ) particip-ates in the proof . A proof might contain several nodes bearing atomic types which contain the required hypotheticals  , and Ao-(al:i , j ) might combine in at any of these nodes , giving equivalent results .   6 The above ideas for handling the multiplicat-ive are combined with the methods developed  5This follows from the proof term equivalence E ~ , y(f , ( ga )) = ( E  ~ , ~(f , 9) a ) where x , yEfreevars(g ) . 
The move of requiring the minor premise to be atomic effects a partial normalisation which involves not only the relative ordering of ? E and o--E steps  , but also that between interdependent ? E steps ( as might arise for an assumption such as ( ( ANB ) ? C ) ) . It is straightforward to demonstrate that the restriction results in no loss of readings  . See ( Benton et al ,  1992 ) regarding term assignment and proof normalisation for linear logic  . 
6It is anticipated that this problem can be solved by using normalisation results as a basis for discarding partial analyses during processing  , but further work is required in developing this idea  . 
for the implicational fragment to give the compilation procedure  ( ~- )  , stated in Figure 1 . This takes a sequent F => A as input ( case T1) , where A is a type and each assumption in F takes the form Type : Sere  ( Sereminimally just some unique variable )  , and it returns a structure (~ ,  ? , A , where ~ is a goal atom , ? the set of all identifying indices , and A a set of indexed first order formulae ( with associated semantics )  . 
Let A * denote the result of closing A under the single inference rule  . The sequent is proven iff (? ,  ~ , t ) EA * for some term t , which is a complete proof term for the implicit deduction  . The statement of the compilation procedure here is somewhat different to that given in  ( Hepple ,  1996) , which is based on polar translation functions . In the version here , the formula related cases address only positive formulae  . T
As an example , consider the deduction
Xo--Y , Y ? Z => XNZ . Compilation returns the goal atomg O , the full index set g , h , i , j , k , l , ) lus the formulae show in (16) below . 
1 . (9, gOo-(gl:h ), At . t ) 2 . ( h,glo-(X:O)o-(Z:O ), AvAw . ( w?v )) 3 . ( i,Xo-(Y : O ), kx . ( ax )) 4 . ( j , A ~-( A : k , 0), ~ . E~z(b , u ) > 5 . k,Y , y6 . (/, Z , z ) 7 . ( i,k,X , ( ay ))\[3+5\]8 . < h,l,glo---(X:O ), Aw . ( w?z ))\[2+6\]9 . h,i,k,l,gl,((ay ) ? z))\[7+8\]10 . (h,i,j,k,l,gl,E~z(b,((ay)?z )))\[4+9\]11 . (g , h,i,j,k,l,gO,E~(b,((ay)?z )))\[1+11\]12 . g , h,i,k,l,gO,((ay ) ? z))\[1+9\]13 .  (9 , h , i , j , k , l , gO , E ~( b , ( ( ay ) N z ) ) ) \[4+12\] The formulae ( 713 ) arise under combination . 
Formulae ( 11 ) and ( 13 ) correspond to successful over all analyses ( i . e . have type gO , and are labelled with the full index set ) . The proof illustrates the possibility of multiple derivations  7Note that the complexity of the compilation is linear in the ' size ' of the initial deduction  , as measured by a count of type atoms . For applications where the formulae that may participate are preset  ( e . g . they are drawn from lexicon ) , formulae can be precompiled , although the results of precompilation would need to be parametised with respect othe variables /indices appearing  , with a sufficient supply ' fresh'symbols being generated at time of lexical access  , to ensure uniqueness . 
541 ( T1)T ( XI : Xl, .   .   . , Xn:xn=:~Xo ) --( ~, 4, i ) where i0, .   .   .   , infresh indices ; ~ a fresh goal atom ; ? = indices(A)A=7-(<i0 , Go-Xo , y . y >) u 7-(< il , Xl , xl >) u .   .   . u7-(< in , xn ,  (7-2) 7"((4 , X ,  8)) : (4 , X , s ) where X atomic (73) 7-((? , Xo-Y , s )) = 7-((4 , Xo-(Y : O) , s ) ) where Y has no ( inclusion ) index set ( 7-4 ) T ( (4 , Xlo-(Y :?) , s )) = (4 , X2o--(Y :?) , ;~x . t ) UF where Y is atomic ; x a fresh variable ;  7-((4 , X 1 , ( sx ))) = (4 , X2 , t ) + ttJF(T5) 7-((4 , Xo-((Yo-Z ): ?) , s )) = 7-((? , Xo-(Y : ~ r) , A y . s()~z . y ))) U7-((i , Z , z )) where i a fresh index ; y , zfresh variables ; 7r = iU ? (7-6) 7-((4 , Xo-((Y ? Z ): ?) , s )) = 7-((4 , Xo-(G : ~) , s )) u 7-(( i , ~ o-Yo-Z , ~ z ~ y . ( y?z ))) where iafresh index ; Gafresh goal atom ; y , zfresh variables ; 7r = iU(77) T((4 , X ? Y , s )) = (4 , Ao---(A:i , j ) , At . (E~(s , t ))) UT-((i , X , x )) UT((j , Y , y )) where i , j fresh indices ; x , y , tfresh variables ; . 4 a fresh variable over atomic types
Figure 1: The Compilation Procedure assigning equivalent readings  , i . e . (11) and (13) have identical proof terms , that arise by nondeterminism for involvement of formula  ( 4 )  . 
5 Comput ing Exc lus ion Const ra in ts The use of inclusion constraints  ( i . e . requirements that some formula must be used in deriving a given functor's argument  ) within the approach allows us to ensure that hypotheticals are appropriately used in any overall deduction and hence that deductions are valid  . However , the approach allows that deduction can generate some intermediater sults that cannot be part of an overall deduction  . For example , compiling a formula Xo-- ( Yo-- ( Zo--W ) )o-- ( Vo-W ) gives the first-orderesidue Xo-Yo--V , plus hypothetic-als Zo-W and W . A partial deduction in which the hypothetical Zo -W is used in deriving the argument V of X o--Yo-V cannot be extended to a successful loverall deduction  , since its use a gain for the functor's second argument Y  ( as an inclusion constraint will require ) would viol-ate linear usage . For the same reason , a direct combination of the hypotheticals Zo-W and W is likewise a deductive deadend  . 
This problem can be addressed via exclusion constraints  , i . e . annotations to forbid stated formulae having been used in deriving a given funtor's argument  , as proposed in ( Hepple ,  1998) . Thus , a functor might have the form Xo--- ( Y : i : j ) to indicate that i must appear in its argument's index set  , and that j must not . 
Such exclusions can be straightforwardly computed over the set of compiled formulae that derive from each initial assumption  , using simple ( set-theoretic ) patterns of reasoning . For example , for the case above , since W must be used in deriving the argument V of the main residue formula  , it can be excluded from the argument Y of that formula  ( which follows from the disjointness condition on the single inference rule  )  . Given that the argument Y must include Zo--W , but excludes W , we can infer that W cannot contribute to the argument of Zo--W  , giving an exclusion constrain that ( amongst other things ) blocks the direct combination of Zo--W and W . See ( Hepple ,  1998 ) for more details ( although a slightly different version of the first-order formalism is used there  )  . 
6 Tabular Deduction
A simple algorithm for use with the above approach  , which avoids much redundant computation , is as follows . Given a possible theorem to prove , the results of compilation ( i . e . indexed types plus semantics ) are gathered on an agenda . Then , a loop is followed in which an item is taken from the agend and added to the database  ( which is initially empty )  , and then the next triple is taken from the agenda and entry is added to the database  , a check is made to see if it can combine with any that are already there  , in which case new agenda items are generated . When the agenda is empty , a check is made for any successful overall analyses  . Since the result of a combination always bears an index set larger than either parent  , and since the maximal index set is fixed at compilation time  , the above process must terminate . 
However , there is clearly more redundancy to be eliminated here  . Where two items differ only in their semantics , their subsequent involvement in any further deductions will be precisely parallel  , and so they can be collapsed together . For this purpose , the semantic om-ponent of databasentries is replaced with a unique identifer  , which serves as a ' hook ' for semantic alternatives  . Agenda items , on the other hand , instead record the way that the agenda item was produced  , which is either ' presupplied ' ( by compilation ) or ' by combination ' , in which case the entries combined are recorded by their identifiers  . When an agenda item is added to the database , a check is made for an entry with the same indexed type  . If there is none , a new entry is created and a check made for possible combinations  ( giving rise to new agenda items )  . However , if an appropriate x-isting entry is found , a record is made for that entry of an additional way to produce it  , but no check made for possible combinations . If at the end there is a successful overall analsysis  , its unique identifier , plus the records of what combined to produce what  , can be used to enumerate directly the proof terms for successful analyses  . 
7 Application ~1: Categorial

The associative Lambek calculus ( Lambek ,  1958 ) is perhaps the most familiar representative of the class of categorial formalisms that fall within the ' type-logical'tradition  . Recent work has seen proposals for a range of such systems  , differing in their resource sensitivity ( and hence , implicitly , their underlying notion of ' linguistic structure  '  )  , in some cases combining differing resource sensitivities in one system  , s Many of SSee , for example , the formalisms developed in ( Moortgat et al ,  1994) , ( Morrill ,  1994) , ( Hepple ,  1995) . 
these proposals employ a ' labelled deductive system ' methodology  ( Gabbay ,  1996) , whereby types in proofs are associated with labels which record proof information for use in ensuring correct inferencing  . A natural ' base logic ' on which to construct such systems is the multiplicat-ive fragment of linear logic  , since ( i ) it stands above the various categorial systems in the hierarchy of substructural logics  , and ( ii ) its operators correspond to precisely those appearing in any standard categorial logic  . The key requirement for parsing categorial systems formulated in this way is some theorem proving method that is sufficient for the fragment of linear logic employed  ( although some additional work will be required for managing labels  )  , and a number of different approaches have been used  , e . g . 
proofnets ( Moortgat ,  1992) , and SLD resolution ( Morrill ,  1995) . Hepple ( 1996 ) introduces first-order compilation for implicational linear logic  , and show show that method can be used with labelling as a basis parsing implicational categorial systems  . No further complications arise for combining the extended compilation approach described in this paper with labelling systems as a basis for efficient  , nonredundant parsing of categorial formalisms in the core multiplicative fragment  . See ( Hepple , 1996) for a worked example . 
8 Application ~2: Glue Language
Deduction
In a line of research beginning with Dalrymple et al  ( 1993 )  , a fragment of linear logic is used as a ' glue language ' for assembling sentence meanings for LFG analyses in a ' deductive ' fashion  ( enabling , for example , andirect treatment of quantifier scoping , without need of additional mechanisms ) . Some sample expressions : hates : VX , Y . (s  ~ thates(X,Y )) o-((f . , . , eX ) ?( g "-% Y )) everyone : VH , S . ( H-,-*te very ( person , S )) o-(Vx . (H x ) ) The operator ~ serves to pair together a ' role ' with a meaning expression  ( whose semantic type is shown by a subscript )  , where a ' role ' is essentially a node in a LFG f -structure  . For our purposes roles can be treated as if they were just atomic symbols  . For theorem proving purposes , the universal quantifiers above can be deleted : the uppercase variables can be treatedated under matching during proof construction  ; the lowercase variables can be replaced by arbitrary constants  . Such deletion leaves are sidue that can be treated as just expressions of multiplicative linear logic  , with role/meaning pairs serving as ' basic formulae '  .   9 An observation contrasting the categorial and glue language approaches is that in the categorial case  , all that is required of a deduction is the proof term it returns  , which ( for ' linguistic derivations ' ) provides a ' semantic recipe ' for combining the lexical meanings of initial formulae directly  . However , for the glue language case , given the way that meanings are folded into the logical expressions  , the lexical terms themselves must participate in a proof for the semantics of a LFG derivation to be produced  . 
Here is one way that the first-order compilation approach might be used for glue language deduction  ( other ways are possible )  . Firstly , we can take each ( quantifier-free ) glue term , replace each role/meaning pair with just the role component  , and associate the resulting formula with a unique semantic variable  . The set of formulaes o produced can then undergo the first-order compilation procedure  . Crucially for compilation , although some of the role expressions in the formulae may be  ( ' Prolog-like ' ) variables , they correspond to atomic formulae ( so there is no ' hidden structure ' that compilation cannot address  )  . A complication here is that occurrences of a single role variable may end up in different first-order formulae  . In any overall deduction , the binding of these multiple variable instances must be consistent  , but we cannot rely on a global binding context , since alternative proofs will typically induce distinct  ( but intern-ally consistent ) bindings . Hence , bindings must be handled locally ( i . e . relative to each database formula ) and combinations will involve merging of local binding contexts  . Each proof term that tabular deduction returns corresponds to a natural deduction proof over the precompilation formulae  . If we mechanically mirror this pattern of proof over the original glue terms  ( with meanings , but quantifier-free ) , a role/meaning 9See ( Fry ,  1997) , who uses a proofnet method for glue language deduction  , for relevant discussion . This paper also provides examples of glue language uses that require a full deductive system for the multiplicative fragment  . 
pair that provides a reading of the original LFG derivation will result  . 

Nick Benton , Gavin Bierman , Valeria de Paiva & Martin Hyland .  1992 . ' Term Assignment for Intuitionistic Linear Logic  . ' Tech . Report 262, Cambridge University Computer Lab . 
Mary Dalrymple , John Lamping & Vijay
Saraswat .  1993 . ' LFG semantics via constraints . ' Proc . EACL-6, Utrecht . 
John Fry 1997 . ' Negative Polarity Licensing at the Syntax -Semantics Interface  . ' Proc . 
ACL/EACL-97 Joint Con \]erence , Madrid.
Dov M . Gabbay .  1996 . Labelled deductive systems . Volume 1 . Oxford University Press . 
Mark Hepple . 1992.' Chart Parsing Lambek
Grammars : Modal Extensions and Incrementality ' , Proc . COLING-92 . 
Mark Hepple .  1995 . ' Mixing Modes of Linguistic Description in Categorial Grammar  . '
Proc . EACL-7, Dublin.
Mark Hepple . 1996.' A Compilation-Chart
Method for Linear Categorial Deduction.'
Proc . COLING96, Copenhagen.
Mark Hepple .  1998 . ' Linear Deduction via First-order Compilation . ' Proc . First Workshop on Tabulation in Parsing and Deduction  . 
Esther K Snig .  1994 . ' A Hypothetical Reasoning Algorithm for Linguistic Analysis  . ' Journal of Logic and Computation , Vol . 4, No 1 . 
Joachim Lambek .  1958 . ' The mathematics of sentence structure . ' American Mathematical
Monthly , 65, pp 154-170.
Michael Moortgat .  1992 . ' Labelled deduct-ive systems for categorial theorem proving  . ' Proc . o / Eighth Amsterdam Colloquium , ILLI,
University of Amsterdam.
Michael Moortgat & Richard T . Oehrle . 1994.
' Adjacency , dependency and order . ' Proc . of
Ninth Amsterdam Colloquium.
Glyn Morrill .  1994 . Type Logical Grammar : Categorial Logic of Signs . Kluwer Academic
Publishers , Dordrecht.
Glyn Morrill .  1995 . ' Higher-order Linear Lo-gic Programming of Categorial Deduction  . '
Proc . of EACL-7, Dublin.

