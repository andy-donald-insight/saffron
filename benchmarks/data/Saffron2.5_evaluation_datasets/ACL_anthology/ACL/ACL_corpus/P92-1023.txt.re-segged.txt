GPSM:AGENERALIZED PROBABILISTIC
SEMANTIC MODEL FOR AMBIGUITY RESOLUTION
tJing-Shin Chang , * Yih-Fen Luo and tKeh-Yih Su
tDepartment of Electrical Engineering
National Tsing Hua University
Hsinchu , TAIWAN 30043, R.O.C.
tEmail:shin@ee.nthu.edu.tw,kysu@ee.nthu.edu.tw
* Behavior Design Corporation
No .  28 , 2 F , R&DRoadII , Science-Based Industrial Park
Hsinchu , TAIWAN 30077, R.O.C.

In natural anguage processing , ambiguity resolution is a central issue , and can be regarded as a preference assignment problem  . In this paper , a Generalized Probabilistic Semantic Model ( GPSM ) is proposed for preference computation . An effective semantic tagging procedure is proposed for tagging semantic features  . A semantic score function is derived based on a score function  , which integrates lexical , syntactic and semantic preference under a uniform formulation  . The semantic score measure shows substantial improvement in structural disambiguation over a syntaxbased approach  . 
1. Introduction
In a large natural language processing system , such as a machine translation system ( MTS ) , ambiguity resolution is a critical problem . Various rule-based and probabilistic approaches had been proposed to resolve various kinds of ambiguity problems on a case-by-case basis  . 
In rule-based systems , a large number of rules are used to specify linguistic constraints for resolving ambiguity  . Any parse that violates the semantic constraints iregarded as ungrammatical and rejected  . Unfortunately , because very " rule " tends to have exception and uncertainty  , and ill-formedness has significant contribution to the error rate of a large practical system  , such " hard rejection " approaches fail to deal with these situations  . A better way is to find all possible interpretations and place emphases on preference  , rather than we U-formedness ( e . g . ,\[ Wilks 83\] . ) However , most of the known approaches forgiving preference depend heavily on heuristics such as counting the number of constraint satisfactions  . Therefore , most such preference measures cannot be objectively justified  . Moreover , it is hard and cosily to acquire , verify and maintain the consistency of the large finegrained rule base by hand  . 
Probabilistic approaches greatly relieve the knowledge acquisition problem because they are usually trainable  , consistent and easy to meet certain optimum criteria  . They can also provide more objective preference measures for " soft rejection  . " Hence , they are attractive for a large system . The current probabilistic approaches have a wide coverage including lexical analysis\[DeRose  88  , Church 88\] , syntactic analysis \[ Garside 87 , Fujisaki 89 , Su 88 ,  89 , 91 b \] , restricted semantic analysis \[ Church 89 , Liu 89 ,  90\] , and experimental translation systems \[ Brown 90\]  . However , there is still no integrated approach for modeling the joint effects of lexical  , syntactic and semantic information on preference valuation  . 
A generalized probabilistic semantic model ( GPSM ) will be proposed in this paper to overcome the above problems  . In particular , an integrated formulation for lexical , syntactic and semantic knowledge will be used to derive the semantic score for semantic preference valuation  . 
Application of the model to structural disam-show about  10%-14% improvement of the semantic score measure over a model that uses syntactic information only  . 
2. Preference Assignment Using
ScoreFunction
In general , a particular semantic interpretation of a sentence can be characterized by a set of lexical categories  ( or parts of speech )  , a syntactic structure , and the semantic annotations associated with it . Among the-various interpretations of a sentence , the best choice should be the most probable semantic interpretation for the given input words  . 
In other words , the interpretation that maximizes the following score function \[ Su  88  ,  89 ,   91b \] or analysis score\[Chen 91\] is preferred :
Score(Semi , Sgnj , Lexk , Words ) -- P ( Semi , Synj , Lezkl Words ) = P ( Semil Synj , Lexk , Words ) ? P ( SynII Lexk , Words ) xP ( Lexkl Words )   ( 1 )   ( semantic score )   ( syntactic score )   ( lexical score ) where ( Lex , , Synj , Semi ) refers to the kth set of lexical categories , the jth syntactic structure and the ith set of semantic annotations for the input Words  . The three component functions are referred to as semantic score  ( Ssem )  , syntactic score ( Ssyn ) and lexical score ( Stex )  , respectively . The global preference measure will be referred to as compositional score or simply as score  . In particular , the semantic score accounts for the semantic preference on a given set of lexical categories and a particular syntactic structure for the sentence  . 
Various formulation for the lexical score and syntactic score had been studied extensively in our previous works\[Su  88  ,  89 , 91b , Chiang92\] and other literatures . Hence , we will concentrate on the formulation for semantic score  . 
3. Semantic Tagging
Canonical Form of Semantic

Given the formulation in Eqn .  (1) , first we will show how to extract heab stract objects  ( Semi , Synj , LexD from a semantic representation . In general , a particular interpretation of a sentence can be represented by an annotated syntax tree  ( AST )  , which is a syntax tree annotated with feature structures in the tree nodes  . Figure 1 shows an example of AST . The annotated version of a node A is denoted as A = A\[fa\]in the figure  , where fA is the feature structure associated with node A  . Because an AST preserves both syntactic and semantic information  , it can be converted to other deep structure representations easily  . Therefore , without lose of generality , the AST representation will be used as the canonical form of semantic representation for preference valuation  . The techniques used here , of course , can be applied to other deep structure representations as well  . 
A\[~\]//-..<
B\[fB\]C\[fc\]
D\[fD\]E\[fE\]F\[fF\]G\[fc\]
CIC2C3C4(wl ) ( w3) ( w4)
L s = A
L 7= B , C
L ~= B , F , G
Ls = B,F,c4
L4=B,c3, c4
L3=D , E , c3, ca
L2=D , c2, c3, c4
L1 = Cl , C2, C3, C4
Figure 1 . Annotated Syntax Tree ( AST ) and Phrase Levels ( PL )  . 
The hierarchical AST can be represented by a set of phrase levels  , such as L\]throughL8 in Figure 1 . Formally , a phrase level ( PL ) is a set of symbols corresponding to a sentential form of the sentence  . The phrase levels in Figure 1 are derived from a sequence of rightmost derivations  , which is commonly used in an LR parsing mechanism  . For example ,  1- , 5 and L4 correspond to the rightmost derivation BFC a ~+ B  c3   c4  . No term that the first phrase level L\] consists of all lexical categories cl  . . . cn of the terminal words ( wl . . . 
w , , ) . A phrase level with each symbol annotated with its feature structure is called an annotated phrase level  ( APL )  . The ith APL is denoted as Fi . For example ,   L5 in Figure 1 has an annotated phrase level F5 = B\[fB\] , F\[fF\] , c4\[fc , \] as its lexical category c4 , which comes from the lexical item of the 4th word w4  . With the above notations , the score function can be reformulated as follows: 
Score(Semi , Synj , Lexk , Words ) - P(FT , L7 , c ~ I , o7) nn = P ( r~nIL~n , c1 , wl ) xP ( LT'Ic , wDxP ( c , \[ w1 )   ( 2 )   ( semantic score )   ( syntactic score )   ( lexical score ) where c\]" ( a short form for cl . . . c , ,) is the kth set of lexical categories ( Lexk ) ,  /- , 1"(L\] . . . 
Lr , ,) is the jth syntactic structure ( Synj ) , and rlm(F1 . . . Fro ) is the ith set of semantic annotations ( Semi ) for the input words wl " ( wl . . . wn ) . A good encoding scheme for the Fi's will allow us to take semantic information into account without using redundant information  . Hence , we will show how to annotate a syntax trees o that various interpretations can be characterized differently  . 
Semantic Tagging
A popular linguistic approach to annotate a tree is to use a unification-based mechanism  . However , many information irrelevant to disambiguation might be included  . An effective encoding scheme should be simple yet can preserve most discrimination information for disambiguation  . Such an encoding scheme can be accomplished by associating each phrase structure rule A--+  X1X2  .   .   . XM with a head list ( Xi ,, Xi, .   .   . XiM ) . The headlist is formed by arranging the children nodes  ( X 1 , X2 ,   .   .   .   , XM ) in descending order of importance to the compositional semantics of their mother node A  . For this reason , Xi  ~ , Xi ~ and Xi , are called the primary , secondary and the jth heads of A , respectively . 
The compositional semantic features of the mother node A can be represented as an ordered list of the feature structures of its children  , where the order is the same as in the headlist . For example , for S~NP VP , we have a head list ( VP , NP ) , because VP is the ( primary ) head of the sentence . 
When composing the compositional semantics of S , the features of VP and NP will be placed in the first and second slots of the feature structure of S  , respectively . 
Because not all children and all features in a feature structure amequally significant for disambiguation  , it is not really necessary to annotate a node with the feature structures of all its children  . Instead , only the most important N children of a node is needed in characterizing the node  , and only the most discriminative fature of a child is needed to be passed to its mother node  . 
In other words , an N-dimensional feature vector , called a semantic N-tuple , could be used to characterize a node without losing much information for disambiguation  . The first feature in the semantic N-tuple comes from the primary head  , and is thus called the head feature of the semantic N-tuple  . The other features come from the other children in the order of the head list  .   ( Compare these notions with the linguistic sense of head and head feature  . ) An annotated node can thus be approximated as A , ~ A(fl , f2 ,   .   .   .   , fN ) , where fj = HeadFeature X ~7 ~ , ~ ) is the ( primary ) head feature of its jth head ( i . e . , Xij ) in the head list . 
Non-head features of a child node Xij will not be percolated up to its mother node  . The head feature of ~ itself , in this case , is fx . For a terminal node , the head feature will be the semantic tag of the corresponding lexical item  ; other features in the N-tuple will be tagged as ~ b  ( NULL )  . 
Figure 2 shows two possible annotated syntax trees for the sentence "  . . . saw the boy in the park . " For instance , the " loc ( ation ) " feature of " park " is percolated to its mother NP node as the head feature  ; it then serves as the secondary head feature of its grandmother node PP  , because the NP node is the secondary head of PP . Similarly , the VP node in the left tree is annotated as VP ( sta , anim ) according to its primary heads aw(sta , q ~) and secondary head NP ( anim , in) . 
The VP ( sta , in ) node in the fight tree is tagged if-ferently , which reflects different attachment preference of the prepositional phrase  . 
By this simple mechanism , the major characteristics of the children , namely the head features , can be percolated to higher syntactic levels , and
SS def . " definite article .  ~  .  ~ ~ ~  . loc : location anim : animate ? t ( a-hlLz-h2 )  ~~ ( ~- hl , ~-h2) ot(?X-hl~t~sta , in ~ . ._ ~(~-- h~ , ~-h ~) NP~f ~-~) saw(:ta:(~d)e ~: , ~) in ( in ~ , def ) the ( def ' ~ , ?) boy(-y~(~m , ?) in ( in , ~) ~ the(def#)/#)~p ~ par~Nk(loc , ?) the ( def , t ~) park(loc#) Figure 2 . Ambiguous PP attachment patterns annotated with semantic  2-tuples  . 
their correlation and dependency an be taken into account in preference evaluation even if they are far apart  . In this way , different interpretations will be tagged ifferently  . The preference on a particular interpretation can thus be evaluated from the distribution of the annotated syntax trees  . Based on the above semantic tagging scheme , a semantic score will be proposed to evaluate the semantic preference on various interpretations for a sentence  . Its performance improvement over syntactic score \[ Su  88  ,  89 , 91 b \] will be investigated . 
Consequently , a brief review of the syntactic score evaluation method is given beforegoing into details of the semantic score model  . ( See the cited references for details . ) 4 . Syntactic Score According to Eqn .  (2) , the syntactic score can be formulated as follows \[ Su  88  ,  89 , 91b \]: S , y , , =_ P(SynilLeZk , W ' ~) = P ( L'~lc ' ~ , w ~) (3) fti = HP ( Ltl L~-' , c  ~ , w~)1 = 21-IP(L , IL ' , -') ~" IIP ( L'IL'-') = HP(o~t , A , , /3 , Io , , ,  ~' , ) under which the derivation At=~X1X2 .   .   . XM occurs . ( Assume that Lt = at , At , fit and LI-1 = at , X1 , ""  , XM , fil . ) If L left context symbols in al and R right context symbols in fit are consulted to evaluate the syntactic score  , it is said to operate in LLRR mode of operation . When the context is ignored , such an LoRo mode of operation reduces to a stochastic contextfree grammar  . 
To avoid the normalization problem \[ Su 91b \] arisen from different number of transition probabilities for different syntax trees  , an alternative formulation of the syntactic score is to evaluate the transition probabilities between configuration changes of the parser  . For instance , the configuration of an LR parser is defined by its stack contents and input buffer  . For the AST in Figure 1 , the parser configurations after the read of cl , c2 , c3 , c4 and $( end-of-sentence ) are equivalent to L1 , L2 , L4 ,  1- . 5 and Ls , respectively . Therefore , the syntactic score can be approximated as \[ Su 89  , 91 b \]:
S , vn ~ P ( Ls , LT ' " L2IL , ) (4)
P ( LslL  ~ ) xP ( LsIL4 ) xP ( L41L2 ) xP ( L21L1 ) In this way , the number of transition probabilities in the syntactic scores of all AST's will be kept the same as the sentence lngth  . 
5. Semantic Score
Semantic score evaluation is similar to syntactic score evaluation  . From Eqn .  (2) , we have the following semantic model for semantic score : 
S , em(Semi , Synj , Lex ~: , Words ) = p(p ~ nILT , c  ~ , w ~) mI--1 r an n = I "\ [ P ( F , IF1 , L 1 , Cl , Wl ) (5) 1=21"IP(r , lr , _l ) = where 3~j am the semantic tags from the children of A1  . For example , we have terms like e(VP ( sta , anim)\[a , VP ~- vNP , fl ) and P ( VP(sta , in ) la , Ve~v NP PP , fl) , respec-fively , for the left and right trees in Figure 2 . The annotations of the context amignored in evaluating Eqn  .   ( 6 ) due to the assumption of semantics compositionality  . The operation mode will be called LLRR+Alv , where N is the dimension of the N-tuple , and the subscript L ( or R ) refers to the size of the context window . With an appropriate N , the score will provide sufficient discrimination power for general disambiguation problem without resorting to full-blown semantic analysis  . 
where At = At(ft , l , fln, .   .   .   , fuv ) is the annotated version of At , whose semantic N-tuple is ( fl , 1 , fl , 2 , -" , f t , N ) , and 57 , fit are the annotated context symbols . Only Ft . 1 is assumed to be significant for the transition to F t in the last equation  , because all required information is assumed to have been percolated to Ft-j through semantics composition  . 
Each term in Eqn .   ( 5 ) can be interpreted as the probability that At is annotated with the particular set of head features  ( fs , 1 , f t , 2  ,   .   .   . , fI , N ), given that X1 . . . XM are reduced to At in the context of a7 and fit . So it can be interpreted informally as P ( At(fl , 1 , f t , 2 ,   .   .   . , fz~v)IAi ~ X1 .   .   . XM , in the context of ~-7, fit) . It corresponds to the semantic preference assigned to the annotated node At " Since  ( 11 , 1 , fl , ~ , "" ft , N ) are the head features from various heads of the substructures of A  , each term reflects the feature cooccurrence preference among these heads  . Furthermore , the heads could be very far apart . This is different from most simple Markov models , which can deal with local constraints only . Hence , such a formulation well characterizes long distance dependency among the heads  , and provides a simple mechanism to incorporate the feature cooccurrence preference among them  . For the semantic N-tuple model , the semantic score can thus be expressed as follows: 
S  ~ . ~(6) m"~I-\[P ( A*(ft , , , f , ,2 " " " ft , N ) la ,   , A ,   , -- Xl "" gM , /~ l ) l = 2
Semantic Features
As mentioned before , not all constituents are equally important for disambiguation  . For instance , head words are usually more important than modifiers in determining the compositional semantic features of their mother node  . There is also lots of redundancy in a sentence . For instance , " saw boy in park " is equally recognizable as " saw the boy in the park  . " Therefore , only a few categories , including verbs , nouns , adjectives , prepositions and adverbs and their projections ( NP , VP , AP , PP , ADVP ) , are used to carry semantic features for disambiguation  . These categories are roughly equivalent to the major categories in linguistic theory \[ Sells  85\] with the inclusion of adverbs as the only difference  . 
The semantic feature of each major category is encoded with a set of semantic tags that well describes each category  . A few rules of thumb are used to select he semantic tags  . In particular , semantic features that can discriminate different linguistic behavior from different possible semantic N-tuples are preferred as the semantic tags  . 
With these heuristics in mind , the verbs , nouns , adjectives , adverbs and prepositions are divided into 22 ,  30 ,  14 , 10 and 28 classes , respectively . 
For example , the nouns are divided into " human , "" plant , " time , " space , " and so on . These semantic classes come from a number of sources and the semantic attribute hierarchy of the ArchTran 
MTS\[Su90, Chen91\].
Table 1 . Close Test of Semantic Score 7 . Test and Analysis The semantic N-tuple model is used to test the improvement of the semantic score over syntactic score in structure disambiguation  . Eqn .   ( 3 ) is adopted to evaluate the syntactic score in L2RI mode of operation . The semantic score is derived from Eqn . (6) in L2R~+AN mode , for N = 1 ,  2 ,  3 ,  4 , where N is the dimension of the semantic

A total of 1000 sentences ( including 3 unambiguous ones ) are randomly selected from 14 computer manuals for training or testing . They are divided into 10 parts ; each part contains 100 sentences . In close tests ,   9 parts are used both as the training set and the testing set  . In open tests , the rotation estimation approach \ [ Devijver 82\] is adopted to estimate the open test performance . This means to iteratively test one part of the sentences while using the remaining parts as the training set  . The overall performance is then estimated as the average performance of the  10 iterations . 
The performance is evaluated in terms of TopN recognition rate  ( TNRR )  , which is defined as the fraction of the test sentences whose preferred interpretation is successfully ranked in the first N candidates  . Table 1 shows the simulation re-suits of close tests . Table 2 shows partial results for open tests ( up to rank 5 . ) The recognition rates achieved by considering syntactic score only and semantic score only are shown in the tables  . 
( L2RI+A3 and L2RI+A4 performance are the same as L2R~+A2 in the presentest environment . So they are not shown in the tables . ) Since each sentence has about 7075 ambiguous constructs on the average , the task perplexity of the current disambiguation task is high  . 

Rank ( L2R1) ( L2RI+A1) ( L2RI+A2)
Count TNRR (%)
Count TNRR (%) 87 . 07 872 98 . 33 20 99 . 33 5 99 . 89 100 . 00 97 . 21 866 99 . 44 24 100 . 00 4
Count TNRR (%) 96.54 99.22 99.67 99.89 100.00
Data Base : 900 Sentences
TestSet : 897 Sentences
Total Number of Ambiguous Trees = 63233 ( * ) TNRR : Top N Recognition Rate
Table 2. Open Test of Semantic Score
Score Syntax ( L2R1)
Rank Count TNRR (%) 1430 43 . 132 23266 A039475 . 83 4 80 83 . 85 5 35 87 . 36
Semantics ( L2RI+A1)
Count TNRR ! (%) 569 57 . 07 163 73 . 42 90 82 . 45 50 87 . 46 22 89 . 67
Semantics ( L2RI+A2)
Count TNRR (%) 578 57 . 97 167 74 . 72 75 82 . 25 49 87 . 16 28 89 . 97
Data Base : 900 Sentences (+)
TestSet : 997 Sentences (++)
Total Number of Ambiguous Trees = 75339 ( + ) Data Base : effective database size for rotation estimation  ( ++ ) TestSet : all test sentences participating the rotation estimation test for syntactic score  ( 87% ) is quite satisfactory . 
When semantic score is taken into account , substantial improvement in recognition rate can be observed further  ( 97% )  . This shows that the semantic model does provide an effective mechanism for disambiguation  . The recognition rates in open tests , however , are less satisfactory under the presentest environment  . The open test performance can be attributed to the small database size and the estimation error of the parameters thus introduced  . Because the training database is small with respect to the complexity of the model  , a significant fraction of the probability entries in the testing set cannot be found in the training set  . 
As a result , the parameters are somewhat " over-tuned " to the training database  , and their values are less favorable for open tests  . Nevertheless , in both close tests and open tests , the semantic score model shows substantial improvement over syntactic score  ( and hence stochastic on text-free grammar )  . The improvement is about 10% for close tests and 14% for open tests . 
In general , by using a larger database and better robust estimation techniques \[ Su  91a   , Chiang 92\] , the baseline model can be improved further . 
As we had observed from other experiments for spoken language processing \[ Su  91a  \] , lexical tagging , and structure disambiguation \[ chiang92\] , the performance undersparse data condition can be improved significantly if robust adaptive leam -ing techniques are used to adjus the initial parameters  . Interested readers are referred to \[ Su91a,
Chiang92\] for more details.
8. Concluding Remarks
In this paper , a generalized probabilistic semantic model ( GPSM ) is proposed to assign semantic preference to ambiguous interpretations  . The semantic model for measuring preference is based on a score function  , which takes lexical , syntactic and semantic information into consideration and optimizes the joint preference  . A simple yet effective encoding scheme and semantic tagging procedure is proposed to characterize various interpret a-encoding scheme  , one can encode the interpretations with discriminative fatures  , and take the feature cooccurrence preference among various constituents into account  . Unlike simple Markov models , long distance dependency can be managed easily in the proposed model  . Preliminary tests show substantial improvement of the semantic score measure over syntactic score measure  . 
Hence , it shows the possibility to overcome the ambiguity resolution problem without resorting to full-blown semantic analysis  . 
With such a simple , objective and trainable formulation , it is possible to take high level semantic knowledge into consideration i statistic sense  . It also provides a systematic way to construct a disambiguation module for large practical machine translation systems without much human intervention  ; the heavy burden for the linguists to write finegrained " rules " can thus be relieved  . 
REFERENCES\[Brown90\] Brown , P . et al , " A Statistical Approach to Machine Translation , " Computational Linguistics , vol . 16, no . 2, pp . 79-85, June 1990 . 
\[ Chen91\]Chen , S . -C . , J . -S . Chang , J . -N . Wang and K . -Y . Su , " Arch Tran : A Corpus-Based Statistics-Oriented English Chinese Machine Translation System  , " Proceedings of Machine Translation Summit 11I , pp . 33-40, Washington , D . C . , USA , July 14, 1991 . 
\[Chiang92\]Chiang,T . -H . , Y . -C . Lin and K . -Y . 
Su , " Syntactic Ambiguity Resolution Using A Discrimination and Robustness Oriented Adaptive Leaming Algorithm "  , to appear in Proceedings of COLING-92 , 14th Int . Conference on Computational Linguistics , Nantes , France , 2028 July ,  1992 . 
\[Church88\]Church , K . , " A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text  , " ACL Proc . 2nd Conf . on Applied Natural Language Processing , pp . 136143, Austin,
Texas , USA , 912 Feb . 1988.
\[Church89\]Church , K . and P . Hanks , " Word Association Norms , Mutual Information , and Lexicography , " Proc . 27th Annual Meeting of the ACL , pp .  76-83 , University of British Columbia , Vancouver , British Columbia , Canada , 26-29 June 1989 . 
\[DeRose88\]DeRose , Stever LJ . , " Grammatical Category Disambiguation by Statistical Optimization  , " Computational Linguistics , vol . 14, no . 1, pp .  31-39, 1988 . 
\ [ Devijver82\]Devijver , P . A . , and J . Kittler , Pattern Recognition : A Statistical Approach , 
Prentice-Hall , London , 1982.
\[ Fujisaki89\]Fujisaki , T . , F . Jelinek , J . Cocke , E . 
Black and T . Nishino , "A Probabilistic Parsing Method for Sentence Disambiguation  , " Proc . of Int . Workshop on Parsing Technologies ( IWPT-89), pp . 85-94, CMU , Pittsburgh , PA , U . S . A . , 28-31 August 1989 . 
\[Garside87\]Garside , Roger , Geoffrey Leech and Geoffrey Sampson ( eds . ) , The Computational Analysis of English : A Corpus -Based Approach  , 
Longman Inc ., New York , 1987.
\[Liu89\]Liu , C . -L . , On the Resolution of English PP Attachment Problem with a Probabilistic Semantic Model  , Master Thesis , National Tsing Hua University , Hsinchu , TAIWAN , R . O . C . , 1989 . 
\[Liu 90\] Liu , C . -L , J . -S . Chang and K . -Y . Su , " The Semantic Score Approach to the Disambiguation of PP Attachment Problem  , " Proc . of ? ROCLING-III , pp . 253-270, Taipei , R . O . C . ,
September 1990.
\ [ Sells 85\] Sells , Peter , Lectures On Contemporary Syntactic Theories : An Introduction to Government-Binding Theory  , Generalized Phrase Structure Grammar , and Lexical-Functional Grammar , CSLI Lecture Notes Number 3 , Center for the Study of Language and Information , Lel and Stanford Junior University . , 1985 . 
\[ Su88\]Su , K . -Y . and J . -S . Chang , " Semantic and Syntactic Aspects of Score Function  , " Proc . of COLING-88, vol . 2, pp . 642-644, 12th Int . 
Conf . on Computational Linguistics , Budapest,
Hungary , 2227 August 1988.
\[ Su89\]Su , K . -Y . , J . -N . Wang , M . -H . Su and J . -S . 
Chang , " A Sequential Truncation Parsing Algorithm Based on the Score Function  , " Proc . of Int . Workshop on Parsing Technologies ( IWPT-89), pp . 95-104, CMU , Pittsburgh , PA , U . S . A . , 28-31 August 1989 . 
\[ Su90\]Su , K . -Y . and J . -S . Chang , "Some Key Issues in Designing MT Systems , " Machine Translation , vol . 5, no . 4, pp .  265-300, 1990 . 
\[ Su91a \] Su , K . -Y . , and C . -H . Lee , " Robusmess and Discrimination Oriented Speech Recognition Using Weighted HMM and Subspace Projection Approach  , " Proceedings of IEEE ICASSP-91 , vol . 1, pp . 541-544, Toronto , Ontario , Canada . May 1417, 1991 . 
\[ Su91b\]Su , K . -Y . , J . -N . Wang , M . -H . Su , and J . -S . Chang , " GLR Parsing with Scoring " . In M . 
Tomita ( ed . ), Generalized LR Parsing , Chapter 7, pp . 93-112, Kluwer Academic Publishers , 1991 . 
\[ Wilks 83\] Wilks , Y . A . , " Preference Semantics , Ul-Formedness , and Metaphor , " AJCL , vol . 9, no . 34, pp . 178-187, July-Dec .  1983 . 

