Analysis System of Speech Acts and Discourse Structures Using 
Maximum Entropy Model *
Won Seug Choi , Jeong-Mi Cho and Jungyun Seo
Dept . of Computer Science , Sogang University
Sinsu-dong 1, Mapo-gu
Seoul , Korea , 121-742
dolhana , jmcho@nl prep . sogang . ac . kr , seojy@ccs . sogang . ac . kr

We propose a statistical dialogue analysis model to determine discourse structures as well as speech acts using maximum entropy model  . The model can automatically acquire probabilistic discourse knowledge from a discourse tagged corpus to resolve ambiguities  . We propose the idea of tagging discourse segment boundaries to represent the structural information of discourse  . 
Using this representation we can effectively combine speech act analysis and discourse structure analysis in one framework  . 

To understand a natural language dialogue , a computer system must be sensitive to the speaker's intentions indicated through utterances  . 
Since identifying the speech acts of utterances i very important to identify speaker's intentions  , it is an essential part of a dialogue analysis ystem  . 
It is difficult , however , to infer the speech act from a surface utterance since an utterance may represent more than one speech act according to the context  . Most works done in the past on the dialogue analysis has analyzed speech acts based on knowledge such as recipes for plan inference and domain specific knowledge  ( Litman ( 1987 )  , Caberry (1989) , Hinkelman (1990) , Lambert (1991) , Lambert (1993) , Lee (1998)) . Since these knowledge-based models depend on costly handcrafted knowledge  , these models are difficult to be scaled up and expanded to other domains  . 
Recently , machine learning models using a discourse tagged corpus are utilized to analyze speech acts in order to overcome such problems  ( Nagata ( 1994a )  , Nagata (1994b ) , Reithinger (1997) , Lee (1997) , Samuel (1998)) . Machine learning offers promise as a means of associating features of utterances with particular speech acts  , since computers can automatically analyze large quantities of data and consider many different feature interactions  . These models are based on the features such as cue phrases  , change of speaker , short utterances , utterance length , speech acts tag ngrams , and word ngrams , etc . Especially , in many cases , the speech act of an utterance influenced by the context of the utterance  , i . e . , previous utterances . 
So it is very important o reflect the information about he contex to the model  . 
Discourse structures of dialogues are usually represented as hierarchical structures  , which reflect embedding subdialogues ( Grosz ( 1986 ) ) and provide very useful context for speech act analysis  . For example , utterance 7 in Figure 1 has several surface speech acts such as acknowledge  , inform , and response . Such an ambiguity can be solved by analyzing the context  . If we consider then utterances linearly adjacent outterance  7  , i . e . , utterances 6, 5, etc . , as context , we will get acknowledge or in form with high probabilities as the speech act of utterance  7  . However , as shown in Figure 1 , utterance 7 is a response utterance to utterance 2 that is hierarchically recent to utterance 7 according to the discourse structure of the dialogue  . If we know the discourse structure of the dialogue  , we can determine the speech act of utterance 7 as response . 
* This work was supported by KOSEF under the contract  97-0102-0301-3  . 

Some researchers have used the structural information of discourse to the speech act analysis  ( Lee ( 1997 )  , Lee (1998)) . It is not , however , enough to cover various dialogues since they used a restricted rule-based model such as RDTN  ( Recursive Dialogue Transition Networks ) for discourse structure analysis . Most of the previous related works , to our knowledge , tried to determine the speech act of an utterance  , but did not mention about statistical models to determine the discourse structure of a dialogue  . 
I ) User : I would like Io reserve a room.
2 ) Agent : What kind of room do you want ?3 ) User : What kind of room do you have '?4 ) Agent : We have single mid double rooms . 
5 ) User : How much are those rooms ? 6 ) Agent : Single costs 30 , 000 won and double ~ SlS 40 , 000 WOll . 
7) User : A single room . please.
request ask-refask-ref response ask-telresponse acknowledge in form r ~ mmse Figure  1 : An example of a dialogue with speech acts In this paper  , we propose a dialogue analysis model to determine both the speech acts of utterances and the discourse structure of a dialogue using maximum entropy model  . In the proposed model , the speech act analysis and the discourse structure analysis are combined in one framework so that they can easily provide feedback to each other  . For the discourse structure analysis , we suggest a statistical model with discourse segment boundaries  ( DSBs ) similar to the idea of gaps suggested for a statistical parsing  ( Collins ( 1996 ) ) . For training , we use a corpus tagged with various discourse knowledge  . To overcome the problem of data sparseness , which is common for corpus-based works , we use split partial context as well as whole context  . 
After explaining the tagged dialogue corpus we used in section  1  , we discuss the statistical models in detail in section  2  . In section 3, we explain experimental results . Finally , we conclude in section 4 . 
1 Discourse tagging
In this paper , we use Korean dialogue corpus transcribed from recordings in real fields such as hotel reservation  , airline reservation and tour reservation . This corpus consists of 528 dialogues ,  10 , 285 utterances (19 . 48 utterances per dialogue ) . Each utterance in dialogues is manually annotated with discourse knowledge such as speaker  ( SP )  , syntactic pattern ( ST ) , speech acts ( SA ) and discourse structure ( DS ) information . Figure 2 shows a part of the annotated dialogue corpus ~ . SP has a value either " User " or " Agent " depending on the speaker  . 
/SPAJ ser/ENh'ma student and registered/bra language course at University of Georgia in 

ISTl\[decl , be , present , no , none , none\]/SA/introducing-oneself / DS/\[2I /SP/User ~9_  . 
/EN/I have sa ) me questions about lodgings.
IST/Idecl,paa . presenl , no , none , none l/SA/ask-ref ~ DS/121 --> Continue/SP/Agent/EN/There is adormitory in Universily of 
Georgialot language course students.
ISTIIdecl . pvg,present,no,none . none\]/SA/response / DS/\[21 /SPAJ ser/EN frhen , is meal included intuilion lee?/ST/?yn quest . pvg , present . no . none , then I/SA/ask-if/DS/12 . II Figure 2: A part of the annotated dialogue corpus The syntactic pattern consists of the selected syntactic features of an utterance  , which approximate the utterance . In a real dialogue , a speaker can express identical contents with different surface utterances according to a person a linguistic sense  . The syntactic pattern generalizes these surface utterances using syntactic features  . The syntactic pattern used in ( Lee ( 1997 ) ) consists of four syntactic features such as Sentence Type  , Main-Verb , Aux-Verb and Clue-Word because these features provide strong cues to infer speech acts  . We add two more syntactic features , Tense and Negative Sentence , to the syntactic pattern and elaborate the values of the syntactic features  . Table 1 shows the syntactic features of a syntactic pattern with possible values  . The syntactic features are automatically extracted from the corpus using a conventional parser  ( Kim ( 1994 ) ) . 
Manual tagging of speech acts and discourse structure information was done by graduate students majoring in dialogue analysis and postprocessed for consistency  . The classification of speech acts is very subjective without an agreed criterion  . In this paper , we classified the 17 types of speech acts that appear in the dialogue KS represents the Korean sentence and EN represent she translated English sentence  . 
231 corpus . Table 2 shows the distribution of speech acts in the tagge dialogue corpus  . 
Discourse structures are determined by focusing on the subject of current dialogue and are hierarchically constructed according to the subject  . Discourse structure information tagged in the corpus is an index that represents the hierarchical structure of discourse reflecting the depth of the indentation of discourse segments  . 
The proposed system transforms this index information to discourse segment boundary  ( DSB ) information to acquire various statistical information  . In section 2 . 2 . 1, we will describe the DSBs in detail . 
Syntactic feature Values decl , imperative , wh question , yn_question

Sentence T ) ~ e The mood of all utterance pvg , pvd , paa , pad , be , The type of the main verb . For Main-Verb know , ask , etc . special verbs , lexical items are ( total 88 kinds ) used . 
Tensepast , present , future . The tense of an utterance Negative Sentence Yes or NoYes if an utterance is negative  . 
serve , seem , want , will , The modality of an utterance . 
Aux-Verb etc . ( total 31 kinds )
Yes , No , OK . , etc . The special word used in the utterance having particular Clue-Word  ( total 26 kinds speech acts . 
Table I : Syntactic features used in the syntactic pattern 
Speech Act Type Ratio (%)
Accept 2.49
Acknowledge 5.75
Ask-confirm 3.16
Ask-if 5.36
Ask-tel 13.39
Closing 3.39
Correct 0.03
Expressive 5,64 biform 11.90
Speech Act Type Ratio (%) h~troducing-one self 6.75
Offer 0.40
Opening 6.58
Promise 2, 42
Reject 1.07
Request 4.96
Response 24.73
Suggest 1.98
Total 10 0.00
Table 2: The distribution of speech acts in corpus 2 Statistical models We construct wo statistical models : one for speech act analysis and the other for discourse structure analysis  . We integrate the two models using maximum entropy model  . In the following subsections , we describe these models in detail . 
2.1 Speech act analysis model
Let UI , , denote a dialogue which consists of a sequence of n utterances  , U 1 , U2 . . . . . U , , and let Si denote the speech act of U . With these notations , P ( SilU1 , i ) means the probability that S~becomes the speech act of utterance U~given a sequence of utterances  U1  , U2 ,  . .  . , Ui . 
We can approximate the probability
P ( SiIUl . i ) by the product of the sentential probability P ( Ui ISi ) and the contextual probability P ( Si IUI , i-i ,  $1 ,  ~ - 1) . Also we can approximate P ( Sil Ul , i-l , Si , i-i ) by P ( Sil SI , g-l ) ( Charniak (1993)) . 
P ( S~IUI , ~) = P ( SilS ~ , ~- I ) P ( U ~ I Si )   ( 1 ) It has been widely believed that there is a strong relation between the speaker'speech act and the surface utterances expressing that speech act  ( Hinkelman ( 1989 )  , Andernach (1996)) . That is , the speaker utters a sentence , which most well expresses his/her intention ( speech act ) so that the hearer can easily infer what the speaker's speech act is  . The sentential probability P ( UilSO represents the relationship between the speech acts and the features of surface sentences  . Therefore , we approximate the sentential probability using the syntactic pattern 

P ( UiISi ) = P ( PiISi ) (2)
The contextual probability P ( SiI $ 1 ,  ~ - 1 ) is the probability that utterance with speech act Si is uttered given that utterances with speech act  $1  ,  $2  . . . . . S/-1 were previously uttered . Since it is impossible to consider all preceding utterances  $1  ,  $2  . . . . . Si-~as contextual information , we use the ngram model . 
Generally , dialogues have a hierarchical discourse structure  . So we approximate the context as speech acts of n utterances that are hierarchically recent to the utterance  . An utterance A is hierarchically recent to an utterance B if A is adjacento B in the tree structure of the discourse  ( Walker ( 1996 ) ) . 
Equation ( 3 ) represents the approximated contextual probability in the case of using trigram where Uj and U ~ are hierarchically recent to the utterance U  , where l < j < k < i-1 . 

P ( SiIS\],,-,) = P ( SiISj , Sk ) (3)
As a result , the statistical model for speech act analysis is represented in equation  ( 4 )  . 
P ( S , IU , , 0 = P(Si I S , , ,  -  , ) P ( Ui IS , ) = P ( Si ISj , Sk)P ( Pi\[St ) (4) 2 . 2 Discourse structure analysis model 2 . 2 . 1 Discourse segment boundary tagging We define a set of discourse segment boundaries  ( DSBs ) as the markers for discourse structure tagging . ADSB represents the relationship between two consecutive utterances in a dialogue  . Table 3 shows DSBs and their meanings , and Figure 3 shows an example of
DSB tagge dialogue.
DSB Meaning
DEStart a new dialogue
DC Continue a dialogue
SSStart a subdialoguenEEndn level subdialogues nBnE and then SS 
Table 3: DSBs and their meanings
DSDSB1) User : I would like to reserve a room . INULL2 ) Agent : What kind of room do you want ?1 . 1 SS3) User : What kind of room do you have ?1 . 1 . 1 SS4) Agent : We have single and double rooms .  1 . 1 . 1 DC5) User : How much are those rooms ? 1 . ! . 2 IB6) Agent : Single costs 30 , 000 won and double costs 40 , 000 won .  1 . 1 . 2 DC7) User : A single room , please . I .   1   1E Figure 3: An example of DSB tagging Since the DSB of an utterance represents a relationship between the utterance and the previous utterance  , the DSB of utterance 1 in the example dialogue becomes NULL . By comparing utterance 2 with utterance 1 in Figure 3  , we know that a new subdialogue starts at utterance  2  . Therefore the DSB of utterance 2 becomes SS . Similarly , the DSB of utterance 3 is SS . Since utterance 4 is a response for utterance 3 , utterance 3 and 4 belong to the same discourse segment . So the DSB of utterance 4 becomes DC . Since a subdialogue of one level ( i . e . , the DS1 . 1 . 2) consisting of utterances 3 and 4 ends , and new subdialogue starts at utterance 5 . Therefore , the DSB of utterance 5 becomes lB . Finally , utterance 7 is a response for utterance2 , i . e . , the subdialogue consisting of utterances 5 and 6 ends and the segment 1  . 1 is resumed . Therefore the DSB of utterance 7 becomes 1E . 
2 . 2 . 2 Statistical model for discourse structure analysis We construct a statistical model for discourse structure analysis using DSBs  . In the training phase , the model transforms discourse structure ( DS ) information in the corpus into DSBs by comparing the DS information of an utterance with that of the previous utterance  . After transformation , we estimate probabilities for DSBs . In the analyzing process , the goal of the system is simply determining the DSB of a current utterance using the probabilities  . Now we describe the model in detail . 
Let G , denote the DSB of U , . With this notation , P ( Gil U\] , O means the probability that G/becomes the DSB of utterance U~given a sequence of utterances U  ~  , U2 . . . . . U i . As shown in the equation (5) , we can approximate P ( GilU ~ , O by the product of the sentential probability P ( UiIGi ) and the contextual probability P ( GiIU\] , i-\] . GI , i-\]):
P ( GilU1 , i ) = P ( GiIU\] , i-\] , Gi , i-OP ( UiIGi )   ( 5 ) In order to analyze discourse structure , we consider the speech act of each corresponding utterance  . Thus we can approximate each utterance by the corresponding speech act in the sentential probability P  ( UiIGi ) :
P ( UiIG0---P ( SilGO (6) to simplify notations :
Fi ::-( Si , Gi ) (7)
We can approximate the contextual probability P ( Gil Ul . i-i,G l . i-l ) as equation ( 8 ) in the case of using trigram . 
P ( GiIUl , i-l , Gl , i 1) = P ( GiIFI , i-1) = P ( GiIFi-2 , Fi-l ) (8) As a result , the statistical model for the discourse structure analysis is represented as equation  ( 9 )  . 
P ( Gi IUI . i ) = P ( GiIUl . i-i,G l . i-OP(UiIG i ) = P ( G , IF~-2 , F , -OP ( & IGO(9) 2 . 3 Integrated ialogue analysis model Given a dialogue UI  ,   .   , P ( Si , GiIUl , i ) means the probability that S ~ and G i will be , respectively , the speech act and the DSB of an utterance U/ given a sequence of utterances Ut  , U2 . . . . . U  ~ . By using a chain rule , we can rewrite the probability as in equation ( 10 )  . 
P ( Si , GiIUI , i ) = P ( Si IUI , i)P ( GiISi , UI , i )   ( 10 ) In the right hand side ( RHS ) of equation ( 10 )  , the first term is equal to the speech act analysis model shown in section  2  . 1 . The second term can be approximated as the discourse structure analysis model shown in section  2  . 2 because the discourse structure analysis model is formulated by considering utterances and speech acts together  . Finally the integrated dialogue analysis model can be formulated as the product of the speech act analysis model and the discourse structure analysis model : e  ( Si , GiIUl . i ) = P ( S,IULi)P ( GiIUl . i ) = P ( S , ISj , &) P ( P , ISOxP ( G~IFi-2 , F~-OP(SiIGO(102 . 4 Maximum entropy model
All terms in RHS of equation ( 11 ) are represented by conditional probabilities . We estimate the probability of each term using the following representative equation : 
P ( alb ) = P ( a , b ) y  ~ P ( a ', b ) a (12)
We can evaluate P ( a , b ) using maximum entropy model shown in equation ( 13 )   ( Reynar 1997 )  . 
P(a , b ) = lrI"IOt\[' ( '' b ) i = 1 where 0 < c ~ i < o o , i = 1 , 2  . . . . . k (13) In equation (13) , a is either a speech actor a DSB depending on the term  , b is the context ( or history ) of a , 7 r is a normalization constant , and is the model parameter corresponding to each feature function f  . 
In this paper , we use two feature functions : unified feature function and separated feature function  . The former uses the whole context bas shown in equation  ( 12 )  , and the latter uses partial context split-up from the whole context to cope with data sparseness problems  . Equation ( 14 ) and ( 15 ) show examples of these feature functions for estimating the sentential probability of the speech act analysis model  . 
iff a = response and (14) b=User:\[decl , pvd , future , no , will , then \] otherwise 10 iff a = response and f(a , b ) = Sentence Type ( b ) = User : declot herwise ( 15 ) Equation ( 14 ) represents a unified feature function constructed with a syntactic pattern represents a separated feature function constructed with only one feature  , named Sentence Type , among all syntactic features in the pattern . The interpretation of the unified feature function shown in equation  ( 14 ) is that if the current utterance is uttered by " User "  , the syntactic pattern of the utterance is \[ decl , pvd , future , no , will , then \] and the speech act of the current utterance is response then f  ( a , b ) = 1 else f(a , b ) = O . We can construct five more separated feature functions using the other syntactic features  . The feature functions for the contextual probability can be constructed in similar ways as the sentential probability  . Those are unified feature functions with feature trigrams and separated feature functions with  distance-1 bigrams and distance-2 bigrams . 
Equation ( 16 ) shows an example of an unified feature function , and equation ( 17 ) and ( 18 ) which are delivered by separating the condition of b in equation  ( 16 ) show examples of separated feature functions for the contextual probability of the speech act analysis model  . 
10 iff a = response and f(a , b ) = b = User : request , Agent : ask-ref otherwise where b is the information of Uj and Uk defined in equation  ( 3 )   ( 16 ) 10 iff a = response and f ( a , b ) = b_t=Agent : ask-ref otherwise where b_~is the information of Uk defined in equation  ( 3 )   ( 17 ) f ( a'b ) = lo iffa=resp?nseandb-2otherwise=USer:request where b_ 2 is the information of Uj defined in equation ( 3 )   ( 18 ) Similarly , we can construct feature functions for the discourse structure analysis model  . For the sentential probability of the discourse structure analysis model  , the unified feature function is identical to the separated feature function since the whole context includes only a speech act  . 
Using the separated feature functions , we can solve the data sparseness problem when there are not enough training examples to which the unified feature function is applicable  . 
3 Experiments and results
In order to experiment the proposed model , we used the tagged corpus shown in section 1 . The corpus is divided into the training corpus with  428 dialogues ,  8 , 349 utterances (19 . 51 utterances per dialogue ) , and the testing corpus with 100 dialogues ,  1 , 936 utterances (19 . 36 utterances per dialogue ) . Using the Maximum Entropy Modeling Toolkit ( Ristad 1996 )  , we estimated the model parameter ~ corresponding to each feature function f in equation  ( 13 )  . 
We made experiments with two models for each analysis model  . Modem uses only the unified feature function , and Model-II uses the unified feature function and the separated feature function together  . Among the ways to combine the unified feature function with the separated feature function  , we choose the combination i which the separated feature function is used only when there is no training example applicable for the unified feature function  . 
First , we tested the speech act analysis model and the discourse analysis model  . Table 4 and 5 show the results for each analysis model . The results shown in table 4 are obtained by using the correct structural information of discourse  , i . e . , DSB , as marked in the tagged corpus . 
Similarly those in table 5 are obtained by using the correct speech act information from the tagged corpus  . 
Accuracy ( Closed test ) Accuracy ( Open test)
Candidates Top 1 Top 3 Top 1 Top 3
Lee (1997) 78.59% 97.88%
Samuel (1998) 73.17%
Reithinger (1997) 74.70%
Model I 90.65% 99.66% 81.61% 93.18%
Model II 90.65% 99.66% 83,37% 95.35%
Table 4. Results of speech act analysis
Accuracy ( Open test)
Candidates Top-ITop 3
Model I 81.51% 98.55%
Model I \] 83.21% 99.02%
Table 5 , Results of discourse structure analysis In the closed test in table  4  , the results of Model-
I and Model-II are the same since the probabilities of the unified feature functions always exist in this case  . As shown in table 4 , the proposed models show better results than previous work  , Lee (1997) . As shown in table 4 and 5 , Mode MI shows bette results than Model-feature functions are effective for the data sparseness problem  . In the open test in table 4 , it is difficult to compare the proposed model directly with the previous works like Samuel  ( 1998 ) and Reithinger ( 1997 ) because test data used in those works consists of English dialogues while we use Korean dialogues  . 
Furthermore the speech acts used in the experiments are different  . We will test our model using the same data with the same speech acts as used in those works in the future work  . 
We tested the integrate dialogue analysis model in which speech act and discourse structure analysis models are integrated  . The integrated model uses Mode MI for each analysis model because it showed better performance  . In this model , after the system determing the speech act and DSB of an utterance  , it uses the results to process the next utterance  , recursively . The experimental results are shown in table 6 . 
As shown in table 6 , the results of the integrated model are worse than the results of each analysis model  . For top 1 candidate , the performance of the speech act analysis fell off about  2  . 8 9% and that of the discourse structure analysis about  7  . 07% . Nevertheless , the integrated model still shows better performance than previous work in the speech act analysis  . 
Accuracy ( Open test)
Candidates Top-1 Top 3
Result of speech act 80 . 48% 94 . 58% analysis Result of discourse 76 . 14% 95 . 45% structure analysis Table 6 . Results of the integrated anal , ' s is model

In this paper , we propose a statistical dialogue analysis model which can perform both speech act analysis and discourse structure analysis using maximum entropy model  . The model can automatically acquire discourse knowledge from a discourse tagged corpus to resolve ambiguities  . 
We defined the DSBs to represent the structural relationship of discourse between two consecutive utterances in a dialogue and used them for statistically analyzing both the speech act of an utterance and the discourse structure of a dialogue  . By using the separated feature functions together with the unified feature functions  , we could alleviate the data sparseness problems to improve the system performance  . 
The model can , we believe , analyze dialogues more effectively than other previous works because it manages speech act analysis and discourse structure analysis at the same time using the same framework  . 

Authors are grateful to the anonymous reviewer for their valuable comments on this paper  . 
Without their comments , we may miss important mistakes made in the original draft  . 

Andernach , T .  1996 . A Machine Learning Approach to the Classification of Dialogue Utterances  . 
Proceedings of NeMLaP-2.
Berger , Adam L . , Stephen A . Della Pietra , and Vincent J . Della Pietra .  1996 . A Maximum Entropy Approach to Natural Language Processing  . 
Computational Linguistics , 22(1):39-71.
Caberry , Sandra .  1989 . A Pragmatics-Based Approach to Ellipsis Resolution  . Computational
Linguistics , 15(2):75-96.
Carniak , Eugene .  1993 . Statistical Language Learning . A Bradford Book , The MIT Press , Cambridge , Massachusetts , London , England . 
Collins , M . J .  1996 . A New Statistical Parser Based on Bigram Lexical Dependencies  . Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics  , pages 184-191 . 
Grosz , Barbara J . and Candace L . Sidner . 1986.
Attention , Intentions , and the Structure of Discourse . Computational Linguistics , 12(3):175-204 . 
Hinkelman , E . A .  1990 . Linguistic and Pragmatic Constraints on Utterance Interpretation  . Ph . D . 
Dissertation , University of Rochester , Rochester , 
New York.
Hinkelman , E.A. and J.F . Allen . 1989. Two
Constraints on Speech Act Ambiguity.
Proceedings of the 27th Annual Meeting of the Association of Computational Linguistics  , pages 212-219 . 
Kim , Chang-Hyun , Jae-Hoon Kim , Jungyun Seo , and Gil Chang Kim .  1994 . A Right-to-Left Chart Path . Proceeding of the 1994 International Conference on Computer Processing of Oriental 
Languages ( ICCPOL ), pages 175-180.
Lambert , Lynn .  1993 . Recognizing Complex Discourse Acts : A Tripartite Plan-Based Model of Dialogue  . Ph . D . Dissertation , The University of
Delaware , Newark , Delaware.
Lambert , Lynn and Sandra Caberry .  1991 . A Tripartite Plan-based Model of Dialogue . 
Proceedings of ACL , pages 4754.
Lee , Jae-won , Jungyun Seo , Gil Chang Kim .  1997 . A Dialogue Analysis Model With Statistical Speech Act Processing For Dialogue Machine Translation  . 
Proceedings of Spoken Language Translation ( Workshop in conjunction with ( E ) ACL'97 )  , pages 1015 . 
Lee , Hyunjung , Jae-Won Lee and Jungyun Seo .  1998 . 
Speech Act Analysis Model of Korean Utterances for Automatic Dialog Translation  . Journal of Korea Information Science Society ( B ) : Software and Applications , 25(10):1443-1552 ( In Korean ) . 
Litman , Diane J . and James F . Allen .  1987 . A Plan
Recognition Model for Subdialogues in
Conversations . Cognitive Science , pages 163-200.
Nagata , M . and T . Morimoto . 1994a . First steps toward statistical modeling of dialogue to predict the speech act type of the next utterance  . Speech
Communication , 15:193-203.
Nagata , M . and T . Morimoto . 1994b . An information-theoretic model of discourse for next utterance type prediction  . Transactions of Information Processing Society of Japan  ,  35(6):1050-1061 . 
Reithinger , N . and M . Klesen .  1997 . Dialogue act classification using language models  . Proceedings of EuroSpeech-97, pages 2235-2238 . 
Reynar , J . C . and A . Ratnaparkhi .  1997 . A Maximum Entropy Approach to Identifying Sentence Boundaries  . In Proceeding of the Fifth Conference on Applied Natural Language Processing  , pages 1619 . 
Ristad , E .  1996 . Maximum Entropy Modeling Toolkit . Technical Report , Department of Computer Science , Princeton University . 
Samuel , Ken , Sandra Caberry , and K . Vijay-Shanker . 
1998 . Computing Dialogue Acts from Features with Transformation-Based Learning  . Applying Machine Learning to Discourse Processing : Papers from the  1998 AAAI Spring Symposium . 
Stanford , California . Pages 9097.
Walker , Marilyn A .  1996 . Limited Attention and Discourse Structure . Computational Linguistics , 22(2):255-264 . 

