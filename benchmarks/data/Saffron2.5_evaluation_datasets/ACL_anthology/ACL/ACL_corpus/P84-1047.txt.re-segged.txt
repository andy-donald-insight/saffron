Entity-Oriented Parsing
Philip J . Hayes
Computer Science Department , Carnegie . Mellon Llniversity
Pi~tsbur ~ ih , PA 152_13, USA
Abstract f
An entity-oriented approach to restricted-domain parsing is proposed  , In this approach , the definitions of the structure and surface representation of domain entities are grouped together  . 
Like semantic grammar , this allows easy exploitation of limited dolna in semantics  . In addition , it facilitates fragmentary recognition and the use of multiple parsing strategies  , and so is particularly useful for robust recognition of extragrammatical input  . Several advantages from the point of view of language definition are also noted  . Representative samples from an enlity-oriented language definition are presented  , along with a control structure for an entity -oriented parser  , some parsing strategies that use the control structure  , and worked examples of parses . A parser in corporaling the control structure and the parsing strategies is currently under implementation  . 
1. Introduction
The task of lypical natural language interface systems is much simpler than the general problem of natural language understanding : The simplificati ~ nsarise because:  1  . the systems operate within a highly restricted domain of discourse  , so that a preci . .~e set of object types c;~n be established , and many of tl ; e ambiguities that come up in more general natural language processing can be ignored or constrained away  ;  2 . even within the restricted dolna in of discourse , a natural language i . terface system only needs to recognize a limited subset of all the Ihings that could be said -- the subset that its backend can respond to  . 
The most commonly used tr : chnique to exploit these limited domain constraints is semantic ~ j ~ amrnar \[ I  ,  2 , 9\] in which semantically defined categories ( such as < ship > or < ship-attrihute > ) are used in a gramrnur ( usually ATN based ) in place of syntactic categories ( such as < noun > or < adjective > )  . While semantic grammar has been very successful in exploiting limited domain constraint  . ~ to reduce ambiguities and eliminate spurious parses of grammatical input  , it still suffers from the fragility in the face of extragrammatical input characteristic of parsing based on transition nets  \[41  . AI~o . the task of restricted-domain language definition is typically difficult in interlaces based on semantic grammar  , in part bs caus ~ th . ,: grammar definition formalism is not well imegrated with the method of d ~  . .fining the object and actions of tl~e domain of discourse  ( though see\[6\] )  . 
1 This r~t , ; e ~ r chwmJ spont ; ( . cd by the At ; Fnrco Office of Scient = ficResr . ,'l? , "; hund ; r Cow , tract AFOC , R-82-0219\]his paper proposes an alternat ; veap proach to restricted domain langua ~ f e recognition cal I~d entity-oriented p  ; rsing . 
Entity-orie=-ted parsing uses the same notion of semar ~ tl cally-defined catct jeries a  . ' , ~2mantic grammar , but does net embed these cate , : . iories in a grammatical structure designed for sy . tactic recognition . Instead , a scheme more reminiscent of conceptual or case . frame parsers\[3, 10, II\] is employmf . An entity-oriented parser operates from a collection of definitions of the various entities  ( objects . events , cem , m~mds , states , etc . ) that a particular interf:~ce sy-~teln needs to r :  . ~ cognize . These definitions contain informatiol ~ about the internal structure of the entities  , about the way the entitie : ~ will be manifested in the natural language input  , s  ~ ( I about the correspondence belween the internal shucture and surface repres  . ~ ntation . \] his arrangement provides a good frar new o~k for exploiting the simplifications possible in restricted ? locY ~ ain att : rnlanouage recognition because :  1  . the entitle : z ; for ma~dtural set of ! ypes through which to cun : ~ train I h ~  ; recognition semantically . the types also formap . alura ~ basis fnr the structurct l definitions of entities  . 
2 . the set of things thai the backend can respond to corresponds to a subSet of the domain -:- nlities  ( remember that entities can be events or commar , ds as well as objects ) . 
Rethef ~ o ~ l of an entity . ori , ;nted ~ ystem will normally be to recognize one of a " top  . ievel " class of entities . This is analogous to the sotel basic message pa ~ . terns that L heir ;\[ ~ . chin ~ ; translation system of Wilks \[11\] aimed to recognize in any input . 
In addition to providing a good general basis for restricted domain  n41ural language recognition , we claim that the entity ~ o ; iented , ~ pproachals of a ,  . ; i Jitate 5 rubu : . ; tness in the face of ex~r~t grammatical input ~ . l ~ ( I easenf k ~ guage definition for ros ; r ! ctc:ld'm ; cJnI~ng ~ . ~ U a : ~ . EnLity . arie , ~ ted parsh ; gI', . ~ . s the potential to provide better parsing robustness L han more traditional semantic gramn ~  ; \] r techniques for two major reasons : ? The individual definition of aq domain entities facilit ~ lost heir in dep cncl  , ~ mtrecoL4rfilion . As: , um;;t , ': l there is a pl ) rof~ria Leinde ' < ingatenti Liestl ~ roughlex ~ cai ~ toms that mir  ; ih tappt ~ arin a surfaced t . ' . ~ cription ' . f them . thi : ~ rc . cognitior : c ; ; n be done bottom . up , thus rnuking pos: . ible recognition of elliptical , tru~Fner ~ ary , or p ~ r tially in corn pr ~ . h ~; , , si blo input . The same de ~ imtions can ~ i . .-;(, be us~cl i ~ a m . : . ~ reft ; cic : nt topdown f\[l ; Jt * ll ! ~: ' l when t ! leinput conlor rns to the system ' sexDect  . alio~\]s . 
, , Recemwork\[5 ,   8\] h~ls suggested the usefulness of multiple cor ~structioq  . specific reco . qnition str ; tt (; giesf , arrestrict , ~d domah \] parsing , patticularly for dealing witl lextragr; . 'nimaiic . q ! input . 1 heir ~ dividual entity cJo ! in it lons for mani(h ; al\[rc , rnewur ~ arcq ~ , d which to organize lhr multiple strategies are applicable to recognizing it  . Of course , " this only provides a framework for robust recognition  , the robustness achieved still depends on the quality of the actual recognition strategies used  . 
The advantages of entity-oriented parsing for language definition include : ? All information relating to an entity is grouped in one place  , so that a language definer will be able to see more clearly whether a dehnition is complete and what would be the conseouences of any addition or change to the definition  . 
? Since surface ( syntactic ) nnd structural information about an entity is groupe ~ to ~\] ether  , tiles ,  . trface information cau refer to the structure in a clear al '  ; \] coherent way . In particular , this allows hierarchical surface information to use the natural hierarchy defined by the structural informatiol ~  , leading to greater consistency of coverage in the surface language  . 
? Since entity definitions are independent , the information necessary Indrive Jecognilion by the mulliple construction-spucifics trL  , tegi ~: smentioned above can be represented directly in the form most useful to each strategy  , thus removing the need for any kind of " grammar co ~ pilation " step and allowing more rapid ? irammar development  . 
In the remainder of the paper , we make these arguments more concrete by looking at some fragments of an entity-oriented lan  ( \] u ~ ge definition , by outlining the control : ~ truclure of a robust resUicted-domain parser driven by such defiqitions  , and by tracing through some worked examples of ! he parser in operation  . These examples also shown describe some specifi ~ parsing strategies that exploit the control structures  . A parser i ~= corporating the control structure and the parsing strategies is currently under implementation  . Its design embodies our e ; perience with ~ pilot entily-oriented parser that has already been implemented  , but is not described here . 
r--v4 . , .  ~  ,   , ampie Entity Definitions This section present ' ~  . ~ r ) me example eat = t , / and language ( lefi , fitions suitable for use in entity-oriente ( \] parsing . The examples are drawn fiom the Oo main of an in ! ~ r face to a database of college courses  . Here is the ( partial ) de\[initio = ~ of a course ,  \[
Enttty Narne : College Course type : Structured
Components : (\[ Component Name : ? . otlrs eNumber type : Integer
Greater 1 han : g9
LeSSII ~ an: 000 \]\[ Component Name : Course Departmently pe : Co1 legeDepartment\]\[C 011ll0 nenLN ~ ll\[le:CourseCI&ss
F3 , po:CollegeClass\]\[CemponentName:Cuurse\ [ nstructo?lype:ColegeProressor 
J )
Siltrace Rupresen La Lion : \[ SynLax fype: Noun Phr~se 
IIo , l ? l: ( course Ises ninsr $ Courso Departmen LS Cour ' set , umberI ???) A diectival Co , lponen?s : ( Courseae partment .   .   .  )
Adjectives : (
JAdjec Liva \] Phrase : ( new J most . recent)
Cotllp OllOnL : Collrse Semoster
Value:CUI'It!qLSdm(Ster\]i "
Post Nomina I Cases: ( \[ Preposi Lion : ( ? intended For J directed to J .  )
Cofiponellt : Course Class

LPrl:posi Lion : (? L~ugh LbvI .   . , ) Coln pollel1 t:Co(~rse\[i1 . ~ L rllctot\])
J \]
For reasons of space , we cannot explain all the details of this language  . In essence , zz course is definc'd as 3 structured object with components : number , department , instructor , etc . ( square brackets denote attribute/value lists , and round brackets ordinary lists ) . " lhis definition is kept separate from the surface representation of a course which is defined to be a noun phrase with adjectives  , postnor ~ irla ! cases , etc . . At a more deiailed level , note the special purpose way of specifying a course by its department juxtaposed with its number  ( e . g . Computer Science 101 ) is handled by an alternate patt . ' . ,rn for the head of the noun phrase ( dollar signs refer back to the components )  . Tiffs allows the user to s , sy(redur = , ~antly ) phrases like " CS 101 taught by Smith " . Nolo . also that the way the dep~?rtment of a course can appear in the surface representation of a course is specified in terms of the ?: ourseDepartment component  ( and hence in terms of its type , Colleg ( ; Depml n\]ent ) rather than directly as an explicit surface representation  . This ensures consistency througl ~ out the language in what will be recognized as a description of a department  . Coupled wdh the ability to use general syntactic descriptors  ( like Noun Phrase in the description of a Surface Representation  )  , this can prevent the ki ~ , J of patchy coveraqe prevalent with standard semantic grammar language definitions  . 
Subsidiary objects like College Department are defined in similar fashion  . 
\[ rntiLyNnmn : ? oIIegel ) ep avLinentypo:Er . uiiler ' ~ Lion
Enumeratod Values :
Conlptltel SCi , nce Department
Mathema I . icsl ) el ) ar Linent
IIistoryl Jepar Lment " i "
Surface Representation :
J Syntaxlype : PaLternSet
Patterns : ( \[ Patt *: rn: ( CSI Computer Scie , ce J Camp Sol J .   .   .   ) Vahte : Compu Ler Sciet Lcel ~ lpal'tment\] ) \] r ; cllege Coursu will also be involved in higher-level entities e four restricted domain such as a ccm rnan  ( I to the databaseay . *t: . ~ mto +: . rola student in a course . 

IIll . i  ~ l , lall lO:\[l ) l'OCOlll/ll~tl ( Ilype : Structured
Comllonul ~ ts : (
I . CompononI . Nam+!:Fn rolle of ypo:COII~UeSL . det ~ L . I\[CemponenLNamu:I:nee\]\[n
Type : CoIleg , ' ~ Co , lrse\])
Surf'aceRopr , ; se.taL = el;:
Sy = lta~\[:tp ~, :\[ lll ; ~ . ~r . lt . iveC . tsel'ramo Ilea ' J: ( corgiI ? etliSLe ?\] in cl ~ ( le\[ .   .   . ) IIire ? LObju , : I . : ($ E . rollee )
Cases : (\[ PreposiLi,~n : ( in I tote J .   .   .  )
CO ; tlp OltOlL:~:ItI'01\]I\] ) \]\] These examples als ~ show how all information about an entity  , co . cerning both tundamental structure and surface representation  , is grouped to oeth ' , ~ ral~d integrated . T iff , . ; supports the claim that entity-c~ri~nted lanuuage definition makes it easier to deter  . nine whether a language definition is complete . 
3. Control Structure for at q c bust Entity-
Oriented Parser lhepotential advanta . qes of an entily-oriented approach from tile point of view of robLmtne  . ~ 3 in the face of ungr : ? mmatical input were outlined in the inlrodu  (  . tion . To exploit this potential while maintaining efficiency in parsing grammatical input  , special attention mus the paid to the control structure of the parser used  . 
Desirable character i , = . tics for the control Structure uf ; my parser capable of handling ungrammatical as well as grammatical input include :  . the control structure allows grammatical input to be parsed straightforwardly without consider  . ring any of the possible gralnmatical deviations d ; at could occur ; ? the om ~ trol structure enables progr ~: , ~siw: . ly high P . r degrees of grammatical ( leviatior ~ I o be consi ( Ic~: . ~d when the ilt\[~LIt does not satisfy grammatical exp  , ~ctations ; ? the control structure ; dlows simpler deviatio . stobe considered before more complex deviations . 
\] he first two points are self-evident , but the third lll ; + ty require some explanalion . " Ther , robl~mit addresses arises particularly when there are several alternative parses under consideration  . Ins . ch cases , it is important oprevent the parser h'om cons ! tiering drastic  ( levi . x tions in one branch of the par . ~' e before cor ~ si ( lering si~nple ones in the othur . For in ::' . ance , tile par . ~ ersh ( ; uld not start hypothesizir=g missing wordsir ; one bra . ch when a ~; impl , ~ ) sp ~ flli ~ lO correction in another blanch would allow tile parse I ? ~ go through  . 
We have ( le-;i(jned a parser control . ~ hucture for use in e ~, tity-oriented p ~ . ':; in U which ia ~; all ( , ~ , the rh ; lracteristics lis ~ e , t above . 
Thi . ~control structure operates thr r~u ~ ; hanacJend a mechanism . 
Each item of the agenda represents a dii'ier, . : ntnonU/\]uati . on of the paine , i . e . a partial parse plus a specific at it , + ~ of what to do next to continue that partial parse  , With each contnuation is associated an integer flexibility level that represents the degree of grammatical deviation imphed by the continuation  . That is , the flexibility level represents the degree of grammatical deviation in the input if the continuation were to produce a complete parse ' without finding any more deviation  . Continuations with a lower flexibility are run before continuations with a higher flexibility level  . 
Once a complete parse has been obtained , continuations with a , flexibility level higher than that of the continuation which resulted in the parse are abandoned  . This means that the agenda mechanism never activates any continuations with a flexibility level higher than the level representing the lowest level of grammatical deviation necessary to account for the input  . Thus effort is not wasted exploring more exotic grammatical deviations when the input can be accounted for by simpler ones  . This shows that the parser has the first two of the characteristics listed above  . 
In addition to taking care of alternatives at different flexibility levels  , this control structure also handles the more usual kind of alternatives faced by parsers -- those representing alternative parses due to local ambiguity in the input  . Whenever such an ambiguity arises , the control structure duplicates the relevant continuation as many times as there are ambiguous alternatives  , giving each of the duplicated continuations the same flexibility level  . From thereon , the same agenda mechanism used for the various flexibility levels will keep each of the ambiguous alternative separate and ensure that all are investigated  ( as long as their flexibility level is not too high  )  . Integrating the treatment of the normal kind of ambiguities with the treatment of alternative ways of handling grammatical deviations ensures that the level of grammatical deviation under consideration can be kept the same in locally cm biguous branches of a parse  . This fulfills the third characteristic listed above  . 
Flexibility levels are additive , i . e . if some grammatical deviation has already been found in the input  , then finding a new one will raise the flexibility level of the continuation concerned to the sum of the flexibility levels involved  . This ensures a relatively h!gh flexibility level and thus a relatively low likelihood of activation for continuations in which combinations of deviations are being postulated to account for the input  , Since space is limited , we cannot go into the implementation of this control structure  . However , it is possible to give a brief description of the control structure primitives used in programming the parser  . Recall first that the kind of entity-oriented parser we have been discussing consists of a collection of recognition strategies  . The more specific strategies exploit the idiosyncratic features of the entities /construction types they are specific to  , while the more general strategies apply to wider cl3sses of entities and depend on more universal characteristics  . 
In either case , the strategies are pieces of ( Lisp ) program r ~ . ther than more abstract rules or networks . Integration of such strategies with the general scheme of flexibility levels described above is made straightforward through a special split function which the control structure supports as a primitive  . This split function allows the programmer of a strategy to specify one or more alternative continuations from any point in the strategy and to associate a different flexibility increment with each of them  . 

The implementation of this statement a kescare of restarting each of the alternative continuations at the appropriate time and with the appropriate local context  . 
Some examples should make this account of the control structure much clearer  . The examples will also present some specific parsing strategies and show how they use the split function described above  . These strategies are designed to effect robust recognition of extragrammatical input and efficient recognition of grammatical input by exploiting entity-oriented language definitions like those in the previous section  . 
4 . Example Parsest . et us examine first how a simple database command like: 
Enro ; Susan Smithin CS 101 might be parsed with the control structure and language def in  ; tions presented in the two previous sections . We start off with the toplevel parsing strategy , Recognize Any Entity . This strategy first tries to identify a toplevel domain entity  ( in this case a database command ) that might account for the entire input . It does this in a bottom-up manner by indexing from words in the input to those entities that they could appear in  . In this case , the best indexer is the first word , ' enro!' , which indexes Enrol Command . In general , however , the best indexer need not be the first word of the input and we need to consider all words  , thus raising the potential of indexing more than one entity  . In our example , we would also index College Student , College Course , and Co!lege Department However , t t ' e s e are not top . level domain entities and are subsumed by Enrol Command  , and so can be ignored in favour of it . 
Once Enrol Command has been identified as an entity that might account for the input  , Recognize Any Entity initiates an attempto recognize it  . Since Enrol Command is listed as an imperative case frama  , this task is handled by the Imperative Case Frame recognizer strategy  . In contrast to the bottom-up approach of Recognize Any Entity  , this strategy tackles its more specific task in a topdown manner using the case frame recognition algorithm developed for the CASPAR parser  \[8\]  . In particular , the strategy will match the case frame header and the preposition ' in '  , and initiate recognitions of fillers of its direct object case and its case marked by ' in '  . These subgoals are to recognize a College Student to fill the Enrollee case on the input segment " Susan Smith '" and a College Course to fill the En roll n case on the segment " CS  101  " . 
Both of the ~ ere cognitions will be successful , hence causing the Imperative Case Framercognizer to succeed and hence the entire recognition  . The resulting parse would be : \[ Instance Of : EnroICo~n and ? nrol\]ee:\[InstanceOt':Co\]\ ]egeStudent 
First Naaes : ( Susan )
Surname : Smith\]\[nrotZn:\[\] nstance0?: College Course Eourse Department : Computer ScI ence Department  . 
CourseNumber:t01\]\]
Note how this parse result is expressed in terms of the underlying structural representation used in the entity definitions without the need for a separate semantic interpretation step  . 
The last example was completely grammatical and so did not require any flexibility  . After an initial bottom-up step to find a dominant entity  , that entity was recognized in a highly efficient topdown manner  . For an example involving input that is ungramma Ucal  ( as far as the parser is concerned )  , consider : Place Susan Smithin computer science for freshmen There are two problems here : we assume that the user intended ' place ' as a synonym for ' enror  , but that it happens not to be in the system's vocabulary  ; the user has a ! so shortened the grammatically acceptable phrase  , ' the computer science course for freshmen ' , to an equivalent phrase not covered by the surface representation for College Course as defined earlier  . Since ' place ' is not a synonym for ' enrol ' in the language as presently defined  , the Recognize Any Entity strategy cannot index Enrol Command from it and hence cannot  ( as it did in tl~e previous example ) initiate a topdown recognition of the entire input  . 
To deal with such eventualities , Recognize Any Entity executes a split statement specifying two continuations immediately after it has found all the entities indexed by the input  . The first continuation has a zero flexibility level increment  . It looks at the indexed entities to see if one subsumes all the others  . If it finds one , it attempts a topdown recognition as described in the previous example  . If it cannot find one , or if it does and the topdown recognition fails , then the continuation itself fails . The second continuation has a positive flexibility increment and follows a more robust bottom-up approach described below  . This second continuation was established in the previous example too  , but was never activated since a complete parse was found at the zero flexibility level  . So we did not mention it . In the present example , the first continuation fails since there is no subsuming entity  , and so the second continuation gets a chance to run  . 
Instead of insisting on identifyir , gasingle toplevel entity , this second continuation attempts to recognize all of the entities that are indexed in the hope of later being able to piece together the various fragmentary recognitions that result  . The entities directly indexed are College Student by " Susan " and " Smith "  ,   2 College Department by " computer " and " science " , and College Class by " freshmen " . So a topdown attempt is made to recognize each of these entities  . We can assume these goals are fulfilled by simple topdown strategies  , appropriate to the Surface Representation of the corresponding entities  , and operating with no flexibility level increment . 
Having recognized the low-level fragments , the second continuation of Recognize Any Entity now attempts to unify them into larger fragments  , with the ultimate goal of unifying them into a description of a single entity that spans the whole input  . To do this , it takes adjacent fragments pairwise and looks for entities of which they are both components  , and then tries to recognize the subsuming entity in the spanning segment  . The two pairs here are College Student and College Department  ( subsumed by College Student ) and College Department and College Class ( subsumed by College Course )  . 
To investigate the second of these pairings , Recognize Any Entity would try to recognize a College Course in the spanning segment ' computer science for freshmen ' using an elevated level of flexibility  . This gGal would be handled , just like all recognitions of flexibility increment  , tiffs strategy fails because the head noun is missing  . However . with another flexibility increment , the recognition can go through with the Ccllege Department being treated as an adjective and the College Class being treated as a postnominal case--it has the right case marker  , " for " , and the adjective and postnominal are in the right order  . This successful fragment unification leaves two fragments to unify--the old College Student and the newly derived College Course  . 
There are several ways of unifying a College Student and a College Course--either could subsume the other  , or they could form the parameters to one of three database modification commands : Enrol Command  , Withdraw Command , and Transfer Command ( with the obvious interpretations )  . Since the commands are higher level entities than College Student and College Course  , they would be preferred a stop . level fragment unifiers . We can also rule out Transfer Command in favour of the first two because it requires two courses and we only have one  . In addition , a recognition of Enrol Command would succeed at a lower Ile?ibility increment than Withdraw Command  ,   3 since the preposition ' in ' tilat marks the College Course in the input is the correct marker of the Enrolln case of Enrol Command  , but is not the appropriate marker for Withdraw From  , the course-containing case of Withdraw Command . Thus a fragment unification based on Enrol Command would be preferred  . Also , the alternate path of fragment a malgamation -- combining College Student and College Department into College Student and then combining Coilege Student and College Course -- that we left pending above cannot lead to a complete instantiation of a toplevel database command  . So Recognize Any Entity will be in a position to assume that the user really intended the Enrol Command  . 
Since th~s recognition involved several significant assumptions  , we would need to use focused interaction techniques\[7\] to present the interpretation to the user for approval before acting on it  . Note that if the user does approve it , it should be possible ( with further approval ) to add ' place ' to the vocabulary as a synonym for'enrol'since'place'was an unrecognized word in the surface position where ' enrol ' should have been  . 
For a final example , let us examine an extragrammatical input that involves continuations at several different flexibility levels : Transfel Smith from Coi  , ~ pter Science 101 Economics 203 The problems here are that ' Computer ' has been misspelt and the preposition ' to ' is missing from before ' Economics '  . The example is similar to the first one in that Recognize Any Entity is able to identify a toplevel entity to be recognized topdown  , in this case , Transfer Command . Like Enrol Command , Transfer Command is an imperative case frame , and so the task of recognizing it is handled by the Imperative Case Frame strategy  . This strategy can find the preposition ' from ' , and so can ! nitiate the appropriate recognitions for fillers of the O  . tOf Cour ~ e and Student cases . The recognition for the student case succeeds without trouble  , but the recognition for the OutOfCourse case requires a spelling correction  . 
2We assume we have a complete listing of students and SO can index from their names  . 
Whenever a topdown parsing strategy fails to verify that an input word is in a specific lexical class  , there is the possibility that the word that failed is a misspelling of a word that would have succeeded  . In such cases , the lexical lookup mechanism executes a split statement  . 4 A zero increment branch fails immediately , but a second branch with a small positive increment tries spelling correction against the words in the predicted lexical class  . If the correction fails , this second branch fails , but if the correction succeeds , the branch succeeds also . In our example , the continuation involving the second branch of the lexical lookup is highest on the agenda after the primary branch has failed  . In particular , it is higher than the second branch of Recognize Any Entity described in the previous example  , since the flexibility level increment for spelling correction is small  . This means that the lexical lookup is continued with a spelling correction  , thus resolving the problem . Note also that since the spelling correction is only attempted within the context of recognizing a College Course -- the filler of OutOfCourse-- the target words are limited to course names  . This means spelling correction is much more accurate and efficient than if correction were attempted against the whole dictionary  . 
After the OutOfCourse and Student cases have been successfully filled  , the Imperative Case Frame strategy can do no more without a flexibility level increment  . But it has not filled all the required cases of Transfer Command  , and it has not used up all the input it was given  , so it splits and fails at the zero-level flexibility increment  . However , in a continuation with a positive flexibility level increment  , it is able to attempt recognition of cases without their marking prepositions  . Assuming the sum of this increment and the 3pelling correction increment are still less than the increment associated with the second branch of Recognize Any Entity  , this continuation would be the next one run . 
In this continuation , the Imperative Case Frame Recognizer attempts to match unparsed segments of the input against unfilled cases  . There is only one of each , and the resulting attempt to recognize ' Economics  203' as the filler of IntoCourse succeeds straightforwardly  . Now all required cases are filled and all input is accounted for  , so the Imperative Case Frame strategy and hence the whole parse succeeds with the correct result  . 
For the example just presented , obtaining the ideal behaviour depends on careful choice of the flexibility level increments  . 
There is a danger here that the performance of the parser as a whole will be dependent on iterative tuning of these increments  , and may become unstable with even small changes in the increments  . It is too early yet to say how easy it will be to manage this problem  , but we plan to pay close attention to it as the parser comes into operation  . 
3This relatively fine distinction between Enro\ ]Command and Withd~awCemmand  . based on the appropriateness of the preposition ' in '  , is problem ~' , tical in that it assumes that the flexibility level would be incremented in very finegrained steps  . If that was impractical , the final outcome of the parse would be ambiguous between an Enrol Command and a Withdraw Command and the user would have to be asked to make the discrimination  . 
4 If this causes too many splits , an alternative is only to do the split when the input word in question is not in the system's lexicon at all  . 
2165. Conclusion
Entity-oriented parsing has several ~ dvantages as a basis for language rueognilion in restricted domain natural language in t  . ?\[ faces . Like techniques based on semantic grammar , itext ~ loits limited domain semantics through a series of domain-specific entity types  . However , because of its suitability for fragmentary recognitic n and its ability to accornmodate multiple construction  . specific parsing strategies , it has the i > otential for greater robustness in the face of extragramma Lical input than the usu \[  ; I semantic grammar techniques . In this way , it more closely resembles conceptual or case frame parsi~lgtc:t  , niques . 
Moreover , entity-oriented pursing offers advanta . ' jesh : ,   I:~ngua0e d ~ inition because of the integration of struch lr ; tlan J : aur fJ'c ~ representutio ~ z information and the ability to ropr~sent surta  . ' . e information in the form most convenient to drive co + zstruction  . 
specific recogqifion strategies directly.
A pilot implementation of a ~ entity-oriented parser has been completed and provides preliminary support for our claims  . 
t4o wever , a more rigorous lest of the entity-oriented approach rnust wait for the more complete implementation < : urrently being undertaken  . \] heagenda-style control structure we plan to use in this imptementath  ) ~ is described above , along wilh some parsings bate Gies it will employ and some worked examples of thesbategies and control structure in action  . 

I-heideas in this paper benefited cousiderably from discussions with other membr ~ rs of the Multipargroup at Carnegie Mellon Cnraputer Science Department  , parlicu ! arly Jaimo Carbonel L Jill Fain ,   . . rod Ste,~e F4inton . Steva Minton was a co-dc~si?nero ! the . 
controls tru <; tu+e ; ~ resented at t ) ov . ~: , and also founrl : mefficient w : w to i ruplement he split function de  . ' . .cribed in coa+~ec+tion with that control structure  . 
References 1 . Brown , J . S . and Bt ; rton . R . I :: l . Multiple Representations of " Q ~ owl ~ dgo for I utoriai Reasoning  . In Repf(~s , ' ~ nt ; ttion and Uod ~-: rstan ' . ' . 'mrj , Bubr , , w , D .  , . G . and Collins , A . , Ed . ,Academic
Press , New York , 1975, pp ., 311-349.
2 . Burton , R . R . Semantic Grammar : An Engineering Technique for Ccnstructing Natural I  . ai % luae , ~ Understanding Systems . BBN Reporl 3453 , Bolt , Beranek , and Newman , Inc . , Cambridge , Mass . ,
December , 1976.
3 . Carbonell , J . G . , Boggs , W . M . , Mau\]din , M . L . , and Anick , P . G . 
The ? CAI . tBUR Project : A Natural Lanluage Interface ~ o Expert Systems  . Prt ; c . Eighth Int . J t . Conf . on Artificial Intelligence,
Karl . ' ~ ruhe , August , 1983.
4 . Carbonell , J . G+and Hayes , P . J . " Recovery Strategies for Parsing Extragrammatical Language  . " Com ~ utational Linguistics 10 ( t984) . 
5 . Carbonell , J . G . and 14 ayes , P . J . Robust Parsing Using Multiple Construction -Specific Strategies  . In Natural Language Pcrsing Systems , L . Bole , Ed . , Springer-Verlag , 1984 . 
6 . Grosz , B . J . TEAM : A Transport \[ ~ ble Nalural Language Interface System  . Prec . Conf . on Applie ( I Natural L : ~ n ~ tuage Processing , S'mta Monica , February ,  198 , 3 . 
7 . Hayes P . J . A Construction Specific Approach to Focused h , teraction in Flexible Parsing . Prec . of 19th Annual Nl~- . , ~ ting of the Assoc . for Comp ~ Jt . ling . . Stanford University , June , 1981, pp . 

8 . Hi:yes , P . J . and Ca~t : onell , J . G . lv tulti-Strategy P~r , ~i+~g ~; nditsRole in\[~' obust Man . I ~, tachin ? . ~ Cnmmunicatio ' . ~ . Carnegie Mellon IJ ~ iversity Computer Sc~ol Jce Department  . , May , 1981 . 
9 . I'lendrix , G . G . Hum ~ . n Engine + ; ring for At ) plied Natural Language Processi ~ ; g . Prec . Fifth Int . J t . Conf . on Arlificial Into ! l ; genc,~ . , t , . ; ; r . 1077, pp .  183 .  ! 91 . 
IO . i : hes ;) e, . ;;~ . CK . ao,-IS ch~-nk . R . C . Comprehension by C'ompuLr ~ r : Expectation . \[ lase , lAn; . tly : ,; 3elS~nteac + ~ Girt Context . 
rech . Ru'pL 7~5, C , omput c;r Science Dept . , Y?1e Uoiveruity , 1976 . 
1I . W ~ lks , ? . A . Prefere : -, ce Semantics . In F-ormal Semantics of IV ~ tural L ~ . ngu : zge , Keer ; an , k(I . .Canbridge University Press , 1975 . 

