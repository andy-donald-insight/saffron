Speech Acts and Rationality
Philip R . Cohen
Artificial Intelligence Center
SRI International

Center for the Study of Language and Information
Stanford University
Hector J . Levesque
Department of Computer Science
University of Toronto "
1 Abstract
This pallet derives the ha . s is of a theory , of communication from a formal the ov ,  . ' of rational interaction . The major result is a < h,mon~t fallen that . i l h , c , tionary acts need not I ) e primitive , and . ee , Iuothereco ~' nized . .\s a t,'st case . we derive Searle's con-ditions on reqt , est in ~ from pri , ciples of ralionality coupled with a ~; ric ~ , an theory of iml ~ erativ ,  . s . The theory is shown to dis-tingui . ~hin sincere or nonserious imperatives from tr~le requests  . 
\[' ~ x lensions to indirect . ~peech acts . and ramifications for natural language ~ ystcms are also brieily discussed  . 
2 Introduction'\]'hetlnifyin ~ tilt'me of m , whc-trent pragmatics antl discourse re ~ earrhis that the c  . herence . f dialogue is to he folnnd in tile iule raclinn of the cottver ~ all l ' ~'  1~61rI  . I . Thalis , a speaker is regarded a ~ splanning his , lll crance , ~ reachieve his goals , which n , ay involve in h . .lwing a hean'r by the , , se of comm , micative or " speech " acts .   ( - ) ure ceiving an lltler ~ tnce realizing such an action  , the heareral templs Io infer the ~ peaker's goal ( s ) antitoqn deffl and how the 11lleratrv fnrthcrs them . The hearer then adopts new goals ( e . ~ . . to re-pond to a reqllest , to clarify the previous ~ peaker ' ~ lllll'r ~ ince or ~  . : f , al ) and plan ~ hisr ~ wn utterances to a cl , i e :' e those . :\ cotl , cel'?~alionenslle ~ , I This view of language a . ~ p . rpose fidartion has pervaded (' om-putational I , in zui-~icsre ~ carch , and ha . ~ re ~ , lted in numerous protoCyl ~ e systems \[ I ,  2 ,  3 . .', .  9 .  25, 27\] . l lowever , the formal foundations underlying 01n . . . % v ~ l . emshaw " heen unspecified or . nder ~ peril'ied . In this, . late , ~\[' affairs , one cannot characterize what a ~ , y . ', tem . ~llouldih ~ independently from what it does . 
This paper hl , g in storectify this sit-ation by presenting a fl ~ rmalizal innofrational interaction  . ~pon which is erected tile he ~ it min ~'- r , fatheory of reinm ~ miralion attd ~ peech acts . Inter-; wtion is d ~ . riv ~, dfr ~, mprmcil ~ h, . ~ of rational action for indivi , h , ala ~ en as .  ~ . . well as lwinciph's - \ [ helief and goal adoption among a~enls  . The h~s is of a theory nf purpose f i , l communication thus " F , l l ~ , w , , I ' th ~ Canadian lr , sti ~ , ~t ~- f ~) rA , ' . wanc~dR-search . 
~ This re ~, . are h was mad-W , ~sdde;n parthy a gilt from ~ he Systems Dew . l-opm~ . n ~\[" ~ . md : ~ ti , , n . and in part t , ysuFportfr-mti~er ) efens ~ Advanced R ~ . se ~ rrh\['roje . rts . Ag , ncyun . h'rC,~n~ra . ctNf~I ) t ) 3D . 8 . I-K-0078 wilh the . N~v:~\['~lec ~ ronicSystemsC ,, mm~nd . The views and om?lusion seon-tain ~' dint hls document ~ re~hos ~" of the ~ uthor ~ and should not be interpreted  ; ~ represent a , tive of the . omci ~ . policies , ~ ither expre ~ ed or implied , oi " the Defense ~ dvanced Research Projects Agency or the United States  ( Jovernment . Mu~hnf this rrsearrh was done when the second a . uth or wa ~ employed at the Falre hild (' ~ m , r ~ and Instrument Corp . 
emerges as a consequence of principles of action.
2.1 Speech Act Theory
Speech act theory was originally conceived a ~ s part of action theory  . Many of Austin's\[ . l \] insights about the nature of ~ peech acts , felicity conditions , antimodes of lath , reapply equally well to non-communicative actions  . Searle \[2G \] repeatedly mentions lhat many of the condition she attributes to variol  , sillocutionary acls ( such as requests antiqm , stions ) apply more ~ e : . , rally to non-communicative action . \] lowever , re ~ earcher ~ have ~ rad-ually lost ~ ight of their roots  . In recent work\[3 ~ I illoc , ltior , a ~" acts are formalized , antlalogic is proposed , in which propertie ~ of IA's ( e . g . , " preparatory conditions " and " mode ~ of achievement '  ) are primitively stip . laled , rather than derived front more h~ic principles of action  . We helieve this approach misses significant generalities  . "\[' hm paper ~ hows how to derive properties of illocutionary acts from principh  , so frationality ,   . p dating the formalism of \[10J . 
Work in Artificial Intelligence provided the first for ntalgro  . nding of speech act theory in terms of plann in ~ and plan rerog ~ nitmn  , cldminal in ~ in Perra . hand\lh . n'~\[:2:~III .   .   . ry of indirect speech acts . Xhwh ~, I"o ~ 0 rre ~ earchi ~ . in . ~lfir ~' dI , ~lhrir analyses , llowe ~ er , one majoring redien ! ~ I " their the . ryr : m be shown to he redundant in01 illocutionary acts . Alldo . inferential power nf the recolfnition of their dloc ~ itionary acts wa  . s already available in other " operators ' . Nevertheless , the naturallanglnage systems based on this approach\[I  .   , - 3\] always had to recognize which illocution ary act was performed in order to respond to at nser's utterance  . Since the illocutionary acts were unnecessary for achieving their ell'errs  , so too wa . ~ their re~'n~ni-tion . 
The stance that illocution ary arts are not primitive  , and need not here ; og'nize(l , isalih . .ratmg one . () neet a ken , itl ) ecomes apparent that many of the ( lifl ~ cuhies in applying ~ l )  , ,ech act theory to discourse , or to computer systems , stem from taking these acts to oseriously-i . e . , too primitively . 
3 Form of the argument
We show that illocutionary acts need not be primitive hyderiving Searle's conditions on requesting from an independently-motivated theory of action  . The realm of communicative action is entered following Grice  \[13i -- by postulating a correlation between the , ntterance of a sentence with a certain syntactic feature  ( e . g . , its dominant clause is an imperative ) and a complextude becomes true as a result of uttering a sentence with that feature  . Because of certain general principles governing beliefs and goals  , other causal consequences of the speaker's having the expressed goal can be derived  . Such derivations will be " summarized " as lemmas of the form " If  ( conditions ) are true , then any action making ( antecedent ) rue also makes ( consequent ) rue \] These lemmas will be used to characterize illocutionary acts  . 
though they are not themselves acts . For example , the lemma called REQUEST will characterize a derivation that shows how a heater's knowing that the speaker has certain goals can cause the hearer to act  . The conditions licensing that chain will be collected in the REQUEST lemma  , and will be shown to subsume those stipulated by Searle  \[261 as felicity conditions . However , they have been derived here from first principles  , and without the need for a primitive action of requesting  . 
The benefits of this approach become clearer as other illocutionary arts are derived  . We have derived a characterization of the speech act of informing  , and have used it in deriving the speech act of questioning  . The latter derivation also allows us to disting ~ tish real questions from teacher/student questions  , and rhetorical questions . However . for brevity , the discussion of the . , espeech acts has been omitted . 
Indirect speech acts can be handled within the framework  . 
although , again , we cannot present the analyses here . Briefly , axioms similar to those of Perrauh and Allen 22\] can be supplied enabling one to reason that an agent has a goal that q  , ~ iven that he also has a goal p . When the p's and q's are themselves goals of the hearer  ( i . e . . the speaker is trying to get the hearer to do something  )  , then we can derive a set of lemmas for i , , l irect requests . Many of these indirect request lemmas correspond to what have been called % herr-circuited " implicatures  . 
which , it was suggested \[211 underlie the processing of utterances of the form " Can you do X ?'  . " Do you know y ? ", etc . l , emma formation and lemma application thus provide a familiar model of-herr-circuiting  . Furthermore . this approach shows how one ran use general purpose reasoning in concert with conventionalized b~rms  ( e . g . , how one can reason that " Can you reach the salt " is a request to pass the salt  )  , a problem that has plagn wd most theories of speech acts  . 
The plan for the paper is to construct a formalism based on a theory of action that is sufficient for characterizing a request  . 
Most of the work is in the theory of action , as it should be . 
4 The Formalism
To achieve these goals we need a carefl : llyworked out  ( though perhaps , incomplete ) theory of rational action and interaction . 
"!' he theory wil~be expressed in a logic whose mn det theory is ba  . , ed(loosely ) on a possible-worlds semantics . We shall propose a logic with four primary modal operators -- BEL ief  , BMB ,  ~ , f ) AL . and AFTER . W ~ th these , we shall characterize what agents need to know to perform actions that art  , intended to achieve their ~ oals . The . zgents do so with I he knowledge that other agents operate similarly  . Thus , agents have beliefs about . ' her ' ~ g cals , and they have goals to influence others ' beliefs and goals  . The integration of these operators follows that of Moore  20l   , who analyzes how an agent's knowledge affects and is affected by his actions  , by meshing a possible-worlds model of knowledge with a situation calculus model of action  \[18\]  . By adding GOAL , we can begin to talk about an agent's plans , which can include his plans to influence the beliefs and goals of others  . 
Intuitively , a model for these operators includes courses of events  ( i . e . , sequences of primitive acts ) " that characterize what has happened . Courses of events ( O . B . e . ' s ) are paths through a tree of possible future primitive acts  , and after any primitive act has occurred , one can recover the course of events that led up to it  . C . o . e . 's can also be related to one another via accessiblity relations that partake in the semantics of BEL and GOAL  . Further details of this semantics must a waitour forthcoming paper  \[17\]  . 
As a general strategy , the formalism will be too strong . First , we have the usual consequential closure problems that plague possible-worlds models for belief  . These , however , will be accepted for the time being . Second , the formalism will describe agents as satisfying certain properties that might generally he true  , but for which there might be exceptions . Perhaps a process of nonmonotonic reasoning could smooth over the exceptions  , but we will not attemp to specify such reasoning here  . Instead , we assemble a set of basic principles and examine their consequences for speech act use  . Third , we are willing to live with the difficulties of the situation calculus model of action-e  . g . , the lack of a way to capture tnse parallelism , and the frame problem . Finally . the formalism should be regarded as a de , ~eription or specification Bran agent , rather than one that any agent could or should use  . 
Our approach will be to ground a theory of communication ia theory of rational interaction  , itself supported by a theory , of rational action , which is finally grounded in mental states . Accordingly , we first need to describe the_behavior of BEL , BMB . 
GOAL and AFTER . Then , these operators will be combined to describe how agents ' goals and plans influence their actions  . 
Then . we characterize how having beliefs about the beliefs and go also fo the ~ can affect one's own beliefs and goals  . Finally , we characterize a request . 
To be more spe ~ if lc , here are the primitives that will be used , with a minimal explanation . 
4, 1 Primitives
Assume p , q, .   .   . are schema variables ranging over wffs , and a , b ? ? are schematic variables ranging over acts . Then the following are wlfs . 
4 . 1 . 1 tVffs~ppvq(AFTEI ' ~ . ap-p is true in all courses of events that obt  , - , in from acta's happening '; , ( if a denotes a halting act ) . 
( DONI :' . a ) - The event denoted by a has just happened . 
(AGTa x ) -Agent x is the only agent of acta a ~ b - - Arta I  ) r ~ ce desact b in the current course of events . 
3 zp , ~ here p contains a free occurrence of variable z . 

True . False ( BELxp ) - pfoUows from X'S beliefs . 
~OALxp ) -- p fotlot ps from x's goals.
BMB xyp . -p/~llows from x's beliefs about what is mutually believed by x and y  . 
: P'w chlspaper , the only events that will be considered & re primitive acts  . 
3 Th & t is . p is true in ~ . 11c . oe . 's resulting from concatenating the current c . o . e , with the c . o . e , denoted by a . 
504.1.2 Action Formation
If a , b , c , d range over sequences of primitive acts , and p is a w f f . then the following are complex act descriptions : a : b--sequential action a\[b-- nondeterministic hoice  ( a or b ) action p ? -- action of positively testing p . 
def ( IFpab ) -- conditional action = ( p ? : a )  1  ( ~ pT ; b ) , as in dynamic logic . 
( UNTILpa ) -- iterative action d*~(~p : a)' ; ~ p ? ( again , as in dynamic logic ) . 
The recta-symbol "1-' will prefix formulas that are theorems , i . e . . that are derivable . Properties of the formal system that will be assumed to hold will be termed Propositions  . Propositions will be both formulas that should always be valid  , for our forthcoming ~ emantics , and rules of inference that should be sound . 
No attempto prove or validate these propositions here  , but we do so in It 7\] . 
4.2 Properties of Acts
We a do p ! , In ' , Isual axioms characterizing how complex actions behave  . mh ' rAFTER , a . streated in a dynamic logic ( e . g . , \[20\]) namely , Proposition tPropert * eso/compleza et ~-- ~   ( AFTER ( AFTER ( AFTER
AFTER atttlties :
Proposition
Proposition
Proposition
Propositlon
Proposition a : bp )  ---  ( AFTER a ( AFTER bp ) ) . 
a\]bp ) -= ( AFTERap ) ^( AFTER bp).
p ' tq ) -= p^q .
DONE will have ~ he following additional proper.
2 Vact ( AFTER act ( DONExact ) ) 4 $ Va \[ DONE ( AFTER ap ) ?: a ) ~ p\]4\[lb . ~D , q then ( DONE~?:a ) : ~( DONE , ') ?; a) , 5 p -= DONE p ?6(DONE\[(p3q )^ p\]? . ~  ( DONE q ? ) Our treatment of acts requires that we deal somehow with the " frame problem "  \[18\]  . That is , we must characterize not only what changes as a resuh of doing an action  , but also what does not change . To approach this problem , the following notation will he convenient : Def inition t  ( PRESERVES ap ) d . f P ~ ( AFTER ap ) Of co . rse , all theorems are preserved . 
Temporal concepts are introduced will DONE ( for past hap-penings ) and < > ( read " eventually ' . To say that p was true at ~( , mepoint in the past , we use 3a ( DONE p ? : a) . <> is to he regarded in the " branching time * sense\[I  1\]  , and will be defined more rigorously in !17\] . Essentially , OP is true iff for all infinite extensions of any course of events there is a finite prefix satisfying p  . OP and O~pare jointly satisfiable . Since OP starts " now " , the following property is also true , * ( AFTERt(DONE t )) , where tisterm denoting a primitive act ( or a sequence of primitive acts l , is ant always true since aft ; ~ t ' ~ ay change the values of terms ( e . g . , an election changes the value of the term ( PRESIDENTU . S . ))
Proposition 7t-p30 P
Also , we have the following rule of inference : Propos ition  8 I/I-a ~ fl then O ( avp ) ~ O ( 3 vp )  4  . 3 The Attitudes Neither BEL , BMB . nor GOAL characterize what an agent actively believes  , mutually believes ( with someonelse ) , or has as a goal , but rather what is imph'cit in his beliefs , mutual beliefs , and goals , sThat is , these operators characterize what the world would be like if the agent's beliefs and mutlml beliefs were true  , and if his goals were made true . Importantly . we do not in ch , dean operator for wanting , since desire ~ m , ed no the consistent . Weass . me that once an agent has sorted o~l this possibly inconsistent desires in deciding what he wishes to achieve  , the worhls he will hestriving for are consisteal  . ~' on-versely recognition of an agent's plans n , ' ed not , com , ider that agent's possibly inconsistent desires . F , zr ther more . there is al~ono explicit operator for intending . If an agent intends to bring about p , the agent is usually regarded as also being able to bring about p  . By using GOAL , we will be able to reason about the end state the agent is aiming at separately from our reasoning about Irisability to achieve that state  . 
For simplicity , we assume the usual Hintikka axiom schemata for BEL\[I  , SI , and we introduce KNOW by definition : Def in it ion  2   ( KNOW xp ) ~ fp ^ ( BEL xp )  4 . 3 . 1 Mutua l Be l ie f Human communicat ion depends crucially on what is mutually believed \[ I  ,  6 ,  7 ,  9 ,  22 ,  23 ,  2 . 1\] . We do not use the standard definitions , but employ ( nMB yxp) , which stands for y's belief that it is mutually believed between y and x that p  .   ( BMB yxp is true iff ( BELy\[pA ( BMD xyp ) \] )  . ~ BMB has the following properties : Proposit ion  9   ( BMB yxpAq )  =-  ( BMB yxp ) A ( DMB yxq ) 
Proposition 10 ( BMB yxp Dq )  3  (   ( BMD yxp )  3  ( BMB yxq ) )
Proposition 111/I- , ~3#then~-(BMByx ~):3 ( BMB yxJ ) Also , we characterize mutual knowledge as : Definit ion  3   ( MK xyp ) d . = fP ^ ( BMB xyp )  ^  ( BMD yxp ) r 5For an exploration of the issues involved in explicit vs  . implicit belief , seeilel . 
S Notice that ( BMB yxp )$ ( BMB xyp).
~ This definition is not entirely correct , but is adequate for present purposes . 
514.3.2 Goals
For GOAL , we have the following properties : Proposit ion  12 GOAL x GOAL xp ) ) ~  ( GOAL xp ) If an agent think she has a goal , then he does . 
Proposition 13 BELxGOAL xp-GOAL xp Proposition 14 GOAL xp ^ GOAL xp ~ q ) GOAL xq ) 8 The following two derived rules are also useful : Proposition  15 If i " oD ~ then ~' ( GOAL xa ) D ( GOALx ~ ) Proposition t0Ilk-aA ; 1D "7 then I-BMB y x ( GOALx ~ ) ) ^  ( BMB yxGOALx ~ )  :~  ( BMB yxGOALx " ~ ) )
More properties of GOAL follow.
4 . 4 Attitudes and Rational Action Next . we must characterize how beliefs , goals , and actions are related . " the interaction of BE Lanti AFTER will be patterned after Moore's analysis  \['20l   . In particular , we have : Proposition IT v x . act ( AGTax ) D ( AFTER act ( KNOWx ( DONE act ) ) ) Agents know what they have done . Moreover , they think certain effects of their own actions are achieved : Proposition  18   ( BELxRESULT xap ) ) 3  ( RESULTx a ( BEL xp ) ) . tv here def Definition 4 ( RESULT xap )  =  ( AFTER ap )  ^  ( AGTax ) The major addition we have made is GOAL . which interacts tightly with the other operators . 
We will say a rational agent only adopts goals that are achievable  , and accepts as " desirable " those states of the world that are inevitable  . To characterize inevitabiJities , we have Definition 5 ( ALWAYSp ) 4 . ~ Va ( AFTER ap ) This says that no matter what happens , p is true . Clearly , we want Proposition 19 lf~-r ~ then ~- ( BELx ( ALWAYS , ~)) That is , theorems are believed to be always true . 
Another property we want is that no sequence of primitive acts is for ever ruled out from happening  . 
Proposition 20 ~" Va ( ACT a )  ~ ~ ( ALWAYS ~ ( DONE a ) ) , where ( ACT a ) ~ f  ~ ( AFTER a -- ( DONE a ) ) One important variant of ALWAYS is ( ALWAYS xp )   ( relative to an agent )  , which indicates that no matter what that aqent does  , p is true . The definition of this version is : d~fDefini tion  6   ( ALWAYS xp ) = VaRESULT xap ) Au : ~ eful instance of ALWAYSIs ( ALWAYS pDq ) ill which no matter what happens , p still implies q . We can now distinguish between p : ~ q's being logically valid  , its being true in all courses of events , and its merely being true after some event happens  . 
S Notice that it pDq is true ( or even believed but ( GOAL xp Dq ) is not true , we should not reach this conclusion since some act could make it laise  . 
4.4.1 Goals and Inevitabilities
What an agent believes to be inevitable is a goal ( he accepts what he cannot change )  . 
Proposition 21 ( BELxAL WAYSp ) ) ~  ( GOAL xp ) and conversely ( almost )  , agents do not adopt goals that they believe to be impossible to achieve -- Proposition  22 N of utility -- ( GOAL xp )  ~ ( BELx ( ALWAYS ~ p ) ) This gives the following useful lemma:
Lemma II nevitable Consequences ( GOAL xp ) A ( BELx ( ALWAYS p~q ) ) D ( GOAL xq ) Proof : By Proposition 21 , if an agent believes pD q is always true , he has it as a goal . Hence by Proposition 14 , q follows from his goals , This lemma states that if one's goal is ac . o . e , in which pholds , and if one thinks that no matter what happens , pDq , the none's goal is ac . o . e , in which q holds . Two aspects of this property are crucially important o its plausibility  . First , one must keep in mind the " follows from * interpretation of our propositional attitudes  . Second , the key aspect of the connection between p and q is that no one can achieve p without achieving q  . If someone could do so , then q need not be true in ac . o . e , that satisfies the agent's goals . 
Now , we have the following as a lemma that will be used in the speech act derivations : 
Lemma 2 Shared Recoqnition ( BMB yxGOAL xp ) A ( BMB y x ( BELx ( ALWAYS p~q ) )  )  3  ( BMB y x ( GOAL xq ) ) The proof is a straightforward application of Lemma I and 
Propositions 9 and 10.
4.4.2 Persistent goals
In this formalism , we are attempting to capture a number of properties of what might be called " intention " without postu-lating a primitive concept for " intend "  . Instead , we will combine acts , be qiefs , goals , and a notion of commitment built out of more primitive notions  . 
To capture , megrade of commitment hanan agent might have towards his goals  , we define a persistent goal . P-GOAL , to be one that the agent will not give up until he thinks it has been an:  ( stied , or until he think she cannot achieve it . 
Now , in order to state constraints on c . o . e . ' s we define : d * f Definition T ( PREREQ xpq ) = Vc ( RESULT x ? q ) ~3a ( a ~ c ) A ( RESULT xap This definition states that p is a prerequisite for x's achieving q if all ways for x to bring about q result in a course of events in which p has been true  . Now , we are ready for persistent goals : ( GOAL xp ) ^\[ PREREQ x (   ( BEL xp ) vBEL x ( ALWAYS x~p )   )   )  ~ ( GOAL xp ) l Persistent goals are ones the agent will replan to achieve if his earlier attempts to achieve it fail to do so  . Our definition does not say that an agent must give uph is goal when he thinks it is satisfied  , since goals of maintenance are allowed . All this says is that somewhere along the way to giving up the persistent goal  , the agent had to think it was true ( or belie ~ , e it was impossible for him to achieve ) . 
Though an agent may be persistent , he may be foolishly so be ca , seheha . ~ no competence to achieve his goals . We characterize competence below . 
4.4.3 Competence
I'e . pleare ~ ometimes experls in certain fiehts , as well as in their own bodily movements . For example , a competent electrician will form correct plans to achieve world states in which " electrical "  . -tares of affairs obtain . Most aduhs are competent in achievimz worhl states in which their teeth are brushed  , etc . 
We will say an agent is COMPETENT with respect to p if  , whenever he thinks p will tnJeafter some action happens  , he is correct : def Definition 9 ( COMPETENT xp =
Va(BELx(AFTER xp )) 2) ( AFTER ap
One property of competence we will want is :
Proposition 23 Vx . a ( AGT x a )   ( ALWAYS ( COMPETENT x ( DONExa ) ) )  , where Definltlon I0 ( DONExa ) a ---' f ( DONE a )   . ' ~( AGTax ) That is . any person is always competent to do the acts of which he is the agent  . ~Of course , he is not always competent to achieve any particular effect  . 
Finally . ~ iven all these properties we are ready to describe rational agents  . 
4  . 5 Rat iona l Agents i~elow are properties of ideally ration alagents who adopt per-~i  . ~tentgnals . 
First . a ~ ents are care fuhthey do not knowingly and deliberately make their persistent goals impossible for them achieve  . 
Proposition 24 ( DONEx act ) 2) DON Exp? ; act ) , where p % ' J ( P-GOAL xq )  ~ ~ ( DEL x ( AFTER act ( ALWAYS x~p ) ) ) v ~ ( COALx ( DONExact ) ) l0 in other words , node liberately shooting ones set f in the foot . 
Now , agents are cautious in adopting " persistent goats  , since they must eventually come to some decision about their feasibility  . We require an agent to either come up with a " plan ~ to Slecause of Proposition  2  . all Proposition 23 says is that if a competent agen , , believes his own pr imi t iw act halts , it will . 
~ nNotice * hatttise ruciad that p be true in ~ hesane world in which the agent does act  , hence the use , if " p ?; aet * . 
achieve them--a belief of some act ( or act sequence ) that it achieves the persistent goal--or to believe he cannot bring the goal about  . That is , agents do not adopt persistent goals they could never give up  . The next Proposition will characterize this property of P-GOAL  . 
But , even with a correct plan and a persistent goal . there is still the possibility that the competent agent never executes the plan in the right circumstances -- some other agent has changed the circumstances  , thereby making the plan incorrect . 
\[f the agent is competent , hen if he formulates another plan . it will be correct for the new circumstances . But again , the world could change out from under him . Now , just as with operating systems , we want to say that the world is " fair " - the agent will eventually get a chance to execl  , te his plans . This property is also characterized in the following Proposition : Proposition  25 f a , rEzecuHon--The agent u , dl prentually for maplanan dezeeute * t . believing it achieves his persistent go a line , rcumstanees he believes to be appropriate for its suce es  . ~ . 
Vx(P-GOALxq ) 2)0\[3act'(DONExp? ; act')\]v\[BELx(ALWAYSx~ql\[ , where p4 =* ?( nELx(RESULTxact'q))
We now give a crucial theorem :
Theorem IC on sequences of a pers , stent goal--If . ~ omeone has a pers * stent goal of bringing about p  , and brmgm 9 ~l ~ ut pisus f fhinh is a rea of competence , then eventually either p becomes true or hew all believe there is nothing that can be done to achiet  , e
P ? y(P . GOALyp ) A ( ALWAYS ( COMPETENT yp ) ) D ( >  ( pv ( BELy ( ALWAYS y~p ) )
Proof sketch :
Since the agent has a persistent goal . heeventually will either find and execute a plan  . or will believe there is nothing he can do to achieve the goal  . Since he is competent with respect top , the plan she forms will be correct . Since his plan act ' is correct , and since any other plans he forms for bringing about p are also correct  , and since the world is " fair ' , eventually either the agt , ntexecutes his correct plan , making p true , or the agent comes to believe he cannot achieve p  . A more rigorous proof can be found in the Appendix  . 
This theorem is a major cornerstone of the formalism  , telling us when we can conclude  p , given a plan and a ~ oal . and is used throughout he speech act analyses . \[ fanagent who is not COMPETENT with respect top adopts pa  . sapersistent goal , we cannot conclude that eventually either p will be true  ( or the agent will think he cannot bring it about )  , since the agent could for ever create incorrect plans  . \[f the goal is not persistent , we also cannot conclude OP since the agent could give it up without achieving it  . 
The use of ~ opens the formalism to McDermott's " Little Nell * paradox  \[19l   . ttIn our context , the problem arises as follows : First , since an agent has a persistent goal to achieve p  , ~ lLittle Nellistied to the rail road tracks , and will be muhed by then eXt train . Dudley Doright is planning to save her . McDermott claims that , according to various A\[theories of planning , henever will , even though he always knows just what to do . 
5 3 and we assume here he is always competent with respectop  , ~ p is true . But , when p is of the form Oq(eg . , <>( SAVED LITTLE-NELL )) , <><> q is true , so <> q is true ~ well . Let us assume the agent knows all this . Hence , by the definition of P-GOAL , one might expect the agent to give uph is persistent goal that <> q  , since it is already satisfied ! On the other hand  , it would appear that Proposition 25 is sufficient oprevent heagent from giving up his goal too so on  , since it states that the agent with a persistent goal must act on it  , and , moreover , the definition of P-GOAL does not require the agent to give uph is goal immediately  . For persistent goals to achieve <> q . within someone's cope of competence , one might think the agent need " only " maintain <> q as a goal  , and then the other properties of rationality force the agent to perform a primitive act  . 
Unfortunately , the properties given so far do not yet rule out Little Nell's being mashed  , and for two reasons . First , NIL denotes a primitive act--the empty sequence  , llence , doing it would satisfy Proposition 25 , but the agent never does anything substantive . Second , doing anything that does not affect q also satisfies Proposition  25  , since after doing the unrelated act , <> q is still true . We need to say that the agent eventually acts on q ! To do so  , we have the following property :
Proposition 26 ( P-GOALyOq ) 3
O\[ ( P-GOALyq ) v ( rtgLy ( ALWAYS y~q ) ) \ ]  , That is . eventually the agent will have the persistent goal that q  , and by Proposifion 25 . will act on it . If heeventually comes to believe he cannot bring about q  , heeventually comes to believe he cannot bring about eventually q as well  , allowing him to give up his persistent goal that eventually q  . 
4.6 Rational Interaction
This ends our discussion of single agents . We now need to characterize rational interaction sufficiently to handle a simple re-qt  , ? st . First , we, . liscuss cooperative agents , and then the effects of uttering sentences . 
4 . 6 . 1 Proper t ies of Cooperat ive Agents We describe agents as sincere  , helpful , and more knowledge able than others about the t ~ lth of some ~ tate of affairs  . Essentially , O . , , ~ e concepts capture ( quite ~ iml ) li , qic ) constraints on influegc-ing ~ ome one clse's beliefs and goals  , and on adopting the beliefs and goal ~ of someone lse~one ' ~ own  . More refined versions are certainly desirable . Ultimately . we expect such properties of cooperative agents , a . sembedded in a theory of rational interaction , to provide a formal description of the kinds of conversational behavior ~ rice  \[1-t \[ describes with his " conversational m ; Lxims" . 
First , we will say an agcnti ~ SINCERE with respect to p if whenever his goal is to get someone else to beliet pep  , his goal is in fact to get that person to knomp . 
dec Definition tl ( SINCER Exp )  =  ( GOALx ( laELyp ) ) D ( GOALx ( KNO Wyp ) ) An agent is HELPFUL to another if he adopts as his own persistent goal another agent's goal that heeventually do something  ( provided that potential goal does not conflict with his own I  . 
Definition 12 ( HELPFULxy)a , ? =' Ca ( BELx ( GOALy ( ( DONE y a ) ) )  ^ ~ ( GOALx ~ ( DONExa ) ) D ( P-GOALx ( DONExa ) ) Agent x thinks agent y is more EXPERT about the true of p than x if heal ways adopts x's beliefs about pash is own  . 
def Definition 13 ( EXPERT yxp )  :  ( BELx ( BELyp )   )  :3  ( BEL xp )  4 . 0 . 2 Ut ter ing Sentences with Cer ta in aFeatures " Finally  , we need to describe the effects of uttering sentences with certain " features "  \[141  , such an mood . In particular , we need to characterize the results of uttering imperative  , interrogative , and declarative sentences t : Our descriptions of these effects will be similar to Grices's  \[131 and to Perrauh and Allen's 22\] % urface speech acts ' . Many times , these sentence forms are not used literally to perform the corresponding speech acts  ( requests , questions , and assertions ) . 
The following is used to characterize uttering an imperative : 
Proposition 27 Imperatives:
V x y ( MK xy ( ATTEND yx )  3  ( RESULTx\[IN 4 PER xy " do yact " 1 ( laMByx ( GOALx ( BELy ( GOALx ( P-GOALy ( DONEyact )   ) ) ) ) ) ) ) The ac:!IMPER speaker hearer'p\]stands for " make ptr~w " Proposition  27 states that if it is mutually known that y is attending to x  , is then tile result of uttering an imperative to y to make it the case that y has done action act is that y thinks it is mutitally believed that the speaker*s goal is that y should think his goal is foey to form the persistent goal of doing act  . 
We also need to a ~ ser that IMPER preserves incerity about the speak  , ' r's coals and helpfulness . These restrictions c , ~ uld be loosened , but maintaining them is simpler . 
Proposition 28 PRESERVES\[IMPERxy"doyact'\] ( BMB y x ( SINCERE y ( GOALyp ) ) ) ) Propos i t ion 29 ( PRESERVES\[IMPER xy " rioy ; Jet '\] ( HELPFULyxt ) All t ' , ricean " feature'-based theories of communication need to acco  , mt for cases in which a speaker uses an utterance with a feat'tre  , but does not have the attitudes ( e . g . . beliefs , and goals ) ' 2 l lowever ,  #e can only present the analysis of imperatives here  . 
tall it is not mutually known that y is attending , for example , if the speaker i ~ not speaking to an ~ udience , then we do not say what the result of uttering an imperative is  . 
5 4 usually attributed to someone uttering sentences with that feature  . Thus , the attribution of the attitudes needs to be context-dependent  . Specifically , proposition 28 needs to be weak enough to prevent nonserious utterance such as " go jump in the lake ~ from being automatically interpreted as requests even though the utterance is an imperative  . On the other hand , the formula must be strong enough that requests a rederivable  . 
5 Deriving a Simple Request
In making a request , the speaker is trying to get the hearer to do an act  . We will show how the speaker's uttering an imperative to do the act leads to its eventually being done  . What we need to prove is this:
Theorem 2 Resulto\[an Imperative -- ( DONE\[ ( MK xy ( ATTEND yx ) ) ^  ( BMB y x ( SINCEREx ( GOALx ( P-GOALy ( DONEyact )   )   )   )   ) ^  ( HELPFULyx ) l ? ; lIMPER xy"do yact'\]):3
O(DONE yact)
We will give the major steps of the proof in Fi ~ lreI  , and point In their justifications . The full-fled ~' ed proofs are h'f t to I he , , nergetic reader . All formula . s preceded by a * are supposed t , , be Irue just prior to performing the IMPER , are preserved by il . an , I thus are implicitly conjoined to formulas 2-9 . By their placement in the proof , we indicate where they are necessary for making t he deductions  . 
E~entially . the proof proceeds as follows : If it is mutually known that y is attending to x  . and y thinks it i ~ mutually believed I hat I hee -condition shohl  . then x's , lltering an imlwrative to y to do some action results in formula  ( 2 )  . Since hi ~ mutually believed x is sincere about his goals  , then ( :~ ) it is miltually believed his goaltndy is that y for maper sistent goal to  , Iotheact . Since everyone is always competent to do acts of which they are the agent  .  ( . 1 ) it is mutltally believed that the act will eventually be done  , or y will think it is forever impossible to do . But since no halting act is for ever impossible to do  , it is ( . 3 ) mutually believed that x's goal is that y eventually do it  . 
I h , nee ,  16 ) y thinks x's ~ o a \] is that y eventually do the act  . Now , ~ incey is help fillly disposed towards x , and has no objections Io doing the act . 17) y takes it on as a persistent goal . Since he is alwa . w competent about doing his own arts , 18) eventually it ~ illI ,   . , I one or he will think it impossible to do . Again . since it is n ( , If ~) rever impossible . (3) hev , illeventually do it . 
W , . have shown how the p, . r forming of an imperative to do an act leads to the act's evemually being done  . We wish to create a number of lemmas from this proof  ( and others like it ) to characterize iilocutionary acts . 
8Plans and Summaries 6.t Plans
A plan for agent " x " to achieve some goal " q " is an action term ~ a " and two sequences of wits  "  . no ', ~ Pl " .   .   .   . " pt , " and " q0"," qz", .   .   . ~ qk " where " qk " is ~ q " and satisfying
I . I-(BELx(poAptA .   .   . A p ~( RESULT x a qoapt A .   .   . APk ))) 2 . h(BELx(ALWAYS(p ~ aCh-t)Dq ,))) i = l , e .   .   .   . kIn other words , given a state where " x " believes the " pi ~ , he will believe that if he does ~ a " then " q0" will hold and moreover . 
given that the act preserves pi , and he believes his making " qi-i ~ true in the presence of pi will also make " qi * tale  . Consequently , a plan is a special kind of proof that I- ( BELx ( ( Po ^ . - . APk ) ~( RESULTxaq ))) and therefore , since ( BEL xp ) D ( BELx ( BEL xp ) ) and ( BELx ( p ~ q ) ) D ( ( BEL x p ) D ( BELx q ) ) . are axioms of belief , a plan is a proof that h(BELx(p . A .   .   . ^ p~))~(BELx ( RESULTxa'l ))
Among tile corollaries to a plan a re- ( BELx (   ( Poa .   .   . ^ p ,) ~( RESULTxaq ,))) i =\ [ .   .   .   . k and -( BELx((p , " a .   .   . aPi)~(ALWAYSq~-iDqi ))) i:1 .   .   .   . k \] = l " .   .   .   . k There are two main points to be made about the ~ ecorollaries  . 
First of all , since they are theorems , the implications can be taken to be believed by the agent " x " in every  , state . In this sense , these wits express general methods believed to achieve certain effects provided the assumptions are satisfied  . The second point is that these corollaries are in precisely the form that is required in a plan and therefore can be used as justification for a step in a filture plan in much the same way a lemma becomes a single step in the proof of a theorem  . 
6.2 Summaries
We therefore propose a notation for describing many ~ t  ,  . p ~ of a plan as a single summarizing operator . A 3ummary consists of a name , a list of free variables , a disting a fished free variable called the agent of the summary  ( who will always be list , ,d tirst ) , an Effect which is a wff , a optional Body which is either an action or a wff and finally  , an optional Gate which is a wff . The understanding here is that summaries are associated with agent and for an agent " x " to have summary " u "  . then there are three cases depending on the body of " u': 
I . If the Body of " u " is a wff , then ( BELx ( ALWAYS ( Gate ^ Bod ~ ) ~ Gate ^ Effect ) ) Is 2 . If the Body of " u " is an action term , then I- ( BELx ( Gate ~ ( RESULT agent Bod ~ ( Gate A Effect ) ) ) :60 fcourse , many actions change the truth of their preconditions  . H~ndllng such actions and preconditions i $ straightforward  . 




P27, P3, P4, I3 . Pll , P12 , 2 ( DONE\[(MKxy(ATTENDyx )) A( . conditions)\]? ; lIMPER xy"do yact*\] )   ( BMB y x ( GOALx ( BELy ( GOALx ( P-GOALy ( DONEyact ) ) ) ) ) ) A * ( BMB y x ( SINCEREx ( GOALx ( P-GOALy ( DONEyact ) ) ) ) )   ( BMB y x ( GOALx ( P-GOALy ( DONEyact ) ) ) ) ^ * ( BMB y x ( ALWAYS ( COMPETENT y ( DONEyact ) ) )   ( BMB y x ( GOALxO\[ ( DONEyact ) v4 . 
( BELy(ALWAYS ~ ( DONE yaet ))) l ))^ TX , Plf ,  3  , ( BMByx ~( ALWAYS ~ ( DONEyact ))) 5 . ( BMByx ( GOALxO(DONEyact ))) AP160P20 , P8 ,  4 6 . ( BELyx ( GOALxO(DONEyact )))^ Def . BMB ( HELPFULyx ) T . ( P-GOALyx ( DONEyact ))^ Def . of HELPFUL , MP ? ( ALWAYS ( COMPETENT y(DONEyact ))) 8 .  <>\[ ( DONEyact ) v ( BELy ( ALWAYS ~ ( DONEyact ) )l ^ T1 ? ~ ( ALWAYS ~ ( DONEyact ) ) 9 . <> ( DONEyact P20, P8

Figure 1: Proof of Theorem 2 -- An imperative to do an act result ~ in its eventually be in  9 done .   14 One thing worth noting about summaries i that normally the wiTs used above ~"  ( BELx ( Ga:eD .   .   . )) will follow from the more general wff
I-(;ate D ...
l lowever , this need not be the ca , ~ e and different agents could have different summaries  ( even with the same name )  . Saying that an agent has a summary is no more than a convenient way of saying that the agent always believes an implication of a certain kind  . 
7 Summarization of a Request
The following is a summary named REQUEST that captures steps  2 through steps 5 of the proof of Theorem 2  . 
\[ REQUEST xyact\]:
Gate : it )   ( BMB y x ( SINCEREx ( GOALx ( P-GOALy ( DONEyact ) ) ) ) )  ^  ( 2 )   ( BMB y x ( ALWAYS ( COMPETENT y ( DONEyact ) ) ) )  ( 3 )   ( BMB y x ~ ( ALWAYS ~ ( DONEyact ) ) ) 
Bo ~ i  ~ .   ( BMB y x ( GOALx ( BELy ( GOALx ( P-GOALyDONEyact ) ) ) ) ) Effect : ( BMB y x ( GOALxO ( DONEyact ) ) ) This summary allows us to conclude that any action preserving the Gate and making the Bod ! /true makes the Effect true  . 
Conditions ( 2 ) and ( 3 ) are theorems and hence are always preserved . Condition (1) was preserved by assumption . 
Searle's conditions for requesting are captured by the above  . 
Specifically , his " propositional content " condition , which states that one requests a future act , is present as the Effect because of Theorem 2 . Searle's first " preparatory " condition -- that the hearer be able to do the requested act  , and that the speaker think so is satisfied by condition  ( 2 )  . Searle's second prepara * tory condition -- that it not be obvious that the hearer was going to do the act anyway--is captured by our conditions on persistence  , which state when an agent can give up a persistent goal  , that is not one of maintenance , when it has been satisfied . 
Grice's " recognition of intent * condition\[12 ,   13\] is satisfied since the endpoint in the chain ( step 9 ) is a goal . Hence , the speaker's goal is to get the hearer to do the acthy means  , in part , of the ( mutual ) recognition that the speaker's goal is to get the hearer to do it  . Thus , according to Grice , the speaker has meant , , , , that the hearer should do the act . Searle's revised Gricean condition , that the hearer should " understand " the literal meaning of the utterance  , and what illocutionary act the utterance " counts as * are also satisfied  , provided the summary is mutually known , le
T.1 Nonserious Requests
Two questions now arise . First , is this not overly complicated ? The answer , perhaps surprisingly , is " No ' . By applying this REQUEST theorem , we can prove that the utterance of an imperative in the circumstances specified by the Gate results in the Effect  , which is as simple a propositional attitude as anyone would propose for the effect of uttering an imperative--namely that it is mutually believed that the speaker's goal is that the hearer eventually do the act  . The Bod V need never be considered 16~'he further elaboration of this point that it deserves is outside the ~ cope  . ot this paper . 
56 unless one of the gating conditions fails.
Then , if the Body is rarely needed , when is the " extra " embedding ( GOAL speaker ( BEL hearer . . . ) attitude of use ? The answer is that these embeddings are essential to preventing nonserious or in sincere imperatives from being interpreted un-conditionally as requests  . In demonstrating this , we will show how Searle's " Sincerity ~ condition is captured by our SINCERE predicate  . 
The formula ( SINCERE speaker p ) is false when the speaker does something to get the hearer to believe he  , the speaker , has the goal of the bearer's believing p , when he in fact does not have the goal of the heater's knowing that pLetus see see how this would he applied for " Go jump in the lake '  , uttered idiomatically . Notice that it could be uttered and meant as a request  , and we should be able to capture the distinction between serious and nonserious uses  . In the case of uttering this imperative , the content of SINCERE . pp = (   ( : OAL speaker ( P-GOAL hearer ( DONE hearer/JUMP-INTOLaker\] ) ) )  . 
Assume that it is mutually known/believed that the lake is frigidly cold  ( any other conditions leading to- ,  . GOALxp ) would do as well . e . g . , that the hearer is wearing his best suit , or that there is no lake around ) . So , by a reasonable axiom of goal formation , no one has goals to achieve states of affairs that are objectionable  ( assume what is " objectionable " involves a weighing of alternatives  )  . ~ o , it is mutually known/believed that ~ ( GOAL speaker ( DONE hearer\[JUMP-INTOLaket\] ) ) , and so the speaker does not believe he has such a goal  . l'l The consequent to the implication defining SINCERE is false  , and because tile result of tile imperative is a mutual belief that the speaker's goal is that the hearer think he has the goal of the bearer's jumping into the lake  , the antecedent of the implication is true . Hence , the speaker is in sincere or not serious , and a request interpretation is blocked , is In the case of there not being a lake around , the speaker's goal cannot be that the hearer form the persistent goal of jumping in some nonexistent lake  . since by the 3/0 F utility property , the hearer will not adopt a goal if it is unachievable  , and hence the speaker will not form hisg ~ alto achieve the unachievable state of affairs  ( that the hearer adopt a goal he cannot achieve )  . tence , since all this is mutually believed , using the same argument , hespeaker must be in sincere . 
8 Nonspecific requests
The ability conditions for requests are particularly simple  , since as long as the hearer knows what action the speaker is referring to  . he can always do it . He cannot , however , always bring about some goal world . An important variation of requesting is one in which the speaker does not specify the act to be performed  ; heme rely expresses his goal that some p be made true  . This will be captured by the action lIMPER y'p \] for ~ make ptrue *  . Here , tTThe speaker's expressed goat is that the hearer form tpersistent gold to jump in the lake  . But . by the/nee itails Coassqasae eslmma , given that a c . o . e , satisfying the speaker's goal also hutheheater 's eventually jumping in  ( since the hearer knows what to do )  , the speaker's goal is also ? c . o . e , in which the hearer eventually jumps in . In the same way , the speaker's goal would also be that the hearer eventually gets wet  . 
I * 11 o we ver , we do not say what else might be derivable . The speaker's true goals may have more to do with the manner of his action  ( e . g . , tone of voice ), than with the content . All we have done is demo as nurata formally how ? hearer could determine the utterance is not to be talte o ~ r  , face value . 
in planning this act , the speaker need only believe the hearer thinks it is mutually believed that it is always the case that the hearer will eventually findaplan to bring about p  . Ah hough we cannot present he proof that performing an \[ IMPER xy"p\] will make Op true  , the following is the illocutionary summary of that proof:\[NONSPECIFIC-REQUEST xyp\]: Gate :  ( BMB y x ( SINCEREx ( GOALx ( BELy ( GOALx ( P-GOALy p )   )   )   )   )   ) A ( BMB y x ( ALWAYS ( COMPETENT yp ) ) )   ( BMB y x ( ALWAYS ~-7 act ' ( DONE yq ? ; act ') , where q~((BELy(RESULT yact'p ))))
Body: .   ( IJMB yx ( GOALx ( BELy ( GOALx ( P-GOALy p ) ) ) ) ) 
Effect : ( nMByx ( GOALxOPt)
Since the speaker only asks the hearer to make p true  . the ability conditions are that the hearer think it is mutually believed that it is always true that eventually there will be some act such that the hearer believes of it that it achieves p  ( or he will believe it is impossible for him to achieve  )  . The speaker need not know what act the hearer might choose  . 
9 On summarization
Just as mathematicians have the leeway to decide which proofs are useful enough to be named a  . slemmas or theorems , so too does the language user . linguist , computer system , and speech act theoretician have greatlee way in deciding which summaries to name and form  . Grounds for making such decisions range from the existence of il focutionary verbs in a particular language  , to efficiency . However . summaries are flexible -- they allow for different languages and different agents to carve up the same plans differently  .   , oFurthermore , a summary formed for efficiency may not correspond to a verb in the language  . 
Philosophical considerations may enter into how much of a plan to summarize for an illocutionary verb  . For example , most illocutionary acts are considered successful when the speaker has communicated his intentions  , not when the intended effect has taken hold , This acgues for labelling as Effects of summaries intended to capture illocutionary acts only formulas that are of the form  ( BMI3 hearer speaker ( GOAL speaker p ) ) , rather than those of the form ( BMB hearer speaker p ) or ( BEL hearer p )  , where p is not a GOAL-dominated formula . Finally , summaries may be formed as conversations progress . 
The same ability to capture varying amounts of a chain of inference will allow us to deal with muhi-utterance or muhi-agent acts  , such as , betting , complying , answering , etc . , in which there either needs to be more than one act  ( a successful betr . quires an offer and an acceptance ) , or one act is defined to require the presence of another  ( complying makes sense only in the presence of a previous directive  )  . For example , where REQUEST captured the chain of inference from step  2 to step 5  , one called COMPLY could start at 5 and stop at step 9  . 
tSRemember , summaries are actually beliefs of agents , and those beliefs need oct be shared . 

Thus , the notion of characterizing illocution ary acts as lemma-like summaries  , i . e . , as chains of inference subject to certain conditions  , buys us the ability to encapsulate distant inferences at " one-shot '  . 
9.1 Ramifications for Computational Models of
Language Use
The use of these summaries provides a way to prove that various shortcuts that a system might take in deriving a speaker's goals are correct  . Furthermore , the ability to index summaries by their Bodies or from the utterance types that could lead to their application  ( e . g . , for utterances of the form "( . ' , anyoudo < X > ~ ) allows for fast retrieval of a lemmatlmt is likely to result in goal recognition  . By an appropriate organization of summaries \[5\] , a system can attempt to apply the most comprehensive summaries first  , and if inapplicable , can fall back on less comprehensive ones , event uMly relying on first principles of reasoning about actions  . Thus . the apparent difficulty of reasoning about speaker-intent can be tamed fortile " short -circuhed ~ cases  , but more general-purpose rasoning can deployed when necessary  . 
I Iowever . the conil ) lexities of rea . ~oning about others ' beliefs and goals remains . 
10 Extensions : In direction
Indireciion will be modeh'dilltills framework a . stile derivation of propositions ( lUlling with the speaker's goals that are not stated as such by tile initial propositional attitude  . For example , if we can conchlde from IBMByx ( GOALx ( GOALyNil that ( BMB y x ( GOALx ( GOALy0 q ) ) )  , where p does not entail q , then . " loosely ' , we will say an indirect request has been made by x  . 
( ; iven the properties of O . ( GOALxp ) D(GOAL x<C>P ) is ad worcm . ( GOALxp ) an ( l((;()At , x-li ) ar ~" mutually un-~ati ~\[ ial ) le , hilt ( COALxOP ) and ( GOALxO~p ) are jointly ~ ali ~ liahh ' . \["( rexamllh " ,  ( (  ; OALBILLOH AVEBILL HAM-MERI )   )   ) and ( GOALBILL < ~ ( HAVE JO HN HAM MERI )   ) could both be part of a description of Bill's plan for John to get a hammer and give it to him  . Such a plan could be triggered by Bill's merely saying " C  , ettile i lammer " in the right circumstances , such as when Billis on a ladder plainly holding anail  . 
: 0 A subsequent paper will demonstrate the conditions under which such reasoning is ~ ound  . 
I1 Concluding Remarks rhi ~ i ) aliertia . ~ demonstrated tilatallillocutionary acts ne , ' dantt ) , ' primitive . At least some can be derived from more basic priuciph  . sof ration alotion , and an account of tile propositional attitudes affected by the uttering of sentences wittl decl  . ' u-ative , interrogative , and imperative moods . This account satisfies a number of criteria for a good theory of illocutionary acts  . 
* Most elements of : he theory are independently motivated  . 
The ~ heory of rational action is motivated independently from any notions of communication  . Similarly , the properties of cooperative agents are also independent of communication  . 
l ? Notice thllt molt the or it q tOt I peechgt a would treat the above utterance uBed II direct request  . We do not . 
The characterization of the result of uttering sentences with certain syntactic moods is justified by the results we derive for illocutionary acts  . as well as the results we cannot derive ( e . g . . we cannot derive a request under conditions of in sincerity  )  . 
Summaries need not correspond to illocutionary verbs in a language  . Different languages could capture different parts of the same chain of reasoning  , and an agent might have formed a summary for purposes of efficiency  , but that summary need not correspond to any other agent'summary  . 
The rules of combination of illocution ary acts ( characterizing , for example , how mnltiple assertions could constitute the performance of a request  ) are now reduced to nlles for combining propositional contents and attitudes  . Thus , multi-utterance illocutionary acts can be handled by accumulating the speaker's goals expressed in multiple titter-antes  , to allow an illocutionary theorem to be applied . 
Multi-act utterances are also a natural outgrowth of lliS approach  . There is no rea . ~ on why one cannot apply mulliple illocutionary sunlniariest Otile  res0ill of utlt , ringaS ? ' lllen ??' . 
Those sllmmaries , however , need not ? ' or re~pond I oilloc 0 ftionary verbs . 
The theory is naturally extensible to indirection ( to lie argued for hi another paper )  , to other illoc . tio . ary act , suchuquestions , commands , informs , a ~ sertions , and to tile act of referring \ [ gl . 
Finally . allllougtiil locutionary actrerog ' nition may h , , ~ lricily unntwcssary , given the complexily of o01 r proofs , it is likely to heloser 011 . I '\] ~ s , . nliall v . s01et lrec~l ~ nilhmwould ; lillOlill ~ tolh( . 
application ( if ill , lc01tl*lnarySllnllll lriesllleort'nl . ~ Iodi . ~ cover the speaker ' ~ I ~ ( ml ( sL12 Acknowledgements We wo . ld like to thank Tom Blenko , Ih . rb(:lark , Michul ( , eorg, . lr , David I ~ r ~ el , Bob Moore , ( ; (, off . NU liierg ', Fernan(o\[)ereira . flay Penault, . ":, tan Rosenschein , Ivall ~ ag , and , ~ loshe
Vacdi for valuable dise.ssions.
13 References 1 . AIh'n . .! . F . Allhin-lla-'~ed atll ) roa ~' hI(iSll,,0 . chact rrc . ~nh . ion . 
"r, . , ctinic : llI ~ . , . port 17 . 1 . Di ' p ; lrtnit ' ! it of (' or npill . (' r ~ cil ' nce . 
llilivei ~ ity()f'r ,) roiito , January . ll . )\]'? . ) . 
2 . Allen . .I .  \[: . , Frith . A . M . . <\[" l,il,nan . I ) . .I . ARt ; ( iT : The Rochester dialogue system . Proceedings of the . Vat , . . , d Conference on Artificial Intelligence , Phtsh , r ~ h , I ) , ' nn~yl-van la ,  1982 . ? I,-70 . 
3 . Appelt , D . Planning Natural Language Utterances to S ( it is fy Multiple Goals . Ph . D . Th . . Stanford University , Stanford,
California , December 1981.
4 . Austin , J . L . // ol . to do thin fs~ith wo , da . Oxford University
Press , London , 1962.
58 5 . Bracbman . R . , Bobrow , R . , Cohen , P . , Klovatad , J . , Wel>-bet , B . L . , & Woods , W . A . Research in natural language understanding . Technical Report 4274, Bolt Beranek and
Newman Inc ., August , 1979.
6 . Bruce , B . C . , & Newman , D . Interacting plans . Cogn Riee
Science ~, 3, 1978, pp . 195-233.
T . Clark . H . H . , & Marshall , C . Definite reference and mutual knowledge . In Elements of Discourse Understanding , Academic Press , Joshi , A . K . , Sag , ! . A . , & Webber , B . , Eds . ,
New York . 1981.
8 . Cohen , P . R . The Pragmatics of Referring and the Modality of Communication  . Computational LinquMtics lO , 2, 198, 1, pp .  97-1 . 16 . 
9 . Cohen , P . R . On Knowin 9 what to Say : Plann in 9Speech Acts . Ph . D . Th . , University of Toronto . Toronto , January 1978 . Technical Report No . 118, Dept . of Computer Science . 
lO , (: ohen , P . R . . & Levesque , II . J . Speech Acts and the Rerog-nition of Shared Plans . Proe .   , \[ the Third Iliennial Conference , Canadian Society for ( ~omputa ! ional Studies of Intelligence , Victoria . B .  (; . , May .  1980, 263-271 . 
II . Emerson , E . A . , and Ilalpern . J . Y . "Sometimes " and " Not Never " Revisited : On Branching versus\[  . in earTime . ACM Sympa . ~ iumon Prinr ~ ple . ~ oft ) rt ~ jramm in 9Lanquaqes , 1983 . 
12 . (; rice . l . I ' . .\caning . Phdo , , ophiral Ret , iet p 66, 1957, pp . 

13 . Grice . II .  1' . Utterer ' . ~ Meaninganti Intentions . t'hilo . ~ ophi-cal Reriew 63, 2 . 1969, pp .  1 . 17-177 . 
14 . Grice , t . P . Logic and conversation . Int : ole . , P . and Margan , J .  \[, . , Eds . , Syntaz and Semantics : Speech Acts , Ace . 
demic Press , New York , 1975.
15 . Halpern , J . Y . , and Moses . Y . O . Atluide to the Modal Logics of Knowledgeanti Belief  . Pr  ~ . a/the Ninth Inter . 
national Joint (; on\[erenre on . 4 rtl\]ir:al intelligence , J . J(:AI,
Los Angeles , (' a lif . . Augnst , 1985.
Levesque , tlector , J . A logic of implicit and explicit belief . 
Proceedings of the National t , ' of l/erence a/the American As-~ciation for Artificial Intelligence  , ~ ustin , Texan ,  198 . 1 . 
esque , H . J . , & Cohen , P . R . A Simplified I , ogic of In-~eraction . in preparation 18 . McCarthy . J . . A : Ilayes . P . .1 . ~ ome Philo ~ . phical \[' rnhlems from the :-; t and point of . .\ rtifi?ial l . h'lli ~, ehce,In3t ? ~ rhl , eintelh'fence . i American El . ~evier , B . Mehzer & D . Michh ' . 
Eds ., New York . 1~; 9.
I9 . McDermott , D . A temporalogic for reasoning about processes and plans  . Cognitive Science ~, 2, 1982, pp .  101-55 . 
20 . Moore , R . C . Reasoning about Knowledge and Action . 
Technical Note 191 , Artificial Intelligence Center , SR ! International , October ,  1980 . 
21 . Morgan , J . L . Two types o\[convention in indirect speech acts  . In Syntaz and Semantics , Volume 9: Pragmaties , Academic Press , P . Cole . Ed . , New York , 1978, 261-280 . 
22 . Perrault , C . R . . & Allen , J . F . A Plan-Based Analysis of Indirect Speech Acts . American Journal of Computational
Linguiatic J 6, 3, 1980, pp . 167-182.
25 . Perrauit , C . R . , & Cohen , P . R . It's for your own good : A note on inaccurate reference  . In Elements of Discourse Understand in 9 , Cambridge University Press , Joshi , A . , Sag , i . , & Webber , B . , Eds . , Cambridge , Mass . , 1981 . 
24 . Schiffer , S . Mctmin 9 . Oxford University Press , London . 

25 . Schmidt , D . F . , Sridharaa , N . S . , & Goodson , J . L . The plan recognition problem : An intersection of artificial intelligence ant psychology  . Artificial Intelligence 10, 1979 . pp . 

26 . Searle , J . R . Speech acts : . . In essay in the philosophy of language . (? ambridge University Pre~s , (: ambridge , 1969 . 
27 . Sidner , (', .  1, . , Bates , M . , lgobrow . R .  ,1 . , Brachman , R . J . , Cohen , P . R . . Israel , D . J . , Wehber . B . l , . , & Woods , W . A . 
Research in knowledge representation for natural language undecstaz  , liog . Annual R , ' p ~) rt . 1785, Bolt , Beranek and
Newman Inc ., November , 1981.
28 . Vanderveken . I ) . A Model-Theoretic Semantics \[' or illocutionary Force  . Logique et , 4n , dy . ~ e ~' 6, 10::-I0 . l , 19 ~ q'l , pp . 

591 3 Appendix
Proof of Theoreml :
First , we need a lemma:
Lemma $ Va ( DONEx\[ ( BELx ( AFTER & p ) ) ^  ( COMPETENT xp ) \[? ; a ) : ) p

Lo 3, 4.


VaDONEx\[ ( BELxAFTER & p ) A ( COMPETENT xp ) l? ; a ) Ass\[BELx ( AFTER xp ) ) A ( COMPETENT xp ) DAFTER ap ) Def . of
COMPETENT , MP
Ya(DON ExAFTER&p ) ?; a2 , P4 p3 , P3YaDONEx\[ ( BELx ( AFTER ap ) ACOMPETENT xpJl ? ; a ) DpImpl . lntr . 
Theorem I . . Vy ( P-COALyp ) A ( ALWAYS ( COMPETENT yp ) ) D O ( pvBELyALWAYS ~ p ) ) ) 

I , 2.



P . GOALy ( DONEyact AALWAYS COMPETENT yDONE yactJ O3a DONE y\[ ( BELy ( AFTERapl ?: avBELy ( ALWAYS ~ p
OP vBEL y ( ALWAYS ~ p\[P-GOALy ( DONEyact )  ^  ( ALWAYS ( COMPETENT yDONE yactJ : ) 
O(PvBELy(ALWAYS ~ p )))

I , P25, MP
L3, P8,:2
Impl . Intr ., 3
