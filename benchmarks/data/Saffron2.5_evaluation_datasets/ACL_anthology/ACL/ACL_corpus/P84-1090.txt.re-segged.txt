Correcting Object-Related Misconceptions :
How Should The System Respond?t
Kathleen F . McCoy
Department of Computer & Inft ~ rmation Science
University of Pennsylvania
Philadelphia , PA 19104

Tillspaper describes a computational method for correcting users ' mise on ceptio as concerning the objects modelled by a compute  , " s . ystem . The method involves classifying object-related misc  , mce , tions according to the knowledge base fature involved in the incorrect information  . For each resulting class subtypes are identified ,  : . : cording to the structure of the knowledge base , which indicate wh : LIi . formativn may be supporting the misconception and therefore what information to include in the response  . Such a characteriza * i , , n , along with a model of what the user knows , enables the syst . cm to reas , mina domain-independent way about how best to c ~rrv  , ' t\[heuser . 
1. Introduction
Ameierar, . a of Al research as been the development of " expert sys  . tcms "- systems which are able to answer user's que : ~ titms concerning a particular domain  . Studies identifying desirabl , , iutora , ' tive capabilities for such systems\[Pollacket al  82\] have f t , und that . it is not sufficient simply to allow the user to , ~ka question and Itavo the system answ ~ . rit . Users often want to question the system's rea- ~oning  , to make sure certain constraints have been taken into consideration  , antiso on . Thus we must strive to provide expert systems with the ability to interact with the user in the kind of cooperative di:LIogues that we see between two bullish ctm versational partners  . 
Allowing . , uch interactions between the system and a user raises difficulties for a Natural Language system  . Since the user is interacting with a system a . ss/he would with a human export , s/he will nizam likely exp-ct the system to b ( have as a human expert . 
Among other things , then: . er will expect the systen l to be adhering to the cooperative principles of conversation \[ Grice  7  , 5 ,   . loshi8 21 . 
If these principte ~ are not followed by the system  , the user is bkeiy to become confu~ed . 
In this paper I . focus on one a , ;pect of the cooperative behavior found between two conversat  , ional partners : responding to recognized ifferences in the beliefs of the two participants  . Often when two people interact , ouc reveals - a belief or assumption that is incompatible with the b ~* liefs held by the other  . Failure to correct this disparity may not only implicitly confirm the disparate bcli  , ' f , but may even make it impos ~ ; i bie to complete tile ongoing task . Imagine the following excilange : U . Givellethe It UI . LNO of all Destroyers whose
MAST_IIEIGIIT is above 190.
E . All Destrt , yers that I know al ) out lave a MAbT_HEIGllT between 85 and 90 . We reyout hinking of the Aircraft-Carriers ? in this example  , the user ( U ) ha . sapparently ctmf used a Destroyer with an Aircraft -Carrier  . This confusion has caused her to attribute a property value to Destroyers that they do not have  . In this case a correct a/ts wer by the expert ( E of * none " is likely to confuse U ' . In order to continue the conver . -ation with a minimal amount of eo a fu . ~ ion , the user's incorrect belief must first be addressed  . 
My primary interest is in what an expert system , aspiring to human expert performance , should include in such responses . In particular , \[ am concerned with system responses to te ~ ' ognized disparate beliefs/assumptions about c b f l c t  . ~ . In the past this problem has been h , ft to the tutoring or CAI systems \[ Stevenset aL  79  , Steven ~& (' ollins 80 , Browng::Burton 78 , Sleeman 82\] , which attetup to correct student's misconceptions concerning a particular domain  . For the most part , their approach ha . ~ been to list a priori : dlmi . -conceptions in a given domain . Tilefutility t , f this appr , ~ a chise mpha ' . , ized in\[gleeman , ~2\] . In contrast , the approach taken hvrei ~ to , - la : , ~ iry . in a dolttn in independent way , obj , ' ct-related di . -pariti,~s;u:c,~rding to the l'~n . wh'dge~:tse(l ( . I ~) feature involved . An und ) er of respon : ~ estrategies : ire associated with each resulting cla  , ~ . Deciding which strategy to use for a given mise on cept i  , m will be determined by analyzing a user model and the discourse situation  . 
2. What Goes Into a Correction ?
In this work I am making th cbtllowing assunlptions : ?\]: orth*  , purposes . f the initial correct . i on attempt , the system is a ~ umed to have complet , , attd corr~'ct knowledge of the domain . Th : tt is . the system will initiMly perceive a disparity as a mise  . neel , tion on the part of the u~erIt will thus attemp to bring tile user's beli ~  , fs into line with its own . 
? The system's KBi~t clude -: the following fo:t ~ trce : an object taxonomy  , knowledge of object attributes and their possible values  , and into rnlation about I ) O . ~ ible relationships between ol ) jects . 
? Tile user's KB contain similar features , l lowev , ' r , mneh of the information ( content in the system's !' ( B may hemb- . ~ing from the u ~ or ' ~ b ~ ll\[e . g . , the us+ , r ' sl ' ( \[~ may I ) e ~ parser ot coarser than the system's I ( B , c , r various attributes ( , ~fc~:nccptsma~t ; emissi:~gfrets theu ~ , ' r'sI'(P ,  . In add it i ~ m .  ~ . meinf , ~ rmationia theu . ,er's KB may be wrong , intiffs work , to say that the user's KB isu'rong means that it isi  . ,:'m . :i . ~ter J with the , ~ g . , t,m)KB ( e . g . , things may be c!a . ' ~ ifie differently , properties attribute differently , and ~' oon ) . 
I Thizv , or k is p~rtiMb " supported by the NSF gr~nt # MC~81-07200  . 
444 ? Whiw the system t ~\] ayn , ,t km , we :; actly what is c(m ~ ained in the user'sl , ~ b ' , information about the user ?-: tt ~ b , ~ d ( , riv , ' dhum two smtrcrs . First , the . ~ystem can have , qtm . h , I of a canoni , : at u , mr . ( Of course this m . , h,\[m:tyturno . tt , , differ from any given user's model . ) ~ . ~ , , , '~ , ndl ) ' , it , ' anderiw " knowledge about what ? the user kn . ws fr , nt the ongoing dise . urse . Thisl : tt, . r type of k m ) ~ h ' d geop , ~titutes what the ' system discer ~ stobt , tits , mutual h ( . liv . :s of the system at td user as def in . diu\[ . h , . hi82\] . "\[' he . -, et~s,~s ,) ur (', ~, s . f informati , m together ' . n ~ titul c the s ) stem's model of the user's KB . ThNh , , , : t . I itself may be in compi , ,te arid/or ine , ,rrect witlt respect tt , t\]te system's KB . 
Att , -' r ' ~; utterance refh . cls . it her the state of his/her KIL-r ~ , , m , ) re:~s . .i~,g s/he ha ~ just done t () fill in some mi . , sing p:;rt of ~ . h : , tK , q , or both . 
(; lynnIlu , ~ ea ~ suinptit , ns , we earl consider what shouhl I ) e h t c h ~ d , : dinarcs p . nse to an object-r,'htt,'d disparity . If a person exhilt it ~ wh . a thi-/her conv ~ r . - . ationa \] part n ~ , r perceives as a In is concell ti , , n , IIH'vory least one w~mld expect from that partner is to denyt  .   . fal . einf . rmation ~- for example -
U . Ith . ugha whalewa ~ a fish.
g . It's n.t.
' l ' ranscript ~ u : dura\[ly~w curring " expert system show that experts often include more informati  , m in their response than a siHIpl , ' d , ' nial . T i t ( .   , ' xp ~ , rtInn ) ' provide all alterhative truest : ~ tem ~ . nt(e . g . , "\ V ha ; , . ~:, remarnnt : d ';') . S/he may offer ju ~ . t if b'ation and b , rsupp . rt for the rt ~ rr , wtion(e . g . , ? VChales are nt:~mln:~l ~ J)r , ('au ~*" t il%V hen:/the through hmgs and h'ed their young with milk  . ' . S/hen myals . refute the faulty reasoning s/hetho~tght then s ~ r h a d d  . nett , ~, rrive at the misconception ( e . g . , " l laving fins and li ~ ing in the water is not enough to make a whalea fish  .  '  . This behavior can be characterized a . sconfirming the corr 4 . et in h , rmation which mc\]y have h'd the user to the wrong conclusion  , but indi (: ating w . hy the false conclusion does no ! follow by bringing in a : lditional  , overriding information , sTheltroblemf , ,r a computer sy , -tem is to decide what kind ~? ih form u ! it mre:C , ' I , esupporting a given misconception . What thingsm :: y he relevant ? What faulty reasoning may have been done ?  1 char : ~ cterize-bject-relatcd miscone eptious in terms of the Kllfl  , tturt in wJved . Misclgssifying an object , ?1 thought a whale was a fish ' , i . wAw . s the SU lwrordinate KB feature . Giving an object a pr-p . r t y i t d o e ~ not have , " ~ V hat is the interest rate on this st ,   , ck ? ' , lovely ,  . : the , attriltu : eKB feature . This chatact ? ~ ri~:di-ni . helpful in d , -termining , in terms of the structure of a K\[L whathtform ; \] tion may be supporting a particular mis , 'onr , ' p tion . Thus , it is helpful in determining what to include in the r-  . .'ponso . 
2 Throtlghout this work I am as . - ~ tmlng that thtmise one*ption if imp ttrt~nt to the tlk ~ kath and and should therefore be corrected  . There . q , ~ases I am in tcrest ( , d in ? enera Vingat ( the " full blown " resl , Ot ; ~ es . if ? mlsecneeption is det ~ , c\]rd which Nn , aliln l , or\] . t . ! ~ t to he task at hand . it is conceivable that eith , : rth, . lillSc')ll , ' olltiOBtl ~ ignored or aIt , rlrtlllledIvPr ? ~ on of o/\]et;\['thoser , ,~l , Oll . ., . $ Ingiv Pii . 
5' l'h ~ . : ~ r~l,~;b'exhH . ih, . I hy*i ~,' . .:, r; . , u . . xp , t t ~ is v , ,cy Anfilar to the " grain of truth " rorr~ . , ' tionf , ~ . n dictu ~ erit ~ gsi \] uations a ~ i , t , I , '; fied in tWo . If & Mcl ),* . ald ~3I . " FhN . ' trat , ' gy first id , . nGSesth , , grai ~; t , ( truthi\[~a student's answ ~ . rxlldlip-it go ~ . ' < Oil to give tit-e or r ?, tI ;, n , ~ or . 
In the foil . wing sections l will discuss the two classes of object trii ~  . conreptions just mentioned : superordinate misconceptions and attribute misconceptions  . Examples of these classes : d . ng with correction strategies will be given . In addition , indications of how a system might choose apart icular strategy will be investigated  . 
3. Superordinate Misconceptions
Si . , . e the information ttm thuman experts include in their respon ~ l  . Coagal . , r . rd in atem is c . ncepti , m seems to hinge on the exl .   . rl'sl , ere ~ . p tion < , f ~ tiw misconception occurred or what informati ( , nmayh : tvebt . cn supporting the misconception , I have sub-cat , 'g , ,rized s , q wrordinate misconct , ptions according to the kind of support they hate  . F . reach type ( ~ ub-category ) of sup , ,r(udinat ( , mis ,  . (, m :,, iJ tion , 1 have identified information thal . 
would I . " relevant u , the correction.
In this analysist , fsupf . rordinate misconceptieus , I am assulning that the user's knowledge al ) out the sn per ordinate concept is correct . The user therefore arrives at the misconception because of his/her incomplete understanding of the object  . 1 amalso , for Ihemoment , ignoring misconceptions that occur because two objects have similar names  . 
Given these restrictions ,   1found three major correction strategies used by human experts  . These correspond to three reasons whyu user might misclassify an object : TYPEONE-Object Shares Many Properties with Posited Supe ~ ordinate -This may cause the user wrongly to c  . nclude that these shared attributes are inherited from the superordinate  . This type of misconc, . p tion is illustrated by an example involving a student and a teacher :  4 
U.\] though law hale w.~s a fish.
E . No , it's a mammal . Ah hou ~ hit has fins and li~e ~ in the water , it's a mamntal s~nce it is warm blooded and feeds its young with milk  . 
Nc , tice the expert not only specifi ~ the correct s0perordinate   , but also gives additional in f . rn = ati,~ntt , justify the c ~) rre , : i,~n . Shedo ~ . s this by acknowledging that there are some pr6per~ies that whales . d/are with fish which m : O ' lead the student to conclude  th8% a whah : is a fish . At the same times he indicates that these pc . pectins are not sufficient , h , r inclusion in the cla . ~soffish . The whale , in fact , lia . so ther properties which define it to be a mamm m : d . 
Thus , the strategy the expert uses when s/heperceives the misc  , ,J , ct , ption tube of TYPEONE may be characterized as: ( I ) l ) e , y the posited superordinate and iudk : ate the correct one  , (2) State attributes ( prol > , 'rties ) that the obj+ct has in common with the posited super < ~ rdin : tte  ,   ( at State defining attributes of the real super-r < thmte  , thus giviug evidence/justification for the correct ch  , ~+:ifi , '~ti . n . Thesy , lemma y hdlow this strategy when the user mod ~ l indicates that the itser thinks the p++sited su Ferordinate and the  . hi \] el are simih \] rbee : ruse they share man ) ' common properties n , ,t held by the real SUl~ . rordinate) . 
TYPETWO-Objt , ctSharesProperties with Auother Object which is a Member of Pos : ited Superordinate-In this c : rsethelAhho  , Jgh the analysis given her ow a ~ d ~: rived through , t  ~ , lying xr ~ uLI human interactions , the exarap Ds givenire simply illustrative and have not been extrs  , ,-t~d frorn a real interaetiJn . 
4 45 misclassified object and the " other object " are similar because they have some other common superordinate  . The properties that they share arc no_ . .~t those inherited from the posited superordinate  ; but those inherited from this other common superordhlate  . Figure 31 shows a representation of this situation . OBJECT and OTIIE Ii-LIBJEC'E have many common properties because the yslt :  . t . reaCtHltllton superordinate ( COMMON-St!I'E2OI2DINATE )  . 
Hence . if the user knows that OTIIE I1-OBJECT is at nember of the POS rFED SUPER Oll DINATE , ~/ Jeinay wr ~ mgly conclude that OBJECT is also a member of POSITED :  SUI>ERORD1NATE  . 
Figure 31: TYPETWO Superordinate Miscone eptio.
For example , imagine the following exchange taking place i't a junior highsch  . -Ibioh , gyela _,~s(here U is as t,d, . nt , E at eacher ) : U . I thought atomato was a vegetable . 
E . Noit's a fruit . You may think it's avege table since you grow tomatoes in your vegetal '  , \] egarden : ? h ) ug with the lettuce and green beans . However . it's a fruit because it's really the ripened ovary of a seed plant  . 
Here it is int portant for the studen to understand about plants  . 
Thus , the teacher denies the posited superordinate , vegetable , and gives the corr , -ctone , fruit . She backs this up by refuting evidence that the student may I  ) e using to support the misconception . In this ca . . . e , the stl . hntmay wrongly believe that tomatoes are vegetables becau ~  . elh ~' y are like some other objects which are vegetables  , lettuce and green beans , in that all three share the common super . rdln:tte:I,l:mts grown invegetable garden . The teacher acknowledges this similarity but refutes the conclusion that tomatoes are vegetables by giving the property of tomatoes which define them to be fruits  . 
The correction strategy used in this case was : ( I ) Denythechk , csification posited by the user attd indicate the correctela :  . , . ifieation . (2) Cite the-tiler memb ~ . rs of the posited sup * , rordinale that the user may be either confusing with the object being discu  . ' . sed(Drmakhtgab:tdan:dogy from . (,3) Give the features which disling ~ Jl . h the correct and p~sited superordinates thus justifying the class lfi  ( ': ttion . A system may f . llowlt . ;s strategy if a structure like that ht figure ; 31 is f(~und in the user model . 
TYPETHREE-Wrong Information-The user either has been told wrying informal i  . n and h . ' ~ not done any rea ; tming to justify it , or hast tt is classified the object in response to some cot npl *  . xrea . soniug process that the system can't duplicate . In this kind of situation , the system , just like a human expert , can only c . rtect the wrong information , give the corresponding true information , at . t possibly give some defining features distinguishing the posited and actual superordiuates  . ; f this cn rrection does not satisfy the user . it is up to him/her to continue the interaction until the underlying misconceptionisch  . a redup ( see\[ . J ' eff ~ rson 72\]) . 
The iuformation included in this kind of response is similar to that which McKeown's TEXT system  , which answers questions about database structure \[ McKeown  82 l , would include if the user had asked about the diff ~  . rence between two entities . In her case , the information included would depend on how ' similar the two objects were according to the system KB  , not on a model of what the user knows or why the user might be asking the question  .  5
U.Is a debenture a secured bond ?
S . No it's an unsecured bond-it has nothing backing it should the issuing company default  . 

U . Is the whiskey a missile ?
S . No . it's a submarine which is an underwater vehicle ( not a destructive device )  . 
The strategy folh ; wed in these ca . . , es can be characterized as : (1D eny posited supev , rdinate and give correct one . (2) Give additional iu formathm as lleeded . Tills . xtrain form : ttion may include defining features of the correct  , superordinate or information ab . ut the highest superordinate that distinguishes the object from the posited superordinate  . This strategy may be followed by the system when there is insufficient evidence in the user Iood el for concI  . Jding that either a TYPEONE or a TYPE
TWOmls concepti(m has occurred.
4. Attribute Misconceptions
A second class of nlisconception occurs when a person wrongly attributes a properly to an object  . There are at least three reasons wlvthi ~ , kind of ntisc~mception : ay occur . 
TYPE()NE-Wren ! . ; Object-The user is either confusing the obj , ct being discussed with : Hm ther object that has the specified property  , or s/he is making ab ~ . t analogy using a similar object . In either c . ' ~ e the second object should be included in the correft i  . : luSO the problem does not f :, ~ ulinu ?* . 
\[ u the foll ,) wing example the , ' x pert assume . ,~ the user is confusiug the object with as imi lar object  . 
U . I have my money in a money market certificate so I can get to it right away  . 
E . But you can't ! Y our money is tied up in a eert it ' i cate-do you mean a money market fund ? The strategy followed in this situation can be characterized ~  . s : ( l ) Deny the wrong information . (2) (; ire the corresp . mling correct information .   ( 3 ) Mention the object of confusion or possible analogical reas  . ning . This srategy can I ) e followed by a . sy~ten lv . ' hP it there is a to the robj , ' ct which is " cio ~ eincon , eel = to I he object being discussed and zhi , : hha . -the property involved in the inisconceptiou . Orcourse , the perception of h(,w"cl ( . : ~ eincant'clot = two objects are chan ' ~ . es with conte . \ t . This may be because some attributes are highlighted in SO lile contexts and hidden in others  .   ; ' or this reason it is anticipated that a el ' : sette'~s  5McKeown do ~* in dl . -:~te that this kind of inf ' ~ rm: , tlonwou\] , i improve her re-ponsos . Th-niai or Ihru : ~ t of her work was , ~ nt ,,: . i . . trlicture ; the tie # of i user model could hP eL . aily hltegrilil . d into hert ' ri,m . w,-,rk . 
4 46 measure such as that described in \[ Tversky 77\]  , which takes into account he salience of various attributes  , will be useful . 
TYPETWO-Wrong Attribute-The user has confused the attribute being discussed with another attribute  . In this case the correct attribute should be included in the response along with additional information concerning the confused attributes  ( e . g . , their similarities and differences ) . In the following example the similarity of the two attributes  , in this case a common function , is mentioned in the response :
U . Where are the gills on the whale ?
S . Whales don't have gills , they breathe throughlungs . 
The strategy followed was: ( 1 ) Deny attribute given , (2) Give correct attrihut c ,   ( 3 ) Bring in similarities/differences of the attributes which may have led to the confusion  . A system may follow this strategy when a similar attribute can be found  . 
There may be some difficulty in distinguishing between a TYPEONE and a TYPETWO attribute misconception  . In some situations the user model alone will not be enough to distinguish the two cases  . The use of past immediate focus ( see\[Sidner83\] ) looks to be promising in this case . Heuristics are currently being worked out for determining the most likely misconception type based on what kinds of things e  . g . , sets of attributes or objects ) have been focused on in the recast . 
TYPETHREE-The user w~s simply given bad information or has done some complicated reasoning which cannot be duplicated by the system  . Just as in the TYPETI~IREE superordinate misconception  , the system can only respond in a limited way . 
U .   1 amnot working now and my husband has opened a spousal IRA for us  . 1 understand that if 1 start working again , and want to contribute to my own IRA , that we will have to pay a penalty on anything that had been in our spousal account  . 
E . No-There is no penalty . You can split that spous alone anywayyou wish ? You can have  2000 in each . 
Here the strategy is : (1) Deny attribute given , (2) Give correct attribute . This strategy can be followed by the system when there is not enough evidence in the user model to conclude that either a TYPEONE or a TYPETWO attribute misconception has occurred  . 
5 . Conclusions ? In this paper I have argued that any Natural Language system that allows the user to engage in extende dialogues must be prepared to handle misconceptions  . Through studying various transcripts of how people correct misconceptions  , I found that they not only correct he wrong information  , but often include additional information to convince the user of the correction and/or refute the reasoning that may have led to the misconception  . This paper describes a framework for allowing a computer system to mimic this behavior  . 
The approach taken here is first to classify object-related misconceptions according to the KB feature involved  . For each resulting class , subtypes are identified in terms of the structure of a KB rather than its content  . The subtypes characterize the kind of information that may supporthemis conception  . A correction strategy is associated with each subtype that indicates what kind of information to include in the response  . Finally , algorithms are being developed for identifying the type of a particular misconception based on a user model and a model of the discourse situation  . 
6. Acknowledgements
I would like to thank Juliatlirschberg , Aravind Joshi , Martha Poll . ~ ck , and Bonnie Webber for their many helpful comments concerning this work  . 
7. References \[ Brown & Burton 78\]
Brown , J . S . and Burton , R . R . Diagnostic Models for Procedural Bugs in B ~ ic Mathematical Skills  . Cognitive
Science 2(2):155-192, 1978.
\[Grice 75\] Grice , H . P . Logic and Conversation . In P . Cole and J . L . Morgan ( editor ) , Syntax and Semantics 111: Speech Acts , pages 4158 . Academic Press , N . Y . , 1975 . 
\[Jefferson 721 Jefferson , G . Side Sequences . In David Sudnow ( editor ), Studies in . Social Interaction, . Macmillan , New York , 1972 . 
\[ Joshi82 \] Joshi , A . K . Mutual Beliefs in Question Answer Systems . in N . Smith\[editor ), Mutual Beliefs, . Academic Press,
N . Y ., 1982.
\[ McKeown82\] McKeown , K .   . Generating Natural Language Text in Response to Questions About Database Structure  . PhD thesis , University of Pennsylvania , May ,  1982 . 
\[ Pollack et al82\]
Pollack , M . , Hirschberg , J . , & Webber , B . User Participation in the Reasoning Processes of Expert Systems  . Int ' ? oceedings of the 198e National Conference on Artificial Intelligence . AAAI , Pittsburgh , Pa . , August , 1982 . 
\[ Sidner83\] Sidner , C . L . Focusing in the Comprehension fDefinite Anaphora  . In Michael Brady and Robert Berwick ( editor ) , Computation all t4 od cl8 of Discourac , pages 267-330 . MIT Press,
Cambridge , Ma , 1983.
\[Sleeman82\] Sleeman , D . Inferring ( Mal ) Rules From Pupil's Protocols . In Proceedings of ECAI-8~, pages 160-164 . ECAI-82,
Orsay , France , 1982.
\[Stevens&Collins80\]
Stevens , A . L . and Collins , A . Multiple Conceptual Models of a Complex System . In Richard E . Snow , Pat-Anthony Fedcrico and William E . Montague ( editor ) , Aptitude , Learning , and Instruction , pages 177-197 . Erlbaum , Hillsdale , N . J . , 1980 . 
\[Stevens et al 79\]
Stevens , A ., Collins , A . and Goldin , S.E.
Misconceptions in Student's Understanding . Intl . J . Alan-Machine
Studic , s11:145-156, 1979.
\[ Tversky 77\] Tversky , A . Features of Similarity . Psychological
Review 84:327-352, 1977.
\[Woolf&McDonald83 J
Woolf , B . and McDonald , D . Human Computer Discourse in the Design of a PASCAL Tutor  . In Ann Jandaleditor ,   CItI'88 Conference Proceedings - Human Factors in Computing Systems  , pages 230-234 . ACM SIGCHI/HFS , Boston,
Ma ., December , 1983.

