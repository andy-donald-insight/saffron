Parsing with Discontinuous Constituents
Mark Johnson
Center for the Study of Language and Information

Department of Lin Kuktics , StLnford University.

By generalizing the notion of location of a constituent to allow discontinuous Ioctaions  , one can describe the discontinuous constituents of nonconfiguration all nguages  . These discontinuous constituents can be described by a variant of definite clause grammars  , and these grammars can be used in conjunction with a proof procedure to create a parser for nonconfigurational languages  . 
1. Introduction
In this paper \[ discuss the problem of describing and computationally processing the discontinuous constituents of nonconfigurational languages  . In these languages the grammatical function that an argument plays in the clause or the sentence is not determined by its position or confguration in the sentence  , as it is in configurational languages like English  , but rather by some kind of morphological marking ontile argument or on the verb  . Word order in nonconfigurational languages is often extremely free : it has been claimed that if some string of words S is grammatical in one of these languages  , then the string S ' formed by any arbitrary permutation of the words in S is also grammatical  . Most attempts to describe this word order freedom take mechanisms designed to handle fairly rigid word order systems and modify them in order to account for the greater word order freedom of nonconfigurational languages  . 
.Mthough it is doubtful whether any natural language ever exhibits such total scrambling  , it is interesting to investigate the computational and linguistic implications of systems that allow aifigh degree of word order freedom  . So the approachere is the opposite to the usual one : I start with a system which  , unconstrained , allows for unrestricted permutation of the words of a sentence  , and capture any word order regularities the language may have by adding res-trictions to the system  . The extremely free word order of nonconfigurational languages is described by allowing constituents to have discontinuous\[ ocatio  , ls . To demonstrate that it is possible to parse with such discontinuous constituents  . I show how they can be incorporated into a variant of definite clause grammars  , and that these grammars can be used in conjunction with a proof procedure  . 
such as Ear\[ey deduction , to coestruct a parser , a . s shown in Pereira and Warren (1983) . 
This paper is organized as follows : section 2 contains an informal introduction to Definite Clause Grammars and  , lisctmses how they can be used in parsing , section : lgiws a brief description of some of the grammatical features of o * * o non -  , ' onligurational language . Guugu Yimhlhirr , section I presents ; t deiinite clause fragment for this language , aml shows how this can be u~ed for parsing . 
Section 5 notes that the use of di~conti*uiot*scon . ~l . ituent . ~ is * lot limited to definite clause granunars .  \[ ) lit they could lie incorporated into such disparate formalisnts as GP ~  (  ;  , I , FG or (' ; \[L Section 6 discusses whether a unified account of par . qng both conligurational and nonconfiguration all nguages can be given  , and section 7 compares the notion of discontinuous constituents with other approaches to free word order  . 
2 . Definite Clam Grammars and Parsing \[ n this section \[ show how to represent both an utterance and a contextfree granmmz  ( CI " G ) so that tile locations of e oustituents are explicitly represented in the grammar formalism  . Given this , it will be easy to generalize the notion of location so that it can describe the discontinuous constituents of nonconfigurational languages  . The formalism\[use here is the DefiniteClause Grammar formalism described in Clocks in and Mellish  ( 1084 )  . To fatal-liarize the reader with the DCG notation  , I discuss a fragment for English in this section . In fact , the DCG representation is even more general than is brought outhere : as Pereira and Warren  ( 1083 ) demonstrated , one can view pars in K algorithms highly specialized proof procedures  , and the process of parsing as logical inferencing on the representation of the utterance  , with the grammar functioning as the axioms of the logical system  . 
Given a contextfree grammar , as in ( l ) , the parsing problem is to determine whether a particular utterance  , such as the one in (2 , is an S with respect to it . 
1) S--NP VP
VP ~ VNP
NP--Det N
Det--NP\[?Ce~l ( ' 2   0 the tboy's 2 father 3 hit 4 the s dogs The subscripts in ( 2 serve to locate the lexical items : they indicate that  , for instance , the utterance of the word d0~ began at time ts and ended at time ts . That is , the location of the utterance " dog " in example ( 2 ) was the interval ( t  ~ , tsl . \[ interpre the subscripts a a the points in time that segment the utterance into individual words or morphemes  . Note that they perform the same function as the vertices of a standard chart parsing system  . 
Parsing 2 is the same as searching for an S node that dominates the entire string  , i e . whose location is \[0, 6! . By looking at the rules in I ) , we see that an S node is composed of an NP and a VP node  . The interpretation conventions associated with phrase structure rules like those in  ( I ) tell us this , and also tell us that the location of the S is the concatenation of the location of tile NP and the VP  . That is , tile existence of an S node located at i0 . t ~! would be implied by the existetlce of an NP node located at interval rO  . zi ( zavariable ) and a V'P node located at \[: , 8 t . 
The relationship between the mother constituent's location ant i those of its daughters is made explicit in the definite clause grauunar  ,   . ~ hown in (3, that corresponds to the CFG ( l . The utter-ante ( 1 )   ( after lexical analysis would be represented as in  ( 4 )  . 
Those familiar with Prolog should note that \[\[ lave reversed the usual orthographic convention by writing variables with a lower ca~eintial letter  ( they are also italicized )  , while constants begin with an uppercase letter . 
(3) S(z , :) -- NP (. r , y , 0) & VP V , :.
VP (:, :) -- V(z , y ) & NP ( y , : , O.
NP(z . :, case ) -- Det(z . y ) & N(y , ", ca **) . 
Det(z , y ) -- NP(x , y , Gen)





(3) contains four definite clauses ; each corresponds to one phrase structure rule in the CFG  ( I )  . The major difference for us between ( 1 ) and ( 3 ) is that in ( 3 ) the locations of the constituents fie . the endpoints ) are explicit in the formalism : they are arguments of the constituents  , the first argument being the beginning time of the constituent's location  , the second argument its ending time . 
AL so note the way that syntactic features arc treated in this system : the difference between genitive and non-genitive case marked nouns is indicated by a third argument in both the N and NP constituents  . 
Genitive nouns and noun phrases have the value Gen for their third argument  , while non-genitive NP have the value ~ , and the rule that expands NP explicitly passes the case of the mother to the head daughter t  . 
We can use ( 3 ) and ( 4 ) to make inferences about the existence of constituents in utterance  ( 2 )  . For example , using the rule that expands ~ in ( 3 ) together with the first two facts of ( 4 )  , we can infer the existence of constituent NP (0 , 2 , Gen) . 
The simplest appruach to parsing is probably to use  ( t ) in a top * down fashion , and start by searching for an S with location \[0 , 6\]; that is , search for goal S(0 , 6) . This method , topdown recursive descent , is the method the programming language Prolog uses to perform deduction on definite clauses ystems  , so Prulog can easily be used to make very efficient op * down parsers  . 
Unfortunately , despite their intuitive simplicity , topdown recursive descent parsers have certain properties that make them less than optimal for handling natural language phenomena  . Unless the grammar the parser is using is very specially crafted  , these parsers tend to go into infinite loops . For example , the rule that expands NP into Det and N in ( 3 ) above would be used by a topdown parser to create a Det subgoal from an NP goal  . But Det Ltself can be expanded as a genitive NP , so the parser would create another NP subgual from the Detsubgoal  , and so on infinitely . 
The problem is that the parser is searching for the same\[NP many times over : what is needed is a strategy that reduces multiple searches for the same item to a single search  , and arranges to share its results . Eariey deduction , based on the Eariey parsing algorithm . 
is capable of doing this . For reasons of time , I wo n't go into details of Eariey Deduction ( see Pereira and Warren ( 1983 ) for details ; \[ will simply note here that using Eariey Deduction on the definite clause grammar in  3  ) results in behaviour that corresponds exactly to the way an Earley chart parser wouhlparse  ( I )  . 
3 . Non-conflguratlon ~ lLanguages in this section I identify some of the properties of u on -conhgurational languages  . Since this is a paper on discontinuous constituents  , \[ focus on word order properties , as exemplified in the nonconfiguration all nguage Guugu Yimid hirr  . The treatment here is necessarily superficial : \ [ have completely ignored many complex phonological  , inflectional and syntactic processes that a complete grammar would have to deal with  . 
A non-configuration a\[language dilfer ~ front configurational languages like English in that morphological form  ( eg . affixes ), rather than position fie . configuration ) , indicates which words are syntactically connected to each other  , in Engii ~ h the grammatical , and hence semantic , relations it ip betwe ~ . n bog . father and dog in ( 5 ) are indicated in surface form by their positiou ~ , ~ t , l changing these positions changes these relationships  , and hence the meaning , ~sin ' Of course , there is nothing special about these two values : any two distinct values would have done  . 

(5 ) The boy's father hit the dog ( 6 ) The father's do shit the boyInGuuguYimid hirr , an Australian language spoken in northeast Queensland  , the relationships in 7 )   2 are indicated by the affixes on the various nouns  , and to change the relationships , one would have to change the alf Lxes . 
(7 ) Yarraga-aga ~ mu-ngu daagunda-ybiiba-ng unboy -GEN-mu-ERG dog+ABS hit-PAST father-l~RG'The boy 's father hit the dog ' The idea  , then , is that in these languages morphological form plays the same rule that word order does in a configurational language like English  . One might suspec that word order would be rather irrelevant in a nonconfiguration all nguage  , and in fact Guugu Yimid hirr speakers remark that their language  , unlike English , can be spoken ' back to front ': that is , it is possible to scramble words and still produce a grammatical utterance  ( Havil and 1979 , p26 . ) Interestingly , in some Guugu Yimid hirr constructions it appears that information about grammatical relations can be obtain either through word order or morphology : in the possessive construction When a complex NP carries case inflection  , each element ( in this case , both possession and possessive x pression ) may bear case inflection - and both must be inflected for case if they are not contiguous - but frequently the ' head noun '  ( the posac ~ ion ) I directly MJI precedes the possessive expre ~ ion , and only the latter has explicit case inflection ( Havil and 1979 , p . 56) Thus in (8) , biiba ' father ' shows up without an ergative suffix because it is immediately to the left of the NP that possesses it  ( is . 
possession is indicated by position).
(8 ) Biibayar raga-aga-m~ngu daagunda-y father boy -GEN-mu-ERG dog+ABS hit-PAST ' The boy's father hit the dog ' While ultimate judgement will have to a wait a full analysis of these constructions  , it does seem as if word order and morphological form do supply the same sort of information  . 
In the sections that follow . \[ will show how a variant of definite clause grammar can be used to describe the examples given above  , and how this grammar can be used in conjunction with a proof procedure to construct a parser  . 
4 . Repeesent in $ Discontinuotm Consti tuent8 \[ propose to represent discontinuous constituents rather directly  , in terms of a syntactic ategory and a discontinuous location in the utterance  . For example , \[ represent the location of the discontinous constituent in  ( 7 )  , Yarraga . aea . mu . n . . . biiba . ngun " boy's father ' a . ~ a set of continuous locations , as in (9) . 
( ol\[o . tl,:~ . 4 i . Alternatively , one could represent discontinuous locations in terms of a ' bit-pattern '  , amin (10) , where a ' l ' indicates that the constituent occupies this position  . 
(10) ~00i \]
While the descriptive power of both representations is the same  , \[ will use the representation of ( 9 ) because it is Somewhato AJI examples are from Havil and  ( 1979 )  . The constructions shown here are used to indicate alienable pcnse~ion  ( which includes k in ship relationships )  . 
128 easier to state configur ` ional notions in it . For example , the requirement thw ; a constituent be contiguous can be expressed by requiring its location set to have no more than a single interval member  . 
To represent the morphological form of NP constituents I use two argument positions  , rather than the single argument position used in the DCG in  ( 3 )  . The firet takes as values either Er ~ , ~ or ~ , and the second either Genor ~ . Thus our discontinuous NP has three a4"gument positions in total , and would here presented as (11) . 
(U ) NP(\[\[0, t,\[a , 4ll , Erz , ~).
\[ Zz(II) , the firet argument pmition identifies the constituent's location  , while the next two are the two morphological form arguments discussed immediately above  . The gramma rules must tell us under what conditions we can infer the existence of a constituent like  ( I 1 )  . The morphologies/form feature seem to pose no particular problem : they can be handled in a similia ~ way to the genitive feature in the min i -DCG for English in  ( 3 )   ( although a full account would have to deal with the dualergative/ahsohtive and nominative /accusative systems that Guugu Yimid hirr possesses  )  . 
But the DCG rule format must be extended to allow for discontinuous locations of constituents  , like (11) . 
\[ n the rule ~ in (3) , the endpoints of the mother's location ~ re explicitly constructed from the endpoints of the daughter's locations  . \[ n general , the realtionship between the mother's location and that of its daughters can be represented in terms of a predicate that holds between them  . \[ n the DCG rules for Guugu Yimid hirr , (12) to (14 , the relationship between the mother's location and those of its daughters ire presented by the predicate combines  . 
The definition of combines ~ ~ , follows : combines ( I , l ,   , l  ~ ) is true if and only if I is equal to the ( bitwise ) union of I ~ and I ~ , and the ( bitwise ) intersection of I ~ and I ~ is nullie . I ~ and I ~ must be nonoverlapping locations ) , (12) S(i)--V(I , ) & NP ( I: , EnI , ~) & NP ( Is , Abs , m ) ~ combine * . (/ , I 1 , l~ , la ) -(~3) NP (/ , cue , e)--N(lz , c ~ e , e ) & NP ( l ~ . c~e , Gen ) &: combines (/, lz , l ~) . 
(14 NP (/ , case t , caae2)~N (/ , c ~ c t , casc ~) Following Hale (1983) , I have not posited a VP node in this grammar , a/though it would have trivial to do so . To a ~ count for the ' configurational ' possessive shown in  ( 8 )  , \[ add the additions/clause in ( 15 ) to the grammar . 
(15) NP(z , : t\] , c ~ se , ~) -- NP(\[z , ~ \]\] , e , e ) & N(II ~ , zl , case , Gen ) Given this definite clause grammar and a proof procedure such a ~ Earley Deduction  , it is quite straightforward to construct a parser  . In ( 16 ) \[ show how one can parse\[7 ) using the above grammar and the Eariey Deduction proof procedure  . The Prolog predicate'p'starts the parser . First the lexical analyser adds lexical items to the state  ( the work in ~ store of the deduction procedure )  , when this is finished the deduction pr~edure uses the DCG rules above to ma & e inferences about the utterance  . The answer '*- yes'given by the parser indicates that it waaable to find an S that spans the entire utterance  . The command ' print state ' prints the state of the deductions y  , ~ tem ; since new inferences are always added to the bottom of the state  , it provides a chonn logica/records of the deductions made by the system  . The state is printed in Prolognotation : variables are written a  . s '_I ','_ . ~', etc . , and the implication symbol ( re ) a ~ prologeariey at ucns cr
UNSW-PROLOG : p(\[yarragaagamun , gudaa , gunday , hiibangun\])?Wordyarragaagmmanisan(\[\[O , Z\]\] , era , sen ) Word q , ~ u ~ an(\[\[Z ,  ~1\] ,   , ~ ,   , o )
Word ~, . #~ v ~ a ~(\ [ z , 31\])
Word b ; ; 66 ng~n is a . (\[\[*,41\], ~' s,o )** yes:print_sta~e! . .( frO , 111, " g , Z " ) ,,,(\[\[ z , 21\], . b , , , , o ) , ,(\[\[2 , aid " fills , 4 t1 , erg , o)~1\[0 , 4\]):-v(_z ) , np(_~ , erg , o ) , ~ p(_3 , abs , o ) , eombines(O . 411,_z,_2,_3~8 (((0 . 4 i): . np(_t , er ~, o , np(_2, abs , o) . 
combines\[0 , 4 J \] ,  2 , 3\[l , _ t , _2) np(_t , erE , o):-n(_2 , er ~ , o ) , rip(_3 , ez ' ~ , gen ) , combines (_t ,   . .2 , _3) np(_Z , er & , o):-rip(_2 , erz , sen ) , combine ~_ l . ~ I3 ,  411 , _2) np(_Z , e  ~ , sen):-n(_Lerg , zen ) np(\[\[o , ill ,   ,   , s , z ~) np(_t , err , o ) :- combines(_t ,  \[\[3 , 4H ,  \[\[0 , Z !\]) combines(l\[0 , tl ,  \[3 , -lJ\] , I\[3 , 4 lJ ,  \[0 , tJJ ) ,  . p(\[\[o , xl ,  \[3 , 41 l , ~' s , o ) ~((0 , 4(0:-np(_l , abs , o ) , combines ( O ,  411 ,  \[\[2 ,  31\[ ,  \[\[0 ,  11 ,  3 ,  4\[\] , _/) up(J , abs , o):-n(_2 , abs , o ) , np ( . .3, abs . gen ) , combines (_l ,  _2 , 3) np(L , abs , o):-np(_2 , abs , gen ) , combines ( J , IIt 21I , _2) np(_l , abs , gen ) :- . (_1, abs , gen ), p(_t . a  ~ . o): . n_t .  ~  . o ) op fl\[z , 2 hab . , o ) s(0,41\[): . combines (\[0'4\[ ,  \[2 ,  3  ,  \[\[0 , l ,  3 41\[ , I\[1 , 2J \] combin O ,  4  ,  2 , 3? ( frO , ~ IIIII If , I\[0 ,  1 ,  3 ,  4 \[ , Ill , -OIl ) . P\[_Z ,_? . l \] , ~ bs , o ) :- np flI_L_all , o , o ) , "( if_3 , --~/! , abs , St . ) np\[\[__1,_? . If , o , o): . n(_3 , o , o ) , np(_~ , o , genl , combines ( !_l ,  _211 ' _3 , _4) nPLI , - - ~ ll , o , o ) :- . ( I_t ,_ . oil , o , o ) nl ~ I\[_i , _2 fJ , o , o ) :- np(\[(_/ ,  _3\]1  , o , o ) , n((\[_3 , _2 JJ , o , Sen ) . IN_I , er ~, o ) :- n(_/,er ~, o) . ~\ [\ [ a ,  4\]\] ,   , g , o ) s(0 , 4\]):-rip (_/ , abs , o ) , combnes(\[\[04\]J ~\ [ o3~if 3411 , , ?  . ll ), omb,nv(II0,3!i,!f3 ii .   .   .   .   .   .   .   . 
I'P ~\[- L , -- I berg , o ) :- np(\[\]_l ,  _31\]  , o , o ) , n(fI_3 , _2!1' erg , gen ) 6 . UalntDh ~ ontinuoua Constituents in Grs mamgrs Ah hough the previou section introduced is continuous constituents in terms of definite cianse grammar  , there is no reason we could not invent a notation that abbreviates or implies the " combines ' relationship between mother and daughters  , just a . s the CFG in ( 1 ) " implies " the mother-daughter location relationships made explicit in the DCG  ( 3 )  . For instance , we could choose to interpret a rule like ( 1 71 ~simplying the ' combines ' relationship between the mother and its daughters  . 
(17) A-*/7; C ; D
Then the DC'G grammar presented in the last section could be written in the GPSG like notation of  ( 18 )  . Note that the third rule is a stamdaed phrase structure rule : it expresses the ' configuration ai'p ~ sessive shown in  ( 81 . 
129 ( zs~s-\[c ~ E ~ l ; v ; \[CAS ~' A bel It is easy to show that grammars based on the ' combines'predicate lie outside the class of contextfree languages : the str inp the grammar  ( 19 ) accepts are the permutations of amb'c " ; thus this grammar does not have weakly equivalent CFG  . 
(, 91S--=; b ; c;(S )
While it would he interesting to investigate other properties of the ' combines'predicate  , I suspec that it is not optimal for describing linguistic systems in general  , including nonconfigurational languages . It is difficult to state word order requirements hat refer to a particular constituent position in the utterance  . For instance , the only word order requirement in Waripiri , another nonconfigurational language , is that the auxilary element must follow exactly one syntactic on stituent  , and this would be difficult to state in a system with only the predicate ' combines '  , although it would be easy to write a special DCG predicate which forces this behaviour  . 
Rather , l suspect it would be more profitable to investigate other predicates on constituent locations besides ' combines ' to see what implications they have  . \[ n particular , the wrapping operations of Pollard ( 1984 ) would seem to be excellent candidates for such rL , ~ eagch . 
Finally , I note that the discontinuous constituent analysis described here is by no means incompatible with standard theories of grammar  . A ~ I noted before , the rules in (18) look very much like GPSG rules , and with a little work much of the machinery of GSPG could be grafted onto such a formalism  . Similiarly , the CFG part of LFG , the C-structure , could be enriched to allow discontinuous constituents if one wished  . And introducing some version of discontinuous constituents to GB could make the mysterious " mapping " between P-structure and L-structure that Hale  ( t983 ) talks about a little less perplexing . 
Myown feeling is that the approach that would bring the most immediate results would be to adopt some of the " head driven " aspects of Pollard's  ( 1984 ) Head Grammars . \[ nhis conception , heads contain as lexical information a list of the items they subcategorize for  . This strongly suggests that one should parse according to a " head first " strategy : when one parses a sentence  , one looks for its verb first , and then , based on the lexical form of the verb , one looks for the other arguments in the clause . Not only would such an approach be easy to implement in a DCG framework  , but given the empirical fact that the nature of argument NPs in a clause is strongly determined by that clause's verb  , it seems a very reasonable thing to do . 
8. Implement hag the Parser
In their 1983 paper , Pereira and Warren point out several problems involved in implementing the Earley proof procedure  , and proposed ways of circumventing or minimizing these problems  . In: . his section \[ only consider the specialized case of Earley Deduction working with clauses that correspond to grammars of either the continuous or discontinuous constituent type  , rather than the general ca~e of performing deduction on an arbitrary set of clauses  . 
Considering first the case of Earley Deduction applying to a set of clauses like  ( 3 ) that correspond to a CFG , a sensible thing to do would be to index the derived clauses fie  . the intermediate results ) on the left edge of their location . Because Earley Deduction on such a set of clauses always proceeds in exactly the same manner as Eariey chart parsing  , namely strictly left to right within a constituent  , the position of the left edge of any constituent being searched for is always determined by the ending location of the constituent immediately preceeding it in the derivation  . That is , the proof 15ro-cedure is always searching for constituents with hard , i e . non-variable , left edges . I have no empirical data on this point , but the reduction in the number of clauses that need to be checked because of this indexing could be quite important  . Note that the vertices in a chart act essentially as indices to edges in the manner described  . 
Unfortunately , indexing on the left edge in system working with discontinuous constituents in the manner suggested above would not be very useful  , since the inferencing does not proceed in a left to right fashion  . Rather , if the suggestions at the end of the last section are heeded  , the parser proceeds in a " head first " fashion , looking first for the head of a constituent and then for its complements  , the nature and number of which are partially determined by information available from the head  . ht such a strategy , it would seem reasonable to index clauses not on their location  , but on morphological or categorial features , such as category , case , etc . , since these are the features they will be identified by when they are searched for  . 
It seems then that the optimal data structure for one type of constituent is not optimal for the other  . The question then arises whether there is a unified parsing strategy for both configurational and nonconfiguration all nguages  . Languages with contiguous constituents could be parsed with a head first strategy  , but I suspect that this would proveless efficient than a strategy that indexed on left edge position  . Locations have the useful property that their number grows as the size of the sentence  ( and hence the number of constituents ) increases , thus giving more indexing resolution where it is needed  , namely in longer sentences . But of course , one could always index on both morphological category and utterance iota-lion  . . . 
?. Comptwison with oth ~ Fram ~ orks
In this section I compare the discontinuous locm ~ ion approach \[ have developed above to some other approaches to free word order : the ID/LP rule format of GPSG  , and the nonconfigurational encoding of LFG . \[ have omitted a discussion of the scrambling and raising rules of Standard Theory and their counterparts in current GB theory because their properties depend strongly on properties of the grammatical system as a whole  ( such a . sauniversal theory of " landing sites ", etc . ): which ( as far as I know ) have not been given insufficiently specific form to enable a comparison  . 
The ID/LP rule format ( Gazdar et al 1985 ) can be regarded as a factoring of " normal " contextfree rules a into two components  , one expressing immediate domination relationships  , the other the linear precedence relationships that hold between daughter constituents  . 
For example , the ID rule in ( 20 ) and the LP rule in ( 21 ) express the same mother-daughter rlationships as the rules in  ( 22 )  . 
(20) S"Io V , NIP , NP , S ' (21) V < S'(22) S--VNP NPS'
S--VNP S*NP
S--VS fNP NP
S--NP VNPS'
S--NP VS fNP
S--NP NP VS'
Because a grammar in ID/LP format always has a strongly equivalent contextfree grammar  , only contextfree languages can be generated by these grammars  . Since it is possible to write grammarss In Gasdaretad  . (1985) the system is more complicated than this , since the ID/LP component interacts with the feature instan-elation principles and other components of the grammar  . 
1 30 for non-context-free languages using discontinuous constituents  ( us shown above )  , it is clear tha & ID/LP format is I~powerful than the discontinuous constituent analysis proposed here  . ~n particular , ID/LP allows only reordering of the daughters of a constitiuent rels-tire to the other daughters : it does not allow a constituent to be " scattered " accrom the sentence in the way a discontinuous constituent analysis allows  , Thus an ID/LP grammar o\[Guugu Yimid hirr could not an a/yse sentence  ( 7 ) in the same way we did here . Infa~t , if we added the requirement that all locations be continuous  ( i e . t bag the location sets contain at moat one member  ) to the DCGr ~ es using the ' combines'predicate , the word order freedom allowed would be the same as that allowed by an ID rule without any LP restrictions  . I do n't claim that it is imposaible to write a GPSG grammar\[ora ~  angua4$e like Guu~pa ~ fL midlxit ~ outhebus is of the formatism's not=flowing dL ~: outinuous cormtituents : on closer inve S-ti Satio ~ it misht turn out that the " discontinuities " could be described by some set of medium or long distance dependencies  . 
In LFG the nature of the mapping between c -structure and f-structure nables it to achieve many of the effects o\[discontinuous ? on stituent a  , even though the phrase structure component ( the c-structure ) does not allow discontinuous constituents ~ such . In psi-ticular , the information represented in one component o\[ the f-structure may come from several di~erent c -structure constituents located throughout the sentence  . For example , in their analysis of the cross serial dependencies in Dutch  , Bresnan , Kaptan , Peters and Zaenen ( 1982 ) propose that the PREP feature of the VCONIP component of the f-structure is set by a verb located down one branch of the c  . structure tree , while the OBJ feature of that component is set by an NP located on another branch othec  . structure tree . 
Thus in LFG one would not claim that there was a discontinuous NP in  ( 7~ , but ralAer that both the ergative NP and the genitive msrkede~ative NP were contributing information to the same corn-portent of the f -structUre  . 
\[ n the . on-confiquratian aicn codlaf of Bresnan (1982, p . 297) , the c-structure is relatively impoverished , and the morphology ' on the lexica ~ items identifies the component of the f-structure they supply information to  . For example , the c-structure in ( 23 ) together with the lexical items in ( 24 ) give sentence ( 7 ) the f-structure ( 25 )  . 
(23) S_NP , ~=\[ V *
NP ( TSUBJ poss ) = L
Varraea.aga.mu-n(I,CASE == Erg(LOcal=+
NPg . d == ( tOBJ ) =\[( tCASE-~--Abs
V gunda.y(TPRED ) ~ ffihit((tSUBJ),(\[OBJ))
NP biiba.nonn.(1SUBJ==L(tCASE\]-----~rZ(25)
CASE = - Erg1
POSS == Gen == +
LPRED == aoy
SUBJ=CASE == Erg " ~
PRED=\[=ther/oASE = Abs/
OBJ-PRED = do 9~..-'~
PP~D = h;t(-~
LFG is capable of describing the " discontinuity " of  ( 7 ) without using discontinuous constituents . There is , however , a subtle difference in the amount of " discontinuity " allowed by the LFG and the discontinuous constituent analyses  . As remarked at the beginning of the paper , the discontinuous constituent approach al/ows grammars that accept to ts/scrambling of the lexical items : if a string S is accepted  , then so is any permutation of S . In particular , the discontinuous constituent approach glows unrestricted scrambling of elements out of embedded clauses and stacked N'Ps  . 
which the LFC nonconfigurational encoding analysis cannot  . This is because the position in the sentence's f -structure that any lexical item occupies is determined solely by the f-equation annotations attached to tha L lexical item  , since the only equations in the c-structure are of the form ~ L  , and these create no new components in the f -structure for the clause to embed the fstructures from lexi-ca/items into  . 
Suppose , for example , Guugu Yimid hirrallowed stacked NP poesees ors , in the same way that English allows them in constructions like my mother's  lather'8 brother , except that , because the language is non-conFigurational , the lexical elements could be scattered throughout the entire sentence  . The LFG analysis would run into problems here , because there would be a potentially infinite number of positions in the f-structure where the possessor could be located : implying that there are an infinite number of lexical entries for each poaae ~ ive NP  . 
Guugu Yimid hirr does not exhibit such stacked possessives  . 
Rather , the possessor of the possessor is indicated by a dative construction and so *  , he LFG analysis is supported here . Nonetheless , a similiar argument shows that embedded clausal f -structure components such a  . sadjunts or VCOMP must have corresponding c -structure nodes so that the lexical items in these clauses can be attached sufficiently " far down " in the f-structure for the entire sentence  . ( Another possibility , which\[won't explore here , would be to allow f-equation annotations to include regularez pressiona over items like VCOMP I-Still  , it would be interesting to investigate further the restrictions on scrambling that follow from the nonconfigurational encoding analysis and the bame principles of LFG  . 
For instance , the a ~ T in c parsa 6 dity property ( F'ereira and Warren 1983 ) that is required to assure decidablity in LFG ( Bresnan and Kaplan 1982 ) essentially prohibits scrambling of single lexical elements from doubly embedded clauses  , because such scrambling would entail one S node exhaustively dominating another  . But these distinctions are quite subtle , and , unfortunately , our knowledge of u on-configurational languages is insufficient o determine whether the scrambling they exhibit is within ' the limits allowed by non -configurations/encoding  . 
8 . Conchmion\['\[ale ( 1983 ) begins his paper by listing three properties tha ~ . 
have come to be associated with the typological label ~ nonconfigurational '  , namely ( i ) free word order ,   ( ii ) the use of : ~ yntacti-tally discontinuous constituents and  ( iii ) the extensive use of null anaphora . \[ n this paper \[ have shown that the flint two properties follow from a system that allows constituents that have discontinuous constituents and that captures the mother daughter location relationships using a predicate like ' combines '  . 

It is still far too early to ~ ell whether this approach really is the moe~appropriate way to deal with discontinuous coustituente : it may be that for a grammar of ressons ble size some other t~echnique  , such as the nonconfigurational encoding of LFG , will be superior on linguistic and computational grounds  . 
9. Bibliosrsphy
J . Bresnaa (1982) , " Control and Complemencation , " in The Mental Representation of Gr4mmatizal Rdatione , J . Bresn~n , ed . , pp .  173 . 281, ~ Pre ~, Cambrid Ke , Ma ~ . 
J . Bresnan and R . Kaplan (1982) , " Lexical Functional Grammar : A Formal System for Grammatical Representation  , " in The Mental Reprce cntatien of Grammatical Relations  , J . Bresnan , ed . , pp . t73 . 281, MIT Press , Cambridge , Mass . 
J . Bresnan , R . Kaplan , S . Peters and A . Zaenen (1982), Croee . Serial Dependeneic * in Detek , Linguistic Inquiry , II . 4, pp . 

G . Ga:ldar , E . Klein , G . Pullum and I . Sag , (1985) Generalized Phrc~e Structure Grammar , Havard University Press , C&m bridge , 

K . Hale (1983) , " Warlpiri and the Grammar of Non-configur , ,tional Languages " , Natural Language and Linguietic
Theory , t.t , pp . 5-.49.
J . H , ~viland (1979) , " Guugu Yimid hirr " , in tf and book of Au-tralian Languegce , R . Dixon and B . Blake , eds . , Benjamius . Amsterdam . 
F . C . N . Pereira . and D . H . D . Warren (1983), " Parsing as Deduction ", Prec . of the 2 let AnnlalMecrinfo\[the ACL , pp . 137-143, A . ~ociation for Computa J : ional Linguistics . 
C . Pollard (1984) , Generalized Phrue Streeturc Grammar a , \[' lead Grammars , and Natural Language , unpublished thesis , Stanford Universiey . 

