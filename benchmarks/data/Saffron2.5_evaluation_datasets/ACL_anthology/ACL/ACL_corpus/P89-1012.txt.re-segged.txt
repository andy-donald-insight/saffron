DICTIONARIES , DICTIONARY GRAM MARS AND DICTION ARYEN TRY PARSING
Mary S . Neff
IBMT . J . Watson Research Center , P . O . Box 704, Yorktown Heights , New York 10598
Branimir K . Boguraev
IBMT . J . Watson Research Center , P . O . Box 704 , Yorktown Heights , New York 10598; Computer Laboratory , University of Cambridge , New Museums Site , Cambridge CB 23 QG Computerist: . . . But , greatScott , what about structure ? You can't just bang that lot into a machine without structure  . Half a gigabyte of sequential fie . . . 
Lexicographer : Oh , we know all about structure . Take this entry for example . You see here italics as the typical ambiguous tructural element marker  , being apparently used as an undefined phrase -entry lemrna  , but in fact being the subordinatentry head word address preceding the small-cap cross-reference h adword address which is nested within the gloss to a defined phrase entry  , itself nested within a subordinate ( bold lower case letter ) sense section in the second branch of a forked multiple part of speech main entry  . Now that's typical of the kind of structural relationship that must be made crystal-clear in the eventual database  . 
from " Taking the Words out of His Mouth "-- Edmund Weiner on computerising the Oxford English Dictionary  ( The Guardian , London , March ,  1985)

We identify two complementary p . ro . cesses in . the conversion of machine-readabledmUonanes into lexical databases : recovery of the dictionary structure from the typographical markings which persist on the dictionary distribution tapes and embody the publishers ' notational conventions  ; followed by making explicit all of the codified and ellided information packed into individual entries  . 
We discuss notational conventions and tape formats  , outline structural properties of dictionaries , observe a range of representational phenomena particularly relevant to dictionary parsing  , and derive a set of minimal requirements for a dictionary grammar formalism  . We present a general purpose dictionary entry parser which uses a formal notation designed to describe the structure of entries and performs a mapping from the flat character stream on the tape to a highly structured and fully instantiated representation f the dictionary  . We demonstrate the power of the formalism by drawing examples from a range of dictionary sources which have been processed and converted into lexical databases  . 
I . INI"RODUCTION
Machine-readable dictionaries ( MRD's ) axe typi , tally ayailable in the form of publishers type setting tapes  , and consequently are represented by a fiat character stream where lexical data proper is heavily interspersed with special  ( control ) characters . These map to the font changes and other notational conventions used in the printed form of the dictionary and designed to pack  , and present in a codified compact visual format , as much lexical data as possible . 
To make maximal use of MRD's , it is necessary to make their data , as well as structure , fully ex-~licit , in a database format that lends itself to exible querying  . However , since none of the lexical database ( LDB ) creation efforts to datefully addresses both of these issues  , they fail to offer a general framework for processing the wide range of dictionary resources available in machine-readable form  . As one extreme , the conversion of an MRD into an LDB may be carried out by a ' one-off " program -- such as  , for example , used for the Longman Dictionary of Contemporary English  ( LDOCE ) and described in Bogtbr_aev and Briscoe ,  1989 . While the re-suiting LDB is quite explicit and complete with respect othed at a in the source  , all knowledge of the dictionary structure is embodied in the conversion program  . On the other hand , more modular architectures consisting of a parser and a_grammar--best exemplified by Kazman's  ( 1986 ) analysis of the Oxford English Dictionary ( OED ) -- do not deliver the structurally rich and explicit LDB ideally required for easy and unconstrained access to the source data  . 
The majority of computational lexicography projects  , in fact , fall in the first of the categories above , in that they typically concentrate on the conversion of a single dictlonar v into an LDB : examples here include the work l~ye  . g . Ahlswede et al ,  1986 , on The Web ster's Seventh New Collegiate Dictionary  ; Foxeta / . , 1988 , on The Collins English Dictionary ; Calzolari and Picchi ,  1988 , on HNuovo Dizionario Italiano Garzanti ; van der Steen ,  1982 , and Nakamura ,  1988 , on LDOCE . Even work based on multiple dictionaries ( e . g . in bilingual context : see Calzolari and Picchi ,  1986 ) appear to have used specialized programs for eac ~dictionary source  . In addition , not an uncommon property of the LDB's cited above is their incompleteness with respect othe original source : there is a tendency_to extract  , in a preprocessing phase , only some fragments ( e . g . 
9 1 part of speech information or definition fields ) while ignoring others ( e . g . etymology , pronunciation or usage notes ) . 
We have built a Dictionary Entry Parser ( DEP ) together with grammars for several different dictionaries  . Our goal has been to create a general mechanism for converting to a common LDB format a wide range of MRD's demonstrating a wide range of phenomena  . In contrast othe OED project , where the data in the dictionary is only tagged to indicate its structural characteristics  , we identify , two processes which are crucial for the ' unfolding  , or making explicit , the structure of an MRD:identification of the structural markers  , followed by their interpretation i context resulting in detailed parse trees for individual entries  . Furthermore , unlike the tagging of the OED , carried out in several passes over the data and using different grammars  ( in order to cope with the highly complex , idiosyncratic and ambiguous nature of dictionary entries  )  , we employ a parsing engine exploiting unification and backtracking  , and using a single grammar consisting of three different sets of rules  . The advantages of handling the structural complexities of MRD sources and deriving corresponding LDBs in one operation become clear below  . 
While DEP has been described in general terms before  ( Byrd et al , 1987; Neffeta/ .   ,  1988) , this paper draws on our experience in parsing the Collins German-English/Collins English German  ( CGE/CEG ) and LDOCE dictionaries , which represent wo very differentypes of machine -readable sources vis-~t-vis format of the type setting tapes and notational conventions exploited by the lexicographers  . We examine more closely some of the phenomena encountered in these dictionaries  , trace their implications for MRD-to-LDB parsing , show how they motivate the design of the DEP grammar formalism  , and discuss treatment of typical entry configurations  . 
2. STRUCTURAL PROPERTIESOFMRD'S
The structure of dictionary entries is mostly implicit in the font codes and other special characters controlling the layout of an entry on the printed page  ; furthermore , data is typically compacted to save space in print  , and it is common for different fields within an entry to employ radically different compaction schemes and abbreviatory devices  . For example , the notation T5 a , b , 3 stands for the LDOCE grammar codes T5 a ; T5b ; T3 ( Boguraev and Briscoe ,  1989 , present a detaile description of the grammar coding system in this dictionary  )  , and many adverbs are stored as run-ons of the adjectives  , using the abbreviatory convention ~ ly ( the same convention applies to ce ~ a ~ o types of at fixation in general : er  , less , hess , etc . ) . In CGE , German compounds with a common first element appear grouped together under it : Kinder-:  . ~ . eh orm children's choir ; -- do ent children's\[village ; -ehef child marriage . IDictionaries often factor out common substrings in data fields as in the following LDOCE and 
CEG entries : i a . cu . bLtor . . . a machine for a keeping eggs warm until they HATCH b keeping a live babies that are too small to live and breathein ordinary air Figure I  . Def'mition-initial common fragment Bankrottm- ( e ) 6 , -ebankruptcy ; ( fig ) break down , collapse ; ( moralisch ) bankruptcy . ~machen to become orgo bankrupt ; den-an mel denoransage norerld ~ rento declare one self bankrupt  . 
Figure 2 . Definition-final common fragment Furthermore , a variety of conventions exists for making text fragments perfo  . ,rm more than one function ( the capitalization of ' HATCH above , for instance , signals a close conceptual link with the word being defined  )  . Data of this sort is not very useful to an LDB user without explicit expansion and recovery of compacted head words and fragments of entries  . Parsing a dictionary to create an LDB that can be easily queried by a user or a program therefore implies not only tag-g ~ ag the data in the entry  , but also recovering ellided information , both inform and content . 
There are two broad types of machine-readable source  , each requiring a different strategy for recovery of implicit structure and content of dictionary entries  . On the one handtapes may consist of a character stream with no explicit structure markings  ( as OED and the Collins bi-linguals exemplify )  ; all of their structure is iml ~ li . ed in the font changes and the overall syntaxot the entry  . On the other hand , sources may employ mixed r ~ presentation , icorporating both global record delhniters and local structure n coded in font change codes and /or special character sequences  ( LDOCE and Web sters Seventh )  . 
Ideally , all MRD's should be mapped onto LDB structures of the same type  , accessible with a sin-~le query language that preserves the users intuition about tile structure of lexical data  ( Neffeta / . , 1988; Tompa ,  1986) , Dictionary entries can be naturally represented as shallov ~ hierarchies with a variable number of instances of certain items at each level  , e . g . multiple homographs within an entry or multiple senses within a homograph  . The usual in lieritance mechanisms associated with a hierarchical orgard sation of data not only ensure compactness of representation  , but also fit lexical intuitions . The figures overleaf show sample entries from CGE  , and LDOCE and their LDB forms with explicitly unfolded structure  . 
Within the taxonomy of normal forms . ( NF ) de-freed by relational database the o ~ , dictionary entries are ' unnormalized relations in which attributes can contain other relations  , rather than simples calar values ; LDB's , therefore , cannot be correctly viewed as relational data bases  ( seeNeff et al ,  1988) . Other kinds of hierarchically structured data similarly fall outside of the relational Uberschriftf  ; ( Film ) Untertitelm ; ( form of address ) Am'e def . what--do yongive a bish op ? wie redetor sprichtman?inen Bischofan ?  ( b )   ( Jur )   ( right )   ( Rechts ) ans pruch ( to auf + acc )  , Titel ( spec)m ; ( document ) Eigentum surkundef . 
entry + - hc : l ~: title t ? -$ upert ' K ~ ...
+- pos:n~-slns?-seflsflclm:a+-tran . _qroupl +- tran
I ? ~ rd:Tite l
I+-gendmr:m
I+S in : also Sport
I?-tran_group
I :-~_ rlote : of chapter

I ?- word : ( lberschrift
I?-gender:f
I+-tran_. group
I+-domain : Film
I?-trim
I +- woPd : Untertite l
I+-~r:m
I ?- tran~r ~ 3 up
I+-usaglt_note:form of address
I ? -? ran
I + -' NON : Ant ? de I +- gender : f + - collocat ?- source : what--?o you give a bishop ?*-~ rget ? - ~ ease : wiere det/or/sprichtman ? inert Bischofan ?  ?-$11~1 ?-$ ensllum:b+-domain:Jur ?-? r-an_group ? -usagl_noti:rightt-train?-Nord : Rechtsans pruch ?'- Nord : Ans pruch +- comlmmmt 
I ? - ~ r4) co~p:to
I+-~Poomp : auf + acc ?- gef ~ Br:me-?ran+- word:Titel+-style:spec?-~ndlr:m ?-? rangroup ? - usage_note:document ?-? ran+- Nord : Eigentum surkunde ?- gender : f 
Figure 3. LDB for a CEG entry
NF mould ; indeed recently there have been efforts to design a generalize data model which treats fi at relations  , lists , and hierarchical struc-Ures uniformly ( Dadam et al ,  1986) . Our LDB rmat and Lexical Query l_anguage ( LQL ) support the hierarchical model for dictionary data  ; the output of the . parser , similar to the examples in Figure 3 and Figure 4 , is compacted , encoded , and loaded into an LDB . 
nei . ~, . ce/'nju:s~nsII'nu:-:nIa person or an ? real that annoys or causes trouble  , PEST : Don't make a nuisance of your self . " sitdown and be quiet ! 2 an action or state of affairs which causes trouble  , offence , or unpleasantness : What a nuisance ! I've forgotten my ticket  3 Commit nonuisance ( as a notice in a public place ) Do not use this place as a alavatory baTIP ~ entry ?- I'w Jb #: nuisance 
I+-SUlmPhom?-print foist1:nui.sance
I+-primaw
I ? - peonstrir ~ j : " nju:sFnsII " nu : -+ -syncat:n 
I+-sensa_def+-sense_no:1?-darn
I ?- implicit_xrf
II+-to:pest
I ?- defstril ~: a person or animal that annoys or causes trouble: 
I pest?-example ?- eXstril ~: Don't make a nuisance of your self:s it down an ? be quiet /? -sense_def?-slmse  . no:2 + . -defnI?-def_string : an action or state of affairs \[ which causes trouble  , offence . 
I or unpleasantness +- example ?- ex_strirlg : What a nuisance li've forgotten my ticket+- sense_def?-sense no:  3 ?- de~-?-h ? ~ j ~ rase : Commit nonuisance + - quail ? let : as a notice in a public place +- subdefn 
I a
I+-def_stril ~: Do not use this place
I as a lavatory ?-~ . ~ b_dlfn+-seq_no : b ? -- defn*-i . ~li ? it_xrf
I*-to:tip
I ? - h ? ~ no: 4 ?- dQfs\]ril ~ J ~: Do not use this place as a tip
Figure 4 . LDB for an LDOCE entry 3 . DEP GRAM MAR FOR MALISM The choice of the hierarchical model for the representation of the LDB entries  ( and thus the output of DEP ) has consequences for the parsing mechanism . For us , parsing involves determining the structure of all the data  , retrieving implicit information to make it explicit  , reconstructing ellided information , and filling a ( recursive ) template , without any data loss . This contrasts with a strategy that fills slots in predefmed  ( and finite ) sets of records for a relational system , often discarding information that does not fit . 
In order to meet these needs , the formalism for dictionary entry grammars must meet at least three criteria  , in addition to being simply a notational device capable of describing any particular requirements for such a formalism  . 
3.1 Effects of context
The graham ,_ . ~formalism should be capable of handling mildly context sensitive ' input streams  , as structurally identical items may have widely differing functions depending on both local and global contexts  . For example , parts of speech , field labels , paraphrases of cultural items , and many other dictionary fragments all appear in the CEG in italics  , but their context defines their identity and , consequently , their interpretation . 
Thus , in the example entry in Figure 3 above , m , ( also Sport ) , ( of chapter ) , and ( spec ) acquire the very different labels of pos , do , in , us = g=_not = , and sty1 . = . In addition , to distin-t~ish between domain labels , style labels , dialectels , and usage notes , the rules must be able to test candidate lements against a closed set of items  . Situations like this , involving subsidiary application of auxiliary procedures  ( e . g . string matching , or dictionary lookup required for an example below  )  , require that the rules be allowed to selectively invoke external functions  . 
The assignment of labels discussed above is based on what we will refer to in the rest of this paper as global context  . In procedural terms , this is defined as the expectations of a particular grammar fragment  , reflected in the names of the asso-date drides , which will be activated on a given p are through the grammar  . Global context is a dynamic notion , best thought of asa'snapshot ' of the state of the parser at any_point of processing an entry  . In contrast , local context is defined by finite-length patterns of input tokens  , arid has the effect of Identifying typographic' lues to the structure of an entry  . Finally , immediate context reflects v . eryloc ~ character patte12as which tend t 9 drive the initial segment at m not the ' raw'tape character stream and its fragmentation i to structure - and information-carrying tokens  . 
These three notions underlie our approach to structural analysis of dictionaries and are fundamental to the grammar formalism design  . 
3.2 Structure manipulation
The formalism should allow operations on the ( partial ) structures delivered during parsing , and not as . separate reetranstormations once processing is complete  . This is needed , for instance , in order to handle a variety of scoping phenomena  ( discussed in section 5 below )  , factor out items common to more than one fragment within the same entry  , and duplicate ( sub- ) trees as complete LDB represent at mns ~ being fleshed out  . 
Consider the CEG entry for a butment ":
I a butment\[ . , . \] n(Archit ) Fl tigel-or Wangenmau erf . I Here , as well as in " title " ( Figure 3) , a copy of the gender marker common to both translatmns needs to migrate back to the ftrst tram  . In addition , a copy of the common second compound element- mauer also needs to migrate  ( note that e _ : a but ment
I?-superhom , I .-$ ens?-tPan_group+-tran
I+-i Nord : F/O gelmauer
I*-~nd=r:f?-tran+ . - t , K ) rd:Wangenmauer?-gender:fidentifying this needs a separate noun compound parser augmented with dictionary lookup  )  . 
An example of structure duplication is illustrated by our treatment of  ( implicit ) cross-references in LDOCE , where a link between two closely related words is indicated by having one of hem type set in small capitals embedded in  , a definition of the other ( e . g . " PEST ' and " TIP ' in the deft-nitions of " nuisance " in Figure  4  )  . The dual purpose such words serve requires them to appear on at least two different nodes in the final LDB structure : ? ~ f_string and implicit_xrf  . In order to perform the required transformations , the formalism must provide an explicit dleon partial structures  , as they are being built by the parser , together with operations which can mariipulate the m--both in terms of structure decomposition adnode migration  . 
In general , the formalism must be able to deal witli discontinuous constituents  , a problem not dissimilar to the problems of discontinuous constituents in natural language parsing  ; however in dictionaries like the ones we discuss the phenomena seem less regular  ( if discontinuous constituents can be regarded as regular at all  )  . 
3.3 Graceful failure
The nature of the information contained in dic -tionaxies is such that certain fields within entries do not use any conventions or formal systems to present heir data  . For instance , the " USAGE " notes in LDOCE can be arbitrarily complex and unstructured  .   . fragments, . c?m bining straagh text with a vanety of not attonal devices  ( e . g . font changes , item highlighting and notes segmentation ) in such a way that no principled structure may be imposed on them  . Consider , for example , the annotation of " loan ": loan2 v . . . . . . . . esp . AmE to give ( someone ) the use of , lend . . . . . . . . USAGE It is perfectly good AmE to use loan in the meamng of lend : He loaned me ten dollars  . 
The word is often used mBrE , esp . in the meaning ' to lend formally for along period ': Helo an edh/s collection of pictures to the public GALLERY but many people do not like it to be used simply in the meaning of lend in BrE  . . . 
Notwithstanding its complexity , we would still like to be able to process the complet entry  , recovering as much as we can from the regularly encoded information and only'skipping'over its truly unparseable fragment  ( s )  . Consequently , the formalism and the underlying processing flame -for explicitly handling such data  , systematically occumng in dictionaries . 
The notion of . graceful failure is , in fact , best regarded as ' sele dive parsing ' . Such a mechanism has the additional benefit of allowing the incremental development of dictionary grammars with  ( eventually ) complete coverage , and arbit . r - ~ . rydepth of analysis , of the source data : a particular grammar might choose  , for instance , to treat everything but the head word , part of speech , and pronunciation as ' junk ' , and concentrate on elaborate parsing of the pron . u:n , ciation fields , while still being able to accept all input without having to assign any structure to most of it  . 
4. OVERVIE WOFDEP
DEP uses as input a collection of ' raw ' type setting images of entries from a dictionary  0  . e . a type setting . tape . with begin-end'boundaries of entries explicitly marked  ) and , by consulting an externally supplied . gr-qmmars . p  ~ . " c for that particular dictionary , produces explicit structural representations for the individual entries  , which are either displayed or loaded into an LDB . 
The system consists of a rule compiler , a parsing n D g ~ B e , a dictionary entry template generator , an loader , and various development facilities , all in a PROLOGs hell . User-written PROLOG functions and primitives are easily added to the system  . The fdrmalism and rule compiler use the Modular Logic Grammars of McCo /' d  ( 1987 ) as a point of d~ure , but they have been substantially modified and extended to reflect here quirements of parsing dictionary entries  . 
The compiler accepts three different kinds of rules corresponding to the three phases of dictionary entry analysis : tokenization  , retokenization , and proper . Below we present informally ghts of the grammar formalism  . 
4.1 Tokenization
Unlike in sentence parsing , where tokenization ( or lexical analysis ) is driven entirely by blanks and punctuation , the DEP grammar writer explicitly defines token delimiters and token substitutions  . Tokenixation rules specify a one-to-one mapping from a character substring to a rewrite token  ; the mapping is applied whenever the specified substring is encountered in the original type setting tape character stream  , and is only sensitive to immediate context . Delimiters are usually font change codes and other special characters or symbols  ; substitutions axe atoms ( e . g . 
ital_correction , field_m ) or structured terms be . g . fmtlitalicl , ~!"1"I) . Tokenization reaks the source character stream into a mixture of tokens and strings  ; the former embody the notational conventions employed by the printed dictionary  , and are used by tlae parser to assign structure to an entry  ; the latter carry the textual ( lexical ) content of the dictionary . Some sample rules for the LDOCE machine-readable source  , marking the beginning and end of font changes , or making explicit special print symbols , are shown below ( to facilitate readability ,   ( * AS ) re-presents the hexa decimal symbol x ' AS ' )   . 
do lim ("( ~ i ) ", font(i ~ alic).
dolia (" ( UCA ) " , font(beginlsamll_caps)I ) . 
do lim ( II~mS ) i if ~ r ~ t ( end ( small_caps )   )   )  . 
do lim ! "( ~) ", ital correction).
delill("OqlO ) ", hyl~in_mark).
Immediate context , as well as local string rewrite , " can be specified by more elaborate tokenization rules  , in which two additional argument specify strings to be ' glued ' to the strings on the left and right of the token delimiter  , respectively . For
CEG , for instance , we have dotiml " . > u4<", f~t;~l ;) > ~) . <? ' )  . delim(":>u ~<" , delim ("> uS <" , font(roman)) . 
Tokenization ope Eates recursively on the string fragments formed by an active rule  ; thus , appli-catton of the first two rules above to the stnng  , , mo ~ . : ~ a , : ~ r ~" results in the following token list : " xxx "  . lad . fontlbold ), " y~?" . 
4.2 Retokenization
Longer_-range ( but still local ) context sensitivity ~ isir fiplemented via retokenization  , the effect ot which is the ' normalization ' of the token list  . 
Retokenization rules conform to a general rewrite format--a pattern on the lefthand side defines a context as a sequence of  ( explicit or variable placeholder ) tokens , in which the token list should be adlusted as indicated by the righthand side--and can be used to  . perform a range of cleaning up tasks before parsing proper  . 
Streamlining the token list . Tokens without information-or structure-bearing content  ; such as associated with the codes for fialic correction or thin space  , are removed : ital correction : , Seg < :> ? Seg . 
Superfluous font control characters can be simply deleted  , when they follow or precede certain data-can'ying tokens which also incorporate type setting information  ( such as a homogra . phsuperscript symbol or a pronunciation marker indicating the be ~ finning of the scope of a phonetic font  ) : rkfont ! phonetic ) < ? rk . 
suplN ) < ? R(R e ) adjusting the token list . New tokens can be introduced in place of certain token sequences : bra:fonttitalic  ) <=> begin l restric ~ ion )   . 
f ~' t t ( r ~ m ~' t ) : ket <? ~ wl ( r ~ strict i ~' b )   . 
Reconstruction of string segments . Where the initial ( blind ) tokenization has produced spurious lragraentation  , string sewnents can be suitably reconstructed . For instance , a hyphen-delimited sequence of syllables in place of the print form of a head word  , created by tokeni ~ ation on ~ , -rg ) , can be ' glued ' back as follows : * Syl_l : ~ mark :+$  1 Zt strxngpTSyl 1   ) :$ s~r~ngp ( S ?12 ) <=> w ~ oin ( Seg , S~1_1 .  '  .   .   .   .   . $ yl_2 . n : l " It ~ . 
This rule demonstrates a characteristic property.
of the DEP formalism , discussed in more detail to e . g . constrain rule application or manipulate strings . Thus , the rule oialy applies to string tokens surrounding a hyphen character  ; it manufactures , by string concatenation , a new segment which replaces the triggering pattern  . 
Further segmentation . Often strings need to be split , with new tokens inserted between the pseces , to correct in felicities in the tapes , or to insert markers between recognizably distinct contiguous segments that appear in the same font  . 
The rule below implements the CGE/CEG convention that as wung dash is an implicit switch to bold if the current font is not bold already  . 
font IX : $ ( -X = bold ) : ? E : t string pl Etcm ~= at ( A , B , E ) t concat("~' , re , B :<=> rant(X ): ? A : font(bold:+B . 
Dealing with irregular input . Rules that rearrange tokens are o~te needed to correct errors in the tapes  . In CEG/CGE , parentheses surrounding italic items often appear  ( erroneously ) in a roman font . A suite of iaxles detaches the stray parentheses from the surrounding tokens  , moves them around the fontmarker , and glues them to the item to which they belong . 
+ E : $ strir ~ piE ): t ? on cat (") " ~ E1 , EI <=> t0)n-:+El . /* detach*/font(F ) :") "< ? . , ), o :: retoKen(font(F )) . /* move */+ E : Sstrirtgl = iE )  : "  ) ": to c ~: at ( E , ") " ~ E1 < :> ? El . / ~ gluo*/eot ~ um invokes retokenization recursively on the sublist beginning with font t e  ) and including all tokens to its right . Inp " nneiple , the three rules can be subsumed by a single one ; in practice , separate rules also ' catch ' other types of erroneous or not s  )  , input . 
Although retokenization is conceptually a separate process  , it is interleaved in practice with tokemzation , bringing imp . rovements in performance . Upon completion , the tapes tream corresponding , for instance , to the LDOCE entry nontrivial manipulation of ( partial ) trees , a simplicit and/or ellided information packed in the bntries is being recovered and reor -gaxxized  . Parsing is a topdown depth-first operation , and only the first successful parse is used . This strategy , augmented by a ' junk collection ' mechanism ( discussed below ) to recover from parsing failures , turns out to be adequate for handling all of the phenomena encountered while assigning structural descriptions to dictionary entries  . 
Dictionary grammars follow the basic notational conventions of logic grammars  ;   . however , we use additional operators tailored to the structure manipulation requirements of dictionary parsing  . In pLrticular , the right hand side of gramma rules admits the use of-four different types ot operators  , designed to deal with token list consumption , token list manipulation , structure assignment , and ( local ) tree transformations . These operators suitably modify the expansions of grammar rules  ; ultimately , all rules are compiled into Prolog . 
Token consumption . Tokens axe removed from the token list by the + and-operators  ; + also assigns them as terminal nodes under the head of the invoking rule  . Typically , delimiters introduced by tokenization ( and retokenization ) are removed once they serve their primary function of identifying local context  ; string segments of the token list are assigned labels and migrate to appropriate places in the final structural represen-iatio not an entry  . A simple rule for the part of speech fields in CEG  ( Figure 3 ) would be : los : :>- fzntlitalic ) = + Sag . 
A structured terms tpos , " n " . nil ) is built as a result of the rule consuming , for instance , the token " n " , Rule names are associated with attributes in the LDB representation for a dictionary entry  ; structures built by rules are pairs of the form sire  , V i i = l , wherevel t ~ is a list of one or more elements ( strings or further structures ' returned ' by reeunively invoked rules  )  . 
au . tit . fi ?; ??' tistik , adj suffering from AUTISMI : I autistic chlld / behaviour --  . . . all y adv\[ Wa4\] IF < wtistic < F <> wO~Oti tC*80~icP<C : " fist ZkH < adj < S < OOOO < O < sufqering from ~CA  ) autism ? ~ B ) * SA ) : ? u ~6 autistic childrm ~ behaviour ( ~ ) R < OZ < R <- nmlZy < R <> < adv < N~<is converted into the following token list : maHtarf ld ~  . p@ma Hter . 
pro~_wm rker-~s d_--rker do ~ marker font . T ~, inlmll caps ) . 
~t ..11. bag in ~ e~m).
" autistic " " au-tis-tic " " C:"t lst lk "- adp  0   "0000" " suffering from " " a ~ uti ~ a #'" amtisti ? a hild/be ~ viour "  "01" Token list manipulation . Adjustment of the token list may be required in , for instance , simple cases of recovering ellided information or reordering tokens in the input stream  . This is achieved by the tmandir ~ x operators , which respectively insert single , or sequences of , tokens into the token list at the current position  ; and the ++ operator , which inserts tokens ( or arbitrary tree fragments ) directly into the structure under construction . Assuming a global variable, . rod , bound to the head word of the current entry , and the ability to invoke a Prolog string concat -enation tunction trom within a rule  ( ~athe * operator ; see below ) , abbreviated morphological derivation stored as run-ons might be recovered ~ l ~ eltlqc ~ rin ~ dor iv  . " autisti(ally " by : ! doriv) . fld_sep . " adv " fl d_sep . " Ha 4" . fld_sep . run_on=:>-rurmn mark:-fon~lbold:-Sag: . . e~x~=~l ,,-,,~ X , Seg ) wi . IX . suffix ) 4 . 3 Parsing t ~ , n ~' l:te , m , : l , x , Oerivl ++ Ooriv . Parsing proper makes use of unification and backtrracking to handle identification of segments  ( it in is separately defined to test for membership by context  , and is heavily augmented with some of a closed class of suffixes  . ) assign arbitrary structures directly to the node in the tree which is currently under construction  . A more general mechanism for retaining structures for future use is provided by allowing variables to be  ( optionally ) associated with gramma rules : in this way the grammar writer can obtain an explicit handle on tree fragments  , in contrast otlae default situation where each rule implicitly ' returns ' the structure it constructs to its caller  . 
The following rule , for example , provides a skel-et on treatmen to the situation exemplified in Figure  4  , where a definition-initial substring is common to more than one sub-definition : d of s = ?  ( Sag ) : sstj  xkafs ( X ) ==> subdof ( X ) : opt ( subdofs ( X )   )   . 
subd of ( X ) ==>- font ( bold ) : sdletter:-fontlrol~n ) : ~ n cat lX , Seg , DefStr~ng ) : in s ( Def String ) : dof_strxng . 
Sd : Fletter=>*Sag~veri~(Seg , " a be ") . 
de_siring=:>+Sag~estring p(Seg).
The defs rule removes the defmition-irtitial string segment and passes : it onto the repeatedly invoked~s  . This manufactures the complete definition string by concatenating the common initial segment  , available as an argument instantiated two levels higher  , with the continuation string specific to any given sub-definition  . 
Tree transformations . The ability to refer , by name , to fragments of the tree being constructed by an active gramma rule  , allows arbitrary tree transformations using the complementary operators - z  . and + ~ . . They can only be applied to nonterminal grammar ules  , and require the explicit specification of a placeholder variable as a rule argument  ; this is bound to the structure constructed by the rule  . The effect of these operators on the tree fragments constructed by the rules they modify is to prevent heir incorporation into the local tree  ( in the case of - z )  , to explicitly splice it in ( in the case of ? z ) , or simply to capture it ( z ) . The use of this mechanism in conjunction with the structure naming facility allows both permanent deletion of nodes  , as well as their practically unconstrained migration between  , and within , different levels of grammar ( thus implementing node raising and reordering )  . It is also possible to write a rule which builds no structure  ( the utility of such rules , in particular for controlling token consumption and junk collection  , is discussed in section 5) . 
Node-raising is illustrated by the grammar fragment below  , which might be used to deal with certain collocation phenomena  . Sometimes dictionaries choose to explain a word in the course of defining  . anothe related word by arbitrarily in-setting mm ~ -entnes in their defmit mns:lach  . ry . mal'l~kfimal adj\[ Wa51 of or concerning tears of the organ ( lach ~ maigland /'_ . / ) of the body that produces them The potentially complex structure associated with the embedded entry specification does not belong to the definition string  , and should be factored out as a separate node moved to a higher level of the tree  , or even used to create a new tree entirely . 
The rule for parsi . n . g the definition fields of an entry makes a provmon for embedded entries  ; the structure built as an ~ entry is bound to the str  , acargument in the a of n rule . The-z operator prevents the ~_ entry node from being incorporated as a daughter to a e~n : however  , by finification , it begh as its , mi ' , gr , ation ' upwards ' through the tree , till it is ' caught by the entry rule several evels ~ gher and inserted  ( via ? x ) in its logically appropnate place . 
entry::>head:ton:pos:code:defn ( Em~fled ) : + X embedded_entry l Embedded )   . 
ckafn ( StrIJc ) = => - Segl : S string p ( Segl ) :- Ze ~= ~ KJ ded entry ( Struc ) -Seg2: $ s ~ ring p ( Seg 2 ) $ concatSegl , S ~2 , 
De?String ) :*+ OefString.
embedded_entry ==>- bra: .   .   .   .   .   .   .   . :- ket . 
Capturing generalizations/execution control.
The expressive power of the system is further enhanced by allowing optionality  ( via the opt operator )  , alternations ( I ) and conditional constructs in the gra'--: nar ules  ; the latter are useful both for more co ~::: ,  . ,ct rule specification and to control backtracking while parsing  . Rule application may be constrained by arbitrary tests  ( revoked , as Prolog predicates , via at operator ) , and a string operator is available for sampling local context  . The mechanism of escaping to Prolog , the motivation for which we discuss below , can also be invoked when arbitrary manipulation of lexical data -- ranging from e  . g . simple string processing to complex morphological analysis -- 
Is required during parsing.
Tree structures . Additional control over the shape of dictionary " entry trees is provided by having two types of nonterminal nodes : weak and strong ones  . The difference is in the explicit presence or absence of nodes  , corresponding to the rule names , in the final tree : a structure fragment manufactu ~ d by a weak nonterminal is effectively spliced into the higher level structure  , without an intermediate level of naming . One common use of such a device is the ' flattening ' of branching constructions  , typically built by recursive rules : the declarations tr ~  ;   ,  -  , ~_ nonterminals ( clefs . subde ? . nil1 . 
when applied to the sub-definitions fragment above  , would lead to the creation of a group of sister ~ f nodes  , immediately dominated bvaaefs node . Another use of the distinction be-wcteen weak and strong nonterminals is the ef-ive mapping from typographically identical entry segments to appropriately named structure fragments  , with global context driving the name assignment . Thus , assuming a weak label rule which captures the label string for further testing  , analysis of the example labels discussed in 3 . 1 could be achieved as follows ( also see Figure 3 ) : $ strir ~ p ( X\]:-endf resxriction l . 
tr~n ==> opt I do amin I style Idia ZI usaga_note-  ) : word . 
~ o~en==>labeltXi,i ,, X,~_!ab) . ==> label(XS is alX , lab\] . 
dial = ? labellX $ isal X , dial-lab) . 
usa genote == > labellX).
Such a mechanism captures g ~ a eralities in typograp ~ tc conventions employed across any given dictionary  , and yet preserves the distinct , name spaces required for a meaningful unfolding of a dictionary entry structure  . 
5. RANGE OF PHENOME NA TO HANDLE
Below we describe some typical phenomena encountered in the dictionaries we have parsed and discuss their treatment  . 
5 . 1 Messy token lists : controlling token consumption The unsystematic encoding of font changes before  , as well as after , punctuation marks ( commas , semicolons , parentheses ) causes blind tokenization to remove punctuation marks from the data to which they are visually and conceptually attached  . As already discussed ( see 4 . 2) , most errors of this nature can be corrected by retokenization  . Similarly , the confusing effects of another pervasiv error , namely the occurrence of consecuti , efont changes , can be avoided by having are tokenization rule simply remove all but the last one  . In general , context sensitivity is handled by ( re ) adjusting the token list ; retokenization , however , is only sensitive to local context . Since global context cannot be determined unequivob  . ally till parsing , the grammar writer is given complete control over the consumption and addition of tokens as parsing proceeds from left to right--this allows for motivated recovery of ellisions  , as well as discarding of tokens in local transformations  . 
For instance , spurious occurrences of a font marker before a print symbol such as an opening parenthesis  , which is not affected by a font dec-'laration , clearly cannot be removed by are tokenization rulefont ! roman \]: bra <=> bra  . 
(The marker may be genuinely closing a font segment prior to a different entry fragment which commences with  , e . g . , a left parenthesis ) . Instead , a grammar rule anticipating a br~token within its scope can readius the token list using either of :  .   .   .  ==>  .   .   . :-fontlroman):-bra:inslbr-a ) . 
.  .   .  ==>  .   .   . :-fantlromanl:stringlbra .  * \ ]  . 
(The $* ri-e operator tests for a token list with br  ~ as its first element  . ) 5 . 2 The Peter-1 principle : scoping phenomena Consider the entry for " Bankrott " in Figure  2  . 
Translation sharing the label ( fig )   ( " breakdown , collapse ' ) are grOUl > ed together ~6ith commas and separated from other lists with semicolons  . The rest nct lon ( context or label ) precedes the llst and can be said to scope ' right ' to the next semicolon  . 
We place the righ-t-scoping labels or context under the  ( semicolon-delimited ) t  ~ , n_group assister nodes to the multiple ( comma-delimited ) tr--~nodes ( see also the representation of " title " in Figure  3  )  . Two principles a teat work here : mei intaining implicite ~ dence of synonymy among terms in the target langtm ge responds to the " do not discard anything " philosophy  ; placing common data items as high as possible in the tree  ( the ' Peter-minus-1princaple ' ) is in the spirit of Flickinger et al ( 1985 )  , and implements the notion of placing at ~ al node at the hi ~  . est position hitlae tree w laere its value is valid in combination with the values at or below its sister nodes  . The latter principle also motivate sets of rules like ~ rm ~==> "'" pr~n  .   .   . : homograph .   .   .   . 
= => pratt used to account for entries in English where the pronunciation differs for different homographs  . 
5.3 Tribal memory : rule variables
Some compaction or notational conventions in dictionaries require a mechanism for a rule to re  , -member ( part of ) it sancestry or know its sisters descendants . Consider the l ~ roblem of determining the scope of gender or labels immediately following variants of the head word : Advolm turb firont  ( Sw )  , Advokaturskanzleif(Aus)lawyer's offize . 
Tipp fr~eint(lnf ) , ~ pp sef- , - n(pej ) typist . 
Alchemic ( esp Aus ), Akhimi ef alchemy.
The first two entries show forms differing , respectively , in dialect and gender , and register and gender . The third illustrates other combinations . 
The rule accounting for labels after a variant must know whether items of like type have already been found after the hcad word  , since items before the variant belong to the head word  , different items of identical type following both belong in  . -dividua Uy , and all the rest are common to botl a . 
This'tribal'memory is implemented using rule variables : entry : :>  .   .   . ( Idial :$( N : dial )) I(N = f - , ~ dial): .   .   . : opt ( subhm~lN ) .   .   .   . 
subham dl N ==> opt (  $  ( N = nodial ) : optldial )   )  :  .   .   .   . 
In addition to enforcing rule constraints via unification  , rule arguments also act as ' channels ' for node raising and a samcchanis rn for controlling rule behaviour depending on invocation context  . 
This latter need stems from a pervasive phenomenon in dictionaries : the notational conventions for a logical unit within an entry persist across different contexts  , and the subgrammar for such a unit should be aware of the environment i is activated in  . Implicit cross-references in LDOCE are consistently introduced by fontlstall csos \]  , independent of whether the run n in 8 text is a de-fmiu on ( roman font )  , example ( italic ) , or a nera-return to the fontactive before the invocation of iaq  ) iioit = xrf , we allow the analysis of cross-references to be shared : implicit x rftX  ) ==>-1Font ( begin ( stall cams )   )  - :  .   .   . :-? ont(X ) . -dftx *==> .   .   . implicit x r flroaan): .   .   .   . 
ex-txt = ffi > implicit-xrf ( italic ) id_-_tx *==> .   .   . implioit-xvfl bold ) .   .   .   .   . 
5 . 4 Unpacking , duplication and movement of structures : node migration The whole range of phenomena requiring explicit manipulation of entry fragmen trees is handled by the mechanisms for node raising  , reordering , and deletion . Our analysis of implicit cross-references in LDOCE factors them out as separate structural units participating in the make up of a word sense definition  , as well as reconstructs a ' text image ' of the definition text  , with just the orthography of the cross-reference itm's pliced in '  ( see Figure 4 )  . 
darn == > . d of_segs . ! O_String) . : ooT_szringCD_StrtrigJ . 
clefsegs lStr_l ) = ? def_nugget ( Seg )   ( d~fsegslStrO ) 
Str-O : "") - tcon(~*(Seg , Str_O , Str_l ) . 
def_nugget(Ptr ) == > 7 . iatPlicitxr?(s(impliEitxrf , . 
s(to , Ptr . Ril ). Resx)).
def_nuggot ! Seg ) ==> - Seg : Sstring ptSeg) . 
def_strlngiDof ) = = > ? + Oef.
The rules build a definition string from any sequence of substrings or lexical items used as cross-references : by invoking the appropriated e ?_nusmat rule  , the simple segments are retained only for splicing the complete definition text  ; cross-reference pointers are extracted from the structural representation of an implicite ross -reference  ; and it mlicit . _xef nodes are propagated up to a sister position to the dab_string  . The string image is built incrementally ( by string concatenation , as the individual a-?_nutmts are parsed ); ultim , ately the ~?_strir ~ rule simply incorporates tt into the structure for a e ~  . De-claring darn , defstring and implicit_xrf to be strong nonterminal sultimately results in a dean structure similar to the one illustrated in 
Figure 4.
Copying and lateral migration of common gender labels in CEG translations  , exemplified by title ' ( Figure 3 ) and " a butment " ( section 3 . 2) , makes a differr-entuse of the ? z operator . To capture the leftward scope of gender labels , in contrast to common ( right-scoping ) context labels , we create , for each noun translatt on ( tran ) , a gender node with an empty value . The comma-delimited * ran nodes are collected by a recursive weak nonterminal * fans rule  . 
trams ==> tran ( G ) : opt ( -ca:trans ( G )   )   . 
tran(G ) := > .   .   . word .   .   . : opt(-Zoenektr!G )):*7 . gendor ( G ) . 
The ( conditional ) removal of gander " in the second rule followed by  ( obligatory ) insertion of a ~ ne ~ r node captures the gender if present and ' digs a hole ' for it if absent  . Unification on the last iteration of tear ~ fills the holes  . 
Noun compound fragments , as in " a butment " can be copied and migrated forward or backward using the same mechknism  . Since we have not implemented the noun compound parsing mech-ams m required for identification of segments to be copied  , we have temporized by naming the fragments needing partners alt_  . = ? xoralt_sex . 
5 . 5 Conflated lexical entries : homograph unpacking We have implemented a mechanism to allow creation of additional entries out of a single one  , for example from orthographic , dialect , or morphological variants of the original head word  . 
Some CGE examples were given in sections 2 and 5 . 3 above . To handle these , the rules build the second entry inside the main one and manufacture cross reference information for both main form and variant  , in anticipation of the implementation of a splitting mechanism  . Examples of other types appear in both CGE and CEG:vampire\[  . . . \] n(lit)Vampir , Blutsauger ( old ~ m ; ( fig ) Vampirm . -hat Vampir , Blutsauger ( old ) m . 
wader\[ . . . \] n(a ) ( Orn ) Watvogelm . (b ) ~ spl(boots )
Watstief elpl.
house in cpd ~ HaLts- ; ~arrestnHausarrestm ; ~ boatnHaus bootn~-baundadjansHaus gefesselt  ;   . . . .
house: . --hunt via uf Haus suchese in ; they have started--hunting sich a ben angefangen  , a cheinem Hauszu suchen ; -hunting n Haus such en ;   . . . .
The conventions for morphological vari , ' ants , used heavily in e . g . LDOCE and Web sters Seventh , are different and would require a different mechanism  . We have not yet developed a generalized rule mechanism for ordering any kind of split  ; indeed we do not know if itts possible , given the wide variation ~ , seemingly a a hocconventions for's neaking in logically separatentries into related head word efinitions : the case of " lachrymalgland " in  4  . 3 is iustone instance of this phenomena ; below we list some more conceptually similar , but notationally different , examples , demonstrating the embedding of homographs in the variant  , run-on , word sense and example fields of LDOCE . 
d add y long . legs . da ~ i lot ~ jzalso(/'m /) cranefly--n . . . a type of flying insect with long legs ac . rLmo . ny . . . n bitterness , as of manner or language---nious ~ , kri'maunias/adj : an acrimonious quarrel--- niously adv crash I  . . . v . . . 6 in fml also gate crash--to join ( a party ) without having been invited . . . 
folket . y . mol . o . gy , , . .'--~ n the changing of straage or foreign words so that they become like quite common ones : some people say ~ parrow grass instead of ASPARAGUS : that ia an example of folk etymology tokenization Often distinctly different data items appear contiguous in the same font : the grammar codes of LDOCE  ( section 2 ) are just one example . Such run-together segments clearly need their own tokenization rules  , which can only be applied when they are located during parsing  . Thus , commas and parentheses take on special meaning in the string " X  ( to be ) l , 7" , indicating , respectively , ellision of data and optionality of p~ase . 
This is a different interpretation from e . g . alternation ( consider the meaning of " adj , noun " ) or the enclosing of italic labels m parentheses ( Figure 3 )  . Submission of a string token to further tokemzation is best done by revoking a special purpose pattern matching module  ; thus we avoid global ( and blind ) tokenization on common ( and ambiguous ) characters such as punctuation marks . The functionality required for selective tokenization is provided ' by a ~ e primitive  ; below we demonstrate he construction of a list of sister synca * nodes from a segment like " n  , v , adj " , repetitively invoking o a ) - ~ a ) to break a string into two substring separated by a comma:-Seg : $ stri  (   ) : syr~ats==>$t~rse ( Hd . " ~ n ~ . Re~s . nil , Se9): in s1(Hd . Rest . nil):st syncat ?, ~ a:: optt syncats ) . == tin(Seg , port of speec : h1 . 
5.7 Parsing failures : junk collection
The systematic rregularity of dictionary data ( see section 3 . 3 ) is only one problem when parsing dictionary entries  . Parsing failures in general are common during . gr- , ~maar development ; more specifically , theytmght arise due to the format of an entry segment being beyond  ( easy ) capturing within the grammar formalism , or requiring nontrivial external functionality ( such as compound word parsing or noun/verb phrase analysis  )  . 
Typically , external procedures o ~ . rate on a newly constructed string token which represents a ' packed ' unruly token list  . Alterna Uvely , if no format need be assigned to the input , the grax n . -mar should be able to'skip over ' the tokens m the list  , collecting them under a ' junk ' node . 
If data loss is not an issue for a specific application  , there is no need even to collect tokens from irregular token lists  ; a simple rule to skip over
USAGE fields might bewntten as usacj e ==>- usage nmrk : use field  . 
usefield==>-UToKen:Snotiee ~ du field: opt  ( use_field )  . -( Rules like these , building no structure , are especially convenient when extensive reorganizat mn of tile token list is required -- typically in cases of grammar-driven token reordering or token deletion without token consumption  . ) In order to achieve skipping over unparseable input without data loss  , we have implemented a ootleztive rule class . The structure built by such rules the ( transitive ) concatenation of all the character strings in daughter segments  . Coping with grossir regularities is achieved by picking up any number of tokens and ' packing ' them to-ther  . This strategy is illustrated by a grammar phrases conjoined with italic ' or ' in example sentences and/or their translations  ( ee Figure 3 )  . 
The italic conjunction is surrounded by slashes in the resulting collected string as a naudit trail  . The extra argument oe ~ n $ eh forces , following the strategy outlined in section 5 . 3 , rule application only m the correct font context . 
stron ~ nonterminals ( source.targ.hill.
colle ~ ives ! conj . nil).
source ==>? on~(bo\].d).
r ~==> (: ~ r l . . 11 r Olllilr ~ J.-
IX ) : :>- TOrt~X ) + ~- for t ~ ( i ~ l1:44'*/"4 , "Or"~++"/"-fontIX)+Seg . 
Finally , for the most complex cases of truly irregular input  , a mechanism exists for constraining juiak collection to operate only as a last resort and only at the point at which parsing can go no further  . 
5 . 8 Augmenting the power of the formalism : escape to Prolog Several of the mechanisms described above  , such as contextual control of token consumption ( section 5 . 1), explicit structure handling (5 . 4), or selective toke/fization (5 . 6), are implemented as ? separate Prolo ~ z modules . Invoking such extemai functionality from the gramma rules allows the natural integration of the form - and content-recovery procedures into the topdown process of dictionary entry analysis  . The utility of this device should be clear from the example so far  . 
Such escape to the underlying implementation language goes agains the grain of recent developments of declarative  gran3m_ arformalisms . ( the procedura lramifications of , for instance , being able to call arbitrary LISP functions from the arcs of an ATN grammar have been discussed at length : see  , for instance , the opening chapters in Whitelock et al ,  1987) . However , we feel justified in augmenting , the .   .   .   .   . formalism in such a way , as we are dealing with input which Is different m nature from  , and on occasions possibly more complex than , straight natural anguage . Unho-mogeneous mixtures of heavily formal notations and annotations in totally free format  , interspersed with ( occasionally incomplete ) fragments of natural anguage phrases , can easily defeat any attempts at ' cleafi ' parsing  . Since the DEP system is designed to deal with an open-ended set of dictionaries  , it must be able to corffront a similarly open -ended set of notational conventions and abbreviatory devices  . Furthermore . dealing in full with some of these notations requires access to mechanisms and theories well beyond the power of any grammar formalism : consider  , for stance , what is involved in analyzing pronunciation fields in a dictionary  , where alternative pronunciation patterns are marked only for syllable  ( s ) which differ from the primar 3~ pronun-caation ( as in arch . bish . op:/ , a:tfbiDpII , at -/) ; where the pronunciation string itselfts not marked for syllable structure  ; and where the assignment of syllable boundaries i far from trivial  ( as in fas . cist:/'f=ej'a , st /)! The runtime environment of DEP includes gr . ammarde bugging utilities , and a number of opttons . All facilities have been implemented , except where noted . We have very detailed grammars for CGE ( parsing 98% of the entries )  , CEG (95%) , and LDOCE (93%) ; less detailed grammars for Web sters Seventh ( 98% )  , and both laalves of the Collins French Dictionary  ( approximately 90% )  . 
The Dictionary Entry Parser is an integra . 1 , part of a larger system designed to recover dictionary structure to an arbitrary depth of detail  , convert the resulting trees into LDB records , and make the data av/tilable to end users via a flexible and powerful lexical query language  ( LQL )  . Indeed , we have built LDB's for all dictionaries we have parsed  ; further development of LQL and the exploitation of the LDB's via query for a number of lexical studies are separate projects  . 
Finally , we note that , in the light of recent efforts to develop an interchange standard for  ( English monolingual ) dictionaries ( Amsler and Tompa ,  1988) , DEP acquires additional relevance , since it can be used , given a suitable annotation of the grammar rules for the machine-readable source  , to transduce a type setting tape into an interchangeable dictionary source  , available to a larger user commumty . 
ACILNOWLED GEMENTS.
We would like to thank Roy Byrd , Judith
Klavans and Beth Levin for many discussions concerning the Dictionary Entry Parser system in general  , and this paper in particular . Any remaining errors are ours , and ours only . 

A h l s w e d e , T , MEvens , K Rossi and J Markowitz W1986 ) " Building a Lexical Database by Parsing ebster's Seventh New Collegiate Dictionary ' ~  , Advances in Lexicology , Second Annual Conference of the UWC entre for the New Oxford 
English Dictionary , 65-78.
Amsler , R and F Tompa (1988) " An
SGML-Based Standard for English Monolingual Dictionaries "  , Information in Text , Fourth Annual Conference of the L'W Centre for the New 
Oxford English Dictionary , 61-79.
Boguraev , B , and EBriscoe ( Eds )   ( 1989 ) Computational Lexicography for Natural Language
Processing , Longman , Harlow.
.~yrd , R , N Calzolari , MChodorow , JK lavans , Neff and O Rizk ( 1987 ) " Tools and Methods for Computational Lexicology  "  , Computational Linguistics , vol .  13(3 - 4), 219 - 240 . 
Calzolari ~ N and E Picchi ( 1986 ) " A Project for a Bilingual Lexical Database System "  , Advances in Lexicology , Second ~ ual Conference of the L . ' WC entre for the New Oxford English Dictionary ,  79- 92 . 
Calzolari , N and E Picchi (1988) " Acquisition of
Semantic Information from an OnLine
Dictionary . " , Proceedings of the 12th International Conference on Computational Linguistics  ,  87- 92 . 
Collins ( 1980 ) Collins German Dictionary : German-English , English-German , Collins
Publishers , Glasgow.
Gaxzanti (1984) II Nuovo Dizionario Italiano
Garzanti , Garzanti , Milano.
Longman ( 1978 ) Longman Dictionary of Contemporary English , Longman Group , London . 
Dadam , P , KKuespert , F Andersen , H Blanken , RErbe , J Guenauer , V Lure , PPistor and G Walsh ( 1986 ) " ADBMS Prototype to Support Extended NF2 Relations : An~tegrated View on Flat Tables and Hierarchies  , Proceedings of ACM SIGMOD'86: International Conference on
Management of Data , 356-367.
Flickinger , D , C Pollard , TW as ow ( 1985 ) " Structure Sharing in Lexical Representation " , Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics  ,  262- 267 . 
Fox , E , TNutter , T Alhs we de , MEvens and J Markowitz ( 1988 ) " Building a Large Thesaurus for Information Retrieval "  , Proceedings of the Second Conference on Applied Natural Language 
Processing , 101-108.
Kazman , R ( 1986 ) " Structuring the Text of the Oxford Engl!s , h Dictionary through Finite State Transduction , University of Waterloo Technical
Report No . TR-86-20.
McCord , M ( 1987 " Natural Language Processing and Prolog " , mA Walker , MMcCord , J Sowa and W Wilson ( Eds ) Knowledge Systems and ' Prolog , Addison-Wesley , Waltham , 
Massachusetts , 291-402.
Nakamura , J and Makoto N ( 1988 ) " Extraction of Semantic Information from an Ordinary English Dictionary and Its Evaluation "  , Proceedings of the 12th International Conference on Computational Linguistics  ,  459 - 464 . 
Neff , M , R Byrd and O Rizk ( 1988 ) " Creat ~ g and Querying Hierarchical Lexical Data Bases  , Proceedings df the Second Conference on Applied
Natural Language Processing , 84-93.
van der Steen , GJ ( 1982 ) " A Treatment of Queries in Large Text Corpora " , in SJohansson ( Ed )
Computer Corpora in English Language
Research , Norwegian Computing Centre for the
Humanities , Bergen , 49-63".
Tompa , F ( 1986 ) "' Database Design for a Dictionary of the Future  '  , University of Waterloo , unpublished . 
W7(1967) Webster's Seventh Collegiate
Dictionary , C . & C . Merriam Company,
Springfield , Massachussetts.
Whitelock , P , M Wood , H Somers , R Johnson and P Bennett ( Eds )   ( 1987 ) Linguistic Theory and Computer Applications , Academic Press , New


