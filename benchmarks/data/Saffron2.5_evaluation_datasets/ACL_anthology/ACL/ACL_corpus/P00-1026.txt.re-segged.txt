A Morphologically Sensitive Clustering Algorithm for Identifying 
Arabic Roots
Anne N . DEROECK
Department of Computer Science
University of Essex
Colchester , CO4 3SQ , U.K.

Waleed AL-FARES
Computer Science Department
College of Business Studies,
Hawaly , Kuwait


We present a clustering algorithm for Arabic words sharing the same root  . Rootbased clusters can substitute dictionaries in indexing for IR  . Modifying Adamson and Boreham (1974) , our Two-stage algorithm applies light stemming before calculating word pair similarity coefficients using techniques sensitive to Arabic morphology  . 
Tests show a successful treatment of infixes and accurate clustering to up to  94  . 06% for unedited Arabic text samples , without the use of dictionaries . 

Canonisation of words for indexing is an important and difficult problem for Arabic IR  . 
Arabic is a highly inflectional language with 85% of words derived from tri-lateral roots ( Al-Fedaghi and Al-Anzi 1989 )  . Stems are derived from roots through the application of a set of fixed patterns  . Addition of affixes to stems yields words . Words sharing a root are semantically related and root indexing is reported to outperform stem and word indexing on both recall and precision  ( Hmeidi et al 1997 )  . 
However , Arabic morphology is excruciatingly complex ( the Appendix attempts a brief introduction )  , and root identification on a scale useful for IR remains problematic  . 
Research on Arabic IR tends to treat automatic indexing and stemming separately  . Al-Shalabi and Evans ( 1998 ) and El-Sadany and Hashish ( 1989 ) developed stemming algorithms . Hmeidi et al ( 1997 ) developed an information retrieval system with an index  , but does not explain the underlying stemming algorithm  . In Al-Kharashi and Evans (1994) , stemming is done manually and the IR index is built by manual insertion of roots  , stems and words . 
Typically , Arabic stemming algorithms operate by ? trial and error ?  . Affixes are stripped away , and stems ? undone ? , according to patterns and rules , and with reference to dictionaries . Root candidates are checked against a root lexicon  . If no match is found , affixes and patterns are read justed and the new candidate is checked  . The process is repeated until a root is found . 
Morphosyntactic parsers offer a possible alternative to stemming algorithms  . Al-Shalabi and Evans (1994) , and Ubu-Salem et al ( 1999 ) develop independent analysers . Some work builds on established formalisms such a DATR  ( Al-Najem 1998 )  , or KIMMO . This latter str and produced extensive deep analyses  . Kiraz ( 1994 ) extended the architecture with multileveltape , to deal with the typical interruption of root letter sequences caused by broken plural and weak root letter change  . Beesley ( 1996 ) describes the reimplementation of earlier work as a single finite state transducer between surface and lexical  ( root and tag ) strings . This was refined ( Beesley 1998 ) to the current online system capable of analysing over  70 million words . 
So far , these approaches have limited scope for deployment in IR  . Even if substantial , their morphosyntactic coverage remains limited and processing efficiency implications are often unclear  . In addition , modern written Arabic presents a unique range of orthographic problems  . Short vowels are not normally written ( but may be )  . Different regional spelling conventions may appear together in a single text and show interference with spelling errors  . 
These systems , however , assume text to be in perfect ( some even vowelised ) form , forcing the need for editing prior to processing . Finally , the success of these algorithms depends critically on root  , stem , pattern or affix dictionary quality , and no sizeable and reliable electronic dictionaries exist  . Beesley ( 1998 ) is the exception with a reported 4930 roots encoded with associated patterns , and an additional affix and nonroot stem lexicon 1 . Absence of large and reliable electronic lexical resources means dictionaries would have to be updated as new words appear in the text  , creating a maintenance overhead . Overall , it remains uncertain whether these approaches can be deployed and scaled up cost-effectively to provide the coverage required for fullscale IR on unsanitised text  . 
Our objective is to circumvent morphosyntactic analysis of Arabic words  , by using clustering as a technique for grouping words sharing a root  . In practise , since Arabic words derived from the same root are semantically related  , root based clusters can substitute root dictionaries for indexing in IR and furnish alternative search terms  . Clustering works without dictionaries , and the approach removes dictionary overheads completely  . Clusters can be implemented as a dimension of the index  , growing dynamically with text , and without specific maintenance . They will accommodate effortlessly a mixture of regional spelling conventions and even some spelling errors  . 
1 Clustering and Arabic.
To our knowledge , there is no application of automatic root-based clustering to Arabic  , using morphological similarity without dictionary . 
Clustering and stemming algorithms have mainly been developed for Western European languages  , and typically rely on simple heuristic rules to strip affixes and conflate strings  . For instance , Porter ( 1980 ) and Lovins ( 1968 ) confine stemming to suffix removal , yet yield acceptable results for English , where roots are relatively inert . Such approaches exploit the morphological frugality of some languages  , but do not transfer to heavily inflected languages such as Arabic  . 
In contrast , Adamson and Boreham ( 1974 ) developed a technique to calculate a similarity coefficient between words as a factor of the number of shared substrings  . The approach ( which we will call A dams on?s algorithm for short ) is a promising starting point for Arabic 1 Al-Fedaghi and Al-Anzi ( 1989 ) estimate there are around 10 , 000 independent roots . 
clustering because affix removal is not critical to gauging morphological relatedness  . 
In this paper , we explain the algorithm , apply it to raw modern Arabic text and evaluate the result  . We explain our Two-stage algorithm , which extends the technique by ( a ) light temming and ( b ) refinements sensitive to
Arabim or phology . We show how the adaptation increased successful clustering of both the original and new evaluation data  . 
2 Data Description
We focus on IR , so experiments use modern , unedited Arabic text , with unmarked short vowels ( Stalls and Knight 1998 )  . In all we constructed five datasets . The first set is controlled , and was designed for testing on a broad spectrum of morphological variation  . It contains selected roots with derived words chosen for their problematic structure  , featuring infixes , root consonant changes and weak letters . 
It also includes superficially similar words belonging to different roots  , and examples of hamza as a root consonant , an affix and a silent sign . Table 1 gives details . 
Table 1: Cluster size for 1st dataset root size root size k tb wrote 49 HSL obtained 7 qwm straightened38 s?a Lasked 6 mrpassed 26 HSd cultivated5 wSL linked 11 shm shared 4 r ? as headed 10 Datasets two to four contain articles extracted from Al-Raya  ( 1997 )  , and the fifth from Al-Watan (2000) , both newspapers from Qatar . 
Following Adams on , function words have been removed . The sets have domain bias with the second ( 575 words ) and the fourth ( 232 words ) drawn randomly from the economics and the third ( 750 words ) from the sports section . The fifth ( 314 words ) is a commentary on political history . Sets one to three were used to varying extents in refining our Two-stage algorithm  . Sets four and five were used for evaluation only . 
Electronically readable Arabic text has only recently become available on a useful scale  , hence our experiments were run on short texts . 
On the other hand , the coverage of the datasets allows us to verify our experiments on demanding samples  , and their size lets us verify correct clustering manually  . 
3. Testing Adamson?s Algorithm 3.1 The Algorithm
Adamson and Boreham ( 1974 ) developed a technique expressing relatedness of strings as a factor of shared substrings  . The algorithm drags an n-sized window across two strings  , with a 1 character overlap , and removes duplicates . The string s'similarity coefficient ( SC ) is calculated by Dice?s equation : SC ( Dice )  = 2* ( number of shared unique n-grams ) / ( sum of unique ngrams in each string ) Table 2: A dams on's Algorithm Illustrated
String 2grams Unique 2grams phosphorus phhoosspphhoor ruus phhoossp or ruus  ( 7 ) phosphate phhoosspphha attephhooss pha atte  ( 7 ) 
Shared unique 2grams phhooss p(4)
SC(Dice ) = 2(4)/(7+7) = 0.57
After the SC for all word pairs is known , the single link clustering algorithm is applied . A similarity ( or dissimilarity ) threshold is set . The SC of pairs is collected in a matrix . The threshold is applied to each pair?s SC to yield clusters  . A cluster absorbs a word as long as its SC to another cluster item exceeds the threshold  ( van Rijsbergen 1979 )  . Similarity to a single item is sufficient . Cluster size is not preset . 
3.2 Background Assumptions
This experiment tests A dams on's algorithm on Arabic data to assess its ability to cluster words sharing a root  . Each of the datasets was clustered manually to provide an ideal benchmark  . This task was executed by a native Arabic speaker with reference to dictionaries  . 
Since we are working with very small texts , we sought to remove the effects of sampling in the tests  . To assess A dams on ? s algorithm?s potential for clustering Arabic words  , we preferred to compare instances of optimal performance  . We varied the SC to yield , for each dataset , the highest number of correct multiword clusters . 
Note that the higher the SC cutoff , the less likely that words will cluster together , and the more single word clusters will appear . This has the effect of growing the number of correct clusters because the proportion of correct single word clusters will increase  . As a consequence , for our purposes , the number of correct multiword clusters ( and not just correct clusters ) are an important indicator of success . 
A correct multiword cluster covers at least two words and is found in the manual benchmark  . It contains all and only those words in the data set which share a root  . Comparison with a manual benchmark inevitably introduces a subjective element  . Also , our evaluation measure is the percentage of correct benchmark clusters retrieved  . This is a ? recall ? type indicator . Together with the strict definition of correct cluster  , it cannot measure cluster quality . 
Finer grained evaluation of cluster quality would be needed in an IR context  . 
However , our main concern is comparing algorithms . The current metrics aim for a conservative gauge of how A dams on?s algorithm can yield more exact clusters from a full range of problematic data  . 
Table 3: A dams on's Algorithm Test Results
Dataset Set 2 Set 3 Set 4Set 5
Benchmark : Total Manual Clusters ( A ) 9 267 337 151 190 Multiword ( B ) 913016 4506 3 Single word ( C ) 0137173101127 SC cut-off 20 . 50 0 . 54 0 . 75 0 . 58-0 . 60 0 . 61-0 . 66
Test : ( % of Benchmark ) Correct Clusters ( % of A ) 11 . 11% 56 . 55% 60 . 83% 70 . 86% 74 . 21% Multiword (% of B ) 11 . 11% 38 . 46% 21 . 95% 40% 34 . 92% Single word (% of C ) 0 . 0% 73 . 72% 97 . 69% 86 . 14% 93 . 7 0%   2 Ranges rather than specific values are given where cutoffs between the lower and higher value do not alter cluster distribution  . 
Our interpretation of correct clustering is stringent and therefore conservative  , adding to the significance of our results . Cluster quality will be reviewed informally . 
3.3 A dams on ? s Arabic Test Results
Table 3 shows results for A dams on?s algorithm . The figures for the first dataset have to be suitably interpreted  . The set deliberately did not include single word clusters  . 
The results suggest that the algorithm is very successful at identifying single word clusters but performs poorly on multiword clusters  . The high success rate for single word clusters is partly due to the high SC cutoff  , set to yield as many correct multiword clusters as possible  . 
In terms of quality , however , only a small proportion of multiword clusters were found to contain in fix derivations  ( 11 . 11%, 4 . 76%, 0 . 0% 4 . 35% and 9 . 09% for each dataset respectively ) , as opposed to other variations . In other words , strings sharing character sequences in middle position cluster together more successfully  . Infix recognition is a weak point in this approach  . 
Whereas the algorithm is successful for
English , it is no surprise that it should not perform equally well on Arabic  . Arabic words tend to be short and the chance of words derived from different roots sharing a significant proportion of characters is high  ( eg Khbr ( news ) vs Khbz ( bread ) ) . Dice?s equation assumes the ability to identify an uninterrupted sequence of root consonants  . The heavy use of infixes runs against this . Similarly , affixes cause interference ( see 4 . 1 . 1) . 
4 The TwoStage Algorithm.
The challenge of root based clustering for Arabic lies in designing an algorithm which willive relevance to root consonants only  . Using A dams on?s algorithm as a starting point , we devised a solution by introducing and testing a number of successive refinements based on the morphological knowledge and the first three data sets  . The rational emotivating these refinements is given below  . 
4 . 1 Refinements 4 . 1 . 1Affixes and light stemming : The high incidence of affixes keeps accurate cluster formation low  , because it increases the SC among words derived from different roots  , and lowers the SC between derivations of the same root using different affixes  , as illustrated in tables 4 and 5 . Following Popovic and Willet (1992) , we introduced stemming to minimise the effect of affixes  . We found empirically that light stemming , removing a small number of obvious affixes , gave better results than heavy stemming aimed at full affix stripping  . Heavy stemming brought the risk of root consonant loss  ( egt ? amyn ( insurance ) from root a mn ( sheltered ) : heavy stemming : t?am , light stemming : t?amn ) . 
Light stemming , on the other hand , does little more than reducing word size to 3 or 4 characters . 
4 . 1 . 2 Weak letters , infixes and ? cross ?: Weak letters ( alif , waw , ya ) occur freely as root consonants as well as affixes  . Under derivation , their form and location may change , or they may disappear . As infixes , they interfere with SC , causing failure to cluster ( table 6) . 
Their effects were reduced by a method we refer to as ? cross ?  . It adds a bigram combining the letters occurring before and after the weak letter  . 
Table 4: Inflected words from different roots : ? Lm ( learned ) and arb ( arabised ) String Unique 2grams with affixes Unique 2grams without affixes a L?a Lmyh ( the universal ) a LL??a Lmmyyh ( 6 ) ? aLm ( 2 ) a L?rbyh ( the Arabic ) a LL ?? rrb by y h ( 6 ) ? rrb ( 2 ) SC ( Dice )  2 ( 3 ) / ( 6+6 )  = 0 . 50 2 ( 0 ) / ( 2+2 )  =  0 Table 5: Inflected words from the same root : mrr ( passed ) String Unique 2grams with affixes Unique 2grams without affixes mstmr ( continuous ) mssttmmr ( 4 ) mr ( 1 ) mr ( passed ) mr ( 1 ) mr ( 1 ) SC ( Dice )  2 ( 1 ) / ( 4+1 )  = 0 . 40 2(1)/(1+1) = 1 . 0 Table 6: Infix derivation from root wqf ( stopped ) -postlight stemming String Unique 2grams without cross Unique di-grams with cross q af q a af  ( 2 ) q a a f q f ( 3 ) w q f w q q f ( 2 ) w q q f ( 2 ) SC ( Dice )  2 ( 0 ) / ( 2+2 )  = 0 2 ( 1 ) / ( 2+3 )  = 0 . 4 4 . 1 . 3Suspected affixes and differential weighting : Our objective is to define an algorithm which gives suitable precedence to root consonants  . 
Light stemming , however does not remove all affixes . Whereas fool proof affix detection is problematic due to the overlap between affix and root consonants  , affixes belong to a closed class and it is possible to identify ? suspect ? letters which might be part of an affix  . 
Following Harman ( 1991 ) we explored the idea of assigning differential weights to substrings  . Giving equal weight of 1 to all substrings equates the evidence contributed by all letters  , whether they are root consonants or not . Suspected affixes , however , should not be allowed to affect the SC between words on a par with characters contributing stronger evidence  . 
We conducted a series of experiments with differential weightings  , and determined empirically that 0 . 25 weight for strings containing weak letters , and 0 . 5 0 for strings containing suspected non-weak letter affixes gave the best SC for the first three data sets  . 
4.1.4 Substring boundaries:
Ngram size can curtail the significance of word boundary letters  ( Robertson and Willet 1992 )  . To give them opportunity to contribute fully to the SC  , we introduced word boundary blanks ( Harman 1991) . 
Also , the larger the ngram , the greater its capacity to mask the shorter substring which can contain important evidence of similarity between word pairs  ( Adamson and Boreham 1974 )  . Of equal importance is the size of the sliding overlap between successive ngrams  ( Adams 1991 )  . 
Table 7: Blank insertion with ? cross ?
String Unique 2grams ( no ) q a f * q q a a f q f f * ( 5 ) wqf * wwq*qqff* ( 5 ) 
SC(Dice ) 2(3)/(5+5) = 0.60
The problem is to find the best setting for ngram and overlap size to suit the language  . We sought to determine settings experimentally . Bigrams with single character overlap and blank insertion  ( * in the examples ) at word boundaries raised the SC for words sharing a root in our three datasets  , and lowered the SC for words belonging to different roots  . 
4.1.5 SC formula:
Dice?s equation boosts the importance of unique shared substrings between word pairs  , by doubling their evidence . As we argued earlier , since Arabic words tend to be short , the relative impact of shared substrings will already be dramatic  . We replaced the Dice metric with the Jaccard formula below to reduce this effect  ( seevan Rijsbergen 1979 )  . SC ( Jac ) = shared unique n-grams / ( sum of unique ngrams in each string-shared unique ngrams  )  4 . 2 The Two-stage Algorithm The Two-stage algorithm is fully implemented  . 
Words are first submitted to light stemming to remove obvious affixes  . The second stage is basd on A dams on?s algorithm , modified as described above . From the original , we retained bigrams with a one character overlap , but inserted word boundary blanks . Unique bigrams are isolated and cross is implemented  . Each bigram is assigned a weight (0 . 25 for bigrams containing weak letters ; 0 . 5 for bigrams containing potential non-weak letter affixes  ; 1 for all other bigrams ) . Jaccard?s equation computes a SC for each pair of words  . We retained the single-link clustering algorithm to ensure comparability  . 
4.3 Testing the Two-stage Algorithm
Table 8 shows the results of the Two-stage algorithm for our datasets  . The maximally effective cut of point for all sets lies closer  . 
Figures for the first set have to be treated with caution  . The perfect clustering is explained by the text?s perfect spelling and by the sample containing exactly those problematic phenomena on which we wanted to concentrate  . 
Table 8: Two-stage Algorithm Test Results
Dataset Set 2 Set 3 Set 4Set 5
Benchmark : Total Manual Clusters ( A ) 9 267 337 151 190 Multiword ( B ) 913016 4506 3 Single word ( C ) 0137173101127 SC cutoff 0 . 42-0 . 66 0 . 54 0 . 54 0 . 53-0 . 540 . 62-0 . 66
Test : ( % of Benchmark ) Correct Clusters ( % of A )  100% 88 . 05% 86 . 94% 94 . 04% 86 . 84% Multiword (% of B ) 100% 85 . 39% 82 . 93% 94% 74 . 60% Single word (% of C ) - 90 . 51% 90 . 75% 94 . 06% 92 . 91% The algorithm deals with weak letter mutation , and infix appearance and disappearance in words sharing a root  ( eg the root qwm and its derived words , especially the role of Hamza as an infix in one of its variations  )  . Even though the second and third datasets informed the modifications to a limited extent  , their results show that the improvements stoodup to freetext  . For the second dataset , the Two-stage algorithm showed 31 . 5% improvement over Adams on?s algorithm . Importantly , it discovered 84 . 1 3% of the multiword clusters containing words with infixes  , an improvement of 79 . 37% . 
The values for single word clustering are close and the modifications preserved the strength of A dams on?s algorithm in keeping single word clusters from mixing  , because we were able to maintain a high SC threshold  . 
On the third dataset , the Two-stage algorithm showed an 26 . 11% overall improvement , with 84% successful multiword clustering of words with infixes  ( compare 0% for A dams on )  . The largest cluster contained 14 words .   10 clusters counted as unsuccessful because they contained one superficially similar variation belonging to a different root  ( egTwL ( lengthened ) and bTL ( to be abolished ) ) . If we allow this error margin , the success rate of multiword clustering rises to  90%  . Since our SC cutoff was significantly lower than in Adams on?s baseline experiment  , we obtained weaker results for single word clustering  . 
The fourth and fifth datasets played no role in the development of our algorithm and were used for evaluation purposes only  . The Two-stage algorithm showed an 23 . 18% overall improvement in set four . It successfully built all clusters containing words with infixes  ( 100% - compare with 4 . 35% for Adamson?s algorithm ) , an improvement of 95 . 65% . The twostage algorithm again preserved the strength of Adams on at distinguishing single word clusters  , is pite of a lower SC cutoff . 
The results for the fifth dataset are particularly important because the text was drawn from a differnt source and domain  . Again , significant improvements in multiand single word clustering a revisible  , with a slightly higher SC cutoff . The algorithm performed markedly better at identifying multiword clusters with infixes  ( 72 . 72% - compare with 9 . 09% for

The results suggest that the Two-stage algorithm preserves the strengths of Adamson and Boreham  ( 1994 )  , whilst adding a marked advantage in recognising infixes  . The outcome of the evaluation on fourth and fifth datasets are very encouraging and though the samples are small  , they give a strong indication that this kind of approach may transfer well to text from different domains on a larger scale  . 
5 Two-stage Algorithm Limitations
Weak letters can be root consonants , but our differential weighting technique prevents them from contributing strong evidence  , whereas non-weak letters featuring in affixes , are allowed to contribute full weight . Modifying this arrangement would interfere with successful clustering  ( eg after light stemming : t is a root consonant in ntj  ( produced ) and an infix in Ltqy ( from root Lqy-encountered )  . These limitations are a result of light stemming . 
Although the current results are promising , evaluation was hampered by the lack of a sizeable dataset to verify whether our solution would scale up  . 

We have developed , successfully , an automatic classification algorithm for Arabic words which share the same root  , based only on their morphological similarities . Our approach works on unsanitised text . Our experiments show that algorithms designed for relatively uninflected languages can be adapted for highly inflected languages  , by using morphological knowledge . 
We found that the Two-stage algorithm gave a significant improvement over A dams on?s algorithm for our datasets  . It dealt successfully with infixes in multiword clustering  , an area where Adams on?s algorithm failed . It matched the strength of Adams on in identifying single word clusters  , and sometimes did better . Weak letters and the overlap between root and affix consonants continue to cause interference  . 
Nonetheless , the results are promising and suggest that the approach may scale up Future work will concentrate on two issues  . 
The light stemming algorithm and the differential weighting may be modified to improve the identification of affixes  . The extent to which the algorithm can be scaled up must be tested on a large corpus  . 

Our thanks go to the Kuwait State's Public Authority for Applied Education and Training  , for the supporting research studentship , and to two anonymous referees for detailed , interesting and constructive comments . 
Appendix-Arabic in a Nutshell
The vast majority of Arabic words are derived from  3   ( and a few 4 ) letter roots via a complex morphology . Roots give rise to stems by the application of a set of fixed patterns  . Addition of affixes to stems yields words . 
Table 9: Stem Patterns
Root Pattern Stemkt b wrote f a ? L k a t b w r i term f ? wL mk twb document qtL killed fa?L qat Lkiller mf?wL mq twL corpse Table  9 shows examples of stem derivation from 3-letter roots . Stem patterns are formulated as variations on the characters f?L  ( pronounced as f'l-?is the symbol for ayn , a strong glottal stop ) , where each of the successive consonants matches a character in the bare root  ( for ktb , k matches f , t matches ? and b matches L ) . Stems follow the pattern as directed . As the examples show , each pattern has a specific effect on meaning . Several hundred patterns exist , but on average only about 18 are applicable to each root ( Beesley 1998 )  . 
The language distinguishes between long and short vowels  . Short vowels affect meaning , but are not normally written . However , patterns may involve short vowels , and the effects of some patterns are in distinguishable in written text  . 
Readers must infer the intended meaning.
Affixes may be added to the word , either under derivation , or to mark grammatical function . For instance , walktab breaks down as w ( and ) + al ( the ) + ktab ( writers , or book , depending on the voweling ) . Other affixes function as person , number , gender and tense markers , subject and direct object pronouns , articles , conjunctions and prepositions , though some of these may also occur as separate words  ( egwal ( and the ) ) . 
Arabic morphology presents some tricky NLP problems  . Stem patterns ? interdigitate ? with root consonants  , which is difficult to parse . Also , the long vowels a(lif ) , w ( waw ) and y ( ya ) can occur as root consonants , in which case they are considered to be weak letters  , and the root a weak root . Under certain circumstances , weak letters may change shape ( eg waw into y a ) or di appear during derivation . Long vowels also occur as affixes , so identifying them as affix or root consonant is often problematic  . 
The language makes heavy use of infixes as well as prefixes and suffixes  , all of which may be consonants or long vowels . Apart from breaking up root letter sequences ( which tend to be short )  , infixes are easily confused with root consonants , whether weak or not . The problem for affix detection can be stated as follows : weak root consonants are easily confused with long vowel affixes  ; consonant affixes are easily confused with non -weak letter root consonants  . 
Erroneus stripping of affixes will yield the wrong root  . 
Arabic plurals are difficult . The dual and some plurals are formed by suffixes , in which case they are called external plurals . The broken , or internal plural , however , changes the internal structure of the word according to a set of patterns  . To illustrate the complexity , masculine plurals take a-wn or-yn suffix , as in m hnds ( engineer ) , mhndswn . Female plurals add the-at suffix , or change word final-hto-at , as in mdrsh ( teacher ) , mdrsat . Broken plurals affect root characters , as in mal ( fund from root mwl ) , amwal , or wSL ( link from root wSL ) , ?ay SaL . 
The examples are rife with long vowels ( weak letters ? )  . They illustrate the degree of interference between broken plural patterns and other ways of segmenting words  . 
Regional spelling conventions are common : eg . three versions of word initial alif occur . The most prominent orthographic problem is the behaviour of hamza  ,  (?) , a sign written over a carrier letter and sounding alen is glottal stop  ( not to be confused with a yn )  . Hamza is not always pronounced . Like any other consonant , it can take a vowel , long or short . In word initial position it is always carried by alif  , but may be written above or below , or omitted . Mid-word it is often carried by one of the long vowels  , depending on rules whose complexity often gives rise to spelling errors  . At the end of words , it may be carried or written independently . 
Hamza is used both as a root consonant and an affix  , and is subject to the same problems as non-weak letter consonants  , compounded by unpredictable orthography : identical words may have differently positioned hamzas and would be considered as different strings  . 

Adams , E .   ( 1991 ) A Study of Trigrams and their feasibility as Index Terms in a fulltext Information Retrieval System  . PhD Thesis , George Washington
University , USA.
Adamson , George W . and J . Boreham ( 1974 ) The use of an association measure based on character structure to identify semantically related pairs of words and document titles  . Information Storage and Retrieval, . Vol 10, pp 253-260 Al-Fedaghi Sabah S . and Fawaz Al-Anzi ( 1989 ) A new algorithm to generate Arabic root-pattern forms  . Proceedings of the 11th National Computer Conference , KingFahd University of Petroleum & Minerals , Dhahran , Saudi Arabia . , pp04-07 Al-Kharashi , I . and M . Evens (1994) Comparing words , stems , and roots as Index terms in an Arabic Information Retrieval system  . Journal of the American Society for Information Science  ,  45/8 , pp . 548-560 Al-Najm , Salah R .  (1998) . An Explanation of
Computational Arabic Morphology . DATR
Documentation Report , University of Sussex.
Al-Raya (1997) Newspaper . Quatar.
Al-Shalabi , R . and M . Evens (1998) A
Computational Morphology System for Arabic.
Proceedings of COLINGACL , New Brunswick,

Al-Watan (2000) Newspaper . Qatar.
Beesley , K . B . (1996) Arabic Finite State
Morphological Analysis and Generation.
Proceedings of COLING96, pp8994.
Beesley , K . B .   ( 1998 ) Arabic Morphological Analysis on the Internet . Proceedings of the 6th International Conference and Exhibition on MultiLingual 
Computing , Cambridge.
El-Sadany , T . and M . Hashish (1989) An Arabic morphological system . IBM System Journal , 28/4 Harman , D .   ( 1991 ) How effective is suffixing ? Journal of the American Society for Information 
Science , 42/1, pp7-15.
Hmeidi , I . , Kanaan , G . and M . Evens ( 1997 ) Design and Implementation of Automatic Indexing for Information Retrieval with Arabic Documents  . 
Journal of the American Society for Information
Science , 48/10, pp . 867-881.
Kiraz , G .   ( 1994 ) Multitape two-level Morphology : a case study in Semitic nonlinear morphology  . 
Proceedings of COLING94, pp 180-186.
Lovins , J . B . (1968) Development of a Stemming
Algorithm . Mechanical Translation and
Computational Linguistics , 11/1.
Popovic , M . and P . Will et ( 1992 ) The effectiveness of stemming for natural language access to Sloven textual data  . Journal of the American Society for Information Science  ,  43/5 , pp .  384-390 . 
Porter , M . F . (1980) An Algorithm for suffix stripping . Program , 14/3, pp 130-137 Stalls , B . and Knight , K .   ( 1998 ) Translating names and technical terms in Arabic text  . Proceedings of
COLINGACL , New Brunswick , NJ , 1998 van Rijsbergen , C . J . (1979) Information Retrieval . 
Butterworths , London.
Robertson , A . and Willett , P . (1992 ) Searching for historical wordforms in a database of  17th-century English text using spelling-correction methods . 15th
Annual International Conference SIGIR.
Ubu-Salem H . , Al-Omari M . , and M . Evens ( 1999 ) Stemming methodologies over individual query words for an Arabic information retrieval system  . 
Journal of the American Society for Information
Science . 50/6, pp 524-529.
