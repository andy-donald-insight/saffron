A Psycholinguistically Motivated Parser for CCG
Michael Niv *
Technion-Israel Institute of Technology
Haifa , Israel
Internet : niv@linc.cis.upenn.edu
Abstract
Considering the speed in which humans resolve syntactic ambiguity  , and the overwhelming evidence that syntactic ambiguity is resolved through selection of the analysis whose interpretation is the most ' sensible '  , one comes to the conclusion that interpretation , hence parsing take place incrementally , just about every word . Considerations of parsimony in the theory of the syntactic processor lead one to explore the simplest of parsers : one which represents only analyses as defined by the grammar and no other information  . 
Toward this aim of a simple , incremental parser I explore the proposal that the competence grammar is a Combinatory Categorial Grammar  ( CCG )  . 
I address the problem of the proliferating analyses that stem from CCG's associativity of derivation  . 
Mysolution involves maintaining only the maximally incremental analysis and  , when necessary , computing the maximally right-branching analysis . 
I use results from the study of rewrite systems to show that this computation is efficient  . 
1 Introduction
The aim of this paper is to work towards a computational model of how human syntactically process the language that they hear and read  . The endpoint of this enterprise is a precise characterization f the process that humans follow  , getting details such as timing and garden pathing exactly right  . 
* The research reported here was conducted as part of my Ph  . D . thesis work at the University of Pennsylvania and supported by the following grants : DARPA  N00014-90-J-1863  , ARODAAL03-89-C-0031 , NSF IRI90-16592 , BenFranklin 91 S . 3078C-1 . Preparation of this paper was supported by a postdoctoral fellowship at the Technion in Israel  . I am grateful to Mark Hepple , Mitch Marcus , Mark Steedman , VM Tannen , and Henry Thompson for helpful suggestions , and to Jeff Siskind for help with type setting CCG derivations  . Any errors are my own . 
1.1 Ambiguity Resolution
Recently , a great deal of evidence has accumulated that humans resolve syntactic ambiguity by considering the meaning of the available analyses and selecting the ' best'one  . Various criteria for goodness of meaning have been advanced in the psycholinguistic literature : e  . g . thematic compatibility and lexical selection ( Trueswell and Tanenhaus 1994 )  , discourse felicity of definite expressions ( Altmann et al 1994 )  , temporal coherence in discourse ( Trueswell and Tanenhaus 1991 )  , grammatical function visavis given/new status ( Niv 1993b )  , and general world-knowledge ( Kawamoto and Far-rar 1993 )  . 
Many of the works cited above consider the timing of the ambiguity resolution decision  . The evidence is overwhelming that ambiguity is resolved within a word or two of the arrival of disambiguating information -- that is  , when there is a meaning-based criterion which militates toward one or another syntactically available analysis  , that analysis is selected . Should the other analysis turn out to be the ultimately correct analysis  , a garden path will result . Given that the various analyses available are compared on various criteria of sensibleness  , it follows that these analyses are constructed and maintained in parallel until disambiguating information arrives  . Indeed , there is psycholinguistic evidence that the processor maintains the various analyses in parallel  ( Nicol and Pickering 1993 ; MacDonland et al 1992) . 
Our parser , therefore , must be able to build and maintain analyses in parallel  . It must also extract from the developing parse in a prompt fashion all of the semantically relevant syntactic ommitments  ( e . g . predicate-argument relations ) in order to allow the interpretation module that it feeds to make accurate evaluations of the meaning  . Recovery from garden paths is not addressed in this paper  . 
125 1.2 Parser and Grammar
Let us adopt the widely held position that humans posses a representation of grammatical competence which is independent of any process  ( e . g . production , perception , acquisition ) that uses it . Steedman ( 1994 ) argues that if two theories of the grammar and processor package have identical empirical coverage  , but one has a more complex parser , then the other is preferred . This preference is not just on philosophical grounds of cleanliness of one's theories  , but stems from consideration of the evolution of the human linguistic capacity : A theory whose grammar requires a complex parser in order to be of any use would entail a more complex or less likely evolutionary path which the parser and grammar took together than would a theory whose grammar requires little specialized apparatus by way of a parser  , and could thus have evolved gradually . 
So what is the simplest parser one can construct ? In other words  , what is the minimal addition of computational apparatus to the competence grammar necessary to make it parse ? From the argument in section  1  . 1 , this addition must include a mechanism for maintaining analyses in parallel  . Minimally , nothing else is necessary -- the data structure which resides in each parallel slot in the parser is a direct representation of an analysis as defined by the competence machinery  . 
Suppose the grammatical competence is one that always divides an English clause into a subject and a predicate  ( V Phenceforth )  . Suppose also that the primary operations of the grammar are putting constituents together  . Could the minimal parser for such a grammar account for the minimal pair in  ( 1 ) ?  ( 1 ) a . The doctor sent for the patient arrived . 
b . The flowers sent for the patient arrived.
(1) a is a garden path . In ( 1 ) b the garden path is avoided because flowers are not good senders  . The difference between ( 1 ) a and b indicates that well before the word ' arrived ' is encountered  , the processor has already resolved the ambiguity introduced by the word ' sent '  . That is , in the main-verb analysis of ' sent ' , the interpreter is aware of the relation between the subject the verb before the end of the VP  . But the minimal parser cannot put the subject together with ' sent ' or ' sent for the ' because the latter are not a complete VP ! There are two possible solutions to this problem  , each relaxes one of the two suppositions above : Steedman  ( 1994 ) argues for a grammatical theory ( CCG ) which does not always make the subject-predicate juncture the primary division point of a clause  . Shieber and Johnson (1993) on the other hand , argue that there is no need to assume that a constituent has to be complete before it is combined with its sister  ( s )  . At this time , neither approach is sufficiently developed to be evaluable  ( e . g . they both lack broadcoverage grammar ) so either one is viable . In this paper , I develop the first . 
2 Preliminaries
CCG is a lexicalized grammar formalism--a lexicon assigns each word to one or more grammatical categories  . Adjacent constituents can combine by one of a small number of combinatory rules  . The universe of grammatical categories contains a collection of basic categories  ( e . g . atomic symbol such as n , np , s , etc . or Prolog terms such np (3 , sg ) ) and is closed under the category-forming connectives / and \  . Intuitively a constituent of category X/Y ( resp . X\Y ) is something of category X which is missing something of category Y to its right  ( resp . 
left ) . The combinatory rules are listed 1 in table 1 . 
They formalize this intuition . A combinatory rule may be qualified with a predicate over the variables 
X , Y , and Z1 . . . Zn.
A derivation is a binary tree whose leaves are each a single-word constituent  , and whose internal nodes are each a constituent which is derived from its children by an application of one of the combinatory rules  . A string w is grammatical just in case there exists a derivation whose frontier is w  . I equivocate between a derivation and the constituent at its root  . An analysis of a string w is a sequence of derivation such that the concatenation of their frontiers is w  . 
3 The Simplest Parser
Let us consider the simplest conceivable parser . Its specification is " find all analyses of the string so far  . "It has a collection of slots for maintaining one analysis each  , in parallel . Each slot maintains an analysis of the string seen so far--a sequence of one or more derivations  . The parser has two operations , as shown in figure 1 . 
This parser succeeds in constructing the incremental analysis  ( 2 ) necessary for solving the problem in ( 1 )  . 
1 Two common combinatory rules , typeraising and substitution are not listed here . The substitution rule ( Steedman 1987 ) is orthogonal to the present discussion and can be added without modification  . The rule for typeraising ( see e . g . Dowty 1988 ) can cause difficulties for the parsing scheme advocated here  ( Hepple 1987 ) and is therefore assumed to apply in the lexicon . Soa proper name , for example , would behave two categories : np and s/(s\np ) . 

Forward combination rule name
X/Y Y X > 0
X/Y Y I Z X\[Z > 1
X/Y Y\]-Z11Z2 X~z\[Z2>2
Backward Combination rule name
X/Y Y IZ 1... IZ . XIZI . . .\[ Z .> n
Y X\Y , X < 0
YIZx\Y , xlz < 1
Y \]-Z,\[Z2X\Y ~ X\]-ZIIZ2"<2
Y\[Z1...\[ZnX\Y'X\[Z1...\[Zn<n
IZ stands for either/Z or\Z . Underlined regions in a rule must match . 
Table 1: The combinatory rules?s can get the next word from the input stream for each analysis a in the parser's memory empty the slot containing a for each lexical entry e of the word make a cop ya ~ of a add the leaf derivation e to the right of a ~adda ~ as a new analysis ? combine for each analysis a in the parser's memory if a contains more than one constituent and some rule can combine the rightmost two constituents in a then make a copya ~ of a replace the two constituents of a ~ by their combination add a/as a new analysis 
Figure 1: Parser operations the flowers sent ( 2 ) s/ ( s\np ) / , n > 0 s\np/pps / ( s\np ) > Is/ppBut this parser is just an unconstrained shift-reduce parser that simulates nondeterminism via parallelism  . It suffers from a standard problem of simple bottom-u parsers : it can only know when a certain substring has a derivation  , but in case a substring does not have a derivation  , the parser cannot yet know whether or not a larger string containing the substring will have a derivation  . This means that when faced with a string such as ( 3 ) The insults the new students shouted at the teacher were appalling  . 
the parser will note the noun-verb ambiguity of ' insults '  , but will be unable to use the information that ' insults ' is preceded by a determiner to rule out the verb analysis in a timely fashion  . It would only notice the difficulty with the verb analysis after it had come to the end of the string and failed to find a derivation for it  . This delay in ruling out doomed analyses means that the parser and the interpreter are burdened with a quickly proliferating collection of irrelevant analyses  . 
Standard solution to this problem ( e . g . Earley's 1970 parser ; LR parsing , Aho and Johnson 1974 ) consider global properties of the competence grammar to infer that no grammatical string will begin with a determiner followed by a verb  . These solutions exact a cost in complicating the design of the parser : new data structure such as dotted rules or an LR table must be added to the parser  . 
The parser is no longer a generic search algorithm for the competence grammar  . Given the flexibility of CCG derivations , one may consider imposing a very simple constraint on the parser : every prefix of a grammatical string must have a derivation  . But such a move it too heavy-handed . Indeed CCG often gives left-branching derivations  , but it is not purely left-branching . For example , the derivation of a WH-dependency requires leaving the WH-filler constituent uncombined until the entire gap-containing constituent is completed  , as in (4) . 
(4 ) whose cat did Fredfind ns/ss/ ( s\np ) > is\np/npq/ ( s/np ) / n > 0 q / ( s/np ) s/ ( s\np ) s/np > I >0   4 The Viable Analysis Criterion Given the desideratum to minimize the complexity of the biologically specified parser  , I propose that the human parser is indeed as simple as the scan-combine algorithm presented above  , and that the ability to rule out analyse such as determiner+verb is not innate  , but is an acquired skill . This'skill'is implemented as a criterion which an analysis must meet in order to survive  . An infant starts out with this criterion completely permissive  . Consequently it cannot process any utterances longer than a few words without requiring excessively many parserses in the parser memory and tracks their respective outcomes  , it notices that certain sequences of categories never lead to a grammatical over all analysis  . 
After observing an analysis failing a certain number of times and never succeeding  , the child concludes that it is not a viable analysis and learns to discard it  . The more spurious analyses are discarded , the better able the child is to cope with longer strings  . 
The collection of analyses that are maintained by the parser is therefore filtered by two independent processes : The Viable Analysis Criterion is a purely syntactic filter which rules out analyses independently of ambiguity  . The interpreter considers the semantic information of the remaining analyses in parallel and occasionally deems certain analyses more sensible than their competitors  , and discards the latter . 
Given that English sentences rarely require more than two or three CCG constituents at any point in their parse  , and given the limited range of categories that arise in English  , the problem of learning the viable analysis criterion from data promises to be comparable to other ngram learning tasks  . The empirical validation of this proposal awaits the availability of a broadcoverage CCG for 
English , and other languages . 25 CCG and flexible derivation 5 . 1 The Prob lem CCG's distinguishing characteristic is its derivational flexibility -- the fact that one string is potentially assigned many truth -conditionally equivalent analyses  . This feature is crucial to the present approach of incremental parsing  ( as well as for a range of grammatical phenomena , see e . g . Steedman 1987, 1994; Dowty 1988) . But the additional ambiguity , sometimes referred to as ' spurious ' , is also a source of difficulty for parsing . For example , the truth-conditionally unambiguous string ' John was thinking that Bill had left'has CCG derivations corresponding to each of the  132 different binary trees possible for seven leaves . The fact that this sentence makes noun usual demands on humans makes it clear that its exponentially prolif ~ crating ambiguous analyses are pruned somehow  . 
The interpreter , which can resolve many kinds of ambiguity , cannot be used to for this task : it has no visible basis for determining  , for example , that the single-constituent analysis ' John was thinking '  2In addition to the category-ambiguity problem in ( 3 )  , the viable analysis criterion solves other problems  , analogous to shift-reduce ambiguities , which are omitted here for reasons of space . The interested reader is referred to Niv ( 1993a ) for a comprehensive discussion and an implementation f the parser proposed here  . 
somehow makes more sense ( in CCG ) than the two-constituent analysis ' John '+' was thinking '  . 
Note that the maxim Mlyleft-branching derivation is the one which most promptly identifies yn -tactic relations  , and is thus the prefer rederivation . 
It is possible to extend the viable analysis criterion to encompass this consideration of efficiency as well  . 
The infant learns that it is usually most efficient to combine whenever possible  , and to discard an analysis in which a combination is possible  , but not taken .  3 . 
While this left-branching criterion eliminates the inefficiency due to flexibility of derivation  , it gives rise to difficulties with (5) . 
John loves Mary madly ( 5 ) s/vpvp/np np vp\vpIn ( 5 )  , it is precisely the non-left-branching derivation of ' John loves Mary ' which is necessary in order to make the VP constituent available for combination with the adverb  . ( See Pareschi and
Steedman 1987 . ) 5 . 2 P rev ious Approaches Following up on the work of Lambek  ( 1958 ) who proposed that the process of deriving the grammaticality of a string of categories be viewed as a proof  , there have been quite a few proposals put forth for computing only normal forms of derivations or proofs  ( KS nig 1989 ; Hepple and Morrill 1989 ; Hepple 1991 ; inter alia ) . The basic idea with all of these works is to define ' normal forms '-- distinguished members of each equivalence class of derivations  , and to require the parser to search this smaller space of possible derivations  . But none of the proposed methods result in parsing systems which proceed incrementally through the string  . 4 Karttunen ( 1989 ) and others have proposed chart-based parsers which directly address the derivational ambiguity problem  . For the present purpose , the principal feature of chart parsing -- the factoring out of constituents from analyses -- turns out to create a nencumberance : The interpreter cannot compare constituents  , or arcs , for the purposes of ambiguity resolution . It must compare analyses of the entire prefix so far  , which are awkward to compute from the developing chart  . 
3 Discussion of the consequences of this move on the processing of picture noun extractions and ambiguity-related filled-gap effects is omitted for lack of space  . See
Niv (1993a).
4In the case of Hepple's (1991) proposal , a left-branching normal form is indeed computed . But its computation must be delayed for some words  , so it does not provide the interpreter with timely information about the incoming string  . 

Pareschi and Steedman ( 1987 ) propose the following strategy : ( which can be taken out of the chart-parsing context of their paper  ) construct only maximally left-branching derivations  , but allow a limited form of backtracking when a locally non-left-branching derivation turns out to have been necessary  . For example , when parsing (5) , Pareschi and Steedman's algorithm constructs the left branching analysis for ' John loves Mary '  . When it encounters ' madly ' , it applies >0 in reverse to solve for the hidden VP constituent ' loves Mary ' by subtracting the s/vp category ' John ' from the scategory ' John loves Mary ': 
John loves Mary ( 6 ) s/vpvp/nP > lnp s/np v pv pmadly vp\vp >0 reveal >0   <0   >0 The idea with this ' revealing ' operation is to exploit the fact that the rules > n and < n  , when viewed as three-place relations , are functional in all three arguments . That is , knowledge any two of left constituent , right constituent , result ) , uniquely determines the third . There are many problems with the completeness and soundness Pareschi and Steed-man's proposal  ( Hepple 1987 ; Niv 1993a ) . For example , in (7) , the category b\c cannot be revealed after it had participated in two combinations of mixed direction :  <0 and >0  . 
(7 ) a/bcd\C < ob\db\c\ ( b\c ) d <0 b >0 a stuck 6 A Proposal Pareschi and Steedman's idea of lazy parsing is very attractive in the present setting  . I propose to replace their unification-based revealing operation with a normal-formbased manipulation of the derivation history  . The idea is to construct and maintain the maximally incremental  , left-branching derivations . ( see section 4 . ) When a constituent such as the VP ' loves Mary ' in  ( 5 ) may be necessary , e . g . whenever the rightmost constituent in an analysis is of the form X\Y  , the next-to-right-most derivation is rewritten to its equivalent right-branching derivation by repeated application the local transformations  , defined in (8) and (9) . 
The right frontier of the rewritten derivation ow provides all the grammatically possible attachment sites  . 

W/X x\[YI'''IYm-~/Ym
W\[Yz'.'lY re-1/Y,~
Ym\[Zl ""\[ Z,~>m>n
WIYz'-'IYm-IlZI''-IZ ~
W/XX\[Y1...\[Ym_I/Y mYmIZl'''\]Zn
XlYe.-.\[Ym-~IZ ~... IZ , ~~ n~m+n-1(9)
WIY 1.-. Wm-~lZ~"''IZ,
Y . ~\[ Z1- . .lZn X \[ Ya ' ' ' IY , ~- I\Y mW\X < nxIYz """ IY , , , - aIza . .- IZ,
WIYI-.-IYm_IIZI '.. IZn .._ .._4 < m+n-I
YmIZ ~'-- IZ . XIY 1.-. IY . ~_ I\Y mW\X < m
W\[Y1-..IY.~-~\Ym<n
WWI""\[Y~-I\[Za'.-\[Z,
Results from the study of rewrite systems ( see Klop ( 1992 ) for an overview ) help determine the computational complexity of this operation :  6  . 1 A Rewri te System for Derivations If x is a node in a binary treelet A  ( x )   ( resp . p(x )) refer to its left ( right ) child . 
Any subtree of a derivation which matches the left -hand-side of either  ( 8 ) or ( 9 ) is called are dez . 
The result of replacing a redex by the corresponding right-hand-side of a rule is called the eontractum  . A derivation is in normal form ( NF ) if it contains no redexes . In the following I use the symbol--~ to also stand for the relation over pairs of derivations such that the second is derived from the first by one application of  , 7 . Let ~-- be the converse of ---* . Let (, be ~ U ~ - - - . Let , ~ be the reflexive transitive closure of --~ and similarly  , the reflexive transitive closure of ~--- , and ,   , , the reflexive transitive closure of ~ ,  . Note that .   .   .   . 
is an equivalence relation.
A rewrite system is strongly normalizing ( SN ) iff every sequence of applications of ~ is finite . 
Theorem 1 ---* is SN 5 proofEvery derivation with n internal nodes is assigned a positive integer score  . An application of is guaranteed to yield a derivation with a lower  5Hepple and Morrill ( 1989 ) Proved SN for a slight variant of ---* . The present proof provides a tighter score function  , see lemma 1 below . 

Figure 2: Schema for one redex in DRS score . This is done by defining functions  #and for each node of the derivation as follows:  ( ~ if x is a leaf node # ( x )  = + # ( A ( x ) ) + # ( p ( x ) ) otherwise f0 if x is a leaf node ~ ( x ) = ~? r ( A ( x ) ) + ~ ( p ( x ) ) + # ( A ( x ) ) otherwise Each application of ---+ decreases a , the score of the derivation . This follows from the monotonic dependency of the score of the root of the derivation upon the scores of each subderivation  , and from the fact that locally , the score of a redex decreases when ---+ is applied : In figure  2  , a derivation is depicted schematically with a redex whose subconstituents are named a  , b , and c . Applying ~ reduces ~( e ) , hence the score of the whole derivation . 
in redex : # ( d )  -=- # ( a ) - t-# ( b ) + Icr ( d ) = or ( a )  + ~ ( b )  + # ( a )  ~ ( ~ )  = ~ ( d )  + ~ ( c )  + # ( d ) = c ~ ( a ) + q ( b ) + q ( c )  + # ( b ) +2-~ t ( a ) +1 in contractum : ~ ( f ) = a ( b )  + ~ ( c )  +# ( b )  ~ ( ~' )  = ~ ( ~ )  + ~ ( f )  + #0 )  = ~ ( ~ )  + ~ ( b )  + ~ ( c )  + #0 )  + # ( ~ )  < ~ ( ~ )  + ~ ( b )  + ~ ( 0 + #0 )  + 2 .  # ( ~ ) +1\[\] Observe that # ( x ) is the number of internal nodes in x . 
Lemma I Given a derivation x , let n =  #x . Every sequence of applications of ---+ is of length at most n  ( n-1 ) /2 . 6 proofBy induction on n : Base case : n = 1 ; 0 applications are necessary . 
Induction : Suppose true for all derivations of fewer than n internal nodes  . Let m =  #A(x ) . So0 < 6 Niv ( 1994 ) shows by example that this bound is tight . 
m_<n--1 and #p(x ) = n-m-1.
~ ( ~ ) - n ( n-1 ) /2 == a ( A ( x ) ) + a ( p ( x ) ) + # ( A ( x ) ) - n ( n-1 ) /2 < ~ (   . ~-~) (  , ~-~- i ) ( , ~-  , ~-2 )  ~ ( n1 ) -2+2+m-2 = ( m + 1 ) (rn - ( n-1 ) ) _<  0 recalling that 0 _ < m_<n- 1 \[\] So far I have shown that every sequence of applications of ----+ is not very long : at most quadratic in the size of the derivation  . In ow show that when there is a choice of redex , it makes no difference which redex one picks . That is , all redex selection strategies result in the same normal form  . 
A rewrite system is Church-Rosser ( CR ) just in case w , y . ( z , , , , y ~ 3z . ( z - - - ~ z ^ y , , z ) ) A rewrite system is Weakly Church-Rosser ( WCR ) justinease w ,  ~ , w . ( w ~ ~^ w ~ y)~3 z . (, ~ z^y , , z)
Lemma 2---, is WCR.
proofLet w be a derivation with two distinct re -dexes x and y  , yielding the two distinct derivations wI and w " respectively  . There are a few possibilities : case 1: x and y share no internal nodes . There are three subcases : x dominates y ( includes y as a subconstituent )  , x is dominated by y , or z and y are incomparable with respect o dominance  . Either way , it is clear that the order of application of ---+ makes no difference  . 
case 2: x and y share some internal node . Without loss of generality , y does not dominate x . There exists a derivation z such that w~----~ zAw " - - - ~ z  . 
This is depicted in figure 3 .   ( Note that all three internal nodes in figure 3 are of the same rule direction , either > or < . ) \[\]
Lemma 3 ( Newman ) WCRASNDCR.
Theorem 2 ~ is CR.
proof From theorem 1 and lemmas 2 and 3 . \[\] Therefore any maximal sequence of applications of ~ will lead to the normal form  7  . We are free to select the most efficient redex selection scheme  . From lemma1 the worst case is quadratic . 
Niv (1994) shows that the optimal strategy , of applying --+ closest as possible to the root , yields ---+ application sequences of at most n steps  . 
7 Assuming , as is the case with extant CCG accounts , that constraints on the applicability of the combinatory rules do not present significant road blocks to the derivation rewrite process  . 
1 30 dcc ? / ~ ax ~ ~ adcbaaba Arrows are annotated by the substrucure to which they are applied Figure  3: Why--~ is weakly Church-Rosser Note that all that was said in this section generalizes beyond CCG derivations to any associative algebra  . 
6.2 Discussion
Given the rightmost subconstituent recovered using the normal form technique above  , how should parsing proceed ? Obviously , if the leftward looking category which precipitated the normal form computation is a modifier  , i . e . of the form X\X , then i tought to be combined with the recovered constituent in a form analogous to Chomsky adjunction  . But what if this category is not of the form X\X ? For example  , should the parser compute there analysis n ( 10 ) ?  ( lO ) a/bb/C > lC/ds\ ( a/b ) \ ( b/d ) a/c > 1a/da/bb/cc/d>lS\ ( a/b ) \ ( b/d ) b/d < 0 s\ ( a/b )  <0

Ascribing the same non-garden-path status to the reanalysis n  ( 10 ) that we do to ( 6 ) would constitute a very odd move : Before reanalysis  , the derivation encoded the commitment that the / b of the first category is satisfied by the b of the b/c in the second category  . This commitment is undone in the reanalysis . This is an undesirable property to have in a computational model of parsing commitment  , as it renders certain revisions of commitments easier than others  , without any empirical justification . 
Furthermore , given the possibility that the parser change its mind about what serves as argument to what  , the interpreter must be able to cope with such nonmonotonic updates to its view of the analysis so far -- this would surely complicate the design of the interpreter  , s Therefore , constituents on the right-frontier of a right -normal-form should only combine with ' en do centric ' categories to their right  . 
The precise definition of ' en do centric ' depends on the semantic formalism used--it certainly includes post-head modifiers  , and might also include coordination . 
Stipulating that certain reanalyses are impossible immediately makes the parser ' incomplete ' in the sense that it cannot find the analysis in  ( 10 )  . 
From the current perspective of identifying arden paths  , this incompletenessia desirable , vena necessary property . In (10) , committing to the composition of a/b and b/c is tantamount to being led down the garden path  . In a different sense , the current parser is complete : it finds all analyses if the Viable Analysis Criterion and the interpreter never discard any analyses  . 
7 Conclusion
The current proposal shifts some of the burden traditionally associated with the parser to other components of the human cognitive faculty : the interprete resolves ambiguity  , and an acquired skill removes ' garbage ' analyses from the parser's memory--solving the so called spurious ambiguity problem  , as well as effectively apply in grammar-global constraints traditionally computed by topdown techniques or grammar compilation  . The resultant parser adheres to the desideratum that it be a generic search algorithm for the grammar formalism  , provided the definition of CCG explicitly includes the notion of ' derivation ' and explicates the truth conditional equivalencer lation  . Such inclusions have indeed been proposed ( Steedman 1990 )  . 
Bibliography
Aho , Alfred and S . C . Johnson .  1974 . LR Parsing . 
ACM Computing Surveys 6(2):99-124.
Altmann , Gerry T ., Alan Garnham , and Judith A.
Henstra .  1994 . Effects of syntax in human sentence parsing : Evidence against a structure-based proposal mechanism  . Journal of Experimental Psychology : Learning , Memory and
Cognition 20(1):1-8.
Dowty , David .  1988 . Type Raising , Functional Composition , and Non-Constituent Conjunction . In Richard T . Oehrle , Emmon Bach , and sI am indebted to Henry Thompson for a discussion of monotonicity  . 

Deirdre Wheeler ( Eds . ) , Categorial Grammars and Natural Language Structures  . Reidel . 
Earley , Jay .  1970 . An Efficient ContextFree Parsing Algorithm . Communications of the Association for Computing Machinery  13:94-102  . 
Hepple , Mark R .  1987 . Methods for Parsing Combinatory Grammars and the Spurious Ambiguity Problem  . Master's thesis , University of Edinburgh . 
Hepple , Mark R .  1991 . Efficient Incremental Processing with Categorial Grammar  . In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics  ,  7986 . 
Hepple , Mark R . and Glyn V . Morrill .  1989 . Parsing and Derivational Equivalence . In Proceedings of the Annual Meeting of the European Chapter of the Association for Computational 

Karttunen , Lauri .  1989 . Radical Lexicalism . In Mark Baltin and Anthony S . Kroch ( Eds . ) , Alternative Conceptions of Phrase Structure ,  43-65 . Chicago : University of Chicago Press . 
Kawamoto , Alan and William Farrar .  1993 . The Return of Visiting Relatives : Pragmatic Effects in Sentence Processing  . Quarterly Journal of Experimental Psychology 46 A ( 3 ) :463 -487 . 
Klop , Jan W . 1992. Term Rewrite Systems.
In Sams on Abramsky , Dov M . Gabbay , and
T . S . E . Maibaum ( Eds . ), Handbook of Logic in Computer Science , Vol .  2, 1 - 116 . Oxford :
Clarend on Press.
KSnig , Esther .  1989 . Parsing as Natural Deduction . 
In Proceedings of the g7th Annual Meeting of the Association for Computational Linguistics  ,  272-279 , June . 
Lambek , Joachim .  1958 . The Mathematics of Sentence Structure . American Mathematical
Monthly 65: 154-169.
MacDonland , Maryellen , Adam Just , and Patricia Carpenter .  1992 . Working Memory Constraints on the Processing of Syntactic Ambiguity  . Cognitive Psychology 24:56-98 . 
Nicol , Janet L . and Martin J . Pickering .  1993 . Processing Syntactically Ambiguous Sentences : Evidence from Semantic Priming  . Journal of
Psycholinguistic Research.
Niv , Michael . 1993a . A Computational Model of Syntactic Processing : Ambiguity Resolution from Interpretation  . PhD thesis , University of Pennsylvania . ( ftp://ftp . cis . upenn . edu/pub/-ircs/tr/93-27 . ps) . 
Niv , Michael . 1993b . Resolution of Syntactic Ambiguity : the Case of NewSubjects  . In Proceedings of the 15th Annual Conference of the Cognitive Science Society  , Hillsdale , NJ . Lawrence
Erlbaum Associates.
Niv , Michael .  1994 . The complexity of normal form rewrite sequences for Associativity  . Technical Report LCL94-6 , Computer Science Department , Technion . ( ftp://ftp . cis . upenn . -edu/pub/niv/rewrite . ps) . 
Pareschi , Remo and Marka . Steedman .  1987 . A Lazy Way to Chart Parse with Combinatory Grammars  . In Proceedings of the 25th Annual Meeting of the Association for Computational 

Shieber , Stuart M . and Mark Johnson .  1993 . Vari-ations on Incremental Interpretation . Journal of Psycholinguistic Research . ( to appear) . 
Steedman , Mark J .  1987 . Combinatory Grammars and Parasitic Gaps . Natural Language and Linguislic Theory 5: 403-439 . 
Steedman , Mark J .  1990 . Gapping as Constituent Coordination . Linguistics and Philosophy 13: 207-264 . 
Steedman , Mark J .  1994 . Grammars and Processors . In Hans Kamp and Christian Rohrer ( Eds . ), Aspects of Computational Linguistics . 
Springer Verlag . ( to appear).
Trueswell , John C . and Michael K . Tanenhaus.
1991 . Tense , Temporal Context and Syntactic Ambiguity Resolution  . Language and Cognitive Processses 6: 303-338 . 
Trueswell , John C . and Michael K . Tanenhaus.
1994. Toward a Lexicalist Framework of
Constraint-Based Syntactic Ambiguity Resolution . In Charles Clifton , Lyn Frazier , and Keith Rayner ( Eds . ), Perspectives on Sentence Processing . Hillsdale , NJ : Lawrence Erlbaum


