Efficient Construction of Underspecified Semantics under 
Massive Ambiguity
Jochen D5 rre *
Institut fiir maschinelle Sprachverarbeitung
University of Stuttgart
Abstract
We investigate the problem of determining a compact underspecified semantical representation for sentences that may be highly ambiguous  . Due to combinatorial explosion , the naive method of building semantics for the different syntactic readings independently is prohibitive  . We present a method that takes as input a syntactic parse forest with associated constraint -based semantic on struction rules and directly builds a packed semantic structure  . 
The algorithm is fully implemented and runs in O ( n4log ( n ) ) in sentence length , if the grammar meets some reasonable ' nor-mality ' restrictions  . 
1 Background
One of the most central problems that any NL system must face is the ubiquitous phenomenon of ambiguity  . In the last few years a whole new branch developed in semantics that investigates underspecified semantic representations i order to cope with this phenomenon  . Such representations do not stand for the real or intended meaning of sentences  , but rather for the possible options of interpretation  . Quantifier scope ambiguities are a semantic variety of ambiguity that is handled especially well by this approach  . Pioneering work in that direction has been ( Alshawi 92 ) and ( Reyle 93 )  . 
More recently there has been growing interest in developing the underspecification approach to also cover syntactic ambiguities  ( cf . ( Pinkal 95; EggLe-beth 95; Schiehlen 96)) . Schiehlen's approach is outstanding in that he fully takes into account syntactic * This research as been carried out While the author visited the Programming Systems Lab of Pr of  . 
GertSmolk at the University of Saarland , Saarbriicken . 
Thanks to John Maxwell , Martin Miiller , Joachim Niehren , Michael Schiehlen , and an anonymous reviewer for valuable feedback and to all at PSLab for their helpful support with the OZ system  . 
constraints . In ( Schiehlen 96 ) he presents an algorithm which directly constructs a single underspecified semantic structure from the ideal " underspeci-fled " syntactic structure  , a parse forest . 
On the other hand , a method for producing " packed semantic structures "  , in that case " packed quasi-logical forms " , has already been used in the Core Language Engine  , informally described in ( A1-shawi92 , Chap .  7) . However , this method only produces a structure that is virtually isomorphic to the parse forest  , since it simply replaces parse forest nodes by their corresponding semantic operators  . No attempt is made to actually apply semantic operators in the phase where those " packed QLFs " are constructed  . Moreover , the packing of the QLFs seems to serve no purpose in the processing phases following semantic analysis  . Already the immediately succeeding phase " sortal filtering " requires QLFs to be unpacked  , i . e . enumerated . 
Contrary to the CLE method , Schiehlen's method actively packs semantic structures  , even when they result from distinct syntactic structures  , extracting common parts . His method , however , may take time exponential w . r . t , sentence length . Already the semantic representations it produces can be exponentially large  , because they grow linear with the number of ( syntactic ) readings and that can be exponential , e . g . , for sentences that exhibit the wellknown attachment ambiguity of prepositional phrases  . It is therefore an interesting question to ask , whether we can compute compact semantic representations from parse forests without falling prey to exponential explosion  . 
The purpose of the present paper is to show that construction of compact semantic representations like in Schiehlen's approach from parse forests is not only possible  , but also cheap , i . e . , can be done in polynomial time . 
To illustrate our method we use a simple DCG grammar for PP-attachment  . ambiguities , adapted from ( Schiehlen 96) , that yields semantic representations ( called UDI~Ss ) according to the Underspec-ified Discourse Representation Theory  ( Reyle 93 ; Kamp Reyle 93) . The grammar is shown in Fig .  1 . 
386 start ( DRS ) --> s(\[ . . . . itop \], \[\], DRS) . 
s(\[Evenc , VerbL , DomL\] , DRS i , PRS_o ) --> np(\[X , VerbL , DomL\] , DRS_i , DRSI ) , vp(\[Event , X , VerbL , DomL\] , DRS1 , DRS_o) . 
s(\[Event , VerbL , DomL\] , DRS_i , DRS_o ) --> s(\[Event , Verb L , DomL\] , DRSi , DRS l ) , pp(\[Event , VerbL , DomL\] , DRSi , DRSo) . 
vp(\[Ev , X , VerbL , DomL\] , DRS_i , DRSo)-->vt(\[Ev , X , Y , VerbL , DomL\] , DRS_i , DRSI ) , np(\[Y , VerbL , DomL\] , DRSI , DRS_O) . 
np(\[X , VbL , DomL\] , DRS i , DRS_o ) --> det(\[X , Nou~ , L , VbL , DomL\] , DRS_i , DRSI ) , n(\[X , NounL , DomL\] , DRSI , DRSo) . 
n(\[X , NounL , DomL\] , DRS i , DRS_o ) --> n(\[X , NounL , DomL\] , DRS i , DRSI ) , pp(\[X , NounL , DomL\] , DRSI , DRS_o) . 
pp(\[X , L , DomL\] , DRS_i , DRSo ) --> prep(Cond , X , Y ) , np(\[Y , L , DomL\] , \[ L:CondlDRSi \] , DRS o ) . 
vt(\[Ev , X , Y , L , _DomL\] , DRS_i , DRS)-->\[saw\] , \[ DRS=\[L:see(Ev , X , Y ) IDRS_i \] . 
det(\[X , Lab , VerbL , _\]  , DRS i , DRS ) -->\[ a\] , \[ DRS=\[It(Lab , ltop ) , It(VerbL , Lab) , 
Lab : XIDRS_i \], gensym(l , Lab ), gensym(x,X).
det(\[X , ResL;VbL , DomL\] , DRSi , DRS ) -->\[ every \] , ( DRS =\[ lt(L , DomL ) , lt(VbL , ScpL) , ResL:X , 
L:every(ResL , ScpL)IDRS_i \] , gensym(l , L) , gensym(l , ResL ) , gensym(l , ScpL) , gensym(x , X) . 
np(\[X . . . . \] , DRS_i , DRS ) -->\[ i \] , \[ DRS=\[itop:X , anchor(X , speaker ) IDRS_i \] , gensyrn(x , X) . 
n(\[X , L , _\] , DRS , \[L:man(X ) IDRS\])-->\[man\] . 
n(\[X , L , _\] , DRS , \[L : hilI(X)IDRS \]) -->\[ hill\] . 
prep(on(X,Y ), X,Y)-->\[on\].
prep(with(X,Y ), X,Y ) -->\[ with\].
Figure h Example DCG
The UDRSs constructed by the grammar are flat lists of the UDRS-constraints I < __ l '  ( subordination ( partial ) ordering between labels ; Prolog representation : it(l , l ')) , l : Cond ( condition introduction in subUDRS labeled l )  , I : X ( referent introduction in l) , l : Gen Quant(l ' , l " )   ( generalised quantifier ) and an anchoring function . The meaning of a UDKS as a set of denoted DRSs can be explained as follows  .   1 All conditions with the same label form a subUDRS and labels occurring in subUDRSs denote locations  ( holes ) where other subUDRSs can be plugged into . The whole UDRS denotes the set of wellformed DRSs that can be formed by some plugging of the subUDRSs that does not violate the ordering <  . Scope of quantifiers can be underspecified in UDRSs  , because subordination can be left partial . 
In our example grammar every nonterminal has three arguments  . The 2nd and the 3rd argument represent a UDRS list as a difference list  , i . e . , the UDRS is " threaded through " . The first argument is a list of objects occurring in the UDRS that play a specific role in syntactic ombinations of the current node  . 2 An example of a UDRS , however a packed UDRS , is shown later on in ?5 . 
To avoid the dependence on a particular grammar formalism we present our method for a constraint -based grammar abstractly from the actual constraint  1Readers unfamiliar with DRT should think of these structures as some Prolog terms  , representing semantics , built by unifications according to the semantic rules  . It is only important onotice how we extract common parts of those structures  , irrespective of the structures ' meanings . 
~E . g . , for an NP its referent , as well as the upper and lower label for the current clause and the top label  . 
system employed . We only require that semantic rules relate the semantic ' objects ' or structures that are associated with the nodes of a local tree by employing constraints  . E . g . , we can view the DCG rule s ~ np vp as a relation between three'semantic construction terms ' or variables SereS  , SemNP , 
SemVP equivalent to the constraints
Seres =\[\[ Event , Verb L , Dom L , TopL\] , DRS_i , DRS_o\]SemNP=\[\[X , VerbL , DomL , TopL\] , DRS_i , DRSI\]SemVP=\[\[Event , X , Verb L , Dom L , TopL\] , DRS 1 , DRS_o\]Here is an overview of the paper .   ?2 gives the pre-liminaries and assumptions needed to precisely state the problem we want to solve  . ?3 presents the abstract algorithm . Complexity considerations follow in ?4 . Finally , we consider implementation issues , present results of an experiment in ?5 , and close with a discussion . 
2 The Problem
As mentioned already , we aim at calculating from given parse forests the same compact semantic structures that have been proposed by  ( Schiehlen 96 )  , i . e . structures that make explicit the common parts of different syntactic readings  , so that subsequent semantic processes can use this generalised information  . Ashedoes , we assume a constraint-based grammar , e . g . a DCG ( Pereira Warren 80 ) or HPSG ( Pollard Sag 94 )   , in which syntactic on straints and constraints that determine a resulting semantic representation can be seperated and parsing can be performed using the syntactic on straints only  . 
Second , we assume that the set of syntax trees can be compactly represented as a parse forest  ( cf . ( Earley 70; Billot Lang 89; Tomita86)) . Parse forests are rooted labeled directed acyclic graphs with AND-nodes  ( standing for contextfree branch-npp/\//np np  12  /  , 3

PP 2324 2526 2728 2930 np 3132
Is a waman on the hill with the tele
Figure 2: Example of a parse foresting ) and OR-nodes ( standing for alternative subtrees )  , that call be characterised as follows ( cf . Fig . 2 for an example ) . 3 1 . The terminal yield as well as the label of two AND-nodes are identical  , if and only if they both are children of one OR -node  . 
2. Every tree reading is . a valid parse tree.
Tree readings of such graphs are obtained by replacing any OR-node by one of its children  . Parse forests can represent an exponential number of phrase structure alternatives in o  ( n3 ) space , where n is the length of the sentence . The example uses the 3OR-nodes ( A , B , C ) and the AND-nodes 1 through 32 to represent 5 complete parse trees , that would use 5x19 nodes . 
Third , we assume the rule-to-rule hypothesis , i . e . ,  3The graphical representation fan OR-node is a box surroux ~ ding its children  , i . e . the AND-OR-graph structure of ~ iso ~ . 
ND that the grammar associates with each local tree a ' semantic rule ' that specifies how to construct hem other node's semantics from those of its children  . 
Hence , input to the algorithm is ? a parse forest ? an associated semantic rule for every local tree  ( AND-node together with its children ) therein ? and a semantic representation for each leaf  ( coming from a semantic lexicon )  . 
To be more precise , we assume a constraint language C over a denumerable set of variables X  , that is a sublanguage of Predicate Logic with equality and is closed under conjunction  , disjunction , and variable renaming . Small greek letters ? , ? will l lhen ce forth denote constraints ( open formulae ) and letters X , Y , Z ( possibly with indeces ) will denote variables . Writing ?( X1, .   .   . , Xk ) shall indicate that X1 .   .   .   . , Xk are the free variables in the constraint ~ . 
Frequently used examples for constraint languages are the language of equations over first-order terms typed feature structure description languages  ( like the constraint languages of ALE ( Carpenter 92 ) or CUF ( D6 rreDorna 93 ) ) for HPSG-style grammars . 
Together with the constraint language we require a constraint solver  , that checks constraints for satis-fiability , usually by transforming them into a normal form ( also called ' solved for m ' )  . Constraint solving in the DCG case is simply unification of terms  . 
The semantic representations mentioned before are actually not given directly  , but rather as a constraint on some variable , thus allowing for partiality in the structural description  . To that end we assume that every node in the parse forest u has associated with it a variable X v that is used for constraining the  ( partial ) semantic structure of u . The semantics of a leaf node  #is hence given as a constraint ?  , ( X ,  )  , called a leaf constraint . 
A final assumption that we adopt concerns the nature of the ' semantic rules '  . The process of semantics construction shall be a completely monotonous process of gathering constraints that never leads to failure  . We assume that any associated ( instantiated ) semantic rule r ( u ) of a local tree ( AND-branching ) u ( ul ,   .   .   .   , u  ~ ) determines u's semantics Z ( u ) as follows from those of its children : Z (  , ,) = 3X , ,  ,   .   .   . 3X ~,(?~( , , )( X , , , X , , , , .   .   . , X , , , ) A
Z(I."I)A . . . AE(Uk)).
The constraint Cr(v ) ( Xv , Xvl, .   .   . , X ~) is called the rule constraint for ~, . It is required to only depend on the variables X  ~  , X  ~ I ,   .   .   . , X  ~ , . Note that if the same rule is to be applied at another node  , we have a different rule constraint . 
Note that any F , (~ , ) depends only on Xv and can be thought of as a unary predicate  . Now , let us consider semantics construction for a single parse tree for the moment  . The leaf constraints together with the rules define a semantics constraint Z  ( ~ , ) for every node u , and the semantics of the full sentence is described by the T-constraint of the root node  ,  ~ , ( root ) . In the T-constraints , we actually can suppress the existential quantifiers by adopting the convention that any variable other than the one of the current node is implicitly existentially bound on the formula top level  . Name conflicts , that would force variable renaming , cannot occur . Therefore ~ ( root ) is ( equivalent to ) just a big conjunction of all rule constraints for the inner nodes and all leaf constraints  . 
Moving to parse forests , the semantics of an OR-node u(~ , l ,  . . . , uk ) is to be defined as z(, . , ) = 3x ~ , .   .   . 3x,~(z ( ,,~)^ x ~= x ~, v .   .   . 
vz(~k)^x ~= x ~) ,   4DCG shall refer in this paper to a logically pure version  , Definite Clause Grammars based on pure PROLOC , involving nononlogical devices like Cut , var/1 , etc . 
specifying that the set of possible ( partial ) semantic representations for u is the union of those of u's children  . However , we can simplify this formula once and for all by assuming that for every OR-node there is only one variable Xu that is associated with it and all of its children  . Using the same variable for ul . . . uk is unproblematic , because no two of these nodes can ever occur in a tree reading  . Hence , the definition we get is ~"\]( IJ ): Z(I\]I)V .   .   . VZ(lYk ) . 
Now , in the same way as in the single-tree case , we can directly " read off " the T-constraint for the whole parse forest representing the semantics of all readings  . Although this constraint is only half the way to the packed semantic representation we are aiming at  , it is nevertheless worthwhile to consider its structure a little more closely  . Fig . 3 shows the structure of the F , -constraint for the OR-node B in the example parse forest  . 
In a way the structure of this constraint directly mirrors the structure of the parse forest  . However , by writing out the constraint , we loose the sharings present in the forest . A subformula coming from a shared subtree ( as Z ( 18 ) in Fig .  3 ) has to be stated as many times as the subtree appears in an unfolding of the forest graph  . In our PP-attachment example the blowup caused by this is in fact exponential  . 
On the other hand , looking at a T-constraint as a piece of syntax , we can represent this piece of syntax in the same manner in which trees are represented in the parse forest  , i . e . we can have a representation fZ ( root ) with a structure isomorphic to the forest's graph structure  , sIn practice this difference becomes a question of whether we have full control over the representations the constraint solver employs  ( or any other process that receives this constraint as input  )  . 
If not , we cannot contend ourselves with the possibility of compact representation f constraints  , but rather need a means to enforce this compactness on the constraint level  . This means that we have to introduce some form of functional abstraction i to the constraint language  ( or anything equivalent that allows giving names to complex constraints and referencing to them via their names  )  . Therefore we enhance the constraint language as follows  . We allow to our disposition a second set of variables  , called names , and two special forms of constraints 1 . def(<name >, < constraint >) name definition 2 . < name > name use with the requirements , that a name may only be used , if it is defined and that its definition is unique  . 
Thus , the constraint Z ( B ) above can be written as ( ? r ( 6 ) A .   .   . A ? 26 AN
V ? ~(7) A . . . A ? 26AN)
A def(N , ? r ( 18 ) A ? 27 A ? r ( 21 ) A?2SA?29 ) 5 The packed QLFs in the Core Language Engine ( A1-shawl 92 ) are an example of such a representation . 
3896 r ( 6 ) A623 Ad ) r ( 10 ) A024 A6 r ( 12 iA ( ~25 ACr ( lS ) A626 A~r ( ISA~27A ( ~ r ( 21 ) A628 A~29 . z ( s )  ~ ( 6 ) v6r ( 7 ) A ~ r ( 14 ) A623 AOr ( 17 ) A624 A6 r ( 20 ) A625A626/~~r ( 18 ) A ~27 A6 r ( 21 ) A 628 A6 29

Figure 3: Constraint E ( B ) of example parse forest The packed semantic representation as constructed by the method described so far still calls for an obvious improvement  . Very often the different branches of disjunctions contain constraints that have large parts in common  . However , although these overlaps are efficiently handled on the representational level  , they are invisible at the logical level . Hence , what we need is an algorithm that fac-tores out common parts of the constraints on the logical level  , pushing disjunctions down .   6 There are two routes that we can take to do this efficiently  . 
In the first we consider only the structure of the parse forest  , however ignore the content of ( rule or leaf ) constraints . I . e . we explore the fact that the parts of the E -constraints in a disjunction that stem from nodes shared by all disjuncts must be identical  , and hence can be factored out/More precisely , we can compute for every node v the set must -occur  ( v ) of nodes ( transitively ) dominated by v that must occur in a tree of the forest  , whenever u occurs . We can then use this information , when building the disjunction E ( u ) to factor out the constraints introduced by nodes in must-occur  ( v )  , i . e . , we build the factor ? = Av'emust-occur ( v ) Z ( u ' ) and a ' remainder ' constraint E ( ui ) \ ~ for each disjunct . 
The other route goes one step further and takes into account he content of rule and leaf constraints  . 
For it we need an operation generalise that can be characterised informally as follows  . 
For two satisfiable constraints ? and ~ , generalise (? , ! b ) yields the triple ~ ,  ?' ,  ~3' , such that ~ contains the ' common part ' of ? and  19 and ?' represents the ' remainder ' 6\~ and likewise 19' represents 19\~  . 
6 Actually , in the E ( B ) example such a factoring makes the use of the name N superfluous  . In general , however , use of names is actually necessary to avoid exponentially large constraints  . Subtrees may be shared by quite different parts of the structure  , not only by dis-juncts of the same disjunction . In the PP-attachment example , a compression of the E-constraint to polynomial size cannot be achieved with factoring alone  . 
7 ( Maxwell III Kaplan 93 ) exploit the same idea for efficiently solving the functional constraints hat an LFG grammar associates with a parse forest  . 
The exact definition of what the ' common part ' or the ' remainder's hall be  , naturally depends on the actual constraint system chosen  . For our purpose it is sufficient o require the following properties : If generalise  ( ~ .  19) ~-~ (~ ,  ~' , ~b ') , then ~ I - and Of -~ and o = ~ A ? ' and ~ b -= ~ A ~ b ' . 
We shall call such a generalisation operation simplifying if the normal form of ~ is not larger than any of the input constraints ' normal form  . 
Example : An example for such a generalisation operation for PROLOG'S constraint system  ( equations over first-order terms ) is the socalled anti-unify operation , the dual of unification , that some PROLOG implementations provide as a library predicate  , s Two terms T1 and T2'anti-unify ' to T , iffT is the ( unique ) most specific term that subsumes both T1 and T2 . The ' remainder constraints ' in this case are the residual substitution sal and  a2 that transform T into T1 or T2  , respectively . 
Let us now state the method informally . We use generalise to factor out the common parts of disjunctions  . This is , however , not as trivial as it might appear at first sight . Generalise should operate on solved forms , but when we try to eliminate the names introduced for subtree constraints in order to solve the corresponding constraints  , we end up with constraints that are exponential in size  . In the following section we describe an algorithm that circumvents this problem  . 
3 The Algorithm
We call an order < on the nodes of a directed acyclic graph G =  ( N , E ) with nodes N and edges E bottom-up , iff whenever ( i , j ) EE (" i is a predecessor to j ") , then j < i . 
For the sake of simplicity let us assume that any nonterminal node in the parse forest is binary branching  . Furthermore , we leave implicit , when conjunctions of constraints are normalised by the constraint solver  . Recall that for the generalisation operation it is usually meaningful to operate on Santi_unify in Quintus Prolog  , term_subsumer in
Sicstus Prolog.

Input : ? parse ' forest , leaf and rule constraints as described above ? array of variables X ~ indexed by nodes  . t . if v is a child of OR-node v ' , then X v = X v , Data structures : ? an array SEM of constraints and an array D of names  , both indexed by node ? a stack ENV of def constraints Output : a constraint representing a packed semantic representation 
Method : ENV := nil process nodes in a bottom-up order doing with node u : if u is a leaf then 
SEM\[v\]:=?,
D\[v\]::true eise if v is AND(v1 , v2) then SEIVlIv\]:=Cr ( , ) A SEM\[vl \] A SEM\[v2\] if D\[vl\]=true then D\[v\]:= D\[u2\] else if Dive \] = true then D\[v\]:=D\[vl\] else D\[v\]:=new name push def  ( D\[v\] , D\[vl\]AD\[v2\] ) onto ENV end else if v is OR ( v1 , v2) then let GEN , REM 1 , REM2 such that generalise ( SEM\[vl\] , SEM\[v2\])~-+(GEN , REM 1 , REM2)
SEM\[v\]:=GEN
D\[v\]:=new name push def(D\[v\] , REM1AD\[vl\]VREM2AD\[v2\] ) onto ENV end return SEM\[root\]AD\[root\]A ENV Figure  4: Packed Semantics Construction Algorithm solved forms  . However , at least the simplifications true A ?--? and ? A true = -- ? should be assumed  . 
The Packed Semantics Construction Algorithm is given in Fig  .  4 . It enforces the following invariants , which can easily be shown by induction . 
1. Every name used has a unique definition.
2 . For any node v we have the equivalence ~ ( v ) -SEM\[u \] A\[D\[v\]\] , where \[ D\[u \]\] shall denote the constraint obtained from D\[v\]when recursively replacing names by the constraints they are bound to in ENV  . 
3 . For any node u the constraint SEM\[v\]is never larger than the ~- constraint of any single tree in the forest originating in u  . 
Hence . the returned constraint correctly represents the semantic representation for all readings  . 
4 Complexity
The complexity of this abstract algorithm depends primarily on the actual constraint system and generalisation operation employed  . But note also that the influence of the actual semantic operations prescribed by the grammar can be vast  , even for the simplest constraint systems . E . g . , we can write a DCGs that produce abnormal large " semantic structures " of sizes growing exponentially with sentence length  ( for a single reading )  . For meaningful grammars we expect his size function to be linear  . Therefore , let us abstract a way this size by employing a function fa  ( n ) that bounds the size of semantic structures ( respectively the size of its describing constraint system in normal form  ) that grammar G assigns to sentences of length n . 
Finally , we want to assume that generalisation is simplifying and can be performed within a bound of g  ( m ) steps , where m is the total size of the input constraint systems  . 
With these assumptions in place , the time complexity for the algorithm can be estimated to be  ( n = sentence length , N = number of forest nodes ) O ( g ( fc ( n )   ) " N ) <_ O ( g ( f a ( n )   )   . n3) , since every program step other than the generalisation operation can be done in constant ime per node  . Observe that because of Invariant 3 . the input constraints to generalise are bounded by fc as any constraint in SEM  . 
In the case of a DCG the generalisation operation is anti_unify  , which can be performed in o(n . log ( n ) ) time and space ( for acyclic struc-tures )  . Hence , together with the assumption that the semantic structures the DCG computes can be bounded linearly in sentence length  ( and are acyclic )  , we obtain a O(n . log(n ) . N ) < O(n41 og(n )) total time complexity . 

SEM\[top\]:\[itop:xl , anchor(xl , ' Speaker ') ii : see ( el , xl , x2) , it (12 , 1 top ) , it ( ll , 12) , 12: x2 , 12: man(x2) , 
A : on(B , x3), it (13, 1 top),
It(A , 15) , 14: x 3 , 13: every (14 , 15) , 14: hill ( x3) , 
C : with(D , x4) , it (16 , 1 top ) , it(C , 16) , 16: x 4 , 16: tele(x4)\]
D\[top\](aProlog goal):dEnv(509 , 1 , \[B , A , D , C\])
ENV ( as Prolog predicates ): deny (506 , i , A ) ( A = \[ e , ll \] iA =\[ x2 , 12\]dEnv (339 , i , A ) :-( A =\[ C , B , C , B \]; A = Ix 3 , 14  . . .   . \]) dEnv(509 ,  2 , A ) :-( A = \[ el , ll , x3 , 14\]; A = Ix 2 , 12 , C , B \] , dEny (339 , I , \[ C , B , x2 , 12\])) dEnv (509 , i , A ) :-( A =\[ G , F , eI , II\] , deny (506 , i , \[G , F\])
A =\ [ E , D , C , B \] , dEny(509 ,  2 , \[ E , D , C , B \] ) Figure 5: Packed UDRS : conjunctive part ( left column ) and disjunctive binding environment 5 Implementation and Experimental
Results
The algorithm has been implemented for the PRO -LOG  ( or DCG ) constraint system , i . e . , constraints are equations over first-order terms  . Two implementations have been done . One in the concurrent constraint language OZ ( Smolka Treinen 96 ) and one in Sicstus Prolog . 9The following results relate to the
Prolog implementation , l ?
Fig .   5 shows the resulting packed UDRS for the example forest in Fig  .  2 . Fig . 6 displays the SEM part as a graph . The disjunctive binding environment only encodes what the variable referents B and D  ( in conjunction with the corresponding labels A and C  ) may be bound to to : one of el , x2 , or x3 ( and likewise the corresponding label ) . Executing the goal deny (509 , 1 , \[ B , A , D , C \]) yields the five solutions : A = ii , B = el , C = ii , D = el ?; A=12 , B = x2 , C = ii , D = el ?; A=11 , B = el , C = 14 , D =  x3?; A=12 , B = x2 . C = 12 , D = x2?; A=12 , B = x2 , C = 14 , D =  x3?; no
I ? -
Table 1 gives execution times used for semantics construction of sentences of the form Isawa man  ( on a hill ) n for different n . The machine used for ? The OZ implementation has the advantage that feature structure constraint solving is builtin  . Our implementation actually represents he DCG terms as a feature structures  . Unfortunately it is an order of magnitudes lower than the Prolog version  . The reason for this presumablyies in the fact that meta-logical operations the algorithm needs  , like generalise and copy_term have been modeled in OZ and not on the logical level were they properly belong  , namely the constraint solver . 
1? This implementation is available from http://www . ims . uni-stuttgart . de/'jochen/CBSem . 
12 ~ x21415 Iman ( x2 ) Ix3'\[hill ? x3 ) x ~ I11'A/
I see ( el'x2) l?n(B'x3) Jl to panchor(x1 , ' Speaker ')


I with ( D , x4)
Figure 6: Conjunctive part of UDRS , graphically n
Readings 5   35   42   91   429   183   4862   319   58786   507   742900   755   9694845   1071   129Mio   .  1463
AND -+ OR-nodes Time 4 msec 16 msec 48 msecl l4 msec 220 msec 430 msec 730 msec i140 msec
Table 1: Execution times the experiment was a Sun Ultra-2   ( 168 MHz )  , running Sicstus3 . 0~3 . In a further experiment an nary anti_unify operation was implemented  , which improved execution times for the larger sentences  , e . g . , the 16 PP sentence took 750 msec . These results approximately fit the expectations from the theoretical complexity bound  . 
3926 Discussion
Our algorithm and its implementation show that it is not only possible in theory  , but also feasible in practice to construct packed semantical representations directly from parse forests for sentence that exhibit massive syntactic ambiguity  . The algorithm is both in asymptoticomplexity and in real numbers dramatically faster than an earlier approach  , that also tries to provide an underspecified semantics for syntactic ambiguities  . The algorithm has been presented abstractly from the actual constraint system and can be  2dapted to any constraint-based grammar formalism . 
A critical assumption for the method has been that semantic rules never fail  , i . e . , no search is involved in semantics construction . This is required to guarantee that the resulting constraint is a kind of ' solved form ' actually representing so-to-speak the free combination of choices it contains  . Nevertheless , our method ( modulo small changes to handle failure ) may still prove useful , when this restriction is not fulfilled , since it focuses on computing the common information of disjunctive branches  . The conjunctive part of the output constraint of the algorithm can then be seen as an approximation of the actual result  , if the output constraint is satisfiable . Moreover , the disjunctive parts are reduced , so that a subsequent fullfledged search will have considerably less work than when directly trying to solve the original constraint system  . 

H . Alshawi ( Ed .). The Core Language Engine.
ACL-MIT Press Series in Natural Languages Processing  . MIT Press , Cambridge , Mass . , 1992 . 
S . Billot and B . Lang . The Structure of Shared Forests in Ambiguous Parsing  . In Proceedings of the 27th Annual Meeting of the ACL , University of British Columbia , pp . 143-151, Vancouver , B . C . ,
Canada , 1989.
B . Carpenter . ALE : The Attribute Logic Engine User's Guide . Laboratory for Computational Linguistics , Philosophy Department , Carnegie Mellon University , Pittsburgh PA 15213 , December 1992 . 
J . DSrre and M . Dorna . CUF - - A Formalism for Linguistic Knowledge Representation  . IJ . DSrre(Ed . ) , Computational Aspects of Constraint-Based Linguistic Description I  , DYANA-2 deliverable R1 . 2 . A . ESPRIT , Basic Research Project 6852,
July 1993.
J . Earley . An Efficient ContextFree Parsing Algorithm . Communications of the ACM , 13(2):94-102, 1970 . 
M . Egg and K . Lebeth . Semantic Underspecification and Modifier Attachment Ambiguities  . 
In J . Kilbury and R . Wiese ( Eds . ), Integrative Ansiitze in der Computer linguistik . Beitriige zur 5 . Fachtagung der SektionComputerlinguis-tikder Deutschen Gesellschaft fiir Spraehwis-senschaft  ( DG fS )  , pp .  1924 . Dfisseldorf , Germany , 1995 . 
H . Kamp and U . Reyle . From Discourse to Logic . Introduction to Modeltheoretic Semantics of Natural Language  , Formal Logic and Discourse Representation Theory . Studies in Linguistics and Philosophy 42 . Kluwer Academic Publishers , Dordrecht,
The Netherlands , 1993.
J . T . Maxwell III and R . M . Kaplan . The Interface between Phrasal and Functional Constraints  . 
Computational Linguistics , 19(4):571-590, 1993.
F . C . Pereira and D . H . Warren . Definite Clause Grammars for Language Analysis -- A Survey of the Formalism and a Comparison with Augmented Transition Networks  . Artificial Intelligence , 13:231-278, 1980 . 
M . Pinkai . Radical Underspecification . In Proceedings of the l Oth Amsterdam Colloquium , pp . 
587-606, Amsterdam , Holland , December 1995.
ILLC/Department of Philosophy , University of

C . Pollard and I . A . Sag . Head Driven Phrase Structure Grammar . University of Chicago Press,
Chicago , 1994.
U . Reyle . Dealing with Ambiguities by Underspecification : Construction  , Representation , and Deduction . Journal of Semantics , 10(2):123-179, 1993 . 
M . Schiehlen . Semantic Construction from Parse Forests . In Proceedings of the 16th International Conference on Computational Linguistics  , Copenhagen , Denmark ,  1996 . 
G . Smolka and R . Treinen ( Eds . ) . DFKIOz Documentation Series . German Research Center for Artificial Intelligence  ( DFKI )  , Stuhls at zen-haus weg3 , D-66123 Saarbriicken , Germany ,  1996 . 

M . Tomita . Efficient Parsing for Natural Languages . 
Kluwer Academic Publishers , Boston , 1986.

