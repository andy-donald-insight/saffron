Predicting the Semantic Orientation of Adjectives
Vasileios Hatzivassiloglou and Kathleen R . McKeown
Department of Computer Science
450 Computer Science Building
Columbia University
New York , N.Y . 10027, USA
vh , kathy ) ? cs , columbia , edu

We identify and validate from a large corpus constraints from conjunctions on the positive or negative semantic orientation of the conjoined adjectives  . A loglinear regression model uses these constraints to predict whether conjoined adjectives are of same or different orientations  , achieving 82% accuracy in this task when each conjunction is considered independently  . 
Combining the constraints across many adjectives , a clustering algorithm separates the adjectives into groups of different orientations  , and finally , adjectives are labeled positive or negative . Evaluations on real data and simulation experiments indicate high levels of performance : classification precision is more than  90% for adjectives that occur in a modest number of conjunctions in the corpus  . 
1 Introduction
The semantic orientation or polarity of a word indicates the direction the word deviates from the norm for its semantic group or lezical field  ( Lehrer ,  1974) . 
It also constrains the word's usage in the language  ( Lyons ,  1977) , due to its evaluative characteristics ( Battistella ,  1990) . For example , some nearly synonymous words differ in orientation because one implies desirability and the other does not  ( e . g . , simple versus simplisfic ) . In linguistic construct such as conjunctions , which impose constraints on the semantic orientation of their arguments  ( Anscombre and Ducrot , 1983; Elhadad and McKeown ,  1990) , the choices of arguments and connective are mutually constrained  , as illustrated by:
The tax proposal was simple and well-received simplistic but well-received * simplistic and well-received by the public  . 
In addition , almost all antonyms have different semantic orientations3 If we know that two words relate to the same property  ( for example , members of the same scalar group such as hot and cold  ) but have different orientations , we can usually infer that they are antonyms . Given that semantically similar words can be identified automatically on the basis of distributional properties and linguistic cues  ( Brown et al , 1992; Pereira et al , 1993; Hatzivassiloglou and McKeown ,  1993) , identifying the semantic orientation of words would allow a system to further refine the retrieved semantic similarity relationships  , extracting antonyms . 
Unfortunately , dictionaries and similar sources ( the usari , WordNet ( Miller et al ,  1990 ) ) do not include semantic orientation information .   2 Explicit links between antonyms and synonyms may also be lacking  , particularly when they depend on the domain of discourse  ; for example , the opposition bear-bull appears only in stock market reports  , where the two words take specialized meanings . 
In this paper , we present and evaluate a method that automatically retrieve semantic orientation i- formation using indirect information collected from a large corpus  . Because the method relies on the corpus , it extracts domain-dependent iformation and automatically adapts to a new domain when the corpus is changed  . Our method achieves high precision ( more than 90% )  , and , while our focus to date has been on adjectives , it can be directly applied to other word classes . Ultimately , our goal is to use this method in a larger system to automatically identify antonyms and distinguish near synonyms  . 
2 Overview of Our Approach
Our approach relies on an analysis of textual corpora that correlates linguistic features  , or indicators , with 1 Exceptions include a small number of terms that are both negative from a pragmatic viewpoint and yet stand in all antonymic relationship  ; such terms frequently lexicalize two unwanted extremes  , e . g . , verbose-terse . 
2 Except implicitly , in the form of definitions and usage examples . 
174 semantic orientation . While no direct indicators of positive or negative semantic orientation have been proposed  3  , we demonstrate that conjunctions between adjectives provide indirect information about orientation  . For most connectives , the conjoined adjectives usually are of the same orientation : compare fair and legitimate and corrupt and brutal which actually occur in our corpus  , with ~ fair and brutal and * corrupt and legitimate  ( or the other cross-products of the above conjunctions  ) which are semantically anomalous . The situation is reversed for but , which usually connects two adjectives of different orientations  . 
The system identifies and uses this indirect information in the following stages :  1  . All conjunctions of adjectives are extracted from the corpus along with relevant morphological relations  . 
2 . A logline a regression model combines information from different conjunctions to determine if each two conjoined adjectives are of same or different orientation  . The result is a graph with hypothesized same-or different-orientation links between adjectives  . 
3 . A clustering algorithm separates the adjectives into two subsets of different orientation  . It places as many words of same orientation as possible into the same subset  . 
4 . The average frequencies in each group are compared and the group with the higher frequency is labeled as positive  . 
In the following sections , we first present he set of adjectives used for training and evaluation  . We next validate our hypothesis that conjunctions constrain the orientation of conjoined adjectives and then describe the remaining three steps of the algorithm  . After presenting our results and evaluation , we discuss simulation experiments that show how our method performs under different conditions of sparseness of data  . 
3 Data Collection
For our experiments , we use the 21 million word 1987 Wall Street Journal corpus 4  , automatically annotated with part-of-speech tags using the PARTS tagger  ( Church ,  1988) . 
In order to verify our hypothesis about the orientations of conjoined adjectives  , and also to train and evaluate our subsequent algorithms  , we need a 3Certain words inflected with negative affixes ( such as in - or un- ) tend to be mostly negative , but this rule applies only to a fraction of the negative words  . Furthermore , there are words so inflected which have positive orientation  , e . g . , independent and unbiased . 
4Available form the ACL Data Collection Initiative as CD ROM  1  . 
Positive : adequate central clever famous intelligent remarkable reputed sensitives lender thriving Negative : contagious drunken ignorant lanky listless primitive stridentrouble some unresolved unsuspecting Figure  1: Randomly selected adjectives with positive and negative orientations  . 
set of adjectives with predetermined orientation labels  . We constructed this set by taking all adjectives appearing in our corpus  20 times or more , then removing adjectives that have no orientation  . These are typically members of groups of complementary  , qualitative terms ( Lyons ,  1977) , e . g . , domestic or medical . 
We then assigned an orientation label ( either + or - ) to each adjective , using an evaluative approach . 
The criterion was whether the use of this adjective ascribes in general a positive or negative quality to the modified item  , making it better or worse than a similar unmodified item  . We were unable to reach a unique label out of context for several adjectives which we removed from consideration  ; for example , cheap is positive if it is used as a synonym of inexpensive  , but negative if it implies inferior quality . 
The operations of selecting adjectives and assigning labels were performed before testing our conjunction hypothesis or implementing any other algorithms  , to avoid any influence on our labels . The final set contained 1 , 336 adjectives ( 657 positive and 679 negative terms )  . Figure 1 shows randomly selected terms from this set . 
To further validate our set of labeled adjectives , we subsequently asked four people to independently label a randomly drawn sample of  500 of these adjectives . They agreed with us that the posi-tive/negative concept applies to  89  . 15% of these adjectives on average . For the adjectives where a positive or negative label was assigned by both us and the independent evaluators  , the average agreement on the label was 97 . 38% . The average inter-reviewer agreement on labeled adjectives was  96  . 97% . These results are extremely significant statistically and compare favorably with validation studies performed for other tasks  ( e . g . , sense disambiguation ) in the past . They show that positive and negative orientation are objective properties that can be reliably determined by humans  . 
To extract conjunctions between adjectives , we used a two-level finite-state grammar , which covers complex modification patterns and noun-adjective apposition  . Running this parser on the 21 million word corpus , we collected 13 , 426 conjunctions of adjectives , expanding to a total of 15 , 431 conjoined adjective pairs . After morphological trans-
Conjunction types analyzed
All appositive and conjunctions
All conjunctions 2,748
All and conjunctions 2,294
All or conjunctions 305
All but conjunctions 214
All attributive and conjunctions 1,077
All predicative and conjunctions 860 orientation ( types )  77 . 84% 81 . 73% 77 . 05% 30 . 84% 80 . 04% 84 . 77% 70 . 00% % same-orientation ( tokens ) 72 . 39% 78 . 07% 60 . 97% 25 . 94% 76 . 82% 84 . 54% 63 . 64%
P-Value ( for types ) < i ? i0-I~<1?10-1~<1?10-1~2 . 09 . 10 -:~ < 1 . i0-16<1 . i0-I ~0 . 0 4277 Table 1: Validation of our conjunction hypothesis . The P-value is the probability that similar extreme results would have been obtained if same - and different-orientation conjunction types were equally distributed  . 
or more actually formations , the remaining 15 , 048 conjunction tokens involve 9 , 296 distinct pairs of conjoined adjectives ( types )  . Each conjunction token is classified by the parser according to three variables : the conjunction used  ( and , or , bu  ~ , either-or , or neither-nor ) , the type of modification ( attributive , predicative , appositive , resultative ) , and the number of the modified noun ( singular or plural )  . 
4 Validation of the Conjunction

Using the three attributes extracted by the parser  , we constructed a cross-classification f the conjunctions in a three-way table  . We counted types and tokens of each conjoined pair that had both members in the set of preselected labeled adjectives discussed above  ;  2 , 748 (29 . 56%) of all conjoined pairs ( types ) and 4 , 024 (26 . 74% ) of all conjunction occurrences ( tokens ) metthis criterion . We augmented this table with marginal totals , arriving at 90 categories , each of which represents a triplet of attribute values  , possibly with one or more " don't care " elements . 
We then measured the percentage of conjunctions in each category with adjectives of same or different orientations  . Under the null hypothesis of same proportions of adjective pairs  ( types ) of same and different orientation in a given category  , the number of same-or different-orientation pairs follows a binomial distribution with p =  0  . 5 ( Conover , 1980) . 
We show in Table 1 the results for several representative categories  , and summarize all results below : ? Our conjunction hypothesis ivalidated over all and for almost all individual cases  . The results are extremely significant statistically  , except for a few cases where the sample is small . 
? Aside from the use of but with adjectives of different orientations  , there are , rather surprisingly , small differences in the behavior of conjunctions between linguistic environments  ( as represented by the three attributes )  . There are a few exceptions , e . g . , appositive and conjunctions modifying plural nouns are evenly split between same and different orientation  . But in these exceptional cases the sample is very small  , and the observed behavior may be due to chance . 
? Further analysis of different-orientation pairs in conjunctions other than but shows that conjoined antonyms are far more frequent han expected by chance  , in agreement with ( Justeson and Katz ,  1991) . 
5 Prediction of Link Type
The analysis in the previousection suggests a baseline method for classifying links between adjectives : since  77  . 8 4% of all links from conjunctions indicate same orientation  , we can achieve this level of performance by always guessing that a link is of the same -orientation type  . However , we can improve performance by noting that conjunctions using but exhibit the opposite pattern  , usually involving adjectives of different orientations  . Thus , a revised but still simple rule predicts a different-orientation link if the two adjectives have been seen in a but conjunction  , and a same-orientation lik otherwise , assuming the two adjectives were seen connected by at least one conjunction  . 
Morphological relationships between adjectives also play a role  . Adjectives related in form ( e . g . , ade-quate-inadequate or thoughtful-thoughtless ) almost always have different semantic orientations  . We implemented a morphological naly zer which matches adjectives related in this manner  . This process is highly accurate , but unfortunately does not apply to many of the possible pairs : in our set of  1  , 336 labeled adjectives (891 , 780 possible pairs ) , 102 pairs are morphologically related ; among them , 99 are of different orientation , yielding 97 . 06% accuracy for the morphology method . This information is orthog-on alto that extracted from conjunctions : only  12 of the 102 morphologically related pairs have been observed in conjunctions in our corpus  . Thus , we method
Always predict same orientation
But rule
Loglinear model
Morphology used ?




Accuracy on reported same-orientation liks 77 . 84% 78 . 18% 81 . 81% 82 . 20%

Yes 81.53% 82.00%
Accuracy on reported different-orientation links 97  . 06% 69 . 16% 78 . 16% 73 . 70% 82 . 4 4% Table 2: Accuracy of severalink prediction models . 
Overall accuracy 77 . 84% 78 . 86% 80 . 82% 81 . 75% 80 . 97% 82 . 0 5% add to the predictions made from conjunctions the different-orientation links suggested by morphological relationships  . 
We improve the accuracy of classifying links derived from conjunctions as same or different orientation with a loglinea regression model  ( Santner and Duffy ,  1989) , exploiting the differences between the various conjunction categories  . This is a generalized linear model ( McCullagh and Nelder ,  1989 ) with a linear predictor = wWx where x is the vector of the observed counts in the various conjunction categories for the particular adjective pair we try to classify and w is a vector of weights to be learned during training  . The response y is nonlinearly related to r/ through the inverse logit function  , e0
Y = lq-e "
Note that yE (0 ,  1) , with each of these endpoints associated with one of the possible outcomes  . 
We have 90 possible predictor variables , 42 of which are linearly independent . Since using all the 42 independent predictors invites overfitting ( Duda and Hart ,  1973) , we have investigated subsets of the full loglinear model for our data using the method of iterative stepwise refinement : starting with an initial model  , variables are added or dropped if their contribution to the reduction or increase of the residual deviance compares favorably to the resulting loss or gain of residual degrees of freedom  . This process led to the selection of nine predictor variables  . 
We evaluated the three prediction models discussed above with and without he secondary source of morphology relations  . For the loglinear model , we repeatedly partitioned our data into equally sized training and testing sets  , estimated the weights on the training set , and scored the model's performance on the testing set  , averaging the resulting scores . 5 Table 2 shows the results of these analyses . Although the loglinear model offers only a small improvement on pair classification than the simpler but prediction rule  , it confers the important advantage 5When morphology is to be used as a supplementary predictor  , we remove the morphologically related pairs from the training and testing sets  . 
of rating each prediction between 0 and 1 . We make extensive use of this in the next phase of our algorithm  . 
6 Finding Groups of Same-Oriented

The third phase of our method assigns the adjectives into groups  , placing adjectives of the same ( but unknown ) orientation in the same group . Each pair of adjectives has an associated is similarity value between  0 and 1  ; adjectives connected by same-orientation links have low dissimilarities  , and conversely , different-orientation links result in high dissimilarities  . Adjective pairs with no connecting links are assigned the neutral dissimilarity  0  . 5 . 
The baseline and but methods make qualitative distinctions only  ( i . e . , same-orientation , different-orientation , or unknown ); for them , we define dissimilarity for same-orientation li ks as one minus the probability that such a classification link is correct and dissimilarity for different-orientation links as the probability that such a classification is correct  . These probabilities are estimated from separate training data  . Note that for these prediction models , dissimilarities are identical for similarly clas -sifted links  . 
The loglinear model , on the other hand , offers an estimate of how good each prediction is  , since it produces a value y between 0 and 1 . We construct the model so that 1 corresponds to same-orientation , and defined is similarity as one minus the produced value  . 
Same and different-orientation links between adjectives form a graph  . To partition the graph nodes into subsets of the same orientation  , we employ an iterative optimization procedure on each connected component  , based on the exchange method , a nonhierarchical clustering algorithm ( Spgth ,  1985) . We define an objective/unction~scoring each possible partition  7   ) of the adjectives into two subgroups C1 and C2 as i=1 x , y ECi adjectives in test set ( \[ An\[ )  2 730 3 516 4 369 5 236
Number of links in test set (\[ L~\[)2 , 568 2 , 159 1 , 742 1 , 238
Average number of links for each adjective 7 . 04 8 . 37 9 . 44 10 . 49
Accuracy 78.08% 82.56% 87.26% 92.37%
Ratio of average group frequencies 1.8699 1.9235
L 3486 1.4040
Table 3: Evaluation of the adjective classification and labeling methods  . 
where \[ Cil stands for the cardinality of cluster i  , and d(z , y ) is the dissimilarity between adjectives z and y . We want to select the partition : Pm in that minimizes ~  , subject to the additional constraint that for each adjective z in a cluster C  ,  1 1
ICl-1 d (= , y ) <-- IV ld (= , y ) (1) where C is the complement of cluster C , i . e . , the other member of the partition . This constraint , based on Rousseeuw's (1987) s = lhoue ~ es , helps correct wrong cluster assignments . 
To find Pmin , we first construct a random partition of the adjectives  , then locate the adjective that will most reduce the objective function if it is moved from its current cluster  . We move this adjective and proceed with the next iteration until no movements can improve the objective function  . At the final iteration , the cluster assignment of any adjective that violates constraint  ( 1 ) is changed . This is a steepest-descent hillclimbing method , and thus is guaranteed to converge . However , it will in general find a local minimum rather than the global one  ; the problem is NP-complete ( Garey and $ ohns on ,  1979) . We can arbitrarily increase the probability of finding the globally optimal solution by repeatedly running the algorithm with different starting partitions  . 
7 Labe l ing the C lus ters as Pos i t ive or Negat ive The clustering algorithm separates each component of the graph into two groups of adjectives  , but does not actually label the adjectives as positive or negative  . To accomplish that , we use a simple criterion that applies only to pairs or groups of words of opposite orientation  . We have previously shown ( Hatzivassiloglou and McKeown ,  1995 ) that in oppositions of gradable adjectives where one member is semantically unmarked  , the unmarked member is the most frequent one about  81% of the time . This is relevant to our task because semantic markedness exhibits a strong correlation with orientation  , the unmarked member almost always having positive orientation  ( Lehrer , 1985; Battistella ,  1990) . 
We compute the average frequency of the words in each group  , expecting the group with higher average frequency to contain the positive terms  . This aggregation operation increases the precision of the labeling dramatically since indicators for many pairs of words are combined  , even when some of the words are incorrectly assigned to their group  . 
8 Results and Evaluation
Since graph connectivity affects performance , we devised a method of selecting test sets that makes this dependence explicit  . Note that the graph density is largely a function of corpus size  , and thus can be increased by adding more data . Nevertheless , we report results on sparser test sets to show how our algorithm scales up  . 
We separated our sets of adjectives A ( containing 1 , 336 adjectives ) and conjunction - and morphology-based links L ( containing 2 , 838 links ) into training and testing groups by selecting , for several values of the parameter a , the maximal subset of A , A n , which includes an adjective z if and only if there exist at least a links from L between x and other elements of An  . This operation in turn defines a subset of L , L  ~ , which includes all links between members of An . We train our loglinear model on L-La ( excluding links between morphologically related adjectives  )  , compute predictions and dissimilarities for the links in L  ~  , and use these to classify and label the adjectives in An  . c ~ must be at least 2 , since we need to leave some links for training . 
Table 3 shows the results of these experiments for a = 2 to 5  . Our method produced the correct classification between  78% of the time on the sparsest test setup to more than  92% of the time when a higher number of links was present  . Moreover , in all cases , the ratio of the two group frequencies correctly identified the positive subgroup  . These results are extremely significant statistically  ( P-value less than 10-16 ) when compared with the baseline method of randomly assigning orientations to adjectives  , or the baseline method of always predicting the most frequent  ( for types ) category ( 50 . 8 2% of the adjectives in our collection are classified as negative  )  . Figure 2 shows some of the adjectives in set A4 and their classifications . 

Classified as positive : bold decisive disturbing enerous good honest important large mature patient peaceful positive prouds ound stimulating straightforwards trangetalented vigorous witty 
Classified as negative : ambiguous cautious cynicale vasive harmful hypocritical inefficient in secureir rational irresponsible minor outspoken pleasant reckless risky selfish tedious unsupported vulnerable wasteful Figure  2: Sample retrieved classifications of adjectives from set  A4  . Correctly matched adjectives are shown in bold . 
9 Graph Connectivity and
Performance
A strong point of our method is that decisions on individual words are aggregated to provide decisions on how to group words into a class and whether to label the class as positive or negative  . Thus , the overall result can be much more accurate than the individual indicators  . To verify this , we ran a series of simulation experiments . Each experiment measures how our algorithm performs for a given level of precision P for identifying links and a given average number of links k for each word  . The goal is to show that even when P is low , given enough data ( i . e . , high k ) , we can achieve high performance for the grouping . 
As we noted earlier , the corpus data is eventually represented in our system as a graph  , with the nodes corresponding to adjectives and the links to predictions about whether the two connected adjectives have the same or different orientation  . Thus the parameter P in the simulation experiments measures how well we are able to predict each link independently of the others  , and the parameter kmeasures the number of distinct adjectives each adjective appears with in conjunctions  . P therefore directly represents the precision of the link classification algorithm  , while k indirectly represents the corpus size . 
To measure the effect of P and k ( which are reflected in the graph topology )  , we need to carry out a series of experiments where we systematically vary their values  . For example , ask ( or the amount of data ) increases for a given level of precision P for individual links  , we want to measure how this affects over all accuracy of the resulting groups of nodes  . 
Thus , we need to construct a series of datasets , or graphs , which represent different scenarios corresponding to a given combination of values of P and k  . To do this , we construct a random graph by randomly assigning  50 nodes to the two possible orientations . Because we don't have frequency and morphology information on these abstract nodes  , we cannot predict whether two nodes are of the same or different orientation  . Rather , we randomly assign links between nodes so that , on average , each node participate sink links and 100 xP % of all links connect nodes of the same orientation  . Then we consider these links as identified by the link prediction algorithm as connecting two nodes with the same orientation  ( so that 100 xP % of these predictions will be correct )  . This is equivalent othe baseline link classification method  , and provides a lower bound on the performance of the algorithm actually used in our system  ( Section 5 )  . 
Because of the lack of actual measurements such as frequency on these abstract nodes  , we also decouple the partitioning and labeling components of our system and score the partition found under the best matching conditions for the actual labels  . Thus the simulation measures only how well the system separates positive from negative adjectives  , not how well it determines which is which . However , in all the experiments performed on real corpus data  ( Section 8 )  , the system correctly found the labels of the groups  ; any misclassifications came from misplacing an adjective in the wrong group  . The whole procedure of constructing the random graph and finding and scoring the groups is repeated  200 times for any given combination of P and k , and the results are averaged , thus avoiding accidentally evaluating our system on a graph that is not truly representative of graphs with the given P and k  . 
We observe ( Figure 3 ) that even for relatively low t9 , our ability to correctly classify the nodes approaches very high levels with a modest number of links  . For P = 0 . 8 , we need only about ? links per adjective for classification performance over  90% and only 12 links per adjective for performance over 99%  . s The difference between low and high values of P is in the rate at which increasing data increases overall precision  . These results are somewhat more optimistic than those obtained with real data  ( Section 8 )  , a difference which is probably due to the uniform distributional assumptions in the simulation  . 
Nevertheless , we expect the trends to be similar to the ones shown in Figure  3 and the results of Table 3 on real data support his expectation . 
10 Conclusion and Future Work
We have proposed and verified from corpus data constraints on the semantic orientations of conjoined adjectives  . We used these constraints to automatically construct a loglinea regression model  , which , combined with supplementary morphology rules , predicts whether two conjoined adjectives are of same  812 links per adjective for a set of n adjectives requires  6n conjunctions between then adjectives in the corpus  . 


60"55-50~0i2~4567891()1'214 16182 0
Avem 0 eneio hbo ~ pernode(a)P = 0 . 75 25 30 32 . 77 95 . 



Average neighbors per node ( b)P = 0 . 8, ~705, 5 ( c ) P = 0 . 85 25 28 . 6 4 Figure 3: Simulation results obtained on 50 nodes . 
10 (~7 o(d ) P = 0.9
In each figure , the last z coordinate indicates the ( average ) maximum possible value of k for this P , and the dotted line shows the performance of a random classifier  . 
or different orientation with 82% accuracy . We then classified several sets of adjectives according to the links inferred in this way and labeled them as positive or negative  , obtaining 92% accuracy on the classification task for reasonably dense graphs and  100% accuracy on the labeling task . Simulation experiments establish that very high levels of performance can be obtained with a modest number of links per word  , even when the links themselves are not always correctly classified  . 
As part of our clustering algorithm's output , a " goodness-of-fit " measure for each word is computed  , based on Rousseeuw's (1987) silhouettes . 
This measure ranks the words according to how well they fit in their group  , and can thus be used as a quantitative measure of orientation  , refining the binary positive-negative distinction  . By restricting the labeling decisions to words with high values of this measure we can also increase the precision of our system  , at the cost of sacrificing some coverage . 
We are currently combining the output of this system with a semantic group finding system so that we can automatically identify antonyms from the corpus  , without access to any semantic descriptions . 
The learned semantic a tegorization of the adjectives can also be used in the reverse direction  , to help in interpreting the conjunctions they participate  . We will also extend our analyses to nouns and verbs  . 

This work was supported in part by the Office of Naval Research under grant  N00014-95-1-0745  , jointly by the Office of Naval Research and the Advanced Research Projects Agency under grant  N00014-89-J-1782  , by the National Science Founda-York State Center for Advanced Technology under contracts NYSSTF -CAT  ( 95 ) -013 and NYSSTF-CAT ( 96 ) -013 . We thank Ken Church and the AT&T Bell Laboratories for making the PARTS part-of-speech tagger available to us  . We also thank Dragomir Radev , Eric Siegel , and Gregory Sean McKinley who provided models for the categorization of the adjectives in our training and testing sets as positive and negative  . 

Jean-Claude Anscombre and Oswald Ducrot . 1983.
L ' Argumentation dans la Langue . Philosophicet Langage . Pierre Mardaga , Brussels , Belgium . 
Edwin L . Battistella .  1990 . Markedness : The Evaluative Super structure of Language  . State University of New York Press , Albany , New York . 
Peter F . Brown , Vincent J . della Pietra , Peter V . 
deSouza , Jennifer C . Lai , and Robert L . Mercer . 
1992 . Class-based ngram models of natural language . Computational Linguistics , 18(4):487-479 . 
Kenneth W . Church .  1988 . A stochastic parts program and noun phrase parser for unrestricted text  . In Proceedings of the Second Conference on Applied Natural Language Processing  ( ANLP-88 )  , pages 136143 , Austin , Texas , February . Association for Computational Linguistics . 
W . J . Conover .  1980 . Practical Nonparametric Statistics . Wiley , New York , 2nd edition . 
Richard O . Duda and Peter E . Hart .  1973 . Pattern Classification and Scene Analysis . Wiley , New

Michael Elhadad and Kathleen R . McKeown . 1990.
A procedure for generating connectives . In Proceedings of COLING , Helsinki , Finland , July . 
Michael R . Garey and David S . Johnson . 1979.
Computers and Intractability : A Guide to the Theory of NP-Completeness  . WH . Freeman , San
Francisco , California.
Vasileios Hatzivassiloglou and Kathleen R . McKeown .  1993 . Towards the automatic dentification of adjectival scales : Clustering adjectives according to meaning  . In Proceedings of the 31st Annual Meeting of the ACL , pages 172-182 , Columbus , Ohio , June . Association for Computational Linguistics . 
Vasileios I-I at zivassiloglou and Kathleen R . MeKe-own .  1995 . A quantitative evaluation of linguistic tests for the automatic prediction of semantic markedness  . In Proceedings of the 83rd Annual Meeting of the ACL , pages 197-204 , Boston , Massachusetts , June . Association for Computational

John S . Justeson and Slava M . Katz .  1991 . Cooccurrences of antonymous adjectives and their contexts  . Computational Linguistics , 17(1):1-19 . 
Adrienne Lehrer .  1974 . Semantic Fields and Lezical Structure . North Holland , Amsterdam and New

Adrienne Lehrer . 1985. Markedness and antonymy.
Journal of Linguistics , 31(3):397-429, September.
John Lyons . 1977. Semantics , volume 1. Cambridge
University Press , Cambridge , England.
Peter McCullagh and John A . Nelder .  1989 . Generalized Linear Models . Chapman and Hall , London , 2nd edition . 
George A . Miller , Richard Beckwith , Christiane Fellbaum , Derek Gross , and Katherine J . Miller . 
1990 . Introduction to WordNet : An online lexical database  . International Journal of Lexicography ( special issue )  ,  3(4):235-312 . 
Fernando Pereira , Naftali Tishby , and Lillian Lee . 
1993. Distributional custering of English words.
In Proceedings of the 3Ist Annual Meeting of the ACL , pages 183-190 , Columbus , Ohio , June . Association for Computational Linguistics . 
Peter J . Rousseeuw .  1987 . Silhouettes : A graphical aid to the interpretation advalidation of cluster analysis  . Journal of Computational and Applied
Mathematics , 20:53-65.
Thomas J . Santner and Diane E . Duffy .  1989 . The Statistical Analysis of Discrete Data . Springer-
Verlag , New York.
Helmuth Sp ~ ith .  1985 . Cluster Dissection and Analysis : Theory , FORTRAN Programs , Examples . 
Ellis Horwo0d , Chiehester , West Sussex , England . 

