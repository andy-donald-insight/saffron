COMPUTER AIDED INTERPRETATION OFLEXICAL COOCCURRENCES 
Paola Velardi (*)
Mafia Teresa Pazienza (**)
(*) University of Ancona , Istituto di Informatica , via Brecce Bianche , Ancona
(**) University of Roma , Dip . diln formatica e Sistemistica , via Buonarroti12 , Roma

This paper addresses the problem of developing a large semantic lexicon for natural language processing  . The increas~gavailability of machine readable documents offers an opportunity to the field of lexieal semantics  , by providing experimental evidence of word uses ( online texts ) and word definitions ( online dictionaries )  . 
The system presented hereafter , PETRARCA , detects word e . occurrences from a large sample of pressagency releases on finance and economics  , and uses these associations to build a ease-based semantic lexicon  . Syntactically valid cooccurenees including a new wordWare detected by a high-coverage morphosyntactic analyzer  . Syntactic relations are interpreted e,g . replaced by case relations , using a a catalogue of patterns/interpretation pairs  , a concept type hierarchy , and a set of selectional restriction rules on semantic interpretation types  . 

Semantic knowledge codification for language processing requires two important issues to be considered :  1  . Meaning representation . Each word is a world : how can we conveniently circumscribe the semantic information associated to a lexic  , ; dentry ?2 . Acquisition . For a language processor , to implement a useful application , several thousands of terms must have an entry in the semantic lexicon : how do we cope with one such a prohibitive task ? which preoccupied scientists of different disciplines since the early history of human culture  . We will not attempt an overall survey of the field of semantics  , that provided material for many fascinating books  ; rather , we will concentrate On the computer science perspective  , i . e . how do we go about representing language x pressions on a computer  , in a way that can be useful for natural language processing applications  , e . g . machine translation , information retrieval , user-friendly interfaces . 
In the field of computation a linguistics , several approaches were followed for representing semantic knowledge  . We are not concerned here with semantic languages  , which are relatively well developed ; the diversity lies in the meaning representation principles  . We will classify the methods of meaning representations in two categories : conceptual  ( or deep ) and coilocative ( or surface )  . The terms " conceptual " and " collocative " have been introduced in  \[81  ; we decided to adopt an existing terminology , even though our interpretation of the above two categories is broader than for their inventor  . 
1 . Conceptual Meaning Conceptual meaning is the cognitive content of words  ; it can be expressed by features or by primitives . Conceptual meaning is " deep " in that it expresses phenomena that are deeply embedded in language  . 
2 . Colloc at lve meaning . What is communicated through associations between words or word classes  . Coilocative meaning is " superficial " in that does not seek for " the deep sense " of a word  , but rather it " describes " its uses in everyday language  , or in some sub-w , rid language ( economy , computers , etc . ) . It provides more than a simple analysis of cooccurr ~ aces  , because it attempts an explanation of word associations in terms of conceptual relations between a lexical item and other items or classes  . 
Both conceptual and collocative meaning representations are based on some subjective  , human-produced set of primitives ( features , conceptual dependencies , relations , type hierarchies etc . ) on which there is no shared agreement at the current state of the art  . As far as conceptual meaning is concerned , the quality and quantity of phenomena to be shown in a representation is subjective as well  . On the contrary , surface meaning can rely on the solid evidence represented by word associations  ; the interpretation of an association is subjective  , but valid associations arc an observable , even though vast , phenomenon . To confu'm this , one can notice that different implementations of lexicons based on surface meaning are surprisingly similar  , whereas conceptual lexicons arc very dishomogeneous  . 
In principle , the inferential power of collocative , or surface \[18\] meaning representation is lower than for conceptual meaning  . In our previous work on semantic knowledge representation  , however ,   \[10l   \[18\]   [12\] we showed that a semantic dictionary in the style of surface meaning is a useful basis for semantic interpretation  . 
The knowledge power provided by the semantic lexicon  ( limited to about I000 manually entered defmitions ) was measured by the capability of the language processor DANTE  \[2\]   \[18\]   [11\] to answer a variety of questions concerning previously analyzed sentences  ( press agency releases on finance and economics )  . It was found that , even though the system was unable to perform complex inferences  , it could successfully answer more than 90% of the questions \[12\]L In other terms , surface semantic seems to capture what , at first glance , a human reader under stands of a piece of text . 
In \[26\] , the usefulness of this meaning representation method is demonstrated for 
TRANSALTOR , a system used for machine translation in the field of computers  . 
An important advantage of surface meaning is that makes it easier the acquisition of the semantic lexicon  . This issue is examined in the next section . 
Acquisition of Lexical Semantic

Acquiring semantic knowledge on a systematic basis is quite a complex task  . One needs not to look at metaphors or idioms to fred this  ; even the interpretation of apparently simple sentences is riddled with such difficulties that makes it hard even cutting out a piece of the problem  . A manual codification of the lexicon is a prohibitive task  , regardless of the framework adopted for semantic knowledge representation  ; even when a large team of knowledgenters is available  , consistency and completeness are a major problem . We believe-that automatic , or semiautomatic acquisition of the lexicon is a critical factor in determining how widespread the use of natural language processors will be in the next few years  . ' Recently a few methods were presented for computer aided semantic knowledge acquisition  . A widely used approach is accessing online dictionary defmitions to solve ambiguity problems  \[3\] or to derive type hierarchies and semantic features  \[24\]  . 
The information presented in a standardictionary has in our view some intrinsic limitation : s definitions are often circular e  . g . the definition of a term A may refer to a term B that in turn points to A  ; * definitions are not homogeneous as far as the quality and quantity of provided information : they can be very sketchy  , or give detailed structural information , or list examples of use-types , or attempt some conceptual meaning definition ; ? a dictionary is the result of a conceptualization effort performed by some human specialist  ( s )  ; this effort may not be consistent with , or The test was performed over a 6 month period on about S0 occasional visitors and staff members of the IBM Romescientificenter  , unaware of the system capabilities and structure . The user would look at 60 different releases , previously analyzed by the system ( or reanalyze during the demo )  , and freely asks questions about the content of these texts  . In the last few months , the test was extended to a different domain , e . g . the Italian Constitution , without significant performance changes . See the referenced papers for examples of sentences and of  ( answered and not answered ) query types ( in general wh-questions )  . 
186 exl ( from\[8\] ) : boy=+artimate-adult+maleex2 . ( from\[251): help = Y carrying out Z , X uses his resources W in order for W to help Y to carry out Z  ; the use of resources by X and the carrying out of Z by Y are simultaneous  ex2   ( from I1 61 ) : throw = actor PROPELs and object from a source LO Cation to a destination LO Cation 
Figure I.
suitable for , the objectives of an application for which a language processor is built  . 
Examples of conceptual meaning representation in the literature A second approach is using corpora rather than human-oriented dictionary entries  . Corpora provide an experimental evidence of word uses  , word associations , and language phenomena as metaphors , idioms ; and metonymies . 
The problem and at the same time the advantage of corpora is that they are raw texts whereas dictionary entries use some formal notation that facilitates the task of linguistic data processing  . 
No computer program may ever be able to derive formatted data from a completely unformatted source  . Hence the ability of extracting lexical semantic information form a corpus depends upon a powerful set of mapping rules between phrasal patterns and human-produced semantic primitives and relations  . We do not believe that a semantic representation framework is " good " if it mimics a human cognitive model  ; more realistically , we believe that a set of primitives , relations and mapping rules is " fair ' , when its coverage over a language subworld is suitable for the purpose of some useful language processing activity  . Corpora represent an ' objective " description of that subworld  , against which it is possible to evaluate the power of a representation scheme  ; and they are particularly suitable for the acquisition of a colloeative meaning based semantic lexicon  . 
Besides our work\[19\] , the only knowledge acquisition system based on corpora  ( as far as we know ) is described in\[7\] . In this work , when an unknown word is encountered , the system uses preexisting knowledge on the context in which the word occurred to derive its conceptual category  . 

The context is provided by online texts in the economic domain  . For example , the unknown word merger in " another merger offer " is categorized as merger-transaction using semantic knowledge on the word offer and on pre -analyzed sentences referring to a previous offer event  , as suggested by the word another . This method is interesting but reties upon a preexisting semantic lexicon and contextual knowledge  ; in our work , the only preexisting knowledge is the set of conceptual relations and primitives  . 
PETRARCA : a method for the acquisition and interpretation of cooccurrences PETRARCA detects cooccurrences using a powerful morphologic and syntactic anal ~ er  \[141   I11  ; cooccurences are interpreted by a set of phrasal -patterns/emantic-interpretation mapping rules  . The semantic language is Conceptual Graphs \[17\] ; the adopted type hierarchy and conceptual relations are described in  \[10l   . The following is a summary description of the algorithm : 
For any word W , 1 .   ( A ) Parse every sentence in the corpus that uses W . 
Ex : W = AGREEMENT " Yester day an agreement was reached among the companies "  . 
exl ( from I 181 ) : agreement = is a decision act participant pe -rson  , organization theme transaction cause communication_exchange manner interesting important effective  . .
ex2 ( from\[26\] ) : person=/sa creature agent_of take putfred speech-action mental-action consist of hand foot  . .
source_of speech-action destination_of speech -action power human speeds low mass human Figure  2  . Examples of eollocative meaning representation i the literature  2  .   ( A ) Determine all syntactic attachments of W * ( e . g . syntactically valid cooccurrences ) Ex : . 

VP_OBJ(TOREACH , AGREEMENT).
( A ) Generate a semantic interpretation for each attachment : step  3 might produce more than one interpretation for a single word pattern  , due to the low selectivity of some semantic rule . 
step 3 might fail to produce an interpretation for metonymies and idioms  , which violate semantic on straints . Strong syntactic evidence ( unambiguous syntactic rules ) is used to " signal " the user this type of failure  . 
Ex : Knowledge sources used by PETRARCA
IAGREEMENT-?(PARTICIPANT ) -? ICOMPANYi.
4. ( A ) Generalize the interpretations.
Ex : Given the following examples : \[ AGREEMENT l  - ?   ( PARTICIPANT ) -> ICOMPANYI . 
\[AGREEMENT\]->(PARTICIPANT ) -?\[ COUNTRY . ORGANIZATIONI . 
\[ AGREEMENT-?(PARTICIPANT ) -?\[ PRESIDENTI.
derive the most general constraint : \[ AGREEMENT \]- ?   ( PARTICIPANT ) -> IHUMAN . ENTITYI . The above is a new case description added to the definition of AGREEMENT  5  . ( M ) Check the newly derived entry . 
To perform its analysis , PETRARCA uses five knowledge sources : I . an online natural corpus ( press agency releases ) to select a variety of language expressions including a new word W  ;  2 . a high coverage morphosyntactic analyzer , to derive phrasal patterns centered around W ; 3 . a catalogue of patterns/interpretation pairs , called Syntax-to-Semantic ( SS rules ); 4 . a set of rules expressing selectional restriction on conceptual relation uses  ( CR rules )  ;  5 . a hierarchy of conceptual classes and a catalogue associating to words conceptypes  . 
Steps marked ( A ) are automatic ; steps marked ( M ) axe manual . The only manual step is the last one : this step is however necessary because of the following : The natural corpus and the parser are used in steps  1 and 2 of the above algorithm ; SS rules , CR rules and the word/concept catalogue are used in step  3  ; the type hierarchy is used in steps 3 and 4 morphosyntactic analyzer developed in the context of the DANTE system  . The lexical parser is based on a ContextFree grammar  , the complete set of Italian prefixes and suffixes  , and a lexicon of 7000 elementary lernmata ( stems without affixes )  . At present , the morphologi component has an 100% coverage over the analyzed corpus ( 100 , 000 words ) 114 113 1 . 
The syntactic analysis determines syntactic attachment between words by verifying grammar rules and forms agreement  ; he system is based on an Attribute Grammar , augmented with lookahead sets I1\] ; the coverage is about 80% ; when compiled , the parsing time is around 12 see . of CPU time for a sentence with 34 prepositional phrases ; the CPU is an IBM main frame . 
The syntactic relations detected by the parser are associated to possible semantic interpretations u ingSS rules  . An excerpt of SS rules is given below for the phrasal pattern : noun  . .phrase ( NP ) + prepositional . .phrase ( PP ) ( di=o . D . 

NP PP (' word l,d . " word2) ?- tel(PO . f~E$S,di?'word2,*lmrdl) . 
l ' clnedl Pletro ( the dos of Peter ) '/ NP_PP ( 'wordl , dl , ' word2) < . reI ( . SOCRELATION , dl , ' word2, ' wordl) . 
/' litmtdrer qElet , o ( them it ther of Peter ) '/ NPPP (' wm'dh di , ' word2) < ? rei(PART1CIPANT , di , *wofdl , 'word2) . 
/' riunioned eideleptl ( the meeting of the delesliel ) '/ NP PP ( 'wocdl . di . ' word2) <- rel($UBSET0dt . 'wocd2 . 'wordl) . 
/' dued!nol(two of us ) '/
NP_PP('wo~I,di . ' word2) <- mI(PARTOF . di . 'wortl2,'wordl) . 
/' p = glne del It bro ( the pitgel of the book ) '/ NP_PP ( 'wonll . dl . ' word2) ? . ml ( MATTER . dl,'wordl . 'word2) . 
I'oglFttodllegno ( it n object of wood ) '/ NP_PP ( 'wordl , dl , ' word3) <- rel(PRODUeER , d i , ' word l , *word2) . 
/' rul ~ i to delle onl ( the rmlr of the lions ) '/ NP_PP ( "~mrdl , dl , ' wott l'2) <- reI(CHARACTERISTIC . d . I,'word2 . 'wordl) . 
/' rintelll genza delrtlomo ( the intelligence of them an ) '/ Overall , we adopted about 50 conceptual relations to describe the set of semantic relations commonly found in language  ; see\[10\] for a complete list . The catalogue of SS rules includes about 200 pairs . 
Given a phrasal pattern produced by the syntactic parser  , SS rules select a first set of conceptual relations that are candidate interpretations for the pattern  . 
Selectional restriction rules on conceptual relations are used to select a unique interpretation  , when possible . Writing CR rules was a very complex task , that required a process of progressive refinement based on the observation of the results  . 
The following is an example of CR rule for the conceptual relation PARTICIPANT : participant-- is  . participant : human_entity Examples of phrasal patterns interpreted by the participant relation are : John flies  ( to New York )  ; the meeting among parties ; the march of the pacifists , " a contract between Fiat and Alfa ; the assembly of the administrators , etc . 
An interesting result of the above algorithm is the following : in general  , syntax will also accept semantically invalid cooccurrences  . In addition , in step 3 , ambiguous words can be replaced by the " wrong " concept names  . Despite this , selectional restrictions are able to interpret only valid associations and reject the others  . For example , consider the sentence : " The party decided a new strategy "  . The syntax detects the association SUBJ(DECIDE , PARTY ) . Now , the word " party " has two concept names associated with it : POLPARTY  , and FEAST , hence in step 3 both interpretations are examined . I lowever , no conceptual relation is found to interprethe pattern " FEASTDECIDE "  . This association is hence rejected . 
Simalirily , in the sentence : " An agreement is reached among the companies  , the syntactic analyzer will submit to the semantic interpreter two associations : NP_PP  ( AGREEMENT , AMONG , COMPANY ) and
VP_PP(REACIt , AMONG , COMPANY ) Now , the preposition among in the SS rules , points to such conceptual relations as PARTICIPANT  , 
SUBSET ( e.g."two among all us "), and
LOCATION ( e . g . " apine among the trees '% but none of the above relates a MOVE ACT with a IIUMANORGANIZATION  . The association is m hence rejected . 
Future experimentation issues
This section highlights the current limitations and experimentation issues with PETRARCA  . 
Definition of type hierarchies
PETRARCA gets as input not only the word W , but a list of concept labels CW i , corresponding to the possible senses of W . For each of these CW i , the supertype in the hierarchy must be provided . 
Notice . however that the system knows nothing about conceptual classes  ; the hierarchy is only an ordered set of labels . 
In order to assign a supertype to a concept , three methods are currently being investigated . First , a program may " guide " the user towards the choice of the appropriate supertype  , visiting topdown the hierarchy . This approach is similar to the one described in I261  . 
Alternatively , the user may give a fist of synonymous or near synonymous words  . If one of these was already included in the hierarchy  , the same supertype is proposed to the user . 
A third method lets the system propose the supertype  . The system assumes CW = W and proceeds through steps  1  ,   2 and 3 of the case descriptions derivation procedure . As the supertype of CW is unknown , CR rules are less effective at determining a unique interpretation of syntactic patterns  . If in some of these patterns the partner word is already defined in the dictionary  , its case descriptions can be used to restrict the analysis  . 
For example , suppose that the word president is unknown in :
The president nominated etc.
Pertini was a good president ' the knowledge on possible AGENTs for 
NOMINATE let us infer
PRESIDENT < HUMANENTITY ; from the second sentence , it is possible to further estrict to:
PRESIDENT < HUMANROLE . The third m method is interesting because it is automatic  , however it has some drawbacks . For example , it is slow as compared 1: o methods 1 and 2 ; a trained user would rather use his experience to decide a supertype  . Secondly , if the word is found with different meanings in the sample sentences  , the system might never get to a consistent solution  . 
Finally , if the database includes very few or vague examples  , the answer may be useless ( e . g . ACT , or TOP) . It should also be considered that the effort required to assign a supertype to  , say ,  10 . 0 00 words is comparable with the encoding of the morphologic lexicon  . This latter equired about one month of data entry by  56 part-time researchers , plus about 23 months for an extensive testing . 
The complexity of hierarchically organizing concepts however  , is not circumscribed to the time consumed in associating a type label to some thousand words  . All NLP researchers experimented the difficulty of associating concept efforts  , no commonly accepted hierarchies have been proposed so far  . In our view , there is no evidence in humans of primitive conceptual categories  , except for a few categories as animacy , time , etc . We should perhaps accept the very fact that type hierarchies are a computer method to be used in NLP systems for representing semantic knowledge in a more compact form  . Accordingly , we are starting a research on semiautomatic word clustering  ( in some given language subworld described by a natural corpus  )  , based on fuzzy set and conceptual custering theories  . 
Interpretation of idiomatic expressions
In the current version of PETRARCA , in case of idiomatic expressions the user must provide the correct interpretation  . In case of metaphors , syntactic evidence is used to detect a metaphor , under the hypothesis that input sentences to the system are syntactically and semantically correct  . 
At the current state of implementation , the system does not provide automatic interpretation of metaphors  . However , an interesting method was proposed in 1201 . According to this method , when for example a pattern such as " car drinks " is detected  , the system uses knowledge of canonical definitions of the concepts " DRINK " and " CAR " to establish whether ~ CAR " is used metaplaorically as a HUMANENTITY  , or " DRINK " is used metaphorically as 1"O BEFEDBY " . An interesting user aided computer program for idiomatic expressions analysis is also described in  1231  . 
Generalization of case descriptions
In PERTRARCA , phrasal patterns are first mapped into ' low level " case description  ; in step 4 , " similar " patterns are merged into " high level ' case descriptions  . In a first implementation , two or three low level case descriptions had to be derived before creating a more general semantic rule  . This approach is biased by the availability of example sentences  . A word often occurs in dozens of different contexts  , and only occasionally two phrasal patterns reflect the same semantic relation  . 
For example , consider the sentences :
The company signs a contract for new fimding The ACE stipulates a contracto increase its influence Restricting ourselves to the word " contract '  , we get the following semantic interpretations of syntactic patterns :  14SIGNI   , > frHBlmtl ~> l ? Ol ~ Crl 2 . 1COl~t ~- ~ r . ~ll~ll~l~-?ll~l ~ llqO-'lMs'rII~JI . & TIBI->crI-IIBMII) . > l ? OlCraAc ~ rl 4 . \[CONTRA~WI->(PIJRPOS li) . ? ll ~ lllIn patterns 1 and 3 " sign " and " stipulate " belong to the same supertype  , i . e . 
INFOR MATIONEX CHANGE ; hence a new case description can be tentatively created for 

ICOl,?rr~cl+ . l . ?( TI'll IMI ~ . > IlI ,+ F'ORMA'rioI,,I+BXO . IAI ~ F . ! Indeed , one can tell , talk about , describe etc . a contract . 
Conversely , patterns 3 and 4 have no common supertype ; hence two " low level " case descriptions are added to the definition of CONTRACT  . 
lCONTRAC'rl.?(PURPOSE)-~ILmlJNDINGI
ICOiCTRACI"I->(PURPOSE)-?lll'~'ll,tt . ,~IIl Even with a large number of input sentences , the system creates many of these specific patterns  ; a human user must review the results and provide for case descriptions generalization when he/she feels this being reasonable  . 
A second approach is to generalize on the basis of a single example  , and then retract ( split ) the rule if a counterexample is found . Currently , we axe ~ a ' udying different policies and comparing the results  ; one interesting issue is the exploitation of counterexamples  . 
Concluding remarks
Even though PETRARCA is still an experiment and has many unsolved issues  , it is , to our knowledge , the first reported system for extensive semantic knowledge acquisition  . There is room for many improvements ; for example , PETRARCA only detects , but does not interpret idioms ; neither it knows what to do with errors ; if a wrong interpretation of a phrasal pattern is derived  , error correction and refinement of the knowledge base is performed by the programmer  . However PETRARCA is able to process automatically raw language expressions and to perform a first linguistic material produced by PETRARCA provides a basis for future analysis and refinements  . 
Despite its limitations , we believe this method being a first , useful step towards a more complete system of language learning  . 
References 111 F . Antonacci , P . Velardi , M . T . Pazienza , A
High Coverage Grammar for the Italian
Language , Journal of the Assoc . for Literary and Linguistic Computing , inprint 1988 . 
121 F . Antonacci , M.T . Pazienza , M . Russo,
P . Velardi , Representation and Control
Strategies for large Knowledge Domains : an Application to NLP  , Journal of Applied Artificial Intelligence , inprint 1988 . 
\[31 JL . Binot and K . Jensen A SemanticExpert
Using an Online Standard Dictionary
Proceedings of the IJCAI Milano , 1987\[41K . Dahlgren and J . McDoweUKind Types in Knowledge Reimesentation Proceedings of the 
Coling-861986151 Heidorn G . E . " Augmented Phrase Structure Grammar " in " Theoretical Issues in Natural Language Processing " Nash-Webber and 
Schank , eds , ACL 1975161 J . Katz , P . Postal An Integrated Theory of Linguistic Descriptions Cambridge  , M . LT . 
Press , 1964.
171 P . Jacobs , U . Zernik Acquiring Lexical
Knowledge from Text : a Ca . ~ e Study,
Proceedings of the AAAI 88, St . Paul , August Meaning second edition , Penguin Books 1981 . 
191 Michalsky R.S ., Carbonell J.C ., Mitchell
T.M . Machine Learning voli Tioga
Publishing Company Palo Alto , 1983\[101M . T . Pazienza and P . Velardi , A Structured Representation f Word Senses for Semantic Analysis Third Conference of the European  \[111   \[12l 
I 131\[141\[15\]\[161
I 1711987.
M . T . Pazienza and P . Velardi , Integrating Conceptual Graphs and Logicina Natural Language Understanding System  , in " Natural
Language Understanding and Logic
Programming II ~, V . Dahl and P.
Saint-Dizier editors , North-Holland , 1988.
M.T . Pazienza , P . Velardi , Using a Semantic
Knowledge Baseto Support A Natural
Language Interface to a Text Database , 7th
International Conference on
Entity-Relationship Approach , Rome,
November 1618 1988.
M . Russo , A Rule Based System for the
Morphologic and Morphosyntactic Analysis of the Italian Language  , in " Natural Language Understanding and Logic Programming  11"  , 
V . Dahl and P . Saint-Dizier editors,
North-Holland , 1988.
M . Russo , A Generative Grammar-Approach ? for the Morphologie and Morphosyntactie Analysis of Italian  , Third Conference of the European Chapter of the , 4 CL , Copenhagen , 
April 131987.
Shank R . C . Conceptual Dependency : a theory of natural language understanding  . 
Cognitive Psicology , vol 31972
Shank R . C , Goldman , Rieger , Riesbeck
Conceptual Information Processing
Noth-Holland/american Elsevier 1975
J.F . Sowa , Conceptual Structures:
Information Processing in Mind and Machine ,   , 4d dison . Wesley , Reading , 1984 . 
P . Velardi , M.T . Pazienza and M.
De Giovanetti , Conceptual Graphs for the
Analysis and generation of sentences , IBM Journal of Research and Development , March 1988 . 


P . Velardi , M.T . Pazienza , S . Magrini
Acquisition of Semantic Patterns from a natural corpus of texts  , 4CM-SIG , 4RT special issue on knowledge acquisition iprint
E . Way Dinamic Type Hierachies : An
Approach to Knowledge Representation through Metaphor PhD dissertation  , Dept . of System Science , State Univ . of NY at
Binghamton 1987.
Y . Wilks , Preference Semantics Memor and a from the Artificial Intelligence Laboratory  , 
Stanford University Stanford , 1973
Y . Wilks , Deep and Superficial Parsing , in " Parsing natural Language " M . Kingeditor,
Academic Press , 1983.
U . Zemik Strategies in Language Acquisition :
Learning Phrases from Examples in
Contexts . Phddissertation , Tech . Rept.
UCL , 4- , 41-87-1 , University of California , Los , 4 ngeles 1987 R . Byrd , N . Calzolari , M . Chodorow , J . 
Klavans , M . Neff , O . Rizk Large lexicons for Natural Language Processing : Utilizing the grammar Coding System of LDOCE Computational Linguistics  , special issue of the Lexicon D . Walker , , 4 . Zampolli , N . Calzolarieditors July-December 1987 1987 . 
I . Mel'cuk , A . Polguere A Formal Lexicon in Meaning-Text Theory ( or How To Do Lexica with Words ) Computational Linguistics , special issue of the Lexicon D . Walker , 4 . 
Zampoili , N . Calzolarieditors July-December 1987 1987 . 
S . Nirenburg , V . Rask in 111 e Subworld
Concept Lexicon and the Lexicon
Management System Computational
Linguistics , special issue of the Lexicon D.
Walker ,, 4. Zampoili , N . Calzolari editors
July-December 19871987.
J . Pustejovsky Constraints on the Acquisition of Semantic Knowledge  , Journal of Intelligent Information Systems , vol 3 , n . 3, fall 1988
