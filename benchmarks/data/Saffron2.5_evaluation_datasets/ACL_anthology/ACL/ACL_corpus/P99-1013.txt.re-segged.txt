Compositional Semantics for Linguistic Formalisms
Shuly Wintner *
Institute for Research in Cognitive Science
University of Pennsylvania
3401 Walnut St ., Suite 400A
Philadelphia , PA 19018
shuly@:t?nc , cis.upenn , edu
Abstract
In what sense is a grammar the union of its rules ? This paper adapts the notion of composition  , well developed in the context of programming languages  , to the domain of linguistic formalisms . We study alternative definitions for the semantics of such formalisms  , suggesting a denotational semantics that we show to be compositional and fully-abstract  . This facilitates a clear , mathematically sound way for defining grammar modularity  . 
1 Introduction
Developing largescale grammars for natural languages is a complicated task  , and the problems grammar engineers face when designing broadcoverage grammars are reminiscent of those tackled by software engineering  ( Erbach and Uszkoreit ,  1990) . Viewing contemporary linguistic formalisms as very high level declarative programming languages  , a grammar for a natural language can be viewed as a program  . 
It is therefore possible to adapt methods and techniques of software engineering to the domain of natural language formalisms  . We believe that any advances in grammar engineering must be preceded by a more theoretical work  , concentrating on the semantics of grammars . 
This view reflects the situation in logic programming  , where developments in alternative definitions for predicate logic semantics led to implementations of various program composition operators  ( Bugliesi et al ,  1994) . 
This paper suggests a denotational semantics tbr unification-based linguistic formalisms and shows that it is compositional and fully -* I amgrateful to Niss im Francez for commenting on an em'lier version of this paper  . This work was supported by an IRCS Fellowship and NSF grant SBR  8920230  . 
abstract . This facilitates a clear , mathematically sound way for defining grammar modularity  . While most of the results we report on are probably not surprising  , we believe that it is important oderive them directly for linguistic formalisms for two reasons  . First , practitioners of linguistic form Misms usually do not view them as instances of a general logic programming framework  , but rather as first-class programming environments which deserve independent study  . Second , there are some crucial differences between contemporary linguistic formalisms and  , say , Prolog : the basic elements -- typed feature -structures -- are more general than first-order terms  , the notion of unification is different , and computations amount to parsing , rather than SLD-resolution . The fact that we can derive similar results in this new domain is encouraging  , and should not be considered trivial . 
Analogously to logic programming languages , the denotation of grammars can be defined using various techniques  . We review alternative approaches , operational and denotational , to the semantics of linguistic formalisms in section  2 and show that they are " too crude " to support grammar composition  . Section 3 presents an alternative semantics , shown to be compositional ( with respectogrammar union , a simple syntactic combination operation on grammars  )  . However , this definition is " to ofine ": in section 4 we present an adequate , compositional and fully-abstract semantics for linguistic formalisms  . For lack of space , some proofs are omitted ; an extended version is available as a technical report  ( Wintner ,  1999) . 
2 Grammar semantics
Viewing grammars as formal entities that share many features with computer programs  , it is 9 natural to consider the notion of semantics of ratification-based formalisms  . We review in this se ( : tion the operational definition of Shieber et a , 1 . (1995) and the denotational definition of , e . g . , Pereira and Shieber (1984) or Carpenter (1992 , pp .  204-206) . We show that these finitions are equivalent and that none of them supports compositionality  . 
2.1 Basic notions
W ( , assume familiarity with theories of feature structure based unification grammars  , as formulated by , e . g . , Carpenter (1992) or Shieber (1992) . Grammars are defined over typed fea-twre . structures ( TFSs ) which can be viewed as generalizations of first -order terms  ( Carpenter ,  1991) . TFSs are partially ordered by subsumption , with ? the least ( or most general ) TFS . A multirooted structure ( MRS , see Sikkel ( 1997 )   ( ) r Wintner and Francez ( 1999 ) ) is a sequence of TFSs , with possible reentrancies among dif-fi ; rent elements in the sequence . Meta-variables A , /3 range over TFSs and a , p-over MRSs . 
MRSs are partially ordered by subsumption , de-n()ted'__' , with a least upper bound operation ( ) f ' an'llfication , denoted'U ' , and a greatest lowest t ) ( mnd denoted ' W . We assume the existence of a . fixed , finite set WORDS of words . A lexicon associates with every word a set of TFSs  , its category . Meta-variable a ranges over WORDS and . w--over strings of words ( elements of WORDS *) . 
Grammars are defined over a signature of types and features  , assumed to be fixed below . 
Definition 1 . A rule is an MRS of length greater than or equal to  1 with a designated ( fir'st ) element , the head o . f the rule . The rest of the elements . form the rule's body ( which may beem , pty , in which case the rule is depicted a . s'aTFS ) . A lexicon is a total . function . from WORDS to . finite , possibly empty set so . fTFSs . 
A grammar G = ( T ?, /:, As is a . finite set of , rules TO , a lexicon ? . and a start symbol As that is a TFS . 
Figure 1 depicts an example grammar , 1 suppressing the underlying type hierarchy .   2 The definition of unification is lifted to MRSs : let a  , p be two MRSs of the same length ; the ' Grammars are displayed using a simple description language  , where ':' denotes feature values . 
2 Assmne that in all the example grammars , the types s , n , v and v p are maximal and ( pairwise ) inconsistent . 
A '~= (~: at: . ~)( cat : s)-+(co , t:n )   ( cat : vp )  \] 7~ =  ( cat : vp )  --->  ( c . at : v ) ( cat : n ) vp ) + . ,,)
Z2 ( John ) = Z ~ ( Mary )  =  ( cat : ' n )  ? ( sleeps )  = ? ( sleep )  = ? ( lovcs )  =  ( co , t : v )
Figure 1: An example grammar , Gunification of a and p , denoted c , Up , is the most general MRS that is subsmned by both er and p  , if it exists . Otherwise , the unification . fails . 
Definition 2 . An MRS ( AI, . .  .   , A ~:) reduces to a TFSA with respect to agram , marG ( denoted ( At ,   .   .   .   , Ak ) ~(- ~ A)'li ~' th , ere exists a rule pET ~ such , that ( B , 131 ,  . .  . , B ~:) = pll(_L , A1, . . . , Ak ) and BV-A . Wll , en Gisunderstood from . the context it is om , itted . Reduction can be viewed as the bottom-up counterpart of derivation  . 
Iff , g , are flmctions over the same ( set ) domain ,   . f + g is ) ~ I . .f(I ) U . q(I ) . Let ITEMS =\[ w , i , A , j\]\[wEWORDS* , A is a TFS and i , jE0 , 1  , 2  , 3  ,   .   .   .   . Let Z = 2ITEMS . Meta-variables x , y range over items and I-oversets of items . When 27 is ordered by set inclusion it forms a complete lattice with set union as a least upper bound  ( lub ) operation . Aflmction T : 27  -+  27 is monotone if whenever 11   C_/2  , also T ( I1) C_T ( I2) . It is continuous if t brevery chain I1C_/2C_ .   .   . , T ( Uj < ~/ . i ) = Uj < ~ T ( Ij ) . If a function T is monotone it has a least fix point  ( Tarski-Knaster theorem )  ; if T is also continuous , the fix point can be obtained by iterative application of T to the empty set  ( Kleene theorem ) : lf p ( T ) = TSw , where TI "0 = 0 and T tn = T ( T t ( n-1 ) ) when ' n is a successor ordinal and ( _Jk<n ( Ti " n ) when n is a limit ordinal . 
When the semantics of programming languages are concerned  , a notion of observables is called for : Obisaf lmction associating a set of objects  , the observables , with every program . 
The choice of semantics induces a natural equivalence operator on grammars : given a semantics'H'  , G1 ~ G2 iff ~ GI ~= ~ G2 ~ . An essential requirement of any semantic equivalence is that it  97' be correct ( observables - preserving ) : if G1-G2 , then Ob(G1) = Ob(G2) . 
Let ' U ' be a composition operation on grammars and '?' a combination operator on deno -rations  . A(correct ) semantics'H ' is compo- . s ' itional ( Gaifinan and Shapiro ,  1989 ) if whenever ~1~:~G2~ and ~ G3\]--~G4\] , also ~ G , UG3~=\[G2UG4\] . A semantics is commutative ( Brogi et al , 1992) if ~ G1UG2\]=~G , ~?\[ G2 ~ . This is a stronger notion than ( : ompositionality : if a semantics is commutative with respect osome operator then it is compositional  . 
2.2 An operational semantics
As Van Emden and Kowalski (1976) note , " to define an operational semantics for a program-ruing language is to define an implementational independent interpreter for it  . For predicate logic the proof procedure behaves as such an interpreter  . "Shieber et al (1995) view parsing as a . deductive process that proves claims about the grammatical status of strings from assumptions derived from the grammar  . We follow their insight and notation and list a deductive system for parsing unification-based grammars  . 
Definition 3 . The deductive parsing system associated with a grammar G =  ( 7~ , F . ,AS  is defined over ITEMS and is characterized by : Axioms : \[ a  , i , A , i+1\]i . fBEZ . (a ) and BKA;\[e , i , A , i \] if B is an e-rule in T ~ and BK_A Goals : \[ w  ,  0 , A , \[ w \]\] where A~As
Inference rules :\[ wx , il , A1, ill, .   .   .   , \[ Wk , ik , A k , Jk\]\[Wl """ Wk , i , A , j \] if . ' h=i1,+1 . for 1 <_l < k and i = il and
J = Jk and ( A1, . . . , Ak ) = > aA
When an item \[ w , i , A , j \] can be deduced , applying k times the inference rules associ-z~ted with a grammar G  , we write F-~\[w , iA , j \] . 
When the number of inference steps is irrelevant it is omitted  . Notice that the domain of items is infinite , and in particular that the number of axioms is infinite  . Also , notice that the goal is to deduce a TFS which is subsumed by the start symbol  , and when TFSs can be cyclic , there can be infinitely many such TFSs ( and , hence , goals ) - see Wintner and Francez (1999) . 
Definition 4 . The operational denotation o . fagrammar G is EG~o ,, = xIF-v ; :,: . G1-op
G2 iy \] C1o , = G2Bo,
We use the operational semantics to define the language generated by a grammar G : L  ( G )  =  ( w , A\[\[w , O , A , l ' , ,\[\] E \[ G\]o ,  . Notice that a language is not merely a set of strings  ; rather , each string is associated with a TFS through the deduction procedure  . Note also that the start symbol A ' does not play a role in this definition  ; this is equivalent to assuming that the start symbol is always the most general 
TFS ,_k.
The most natural observable for a grammar would be its language  , either as a set of strings or augmented by TFSs . Thus we take Ob ( G ) to be L ( G ) and by definition , the operational semantics ' ~ . \] op'p reserves observables . 
2.3 Denotational semantics
In this section we consider denotational semantics through a fix point of a transformational operator associated with grammars  . -This is essentially similar to the definition of Pereira and Shieber  ( 1984 ) and Carpenter ( 1992 , pp .  204-206) . We then show that the denotational semantics is equivalent othe operation alone  . 
Associate with a grammar G an operator 7~ that , analogously to the immediate consequence operator of logic programming  , can be thought of as a " parsing step " operator in the context of grammatical formalisms  . For the following discussion fix a particular grammar 
G = ( n , E , A ~).
Definition 5 . Let Tc:Z-+Z be a transformation on set so . fitems , where . for every IC_ITEMS , \[ w , i , A , j\]ET ( ~( I ) iff either ? there exist Yl ,   .   .   . , ykEI such that Yl =\[ w1,,iz,Al,jt\] . for " 1  <  1 <_k and il + l = jz for 1 <l < k and il = 1 and jk = J and ( A 1 ,  .   .   . , Ak ) ~ A and w = " w ~ . . ? wk ; or ? i = j and B is an e-rule in G and BKA and w = e  ; or ? i + l = j and \[ w\[=1 and BG12 ( w ) and

For every grammar G , To . , is monotone and continuous , and hence its least fix point exists and l . fp(TG ) = TG$w . Following the paradigm point semantics for unification-based grammars by taking the least fix point of the parsing step operator as the denotation of a grammar  . 
Definition 6 . The fix point denotation of a grammar G is ~ G\[ . fp = l . fp(T a ) . G1=-- . fpG2 iff ~ ti , ( T <; ~) = lfp(Ta ~) . 
The denotational definition is equivalent othe operation alone : Theorem  1  . For xEITEMS , XE lf p(TG ) iff ~-(? x . 
The proof is that \[ w , i , A , j\]ET a$n iffF-7; , \[ w , i , A , j \] , by induction on n . 
Corollary 2 . The relation '= fp'iscorrect : whenever G1 = . fpG2, also Ob(G1) = Ob(a2) . 
2.4 Compositionality
While the operational and the denotational semantics defined above are standard for complete grammars  , they are too coarse to serve as a model when the composition of grammars is concerned  . When the denotation of a grammar is taken to be ~ G\]op  , important characteristics of the internal structure of the grammar are lost  . To demonstrate the problem , we introduce a natural composition operator on grammars  , namely union of the sets of rules ( and the lexicons ) in the composed grammars . 
Definition 7 . / fGI = < T?1 ,  ~1 , A ~) and G2 = (7-~2 , E'2 , A ~) are two grammars over the same signature , then the union of the two grammars , denoted G1 UG2 , is a new grammar G = ( T ~ ,  ? , AS > such that T~=7~1( . J 7 " ~2, f t . = ff~l+ff~2 and As = A ~ rqA ~ . 
Figure 2 exemplifies grammar union . Observe that for every G , G ', GOG '= G'OG . 
? Proposition 3 . The equivalence relation '= op ' is not compositional with respect to Ob  , U . 
Proof . Consider the grammars in figure 2.
~ a : ~ o , , = la do . =\ [" loves " , / , ( cat : v) , i+1\]li > 0 but tbrI=\["John loves John " , i , ( cat : s) , i + 3Ii > _0 , IC_\[G1UG4\]op whereas
I~\[G1UGa~op . Thus Ga=-op G4 but ( Gl ( 2Go ) ~ op ( G1tOG4 )  , hence ' ~-- Op ' is not compositional with respect oOb  , tO .  \[\]
G1:As=(cat: . s)(co , t:s)-+(c . , t : , , , , ) ( co , t : vp)
C(John ) = ((: . t:n ) a2 : As = (_1_)(co , t : vp ) -+ ( co , t : v )   ( cat : vp )  -+  ( cat : v )   ( cat : n )  /: ( sleeps )  =/: ( loves )  =  ( cat : v ) 
Go : As = (&)/: ( loves ) = ( cat : v)
G4: As=(_1_)(cat:vp)-+(co , t : v ) ( cat : n )
C(loves ) = ( cat : v)
G1UG2:As=(cat:s)(co , t : ~) -+ (~: o , t : , , , ,) (~ . at : vp ) ( cat : vp)-~(co , t : v )   ( cat : vp )  --+  ( cat : v )   ( cat : n )  /: ( John )  =  ( cat : n )  ? ( sleeps )  = ? ( loves )  =  ( cat : v ) 
G1UGa : As = ( cat : s )   ( cat : s )  --+  ( cat : n )   ( cat : vp ) 
C(John ) = ( cat:',,,)?(loves ) = ( cat : v)
GIUG4: As=(cat:s)(co,t:~)+(co . t : , , , . )( cat : vp ) ( co , t : vp ) -~( cat : ,   , ) ( co , t : ~ )  /: ( John )  =  ( cat : n )  /: ( loves )  =  ( cat : v ) 
Figure 2: Grammar union
The implication of the above proposition is that while grammar union might be a natural  , well defined syntactic operation on grammars , the standard semantics of grannnars is too coarse to support it  . Intuitively , this is because when a grammar G1 includes a particular ulep that is inapplicable for reduction  , this rule contributes nothing to the denotation of the grammar  . But when G1 is combined with some other grammar , G2 , p might be used for reduction in G1UG2 , where it can interact with the rules of G2 . We suggest an alternative , fix point based semantics for unification based grammars that naturally supports compositionality  . 
3 A compositional semantics
To overcome the problems delineated above , we follow Mancarella and Pedreschi ( 1988 ) in considering the grammar transformation operator itself  ( rather than its fix point ) as the denota-Definition 8 . The algebraic denotation o . fG is ffGffaI = Ta . G1-at G2 iff Tal=TG 2 . 
Not only is the algebraic semantics composi-tionM , it is also commutative with respect to grammar union  . To show that , a composition operation on denotations has to be defined  , and wetbllow Mancarella and Pedreschi ( 1988 ) in its definition :
Tc;~?To ; .,=), LTc,(~)uTa2(5
Theorem 4 . The semantics '==- at ' is commutative with respect to grammar union and '?': for e  , v cry two grammars G1 , G2 , \[ alffat " ~ G2ffal=:GI\[-JG2ff ( tl . 
Proof . It has to be shown that , for every set of items LT ca ~ a . , ( I ) = T a , ( I ) u T a . ,(I) . 
? if xETG1(I ) UTG ~ , ( I ) then either xGT ch(I ) or xET a . , ( I ) . From the definition of grammar union , xETG1 uG2 ( I ) in any case . 
? if zET a ~ ua . , ( I ) then x can be added by either of the three clauses in the definition of Ta  . 
- if x is added by the first clause then there is a rule pG  7~1 U T~2 that licenses the derivation through which z is added  . Then either pE7~1 or pGT~2 , but in any case p would have licensed the same derivation  , so either ~ Ta~(I ) or ? ~ Ta~(I) . 
- if x is added by the second clause then there is ane-rule in  G1 U G2 due to which x is added , and by the same rationale either xCTG ~ ( I ) or xE

- if x is added by the third clause then there exists a lexical category in  ?1 U ?2 due to which x is added , hence this category exists in either ?1 or ?2 , and therefore xCTG ~( I ) UTG2(I ) . 

Since ' ==- at ' is commutative , it is also compositional with respect to grammar union  . Intuitively , since TG captures only one step of the computation  , it cannot capture interactions among different rules in the  ( unioned ) grammar , and hence taking To : to be the denotation of G yields a compositional semantics  . 
The Ta operato reflects the structure of the grammar better than its fix point  . In other words , the equivalence rlation induced by TG is finer than the relation induced by lfp  ( T c )  . The question is , how fine is the '- al ' relation ? To make sure that a semantics is not to of in e  , one usually checks the reverse direction . 
Definition 9 . A fully-abstract equivalence relation '- ' is such that  G1  =-  G'2 ' i ,  . \[ . -f for all G ,
Ob(G1UG ) = Ob(G.eUG).
Proposition 5 . Th , e semantic equivalence relation '-- at ' is not fully abshuct  . 
Proof . Let G1 be the grammar
A ~=?, ?1 = 0, ~= ( cat : ~)-~( ~: . , t : , , , , p ) ( c . , t : vp ), ( cat : up ) -~( ,: . . t : ',, . p ) and G2 be the gramm ~: r
A ~= 2,
Z : 2 = O , n ~= (~ at: . ~) -~ (~, . , t : . , p )( . at : ~ p )  ?  G1 ~ at G2: because tbrI =\ [" John loves Mary " , 6 , ( cat : np ) , 9\] , T (; I(I ) = I but
To . , ( I ) = O ? for all G , Ob(GUG ~) = Ob(G\[3G2) . The only difference between GUG1 and GUG2 is the presence of the rule ( cat : up )  -+  ( cat : up ) in the former . This rule can contribute nothing to a deduction procedure  , since any item it licenses must already be deducible  . 
Therefore , any item deducible with GU G1 is also deducible with GU G2 and hence
Ob(GUG1)----Ob(GUG , 2).

A better attempt would have been to consider , instead of TG , the fbllowing operator as the denotation of G :\ [ G\]id=AI  . Ta(I ) UI . In other words , the semantics is Ta+Id , where Id is the identity operator . Unfortunately , this does not solve the problem , as '~'\] id'is still not fully-abstract . 
1004 A fully abstract semantics
We have shown so fart hat'Hf p ' is not compositional  , and that ' Hid ' is compositional but not fully abstract  . The " right " semantics , therefore , lies somewhere in between : since the choice of semantics induces a natural equivalence on grammars  , we seek an equivalence that is cruder thzm ' Hid ' but finer than ' H  . fp ' . In this section we adapt results from Lassez and Maher  ( 1984 ) a . nd Maher ( 1988 ) to the domain of unification-b~Lsed linguistic formalisms  . 
Consider the following semantics for logic programs : rather than taking the operator as so -dated with the entire program  , look only at the rules ( excluding the facts ) , and take the meaning of a program to be the function that is obtained by an infinite applications of the operator associated with the rules  . In our framework , this would amount to associating the following operator with a grammar : Definition  10  . Let RG:Z-~Z be a trans-formation on set so . fitems , where . for every \[ CITEMS , \[ w , i , A , j \] ERG(I ) iff there exist Yl ,   .   .   . , YkEI such that yl =\[ wz , it , Al , jd . for 1_< l_<k and il + t = jl . for 1 < l < k and i , = 1 and . jk = J and ( A1, .   .   . , Ak ) ~ A and "~1) ~' tl ) 1 ? ? ? ? U k . 
Th , e functional denotation of a grammar G is /\[ G ~ . f , ,,=( Re+Id ) ~= End-0(RG+Id)n . Notice that Rw is not RG"\[w : the former is a function " d from sets of items to set of items  ; the latter is a . set of items . 
Observe that Rc is defined similarly to Ta ( definition 5 )  , ignoring the items added ( by Ta ) due to e-rules and lexical items . If we define the set of items I'n it c to be those items that area  . dded by TG independently of the argument it operates on  , then for every grammar G and every set of items I  , Ta(I ) = Ra(I ) UInita . Relating the functional semantics to the fix point one  , wetbllow Lassez and Maher ( 1984 ) in proving that the fix point of the grammar transformation operator can be computed by applying the fimctional semantics to the set In it G  . 
Definition 11 . For G = ( hg , ? , A ~) , In it c =\ [ e , i , A , i \]\[ B is an e ~- rule in G and BE_AU\[a , i , A , i+1 JIBE?(a ) . for BEA
Theorem 6 . For every grammar G , ( R . c + f d . )( z ', , . it cd = tb(TG ) Proof . We show that t brevery ' n . , ( T ~+ I d ) n = ( E ~ . -~( Re+Id ) ~:) ( I'nit (;) by induction on

For n = 1 ,   ( Tc+Id )  ~\[ 1 =  ( T c ~+ I d )   (   ( Ta+Id ) ~ O )  =  ( T c , +Id ) ( O ) . Clearly , the only items added by TG are due to the second and third clauses of definition  5  , which are exactly Inita . Also , ( E~=o(Ra+Id ) ~:) ( Initc ;) = ( Ra +
Id ) ? ( In itc ) = I ' nitc;.
Assume that the proposition holds tbrn-1 , that is , ( To+Id ) "\[(' , , - 1) = t~E'"-2t~'a:=0 xta +
Id ) k ) Unite ) . Then ( Ta+Id ) $ n = definition of i " ( TG+Id )   (   ( Ta+Id )  ~\[  ( v ,  - 1 ) ) = by the induction hypothesis ~ n--2 ( Ta+Id )   (   ( k = 0 ( RG+Id ) k )   ( Inita )   ) = since Ta ( I ) = Ra ( I ) UInitaEn-2 ( Ra + Id ) (  ( k = Q ( Rc ; + Id ) ~'  )   ( Inita )   ) UInita = ( Ra + ( Ra + Id ) k )   ( 1' , , , its , )) = ( y\]n-1/R , Id ) h :) ( In it (:) k = 0 ~ ,   , G-I-Hence ( RG+Id ) ~( Init ( ;  = (27( ; +Id ) ~ w = lfp(TG ) . \[\] The choice of ' Hfl ~' as the semantics calls for a different notion of ' observables  . The denotation of a grammar is now a flmction which reflects an infinite number of ' applications of the grammar's rules  , but completely ignores the e-rules and the lexical entries  . If we took the ob-servables of a grammar G to be L  ( G ) we could in general have ~ G1\] . f , . = ~ G2\]fl ~ . but Ob ( G1 ) 7 ~ Ob ( G2 )   ( due to different lexicons )  , that is , the semantics would not be correct . However , when the lexical entries in a grammar ( including the e-rules , which can be viewed as empty categories , or the lexical entries of traces ) are taken as input , a natural notion of observables preservation is obtained  . To guarantee correctness , we define the observables of a grammar G with respect to a given input  . 
Definition 12 . Th , e observables of a grammar G = ( ~ ,  / :  , As with respect to an input set of items I are Ot  , ( C ) = (' , , ,   , A ) I\[w , 0 , d , I1\]e'llfG1=fnG2 then . for every I , Obl(G1) =
Ol , ( a , e).
The above definition corresponds to the previous one in a natural way : when the input is taken to be Inita  , the observables of a grammar are its language . 
Theorem 8. For all G , L(G ) = Obinita(G).

L(G ) = definition of L(G ) (' , , , , A ) I \[ w , O , A , I 1\]e I\[C \] lo , , = definition 4 ( w , A)\[F-c\[w , O , A , = by theorem 1 < w , A > I\[ , w ,  0 , A , Iwl\]el . fp(T a ) = by theorem 6( , w , A ) I\[w , O , A , \[ wl\]e\[G\]fn ( In it G ) = by definition 12
Obt , ,, ~ tc;(G)\[\] . To show that the semantics ' Hfn'is compositional we must define an operator for combining denotations  . Unfortunately , the simplest operator ,  '+' , would not do . However , a different operator does the job . Define ~ Gl ~ . f~?\[G2~f ~ to1) e(\[\[G1\]l . fn+\[G2~f ~)?' . Then ' H . f ~' is commutative ( and hence compositional ) with respect to ~?' and ' U' . 
Theorem 9. fiG1UG2~fn=~Gl\]fn"~G2~.fn.
The proof is basically similar to the case of logic programming  ( Lassez and Maher , 1984) and is detailed in Wintner (1999) . 
Theorem 10 . The semantics ' ~'\ [ fn ' is fully abstract : , for every two grammars G1 and G2 , ' llf . for " every grammar G and set of items I , Obr(G1UG ) = ObI(G2UG) , then G1 = fnG2 . 
The proof is constructive : assuming that Gt ~ f ; ~ G2 , we show a grammar G ( which de-t ) ends on G1 and G2 ) such that Obt ( G1 UG ) ? Obr ( G2UG )  . For the details , see Wintner (1999) . 
5 Conclusions
This paper discusses alternative definitions for the semantics of unification-based linguistic formalisms  , culminating in one that is both compositional and fully-abstract  ( with respect to grammar union , a simple syntactic ombination operations on grammars  )  . This is mostly an adaptation of wellknown results from h  ) gic programming to the ti'amework of unification -based linguistic tbrmalisms  , and it is encouraging to see that the same choice of semantics which is compositional and fiflly -abstra  ( : t for Prolog turned out to have the same desirable properties in our domain  . 
The functional semantics ' ~ . \] . f , ' defined here assigns to a grammar a fimction which reflects the  ( possibly in finite ) successive application of gramma rules , viewing the lexicon as input to the parsing process  . We , believe that this is a key to modularity in grammar design  . A grammar module has to define a set of items that it " exports "  , and a set of items that can be " imported " , in a similar way to the declaration of interfaces in programming languages  . We are currently working out the details of such a definition  . An immediate application will facilitate the implementation of grammar development systems that support modularity in a clear  , mathematically sound way . 
The results reported here can be extended in various directions  . First , we are only concerned in this work with one composition operator  , grammar union . But alternative operators are possible , too . In particular , it would be interesting to define an operator which combines the information encoded in two gramma rules  , for example by unifying the rules . Such an operator would facilitate a separate development of grammars along a different axis : one module can define the syntactic component of a grammar while another module would account for the semantics  . The composition operator will unify each rule of one module with an associated rule in the other  . It remains to be seen whether the grammar semantics we define here is compositional and fully abstract with respecto such an operator  . 
A different extension of these results should provide for a distribution of the type hierarchy among several grammar modules  . While we assume in this work that all grammars are defined sume separate  , interacting signatures . We hope to be able to explore these directions in the future  . 

Antonio Brogi , Evelina Lamina , and Paola Mello .  1992 . Compositional model theoretic semantics for logic programs  . New Generation Computing , 11:1-21 . 
Michele Bugliesi , Evelina Lamina , and Paola
Mello .  1994 . Modularity in logic programming . Journal of Logic Programming , 19, 20:443502 . 
Bob Carpenter .  1991 . Typed feature structures : A generalization of first-order terms  . 
In Vijai Saraswat and Ueda Kazunori , editors , Logic Programming-Proceedings of the 1991 International Symposium , , pages 187-201 , Cambridge , MA . MIT Press . 
Bob Carpenter .  1992 . The Logic of Typed Feature Structures . Cambridge Tracts in Theoretical Computer Science . Cambridge University Press . 
Gregor Erbach and Hans Uszkoreit . 1990.
Grammar engineering : Problems and prospects . CLAUS report 1 , University of the Saarland and German research center for 
Artificial Intelligence , July.
Haim Gaifman and Ehud Shapiro .  1989 . Fully abstract compositional semantics for logic programming  . In 16th Annual ACM Symposium on Principles o . fLogic Programming , pages 134-142 , Austin , Texas , January . 
J . -L . Lassez and M . J . Maher .  1984 . Closures and fairness in the semantics of programming logic  . Theoretical computer science , 29:167-184 . 
M . J . Maher .  1988 . Equivalences of logic programs . In . Jack Minker , editor , Foundations of Deductive Databases and Logic Program-rain  . q , chapter 16, pages 627-658 . Morgan
Kaulinann Publishers , Los Altos , CA.
Paolo Mancarella and Dino Pedreschi . 1988.
An algebra of logic programs . In Robert A.
Kowalski and Kenneth A . Bowen , editors , Logic Programming : Proceedings of the F@h international conference and sympo-  , sium , pages 1006-1023 , Cambridge , Mass . 
MIT Press.
Fernando C . N . Pereira and Stuart M . Shieber.
1984 . The semantics of grammar formalisms seen as computer languages  . In Proceedings of the l Oth international con . ference on computation a linguistics and the 22nd annual meeting o . f the association . for computational linguistics , pages 123-129 , Stant brd , CA , July . 
Stuart Shieber , Yves Schabes , and Fernando Pereira .  1995 . Principles and implementation of deductive parsing  . Jo ' wrr ~ , alo \] " Logic Programming ,  24(1-2):3-36 , July/August . 
Stuart M . Shieber .  1992 . Constraint-Based Grammar Form , alism , s . MIT Press , Cambridge , Mass . 
Klaas Sikkel .  1997 . Par'sing Schemata . Texts in Theoretical Computer Science-An EATCS
Series . Springer Verlag , Berlin.
M.H . Van Emden and Robert A . Kowalski.
1976 . The semantics of predicate logic as a programming language  . .Iournal of the Association . for Ccrmputing Machinery , 23(4):733-742, October . 
Shuly Wintner and Nissim Francez .  1999 . Offline parsability and the well-tbundedness of subsumption  . Journal of Logic , Language and In . formation , 8(1):1-16, January . 
Shuly Wintner .  1999 . Compositional semantics for linguistic formalisms  . IRCS Report 99-05 , Institute for Research in Cognitive Science , University of Pennsylvania , 3401 Wahmt St . ,
Suite 400A , Philadelphia , PA 19018.

