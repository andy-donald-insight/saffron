PLANNING COHERENT
MULTISENTENTIALTEXT
Eduard H . Hovy
USC/Information Sciences Institute
4676 Admiralty Way , Suite 1001
Marina del Rey , CA 90292-6695, U.S.A.


Though most text generators are capable of simply stringing together more than one sentence  , they cannot determine which order will ensure a coherent paragraph  . A paragraph is coherent when the information in successive sentences follows some pattern of inference or of knowledge with which the hearer is familiar  . To signal such inferences , speakers usually use relations that llnk successive sentences in fixed ways  . A set of 20 relations that span most of what people usually say in English is proposed in the Rhetorical Structure Theory of Mann and Thompson  . This paper describes the formalization of these relations and their use in a prototype text planner that structures input elements into coherent paragraphs  . 
1 The Problem of Coherence
The example texts in this paper are generated by Penman  , a systemic grammar-based generator with larger coverage than probably any other existing text generator  . Penman was developed at ISI ( see\[Mann & Matthiessen 831 , \[ Mann 831 , \[Matthiessen84\]) . The input to Penman is produced by PEA ( Programming Enhancement Ad-visor ; see\[Moore87\]) , a program that inspects a user's LISP program and suggests enhancements  . 
PEA is being developed to interact with the user in order to answer his or her questions about the suggested enhancements  . Its theoretical focus is the production of explanations over extended interactions in ways that are superior to the simple goal-tree traversal of system such as TYRESIAS  ( \[Davis 76\] ) and MYCIN ( \[Shortliffe 76\] )  . 
Supported by DARPA contract MDAg0381C0~5.
In answer to the question how does the system enhance a program ~  , the following text ( not generated by Penman ) is not satisfactory: ( a )  . The system performs the enhancement . Before * hat , the system resolves conficts . First , the system asks the user to tell Jt the characteristic of the program to be enhanced  . The system app//es transformations to the program . 
/t confrms the enhancement with the user . It scans the program in order to find opportunities to apply transfarma-tions to the program  . 
.  .   . because you have to work too hard to make sense of it  . In contrast , using the same propositions ( now rearranged and linked with appropriate connectives  )  , paragraph ( b ) ( generated by
Penman ) is far easier to understand : ( b) . The system as/ca~he user to tell it the characteristic of the program to be enhanced  . Then the system applies transformations to the program  . In particular , the system scans the program in order to ~ nd opportunities to apply transformations to the program  . Then the system resolves contlicts . It con~rms the enhancement with the user . Fina // y , it performs the enhancement . 
Clearly , you do not get coheren text simply by stringing together sentences  , even if they are related--note especially the underlined text in  ( b ) and its corresponding three propositions in ( a )  . 
The goal of this paper is to describe a method of planning paragraphs to be coherent while avoiding unintended spurious effects that result from the juxtaposition of unrelated pieces of text  . 
1632 Text Structuring
This planning work , which can be called tezt siructuring , must obviously be clone before the actual generating of language can begin  . Text structuring is one of a number of pre -generation text planning tasks  . For some of the other tasks Penman has special -purpose domain-specific solutions  . They include : ? aggregation : determining , for input elements , the appropriate level of detail ( see\[Hovy 87\] )  , the scoping of sentences , and the use of connectives ? reference : determining appropriate ways of referring to items  ( see\[Appelt 87 a , 87 b \] ) ? hypotheticals : determining the introduction , scope , and closing of hypothesis contexts ( spans of text in which some values are assumed , as in air you want to go to the game , then . . .  ~ ) The problem of text coherence can be characterized in specific terms as follows  . Assuming that input elements are sentence-or clause-sized chunks of representation  , the permutation set of the input elements defines the space of possible paragraphs  . 
A simplistic , brute-force way to achieve coherent text would be to search this space and pick out the coherent paragraphs  . This search would be factor lally expensive . For example , in paragraph ( b ) above , the 7 input clusters received from PEA provide 7!  ----  5  , 040 candidate paragraphs . However , by utilizing the constraints imposed by coherence  , one can formulate operators that guide the search and significantly limit the search to a manageable size  . In the example , the operators described below produced only 3 candidate paragraphs . Then , from this set of remaining candidates , the best paragraph can be found by applying a relatively simple evaluation metric  . 
The contention of this paper is that , exercising proper care , the coherence relations that hold between successive pieces of text can be formulated as the abovementioned search operators and used in a hierarchical-expans lonplanner to limit the search and to produce structures describing the coherent paragraphs  . 
The illustrate this contention , the Penman text structurer is a simplified topdown planner  ( as described first by \[ Sacerdoti77\] )  . It uses a formalized version of the relations of Rhetorical Structure Theory  ( see immediately below ) as plans . Its output is one ( or more ) tree ( s ) that describe the structure ( s ) of coherent paragraphs built from the input elements  . Input elements are the leaves of the tree(s ) ; they are sent to the Penman generator . 
to be transformed into sentences.
3 Previous Approaches
The heart of the problem is obviously coherence.
Coherentext can be defined as text in which the hearer knows how each part of the text relates to the whole  ; i . e . , ( a ) the hearer knows why it is said , and ( b ) the hearer can relate the semantics of each part to a  . single overarching framework . 
In 1978 , Hobhs (\[ Hobhs 78 ,  79 ,  82\] ) recognized that in coherent text successive pieces of text are related in a specified set of ways  . He produced a set of relations organised into four categories  , which he postulated as the four types of phenomena that occur during conversation  . His argument , unfortunately , contains a number of shortcomings ; not only is the categorization not well -motivated  , but the llst of relations is incomplete . 
In her thesis work , McKeown took a different approach ( \[ McKeown82\] )  . She defined a set of relatively static schemas that represent the structure of stereotypical paragraphs for describing objects  . In essence , these schemas are paragraph templates ; coherence is enforced by the correct nesting and 6\]llng  . in of templates . No explici the-ory of coherence was offered . 
Mann and Thompson , after a wide-ranging study involving hundreds of paragraphs  , proposed that a set of 20 relation suffice to represent the relations that hold within the texts that normally occur in English  ( \[ Mann & Thompson 87 ,  86 ,  83\]) . These relations , called RST ( rhetorical structure theory ) , are used recursively ; the assumption ( never explicitly stated ) is that a paragraph is only coherent if all its parts can eventually be made to fit into one overarching relation  . The enterprise was completely descriptive ; no formal definition of the relations or justification for their completeness were given  . However , the relations do include most of Hobbs's relations and support McKeown's schemas  . 
A number of similar descriptions exist . The description of how parts of purposive text can relate goes back at least to Aristotle  ( \[Aristotle54 D . 
Both Grimes and Shepherd categorize typical intersentential relations  ( \[ ( \] rimes 75\] and\[Shepherd26\] )  . Hovy ( \[ Hovy 86\] ) describes a program that uses some relations to slant text  . 
1644 Formalizing RST Relations
As defined by Mann and Thompson , RST relations hold between two successive pieces of text  ( at the lowest level , between two clauses ; at the highest level , between two parts that make up a paragraph 1 . Therefore , each relation has two parts , a aucle ~ and a satell~te . To determine the applicability of the relation , each part has a set of constraints on the entities that can be related  . 
Relations may also have requirements on the combination of the two parts  . In addition , each relation has an effect field , which is intended to denote the conditions which the speaker is attempting to achieve  . 
Informalizing these relations and using them generatively to plan paragraphs  , rather than analytically to describe paragraph structure  , a shift of focus is required . Relations must be seen as plans the operators that guide the search through the permutation space  . The nucleus and satellite constraints become requirements that must be met by any piece of text before it can be used in the relation  ( i . e . , before it can be coherently juxtaposed with the preceding text  . The effect field contains a description of the intended effect of the relation  ( i . e . , the goal that the plan achieves , if properly executed . Since the goals in generation are communicative , the intended effect must be seen as the inferences that the speaker is licensed to make about the bearer's knowledge after the successful completion of the relation  . 
Since the relations are used as plans ~ and since their satellite and nucleus constraints must be reformulated as subgoa is to the structurer  , these constraints are best represented in terms of the communicative intent of the speaker  . That is , they are best represented in terms of what the hearer will know--i  . e . , what inferences the hearer would run - - upon being told the nucleus or satellite filler  . 
As it turns out , suitable terms for this purpose are provided by the formal theory of rational interaction currently being developed by  , among others , Cohen , Levesque , and Perrault . For example , in ICohen~z Levesque 851 , Cohen and Levesque present a proof that the indirect speech act of requesting can be derived from the following bask modal operators ?  ( BEL xp ) --p follows from x's beliefs 1This is not strictly true ; a small number of relations , such as Seqtlence , relate more than two pieces of text . 
However , for ease of use , they have been implemented as binary relations in the structurer  . 
?  ( BMB xyp ) --p follows from x's beliefs about what x and y mutually believe ?  ( GOAL xp ) --p follows from x's goals ? (   . AFTER ap ) --p is true in all courses of events after action a as well as from a few other operators such as AND and OR  . They then define suture , ties as , essen-tia Uy , speech act operators with activating condi-tious ( g~tes ) and e~ect z . These summaries closely resemble , in structure , the RST plans described here , with gates corresponding to satellite and nucleus constraints and effects to intended effects  . 
5 An Example
The RST relation Purpose expresses the relation between an action and its intended result := Pro  . pose
Nucleus Constraints z1 . ( BMBSH(ACTION ? act-l )) 2 . ( BMBSH(ACTOR ? act1 ? agt-1))
Satellite Constraints z1 . ( BMBSH(STATE ? state-l )) 2 . ( BMBSH(GOAL?a~-I ? state-l )) s . ( B~SH(RESULTZ act-1 ? ~ t2)) 4 . ( BMBSH(OBJ ? act-2 ? state-I))
Intended E Eects s1 .   ( BMBSH ( BEL?ag~-I ( RESULT ? act1 ? state-l ) ) )  2 .   ( BMBSH ( PURPOSE ? act-I ? state-l ) ) For example , when used to produce the sentence The system scans the program in order to find op-portunlt Jes to apply ~ ansformatlons to t~e program  , this relation is instantiated as

Nucleus Coustraints -
I . ( B~mSH(ACTIONSCA~-I ) i
The program k scanned 2 . ( BMBSH ( ACTORSCAN-ISYS-I )
The systems cans it
Satellite Constraints : 1 .   ( BMBSH ( STATE oee-1 ) ) Opportunities to apply transformations exkt 2 . ( BMBSH ( GOALSYS-10 PP-1))
The system = wants " to find them 3 . ( BMBSH ( RESULT SCAN-1FIND-I))
Scanning wil/result ; in find lng 4 . ( BMBSH(OBJFIND-10 PP-1)) the opportunities
Intended Effects : 1 . ( BMBSH ( BELSYS1 ( RESULT SCAN-10 PP-1))
The system ~ believe s = that scanning will disclose the opportunities  2  . ( BMBSH ( PURPOSESCAN-10 PP-I))
This is the purpose of the scanning 15 S?/SRTELL . IrTE_SEQUEttCE~qTELL~TE- , (YHPUTREC with ( P3 ) ='  ( ~ ) SRTELL~TE--SEQUEtl CI~I'OJCL?US--<Irl PUTREC , A'lth(C2f14)*(~% rlUCLEUS--<Ir(PUTRECvlt . h(R1C4))~P-)( , ~ I'ELLITE--SEOUEtICE/tJ ~ , /SRTELL'II'E-- ( ' rltPUTREC u 4th ( FIKS ) *  ( ~ ) /SATELLITE--ELROORRTIO ~" tNUCLEUS--PURPOS % NUCLEUS - - ? Itt PUTREC v  , th(S2)* Co ) S~QUEHC~I = I'tt , ICLEUS- . < ZHPUTRE Cutth ( R2 )  ? ~ ~ ) ttUCL ? US-- ( IHPUTR gCvlth ( RIP4E6 )   ) ~
Figure 1: Paragraph Structure ~ ree
The elements SCAN-l , OPP-1, etc . , are part of a network provided to the Penman structurer by PEA  . These elements are defined as propositions in a property-inheritance network of the usual kind written in NIKL  ( \[Schmolze & Lipkis83\] , \[KaczmareketaL86\]) , a descendant of KL-ONE (\[ Brachman 78\]) . Some input for this example sentence is: ( PEA-SYST ~4 SYS-I )  "  ( OPPORTUNITY OPP-I )   ( PROGRAM PROG-I )   ( EHABL~4 ENTENAB-S )   ( SCANSCAN-I )   ( DOMAINF~-SOPP-I )   ( ACTORSCAN-I&" , ' S-l )   ( RANGEEN ) 3 - SAPPLY -3 )   ( OBJ SCAN-IPR OG-I )   ( APPLYAPPLY-3 )   ( RESULT SCAN-1-FIND-l )   ( ACTORAPPLY-3SYS1 )   ( FINDFIND-I )   ( OBJAPPLY-STKANS-2 )   ( ACTORFI ~ ) -ISYS-I )   ( RZCIPAPPLY-3PROG-1 )   ( OBJFIND-IO PP-I )   ( TRANSFOR MATION TRANS-2 ) The relations are used as plans ; their intended effects are interpreted as the goals they achieve  . 
In other words , in order to bring about the state in which both speaker and hearer know that  OPP-1 is the purpose of SCAN-I ( and know that they both know it , etc . ) , the structure ruses Purpose as a plan and tries to satisfy its constraints  . 
In this system , constraints and goals are inter-changable ; for example , in the event that ( RESULT SCAN-IFIND-I ) is believed not known by the hearer , satellite constraint 3 of the Purposer e = lation simply becomes the goal to achieve  ( BHBSH ( RESULT SCAN-IFIND-I ) ) . Similarly , the propositions ( B ~ SH ( RESULT SCAN-1 ? ACT-2 ) )  ( BMBSH ( 0BJ ? ACT-20 PP-I ) ) are interpreted as the goal to find some element that could legitimately take the place of ?  ACT-2  . 
In order to enable the relations to nest recursively  , some relations ' nucleuses and satellites con -taln requirements that specify additional relations  , such as examples , contrasts , etc . Of course , these additional requirements may only be included ff such material can coherently follow the content of the nucleus or satellite  . The question of ordering such additional constituents i still under investigation  . The question of whether such additional material should be included at all is not addressed  ; the structure , " tries to say everything it is given . 
The structurer produces all coherent paragraphs ( that is , coherent as defined by the relations ) that satisfy the given goal ( s ) for any set of input elements . For example , paragraph ( b ) is produced to satiny the initial goal ( BMBSe ( SEQUENCE ASK-1 ? l~E~r ) ) . This goal is produced by PEA , together with the appropriate representation elements  ( ASK-1 . SCAM-I , etc . ) in response to the question hoto a~oes ~ e system enhance a progr~m~  . 
Dijerent initial goals will result in di~erent pars-graphs  . 
Each paragraph is represented as a tree in which branch points are RST relations and leaves are input elements  . Figure 1 is the tree for paragraph ( b ) . It cont ~ n , the relations Sequence ( signalled by " then " and " finally ' i , Elaboration (' in particular') , and Purpose (' in order to ') . 
In the corresponding paragraph produced by Pen -man  , the relations ' characteristic words or phrases ( boldfaced below ) appear between the blocks of text they relate : \ [ The system asks the user to tell it the character ~ stlc of the program to be enhanced  . l ( 6 ) Then\[the system applies transformations to the program  . \]( b ) In particular , \[ the system scans the pro-gram\] ( c ) in order to \[ f ~ n dop portu-nitle a to apply ~ ranaformations to the program  . \] a ) Then\[the system resolves conflicts . \] ( e ) lit confu'ms the enhance-meng with the user . \](/) Finally , \[ it performs the enhancement . \]( g )
I input update a gendage t next bud expand budgrow tree 
H \]
I choose final plan
RST relations sentence generator
Figure 2: Hierarchical Planning Structurer 6 . . . . The St ructurer As stated above , the structurer is a simplified topdown hierarchical expansion planner  ( see Figure 2 )  . It operates as follows : given one or more communicative goals  , it finds RST relations whose intended effects match  ( some of ) these goals ; it then inspects which of the input elements match the nucleus and subgoal constraints for each relation  . Unmatched constraints become subgoals which are posted on an agenda for the next level of planning  . The tree can be expanded in either depth-first or breadth-first fashion  . Eventually , the structuring process bottoms out when either :   ( a ) all input elements have been used and unsatisfied subgo a is remain  ( in which case the structurer could request more input with desired properties from the encapsulating system  )  ; or ( b ) all goals axe satisfied . If more than one plan ( i . e . , para . 
graph tree structure ) is produced , the results axe ordered by preferring trees with the minimum unused number of input elements and the minimum number of remaining unsatisfied subgoals  . The best tree is then traversed in left-to-right order  ; leaves provide input to Penman to be generated in English and relations at branch points provide typical interclausal relation words or phrases  . In this way the structurer performs topdown goal refinement clown to the level of the input elements  . 
7 Shortcomings and Further

This work is also being tested in a completely separate domain : the generation of text in a multimedia system that answers database queries  . Pen-man produces the following description of the ship Knox  ( where CTG070 . 10 designates a group of ships ): ( c) . Knoxisen route in order to ren-denvous with CTG  070  . 10 , arriving in Pearl Harbor on 4/24 , for port visit until 4~ so . 
In this text , each clause ( enroute , rendezvous , arrive , visit ) is a separate input element ; the structurer linked them using the relations Sequence and Purpose  ( the same Purpose as shown above ; it is signalled by ~ in order to N ) . 
However , Penman can also be made to produce ( d) . Knoxisen route in order to ren-dezvous with CJTG  070  . 10 . It w~11 arrive in Pearl Harbor on 4/24 . It will be on port visit until 4/30 . 
The problem is clear : how should sentences in the paragraph be scoped ? At present  , avoiding any claims about a theory , the structurer can feed tence , or make each input element a separate sentence . However , neither extreme is satisfactory ; as is clear from paragraph ( b ) , a short " spans of text can be linked and " long " ones left separate  . 
A simple way to implement this is to count the number of leaves under each branch  ( nucleus or satellite ) in the paragraph structure tree . 
Another shortcoming is the treatment of input elements as indivisible entities  . This shortcoming is a result of factoring out the problem of aggregation as a separate text planning task  . Chunking together input elements ( to eliminate detail ) or taking them apart ( to be more detailed ) has received scant mention--see\[Hovy 87\] , and for the related problem of paraphrase see\[ Schank  75\] -- but this task should interact with text structuring in order to provide text that is both optimally detailed and coherent  . 
At the present time , only about 20~ of the RST relations have been formalized to the extent that they can be used by the structurer  . This formalization process is di ~ cult , because it goes hand-in-hand with the development of terms with which to characterize the relations ' goals/constra?uts  . 
Though the formalization can never be completely finalized -- who can hope to represent something like motivation or justification complete with all ramifications ?-- the hope is that  , by having the requirements stated in rather basic terms  , the relations will be easily adaptable to any new representation scheme and domain  . ( It should be noted , of course , that , to be useful , these formalizations need only be as specific and as detailed as the do-m ~ in model and representation requires  . ) In addition , the availability of a set of communicative goals more detailed than just say or ask  ( for example )  , should make it easier for programs that require output text to interface with the generator  . This is one focus of current text planning work at ISL  8 Acknowledgments For help with Penman , Robert Albano , John Bateman , Bob Kasper , Christian Matthiessen , Lynn Poulton , and Richard Whitney . For help with the input , Bill Mann and Johanna Moore . For general comments , all the above , and Cecile Paris , Stuart
Shapiro , and Norm Sondheimer.



Appelt , D . E ., 1987 a.
A Computational Model of Referring , SRI
Technical Note 409.
Appelt , D.E ., 1987b.
Towards a Plan-Based Theory of Referring Actions , in Natural Language Generation : Recent Advances in Artificial Intelligence  , Psyclwlogy , and Linguistic 8 , Kempen , G . 
( ed ) , ( Kluwer Academic Publishers , Boston ) 637 0 . 


Aristotle , 1954.
The Rhetoric , in Thel ~ , eto ~ c and the Po-etics of Ar ~ to ~ e , W . Rhys Roberts ( Pans ), ( Random House , New York) . 
Brachman , R . J ., 1987.
A Structural Paradigm for Representing
Knowledge , Ph . D . dissertation , Harvard University ; also BBN Research Report 3605 . 
5. Cohen , P.R .& Levesque , H.J ., 1985.
Speech Acts and Rationality , Proceedings of the ACL Conference , Chicago (49-59) . 
6. Davis , R ., 1976.
Applications of Meta-Level Knowledge to the Constructions  , Maintenance , and Use of Large Knowledge Bases , Ph . D . dissertation,
Stanford University.
7. Grimes , J.E ., 1975.
The Thread of D/~course

( Mouton , The 8. Hobbs , J.R ., 1978.
Why is Discourse Coherent ?., SRI Technical
Note 176.


Hobbs , J.R ., 1979.
Coherence and Coreference , in Cognitive Science 3(1) ,  67-90 . 
Hobbs , J.R ., 1982.
Coherence in Discourse , in Strategies for Natural Language Processing , Lehnert , W . G . & Ringle , M . H . ( eds ), ( Lawrence Erlbaum Associates , \]:\[ HI . dale NJ ) 223-243 . 
11. Hovy , E.H ., 1986.
Putting Affect into Text , Proceedings of the Cognitive Science Society Conference  , 
Amherst (669-671).
16812. Hovy , E.H ., 1987.
Interpretation iGeneration , Proceedings of the AAAI Conference , Seattle (545-549) . 
13 . Kaczmarek , T . S . , Bates , R . & Robins , G . , 1986 . 
Recent Developments in NIKL , Proceedings of the AAAI Conference , Philadelphia (978-985) . 
14. Mann , W.C ., 1983.
An Overview of the Nigel Text Generation Grammar , USC/Information Sciences Institute Research Report  RR-83-113  . 
15. Mann , W.C . & Matthiessen , C.M.I.M ., 1983.
Nigeh A Systemic Grammar for Text Generation , USC/Information Sciences Institute
Research Report RR-83-I05.
16. Mann , W.C .& Thompson , S.A ., 1983.
Relational Propositions in Discourse , USC/-Information Sciences Institute Research Report  RR-83-115  . 
17. Mann , W.C .& Thompson , S.A ., 1986.
Rhetorical Structure Theory : Description and Construction of Text Structures  , in Natural Language Generation : Nero Results in Artificial Intelligence  , Psychology , and L~n-guistics , Kempen , G . ( ed ) , ( Kluwer Academic Publishers , Dordrecht , Boston MA ) 279-300 . 
18. Mann , W.C .& Thompson , S.A ., 1987.
Rhetorical Structure Theory : A Theory of Text Organization  , USC/Information Sciences Institute Research Report  RR-87-190  . 
19. Matthiessen , C.M.I.M ., 1984.
Systemic Grammar in Computation : the
Nigel Case , USC/Information Sciences Institute Research Report  RR-84-121  . 
20. McKeown , K.R ., 1982.
Generating Natural Language Text in Response to Questions about Database Queries  , Ph . D . dissertation , University Of Pennsylvania . 
21. Moore , J . D ., 1988.
Enhanced Explanations in Expert and
Advice-Giving Systems , USC/Information
Sciences Institute Research Report ( forthcoming).
22. Sacerdoti , E ., 1977.
A Structure for Plans and B?l ~ avior ( North-
Holland , Amsterdam).
23. Schank , R.C ., 1975.
Conceptual Information Processing , ( North-
Holland , Amsterdam).
24. Schmolze , J.G .& Lipkis , T.A ., 1983.
Classification in the KL-ONEK nowledge
Representation System , Proceeding 8 of the IJ-
CAI Conference , Karisruhe (330-332).
25. Shepherd , H.R ., 1926.
The Fine Art of Writing , ( The Macmillan Co,
New York).
26. Shortliffe , E.H ., 1976.
Computer-Based Medical Consultations :


