MOVEMENTINACTIVE PRODUCTION NETWORKS
Mark A . Jones
Alan S . Dria coll
AT&T Bell Laboratories
Murray Hill , New Jersey 07974

We describe how movement is handled in a class of computational devices called active production networks  ( APNs )  . The APN model is a parallel , activation-basod framework that ha = been applied to other aspects of natural language processing  . The model is briefly defined , the notation and mechanism for movement is explained  , and then several examples are given which illustrate how various conditions on movement can naturally be explained in terms of limitations of the APN device  . 
I . INTRODUCTION
Movement is an important phenomenon in natural languages  . Recently , proposal such as Gazdar's dcrivod rules ( Gazdar ,  1982 ) and Pereira's extraposition grammars ( Pereirao 1983 ) have attemptod to find minimal extensions to the contextfree framework that would allow the description of movement  . In this paper , we describe a class of computational devices for natural language processing  . 
called active production networks ( APNs ) , and explore how certain kinds of movement are handled  . In particular . 
we are concerned with left extraposition , such as Subject-auxiliary Inversion . Wh-movement , and NP holes in relative clauses , in these cos?s , the extraposod constituent leaves a trace which is inserto data later point in the processing  . This paper builds on the research reported in
Jones (1983) and Jones ( forthcoming).
7, . ACTIVE PRODUCTION Ngr wo PJ ~7 . . 1 Timi~vk ~ Our contention is that only a class of parallel devices will prove to be powerful enough to allow broad contextual priming  , to pursue alternative hypotheses , and to explain the paradox that the performance of a sequential system often degrades with new knowledge  , whereas human performance usually improves with learning and experience  . = There are a number of new parallel processing ( connection-?st ) models which are sympathetic to this view- -Anderson  ( 1983 )  . Feldman and Ballard (1982) , Waltz and Pollack (1985) . McClelland and Rumelhart (1981, 1982), and
Fahlman . Hinton and Sejnowski (1983).
Many of the connection?st models use iterative relaxation techniques with networks containing excitatory and inhibitory links  . They have primarily been used as best-fit categorizers in large recognition spaces  , and it is not yet clear how they will implement the rule-governed behavior of parsers or problem solvers  . Rulebased systems need a strong notion of an operating state  , and they depend heavily on appropriate variable binding schemes for operations such as matching  ( e . g . . unification ) and recurs?on . 
The APN model directly supports a rule-based interpretation  , while retaining much of the general flavor of I .   1"be htmmmli ~ ity to L : mrf of mml patz tmmtlly e ? pat m , mopmltmm = alias ~ y ~ , imt ' alkdloud , mumrem for out hisb ? fid . 
connection?s in . An active production network is a rule-oriented , distributed processing system based on the following principles :  1  . Each node in the network executes a uniform activation algorithm and assumes states in response to message  (  , such as expectation , inhibition , and activation ) that arrive locally ; the node can , in turn , relay messages , initiate messages , and spawn new instances to process message activity  . Although the patterns that define a node's behavior may be quite idiosyncratic or spocializod  , the algorithm that interprets the pattern is the same for each node in the network  . 
2 . Messages are relatively simple . They have an associated time , strength , and purpose ( e . g . , to post an expectation ) . They do not encode complex structures such as entire binding lists  , parse trees , feature lists , or meaning representations , z Consequently , no structure is explicitly built ; the " result " of a computation consists entirely of the activation trace and the new state of the network  . 
Figure I gives an artificial ' , but comprehensive example of an APN grammar in graphical form  . The grammar generates the string s--a , b . acd . ace . bed . bee . fg and gl - and illustrates mapy of the pattern language features and grammar writing paradigms  . The network responds to $ our cex which activate the network at its leaves  . Activation messages spread '* upward " through the network  . At conjunctive nodes ( seq and and ) , expectation messages are posted for the legal continuations of the pattern  ; inhibition messages are sent down previous links when new activations are recorded  . 
PJ  ~
Figurei . A Sample APN
In parsing applications , partially instantiat cd nodes are viewed as phrase structure rules whose next constituent is expected  . The sources primarily arise from exogenous2 . For ? sit'tatar?o aaectio aettv new , ~ F?ldmansad B  #llard ( 1982 ) or Waltzted Pollack ( 198 S )  . A compemoa or mark or patuns , value Imaan I?aduo reltricted melmzlep in ball = yttm = t=iipveaiaFahlmnm  , 
Hlal all adScj now l~(IgS)).
161 strobings of the network by external inputs . In generation or problem solving applications , partially instantiated nodes are viewed as partially satisfied goals which have out  . stand-ing subgoa Ls whine solutions are de = ired . The source = in this case are endogenously generated  . The compatibility of the = e two views not only allows the same network to be used for both parsing and generation  , but also permits procesu ~ to share in the interaction of internal and external sources of information  . This compatibility , somewhat surprisingly , turned out to be crucial to our treatment of movement  , but it is a Lso clearly desirable for other aspects of natural anguage processing in which parsing and problem solving interact  ( e . 8 . , refer encore solution and infer-en(~P . ) . 
Each node in an APN is defined by a pattern , written in the pattern language of Figure 2 . A pattern describes theme = age = to which a node rmponds  , and the new message = and internal state = that are produced  . Each subpat-tern of the form ( $ v binding-put ) in the pattern for node N is a variable binding site  ; a variable binding takes place when an instance of a node in binding-gat activates a reference to variable v of node N  . Implicitly , a pattern defines the set of state = and . state transitions for a node . 
The ? ( optiouality ) ,  +  ( repetition ) and ? ( optional repetition ) operators do not extend the expressiveness of the language  , but have been added for convenience . They can be replaced in preprocessin8 by equivalent expre&sions , j Formal semantic definitions of the m_~_~$ e passing behavior for each primitive operator have been specified  . 
pattern : :-- binding-site(seq pattern . . . )( and pattern . . . ) ( or pattern . . . )(? pattern )(+ binding . site )( . binding-site ) binding-site::-- ( $ vatbinding-pattern ) binding . pauern : :-- node
I ( and binding-pattern ...)
I ( or binding-pattern ...)
Figure 7.. The APN Pattern Language
An important distinction that the pattern language makes is in the synchronicity * of activation signals  . The pattern ( and ( $ vl X )   ( $ v2\]'3 ) require = that the activation from X and F emanate from distinct network sources  , while the pattern ( $ v ( and XI"3 ) insists that instances of X and Y are activated from the same source  . In the \] . The enact chore = o ( cq~s ' a cors in the pattern tanupitt mate what ~ at = mine from the =!~ = m~attma of the APN macia a ~  . 
4 , -r~?nulreatAPN model allocate=~ telue at mUy  . The ten = $ yllgite omlclly reflC~ltthlfactth llt\[~~kicl ~ Uly  o4 rt~i~m~se = can be Ioc~yCOmlm ' . , , If ~ mtlm = rtiuw~f ~ TI~ukinu the , ctJvuua = pmau = rims\[===a ~ ugb to coacli ~ aa the network bmmi  , maim y , m0s cuvatmm . Alua ' aa Uvety , a , : Uvalmamelal ~ covidem Vtl~mmr ? ~ ideatiW = tas  a4di  , t* . . . - tl~ram , et ~ n . i at l ~ c sm . m = Jmea euntiom cama * su . hq ~ ~ attt '' promt ' ~ h , ~ e(titia a emmltal cxp ~ ? ume~mvtm , ,_ , ~ . _F . = re~l~iyill lequndeuti , i . . o,m'lap may nm po ~ a p~Vlem . 
graphical representation fan APN , synchrony is indicated by a short tail above the subpattern expression  ; the definition of U in Figure I illustrates both conventions :  ( and ( $ vl ( and TI ) )  ( $ v2S ) ) . 
2.3 AmF . . ~ m ~
Figure 3 shows the stages in parsing the string acd . An exogenous source Exog-srcO first activates a , which is not currently supported by a source and , hence , is in an inactive state . The activation of an inactive or inhibited node give=rise to a new instance  ( nO ) to record the binding . 
The instance is effectively a new node in the network  , and derives its pattern from the spawning node . The activation spreads upward to the other instance shown in Figure  3  ( a )  . The labels on each node indicate the current activation level  , repreu : nted as an integer between 0 and 9 , inclusive . 
PO(9) q o (9) c
II a O(9) I

Exog-~rc0 ( 9 ) \[ Exog-srcJ ( a ) trace structure after apo ( 4 ) 
Q0 c0 (4) saOIT
Exog-src0Exog-srcl(9) def
Exog-src(b ) trace structure after acpO(9)
Q0cOS0(9)
IExog-src0Exog-srcld0(9)

Exog-src2 ( 9 )   ( c ) trace struct zure after acd\[~ple3 , Stalp = linParsing acd 4 re ) instantiated and a variable to be ( re ) bound . For exam-pie . in the activation of RO , the pattern ( seq ( $ viQ )   ( 5 v2c '9 ) is replaced by ( seq ( $ vi ( or QQO ) )  ( $ v2c ) ) . and the variable v l is bound to (20 . For simplicity , only the active links are shown in Figure 3 . RO posts an expectation message for node C which can further its pattern  . 
The source Exog-secO is said to be supporting the activation of node an O  . QO . RO and PO above it , and the expectations or inhibitions that are generated by these nodes  . For the current paper we will assume that exogenous sources remain fully on for the duration of the sentenco  , sIn Figure 3(b ) , another exogenou source Exog-sr clactivates c , which furthers the pattern for RO . RO sends an inhibition message to QO , posts expectations for S , and relays an activation message to P0 , which rebind ~ its variable to RO and a ~ umes a new activation value  . Figure 3 ( c ) shows the final situation after d has been activated  . 
The synchronous conjunction of SO is satisfied hy TO and dO  . RO is fully satisfied ( activation value of 9) , and PO is re-satisfied . 
1, 4Gramm ~ Writb qlP ~ Ulpm
The APN in Figure I illustrate several grammar writing paradigms  . The situation in which an initial prefix string ( a or b ) satisfies a constituent ( P )  , but can be followed by optional suffix strings ( cdorce ) occurs frequently in natural language grammars . For example , noun phrase heads in English have optional prenominal and postnominal modifiers  . The synchronous disjunction at P allows the local role of a or b to change  , while preserving its interpretation as part of a P  . It is also simple to encode optional prefixes . 
Another common situation in natural language grammars is specialization of a constituent based on some inter-hal feature  . Noun phrases in English , for exampl ? , can be specialized hycase ; verb phrases can be specialized as participial , tensed or infinitive . In Figurel , node S is a spe . 
cialization which represents " Ts with d-nessore -ness  , but not f-he SS . ' " The specialization is constructed by a synchronous conjunction of features that arise from subtrees somewhere below the node to be specialized  . 
The APN model also provides for node outputs to he partitioned into independent classes for the purl ~s ? ~  , ~) f the activation algorithm . The nodes in the classes form levels in the network and represent orthogonal systems of classification  . The cascading of expectations from dilfcrent I ~els can implement context-sensitive bhavior such as feature agreement and s':mantics clection ai restrictiops  . 
This is described in Jones ( forthcoming ) . In the next section , we will introduce a grammar writing paradigm to represent movement  , another type of non . .context-fre ? behavior . 
$ . It is interert in stosp ~' ulat c : on the oOm ~ lUamC ~ o  ( vsr~wrelauua ~ q of ~ hiu ? al~m~l ~ Oe . Fundam , mt ~ llimit atmm in the allocatm of ~ may be reJalod to limiu Umnains luart term memory  ( ~rbuff'respace ind c'tl ~ iatMi?zz leJ?l~I ? ? Matctul  , 19 BO ) . Linuilti ? ? emmz in Ul ~ on OoQM ~ tlt~l ? IcqtStb oou ~ be col=tedt O~rl~daca  )  ,  . ~ yntlcli ? Mlzd capath be bav ~ ? mJlblbe r clltad to accc  . h = It a diowr ~ decay r . at mmd by in bibitio of rom ? ~ up ~ mll by pmbmia . Anythin $ mum than ? f , ~ m ~ iJ ~ t t treat , hi = 3 . MOVI~W . .NT From the APN perspective , movement ( limited here to left-extrapnsition ) ecessitates the endogenous reactivation of a trace that was created earlier in the process  . To cap . .
ture the trace so that expectations for its reactivation can be posted  , we use the following type of rule : ( seq(5vl . . . 
X . . . )($ v2 . . . ( and X X-see Y ) . . . ) . When an instance , XO , first activate a this rule , vl is bound to XO ; the second occurrence X in the rule is constrained to match instances of XO  , and expectations for XO , X-see and Y are created . 
No new exogenous source can satisfy the synchronous conjunction  ; only an endogenous X . src can . The rule is similar to the notion of an X followed by a Y with an X hole in it  ( cf . Gazdar , 1982) . 
NP-traell CNP VV\]
I ? . ~  . <> . ~7 p .   .   . /I ~ . ~et ~ N ~ rancnase cl /
I a the ?. ~ mOU ..~/
Figure 4 . A Grammar for Relative Clauses Figure 4 defines a grammar with an NP hoic in a relative clause  ; other type , s of \[ eft-extra position are handled analogously  . Our treatment of relatives is adapted from C ' homsky and Lasnik  ( 1977 )  . The movement rule for S is: ( seq ( $ vl ( and Cutup Re / ( or Exog . srcPRO-src )) ($ v2( and RelRel . srcS ))) . The rule restricts the first instance of Re/to arise either from an exogenous relative pronoun such as which or from an endogenously generated  ( phonologically null ) pronoun PRO . The second variable is satisfied when Rei , srcsimultaneously reactivates a trace of the Rel instance and inserts an NP-tracc into an S  . 
It is instructive to consider how phonologically null pronouns are inserted before we discuss how movement occurs by trace insertion  . The phrase , \[ NP themouse\[~PRO = " that . . . \]\] , illustrates how a relative pronoun PRO is inserted  . Figure 5 ( a ) shows the network after parsing the cat . When the complementizer that appears next in the input  , PRO-src receives inhibition ( marked by downward arrows in Figure 5 ( b ) ) from Rel . CompO . Non-exogenous texts in which they are expected and then receive inhibition  . Figure 5 ( c ) shows the resulting network after PRO-srch as been activated  , The inserted pronoun behaves precisely as an input pronoun with respect to subsequent movement  . 
The trace generation ecessary for movement uses the same insertion mechanism described above  . Figures 6 ( a ) - ( d ) illustrate various stages in parsing the phraso , \[/ vp the cat\[~"whichi\[$tlranll\] , in Figure 6(a ) , after parsing the cat which , synchronous expectations are posted for an S which contains a reactivation of the RelO trace by Rel  . 
see . The signal sent to S by Rei . src will be in the form of an NP ( through NP-trace )  . 
Figure 6 ( b ) shows how the input of ran produces inhibition on Rei-src from SI  . The inhibition on Rei-srccaus ~ it to activate ( just as in the null pronoun insertion ) to try to satisfy the current contextual expectations  . Figure 6 ( c ) shows the network after Rel-srch as activated to supply the trace  . The only remaining problem is that Rel-src is actively inhibiting itself through  . ~0 . 6 When Rel-src activates again , new instances are created for the inhibited nodes as they are re-activated  ; the uninhibited nodes are simply rebound . The final structure is shown in
Figure 6(d).
it is interesting that the network automatically enforces the restriction that the relative pronoun  , complementizer and subject of the embedded sentence cannot all be missing  . PRO must be generated before its trace can be inserted as the subject  . Furthermore . since expectations are strongest for the first link of a sequence  , expectations will be much weaker for the VP in the relative clause  ( under Sunder S " ) than for the top level VP under SO . 
The fact that the device blocks certai'n structures  , without explicit we li-formedness constraints , is quite significant . Wherever possible , we would like to account for the complexity of the data through the composite behavior of a universal device and a simple  , general grammar . We consider the description of a device which embo-dies the appropriate principles more parsimonious than a list of complex conditions and filters  , and , to the extent that its architecture is independently motivated by proc  , ' ss-ink(i . e . . performance ) considerations , of greater thcorctical interest fAs we have seen , certain interpretations can be suppressed by expectations from elsewhere in the network  . 
Furthermore , the occurrence of traces and empty constituents is severely constrained because they must be supplied by endogenou sources  , which can only suppurt as in-tie constituent at any given time  . For NP movement , these two properties of the device , taken together . 
elfectively enforce Ross's Complex NP Constraint ( Ross . 
1967) , which states that , " No element contained in a 6 . Another , ~ syo4"rut ? in Sthi , JiJ that the no a ~ ynchroet M : ity of the two van a Mea in the I~tternhat ~ viohtted  . The wdt-inhibit to af?murcgocgt wtinoth cn r conteat ~ in the APN ft'tnM:lmekeve ? for e golg no ~ t to Mt ~ eLIs net  , a erita hat contai ? leJ't . rm ; urtiv ? cyr . t ~ or , endmSl ~ tmtttaghn~nta(e . S . . PP lUaghfl~'ltt ) , tett-iahibltio a CllIfiunaturally Uthet ~ ult at nemum~me-de ~ rmiaim ~ ae  . tctivatio ef ? ~\[- inhil~t ~ mumd'egUvety Ixorgtva theaea-tyar Jumigity ~ pmuwnt  . 
?.1"I ~ work 4Margin (1980) iaint J~tm ~& l~t.
sentence dominated by an NP with a lexL calhead noun may be moved out of that NP by a transformation  . " To see why this constraint is enforced , consider the two kinds of sentences that an NP with a lexical head noun might dominate  . If the embedded sentence is a relative clause , as in . \[ piptherat\[~"whichl\[$thecat\[~" which j\[Sfj chased/I \]\] likes fish\]J\]  , then Rel . src cannot support both traces . If the embedded sentence is a noun complement ( not shown in Figure 4 )  . as in . \[NP the rat\[~"whichi\[Shereada report\ [ ~" that\[$the cat chased fl\]\]\]\]\]  , then there is only one trace in the intended interpretation  , but there is nondeterminlsm during parsing between the noun complement and the relative clause interpretation  . The interference aus ? , , the trace to be bound to the innermost relative pronoun in the relative clause interpretation  . ' Thus , the combined properties of the device and grammar consistently block those structures which violate the Complex NP Constraint  . Our preliminary findings for other types of movement  ( e . g . , Subject-auxiliary Inversion , Wh-movement , and Raising ) indicate that they also have natural APN explanations  . 
4 . IMPLF . a MENTATION8 mlFu'ruRgDIMF . CrlONS Although there . torch described in this summary is primarily of a theoretic nature  , the basic ideas involved in using APNs for recognition and generation are being implemented and tested in Zetalisp on a Symbolics Lisp Machine  . We have also hand-simulated data on movement from the literature to design the theory and algorithms presented in this paper  . We are currently designing networks for a broad coverage syntactic grammar of English and for additional  , cascaded levels for NP role mapping and case frames  . The model has a L so been adapted as a general , context-driven problem solver , although more work remains to be done . 
We are considering ways of integrating iterative relaxation techniques with the rule-based framework of APNs  . 
This is particularly necessary in helping the network to identify expectation coalitions  . In Figure 5(a ), for exam-pie . there should be virtually no expectations for Rel -src  , since it cannot satisfy any of the dominating synchronous conjunctions  . Some type of non-activating feedback from the source seems to be necessary  . 
S . SUI~ARY
Recent linguistic theories have attempted to induce general principles  ( e . g . , CNPC . Subjacency , and the Structure Preserving Hypothesis ) from the detailed structural descriptions of earlier transformational theories  ( Chomsky ,  1981) , Our research can be viewed as an attempt tu induce the machine that embodies theae principles  . In this paper , we have described a class of candidate machine ~ , called active production networks , and outlined how they handle movement as a natural way in which machine and grammar interact  . 
The APN framework was initially developed as a plausible cognitive model for language processing  , which would have realtime processing behavior , and extensive 8 . UhletOr ~ - . ~,-~ . - - i ? oesk Js ~ ttmsJ wb~trg ~ ltotOe . lp~t~omq~t ~ nfftb~tJr ? ~ tm heudias ~ . trtlmt ~ nemmtg . 
164 so (4)
NPO(9) VP
CNP O(9) "'" osthe O

Exog-srcOcat0(9) ~"" LTComn
Exog-sr?l (9) Ir ~/ . h4 ChPRO %\ that for ( a ) trace structure after the cat




NO--~

Oet O?I\'/..=, ~ Rel-Com?O(4)
ReI~---~~4=er0(9)
I(b ) trace structure after the cat ... that
NPO (4) vP/

Oat0NO/ItneOcatO
Il Ex Og-Sr CO ~ x Og-S ?' C !
SO(4)/_~~,-Ico ~, oo ~9) ~~"-- . ~ NP-tr'ace CNP Rel O ( 9 ) I\[Com glement tzer OI/ . I . .
\1 , . ' . . o J / \[ p~o-src (   ) \[ g- ( c ) trace structure after the cat PRO that . Figure 5 . Relative Pronoun Insertion contextual processing and learning capabilities based on a formal notion of expectations  . That movement also seems naturally expressible in a way that is consistent with current linguistic theoriesiquite intriguing  . 

Anderson , J . R .  (1983) . The Architecture of Cognition,
Harvard University Press , Cambridge.
Chomsky . N .  (1981) . Lectures on Government and Binding . Foris Publications , Dordrecht . 
Chomsky , N . and Lasnik , H .  (1977) . " Filters and Control , " Linguistic Inquiry g ,  425-504 . 
Fahlman , S . E .  (1979) . NETL " A System for Representing and Using Real -World Knowledge  . MIT Press , Cambridge . 
Fahlman , S . E . , Hinton , G . E . and Sejnowski , T . J . 
(1983) . " Massively Parallel Architectures for AhNFTL , Thistle , and Boltzmann Machines , " AAAI . 83 Conference

Feldman . J , A . and Ballard , D . It .  (1982) . " Connectionist Models and Their Properties , " Cognitive Science 6 ,  205-254 . 
Gazdar , G .  (1982) . " Phrase Structure Grammar , " The Nature of Syntactic Representation , Jacubson and Pullum , eds . , Reidel , Boston , 131-186 . 
Jones . M . A . . (1983) . " Activation-Based Parsi . g . "8th IJCAI , Karlsruhe , W . Germany , 678-682 . 
Jones , M . A . ( forthcoming ) . submitted for publication . 
Marcus . M . P .  (1980) . A Theory of S ), ntactic Recogni . 
lion for Natural L , znguage , MIT Press , Cambridge . 
Pereira . F .  (1983) . " Logic for Natural Language Analysis , " technical report 275 , SRI International . Menlo

Ross , J . R .  (1967) . Constraints on Variables . in Syntax , unpublished Ph . D . thesis , MIT , Cambridge . 
Waltz . D . L . and Pollack , J . B .  (1985) . " Massively Parallel Parsing : A Strongly Interactive Model of Natural Language Interpretation  , " Cognitive Science ,  9 ,  51-74 . 


VP NP O(4)/

OetONOtfleOiII'~c?.'P?(9.~1s
Ii ~ tchO(t ) ? ll--~riClCNI

NPO(4~*~='~''` mr ~ ~" VP/

OetONO $0(4). Ir ~ = o ~ ~ i ~, (4)
Sxoglife 0 Exoo-srcl I " ~4#"/~ I ~= lo / ~ . ~v = o(9)\[li"//t1
I wnt chO/NI--IPIC iVO(9), . o . - . .<~ . ,/ . ; ~! ? o < , ,  ( a ) trace structure after ihecat which ( b ) trace structure after the cat which . . . ran
NP0(9) VP/
CNP0(9) 0et0NOSO(9~ . . o~,,oo ~, o : . , <,'4 ~ I . o , < . ~ oo/II il ; ~ o / .   .  -<  .   .  /<  . o ( , , ~ ~, o , ~ y , : ? o

NP09) VP/
CNPO(9)..---'70et0NOS0(9)
I w n ~ c ~ O = n 4 cn 00 (9~ NP-trace 0 (9) v0 ~ :\// , Exogran O

Exog-Sr ? 3pel-src ( 9  ) Exog-src3 ( c ) trace structure just after the cat which tran ( d ) final trace structure l ; igwe 6 . Pars in 8R clativ cC lauses
