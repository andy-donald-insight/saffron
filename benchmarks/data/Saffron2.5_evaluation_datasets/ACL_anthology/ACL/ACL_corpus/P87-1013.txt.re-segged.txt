ALOGICAL VERSION OF FUNCTION ALGRAMMAR
William C . Rounds
University of Michigan
Xerox PARC
Alexis Manaster-Ramer
IBM T.J . Watson Research Center
Wayne State University
IAb stract
Kay's functional-unification grammar notation \[5\] is a way of express in grammars which relies on very few primitive notions  . The primary syntactic structure is the feature structure  , which can be visualised as a directed graph with arcs labeled by attributes of a constituent  , and the primary structure-building operation is unification  . 
In this paper we propose a mathematical formulation of FUG  , using logic to give a precise account of the strings and the structures defined by any grammar written in this notation  . 
2 Introduction
Our basic approach to the problem of syntactic description is to use logical formulas to put conditions or constraints on ordering of constituents  , ancestor and descendant relations , and feature attribute information in syntactic structures  . The present version of our logic has predicates specifically designed for these purposes  . 
A grammar can be considered as just a logical formula  , and the structures satisfying the formula are the syntactic structures for the sentences of the language  . This notion goes back to DCG's\[0\] , but our formulation is quite different . In particular , it builds on the logic of Kasper and Rounds\[3\] , a logic intended specifically to describe feature structures  . 
The formulation has several new aspects . First , it introduces the oriented feature structure as the primary syntactic structure  . One can think of these structures as parse trees superimposed on directed graphs  , although the general definition allows much more flexibility  . In fact , our notation does away with the parse tree altogether  . 
A second aspect of the notation is its treatment of word order  . Our logic allows small grammars to define free -word order languages over large vocabularies in a way not possible with standard ID/LP rules  . It is not clear whether or not this treatment of word order was intended by Kay  , but the issue naturally arose during the process of making this model precise  .   ( Joshi \[1\] has adopted much the same conventions in tree adjunct grammar  . ) A third aspect of our treatment is the use of fixed-point formulas to introduce recursion into grammars  . This idea is implicit in DCG's , and has been made explicit in the logics CLFP and ILFP  \[9\]  . We give a simple way of expressing the semantics of these formulas which corresponds closely to the usual notion of grammatical derivations  . There is an interesting use of type ~ ariables to describe syntactic categories and/or constructions  . 
We illustrate the power of the notation by sketching how the constructions of relational grammar  \[7\] can be formulated in the logic . To our knowledge , this is the first attempt to interpret the relation alide as in a fully mathematical framework  . Although relational networks themselves have been precisely specified  , there does not seem to be a precise statement of how relational derivations take place  . We do not claim that our formalization is the one intended by Postal and Perlmutter  , but we do claim that our notation shows clearly the relationship of relational to transformational grammars on one hand  , and to lexical-functional grammars on the other . 
Finally , we prove that the satisfiability problem for our logic is undecidable  . This should perhaps be an expected result , because the proof relies on simulating Turing machine computations in a grammar  , and follows the standard undecidability arguments  . The satisfiability problem is not quite the same problem as the aniversal recognition problem  , however , and with mild conditions on derivations similar to those proposed for LFG  \[2\]  , the latter problem should become decidable . 
We must leave efficiency questions unexamined in this paper  . The notation has not been implemented . We view this notation as a temporary one , and anticipate that many revisions and extensions will be necessary if it is to be implemented at all  . Of course , FUG itself could be considered as an implementation  , but we have added the word order relations to our logic  , which are not explicit in FUG . 
In this paper , which is not full because of space limitations , we will give definitions and examples in Section 3  ; then will sketch the relational application in Section  4  , and will conclude with the undecidability result and some final remarks  . 
3 Definitions and examples 3 . 1 Or iented f - structures In this section we will describe the syntactic structures to which our logical formulas refer  . The next subsection Figure i : A typical DG . Figure 2: An oriented f-structure for a 4b4c4 . 
will give the logic itself . Our intent is to represent not only feature information  , but also information about ordering of constituents in a single structure  . We begin with the unordered version , which is the simple DG ( directed graph ) structure commonly used for non-disjunctive information  . This is formalized as an acyclic finite automaton  , in the manner of Kasper-Rounds\[3\] . Then we add two relations on nodes of the DG : ancestor and linear precedence  . The key insight about these relations is that they are partial  ; nodes of the graph need not participate in either of the two relations  . Pure feature information about a constituent need not participate in any ordering  . 
This allows us to model the " cset " and " pattern " information of FUG  , while allowing structure sharing in the usual DG representation of features  . 
We are basically interested in describing structures like that shown in Figure i  . 
A formalism appropriate for specifying such DG structures is that of finite automata theory  . A labeled DG can be regarded as a transition graph for a partially specified deterministic finite automaton  . We will thus use the ordinary 6 notation for the transition function of the automaton  . Nodes of the graph correspond to states of the automaton  , and the notation 6(q , z ) implies that starting at state ( node ) q a transition path actually exists in the graph labeled by the sequence z  , to the state 6(q , z ) . 
Let L be a set of arc labels , and A be a set of atomic feature values . An(A,L ) - automaton is a tuple . 4= ( Q , 6 , qo , r ) where Q is a finite set of states , q0 is the initial state , L is the set of labels above , 6 is a partial function from QxL to Q , and r is a partial function from terminating states of A to A  . ( q is terminating if 6(q , l ) is undefined for all l ? L . ) We require that , 4 be connected and acyclic . The map r specifies the atomic feature values at the final nodes of the DG  .   ( Some of these nodes can have unspecified values , to be unified in later . This is whyr is only partial . ) Let F be the set of terminating states of . A , and let PC . A ) be the set of full paths of , 4 , namely the set z ? L*:6 ( q0 , z ) ? F . 
Now we add the constituent ordering information to the nodes of the transition graph  . Let Z be the terminal vocabulary ( the set of all possible words , morphemes , etc . ) Nowr can be a partial map from Q to Eu A , with the requirement that if r(q ) ? A , then q ? F . Next , let a and < be binary relations on Q , the ancestor and precedence relations . We require a to be reflexive , an-tisymmetric and transitive ; and the relation < must be irrefiexive and transitive  . There is no requirement that any two nodes must be related by one or the other of these relations  . There is , however , a compatibility constraint between the two relations : v  ( q , r ,  8 , t ) ? Q : ( q <~)^( q as )^( ~ a t ) = s < t . 
Note : We have required that the precedence and dominance relations be transitive  . This is not a necessary requirement , and is only for elegance in stating conditions like the compatibility constraint  . A better formulation of precedence for computational purposes would be the " immediate precedence " relation  , which says that one constituent precedes another , with no constituents intervening . There is no obstacle to having such a relation in the logic directly  . 
Example . Consider the structure in Figure 2 . This graph represents an oriented f-structure arising from a LFG-style grammar for the language anb " cnIn > I  . 
In this example , there is an underlying CFG given by the following productions : 
S--TC
T--aT blab
C--c Clc.
The arcs labeled with numbers (1 , 2 , 3 ) are analogous to arcs in the derivation tree of this grammar  . The root node is of " category " S , although we have not represented this information in the structure  . The nodes at the ends of the arcs 1 , 2 , and 3 are ordered left to right ; in our logic this will be expressed by the formula I <  2  <  3  . 
The other arcs , labeled by COUNT and # , are feature the language . It is a little difficult in the graph representation to indicate the node ordering information and the ancestor information  , so this will wait until the next section . Incidentally , no claim is made for the linguistic naturalness of this example !  3  . 2 A presentat ion o f the log ic We will introduce the logic by continuing the example of the previou section  . Consider Figure 2 . Particular nodes of this structure will be referenced by the sequences of arc labels necessary to reach them from the root node  . These sequences will be called paths . Thus the path 12223 leads to an occurrence of the terminal symbol b . Then a formula of the form , say ,   12 COUNT -22 COUNT would indicate that these paths lead to the same node  . This is also how we specify linear precedence : the last b precedes the first c  , and this could be indicated by the formula 12223<22221  . 
It should already be clear that our formulas will describe oriented fstructures  . We have just illustrated two kinds of atomic formula in the logic  . Compound formulas will be formed using A(and) , and V ( or ) . Additionally , let I be an arc label . Then an f-structure will satisfy a formula of the form I : ?  , iff there is an /- transition from the root node to the root of a substructure satisfying ~ b  . What we have not explained yet is how the recursive information implicit in the CFG is expressed in our logic  . To do this , we introduce type variables as elementary formulas of the logic  . In the example , these are the " category " variables S , T , and C . The grammar is given as a system of equations ( more properly , equivalences ) , relating these variables . 
We can now present a logical formula which describes the language of the previou section  . 
S where
S : : ~
C :: ~

T : :-"
Vl : TA 2: CA ( I count--2 count)
A ( 1 <2 ) A ~ b 12 ( l:cA2: CA ( count #----2 count ) A ? 1 ~ )   ( i:CA ( count ~-- end ) A ~ I )   ( I : aA2:TA3:bA ( count #----2 count ) 
A(I < 2) A(2 < 3) A?1~z ) ( l:a A 2: b
A(count#: end)A(I < 2) A~b12) , where ? I ~ is the formula ( ea1)A(ea2) , in which e is the path of length 0 referring to the initial node of the f-structure , and where the other ~ formulas are similarly defined  .   ( The ~ b formulas give the required dominance information  . ) In this example , the set L-(1 , 2 ,  3 ,  # , count , the set E-a , b , c , and the set A--end . Thus the atomic symbol " end " does not appear as part of any derived string  . It is easy to see how the structure in Figure 2 satisfies this formula . The whole structure must satisfy the formula S , which is given recursively . Thus the substructure at the end of the 1 arc from the root must satisfy the clause for T , and so forth . 
It should now be clearer why we consider our logic a logic for functional grammar  . Consider the FUG description in Figure 3 . 
According to \[5 , page 149\] , this descril ~ tion specifies sentences , verbs , or noun phrases . Let us call such structures " entities " , and give a partial translation of this description into our logic  . Create the type variables ENT , S , VERB , and NP . Consider the recursive formula
ENT where
ENT : :=
S : :--
SvNPv VERB subj:NPA pred:VERB
A ( subj < pred)
A((seomp:none)V ( seomp:S
A(pred<s comp )))
Notice that the category names can be represented as type variables  , and that the categories NP and VERB are freetype variables  . Given an assignment of a set of fstructures to these type variables  , the type ENT will become well-specified . 
A few other points need to be made concerning this example  . First , our formula does not have any ancestor information in it  , so the dominance relations implicit in Kay's patterns axe not represented  . Second , our word order conventions are not the same as Kay's  . For example , in the pattern ( subjpred . . . ) , it is required that the subject be the very first constituent in the sentence  , and that nothing intervene between the subject and predicate  . To model this we would need to add the " immediately eft of " predicate  , because our < predicate is transitive , and does not require this property . Next , Kayuses " CAT " arcs to represent category information  , and considers " NP " to be an atomic value . It would be possible to do this in our logic as well  , and this would perhaps not allow NPs to be unified with VERBs  . However , the type variables would still be needed , because they are essential for specifying recursion  . Finally , FUG has other devices for special purposes . One is the use of nonlocai paths , which are used a tinner levels of description to refer to features of the " root node " of a DG  . Our logic will not treat these , because in combination with recursion , the description of the semantics is quite complicated  . The full version of the paper will have the complete semantics  . 
9\] cat = Spattern = ( subjpred . .  . ) i : i : I cat = VERB\]$corrlp - ~ . none\]pattern = ( . .  . scomp ) \]?co~p=\[~at=S\]J cat=NP\]cat = VERB\] Figure  3: Disjunctive specification iFUG . 
3.3 The formalism 3.3.1 Syntax
We summarize the formal syntax of our logic . We postulate a set A of atomic feature names , a set L of attribute labels , and a set E of terminal symbols ( word entries in a lexicon . ) The type variables come from a set TVAR = X0 , X t .   .   .   .   . The following list gives the syntactical constructions  . All but the last four items are atomic formulas . 
1 . NIL2 . TOP3 . X , in which XET VAR 4 . a , in which a EA 5 . o ', in which o " EE 6 . z < v , in which z and vEL "7 . x c ~ V , in which z and VEL "8 . \[ zt .   .   .   .   . x ~\], in which each z ~ EL = 9 .  / :$ 10 . @^ g , 11 . ~ v , ~12 . ~ b where \ [ X t : := ~ b t ; . . . X , ~ ::= ~ , \] Items ( 1 ) and ( 2 ) are the identically true and false formulas , respectively . Item ( 8 ) is the way we officially represent path equations  . We could as well have used equations like z = V , where ~ and VEL ' , but our deft-nition lets us assert the simultaneous equality of a finite number of paths without writing out all the pairwise path equations  . Finally , the last item ( 12 ) is the way to express recursion . It will be explained in the next subsection . 
Notice , however , that the keyword where is part of the syntax . 
3.3.2 Semantics
The semantics is given with a standard Tarski definition based on the inductive structure of wffs  . Formulae are satisfied by pairs ( . 4 , p ) , where , 4 is an oriented f-structure and p is a mapping from type variables to sets off-structures  , called an environment . This is needed because freetype variables can occur in formulas  . Here are the official clauses in the semantics :
NIL always;
TOP never ; xiff . 4ep(X ); a iff 7"( q0) = a , where q0 is the initial state 1 .  ( . 4, p ) 2 .  ( . 4, p ) 3 .  ( . 4, p ) 4 .  ( . 4, p ) of , 4; 5 . ( A , p ) 6 .  ( . 4, p)
T .  ( . 4, p ) 8 .  ( . 4 , p ) ~ , where o " E ~- , iff r(q0) = o';v < wiff6(q0 , v ) < 6 ( qo , w ); vaw iff 6(qo , v)a ~ ( qo , w );\[= ~ .   .   .   .   .  = . \] iff Vi,j:6(q0, zl ) = ~( qo , xj ); 9 .  ( . 4, p ) ~ l : ~ iff ( . 4/ l , p ) ~ ~, where . 4/1 is the automaton . 4 started at 6(qo , l ); 10 . ( A , p ) ~ ~^ ~ iff(A , p ) ~ ~ and ( A , p ) ~ ~; 11 .  ( . 4, p ) ~ ~ V ~ b similarly ; 12 .  ( . 4, p ) ~ ~ b where\[Xt ::= Ot; .   .   . X , : := 0n \] iff for some k , ( . 4 , p(~))~~b , where p ( k ) is defined inductively as follows : ? p ( ?  )   ( xo = 0 ; ? p(k+~)(X d=BI(~ , p(~))\[= , ~ , , and where p(k)(X ) = p(X ) if X # Xi for any i . 
We need to explain the semantics of recursion . Our semantics has two presentations . The above definition is shorter to state , hut it is not as intuitive as a syntactic , operational definition . In fact , our notation ~ b where \ [ Xt : := ~ bl .   .   .   .   . Xn::-~bn\]in ? . Of course , the Cs may contain free occurrences of certain X variables  , so we need to do this same replacement process in the system of Cs beforehand  . It turns out that the replacement process is the same as the process of carrying out grammatical derivations  , but making replacements of nonterminal symbols all at once  . 
With this idea in mind , we can turn to the definition of replacement . Here is another advantage of our logic- replacement is nothing more than substitution of formulas for type variables  . Thus , if a formula 0 has distinct freetype variables in the set D = X t  .   .   .   .   . An , and Ct, .   .  -  ,  ? , are formulas , then the notation denotes the simultaneous replacement of any free occurrences of the Xj in  0 with the formula Cj , taking care to avoid variable clashes in the usual way  ( ordinarily this will not be a problem . )
Now consider the formula ? where\[Xt ::= Ct; .  -  . X , ::=?,\] . 
The semantics of this can be explained as follows . Let D = XI . . . . . X , ~ , and for each k_> 0 define a set of formulas ? ~ k ) \[I_<i_<n . This is done inductively on k : ~ o ) = ? , \[X*--TOP:XED\];?(k+1) . - elk ) i = ~' i\[X : X eO\] . 
These formulas , which can be calculated iteratively , correspond to the derivation process . 
Next , we consider the formula ? . In most grammars , ? will just be a " distinguished " type variable , say S . If (`4 , p ) is a pair consisting of an automaton and an environment  , then we define (`4 , p ) ~ ? where\[Xt : := ? i; .   .   . X , t : := ?,\] iff for some k , ( . 4, p ) ~?\[ X ,,- elk ): X , ED\] . 
Example . Consider the formula ( derived from a regular grammar ) 
S where
T "' ~ ( I : aA2:S ) V ( I : hA2:T ) Vc ( I:bA2:S ) V ( I : aA2:T ) Vd . 
Then , using the above substitutions , and simplifying according to the laws of Kasper -Rounds  , we have ?( so )
C , ?~) = d;
CH ) = (1: aA2: c)V (1: bA2:d)V c ; ?(~) = (1:bA2:c)V (1: aA2:d)Vd ; ?(2) = I:aA2:(I:aA2:c)V ( I:bA2:d)Vc)
Vl : bA2:((l:bA2:c)V(l:aA2:d)Vd)

The fstructures defined by the successive formulas for S correspond in a natural way to the derivation trees of the grammar underlying the example  . 
Next , we need to relate the official semantics to the derivational semantics just explained  . This is done with the help of the following lemmas  . 
Lemma 1(`4, p ) ~?~) ~(`4, p(k )) ~? i.
Lemma 2(`4, p)~0\[Xj--? . /: X . /ED\]iff(`4 , p ') O , where p?(Xi ) = B\](B , p ) ~? i , if XiED , and otherwise is p(X ) . 
The proofs are omitted.
Finally , we must explain the notion of the language defined by ?  , where ? is a logical formula . Suppose for simplicity that $ has no freetype variables  . Then the notion A ~0 makes sense , and we say that a string wEL ( ~ b ) iff for some subsump fion . minirnal f-structure , 4 , A ~? , and w is compatible with , 4 . The notion of subsumption is explained in \[8\] . Briefly , we have the following definition . 
Let , 4 and B be two automata . We say , 4_B ( . 4 subsumes B ; Bext end s ` 4 ) iff there is a homomorph is rn from `4 to B ; that is , a maph:Q . 4 - - Qs such that ( for all existing transitions )  1 . h(6 . ~( q , l )) = 6B(h(q ), l); 2 . r(h(q )) = r(q ) for all q such that r(q ) EA ;  3 . h(qoa ) = q o ~ . 
It can be shown that subsurnption is a partial order on isomorphism classes of automata  ( without orderings )  , and that for any formula 4 without recursion or ordering , that there are a finite number of subsumption -minimal automata satisfying it  . We Consider as candidate structures for the language defined by a formula  , only automata which are minimal in this sense . The reason we do this is to exclude fstructures which contain terminal symbols not mentioned in a formula  . For example , the formula NIL is satisfied by any f-structure , but only the minimal one , the one-node automaton , should be the principal structure defined by this formula  . 
By compatibility we mean the following . In an f-structure `4 , restrict the ordering < to the terminal sym-bois of  , 4 . This ordering need not be total ; it may in fact be empty . If there is an extension of this partial order on the terminal nodes to a total order such that the labeling w  , then w is compatible with A . 
This is our new way of dealing with free word order  . 
Suppose that no precedence relations are specified in a formula  . Then , minimal satisfying fstructures will have an empty < relation  . This implies that any permutation of the terminal symbols in such a structure will be allowed  . Many other ways of defining word order can also be expressed in this Logic  , which enjoys an advantage over
ID/LP rules in this respect.
4 Modeling Relational Grammar
Consider the relational analyses in Figures 4 and 5  . 
These analyses , taken from \[7\] , have much in common with functional analyses and also with transsformational ones  . The present pair of networks illustrates a kind of raising construction common in the relational literature  . 
In Figure 4 , there are arc labels P , I , and 2 , representing " predicate " , " subject " , and " object " relations . The " cl " indicates that this analysis is at the first linguistic stratum  , roughly like a transformational cycle . In Figure 5 , we learn that at the second stratum , the predicate ( " believed " ) is the same as at stratumi , as is the subject . 
However , the object at level 2 is now " John " , and the phrase " John killed the farmer " has become a " chSmeur " for level  2  . 
The relational network is almost itself a feature structure  . To make it one , we employ the trick of introducing an arc labeled with l  , standing for " previous level " . The conditions relating the two levels can easily be stated as path equations  , as in Figure 6 . 
The dotted lines in Figure 6 indicate that the nodes they connect are actually identical  . We can now indicate precisely other information which might be specified in a relational grammar  , such as the ordering information I < P < 2 . This would apply to the " toplevel " , which for Perlmutter and Postal would be the " final level "  , or surface level . A recursive specification would also become possible : thus 
SENT::=CLAUSEA(I < P < 2)
CLAUSE : := I:NOMAP:VERB
A2: ( CLAUSEVNOM )
A(RAISE VPASSIVEV ...)
AI:CLAUSE l:2: CLAUSEA ( equations in ( 6 ) ) RAISE ::= This is obviously an incomplete grammar  , but we think it possible to use this notation to give a complete specification of an RG and  , perhaps at some stage , a computational test . 
5 Undecidability
In this section we show that the problem of sa ( is/ia-bility-given a formula , decide if there is an f-structure satisfying it- is undecidable  . We do this by building a formula which describes the computations of a given Turing machine  . In fact , we show how to speak about the computations of an automaton with one stack  ( a pushdown automaton . ) This is done for convenience ; although the halting problem for one-stack automata is decidable  , it will be clear from the construction that the computation of a two-stack machine could be simulated as well  . This model is equivalent to a Turing machine- one stack represents the tape contents to the left of the TM head  , and the other , the tape contents to the right . We need not simulate moves which read input , because we imagine the TM started with blank tape  . The halting problem for such machines is still undecidable  . 
We make the following conventions about our PDA.
Moves are of two kinds : ? qi : push b ; go to qj ; ? qi : popstack ; if a go to q j else go to q k . 
The machine has a two-characters tack alphabet a , b . 
( In the push instruction , of course pushing " a " is allowed . ) If the machine attempts to pop an empty stack , it cannot continue . There is one final state q f . The machine halts sucessfully in this and only this state  . We reduce the halting problem for this machine to the satisfiability problem for our logic  . 
Atoms : " none . . . . . bookkeeping marker for telling what is in the stack qO  , ql .   .   .   .   . qn---one for each state
Labels : a , b---for describing stack contents s--pointer to top of stack next---value of next state p-- -pointer to previous stack configuration 
Type variables :
CONF--structure represents a machine configuration 
INIT0FINAL--confi~trations at start and finish
QO . . . . . QN : property of being in one of these states The simulation proceeds as in the relational grammar example  . Each configuration of the stack corresponds to a level in an RG derivation  . Initially , the stack is empty . 
Thus we put b~p ca .

Figure 5: Network for The woman believed John to have killed the farmer  . 
p = lp1 = ll2 = 121
Chop = 12P
Cho2"122
Figure 6: Representing Figure 5 as an f-structure.

INIT::=s:(b:noneAa:none)Anerl;:q0 . 
Then we describe standard configurations : C0//F ::= ISITV ( p : CONFA ( QOV .   .   . VQN )) . 
Next , we show how configurations are updated , depending on the move rules . If q ? is push b ; go to qj , then we write QI ::= nex ~: qjAp:next:qiAs:a : none Asb = ps  . 
The last clause tells us that the current stack contents  , after finding a % " on top , is the same as the previous contents . The %: none " clause guarantees that only a %" is found on the DG representing the stack  . The second clause enforces a consistent state transition from the previous configuration  , and the first clause says what the next state should be  . 
If q ? is pop stack ; if a go to qj else go to qk , then we write the following . 
QI::=p:nex~:qi
A((s = psaAnex ~:: qjAp:s:b:none)
V(s = psbA next:qkAp:s:a:none))
For the last configuration , we put
I~F::----C011FAp:nex~:qf.
We take QF as the " distinguished predicate " of our scheme  . 
It should be clear that this formula , which is a big where-formula , is satisfiable if \[" the machine reaches state q f  . 
6 Conclusion
It would be desirable to use the notation provided by our logic to state substantive principles of particu-lax linguistic theories  . Consider , for example , Kashket's parser for Warlpiri\[4\] , which is based on GB theory . For languages like Warlpiri , we might be able to say that linear order is only explicitly represented at the morphemic level  , and not at the phrase level . This would translate into a constraint on the kinds of logical formulas we could use to describe such languages : the < relation could only be used as a relation between nodes of the MORPHEME type  . Given such a condition on formulas , it might then be possible to prove complexity results which were more positive than a general undecidability theorem  . Similar remarks hold for theories like relational grammar  , in which many such constraints have been studied . We hope that logical tools will provide a way to classify these empirically motivated conditions  . 
References\[1\]Joshi , A . , K . Vijay-Shanker , and D . Weir , The Convergence of Mildly Context-Sensitive Grammar Formalisms  . To appear in T . Wasow and P . Sells , ed . 
" The Processing of Linguistic Structure " , MIT Press . 
\[2\] Kaplan , R . and J . Bresnan , LFG : a Formal System for Grammatical Representation  , in Bresnan , ed . The Mental Representation of Grammatical Relations  , MIT Press , Cambridge ,  1982 ,  173-281 . 
\[3\] Kasper , R . and W . Rounds , A Logical Semantics for Feature Structures , Proceedings of e4th ACL Annual
Meeting , June 1986.
\[4\] Kashket , M . Parsing a free word order language : Warlpiri . Proc . 24th Ann . Meeting of ACL , 1986, 60-66 . 
\[5\] Kay , M . Functional Grammar . In Proceedings of the Fifth Annual Meeting of the Berkeley Linguistics Society  , Berkeley Linguistics Society , Berkeley , California , February 1719 ,  1979 . 
\[6\] Pereira , F . C . N . , and D . Warren , Definite Clause Grammars for Language Analysis : A Survey of the Formalism and a Comparison with Augmented Transition Networks  , Artificial Intelligence 13 ,  (1980) ,  231-278 . 
\[7\] Perlmutter , D . M . , Relational Grammar , in Syntax and Semantics , voi . 18: Current Approaches to Syn-taz , Academic Press ,  1980 . 
\[8\] Rounds , W . C . and R . Kasper . A Complete Logical Calculus for Record Structures Representing Linguistic Information  . IEEE Symposium on Logic in
Computer Science , June , 1986.
\[9\] Rounds , W . , LFP : A Formalism for Linguistic Descriptions and an Analysis of its Complexity  , Computational Linguistics , to appear . 

