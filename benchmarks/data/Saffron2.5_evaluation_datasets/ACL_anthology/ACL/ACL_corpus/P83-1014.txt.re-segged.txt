A Finite-Slate Parser for Use in Speech Recognition 
Kenneth W . Church

Massachusetts Institute of Technology
Cambridge , MA .02139
This paper is divided into two parts .   1 The first section motivates the application of finite-state parsing techniques at the phonetic level in order to exploit certain classes or " contextual constraints  . -In the second section , the parsing framework is extended in order to account\['or ' feature spreading '  ( i: . g . , agreement and coarticulation ) in a natural way . 
I . Parsing at the Phonetic Level
It is wellknown that phonem cs have different acoustic/phonetic realizations depending on the context  . Fur example , the phoneme/t/is typically realized with a different all ophone  ( phonetic variant ) in syllable initial position than in syllable final position  . In syllable initial position ( e . g . , Tom) , /t / is almost always released ( with a strong burst of energy ) and aspirated ( with h-like noise )  , whereas in syllable final position ( e . g . , cat . ) , /t / is often unreleased and unaspirated_It is common practice in speech research to distinguish acoustic/phonetic properties that vary a great deal with context  ( e . g . , release and aspiration ) from those that are relatively invariant to context  ( e . g . , place , manner and voicing ) . 2 In the past , the emphasis has been on invariants ; allophonic variation is traditionally seen as problematic for recognition  . 
(I ) " In most systems for sentence recognition , such modifications must be viewed as a kind of ' noise ' that makes it more difficult to hypothesize lexical candidates given an input phonetic transcription  . To see that this must be the case , we note that each phonological rule \[ in an example to be presented below \] l  , This research was ~ pported ( in part ) by the National Institutes of I lealth Grant No .   1 POtIM 03374-01 and 03374-02 from the National Library of Medicine ,  2 . Place refers IO the location of the constriction in the vocal tracLExamples include : labialt'at the hpsl/p  , b . f , ', . m /, velar / k , g . r ~/ , dental ( at the teeth)/s , z , t . d , I , n/and palatalA ,  ;~ , i: , '/ Manner dislmgu ~ shes among vowels , liquids and slides ( e . g . ,/1, r , y . 
w/t . fricatives le . s . ,/s , z , f . v/t , nasals(e . g . ,/ n . m . rio and stopsleg,/p , t,k,b,d,g /) . 
Voietng ( periodie ~, ibration of the vocal fold . s ) disting m shes sounds like/b , d . S/from sounds like/p,L,k . / . 
results in irreversible ambiguity-the phonological rule does not have a unique inverse that cuuld be used to recover the underlying phonemic representation for aie  , xical item . l : or example . . . . schwa vowels could be the first vowel in a word like ' about ' or the surface realization of almost any English vowel appearing in a sufficiently destressed word  . The tongue tlap\[El could have come from a/t / ora / d /  . " Klatt(MIT)\[21, pp .   548-5491 This view of all ophonic variation is representative of much of the speech recognition literature  , especially during the ARPA speech project . One can find similar statements by Cole and Jakim ~kICMU  ) \[5\] and by Jelinek ( IBM ) \[17\] . 
I prefer to think of variation as use fid . It is wellknown that a tlo-phonic contrasts can be distinctive  , as illustrated by the following famous minimal pairs where the crucial distinction seem to lie in the allophonic realization of the / t /:  ( 2 at a tease/atease aspirated/flapped ( 2b ) nightrate/ni-trateun reteased/retroflexed ( 2c ) great wine/gray twine unreteased/rounded This evidence suggests that all ophonic variation provides a tich source of constraints on syllable structure and word stress  . The recognizer to be discussed here ( and partly tmplcmented in Church\[4\] ) is designed to exploit all ophonic and phonotactic cues by parsing the input utterance into syllables and other suprasegmental constituents using phrase-structure parsing techniques  . 
1.1 An Example of Lexical Retrieval
It might be helpful to work out an example it \] order to illustrate how parsing can play a role in l  . exica \] retrieval . Consider the phonetic transcription , mentioned above in the citation from Klatt\[20 , p . 1346\]\[2\], pp . 548-549 J : It is desired to decode ( 3 ) into the string of words : ( 4 ) Did you hit it to Tom ? In practice , the lexical retrieval problem is complicated by errors in the front cad  . However , even with an ideal error-free frontend , it is difficult to decode (3) because , among other things , there are extensive nile-governed changes affecting the way that words are pronounced in different sentence contexts  , as Klatt's example illustrates : ( 5a ) Pabtalization of/d/before/y/indid you ( 5b ) Reduction of unstressed/u/to schwain )  , ~ u(5c ) Flapping of intervocalic/t/in hit . it ( 5d ) Reduction of schwa and devoicing of / u/into ( 5e ) Reduc:ion of gemin ate/t/init . to These allophonic processes often appear to neutralize phonemic distinctions  . For example , the voicing contrast between / t / and / d / . 
which is usually distinctive , is almost completely lost in wr~er/rid_er , where bod ~/ t / and / d/are realized in Americ an English with a tongue ~ ap  ( q . 
1 . 2  . \n Ogtimistic " v'i cw of Neutralization Fortunately  , there are many fewer cases of true neutralization than it might seem  . Even in writ . er/ri~ . er , the voicing contrast is not completely lost . The vowel in rider tends to be longer than the vowel in w~ter due to a general process that lengthens vowels before voiced consonants  ( e . g . , / d / ) and shortens them before unvoiced consonants ( e . g . ,/t/) . 
A similar lengthening argument can be used to separate In/and/ndl  ( at least in some cases )  . It tmght be suggested that In/is merged with /nd/bya/d/deletion rule that applies in words like mena ~ wind  ( noun )  . wind (', erbL and find .   ( Admittedly there is little if any direct acoustic evidence fi  ) ra/d/segment in this environment . ) However , \[ suspect hat these words cano ) ~ enbe distinguished from men , win . 
) vttte . and fine mostly on the basis of the duration of then a salmur mur which is lengthened in the precedence of a voiced obstruent like / d /  . 
Thus , this/d/-detction process is probably not a true case of neutralization  , Recent studies in acoustic/phonetics seem to indicate that more and more cases of apparent neutralization can be separated as the field progresses  . For instance , it has been said that/s/merges with f~/in a context like ga ~ shortage  \[12\]  . lh)we~cr , a recent experiment 1271 suggests that the/s~/sequence can be distinguished from / ~  , ~/ lasin fisth shortage ) on the basis of a spectral tilt : the/s , ~/' spectrum is more/s/-like in the beginning and more / ~  , /- like at the cad , whereas the f~spectrum is relatively constant hroughout  . A similar spectral tilt argument can be used to separate other cases of apparent gemination  ( e . g . ./z~'/in ~ the) . 
As a final example of apparent n cutra ! ization , consider the portion of the spectrogram in Figure  !  , between 0 . 85 and 1 . 1 seconds . 
This corresponds to the two adjacent/t/s in Did you hit it to Tom ? Klattanalyzed this region with a single geminated / t /  . However , upon further investigation of the spectrum , I believe that there are acoustic cues for two segments  . Note especially the total energy , which displays two peaks at 0 . 95 and 1 . 02 seconds . On the basis of this evidence , I will replace Klatt's transcription ( 6a ) with ( 6b ) :  ( 6a ) \[ dl\]a hlf . lutaml (6b )\[ dl\]i hll'Ittlmml
U 1.3 Parsing and Matching
Even though 1 might be able to reinterpret many cases of apparent neutralization  , it remains extremely difficult to " undo " the allophonic rules by inverse transformational parsing techniques  . Let me suggest an alternative proposal , l will treat syllable structure as an intermediatelvel of representation between the input segment lattice and '  , he output word lattice . In so do ing , I have replaced . : . he lexical retrieval problem with two ( hopefully simpler ) problems : ( a ) parse the segment lattice into syllable structure  , and ( b ) match the resulting constituents a ~ ains the lexicon  . I will illustrate the approach with Fig . I . Did you hit it to Tom ?,-, ~ . ( . .~ . ) o , 0 Pitoi Z . oi . ~ 0  . 406 o . e0 . 7O . a 0 . 9 l . o1 . It , Z1 . 3 :  . 4 l . eas , : ~ o'; Laer ? ~-- t ~, 6 HIm 76OH 8 .   .   .   .   .   .   .   .   . 
-, o ~ .   .   .   .   . --~-~-,;---~-'~-;';'i'L " .   .   .   . ; "~' ~'~ :" ~ , , ill , Igll , , , . Irdli Wavetom ~ ~ ~ IL .  ~ ~,  .   . 
I . _J . ~L , I ', I .   . tI,L-t_~!I- . 1L . \] Il II
Did you hit it to Tom and glottalization ) :  ( 7 ) \ [ dr jighlffthtthaml

Using phonotactic and allophonic on straints on syllable structure such as:  3   ( 8a ) /h / is alway syllable initial , phonotactic (8b )\[1" I is alway syllable final , allophonic (8c )\[?\] is alway syllable final , and allophonie ( Sd ) \[ th\] is alway syllable initial , allophonic the parser can inser the following syllable boundaries :  ( 9 ) \[ di ~ #hlf . #I ? #tht#tham\]It is now it is relatively easy to decode the utterance with l cxical matching routine similar to those in Smith's Noah program at CMU  241  . 
parsed transcription , decod in ldl\]~- . . . ? did you hlf = -- . .* hit l ? -=+ it th ) --- . , to tham --- , Tom In summary , I believe that the lexical retrieval device will be in a superior position to hypothesize word candidates if it exploits all ophonic and phonotactic constraints on syllable structure  . 
1.4 Exploiting Redund : mey
In many cases , atlophonic and phonotacd constraints are redundant  , Even if the parser should miss a few of the cues for syll ~ i bie structure  , it will often be able to find the correct structure by taking advantage of some other edundamcue  . \[: or example , suppose that the frontend failed to notice die glottalized/t  . /in the word it . 
(10) dl\]i9  #hlf_  #I  #tha  #tham

The parser could deduce that the input transcription  ( 10 ) is internally inconsistent , because of a phonotactic constraint on the lax vowel/I /  . 
3 . This formulation f theeonst /' aints is over simplified  forexlx3  , sltory convenience ; see\[10 . lJ .   15\] and references the ret of r discussion f the more subtle issues  . 
Lax vowels are restricted to closed syllables ( sylkdgles ending in a consonant ) \[ I\] . However , in this case ,   /1/ cannot mcct the closed syllable restriction because the following consonant is aspirated  ( arid there f i ) resyllable initial )  . Thus the transcription is internally inconsistent  . The parsers hotlld probably rejcct tbc transcriot ; ? , n ~ m d hope that the frontend can fix dxe problem  . Alternatively , the parser might attempt to correct he error by hypothesizing a second / t /  . 4 There are many other examples like ( 10 ) where phonotactic constraints and allophonic constraints overlap  . Consider the pairs found in figure 2 , where there are multiple arguments for assigning the crucial syllable boundary  . In de-prive vs . dep-rivalion , for instance , the difference is revealed by the vowel argument above  5 and by the aspiration rule . 6 In addition , the stress contrast will probably be correlated with a number of socalled's upra segmental ' cues  , e . g . , duration , fundamental frequency , and intensity\[81 . 
In general , there seem to be a large number of multiple low level cues for syllables trt  , cture . This observation , if correct , could be viewed as a form of a ' constituency hypothesis '  . Just as syntacticians have argued for the constituent-hood f noun phrases  , verb phrases and sentences on the grounds that these constituents seem to capture crucial linguistic generalizations  ( e . g . , question formation , wh-movement ) , so too , I might argue ( along with certain phonologists such as Kahn \[13\]  ) that syllables , on sets , and rhymes are constituents because they also capture important generalizations such as aspiration  , tensing and laxing . 
If this constituency hypothesis for phonology is correct  ( and I believe
Fig .  2 . Some Structural Contrnstsr !_w t2 de-prive dep-rivationta-ttribute att-ributeli decrease dec-riment b celebration cel cb-rity da -ddress add-tessg degrade degradation di-plomacy dip-lumatic decline a-cquire dec-lination acq -uisition o-bligatory ob-ligation  4  . Personally . 1 favor the first alternative : after years of , . , . smessmg Victor Zue read spectrograms . I have become most m pressed with the richness of low level phonetic cues  . 
5 . The syllable de . is open because the vowel is tense ( diphthongiz cd ) : dep " is dosed because the vowel is lax6 . lhe/p/m-prt ve is syllable in ttml because it tsa  . sptrated whereas the/p/indep " is s ) liable final because it is unaspirated . 
93 that it is ) then it seems F ~ a tural to propose a syllabic parser fi  ) r proccss it ~ g speech , by analogy with sentence parsers that have bccome standard practic cind ~ enaturallaoguag c community for processing  . ~ ext . 
2 . Parser Implementation and Feature Spreading A program has bcen impl cm cnt cd  \[41 which parses a lattice of phonetic segmcnts into a lattice of syllables and other phonological constituents  . Except for its nov cl mechanism for handling features  , it is very much like a standard chart parser ( e . g . . Earley's Algorithm lTD . 
P , c call that a chart parser takes as input a sentence and a contextfree grammar and produces as output a chart like that below  , indicating the starting point and ending point of each phrase in the input string  . 
lnput ~ Sentenc ( l : 0 Theytare 2 flying 3 planes 4

N " - - - * they V - - - * are N - - * t l ? ing
A-"*flying V---*flying N--~planes
S--*NP VP VP-..* VNP VP---.~ VVP
NP ~ NNP ~ APNP NP "-* VPAP -'* A('n , , . r t : o o(i ! 1 2 !
I23#Xt ', N , they SS SVP . V . are ) VP ( VP\[NP . VP,AP,N . V , A , flying NP . VP (( NP , N . planes lb Lach entry in the chart represents the possible analyses of the input words between a start position  ( the row index ) and a finish position ( the column index )  . \[-' or example , the entry NP , VP in Chart (2 , 4 ) represents two alternative analyses of the words between  2 and 4: \[ xp fi3ulg pia , esl add\[vpflying planesl . 
.the same parsing methods can be used to find syllable structure from an input transcription  . 
lod ) u\[Sentence:O ~" ? t2S3 l4Z5 ( this ~ ) 
Grammar : onset ~~'\[ SIZ peak - - - ) it\[coda-- . --) ~'\[ SIZ syl----)( onset ) peak ( coda)
Chart : otzst4s(I
I 234 . ~ , \[ . on set . codasylsyl !, pcak . sylsyl)S . onset . codal ( sylsyll , peak . sylsyl Z , onset . cod a )    (   ( I ( This chart shows that the input sentence can be decomposed into two syllables  , one from 0 to 3 ( this ) and another one from 4 to 5 ( is )  . 
Alternatively , the input sentence can be decomposed into \[~' t\ ]\ [ slzl  . In this way . standard chart parsing techniques can be adopted to process all ophonic and phonotactic constraints  , if the constraints are reformulated in terms of a grammar  . 
How can allophonic and phonotactic constraints be cast in terms of contextfree rules ? In many cases  , the constraints can be carried over in a straightforward way  . For example , the following set of roles express the aspiration constraint discussed above  . These rules allow aspiration in syllable initial position  ( under the onset node )  , but not in syllable final position ( under the coda )  . 
( l la ) utt crancc--- ) syllable * ( lib ) syllable ~ ( on set ) peak ( cod a )   ( II . c ) on set--*aspirated-t\[aspirated-kI aspirated - pI  . , . 
( lld ) coda --- , unrel cascd-t Iun rcl cased-k I unr cleased-pI- . -The aspiration constraint ( as stated above ) is relatively easy to cast in terms of contextfree rules  . Other allophonic and pho~aot actic processes may be more difficult  .  7 2 . .1 The Agreement Problem In particular , contextfree roles are generally considered to be awkward for expressing agreement facts  . For example , in order to express subject verb agreement in "' pure " contextfree rules  , it is probably necessary to expand the rule S ~ NP VP into two cases :  ( 12 a ) S---* singular-NP singular-VP singular case ( 12b ) S - - ) plural-NP plural-YP plural case 7 . For example , there may be a problem with constraint S that depend on rule ordering  , since rule or denng is not supported in the contextfree formalism  . This topic is discussed at length in I41 . 

The agreement problem also arises in phonology . Consider the example of homorganic nasal clusters  ( e . g . , cam2II2 , can't , sank ) , where then a salagrees with the following obstruent in place of articulation  . 
That is , the labial nasal/m/is found before the labial stop/p/  , the cor9nal nasal/n/before the coronal stop/t / , and the velar nasal/7// before the velar stop / k / . This constraint , like subject verb agreement . 
poses a problem for pure unaugmented contextfree rules  ; it seems to be necessary to expand out each of the three cases :  ( 13 a ) homorganic-nasal-cluster ~ labial-nasallabial -obstruent  ( 13 b ) homorganie-nasal-cluster ~ coronal-nasal coronal -obstruent  ( 13 c ) homorganic-nasal-cluster---*velar-nasalvelar -obstruent In an effort to alleviate this expansion problem  , many researchers have proposed augmentations of various sorts  ( e . g . , ATN registers \[26\] , LFG constraint equations\[16\] , GPS Grecta-rule still , local constraints\[18\] , bit vectors\[6 ,  22\]) . My own solution will be suggested after I have had a chance to describe the parser in further detail  . 
2 . . 2 A Parser Based on Matrix Operations This scction will show how the grammar can be implemented in terms of operations on binary matrices  . Suppose that the chart is decomposed into a sum of binary matrices :  ( 14 ) Chart = syI + on set Monset+peakMpeak + . , . 
where MsyI is a binary matrix 8 describing the location of syllables and Mons et is a binary matrix describing the location of on sets  , and so forth . 
Each of these binary matrices has a I in position ( i , j ) if there is a constituent of the appropriate part of speech spanning from the imposition in the input sentence to the jth position  . 9 ( See figure 3) . 
Ph'rase-structure rules will be implemented with simple operations on these binary matrices  . For example , the homorganic rule ( 13 ) could be implemented as : 8 . Fhese matnccs will sometimes be called segment att on lattices for historical reasons  . 
Techmcally . the sematnc ~ need not conform to the restrictions of a lattice  , and therefore , the weaker term graph L~more correcL 9 In a probabitisuc framework , one could replace all of the I's and 0's with probabdities . 
A high prohabdity mloeau on ( i . j  ~ of thes ) , liable matn x would say that here probably is as s ' llahle from postuon t to position  1:a low probabdity would say that here probably isn't a syllable between i and  1  . Most of the following apphcs to probabdity matrices welt as binary ntawices  , though the probabdity matnces may be less sparse and consequently less efficient  . 
Fig .  3 . Msyl , Monse and Md tyme for : " O ' ~ It Z s 3 I 4 z 5"   001100   010000   000000   001100   000000   001100   000011   000100   000000   000011   000001   000011   000000   000000   000000   000000   000000   000000 The matrices tend to be very sparse ( a hnost entirely full of 0's ) because syllable grammars are highly constrained . In principle , there could be n2 entries . However , it can be shown that e ( the number of l's ) is linearly related to n because syllables have finite length  . In Church\[4\] , I sharp en this result by arguing that e tends to be bounded by  4n as a consequence of a phonotactic principle known assonority  . Many more edges will be ruled out by a number of other linguistic constraints mentioned above : voicing and place assimilation  , aspiration , flapping . 
etc . In short , these mamces are sparse because allophonic and phonotactic constraints are useful  ( 15 )   ( set qhomorganic-nasal-lattice ( M + ( M * ( phoneme lattice#/m ) labial-lattice )   ( M * ( phoneme lattice#/n ) coronal-lattice )   ( M * ( phoneme lattice#/G ) velar-lattice ) ) ) illustrating tile use of M + ( matrix add it it ) n ) ttt express the uniun of several alternatives and M *  ( matrix multiplication ) to express the concatenation of subparts . It is wellknown that any finite-state grammar could be implemented in this way with just three matrix operations : M  , , M + , and M ** ( transitive closure ) . If contextfree power were required , Valient's algorithm\[25\] could be employed . 
However , since there doesn't seem to be a need tbr additional generative capacity in speech applications  , the system is restricted to handle only the simpler finite state case  .  1? 2 . . 3 Feature Manipulation Although " pure " unaugmented finite state grammars may be adequate furspeech applications  ( in the weak generative capacity sense )  , \[ may , nevertheless , wish to introduce additional mechanism in order to account for agreement facts in a natural way  . As discussed above , the formulation of the homorganic rule in ( 15 ) is unattractive because it splits the rule into three cases  , one for each place of articulation . It would be preferable to state the agreement constraint just once  , by defining a homorganic nasal cluster to be a nasal cluster  \]0  . I personally hold a much more controversial posution  , that in itestate grammars are sufficient for most  . if not nil , natural language ) - asks\[3\] . 
95 subject top hlcc assimilation . In my language of matrix operations , I can say just exactly that : ( 16 )   ( set qhomorganic-na~l-cluster-lattice ( M&nasal-cluster-lattice place-assimilation ) ) where M & ( elementwise intersection ) implements the subject to constraint . Nasal-cluster and place-assimilation are defined as:  ( 17 a )   ( set qn as al-cluster-lattice ( M . nasal-lattice obstruent-lattice ) )  ( 17 b )   ( set q place-assimilation-lattice ( M + ( M * * labial-lattice )   ( M " dental-lattice )   ( M ' " velar-lattice ) ) ) In this way . M& seems to be an attractive solution to the agreement problem  . 
In addition , M&might also shed some light on coarticulation , another problem of ' feature spreading ' . Co-articulation ( articulation of multiple phonemes at the same time  ) makes it extremely difficult ( perhaps impossible ) to segmen the speech wave form into phoneme-co -articulation  , Fujimurasu ~ csts that place , manner and other articulatory features be thought of as a synchronous processes  , which have a certain a motmt of freedom to overlap in time  . 
(tSa ) " Speech is commonly viewed as the result of concatenating phonetic segments  . In most discussions of the temporal structure of speech  , a segment in such a model is assumed to represent a phoneme-sized phonetic unit  . which possesses an inherent\[invariant j target value in terms of articulation or acoustic manifestation  . Any deviation from such an interpretation of observed phenomena requires special attention  . . . \[ Biased on some preliminary results of X-ray microbeam studies \[ which associate lip  , tongue and jaw movements with phonetic events in the utterance J  , it will be suggested that understanding articulator '/ processes  , which are inherently multidimensional \[ and ( more or less ) a synchrouous l , may be essential for a successful description of temporal structures of speech  . "\[9 p . 66\] Inlight of Fujimura ' suggestion , I might reinterpret my parser as a highly parallel feature-based asynchronous architecture  . For example . 
the parser can processhom organic nasal clusters by processing place and manner phrases in parallel  , and then synchronizing the results at the coda node with M&  . That is , (17a ) can be computed in parallel with (17b ) . mid then the rcsulLs are aligned wh cn the coda is computed with  ( 16 )  , as illustrated below for the word tent . Imagine that the frontend produces the following analysis :  ( 19 ) tant dental:III .   .   .   .   . 
vowel : I- .   . I stop:I . II .   .   .   .   . In a salization : I .   . I where many of the ~ atures overlapman a synchronous way  . The parser will correctly locate the codaby intersecting the nasal cluster lattice  ( computed with ( 17 a ) ) with the homorganic lattice ( computed with ( 17b ) ) . 
(20) tant nasal cluster : I .   .   .   .   .   .   . Jhomongan Jc:I .   .   .   .   . Icoda:I .   .   .   .   . I This parser is a bold departure from a standard practice in two respects :  ( 1 ) the input stream is feature-based rather than segmental  , and ( 2 ) the output parse is a heterarchy of overlapping constituents  ( e . g . , place and manner phrases ) as opposed to a list of hierarchical parse-trees . \[ find these two modifications most exciting and worthy of further investigation  . 
In summary , two points have been made . \[: irst . I suggested the use of parsing techniques at the segmental/feature level in speech applications  . Secondly , I introduced M&as a possible solution to the agreement/co-articulation problem  . 
3 . Ack , mwledgements l have received a considerable amount of help and support over the course of this project  . Let me mention just a few of the people that I should thank : Jon Allen  , Glenn Burke , Francine Chen , Scott Cyphers , Sarah I-ergt , son . . , ' v largaret Fleck , Dan Huttenlocher , Jay Kcyser , Lori Lame L Ramesh Patil . Janet Pierrehumbert , Dave Shipman , Pete Szolovits . Meg Withgott and Victor Zue . 
References 1 . Bamwell , T . , An Algorithm for Segment Durations in a Reading Machine Context  , unpublished doctoral dissertation , department of Electrical Engineering and
Computer Science , M1T . 1970.
LChomsky . N . and Halle , M . , The Sound Pattern of ~' nglish,
Harper & R.ow , 1968.
3 . Church , K . , On Memoo ' Limitations in Natural Language Processing  , MS Thesis , MIT , Mr\['/I , CS/TR-245 ,  1980  ( also available from Indiana University Linguistics Club  )  . 
96 4 . Church , K . , PhraseStructure l'arsing : A Method lbr Taking Advantage of Allophonic Constraints  , unpublished doctoral dissertation , department of I-' , lectrical Engineering and Computer Science , MIT , 1983 ( also to appear , I . CS and RLE publications , MIT) . 
5 . Cole , R . , and Jakimik , J . , A Model of Speech Perception , in R . Cole ( ed . ) . Perception and l'roduction of Fluent Speech , Lawrence Erlbaum , Hi Ilsdale , N . J . , 1980 . 
6 . Dostert . B . , and Thompson , F . , How Features Resolve Syntactic Ambiguity , in Proceedings of the Symposium on Information Storage and Retrieval  , Minker . J . , and
Rosenfeld , S . (? d .), 1971.
7 . Farley , J . , An Efficient ContextFree Parsing Algorithm,
CACM , 13:2, February , 1970.
8 . Fry , D . , Duration and Intensity as Physical Correlates of Linguistic Stress  , JASA 17:4 ,  1955 , ( reprinted in Lehiste ( ed . ) , Readings in Acousticl ' honetics , MIT Press ,  1967 . ) 9 . Fujimura , O . , Temporal Organization of Articulatory Movements as Multidimensional Phrasal Structure  , Phonetica , 33: pp .  66-83, 1981 . 
10 . l-'ujimura , O . , and Lovins . J . , Syllables as Concatenative Phonetic UralS , Indiana University Linguistics Club ,  1982 . 
11 . Gazdar , G . , Phrase Structure Grammar , in P . Jacobson and G . Pullum ( eds . ), The Nature of Syntactic Representation,
D . Rcidet , Dordrecht , in press , 1982.
12 . .Heffner , R . , General Phonetics , The University of
Wisconsin Press , 1960.
13 . Kahn , D . , Syllable-Based ( ieneralizations htl Otglish Phonology , , Indiana University Linguistics Club ,  1976 . 
14 . Kiparsky , P . , Remarks on the Metrical Structure of the Syl " lable  , in W . Dressier ( ed . ) Phonologica 1980 . Proceedings of the Fourth International Phonology Meeting  1981  . 
15 . Kiparsky , P . , Metrical Structure , Assignments in Cyclic , Linguistic Inquiry ,  10 , pp .  421-441, 979 . 
16 . Kaplan , R . and Bresnan , J . , LexicabFunctional Grammar : A Formal System for Grammatical Representation  , i Bresnan ( ed . ), The Mental Representation fGrammatical
Relations , MIT Press . 1982.
17. Jetinek , F ., course notes , MIT , 1982.
18 . Joshi , A . , and Levy , L . . Phrase Structure Trees Bear More Fruit Than You Would Have Thought  , AJCL , 8:I ,  \[982 . 
19 . Klatt , D . , Word Verification in a Speech Understanding System  , in P ,  . R , eddy ( ed . ) , Speech Recognition , Invited Papers Presented at the 1974 \[EEE Symposium , Academic
Press , pp . 321-344, 1974.
20 . Klatt , D . , Review of the ARPA Speech Understanding
Project , JASA , 62:6, December 1977.
ZI . Klatt , D . , Scriber and Lal's : Two New Approaches toSpeech Analysis  , chapter 25 in W . Lea , Trends in Speech Recog . 
ration , Prentice-Hall , 1980.
22 . Martin , W . , Church , K . , and Patil , R . , Prelhninary Analysis of a Breadth-First Parsing Algorithm : Theoretical ttdEx " permwntal Results  , MI'I'/LCS/'I'R-2 61 , 1981 ( also to appear in I . .Bolc ( ed . ), Natural language Parsing
Systems , Macmillan , \[. on don).
23 . ReddvR . , Speech Recognition by Machine : A Review , Proceedings of the IEEE , pp . 501-531, April 1976, ~ . Smith , A . , Word flypothesization i the Ilearsay-ll Speech System  , Proc . IEEE Int , Conf . ASSP , pp .  549-552, 1976 . 
25 . Valient , l . . , General ContextFree Recognition iLess Than Cubic Time  , J . Computer and System Sciences 10, pp .  308-315, 1975 . 
26 . Woods , W . , Transition Network Grammars for Natural
Language Analysis , CACM , 13:10, 1970.
Z7 . Zue , V . , and Shattuck-Hufnagel , S . When is a ,/ Ts/nota/3V ?, ASA , Atlanta , 1980 . 

