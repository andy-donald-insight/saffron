EVALUATION OF NATURALL ANGUAGE IN TERFACES TO DATA BASE SYSTEMS 
Bozena Henisz Thompson
California Institute of Technology

Is evaluation , like beauty , in the eye of the beholder ? The answer is far from simple because it depends on who is cons idered to be the proper beholder  . Evalua corsmay range from casual users to soc iet y as a whole  , with sys-tem builders , sophisticated users , linguists , grant providers , system buyers , and others in between . The members of thl spane lare system builders and linguists -- or rather the t ~ a of used in to one--but  , I believe , interested in all or almost all actual or potential bodies of evaluators  . One of our colleagues expressed a force fulop inion while being a member of a similar panel at last year's ACL conference : " Those of us on this panel and other researchers in the field simply don't have the right to determine whether a system is practi-cal  . Only the users of such a system can make Chat determination  . Only a user can decide whether the hi . 
\[ natural language \] capability constitu tessufficient added value to be deemed practical Only a user can decide if thesy s tem's frequency of inappropriate response is sufficiently low to be deemed practica l  . 
Only a user can decide whether the overall NL in terac-tion  , taken into to , offers enough benefits over alter-nat iveformal interactions to be deemed practica l " Ill  . 
It is hardforme codisagree , since I argued as force-fully on the basi s of my study of users * evaluation of machine translation  \[2\] -- a study which was prompted by the evaluat ions of the quality of machine translation as viewed by linguists and users  , ranging from 35Z accept-able for the former to 90Z for the latter . Whet the study also showed was chat the pract i cality of the out-put could indeed only be judged by the users  , since even incomplete and stylistic all yveryine legant translations were found qu ite useful in practice because they  , on the one hand , provided , however crudely , the information sought by the users , and , on the other hand , the users themselves brought knowledge chatmade the texts far more understandable and useful then might appear coanon specialistling u is t  . But this endorsement on mY pert of the user a ~the ultimate judge in evaluations does not preclude my fully subscribing coN or m Sond heimer's  \[3\] introductory co~ents coth is panel stating that to " make progress as a field  , we need to be able Coevalu-ate . " We are now less likely coconfuse the issue of the evaluation by people like ourselves and the judgment of the users  , less likely to be surprised at the disc repan-cies  , and less likely to be surprised at the users " acceptance of the limitations of our NL interfaces  . 
Also , we are far more aware of the fact chac evaluations of ' ~ orth " or " quality " have Co be conducted in the contexts of the actual  , perceived needs . Zn extensive stu-dies on evaluation of innovations  , Mosteller\[4\] , the recently retired president of AAAS , found that " success-fulinnovators better understand user needs  ; \[ and \] pay more attention to marketing .   .   .   . " The same source , however , leads mecothenotorious difficulties of evaluation given the viderange of evalua Cors and their purposes  . We are all undoubtedly convinced of the value of NLI for the society as a whole  , but the evaluation of experiments with these interfaces is another matter  . 
Mosceller was faced with social , sociomedical , and medi-cal fields . Let me recount some of the studies he and his team made for reasons which will so on become obvi-ous  . Histeem scored a given program on a scale from plus ~ wo Cominus ~ wo with zero meaning there was essentially uogain  . Accordingly , a study of delinquent girls that identified th ~- buc failed to prevent them from del inquency received a zero  . Likewise , a zero was assigned Coaprobation experiment for conviction for public drunkenness in which three methods were used :  ( I ) no treatment , (2) an alcoholic clinic , and (3) Alcoholics Anonymous . Since the " no treatment " group performed somewhat better  , short-term referrals were considered of no value  . Amin usone was given to a study whose result s were opposite coth ose hoped for : a major insurance cOmpany increased out patient benefit s in the hope of decreasing hospital costs  , but the outpa-tient group's hospitals tays increased  . Finally , a dou-ble plus was swarded to an experiment involving the Salk vaccine  , which was , predictably , very successful . Now this kind of evaluation may be just if ied when the needs of the society areats take  . I have gone into these details , however , for the purpose of expressing the opinion , in which IknowI'm not alone , that nelative results are as important as positive ones  , that evalua-tion in our case is almost equ ivalent to the amount of information obta in ed in an experiment  . An experiment whose results would be total ly predictable would be almost useless  , but one with results different frOm those hoped for might beem barrassing but very valuable  . 
Another c~ent prompted by those evaluations is ch at the application of any rigid  , finescale is totally inappropriate in the case of NLI evaluations  . 
NLIE VALUATIONS
A . METHODOLOGY AND SOMERESULTS
It had been widely taken for granted some time ago Chatl ~ LI is as good as is its gr -~- r  , and a grammar is as good as it is extensive . The specific needs of users , the requirements of special tasks and the li kecook a back seat  . The nature of ht--and is course was yet to be explored  . Happily , we have been in a different situa-tion for some time  . When the REL\[5 ,  5 ,   7\] system was getting into ? reasonably sturdy shape with respect to speed and buss  , I started planning experiments to test it . The reyes important literature about di scourse  , especially in sociology , such as the work of Schegloff . 
It was thus clear that successful NLI exper iments had Cobe based on knowledge of hi  , and is course . St was also clear chat that was the way Co make the interface more natural  . This ass~ption has already been fruitful : the NL interface in POL\  [9  \ ]  , a successor CoREL , has already been extensively improved as a result of the 
EEL-related experiments.
Experiments were made in three modes : in add it iont of a ce-to-face and human-to-co ~ puter  , cerainal-co-terminal communication was examined  , since at present chat is the only practical mode of accessing the computer  . Throughearly 1980 , Over 80 subjects ,  80 , 000 words , and over 50 hours were analyzed in great detail . In the fall of 1980 , another 13 subjects were tested in the computa-tional mode only  , adding approximately 20 hours . From the start , the experiments were encouraging , although limited to ~ wo modes : FF and TT . Interactions not only showed a great deal of s tructure but extensive similarities in both modes  , the most important being the constancy of then t = a ber of words in sentences  ( about 70Z )  ; the length of sentences ( about 7 words ) ; the existence of fragments ( 7 0Z of messages in FF and 50Z in TT containing them )  ; and phatics (10Z of total for FF and 5Z for TT ) . Thus similarities between the = odes were a candidate for consideration in experiments in the computational mode  , the TT mode being seemingly quite far removed from natural FF  . The sentence having historically been the unit of analysis  ( and since phat-its were considered of lesser Lmportance from the computational vi ~  , although of great interest in general ) , m 7 attention turned Co fragments . REL allowed for three non-sentence types truc tures : " NP ?"  ( including number parsed into NP )  ; " all/none or uomber " answers ; and sible to include individual knowledge and terminology  . 
The analysis of FF and TT protocols , however , showed the existence of other fragment categor i es  , finally analyzed ~ n coadozen categories ( see\[8\] )   . Since they constitute a considerable amount of FF conversations and even TT protocols  , they clearly had cobe watched for in computational experiments  . 
The experiments for actually observin ~ user- system interaction were conducted in the w inter Cem of  1979/80 and produced 21 protocols , the analysis of which was compared with resul ts of eight FF and fou ~ TT experi-ments  . Another 13 computational experiments done in the fall couf imed the results of the earlier ones  . The Cask in all three = odes was are alone : loading cargo onto aship  , the data coming from the actual envirooment of loading U  . S . navy ships by a group in San Diego , California . In the FF and TT experiments , ~ n , ~ opersons were involved--one given cargoitem ~ Cobeloaded  , the other in fot ~ nation about decks ( details in \[8\] )  . In the computational mode ( HC ) the ship data was in ~ he computer and the l is t of cargo to be loaded was handed Co the subjects  , all with Caltech background . Details being available elsewhere and space l imited here  , only some major results are given here . Table 1 shows the comparison of the three modes . 
TABLE1 ~-__~T-__/~.-c
Sentence length 6.8 6.I 7.8
Message length 9.5 10.3 7.0
Frequent length 2.7 2.8 2.8
Zwords in sentences 68.8 72.8 89.3
Zwords in fragments 17.2 21.1 10.7
Toca ~ AvR . ~ ota ~ Avt . To Ca ~ Ave,
Messages 557 46973 1078 109352
Parsed & nonparsed 16 15 77
Sentences 530 266 3385 7788 242
Fragments 325 340 2230 582 1110
Phatics ( including connectors & tags ) 48 A260514837462
Total ~ ota\[Total
Words in messages 4980032858525
Words in sentences 34266 23936880
Words infra~encs 858 469 4823
As can be seen , several statistics shows iailar it i as : sentence length  , message length , fragment length , per-centage of words in sentences and f ragments  . The close-ness of the average of messages in TT and parsed and u on parsed inputs in H--C is striking  . 
Table 2 ( the meaning of abbreviations is given below the cable  ) deals with fragments . Zt is mostly self-explanatory , as is the absence of ds finiclons from ?- F and TT  ( although some abbreviations used the refall in this category  ) and the absence of some other categories from TT and KC  . At lease ~ wo comaents , however , are necessary . The surprisingly low use oftersequestions ? nHC may be accounted for by the tendency toward a formal style in compu Cacionnl interact ion  . The defini-tions used were often of qui te complex character  , although far fever than could be hoped for due apparently to lack of familiarity with thi scapability  . 
The complex character of definitions undoubtedly had some effect on the length of sentences in the HC mode  . 

TABLE 2
FFTTHC
Tota ~ ~ lTOCa ~; TOC atg 532 ?6.4 104.3
ADD 425 13.I4 117.8
CORE 561?7
COMP95 2.9 2.9
SELFI 143.5
T~571 17.667 29.1
TQ4li 12.5 31 13.4
TI29 79.14 820.9
FS4 131 2.72 3I 0.0
TEUN 339I 0.49 3.9
DrYp4~2148
C 1935 34
T3 1913 7o 867 27.8,301 2,453 22.0
Abbreviations
E ( Echo ) : Anezaccor partial repetition of usual ly the other speaker's string  . Oftenan NP , but it may be an elliptical structure of various forms  . 
ADD ( Added ~ n formatiou ) : An elliptical structure , often NP , used to clar if 7 or complete a previous utterance , ofte node " sown , e . g .   , " IC does n "~: say anything here about weight , or breaking chins , down . Except for or us hable e . ", " It's smaller . 
36"x20"x17" . " Spelling out words was Lncluded here . 
CORE ( Correction ) : This may be done by either speaker . 
Tf done by the smm speaker it is related C of a lse start  , but semantic considerations suggest a correct ion  , e . g .   , " Those are 30 ,   , , h , 48 length by 40 width by 14 height . " COMP ( Comole Cion ) : Completion of the other speaker's utte rance  , distinguished from interruption by the cooperative nature of the utterance  , e . g . , " As T ' vegot a lot of .   .   . Z ' veto e B : two pages . A : Yeah . " SZLY . ( Ta~kin Sco0ueself ~: Muttsrings , even to the point of undecipherabiliCy , no c intended for the other person . 
TR ( Tersereply ) : An elliptical reply , often NP , e . go , " No . ", " Probably meters . ", "50 and 7 . 62 . " TQ ( Terse Oues Cion ) : An elliptical question , often NP , e . g .   , ' ~ hy ? " , " How about pyrote chnics ?" , ' ~ hich ones ? " TI ( Terse Information ) : Ara the relusive category , neither question , reply nor co--and , an elliptical statement but one often requiring an action  . 
F8 ( False Sta~c ) : These are also abandoned utter-ances , but i ~ e distely followed by usually syntac- tically and semantically related ones  , e . g . , " They may , they may be identical classes .  "  , ' ~ ell , the height , the next largest height I'vegot is 34 . " TRUN ( Truncated . ): An incomplete utterance , voluntarily abandoned . 
DEF ( Definition ): E . g . , ' ~ 0 efine : ED : each deck of the

P ( Phatics ) : The largest subgroup of fragments whose nets is borrowed from Malino weki?stern " phacic colmtmion " with which he referred to chose vocal utterances chat serve to establish social relations racher than the direct purpose of communication  . 
This term has been broadened to include all f rag-ments which help keep the channel of communication open  , such as ' ~ ell " , ' ~ aic " , and even ' ~ ou Cur-kay " . Two subcategories of phacics are : C ( Dialogue Connectors ) : Words such as " Then " , " And " , " Because " ( at the beginning of a message or utterance )  . 
T ( Tan Ouescions ): E . g . , " They'reallunder60, seen " t they ?"
ANDERRORANALYSIS
System performance can obviously be evaluated in a number of ways  , but without good response time meaning-ful experiments are impossible  . When much data is involved in processing a delay of a few minutes can probably be toler a ted  , but the vast majority of requests should be responded to within seconds  . The latter was the case in my experiments . Fairly complex messages of about 12 words were responded to in about l0 seconds . 
The system clearly has to be reasonably free of bugs -- in my case  ,   12 bugs were hit in the total of 1615 parsed and nonparsed messages . The adequate extent of natural language syntaxi simpossible to determine  . Table 3 shows the syntax used by my subjects . 
sentences ; or possibly just " baby talk " due to the suspicion of the computer's limitations  . 
An interesting fact to note is that similar results with respect to syntax were obtained in the exper~nents with USL  , the " sister system " of REL developed by IBM Heidelberg  \[10\] -- with German used as gLl in two studies of high school students : predominance of wh-questions  ( 317 in total of 451 )  ; not many relative clauses (66) ; commands (35) ; conjunctions (26) ; quantifiers (15) ; definitions ( ii ) ; comparisons (2) ; yes/no questions ( i ) . 
An evaluation which would not include an analysis of unparsed input would at best be of limited value  . It was shown in Table i that i093 out of 1515 or about ~ othirds were parsed in my exper iments  . 
TABLE 3
SENTENCE TYPES

All sentences
Simple sentences , e . g . , " List the decks of the Alamo . " 73 . 8 Sentences with pronouns , e . g .   , ' ~/ hatis its length ?" , " what is in its pyro-technic looker ? "303 . A
Sentences with quantifier(s ), e . g . , " List the class of each cargo . " 71 8 . 0 Sentences with conjunctions , e . g . "What is the maxim , --stowheight and balecube of the pyrotechnic locker of the 
AL ? "88I 0.0
Sentences with quantifier and conjunc-tion(s ), e . g . , " List hatch width and hatch length of each deck of the Alamo  . " 13 2 . 6 Sentences with relative clause , e . g . , " List the ships that have water . " 6  . 7
Sentences with relative clause ( or related construction ) and cemparator , e . g . , " List the ships with a beam less than lO00 . " 6  . 7 Sentences with quantifier and relative clause , e . g . , " List height of each content whose class is class IV  . " 2  . 23 Sentences with quantifier , conjunction and relative clause , e . g . , " List length , width and height of each content whose class is a -- nunicion  . " 2  . 23 Sentences with quantifiers and comparator , e . g .   , ' ~ Iow many ships have a beam greater than 10007'*   3   . 34
Wh-questions 75.0
Yes/no questions 1.0
Con=s and s19.0
Statements ( data addition ) 5.0
Considering the wide range of Rk'r-syntax\ [7\]   , the pau-city of complex sentences is surpris ing  . The use of definitions which often invo lved complex constructions  ( relative clauses , conjunctions , even quantifiers ) had a definite influence . So did , undoubtedly , the task situation causing optimization of work methods  . The influence of the specific nature of the task would require additional studies  , but the special device provided by the system  ( aloading prompt sequence -- which was not analyzed  ) was employed by every subject . Dew-ices such as these obviously area great a id in accom-plish in  8 tasks . They should be tested extensively to determine how they can augment the uaturalness of NLIs  . 
Other reasons for the relatively simple syntax used were special strategies : paraphrasing into simpler syntax even though a sentence did not parse for other reasons  ; " SUCCesS strategy " resulting in repetitious simple 
TABLE 4
Total %
Vocabulary 161 36.1
Punctuation 72 16.1
Syntax 62 13.9
Spelling 611 3.6
Transmission 327.2
Definition format 306.7
Lack of response 163.6
Bus 122.7
Table 4 st ~_erizes the categories of errors . The predominance of vocabulary is not surpris ing  , but rela-tively few syntactic errors are  . In part this may be due to the method of scor ing in which errors were counted only once  , so if a sentence contained an unknown vocabu lary item  ( e . g . " On what decks of the Alamo cargo be stored ?" ) but would have failed on syatactic grounds as well  , it would fall in the vocabulary category . A comparison can be made here with Damerau's study Ill\]of the use of the ll ~ A system by the city plann in S department in WhitePla in s  , at least with regard to the total of quer ies to those completed :  788 to 513  . So , again , roughly t ~ aothirds were parsed . In other categories " pars in Sfailure " i s  147  , " lookup failures "1 19 , " nothing in database " 61 , " program error " 39 , but this only points to the general difficulties of comparisons of system performance  . 
SOMECONCLUSIONS
Norm Sond heimer suggested some questions we might try to answer  . What has been learned about user needs ? What most important linguistic phenomena to all OW for ? What other kinds of interactions ? Error analysis points in the obvious directions of user needs  , and so do the types of sentences employed . While it is justified to quit the search for an almost perfect gr nmm  , r , it would be a mistake to constrain it to the constructions used  . 
Improved naturalness can be achieved with diagnostics  , definitions , and devices geared to specific tasks such as special prompting sequences  . Some tasks clearly require math in the NLI . How good are systems ? An objective measurement is probably impossible  , but the percentage of requests processed might g ive some idea  . 
In the case of a task situation such as loading cargo items  , the percentage of task completion may signal both system performance and user satisfaction  . System response times are a very important measure  . The questionnaire method can and has been used ( in the case of MT and USL )  , but as yet there is too little experience to measure user satisfaction  . Users seem very good at adapting to systems . They paraphrase , use success strategy , simplify syntax , use special devices -- what they really do is maximize their performance with respect Coa given task  . 

What have we learned about running evaluations7 It is important Coknow what to look for , therefore the need for good knowledge of human to hmn and is course  . Good system response times are as in equan on . Controlled experiments have the advantage of being replicable  , a crucial factor in arriving acevaluat ion criteria  . 
Determining user bias and experience nay be important  , but even more so?s user training . Controlled experi-ment scan show what methods are ~ ost effective  ( e . g . a manual or study of proCocols ~) . Study of user commence - - phacic material - - gives some measure of user  ( dis ) satisfaction ( I have seen'"/oulie , " bucI have ye C to see " Good boy , you Z ") . Clearly , the best indication of user satisfaction is whether he or she uses the sys-tem again  . Extensive I on S-term studies are needed for that  . 
What should the future look like ? Task or iented situa-tions seem to be a promising envirooment for ~ LZ  . The standards of NL systems performance will be set by the users  . Future evaluations ? As Antoine de Sainc-Zxup&r7 wrote , " As for the Future , your task is not to foresee , but to enable it .  "
REFERENCESi . Harris , Larry E . " Prospects of Practical Natural Language Systems  . " Proceedings of the 18th Annual Meet in ~ of the Association for Computationa ~ 
Linguistics , June 1980, p . 129.
Z .   . Henisz-Doster C , B . ; Macdonald , R . E . ; and Zarech-rusk , M . Machine Translation . The Hague : Mouton , 1979 . 
3 . Sondheimer , N . K . " Evaluation of Natural Language Interfaces to Data Base Systems  . " Proceedings o ( the 19th Annual Meecin ~ of the Association for Com -putational Linguistics  , June 1981 . 
4 . Mosteller , F . " ~ nnovation and Evaluation . " Science ( February 27, 1981):881-886 . 
5 . Thompson , F . B . and Thompson , Boaena H . "?tactical Natural Language Processing : The EEL System as Prototype  . " In Advances in Computers , ed . M . Rubi-noff and M . C . Yovits . Yol .  13 . New York:
Academic Press , 1975.
6 . Thompson , Bozena H . and Thompson , F . B . " Rapidly Extendable Natural Language . " Proceedings of the 1978 Nationa ~ Conference of the ACM , pp .  173-182 . 
7. Thompson , Bozena H . REL English for the User.
Pasadena : California Institute of Technology ,  1978 . 
8 . Thompson , Bozena H . " Linguistic Analysis of Natural Language Co-- , unication rich Computers . " COLING 80: Proceedings of the gCh Internation a ~ Conference on Computariona ~ Linguistics  , Tokyo , 
October 1980, pp . 190-201.
9 . Thompson , Bozeua H . and Thompson , F . B . " Shifting to a Higher Gearina Hatural Language System  . " Proceedinzs of the Nat~ona ~ Computer Conference , 
May 1981.
10 . Lehmann , Hubert ; OCt , Nikolaue ; Zoeppri~z , Mag-dalene . ' ~ ser Experiments with Natural Language for DaCeBase Access  . " COLING 78: Proceed in Rs of ch ~ 7oh International Conference on Computational
Linguistics . Bergen , August 1978.
I i . Oamtrau , Fred J . The Transformational ~ uestion Answ ~ rin ~ ~ T ~ A ~ System : Operational Statistics  -1978  . EC 7739 . Yorktown Heights : IBM T . J . Watson research Center , June 1979 . 

