At a bular interpretation of a class of 2 -Stack Automata
Eric Villemonte de la Clergerie
INRIA-Rocquencourt-B.P . 105
78153 Le Chesnay Cedex , FRANCE

Miguel Alonso Pardo
Universid adde La Corufia
Campus de Elvifias/n
15071 La Corufia , SPAIN
alonso?dc , fi.udc.es

The paper presents at a bular interpretation for a kind of  2-Stack Automata . These automata may be used to describe various parsing strategies  , ranging from purely topdown to purely bottom-up , for LIGs and TAGs . The tabular interpretation ensures , for all strategies , a time complexity in O ( n 6 ) and space complexity in O ( n5 ) where n is the length of the input string . 
Introduction 2-Stack automata \[2SA \] have been identified as possible operational devices to describe parsing strategies for Linear Indexed Grammars \[ LIG\]or Tree Adjoining Grammars \[ TAG\]  ( mirroring the traditional use of Push-Down Automata\[PDA \] for ContextFree Grammars\[ CFG\]  )  . Different variants of 2SA ( or not so distant Embedded Push-Down Automata ) have been proposed , some to describe topdown strategies ( Vijay-Shanker , 1988; Becker ,  1994) , some to describe bottom-up strategies ( Rambow , 1994; Nederhof , 1998; Alonso Pardo et al ,  1997) , but none ( that we know ) that are able to describe both kinds of strategies  . 
The same dichotomy also exists in the different tabular algorithms that has been proposed for specific parsing strategies with complexity ranging from O  ( n 6 ) for bottom-up strategies to O ( n9 ) for prefix-valid topdown strategies ( with the exception of a O ( n 6 ) tabular interpretation of a prefix-valid hybrid strategy  ( Nederhof ,  1997)) . It must also be noted that the different abular algorithms may be difficult to understand and it is often unclear to know if the algorithm still hold for different strategies  . 
This paper overcomes these problems by ( a ) introducing strongly-driven 2SA  \[  SD-2SA \] that may be used to describe parsing strategies for TAGs and LIGs  , ranging from purely topdown to purely bottom-up , and ( b ) presenting at a bular interpretation of these automata in time complexity O  ( n 6 ) and space complexity O ( nS )  . 
The tabular interpretation follows the principles of Dynamic Programming : the derivations are broken into elementary subderivations that may  ( a ) be combined in different contexts to retrieve all possible derivations and  ( b ) be represented in a compact way by items , allowing tabulation . 
The strongly-driven 2SA are introduced and motivated in Section 1  . We illustrate in Sections 2 and 3 their power by describing several parsing strategies for LIGs and TAGs  . Items are presented in Section 4 . Section 5 lists the rules to combine items and transitions and establishes correctness theorems  . 
1 S t rong ly - dr iven 2 -Stack Automata 2SA are natural extensions of Push-Down Automata working on a pair of stacks  . However , it is known that unrestricted 2SA have the power of a Turing Machine . The remedy is to consider asymmetric stacks , one being the Master Stack MS where most of the work is done and the other being the Auxiliary Stack AS mainly used for restricted " bookkeeping "  . 
The following remarks are intended to give an idea of the restrictions we want to enforce  . The first ones are rather standard and may be found under different forms in the literature  . The last one justifies the qualification of " strongly-driven " for our automata  . 
\[ Session \] AS should actually be seen as a stack of session stacks  , each one being associated to a session . Only the topmost session stack may be consulted or modified  . This idea is closely related to the notion of Embedded Push-Down 
Automata ( Rambow , 1994, 96-102).
\ [ Linearity \] A session starts in mode write w and switches at some point in modeer a see  . In modew ( resp . e ), no element can be popped from ( resp . pushed to ) the master stack MS . 
Switching back from e to w is not allowed . This requirement is related to linearity because it means that a same session stack is never used twice by " descendants " of an element in MS  . 
\[ SoftSessionExit\]Exiting a session is only possible when reaching back  , with an empty session stack and in modeerase , the MS elemen that initiated the session . 
\[Driving \] Each pushing on MS done in write mode leaves some mark in MS about the action that/zW \W/ZE\E 
IIII--*W~W Write Mode
IIIIIIIIIIIIIII ?
Master stack
Figure 1: Representation f transitions and derivations took place on the session stack  . The popping of this mark ( in erase mode ) will guide which action should take place on the session stack  . 
In other words , we want theer asing actions to faithfully retrace the writing actions  . 
Formally , a SD-2SA . A is specified by a tuple (~, . M , X ,  $0 , $ l , O ) where ~ denotes the finite set of terminals ,   . M the finite set of master stack elements and X the finite set of auxiliary stack elements  . The init symbol $0 and final symbol $ y are distinguished elements of Ad  . O is a finite set of transitions . 
The master stack MS is a word in(D . M ) * where 2) denotes the set/~, x . ~ , ---% ~ of action marks used to remember which action  ( w . r . t . the auxiliary stack AS ) takes place when pushing the next master stack element  . The empty master stack is noted e and a nonempty master stack  ~1A1   . . . ~ nAn where
A , ~ denotes the topmost element.
The meaning of the action marks is: /2 Pushing of an element on AS . 
" x  ~ Popping of the topmost element of AS.
--* No action on AS.
Creation of a new session ( with a new empty session stack on AS )  . 
The auxiliary stack AS is a word of ( K : X * ) * where K := ~ w , ~ e is a set of two elements used to delimit session stacks in AS  . Delimiter ~ w ( resp . 
~ e ) is used to start a new session from a session which is in writing  ( resp . erasing ) mode . The empty auxiliary stack is noted e . 
Given some input string x l .   .   . xiEE *, a configuration of . A is a tuple ( m , u ,  ~ , ~) where mEw , e denotes a mode ( writing orer asing ) , uastring position in \[0 , f \] , -- the master stack and ~ the auxiliary stack . Modes are ordered by w -~ e to capture the fact that no switching from e to w is possible  . The initial configuration of , 4 is ( w ,  0 ,  ~$0 , ~ w ) and the final one ( e , f , ~$ f , ~ W ) . 
A transition is given as a pair ( p ,  -- ,  ~) , z(q , O , 0) where p , q are modes ( or , with some abuse , variables ranging over modes ) , z i n E * ,   . -- and O suffixes of master stacks in . M(2) Ad ) * , and ~ , 0 suffixes of auxiliary stacks in X * ( ~ gX * ) * =  ( XUK : ) * . Such a transition applies on any configuration ( p , u , k ~ -- , ~b ~) such that xu + l .   .   . x , = z and returns ( q , v , ~0, ?0) . 
We restrict the kind of allowed transitions : SWAP  ( p , A ,  ~) , z(q , B ,  ~ ) with p_q and either eK : ( " session bottom check " ) or ~= e ( " no
AS consultation ").
/- WRITE(w , A , e ) , z(w , ATB , b)/-ERASE(e , A/Z B , a ) , z(e , D , e)--*-WRITE(w , A , e ) ,  ~  , ( w , A -* B , e)--*-ERASE(e , A -+ B , e ) , ~ ~( e , C , e)~-WRITE(m , A , e ) , z , ( w , A  ~ B , ~m ) ~- ERASE(e , A  ~ B , ~m ) ~ i ~( m , C , e)x , ~- WRITE(w , A , a ) ,  ~ , ( w , A ' x ~ B , e ) " ~- ERASE(e , A " ~ B , e ) ,  ~  , ( e , C , c ) Figure 1 graphically outlines the different kinds of transitions using a  2D representation where the X-axis ( Y-axis ) is related to the master ( resp . auxiliary ) stack . Figure 1 also shows the two forms of derivations we encounter  ( during a same session )  . 
2 Using 2SA to parse LIGs
Indexed Grammars ( Aho ,  1968 ) are an extension of Context-free Grammars in which a stack of indices is associated with each nonterminal symbol  . Linear Indexed Grammars ( Gazdar ,  1987 ) are a restricted form of Indexed Grammars in which the index stack of at most one body nonterminal  ( the child ) is related with the stack of the head nonterminal  ( the father )  . The other stacks of the production must have a bounded stack size  . 
Formally , a LIGG is a 5-tuple ( V T , VN , S , VI , P ) where VT is a finite set of terminals , VN is a finite set of nonterminals , SEVN is the start symbol , VI is a finite set of indices and P is a finite set of productions  . Following ( Gazdar ,  1987 ) we consider productions in which at most one element can be pushed on or popped from a stack of indices :\[ POP\]Ak  , o \[ oo \] -- . Ak , t\[\] .   .   . Ak , d\[oo'y\] . . . Ak , . ~\[\]\[ PUSH \] Ak , 0\[ooT\]--*Ak , 1\[\] .   .   . Ak , d\[OO\] . . . Ak ,, ~\[\]\[ HOR\]A k , 0\[ oo\]~ak , 1\[1 . . . Ak , d\[OO\] . . . a  ~ , ,~ \[1 To each production k of type PUSH , POP or HOR , we associate a characteristic tuplet ( k ) = ( d ,  5 , a , /3 ) where d is the position of the child and the other arguments given by the following table : 
Type 5a
PUSH/ze7
POP~7e
HOR---*e ?
We introduce symbols ~' k , i as a shortcut for dotted productions\[Ak , 0~Ak , 1  . . . A k , i ? A k , i + l . .  . A k ,, ~\] . 
In order to design a broad class of parsing strategies ranging from pure topdown to pure bottom-up  , we parameterize the automaton to be presented by a call projection -'* from  12 to ) 2 cart and a return projection *'-" from 12 to " Wetwhere ~= VNU VI and \]2 cart and Vret are two sets of elements . We require \]2 cartN\]2 ret = 0 and ("-* , +'-) to be invertible , i . eVX , rev , ( X , * X ) = ( V ,  ~ ) = : ~ x = r The projections extend to sequences by taking  X1  .   .   . X := X-~I . . . ~ and "~= e ( similarly for +-) . 
Given a LIGG and a choice of projections , we define the 2SA . A(G ,  -~ , = ~-) ( Vr , M , X ,  -~ ,  ~  , O ) where M =  Vk , iU~TU~TT , X = ~// U ~// , and whose transitions are built using the following rules  . 
? Call/Return of a nonchild
CALL : ( m , Vk , i , e )*, ( w , Vk , , ~ rn)
RET : ( e ,   , ( m , Vk , i+ , ,e ) ? Call/Return of a child for t(k ) = ( i + 1 , 5 , a , /3) . 
CALL (5): ( w , Vk , i , W ) , ~_ ~( w , Vk , iSAk , - ~+ l , "-~) RET (5): ( e , Vk , iSAk , i++'-'-';1 ,  /3)  ,   , ( e , Vk . i + l,W ) ? Production Selection
SEL:(w , A---~ , 0 , e ) ,   , ( w , Vk , 0 , e ) ? Production Publishing
PUB : ( e , Vk , n~ , e ) ,   , ( e , ~0k , 0 , e ) ? Scanning ( for terminal productions ) SCAN : ( w , ' ma~~mAk , 0 , ~) ~---* ( e , A k , 0 , ~) The reader may easily check that A(G , -'-* , ~-'-) recognizes L(G ) . The choice of the call and return elements for the MS  ( A ~ k , i and Ak , i ) and the AS ( '-~ and ~' ) defines a parsing strategy , by controlling how information flow between the phases of prediction and propagation  . The following table lists the choices corresponding to the main parsing strategies  ( but others are definable )  . 
Strategy ~ ~--~~-
Top-Down A_l_7.l_
Bottom-Up 2. A'_l_7
Earley AA'77'
It is also worth to note that the description of A ( G , -* , +--) could be simplified . Indeed , for every configuration ( m , u , E , ~) derivable with . A(G ,  "--* , *-") , we can show that ---= ~ V kl , il St .   .   . Vk . , i ,, SnX , and that 5 t only depends on Vk ~, i ~ . That means that we could use a master stack without action marks  , these marks being implicitly given by the elements XTk  , i . 
3 Using 2SA to parse TAGs
Tree Adjoining Grammars are a extension of CFG introduced by Joshiin  ( Joshi ,  1987 ) that use trees instead of productions as primary representing structure  . Formally , a TAG is a 5-tuple G = ( VN , VT , S , I , A ) , where VN is a finite set of nonterminal symbols , VT a finite set of terminal symbols , S the axiom of the grammar , I a finite set of initial trees and A a finite set of auxiliary trees  . IUA is the set of elementary trees . Internal nodes are labeled by nonterminals and leaf nodes by terminal sore  , except for exactly one leaf per auxiliary tree ( the foot ) which is labeled by the same nonterminal used as label of its root node  . 
New trees are derived by adjoining : let be a a tree containing a node u labeled by A and let be flan auxiliary tree whose root and foot nodes are also labeled by A  . Then , the adjoining of/3 at the adjunction odeu is obtained by excising the subtree a ~ of a with root u  ,   attaching/3 to u and attaching the excised subtree to the foot  of/3   ( See Fig .  2) . 

Figure 2: Traversal of an adjunction
An elementary tree a may be represented by a set P ( a ) of contextfree productions , each one being either of the form ? Yk , O---4Pk , 1  .   .   . Pk , n  ~ , where Yk , o denotes some nonleaf node k of a and u k , i the ith so n of k . 
1335 ? vk , 0 - -* al ? , where vk , 0 denotes ome leaf node k of c ~ with terminal abel ak  . 
As done for LIGs , we introduce symbols Vk , i to denote dotted productions and consider projections "* and ~ to define the parameterized  2SA   . A(G ,  -'-* , *") = ( V T , At , At , v0 , 0 ,  ~0 , 0 , O ) where At = Vk , i ) Uvk , iUv ~ , /) . The transitions are given by the following rules ( and illustrated in Figure 2 )  . 
? Call/Return for a node not on a spine . The call starts a new session , exited at return . 
CALL:(m , Vk , i , e ) ,   , ( w , mRET : ( e , Vk , /~ vk . i + l , ~) ''( m , Vk , i+l , e ) ? Call/Return for a node vk , i + lona spine . 
The adjunction stack is propagated unmodified along the spine  . 
SCALL : ( w , Vk , i , e ) ,   , ( w , Vk , i---*vk , i+~ , e)SRET : ( e , Vk , i--*bk , i + l , e ) , ~( e , Vk , i+l , e ) ? Call/Return for an adjunction on node uk , 0 . 
The computation is diverted to parse some acceptable auxiliary tree ~  ( with root node rh )  , and a continuation point is stored on the auxiliary stack  . 
ACALL : ( w , vk , 0, e ), , Vk , o/Zr ~, Vk , o)
ARET : ( e , v~ , o/ZF3Z , Vk , ,~) ,   , ( e , ~-" e)/\]k , 0 , ? Call/Return for a foot node f ~ . The continuation stored by the adjunction is used to parse the excised subtree  . 
FCALL : ( w , f ~, A ), -, ( w , f -'-~" ~ A , e)
FRET : ( e , f ~'% A , ~), , ( e,\]~,A)
Note : These two transitions use a variable A over At  . This is a slight extension of 2SA that preserves correctness and complexity . 
? Production Selection
SEL : ( w , vk . ~, e ),, ( w , Vk , 0, e ) ? Production Publishing
PUB:(m , Vk , n~ , e ) , ( e , ~ e)/\]k , 0 , ? Scanning
SCAN : ( w , v ~, 0, ~ m ), ~,( e , ~---
Different parsing strategies can be obtained by choosing the call  ( vk , i ) and return ( vk , i ) elements :
Strategy prefix-valid Top-Down v_l_
Bottom-Up_Lv'prefix-valid Earleyvv ' Non prefix-valid variants of the topdown and Earley -like strategies can also be defined  , by taking ~=_L and ~= r ~ for every root node r ~ of an auxiliary tree  j3   ( the projections being unmodified on the other elements  )  . In other words , we get a full prediction on the contextfree backbone of G but no prediction on the adjunctions  . 
4 Items
We identify two kinds of elementary derivations , namely Context-Free\[CF \] and escaped Context-Free\[xCF\]derivations  , respectively represented by CF and xCF items . An item keeps the pertinent information relative to a derivation  , which allows to apply the sequence of transitions associated with the derivation in different contexts  . 
Before presenting these items , we introduce the following classification about derivations  . 
A derivation ( p , u , EA , ~)\[--~7/( q , v , O , O ) is said rightward if no element of E is accessed  ( even for consultation ) during the derivation and if A is only consulted . Then F ~ A is a prefix of O . 
Similarly , a derivation ( p , u , E , ~)1-~"( q , v , O ,  0 ) is said upward if no element of ~ is accessed ( even for consultation )  . Then ~ is a prefix of 0 . 
We also note w\[q/p \] the prefix substitution of p by q for all words w  , p , q on some vocabulary such that p is prefix of w . 
4.1 Context-Free Derivations
A Context-Free\[CF\] derivation only depends on the topmost element A of the initial stack MS  . That means that no element of the initial AS and no element of MS below element A is needed :  ( o , u , -A , ~) l-~l(w , v , OB , 0) 1-~2(m , w , OBhC , ~ c ) where ? dl and did2 are both rightward and upward . 
? d2 is rightward.
? either (5#~ , o = w , and ceA ') or (5 = ~ , and c = ~ o) . 
For such a derivation , we have:
Proposition 4 . 1 For all prefix stacks E ' , ~' , ( o , u , E ' A , (') I-~ , ( w , v , O'B , 8') ( re , w , O'B6 C , (c ) where O ' = and o ' = O\[gl\] . 
The proposition suggests representing the CF derivation by a CF item of the form 
ABh(7 , m where A = ( u , A ) and B = ( v , B ) are micro configurations and (7= ( w , C , c ) a miniconfiguration . 

B ~ c
A . t  ~ . -- . "" CF (-*) ItemCF (7) or CF (~) Item

CF(X ~) Item B ?:::?::: xCF (--*) Item r ~
IIIIIII : : : xCF(/z ) Item r ~"- ~
IIIII
Figure 3: Items Shapes
AxCF (' x ~) Item r ~
IIIIII , 4 . 2 Escaped Context - F ree Der ivat ions An escaped Context-Free\[xCF\] derivation is almost a CF derivation  , except for an escape subderivation that accesses deep elements of AS  . 
where ( w , u , EA , ~) I~(w , v , eB , e)\[*--"-(w , s , @D , ~ d)d ~
I*--(e , t,@DX,~E , ?) dx
I-~;(e , w , OBSC , ? c ) ? dl and did2 are both rightward and upward ?? d2 and dx are rightward ?? d3 is upward ?? 5# ~ and d , cEX . 
Proposition 4 . 2For all prefix stacks ~ and ~' , stack ? ~ , and rightward derivation ( w , s , @' D , ~' d ) l~x , ( e , t , @' DX , ~ E , ?') where ~' = ?\[~'/ E\] , we have ( w , u , E ' A ,  ~ ' ) \ [ -~-
I ~* d2
I ~* d3(w , v , e\[='/--\]B , e\[~'/~\])( w , s , ?\[-' lZ\]D , ~' d ) . 
( e , t , ?\[ E'/E\]DX ~ E , ?') ( e , w , O\[~-'/Z\]BSC , ?' c ) The proposition suggests representing the xCF derivation by an xCF item of the form 
ABS\[i :) E\]Ce where A = ( u , A ) , B --( v , B / , /~ = ( s , D , d / , E = ( t , E / and C--(w , C , c/ . 
In order to homogenize notations , we also use the alternate notation ABS\[o o\]Cm to represent CF item ABSC'rn  , introducing a dummy symbol o . 
The specific forms taken by CF and xCF items for the different actions  5 are outlined in Figure 3  . 
5 Combining items and transitions
We provide the rules to combine items and transitions in order to retrieve all possible  2SA derivations . 
These rules do not explicit the scanning constraints and suppose that the string z may be read between positions w and k of the input string ? They use holes * to denote slots that not need be consulted  . For any minicon figuration A = ( u , A , a ) , we note ~ o = ( u , A ) its micro projection ?\[--*- WRITE\]r = ( w , C , e ) ,  ~ , ( w , C - -* F , e )
A**\[oo\]Cw=~AC ? ~\[ oo\]~'w where C = < w , C , c > , and F = ( k , F , c ) . 
\[/-WRITE\]r = ( w , C , e ) ,  ~ , ( w , C/Z F , f ) (1)
A**\[oo\]Cw == ~ G?G?/z\[oo\]Fw where C =   ( w , C , c ) , and F = ( k , F , f ) . 
\[~- WRITE\]r = ( m,C,e)vz . "( w,C~F , ~"~) (2)
A**\[oo\]Cm==~C?C ? ~\[ o?\]Fw where C = ( w , C , c ) , and F = k , F , ~ m ) . 
iX-WRITE\]T = ( W , C , c ) : z(w , CX ~ F , e )   ( 3 ) \]i?**\[??\]CWM**\[o o\]Aw ~ MC ?\\ [??\] Fw ( 4 ) where C = ( w , C , c ) , A = ( u , A , a ) , and F = < k , F , a) . 
\[--*-ERASE\]r = ( e , B - -* C , e ) ,  ~  , ( e , F , e ) A ? MA\[??\]\]~ w'4?\]~?~\[DE\]Oe ~ A?MA\[DE\]F e ( 5 ) where C = ( w , C , c ) , b = ( v , B , b ) , ~' = ( k , F , c/ , and ( when D#o ) D = ( s , D , b) . 
1337\[x , ~- ERASE \] ~-= ( e , B x ~ C , e ) , z(e , f , f )   21? B?"~\[D*\]C'e~I ?* A\[o o\]-~lw=~-/V/?O#\[ \] ~ C?\]~'e  ( 6 ) f ~ ? o ~\ [ oolBw where C ' = ( w , C , c ) , /~ = ( v , B , b ) , M = (/ , M , m ) , ~' = ( k , F , f ) , and ( when D~o )
D = (*,*, m).
IF-ERASE \]~-=( e , B  ~ C , ~'~) ~( m , F , e ) /~? B ~\ [ oo\]Ce ~ MNA\[DE\]Fm ( 7 ) MNA\[DE\]Bm where C = ( w  ~ C , ~ m ) , B = ( v , B , b ) , and ~' = ( k , F , a)\[/Z-ERASE\]r = ( e , B/Z C , c ) , = ~( e , F , e ) MNA\[~\]l~w/~?\]~~~~/?/Z\[??\]C e==~MNA\[??\]/ae ( S ) where ( ~7 =  ( w , C , c/ , B = ( v , B , b / , and ~' = ( k , F , b ) . B?B ?/ Z\[DE?\]Ce
MNA\[oolBw ~ MNA\[OPI~'e(9)
MD?x , ~\[OP\]E , e where C ' = ( w , C , c ) , /~ = ( v , B , b ) , ~' = k , F , b ) , and ( when O#o ) O = < l , O , b ) . 
\[SWAP\]r = ( p,C,~), z(q,F,~)
AB6\[DE\]Cm~AB6\[DEI~'m(10) where C ? = ( w , C , c ) , ~' = ( k , F , c ) , and either c = ~= ~? or ~= e . 
The best way to apprehend these rules is to visualize them graphically as done for the two most complex ones  ( Rules 6 and 9 ) in Figures 4 and 5 . 
A"--L
Figure 4: Application of Rule 6
NCD ~ MP "~'-" ~
Figure 5: Application of Rule 95 . 1 Reducing the complexity An analysis of the time complexity to apply each rule gives us polynomial complexities O  ( n " ) with u <_6 except for Rule 9 where u = 8 . However , by adapting an idea from ( Nederhof ,  1997) , we replace Rule 9 by the alternate and equivalent Rule 11  . 
" B?*/\[b'E?\]C'e,D?x,,~\[OP\]~'e
MNA\[oo\]l~w ~ MNA\[OPI~e(11)
M . '%\[OP\]*e where C7:(w , C , c ) , B = ( v , B , b ) , ~' = ( k , F , b ) , and ( when O?v)O = ( l , O , b ) . 
Rule 11 has same complexity than Rule 9 , but may actually be split into two rules of lesser complexity O  ( n6 )  , introducing an intermediary pseudo-item BB/Z\[\ [ OP\]\]Ce  ( intuitively assimilable to a " deeply escaped " CF derivation  )  . 
Rule 12 collects these pseudo-items ( independently from any transition ) while Rule 13 combines them with items ( given a/Z-ERASE transition ~- )  . 
BB/Z\[/ ) E?\]C'e === ~ BB/Z\[\[OP\]\] ( 3' e ( 12 ) * D?\\[OP\]E , e1~?\]~?/ Z\[\[OP\]\]Ce
MNA\[c~\]I~w ~ MNA\[OP\]F e (13)
M * ~ , ~\[ OP\]*e where C7 = ( w , C , c , B = ( v , B , b ) , ~' = ( k , F , b ) , and ( when O?o)O = ( l , O , b ) . 
Theorem 5 . 1 The worst time complexity of the application rules  ( 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 10 , 12 , 13 ) is O ( n 6 ) where n is the length of the input string . The worst space complexity is O(nS ) . 
5.2 Correctness results
Two main theorems establish the correctness of derivable items w  . r . t , derivable configurations . 
A derivable item is either the initial item or an item resulting from the application of a combination rules on derivable items  . The initial item (0 , e ) (0 , e ) ~\[ oo \] < 0 ,  $0 , ~ w > w stands for the virtual derivation step ( w ,  0 , e , e)\[-(w ,  0 ,  ~$0 , ~ w ) . 
Theorem 5 . 2  ( Soundness ) For every derivable item Z = AB6\[?IE\]Cm , there exists a derivation on configurations ( o , e ) ID---Ul~-v such that H\[-~-V is a CF or xCF derivation representable by I  . 
Proof : By induction on the item derivation length and by case analysis  . I configuration ( m , w , EC , ~c ) , there exists a derivable item AB~\[DE\]Cm such that C =  ( w , C , c . 
Proof : By induction on the configuration derivation length and by case analysis of the different application rules  . We also need the following " Extraction Lemma " .  
Proposition 5 . 1 From any derivation (0 , e)I--~-(m , w , EC , ~ c ) may be extracted a suffix CF or xCF subderivation U\[~  ( m ,   . ,, ~ . C,~c ) for some configuration U . 
5.3 Illustration
In the context of TAG parsing ( Sect .  3) , we can provide some intuition of the items that are built with  . A(G ,  "-* ,  +-) , using some characteristic points encountered during the traversal of an adjunction  ( Fig .  6) . 
on ADJ on SPINE on FOOT after CALL

AISI'--'~\[ oO\]FlW
BiFl " N\[oo \] Aaw before RET

AIS1---+\[FIA4\]F2 e
B1F1",.~\[G,B4\]A4 e
Figure 6: Adjunction and Items 6 Conclusion This paper unifies different results about TAGs and LIGs in an uniform setting and illustrates the advantages of a clear distinction between the use of an operational device and the evaluation of this device  . The operational device ( here SD-2SA ) helps us to focus on the description of parsing strategies  ( for LIGs and TAGs )  , while , independently , we design an efficient evaluation mechanism for this device  ( here tabular interpretation with complexity O ( n6 ) ) . 
Besides illustrating a methodology , we believe our approach also opens new axes of research  . 
For instance , even if the tabular interpretation we have presented has  ( we believe ) the best possible complexity , it is still possible ( using techniques outside the scope of this paper , ( Barth 61emy and Villemonte de la Clergerie ,  1996 ) ) to improve its efficiency by refining what information should be kept in each kind of items  ( hence increasing computation sharing and reducing the number of items  )  . 
To handle TAGs or LIGs with attributes , we also plan to extend SD-2SA to deal with first-order terms ( rather than just symbols ) using unification to apply transitions and subsumption to check items  . 
References
Alfred V . Aho .  1968 . Indexed grammars -- an extension of contextfree grammars  . Journal of the
ACM , 15(4):647-671, October.
Miguel Angel Alonso Pardo , Eric de la Clergerie , and Manuel Vilares Ferro .  1997 . Automata-based parsing in dynamic programming for Linear In-dexed Grammars  . In A . S . Narin'yani , editor , Proc . of DIALOGUE'97 Computational Linguistics and its Applications International Workshop  , pages 2227 , Moscow , Russia , June . 
F . P . Barth ~ lemy and E . Villemonte de la Clergerie . 
1996 . Information flow in tabular interpretations for generalized pushdown automata  . To appear in journal of TCS . 
Tilman Becker .  1994 . A new automaton model for TAGs : 2-SA . Computational Intelligence , 10(4):422-430 . 
Gerald Gazdar .  1987 . Applicability of indexed grammars to natural anguages  . In U . Reyle and C . Rohrer , editors , Natural Language Parsing and Linguistic Theories , pages 69-94 . D . Reidel Publishing Company . 
Aravind K . Joshi .  1987 . An introduction to tree adjoin in grammars . In Alexis Manaster-Ramer , editor , Mathematics of Language , pages 87-115 . John Benjamins Publishing Co . , Amster-dam/Philadelphia . 
Mark-Jan Nederhof .  1997 . Solving the correct-prefix property for TAGs . In T . Becker and H . -V . 
Krieger , editors , Proc . of MOL'97, pages 124-130,
Schloss Dagstuhl , Germany , August.
Mark-Jan Nederhof .  1998 . Linear indexed automata and tabulation of TAG parsing  . In Proc . of First Workshop on Tabulation in Parsing and Deduction  ( TAPD'98 )  , pages 19 , Paris , France , April . 
Owen Rambow .  1994 . Formal and Computational Aspects of Natural Language Syntax  . Ph . D . thesis,
University of Pennsylvania.
K . Vijay-Shanker .  1988 . A Study of Tree Adjoining Grammars . Ph . D . thesis , University of Pennsylvania , January . 

