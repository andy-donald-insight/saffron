Separating Surface Order and Syntactic Relations
in a Dependency Grammar
Norbert Br Sker
Universitiit Stuttgart
Azenbergstr . 12
D-70174 Stuttgart
NOBI~IMS . UNI-STUTTGART . DE
Abstract
This paper proposes decoupling the dependency tree from word order  , such that surface ordering is not determined by traversing the dependency tree  . We develop the notion of a word order domain structure  , which is linked but structurally dissimilar to the syntactic dependency tree  . The proposal results in a lexicalized , declarative , and formally precise description of word order ; features which lack previous proposals for dependency grammars  . Contrary to other lexicalized approaches to word order  , our proposal does not require lexical ambiguities for ordering alternatives  . 
1 Introduction
Recently , the concept of valency has gained considerable attention  . Not only do all linguistic theories refer to some reformulation of the traditional notion of valency  ( in the form of 0-grid , subcategorization list , argument list , or extended domain of locality ) ; there is a growing number of parsers based on binary relations between words  ( Eisner , 1997; Maruyama ,  1990) . 
Given this interest in the valency concept , and the fact that word order is one of the main difference between phrase-structure based approaches  ( henceforth PSG ) and dependency grammar ( DG )  , it is valid to ask whether DG can capture word order phenomena without recourse to phrasal nodes  , traces , slashed categories , etc . A very early result on the weak generative quivalence of context-free grammars and DGs suggested that DGs are incapable of describing surface word order  ( Gaifman ,  1965) . 
This result has recently been critizised to apply only to impoverished DGs which do not properly represent formally the expressivity of contemporary DG variants  ( Neuhaus & Br6ker ,  1997) . 
Our position will be that dependency relations are motivated semantically  ( Tesni~re ,  1959) , and need not be projective ( i . e . , may cross if projected onto the surface ordering  )  . We argue for so called word order domains , consisting of partially ordered sets of words and associated with nodes in the dependency tree  . These order domains constitute a tree defined by set inclusion  , and surface word order is determined by traversing this tree  . A syntactic analysis the re-for consists of two linked  , but dissimilar trees . 
Sec .   2 will briefly review approaches to word order in DG  . In Sec . 3, word order domains will be defined , and Sec .   4 introduces a modal logic to describe dependency structures  . Sec .   5 applies our approach to the German clause and Sec  . 6 relates it to some PSG approaches . 
2 Word Order in DG
A very brief characterization of DG is that it recognizes only lexical  , not phrasal nodes , which are linked by directed , typed , binary relations to form a dependency tree ( Tesni~re , 1959; Hudson ,  1993) . The following overview of DG flavors shows that various mechanisms  ( global rules , general graphs , procedural means ) are generally employed to lift the limitation of projectivity and discusses some shortcomings of these proposals  . 
Functional Generative Description ( Sgall et al ,  1986 ) assumes a language-independent underlying order , which is represented as a projective dependency tree  . This abstract representation of the sentence is mapped via ordering rules to the concrete surface realization  . Recently , Kruijff ( 1997 ) has given a categorial-style formulation of these ordering rules  . He assumes associative categorial operators , permuting the arguments to yield the surface ordering  . One difference to our proposal is that order ( based on valid structures representing word order  )  , eschewing the nondeterminism introduced by unary operators  ; the second difference is the avoidance of an underlying structure ~ which stratifies the theory and makes incremental processing difficult  . 
Meaning-Text Theory ( Melc'fik , 1988) assumes seven strata of representation . The rules mapping fi'om the unordere dependency trees of surface-syntactic representations onto the annotated lexeme sequences of deep -morphological representations include global ordering rules which allow discontinuities  . These rules have not yet been formally specified ( Melc'~tk &
Pertsov , 1987 p . 1870.
Word Grammar ( WG , Hudson ( 1990 ) ) is based on general graphs instead of trees . The ordering of two linked words is specified together with their dependency relation  , as in the proposition " object of verb follows it  "  . Extraction of , e . g . , objects is analyzed by establishing an additional dependency called visitor between the verb and the extractee  , which requires the reverse order , as in " visitor of verb precedes it " . This results in inconsistencies , since an extracted object must follow the verb ( being its object ) and at the same time precede it ( being its visitor )   . The approach compromises the semantic motivation of dependencies by adding purely order-induced epen-dencies  . WG is similar to our proposal in that it also distinguishes a propositional metalanguage describing the graphbased analysis structures  . 
Dependency Unification Grammar ( DUG , Hellwig ( 1986 ) ) defines a treelike data structure for the representation fsyntactic analyses  . ' Using morphosyntactic features with special interpretations  , a word defines abstract positions into which modifiers are mapped  . Partial orderings and even discontinuities can thus be described by allowing a modifier to occupy a position defined by some transitive head  . The approach requires that the parser interpretes several feature specially  , and it cannot restrict the scope of discontinuities  . 
Slot Grammar ( McCord , 1990) employs a number of rule types , some of which are exclusively concerned with precedence  . So-called head/slot and slot/slot ordering rules describe the precedence in projective trees  , referring to arbitrary predicates overhead and modifiers  . 
Extractions ( i . e . , discontinuities ) are merely handled by a mechanism built into the parser  . 
3 Word Order Domains
Summarizing the previous discussion , we require the following of a word order description for DG : ? not to compromise the semantic motivation of dependencies  , ? to be able to restrict discontinuities to certain constructions and delimit their scope  , ? to be lexicalized without requiring lexical ambiguities for the representation for dering alternatives  , ? to be declarative ( i . e . , independent of an analysis procedure ) , and ? to be formally precise and consistent . 
The subsequent definition of an order domain structure and its linking to the dependency tree satisify these requirements  . 
3.1 The Order Domain Structure
A word order domain is a set of words , generalizing the notion of positions in DUG . The cardinality of an order domain may be restricted to at most one element  , at least one element , or-by conjunction-to exactly one element . Each word is associated with a sequence of order domains  , one of which must contain the word itself , and each of these domains may require that its elements have certain features  . Order domains can be partially ordered based on set inclusion : If an order domain d contains word w  ( which is not associated with d )  , every word w ~ contained in a domain d ~ associated with w is also contained in d  ; there for , d ~ Cd for each d ~ associated with w . This partial ordering induces a tree on order domains  , which we call the order domain structure . 
Take the example of German " Den Mannhat der Jungegesehen "  ( " theman AGe-has - the boy NoM-seen " )  . Its dependency tree is shown in Fig . l , with word order domains indicated by dashed circles  . The finite verb , " hat " , defines a sequence of domains , < dl , d2 , d3> , which roughly correspond to the topological fields in the German main clause  . The nouns " M an n ", '' C . " derJunge ; ' . ge~ehen . ,,, , :  . den Mann- . , " '  .   . "' Figure 1: Dependency Tree and Order Domains for " Den Mann hat der Jun geges e hen " d l d  , 4 hatd5 d6
Mann Jungeges ehen
Figure 2: Order Domain Structure for " Den
Mannhat der Jungege sehen " aud " Junge " and the participle " gese hen " each define one order domain  ( d4 , cl5 , d6 , resp . ) . Set inclusion gives rise to the domain structure in Fig  . 2 , where the individual words are attached by dashed lines to their including domains  ( dl and d4 collapse , being identical ) .  1 3 . 2 Sur face Order ing How is the surface order derived from an order domain structure ? First of all  , the ordering of domains is inherited by their respective le-ments  , i . e . , " Mann " precedes ( any element of ) d2 , '! hat " follows ( any element of ) dl , etc . 
Ordering within a domain , e . g . , of " hat " and d6 , or d5 and d6 , is based on precedence predicates ( adapting the precedence predicates of WG )  . There are two differentypes , one ordering a word w . r . t , any other element of the domain it is associated with  ( e . g . , " hat"w . r . t , d 6) , and another ordering two modifiers , referring to the dependency relations they occupy  ( d5 and d6 , referring to subj and vpart ) . A verb like " hat " introduces two precedence predicates  , requiring other words to follow itself and the participle to follow subject and object  , resp . : 2" hat " ~( < . A(vpart ) > subj , obj ) ~ Note that in this case , we have not a single rooted tree , but rather an ordered sequence of trees ( by virtue of ordering dl , d2 , and d3) as domain structure . In general , we assume the sentence period to govern the finite verb and to introduce a single domain for the complete sentence  . 
2 For details of the notation , please refer to Sec .  4 . 
Informally , the first conjunct is satisfied by any domain in which no word precedes " hat "  , and the second conjunct is satisfied by any domain in which no subject or object follows a participle  . The domain structure in Fig . 2 satisfies these restrictions ince nothing follows the participle  , and because " denMann " is not an element of d2 , which contains " hat " . This is an important interaction of order domains and precedence predicates : Order domains define scopes for precedence predicates  . In this way , we take into account that dependency trees are flatter than PS-based ones  3 and avoid the formal inconsistencies noted above for WG  . 
3.3 Linking Domain Structure and
Dependency Tree
Order domains easily extend to discontinuous dependencies  . Consider the nonprojective tree in Fig . 1 . Assuming that the finite verb governs the participle  , no projective dependency between the object " den Mann " and the participle " gesehen " can be established  . We allow nonprojectivity by loosening the linking between dependency tree and domain structure : A modifier  ( e . g . , " Mann " ) may not only be inserted into a domain associated with its direct head  ( " gese-hen " )  , but also into a domain of a transitive head ( " hat " )  , which we will call the positional head . 
The possibility of inserting a word into a domain of some trausitive head raises the questions of how to require contiguity  ( as needed in most cases )  , and how to limit the distance between the governor and the modifier in the case of discontinuity  . From a descriptive viewpoint , the syntactic onstruction is often cited to determine the possibility and scope of discontinuities  ( Bhatt , 1990; Matthews ,  1981) . In PS-based accounts , the construction is represented by phrasal categories  , and extraction is limited by bounding nodes ( e . g . , Haegeman (1994), Becker et al (1991)) . In dependency-based accounts , the construction is represented by the dependency relation  , which is typed or labelled to indicate constructional distinctions which are configurationally defined in PSG  . Given this correspondence , it is natural to employ dependencies in the description of discontinuities as  fol-3Note that each phrasal level in PS-based trees defines a scope for linear precedence rules  , which only apply to sister nodes . 
176 lows : For each modifier of a certain head , a set of dependency tpes is defined which may link the direct head and the positional head of the modifier  ( " gesehen " and " hat " , resp . ) . If this set is empty , both heads are identical and a contiguous attachment results  . The impossibility of extraction from , e . g . , a finite verb phrase may follow from the fact that the dependency embedding finite verbs  , propo , may not appear on any path between a direct and a positional head  .   4   4 The Description Language This section sketches a logical language describing the dependency structure  . It is based on modalogic andowes much to work of Blackburn  ( 1994 )  . Asheargues , standard Kripke models can be regarded as directed graphs with node annotations  . We will use this interpretation to represent dependency structures  . Dependencies and the mapping from dependency tree to order domain structure are described by modal operators  , while simple properties such as word class , features , and cardinality of order domains are described by modal propositions  . 
4.1 Model Structures
In the following , we assume a set of words , l/Y , ordered by a precedence rlation ,  -< , a set of dependency tpes , T ) , a set of atomic feature values . 4, and a set of word classes , C . We define a family of dependency relations RdCW  ?   ~42  , dE : D and for convenience abbreviate the union UdET ~ Rd as R : D  . 
Def : A dependency tree is a tuple ( W , Wr , R  ~ , VA , Vc ) , where R~forms a tree over VP rooted in Wr , VA : V~~2 A maps words to sets of features , and V?:1/~~C maps words to word classes . 
Def : An order domain ( over W ) m is a set of words from ~ ) where V W l , W2 , W3EVV : ( wl-<w2-<w3AwlEmA w3Era)~w2Em . 
Def : An order domain structure ( over W ) f14 is a set of order domains where Vm , m  ~ E . ?4:mMm~=OVmCm'Vm~Cm . 
4One review pointed out that some verbs may allow extractions  , i . e . , that this restriction is lexical , not universal . This fact can easily be accomodated because the possibility of discontinuity  ( and the dependency tpes across which the modifier may be extracted  ) is described in the lexical entry of the verb . In fact , a universal restriction could not even be stated because the treatment is completely lexicalized  . 
Def : A dependency structure T is a tuple ( VV , Wr , R  ~ , VA , Vc ,   . A4 , VM > where ( I , V , wr , R z ~ , VA , VC > is a dependency tree , A4 is an order domain structure over ~ V , and VA a:V ~ ~ . Alln maps words to order domain sequences . 
Additionally , we require for a dependency structure four more conditions :  ( 1 ) Each word w is contained in exactly one of the domains from V  ~  ( w )   , (2) all domains in V ~( w ) are pairwise disjoint ,   ( 3 ) each word ( except w ~ ) is contained in at least two domains , one of which is associated with a ( transitive ) head , and ( 4 ) the ( partial ) ordering of domains ( as described by VM ) is consistent with the precedence of the words contained in the domains  ( see ( Brhker , 1997) for more details) . 
4.2 The Language ?: ~
Fig . 3 defines the logical language /:~ used to describe dependency structures  . Although they have been presented ifferently , they can easily be rewritten as ( multimodal ) Kripke models : The dependency relation Rd is represented as modality  ( d > and the mapping from a word to its it horder domain as modality o ~  . 5 All other formulae denote properties of nodes , and can be formulated as unary predicates-most evident for word class and feature assignment  . For the precedence predicates < . and < ~, there are inverses > . and > ~ . For presentation , the relation places C 142 x 142 has been introduced , which holds between two words iff the first argument is the positional head of the second argument  . 
A more elaborate definition of dependency structures and ?~ defines two more dimensions  , a feature graph mapped off the dependency tree much like the proposal of Blackburn  ( 1994 )  , and a conceptual representation based on terminological logic  , linking content words with reference objects and dependencies with conceptual roles  . 
5 The German Clause
Traditionally , the German main clause is described using three topological fields  ; the initial and middle fields are separated by the finite  ( auxiliary ) verb , and the middle and the 5The modality O ~ can be viewed as an abbreviation of o ~ O  ~  , composed of a mapping from a word to its ith order domain and from that domain to all its elements  . 

Syntax ( valid formulae ) Semantics ( satisfaction relation ) c ? ? v , Vc?CT , wa??v , Va ? AT , w < d ) ? ? ? v , Vd ? 79 , ? ? ? vT , w < . 6 ? v , T , w < ~? ? 9 , V6c_79$~??v , VT c Doisingle ? ED , Vi ?$ V , % 4o ~ filled ? ? D , V i ? ~ V
D  ~ a ? ? D , Vi ?$ V , a ? A ?^? ? ? ~ , V ? , ??? v-~?6 . ? ~, V ? ? ? v
T , w
T , w
T , w
T , w
T , iv
T , w
T , w~cka < d ) ? : ?* c=Y c ( w ) : ?* ae Y ( w ) : ?~3w'6142:wRdW'AT , w'~?:~3m?M:(V . ~( w ) = ( .   .   . m .   .   . )^Vw'?m:(w=w'Vw-<w')):?~~3w' , w " , w ''' ? W : places(w' , w)
A places(w ' , w")Aw'"R6wAw'""<w$6:?~3w' , w "? ~42: wRvwAplaces(w " , w)Aw"R ; w'o ! w'?( , , , 11^\]o ~ single : ? t , w ' ~ Bw ": ( w"RT ) w'n , , <  1 w " e-k ob filled I 1   t:3~a : ?* Vw '? Oi ( V . M(w )): T , w ' k a ~? A ? : ? ~ , T , w ~? and T , w~?-- , ? :?? , not T , w ~? Figure 3: Syntax and Semantics of Ev Formulae Vfin ~ ol ( single A filled ) AOL initial\[1\]
AOL(middleAnorel)\[2\]
A03 single ADL(finalAnorel)\[3\]
AV2?~( middleA <, A\[3~norel)\[4\]
AVEnd ? ~( middleA > ,)\[5\]
AVl ? ~ ( initial Anorel)\[6\]
Figure 4: Domain Description of finite verbs " hat " A Vf in  \[7\] 
A ( subj ) (" Junge " A1"0)\[8\]
A(vpart ) (" gesehen " AS0\[9\]
A ~ finalA > subj , obj\[i0\]
A ( obj ) (" Mann " Atv part ))\[11\]
Figure 5: Hierachical Structure final fields by infinite verb parts such as separable prefixes or participles  . We will generalize this field structure to verb -initial and verb-final clauses as well  , without going into the linguistic motivation due to space limits  . 
The formula in Fig . 4 states that all finite verbs ( word class Vf in 6C ) define three order domains , of which the first requires exactly one element with the feature initial  \[1\]  , the second allows an unspecified number of elements with features middle and no rel  \[2\]  , and the third allows at most one element with features final and no rel  \[3\]  . The features initial , middle , and final 6 . 4 serve to restrict placement of certain phrases in specific fields  ; e . g . , no reflexive pronouns can appear in the final field  . Thenorel 6 . 4 feature controls placement of a relative NP or PP  , which may appear in the initial field only in verb-final clauses  . The order types are defined as follows : In a verb-second clause  ( feature V2 )  , the verb is placed at the beginning (< . ) of the middle field ( middle ) , and the element of the initial field cannot be a relative phrase  ( o ~ no rel in\[4\] )  . In a verb-final clause ( VEnd ) , the verb is placed at the end (> . ) of the middle field , with no restrictions for the initial field ( relative clauses and non-relative verb-final clauses are subordinated to the noun and conjunction  , resp . ) \[5\] . In a verb-initial clause ( Vl ) , the verb occupies the initial field\[6\] . 
The formula in Fig . 5 encodes the hierarchical structure from Fig . 1 and contains lexical restrictions on placement and extraction  ( the surface is used to identify the word )  . Given this , the order type of " hat " is determined as follows : The participle may not be extraposed  ( ~final in\[10\] ; a restriction from the lexical entry of " hat ") , it must follow " hat " ind 2 . Thus , the verb cannot be of order type V End , which would require it to be the last element in its domain  ( > . in\[5\]) . " Mann " is not adjacento " gesehen " , but may be extracted across the dependency vpart ( $ vpart in \[11\] )  , allowing its insertion into a domain defined by " hat "  . It cannot precede " hat " ind 2 , because " hat " must either begind 2 ( due to < . in\[4\]) or itself go into dl . But dl allows only one phrase ( single ) , leaving only the domain structure from Fig . 2, and thus the order type V2 for " hat " . 
1786 Comparison to PSG Approaches
One feature of word order domains is that they factor ordering alternatives from the syntactic tree  , much like feature annotations do for morphological alternatives  . Other lexicalized grammars collapse syntactic and ordering information and are forced to represent ordering alternatives by lexical ambiguity  , most notable L-TAG ( Schabes et al , 1988) and some versions of CG ( Hepple ,  1994) . This is not necessary in our approach , which drastically reduces the search space for parsing  . 
This property is shared by the proposal of Reape ( 1993 ) to associate HPSG signs with sequences of constituents  , also called word order domains . Surface ordering is determined by the sequence of constituents associated with the root node  . The order domain of a mother node is the sequence union of the order domains of the daughter nodes  , which means that the relative order of elements in an order domain is retained  , but material from several domains may be interleaved  , resulting in discontinuities . 
Whether an order domain allows interleaving with other domains is a parameter of the constituent  . This approach is very similar to ours in that order domain separate word order from the syntactic tree  , but there is one important difference : Word order domains in HPSG do not completely free the hierarchical structure from ordering considerations  , because discontinuity is specified per phrase , not per modifier . For example , two projections are required for an NP , the lower one for the continuous material ( determiner , adjective , noun , genitival and prepositional attributes ) and the higher one for the possibly discontinuous relative clause  . This dependence of hierarchical structure on ordering is absent from our proposal  . 
We may also compare our approach with the projection architecture of LFG  ( Kaplan & Bresnan , 1982; Kaplan ,  1995) . There is a close similarity of the LFG projections  ( c-structure and f-structure ) to the dimensions used here ( order domain structure and dependency tree , respectively ) . C-structure and order domains represent surface ordering  , whereas f-structure and dependency trees how the subcategorization rvalence requirements  . What is more , these projections or dimensions are linked in both accounts by ' an elementwise mapping  . The difference between the two architectures lies in the linkage of the projections or dimensions : LFG maps f-structure of fc-structure  . In contrast , the dependency relation is taken to be primitive here  , and ordering restrictions are taken to be indicators or consequences of dependency relations  ( see also BrSker ( 1998b , 1998a )) . 
7 Conclusion
We have presented an approach to word order for DG which combines traditional notions  ( semantically motivate dependencies , topological fields ) with contemporary techniques ( logical description language , model theoretic semantics ) . Word order domains are sets of partially ordered words associated with words  . A word is contained in an order domain of its head  , or may float into an order domain of a transitive head  , resulting in a discontinuous dependency tree while retaining a projective order domain structure  . Restrictions on the floating are expressed in a lexicalized fashion in terms of dependency relations  . An important benefit is that the proposal is lexicalized without reverting to lexical ambiguity to represent order variation  , thus profiting even more from the efficiency considerations discussed by Schabes et al  ( 1988 )  . 
It is not yet clear what the generative capacity of such lexicalize discontinuous DGs is  , but at least some index languages ( such as an bncn ) can be characterized . Neuhaus & Br Sker ( 1997 ) have shown that recognition and parsing of such grammars is  A/'7~-complete   . A parser operating on the model structures is described in  ( Hahn et al ,  1997) . 
References
Becket , T . , A . Joshi & O . Rainbow (1991) . Long-Distance scrambling and tree-adjoining grammar  . In Proc . 5th Conf . of the European Chapter of the ACL , pp .  2126 . 
Bhatt , C .  (1990) . Die syntaktische Strukturder Nominal phrase im Deutschen  . Studien zurdeutschen Grammatik 38 . Tfibingen : Narr . 
Blackburn , P .  (1994) . Structures , Languages and Translations : The Structural Approach to Feature Logic  . In C . Rupp , M . Rosner & R . Johnson ( Eds . ), Constraints , Language and Computation , pp .  127 . London : Academic Press . 
BrSker , N .  (1997) . Eine Dependenz grammatik zur Kopplung heterogener Wissens system eauf modal logischer Basis  . Dissertation , Deutsches
Seminar , Universit ~ it Freiburg.

BrSker , N . (1998a ) . How to define a contextfree backbone for DGs : An experiment in grammar conversion  . In Proc . o \] the COLING-A CL'98 workshop " Processing of Dependency-based Grammars "  . Montreal/CAN , Aug 15, 1998 . 
BrSker , N . (1998b ) . A Projection Architecture for Dependency Grammar and Howit Compares to LFG  . In Proc . 1998 Int'l Lexical-Functional Grammar Conference .   ( accepted as alternate paper ) Brisbane/AUS : Jun30-Jul2 ,  1998 . 
Eisner , J .  (1997) . Bilexical Grammars and a Cubic-Time Probabilistic Parser  . In Proc . of Int'l Workshop on Parsing Technologies , pp .  54-65 . 
Boston/MA : MIT.
Gaifman , H .  (1965) . Dependency Systems and Phrase Structure Systems . Information and
Control , 8:304-337.
Haegeman , L .  (1994) . Introduction to Government and Binding . Oxford/UK : Basil Blackwell . 
Hahn , U . , P . Neuhaus & N . BrSker (1997) . Message-Passing Protocols for Real-World Parsing -An Object-Oriented Model and its Preliminary Evaluation  . In Proc . Int'l Workshop on Parsing Technology , pp .  101-112 . Boston/MA : MIT,
Sep 1721, 1997.
Hellwig , P .  (1986) . Dependency Unification Grammar . In Proc . I 1th Int'l Conf . on Computational Linguistics , pp .  195-198 . 
Hepple , M .  (1994) . Discontinuity and the Lambek Calculus . In Proc . 15th Int'l Conf . on Computational Linguistics , pp .  1235-1239 . Kyoto/JP . 
Hudson , R .  (1990) . English Word Grammar . Ox-ford/UK : Basil Blackwell . 
Hudson , R .  (1993) . Recent developments in dependency theory . In J . Jacobs , A . v . Stechow , W . Sternefeld & T . Vennemann ( Eds . ), Syntax . Ein internationales H and buchzeit genSssis-cher For sehung  , pp .  329-338 . Berlin : Walter de

Kaplan , R .  (1995) . The formal architecture of Lexical-Functional Grammar  . In M . Dalrymple , R . Kaplan , J . I . Maxwell &: A . Zaenen ( Eds . ) , Formal Issues in Lexical-Functional Grammar , pp .  727 . Stanford University . 
Kaplan , R . & J . Bresnan (1982) . Lexical-Functional Grammar : A Formal System for Grammatical Representation  . In J . Bresnan & R . Kaplan ( Eds . ) , The Mental Representation of Grammatical Relations  , pp .  173-281 . Cambridge,
MA : MIT Press.
Kruijff , G . -J . v .  (1997) . A Basic Dependency-Based Logical Grammar . Draft Manuscript . Prague:
Charles University.
Maruyama , H .  (1990) . Structural Disambiguation with Constraint Propagation  . In Proc . 28th Annual Meeting of the ACL , pp .  31-38 . Pitts-burgh/PA . 
Matthews , P .  (1981) . Syntax . Cambridge Textbooks in Linguistics , Cambridge/UK : Cambridge Univ . Press . 
McCord , M .  (1990) . Slot Grammar : A System for Simpler Construction of Practical Natural Language Grammars  . In R . Studer ( Ed . ), Natural Language and Logic , pp .  118-145 . Berlin , Heidelberg : Springer . 
Melc'hk , I .  (1988) . Dependency Syntax : Theory and Practice . Albany/NY : State Univ . Press of New

Melc'hk , I . & N . Pertsov (1987) . Surlace Syntax of English : A Formal Model within the MTT Framework  . Philadelphia/PA : John Benjamins . 
Neuhaus , P . &: N . BrSker (1997) . The Complexity of Recognition of Linguistically Adequate Dependency Grammars  . In Proc . 35th Annual Meeting of the ACL and 8th Conf . of the EACL , pp . 
337-343. Madrid , July 712, 1997.
Reape , M .  (1993) . A Formal Theory of Word Order : A Case Study in West Germanic  . Doctoral Dissertation . Univ . of Edinburg . 
Schabes , Y . , A . Abeille & A . Joshi (1988) . Parsing Strategies with ' Lexicalized ' Grammars : Application to TAGs  . In Proc . 12th Int'l Con\] . on Computational Linguistics , pp .  578-583 . 
Sgall , P . , E . Hajicova & J . Panevova (1986) . The Meaning of the Sentence in its Semantic and Pragmatic Aspects  . Dordrecht/NL:D . Reidel . 
Tesni & e , L .  (1959) . Elemdnts de syntaxe structurale . 
Paris : Klincksiek.

