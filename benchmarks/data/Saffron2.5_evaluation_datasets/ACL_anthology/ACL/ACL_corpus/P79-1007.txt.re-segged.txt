GENF ~ ALIZED AUGMENTED TRANSITION NET WORKG RAMMARS
FOR GENERATION FROMSD ?% NTICNET WORKS
Stuart C . Shapiro
Department of Computer Science , SUNY at Buffalo
I . YNTRODUCTYON
Augmented transition network ( ATN ) grammars have , since their development by Woods\[7; ~ , become the most used method of describing grammars for natural language understanding end question answering systems  . The advantages of the ATN notation have been su , naarized as " I ) perspicuity , 2) generative power , 3) efficiency of representation ,  4 ) the ability to capture linguistic regularities and generalities  , and 5) efficiency of operation . ,\[ I , p . 191 \] . The usual method of utilizing an ATN grammar in a natural language system is to provide an interpreter which can take any ATH graam ~ ar  , a lexicon , and a sentence as data and produce either a parse of a sentence or a message that the sentence does not conform to the granunar  . A compiler has been written\[2 ; 3 \] which takes an ATH grammar as input and produces a specialized parser for that grammar  , but in this paper we will presume that an Interpreter is being used  . 
A particular ATN grammar may be viewed as a program written in the ATH language  . The program takes a sentence , a linear sequence of symbols , as input , and produces as output a parse which is usually a parse tree  ( often represented by a LISPS-expression ) or some " k ~ ewledge reprssentatioc " such as a semantic network  . 
The operation of the program depends on the interpreter being used and the particular program  ( grannar )  , as well as on the input ( sentence ) being processed . 
Several methods have been described for using ATN grammars for sentence generation  . One method\[1, p . 2 35\]is to replace the usual interpreter by a generation interpreter which contake an ATN grammar written for parsing and use it to produce random sentences conforming to the grammar  . This is useful for testing and debugging the granmm Lr  . Another method \[5 \] uses a modified interpreter to generate sentences from a semantic network  . In this method , an ATN register is initialized to hold a node of the semantic network and the input to the grammar is a linear string of symbols providing a pat tern of the sentence to be generated  . Another method \[4 \] also generates sentences from a semantic network  . 
In this method , input to the granmmr is the semantic network i tself  . That is , instead of successive words of a surface sentence or successive symbols of a linear sentence pattern being scanned as the ATM grammar is traversed by the interpreter  , different nodes of the ssmantic network are scanned  . The gramnar controls the syntax of the generated sentence based on the structural properties of the semantic network and the information contained therein  . 
It was intended that a single ATN interpreter could be used both for standard ATN parsing and for generation based on this last method  . However , a special interpreter was written for generation grammars of the type described in  \[4  \] , and , indeed , the definition of the ATN formalism given in that paper  , though based on the standard ATN formalism , was inconsistent enough with the standard not at i on that a single interpreter could not be used  . This paper reports the results of work carried out to remo ~ those inconsistencies  . A generalization of the ATN formalism has been derived which allows a single interpreter to be used for both parsing and generating gras~re  . In fact , parsing and generating grammars can be subnetworks of each other  . For example an A ~ M grammar can be constructed so that the  , , parse , , Th is mater ia l i s based on work suppor ted in part by the Maticeu Ll Science Foundation under Grant #  MCS78-O2274  . 
of a natural language question is the natural language statement which answers it  , interaction with represent a-tion end in ference routines be in Rd one on arcs along the way  . The neW formalism is a strict generalization in the sense that it interprets all old ATN gralnars as having the same semantics  ( carrying out the same actions and producing the same parses  ) as before . 
2 . Gm~ERATION FROMA S~2~ANTIC NET WGRK--BRIEFOV ~ VIEg In our view , each node of a semantic network represe ats a concept  . The goal of the generator is , given a node , to express the concept represented by that node in a natural language surface string  . The syntactic category of the surface string is determined by the grammar  , which can include tests of the stracture of the semantic network connected to the node  . In order to express the concept , it is often necessary to include in the string substrings which express the concepts represented by adjacent nodes  . For example , if a node represents a fact to he expressed as a statement  , part of the statement may heanoun phrase expressing the concept represented by the node connected to the original node by an AGENT case arc  . 
This can be done by a recursive call to a sect ion of the grammar in charge of building noun phrases  . This section will be passed the adjacent node . When it finishes , the original statement section of the grammar will continue adding additional substrings to the growing statement  . 
In ATN grmrs written for parsing , are curst vepush does not change the input symbol being examined  , but when the original level continues , parsing continues at a different symbol . In the generation approach we use , a recursive push often involves a change in the senantic node being examined  , and the original level continues with the original node  . This difference is a major motivation of some of the generalizations to the ATN formalism discussed below  . ~ neother major motivation is that , in parsing a string of symbols , the . , next . . symbol is well defined , but in , . parsing . a network, . next " mast be explicitly specified . 
3. THEGEN~IALIZATION
The following subsections shoW the generalized syntax of the ATN formalism  , and assume a knowledge of the standard formalimm ( \[ I \] is an excellent introduction )  . 
Syntactic structures already familiar to ATH users  , but not discussed here remain unchanged . Parentheses and terms in uppercase letters are terminal symbols  . 
Lowercase terms in angle brackets are nonterminals  . 
Ternmenclosed in square brackets are optional . Terms followed by . *, m~occur zero or more times in succession . To avoid confusion , in there , sAnder of this section we will underline the name of the * register  . 
3.1 TERMINAL ACTIONS
Successful traversal of an ATN arc might or might not consume an input symbol  . When parsing , such consump-ticn normally occurs , when ge~erating it normally does not , but if it does , the next symbol ( semantic node ) must be specified . To allow for these choices , we have returned to the technique of \[6 \] of having two terminal action , TO and J~P , and have added an optional second argent to TO . The syntax is: ( TO < stats >\[~ for ~\] )   ( JUMP < state > ) JUMP never conswms the input symbol ; TO always does . 
It the < for w ~ is absentint be TO action , the nex~symbol to be scanned will be the next one in the input buffer  . If < form is present , its value will be the next symbol to be scanned . All traditional ATN arcs except JU ~ and POP end with a terminal action  . 
The explanation given for the replacement of the JUMP terminal action by the Ob ~ are ~ acth at  ,   , since POP , PUSH and VTR ares never advance the input , to decide whether or not an arc advanced the input required k~o~-ledge of both the arc type and termination action  . The introduction o ? the JUMP arc .   .   . means that the inputed vancement is a funetinn of the arc type alone  . "  \[2\] That our reintroduction of the JUMP ter ~ L~tl action does not bring back the con/~ion is explained below in ~ tionh  . 
3.2 A PeS
We retain a JU~arc a8 veil as a JU~temlnal action . 
The JUMP arc provides a place to make a narbit rary test and par'forms ow actions without consuming an input symbol  . We need such an are that does conmmmits inputs ~ bol  , but TST is not adequate since it , ~ CAT , is really abundle of ares , one for each lexloal entry of the scarmed symbol , should the letter be lexl call 7 ambiguous . A semntle node , however , does not have a lexlcal entry . We therefore introduce a TO eros ( TO ( < state>\[<~em\] ) < test > < aetion ~ ) It < test > is successful , the < aotion > s are performed and transfer is made to < state >  . The inputs ~ uboliscon ~ . The next symbol to be scanned is the value OF < form > if it is present or the next symbol in the input buffer if ~ fer ~ is ~ Losing  . 
The PUSH arc mBk ~8 two as nn ~ lo~ms 1 ) the first symbol to be scudint hs ~ zheetvoz4c is the cmTent contents of the * registers 2  ) the cuzTent input symbol will be consuned ~ oy the subnet ~ or k  , so the content8 of can be replaced by the value returned by the subnet-~ork  . We need an are that causes a ~ ive call to su ~a etwork  , but makes neither of ~ heeat wo assmnp-tions , so we introduce the CALL arc: ( CALL < state > ~ fom ~ es ~> < preaction or ac ~ ion~<rcgieter > < action >* < terminal action ~   ) where < preaction or action > is < preaetice ~ or < aotloa ~>  . 
Lf the < test > is successful , all the < action ~ e of < preact lonoraction > are performed and a z qenw sl ve is made to the state < state > whore the nexts ~ mbol to be scanned is the value of < fo ~ and registers are initia lized by the < prenc ~ I on > s  . Y . f the subnetwer k succeeds , its value is placed into < rsgl star > and the < action  , s and < terminal action > are performed . 
Just as the normal TO terminal action is the general-Ised TO terminal action with  . a default for u , the PUSH arc ( which we retain ) is the CALL arc with the folloe-ing defanlts s < form > ise ! the < preact lonoraotlon~s are only < prcaotion > e ! < ~ gister > is_~  . 
The on ~ fm ~ which must be added is ( OETA < arc > ( < node to m >\] ) " m < no defern is a form which evaluates to a semantic node  . Y  ~ abeant , < node fozs ~ defaults to ~ . The value of OETA i8 than ode at the end c ~ the ar ~ label-led < arc > fm the spaoified node  , or a IAst of such nodes L~there are more than rose  . 
3.2 TESTS , PREACTION , ETC.
The generalization o ? the ATN formalism to one which all N for writing gre~rs which generates ~' Tace strings from semantic networks  , yet csn be interpreted bY the same interpreter whAch handles parsing  grsm~8  , requires no changes other t ~ an the ones des-er ibed above  . Of course , each t ~ plementation fan ATN interpreter contains slight di~erences in the set oftes ts and actions implemented beyond the basic ones  . 
h.MINPUTBb~ee ~
Zr ~ ut to the ATN parser can be thought of as being the content so ? a stack  , called the input buffer . Z f the input is a string of ' words , the ~~--'-~ vill beat the top of the input buffer and successive words will be in successively deeper positions of the input buffer  . 
ZF the input is a graph , the input buffer might controLs only a single node OF the graph  . 
Caantes-Lugan arc , the ? register is set to the top element of the input buffer  , uhl ch must not be empty . 
The on ~ exceptions to this are the VTR and POP arcs  . 
VIR setse to an element of the HOLD register . POP leaves . M , undefined since e is always the element to be accounted for by the current arc  , and a POP arc is not trying to account for ar ~ elmmut  . ~ he input buffer is not changed between the time a PUSH  8re is entered and t ~ fine a narce manating from the stata pushed to is anto M  )   8o the contents of e on the latter ar ~ will be the same as on the former  . A CALL arc is all mred to opeei ~ the centanteo f  . on the arcs of the called s1~ta . This is accue plished by replacing the top element of the input buffer by that value before transfer to the called state  . Y ~ the value is a list of olem n to ) we push each elmwnt individual ~ onto the input buffer  . ~ makes it particularly easy to loop thz ~ a set of nodes  , each of which uili contribute the sane syntactic tom to the growing santenee  ( no basast ~ A ~ go ? adJectlves )  . 
on an arc ( except for POP ), i . e . during evaluation OF the test and the acts , the onntents OF ~ and the top el an ent of the input buffer are the same  . This requires spaeial pz ~ eessing for V~R , P ~ H , and CALL ares . 
Atter setting % a VIR are pushes the contents of ~on-totbe input buffer  . When a PUSH are resuaes , and the lower level has suece estu ~ returned a value  , the value is placed into * and also pushed onto the input buffer  . ~ anaCALL resumes , and the Immr level has 8uceassfUlly returned a value , the value is placed into the spueified regis ter  , and the centers of ~ is pushed onto the input butter  . The s1~ei tied register might or might not be e . In either case the contents of . e and the top OF the input buffer a ~ the sane . 
There are two possible terminal acts , JUMP and TO . 
JUMP does not affect the input buffer , so the contents OFe will be same on the successor ares  ( except for POP and VIR ) as at the end OF the curreut arc . TO pops the input buffer , but if provided with an optional to m , also pushes the value of ~ Jmt form on ~ othe input but-ler  . 
POPping from ~ e top level is one7 legal if the input buffer is empty . POPP in tfz ~ many level should that a consti tuent has been accounted for  . Accounting for a constituent should en~l removing it from the  in1~t buffer . From this we conclude that ever ~ path within a levelf man initial state to a POP ere  oon1'~Lin at least one TO transfer , and in most cases , it is proper to trausfer TO ra~her than to JUMP to a state that hss a POP are emanat ~ from it  . TO will beteruln a last for most V~R and PUSH a~s . 

In an ~ ATN interpreter which abides by this d is cussion  , advancement of the input is a function of the terminal action alone in the sense that at any state JUMPed to  , the top of the input buffer will be the las t value of *  , and at any state Jumped TO it will not be . 
Parsing and generating require a lexicon--a file of words giving syntactic categories  , features and inflectional forms ~ or irregularly inflected words  . Parsing and generating require different information  , yet we wish to avoid duplication as much as possible  . 
During parsing , morphological analysis is performed . 
The analyzer is given an inflected form , must segment it , find the stem in the lexicon and modify the lexical entry of the stem according to its analysis of the original form  . Irregularly inflected forms must have their own entries in the lexicon  . An entry in the lexicon may be lexically ambiguous  , so each entry must be associated with a list of one or more lexical feature lists  . Each such list , whether stored in the lexicon or constructed by the morphological analyzer  , must include a syntactic category and a stem , which serves as a link to the semantic network , as well as other features such as transitivity for a verb  . 
In the semantic network , sc ~ e nodes are associated with lexical entries . During generation , these entries , along with other information from the semantic network  , are used by a morphological synthesizer to construct an inflected word  . We assume that all such entries are unambiguous stems  , and so contain only a single lexical feature li s t  . This feature list must contain any irregularly inflected forms  . 
In summary , a single lexicon may be used for both parsing and generating under the following conditions  . 
An unambiguous stem can be used for both parsing and generating if its one lexlcal feature list contains features required for both operations  . An ambiguous lexical entry will only be used during parsing  . Each of its lexlcal feature lists , met contain a unique but arbitrary , stem , ' for connection to the semantic network and for holding the lexical information required for generation  . Every lexical feature list used for generating must contain the proper natural language  spe!1~ng of its stem as well as any irregularly inflected forms  . Lexical entries for irregularly inflected forms will only be used during parsing  . 
For the purposes of this paper , it should be irrelevant whether the " stems , , connected to the semantic network are actual surface word sllke " give  , , , deeper sememes such as that underlying both , , give , and , , take " , or primitives such as . ATRANS " . 
6. EXAMPLE
Figure Ish OWs an example interaction using the SNePS Semantic Network Processing ~ ystem  \[5\] in which I/O is controlled by a parsing -generating ATN grammar  . Lines begun by "**" are user's input , which are all calls to the function named , , : " . This function passes its argument llst as the input buffer for a parse to begin in state S  . The form popped by the toplevel ATNned-worm is then printed  , folluwed by the CPU time in milliseconds . ( The system is partly c~lled , partly interpreted LISP on a CYB~173 . The ATN gra , meris interpreted .   ) Figure 2 shores the grammar in abbreviated graphical form , and Figure 4 gives the details of each arc . The parsing network , beginning at state S~is included for completeness  , but the reader unfamiliar with SMePSUL , the S~ePSUser Language , \[5\] is not expected to understand its details . 
The first arc in the network is a PUSH to the parsing network  . This network determines whether the inlmat is a statement  ( type D ) or a question ( type Q )  . If a statement , the network builds a SNAPS network representing the information contained in the sentence and pops a semantic node representing the fact con -rained in the main clause  . If the input is a question the parsing network calls the SN ePS deduction routines  ( DEDUCE ) to find the answer , and pops the semantic node representing that ( no actual deduction is required in this example )  . Figure 3 shews the complete SNePS network built during this example  . Nodes MTh-M 85 were built by the first statement , nodes M89 and
MgO by the second.
When the state RESPOND is reached , the input buffer contains the SNAPS node popped by the parsing network  . 
The generating network then builds a sentence . The first two sentences were generated from node  M85 before M89 end MgO were built . The third sentence was generated from MgO , and the fourth from M85 again . Since the voice ( VC ) register is LIFTRed from the parsing network , the generated sentence has the same voice as the input sentence  ( see Figure I )  . 
Of particular note is the subnetwork at sta tePRED which analyzes the proper tense for the generated sentence  . For brevity , only simple tenses are included here , but the more complicated tenses presented in \[4\] can be handled in a similar manner . Also of interest is the subnetwork at state ADJS which generates a string of adjectives which are not already scheduled to be in the sentence  .   ( Compare the third and fourth generated sentences of Figure  1  . ) 7 . CONCLUSIONS A generalization of the ATN formalism has been presented which allows grammars to be written for generating surface sentences from semantic networks  . The generalization has involved : adding an optional argument to the TO terminal act  ; reintroducing the JUMP terminal act ; introducing a TO arc similar to the JUMP arc ; introducing a CALL arc which is a generalization of the PUSH arc  ; introducing a GETA form ; clarifying the management of the input buffer . The benefits of these few changes are that parsing and generating gramnars may be written in the same familiar notation  , may be interpreted ( or compiled ) by a single program , and may use each other in the same parser -generator network grammar  . 
R ~ ENCES\[1\]Bates , Nadeleine . The theory and practice of augmented transit ion network grammars  . In L . Bloc , ed . 
Natural Language Communication with Ccm~uters , Springev-~'erlag , Berlin , 197 U ,  192-259 . 
\[2\] Burton , R . R . Semantic grammar , an engineering technique for constructing natural language understanding systems  . BBN Report No . 3h 53, Bolt Beranek and Newman , Inc . , Cambridge , MA . , December 1976 . 
\[3\] Burton , Richard R . and Woods , ~ . A . A compiling system for augmented transition networks  . Prt prints of COLING 76z The Lnternational Conference on Computation-al Linguistics  , Ottawa , June 1976 . 
\[4\] Shapiro , Stuart C . Generation as parsing from a network into al in earstring  . AJCLMicrofiche 33 (1975) ~5-62 . 
\[5\] Shapiro , Stuart C . The SN oPS semantic network processing system . In N . Y . Findler , ed .   , Associative Networks : Representation and Use of Knowled Keby Computers  , Academic Press , New York , I ~79 ,  17~-203 . 
\[6\]~1~ew , R . and Slocum , J . Generating e ~ gllsh discot ~' se from e ~ tic networks  . CACN ~, 10 ( October 1972), 8~-905 . 
27\[7\]Woods , W . A . Transition natwcrk~smuars for ~ . ~ ( zADOGKISSEDYOUNGLUCY ) natural langua@sana ~ TSl SoCACMI ~ , 10 ( October 1970) , ( IUND~STANDTHATADOGKISSEDYOUNGLUCY ) 591 . . . 606 . 3769 MSECS\[8\]Woods,W . A . An experimental parsing system for #~( , WHOKISS ~ LUCY ) transition network Rrsmmaz ~ . In RoRns ~ Ln , ed . , Nat - ( A DOG KIS3~ YOUNG LUCY ) u~al LanRua~e P , -ocess in ~ . Algorlthmlcs Press , Mew~o ~ , 27 14 MSEC 319 73 ,  111-15~ . 
~( , LUCYISS WEET )   ( I~D ~ L~TAND THATYOUNG LUCTISS WEET ) 2127 MSECS # , ~ ( zWHOWASKISSED ~ ADOG )   ( SWEETYOUNG LUCY WASKISSED BY AraG ) 3 O O h M SZ CS
Figure I . Example Interaction ~ SHSPJ ~ CALL NQ~3RJ )   ( ~CALL NPJ ~ ) CALL PREDJ ~ . ~
ADJ SJC ALL NP TO
CALL PASTTO
CATVTO ~ ~ .   .   .   .   . ~_J ~ ~ WRDBYTOPUSH gNP
CATADJTO ~
Figure 2. A ? arsL~-(~nerating Grammar
Terminal actaaretnd : L cated by " J " or " TO " Figure  3  . Samnt , ic Hetwoz . tcBuild by ~ ent , encea of Figure 1 ( RESPO ~ ( JeWG ( Z  ~ ( OK rRT rPZ ) 'D )   ( SK rRST~INO' ( IUt mmSTAND THAT ) ) )   ( av ~ G ( za ( G  ~ . ' m ~ PZ ) , ~ ) ) )   ( O ( JUMP ~ ( AND ( GE~AOBJECT )   ( OVERLAP ( GETRVC ) ' PASS ) )  ( SE rR ~ ( O~AOBJECT ) ) )   ( JUMP@$ ( AND ( O~AAGENT )   ( DISJOINT ( OK"HIVC )   , PASS ) )  ( SErRSUBJ ( OK"rAAO~T ) )  ( SE rRVC'ACT ) )  ( ~ ~  ( OK'PAWHICH )   ( SEI'R5 ~ IBJ ( GErAWHICH ) )  ( SETRVC'ACT ) ) )   ( os ( cALL NUmRSUS a TNUmR ( szmm  ~ z . )  ( JUM Pore ) ) )   ( 081  ( CaLL NP SUBJT ( S~ImDONE )   ( SENDR NUMBR ) Rm ( ADDR STRINGREO )   ( JUMPS gB ) ) )   ( SVB ( CALL PRED*T ( S~DRNUMBR )   ( S~#ERVC )   ( SENIRVB ( OR ( OKRALEX ( GET AVERB ) ) ' BE ) ) REG ( AIERSTRING PEG )   ( Ju ~ smo  ~ a ) ) )   ( SUROBJ ( CALL NP ( OKRAAGENT )   ( ANDGETAAGO'r )   ( OVERLAP VC'PASS ) )  ( SENDRDONE )  *  ( ADDRSTRING ' BY* )   ( TO~D ) )  ( CALL NP ( OKRAOBJECT )   ( An D ( OKRAOBJECT )   ( OVmLAPVO'ACT ) )  ( S ~ XmDONE )  *  ( ADIRSm~O* )   ( TOram ) )  ( CaLLNP ( GETAADJ )   ( OEPAADJ )  *  ( ADDRSTRING * )   ( TO~D ) )  ( TO ( roD ) T ) )  ( z  ~ ( POPsmi NoT ) )  ( NUMBR ( TO ( NUMBRI )   ( OR ( OETASUB- )   ( OKRASUP- )   ( OKRACLASS- ) )  ( SKTR NUM ~' FL ) )  ( TO ( NLR ~ RI )   ( NOT ( OR ( GE~ASUB- )   ( OKRASUP- )   ( OKRACLASS- ) ) )   ( SETRNUMBR'SING ) ) )   ( NU~RI ( POP NUM SRT ) )  ( PRED ( CALL PAST ( OKRAE'f ~ ) TT ~ SE ( TOO~VB ) )  ( CALL ~ ( OKRA5"r ~ ) TTENSE ( TOGE~qVB ) )  ( TO ( G~-NVB ) T ( SKRRTENSE'PRES ) ) )   ( G  ~ ( IOP ( V ~ BIZE ( GEI~NUMBR )   ( GE~I~TENSE )   ( GEI~VC )   ( Gm VB ) ) T ) )  ( PAST ( TO ( PASTEND )   ( OVmLAP ** NOW ) )  ( TO ( PAST ( GET ABE FORE ) ) T ) )  ( PASTmD ( POP ' PASTT ) )  ( FUTR ( TO ( ZUTRZ ~ )   ( ovm LAp . ~ ow ) )  ( TO ( rUT ~ ( GETA Arrm ) ) T ) )  (  ~  ( POP ' ~ T ) )  ( NP ( TO ( roD )   ( GKRALEX )   ( SE % ~ STRING ( WHDIZE ( GETR ~ rb'F d~R )   ( GKRAIF , I\[))))(at . eN ~ A ( ~  ( OKRANANED- )   ( ~ ZSJOI~T ( OKRAN~d ~ ) ~ X ~ a Z ) ) )   ( JUMPNPMA ( AND ( OKRAMEMBER- )   ( DISJOINT ( OKRAMEMBER- ) DONE ) ) ) )  ( trP ~ A ( CALl . ADJS ( OKRAWHICH- )   ( GK rAW HICH- )   ( SE~DONE ) RZO ( ADIRETRINORm )   ( JUMP ~ N ) )  ( JUMP ~ P~T ) )  ( ~  ( TO~m )   ( ~ . STRI . G ( VaCaTE(GKRR~m'~)(OKRA ; 2X ( OZ ~ Art ~ MZ ( OKRA ~ )   )   )   )   )   )   )   ( ~ Pm ( CALLA ~ S ( OZnWHICH- )   ( On AWHZC . - )   ( S ~ DSm ~ Z ) Rm ( aams'miNo'Azm )   ( JUMP ~ ) )  ( ~ ~ T ( ADDRSTRING'A ) ) )   ( NPM ( CALL NP ( GET ACL ASS ( OKRAM ~ SER- ) ) T ( S~T ~ RDONE ) REG ( AD~RSTRING REG )   ( TO roD ) ) )   ( ADJS ( CALL NP ( GETAADJ )   ( DISJOINT*DONE )   ( S~DRDONE )  *  ( ADDRSTRING * )   ( TOADJS ) )  ( TO ( A ~ JS ) T )   ( raPSTRINGT ) )  ( s P ( w ~ WHOT ( SK rRTYPE'Q )   ( LIFTSTYPE )   ( szms VS a~X ( Tov ) )  ( maSH NPPT ( sz~mRnet , D ) ( SETRn'PZ'D ) ( Un~n~Z ) ( sz'ms us a . )  ( Tov ) ) )   ( v ( CaTvT ( szm vs ( FmmR EurmLZX ( + ( OK rR * ) ) ) )  ( SK rRTNS ( OKrZZ ~ SZ ) )  ( WCOMPL ) ) )   ( C ( ~ L ( CATV ( AND ( GET FP PRT )   ( OVmLAP ( GETRVB )   ( GETAI~X-'BE ) ) )   ( SKTROBJ ( OKTRSUBJ ) )  ( SETRSIBJ NIL )   ( SK rRVC'PASS )   ( szm  ~ ( FINmPaUZU ~ ~ ( ~ ( ozm . ) ) ) )   ( Tosv ) )  ( CaTADJ ( OVER laP ( ore VB )   ( OETALEX-'BE ) )  ( SK rRADJ ( FINDORBUILDLEX ( ~ ( GETR * ) ) ) )  ( TOS VO ) )  ( JUMPSVT ) )  ( SV ( JUMP0 ( EQ ( OETRTNS ) ' FRES )   ( SE rRSTM ( BUILDBEI ~ ORE * NOW ( BUILDAFTra * NOW ) -ETM ) ) )   ( ameo ( zQ ( GZ'mT . S ) ' PAS'r ) ( SZ~STM(BU rLDSm'ORZ(B , ZLDsm ~ oaz . Now ) -KrM ) ) ) )  ( 0  ( WRDBY ( EQ ( O~VC ) ' PASS )   ( TOPAO ) )  ( ~SH ~ Pr ( sm~'mn , Pz ) ( szmo BJ . )  ( LZ ~ VC )   ( TOS VO ) ) )   ( PAO ( PUS ~ NP PT ( S ~\] ~ R TYPE )   ( SETRSUBJ * )   ( LIFTRVC )   ( TOS VO ) ) )   ( ~  ( raP ( BU  ~ . nAG ~ ( ? ( OETR ~ J )   ) VERB ( + ( OE'I~R ~ ) ) OBJECT ( ~ ( GmOBJ ) )ST~2E . ' ( f ( OETRS'rM ) ) ~ *~ TH )   ( zQ ( oz mT ~ PZ'D ) )  ( rap ( ~ AL ( BU  ~ (  mmczAOZtrr+v ~+ OSJmT + ) s ~ mJ wo ~ ) )  ( zQ ( ozm TrPz )   , Q ) ) )   ( SVC ( POp ( EVAL ( BIHIIX ~ ( FINDORBUILDWHICH + AIIJ + ) SUBJADJ ) )  ( ~  ( GKTRT3\[PE ) 'D ) )  ( POP ( EVAL ( B  ~ ( DEDUCE WHICH + ADJ + ) S  ~ J  ~ )   )   ( EQ ( OEI'RTYPE ) ' Q ) ) )   ( ~  ( ~ n  ~ AT ( sm~~T )   ( To ~ PDKr ) )  ( ~ NP DET T ) )  ( ~ nZT ( CA ~ AmT ( HOLD ( P ~ m , SU ~ ~ X( , ( ozm . ) ) ) )   ( m  ~ ) )  ( CATN ( AND ( GETRINDEF )   ( EQ ( OE'i ~ TYPE ) 'D ) )  ( sin ~ ( BONDM msm- ( ~ u'~c~ass ( zi NmP a ~ LD~x ( * ( oz'm . ))))))) ( TOre , A ) )  ( CATN ( AND ( OETR\]~qDEF )   ( EQ ( OETRTI'PE ) ' Q ) )  ( SK rR ~ ( FINDM ~ B~R- ( DEDUCEM ~ ER % Y CLASS ( TBUILDLEX ( + ( OKTR * ) ) ) ) ) )  ( TOICPA ) )  ( CAT NP RT ( SETRNH ( FINDOR BUILDNAMED- ( FINDOR BUILD NAME ( F ~ UILDLEX ( + ( GETR * ) ) ) ) ) )  ( TO~Z ) ) )   ( ~ A Orm ~ T ( ~ AL ( B ~ r ~ ( FZ ~ rmREuI~mW ~ CH . Aa)J *) ~ H )) ( TO ~ PA )) ( POP ~ T )) Figure 4 . Details of the Parser ~2 en ~ rator ~ t ~ mork
