Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics , pages 1492?1501,
Uppsala , Sweden , 1116 July 2010. c?2010 Association for Computational Linguistics
A Transition-Based Parser for 2Planar Dependency Structures
Carlos Go?mez-Rodr??guez
Departamento de Computacio?n
Universidade da Corun?a , Spain
carlos.gomez@udc.es
Joakim Nivre
Department of Linguistics and Philology
Uppsala University , Sweden
joakim.nivre@lingfil.uu.se
Abstract
Finding a class of structures that is rich enough for adequate linguistic representation yet restricted enough for efficient computational processing is an important problem for dependency parsing . In this paper , we present a transition system for 2planar dependency trees ? trees that can be decomposed into at most two planar graphs ? and show that it can be used to implement a classifier-based parser that runs in linear time and outperforms a state-of-the-art transition-based parser on four data sets from the CoNLLX shared task.
In addition , we present an efficient method for determining whether an arbitrary tree is 2planar and show that 99% or more of the trees in existing treebanks are 2planar.
1 Introduction
Dependency-based syntactic parsing has become a widely used technique in natural language processing , and many different parsing models have been proposed in recent years ( Yamada and Matsumoto , 2003; Nivre et al , 2004; McDonald et al , 2005a ; Titov and Henderson , 2007; Martins et al , 2009). One of the unresolved issues in this area is the proper treatment of nonprojective dependency trees , which seem to be required for an adequate representation of predicate-argument structure , but which undermine the efficiency of dependency parsing ( Neuhaus and Bro?ker , 1997; Buch-Kromann , 2006; McDonald and Satta , 2007).
Caught between the Scylla of linguistically inadequate projective trees and the Charybdis of computationally intractable nonprojective trees , some researchers have sought a middle ground by exploring classes of mildly nonprojective dependency structures that strike a better balance between expressivity and complexity ( Nivre , 2006; Kuhlmann and Nivre , 2006; Kuhlmann and Mo?hl , 2007; Havelka , 2007). Although these proposals seem to have a very good fit with linguistic data , in the sense that they often cover 99% or more of the structures found in existing treebanks , the development of efficient parsing algorithms for these classes has met with more limited success . For example , while both Kuhlmann and Satta (2009) and Go?mez-Rodr??guez et al (2009) have shown how well-nested dependency trees with bounded gap degree can be parsed in polynomial time , the best time complexity for lexicalized parsing of this class remains a prohibitive O(n7), which makes the practical usefulness questionable.
In this paper , we explore another characterization of mildly nonprojective dependency trees based on the notion of multiplanarity . This was originally proposed by Yli-Jyra ? (2003) but has so far played a marginal role in the dependency parsing literature , because no algorithm was known for determining whether an arbitrary tree was m-planar , and no parsing algorithm existed for any constant value of m . The contribution of this paper is twofold . First , we present a procedure for determining the minimal number m such that a dependency tree is m-planar and use it to show that the overwhelming majority of sentences in dependency treebanks have a tree that is at most 2planar . Secondly , we present a transition-based parsing algorithm for 2planar dependency trees , developed in two steps . We begin by showing how the stack-based algorithm of Nivre (2003) can be generalized from projective to planar structures.
We then extend the system by adding a second stack and show that the resulting system captures exactly the set of 2planar structures . Although the contributions of this paper are mainly theoretical , we also present an empirical evaluation of the 2planar parser , showing that it outperforms the projective parser on four data sets from the CoNLLX shared task ( Buchholz and Marsi , 2006).
1492 2 Preliminaries 2.1 Dependency Graphs Let w = w1 . . . wn be an input string.1 An interval ( with endpoints i and j ) of the string w is a set of the form [ i , j ] = { wk | i ? k ? j}.
Definition 1. A dependency graph for w is a directed graph G = ( Vw , E ), where Vw = [1, n ] and
E ? Vw ? Vw.
We call an edge ( wi , wj ) in a dependency graph G a dependency link2 from wi to wj . We say that wi is the parent ( or head ) of wj and , conversely , that wj is a syntactic child ( or dependent ) of wi . For convenience , we write wi ? wj ? E if the link ( wi , wj ) exists ; wi ? wj ? E if there is a link from wi to wj or from wj to wi ; wi ?? wj ? E if there is a ( possibly empty ) directed path from wi to wj ; and wi ?? wj ? E if there is a ( possibly empty ) path between wi and wj in the undirected graph underlying G ( omitting reference to E when clear from the context ). The projection of a node wi , denoted bwic , is the set of reflexive-transitive dependents of wi : bwic = { wj ? V | wi ?? wj}.
Most dependency representations do not allow arbitrary dependency graphs but typically require graphs to be acyclic and have at most one head per node . Such a graph is called a dependency forest.
Definition 2. A dependency graph G for a string w1 . . . wn is said to be a forest iff it satisfies : 1. Acyclicity : If wi ?? wj , then not wj ? wi.
2. Single-head : If wj ? wi , then not wk ? wi ( for every k 6= j).
Nodes in a forest that do not have a head are called roots . Some frameworks require that dependency forests have a unique root ( i.e ., are connected).
Such a forest is called a dependency tree.
2.2 Projectivity
For reasons of computational efficiency , many dependency parsers are restricted to work with projective dependency structures , that is , forests in which the projection of each node corresponds to a contiguous substring of the input : 1For notational convenience , we will assume throughout the paper that all symbols in an input string are distinct , i.e ., i 6= j ? wi 6= wj . This can be guaranteed in practice by annotating each terminal symbol with its position in the input.
2In practice , dependency links are usually labeled , but to simplify the presentation we will ignore labels throughout most of the paper . However , all the results and algorithms presented can be applied to labeled dependency graphs and will be so applied in the experimental evaluation.
Definition 3. A dependency forest G for a string w1 . . . wn is projective iff bwic is an interval for every word wi ? [1, n].
Projective dependency trees correspond to the set of structures that can be induced from lexicalised contextfree derivations ( Kuhlmann , 2007; Gaifman , 1965). Like contextfree grammars , projective dependency trees are not sufficient to represent all the linguistic phenomena observed in natural languages , but they have the advantage of being efficiently parsable : their parsing problem can be solved in cubic time with chart parsing techniques ( Eisner , 1996; Go?mez-Rodr??guez et al , 2008), while in the case of general nonprojective dependency forests , it is only tractable under strong independence assumptions ( McDonald et al , 2005b;
McDonald and Satta , 2007).
2.3 Planarity
The concept of planarity ( Sleator and Temperley , 1993) is closely related to projectivity3 and can be informally defined as the property of a dependency forest whose links can be drawn above the words without crossing.4 To define planarity more formally , we first define crossing links as follows : let ( wi , wk ) and ( wj , wl ) be dependency links in a dependency graph G . Without loss of generality , we assume that min(i , k ) ? min(j , l ). Then , the links are said to be crossing if min(i , k ) < min(j , l ) < max ( i , k ) < max ( j , l).
Definition 4. A dependency graph is planar iff it does not contain a pair of crossing links.
2.4 Multiplanarity
The concept of planarity on its own does not seem to be very relevant as an extension of projectivity for practical dependency parsing . According to the results by Kuhlmann and Nivre (2006), most nonprojective structures in dependency treebanks are also non-planar , so being able to parse planar structures will only give us a modest improvement in coverage with respect to a projective parser.
However , our interest in planarity is motivated by the fact that it can be generalised to multiplanarity ( Yli-Jyra ?, 2003): 3For dependency forests that are extended with a unique artificial root located at position 0, as is commonly done , the two notions are equivalent.
4Planarity in the context of dependency structures is not to be confused with the homonymous concept in graph theory , which does not restrict links to be drawn above the nodes.
1493
Figure 1: A 2planar dependency structure with two different ways of distributing its links into two planes ( represented by solid and dotted lines).
Definition 5. A dependency graph G = ( V,E ) is m-planar iff there exist planar dependency graphs G1 = ( V,E1), . . . , Gm = ( V,Em ) ( called planes ) such that E = E1 ? ? ? ? ? Em.
Intuitively , we can associate planes with colours and say that a dependency graph G is m-planar if it is possible to assign one of m colours to each of its links in such a way that links with the same colour do not cross . Note that there may be multiple ways of dividing an m-planar graph into planes , as shown in the example of Figure 1.
3 Determining Multiplanarity
Several constraints on nonprojective dependency structures have been proposed recently that seek a good balance between parsing efficiency and coverage of nonprojective phenomena present in natural language treebanks . For example , Kuhlmann and Nivre (2006) and Havelka (2007) have shown that the vast majority of structures present in existing treebanks are well-nested and have a small gap degree ( Bodirsky et al , 2005), leading to an interest in parsers for these kinds of structures ( Go?mez-Rodr??guez et al , 2009). No similar analysis has been performed for m-planar structures , although Yli-Jyra ? (2003) provides evidence that all except two structures in the Danish dependency treebank are at most 3-planar . However , his analysis is based on constraints that restrict the possible ways of assigning planes to dependency links , and he is not guaranteed to find the minimal number m for which a given structure is m-planar.
In this section , we provide a procedure for finding the minimal number m such that a dependency graph is m-planar and use it to show that the vast majority of sentences in dependency treebanks are Figure 2: The crossings graph corresponding to the dependency structure of Figure 1.
at most 2planar , with a coverage comparable to that of well-nestedness . The idea is to reduce the problem of determining whether a dependency graph G = ( V,E ) is m-planar , for a given value of m , to a standard graph colouring problem . Consider first the following undirected graph:
U(G ) = ( E,C ) where
C = {{ ei , ej } | ei , ej are crossing links in G } This graph , which we call the crossings graph of G , has one node corresponding to each link in the dependency graph G , with an undirected link between two nodes if they correspond to crossing links in G . Figure 2 shows the crossings graph of the 2planar structure in Figure 1.
As noted in Section 2.4, a dependency graph G is m-planar if each of its links can be assigned one of m colours in such a way that links with the same colours do not cross . In terms of the crossings graph , this means that G is m-planar if each of the nodes of U(G ) can be assigned one of m colours such that no two neighbours have the same colour . This amounts to solving the wellknown k-colouring problem for U(G ), where k = m.
For k = 1 the problem is trivial : a graph is 1-colourable only if it has no edges . For k = 2, the problem can be solved in time linear in the size of the graph by simple breadth-first search . Given a graph U = ( V,E ), we pick an arbitrary node v and give it one of two colours . This forces us to give the other colour to all its neighbours , the first colour to the neighbours ? neighbours , and so on.
This process continues until we have processed all the nodes in the connected component of v . If this has resulted in assigning two different colours to the same node , the graph is not 2-colourable . Otherwise , we have obtained a 2-colouring of the connected component of U that contains v . If there are still unprocessed nodes , we repeat the process by arbitrarily selecting one of them , continue with the rest of the connected components , and in this way obtain a 2-colouring of the whole graph if it Arabic 2995 205 ( 6.84%) 158 ( 5.28%) 0 (0.00%) 0 (0.00%) 0 (0.00%) 1 (0.03%) Czech 87889 20353 (23.16%) 16660 (18.96%) 82 (0.09%) 0 (0.00%) 0 (0.00%) 96 (0.11%) Danish 5512 853 (15.48%) 827 (15.00%) 1 (0.02%) 1 (0.02%) 0 (0.00%) 6 (0.11%) Dutch 13349 4865 (36.44%) 4115 (30.83%) 162 (1.21%) 1 (0.01%) 0 (0.00%) 15 (0.11%) German 39573 10927 (27.61%) 10908 (27.56%) 671 (1.70%) 0 (0.00%) 0 (0.00%) 419 (1.06%) Portuguese 9071 1718 (18.94%) 1713 (18.88%) 8 (0.09%) 0 (0.00%) 0 (0.00%) 7 (0.08%) Swedish 6159 293 ( 4.76%) 280 ( 4.55%) 5 (0.08%) 0 (0.00%) 0 (0.00%) 14 (0.23%) Turkish 5510 657 (11.92%) 657 (11.92%) 10 (0.18%) 0 (0.00%) 0 (0.00%) 20 (0.36%) Table 1: Proportion of dependency trees classified by projectivity , planarity , m-planarity and ill-nestedness in treebanks for Arabic ( Hajic ? et al , 2004), Czech ( Hajic ? et al , 2006), Danish ( Kromann , 2003), Dutch ( van der Beek et al , 2002), German ( Brants et al , 2002), Portuguese ( Afonso et al , 2002), Swedish ( Nilsson et al , 2005) and Turkish ( Oflazer et al , 2003; Atalay et al , 2003).
exists . Since this process can be completed by visiting each node and edge of the graph U once , its complexity is O(V + E ). The crossings graph of a dependency graph with n nodes can trivially be built in time O(n2) by checking each pair of dependency links to determine if they cross , and cannot contain more than n2 edges , which means that we can check if the dependency graph for a sentence of length n is 2planar in O(n2) time.
For k > 2, the k-colouring problem is known to be NP-complete ( Karp , 1972). However , we have found this not to be a problem when measuring multiplanarity in natural language treebanks , since the effective problem size can be reduced by noting that each connected component of the crossings graph can be treated separately , and that nodes that are not part of a cycle need not be considered.5 Given that nonprojective sentences in natural language tend to have a small proportion of nonprojective links ( Nivre and Nilsson , 2005), the connected components of their crossings graphs are very small , and k-colourings for them can quickly be found by brute-force search.
By applying these techniques to dependency treebanks of several languages , we obtain the data shown in Table 1. As we can see , the coverage provided by the 2-planarity constraint is comparable to that of well-nestedness . In most of the treebanks , well over 99% of the sentences are 2planar , and 3-planarity has almost total coverage.
As we will see below , the class of 2planar dependency structures not only has good coverage of linguistic phenomena in existing treebanks but is also efficiently parsable with transition-based parsing methods , making it a practically interesting subclass of nonprojective dependency structures.
5If we have a valid colouring for all the cycles in the graph , the rest of the nodes can be safely coloured by breadth-first search as in the k = 2 case.
4 Parsing 1-Planar Structures
In this section , we present a deterministic linear-time parser for planar dependency structures . The parser is a variant of Nivre?s arc-eager projective parser ( Nivre , 2003), modified so that it can also handle graphs that are planar but not projective . As seen in Table 1, this only gives a modest improvement in coverage compared to projective parsing , so the main interest of this algorithm lies in the fact that it can be generalised to deal with 2planar structures , as shown in the next section.
4.1 Transition Systems
In the transition-based framework of Nivre (2008), a deterministic dependency parser is defined by a nondeterministic transition system , specifying a set of elementary operations that can be executed during the parsing process , and an oracle that deterministically selects a single transition at each choice point of the parsing process.
Definition 6. A transition system for dependency parsing is a quadruple S = ( C , T , cs , Ct ) where 1. C is a set of possible parser configurations , 2. T is a set of transitions , each of which is a partial function t : C ? C , 3. cs is a function that maps each input sentence w to an initial configuration cs(w ) ? C , 4. Ct ? C is a set of terminal configurations.
Definition 7. An oracle for a transition system S = ( C , T , cs , Ct ) is a function o : C ? T .
An input sentence w can be parsed using a transition system S = ( C , T , cs , Ct ) and an oracle o by starting in the initial configuration cs(w ), calling the oracle function on the current configuration c , and updating the configuration by applying the transition o(c ) returned by the oracle . This process is repeated until a terminal configuration is Terminal configurations : Cf = {??, [], A ? ? C } Transitions : SHIFT ??, wi|B,A ? ? ??| wi , B,A?
REDUCE ??| wi , B,A ? ? ??, B,A?
LEFT-ARC ??| wi , wj | B,A ? ? ??| wi , wj | B,A ? {( wj , wi )}? only if 6 ? k|(wk , wi ) ? A ( single-head ) and not wi ?? wj ? A ( acyclicity).
RIGHT-ARC ??| wi , wj | B,A ? ? ??| wi , wj | B,A ? {( wi , wj )}? only if 6 ? k|(wk , wj ) ? A ( single-head ) and not wi ?? wj ? A ( acyclicity).
Figure 3: Transition system for planar dependency parsing.
reached , and the dependency analysis of the sentence is defined by the terminal configuration.
Each sequence of configurations that the parser can traverse from an initial configuration to a terminal configuration for some input w is called a transition sequence . If we associate each configuration c of a transition system S = ( C , T , cs , Ct ) with a dependency graph g(c ), we can say that S is sound for a class of dependency graphs G if , for every sentence w and transition sequence ( cs(w ), c1, . . . , cf ) of S , g(cf ) is in G , and that S is complete for G if , for every sentence w and dependency graph G ? G for w , there is a transition sequence ( cs(w ), c1, . . . , cf ) such that g(cf ) = G.
A transition system that is sound and complete for
G is said to be correct for G.
Note that , apart from a correct transition system , a practical parser needs a good oracle to achieve the desired results , since a transition system only specifies how to reach all the possible dependency graphs that could be associated to a sentence , but not how to select the correct one . Oracles for practical parsers can be obtained by training classifiers on treebank data ( Nivre et al , 2004).
4.2 A Transition System for Planar
Structures
A correct transition system for the class of planar dependency forests can be obtained as a variant of the arc-eager projective system by Nivre (2003).
As in that system , the set of configurations of the planar transition system is the set of all triples c = ??, B,A ? such that ? and B are disjoint lists of words from Vw ( for some input w ), and A is a set of dependency links over Vw . The list B , called the buffer , is initialised to the input string and is used to hold the words that are still to be read from the input . The list ?, called the stack , is initially empty and holds words that have dependency links pending to be created . The system is shown in Figure 3, where we use the notation ?| wi for a stack with top wi and tail ?, and we invert the notation for the buffer for clarity ( i.e ., wi|B is a buffer with top wi and tail B).
The system reads the input from left to right and creates links in a left-to-right order by executing its four transitions : 1. SHIFT : pops the first ( leftmost ) word in the buffer , and pushes it to the stack.
2. LEFT-ARC : adds a link from the first word in the buffer to the top of the stack.
3. RIGHT-ARC : adds a link from the top of the stack to the first word in the buffer.
4. REDUCE : pops the top word from the stack , implying that we have finished building links to or from it.
Note that the planar parser?s transitions are more finegrained than those of the arc-eager projective parser by Nivre (2003), which pops the stack as part of its LEFT-ARC transition and shifts a word as part of its RIGHT-ARC transition . Forcing these actions after creating dependency links rules out structures whose root is covered by a dependency link , which are planar but not projective . In order to support these structures , we therefore simplify the ARC transitions ( LEFT-ARC and RIGHT-ARC ) so that they only create an arc . For the same reason , we remove the constraint in Nivre?s parser by which words without a head cannot be reduced.
This has the side effect of making the parser able to output cyclic graphs . Since we are interested in planar dependency forests , which do not contain cycles , we only apply ARC transitions after checking that there is no undirected path between the nodes to be linked . This check can be done without affecting the linear-time complexity of the of each node in g(c).
The finegrained transitions used by this parser have also been used by Sagae and Tsujii (2008) to parse DAGs . However , the latter parser differs from ours in the constraints , since it does not allow the reduction of words without a head ( disallowing forests with covered roots ) and does not enforce the acyclicity constraint ( which is guaranteed by postprocessing the graphs to break cycles).
4.3 Correctness and Complexity
For reasons of space , we can only give a sketch of the correctness proof . We wish to prove that the planar transition system is sound and complete for the set Fp of all planar dependency forests . To prove soundness , we have to show that , for every sentence w and transition sequence ( cs(w ), c1, . . . , cf ), the graph g(cf ) associated with cf is in Fp . We take the graph associated with a configuration c = (?, B,A ) to be g(c ) = ( Vw , A ). With this , we prove the stronger claim that g(c ) ? Fp for every configuration c that belongs to some transition sequence starting with cs(w ). This amounts to showing that in every configuration c reachable from cs(w ), g(c ) meets the following three conditions that characterise a planar dependency forest : (1) g(c ) does not contain nodes with more than one head ; (2) g(c ) is acyclic ; and (3) g(c ) contains no crossing links . (1) is trivially guaranteed by the single-head constraint ; (2) follows from (1) and the acyclicity constraint ; and (3) can be established by proving that there is no transition sequence that will invoke two ARC transitions on node pairs that would create crossing links . At the point when a link from wi to wj is created , we know that all the words strictly located between wi and wj are not in the stack or in the buffer , so no links can be created to or from them.
To prove completeness , we show that every planar dependency forest G = ( V,E ) ? Fp for a sentence w can be produced by applying the oracle function that maps a configuration ??| wi , wj | B,A ? to : 1. LEFT-ARC if wj ? wi ? ( E \ A ), 2. RIGHT-ARC if wi ? wj ? ( E \ A ), 3. REDUCE if ? x[x<i][wx ? wj ? ( E \ A )], 4. SHIFT otherwise.
We show completeness by setting the following invariants on transitions traversed by the application of the oracle : 1. ? a , b[a,b<j][wa?wb?E ? wa?wb?A ] 2. [ wi?wj?A ? ? k[i<k<j][wk?wj?E ? wk?wj?A ]] 3. ? k[k<j][wk 6??? ? l[l>k][wk?wl?E ? wk?wl?A ]] We can show that each branch of the oracle function keeps these invariants true . When we reach a terminal configuration ( which always happens after a finite number of transitions , since every transition generating a configuration c = ??, B,A ? decreases the value of the variant function | E | + |?| + 2|B | ? | A |), it can be deduced from the invariant that A = E , which proves completeness.
The worst-case complexity of a deterministic transition-based parser is given by an upper bound on transition sequence length ( Nivre , 2008). For the planar system , like its projective counterpart , the length is clearly O(n ) ( where n is the number of input words ), since there can be no more than n SHIFT transitions , n REDUCE transitions , and n ARC transitions in a transition sequence.
5 Parsing 2Planar Structures
The planar parser introduced in the previous section can be extended to parse all 2planar dependency structures by adding a second stack to the system and making REDUCE and ARC transitions apply to only one of the stacks at a time . This means that the set of links created in the context of each individual stack will be planar , but pairs of links created in different stacks are allowed to cross . In this way , the parser will build a 2planar dependency forest by using each of the stacks to construct one of its two planes.
The 2planar transition system , shown in Figure 4, has configurations of the form ??0,?1, B,A ?, where we call ?0 the active stack and ?1 the inactive stack , and the following transitions : 1. SHIFT : pops the first ( leftmost ) word in the buffer , and pushes it to both stacks.
2. LEFT-ARC : adds a link from the first word in the buffer to the top of the active stack.
3. RIGHT-ARC : adds a link from the top of the active stack to the first word in the buffer.
4. REDUCE : pops the top word from the active stack , implying that we have added all links to or from it on the plane tied to that stack.
5. SWITCH : makes the active stack inactive and vice versa , changing the plane the parser is working with.
1497
Initial configuration : cs(w1 . . . wn ) = ?[], [], [ w1 . . . wn ], ?? Terminal configurations : Cf = {??0,?1, [], A ? ? C } Transitions : SHIFT ??0,?1, wi|B,A ? ? ??0|wi,?1|wi , B,A?
REDUCE ??0|wi,?1, B,A ? ? ??0,?1, B,A?
LEFT-ARC ??0|wi,?1, wj | B,A ? ? ??0|wi,?1, wj | B,A ? {( wj , wi )}? only if 6 ? k | ( wk , wi ) ? A ( single-head ) and not wi ?? wj ? A ( acyclicity).
RIGHT-ARC ??0|wi,?1, wj | B,A ? ? ??0|wi,?1, wj | B,A ? {( wi , wj )}? only if 6 ? k|(wk , wj ) ? A ( single-head ) and not wi ?? wj ? A ( acyclicity).
SWITCH ??0,?1, B,A ? ? ??1,?0, B,A?
Figure 4: Transition system for 2planar dependency parsing.
5.1 Correctness and Complexity
As in the planar case , we provide a brief sketch of the proof that the transition system in Figure 4 is correct for the set F2p of 2planar dependency forests . Soundness follows from a reasoning analogous to the planar case , but applying the proof of planarity separately to each stack . In this way , we prove that the sets of dependency links created by linking to or from the top of each of the two stacks are always planar graphs , and thus their union ( which is the dependency graph stored in A ) is 2planar . This , together with the single-head and acyclicity constraints , guarantees that the dependency graphs associated with reachable configurations are always 2planar dependency forests.
For completeness , we assume an extended form of the transition system where transitions take the form ??0,?1, B,A , p ?, where p is a flag taking values in {0, 1} which equals 0 for initial configurations and gets flipped by each application of a SWITCH transition . Then we show that every 2planar dependency forest G ? F2p , with planes G0 = ( V,E0) and G1 = ( V,E1), can be produced by this system by applying the oracle function that maps a configuration ??0|wi,?1, wj | B,A , p ? to : 1. LEFT-ARC if wj?wi?(Ep \ A ), 2. RIGHT-ARC if wi?wj ?( Ep \ A ), 3. REDUCE if ? x[x<i][wx?wj ?( Ep \ A )? ?? y[x<y?i][wy?wj ?( Ep \ A )]], 4. SWITCH if ? x<j : ( wx , wj ) or ( wj , wx ) ? ( Ep\A ), 5. SHIFT otherwise.
This can be shown by employing invariants analogous to the planar case , with the difference that the third invariant applies to each stack and its corresponding plane : if ? y is associated with the plane
Ex,6 we have : 3. ? k[k<j][wk 6? ? y ]? ? l[l>k][wk?wl?Ex ]? [ wk?wl?A ] Since the presence of the flag p in configurations does not affect the set of dependency graphs generated by the system , the completeness of the system extended with the flag p implies that of the system in Figure 4.
We can show that the complexity of the 2planar system is O(n ) by the same kind of reasoning as for the 1-planar system , with the added complication that we must constrain the system to prevent two adjacent SWITCH transitions . In fact , without this restriction , the parser is not even guaranteed to terminate.
5.2 Implementation
In practical settings , oracles for transition-based parsers can be approximated by classifiers trained on treebank data ( Nivre , 2008). To do this , we need an oracle that will generate transition sequences for goldstandard dependency graphs . In the case of the planar parser of Section 4.2, the oracle of 4.3 is suitable for this purpose . However , in the case of the 2planar parser , the oracle used for the completeness proof in Section 5.1 cannot be used directly , since it requires the goldstandard trees to be divided into two planes in order to generate a transition sequence.
Of course , it is possible to use the algorithm presented in Section 3 to obtain a division of sentences into planes . However , for training purposes and to obtain a robust behaviour if non-2-planar 6The plane corresponding to each stack in a configuration changes with each SWITCH transition : ? x is associated with Ex in configurations where p = 0, and with Ex in those where p = 1.
1498
Czech Danish German Portuguese
Parser LAS UAS NPP NPR LAS UAS NPP NPR LAS UAS NPP NPR LAS UAS NPP NPR 2planar 79.24 85.30 68.9 60.7 83.81 88.50 66.7 20.0 86.50 88.84 57.1 45.8 87.04 90.82 82.8 33.8 Malt P 78.18 84.12 ? ? 83.31 88.30 ? ? 85.36 88.06 ? ? 86.60 90.20 ? ? Malt PP 79.80 85.70 76.7 56.1 83.67 88.52 41.7 25.0 85.76 88.66 58.1 40.7 87.08 90.66 83.3 46.2 Table 2: Parsing accuracy for 2planar parser in comparison to MaltParser with ( PP ) and without ( P ) pseudoprojective transformations . LAS = labeled attachment score ; UAS = unlabeled attachment score ; NPP = precision on nonprojective arcs ; NPR = recall on nonprojective arcs.
sentences are found , it is more convenient that the oracle can distribute dependency links into the planes incrementally , and that it produces a distribution of links that only uses SWITCH transitions when it is strictly needed to account for non-planarity . Thus we use a more complex version of the oracle which performs a search in the crossings graph to check if a dependency link can be built on the plane of the active stack , and only performs a switch when this is not possible . This has proved to work well in practice , as will be observed in the results in the next section.
6 Empirical Evaluation
In order to get a first estimate of the empirical accuracy that can be obtained with transition-based 2planar parsing , we have evaluated the parser on four data sets from the CoNLLX shared task ( Buchholz and Marsi , 2006): Czech , Danish , German and Portuguese . As our baseline , we take the strictly projective arc-eager transition system proposed by Nivre (2003), as implemented in the freely available MaltParser system ( Nivre et al , 2006a ), with and without the pseudoprojective parsing technique for recovering nonprojective dependencies ( Nivre and Nilsson , 2005). For the two baseline systems , we use the parameter settings used by Nivre et al (2006b ) in the original shared task , where the pseudoprojective version of MaltParser was one of the two top performing systems ( Buchholz and Marsi , 2006). For our 2planar parser , we use the same kernelized SVM classifiers as MaltParser , using the LIBSVM package ( Chang and Lin , 2001), with feature models that are similar to MaltParser but extended with features defined over the second stack.7 In Table 2, we report labeled ( LAS ) and unlabeled ( UAS ) attachment score on the four languages for all three systems . For the two systems that are capable of recovering nonprojective de-7Complete information about experimental settings can be found at http://stp.lingfil.uu.se / nivre/exp/.
pendencies , we also report precision ( NPP ) and recall ( NPR ) specifically on nonprojective dependency arcs . The results show that the 2planar parser outperforms the strictly projective variant of MaltParser on all metrics for all languages , and that it performs on a par with the pseudoprojective variant with respect to both overall attachment score and precision and recall on nonprojective dependencies . These results look very promising in view of the fact that very little effort has been spent on optimizing the training oracle and feature model for the 2planar parser so far.
It is worth mentioning that the 2planar parser has two advantages over the pseudoprojective parser . The first is simplicity , given that it is based on a single transition system and makes a single pass over the input , whereas the pseudoprojective parsing technique involves preprocessing of training data and postprocessing of parser output ( Nivre and Nilsson , 2005). The second is the fact that it parses a well-defined class of dependency structures , with known coverage8, whereas no formal characterization exists of the class of structures parsable by the pseudoprojective parser.
7 Conclusion
In this paper , we have presented an efficient algorithm for deciding whether a dependency graph is 2planar and a transition-based parsing algorithm that is provably correct for 2planar dependency forests , neither of which existed in the literature before . In addition , we have presented empirical results showing that the class of 2planar dependency forests includes the overwhelming majority of structures found in existing treebanks and that a deterministic classifier-based implementation of the 2planar parser gives state-of-the-art accuracy on four different languages.
8If more coverage is desired , the 2planar parser can be generalised to m-planar structures for larger values of m by adding additional stacks . However , this comes at the cost of more complex training models , making the practical interest of increasing m beyond 2 dubious.
1499
Acknowledgments
The first author has been partially supported by Ministerio de Educacio?n y Ciencia and FEDER ( HUM2007-66607-C04) and Xunta de Galicia ( PGIDIT07SIN005206PR , Rede Galega de Procesamento da Linguaxe e Recuperacio?n de Infor-macio?n , Rede Galega de Lingu???stica de Corpus , Bolsas Estad??as INCITE/FSE cofinanced).
References
Susana Afonso , Eckhard Bick , Renato Haber , and Diana Santos . 2002. ? Floresta sinta?(c)tica ?: a treebank for Portuguese . In Proceedings of the 3rd International Conference on Language Resources and Evaluation ( LREC 2002), pages 1968?1703, Paris,
France . ELRA.
Nart B . Atalay , Kemal Oflazer , and Bilge Say . 2003.
The annotation process in the Turkish treebank.
In Proceedings of EACL Workshop on Linguistically Interpreted Corpora ( LINC-03), pages 243? 246, Morristown , NJ , USA . Association for Computational Linguistics.
Leonoor van der Beek , Gosse Bouma , Robert Malouf , and Gertjan van Noord . 2002. The Alpino dependency treebank . In Language and Computers , Computational Linguistics in the Netherlands 2001. Selected Papers from the Twelfth CLIN Meeting , pages 8?22, Amsterdam , the Netherlands . Rodopi.
Manuel Bodirsky , Marco Kuhlmann , and Mathias Mo?hl . 2005. Well-nested drawings as models of syntactic structure . In 10th Conference on Formal Grammar and 9th Meeting on Mathematics of Language , Edinburgh , Scotland , UK.
Sabine Brants , Stefanie Dipper , Silvia Hansen , Wolfgang Lezius , and George Smith . 2002. The tiger treebank . In Proceedings of the Workshop on Treebanks and Linguistic Theories , September 2021,
Sozopol , Bulgaria.
Matthias Buch-Kromann . 2006. Discontinuous Grammar : A Model of Human Parsing and Language Acquisition . Ph.D . thesis , Copenhagen Business
School.
Sabine Buchholz and Erwin Marsi . 2006. CoNLLX shared task on multilingual dependency parsing.
In Proceedings of the 10th Conference on Computational Natural Language Learning ( CoNLL ), pages 149?164.
Chih-Chung Chang and Chih-Jen Lin , 2001.
LIBSVM : A Library for Support Vector Machines . Software available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.
Jason Eisner . 1996. Three new probabilistic models for dependency parsing : An exploration . In Proceedings of the 16th International Conference on Computational Linguistics ( COLING96), pages 340?345, San Francisco , CA , USA , August . ACL /
Morgan Kaufmann.
Haim Gaifman . 1965. Dependency systems and phrase-structure systems . Information and Control , 8:304?337.
Carlos Go?mez-Rodr??guez , John Carroll , and David Weir . 2008. A deductive approach to dependency parsing . In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics : Human Language Technologies ( ACL?08:HLT ), pages 968?976, Morristown , NJ , USA . Association for Computational Linguistics.
Carlos Go?mez-Rodr??guez , David Weir , and John Carroll . 2009. Parsing mildly nonprojective dependency structures . In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics ( EACL ), pages 291? 299.
Jan Hajic ?, Otakar Smrz ?, Petr Zema?nek , Jan S?naidauf , and Emanuel Bes?ka . 2004. Prague Arabic dependency treebank : Development in data and tools.
In Proceedings of the NEMLAR International Conference on Arabic Language Resources and Tools , pages 110?117.
Jan Hajic ?, Jarmila Panevova ?, Eva Hajic?ova ?, Jarmila Panevova ?, Petr Sgall , Petr Pajas , Jan S?te?pa?nek , Jir ??? Havelka , and Marie Mikulova ?. 2006.
Prague Dependency Treebank 2.0. CDROM
CAT : LDC2006T01, ISBN 1-58563-370-4. Linguistic Data Consortium.
Jiri Havelka . 2007. Beyond projectivity : Multilingual evaluation of constraints and measures on nonprojective structures . In Proceedings of the 45th Annual Meeting of the Association of Computational
Linguistics , pages 608?615.
Richard M . Karp . 1972. Reducibility among combinatorial problems . In R . Miller and J . Thatcher , editors , Complexity of Computer Computations , pages 85?103. Plenum Press.
Matthias T . Kromann . 2003. The Danish dependency treebank and the underlying linguistic theory . In Proceedings of the 2nd Workshop on Treebanks and Linguistic Theories ( TLT ), pages 217?220, Va?xjo?,
Sweden . Va?xjo ? University Press.
Marco Kuhlmann and Mathias Mo?hl . 2007. Mildly context-sensitive dependency languages . In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics , pages 160?167.
Marco Kuhlmann and Joakim Nivre . 2006. Mildly nonprojective dependency structures . In Proceedings of the COLING/ACL 2006 Main Conference
Poster Sessions , pages 507?514.
1500
Marco Kuhlmann and Giorgio Satta . 2009. Treebank grammar techniques for nonprojective dependency parsing . In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics ( EACL ), pages 478?486.
Marco Kuhlmann . 2007. Dependency Structures and Lexicalized Grammars . Doctoral dissertation , Saarland University , Saarbru?cken , Germany.
Andre Martins , Noah Smith , and Eric Xing . 2009.
Concise integer linear programming formulations for dependency parsing . In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP ( ACL-
IJCNLP ), pages 342?350.
Ryan McDonald and Giorgio Satta . 2007. On the complexity of nonprojective datadriven dependency parsing . In Proceedings of the 10th International Conference on Parsing Technologies ( IWPT ), pages 122?131.
Ryan McDonald , Koby Crammer , and Fernando Pereira . 2005a . Online large-margin training of dependency parsers . In Proceedings of the 43rd Annual Meeting of the Association for Computational
Linguistics ( ACL ), pages 91?98.
Ryan McDonald , Fernando Pereira , Kiril Ribarov , and Jan Hajic ?. 2005b . Nonprojective dependency parsing using spanning tree algorithms . In HLT/EMNLP 2005: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing , pages 523?530, Morristown , NJ , USA . Association for Computational
Linguistics.
Peter Neuhaus and Norbert Bro?ker . 1997. The complexity of recognition of linguistically adequate dependency grammars . In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics ( ACL ) and the 8th Conference of the European Chapter of the Association for Computational Linguistics ( EACL ), pages 337?343.
Jens Nilsson , Johan Hall , and Joakim Nivre . 2005.
MAMBA meets TIGER : Reconstructing a Swedish treebank from antiquity . In Proceedings of NODALIDA 2005 Special Session on Treebanks , pages 119? 132. Samfundslitteratur , Frederiksberg , Denmark,
May.
Joakim Nivre and Jens Nilsson . 2005. Pseudo-projective dependency parsing . In ACL ?05: Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics , pages 99?106, Morristown , NJ , USA . Association for Computational Linguistics.
Joakim Nivre , Johan Hall , and Jens Nilsson . 2004.
Memory-based dependency parsing . In Proceedings of the 8th Conference on Computational Natural Language Learning ( CoNLL2004), pages 49? 56, Morristown , NJ , USA . Association for Computational Linguistics.
Joakim Nivre , Johan Hall , and Jens Nilsson . 2006a.
MaltParser : A datadriven parser-generator for dependency parsing . In Proceedings of the 5th International Conference on Language Resources and
Evaluation ( LREC ), pages 2216?2219.
Joakim Nivre , Johan Hall , Jens Nilsson , Gu?lsen Eryig?it , and Svetoslav Marinov . 2006b . Labeled pseudoprojective dependency parsing with support vector machines . In Proceedings of the 10th Conference on Computational Natural Language Learning ( CoNLL ), pages 221?225.
Joakim Nivre . 2003. An efficient algorithm for projective dependency parsing . In Proceedings of the 8th International Workshop on Parsing Technologies ( IWPT ), pages 149?160.
Joakim Nivre . 2006. Constraints on nonprojective dependency graphs . In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics ( EACL ), pages 73? 80.
Joakim Nivre . 2008. Algorithms for Deterministic Incremental Dependency Parsing . Computational Linguistics , 34(4):513?553.
Kemal Oflazer , Bilge Say , Dilek Zeynep Hakkani-Tu?r , and Go?khan Tu?r . 2003. Building a Turkish treebank . In A . Abeille ( ed .), Building and Exploiting Syntactically-annotated Corpora , pages 261?277,
Dordrecht , the Netherlands . Kluwer.
Kenji Sagae and Jun?ichi Tsujii . 2008. Shift-reduce dependency DAG parsing . In COLING ?08: Proceedings of the 22nd International Conference on Computational Linguistics , pages 753?760, Morristown , NJ , USA . Association for Computational Linguistics.
Daniel Sleator and Davy Temperley . 1993. Parsing English with a Link Grammar . In Proceedings of the Third International Workshop on Parsing Technologies ( IWPT?93), pages 277?292. ACL/SIGPARSE.
Ivan Titov and James Henderson . 2007. A latent variable model for generative dependency parsing . In Proceedings of the 10th International Conference on Parsing Technologies ( IWPT ), pages 144?155.
Hiroyasu Yamada and Yuji Matsumoto . 2003. Statistical dependency analysis with support vector machines . In Proceedings of the 8th International Workshop on Parsing Technologies ( IWPT ), pages 195?206.
Anssi Mikael Yli-Jyra ?. 2003. Multiplanarity ? a model for dependency structures in treebanks . In Joakim Nivre and Erhard Hinrichs , editors , TLT 2003. Proceedings of the Second Workshop on Treebanks and Linguistic Theories , volume 9 of Mathematical Modelling in Physics , Engineering and Cognitive Sciences , pages 189?200, Va?xjo ?, Sweden , 1415 November . Va?xjo ? University Press.
1501
