Comprehension and Compilation in Optimality Theory ? 
Jason Eisner
Department of Computer Science
Johns Hopkins University
Baltimore , MD , USA 21218-2691


This paper ties up some loose ends in finite-state Optimality Theory  . First , it discusses how to perform comprehension under Optimality Theory grammars consisting of finite -state constraints  . Comprehension has not been much studied in OT ; we show that unlike production , it does not always yield a regular set , making finite-state methods inapplicable . However , after giving a suitably flexible presentation of OT  , we show carefully how to treat comprehension under recent variants of OT in which grammars can be compiled into finite-state transducers  . We then unify these variants , showing that compilation is possible if all components of the grammar are regular relations  , including the harmony ordering on scored candidates  . A side benefit of our construction is a far simpler implementation of directional OT  ( Eisner ,  2000) . 
1 Introduction
To produce language is to convert utterances from their underlying  ( ? deep ? ) form to a surface form . 
Optimality Theory or OT ( Prince and Smolensky ,  1993 ) proposes to describe phonological production as an optimization process  . For an underlying x , a speaker purportedly chooses the surface form z so as to maximize the harmony of the pair  ( x , z ) . 
Broadly speaking , ( x , z ) is harmonic if z is ? easy ? to pronounce and ? similar ? to x  . But the precise harmony measure depends on the language  ; according to OT , it can be specified by a grammar of ranked desiderata known as constraints  . 
According to OT , then , production maps each underlying form to its best possible surface pronunciation  . It is akin to the function that maps each child x to his or her most flattering out fit z  . Different children look best in different clothes  , and for an oddly shaped child x , even the best conceivable outfitz may be an awkward compromise between style and fit ? that is  , between ease of pronunciation and similarity to x . 
Language comprehension is production in reverse . In OT , it maps each outfitz to the set of chil-?Thanks to Kie Zuraw for asking about comprehension  ; to R on Kaplan for demanding an algebraic construction before he believed directional OT was finite-state  ; and to others whose questions convinced me that this paper deserved to be written  . 
dren x for whom that outfit is optimal , i . e . , is at least as flattering as any other outfit z ?: PRODUCE  ( x ) = z : ( @ z ? )   ( x , z ?) >( x , z )
COMPREHEND ( z ) = x : z ? PRODUCE ( x ) = x : ( @ z ? )   ( x , z ?) >( x , z ) In generalz and z ? may range over infinitely many possible pronunciations  . While the formulas above are almost identical , comprehension is in a sense more complex because it varies both the underlying and surface forms  . While PRODUCE(x ) considers all pairs ( x , z ?) , COMPREHEND ( z ) must for each x consider all pairs ( x , z ?) . Of course , this nested definition does not preclude computational shortcuts  . 
This paper has three modest goals : 1 . To show that OT comprehension does in fact present a computational problem that production does not  . Even when the OT grammar is required to be finite -state  , so that production can be performed with finite -state techniques  , comprehension cannot in general be performed with finite-state techniques  . 
2 . To consider reconstructions that cut through this problem  ( Frank and Satta , 1998; Karttunen , 1998; Eisner , 2000; Gerdemann and van Noord ,  2000) . By altering or approximating the OT formalism ? that is  , by hook or by crook ? these constructions manage to compile OT grammars into finite-state transducers  . Transducers may readily be inverted to do comprehension as easily as production  . We carefully layout how to use them for comprehension in realistic circumstances  ( in the presence of correspondence theory , lexical constraints , hearer uncertainty , and phonetic postprocessing ) . 
3 . To give a unified treatment in the extended finite-state calculus of the constructions referenced above  . 
This clarifies their meaning and makes them easy to implement  . For example , we obtain a transparent algebraic version of Eisner?s  ( 2000 ) unbearably technical automaton construction for his proposed formalism of ? directional OT  . ? Computational Linguistics ( ACL ) , Philadelphia , July 2002 , pp .  5663 . 
Proceedings of the 40th Annual Meeting of the Association for The treatment shows that all the constructions emerge directly from a generalized presentation of OT  , in which the crucial fact is that the harmony ordering on scored candidates is a regular relation  . 
2 Previous Work on Comprehension
Work focusing on OT comprehension ? or even mentioning it ? has been surprisingly sparse  . While the reconstructions mentioned in ?1 can easily be applied to the comprehension problem  , as we will explain , they were motivated primarily by a desire to pare backOT?s generative power to that of previous rewrite-rule formalisms  ( Johnson ,  1972) . 
Fosler ( 1996 ) noted the existence of the OT comprehension task and speculated that it might suc-cumb to heuristic search  . Smolensky ( 1996 ) proposed to solve it by optimizing the underlying form  , 
COMPREHEND(z ) ? = x : (@ x ?)( x? , z ) > ( x , z ) Hale and Reiss ( 1998 ) pointed out in response that any comprehension-by -optimization strategy would have to arrange for multiple optima : after all  , phonological comprehension is a one-to-many mapping  ( since phonological production is many-to-one )  . 1 The correctness of Smolensky?s proposal ( i . e . , whether it really computes COMPREHEND ) depends on the particular harmony measure . It can be made to work , multiple optima and all , if the harmony measure is constructed with both production and comprehension in mind  . Indeed , for any phonology , it is trivial to design a harmony measure that both production and comprehension optimize  . ( Just define the harmony of ( x , z ) to be 1 or 0 according to whether the mapping x 7? z is in the language ! ) But we are really only interested in harmony measures that are defined by OT-style grammars  ( rankings of ? simple ? constraints )  . In this case Smolen-sky?s proposal can be unworkable  . In particular ,   ?4 will show that a finite-state production grammar in classical OT need not be invertible by any finite-state comprehension grammar  . 
1Hale & Reiss?s criticism may be specific to phonology and syntax  . For some phenomena in semantics , pragmatics , and even morphology , Blutner ( 1999 ) argues for a one-to-one form-meaning mapping in which marked forms express marked meanings  . He deliberately uses bidirectional optimization to rule out many-to-one cases : roughly speaking  , an(x , z ) pair is grammatical for him only if z is optimal given x and vice versa  . 
3 A General Presentation of OT
This section ( graphically summarized in Fig .  1 ) lays out a generalized version of OT?s theory of production  , introducing some notational and representational conventions that may be useful to others and will be important below  . In particular , all objects are represented as strings , or as functions that map strings to strings . This will enable us to use finite-state techniques later  . 
The underlying form x and surface form z are represented as strings  . We often refer to these strings as input and output  . Following Eisner (1997) , each candidate ( x , z ) is also represented as a string y . 
The notation ( x , z ) that we have been using so far for candidates is actually misleading  , since in fact the candidates y that are compared encode more than just x and z  . They also encode a particular alignment or correspondence between x and z  . For example , if x = abdip and z = a[di ] [ bu] , then a typical candidate would be encoded y = aab0[ddii][pb0u ] which specifies that a corresponds to a , b was deleted ( has no surface correspondent ) , voiceless p surfaces as voiced b , etc . The harmony of y might depend on this alignment as well as on x and z  ( just as an outfit might fit worse when worn backwards  )  . 
Because we are distinguishing underlying and surface material by using disjoint alphabets ? = a  , b ,   .   .   . and ? = [ ,], a,b , .   .   . , 2 it is easy to extract the underlying and surface forms  ( x and z ) from y . 
Although the above example assumes that x and z are simple strings of phonemes and brackets  , nothing here in depends on that assumption . Autoseg-mental representations too can be encoded as strings  ( Eisner ,  1997) . 
In general , an OT grammar consists of 4 components : a constraint ranking , a harmony ordering , and generating and pronouncing functions . The constraint ranking is the language-specific part of the grammar  ; the other components are often supposed to be universal across languages  . 
The generating function GEN maps any x ??? to the  ( nonempty ) set of candidates y whose underlying for misx . In other words , GEN just inserts 2An alternative would be to distinguish them by odd and even positions in the string  . 
x ? ? ? ? underlying form x ? ? ?
GEN ? ? Y0(x)
C1??Y1(x )
C2??Y2(x ) ? ? ?
Cn ? ? Y n(x ) ? ? ? ? sets of candidates y ?(???)?
PRON ? ? Z ( x ) ???? set of surface forms z ??? where Yi?1 ( x ) 
Ci ? ? Yi(x ) really means Yi?1(x ) ? ? ? ? y?(???)?
Ci ? ? Y ? i ( x ) prune ? ? optimal subset of Y ? i ( x ) ???? y ?? ( ????? ) ? delete ? ? ? Yi ( x ) ???? y ? ( ??? ) ? Figure 1: This paper?s view of OT production . In the second line , Ci insert s ? ? s into candidates ; then the candidates with suboptimal starrings are pruned away  , and finally the ?? s are removed from the survivors  . 
arbitrary substrings from ?? amongst the characters of x  , subject to any restrictions on what constitutes a legitimate candidate y  . 3  ( Legitimacy might for instance demand that y?s surface material z have matched  , nonnested left and right brackets , or even that z be similar to x in terms of edit distance  . ) A constraint ranking is simply a sequence C1 , C2 ,   .   .   . Cn of constraints . Let us take each Ci to be a function that scores candidates y by annotating them with violation marks ?  . For example , a NODELETE constraint would map y = aab0c0[ddii][pb0u ] to y ? = NO DELETE ( y ) = aab ? 0 c ? 0 [ ddii ] [ pb0u] , inserting a ? after each underlying phoneme that does not correspond to any surface phoneme  . This unconventional formulation is needed for new approaches that care about the exact location of the ?? s  . In traditional OT only the number of ?? s is important  , although the locations are sometimes shown for readability  . 
Finally , OT requires a harmony ordering  on scored candidates y ? ?  ( ? ? ? ? ? ) ? . In traditional OT , y ? is most harmonic when it contains the fewest ? ? s  . For example , among candidates scored by NODELETE , the most harmonic ones are the ones with the fewest deletions  ; many candidates may tie for this honor . ?6 considers other harmony orderings , a possibility recognized by Prince and Smolensky ( 1993 )   (  corresponds to their H-EVAL )  . In general  may be a partial order : two competing candidates may be equally harmonic or incomparable  ( in which case both can survive )  , and candidates with different underlying forms never compete at all  . 
Production under such a grammar is a matter of successive filtering by the constraints  C1  ,   .   .   . Cn . 
Given an underlying form x , let
Y0 ( x ) = GEN ( x )   ( 1 )   3It is never really necessary for GEN to enforce such restrictions  , since they can equally well been forced by the top-ranked constraint  C1   ( see below )  . 
Yi ( x ) = y?Yi?1 ( x )  :  ( 2 )   ( @ y ? ? Yi?1 ( x ) ) Ci ( y ? )  Ci ( y ) The set of optimal candidates is now Yn ( x )  . Extracting z from each y ? Y n ( x ) gives the set Z ( x ) or PRODUCE ( x ) of acceptable surface forms :
Z(x ) = PRON(y ) : y?Y n(x ) ? ? ? (3)
PRON denotes the simple pronunciation function that extracts z from y  . It is the counterpart to GEN : just as GEN fleshes out x ??? into y by inserting symbols of  ?  , PRONs limsy downtoz ? ? ? by removing symbols of ?  . 
Notice that Yn ? Y n?1 ? .   .   . ? Y0 . The only candidates y ? Yi?1 that survive filtering by Ci are the ones that Ci considers most harmonic  . 
The above notation is general enough to handle some of the important variations of OT  , such as Paradigm Uniformity and Sympathy Theory . In particular , one can define GEN so that each candidate y encodes not just an alignment between x and z  , but an alignment among x , z , and some other strings that are neither underlying nor surface  . These other strings may represent the surface forms for other members of the same morphological paradigm  , or intermediate throw away candidates to which z is sympathetic  . Production still optimizes y , which means that it simultaneously optimizes z and the other strings  . 
4 Comprehension in Finite State OT
This section assumes OT?s traditional harmony ordering  , in which the candidates that survive filtering by Ci are the ones into which Ci inserts fewest ?? s  . 
Much computational work on OT has been conducted within a finite-state framework  ( Ellison ,  1994) , in keeping with a tradition of finite-state phonology  ( Johnson , 1972; Kaplan and Kay ,  1994) . 44 The tradition already included ( in violable ) phonological Finitestate OT is a restriction of the formalism discussed above  . It specifically assumes that GEN , C1, .   .   . Cn , and PRON are all regular relations , meaning that they can be described by finite -state transducers  . GEN is a nondeterministic transducer that maps each x to multiple candidates y  . The other transducers map each y to a single y ? or z  . 
These finite-state assumptions were proposed ( in a different and slightly weaker form ) by Ellison ( 1994 )  . Their empirical adequacy has been defended by Eisner  ( 1997 )  . 
In addition to having the right kind of power linguistically  , regular relations are closed under various relevant operations and allow  ( efficient ) parallel processing of regular sets of strings . Ellison ( 1994 ) exploited such properties to give a production algorithm for finite-state OT  . Given x and a finite-state OT grammar , he used finite-state operations to construct the set Yn  ( x ) of optimal candidates , represented as a finite-state automaton . 
Ellison?s construction demonstrates that Yn is always a regular set  . Since PRON is regular , it follows that PRODUCE ( x ) = Z ( x ) is also a regular set . 
We now show that COMPREHEND(z ) , in constrast , need not be a regular set . Let ? = a , b , ? = [ ,], a,b, .   .   . and suppose that GEN allows candidates like the ones in  ?3  , in which parts of the string may be bracketed between [ and ]  . The crucial grammar consists of two finite-state constraints  . 
C2 penalizes a?s that fall between brackets ( by inserting ? next to each one ) and also penalizes b?s that fall outside of brackets  . It is dominated by C1 , which penalizes brackets that do not fall at either edge of the string  . Note that this grammar is completely permissive as to the number and location of surface characters other than brackets  . 
If x contains more a?s than b?s , then PRODUCE ( x ) is the set ??? of all unbracketed surface forms , where ?? is ? minus the bracket symbols . If x contains fewer a ? s than b?s , then PRODUCE(x ) = [???] . 
And if a ? s and b?s appear equally often in x , then PRODUCE(x ) is the union of the two sets . 
Thus , while the x-to-z mapping is not a regular relation under this grammar  , at least PRODUCE ( x ) is a regular set for each x ? just as finite-state OT constraints  , notably Koskenniemi?s (1983) two-level model , which like OT used finite-state constraints on candidates y that encoded an alignment between underlying x and surface z  . 
guarantees . But for any unbracketed z ???? , such as z = abc , COMPREHEND ( z ) is not regular : it is the set of underlying strings with  #of a ? s ?  #of b?s  . 
This result seems to eliminate any hope of handling OT comprehension in a finite-state framework  . It is interesting to note that both OT and current speech recognition systems construct finite-state models of production and define comprehension as the inverse of production  . Speech recognizers do correctly implement comprehension via finite-state optimization  ( Pereira and Riley ,  1997) . 
But this is impossible in OT because OT has a more complicated production model  . ( In speech recognizers , the most probable phonetic or phonological surface form is not presumed to have suppressed its competitors  . ) One might try to salvage the situation by barring constraints like  C1 or C2 from the theory as linguistically implausible . Unfortunately this is unlikely to succeed . Primitive OT ( Eisner ,  1997 ) already restricts OT to something like a bare minimum of constraints  , allowing just two simple constraint families that are widely used by practitioners of OT  . Yet even these primitive constraints retain enough power to simulate any finite-state constraint  . In any case ,   C1 and C2 themselves are fairly similar to ? domain ? constraints used to describet one systems  ( Cole and Kisseberth ,  1994) . While C2 is somewhat odd in that it penalizes two distinct configurations at once  , one would obtain the same effect by combining three separately plausible constraints :  C2 requires a?s between brackets ( i . e . , in a tone domain ) to receive surface high tones ,   C3 requires b?s outside brackets to receive surface hight ones  , and C4 penalizes all surface hight ones . 5 Another obvious if unsatisfying hack would impose heuristic limits on the length of x  , for example by allowing the comprehension system to return the approximation COMPREHEND  ( z ) ? x : x?2 ? z . This set is finite and hence regular , so per-5Since the surface tones indicate the total number of a ?s and b?s in the underlying form  , COMPREHEND ( z ) is actually a finite set in this version , hence regular . But the nonregularity argument does go through if the tonal information in z is not available to the comprehension system  ( as when reading text without diacritics )  ; we cover this case in ?5 .   ( One can assume that some lower-ranked constraints require a special suffix before ]  , so that the bracket information need not be directly available to the comprehension system either  . ) haps it can be produced by some finite-state method  , although the automaton to describe the set might be large in some cases  . 
Recent efforts to force OT into a fully finite -state mold are more promising  . As we will see , they identify the problem as the harmony ordering    , rather than the space of constraints or the potential in fini-tude of the answer set  . 
5 Regular-Relation Comprehension
Since COMPREHEND ( z ) need not be a regular set in traditional OT , a corollary is that COMPREHEND and its inverse PRODUCE are not regular relations  . 
That much was previously shown by Markus Hiller and Paul Smolensky  ( Frank and Satta ,  1998) , using similar examples . 
However , at least some OT grammar sought to describe regular relations  . It has long been hypothesized that all human phonologies are regular relations  , at least if one omits reduplication , and this is necessarily true of phonologies that were successfully described with pre-OT formalisms  ( Johnson , 1972; Koskenniemi ,  1983) . 
Regular relations are important for us because they are computationally tractable  . Any regular relation can be implemented as a finite-state transducer T  , which can be inverted and used for comprehension as well as production  . PRODUCE(x ) = T ( x ) = range(x ? T ) , and COMPREHEND(z ) = T?1(z ) = domain(T ? z) . 
We are therefore interested in compiling OT grammars into finite-state transducers ? by hook or by crook  . ? 6 discusses how ; but first let us see how such compilation is useful in realistic situations  . 
Any practical comprehension strategy must recognize that the hearer does not really perceive the entire surface form  . After all , the surface form contains phonetically invisible material  ( e . g . , syllable and foot boundaries ) and makes phonetically imper-ceptible distinctions  ( e . g . , two copies of a tone versus one doubly linked copy  )  . How to comprehend in this case ? The solution is to modify PRON to ? go all the way ?? to delete not only underlying material but also phonetically invisible material  . Indeed , PRON can also be made to perform any purely phonetic processing  . Each output z of PRODUCE is now not a phonological surface form but a string of phonemes or spectrogram segments  . So long as PRON is a regular relation ( perhaps a nondeterministic or probabilistic one that takes phonetic variation into account  )  , we will still be able to construct T and use it for production and comprehension as above  . 6 How about the lexicon ? When the phonology can be represented as a transducer  , COMPREHEND(z ) is a regular set . It contains all inputs x that could have produced output z  . In practice , many of these inputs are not in the lexicon , nor are they possible novel words . One should restrict to inputs that appear in the lexicon  ( also a regular set ) by intersecting COMPREHEND ( z ) with the lexicon . For novel words this intersection will be empty ; but one can find the possible underlying forms of the novel word  , for learning?s sake , by intersecting COMPREHEND ( z ) with a larger ( infinite ) regular set representing all forms satisfying the language?s lexical constraints  . 
There is an alternative treatment of the lexicon.
GEN can be extended ? backwards ? to incorporate morphology just as PRON was extended ? forwards ? to incorporate phonetics  . On this view , the input x is a sequence of abstract morphemes , and GEN performs morphological preprocessing to turn x into possible candidates y  . GEN looks up each abstract morpheme?s phonological string ??? from the lex-icon  , 7 then combines these phonological strings by concatenation or template merger  , then nondeterministically inserts surface material from ??  . Such a GEN can plausibly be built up ( by composition ) as a regular relation from abstract morpheme sequences to phonological candidates  . This regularity , as for PRON , is all that is required . 
Representing a phonology as a transducer T has additional virtues  . T can be applied efficiently to any input string x  , whereas Ellison ( 1994 ) or Eisner ( 1997 ) requires a fresh automaton construction for each x  . A nice trick is to build T without 6Pereira and Riley ( 1997 ) build a speech recognizer by composing a probabilistic finite-state language model  , a finite-state pronouncing dictionary , and a probabilistic finite-state acoustic model . These three components correspond precisely to the input to GEN  , the traditional OT grammar , and PRON , so we are simply suggesting the same thing in different terminology  . 
7Nondeterministically in the case of phonologically conditioned allomorphs : INDEFINITE APPLE  7? ? ? pl , ? n ? pl ? ? ? . This yields competing candidates that differ even in their underlying phonological material  . 
PRON and apply it to all conceivable x?s in parallel  , yielding the complete set of all optimal candidates Yn  ( ?? ) = ? x???Yn ( x )  . If Y and Y ? denote the sets of optimal candidates under two grammars  , then ( Y ? ? Y ? )  ?  ( Y ? ? ? Y ) yields the candidates that are optimal under only one grammar  . Applying GEN?1 or PRON to this set finds the regular set of underlying or surface forms that the two grammars would treat differently  ; one can then look for empirical cases in this set  , in order to distinguish between the two grammars . 
6 Theorem on Compiling OT
Why are OT phonologies not always regular relations ? The trouble is that inputs may be arbitrarily long  , and so may accrue arbitrarily large numbers of violations  . Traditional OT ( ?4 ) is supposed to distinguish all such numbers . Consider syllabification in English , which prefers to syllabify the long input bibambam  .   .   . bam ? ? ? ? k copies as [ bi ] [ bam ] [ bam] .   .   . [ bam ] ( with k cod as ) rather than [ bib][am][bam] .   .   . [ bam](withk+1 codas) . NOCODA must therefore distinguish annotated candidates y ? with k ? ? s  ( which are optimal ) from those with k+1??s ( which are not )  . It requires a ( ? k+2 ) -state automaton to make this distinction by looking only at the ?? siny ?  . And if k can be arbitrarily large , then no finite-state automaton will handle all cases  . 
Thus , constraints like NOCODA do not allow an upper boundon k for all x ? ? ?  . Of course , the minimal number of violations k of a constraint is fixed given the underlying form x  , which is useful in pro-duction . 8 But comprehension is less fortunate : we cannot bound k given only the surface form z  . In the grammar of ?4 , COMPREHEND ( abc ) included underlying forms whose optimal candidates had arbitrarily large numbers of violations k  . 
Now , in most cases , the effect of an OT grammar can be achieved without actually counting anything  .   ( This is to be expected since rewrite-rule 8Ellison   ( 1994 ) was able to construct PRODUCE ( x ) from x . 
One can even build a transducer for PRODUCE that is correct on all inputs that can achieve ? K violations and returns ? on other inputs  ( signalling that the transducer needs to be recompiled with increased K  )  . Simply use the construction of ( Frank and Satta , 1998; Karttunen ,  1998) , composed with a hard constraint that the answer must have ? K violations  . 
grammars were previously written for the same phonologies  , and they did not use counting ! ) This is possible despite the above arguments because for some grammars  , the distinction between optimal and suboptimaly ? can be made by looking at the non-?symbols in y ? rather than trying to count the ?? s  . In our NOCODA example , a surface substring such as .   .   . ib ?] [ a .   .   . might signal that y ? is suboptimal because it contains an ? unnecessary ? coda  . Of course , the validity of this conclusion depends on the grammar and specifically the constraints  C1  ,   .   .   . C i?1 ranked above NOCODA , since whether that coda is really unnecessary depends on whether  Y?i?1 also contains the competing candidate .   .   . i ] [ ba .   .   . with fewer codas . 
But as we have seen , some OT grammars do have effects that over step the finite-state boundary  ( ?4 )  . 
Recent efforts to treat OT with transducers have therefore tried to remove counting from the formalism  . We now unify such efforts by showing that they all modify the harmony ordering   . 
? 4 described finite-state OT grammars as ones where GEN  , PRON , and the constraints are regular relations . We claim that if the harmony ordering  is also a regular relation on strings of  ( ????? ) ? , then the entire grammar ( PRODUCE ) is also regular . 
We require harmony orderings to be compatible with GEN : an ordering must treat y ? ?  , y ? as in comparable ( neither is  the other ) if they were produced from different underlying forms  . 9 To make the notation readable let us denote the  relation by the letter H  . Thus , a transducer for H accepts the pair ( y ? ? , y ?) if y ? ? y ? . 
The construction is inductive . Y0 = GEN is regular by assumption . If Yi?1 is regular , then so is Yi since ( as we will show )
Yi = ( Y ? i ? ? range ( Y ? i ? H ) ) ? D ( 4 ) where Y ? i def = Yi?1 ? Ci and maps x to the set of starred candidates that C i will prune  ; ? denotes the complement of a regular language ; and D is a transducer that removes all ?? s . Therefore PRODUCE =
Yn ? PRON is regular as claimed.
9For example , the harmony ordering of traditional OT is ( y ? ? , y ?): y ? ? has the same underlying form as , but contains fewer ?? s than , y ? . If we were allowed to drop the same-underlying -form condition then the ordering would become regular  , and then our claim would falsely imply that all traditional finite-state OT grammars were regular relations  . 
It remains to derive (4) . Equation ( 2 ) implies Ci ( Yi ( x ) ) =  y ? ? Y?i ( x )  :  ( @ y ? ? ? Y ? i ( x ) ) y ??  y ? ( 5 ) = Y ? i ( x ) ? y?: ( ? y???Y ? i ( x ) ) y ? ?  y ? ( 6 ) = Y ? i ( x ) ?H ( Y?i ( x ) )  ( 7 ) One can read H ( Y?i ( x ) ) as ? starred candidates that are worse than other starred candidates  , ? i . e . , suboptimal . The set difference ( 7 ) leaves only the optimal candidates . We now see(x , y ? ) ?Yi?Ci ? y??Ci ( Yi ( x ) )  ( 8 ) ? y??Y ? i ( x )  , y?6?H(Y?i(x )) [ by (7)] (9) ? y??Y?i(x ) , (@ z)y ? ? H(Y ? i(z )) [ see below ] (10) ?( x , y ?) ? Y ? i , y ? 6 ? range(Y ? i ? H ) (11) ?( x , y ? ) ? Y ? i ? ? range ( Y ? i ? H )   ( 12 ) therefore Yi ? Ci = Y ? i ? ? range ( Y ? i ? H )   ( 13 ) and composing both sides with D yields ( 4 )  . To justify ( 9 ) ?  ( 10 ) we must show when y ? ? Y ? i ( x ) that y ? ? H ( Y?i ( x ) ) ?  ( ? z ) y ? ? H ( Y?i ( z ) ) . For the ? direction , just take z = x . For ? , y ? ? H ( Y?i ( z ) ) means that ( ? y???Y ? i ( z ) )y ??  y ? ; but then x = z ( giving y ? ? H(Y ? i(x ))) , since if not , our compatibility requirement on H would have made y ? ? ? Y ? i  ( z ) incomparable with y ? ? Y ? i ( x )  . 
Extending the pretty notation of ( Karttunen ,  1998) , we may use ( 4 ) to define a left-associative generalized optimality operator oo H : 
Yoo HC def = ( Y ? C ? ? range ( Y ? C ? H ) )?D ( 14 ) Then for any regular OT grammar , PRODUCE =
GEN oo H C1 oo H C2 ? ? ? oo HCn ? PRON and can be inverted to get COMPREHEND  . More generally , different constraints can usefully be applied with different H?s  ( Eisner ,  2000) . 
The algebraic construction above is inspired by a version that Gerdemann and van Noord  ( 2000 ) give for a particular variant of OT . Their regular expressions can be used to implement it  , simply replacing their add_violation by our H . 
Typically , Hignores surface characters when comparing starred candidates  . SoH can be written as elim ( ? ) ?G?elim ( ? ) ?1 where elim ( ? ) is a transducer that removes all characters of ? . To satisfy the compatibility requirement on H , G should be a subset of the relation ( ? ?  (  : ? ) (? :  ) )? . 1 0   10This transducer regexpsays to map any symbol in ??? to itself  , or insert or delete ?? and then repeat . 
We now summarize the main proposals from the literature  ( see ?1 )  , propose operator names , and cast them in the general framework . 
? YoC : Inviolable constraint ( Koskenniemi , 1983; Bird ,  1995) , implemented by composition . 
? Yo + C : Counting constraint ( Prince and Smolensky , 1993): more violations is more disharmonic . No finite-state implementation possible . 
? YooC : Binary approximation ( Karttunen , 1998; Frank and Satta ,  1998) . All candidates with any violations are equally disharmonic  . Implemented by G = (??( : ?) ??) + , which relates underlying forms without violations to the same forms with violations  . 
? Yoo3C:3-bounded approximation ( Karttunen , 1998; Frank and Satta ,  1998) . Likeo + , but all candidates with ? 3 violations are equally disharmonic . G is most easily described with a transducer that keeps count of the input and output ?? s so far  , on a scale of 0 ,  1 ,  2 ,  ? 3 . Final states are those whose output count exceeds their input count on this scale  . 
? Yo ? C : Matching or subset approximation ( Gerdemann and van Noord ,  2000) . A candidate is more disharmonic than another if it has stars in all the same locations and some more besides  . 11 Here
G = ((??) ?(  : ?)(??)?) + .
? Yo > C : Left-to-right directional evaluation ( Eisner ,  2000) . A candidate is more disharmonic than another if in the leftmost position where they differ  ( ignoring surface characters )  , it has a ? . This revises OT?s ? do only when necessary ? mantrato ? do only when necessary and then as late as possible ?  ( even if delaying ?? s means suffering more of them later  )  . 
Here G = (??) ?((  : ?)(( ? : ?)( ??) ?)) . Unlike the other proposals , here two forms can both be optimal only if they have exactly the same pattern of violations with respect to their underlying material  . 
? Y < oC : Right-to-left directional evaluation.
? Do only when necessary and then as early as possible  . ? Here G is the reverse of the Gusedino > . 
The novelty of the matching and directional proposals is their attention to where the violations fall  . 
Eisner?s directional proposal ( o > , < o ) is the only 11Many candidates are in comparable under this ordering , so Gerdemann and van Noord also showed how to weaken the notation of ? same location ? in order to approximate o + better  . 
( a ) x = banto dibo [ ban ] [ to][di][ban][ton][di ] [bo][ban][to][dim][bon][ban][ton][dim][bon ]   ( b ) NOCODA ban?to diboban?to?di boban?to di?bo?ban ? to ? di ? bo ?  ( c ) C1NOCODA *!*+***** !***!* ( d )   C1   ?1   ?2   ?3   ?4 *!***!+*****!** Figure 2: Counting vs . directionality . [ Adapted from ( Eisner , 2000) . ]  C1 is some high-ranked constraint that kills the most faithful candidate  ; NOCODA dislikes syllable codas . ( a ) Surface material of the candidates . (b ) Scored candidates for G to compare . 
Surface characters but not ?? s have been removed by elim  ( ? )  . (c ) In traditional evaluation o + , G counts the ?? s .   ( d ) Directional evaluation o > gets a different result  , as if NOCODA were split into 4 constraints evaluating the syllables separately . More accurately , it is as if NOCODA were split into one constraint per underlying letter  , counting the number of ?? s right after that letter  . 
one defended on linguistic as well as computational grounds  . He argues that violation counting ( o + ) is a bug in OT rather than a feature worth approximating  , since it predicts unattested phenomena such as ? majority assimilation ?  ( Bakovic ? , 1999; Lombardi ,  1999) . Conversely , hear gues that comparing violations directionally is not a hack but a desirable feature  , since it naturally predicts ? iterative phenomena ? whose description in traditional OT  ( via Generalized Alignment ) is awkward from both a linguistic and a computational point of view  . Fig .   2 contrasts the traditional and directional harmony orderings  . 
Eisner ( 2000 ) proved that o > was a regular operator for directional H  , by making use of a rather different insight , but that machine-level construction was highly technical  . The new algebraic construction is simple and can be implemented with a few regular expressions  , as for any other H . 
7 Conclusion
See the itemized points in ?1 for a detailed summary . 
In general , this paper has laid out a clear , general framework for finite-state OT systems , and used it to obtain positive and negative results about the understudied problem of comprehension  . Perhaps these results will have some bearing on the development of realistic learning algorithms  . 
The paper has also established sufficient conditions for a finite-state OT grammar to compile into a finite-state transducer  . It should be easy to imagine new variants of OT that meet these conditions  . 

Eric Bakovic ? .  1999 . As similation to the unmarked . Rutgers Optimality Archive ROA-340 . , August . 
Steven Bird . 1995. Computational Phonology : A
Constraint-Based Approach . Cambridge.
Reinhard Blutner .  1999 . Some aspects of optimality in natural language interpretation  . In Papers on Optimality Theoretic Semantics . Utrecht . 
J . Cole and C . Kisseberth .  1994 . An optimal domains theory of harmony . Studies in the Linguistic Sciences , 24(2) . 
Jason Eisner .  1997 . Efficient generation in primitive Optimality Theory  . In Proc . of ACL/EACL . 
Jason Eisner .  2000 . Directional constraint evaluation in
Optimality Theory . In Proc . of COLING.
T . Mark Ellison .  1994 . Phonological derivation in Optimality Theory . In Proc . of COLING J . Eric Fosler .  1996 . On reversing the generation process in Optimality Theory  . Proc . of ACL Student Session . 
R . Frank and G . Satta .  1998 . Optimality Theory and the generative complexity of constraint violability  . Computational Linguistics , 24(2):307?315 . 
D . Gerdemann and G . van Noord .  2000 . Approximation and exactness in finite-state Optimality Theory  . In
Proc . of ACL SIGPHON Workshop.
Mark Hale and Charles Reiss .  1998 . Formal and empirical arguments concerning phonological acquisition  . 
Linguistic Inquiry , 29:656?683.
C . Douglas Johnson .  1972 . Formal Aspects of Phonological Description . Mouton . 
R . Kaplan and M . Kay .  1994 . Regular models of phonological rule systems . Comp . Ling . , 20(3) . 
L . Karttunen .  1998 . The proper treatment of optimality in computational phonology  . In Proc . of FSMNLP . 
Kimmo Koskenniemi .  1983 . Two-level morphology : A general computational model for wordform recognition and production  . Publication 11, Dept . of General
Linguistics , University of Helsinki.
Linda Lombardi .  1999 . Positional faithfulness and voicing assimilation in Optimality Theory  . Natural Language and Linguistic Theory ,  17:267?302 . 
Fernando C . N . Pereira and Michael Riley .  1997 . Speech recognition by composition of weighted finite automata  . In E . Roche and Y . Schabes , eds . , Finite State
Language Processing . MIT Press.
A . Prince and P . Smolensky .  1993 . Optimality Theory : Constraint interaction in generative grammar  . Ms . ,
Rutgers and U . of Colorado ( Boulder).
Paul Smolensky .  1996 . On the comprehen-sion/production dilemma in child language  . Linguistic
Inquiry , 27:720?731.
