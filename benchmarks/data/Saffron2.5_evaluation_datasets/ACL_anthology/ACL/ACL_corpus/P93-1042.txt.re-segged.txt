HOWDOWECOUNT ?
THE PROBLEM OF TAGGING PHRAS ALVERBS IN PARTS
Nava A . Shaked
The Graduate School and University Center
The City University of New York 33 West 42nd Street . New York , NY 10036 nava@nyn exst . com

This paper examines the current performance of the stochastic tagger PARTS  ( Church 88 ) in handling phrasal verbs , describes a problem that arises from the statistical model used  , and suggests a way to improve the tagger's performance  . The solution involves a change in the definition of what counts as a word for the purpose of tagging phrasal verbs  . 
1. INTRODUCTION
Statistical taggers are commonly used to preprocess natural anguage  . Operations like parsing , information retrieval , machine translation , and so on , are facilitated by having as input a text tagged with a part of speech label for each lexical item  . In order to be useful , a tagger must be accurate as well as efficient . The claim among researchers advocating the use of statistics for NLP  ( e . g . Marcus et al 92 ) is that taggers are routinely correct about 95% of the time . The 5% error rate is not perceived as a problem mainly because human taggers disagree or make mistakes at approximately the same rate  . On the other hand , even a 5% error rate can cause a much higher rate of mistakes later in processing if the mistake falls on a key elemen that is crucial to the correct analysis of the whole sentence  . One example is the phrasal verb construction ( e . g . gundown , backoff ) . An error in tagging this two element sequence will cause the analysis of the entire sentence to befaulty  . 
An analysis of the errors made by the stochastic tagger PARTS  ( Church 88 ) reveals that phrasal verbs do indeed constitute a problem for the model  . 
2. PHRASAL VERBS
The basic assumption underlying the stochastic process is the notion of independence  . Words are defined as units separated by spaces and then undergo statistical approximations  . As a result the elements of a phrasal verb are treated as two individual words  , each with its own lexical probability ( i . e . the probability of observing part of speech i given word j  )  . An interesting pattern emerges when we examine the errors involving phrasal verbs  . A phrasal verb such as sum up will be tagged by PARTS as noun + preposition instead of verb + particle  . This error influences the tagging of other words in the sentence as well  . One typical error is found in infinitive constructions  , where a phrase like to gundown is tagged as INTO NOUN IN  ( a prepositional ' to ' followed by a noun followed by another preposition  )  . Words like gun , back , and sum , in isolation , have a very high probability of being nouns a . sopposed to verbs , which results in the misclassification described above  . However , when these words are followed by a particle , they are usually verbs , and in the infinitive construction , always verbs . 
2.1. THEHYPOTHESIS
Tile error appears to follow froln the operation of the stochastic process itself  . In a trigram model the probability of each word is calculated by taking into consideration two elements : the lexical probability  ( probability of the word bearing a certain tag ) and the contextual probability ( probability of a word bearing a certain tag given two previous parts of speech  )  . As a result , if an element has a very high lexical probability of being a noun  ( gun is a noun in 99 out of 102 occurrences in the Brown Corpus )  , it will not only influence but will actually override the contextual probability  , which might suggest a different assignment . In the case of to gun down the ambiguity of to is enhanced by the ambiguity of gun  , and a mistake in tagging gun will automatically lead to an incorrect agging of to as a preposition  . 
It follows that the tagger should perform poorly onement occurs much more frequent y as a noun  ( or any other element hat is not a verb )  . The tagger will experience fewer problems handling this construction when the ambiguous element is a verb in the vast majority of instances  . If this is true , the model should be changed to take into consideration the dependency between the verb and the particle in order to optimize the performance of the tagger  . 
3. THEEXPERIMENT 3.1. DATA
The first step in testing this hypothesis was to evaluate the current performance of PARTS in handling the phrasal verb construction  . To do this a set of 94 pairs of Verb+Particle/Preposition was chosen to represent a range of dominant frequencies from overwhelmingly noun to overwhelmingly verb  .   20 example sentences were randomly selected for each pair using an online corpus called MODERN  , which is a collection of several corpora ( Brown , WSJ , AP88-92 , HANSE , HAROW , WAVER , DOE , NSF , TREEBANK , and DISS ) totaling more than 400 million words . These sentences were first tagged manually to provide a baseline and then tagged automatically using PARTS  . The a priori option of assuming only a verbal tag for all the pairs in question was also explored in order to test if this simple solution will be appropriate in all cases  . The accuracy of the 3 tagging approaches was evaluated . 
3.2. RESULTS
Table 2 presents a sample of the pairs examined in tile first column  , PARTS performance for each pair in tile second , and the results of assuming a verbal tag in the third  . ( The " choice " colun misexplained below . ) The average performance of PARTS for this task is  89%  , which is lower than the general average performance of the tagger as claimed in Church  88  . Yet we notice that simply assigning a verbal tag to all pairs actually degrades performance because in some cases the content word is a  . l most always a noun rather than a verb . For example , a phrasal verb like box in generally appears with an intervening object  ( to box something in )  , and thus when box and in a read jacent ( except for those rare cases involving heavy NP shift  ) box is a noun . 
Thus we see that there is a need to distinguish between the cases where the two element sequence should be considered as one word for the purpose of assign-iug the Lexical Probability  ( i . e . ,phrasal verb ) and cases where we have a Noun+Preposition combination where PARTS ' analyses will be preferred  . The " choice " in
PHRASALIMP.

FREQ . DIST.
( BROWN ) date-from 1 . 00 date flesh-out 0 . 59 flesh bottle-up 0 . 55 bottle hand over 0 . 35 hand narrow-down 0 . 23 narrow close-down 0 . 22 closed rive-off 0 . 22 drive cry-out 0 . 21 cryaverage-out 0 . 20 average head-for 0 . 18 head end-up 0 . 16 end account-for 0 . 15 account double-up 0 . 14 double backoff 0 . 13 back cool-off 0 . 13 cool clear-out 0 . 12 clear cahn-down 0 . 10 cMm
NN/98 VB/6
NN/53 VB/1
NN/77 VB/1
NN/411 VB/8
JJ/61 NN/1 VB/1
JJ/81 NN/16
QL/1RB/95 VB/40
NN/49 VB/46
NN/31 VB/19
JJ/64 NN/60 VB/6
JJ/4NN/404 VB/14
NN/359 VB/41
NN/89 VB/28
JJ/37 NN/llRB/4

JJ/27 NN/177 RB/720

JJ/49 NN/3
RB/1 VB/S
JJ/197 NN/1
RB/10 VB/15
JJ/22 NN/8 VB/7
Table 1:   10% or more improvement for elements of nonverbal frequency  . 
Table 2 shows that allowing a choice between PARTS ' analysis and one verbal tag to the phrase by taking the higher performance score  , improves the performance of PARTS from 89% to 96% for this task , and reduces the errors in other constructions involving phrasal verbs  . 
When is this alternative needed ? In the cases where PARTS had  10% or more errors , most of the verbs occur l nuch more often as nouns or adjectives  . This confirms my hypothesis that PARTS will have a problem solving the N/V ambiguity in cases where the lexical probability of the word points to a noun  . These are the very cases that should be treated as one unit in the system  . The lexical probability should be assigned to the pair as a whole rather than considering the two element separately  . Table 1 lists the cases where tagging improves 10% or more when PARTS is given the additional choice of assigning a verbal tag to the whole expression  . Frequency distributions of these tokens in tile Brown Corpus are presented as well  , which reflect why statistical probabilities err in these cases  . In order to tag these expressions correctly , we will have to capture additional information about the pair which is not available frolntile PARTS statistical model  . 
290 pairs parts all verb choice account-for 0 . 841 1 aim-at 0 . 90 0 . 30 0 . 90 average-out 0 . 7 0 . 9 0 . 9 backoff 0 . 8611 balance-out 0 . 92 0 . 84 0 . 92 bargain-for 0 . 87 0 . 58 0 . 87 block-in 0 . 97 0 . 02 0 . 97 book-in 101 bottle-up 0 . 36 0 . 90 0 . 90 bottom-out 0 . 8 0 . 85 0 . 85 box-in 10 . 021 break-away 111 call-back 0 . 96 0 . 84 0 . 96 calm-down 0 . 85 0 . 95 0 . 95 care-for 0 . 9 0 . 48 0 . 93 cash-in 0 . 95 0 . 25 0 . 95 change-into 0 . 85 0 . 89 0 . 89 check-in 0 . 96 0 . 48 0 . 96 clear-out 0 . 8711 close-down 0 . 7711 contract-in 10 . 021 cool-off 0 . 8611 credit-with 101 cry-out 0 . 7911 date-from 011 deal-with 0 . 96 0 . 92 0 . 96 demand-of 10 . 041 double-up 0 . 80 0 . 95 0 . 95 end-up 0 . 8311 fall-in 0 . 92 0 . 29 0 . 92 feel-for 0 . 93 0 . 33 0 . 93 flesh-out 0 . 4111 flow-from 0 . 94 0 . 42 0 . 94 fool-around 0 . 9111 force-upon 0 . 84 0 . 61 0 . 84 gun-down 0 . 60 0 . 62 0 . 62 h and over 0 . 6511 head-for 0 . 63 0 . 81 0 . 81 heat-up 0 . 9411 hold-down 0 . 9211 lead-on 10 . 071 let-down 0 . 57 0 . 57 0 . 57 live-for 0 . 9111 move-in 0 . 96 0 . 60 0 . 96 narrow-down 0 . 7711 part-with 0 . 79 0 . 430,79 phone-in 0 . 91 0,12 0 . 91
TOTALAVERAGE 0.89 0,79 0.96
Table 2: A Sample of Performance Evaluation 4 . CONCLUSION : LINGUISTIC
INTUITIONS
This paper shows that for some cases of phrasal verbs it is not enough to rely on lexical probability alone : We must take into consideration the dependency between the verb and the particle in order to improve the performance of the tagger  . The relationship between verbs and particles is deeply rooted in Linguistics  . Smith (1943) introduced the term phrasal verb , arguing that it should be regarded as a type of idiom because the elements behave as a unit  . He claimed that phrasal verbs express a single concep that often has a one word counterpart in other languages  , yet does not always have compositional meaning . Some particles are syntactically more adverbial in nature and some more prepositional  , but it is generally agreed that the phrasal verb constitutes a kind of integral functional unit  . Perhaps linguistic knowledge can help solve the tagging problem described here and force a redefinition of the boundaries of phrasal verbs  . For now we can redefine the word boundaries for the problematicases that PARTS doesn't handle well  . Future research should concentrate on the linguistic characteristics of this problematic construction to determine if there are other cases where the current assumption that one word equals one unit interferes with successful processing  . 
5. ACKNOWLED GEMENT
I wish to thank my committee members Virginia Teller  , Judith Klavans and John Moyne for their helpful comments and support  . I am also indebted to Ken Church and Don Hindle for their guidance and help all along  . 
6. REFERENCES
K . W . Church . A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text  . Proc . Conf . on Applied Natural Language Processing ,  136143 ,  1988 . 
K . W . Church , & R . Mercer . Introduction to the Special Issue on Computational Linguistics Using Large Corpora  . To appear in Computational Linguistics , 1993 . 
C . Leraux . On The Interface of Morphology & Syntax . 
Evidence from Verb-Particle Combinations in Afi -ican  . 
SPIL 18. November 1988. MA Thesis.
M . Marcus , B . Santorini & D . Magerman . First steps towards an annotate database of American English  . 
Dept . of Computer and Information Science , University of Pennsylvania ,  1992 . MS . 
L . P . Smith . Words ~" Idioms : Studies in The English
Language .5 the d . London , 1943.

