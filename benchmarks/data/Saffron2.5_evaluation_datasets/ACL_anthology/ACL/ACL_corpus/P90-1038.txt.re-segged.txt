BOT TOM-UPPARSING EXTENDING CONTEXT-FREENESS
INAPROCES SGRAM MAR PROCESSOR
Massimo Marino
Department of Linguistics - University of Pisa 
Via S . Maria 361-56 100 Pisa-ITA LY
Bitnet:massimom@icnucevm.cnuce.cn r.it

A new approach to bottom-u parsing that extends Augmented ContextFree Grammar to a Process Grammar is formally presented  . A Process Grammar ( PG ) defines a set of rules suited for bottom-up arsing and conceived as processes that are applied by a PG Processor  . The matching phase is a crucial step for process application  , and a parsing structure for efficient matching is also presented  . 
The PG Processor is composed of a processcheduler that allows immediate constituent analysis of structures  , and behaves in a nondeterministic fashion . On the other side , the PG offers means for implementing spec ~ c parsing strategies improving the lack of determinism innate in the processor  . 
1. INTRODUCTION
Bottom-up parsing methods are usually preferred because of their property of being driven from both the input's syntactic/semantic structures and reduced constituents structures  . Different strategies have been realized for handling the structures construction  , e . g . , parallel parsers , backtracking parsers , augmented contextfree parsers ( Aho et al , 1972; Grishman , 1976; Winograd ,  1983) . The aim of this paper is to introduce a new approach to bottom-up parsing starting from a wellknown and based framework-parallel bottom -uparsing in immediate constituent analysis  , where all possible parses are considered-making use of an Augmented Phrase-Structure Grammar  ( APSG )  . In such environment we must perform efficient searches in the graph the parser builds  , and limit as much as possible the building of structures that will not be in the final parse tree  . For the efficiency of the search we introduce a Parse Graph Structure  , based on the def'mition of adjacency of the subtrees  , that provides an easy method of evaluation for deciding at any step whether a matching process can be accomplished or not  . The control of the parsing process is in the hands of an APSG called Process Grammar fPG  )  , where grammar rules are conceived as processes that are applied whenever proper conditions  , detected by a process scheduler , exist . This is why the parser , called PG Processor , works following a nondeterministic parallel strategy  , and only the Process Grammar has the power of altering and constraining this behaviour by means of some Kernel Functions that can modify the control structures of the PG Processor  , thus construction of useles structures . Some of the concepts introduced in this paper , such as some definitions in Section 2 , are a development from Grishman ( 1976 ) that can be also an introductory reading regarding the description of a parallel bottom-up parser which is  , even if under a different aspect , the core of the PG Processor . 
2. PARSEGRAPHSTRUCTURE
The Parse Graph Structure ( PGS ) is built by the parser while apply in grammar rules  . If s = aaa2 . . . a is an input string the initial PGS is composed by a set of terminal nodes  <0  , $> , < l , a a > ,  <2 , a2> . . . . . < n , a > , < n + l , $> , where nodes 0 , n+1 represent border markers for the sentence . All the next nonterminal nodes are numbered starting from  n+2  . 
Definition 2 . 1 . A PGS is a triple ( Nr , Nr~ , T ) where Nr is the set of the terminal nodes numbers  0  ,  1  . .  .   .   . n , n + l ; NN is the set of the nonterminal nodes numbers n+2   . . . . , and T is the set of the subtrees . 
The elements of NN and NT are numbers identifying nodes of the PGS whose structure is defined below  , and throughout the paper we refer to nodes of the PGS by means of such nodes number  . 
Definition 2 . 2 . If ke Nr ~ the node ie Nr labeling ai at the beginning of the clause covered by k is said to be the left corner leaf of klcl  ( k )  . If ke Nr then lcl(k ) = k . 
Definition 2 . 3 . If keNs the node jeNT labeling aj at the end of the clause covered by k is said to be the right corner leaf of krcl  ( k )  . If k eNT then rcl(k ) = k . 
Definition 2 . 4 . If k ~ NN the node he Nr that follows the right corner leaf of k rel  ( k ) is said to be the anchor leaf of kal ( k )  , and al ( k ) = h = rel ( k ) + LIfke NT-n+l then al ( k ) = k + l . 
Definition 2 . 5 . If keNT the set of the anchored nodes of k an ( k ) is an ( k ) = j~NTUNsIalQ ) = k . 
From this definition it follows that for every k e NT-0  , an ( k ) contains at the initial time the node number ( k-l )  . 
Definition 2 . 6 . a . If keNT the subtree rooted in kT ( k ) is represented by T ( k ) = < k , lcl(k) , rcl(k) , an(k) , cat(k ) > , where k is the root node ; lcl(k)--rel(k ) = k ; an ( k ) = ( k-l ) initially ; cat(k ) = a ~ , the terminal category of the node . 
b . If keNr ~ the subtree rooted in kT ( k ) is represented by T ( k ) =<k , lcl(k) , rcl(k) , sons(k) , cat(k ) > , where k is the root node ; sons(k ) = sI . . . . . sv , sicNTuNs , i = 1 . . . . . p , is the set of the direct descendants of k ; cat(k ) = A , a nonterminal category assigned to the node . 
From the above definitions the initial PGS for a sentences = a ~ av  . .a n is : Nr=0,1 . . . . . n,n+l,Ns =, T = T (0), T (1) . . . . . T ( n) , T ( n+1); and : T(0) = < 0 , 0 , 0 ,    $> , T ( i ) = < i , i , i , i-1 , ai>for i = 1 . . . . . n , and T ( n + 1) = < n + 1, n + l , n + l , n , $ > . With this PGS the parser starts its work reducing new nodes from the already existing ones  . If for some k ~ N r ~, T ( k ) = < k , lcl(k ), r cl(k ), s1 . . . . . sp , A >, and T ( s ) = < si , lcl(sl ), rcl(s ~), sn . . . . . s~t,zi>eT , for i = 1 . . . . . p0 are the direct descendants of k , the nk has been reduced from s ~ . . . .  , st by some grammar rule whose reduction rule , as we shall see later , has the form ( A~---zv . . zp ) , and the following holds : lcl(k ) = lcl(st ) , rcl(s ~) = l cl(s2)-l , rcl(s2) = lcl(ss)-1 . . . . . 
rcl(sr , l ) = lcl(sr)-1,rcl(sp ) = rcl(k) . From that we can give the following definition : <12  , a 12> <14 , a 14> <13 , a 13> < 0 , $> < l , al > < 2 , a 2>    0 I of the match process the matcher must start from the last scanned or built node zs  , finding afterwards z2 and z ~ , respectively , sailing in the PGS right-to-left and passing through adjacent subtrees  . Steps through adjacent subtrees are easily accomplished by using the sets of the anchored nodes in the terminal nodes  . It follows from the above def'mitions that if k ~ NN then the subtrees adjacent to T  ( k ) are given by an ( lel ( k ) ) , whereas ffk ~ Nr then the adjacent subtrees are given by an  ( k )  . The lists of the anchored nodes provide an efficient way to represent the relation of adjacency betwee nodes  . These sets stored only in the terminal nodes provide an efficient data structure useful for the matcher to accomplish its purpose  . Figure 1 shows a parse tree at a certain time of a parse , where under each

T(9) = <9,1,2,1,2, a9>
TOO ) = <10,2,2,2, a10>
T ( ll ) = <11,2,3,10,3, al1>
T (12) = <12,1,3,9,3, a12>
T (13) = <13,4,5,4,5, a13>
T (14) --<14 , 3 , 5 , 3 , 4 , 5a 14> <3#3 > < 4 , a 4> < 5 , a 5> < 1 , a 6> < 7 , a 7> < 8 , $> 2 , 9 , 10 3 , 11 , 12 4 5 , 13 , 1467 Figure 1 . A parse tree with the sets of the anchored nodes a7 I 13   14   3   11   12   2   9   10   1 lalal\[ 1   1 
Figure 2.
Definition 2 . 7 . If st . . . . . s . is a set of nodes in the PGS , then their subtrees T ( sa ) . . . . . T ( ~ p ) are said to be adjacent when rcl ( si ) = lcl ( si . ~)-1 or , alternatively , al(si ) = lcl(sm ) , for i = 1 . . . . , p1 . 
During a parsing process a great effort is made in finding a set of adjacent subtrees that match a fight-hand side of a reduction rule  . Let ( A~z~z2z3) be a reduction rule , then the parser should start a match process to find all possible sets of adjacent subtrees such that heir categories matchzaz  2 z 3  . 
The parser scans the input string left-to-right , so reductions grow on the left of the scanner pointer  , and for the efficiency terminal node there is the corresponding list of the anchored nodes  . A useful structure that can be derived from these sets is an adjacency tree  , recursively defined as follows : Definition 2 . 8 . If ( Nr , NwT ) is a PGS for an input sentences , and Isl=n , then the adjacency tree for the PGS is so built :  -   n+1 is the root of the adjacency tree ; -for every k ~ Nr - 0 , 1uN . , the sons ofk are the nodes in an ( Icl ( k ) ) unless an ( Icl ( k ) )= 0 . 
Figure 2 shows the adjacency tree obtained from the partial parse tree in Figure  1  . Any passage from a node k to one of its sonsh in the adjacency tree represents a passage from a  3   11   12   2   9   10 talt 2   9   10   1   1   1 
I "111 subtree T ( k ) to one of its adjacent subtrees T ( h ) in the PGS . 
Moreover , during a match process this means that a constituent of the right hand side has been consumed  , and matching the first symbol that-match process is f ' mished  . 
The adjacency lace also provides further useful information for optimizing the search during a match  . For every node k , if we consider the longest path from k to a leaf , its length is an upper bound for the length of the right hand side still to consume  , and since the sons of k are the nodes in an ( lcl ( k ) ) , the longest path is always given by the sequence of the terminal nodes from the node  1 to the node l c l ( k ) - 1 . Thus its length is just l cl(k)-l . 
Property 2 . 1 . If ( Nr , Ns , T ) is a PGS , ( A ~ zl .   .   . zv ) is a reduction rule whose righthand side has to be matched  , and
T ( k ) ~ T such that cat(k ) = z , then : a . the string zt . . . zp is mat c ' hable iff p < lcl(k ); b . for i = p . . . . .  1 , zt is partially match able to a node Definition 2 . 10 . If ( Nr , Ns , T ) is a PGS , an adjacency digraph can be represented as follows : a  . for any ke Nr , k has outgoing arcs directed to the nodes in an ( k )  ; b . for any k ? NN , k has one outgoing arc directed to lcl(k ) . 
In the classic literature the lists of the anchored nodes are called adjacency lists  , and are used for representing graphs ( A hoet at . , 1974) . A graph G = ( V , E ) can be usually represented by IVI adjacency lists . In our representation we can obtain an optimization representing an adjacency digraph by n adjacency lists  , if n is the length of the sentence , and by INs l simple pointers for accessing the adjacency lists from the nonterminal nodes  , with respect to n+lNsladjacency lists for a full representation f an adjacency digraph composed of arcs as in Det'mition  2  . 10 . a . 
Figure 3 shows how a new nonterminal node is connected in an adjacency digraph  , and Figure 4 shows the adjacency k\[lcl ( k ) ~ I - - - - k access from k to l c l ( k )   , ql-lcl(k-1) ~ lcl(k ) , ~-  . . . al(k ) = rcl(k ) + l . ~- Ir~kT ( k ) is adjacent to T ( r ) Figure 3 . Adding a nonterminal node k to an adjacency digraph  04$_   1   ~4r " a ~""" ; ~"" ~_~ a45 . 4t . . . . . ~ . .__~ ~7 . ~ . ~__8 " . . , / , "  .   . j ' -- . 
-Id"'~llP"""'14~'13 r
Figure 4 . Adjacency Digraphhe NNu Nriff cat ( h ) = z i and i < I cl ( h )  . 
Property 2 . I . along with the adjacency relation provides a method for an efficient navigation within the PGS among the subtrees  . This navigation is performed by the matcher in the PGS as visiting the adjacency tree in a preorder fashion  . 
It is easy to see that a preorder visit of the adjacency trees cans all possible sequences of the adjacent subtrees in the PGS  , but Property 2 . 1 provides a shortcut for avoiding useless passages when matchable conditions do not hold  . 
When a matchends the matcher returns one or more sets of node satisfying the following conditions : Definition  2  . 9 . A set RSet = nI . . . . , np  is a match for a string zl . . . zpiff cat(nl ) ffizi , for i = 1, . . . , p , and T ( nl ) is adjacent to T ( ni , l ) , for i = 1 . . . . , p1 . The set RSet is called a reduction set . 
The adjacency tree shows the hypothetical search space for searching the reduction sets in a PGS  , thus it is not a representation f what memory is actually required to store the useful data for such a search  . A more suitable representation is an adjacency directed graph defined by means of the lists of the anchored nodes in the terminal nodes  , and by the pointers to the left comer leaf in the nonterminal nodes  . 
301 digraph for the parse tree of Figure 1.
3. PROCES SGRAMMAR
The Process Grammar is an extension of the Augmented ContextFree Grammar such as APSG  , oriented to bottom-up parsing . Some relevant features make a Process Grammar quite different from classical APSG  . 
1 . The parser is a PG processor that ries to apply the rules in a bottom-up fashion  . It does not have any knowledge about herunning rammar but for the necessary structures to access its rules  . Furthermore , it sees only its internal state , the Parse Graph Structure , and works with a nondeterministic strategy . 
2 . The rules are conceived as processes that the PG processor schedules somehow  . Any rule defines a reduction rule that does not represent a rewriting rule  , but rather a statement for search and construction of new nodes in a bottom-up way within the Parse Graph Structure  . 
3 . The rules are augmented with some sequences of operations to be performed as in the classical APSG  . In general , augmentations such as tests and actions concern manipulation flinguistic data at syntactic and/or semantic level  . In this paper we are not concerned with this aspect  ( an informal description about his is in Marino ( 1989 ) ) , rather we examine some aspects concerning parsing strategies by means of the augmentations  . 
In a Process Grammar the rules can have knowledge of the existence of othe rules and the purpose for which they are defined  . They can call some functions that act as filters on the control structures of the parser for the scheduling of the processes  , thus altering the state of the processor and forcing alternative applications  . This means that any rule has the power of changing the state of the processor requiring different scheduling  , and the processor is a blind operator that works following a loose strategy such as the nondeterministic one  , whereas the grammar can drive the processor altering its state  . In such a way the lack of determinism of the processor can be put in the Process Grammar  , implementing parsing strategies which are transparent to the processor  . 
Definition 3 . 1 . A Process Grammar PG is a 6-tuple ( V T , Vs , S , R , Vs , F ) where: . Vr is the set of terminal symbols ; -VN is the set of nonterminal symbols ; -S?V N is the Root Symbol of PG ; -R = r1 . . . . , rt  is the set of the rules . Any rule ri in R is of the form ri = < red(ri ) , st(ri) , t(ri) , a(Q > , where red(ri ) is a reduction rule ( A~---a ) , A ~ V r ~ , ct ~( V ru VN ) + ; s t ( r ) is the state of the rule that can be active or inactive  ; t(Q and a(Q are the tests and the actions , respectively ; -Vs is a set of special symbols that can occur in a reduction rule and have a special meaning  . A special symbol is e a , a null category that can occur only in the lefthand side of a reduction rule  . Therefore , a reduction rule can also have the form ( e ~? --- a )  , and in the following we refer to it as e -reduction  ; - F = fl . . . . . f \] is a set of functions the rules can call within their augmentations  . 
Such a definition extends classical APSG in some specific ways : first  , a Process Grammar is suited for bottom-up parsing  ; second , rules have a state concerning the applicability of a rule at a certain time  ; third , we extend the CF structure of the reduction rule allowing null left hand sides by means of e -reductions  ; fourth , the set F is the strategic side that should provide the necessary functions to perform operations on the processor structures  . As a matter of fact , the set F can be further structured giving the PG a wider complexity and power  . In this paper we canno treat a formal extended definition for F due to space restrictions  , but a brief outline can be given . The set F can be defined as F = Fr ~ uF t , . In F ~ are all those functions devoted to operations on the processor structures  ( Kernel Functions )  , and , in the case of a feature-based system , in F t , are all the functions devoted to the management of feature structures  ( Marino ,  1989) . In what follows we are also concerned with the combined use of e-reductions and the function RA  , standing for Rule Activation , devoted to the immediate scheduling of a rule . RAeFx ~' and a call to it means that the process we describe in Section  4  . Before we introduce the PG processor we must give a useful definition : Definition  32  . Let reR be a rule with t(r ) = \[ f , 1; . . . ; f . ~\], a(r ) =\[ fl; .   .   .   ; f \] be sequences of operations in its augmentations  , f , ~ . . . . . f ~, f t . . . . . feF . Let n1 . . . . . rip ) be a reduction set for red(r ) = ( A ~ zr . .zv ) , and he Nr ~ be the new node for A such that T ( h ) is the new subtree created in the PGS , then we define the Process Environment for t ( r ) and a ( r )  , denoted briefly by ProcEnv(r ) , as:
ProcEnv(r ) = h,n1 . . . . , n.
If red ( r ) is an e-reduction then ProcEnv ( r ) = nl . . . . , np . 
This definition states the operative range for the augmentations of any rule is limited to the nodes involved by the match of the reduction rule  . 
4. PG PROCESSOR
Process Scheduler . The process scheduler makes possible the scheduling of the properules to run whenever a terminal node is consumed in input or a new nonterminal node is added to the PGS by a process  . By prope rules we mean all the rules satisfying Property  2  . 1 . a . with respect to the node being scanned or built . These rules are given by the sets def'med in the following definition : Definia ' on  4  . 1 . Vce Vsu Vr such that 3r ~ R where red ( r )  =  ( Ac---ac )  , AeVNue ~ , being c the right comer of the reduction rule , and lacl_<L , being L the size of the longest righthand side having c as the right comer  , the sets P ( c , i ) , P , (c , i ) for i = 1 . . . . . L , can be built as follows : P ( c , i ) = reRIred(r ) = ( At---cxc) , 1 < Itxcl_<i , st(r ) = aclivePe(c , i ) = reRIred(r ) = ( eac---ac ) , 1 < lacl < i , s t ( r ) = active Whenever a node he Nru Nr ~ has been scanned or built and k = lcl  ( h )  , then the processcheduler has to schedule the rules in P  ( cat ( h )  , k)uP , ,(cat(h) , k ) . In the following this union is also denoted by Yl ( cat0a )  , k ) . Such a rule scheduling allows an efficient realization of the immediate constituent analysis approach within a bottom-u parser by means of a partitioning of the roles in a Process Grammar  . 
The processcheduler sets up a process descriptor for each rule in l-l  ( cat0a )  , k ) where the necessary data for applying a process in the proper environment are supplied  . In a Process Grammar we can have three main kinds of rules : rules that are activated by others by means of the function RA  ; e-reduction roles ; and standard rules that do not fall in the previous cases  . This categorization implies that processes have assigned a priority depending on their kind  . Thus activated rules have the highest priority , e-reduction rules have an intermediate priority and standard rules the lowest priority  . Rules becomes cheduled processes whenever a process descriptor for them is created and inserted in a priority queue by the process cheduler  . The priority queue is divided into three stacks , one for each kind of rule , and they form one of the structures of the processor state  . 
Definition 4 . 2 . A process descriptor is a triple PD =\ [ r , h , C \] where : mR is the rule involved ; he N ruNsuNIL is either the right corner node from which the marcher starts or NIL  ; C is a set of adjacent nodes or the empty set . A process descriptor of the form\[r,NiL,\[nl . . . .  , nc\]isbuilt for an activated rule r and pushed in the stacksrAprocess descriptor of the form \[ r  , h , \[\] is built for all the othe rules and is pushed either in the stacks  2 if r is an e-reduction rule or in the stacks 3 if a standard rule . Process descriptors of these latter forms are handled by the processcheduler  , whereas process descriptors for activated rules are only created and queued by the function RA  . 
State of Computation . The PG processor operates by means of an operation Opon some internal structures that define the processor state ProcState  , and on the parsing structures accessible by the process environment ProcEnv  . 
The whole state of computation is therefore given by :\[ Op  , ProcState , ProcEnv\]=\[Op , pt , \[s~ , svs3\] , PD , pn , R Set\]where pt ? N r is the input pointer to the last terminal nodes canned  ; pn ~ N ~ is the pointer to the last nonterminal node added to the PGS  . For a sentence s = ar .   . a . the computation starts from the initial state \[ begin  , 0 , \[NIL , NIL , NIL\] , NIL , n + I , \] , and terminates when the state becomes \[ end , n , \[NIL , NIL , NIL\] , NIL , pn , \[ \] . The aim of this section is not to give a complete description of the processor cycle in a parsing process  , but an analysis of the activation mechanism of the processes by means of two main cases of rule scheduling and processing  . 
Scheduling and Processing of Standard Rules.
Whenever the state of computation becomes as \[ scan  , pt , \[ NIL , NILMIL\]MIL , pn , \] the processor scans the next terminal node , performing the following operations : scan : scl if p t = n then Op <--- end  sc2 else p t *-- p t + 1  ; sc3schedule0"I(cat(pt ) , lcl(pt ))); sc4Op <--- activate . 
Step sc4 allows the processor to enter in the state where it determines the first nonempty higher priority stack where the process descriptor for the next process to be activated must be popped off  . Let suppose that cat(pt ) = zp , and l'I(z , lcl ( p0 ) = r where r is a standard rule such that red ( ~ ) = ( A<--zr . .z ~ . At this point the state is \[ activate , pt , \[NILMIL , \[r , pt , \[\]\] MIL , pn , \[\] and the processor has to try reduction for the process in the stacks v thus Op <-- reduce performing the following statements : reduce : rl PD <---pop  ( % )  ; \[ reduce , pt , \[NIL , NIL , NIL\] , \[r , pt ,    \] , pn , \] r2C0--match(red(r ) , pt );
C = n l , . . . ,n vpt  r3 PD<-Lir , pt , C\];r4Vrset ~ C:r5RSet ~ rset;\[reduce , pt , \[NiL , NILMIL\] , \[r , pt ,    \] , pn~RSet\]r6ift(r ) then pn < -- pn+1 ; r7 add subtree(pn , red(r ) , RSe0;r8a(r ); r9 schedule(H(cat(pn) , lcl(pn ));\[ reduce , pt , \[NIL , sv%\] , \[r , pt ,    \] , n , R Set\]rl00p <-- activate . 
Step r9 , where the process scheduler produces process descriptors for all the rules in H  ( AJcl ( pn ) ) , implies immediate analysis of the new constituent added to the PGS  . 
Scheduling and Processing of Rules Activated by ~- Reduction Rules  . Let consider the case when an ~- reduction rule r activates an inactive rule r ' such that : red  ( r ) f- ( eat--zr . .zp ), a(r)=\[RA ( r ')\], red(r')=(A~zr . .Zh ), l~,_< . h < p , and s t(r ') = in active . When the operation activate has checked that ang -reduction rule has to be activated then Olx--~ -reduce  , thus the state of computation becomes : \[ e . reduce , pt , \[NIL , \[r , m , \] , NIL\] , NIL , pn , \] , ad the following statements are performed : e -reduce :  0-I PD <---pop ( sz )  ; \[ e-reduce , pt , \[NIL , NIL . NIL\] , \[ r , m ,    \]  , pn , \]~2C <--- match(red(r) , m );
C = ( nI . . . . , n I , m  03 f~b . \[ r,m,C\];\[e . reduce , pt,\[NIL , NIL . NIL\] , \[ r , m , C \] , pn , \]04 VrsemC:0"5RSet . --rset;\[e-reduce , pt . \[ NIL , NIL , NIL\] , \[r , m ,    \] , pn , RSet\]06 if t(r ) then a(r ) =\[ RA(r')\];\[? . reduce , pt,\[\[r',NIL,nk . . . .  , h\] , NIL , NIL\] , \[ r , m , \] , pn , RSet\]0" 70 lx--activate . 
In this case , unlike that which the processcheduler does , the function RA performs at step 06 the scheduling of a process descriptor in the stacks  , where a subset of ProcEnv ( r ) is passed as the ProcEnv ( r ' )  . Therefore , when an e-reduction rule r activates another rule r ' the step  er2 does the work also for r ' , and RA just has to identify the ProcEnv of the activated rule inserting it in the process descriptor  . 
Afterwards , the operation activate checks the highest priority stacks  , is not empty , therefore it pops the process descriptor\[r' , NIL , nk . . . . . nu \] and OIx--h-reduce that skips the match process applying immediately the rule r':h -reduce : hrlRSet <-- C  ; \[h-reduce , pt , \[NiL , NIL , NlL\] , \[r' , NIL ,   \] , pn , RSet\]hr2 throughhr6 as r6 throughrl 0 . 
From the above descriptions it turns out that the operation activate plays a central role for deciding what operation must run next depending on the state of the three stacks  . The operation activate just has to check whether some process descriptor is in the first nonempty higher priority stack  , and afterwards to set the proper operation . 
The following statements describe such a work and Figure  5 depicts graphically the connections among the operations defined in this Section  . 
activate:alifs I = NIL a2 then if %= NIL a3 then if s , = NIL a4 then Op~s can a5 else Op <-- reduce a6 else Op < --- c-reduce a7 else PD~pop ( % )  ; 
PD=\[r,NIL,C\]a8Op<--h-reduce.
sl = s2 = s3 = NI ~
Figure 5 . Operations Transition Diagram 5 . EXAMPLE It is wellknown that bottom-up parsers have problems in managing rules with common righthand sides like X--->ABCD  , X - - -> B C D , X - - -> CD , X - - -> D , since some or all of these rules can be fired and build unwanted nodes  . A strategy called topdown filtering in order to circumvent such a problem has been stated  , and it is adopted within bottom-up parsers ( Kay , 1982; Pratt , 1975; Slocum , 1981; Wir6n ,  1987 ) where it simulates a topdown parser together with the bottom-up parser  . The PG Processor must face this problem as well , and the example we give is a Process Grammar subset of rules that tries to resolve it  . The kind of solution proposed can be put in the family of topdown filters as well  , taking advantage firstly of using e-reduction rules  . 
Unfortunately , the means described so far are still insufficient o solve our problem  , thus the following definitions introduce some functions that extend the Process Grammar and the control over the PGS and the PG 

Definition 5 . 1 . Let r be a rule of R with red(r ) = (~-- zv . .z ), and RSet=n, . . . np be a reduction set for red(r ) . Taken two nodes % , njeRSet where n , eNN such that we have cat(n)--z , , cat(nj)=zj , and T ( n ~) , T ( n ) are adjacent , i . e . , either j=i + 1 or a ( r ) as Add_Son_Rel ( zi  ~ z ) has the effect of creating a new parent-s on relation between %  , the parent , and n , the son , altering the sets sons(n ) , and either 1cI ( % ) or rcl ( n ) as follows : a ) sons ( n ) ~- sons ( n ) unjb ) lcl ( n ) ~ lcl ( nj ) if j = i-1c ) rcl ( n ) 6--rcl ( n ) if j = i + l Such a function has the power of making an alteration i the structure of a subtree in the PGS extending its coverage to one of its adjacent subtrees  . 
Definition 5 . 2 . The function RE of Fr ~ , standing for Rule Enable , when called in the augmentations of some rule r as RE  ( r ' )  , where r , r ' are in R , sets the state of r ' as active , masking the original state set in the definition of r '  . 
Without entering into greater detail , the function RE can have the side effect of scheduling the just enabled ruler ' whenever the call to RE follows the call Add SonRel  ( X , Y ) for some category XeV , , , Ye V , wVr , and the right corner of red(r ') is X . 
Definition 5 . 3 . The function RD of Fx ,   , standing for Rule Disable , when called in the augmentations of ome rule ras RD  ( r ' )  , where r , r ' are in R , sets the state of r ' as in active , masking the original state set in the definition of r '  . 
We axe now ready to put the problem as follows : given  , for instance , the following set P1 of productions : PI = X-->ABCD , X - - -> B C D , X - -> C D , X - - -> D we want o define a set of PG rules having the same coverage of the productions in PI with the feature of building in any case just one node X in the PGS  . 
Such a set of rules is shown in Figure 6 and its aim is to create links among the node X and the other constituents just when the case occurs and is detected  . All the possible cases are depicted in Figure 7 in chronological order of building . 
The only active rule is r0 that is fired whenever a Disinserted in the PGS  , thus a new node X is created by r0(case(a)) . 
Since the next possible case is to have a node C adjacent to the node X  , the only action of r0 enables the rule rl whose work is to find such an adjacency in the PGS by means of the e-reduction rule red  ( rl ) = ( e , ~ CX') . If such a Cexists r l is scheduled and applied , thus the actions of rl create a new link between X and C  ( case Co ) ) , and the rule r2 is enabled in preparation of the third possible case where a node B is adjacent to the node X  . The actions of rld is a bler l itself before ending their work  . Because of the side effect of RE cited above the rule  r2 is always cheduled , and whenever a node B exists then it is applied . At this point it is clear how the mechanism works and cases  ( c ) and ( d ) are handled in the same way by the rules r2 and r3  , respectively . 
As the example . shows , henever the rules r l ?2?3 are scheduled their task is realized in two phases  . The first phase is the match process of the e -reduction rules  . At this stage it is like when a topdown parser searches lower-level constituents for expanding the higher level constituent  . If this search succeeds the second phase is when the red  ( r0 )  =  ( X ~ -- D ) s t ( r0 ) = active a ( r0 ) = iRE ( rl ) \] red ( rl )  =  ( el <--- CX ) s t ( rl ) = in active a ( rl ) =\[ AddSon_Rel ( X , C ) ; RE(r2) ; RD ( rl ) \] red ( a ) = BXOst ( r2 ) = in active a ( r2 ) =\[ Add_S on Rel ( X , B ) ; RE(r3) ; RD ( r2 ) \] red ( r3 )  --  ( el ? --- AX ) s t ( r3 ) = in active a ( r3 ) =\[ AddSon_Rel ( X , A ); RD(r3)\] Figure 6 . The Process Grammar of the example


A(a )
X rl/'N
CD



BCD/x/A(c )

ABCD
AAAA(d )
Figure 7 . All the possible cases of the example appropriate links are created by means of the actions  , and the advantage of this solution is that the search process terminates in a natural way without searching and proposing useless relations between constituents  . 
We terminate this Section pointing out that this same approach can be used in the dual case of this example  , with a set P2 of productions like : P2 = X--~A , X - - -> A B , X - - -> A B C , X - - -> A B C D The exercise of finding a corresponding set of PG rules is left to the reader  . 
6. RELATED WORKS
Some comparisons can be made with related works on three main levels : the data structure PGS  ; the Process
Grammar ; the PG Processor.
The PGS can be compared with the chart ( Kaplan , 1973; Kay ,  1982) . The PGS embodies much of the information the chart has  . As a matter of fact , our PGS can be seen as a denotational variant of the chart  , and it is managed in a different way by the PG Processor since in the PGS we mainly use classical relations between the nodes of the parse-trees : the dominance rlation between a parent and a son node  , encoded in the nonterminal nodes ; the left-adjacency relation between subtrees , encoded in the terminal nodes . Note that if we add the fight-adjacency relation to the PGS we obtain a structure fully comparable to the chart  . 
The Process Grammar can embody many kinds of information  . Its structure comes from the general structure stated for the APSG  , being very close to the ATN Grammars structure . On the other hand , our approach proposes that grammar rules contain directives relative to the control of the parsing process  . This is a feature not in line with the current rend of keeping separate control and linguistic restrictions expressed in a declarative way  , and it can be situation-action rules 0 Vinograd , 1983); furthermore , our way of managing rammar rules , i . e . , operations on the states , activation and scheduling mechanisms , is very similar to that realized in Marcus (1980) . 
7. DISCUSSION AND CONCLUSIONS
The PG Processor is bottom-up based , and it has to try to take advantage from all the available sources of information which are just the input sentence and the grammar structure  . As lrong improvement in the parsing process is determined by how the rules of a Process Grammar are organized  . Take , for instance , a grammar where the only active rules are e -reduction rules  . Within the activation model they merely have to activate in active rules to be needed next  , after having determined a proper context for them  . This can be extended to chains of activations at different levels of context in a sentence  , thus limiting both calls to the matcher and nodes prolife ration i the PGS  . This case can be represented writing ( ea ~ off l3 )  ~  ( A ~ -- T )  , reading it as if the e-reduction in the lhs applies then activate the rule with the reduction in the rhs  , thus realizing a mechanism that works as a context-sensitive reduction of the form  ( ot A\[3~---? c# )  , easily extendable also to the general case = , This is not the only reason for the presence of the e-reduction rules in the Process Grammar  . It also becomes apparent from the example that the e-reduction rules are a powerful tool that  , extending the context-freeness of the reduction rules  , allow the realization of a wide alternative of techniques  , especially when its use is combined together with Kernel Function such as RA getting a powerful mean for the control of the parsing process  . From that , a parser driven by the input-for the main scheduling - and both by the PGS and the rules - for more complex phenomena-can be a valid framework for solving  , as much as possible , classical problems of efficiency such as minimal activation of rules  , and minimal node generation . Our description is implementation-independent , it is responsive to improvements and extensions , and a first advantage is that it can be a valid approach for realizing efficient implementations of the PG Processor  . 
Extending the Process Grammar . In this paper we have described a Process Grammar where rules are augmented with simple tests and actions  . An extension of this structure that we have not described here and that can offer further performance to the parsing process is if we introduce in the PG some recovery actions that are applied whenever the detection of one of the two possible cases of process failure happens in either the match processor the tests  . Consider , for instance , the reduction rule . Itsf'malaim is to find a process environment for the rule when scheduled  . 
This leads to say that whenever some failure conditions happen and a process environment cannot be provided  , the recovery actions would have to manage just the control of what to do next to undertake some recovery task  . It is easy to add such an extension to the PG , consequently modifying properly the reduction operations of the PG processor  . 
Other extensions concern the set F ~ , by adding further control and process management functions  . Function such as RE and RD can be defined for changing the state of the rules during a parsing process  , thus a Process Grammar can be partitioned in clusters of rules that can be enabled or disabled under proper circumstances detected by qow -level'  ( e-reduction ) rules . Finally , there can be also some cutting functions that stop local partial parses  , or even halt the PG processor accepting or rejecting the input  , e . g . , when a fatal condition has been detected making the input unparsable  , the PG processor might be halted , thus avoiding the complete parse of the sentence and even starting are covery process  . The reader can refer to Marino ( 1988 ) and Marino ( 1989 ) for an informal description regarding the implementation of such extensions  . 
Conclusions . We have presented a complete framework for efficient bottom-uparsing  . Efficiency is gained by means of : a structured representation of the parsing structure  , the Parse Graph Structure , that allows efficient matching of the reduction rules  ; the Process Grammar that extends APSG by means of the process-based conception of the grammar rules and by the presence of Kernel Functions  ; the PG Processor that implements a nondeterministic parser whose behaviour can be altered by the Process Grammar increasing the determinism of the whole system  . The mechanism of rule activation that can be realized in a Process Grammar is context -sensitive-based  , but this does not increase computational effort since processes involved in the activations receive their process environments - which are computed only once-from the activating rules  . At present we cannot ell which degree of determinism can be got  , but we infer that the partition of a Process Grammar in clusters of rules  , and the driving role the e-reductions can have are two basic aspects whose importance should be highlighted in the future  . 

The author is thankful to Giorgio Satta who made helpful comments and corrections on the preliminary draft of this paper  . 

Aho , Alfred , V . and Ullman , Jeffrey , D .  (1972) . The Theory of Parsing , Translation , and Compiling . Volume 1: Parsing . Prentice Hall , Englewood Cliffs , NJ . 
Aho , Alfred , V . , Hopcroft , John , E . and Ullman , Jeffrey , D .  (1974) . The Design and Analysis of Computer
Algorithms . Addison-Wesley.
Grishman , Ralph (1976) . A Survey of Syntactic Analysis Procedures for Natural Language  . American Journal of Computational Linguistics . Microfiche 47, pp .  2-96 . 
Kaplan , Ronald , M .  (1973) . A General Syntactic Processor . In R and all Rust in , ed . , Natural Language Processing , Algodthmics Press , New York , pp .  193-241 . 
Kay , Martin (1982) . Algorithm Schemat and Data Structures in Syntactic Processing  . In Barbara J . Grosz , Karen SparckJones and Bonnie Lynn Webber , eds . , Readings in Natural Language Processing , Morgan Kaufmann , Los Altos , pp .  35-70 . Also CSL-80-12, Xerox
PARC , Palo Alto , California.
Marcus , Mitchell , P .  (1980) . A Theory of Syntactic Recognition for Natura I Language  . MIT Press , Cambridge,

Marino , Massimo (1988) . A Process-Activation Based Parsing Algorithm for the Development of Natural Language Grammars  . Proceedings of 12th International Conference on Computational Linguistics  . Budapest,
Hungary , pp . 390-395.
Marino , Massimo (1989) . A Framework for the Development of Natural Language Grammars  . Proceedings of lnternational Workshop on Parsing Technologies  . CMU , Pittsburgh , PA , August 28-311989, pp .  350-360 . 
Pratt , Vaughan , R .  (1975) . LINGOL-A Progress Report . Proceedings of 4th IJCAI , Tbilisi , Georgia , USSR , pp .  422-428 . 
Slocum , Johnathan (1981) . A Practical Comparison of Parsing Strategies . Proceedings of 19th ACL , Stanford,
California , pp . 16.
Winograd , Terry (1983) . Language as a Cognitive Process . Vol . 1: Syntax . Addison-Wesley , Reading , MA . 
Wirtn , Mats (1987) . A Comparison of Rule-Invocation Strategies in ContextFree Chart Parsing  . Proceedings of 3rd Conference of the European Chapter of the ACL , 
Copenhagen , Denmark , pp . 226-233.

