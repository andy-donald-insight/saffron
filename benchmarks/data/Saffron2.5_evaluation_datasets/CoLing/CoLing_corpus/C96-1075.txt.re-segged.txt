Multi-lingual Translation of Spontaneously Spoken Language 
in a Limited Domain
Alon Lavie , Donna Gates , Marsal Gavaldh,
Laura Mayfield , Alex Waibel and Lori Levin
Center for Machine Translation
Carnegie Mellon University
5000 Forbes Ave ., Pittsburgh , PA 15213
email : lavie@cs.cmu.edu
Abstract
JANUS is a multilingual speech-to-
speech translation system designed to
facilitate communication between two
parties engaged in a spontaneous con-
versation in a limited domain . In an
attemp to achieve both robustness and
translation accuracy we use two ( lifter-
ent translation components : the GLR
module , designed to be more accu-
rate , and the Phoenix module , designed
to be more robust . We analyze the
strengths and weaknesses of each of the
approaches and describe our work on
combining them . Another recent focus
has been on developing a detailed end-
to-end evaluation procedure to measure
the performance and effectiveness of the
system . We present our most recent
Spanish-to-English performance evalua-
tion results.
1 Introduction
JANUS is a multilingual speech-to-speech translation system designed to facilitate communication between two parties engaged in a spontaneous conversation in a limited domain  . In this paper we describe the current design and performance of the machine translation module of our system  . The analysis of spontaneous speech requires dealing with problenls such as speech disfluencies  , looser notions of grammaticality and the lack of clearly marked sentence boundaries  . These problems are further exacerbated by errors of the speech recognizer  . We describe how our machine translation system is designed to effectively handle these and other problems  , hi an attempt to achieve both robustness and translation accuracy we use two different ranslation components : the  ( JLlt . module , designed to be more accurate , and the Phoenix module , designed to be more robust . Both modules follow an interlingua-based approach  . The translation modules are designed to be language-independent in the sense that they each consist of a general processor that applies independently specified knowledge about different languages  . This facilitates the easy adaptation of the system to new languages and domains  . We analyze the strengths and weaknesses of each of the translation approaches and describe our work on combining them  . Our current system is designed to translate spontaneous dialogues in the Schedul-ing domain  , with English , Spanish and German as both source and target languages  . A recent focus has been on developing a detailed end-to-end evaluation procedure to measure the performance and effectiveness of the system  . We describe this procedure in the latter part of the paper  , and present our most recent Spanish-to-English performance evaluation results  . 
2 System Overview
The JANUS System is a largescale multilingual speech-to-speech translation system designed to facilitate communication between two parties engaged in a spontaneous conversation ialimited domain  . A diagram of the architecture of the system is shown in Figure  1  . The system is composed of three main components : a speech recognizer  , a machine translation ( MT ) module and a speech synthesis module . The speech recognition component of the system is described elsewhere  ( Woszczyna et al 1994 )  . For speech synthesis , we use a commercially available speech synthesizer  . 
The MT module is composed of two separate translation submodules which operate independently  . The first is the GLR module , designed to be more accurate . The second is the Phoenix module , designed to be more robust . Both modules follow an interlingua-based approach  . The source language input string is first analyzed by a parser  , which produces a language-independent interlingua content representation  . The interlingua is then passed to a generation component  , which produces an output string in the target language  . 
The discourse processor is a component of the GLR translation module  . It disa Inbiguates the speech act of each sentence  , normalizes temporal
IrI
OU ~"
F Gen Kitenerator\[....
Is?oo . I
Figure 1: The JANUS System expressions , and incorporates the sentence into a discourse plan tree  . ' the discourse processor also updates a calendar which keeps track of what the speakers haw ' ~ said about their schedules  . The discourse processor is described in greater detail else  . - where ( R , os det 31 .  1995) . 
3 The QLR Translation Module
The (\] LR . * parser ( Lavie and Tomita 11993; I , avie 1994 ) is a parsing system based on Tomita's Generalized LI~parsing algorithm  ( Tomita 1987 )  . The parser skips parts of the utterance that it cannot incorporate into a wellformed sentence structure  . 
Thus it is well-suited to do in ains ill which non -grammaticality is coalition  . The parser conducts a search for the maximal subset of the original input that is covered by the grammar  . This is done using a beam search heuristic that limit stile combinations of skipped words considered by the parser  , and ensures that it operates with infeasible time and space bonnds  . 
The GI , R * parser was implemented as an extension to the GLR parsing system  , a unification-I>ased practical natural language system  ( ' lbmita 19 90 )  . The grammars we develop for the , IANUS system are designed to produce\[eature structures that correspond to a frame-based language-independent representation f the meaning of the input utterance  . For a given input utterance . , the parser produces a set ; of interlingua texts , or ILTs . 
The main components of an ILT are the speech act ( e . g . , suggest , accept , reject ) , the sentence type ( e . g . , s tate , query-i ~ , fragment ) , and the main semantic frame ( e . g . , free , busy ) . An example of nnILl'is shown in Figure 2 . A detailed IUI'Specitication was designed as a formal de~scription of the allowable ILTs  . All parser output must conform to this ILl' Speeitication  . The GLR unification based formalism allows the grammars to construct precise and very detailed ILTs  . This in turn allows the GLI translation module to produce highly accurate translations for wellformed input  . 
The GLR*parser also include several tools designed to address the difficulties of parsing spontaneou speech  . To cope with high levels of ambiguity , the parser includes a statis , ical disambiguation module , in which probabilities are attached directly to the actions in the LR parsing table  . The parser can identify sentence boundaries within each hypothesis with the help of a statistical method that determines the probability of a boundary at  ; each point in the utterance . 
The parser must also determine the " best " parse from among tit  (  ; difl Zrent parsable subsets of an input . This is don ( ; using a collection of parse evaluation measures which are combined into an integrated heuristic for evaluating and ranking the parses produced by the parser  . Additionally , a parse quality heuristic allows the parser to self-  ( who ( ( frame*i ) ) )   ( when ( ( frame * . simple-time )   ( day-of-week wednesday )   ( time-of-day morning ) ) )   ( a-speech-act ( * multiple ** suggesic*aec (  , pt ) )  ( sentence-type * state ) ) ) Sentence : 1 could do it Wednesday morning too . 
Figure 2: An Example 112' judge the quality of tile parse chosen as best , and to detect cases in which important information is likely to have been skipt  ) ed . 
Target language generation in the ( ; LR modt de is clone using GenK it ( Tomita and Nyberg 1988 )  , a unification-based generation system . With well-developed generation grammars , GenKit results in very accurate translation for well-specified IUI%  . 
4 The Phoenix Translation Module
The , IANUS Phoenix translation module ( Mayfield et el .  1995 ) is an extension of the Phoenix Spoken Language System  ( Ward 1991 ; Ward 1994) . The translation component consists of at ) arsing module and a generation module . Translation between any of the four source languages  ( English , German , Spanis IL Korean ) and five target languages ( English , German , Spanish , Korean , Japanese ) is possible , although we currently focus only on a few of these language pairs  . 
Unlike the GI , R method which attempts to construct a detailed turfor a given input utterance  , the Phoenix approach attempts to only identify the key semantic concepts represented in the utterance and their underlying structure  . Whereas GLR * is general enough to support both semantic and syntactic grammars  ( or some combination of both types )  , the Phoenix approach was specifically designed for semantic grammars  . Grammatical constraints are introduced at the phrase level  ( as opposed to the sentence level ) and regulate semantic ategories . This allows the ungrammaticalities that often occur between phrases to be ignored and reflects tile fact that syntactically incorrect spontaneous speech is often semantically wellformed  . 
The parsing grammar specifies patterns which represent concepts in the domain  . The patterns are composed of words of the input string as well as other tokens for constituent concepts  . Elements ( words or tokens ) in a pattern may be specified as ol ) tional or repeating ( as in a Kleene star mecha-nisln )  . Each concept , irrespective of its level in the hierarchy , is represented by a separate grammar file . These grammars are compiled into Recursive
Transition Networks ( RTNs).
The interlingua meaning representation of an input utterance is derived directly from the  1  ) arse tree constructed by the parse . r , by extracting the represented structure of concepts  . This representation is usually less detailed than tile corresponding GLRIlfF representation  , and thus often re-suits in a somewhat less accurate translation  . The set of semantic once p tokens for the Scheduling domain was initially developed from a set of  45 example English dialogues . Top-level tokens , also called slots , represent speech acts , such as suggestion or agreement . Intermediate-level tokens dis-tingnish between points and intervals in time  , for example ; lower-level tokens cat ) ture the speciiics of the utterance , such as days of the week , and represent he only words that are translated directly via lookup tables  . 
' File parser matches as much of the inl ) ut utterance as it can to the pattern specified by the I~TNs  . Out-of-lexicon words are ignored , unless they occur in specific locations where open concepts are permitted  . A word that is already known to the system , however , can cause a concept pattern not to match if it occurs in a position unspecified in the grammar  . A failed concept does not cause the entire parse to fail  . The parser can ignore any number of words in between toplevel concepts  , handling out-of-domain or otherwise unexpected input  . Tile parser has no restrictions on the order in which slots ca ~ occur  . This can cause added ambiguity in the segmentation of the utterance into concepts  . The parser uses a disambiguation algorithm that attempts to cover the largest number of words using the smallest number of concepts  . 
Figure 3 shows an example of a speaker utterance and the parse that was produced using the Phoenix parser  . The parsed speech recognizer outpnt is shown with unknown  ( - ) and unexpected ( * ) words marked . These segments of the input were ignored by the parser  . The relevant concepts , however , are extracted , and strung together they provide a general meaning representation of what the speaker actually said  . 
Generation in the Phoenix module is accomplished using a sirnple strategy that sequentially generates target language text for each of the toplevel concepts in the parse analysis  . Each concept has one or more tixed phrasings in the target language  . Variables such as times and dates are extracted from the parse analysis and translated directly  . The result is a meaning fifl translation , but can have a telegraphic feel . 
5 Combining the GLR and
Phoenix Translation Modules 5 . 1 Strengths and Weaknesses of the

As already described , both the GLR*parser and tile Phoenix parser were specifically designed to handle tile problems associated with analyzing spontaneous peech  , l lowever , each of the ap-S\[QIJE'I'E\['AtE ( ' E'\['EN ( IOt , ; 1~MAtTESI)IE(\]IO(:\[OYELMII ; ; RCOI , ESDIE(~IN III . ; VEI , IPII . ESTOI ) OEl , I )\[ APODR(AMOS 111) EMATINI ; " OSE At . ; NI , ATAII ) EVEI
ELI , AI'EL\[f:UI , A ( Ioughly " Yes what do you think\[have Tuesday the Iteenth and Wednesday then znetccn thf~cc all day we  , -ou ~ dqose et lzematm de sozn the afterno on see the the  7novzc   . " )
As decoded hythe . recognizer : % NOISE % SII Q1JEI TEI'AIECE % NOISE % ' I'EN (  ; OEL MARTESI ) IEC , IOCI\[OY H , MIE1RCOLESI ) IECINUI'VELIBRESTOI)OI . , LDI1APODIllAMOSItt,I ) EMATINE 1'X:NOISI . ; % OSEAI , AT AIDE AVEILA
Parsed : ' ~ < S > silquel tcp are celento ( :\[ mattesdi , ~ io cht > y ( ~ 1 miclr coles die cinueve libres to do eldila podr ilamos  *11% * I ) E-MATINF , 1 ose a latar deaver I , A%</S > Parse Tree ( ~ Senlantic l~el ) resentation ) :\[ rcst .   .   .   .   . t \] ( \[ yes\] ( Sll ) ) \[ yourt:urn \] ( QIII , \]ITE\['AII , I ~ CE ) \ [ give ' info\] ( \[ my availability \] ( q'ENGO\[temp'loc\] ( \ [ teml .   .   .   .   .  1\]  ( \[point : \] ( \ [ date \] ( EL\[d'o'w\] ( MAI'JI'ES ) ) \[ , late\](\[clay'oral\](I ) IECIOCIlO)\[ , : on j\](Y ) El , \[ d'o'w\](MIEII'~COI , I ' ; S )   ) \ [ date \] ( \[ dayord\] ( I ) IE ( :\[ NUEVE )   )   )   )   )  1 , 11 HIES ) ) \[ givemfo \] ( \[ my ' availability \] ( [ temp'loc\] ( \[ temporal \] ( \[ range\] ( \[ entire\] ( TOl ) O ) El ,  \[ , mit\] ( Jr ' unit\] ( I ) IIA )   )   )   )   ) I'ODRI1AMOS ) ) \[ suggest \] ( \[ suggest'meeting\] ( \[temp'loc\] ( \[ temporal \] ( OSEA\[point\] ( I , A\[t'o'd\](TARDE )))) AW , : Et ))

English = < Yes what do you think ? 1 could meet : Tuesday eighteenth and Wednesday the nineteenth  1 couhl meet the whole day do you want to try to get togetherm the afternoon > Figure  3: A Phoenix Spanish to English Translation Examl ) h : proaches has some clear strengths and weaknesses  . 
Although designed t <> CO l ) e with speech d is then-cies ,  ( ; LR*cangraeehdly tolerate only moderate levels of deviation from the grammar  . When the input is only slightly ungrammatical , nd contains relatively minor distluencies ,   ( ILR * produces precise and detailed IH's that result in high quality translations  . The ( ILl * parser has < lifliculties in parsing long utterances that are highly dislluent  , or that significantly deviate from the grammar . 
In many such cases , (ILH , * succeeds to parse only a small fragment of the entire utterance  , and important input segments end up being sldl ) t ) ed . 1 l ) hoenix is signitl cantly better suited to analyzing such utterances  . Because Phoenix is capable of skipping over input segments that  <1o not correspond to any toplevel semantic concept , it can far better recover from out-of-domains e . gments in the input , and " restart " itself on an indomain segment that follows  . However , this some time . sre-suits in the parser picking up and mis -translating a small parsal  ) lephrase within an out-of-domain IR ccent work on a method for pre-brcaking the utterance at sentence boundaries prior to parsing have sign iii  ( : antly reduced this l ) rol ) lem . 
segtnent . To handle this problem , we are . attempting to develop methods for automatically detecting out-of-domain segments in an utterance  ( see section 7 )  . 
Because the Phoenix approach ignores small fm lc tion words in them t  ) ut , its translation results are by design bound to be less accurate  . However , the ability to ignore function words is of great ben-ellt when working with speech recognition output  , in which such words are often mistaken . By keying on high-conlidence words l > hoenix takes advantage of the strengths of the speech decoder  . At the current time , Phoenix uses only very simple disambiguation heuristics  , does not employ any discourse knowledge , and does not have a mechanism similar to the parse quality heuristic of GLR *  , which allows the parser to self-assess the quality of the produced result  . 
5.2 Combining the Two Approaches
Iecause a ch of the two translation methods appears to perform better on differentypes of utterances  , they may hopefldly be combined in a way that takes adwm tage of the strengths of each of them  . One strategy that we have investigated is to use the l'hoeIfiX module as a backup to the  ( 1Lt module . The parse result of GLR * is translated whenever it is judged by the parse quality heuristic to be " Good "  . Whenever the parse result t ~' om GLI * is judged as " Bad "  , the translation is generated from the corresponding output of the Phoenix parser  . Results of using this combination scheme are presented in the next section  . We art : in the process of investigating some more sophisticated methods for combining the two translation at  ) proaehes . 
6 Evaluation 6 . 1 The Ewduat ion P rocedure In order to assess the overall eflhctiveness of the two translation contponents  , we developed a detailed end-to-end evaluation procedure  ( Gatesel ; hi .  1996) . We evaluate the translation modules on both transcribed and spee  . ch recognized input . 
The evMuation of transcribed in l ) ut allows us to assess how well our translation modnles wouhl\[unction with " perfect " speech recognition  . ' lhst-ing is performed on a set ; of " unseen " dialogues , that were not used for developing the translation modules or training the speech recognizer  . 
'\[' he translation of an utterance is manually evaluated by assigning it a grade or a set of grades based on the number of sentences in the utter-alice  . ' file utterances are broken clown into sentences for evaluation in order to give more weight to longer utterances  , and so that utterances containing both in and out -of-domain sentences can be  . iudged more accurately . 
Each sentence is cla , ssified first as either relevant to the scheduling domain  ( indomain ) or not rel-Each sentence is then assigned one of four grades for translation quality :  ( 1 ) Perfect-a fluent translation with all information conveyed  ;   ( 2 ) OK-all important information translated correctly but some unimportant details missing  , or the translation is awkward ; (3) Bad-unacceptable translation ;   ( 4 ) Recognition Error-unacceptable translation due to a speech recognition error  . These grades are used for both indomain and out -of-domain sentences  . However , if an out-of-domain sentence is automatically detected as such by the parser and is not translated at all  , it is given an " OK " grade . The evaluations are performed by one or more independent graders  . When more than one grader is used , the results are averaged together . 
6.2 Results
Figure 4 shows the evaluation results for 16 unseen Spanish dialogues containing 349 utterances translated into English . Acceptable is the sum of " Perfect " and " OK " sentences  . For speech recognized input , we used the first-best hypotheses of the speech recognizer  . 
Two trends have been observed from this evaluation as well as other evaluations that we have conducted  . First , The GLR translation module performs better than the Phoenix module on transcribed input and produces a higher percentage of " Perfect " translations  , thus confirming the GLR approach is more accurate  . This also indicates that GLR performance should improve with better speech recognition and improved preparsing utterance segmentation  . Second , the Phoenix module performs better than GLR on the first-best hypotheses from the speech recognizer  , a result of the Phoenix approach being more robust  . 
These results indicate that combining the two approaches has the potential to improve the translation performance  . Figure 5 shows the results of combining the two translation methods using the simple method described in the previous section  . 
The GLR * parse quality judgement is used to determine whether to output the GLR translation or the Phoenix translation  . The results were evaluated only for indomain sentences  , since out-of-domain sentences are unlikely to benefit from this strategy  . The combination of the two translation approaches resulted in a slight increase in the percentage of acceptable translations on transcribed input  ( compared to both approaches separately )  . 
On speech recognized input , although the overall percentage of acceptable translations does not improve  , the percentage of " Perfect " translations was higher  . 22 In a more recent evaluation , this combination method resulted in a 9 . 5% improvement in acceptable translations of speech recognized indomain sentences  . 
Although some variation between test sets is to be  ex-7 Conclusions and Future Work In this paper we described the design of the two translation modules used in the  . JANUS system , outlined their strengths and weaknesses and describe dour et forts to combine the two approaches  . 
A newly developed end-to-end evaluation procedure allows us to assess the overall performance of the system using each of the translations methods separately or both combined  . 
Our evaluations have confirmed that the GLR approach provides more accurate translations  , while the Phoenix approach is more robust . Combining the two approaches using the parse quality judgement of the  ( ILl * parser results in improved performance . We are currently investigating other methods for combining the two translation approaches  . Since ( \] LR * performs much better when long utterances are broken into sentences or sub-utterances which are parsed separately  , we are looking into the possibility of using Phoenix to detect such boundaries  . We are also developing a parse quality heuristic for the Phoenix parser using statistical and other methods  . 
Another active research topic is the automatic detection of out-of-domain segments and utterances  . Our experience has indicated that a large proportion of bad translations arise from the translation of small parsable fragments within out-of-domain phrases  . Several approaches are nnder consideration . For the Phoenix parser , we have implemented a simple method that looks for small islands of parsed words among non -parsed words and rejects them  . On a recent test set , we achieved a 33% detection rate of out-of-domain parses with no false alarms  . Another approach we are pursuing is to use word salience measures to identify and reject out-of -domain segments  . 
We are also working on tightening the coupling of the speech recognition and translation modules of our system  . We are developing lattice parsing versions of both the GLR * and Phoenix parsers  , so that multiple speech hypotheses can be efficiently analyzed in parallel  , in search of an interpretation that is most likely to be correct  . 

The work reported in this paper was funded in part by grants from ATR-Interpreting Telecommunications Research Laboratories of Japan  , the US Department of Defense , and the Verbmobil Project of the Federal Republic of Germany  . 
We would like to thank all members of the JANUS teams at the University of Karlsruhe and Carnegie Mellon University for their dedicated work on our many evaluations  . 
pected , this result strengthens our belief in the potential of this approach  . 

Inl ) omain (605 sentences )( ; LI*Phoenix transcribed speechlst-best transcribed speechlst-best 
Perfect 65.2 34.7 53.3 35.5
OK 18,812.2 25.3 26.3
Bad 16.0 29.2 21.4 17.1 lecog Err ** 23.9
Out of I ) omain ( d 85 sentences )** 21.1
Perfect 58.5 29.7 44.2 29.3
OK 26.74 2.44 4.64 1.1
Bad 7.5 9.1 lecog Err 14.8 11.2 20.4**
Acceptable(l'erfect+OK ) 20.5
Inl)om 84.0 46.9 78.6 61.8
Out of Dora 85.2 72.l 88.8 70.4
Alll ) om 84 . 5 58 . 2 82 . 9 65 . 5 ol (, LI and l ' hoenix . Cross-grading of 16 dialogues . Figure 4: September 1995 e . wduation "'*''
In Domain (605 sentences)
GLR*wid , Phoenix transcribed speechlst-best
Perfect 65.4 39.7
OK 20.8 21.2
Bad 13.8 15.2
Recog Err ** 23.9
Acceptable ( Perfect+OK)\[l In Do , , , I\[-86 . 2 I 60 . 9 ll Figure 5: September 1995 evaluation of ( ILR * combined with Phoenix . Cross-grading of 16 dialogues . 
References
D . Gates , A . bavie , L . Levin , A . Waibel , M . Gavald S . , L . Mayfield , M . Woszczyna and P . Zhan . End-to-end Evaluation in JANUS : a Speech-to -speech Translation System  , To appear in Proceedings of ECAI Workshop on Dialogue Processing in Spoken Language Systems  , 
Budapest , Hungary , August 1996.
A . l , avie and M . To Inita . GLR * - An EJficient Noise , 5'kippmg Parsing Algorithm for Context Free Grammars  , Proceedings of the third International Workshop on Parsing Technologies  ( IWPT-9a )  , Tilburg , The Netherlands , August 1993 . 
A . Lavie . An Integrated Heuristic Scheme for Partial Parse Evaluation  , Proceedings of the 32nd Annual Meeting of the ACL ( ACL-94 )  , 
Las Cruces , New Mexico , June 1994.
L . Mayfield , M . ( lavaldh , YH . Seo , B . Suhm , W . Ward , A . Wail ) el . " Parsing Real Inl ) ut in JANUS : a Concept-Based Al ) proach . " In Pro-eeedings of TMI9, 5 . 
(: . P . los & B . Di Eugenio , L . S . Levin , and (; . VanEss-I ) ykema . Discourse processing of dialogues with multiple threads  . In Proceedings of ACL'95, ftoston , MA , 1995 . 
M . Tomita . An Efficient Augmented Context-free Parsing Algorithm  . Computational Linguistics , 13(1-2):3l-46 ,  1987 . 
M . Tomita . Tile Generalized LR Parser/Compiler Version 8 . 4 . In Proceedings of International ( : onference on Computational Linguistics ( COLING'90 )  , pages 59-63 , llels in ki , Finland ,  1990 . 
M . Tomita and E . H . Nyberg 3rd . Generation Kit and Transformation Kit , Version 3 . 2: User's Manual . Technical Report (\] MU-CMT-88-MEMO , Carnegie Mellon University , Pittsburgh , PA , October\[988 . 
W . Ward . " Understanding Spontaneous Speech : tile Phoenix System  . " In Proceedings of
I(MSb'P-91, 1991.
W . Ward . " Extracting Information in Spontaneous Speech . " In Proceedings of International
CoT@rence on Spoken Language , 1994.
M . Woszczyna , N . Aoki-Waibel , F . D . Buo , N . Coccaro , T . Horiguchi , K . and Kemp , A . Lavie , A . McNair , T . Polzin , 1 . Rogina , ( J . P . 
Ros6, T . Schultz , B . Suhm , M . Tomita , and A . Waibel . JANUS-93: Towards Spontaneous Speech Translation . In Proceedings of IEEE International Conference on Acoustics  , Speech and Signal Processing ( ICASSP'9~) ,  1994 . 

