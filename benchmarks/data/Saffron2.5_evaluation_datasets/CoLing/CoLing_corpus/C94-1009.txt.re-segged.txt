BUILDING ANMTI ) ICTIONARY FROMP ARAI~LEI~TEXTS
BASEDONLINGUISTICANDSTATISTICALINIi'ORMATION
Akira Kumanoltid ckiltirakawa
R&D Center , Toshiba Corporation
1 , Komukai Toshiba-cho , Saiwai-ku , Kawasaki ,  210 , JAPAN
kmn , hirakawa@ist.rdc.toshiba.co.jp

A method for generating a machine translation ( MT ) dictionary from parallel texts is described . 
This method utilizes both statistical information and linguistic information to obtain corresponding words or phrases in parallel texts  . By combining these two types of information , translation pairs which cannot be obtained by a linguistic-based method can be extntcted  . Over 70% accurate translations of compound nouns and over 50% of unknown words are obtained as t be first candidate from small Japanese/Englisb parallel texts containing severe distortions  . 
1 INTRODUCTION
Parallel texts ( corpora ) are useful resources for acquiring a variety of linguistic knowledge  ( Dangan , 1991; Matsumoto ,  1993) , especially for machine translation systems which inherently require cus-tomizations  . Translation dictionaries are , needless to say , the most basic and powerful knowledge source for improving and customizing translation systems  . Our research interest lies in automatic generation of translation dictionaries from parallel texts  . In this perspective , finding corresponding words or phrases in bilingual texts will be the fundamental factor for accurate translation  . 
Statistics-based processing has proven to be very powerful for aligning sentences and words in parallel corpora  ( Brown , 1991; Gale , 1993; Chen ,  1993) . 
Kupiec proposes an Mgorithm for finding ~ loun phrases in bilingual corpora  ( Kupiec ,  1993) . In this algoor ithm , noui ~- phrase candidates are extracted from tagged and aligned parallel texts using a noun phrase recognizer and tile correspondences of these nonn phrases are calculated based on the EM algorithm  . 
Accuracy of around 90% has been attained for the Imndred highest ranking con'espondenccs  . Statistics-based processing is effective when a relatively large amount of parallel texts is available  , i . e . when high frequencies are obtained . 
On the other hand , existing linguistic knowledge can be used for finding corresponding words or phrases in parallel texts  . For example , possible target expressions for a source expression provided by a translation system  ( linguistic knowledge source ) can be a key in searching the corresponding expressions in a corpus  ( Nogami , 1991; Katoh ,  1993) . Yanramo-to ( 1993 ) proposes a method for generating a translation dictionary from Japanese/English parallel texts  . In this method , English and Japanese compound noun phrases are extracted from parallel texts and their correspondences are searched by matching their possible translations generated by tile existing translation dictionary  . However , acquirable noun phrases are limited by tile linguistic generative power of the translation dictionary  . Fur-thernlore , tiffs method utilizes no sentence align-meat information which can reduce errors in finding noun phrase correspondences  . 
This paper proposes a new method for generating an MT dictionary from parallel texts  . It utilizes both statistical and linguistic information to obtain corresponding words or phrases in parallel texts  . By combining these two types of information , translation pairs which cannot be obtained by the above linguistic-based method can be extracted  , and a highly accurate translation dictionary is generated from relatively small par:dlel texts  . 
2 APPROACttTOBUILDING ANMT 1 ) ICTIONARY Our goal in building an MT dictionary from par-all cl texts is to develop a robust method which enables highly accurate extraction of translation pairs from a relatively small amount of parallel texts as well as from parallel texts containing severe distortions  . 
In realworld applications , generally it is extremely difficult especially for MT users to obtain a large amount of high quality parallel texts of one specific domain  . If source and target languages do not belong to the same linguistic family  , like Japanese and Fnglish , tile situation becomes grave . 
As one typical example of MT dictionary compilation  , we have selected Japanese and English patent doemnents which contain many state-of-the-m~t technical terms  . Althougb the s~documents are not cul-
Text l Text; , , nit extractio , , I \[ Corresponding \]- . . ~- - -> ' L~nil Table \[ \ I Linguistic - - r +- -'? d??List\[~l candidate v_~-~-\[j____  . _j -'-'-----~ generation ~______~/
I statistical I/j/f , . mation J\[Translation Pairs Fig . 1: Flow of building an MT dictionary from paralh . q text sturally biased , in many cases , tile organization between Japanese and English greatly differs and extensive changes are made ill translating from Japanese to English text and vice vm  . ~ a . Hence , tile difficulty of word extraction from patents . 
To solve this problem , we explored the appropriate integration method considering the use of linguistic information and statistical information to this end  . Lingt , istic information is useful in making an intelligent judgment about correspondence between two languages even from partial texts because of its lexical  , syntactic , and semantic knowledge ; statistical information is characterized by its robustness against noise because it cantnms form many actual examples into an abstract fom ~  . 
Below is the flow of ot , r method illustrated in
Fig . 1: (1) Unit Extraction :
Pmls of documents ( " units " ) are extracted from both Japanese and English texts  . 
(2) Unit Mapping:
I&mh Japanesenn it is mapped into English units.
(3) Term Extraction:
Japanese term candidates are extracted by the
NP recognizer.
(4) Translation Candidate Generation :
English translation candidates for Japanese terms are extracted from English units  . 
(5) English Translation D ; timation :
Tim translation candidates are evah , a ted to obtain the best one , Tim subsequent sections show tim details of each processing  . 
3 FOR MINGUNIT CORRISPON-

The plausible hypothesis that parallel sentences cont  , ,in corresponding linguistic expressions is the major premise in Kupiec  ( 1993 )  . This type of info , - mation should be wklely used . The problem is that tim alignment method based on tile sentence bead model  ( Brown ,  1991 ) is not applicable to patent documents due to their severed is to  , fions in doculnent strtlctures and sell tence correspolldences  . Conse--quently , we have introduced a concept called " unit " which corresponds to a pa~t of sentence and adopted a new method to extract corresponding units by using linguistic knowledge as a primaxy source of hiformation  . 
3.1 l , : xh'a clion of Units
First , units are extracted from parallel texts.
The unit corresponds to sentences or phrases ill tile text  . Terms which should be extracted can be found within a unit  . " File rest of words in the unit is called contextual infommtion fortile extracted term  . Tile size of units determine stile effectiveness of the st  , eceeding unit mapping process . For exa , n-pie , if we set noun phrases ( enny words in a dictio-naly ) as: . 1 unit , no contextual information is available , and thus t improbability that corresponding relations hold decreases  . In our present implementation , we set sentences as a unit fortile first approximation  . 
3.2 Mal)ping of Uniis
Next , the unit mapping process creates a cone-sponding unit table from Japanese ~  , nd English vails . This table stores the correslmn deneer lation -ship between milts and its likelihood  . The like li . .
hood is calculated based on the linguistic information in an MT bilingual dictionary  , Our trait mapping algorithm is given below : ( 1 ) l , ct , 1 be a set of all content words in tile Japanese unit JU  . ( miStim number of words ), 1 = Jl ' J2 . . . . . lm(2) l . et E be a set of all content words in the F , nglish unit\[\[J . ( nistile number of words )
E = : E1,12 . . . F ; nJ (3) . v is the number of . li's whose translation candi- ( 4 ) y is the number of Ej's which is included in the translation candidate list of some Ji in J  . 
(5) The correspondence likelihood CL is given by
CL(JU , EU ) = - x + ym+n
For each JU , M ( currently 3 ) English units with the highest CL ( JU , EU ) are stored in the corresponding unit table . 
4 GENERATING TRANS LATION
CANDIDATES 4 . 1 Ext rac t ion o f Japanese Terms Errors in the extraction of terms and phrases from parallel texts eventually lead to a failure in acquiring the correct term/phrase correspondences  . 
In Kupiec (1993) and Yamamoto (1993) , term and phrase extraction is applied to both of parallel texts  . In contrast , we extract from units only Japanese terms , thereby reducing the errors caused by term/phrase rcognizer  . Japanese NP's can be recognized more accurately than English NP's because Japanese has considerably essmulticategory words  . 
In the current implementation , the following two types of term candidates are extracted by the 
NP recognizer: ( A ) Compound nouns ( including verbal nouns ) 
Examples : " ~- 7" ye ": , l-~'~3i ~" ( = open bitline colfiguration ) "/ i ~4 -/ JiJm ~ l-fJ ~" ( = minimum featuring size )   ( B ) Unknown words ( nouns , verbal nouns ) Examples : " ~- J - ~" ( = to laminate , to form ) " , lt1 . 1  . ~, 9 : . "" Y '" ( = polishing ) Our NP recognizer utilizes the sentence awdy zer of a practical MT system  . The word dictionary includes approximately 70 , 000 Japanes entries . 
4 . 2 F ind ing Trans la t ion Cand idates Generation of English translation candidates for a Japanese term is essentially based on the following hypothesis : 
Hypothesis 1
The English translation of an extracted term in a Japanese unit is contained in the English corm -sponding unit  . 
Now an arbitrary word sequence in corresponding units can be a translation candidate of the Japanese term  . We extract English translation candidates in two steps : Step  1 : Select English corresponding units . 
Step 2: Extract ngram data from the units.
Step 1:
When the extracted term appears in NJ apanese units  , N?M English units will be stored in the corresponding unit table with their correspondence likelihood  . The N highest corresponding units within N ? M combinations are extracted  . When N is less than M , the M highest combinations arc selected . 
Step 2:
Suppose that tile correct English translation of the Japanese term JW is EW  , and that them nnber of Japanese units in which JW appears is FJU  ( JW )   ( = N )  . From ltypothesis 1 that the translation is contained in the corresponding units EUI  , EU2 . . . . . 
EUFJU(JW ) , EW would be a word sequence which often appears in corresponding units  . In order to get such EW , we use ngram data . 
The frequency of each ngram ( 1 <_n_<2x ( the number of component words in JW ) ) data in FJU ( JW ) English units is calculated and then EW candidates are ranked by the frequency as EWC  1  , EWC2 . . . . EWCj . Because EWC with a low frequency in the corresponding units is unlikely to be the correct wanslation  , the data with a frequency less than FJU ( JW ) 4 are heuristically excluded from the candidates . The data containing be verb and the data which starts or ends with a preposition or an article are also excluded from the candidates  . 
5ESTIMATING ENGLISH TRANS LA-
TIONS
The translation likelihood ( TL ) of one translation candidate EWCi for the term JW is defined as: 
TL(JW , EWCi ) =
F ( TLS(JW , EWC i ) , TLL(JW , EWC i )) where TI~S(JW , EWCi ) is "' Franslation Likelihood based on Statistical information  , " and TLL ( JW , EWCi ) " Translatiou Likelihood based on Linguistic info rmation  2   5  . 1 Statistical hfformation TLS(JW , EWCi ) is the frequency score based on the statistical information from Hypothesis  1 that a word which appears as often in tile corresponding units as JW in Japanese units is more likely to be EW  . It is quantitatively defined a stile probability in which the translation candidate appears in the corresponding traits  . That is , where FEU ( EWCi ) is the number of corresponding units in which EWCi appears  . 
5.2 Linguistic Information
TLL(JW , EWCi ) is tile word similarity score based on the accuracy of the correspondence trmJW and the translation candidate EWC i obtained by using linguistic information in tile MT bilingual dictionary  . Suppose one translation candidate of term JW = WJl , wJ2 . . . . wJk is EWCi=we 1, we 2 . . . . we I . 
Then we use the following hypottms is.
Hypothesis 2 ( a ) If the length of EWC i is close to the length of JW  , JW and EWC i are likely to correspond each other . 
( b ) JW and EWCi with more word translation correspondences are likely to correspond each other  . 
Under this hypothesis , the following correspondence relation ( 1 ) is the best . TermJW and translation candidate EWC i have the same length k  ( -I )  , and all of their component words correspond in the dictionary  , wJi : ~ wei indicates that we i is included in wJi 's translation candidates in the MT bilingual dictionary  . 
(1) wJl =* we1, wJ2~we2 . .  .   .   .   . wJk ~ Wek More generally , tim relation of each word ( wj ) in term JW and each word ( we ) in translation candidate EWC i is classified into the following four classes : i  ) w j ~ w e i i ) wj--*weiii ) wj-4iv ) ~---> we ( q b indicates no word ) it ) shows a pair whose correspondence is not described in the bilingual dictionary  , iii ) and iv ) indicate that the corresponding word for wj or we is missing  . Iniii ) , JW is longer than EWCi ; and vice versainiv) . 
In order to estimate correspondence between JW and EWCi  , i ) and it ) are scored by similarity to the virtual translation which holds the relation  ( I )  . 
When then mnber of words is the same , scoreQ(constant ) is given , c ~ Q ( ct > 0 ) is added to Q when there is a translation relation to reflect higher reliability of i  )  . Therefore , Q+aQ = ( I- , c ~) Q is given to the word pair of i ) , and Q to the word pair of it ) . 
Now since we disregard the word order of a term , JW and EWC i are represented as sets of words : JW = wJl  , wJ2 ,  . ., wJk ~-  wJl , w j2, . ., wJk  EWCi = we I , we2, . ., we I -  wel , we2, . . , welThe number of words with a lexical correspondence relation in wj and we  , the number of words in wj without a relation and the number of words in we without a relation are counted as x  , y , z respectively . That is , x-~y = k and x + z = l . 
T\[ . I . ( JW , EWCi ) is given as the ratio of tile score of the vmual translation to the score of 

When y >_z , x(l-tct ) Qt-zQ
TI2_.(JW , EWCi ) = ( xly ) ( l-ta.)Q


Tl . l . ( JW , EWCi ) = x ( 1-Ia ) Q+yO- ( z-y ) Q ( x-ly ) (l -~ c* ) Q
TI.I.(JW , Ewci)-.
x ( l-t ~ ) + z ( y _>_z )   ( x - ~ y ) (l q cQ x ( l-~~x ) +2y-z ( x + y ) (1-tcx )   ( otherwise ) By definition , TI . L(JW,t!WC i ) < 1 . The value of c ~ is determined as 2 by evaluating samplet nm sla-lion pairs . 
Followings are the TLI , 's of three EWC's for JW : vk--7": . / ff . : tI . ~ Jy: , ~ which consists of four component words ( k = 4) ;  ": , l---7":/(= open ) , " tf . ~, I-(-bit ), "" ~(= line ), " and " J j3 ~ . (- method , process ) . " bitline configuration x : 2, y-2, z = l . ' . T\[ . I ~-(2x3+l)/4x3=0 . 58 open bitlinex : : 3, y : 1, z : - O . ' . Tl . l . = (3x3)/4x3=0 . 75 open bit line configuration x = 3, y : l,z-I . ' . TLL = (3?3+1)/4x3=0 . 83 5 . 3 Combinat ion o f S ta t i s t i ca l and L in - guistic Information We define the translation likelihood TL  ( JW , 
EWC i ) as below:
TL(JW , EWCi ) -: mTLS(JW , F . WC i ) + nTLL(JW , EWCi ) m-tl Examining the value with the ration/ttl constant  , a low value of TI . S(JW , EWC i ) ill affects the total score , especially when the frequency EWCi ) should be much weighed for JW's which appear often  , but not for JW's with a low freq t , en-cy . Therefore we tentatively define ~= n/m as a function of frequency FJU  ( JW )  , because ! 3 s bould be higher when FJU(JW ) is low . 
\]3 = G ( FJU ( JW ) ) P + s  FJU ( JW ) q-r where r is a possible minimum frequency , aqds is limit of 13 as the word frequency is high enough . 
Values p = 4, q = l , r = l , and s = 0 . 5 are used in tile following experiments . By introducing 13, F is rewritten as:
F ( TLS(JW , EWC i ) , TLL(JW , EWC i )) =_TLS(JW , EWC i ) + 13TLL(JW , EWCi ) 1+13 In case FJU ( JW ) q is equal to or less than r , is meaningless , For such JW's , TL(JW , EWC i ) is redefined as simply:
TL(JW , EWCi ) = TLL(JW , EWCi).
Finally the translation candidate EWCi with the largest value of TL  ( JW , EWCi ) is assumed to be the correct English translation . 
Table 1 shows the translation candidates for JW : ~ 7"  >" ~" ~ , I - , ~ j Y ~ with the best three TL's . Its frequency in Japanese text is FJU ( JW )  = 19  ( 13 4 + 0 . 5 = 0 . 72) . Consequently , the correct 19-1 translation EWC3 , open bitline cotfiguration , is obtained . 
Table 1: Estimation of English translation
EWCiFEU'I'LSTLL'I'L bitline configuration 19   1  . 00 0 . 58 0 . 82 open bitline 18 0 . 95 0 . 75 0 . 86 open bit line configuration 18 0 . 95 0 . 83 0 . 9 0   6 EVALUATION ANDDISCUSSION To evaluate this method  , we have estimated English translations of Japanese terms in seven parallel texts  ( Japanese specifications of patents on semi -conductors and their English translations by human translators  ) and compared the translations with the correct data given by experts in building an MT dictionary  . The size of a Japanese text is 7 , 508 to 26 , 927 characters in 127 to 616 sentences ; 99 , 286 characters in 2 , 148 sentences in total . Examples of correct translation pairs estimated with the highest TL 
Compound nouns : \]'~-' J ") 3ll ~-" J " ~ . /2 minimum featuring size ~- j'-5 l~f\[i ~ . t ~ t ~ element separation region 71-  -  ':7" :-" t : :"' uI " ~7  , t ) ': , : ~ open bitline configuration cohtmn address trobe-e  ) t ,  3" ~ . 4 cell array
Unknown words : ~ ltI) , ~ ,   , ~ > , p " polishing 1/~  #collector ~ I~-Y ~ to form
Fig . 2: Correct translation pairs are listed in Fig .  2 . 
Table 2 shows the ranking of the correctly estimated translation pairs in seven sample texts  . The upper row shows the average of seven individual texts  ; the lower shows the result using all seven texts in one time  . The translation of over 70% of compound nouns is obtained as the first candidate  , and over 80% in the top three . The result for unknown words is 54 . 0% and 65 . 0% . Though the accuracy for tile unknown words is relatively low  , the estimation has been impossible for Yamamoto ( 1993 )  . itere , tile terms whose cor , ect translations are not found in English texts are excepted from evaluation  .   . Such data occur when human experts give a noun translation for Japanese verbal noun term which is translated as a verb in the actual text  . Tile ratio of this kind of translation pairs is a bot  , t3% . Tile rate of the correct data is calculated by the ratio of the total occurrences  . 
The accuracy for the average of unknown words is 52  . 4% in the top three . The result using all texts is significantly better than tile average because tile statistical information is the major factor in the current implementation  . Use of more linguistic information such as in Dangan  ( 1991 ) and Matsumoto ( 1993 ) would improve the total performance . 
Linguistic information has proven effective to estimate translations of low-frequency terms  . Of terms which appeared only once in a Japanese text  ,   215 translations are obtained correctly as the first candidate from  327 terms ( 65 . 7%) in seven texts . 
The fourth example of compound nouns in Fig.
2 shows the advantage of statistical information because the correct translation was obtained in spite of the wrong word segmentation  . The Japanese term really consists of three words ( ~ J9A , 7" F1t ~ ,   . z \] .  ~ -  . 7" ) , each of whicb corresponds to " cohtmn , "" address " and " strobe " respectively . But word segmentation output four word . ~( ~ J5'\],, TF1 t ~, l . , ~ -  . 7") because ": < I . ~--7"" is unknown and "-~
Compound nouns ( occurrences ) -total Tl-i ~' t cstq , n--at ~' ~ to , ; ~- e~-tqm:ZteT"1 text , , 7  ext_s ~ 3 , 224_~ . 9% (2,349) 83 . 3% (2,680)
Unkilown words occtnrences ) - t-ot~al--\[-first estimate top 3 estimates ? IO --- 55   6 I 30  . 1~, (16 . 7) 52 . 4% (29 . 1)
I 38954 . 0%, (210) 65 . 0% (253) k1-" is known as " strike . " The CASES where no correct translatkm has been obtained needs to be examined  . The major reasons for faih , resare : 1 . Errors in mappi , lg conesponding units . 
2 . Errors in word segmentation of unknown compound wo  , ds . 
Mapping uniter rm . 's occur when the one-to-onennit correspondence does not exist  . The experiment using one text shows that 12 out of 98 Japanese sentences have no on E-to-one corresponding English sentence  . For better unit correspondence , the trails should be smaller , for example , a clause or a verb phrase , so as to make the corresponding accuracy and frequency in text higher and statistical infornmtion more effective  . It would improve the unit map l ) ing when one Japanese sentence is tnms latcd into several 
English sentences or vice vmsa.
ThE segmentation errors of unknown words arise often in case of Katakana compotmd word  . 
Katakana is the phonetic alphabet in Jal ) anese for spelling foreign words ? Since many compound nour Ls in a technical field consist of Katakana's with no space between component words  , much larger lexicon will contribute to more accurate segmelltation  . 
7 CONCLUSION
An MT dictionary has been generated from Japanese and English parallel texts  . The method proposed in this paper assumes t , nit correspondence and utilizes linguistic information in an MT bilingual dictionary as well as statistical information  , namely , word frequency , to estimate the English translatio , L Over 70% accun~te translations for compound nouns are obtained as the first candidate from small  ( about 300 sentences ) Japanese/Fnglish parallel texts ( patent specifications ) containing severe distortions . The accnracy of the first translatic m candidates I or unknown words  , which calmot be obtained by a linguistic-based method  , is over 50%? Tim current implementation shows promising results for a clifflet  , It target ( patent texts ) despite relatively shnple linguistic knowledge ? The overall lmf formance will be imlnOved by using more linguistic knowledge and optimizing panuneters calculated by sh ~ tistical information ? 

Brown , P . F . ; l , ai , J . C . ; and M Ercer , R .  1, (1991) . 
"Aligning sentences in parallel corlx ), a . " In Proe . of the 29th Annual Meeting of the ACL , 16% 176 . 
Chen , S . F .  (1993) . " Aligning sentences in bilingual corpora using Iexical informatio  , L " In Proc . of the 3lxt Atmual Meeting of the ACL , 916 . 
Dagan , I . ; ltai , A . ; and Schwall , U .  (1991) . " Two languages are mo , ' eintkm native than one . " In Proc . of the 29th Ammal Meeting of the ACL , 130-137 . 
Gale , W . A . , and Chnrcb , K . W .  (1993) . "A program for aligning sentences in biling t , al corpora . " Computational Linguistics , 19(1), 75-90 . 
Katoh , N .  (1993) . " Word selection by searching the translation candidates on monoling nal texts in target language  . "7> chuieal Report of IEICE,
NLC93-32. ( in Japanese)
Kupiec , J .  (1993) . " An algorithm for finding noun phrase correspondences in bilingual corpora  . " In I ' roc . e ( the 31st Ammal Meetingrg " the ACL , 1722 . 
Matsumoto , Y . ;\[ shimoto , ll . ; and Utsuro , T . 
(1993) . " Structural Matching of Parallel Texts . " In I ' roc . of the 31st Annual Meeting of the ACL , 2330 . 
Nogami , lI . ; Kumano , A . ; Tanaka , K . ; and Anmno , S .  (1991) . " l . earning of translation words using target-hm guage documents  . " In Proc . ( f42 ridAm~ualMeeting of II'S . I , 2C-6 . ( in Japanes E ) Yamamolo , Y . , and Sakamoto , M .  (1993) . 
" Extraction of teclmicalte , 'm bilingual dictionary from bilingual corpus . "IPSJ SIG Notes,
N 1,94-12. ( in Japanese)
