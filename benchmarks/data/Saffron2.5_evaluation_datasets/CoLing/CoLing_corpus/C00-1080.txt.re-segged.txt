Chart Parsing and Constraint Programming
Frank Morawietz
Seminarflit Sprachwissenschaft
Universifiit Tfibingen
Wilhehnstr . I13
72074 T fibingen , Germany
frank@sfs.nphil , uni-tuebingen , de

In this paper , lmrsing-as-deduction and constraint programming are brough together to outline a procedure for the speeitication of constraint-based chart parsers  . Foblowing the proposal in Shieber et al (1995) , we show how to directly realize tim inference rulest brdeductive parsers as Constraint Handling Rules  ( Frihwirlh ,  1998 ) by viewing lheitems of a chart parser its constraints and lhe constraint base as a charl  . This allows the direct use of constraint resolution to parse sentences  . 
1 Introduction
The parsing-as-deduction approach proposed in Pereira and Warren  ( 1983 ) and exlended in Shieber et al ( 1995 ) and the parsing schemal a detincd in Sikkel ( 1997 ) are well established parsing paradigms in computalional linguistics  . Their mains lrengths are I heirllexibility and lhelevel of abstraction concerning control informal \] o  , 1 inherenlin parsing algorithms , l Vurlhermore , lh cy are easily exlcn sible In more complex formalisms  , e . g . , at\]g-mcntcd phrase struclure rules or the ID/LP formal  . 
Constraint Programming ( CP ) has been used in computational linguislics in several areas  , for example in ( typed ) featut'e-lmsed systems ( Smolka ,  1995) , or condiotional constraints ( Matiasek ,  1994) , or adwmccd compilation techniques ( G6tz and Meurcrs ,  1997 ) or specialized constraint solvers ( Manandhar ,  1994) . But none of these approaches uses constraint programming techniques lo implement standard chart parsing algorithnls directly in a constraint system  . 
In this papel ; I will bring these two tmm digms together by showing how to implement algorithn \] sfl ' om the parsing-as-deduction sctmme by viewing the parsing process as constraint propagation  . 
The core idea is that the items of a conventional chart parser are constraints on labeled links between the words and positions of an input string  . Then tile inference rules allow for the deduction of new constraints  , again labeled and spanning parts of tim input siring  , via constraint propagation . The resulting constraint store represents he chart which can be accessed to determine whether the parse was successful or to reconstruct a parse tree  . 
While this ntay seem a trivial observation , it is not . iust another way of implementing deductive parsing in yet another language  . " file approach allows for a rapid and very flexible but at lhesame time uniform method of implementation fall kinds of parsing algorithms  ( for constraint-lmsed theories )  . The goal is not necessarily to build tim f as test imrscr  , but rather to build-for an arbitrary algorithm -a parser fast and pcrspict \] ously  . For example , the advantage of our approach compared to the one proposed in Shieber et al  ( 1995 ) is that we do not have to design a specialded t , ction engine and we do not have In handle chart and agenda explicitly  . Furlhemmre , the process can be used in any constrainl-based formalism which allows for constraint propagation and therefore can bceasily integrated into existing applications  . 
The paper proceeds by reviewing Ihc parsing-as -deduction approach and aimrticular way of implementing constraints ysl clns  , Constraint Handling P , ules ( CHR ) as presented in l ~ r fihwir/h (1998) . Then it shows how to implement several parsing algorithms very naturally with constraint propagation rules before concluding with an outlook on how  1o exteml the technique In more advanced applications  . 
1.1 Parsing as Deduction
Although I assume some familiarity with parsing-as -deduction  , I will recall some basic delinitions for convenience  . The nolations and dm three basic algorithms are directly token from Shieber et al  ( t995 )  . 
As usual , string sw result from concalcnation o1' symbols from some alphal ~ et set ? , i . e . , wC-E': . We refer t ( itile decomposition of such asiring into its alphabet symbols with indices  . We lix this notation using w = W l . . . uS , . Further notational conventions are : i , jEN , n for the length of the string to be parsed , A , B , C ,  . . . for arbilrary formulas or nonterminals , ab , c, . . , for terminals , a for the empty string and o ~ , \[3 , 7 ,  . ., for strings of terminals and nonterminals . Form tf las used in parsing will also be called items or edges  . A grammatical deduction system or , in Sikkel's terminology a pal : ring schema , is defined as a set of deduction schemes and a set of axioms  . These are given with the help of formula schemata which contain  ( syntactic ) me\]a-variables which are in-s\]an\]tared with concrete terms on application of tim rules  . 
A deduction scheme R hast11 o general form
AI- . -A , ( side conditions on A\] .   .   . A , , C)

Bottom-Up Top-Down Earley





Complete\[j , c~-\]\[j , ?\[~1\[i , j , A , o ~* ~1\[o , ?\]\[ o , ? Sl\[o , o , s ' , ? s\]\[ , , , s . \] \[,,,  . \]\[0,,,, s ', s . \]\[j,ot*\]\[j,*w . i + l~\]\[i,j,a,o ~* w . i+\[3\]\[j+1 , mvj + l "\]'\[ j + l , ?\[3\]\[i , j + I , A , ~ wj+I*\[3\]~(B___~T)\[i:j , a , o~ . B ~\]( B__+T )\[ j , ?7\[3\]\[j , j , B , ?3'\]\[k , j , n , Vo\](B---+y)\[i , j , A , a B\[3\]\[j , ae?\]where the Ai and Carc formula schemata . The Ai are called antecedents and C the consequence  . Note that deduction schemes may refer to string positions  , i . e . , the indices within the input string , in their side conditions . 
Application of these schemat and derivations of formulas are then detined as in the Shieber et al article  . Intuitively , parsing uses the deductive rules-if their antecedents and the side conditions are met-to infer new items from the axioms and already generated items until no new ones can be derived  . The parse was successful if a goal item was derived  . 
Therefore , all the parsing systems used in this paper are delincd by specifying a class of items  , a set of axioms , a set of inference rules and a subset of the items  , the goals , For better eadability , If ollow Shieber et al in using the familiar dotted items for the presentation  . The three classical example algorithms we will use to illustrate our technique are given in Tab  .  1 . I assume familiarity with these algorithms . 
Unless specified differently , we assume that we are given a contextfree grammar  ~ =   ( N , Z , S , P ) with nonterminals N , terminals Z , start symbol S and se to 1' productions P . For Earley's algorithm we also assume a new start symbol S ' which is not in N  . Each production is of the form A----+ o ~ with A GN  , c ~ E(NUZ )* . For examples I will use the simple PP-attachmcnt grammar ~ given in Fig  .   1 with the obvious sets of nonterminals and terminals  , the start symbol S and productions P . It is left to the reader to calculate xample derivations for the three algorithms t'or a sentence such as John hit the dog with the stick  . 
1.2 Constraint Handling Rules
There are several constraint programming environments available  . The most recent and may be the most tlexible is the Constraint Handling Rules  ( CHR ) package included in SICStus Prolog ( Friihwirth ,  1998) . These systems
S - - + NP VP V--hit
VP - - - - + VNP\[VNPPPPN - - - + John
PP ~ PNPN---+ dog\]stick
NP--+PN\]Det NIP---+ with
NI----+NIN 1 PP Det - - -- q the
Figure 1: Example Grammar : PP-attachment maintain a constraint base or store which is continually monitored for possible rule applications  , i . e . , whether there is enough information present to successfully use a rule to silnplify constraints or to derive new constraints  . 
Whereas usually one deals with a tixed constraint domain and a specialized solver  , CHR is an extension of the Prolog language which allows for the specification of user-defined constraints and arbitrary solvers  . The strengfl ~ of the CHR approach lies in the fact that it allows for multiple  ( conjunctively interpreted ) heads in rules , that it is flexible and that it is tightly and transparently integrated into the Prolog engine  . 
In CHR constraints are just distinguished sets of ( atomic ) formulas . CHR allow the definition of rule sets for constraint solving with three types of rules : Firstly simplification rules  ( <=> ) which replace a number of constraints in the store with new constraints  ; secondly propagation rules ( ==> ) which add new constraints to the store in case a number of constraints is already present  ; and thirdly " simpagation " rules ( <=> in combination with a \ in the head of the rule  ) which replace only those constraints with new ones which are to the right of the back slash  . Rules can have guards . Aguard ( separated from the rest of the body by a I ) is a condition which has to be met before the rule can be applied  . 
We cannot go into the details of the formal semantics of CHR here  . The interested reader is referred to Fr fih wirth ( 1998 )  . Since I will refer back to it let us just and propagation rules are implications if their gtmrd is satislied  . Simpagation rules are special cases of simplification rules  . Soundness and completeness results for CHR are available  ( Abdennadhertal . , 1996 Abdennad-her , 1998) . 
2 Parsing as Constraint Propagation
The basic observation which turns parsing-as -deduction into constraint propagation is simple : items  o1' a chart parser arc just specM formulas which are used in an inference process  . Since constraints in constraint program-ruing are nothing but atomic formulas and c  ( mslraint handling rules nothing but inference rules  , the connection is immediate . 
In more detail , I will present in this section how to implement the three parsing algorithms given in % b  . i in CHR and discuss the advantages and drawbacks of this approach  . Since CHP , are integrated in SICStus Prolog , I will present constraints and rules in Prolog notation  . 
We use tile following two types of constraints . The constraints cor , ' esponding to tile items will be called edge constraints  . They have two arguments in case of the two naive algorithms and tive in tile case  o1' Ear-ley's algorithm , i . e . , edge ( X , N ) means in the case of the bottom-up algorithm that we have recognized a list of categories X up to position N  , in the case of tile topdown algorithm that we are looking for a list of categories X starting at position N and intile case of Earlcy's algorithm edge  ( A , Alpha , Beta , I , J ) means that we found a substring fl'om I to J by recognizing the list of categories Alpha  , bulwe are still looking for a list of categories Betato yield category k  . The second constraint , werd ( Pos , Cat-Word ) , is treed in tile scanning steps . 
It avoids using Icxical entries in prediction /completion since ingramnm rules we do not use wo IWs but their categories  . 
For simplicity , a gramnmr is given as Prok/gIhcts : lexical items as lex  ( Word , Category ) and gramnm rules as rule ( RHS , LHS ) where RHS is a list of categories representing the right hand side and LHS is a single category representing the lefthand side of the rule  . 
The algorithms are simple to implement by specifying the inl'erenee rules as constraint propagation rules  , the axioms and the goal items as constraints . The infer-once rules are translated into CHR in the following way : The antecedents are transformed into constraints appearing in the head of the propagation rules  , the side conditions into the guard and the consequence is posted in the body  . A summarization of the resulting CHR programs is presented in Tab  .  2 . 
We use Earley's algorithm for a closer look at the CHR propagation rules  . In the scanning step , we can movetile head of the list of categories we arc looking for to those we already recognized in case we have an appropriately matching edge and word constraint in our constraints to re  . The result is posted as a new edge constraint parse  ( InList ) :- axiom , posteons t(InList , report ( Length ) . 
0, Length ), post_const(\[\], Len , Len).
post_const(\[WordStr\] , In Len , Len ) :- rAndall(Cat , lex(Word , Cat ) , Cats ) , postwords ( Cats , In Len , Word ) , 
New Lenis In Len+i , postconst(Str , New Len , Len ) . 
Figure 2: Utilities for CHRdmsed deductive parsing with tile positional index appropriately increnmnted  . 
The prediction step is more complex . There is only one head in a rule , namely an edge which is still looking tbrs ( )me category to be found . If one can lind rules with a matching LHS , we collect all of theminal island posttile approl  ) riat cfl'es hedge constraints l breach element of that list with the predicate  post_ea_edges/3 which posts edges of timl bllowing kind : edge ( LHS , \[ J , RHS , J , d ) . 
The collection of all matching rules in a call to set of  /3 is necess m 7 since CHR are a committed choice language . One cannot enumerate all solutions via backtracking  . If there are no matching rules , i . e . , tim list of RHSs we found is cmpty , the call to set of i , the guard will fail and therefore avoid vacuous predictions and nontermination ftile predictor  . 
Lastly , tile completion step is a pure propagation rule which  1"a11s\]alcs literally . The two antecedents are in the head and lhe consequence in the body with appropriate instantiations  o1' the positional variables and with the movement of the category recognized by the passive edge from the categories Iobe found to those found  . 
In the table there is one more type of rule , called an absorption rule . It discovers those cases where we posted an edge consmtint which is already present in the chart and simply absorbs the newly created one  . 
Note that we do not have to specify how to insert edges in to c if lmr chart or agenda  . The chart and the agend are represented by the constraints to re and therefore builtin  . Neither do we need a specialize deduction engine as was necessary for the implementation described in Shieber et al In fact  , the utilities needed are extremely simple , see Fig .  2 . 
All we have to do for parsing ( parse/l ) is to post the axion ? and o~1 traversal of the inputs tri , g to post the word constraints according to the lexicon of the given grammar  . Then the constraint resolution process witll the inference rules will automatically build a complete chart  . 
The call to report /1 will just determine whether dmre is an appropriate edge with the correct length in the chart and print that information to the screen  . 
Coming back to the issues of chart and agenda : the constraints to rel'nnetiot~s as chart and agend at the same i  axiom/0 just posts I he edge ( s ) delined in Tab .  2 . 

Table 2: Parsing systems as CHR programs
Bottom-Up Top-Down Earley
Items edge(X , N)edge(X , N)
Axiom edge(\[\] , 0) edge(\[s\] , 0) Goaledge(Is\] , Len ) edge(\[\] , Len ) edge(A , Alpha , Beta , I , J ) edge(s prime , \[\] , \[s\] , 0 , 0) edge ( s prime , \[s\] , \[\] , 0 , Len)



Earley edge(Stack , N ), word(N , Cat-Word ) := >
N1 is N+I , edge(\[CatlStack\],Nl).
edge(\[CatlT\],N ), word(N , Cat-Word ) == >
N1 is N+I , edge(T , Nl).
edge(A , ilpha , \[CatlBeta\] , I , J ) , word(J , Cat-Word )
JlisJ+l , edge(h,\[Catlilpha \], Beta , I , Jl).



Earley edge (\[ LHSIT\] , N ) : : > set of ( RHS , rule ( RHS , LHS ) , List ) I post_td edges ( List , T , N) . 
edge(A , Alpha , \[ Bl Beta \] , I , d == > set of ( Gan~a , rule ( Gamma , B ) , List ) postea_edges(List , B , J) . 


Earley edge ( Stack , N ) ::> set of ( Rest-LHS , split ( Stack , Rest , LHS ) , List ) postbu_edges(List , N) . 
edge(h , ilpha , \[BIBeta\] , I , K ) , edge(B , Gamma , \[\] , K , J ) ==> edge(i , \[Blilpha\] , Beta , I , J) . 

Bottom-Upedge(L , N ) \ edge(L , N ) < :> true.
Top-Down edge(L,N)\edge(L,N ) <=> true.
Earley edge ( A , Alpha , Beta , I , J ) \ edge(A , Alpha , Beta , I , J ) < :> true . 
time since as soon as a constraint is added all rules are tried for applicability  . If none apply , the edge will remain dormant until another constraint is added which triggers a rule together with it  . 2 So , the parser works incrementally by recursively trying all possible inferences for each  2 Another way to " wake " a constraint is to instanliate any of its variables in which case  , it will be matched against he rules again . Since all our constraints are ground , this does not play a role here , constraint added to the store before continuing with the posting of new constraints fi'om the  post_const/3 predicate . The way this predicate works is to traverse the string fi'om left-to-right  . It is trivial to altertile predicate to post the constraints from right-to-left or any arbitrary order chosen  . This can be used to easily test different parsing strategies  . 
The testing for applicability of new rules also has a with  , the , stick\]) . 
Input recognized.
word (0 , pn-john ) word(I , v-hit ) , word (2 , det-the word (3 , n-dog ) , word (4 , p-with ) word (5 , det-the ) word (6 , n-stick ) edge ( sprlme ,  \[\] , \[ s\] , O , O ) , edge(s , \[\] , \[np , vp\] , O , O ) , edge(np ,  \[\]  , \[ det , nbar \] , O , O ) , edge(np ,  \[\] , \[ pn\] , O , O ) , edge(np , \[phi ,  \[\]  , O , I ) , edge(s , \[ np\] , \[vp\] , O , l ) , edge ( vp , \[\] , \[ v , np\] , l , l ) , edge ( vp ,  \[\] , \[ v , np , pp\] , l , l ) , edge(s , \[vp , np\] , \[\] , O , 7) , edge(s prime , \[ s\] ,  \[\] , 0 , 7) Figure 3: A partial CHP . generated chart connection with the absorption rules  . We absorbtile newer edge since we can assume that all possible propa-gations have been done with lheold identical edge constraint so that we can safely throwtile other one away  . 
As an example I'OZ " tile resulting chart , part of the output of an Earley-parse for John hit the dog with the stick assuming the grammar fl'om Fig  . I is presented in Fig .  3 . 
The entire conslrain lstere is prinlcd lot l~e screen after the constraint resolution process top s  . Tile order of file constraints actually reflects tile order of the construction  o1' the edges , i . e . , the chart constitutes a lrace o1' tile parse at the same time . Although the given siring was ambiguous , only a single solution is visible in lh . echart . This is due to the fact that we only ( lid recognition . No explicit parse wits built which could have differentiated between ihe two solutions  . It is an easy exercise to either write a predicate to extract all possible parses from the chart or to alter the edges in such a way flint an explicit parse tree is built dr  , ring parsing . 
By using a builtin deduction engine , one gives up control of its efficiency . As it turns out , this CHR-based approach is slower titanthe specialized engine developed and provided by Shieber et al by about a factor of  2  , e , g . , for a six word sentence and a simple grammar tile parsing time increased from  0  . 01 seconds to 0 . 02 seconds on a LINUX PC ( Dual Pentiuml I with 400 MH z ) running SICS tus Prolog . This factor was preserved under 5 and 500 repetitions of the same parse . However , speed was not the main issue in developing this setup  , but rather simplicity and ease of implementation . 
q bs unlup this section , tile advantages of the approach lie in its flexibility and its availability for rapid prototyping of different parsing algorithms  . While we used the basic examples fl'om the Shieber et al article  , one can also implement all I ho different deduction schemes from Sikkel  ( 1997 )  . This also includes advanced algorithms st , chasleft-corner or head-corner parsing , the relined Earley-algoriflml proposed by Graham el al  .  (1980) , or ( unification-based ) II ) /LP parsing as defined in Morawietz ( 1995 )  , or any improved version of any of these . 
Furthermore , because of the logical semantics of CHP , with their soundness and completeness , alle or recmess and so/redness proofs for the algorithms can be directly applied to this constraint propagation proposal  . The main disadvantage of the proposed approach certainly lies in its apparent lack of efficiency  . One way to address this problem is discussed in the next section  . 
3 Extensions of the Basic Technique
The , ' eare tw ' o directions the extensions of the presented technique of CHR imrsing mightrake  . Firstly , one might consider lmrsing of more complicated granmm  , 's compared to tile CF ones which were assumed so far  . Following Shieber et al , one can consider ut fification-tmsed grammars or tree adjoining grammars  . Since I think lha ! the previous section showed lhat the Shieber ctal  . approach is transferable in general , the results they present are applicable here as well  . 3 Instead , I want to consider parsing of minimalist grammars  ( Chomsky ,  1995 ) as de-lined in recent work by Stabler ( I997 ,  1999) .  4 3 . 1 Minimalist Parsing We cannot cover the flleory behind deriwltional minimal-ismas presenled in Smbler's papers in any delail  . Very briefly , lexical items arc combined wilh each other by a binary operation meIx'e which is lriggered by the availability of an appropriate pair of clashing features  , here noted as cat : IC ) for Smbler's categories c and comp ( C ) for = c . Fttrl hermor c , there is a treaty operation move which , again on tile awfilability era pair of clashing features  ( e . g . , - case , + case ) , triggers the extraelion era ( possibly trivial ) subtree and its merging in attile root node . On completion of these operations lheclashing feature pairs are removed  . The lexical items are of tile l ' or m o1' linked sequences o1' trees . Accessibility o1' fea-lures is detined via a given order on the nodes in this chain of trees  . A parse is acceptable if all features have been checked  , a part li'om one category feature which spans the length of the string  . The actual algorithm works naively bottom-up and , since the operations are at most binary , the algorithm is CYK-based . 
3 Obviously , using unification will in lroduce addilional complexity  , but no change of the basic melhod is required . If lhet milicazion can be reduced to Prolog unilication  , it can stay in the head of the rule(s ) . If it needs dedicated tmilicalion algorilhms , they have to be called explicitly it \] the guard . 
4 The code for the original implenlenzalion u derlying the paper was kindly provided by Hd Stabler Altar/from I heimplementation in CHP  , , all file rest is his work and his ideas . 

Table 3: Part of a CHR-based minimalist parser


Goaledge(I , J , Chain , Chains ) edge(I , I , Chain , Chains ) edge(I , I + l , Chain , Chains ) edge ( J , J , Chain , Chains ) edge (0 , Length , \[ cat(C)\] , \[\]) (\[ Chainl Chains \]----+ e) , I a variable ( \[Chain I Chains \] - - - - + Wi + l ) and there is no-Xin\[Chain IChains\] ( \[Chainl Chains\]--~wi+l )  , Javariable and - X , I and I+l occur in \[ Chainl Chains \] Merge edge ( I , J , \[ comp(X ) IRestHead\] , Ch0) , edge(K , L , \[ cat(X ) IRestComp\] , Chl ) eheck ( Rest Head , New Head , I , J , K , L , A , B , RestComp , Ch0 , Chl , Ch)1 edge(A , B , NewHead , Ch) . 

An initial edge or axiom in this minimalist parsing system cannot simply be assumed to cover only the part of the string where it was l ~ und since it could have been the result of a move  . So the elements of the lexicon which will have to be moved  ( they contain a movement trigger-X ) actually have the positional indices instantiated in the last  o1' those features appearing . All other movement triggers and the position it will hebase generated are assumed to be traces and therefore mpty  . Their positional markers are identical variables , i . e . , they span no portion of the string and one does not know their value at the moment of the construction of the axioms  . They have to be instantiated during the minimalist parse  . 
Consider the set of items as delined by the axioms  , see Tab .  3 . The general form of the items is such that we have the indices first  , then we separate the chain of trees into the first one and the renmining ones for better access  . 
As an example for the actual edges and to illustrate the discussion about tile possibly variable string positions in the edges  , consider the lexical item it ( as in believe it ) : lex ( it , I , \[(K , K):\[cat(d) , -case(I , J)\]\]):-
J is I + l.
Since I = 1 in the example the following edge results edge ( K , K , \[ cat(d ) , -case (1 , 2 ) \ ] \ ]  ,  \ [ \ ] )  . We know that it has been moved to cover positions 1 to 2  , but we do not know ( yet ) where it was base generated . 
We cannot go into any further detail how the actual parser works  . Nevertheless , the propagation rule for merging complementizers shown in Tab  .   3 demonstrates how easily one can implement parsers for more advanced types of grammars  .   5   5The predicate check implements the checking of the features and i  , l dices and recomputes the new values for the resulting edge  . 
3.2 Compiling the Grammar Rules into the
Inference Rules
A proposal for improving tile approach consists in moving the test for rule applicability from the guards into the heads of the CHR rules  . One can translate a given context-fi'e e grammar under a given set of inference rules into a CHR program which contains constraint propagation rules for each grammar rt de  , thereby making tile processing more efficient . For simplicity , we discuss only timcase of bottom-uparsing . 
For the translation from a CF grammar into a constraint framework we have to distinguish two types of rules : those with from those without an empty RHS  . We treat the trivial case of the conversion first  . For each rule in the CF grammar with a nonempty RHS we create a constraint propagation rule such that each daughter of the rule in u ' oduces an edge constraint in the head of the propagation rule with variable  , but appropriately nmtch-ink string positions and a tixed label  . Tilenew , propagated edge constraint spanst been tire range of the positions ot'the daughters and is labeled with the  ( nonterminal ) symbol of the LHS of tile CF rule . In our example , the resulting propagation rule for Slooks as follows : edge  ( I , K , np ) , edge(K , J , vp ) : :> edge(I , J , s ) The translation is a little bit more complicated for rules with empty RHSs  . Basically , we create a propagation rule for each empty rule , e . g . , A ----+ e , such that the head is an arbitrary edge , i . e . , both positions and the label are arbitrary variables  , and postnew edge constraints with the LHS of the CF rule as label  , using the positional variables and spanning no portion of the string  , resulting in
CHR rules of the following type : edge(I , J , _Sym ) :=> J is I+l edge ( l , I , A ) , edge(J , J , A ) since they would propagate furlhcr constraints on their own output which is avoided by in chlding a guard which ensures flint empty edges are only propagated for every possible string position once by testing whether the edge spans a string of length one  . Recall that storing and using already existing edge conslrair flsi saw  ) id cd with an absorption rule . Since these empty constraints can be reused an arbitrary number of times  , we get the desired effect with . out having to fear nontermination . All hough this is not an elegant solution , it seems lhat other alternatives such as analyzing and transforming the entire grammar or posting the empty constraints while traversing the input string arc not appealing efl her since they give up the one-to-one correspondence b tween the rules of the CF grammar and the constraint program which is advantageous in debugging  . 
With this technique , the parsing timcs achieved were better by a factor of a third compared to the Shieher et al implemenlation  . Although now the process of the compilation obscures the direct com ~ ection betweet ~ parsing -as-deduction and constraint propagalion somewhat  , the increase in speed makes it a worfl ~ while xercise  . 
4 Conclusion
In the paper , the similarity between parsing-as-deduction and constraint propagation is used to propose a llexible and simple system which is easy to implement and flmre-for e offers itself as a t cst bed for different parsing strategies  ( such as topdown or bottom-up )  , for wu ' ying modes ? of processing ( such as left-to-right or right-to-left ) or for differentypes of grammars ( such as for example minimalist grammars )  . Compared to the Shieberal ) proach , the pure version see , ns to be lacking in efliciency . This can be remedied by providing an automatic compilation into more eflicient specialized parsers  . 
While the paper has shown that existing constraint systems are powerful enough to allow chart parsing  , more work has to be invested in the realization of such a larger system combining these techniques with constraint solvers l brexisting constraint-based naturalan-guage theoriesm see whether f t  , rther benelils can be gotten from using parsing as constraint propagation  . Dt , e to the tlexibility of the CHR system , one can now use the constraint propagation approach to drive other constraint solving or constraint resolution techniques  ( also implemented in CHR ) resulting in a homogenous environment which combines both classical constraint solving with a more operational generator  . 
Specifically , one can use each created edge to post other constraints  , for example about hew dl-formedness of associated typed feature structures  . By posting them , they become available for other constraint handling rules  . 
In particular , systems directly implementing HPSG seem to suffer fi'om the problem how to drive the constraint resolution process efficiently  . Some systems , as for example ALE ( Carpenter and Penn ,  1998 ) use a phrase struct tH'e backbone to drivetile process  . Tilep , oposal here would allow to use 111e ID/LP schemata directly as constraints , but nevertheless a the driving tbz'ce behind lhe other constraint satisfi ~ ction techniques  . However , for the moment this remain speculative . 

Abdemmdhcr , S .  (1998) . Almlysey on regel basier ten Constraint li~sern , PhD thesis , Ludwig-Maximilians-
Universitfit Mfinchen.
Abdennadheh S . , Frfihwirth , T . and Meuss , H .  (1996) . 
On conlluence of constraint handling rules , LNCS'1118 , Springer . 
Carpenter , B . and Penn , G .  (1998) . ALE : The attribute logic engine , version 3 . 1 , Usermamtal , Carnegie Mellon University , Pittsburgh . 
Chomsky , N .  (1995) . The Minimalist Program , Vol . 28 of Current Studies in Linguistics , MIT Press . 
Friihwirth , T .  (1998) . Thcory and practice of constraint handling rules , Journal () , /' Logic Pmgtzmlnting 37 . 
G6tz , T . and Meurers , D .  (1997) . Interleaving universal principles and relational constraints over typed feature logic  , ACTJEACL Collj'erence'97 , Madrid , Spain . 
Graham , G . , Harrison , M . G . and Ruzzo , W . L .  (1980) . 
An improved context-li'cc recognizer , ACM7 ) wnsac-tions on Programming Languages and Systems 2   ( 3 )  . 
Manandhar , S .  (1994) . An attributive logic of set descriptions and set operations  , ACL Conference '94 . 
Matiasek , J .  (1994) . PHnciple-Based Processing of Natural Language Using CEP Techniques  , PhD thesis , TU

Morawiclz , F .  (1995) . A Unification-Based ID/LP Parsing Schema , Proceedings of the 4th IWPT , Prag . 
Pereira , F . C . N . and Warren , D . H . D .  (1983) . Parsing as deduction , ACL Collference ' 83 . 
Shieber , S . M . , Schabes , Y . and Pereira , F . C . N .  (1995) . 
Principles and i , nplemenlation of deductive parsing , 
Journal of Logic Pmgtwmming 24(1-2).
Sikkel , K .  (1997) . Patwing Schemata : A Framework Jbr Specification and Analysiso  . fPa ~ wing Algorithms,
ETACS Series , Springer.
Smolka , G .  (1995) . The Oz programming model , in J . van Leeuwen ( ed . ), Conqmter Science 7bday , LNCS 1000, Springer . 
Stabler , E .  (1997) . Derivational minimalism , in C . Retor 6(ed . ), Logical Aspects of Computational Linguistics,
LNAI 1328, Springer.
Stabler , E .  (2000) . Minimalist grammars and recognition , Presented at the Workshop Linguistic Form and its " Conqnttation of the SFB  340 in Bad Teinach , Uni-versitiit Tiibingen . Draft . 

