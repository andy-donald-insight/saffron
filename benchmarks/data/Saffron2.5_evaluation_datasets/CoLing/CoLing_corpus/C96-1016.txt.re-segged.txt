Measuring Semantic Coverage
Sergei Nirenburg , Kavi Mahesh and Stephen Beale
Computing Research L~bor~tory
New Mexico St ~ tte University
bt~s Cruces , NM88003-0001

sergei;m ~ hesh ; sb ~ crl.nmsu.edu

The develop lnent of natural language processing systems is currently driven to a large extent by measures of knowledge base size and coverage of individual phenomena relative to a corpus  . While these measures have led to significant advances for knowledge-lean applications  , they do not adequately motivate progress in computational semantics leading to the development of largescale  , general purpose NLP systems . In this article , we argue that depth of semantic representation is essential for covering a broad range of phenomena in the computational treatment of language and propose  ( lept has an important additional dimension for measuring the semantic coverage of NLP systems  . We propose an operationalization of this measure and show how to characterize an NLP system along the dimensions of size  , corpus coverage , and depth . The proposed framework is illustrated using sever ~fl prominent NLP systems  . We hope the preliminary proposals made in this article will lead to prolonge debates in the field and will continue to be refined  . 
1 Measures of Size versus
Measures of Depth
Evaluation of current and potential performance of ' an NLP system or method is of crucial importance to researchers  , developers and users . Current performance of systems is directly measured using a variety of tests and techniques  . Often , as in the case of machine translation or information extraction  , an entire " industry " of evaluation gets developed  ( see , for example , ARPAMT Evaluation ; MUC4) . Measuring the performance of an NLP method , approach or technique ( and through it the promise of a system based on it  ) is more difficult , as judgments must be made about " blame assigmnent " and the impact of improving a variety of system components on the overall future performance  . One of the widely accepted measures of potential performance improvement is the feasibility of scaling up the static knowledge sources of an NLP system its grammars  , lexicons , worht knowledge bases and other sets of language descriptions  ( the reasoning being that the larger the system's grammars and lexicons  , the greater percentage of input they would be able to match and  , therefore , the better the performance of the system l ) . As a result , a system would be considered very promising if its knowledge sources could be significantly scale dupata reasonable expense  . Natm ' all y , the expense is lowest if acquisition is performed automatically  . This consideration and the recent resurgence of corpus-based methods heighten the interest in the automation of knowledge acquisition  , l lowever , we believe that such acquisition should not 1 ) ejudged solely by the utility of acquired knowledge for ~ particular application  . 
A preliminary to these alability estimates is a judgment of the current coverage of a system's static knowledge sources  . Unfortunately , judgments based purely on size a ce often misleading  . While they may be sufficiently straightforward for less km  ) wledge Antensive methods used in such applications as information extraction and retrieval  , part of speech tagging , bilingual corpus alignment , and so on , the saute is not true about more rule - and knowledge-based methods  ( such as syntactic parsers , semantic analyzers , semantic lexicons , ontological world models , etc . ) . It ix widely accepted , for instance , that judgments of the coverage of a syntactic grammar in terms of the number of rules are tlawed  . It is somewhat less self-evident , however , that the number of lexicon entries or ontology concepts is not an adequate measure of the quality or coverage of NLP a Incidentally  , this consideration e ontributes to evMuation of current perforntance as well  . In the absence of actual evaluation results , it is customary to caim the utility of the system by simply mentioning t it  ( : size of its knowledge sources ( e . g . , " over 550 grammar rules , over 50 , 000 concepts in the ontology and over 100 , 00 ( I word senses in the dictionary ") . 
33 systems . A . nadequate measure of these must examine not only size and its scalability  , but also depth of knowledge along with its scalability  . In addition , these size and depth measures cannot be generalized over the whole system  , but must be directly associated with individual are as that cover the breadth of NLP problems  ( i . e . morphology , word sense ambiguity , semantic dependency , coreference , discourse , semantic inference , etc . ) . 
And finally , the most help fld measurements will not judge the system solely as it stands  , but must in some way reflect the ultimate potential of the system  , along with a quantification of how far additional work aimed at size and depth will bring about advancement toward that potential  . 
In this article , we attempt to formulate measures of coverage important othe development and evaluation of semantic systems  . We proceed h'om the assumption that coverage is a function of not only the number of elements in  ( i . e . , size of ) a static knowledge source but also of the amount of information  ( i . e . , depth ) and the types of information ( i . e . , breadth ) contained in each such element . Static size is often emphasized in evaluations with no attention paid to the often very insignificant amount of information associated with each of the many " labels " or primitive symbols  . 
We snggest a starting framework for measuring size together with other significant dimensions of semantic coverage  . In particular , the evaluation measures we propose reflect the necessary contribution of the depth and breadth of semantic descriptions  . Depth and breadth of semantic description are essential for progress in computational semantics and  , ultimately , for building largescale , general purpose NLP systems . Of course , for a number of applications a very limited semantic analysis  ( e . g . , in terms of , say , a dozen separate features ) may be adequate for sufficiently high performance  . However , in the long run , progress towards the ultimate goal of NLP is not possible without depth and breadth in semantic description and analysis  . 
There is a wellknown belief that it is not appropriate to measure success of NLP using field -internal criteria  . Its adherents maintain that NLP should be evaluated exclusively through evaluating its applications : information retrieval  , machine translation , robotic planning , humancomputer interaction , etc . ( see , for : example , the Proc . of the Active NLP Workshop ; ARPA MT Evaluation ) . This may be true for NLP users , but developers must have internal measures of success  . 
This is because it is very difficult to assign blame for the successor failure of an application on specific components of an NLP system  . For example , in reporting on the MUC3 evaluation efforts , 
Lehnert and Sundheim (1991) write:
A wide range of language processing strategies was employed by the top-scoring systems  , indicating that many natnral language processing techniques provide a viable foundation for sophisticated text analysis  . Further evaluation is needed to produce a more detailed assessment of the relative merits of specific technologies and establish true performance limits tbrautomated information extraction  . \[ emphasis added . \] Thus , evaluating the information extraction application did not provide constructive criticism on particular NLP techniques to enable advances in the state of the art  . Also , evaluating an application does not directly contribute to progress in NLP as such  . This is in part because a majority of current and exploratory NLP systems are not complete nough to fit an application but rather are devoted to one or more of a variety of components of a comprehensive NLP system  ( statice . g . , lexicons , grammars , etc . ; or dynamice . g . , an algorithm for " treating metonymy in English ) . 
1.1 Current Measures of Coverage
Success in NLP ( including semantic analysis and related areas ) is currently measured by the following criteria : ? Size of static knowledge sources : A mere nmn ber indicating the size of a knowledge source does not tell us much about the coverage of the system  , let alne its semantic apa-bilities . For example , most machine readable dictionaries ( MRI ) ) are larger than computational exicons but they are not usable for : computational semantics  . 
? Coverage of corpus , either blanket cover : - age ( "56% of sentences were translated correctly " ) or resolution of a certain phenomenon ( "78% of anaphors were determined correctly " )  . These measures are of l ; en misleading by themselves since what may be covered are just one or two highly specific phenomena such as recognizing place or product names  ( i . e . , limited breadth) . NLP is not yet at a stage where " covering a corpus " can mean " analyzing all elenmnts of meanings of texts in the corpus  . " It may be noted that " correctly " is a problematic term since people often have difficulty judging what is " correct "  ( Will ,  1993) . Moreover , correctness is orthogonal to the entire discussion here since we would like to increase semantic coverage along various dimensions while maintaining an acceptable degree of correctness  . On the same lines , processing efficiency ( often specified in terms such as " A sentence of length  9 takes 750 milliseconds to process " ) is also more or less orthogonal to the dimensions we propose for measuring semantic overage  . Increasing semantic ( : overage would be N tile if " C . rrentState iiiii ,,-~~:: . : i " Knowle de Base Figure 1: Dimensions of Semantic Coverage : ( hlr-rent and Desired l ) irections processing became xponentially expensive as a result  . 
Figure 1 shows the dimensions of size and breadth ( or phenomenon coverage ) along tit ( ' , horizontal plane . Depth ( or richness ) of a semantic system is shown on the vertical axis  . We believe that recent progress in NLP with its emphasis on corpus linguistics and statistic ~ d methods has re-suited in a significant spread a kmg the horizontal plane but little been done to grow the Iield in the vertical dimension  . Figure 1 also shows the desired state of computational semantics advmlced alorg each of the three dimension shown  . If We proceed from the assumption that high -quality NLI  ) systems require optimum coverage on all three scales  , the apparently different roads ( -an be taken to that target . The speet rmn of choices ranges from developing all three dimensions more or less simultaneously to taking care of them in turn  . As is often the case in king-term high-risk enterprises  , in any researchers opt to start out with acquisition work which promises shortterm gains on one of the coverage dimensions  , with little thought about further steps . Of_ten the reason they cite can be summarized by the phrase " Science is the art of the possible  . " This position is quite defensihle . . . . if no claims are made about broad semantic ( : overage . Indeed , it is quite legitimate to study a particular language phenomenon exclusively or to cover large chunks of the lexis of a language in a shallow manner  . I Iowever , for practical gains in largescale computational -selnantie applications one needs to achieve results on each of the three dimensions of coverage  . 
1.2 Desiderata for Large-Scale
Colnputational Semantics
Once the initial knowledge acquisition can q ) aign for a I ) articular apt ) lication has been concluded , the following crucial scalability issues 2 irast be addressed , if any tnderstanding of the longer-term significance of the research is sought : ? domain independence : scalability to new  ( lo-mains ; general-purpose Nl , l ) ? language independence : sealability across languages ? phenolnen on coverage : sealability to new phenomena  ; going beyond core semantic analysis ; ease of integrating component pro-e esses and resources  . 
? application-independence : sealability to new applications  ; toolkito\['NLP techniques applicable to any t ~sk  . 
We believe that coverage in terms of the det ) th and breadth of the knowledge given to an NLI ) system is mandatory for attaining the above goals in the long run  . Such coverage is bestest i ( nated not in terms of raw sizes of lexicons or world models but rather through the availability in them of information ecessary for the treatment of aw > riety of l  ) he no menain natural language issues related to semantic dependency bull  ( ling , lexical disambiguation , semantic on strain tracking and relaxation ( for the cases of unexpected input , including non-lijeral language as well as treatment of unknown lexis  )  , reference , pragmatic impact and discourse structure . The resolution of these issues is at the core of t  ) ost-syntactic text processing . We believe that one can treat the al ) ovephenomena only by acquiring a broad range of relevant knowledg elements for the system  . Onense-flfl measure for sufficiency of infbrmation would be an analysis of kinds of knowledge necessary to generate a text  ( or ( liMog ) meaning representation . 
For applications in which more procedural computational semantics is l  ) refl ~' rable , a corresponding measure of sutliciency should be developed  . 
There exist other , broader desiderata which are applicable to any All systet n  . They include concerns about system robustness , correctness , and efficiency which are orthogonal to the above issues  . EquMly important but more broadly applicable are considerations of economy and ease of acquisition of knowledge sources for example  , reducing the size of knowledge bases and sharing knowledge across applications  . 
2 At present , se~dability is considered in the field ah nost exclusively ~ ts propagation o\[then uln ber of entries in the NLP knowledge bases  , not the quantity and quality of information inside each such entry  . 
852 How to Reason about Depth,
Breadth and Size
A useful measure of semantic coverage must involve measurement along each of the three dimensions with respect o correctness  ( or success rate ) and efficiency ( or speed )  . In this first attempt at a qualitative metric , we list questions relevant for assigning qualitative  ( " tendency " ) scores to an NLP system to measure its semantic overage  . 
Our experience over the years has led us to the following sets of criteria for measuring semantic coverage  . I to we ver , we understand that the following are not complete or unique  ; they are representative of the types of issues that are relevant to measuring semantic overage  . 
2 . 1 Lex ica l Coverage ? ' lb what extent do entries share semantic primitives  ( or concepts ) to represent word meanings ? What is the relation between the number of semantic primitives defined and the number of word senses covered ?? What is the size of the semantic zones of the entry ? tlow many semantic features are covered ? ? How many word senses from standard human-oriented ictionaries are covered in the NLP-oriented lexicon entry ? ? What types of information are included ?- seleetional restrictions - constraint relaxation information syntax -semantics linking-collocations-procedural attachments for contextual processing -- stylistic parameters - aspectual  , temporal , modal and attitu-dinal meanings - other idiosyncratic information about the word ? and  , finally , the total number of entries in the lexicon . 
2.2 Ontological Coverage
The total number of primitive labels in a world model is not a useful measure of the semantic overage of a system  . At least the following considerations must be factored in : ? The number of properties and links defined for an individual concept ? Number of types of non-taxonomic relationships among concepts ? Average number of links per concept : " connectivity "? Types of knowledge included : defaults  , selectional constraints , complex events , etc . 
? Ratio of number of entries in a lexicon to number of concepts in the ontology ? and  , finally , total number of concepts in the ontology . 
2.3 Measuring Breadth of Meaning
Representations
Apart from lexical and ontological coverage , the depth and breadth of the meaning representations constructed by a system are good indicators of the overall semantic overage of the system  . Tile number of differentypes of meaning elements included fl ' om the following set provides a reasonable measure of coverage : ? Argument structure only ? Template filling only ? Events and participants ? Thematic role assignments ? Time and temporal relations ? Aspect ? Properties : attributes of events and objects  ; relations between events and objects . 
? R , eference and coreference ? Attitude , modality , stylistics ? Quantitative , comparative , and other mathematical relations * Textual relations and other discourse relations ? Multiple ambiguous interpretations * Propositional and story/dialog structure  3 Measuring Semantic Coverage :

Figure 2 shows the approximate position of several wellknown approaches and systems  ( including a possible Cyc-based system ) in the 3-dimensional space of semantic overage . We have chosen representative systems fl'om the different approaches for lack of precise terms to nametlle approaches  . 
How do the approaches illustrated in Figure 2 rate with respecto the metrics suggested above ' ? When estimating their profiles  , we thought either about some representative systems belonging to an approach or thought of the properties of a prototypical system in a particular paradigm if no examples presented themselves readily  . In the interests of space , we consider the above criteria for measuring semantic overage but only provide brief summaries of how each system or approach is located along the dimensions of depth  , breadth and size . 
The schema-based reasoner , Boris ( behnert et al ,  1983 ) was used as a prototype system for the 8g ++++++++++!!:i+:-+:::+::+ . 
+ +++++5++ i ~ i + + + + + + + +++5+i+i+?+++++++++++5+++++i  +++  5 i + i + + + i ~+ ii+i5++++++51+5~+++++++  ~! : : : : ,  +77:++ ++ +  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ~' ii . . . . . . . . . . . . .  ,  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Ix ~, tA . . . . . . . . . . . . . . . . . 
i ! iiii ' ,  :: : ?   iiii5~!iii!!5 ~: i ! 5   5!   7!!5  ~ ::::::::::::::::::::::::::::::::::::::::::::::: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : + : : ~ iiii : ! Sii : ~: s ~  ; ii ~: : : : : ! :!~ :! i ~ ~/ : i !!! i !: : ?!:!: : := : : ~ : ::: :::::::::::::::: ::::::::::::::::::::::::::: :: ~   5~!!!: ~: ~:!~ s : ~~: : : ?~: ! i . ' . ,~-: ::::  . . . . . . . . .  :":~ ::: :  , :!~ i ~ i : : : : : : ~: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : .  :::::::::::::::::::::::::::::: ~ :::: : : : : : : : : : : : : : : : : : : : : : : :  2: :::::!:!::!!!:i:::::::::::::::::::::::::::::::::: ::::::::::::: :::::::::::::::::::::::::::::::::::: ::::::::::::: :  ,   . ::: i:2:::::!::::f ?:::: i:: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . I "2;": . .  . . . . . . .  ~*~  . . . . . . . . . . . . .  : ~  . . . . . . . . . . . . . . . . .  ~  . . . . . . . . . 
? !:5!ii!i!iii!:ili ~ i i i i i i i i : i : i : i:i:i:i:i:5:!:i:?i :!~'!!!!! ii . ~ ::::: :::: ::?,~ . : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : ! ; : i : i ~: ~: i : i : : : : i i : : i i : ~! ~ : i ~\ [: : i . : : : : : : : : : t , ,:xx ::::::::::: : : : : : : : : : : : : : : : : :  : : : : : : : : ::::::::::~:: :  , "~:::::: hl::::::::::::::::::::::::::::::::::++::~:::i:i : : : : :!!: z  .   .  : : : : : : : : : : : : : : : : : : : : : : : : : : : i ~ i l i ~ i i i : : i i l  ) + : : i : ~ ti : : ~: ii:: ; : i:~:!i: . ~!! ~ i ! i ~ i ~ . ilili ~ ii ~ iii ~ i # . ~: i : ~: ii ~ v + if < : : : : : : : : : : : 5::::: ; :::::::::::::::::: ::::::::::::::::::::::: ::::::: ::::~::::::::::: qX::::::::: : : : : : : : : : : : : : : : a + + + + + + + + + + + + + + + + + + + ++ t+++++++++++++++++~+-:+~i ~+  i~2~+   ; + + g~i ~ i ) + ; ~ iii+++)Y:+~++:::::::::::::: ; ; . ; ~; ; ~ a : : : : : ~ , < E'I:~::::N~i ~++ : i / ~ i ~ : : : : ~' a::+"*~::i : i : i :  ; + JlKI ~+ p-'~':~:~9 . : ~ : : ~ i < ~ .  + ~ . ~ t::::::Figure2:l ) imensions of Semantic Coverage : Cur-+rent att ( tl ) esired l ) iree tions domain - and task-del ) endent , AI-style , schema-based NLP systc'm . It may I > e considered an extreme example of a system with deep  , rich knowledge of its , rather narrow , worhlin which cowwing language phenomena is nee ( ted only in as much as it supports general reasoning  . Boris was able to process a very smMl number of texts sutticiently for its goMs  . The coverage of phenomena was strictly utilitarian  ( which , we believe , is quite appropriate ) . lilt was not demoim tratext that Boris can be scaled up to  ( : over a signiticant part of the English lexicon . 
As an example of a nearly knowletlge-baset lMT system  ( thai , is , unlike the above , a system whose goals were mainly computational -litguistic  ) we chose the KBMT-89 system ( Goodman and Nirenburg ,  1991) . It covered its small corpus relatively completely and described the necessary phenomena relatively fldly  , lilt was a primary goal of this line of research to begin meeting the above criteria for semantic overage  . 
A pntative NIA ) system based on the ( ~yc project has been selected as a prototyl ) e for systems not devised h ) ra particular application . The Cy clarge-scMe knowledge base \] as significant amounts of deep knowledge  , l lowever , it is not clear whether the knowledge is a pl > licM ) leina straightff ) rward manner to deal with a range of linguistic phenomena  . The big question for this kind of system is whether it is  , in fact , possible , to acquire knowledge without a reference to an intended application  . 
A purely corpus--based , statistic M approach to NLP , on the other hand , has an extremely narrow range of knowledge , but , may haw ; a large size . For example , snchasy stem may have a large lexicon with only word frequency and collocation information in each entry  . Although sta-tistical methods have been shown to work on some problenm and applications  , they are typically applied to one or two phenomen at a time  . It is not rlear that statistical information acquired t brone problel n  ( such as sense disambiguation ) is of use in hmtdling other problems ( such as processing nonliteral expressions )  . 
Mixed-strategy NI , I~systems are epitomized by I'angloss (199d ) , a multi-engine translation system in which semantic processing is only one of the possible translation engines  . The semantics engine of this system is equipped with a large-size ontology of over  50  , 000 entries ( Knight and link , t99 d ) which is nsed essentially as a nam : hot for map l ) inglexicM traits front the 8otlrce to the tar . -gel , language . As shown in I , ' igure 2 , Pangloss has a large size and covers a good range of l  ) het , )m . 
em  ~ as well . l lowew ' , r , there is little information ( only taxonomic and part on olnie relationships ) in each concept in its Sensus ontology . The limited depth constrains the ultimate potentia  . 1 of the sys-tetn as a sent at d , ic and pragmatic processor . I " or exatnple , there is no hfl ' or tnal ; ion i its knowledge sources to make judgements about constr ~ fint re-laxal  , ionto process nonliteral expressions snch as metonymies and metal ~ hors  . 
The Mikrokosn to system ( e . g . , Onyshkevych an(t Nirenburg ,  1994) , has attempted to cover each dimension equally well  . Its knowledge bases and text meaning representations are rather deep and of nontrivial sizes  . It has been designed froln the start to deal with a comprehensiw  ; range ot'seman- . 
tic phenomena including the linldng of syntax attd semantics  , (-ore semantic analysis , sense disam-l ) iguation , I ) rocessing non-liter M expressions , SLIt(so on , althongh not all of them have yet been im plemented  . 
Front the abow ' ~ examples , it is clea . r that having good coverage along one or two of the three dimensions is not good enough for meeting the long term goMs of NI  , P . Poor coverage of language phenomena ( i . e . , poor brea , dth ) indicates that the acquired knowh ; dg e , even when it is deep and large in size , may not be applicable to other phenomena and may not transfer to other applications  . 
Poor depth suggests that knowledge and processing techniques are either application - or language -specific and limits the ultimate potential of the system in solving semantic problems  . Depth and breadth are of course of little use if the system cm motb cscaled up to a signilicant size  . Moreover , as already noted , cow ; rage in depth , breadth , and size must all be achieve tlin conjnnction with maintaining good me  , as nres of correctness , et\[i-ciency , and robustness . 
4 Discussion and Conclusions
All oft-quoted objection to having deep semantic ( : overage is the dilliculty in scMing up such a system along the dimension of size  . This is a valid concern , l lowever , the situation (: an beamelio-ology ( see , e . g . , Mahesh and Nirenburg ,  1995 ) for constraining knowledge acquisition to minimally meet semantic processing needs  . Such concentration of effort will allow knowledge acquirers to have spend a fraction of the effort that must go into building a general machine -tractable encyclopedia of knowledge and yet to attain significant coverage of language phenomena  . Significant scale up can be accomplished under such a constraint without jeopardizing the high values on the depth and breadth scales  . 
Size is important in NLP . But size alone is not a sufficient metric for evaluating semantic over-age  . Focusing on size to the exclusion of other criteria has biased the field away from semantic solutions to NLP problems  . We have made a first step informulating a more appropriate and complete set of measures of semantic overage  . Depth and breadth of knowledge necessary to cover a wide range language phenomena are at least as important to NLP as size  . The discussion of peculiarities of the various approaches should be expanded in at least two directions - greater detail of description and analysis of the relative ditficulty of reaching the set goal of attaining an optimum value on each of the three measurement scales  . We hope that this paper will elicit interest in contin-ned discussion of the issues of coverage measurement  , which , in turn , will lead to better -- quantitative as well as qualitative-measures  , including a methodology for comparing lexicons and ontologies  . 

Many thanks to Yorick Wilks for his constructive criticism  . 

Active NLP Workshop : Working Notes from the AAAI Spring Symposium " Active NLP : Natural Language Understanding in Integrated Systems " March  2123  ,  1994 , Stanford University , California ( Also available as a Technical Report from the American Association for Artificial Intelligence  )  . 
AIPA MT Evaluation : Report of the Advanced Research Projects Agency  , Machine Translation Program System Evaluation , May-August 1993 . 
Goodman , K . and S . Nirenburg ( eds .) (1991).
The KBMT Project : A Case Study in Knowledge-Based Machine Translation  . San Marco , CA:
Morgan Kaufmann.
Knight , K . and Luk , S . K .  (1994) . Building a Large-Scale Knowledge Base for Machine Translation  . In Proc . Twelfth National Conf . on Artificial Intelligence , ( AAAI-94) . 
Leant , D . B . and Guha , R . V .  (1990) . Building Large Knowledge-Based Sysiems . Reading , MA:

Lehnert , W . G . , Dyer , M . G . , Johnson , P . N . , Yang , C . J . , and Harley , S .  (1983) . BORIS-An Experiment in In-I ) epth Understanding of Narratives . Artificial Intelligence , 20(1):15-62 . 
Lehnert , W . G . and Sundheim , B .  (1991) . A performance evaluation of text-analysis technologies  . AI Magazine , 12(3):81-94 . 
Mahesh , K . and Nirenburg , S .  (1995) . A situated ontology for practical NLP . In Proceedings of the Workshop on Basic Ontological Issues in Knowledge Sharing  , International Joint Conference on Artificial Intelligence  ( IJCAI-95 )  , Montreal , Canada , August 1995 . 
MUC4: Proc . Fourth Message Understanding Conference ( MUC4) , June 1992 . Defense Advanced Research Projects Agency . Morgan Kanf-mann Publishers . 
Onyshkevych , B . and Nirenburg , S .  (1994) . The lexicon in the scheme of KBMT things . Technical Report MCCS-94-277 , Computing Research Laboratory , New Mexico State University . Also to appear in Machinerlh ' anslation . 
Pangloss . (1994). The PANGLOSS Mark Ill
Machine Translation System . A Joint Technical Report by NM SUCRL , USCISI and CMUCMT , 
Jan . 1994.
Will , C . A .  (1993) . Comparing human and machine performance for natural anguage information extraction : Results from the Tipster evaluation  . Proc . Tipster Text Program , ARPA , Morgan Kaufmann Publishers . 

