Lexical Transfer:
Betweena Source Rock and a Hard Target
Alan K . MELBY
Department of Linguistics
Brigham Young University
Prove , Utah 84602

Abstract
Lexical transfer is the point of transit ion between an unchangeable source text  ( a rook ) and an infinite array of target texts ( a hard place to find an acceptable one )  . The author's Coling 86 paper ( pp .  104-106 ) described a new methodology for testing lex ical transfer in machine translation  . This paper reports on the application of that methodology to a test of the DLT system and describes a synchronized bilingual data base by product  . Further use of the methodology is encouraged . 
Topic : Evaluation of machine translation Additional Topic : Text databases I  . DEFINITION OFLEXICAL TRANS FER Although the term lexical transfer applies most direc tly to machine translation systems based on a linguistic model of analysis  , transfer , and generation , it can also be applied to systems in which there is no direct correspondance between source and target words  ( f~uch as interlingual systems ) by defining lexieal transfer as the point in processing where the target lexical forms first appear  . It is the crucial point a L which all the info rmation available in the system must be brought to bear on the problem of choosing lex ical forms  . The ehoiees must be appropriate , or all the sophistication of the system in other areas such as word order and discourse markers will be of no avail in producing acceptable output  . 
Lexical transfer must be based on the source text  , which is generally a given . That is , one cannot come back during the evaluation of the output and suggest that the source text be changed to better match the target text  . Thus the source text can be compared to a reckor to a text carved in stone  . The target text , on the other ' h and , is supposedly somewhere in an infinite col lection of texts composed of members of an inf inite set of sentences generated from a large f inite set of lexical items  . Even if one could list in advance all the poss ible translations for each word  , which one cannot , the task is daunting . Thus the space of all target language texts is a hard place in which to find an appropriate one  . For those readers not familiar with the say ing " between a rock and a hard place " on which the title of this paper is based  , I mention that it refers to a difficults ituation in which all apparent options present problems  . Of course , the title twists the saying in several ways . Its purpose is both to emphasize the diffi culty of lexica \] transfer and to illust rate it  . The illustration is this : Please trans late the title into some other language  , basing it on an equivalent target language saying adjusted to describe lexical transfer  . It is novel situations that make \] exica \] t ransfer truly difficult to program for  . 
2. BACKGROUND
At COLING 86 , the author presented a methodology for testing the \] exical transfer mechanism of a mach ine translation system  . Since then , the proposed test has been performed on a near lyversion of the DLT  ( Distributed
Language Translation ) machine translation system . This paper will describe the results of the test  . In the course of performing the test , a bilingual database of French and Engli sh texts was produced  . This database consists of paired documents with will also describe the database  , which has been edited and is now available to qualified researchers for a small fee  . 
3. TUNING DISTORTION
A good methodology for testing lexical trans fer must avoid the trap of " tuning distort ion "  . Tuning distortion refers to the mislead ing  ( distorted ) results obtained from a machine translat ion system when its dictionaries and algori thms are adjusted  ( tuned ) to a particular text . Almost any machine translation system can produce brilliant results when the same text is run through it again and again with successive tuning  . The power of tuning is ~ e\]l-known and has been given a name in AI research  , namely , defining a miero world . Corresponding to this power is the well- known difficulty of expanding a microw or ld system to function intelligently in a macro world  . 
In a machine translation system , difficulties arise when a tuned sys tem 
Js applied to a new text.
4. THE WORDLIST APPROACH
To avoid tuning distortion in a test of lexieal transfer  , one can build a dictionary from a word list without knowing what text will be supplied later  , except that it will consist of words from the word list  . This approach has significant advantages over supplying an arbitrary text and upgrad ing the dictionaries to handle the text  , because there is a conscious or unconscious tuning of the dictionary entries during the upgrade process so long as the text is availab le  . 
In the word list approach , all the words of the text are combined with a number of misleading words which make it d if ficult to tell what is the subject field of the text  . Then the combined words are sorted into a lphabetical order and reduced to their basic forms  . The alphabetic word list is supplied to the machine translation dictionary updaters and the dictionaries are stabilized  . 
Then the text is provided and immediately t ranslated without any updates to the system and without any words missing from the dict ionaries  . 
If one argues that this method forces the dict ionary updaters to consider too many possible collocations of each word in the list  , one is simply eomplaining about the diffi culty of handling real text  . At least this method allows realistictes ting of a system BEFORE its dictionaries have reached full size  . If there is a problem in the system design , it is better to find out with dictionaries of one thousand words and all their collocat ions than after the dictionaries contain th irty thousand words  . 
5. SOMERESULTS FROM THEDLT TEST
The DLT machine translation project is a venture of the BSO company in Utrecht  . The word list approach was used to test its lex ical transfer phase even before the syntact i canalysis phase was complete  . This was done by manually analyzing the test sentences  . The four test passages included over 2000 word tokens which reduced to about 600 content word types , to which were added about 200 misleading words . The word list of about 800 words was used to build dictionaries conta ining thousands of entries  . 
After the texts were translated by the DLT system from English to French  ( during the first quarter of 1987 )  , they were compared with official versions of the texts prepared by professional humant ranslators at the CEC  . This comparison revealed that many words matched the official language versions  , some were acceptable synonymns and , as expected , some words were translated inappropriately . The DLT project is becongratulated on the overall success of the experiment  . The problem words to be discussed in the paper are not intented to be simply a critici sm of DL'rbut rather observations that may be of interest to all machine translation researchers  . Some inappropriate translations would be easily corrected by detecting predictable collocations  . 
In the DLT test , the collocation software was not operation a l  . For example , computer-assisted requires a particular t ranslation of assisted  . 
Another problem is bring , which can sometimes be translated as faire venir but which is normally translated as prendre in the context of the expression bring x to y's consciousness  . This requires syntactic transfer of a type the DLT project calls metataxis and which was not implemented for the test  . 
In a recent issue of Language Monthly ( December 1987 , p .  7) , it was reported that Peter Lau , of the Eurotra project , said , at the 1987 As lib conference , that the real problem of machine translat ion is not the " reduction of structural di fferences " b~t rather the " disambiguation of lexical entries "  . 
The DLT test focussed on such lexical transfer problems  . 
Some words of interest from the test are : hardware  , area , sheet , pratice , giving , perform , produce , schedule , concern , field , application , induced , lead , benefit , covers bachel or , courses duty , and form . 

For each of the above words , the DLT system produced a translation which was not appropriate to the context  . These were not the only mistakes , but on the other hand , the DLT system translated the majority of the words  ( 60 percent ) aocept ~ bly , while a fourth ( 25 percent ) were problems for one reason or another , with I~percent in the gray area between a ceept ? ~ bility and unacceptability  . 
The reader is invited to consider how these words would be handled in his or her system  , be it machine transl ~ tion , content analysis , or other natural language processing system . How would the proper distinctions be made or an appropriate translation for these words be found without being tuned to a part icular text or sublanguage ? Not surpris ingly  , the word hardware needs ~ special translat i on when referring to computer hardware  . But into day ' E ~ technical documents , there can be reference to computers but also to hardware in a more general sense or in refe rence to tools or weapons  . How can the appropriate selection be made w it hout an enormous world model and a system which truly understands the text ?  ( Shades of Bar-Hillel ) Another example is the word area , which can be translated r~gion or pattie . However , these two options are not interchangeable and the distinction is subtle and not dependent on predictable collocations  . A sheet can be a drap ( on a bed ) , a feuille ( of paper ) , or a lame , depending on context . Unfortunately for lexica \] transfer , the word sheet will not always be followed by a prepositional phrase indicating the composition of the sheet  . 
A practice can be what a medical doctor does when treating people  , what a musician does to get ready for a concert  , or what is normally done in some endeavor . These three may be translated different ly  . 
The verb form giving can refer to a transfer of an object to someone or to a result  ( " one plus three gives four " )  . 
To perform can refer to one's normal duty or to a stage performance and may be translated di fferently  . Likewise , to produce can translate differently , depending on whether one is talking about ap liy Or factor y  . 
The reader can use a standard dictionary to see the difficulties in the following words : so he dule  ( time table or price list )  , coneex ~( interest or anxiety ) , field ( literal area ofter rain or figurative fie ld of interest  )   , application ( treatment or level of effort ) , induced ( social or electromagnetic pressure )   , lead ( awire or a sales contact ) , benefit ( advantage or government payment ) , cover ( lidor abstract limit ) , duty ( obligation or import tax ) , and course ( path or aoad memic class ) . 
Two of the words in the list involve an element of poetic justice  . Katz and Fodor distinguished the academic degree and unmarried man readings of bachel or with markers  , but did not tell DLT how to distinguish between them when the word is encountered in text  . And the translation of form depends on its ( ~ ontent . 
6. THEBILING UALD AT ABASE
Preliminary to the DLT test , a corpus of texts was gathered to assist in d ictionary development  . A portion of the corpus was kept secret and the test passages were chosen from this portion  . 
A larger portion was made available to the DLT project for lexical studies  . 
The Waterloo concordance system was Used to generate KWIC listings for the lex icographers to observe the various uses of words in actual texts  . 
The bilingual database used in the test was derived from public domain documents of the CEC and the United Nations  , to avoid copyright problems . 
It consists of twenty documents , each with an English and a French version , on subjects ranging from migrant workers to the ESA space labto the automobile industry to a gr i culture  . The documents were first scanned using a Kurzweil OCR device  . Then the disk files were hand-edited into 400 small synchronized files , 200 English and 200 French , representing a total of about eight megabytes of data  ( i . e . over one million words ) . As of this writing , the small files are being further proofed aga inst the original documents  , and the paragraphs or other logical units of the texts are being synchronized by editing in segment number marks  . These marks are used by a simple preprocessing program to produce synchronized two-column bi lingual output for indexing by Word Cruncher  , a new dynamic concordance system which has become available since the project began  . This two-column format will facilitate the study of all occurrences of words or expressions with the other language segment automatically displayed to allow the researcher to quickly see how that word or expression was translated in the corpus  . 
The edited corpus is available with permiss ion of BSO for a modest feet oqualified researchers  . It is hoped that the corpus , the word list methodology , and the results of the DLT test will be of use to others in the machine translation community  . 

