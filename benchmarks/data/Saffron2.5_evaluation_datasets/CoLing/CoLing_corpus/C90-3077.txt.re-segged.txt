The GENL Tools et :
A Software Foundation for Intelligent Text Processing 
Paul S . Jacobs and Lisa F . Rau
Artificial Intelligence Program
CI'; Research and Development Center
Schenectady , NY 12301 USA
rau ~ crd . ge . com , psj acobs C~crd . ge . com Many obstac lest and in the way of computer programs that could read and digest volumes of natural language text  . The fore most of these difficulties is the quantity and variety of knowledge about language and about the world that seems to be a prerequisite for any substantial language understanding  . 
In its most general form , the robust text processing problem remains insurmountable  ; yet practical applications of text processing are realizable throng ha combination of knowledge representation ad language analysis strategies  . 
This project note describes the GENL Too~s ~ , : T and its use in two text processing applications  . In the first , dornain , the system selects and analyzes to-ries about corporate mergers and acquisitions as they come across a realtime news feed  . In the second do ~ main , the program uses n aval operations messages to fill a  10--field template . In both cases , users can ask natural language questions about , the contents of the texts , and the system responds with direct answers along with the original text  . 
The GENLTooLsET is a software foundation for text processing  . The NL'I'OOLS ~?' r derives from a research effort aimed at preserving the capabilities of natur M language text processing across domains  . 
The program achieves this transportability by using a core knowledge base and lexicon that customizes easily to new applications  , along with a flexible text processing strategy tolerant of gaps in the program's knowledge base  . Developed over the last four years , it runs in realtime on a SUNTM workstation in Common Lispunder UNIX TM  . It performs the following tasks : ? The lexical analysis of the input character stream  , including names , dates , numbers , a , ndeorttractions . 
? The separation of the raw news feed into story structures  , with separate headline , by line and dateline designations . 
? A topic determination fbreach story , indicating whether it is about a corporate merger . 
? The natural language analysis of each selected story using an integration of two interpretation strategies --" bottom-up " linguistic analysis and " topdown " conceptual interpretation  . 
o The storage and retrieval of conceptual representations of the processed texts into and out of a knowledge base  . 
The design of the NLT oo LsET combines artificial intelligence  ( AI ) methods , especially natural language processing , knowledge representation , and information retrieval techniques , with more robust but superficial methods , such as lexical analysis and word-based text search  . This approach provides the broad flmctionality of AI systems without sacrific in grobnstness or processing speed  . In fact , the system has a through put for real text greater than any other text extraction system we have seen  ( e . g . , \[ Sondheimer , 1986; Sundheim ,  1990\]) , while providing knowledge-based capabilitie such as producing answers to English questions and identifying key conceptual roles in the text  ( such as the suitor , target , and per- . share price of a merger offer ) . The NL-TooLs ~' r consists of roughly 50 , 000 lines of Common Lisp code . It was developed entirely on SUN workstations . 
1 Technical Overview
The NLTO oLSFT's design provides each system component with access to a rich handcoded knowledge base  , but each component applies the knowledge selectively  , avoiding the computation that a complete analysis of each text would require  . The architecture of the system allows for levels of language analysis  , f?omrough skimming\[Jacobs ,   1990\] to in depth conceptual i : nter pretation \ [ aa cobs ,  1987\] . 
A custom-built 10 , 0 00 word-root lexicon and concept hierarchy provides a rich source of lexical information  . Entries are separated by their senses , and contain special context clues to help in the sense disambiguation process  . A morphological analyzer contain semantics for about  75 affixes , and can automatically derive the meanings of inflected entries not separately represented in the lexicon  . Domain-specific words and phrases are added to the lexicon by connecting them to higher-level concepts and categories present in the system's core lexicon and con~cept hierarchy  . This is one aspect of the NLTOOLSET that makes it highly portable from one domain to another  . 
The language analysis strategy used in the NL -TOOLSET combines full syntactic  ( bottom-up ) parsing and conceptual expectation-driven ( topdown ) parsing . Four knowledge sources , including syntactic and semantic information and domain knowledge  , interact in a flexible manner . This integration produces a more robust semantic analyzer that deals gracefully with gaps in lexieal and syntactic knowledge  , trans-1373 . ~ mi ~: . ' ~ : V & ~ .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
Article Number : 4
Classlflcation : Takeover ~ . A . IIANNACO . ACQUIRES ~ RU ( ~ ( PLASTICSCO?CLE VELAND-DJ-M . A . HANNACO . SAIDIT : OMPI . ETEDITS PREVIOUSLY REPORTED ACQUISITION OF ~ RUCKPLASTICSCO  .   , A POLY MERRESINS DIST RIBUTOR 9ASED NEARCHICAGO , FOR UNDIS CLOSED TERMS . 
BRUCKHAS ANNUAL REVEHDEO FABOUT $ I00~ILLION.
-0-928 AME DT04-03-89:"?; .   .   .   . , , i ~ mm .  #m+<,i ' . IIi IIII-tcle Mo . :20 ar ~%: May fair Super Harkets
TA~....
AH:icle Mo .: 37
Tar ~%: Major Realty
Suitor : Stone ridge * ~* n ~ TICLE 4 STORY REPRESENTATION ~*
C-CORP-TAKE OVER
R-SUBEVENT : VERB_COMPLETEI
R-TARGET :
C-BUSINESS-ORG
R-CO-SALES : $ 100,000,000
R-NAME : Bruck Plastics
R-SUITOR :
C-BUSINESS-0RG
R-NAME : MA Hanna
L9: Copperal ~ rN . ~, aay 131 . 80 dn . 80\]ly 124 . 50 da 1 . 50 platinu ~ apr 526 . 0 0   ~0: I~r fair 9mrs lmyout p ~ posal +~1: Burgerkingnyse opening prices ~+2: McaIn copening delayed-order il balance-last selsctronlcs outlook  \]3: Poehl-bundes bank-in % ervent lon !4: I h , srnight97-8-3-4"to ~ , -next g 7-   8-   3-   4 sloo%-next 9   7-   8-   3-   4   7   25:   7 Cazhrvsopnet 9 c 215: ~d  ~ C8~?  . za \] ~$9 . 75 ~ ~ hrle ~ Jer ~ m ~ ~ m ~ le % ~27: CORP . claszb's last sale was 27-8 . 
+--  . , ; , r , tn . m~m .   .   .   .   .   .   .   .   .   .   .   . , ~6\]~ne/ho~e/~culp to ~/ u2/~~upka/nlt2 . 0/Tooltool / ~ ~ . 4/tool tool ~ f . . . 

Ray Text . ~"--(3 ~ Tokenized Article "* JL , + tlcl . No . : 51 d\[, . _ . O~ . d ~ J t ?-+ ow v . j ~ ~ ~ Ill .   .   .   . ' " Target : American Building Kaintenaucet /'' ~''++----~-~---- It ~ m~esUo ~ +   . 99 = ~ ~ ~  .   .   .   . - ~ l ~ + + m - .   .   .   .   .   .  __ _ - ,  . . . . . . . . . . . . . . . . ~ t~r the article number : 4 ~ ~ i + ~+ + + ~ + + : + ~ + + + + + + + + + + + ~ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +~++~++++++++++++~m+~  . `~+++++~++++++~i+++i++i~+++~+++++++++++++++++~;+++P:++++~++++++++~+++++++++++~:~:++ . ~++++t+++~++~+++++++~ . ~'~+ . ~ . ~++~+++++i++++#~++++++~~~
Figure h S cl so a in action ports easily to new domains  , and fanilitates the extraction of information from texts \[ Rau and Jacobs  ,  1988\] . 
Two prototype systems ( both to be demonstrated at Coling ) illustrate some of the capabilities of the NLT oo LSET  . SCI SOR ( System for Conceptual Information Summarization , Organization , and Retrieval ) reads financial news stories from a news service , selects stories about mergers and acquisitions , extracts key pieces of information from those stories  , and answers English questions about this information  . MUCK-II ( a demonstration from a message understanding conference in  1989 \[ Sundheim , 1990\]) shows some of the same capabilities , including database generation , question answering , and automatic alert , applied to a set of naval messages ( OPREP-3) . Both systems process texts at a rate of hundreds of paragraphs per hour  . The customization of the NLTO oLSET to the MUCK-II application  , porting from the domain of corporate take overs to naval operations  , required only several weeks . 
2 SCISOR
SCISOR is a customization of the NLTOOLSET to the domain of news stories about mergers and acqui -sitions  . The program analyze stories a . s they come across a live news feed , selecting the take over stories and applying a combination of topdown and bottom-up language analysis to identify conceptual roles in the stories  . The result of this analysis is a single representation of each story that the program adds to a central knowledge base  . The conceptual retrieval component accesses information from this knowledge base by analyzing English questions in the same manner and matching the questions to the story representations stored in the knowledge base  . 
ScBoR provides the user with information in multiple forms  . Users can browse the headlines and the original texts  . A " hot window " continuously displays the target  , suitor , and price of the latest take over stories , and flashes when a new take over story comes across the wire  . For more general information eeds , an " ask question " window allows the user to type in simple English questions  ( e . g . , " What was offered for Polaroid ?" ) as well as query fragments ( e . g . , 3742" acquisitions by Shamrock ") . 
Figure 1 shows a SUN screen during the operation of SC lsoR  . The " Master Control " window in the lower right allows the user to open or access the variou  , ' ~ features of the system . The " Ieadlincs " and " Display Control " in the lower centers how the headlines of all stories  ( with headlines of take over stories in bold ) and guide the selection of texts for browsing . 
The " Hot Window " , or alert feature , is at the lower left , alerting users the instant a new , potentially relevant article comes across the newswire  . The " RawText " and " Trump Representation " windows at the top display each selected story  , showing key portions of text in boldface with a summary of the language analysis in the upper right  . 
More details on the system design and operation of SCISOR can be found in \[ Jacobs and Rau  ,  1990\] . 
3 Performance Evalution
Performance valuation of natural language systems is a new problem  , although the evaluation methods can adopt some of the techniques of traditional information retrieval  ( IR ) systelns . It would be difficult and probably futile to perform a controlled study of the NLTOOLSET against a traditional IR system  , for two reasons : ( 1 ) traditional IR systems are tested on ~ bitrary , unconstrained texts , while natural an-guage system still work only in constraine domains  ;   ( 2 ) the NLTOOLSET performs many tasks other than document retrieval  , such as extracting information from stories and directly answering users ' questions  . 
Evaluation problems of the entire system stem from the unique functionality of the NLTO oLS ~  ; T system . 
Document retrieval systems , even sophisticated ones like RuBRIc\[Tong et al ,  1986\] , do not extract features from from the documents they retrieve  ; thus it is impossible to compare them to NI , Too LsET . tfow-ever , we have performed some tests that do measure the NLT oo LS~T's accuracy in specific tasks  . 
The government-sponsored MUCK-II evaluation is , to our knowledge , the most meaningful test of natural language text processing  , but the participants in the MUCK-II evaluation agreed not to release the specific results of the experiment  . I to we ver , we will try to summarize the status of performance valuation in general terms  . Evaluation of content-based text processing systems like SclsoP ~ is not nearly as established as evaluation methods in information retrieval  . There are many tasks to be tested in this emerging type of system  , including accuracy of question answering , helpfulness of alerts , and coverage of structured information ( such as target and suitor )  . 
No mature methods exist for testing any of these tasks  . 
In spite of the problems with evaluating this sort of system  , we would like to be informative about how our program performs  . As a rule , it can extract key features from large sets of constrained texts with  80-90%   ( combined recall and precision ) accuracy . It can achieve better results ( and has ) with more constrained texts , but would also produce almost nothing useful , say , in reading the entire Wall Street Journal . It is realistic to expect 90% accuracy for certain usef lfl , carefifly-constructed asks , and unrealistic to expect much higher than this 1 . Many ditficulties in reading texts appear when trying to achieve better results  , but the most common limitation seems to be the degree of real inference required for understanding  . In spite of its fairly sophisticated methods for combining linguistic and world knowledge  , the NL-TOOLSE'r really has very little of the latter  . 
In a recent test of ScISOR , the program analyzed one day's worth of stories directly from the newswire source  . Of the 729 stories , the filter achieved slightly over 90% averaged recall and precision in its determination of which stories were about mergers and acquisitions  ( 69 in all )  . Sclso~t correctly identified the target and suitor in  90% of all the stories . When dollar-per-share amounts of offers were present in the stories  , Sclso~t extracted this quantity correctly 79% of the time , and the total value of the offer 82% of the time . 
References\[DeJong , 1979\] Gerald DeJong . Prediction and sub-stantiation : A new approach to natural language processing  . Cognitive Science , 3(3):251---273, 1979 . 
\[Jacobs and Ran , 1990\] Paul Jacobs and Lisallau . 
SCISOR : A system t brextracting information from online news  . Communications of the Association for Computing Machinery  ,  35 , ( in . $ ubm . is-sion ) 1990 . 
\[Jacobs , 1987\] Paul S . Jacobs . A knowledge framework tbrnatura language analysis  . In Proceedings of the Tenth International Joint Conference on Artificial Intelligence  , Milan , Italy ,  1987 . 
\[Jacobs , 1990\]P . Jacobs . To parse or not to parse : Relation ~ driven text skimming  . In Proceedings of the Thirteenth Inter'national Confere T~ce on Computational Linguistics  , IIelsinki , Finland ,  1990 . 
\[Rau and Jacobs , 1988\] Lisa F . Rau and Paul S . Jacobs . Integrating topdown and bottom-up strategies in a text processing system  . In Proceedings of Second Conference on Applied Natural Language Processing  , pages 129-135 , Morristown , NJ , Feb 1988 . ACL . 
\[Sondheimer , 1986\]NS on dheimer . Proceedings of DARPA's 1986 strategic computing natural language processing workshop  . Technical Report ISI/SR-86-172 , University of Southern California , 
ISI , 1986.
\[ Sundheim , 1990\] Beth Sundheim . Second message understanding conference ( MUCK-II ) test report . 
Technical Report 1328 , Naval Ocean Systems Center , San Diego , CA ,  1990 . 
\[Tong et al , 1986\] Richard M . Tong , L . A . Appel-baum , V . N . Askman , and J . F . Cunningham . 
RUBRICiII : An object-oriented xpert system for information retrieval  . In Proceedings of the 2nd Annual IEEE Symposium on Expert Systems in Gov-e ~ nrnent  , W ~ hington , DC . , October 1986 . IEEE
Computer Society Press.
1 The I " lUMP\[DeJong , 1979\] program , for comparison purposes , achieved 38% accuracy in one test on newswire stories . 

