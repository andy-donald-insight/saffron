A Multilingual News Summarizer
Ilsin-Hsi Chen
l ) epart lnent of Computer Science and
Information Engineering
National Taiwan University
Taipei , TAIWAN , R.O.C.
hh chen@csie.ntu.edu.tw
Chuan-Jie Lin
Defmltment of Computer Science and
Information Engineering
National Taiwan University
Taipei , TAIWAN , R.O.C.
cjlin@nlg2.csie.ntu.edu.tw

Huge multilingual news articles are reported and disseminated on the Internet  . l to w to extract the k cy information and savc the reading time is a crucial issue  . This paper proposes architecture of multilingual news suml narizer  , including monolingual and multilingual clustering  , similarity measure among lneaningfulull its , and presentation of summarization results . Translation an long news stories , idiosyncrasy among languages , it nplicit information , and user preference are addressed . 

Today many websites on the lnternet provide online news services  . Multilingual news articles are reported periodically  , and across geographic barrier to disseminate to readers  . Readers can access the news stories conveniently , but it takes much time l ' or people to read all tile news  . This paper will present a personal news secretariat that helps online readers absorb news information from multiple sources in different languages  . 
Such a news secretariate liminates the redundant information in tile news articles  , reorganize stile news for readers , and helps them resolve the language barriers . 
Reorganization of news is sonic sort of document summarization  , which creates a short version of original document  . Recently , many papers touch on single document summarization  ( ltovy and Marcu , 1998a ) . Only a few touch on multiple document sulnmarization  ( Chen and Huang , 1999; Mani and Bloedorn , 1997; Radev and McKeown ,  1998 ) and multilingual document summarization ( Hovy and Marcu , 1998b ) . For multilingual multiple news summarization , several issues have to be addressed : ( 1 ) Translation among news stories in different languages 
The basic idea in multiple doculnent sulnmarizations i to identify which paris of news articles present similar reports  . Because the news stories are in different languages  , seine kind of Iranslation is required , e . g . , term translation . 
Besides the problem of translation ambiguity , different news sites often used if l'erent names to refertile same entity  . The translation o1' named entities , which are usually ttn known words , is another probleln . 
(2 ) Idiosyncrasy among languages 1 ) ifferent languages have their own specific features  . For example , a Chinese sentence is composed of characters without word boundary  . 
Word segmentation is indispensable for Chinese.
Besides , Chinese writers often assign l ~ unctuation ntarks at rand onl  , how to determine a mealfingful unit for similarity checking is a crucial issue  . 
Thus seine tasks may be done for specific languages during SU lnmarization  . 
(3 ) hnplicit information in news reports Some information is ilnplicit in news stories  . 
For example , the name of a country is usually not mentioned in a news article reporting an event that happened in that country  . On the contrary , the country name is important in foreign news . 
Besides , time zone is used to specify date/time implicitly in the news  . 
(4) User preference
When users want to read documents in their familiar languages  , news fragments in some N l . lnlnlary Nillllmal'y Sullllllary , ~  11111111 al ' yltlrl ' venl 1 for livent 2 for livem 3 for Eventm
Figure 1. Architecture of
Our Multilingual Sunmmrization System languages are preferred to those in other languages  . 
Even machine translation should be introduced to translate news fragments  . Besides , if a user prefers the news from tile view of his country  , or more precisely , of some news sites , we should mee this need . 
Figure 1 shows the architecture of a multilingual summarization system  , which is used to sulnmarize the news from multiple sources in different languages  . It is composed of threem ~ tior components : several monolingual news clusterers  , a multilingual news clusterer , and a news summarizer . Tile monolingual news clusterer receives a news stream from multiple on  . -line newspapers in its respective language , and directs them into several output news streams by using events  . The multilingual news clusterer then matches and merges the news streams of the same event but in different languages in a cluster  . 
The news summarizer summarizes the news stories for each event  . 
The possible tasks for each component depend on the languages used  . Some major tasks of a monolingual clusterer are listed below  . 
(1 ) identifying word boundaries for Chinese and Japanese sentences  , (2) Extracting named entities like people , place , organization , time , date and monetary expressions ,   ( 3 ) Clustering news streams based on predefined topic set and named entities  . 
The task for the multilingual clusterer is to align the news clusters in the same topic set  , but in different languages . It is similar to document alignment in comparable corpus  . Named entities are also useful cues . 
The major tasks for the news summarizer are shown as follows  . 
(1 ) Partitioning a news story into several meaningful units  ( MUs )  , (2) Linking the lneaningful units , denoting the salnething , from different news reports ,   ( 3 ) Displaying the summarization results under the consideration of language type users prefer  , information decay and views of reporters . 
1 . Clustering 1 . 1 Monolingual Clustering We adopt a two-level approach to cluster the news t  ) o111 multiple sources . At first , news is classified on the basis of a predefined topic set  . 
Then , tile news articles in the same topic set are partitioned into several clusters according to named emities  . Classification is necessary . Oiltile one hand , a famous person may appear in many kinds of news stories  . For example , President Clinton may make a public speech ( political news )  , join an international meeting ( international news )  , or even just show up in the opening of a baseball game  ( sports news )  . On the other hand , a common name is flequently seen but denotes different persons  . Classification reduces the ambiguity introduced by famous persons and/or common names  . 
An event in a news story is characterized by five basic entities such as people  , affairs , time , places and things . These entities form important cues during clustering  . Systems for named entity extraction in a famous lnessage understanding competition  ( MUC ,  1998 ) demonstrate promising performances for English , Japanese and Chinese . 
In our multilingual summarization system , we focus on English and Chinese . Gazetteer approach is adopted to deal with English news articles  . Comparatively , Chinese news articles are segmented at first . Then , several types of inforlnation fiom character , sentence and text levels are employed to extract Chinese named approaches illtile papers  ( Chen and Lee ,  1996;
Chen , elal ., 1998a).
1.2 Multilingual Clustering
Tile multilingual clusterer takes input from the lnonolingual clusterers  , and determines which news clusters ill which languages talk about tile same story  . Recall that a news cluster consists of several news articles reporting tile same event  , and one news cluster exists l brone event ariel monolingual clustering  . Ill this way , there is at most one corresponding news cluster ill another language  . Therefore , the main task of the multilingual news clusterer is to lindtile matchings among tile clusters ill different languages  . Figure 2 shows an example , illTopic ! , cluster cH l is aligned to citr , and cluster C i l2 is aligned to c . i l i . Clusters cii ~ za rid cjl 2 are left unaligned . That means the denoted events arc reported ill only one language  . 
Similarity of two clusters is measured based on verbs  , named entities , and the other nouns . 
Because Chinese words are less an ibiguollst Mn English ones  ( Chen , Biananti Lin ,  1999) , we translate nouns and verbs in the Chinese news articles into English  . If a word Ms more than one translation , we select high fl-equent English translation . For tile named enlities not listed illtile lexicon  , name transliteration similar to tile algoritln n ( Chen , el al . , 1998b ) is introduced for matching in non-alpM betic ( e . g . , Cl finese ) and alphabetic languages ( e . g . , English ) . 
Alignment is made under the same topic . A newschlster ci is a ligried to another cluster cj if their similarity is above a threshold  , and is tile highest between q and the other clusters  . If tile similarity of q and the other clusters is less than a given threshold  , ci is not aligned . It is possible because local news is reported only illtile restricted areas  . 
2 . Similarity Analysis 2 . 1 Meauingful Units The basic idea during smnmarization is to tell which parts of the news articles are similar in the same event  . The basic unit tbr similarity measure may be a paragraph or a sentence  . For
Languagel .,
Language 1i
Topic I Topici

Topic I Topic t
Figure 2 . Matching among tile Clusters in Two Languages tile t ' ormer  , text segmentation is necessary for documents without paragraph markers  ( Chcn and Chen ,  1995) . For the latter , text segmentation is necessary ibr languages like Chinese  . Unlike English writers , Chinese writers often assign punctuation marks at random  ( Chen ,  1994) . 
Thus the sentence boundary is not clear.
Consider the following Chinese example ( Cl ) :  ( Central News Agency ,  1999 . 12 . 02 )   ( Although they were undeterred by mass arrests and a police crack down  , antifree-trade protesters still marched on downtown Seattle today  . The protesters , carrying signs and chanting , opposed lh cglobal tradeliberalization being worked on at a meeting of h+a delninisters flom tile World Trade 
Organization.)
It is composed of four sentence segments separated by commas  .   11' a sentence segment is regarded as a unit for similarity checking  , it may contain too little information . Ontile contrary , if a sentence is regarded as a unit , it may contain too much M ' ormation . Here we consider a meaningful unit ( MU ) as a basic unit for measurement . AMU is composed of several sentence segments and denotes a complete meaning  . We will find two MUs shown as follows for ( C1 ) :  ( Although they were undeterred by mass arrests and a police crack down  , antifree-trade protesters still marched on downtown Seattle today  . ) ( The protesters , carrying signs and chanting , opposed the global tradeliberalization being worked on at a meeting of trade ministers fl'om the 
World Trade Organization.)
In our summarization system , an English sentence itself is an MU . Comparatively , it is a little harder to identify Chinese MUs . Three kinds of linguistic kuowledge-punctuation marks  , linking elements and topic chaius , are proposed . 
(1) Punctuation marks
There are fourteen marks in Chinese ( Yang , 1981) . 
Only period , question mark , exclamation mark , comma , semicolon and caesura mark are employed . The former three are sentence terminators , and the latter three are segment separators . 
(2) Linking elements
There are three kinds of linking elements ( Li and Thompson , 1981): forward-linking elements , backward-linking elements , and couple-linking elements . A segment with a forward-linking ( backward-linking ) elemeut is linked with its next ( previous ) segment . A couple-linking element is a pair of words that exist in two segments  . 
Apparently , these two segments are joined together . Examples ( C4)-(C6) show each ldnd of linkings . 
( C4)T ~, ~:-~,, . . , - ~' q ~& d#g #~? ( After school , I wanted to see a movie . ) ( I wanted to see a movie , but I couldn't get a ticket . )(C6) N-h&a-~~ . ~'; g ', ~ a . rx & a_~- . -24"~ d:V 4 o(Because I could fft get a ticket , ( so ) 1 didn't see a movie . )  ( 3 ) Topic chains The topic of a clausal segment is usually deleted under the identity with a topic in its preceding segment  . The result of such a deleting process is a topic chain  . We employ part of speech information to predict if a subject of a verb is missing  . If it does , we postulate that it must appear in the previous segment and the two segments are connected to form a larger unit  . 
Consider example ( C1) . The word " f '$@" ( although ) is a forward linking element . Thus the first two segments are connected together  ( C2 )  . 
The last segment does not have all y subject , so that it is connected to the previous one by topic chain  ( C3 )  . In summary , two MUs are formed . 
2.2 Similarity Model
Tile next step is to find the similarity among MUs in the news articles reporting the same event  , and to link the similar MUs together . We analyze the news stories within the same language  , and then the news stories among different languages  . The key idea is similar at these two steps . That is , predicate argument structure forms the kernel of a sentence  , thus verbs and nouns are regarded as important cues for similarity measures  . The difference between these two steps is that we have to translate nouns and verbs in one language into another language  . The approach of select-high-frequent translation and name transliteration shown in Section  1  . 2 is adopted here too . Consider ( MUI)-(MU3) . 
The former two are in Chinese and the last one is in English  . They denote a similar event " Seattle's Curfew Hours "  . Each noun ( verb ) is enclosed by parentheses and assigned an index . 
There are 9 common terms between ( MUI ) and ( MU2 )  ; 10 common terms between ( MUI ) and ( MU3) ; and 8 common terms between ( MU2) and ( MU3) . Note the time zones used in ( MU2 ) and ( MUI ) are different , so are ( MU2) and ( MU3) . 
( MU1) . g ( 1~-J5J ~ N ) (2 ~ ~  ) (3 ~'~ ~  ) (4 ~  ) ~I ~- )  ~'~  ( 5 2-~- ( 11~ ) ~% )   ( 12 " qc2\]~ ) (13~\]~ ) (14>J " ; ~v ) " ~' kl 5 ; ~ GI ~" (16 . T- . ~")( , 7 , g ' a ~) 1"( , s ' ? O " fl "' ~) o(Ch in a times ,  1999 . 12 . 02) ( MU2)(, N~IflN ) (2~-~v ) (4Gdff ), ~(5"1~) (6~ . ~/ N , ~) (7( Formosa Television , 1999 . 12 . 02 )   ( MU3 ) GSeattle )   ( 2 Mayor )   ( 2s Paul )   ( 3 Schell ) hasG declared ) a ( s State ) of ( scivil )   ( Temergency ) and ( 13 imposed ) a ( m7p . m . ) to (267:30 a . m ) ((2v10p . m . ) EST-(2s 10:30 a . m . ) EST )( , 4 curfew ) on (2 , downtown ) (29 areas ) of the (30 city ) . 
( Reuters ) ( s3) ($4) once.

Several strategies lnay be considered in similarity measure :  ( SI ) Nouns in one MU are matched to nouns in another MU  , so are verbs . 
The operations in (1) are exact matches.
Thesauri are employed tu-ing matching.
Each term specified in ( S1 ) is matched only Tile order of llOUllS and verbs in MU is not considered  . 
($6 ) ' File order of nouns and verbs in MU is critical  , but it is relaxed within a window . 
( S7) When continuous terms are matched , an extra score is added . 
($8 ) When tile object o1: transitive verbs arc not matched , a score is subtracled . 
($9 ) When date/tim expressions and monetary and percentag expressions are matched  , an extra score is added . 
l ; ive models shown below are colls trtlcted under different combinations of tile strategies specified in tile above  . 
(M t )   ( S1 ) + ( $3 ) + ( $4 ) + ( $5 )   ( M2 )   ( S1 ) + ( $3 ) + ( $4 ) + ( $6 )   ( M3 )   ( S1 ) + ( S3 ) + ( S4 ) + ( S5 ) + ( $7 ) + ( $8 )   ( M4 )   ( S1 ) + ( $3 ) + ( $4 ) + ( $5 ) + ( $7 ) + ( $8 ) + ( $9 )   ( M5 )   ( SI ) + ( $2 ) + ( $4 ) + ( $5 ) + ( $7 ) + ( $8 ) + ( $9 )  3 . Experiments 3 . 1 l ' reparat ion el'Testing Corpus Six events selected from Centrall  ) aily News , China I ) aily Newspaper , China Times Interactive , and FTV News Online in Taiwan arc used to lneasure tile performance of each l node l  . They are shown as follows: ( 1 ) military service : 6 articles ( 2 ) construction permit : 4 articles ( 3 ) lands lide in ShahJr : 6 articles ( 4 ) Buslfssons : 4 articles ( 5 ) Typhoon Babis : 3 articles ( 6 ) stabilization fund: 5 articles The news events are selected from different editions  , including social edition , economic edition , international edition , political edition , etc . 
An annotato reads all tile news articles , and connect stile MUs that discuss the same story . 
Because each MU is assigned a unique ID , the links among MUs form the answer keys for the performance evaluation  . 
Table I . Perfiwmance of Similarity of MUs

MI

M3


Precision Rate 0.5000 0.4871 0.5080 0.5164 0.5243
Recall Rate 0 . 5434 0 . 3905 (/ . 5888 0 . 6198 0 . 5579 3 . 2 Resulls Traditional precision and recall are computed  . 
Table 1 lists the perfornmnce of these five models . 
MI is regarded as a baseline model .   M2 is different l ' ronl M1 in that the matching order of nouns itl\] ( l verbs are kept conditionally . It tries to consider the subject-verl > object sequence  . The experiment shows that tile performance is worse  . 
The major reason is that we c~lt l express the same meaning using different syntactic structures  . 
Movementransformation may affect tile order of sulkiest-verb-object  . Thus in M3 we give up the order criterion , but we add an extra score when continuous terms are matched  , lind subtract some score when tile object of a transitive verb is not matched  . Compared with M1 , the precision is a little higher , and tile recall is improved about 4 . 5% . 
If we further consider some special named entities such as date/tim expressions and monetary and percentage expressions in  M4  , tile recall is increased about 7 . 6% at no expense of precision . 
M 5 tries Io estimate tile function of tile thesauri . 
It uses exact matching . Tile precision is a little higher but the recall is decreased a boll tG % compared with  M4  . 
Severalm ~\ ior errors affect tile overall performance  . Using nouns and verbs to find the similar MUs is not always workable  . Tile same meaning may not be expressed in terms of the same words or synonymous words  . Besides , we can use different format to express monetary and percentag expressions  . Word segmentation is another source of errors . Two sentences denoting tile similar meaning may be segmented differently clue to tile segmentation strategies  . 
Unknown words generate many single-character words  . After tagging , these words tend to be nOUll S and verbs , which are used in computing tile scores for similarity measure  . Thus errors may be introduced . 
1634. Presentation Model
Two models , i . e . , focusing inodel and browsing model , are proposed to display the sumlnarization results  . In the focusing model , a SU lnl narization is presented by voting fi'om reporters  . For each event , a reporte records a news story from his own viewpoint  . Recall that a news article is composed of several MUs  . 
Those MUs that are similar in a specific event are COlnmon focuses of different reporters  . In other words , they are worthy of reading . In the current ilnplementation , the MUs that are reported more than once are our target  . For readability , the original sentences that cover the MUs are selected  . 
For each set of similar MUs , the longest sentence in user-preferred language is displayed  . The display order of the selected sentences is determined by relative position in the original news articles  . 
In the browsing l node l , the news articles are listed by information decay  . The first news article is shown to the user in its whole content  . 
In the latter shown news articles , the MUs denoting the inforlnation mentioned before are shadowed  ( or eliminated )  , so that the reader can focus on the new information  . The alnount of information in a news article is lneasured in terms of the number of MUs  , so that the article that contains lnore MUs is displayed before the others  . 
For readability , a sentence is a display unit . In this model , users can read both the COln monviews and different views of reporters  . It saves the reading time by listing the colnlno11 view only once . 
5. Evaluation of Sumnmrization Results
The same six events specified in Section 3 . 1 are used to measure the performance of the two summarization models  . Three kinds of metrics are considered-say , the document reduction rate , the reading-tilne reduction rate , and the inforlnation carried . The higher the document reduction rate is , the more time the reader may save , but the higher possibility the iln portant information may be lost  . Tables 2 and 3 list the document reduction rates for focusing and browsing summarization  , respectively . Only focuses are displayed in focusing sutnmarization  , 
Table 2. Reduction Rates for
Focusing Summarization
Event Namel ) ocl , enSumLenSum/l ) oc\[Reduction mililary service 7658 24020 . 3137 68 . 63% construction permit 4182 1226 0 . 2932 70 . 68% laMslide in Shah , It " 5491 1823 0 . 3320 66 . 80%
Busiessons 618692 40.1494 85.06%
Typhoon Babis 4068 1460 0 . 3589 64 . I 1% stabilization ftmd 843 422 430 . 2659 73 . 41%
Average 36019 10078 0.2798 72.02%
Table 3 . Reduction Rates for Browsing Summarization Event Name DocLenSumLen+Sum/l  ) ocR eduction military service 7658 27160 . 3547 64 . 53% construclion permit 4182 2916 0 . 6973 30 . 27% landslide in ShahJr 5491 2946 0 . 5365 46 . 35%
Buslfssons 6186 5098 0.8241 17.59%
Typhoon Babis 4068 22700 . 5580 44 . 20% stabilization fund 84344 2990 . 5(197 49 . 03%
Average 36(/19 2024 50.56 214 3.79%
Table 4. Assessors ' Evaluation
Event Name Document Question-Reading-Time
Reduction Answering Reduction
Rate Correct Rate Ratemilitary service 64 . 53% 10(1% 45 . 24% 3/I . 27% 33 . 33% 33 . 54% construction permit lands lide in ShahJ " 46 . 35% 80%I 10 . 28% gush's oils 17 . 59% 100% I 36 . 49%
Typhoon Babis 44 . 20% 100% 35 . 10% stabilization fund 49 . 03% 100% 18 . 49~
Average 43 . 79% 88 . 46% 3(/ . 8 6% so that the average doculnent reduction rate is higher than that of browsing summarization  . 
Besides the document reduction rate , we also measure the correct rate of question -answering  , and reading-time reduction rate . Assessors read the highlight parts only in the browsing summarization  , and answer 3 to 5 questions . 
Table 4 lists the evaluation results of the six events . The average doculnent reduction rate is 43 . 79% . On the average , the summary saves 30 . 86% of reading time . While reading the summary only , the correct rate of question-answering task is 88 . 46% . 

This paper sketches architecture for multilingual news summarizer  . In multilingual clustering , l natching all pairs of news clusters in all languages is time-exhaustive  . Because only English and Chinese news articles are considered in this paper  , it is not a problem . In general , an language pairs according to the degree of translation ambiguity  . The hmguage pair of less ambiguity is tried first . 
To discuss which fi'agments of multilingual news stories denote the salnethings  , this paper defines the concept of MUs . Punctuation marks , linking elements and topic chains are cues to identify MUs for Chinese  . Select-high-frequent English translation and name transliteration are adopted to transhtte Chinese MUs into L  ; nglish . 
Five models are proposed to link the similar MUs together  . Different formats used in time , date and monetary expressions , e . g . , implicit time zone , affect the performance of linking . It should be studied in the fllture . 
In presentation o1' summarization results , the information decay strategy helps reduce the redundancy  , and the user cangetal the information provided by the news sites  . 
However , the news sequence is not presented according to the importance  . The user may quitreading and miss the information not shown yet  . 
The voting strategy from reporters gives a shorter summarization interln S of user-preferred languages  . However , it also misses some unique information reported only by one site  . A hybrid strategy should be developed in the future to meet all the requirements  . 

Chen , H . H .   ( 1994 ) " The Contextual Analysis of Chinese Sentences with Punctuation Marks  , " Litelwlaud Linguistic Computing , Oxford University Press ,  9(4) ,  1994 , pp .  281-289 . 
Chen , H . H ; et al ( 1998a ) " Descriplion of the NTU System Used for MET 2 . " Proceedings of 7 a ' Message Undel:s'tanding Conference ,  1998 . 
Chen , H . H . ; et al ( 1998b ) " Proper Name Translation in CrossLanguage Information Retrieval  , " Proceedings of COLING-ACL 98 ,  1998 , pp .  232-236 . 
Chen , H . H . ; Bian , G . W . and Lin , W . C .   ( 1999 ) " Resolving Translation Ambiguily and Target Polysemy in CrossLanguage Inli  ) rmation Retriew d , "PJ weeedings of 37 ' l ' Auroral Meeting of the Association . /' or Conqmtational Linguistics , 1999, pp . 

Chert , K . H . and Chert , H . H . (1995) " A Corpus-Based Approach to Text Partition , " Pivceedings of International Col !/' erenee of Recent Advances on Natural Language Processing  , Tzigov Chark , 
Bulgaria , 1995, pp . 152-160.
Chen , ILH . and Huang , S . J .   ( 1999 ) " A Sunnnarization System for Chinese News from Multiple Sources  , " Proceedings of 4 ' t ' International Workshop onlq formation Retrieval with Asial ~ nguages  ,  1999 , pp . 

Chert , H . H . and Lee , J . C .   ( 1996 ) " Identification and Classification of Proper Nouns in Chinese Texts  , " Proceedings " of 16th International Conference on Computational Linguistics  ,  1996 , pp .  222-229 . 
Hovy , E . and Mareu , D . (1998a ) Automated Text Smmna Hzation , Tutorial in 17'h ACL attd 36'~' COLING , Montreal , Quebec , Canada ,  1998 . 
Hovy , E . and Marcu , D . (1998b ) Multilingual Text Summarization , Tutorial in AMTA-98 ,  1998 . 
IA , C . N . and Thompson , S . A .   ( 1981 ) Mandarin Chinese : A Functional Re\[erence Giwmmar  , 
University of California Press , 1981.
Mani , I . and Bloedorn , E .   ( 1997 ) " Multi-documenl Summarizalion by Graph Search and Matching  , " Proceedings of the Fourteenth National Con . lisrence oil Arti/icial Intelligence , Providence , RI , pp .  622-628 . 
MUC ( 1998 ) Pt v ce ed ing s of 7   ~1' Messageh Met:s'tanding Cot ! ferenc . e , http://www . muc . saic . 
corn/proceedings/proceedings index.broil.
P , adev , I) . P , . and McKeown , K . R .   ( 1998 ) " Generating Natural Language Summaries from Multiple OnLine Sources  , " Computational Linguistics , Vol . 24, No . 3, pp .  469-500 . 
Yang , Y . (1981) The Research onlh metuation Marks , Tian-iian Publishing Company , ltong Kong ,  1981 . 

