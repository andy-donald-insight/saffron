I . Introduction
A study of formal properties of different styles of formal 
grammars is of great interest because each style ( i . e . , formal char-
acter of rules ) is well suited for characterizing certain aspects of 
natural language structure and is awkward for characterizing certain other aspects  . The awkwardness can be due to either an inherent difficulty in characterizing a certain aspect  ( e . g . , the characterization of the notion of the ' head ' of a constituent in a PSG  ) or an unnecessary complexity in characterizing a certain aspect  ( e . g . , the statements concerning the relational aspects in a PSG  ) or actually a counterintuitive characterization ( e . g . , this often happens in a PSG , especiai \] . 7 in the context of transformational gra~nnars , because a PSG allows an ' uncontrolled ' introduction of new ' nonterminals '  )  . 
This naturally suggests a study of formal gramnars of mixed types in order to take advantage of different styles  . * Thus we try to see how far we can succeed in setting up a class of granmmrs which has no more power than necessary and which also can characterize different aspects of natural language structure in a natural way  . 
The class of grammars studied here and in Joshi ( 1969 ) have been motivated by the type of granmmr proposed by Harris  ( 1962 ,  1968) . 
These gra , ~ars also arose out of an attempt to formalize certain aspects of the type of grammar considered by Joshi  ( 1966 ) where it was used for defining structures for the purpose of defining transformations and ultimately for constructing a transformational decomposition pro-ced ttre  . 
First , in Section 2 , we will introduce a new style of ? formal grammars called String Adjunct Grammars  ( AG )  . The only purpose of Section 2 is to state some of the basic concepts and results concerning AG's  ( including a brief discussion of their linguistic relevance  ) which are needed for the presentation of the material in Section  3   ( for a detailed treatment of AG's , see Joshi , Kosaraju , Yamada (1968)) . 
In Section 3 , we will introduce a class of grammars called Mixed String Adjunct Gra  , ~ars ( ~G ) which use two different types of rules - adjunction rules and a special type of rewrite rules  . After studying some properties of ~ AG's we introduce Generation Schemes Gs =  ( G , A ) . AGS maps strings in the language , L(G ) , corresponding to an MAG , G , into strings in the language , L(G ') , corresponding to another MAG , G ' . 
* See also Robinson ( 1968 ) for a similarly motivated work . 
- i -
Strings in L ( G ) and ~ ( G ' ) are both ' wellformed ' . In Section 3 . ~ we discuss briefly the linguistic relevance of the material in the earlier sections  . A detailed development of the various ideas introduced here will be reported in Joshi  ( 1969 )  . 
Fig . A . at the end summarizes the hierarchy of some subclasses of AL's and MAL's in relation to the phrase structure hierarchy  . 
-2-2. String Adjunct Granmmrs ( AG )
Briefly an AG consists of a finite alphabet , a finite set of strings on this alphabet and a finite set of adJunction rules which state how certain adjunct strings are adjoined to certain host strings  . The corresponding language called a String Adjunct Language  ( AL ) is then defined as the set of all strings derived from a certain specified subset of the given set of finite strings  . The rules in an AG have a considerably different formal character as compared to the ' rewrite rule ' in a general phrase structure grmmmar  ( PSG )  . 
The language hierarchies of AG's and PSG's cut across in many interesting ways  . 
2. ILocal String Ad , iunct Grammar
We will define a local string adjunct grammar ( LAG ) as follows . 
Let A = ~ al , a2, . . . , am ) be a finite alphabet . Let Z be a finite set of finite strings on A and let EcCE be a distinguished set of strings on A  . We will call Z the set of basic strings and Fe the set of basic center strings  . We will define a local left ad , ~unction rule , ~i~k as a 3-tuple ( ai ,  ~  , ? k ) where aie Z , ai ? E and ~ k is a p-~t0 f ~ ad , iunction in ai . We U will call ai as the ( ~ esic ) host of ~ iJk and aj as the ( basic ) ~ of ~ ijk " The point of a d-j ~ c tion of A i ~ k ' k refers to the point of adjunction which is to the left of t~ekth ~ ym bol of the hostai where we associate with each string ai ? ~  , ~i = ailai2 . . . ani ~ aije A , and J = i ~ 2, . . . ~ ni~2ni points of adjunction , one to the left and one to the right of each ai . . Note that a i # 8 ~ the null string . A local right adjunction rule ri~k is similarly defined as a  3-tuple ~ i , oJ , rk ) , ~ ie ~ , ~ d?~~rk is the point of adjunction of rij ~ o and  . refers to the p6int of adjunction to the right of the kth symbol in the host ~ i  . 
In general , ( ~ i , ~ ~ k ) will denote a local ad , iunctio ~ rule , uijk-Ifui . ik is a local ~ left ad ~ unction rule then ~ k = ~ k and if Uijk ~ is a loc~lright adjunction rule then ~ k=rk " Finally  , we have the fon~ng Definition 2 . 1 . 1 A local string adjunct grammar ( LAG ) , G is a 6-tuple , G = ( A ,  ~ , ~ c'~'~a'J ) where A is the alphabet , ~ is the set of basic strings , L ~ is the set of basic center strings , ~ h is the set of basic hosts Erings , ~ is the sat of basic adjunct strings , and J is a finite set of local adjunction rules . ~= ~ uil(ui , uj , ~k ) ? J\]'~a = ~ ajl(~i'~j ' ~ k)eJ , and ~= ~ cU~4J ~ a . Further
Zc may contain ~ but ~ ~ Zh.
- S -//
Given J , Sh and ~ are completely specified and S = ZcUSh ~ re  . Further the alphabet need not be explicitly stated  . Hence , unless otherwise necessary we will write G as a pair  ( Sc , J ) instead of a 6-tuple as in the definitic ~ above . 
Example 2 . 1 . 1Let ~=(~ c , J ) where ~ c - - rabcl , and J = uI = ( abc , pq , r l ) , u2 = . ( pq , pq , ~2) "\ [ We will write uijk as Justu . The indexing of u's in J is arbitrary and is merely for convenience  . \] Here Zc = rabc\] , Zh = ~ abe , pq , re = fpq\] , E = abe , pq\] . Note that a be is a basic center string but pq is not  . 
u 1 is a local right adjunction rule and t ~ 2 is a local left adjunc-t ~ on rule . Here A = ~ a,b,c,p,q . 
2.2 Local String Adjunct Language ( LAL)
The meaning of an adjunction rule , say , u = ( ui , ai , ~k ) is that fr ~ nui we can derive a new string by adjoining u ~ V to the left of the kth symbol in u i  . Thus , for example if u = ( a be , t , ~2) we can derive a string at bc . However , in order to define the language L ( G ) corresponding to a given LAG , Gj we must first define how the rules of adjunction are extended to derived  ( i . e . non-basic ) host strings and adjunct strings . Here we will give an example to illustrate the main idea and c~it the precise definition  ( see Joshi , ~) saraju , Yamada (1968)) . 
Example 2 . 2 . 1 Consider the LAG , G , in Example 2 . 1 . 1 . P = ~ abc , pq ) , Zc = abe\] , J =\ [ u1 = ( a be , pq , r l ) , u2 = ( pq , pq , ~ p)\] . From a beby one application of uI we obtain apq be  . We regard ~ he points of adjunction of a pqbc to be the same as abc  , i . e . , the positions to the left and right of the symbols a  , b and c . This apqbc is a derived host and we can apply uI again  , obtaining a pqpb c where the newly adjoined pq is i  , , , ediately to the right of a . 
Again , starting with pq , by one application of u2 we obtain p p q q . 
Since pq is both a basic host and a basic adjunct ( in the same rule , in this example ) , ppq q is a derived host as well as a derived adjunct and hence it can be used as a host or as an adjunct or both in the rule u  2   . This allows us to derive strings p p p q q q q , p p q p q q q , p p q p p q q q q , etc . Since all of these are derived fr~np q they can be used as adjuncts in Ul  , allowing us to derive app p q q q b c , app q p q q q b c , app q p p q q q q b c , etc . If we use a pqb c as a host in Ul , we can also derive a pp p q q q q q b c , app q p q q q q q q b c , etc . Thus we can derive , for example , from the string abc ? rc the strings app p q q q b c , app q p q q q b c , app p q q q q q q q b c , a p q p q b c , a p q p q p p p q q q q q b c , etc . All these strings will be included in the language L  ( G ) corresponding to G . 
Example 2 . 2 . 2 Let G = ( Ec , J ) , F ~=\[ ab\] , ' J = ~ uI = ( ab , ab , r l )\] . 
This gra ~ nargenerates the language L ( G ) = ~ w/w is a string on A ; " the number of a ' sinw "=" the number of b's in w " and for any  -4  -\ . 
initial proper substring of w , the number of a ' s is greater than the number of b ' s  )  . This language is contextfree and is known to be nonlinear  ( Schatzenberger ( 1961 ) ) . 
Remarks 2 . 2 . 1 i . In the generation of a string in L ( G ) we observe that once a string is adjoined to a host then the adjunct string cannot receive any further adjuncts  . In other words a string which is to be come an adjunct string must acquire all its adjuncts prior to its being used as an adjunct string  . 
2 . Let w be a string in L ( G ) derived from some string ui ~ ~ c " The generation of w does not begin  , however , with the basic center string unless , of course , w is just a basic center string itself or a center string with adjuncts which themselves do not receive any other adjuncts  . We have to start from the " innermost " adjunct ( adjuncts ) and work our way " insideout " and finally use the basic string which is to become the center string of w  . 
3 . During the generation if a host string receives two  ( or more ) adjuncts then we have the two following situations  . If the two adjuncts are adjoined at distinct points of adjunction of the host  , then clearly those adjuncts can be adjoined in any order  . However , if the two adjuncts are adjoined at the same point of adjunction of the host the order is significant  . Let uI = ( ai , oj , ~k ) and u2 = ( ci , am , ~k ) be two rules . Let ~ k--~i for example . If uI is used before u2 then we obtain Ojam Oi ; but if u ~ is used before ul-then we obtain a majO i  . 
In other words , the adjunct adjoined later in the derivation is closer to the point of adjunction in the host  ( ~6 ~ which it was adjoined ) than the adjunct adjoined earlier in the derivation  . 
2 . 3 ' Tree representation for a derivation in LAG Let G =  ( ~ c , J ) be an LAG . Let the rules in J be arbitrarily numbered u_ , u _ ,   . . . , u ? The generation tree is constructed as follows  , ll ) ~ If u ~= n(oi3oj , ~k ) is used in the derivation then we represent this as in Fig  .  2 . 3 . 1a . Here we have two labeled nodes aj and ? i and a directed branch from oj to ? i with the label u ~ : ~ k "  2~ Let a host oi receive more than one adjunct , say , ajl ,   oJ2''"' ejmatpoints of adjunction gkI'~gko'~"''' gkm'i  . e . , we use rules ui ~ = ( oi ' aj2 , ~k ) ? J , ~= l ,  2 ,   . . . , m . We represent this as in Fig .  2 . 3 . 1b . Now , in view of Remark 2 . 2 . 1 -3 we impose a right to left ordering on the points of adjunction of a host and thus in effect define an equivalence relation on the set of derivations of a string  -5 - f , c ,  .  2 . 3  . 1 ~ . 
bqPq(,I ) (9): iI:rz~:~X ~ . : r~t~t ~) a-i>c , ~4, ',, Ex ~, ~,, b , le .  3 . . .  3 . i . 
-6-~ler '; vo , 4; i ' or ~ o : in L(G ) . The tree representation of a derivation with the above conventions will be called a  ri6ht to left ( r - ~ ) tree representation . 
Note that the tree representation of a derivation of a string in L  ( G ) is a rooted tree and the string labeling the root is in Ec"  2   .   . 1 Example = labc , Let G = ( E c , J ) bean LAG where Zc--\[abc ~ , and j = KUl pq , r2) , u2 = ( abc , rs , r2) , uS = ( pq , pq , r l ) , u ~= ( abc , t , ~ l ) , ~=( pq , t ,  ~)3 . The following is a string in
L(G ). w = t t a b r s p p q p t q q r s p q c
Fig .  2 . 3 . 2 show an r -~ tree representation of a derivation of w  . 
We have numbered the nodes for convenience . Nodes l ,  3 ,  5 ,  6 ,  7 ,  8 , and 9 are terminal nodes . Nodel O is the root node . 
The derived strings corresponding to the nodes of the tree in Fig  .  2 . 3 . 2 are as follows : 1 . t ; 2 . ptq ; 3 . P q ; 4 . p p q p t q q ; 5 . P q ; 6 . rs ; 7 . rs ; 8 . t ; 9 . t ; 10 . w = t t a b r s p p q p t q q r s p q c . 

Theorem 2 . ~ . iE very LAL is a CFL ( contextfree language) . 
class of LAL's is properly contained in the class of CFL's  . 
(L = ~ an bnIn ~ i \] is not an LAL.
The 2 . 5 Distributed Strin ~ Adjunct Granmmr ( DAG ) and Lan6ua ~ e ( DAL ) We will generalize the local adjunction rule as follows  . 
Definition 2 . ~ A distributed ad ~ unction rule , dijk is a 3-tuple , ( ai , ( aj ) , ~k ) where ai ? E ; aj ? E ; ( aj ) denotes a specified segmentation of aj ; k is an adjunction ' vector ' , ~ kl ,  % ,   .   .   .   , ~ kn;Eki's are the points of adjunction of ai , " and ~ ki = ~ kiorrki , 1 ~ k i ~ m , k i ~ k i + l , sa difki = ki + 1 then ~ k i = ~ k is a d ~ k i + l-rki + l . 
The meaning of ~ i -' k is that from the host oi string  , say , ap , by adjoining the segments of aj , a jn at the points of adjunction ~ k l ,  ~  ,   . . . , ~ knly . That is , we ' distribute ' the specified segments of a ~ over ai at the points of adjunction ~  ,  ~ ,   . . . , and ~ k ; the j~h segment n is adjoined at ~ k j " The Condition on ~ k prevents permutation of the segments  . 
we can derive a
J2"'Jlofai , respective--7-
The language L(G ) corresponding to a given DAG , G , can be defined by generalizing the definition in Section  2  . 2 . The main idea is that when a derived string is segmented each segment contains all the adjuncts  ( and adjuncts of adjuncts etc . ) of all the symbols in that segment . The tree representation in Section 2 . 3 can also he generalized to DAG's . 
Example 3 . 1 . 1Let G = ( Zn , J ) heaBAG where Z ~=\[ abc , and = ul = Cabc , ( p ) ( qr ) , rl~3) , u2 = ( pqr , ( p ) Cq~(r ) , ~i ~2~3)\] . 
Here Z =\[ abc , pqr , and A = \[ a , b , c , p , q , r . Note that in thin u1 and u2 is not the same . Then nn~(G)-\[apb5r ~ .   .   . qr?Ini ~0, for i = i,2, . . . , m;m~i . 
Example 3 . 1 . ~ Some other DAL's are : LI=\[a ~ omln ~11 , L , 2 =\ [ anbncnln~i , L3=\[xxRIx ? AA* , " ~ Rx = reversal of x , %=\[XXlXCAA*\] , etc . 
Theorem 2 . ~ . 1" The class of LAL's is properly contained in the class of DAL's  . Every DAL is a CSL ( context sensitive laaguage) . 
The clas ~ of DAL's is properly contained in the class of CSL's  . 
( L=\[an In~l is a CSL but not a DAL).
Theorem 2 . ~ . i There are languages which are inherently ambiguous in the class of CFL's but which are unambiguous in the class of DAL's  . 
( Ex ,=; le:~ . - ~ a%J ckli,j,k : . i ; i : j or j : k ) 2 . 6 String Adjunct Grammars with Null Symbols ( AGN ) and Language We will now introduce a somewhat modified form of AG's  ( IAG's or DAG's ) called string adjuncts grammars with null symbols  ( AGN )  . 
The modification consists of allowing in the alphabet a very special type of " nonterminal " symbols called " nul ___ ! lsymbols "  . The main idea is to use the null symbols to tag the strings in Z  . The null sym-*It is possible to generalize the local adjunction rule in the following manner also  . This generalization permits one to adjoin to the host a set of local adjuncts simultaneously  , i . e . ( ai , ajl , ~ J2'"'" ajn , ~k ) where aic Z , k = l ,  2 ,   . . . , n , and ~ k is the adjunction ' vector ' as before . We will call these IAG's with simultaneous ( Continued on Page 9 )  . 
- 8 -bols have no points of adjunction associated with them and they do not receive any adjuncts  . The null symbols are ulit mately erased ( i . e . , rewritten as a null stringE) . 
Definition 2 . 6 . 1 An IAGN ( or DAGN ) , G , is a 7-tuple ( A , N ,  ~ , Zc , Dn , E a , J ) where A is a finite alphabet , N is a finite set ( possibly empty ) of null symbols , ~ is a finite set of basic strings , ZccZ is the set of basic center strings , ~ h is the set of basic host strings and ~ a is the set of basic adjunct strings  , E = ZcUEhUEa and J is a finite set of adjunction rules  . Further a . A ~ N = ~; b . If ~? Z then sc(A ~ N ) ( AUN )*; c . There is no rule in J which adjoins adjuncts to the left or right of a null symbol  , i . e . , null symbols have no points of adjunction . Thus for a oicZ the adjunction ' vectors ' are the same as those that can be defined for the same oi without the null symbols  , i . e . , as far as adjunctions are concerned we ignore the null symbols  . We will use Greek symbols for the null symbols , and unless otherwise necessary , we will write an LAGN ( or DAGN ) , G , as just the pair ( Ec , J ) . 
Theorem 2 . 6 . 1 The class of LAL's C the class of LALN's and the class of DAL's c the class of DALN'a  . ( We conjecture , however , that we have '"' ~ . ns~ead of "_C") . 

An adjunction rule u , if applicable , can be applied arbitra-rily many times . In this sense it is repeatable . We can also consider nonrepeatable rules ,   ( nr-rule ) ~ in the sense that if a rule u = ( ui , aj , ~k ) is nonrep ~ a table then for each occurence of the hostoi in a derivation  , u can be applied no more than once . Let nr-AG and nr-AL be the correspond in ~ grammars  ( i . e . AG's which have at least one nr-rule ) and languages . The class of LAL's the class of LAI/Y'S ( L =\[ anbnln~I \] is an nr-LAL but not an IAL )  .  ~ 2 . 8 We say that a local a~junction rule is uniform if in a rule u the adjunct aj adjoins to the left  ( or right ) of some symbolag ~ A in the host of u , then a ~ adjoins to the left ( or right ) Of ag wherever ag occurs in 8n ~ string in ~ . AnLAG , G , is uniform if all its rules are uniform . 
(, Continued frem Page 8 . ) ad . iunction rules ( LsAG ) . It can be shown that the class of LAL's C the class of LsAL's C the class of DAL's  . This observation is due to Leon Levy . 

AG's with the condition ~= ~_ are of special interest  . String sine an be considered as eleotry sentences  ( or sentence fo ) in L~G ) -- If ? = ~ c then every string in L ( G ) Can be decomposed into a set of elementary sentences  ( or sentence forms )  . Note also that if ~= ~ c then in the r-~tree representation of the derivation of string in L  ( G ) every node is either a sentence or a derived sentence  . 
2. iO
In an LAG ( or DAG ) we do not have nontermlnals in the sense of the nonterminal alphabet of a PHG  . We have , however , auxiliary symbols used implicitly such as the ~ k 's corresponding to the points of adjunctions  . But these auxiliary symbols are used purely as position markers and do not have the same interpretation as the nonterminals in a PSG  ( i . e . , the auxiliary symbols ~ k's do not correspond to phrase types  ) ? If we consider the marking symbol , A , used in making precise the definition in Section 2  . 2 , ( see Joshi , Kosaraju , yamada (1968)) , also as an auxiliary symbol then one can posslbly consider ai  ( aie A ) as a nonterminal which can be interpreted as a phrase ^ type but with the added interpretation that arh rase type ai has ai as the '  heed '  ( or ' center ' ) of the phrase . 
Each sentence in L ( G ) has also a ' center ' namely the center string of W  . 
In an IAGN ( or DAGN ) the null symbols are , however , like the nonterminals in the PSG although highly restricted  . The null symbols are used to tag basic strings and therefore they are not used as position markers  ; in fact , they have no positional interpretation . 
The null symbols as nont crmlnals are highly restricted because they are never ' rewritten '  ( in the sense of a PSG ) into any other string except the null string , i . e . , the only ' rewrite rule ' associated with a null symbol  , say ~ , is ~~? . 
IAGN ( or DAGN ) can be considered as gra~nars of a mixed style as we use rules of two different styles-adjunction rules and ' rewrite rules ' of a special type  . This is a very simple example of a mixed ~ rammar  . In Section 3 we will be considering some more interesting classes of mixed grammars  . 

In the linguistic context the alphabet A in an AG , G , will consist of symbols which denote major dictionary classes  ( lexical classes ) such as N ( nouns )  , t(tense , auxiliaries ) , % ( adjectives ) , V ( verbs) , P ( prepositions ) , wh(who , which , whom ) , R(pronouns ) , D ( adverbs ) , Q(quantifiers ) , etc . N , t , A , V , etc . are thus-i0-preterminal symbols . The basic center strings thus correspond to basic  ( elementary ) sentence forms , e . g . , N t V ( John came ) , Nt VN ( Jipb ~ ht books) , Nt VPN ( people rely on John ) , etc .   ( A subcategorization of V's is implied here and is not explicitly shown  )  . Basic adjunct strings are basic adjunct forms , e . g . , P N ( from Philadelphia ) , A ( old ) , whNtV ( whom John saw ) , wht VN ( who saw Jim ) , D(~--~ , etc . Each de - ~ Ive ' ~- r ~ - ~ in L ( G ) is thus a derived sentence form , e . g . , ( assuming suitable adjunction rules ) , NP Nt VN ( a man from Philadelphia bought books )  , ANtV(an61 dmancame) , Nwh ~ tVD ( the man whom Bills a wran ~) , NwhNwhtV~tVtVD ( ~ he books ( which ) the man who met Jim boush t will arrive so on )   , etc . ( ignoring articles for simplicity ) . 
In an AG , lexleal insertion takes place as each basic string is brot ~ ht into the generation of a sentence  . Let ai = ailal 2 .   .   .   . aim ' aie Abea basic string . As oi is brought into the generation of J ,   , a sentence , each aij can be rewritten ass set , say ,  ~  , of syntactic features and-dictionary items can be inserted immediately  . 
The verification of selectional restrictions that hold within the domain of a basic string can be in mediately carried out as any pair of adjacent symbols of ~ i are contiguous at this stage  . If the basic strings are properly chosen then most selectional restrictions are brought to bear within the domain of some basic string  , and indeed it turns out that basic strings ( with reasonable linguistic interpretations ) can be set up in this way . 
There are some restrictions which hold between a host and an adjtmct string  ; e . g . , in N wh N t V t V ( the man whom John metarrived )  , whNtV is an adjunct of NtV and the N in Nt V is really the ' object ' of V in wh Nt V  . Some other examples are : Zeroing in conjoined sentences  , e . g . , everyday , he runs and swims ; hepls yed tennis hutshedidn't , etc . Restrictions between successive adjuncts at ih6 same p0int of adjunction of the host ( ordering restrictions ) as in Ismlqokin ~ for a book with a green e over whish was lying here somewhere  . Restrictions between a ~ ost and two or more adjuncts at different points of edjunct lon of the host as in boMs who caws wim distrust boys who  9an't   . All these can be easily veriffed . 
? AG's are well suited for formulating the ' endocentric'properties in the sense that this aspect of a constituent can be explicitly brought out in the structural description  . There are , however , constituents which are not'endocentrlc' . These are ' exocentric ' in the sense that we cannot replace them by any word of a character -iziug category contained in them such that the constituents can be considered as constituent expansions of the characterizing category  ; e . g . , who willrepresent us at the meetin ~ in who will represent us-Ii-at the meet ln ~ is unclear  , etc . AG's are not well suited for formulating the exocentric properties  . These properties are better characterized by the use of a ' nonterminal ' and ' rewrite rules ' in the sense of a PSG  ( see Section 3 ) -Sentence adjuncts ( e . g . , in general , today ) can be handled well in an AG ; in particular , that these adjuncts can occupy various sentence positions can be easily characterized in an AG  . This is a wkward to characterize in a PSG . However , the property that these adjuncts eread juncts of a sentence is better characterized by the use of a nonterminal  . 
Distributed adJunction rules are required to handle eases such as two and three are even and odd numbers respectively which is a case of an intercalated structure  . Such structures are not too ? frequent . However , if one tries to construct AG type gran ~ ars as base for transformational grammars then the need for intercalated structures is not so marginal  . This is primarily because one tries to relate each adjunct to an elementary sentence  ( i . e . , one tries to constitute the adjunct and host strings in such a way that the underlying elementary sentence  ( s ) could be reconstructed fr can them )  . 
Some examples are : the man who came . . .   ( double underline indicates the distributed adjunct  )  ; John's proof of the theorem , etc . ( see Hi ~ and Joshi (1967) , Joshi (1906 ,  1969) , for further details ) . 
The kinds of intercalated structures possible in a DAG apparently are adequate for this purpose  . 
If E = ~ c then each string w cL ( G ) has a representation in terms of basic ' sentences '  ( or basic center strings )  . In general , adjuncts are not strings in ? ~ and hence ~$ Ec . But what seems to be true of a natural language is that one can ' almost ' construct an AG  , G , ( actually , a mixed AG , see Section 3 ) for which ~= ~ c and define a set of operations ( these consist of permutations , deletions , and additions of constants ; these operations can be related to transformations in a given language  ) for each ~ cE and for strings derived from ~ such that we can construct a new AG  , G ' , with basic strings E ' , ~ c'where E '$~ c ' and strings in E ' are transformationally derived from strings in ~  . Strings in L ( G ' ) except for morphophonemic operations are the strings  ( sentences ) in the language . In transformational analysis we go in the reverse direction  , i . e . , from G ' to G and reconstruct the set of basic ' sentences '  ( together with the derivation in G ) underlying a given sentence generated by G ' .   ( See Joshi ( 1969 ) for further results and details . ) t-12-3-Mixed Grammars 3 . 1In AGN's ( i . e . , AG's with null symbols ) in Section 2 . 6 we use a very special type of null symbols which are ultimately erased  . * The only rewrite rule associated with a null symbol is ~- where ~ is a null symbol and ~ is the null string  . The AGN's are thus a class of mixed grammars as rules of more than one style are used  . It is , huwever , a rather simple class of mixed granmmrs . 
3.2 Mixed Strin ~ Adjunct Granmmr ( M~G)
We will now consider a more interesting class of mixed grammars  . 
The main idea is to allow a single ' nonterminal '   ( in the sense of a PSG ) in an AG and a special type of ' rewrite rules ' associated with this nonterminal  . We will , however , call them ' replacement rules ' . The reason for adopting this new terminology will become clear later  . More specifically , we will define a MixedStr in ~ Adjunctr ~ ( with replacement rules )   ( MAG )  , G , as follows . 
First , in addition to the ' terminal ' alphabet A we will have a ' nonterminal ' S  . The set of basic strings , E , and the set of basic center strings , Zc , will now be strings on ( AU\[S ) . Thus a string aic ~ may now contain one or more S's in it  . Aoic which does not contain S will be called an elementary basic string and aui ? E which contains one or more S's will be called a basic string  . The adjunction rules ( local or distributed ) are defined as before and we adopt the same convention as in the case of the null symbols  , i . e . , in an adjunction rule if the host is a complex basic string we disregard the S symbols in it as far as points of adjunction are concerned  . Thus the points of adjtu % ction of a string , say , ai = aSbS are the points of adjunction which are to the left and right of a and b  . Further , the S symbols have no points of adjunction . Of course , ~f an adjunct string , say , ~ is a complex basic string and has a specified segmentation  , then ~ ach symbol Sinoj must be included in some segment of aj  . 
* Actually , it is possible to define the recursive extension of the adjunction rules such that the null symbol associated with any basic string is erased at the time the string is ad  . ioined to some host string . The null symbol associated with the center string is thene rased at the end  . 

We now define a replacement a rule Pij ( often written Just as p ) as a pair < ai , oj > where aic ~ , ai is a complex basic string , and a S ? ~ c " The w ~ aning of a replacement rule p = < ai  , aj > is that ~ r ~ ai one can derive a new string by replacing some occurenee of Sinai by a  . . Thus we have the following

Definition ~ . 2 . 1 An MAG , G , is a 9-tuple , G = ( A , S , E , E c ,  ~  , ? Ea'E~'J'R ) where A is the alphabet ( terminal )  , S is a ' nonterminal's ~ m ~ ol(S ~ A) , Z is the set of basic strings , ~ c is the set of basic center strings , E h is the set of basic host strings , E a is the set of basic adjunct strings , Zr is the set of basic replacer strings , J is a finite set of adjunction rules ( local or distributed )  , and R is a finite set of replacement rules . ~=\[ oi !( ai , aj , ~ k ) ? J ) u (% 1 < 5 , aj > ~ RLza = ojl(oi , ~ j , ~k ) ~ J , and Zr =\ [ ajI < ai , aj > ? R\] . Z = ~ eUZhUZaUZr . Z c may contain 8 h ~ ~ Given J and R , Zb , Za , and ~ r are completely specified and = ~ cUZb U ~ aUZ r  . A need not be explicitly stated . Since S is the only ' nonterminal ' it need not be explicitly stated also  . 
~ nce , we will write an MAG , G , as a triple ( Ec , J , R ) instead of a 9-tuple as in the definition above . 
Example ~ . 2 . 1 Let G = ( ~ c'J'R ) bean MAG where Ec = \[ abc , pq , a hSc , J = uI = ( abSc , (a ) ( b ) ( c) ,  ~1~2~3) , ~=( abe , (a ) ( b ) ( c) , ~I~2~3)\] , and R = Pl = < a hSc , abSc > , P2=<abSc , pq~\] . 
Example ~ . 2 . 2Let G = (7~c , J , R ) be an MAG where ~ c = lash , C \] , J = uI = ( aSh , (a ) ( Sb) , rlr2)\] , and R =\[ Pl = < aSb , aSh > , 
P2=<ash,c > .
33 Mixed String Adjunct Language ( MAL)
We now have two different styles of rules in G , namely , the adjunction rules J and the replacement rules R  . If R is empty then we have an AG and we know how the generation proceeds in this case  . 
In particular , we note the ' insideout'characteristic of the generation  . If R is not empty then we have replacement rules associated with the symbol S  . The generation still proceeds in an ' insideout ' manner  . In order to define the language corresponding to an FAG  , we must state how the rules in J and R are extended to derived strings  . Rather than giving a precise definition , we will illustrate the main idea by the following example  . 
Example 3 . 3 . i Consider the MAG , G , in Example 3 . 2 . 1 . Starting with the complex basic string abScand using it as a host in uI and the string abcas an adjunct in Ul  , we obtain a abbScc . Usxng this as a derived host in the replacement rule p ~  , we obtain a abbpqcc . But this is a string derived from a bS~and therefore it can be used as a replacer string in p  ~  . Thus we can obtain a abba abbpqccc c c c ( see Fig .  3 . 3 . 1) . The language L ( G ) = LI is As far as rules in J are concerned we require ' insideout ' generation  . In order to define consistently the recurs ive exten-sion of rules in J and R together it is necessary that once a replacer string replaces an Sno further adjunctions or replacements can be made on it  . Thus before a replacer string is used it must be completely built up  ( i . e . , it must have received all its adjuncts and adjuncts of adjuncts etc  . , and all occurences of S must have received their replacements  )  . * This was the reason for calling the rules in R as replacement rules rather than rewrite rules  . 
Thus the generation begins from either ( a ) the ' innermost ' host-adjunct pair ( s ) or ( b ) the ' innermost ' complex basic host-replacer pair  ( s ) where the replacer is an elementary basic center string  , or ( e ) both ( a ) and ( b) . 
The reader may amuse himself by working out the language  ( 1% ) corresponding to the MAG in Example 3 . 2 . 2 . It is rather complicB ted to write it down in a parametric form  . 
* It is assumed that for every complex basic string  , say , ~ i ' either there is a rule < ~ i , a . S > where ~ j is an elementary basic string or there is a sequence  6f rules < Oil , ajl > , < si2 , ~ J2>'"''' < gin ' ~ Jn > where == ? k=l ,  2 ,   . . . n-l , and siI ~ i , SJk ~ Ik + l'~J n is an elementary basic string . Otherwise , ~ i can be removed from G without affecting L(G ) . 

Both LI and L2 are CSL's ( Context sensitive languages )  . They are both DA~'s also . This can be shown by constructing the equi-valent ' DAG's  . Let GI = (~ c'J ) be a DAG where ~ c = abpqc , pq\] , and J = uI = ( abpqc , ( ab)(c ) , r2rg ) , u2 = ( abpqc , ( a ) ( b ) ( e) , ~i ~2~5)\] . Then L(GI ) = LI . Similarly let G2 = ( E c , J ) be a DAG where Zc = acb , c \] , and J =\[ u1 = ( acb , (a ) ( cb ) , rlr3) , ~2 = ( acb , (a ) ( b) , rlr3) , u3=(acb , (a ) ( b) ,  ~2~3)  , u ~= ( ab , (a ) ( b) , rlr2) , u ~= ( ab , (a ) ( cb ) , rlr2) . It can be shown that L(G2) = L2 . In fact , we have the following Theorem ~ . ~ . I For every NAG , G , there is an equivalent DAG , G ' , ( i . e . , L~G ) = L(G ')) which can be effectively found . 
We will omit the proof here as it is rather long . An examination of MAG's in Examples 3 . 2 . 1 and 3 . 2 . 2 and their corresponding DAG's , GI and G 2 above will give the reader some indication of hew the proof can be constructed  . This is an interesting result because it shows that as far as weak generative power is concerned  , we can eliminate S , the only ' nonterminal ' we have used . It can also be shown ( this is easily seen from GI and G2 above ) that if the NAG , G , satisfies the condition that E = ~ c , then the equivalent DAG , G ~ will not necessarily satisfy the corresponding condition E ' = Z ' In fact  , for some NAG there will be no equivalent DAG satisfy in ~ this condition  ( see Section 3 . 9 . 6 for linguistic relevance ) . 
Remarks 3 . 3 . 1 i . In an MAG , G , not every basic string is a string on A(e . g . , the complex basic strings ) . However , in the tree representation of derivation of a string in L  ( G )  , the derived strings at each node are strings on A  , just as in the case of an AG . In fact , if this condition is not satisfied the tree will not correspond to a tree for some string in L  ( G )  . 
2 . The symbol(s ) S in a complex string , say , ~ i ' will be referred to as a contained S .  ~ . will also be called a container strin ~ and the repla--c-~s-t~-~ng  ( s ) ~ or S will be called contained string ( s~ . 
Let ?~ i = abSc , ~ j = dSe , a k = gSh , and ~= pq . Let uI = ( abSc , dSe , r l ) be an adjunction rule and Pl = < abSc , gSh > , P2=<abSc , Pq > ' P3 = < dSe , pq > , and P4=<gSh , pq > be some replacement rules . Consider the following tree representation of a derivation  ( Fig .  3 . 3 . 2: the superscripts on ~ are used to distinguish the two i is contained distinct occurences of the string p q  )  . Note that a ~-16-o . k , c~c
C(~) c ~ bg ~ (4) a . bc-6-Ae ? mode $ " ~3~4-s~ . . 0 . bez . F9 q . ~c , 5, o_o , % b < xo , bb ~ Iccc ~
FI &.3.3, I.
W = ~ . bloo . ~bh ~ % cccc = ' ~ nMAGrG ~ E ~" ~'~ ~ . 2 . " f . 
= aSe , l2.
o.~Sc=o-,:-17-
FiG " ~.% .2..
A in uj and aj is adjoined too . , and u ~ is contained in and
Uk ? k'depth'2 ) with respect to ~ i and this is so both in the sense of a PSG and an MAG  . No wul is two levels down where the first level is due to an adjunction ~ ud the second due to containment  , but is two levels down where both levels are due to containment  . 
Thus in an MAG the depth of embedding of string can be characterized not only by the number of levels involved but also by stating for each level whether it is due to adjunction or containment  . There is also the possibility of characterizing an arbitrary depth of embedding in terms recurrent patterns of adJunction and/or containment levels  . 
3.4 Deformations and Generation Scheme
In this section we will be concerned with the construction of an MAG  , G , with ~= ~ c for an MAG , G ' , ( for which ?2~~c' , in general ) such that G is related to G ' by means of certain operations  ( see Section 2 . 11-last paragraph ) . 
Let A = Ill ' 12' "'" ~ n\] be a finite set of deformations ( to be defined later )  . 
Definition 3 . 4 . 1 A Generation Scheme , G ~ is a pair ( G , A ) where G is an NAG , G = (~ c , J , R ) , A is af~nite set of deformations , and with each rule ue J and each rule p ? R , we associate unique subsets of A , say , ~ u and ~ respectively . 
Let C be a finite set of constants . We say that a string s ' is a deformed a if every symbol of ~' is either a constant  ( i . e . , is in C ^) or is a symbol of a or both , That is , a ' is obtained from a Eyone or more of the operations of permuting  , deleting , or repeating symbols of a or adding one or more symbols from C  . 

Definition ~ . 4 . 2 Let u = (~ i , a  ~ , ~k ) cJ and let du be the ?' v assoclated subset of deformations  . Then aJi ? Au maps the rule u = ( ai , aj , ~k ) into a 3-tuple ( ui ' , aj ' , ~ k ') where ai ' = ai , aj ' is a deformed aj ( the specific choice of operations of permuting , deleting , or repeating symbols Of a jor adding constants is determined by or i  )   , and ~ k ' is an adjunction ' vector ' of ui not necessarily -  18  -
L the same as ~ k " We write this as Ji ( u ) = u ' where u '= ( ai ' , uj ' , ~k ') . * Similarly , ali ? Ap , P = < ai , a j > , map sp into a pair < oi ' , oj '> where ai ' = oi and aj ' is a deformed aj  ( hidetermines the specific deformation as before  )  . We write this as li(p ) = p' , where p ' = < ai ' , oj ' > . 
Note that lide forms uj and also specifies a new adjonction ' vector '  . Note also that u and p are rules in the MAG , G . u ' and p ' are not rules in G . However , they will be later interpreted as rules in another MAG  , G ' . 
Eachoci can then be extended to the derived hosts and derived adjuncts in u  , and to derived hosts and derived replacers in p in the obvious way  ( i . e . , if a symbol of ~ is permuted it carries with it its adjuncts  , and their adjunct ~ etc . ~ if a symbol of G~is deleted then we delete its adjuncts  , and their adjuncts etc . , addition of constants is not affected ) . More complicated extensions have to defined however for the more complicated li's  . ( See Section 3-5-5 , and for further details , Joshi (1969) . 
For a given Generation Scheme , Gs = ( G ,  4) , we will define the la~ngu ~ e__~c ? r respondi ~ _toGs  , ~ LG  ~ , as follows . We will give her--~only an informal definition . We carry out the generation in the MAG , G , as described in Section 3 . 3, with the following modification . 
If during the generation we plan to use a rule u then instead of i ~ n ~ ~ a ~  . Similarly , p we if using u we use the rule u '= ~ ( u ) where ~ e we plan to use a replacement ~ ep then s of using use the rule p ' = ~ m  ( P ) where 6mc ~ p . The choice of or ~ from ~ u and ~ m from ~ is nondeterministic  . 
* This definition is not quite precise as stated . First , note that ~ k ' is an adJunetion ' vector ' and hence its components must satisfy certain conditions  ( see Section 2 . 5) . Secondly , if ~ k ' has more than one component then 6 i must also specify the appropriate segmentation of ~ j '  . This definition is also weaker than required . 
More c~nplicated ~ . 's can be defined and are required ( see Section 3-5-9 ) - i - 19 -Note that here we use the word ' language ' in the usual sense  , i . e . , a set of strings on A . Ultimately , however , we are interested in the corresponding strings of lexical items  . The lexical insertion proceeds in G in the same general manner as in Section  2  . 11 ( paragraph 2), ( see also Section 3 . ~) . In thlscase the choice of a J ~ from ~ and of Jm from ~ may depend on the lexical entries for ai and a  . which are , of course , available at this point in the generation . 
The ' language ' derived in this way is L(Gs ) . The derivations are not in G but in G s . We could , of course , allow the generation in G to proceed independently but concurrently with the generation in G  . In this case , we would derive a pair of ' corresponding'str i ps  , say w and ws where wcL(G ) and wS~L(Gs ) . Note that GS is not an MAG ; however , we have the following Theorem ~ . 4 . 1 For every Generation Scheme , GS = ( G , 4) there is an equivalent MAG , G ' , ( i . e . L(G ') = L(Gs )) , and G'canhe effectively found . 
The proof is rather involved and we will omit it . At least for the 6's in Definition 3 . ~ . 2 one can state the main idea as follows . * Let G = (~, J , R ) and G ' = (~', J ', R') . Then i . ~c '= ~ c ? 2 . j ' Cobviously contains ~ ll the u '=6 i(u) , u  ~ J , as adjunction rules . But J ' also contains some additional rules which are needed for the following reason  . Let a ~ be an adjunct string in G and let some ~ deform a S into a j '  . N~w , if a . j is also a host string in some adjunction rule , say , u in J then we must add a new adjunction rule ( s ) in G ' which in e ~ fect allows one to adjo in the adjunct in u  ( actually , its deformations under all possible S's ) to a ~' , with r the adjunction ' vector ( s ) ' appropriately specified .  3 . R ' U consists of all the p ' = ~ i(p) , p ? R , as replacement rules . R ' also contains some addltional rules which are needed for the same reason as in  2 above . 
We can impose the condition ~= ~ conthe MAG , G . But then G ' ( equivalent to GS = ( G , 4)) need not satisfy a similar condition , i . e . , ~' need not be equal to ~' . This is because ~' contains , besides strings in ~ c' ( = ~ c ) ' the deformed adjuncts and deformed replacer strings  . 
I * The proof extends to s~ne of the more complicated J's  ( see
Section 3.~-~) --20 -
From Theorems 3 . ~ . i and 3 . 3 . 1 we then have Corollary ~ . ~ . % For every Gs = ( G , A ) there is an equivalent DAG , G " , ( i . e . , L(Gs ) = L(G ")) which can be effectively found . 
3.9 Linguistic Relevance
In this section , we will briefly discuss the various results in Sections  3  . 1 - 3 . 4 in the linguistic context and provide some Justifications and interpretations for these  . 

As is evident from the discussion in Section 2 . 11 , the main motivation for considering FAG's is to provide suitable representations for certain structures  ( e . g . , that he went home surprised me , I told him to 5 o home , t . hat John will come is Certain , I tried to read the book , etc . ) . The purpose for considering MAG's with = ~ c is the same as in Section  2  . 11 ( last paragraph ) . 

In Section 2 . 1 1 we have seen that many restrictions have as their domain a basic string or a basic string and its adjuncts  ; and these can be easily stated and , at the time of adjunction , easily verified . These remarks obviously hold for an FAG as far as adj ~ netions are concerned  . However , in addition to these , in an FAG there are many restrictions which have as their domain a complex string and its replacer  ( s ) string ( i . e  ~ . , a container string and the contained string(s)) . These also can be easily stated and , at the time of replacement , easily verified . Apart from selectional restrictions , some of these restrictions are : ( a ) Identity of one of the N's in the container string and one of the N's in the contained string  ( identity of the ' subject ' or ' object ' noun in the container string and the ' subject ' or ' object ' noun of the contained string  )  , e . g . , It old . John to go home , I promised Bill to purchase books , John deserves promotion , He suffered defeat , I forced him to s~rim , He is uninspirin 5 as a teach e__~r , I saw the bo~bein ~ beaten by the policeman , etc . Actually , since we are considering derivations in an MAG with ~= ~ c  , we should have written these somewhat as follows : Itold John "  ( John " should * 5o home )  , I'promised Bill(l ' would purchase books ) , John ' dese'rves NV~-~ should * pror ~ ote John ' l , He ' ~ suffered(N defeated hin 0 , He ~ is unlinspiring ( He '1% teach N to N ) , etc .  (  , marks the eleme-~with the same reference ; %: untensed ( or tenseless ) 6) .   ( b ) Certain conditions on replacing a noun by a pronoun  , e . g . , Joh ~ hoped ( he " perhaps % . 

J will wl n ~ but not Hee hoped ( John ' will win ) , etc .   ( c ) Possible correlations between tenses in the container and contained strings  ( see examples in ( a ) above )  . 
Later , in the context of generation in Gs = ( G , A ) we will discuss some additional restrictions . These do not affect the ' wellformedness' ( with respect to the satisfaction of restrictions ) in G . Thus the strings of lexical items corresponding to strings in L  ( G ) are also ' wellformed ' . 

We now consider the derivations in Gs = ( G,A) . Obviously , the purpose of 6's is to obtain the corresponding strings inGs ( i . e . , also in G '), e . g . , L to ld John to gq home -- I told Jo_~ ~ d go h ? m-e  )  , etc . Note that for each rule u or p in G , the 6' s are selected from Auor ~ respectively . Some examples of restrictions on ~' s are : ( a ) The choice of a ~ from Au ( or Ap ) may be affected by the lexical entries for the container and contained strings  , mostly by the verb ( including is ___ ~ A and is ___NN ) of the container string , e . g . , I tried to drive a car , I tried driv in ~ a . car , but ~ nly I stopped driv in ~ a car ; That he answered the . letters is true , His answering the letters is strange , but not H is answer in 5 the letters is true , etc .   ( b ) Choice of a particular preposition in a deformation may depend on the lexical entries for the container and contained  ( ? ) strings , e . g . , I know of John's coming , I believe in ( my ) leaving early , etc . 
( see Section 3 . ~ . 5 and Joshi (1969) for further details) . 
3.9.4 A Simple Example of G , Gs and G '
Let G = ( Ze , J , R ) be an NAG ( with Z = Zc ) where A =\[ N , t , V , A \]; Ze = Z =\[ ~ i = NtV , a2 = ~ tvN , o3=~tvS , o4=Nt VNS , a 9= St VN , a 6= StVA , c7=StVS*;J =\[( al , aj , r l \] U ~( o2 , ~ j , rI)O\[(a2 , oj , r ~?) O~(o3 , oj , r l ) 3 U(a \] ? , oj , rl ) ~ U(ab , o~i ' rl ~\] U\[(aS , ( ~ j , r3) , J = I ,  2 ,  3 , b ~) * A subcategorization of N's , V ' s , and A's is implicit here and is not shown explicitly in the notation  . 

R = < al , aj > Ii = 3, ~, 9, 6, 7; J = I,z, . . . , 7 . 
Let Gs = ( G , A ) be a Generation Scheme where A = \[ or i is a set of deformations ~ d the ~' s are defined as follows  . 
( Set of Constants , Cq=\[wh , __ that , ~ t?'__ , ' sing \]) ~ l : ( ai ' aj , ~k ) ~( ai , aSl , ~ k ) where i = i ,  2 ,  3 ,  ~ , 9; J = i , i = whtV , Iz ,  3 , ~; ( ai , aj , ~k)cJ ; and %~2 = whtv ~' aS = whtVS , a = whtVNS . *262: ( ai , aj , ~k)--~(ai , aj , ~ k ) where i = 1 ,  2 ,  3 ,  ~ , 5; 2 = whNtV , j = z ,  ~ , 5; (" i'aj , %) cJ ; and a z2 = w hStV . = whNtVS , o9S : < ai '
S = ~: < ai , < ai , < al , ajS > where i = S ,  ~ ,  5 ,  6 , 7; aS > . .@ i , 2, . . . , 7; < ai , aj > cR ; and a SS = that aj . 
4a S > ~< ai , a S > where i = S , ~; J = i ,  2 ,  3 , 4; aS>~R ; and af '= to V , a2~ = to VN , a 34 = to VS , to VNS . 
~9: < ai ' ~ J > ~< ~ i ' ~ j 9> where i = 3 ,  5 ,  6 , 7; J = I ,  2 , S , 4; < ai , aj > eR ; a19 = ( N's ) Ving , a 25--(N's)VingN , a 35= ( N's ) VingS , ~45 = ( N's ) Ving NS . 
We have not shown explicitly the various subsets of A associated with the rules in J and R in G  . But , these can be worked out fr~n the specification of the o~'s above  . 

Actually , we should use here a distributed adjunction rule to account for the definite article to the left of N in the host  . 
We leave this out in order not to complicate the example  . 

An NAG , G ' , equivalent to Gs = ( G , A ) can now be easily constructed ( see the discussion under Theorem 3~4 . 1) . We will not write G ' here as it is too long . It is easily seen that we can derive in Gs = ( G , A ) and therefore in G ' sentences such as , John wants to ~ o home , I prefer walking , The man who came ordered Jim to shut the door , ! promised Bill to tell John that he should visit Fred  , Bill's for c in 6John to resign annoyed him , the doors blue was the custom , My asking him to write a paper caused his leavin 6 the job , etc . 
3. ~. ~ Some Complex Deformations *
Some examples of deformations more complicated than those in 
Definition 3 . 4 . 2 ~ reasfollows : a . AJ may be defined such that it requires the adjunct string  , aj , ~ n the rule u = ( ~i ' ~ j ' ~ k ) to be a derived string . ~ then refers to not only ~ but string ( s ) which may be at most a fixed finite depth ( counted in terms of adjunction and containment levels  ) relative too . . Mostly depth i ( and occasionally depth 2 ) is adequate , e . g . , The man who had the keys finally came ~ The man finall ~ came who had the keys : The man who finall ~ came who had the keys  . . . 
b . AJ may be defined as above but with the possibility of -- or referring to not only o  . but a string which is at an arbitrary depth relative to ~  . where ~ hear bitrariness of the depth is so constrained that it S can be specified in terms certain recurrent patterns of adjunction and containment levels  , e . g . , The meetin 6 ( which ) I selected John to represent us at . . . , The people we hope that John told to water the plants  . . . , etc . \[Although slightly out of place , it might be worth mentioning here that the distinction between adjunetion and containment levels also helps in stating certain pronouning restrictions to some extent  , e . g . , the pronoun is in the contained string and not in the container string : John "  thou6ht he ' will w in but not He'thou6ht John ? will win ; but if -~ have an adjunction level then we have both : People who know Bill " like him ~ and People who know him ~ like Bill ~ if we have an adjunction level and a containment level  , we again have both : People who know Bil~want to help him ? and People who know him ~ want to help Bill ~ and if we have two successive containment levels  , we have John ' asked Bill to tell Mary to see hi ' but not He " asked Bill to tell Mary to see  John5 etc . S * For further details see Joshi (1969) . 

Cc_ . A ~ may be defined such that it not only deforms the adjunct string a j but also deforms ~ he host string ai  . Since the hostai can also-be deformed by such a or  , the precise definition of how generation proceeds in the Generation Scheme  , Gs , becomes complicated . 
Such ~' s can be used to obtain from the same * container string--contained string pair ~ two related sentences such as  , e . g . , Ths__ tt he came surprised me and it surprised me that he came  , etc . 
d_ . Sets of related l's to cover certain zeroings which have as their d~na in the container and the contained strings  , e . g . , I promised him to come ~ I promised him that I would come  , etc . One may also include here zeroing of ' appropriate ' verbs  , Vamp , e . g . , I expect him ~ I expect him to Vap p where Vap p  = ~_   , ~ r rive , etc . \] ; perhaps also Ishall ~ o ~ I promise you that I shall ~ o  ( Harris ( 1968 )  . 

From Theorem 3 . 3 . 1 we know that for every NAG there is an equivalent DAG which can be effectively found  . This means that we can eliminate the nonterminal Sas far as weak generative capacity is concerned  . Of course , we don't choose to eliminate S , but it is interesing to see the implications of this theorem  . If one examines the proof of this theorem , we notice that in effect for every complex basic string  , say , ai = abScand for every elementary basic string , say , pq , which is a replacer for ai ~ , @ we set up an 8d junction rule ( in this case a distributed rule ) such as ( pq , ( ab)(c ) , ~ ir 2) . Thus we will have to consider I know that in I know that John wenth ~ neasan adjunct of John went home  . Now ( in the spirit of the discussion in Section 3 . 4 ) adjuncts are obtained by deforming a string in Fe  ; also adjuncts have a certain degree of mobility within the host  . 
This is perhaps the reason why in some cases we come close to reali-zing this  , e . g . ,  ( i ) I hope that John will w in : we can obtain a sentence and a semi-sentence  , John will w in I hope so or a sentence and sentence adjunct  , John , I h op e , will w in ,   ( 2 ) That John passed the examination sur2rised me : John passed the examination its ur-~rised me  , John passed the examination tto mY surprise , etc . 
* This avoids having two distinct strings in G generating strings which are paraphrases of each other  . If , however , we allow this possibility the structure of Gs can be considerably simplified  . We do not follow this approach but the nature of these simplifications is discussed in Joshi  ( 1969 )  . In a different context and in a different framework  , Keenan (1969) has made a similar comment . 
-25-d3.9.7
In section 3 . ~ , in GS = ( G , A ) we imposed on G the condition that ~= ~ . Then in G ' ( equivalent to G s ) every adjunct string is obtained by deforming some string in Ec  ( = E ) in G . However , adjuncts such as , e . g . , quite in quite forgot , ~ry in very long , sc ~ equantifiers ( all , sc~e , etc . ) , sc ~ e occurences of articles , sc~etime and manner adverbials , etc . pose a problem here . There are a couple of ways around this problem . 
One solution is to consider these adjuncts as primitively adjoined in G  ( i . e . , regard them as a sort of primitive adjuncts in G  ) * . G , of course , will no longer quite satisfy the condition
E = E.c
Another more attractive solution ( certainly , motivated by some current trends in transformational theory  ) which will maintain the condition that every basic string is also a basic center string is to construct  ( i ) another NAG , G " , by retaining all strings in ~ e in G , excluding the primitive adjuncts in G , but adding new complex basic center strings ( these will now more and more become infra- ~ entence forms  )  , and also adding new adjunction and replacement rules  , and (2) a new Generation Scheme Gs "= ( G " , A ") , where A " is a new deformation set , and G " satisfies the condition ~"= Zc" , such that Gs " is equivalent to G . ( At this point , we may also remove the tenses , auxiliaries , and prepositions . Basic strings in G " will then be strings of N's , V's ( including is A and is N ) and S's) . Thus we have the alternating sequence of MAG's and 
Generation Schemes **.
G .   .   .   .   .   . Gs = ( G " , ~") ~ G : Gs(G , ~) ~ G ' and T , (G ") : L(%") = L(G):LCG s ) = T , (G ' ) * Note that there are very strong restrictions on the repeatability of these primitive adjuncts  . 
~* In principle , we could consider arbitrarily many intermediate stages  , between the first and the last MAG's . However , there would not be much point in considering such sequences  , unless each inter- .   . L?mediate stage has some reasonable llnguist lc interpret at lon  . 
-26-where G " underlies G and G underlies G ' . Further development of these ideas in so ~ e detail will be reported in Joshi  ( 1969 )  . 
Ap~ndix : Fig . A , su ~ narizes the hierarchy of certain subclasses of AL's and MAL's in relation to the phrase structure hierarchy  . 
(The replacement rule in an NAG can be generalized in such a way that all occurences of S in a complex basic string are simultaneously replaced by a specified set of replacer strings  . We call such a grammar an MAG with simultaneot ~ replace me ~ rul_ess  , MsAG , and the corresponding language , MsAL . It can be shown that MAL~MsALCSL . An MsAL has the property that the lengths of the strings in it  ( assuming an ordering in terms of increasing lengths  ) grown of aster than an exponential . The whole class of MsAG's as such does not appear to be linguistically relevant  . ) ~--27-/ r

CFU % ~ nr-LP , ~-// LsI ~
LALAI ~/. en 9~. e . Dg ~.)
I , c , ~; ., , w ~/, Co , dec ' ~", e ' ~ ET ' ~' lc*..y
F , ~./~.

References i . N . Chcmsky (1963) , Formal Properties of Grammars , Handbook of Mathematical Psychology , John Wiley (1963) , Ch .  12 . 
2  . N . Chc~sky , M . P . Sch\]tzenberger ,  (1963) , Algebraic Theory of Contextfree Languages , Computer Prograu ~ ing and Formal Systems , 
North Holland , Amsterdam.
3 . N . Chomsky (1965), Aspects of Theory of Syntax , M . I . T . Press . 
4  . S . Ginsburg (1966) , Mathematical Theory of Context-free
Languages , McGraw Hill.
5 . Z . S . Harris (1962) , String Analysis of Language Structure , Mouton , 
The Hague.
6 . Z . S . Harris (196~) , Elementary Transformations , Transformations and Discourse Analysis Papers , No . 54, University of Pennsylvania . 
7-Z . S . Harris (1965) , Transformational Theory , Language , Vol .  41 . 
8 . Z . S . Harris (1968) , Mathematical Structures of Language , 
Interscience Publishers.
9 . H . Hiz (1967) , Computable and Uncomputabl ~ lemants of Syntax , Logic , Methodology and Philosophy of Science III , North Holland , 

iO . D . Hi ~, A . K . Joshi (1967) , Transformational Decomposition , Proc . IFIP Int . Conf . on Computational Linguistics , Grenoble . 
I i . A . K . Joshi (1966) , String Representation of Transformations , Transformations and Discourse Analysis Papers , No .  ~8,
University of Pennsylvania.
12 . A . K . Joshi (1968) , Transformational Analysis by Computer , Proc . 
NIH Seminar on Computational Linguistics , Bethesda (1966) , 
Published in 1968, U.S . Dept . H.E.W.
13 . A . K . Joshi , S . Kosaraju , H . Yamada (1968) , String Adjunct Grammars , Transformations and Discourse Analysis Papers , No .  75 . 
( revised February 1969) 14 . ~ . K . Joshi (1969) , String Adjunct Gran ~ ars and Transformational Gra- ~ars  , Transformations and Discourse Analysis Papers , No . 7511 2 University of Pennsylvania ( under preparation )  . 




E . L . Keenan (1969) , A Logical Base for a Transformational Grammar of English  , Ph . D . dissertation , University of

J . J . Robinson (1968) , Dependency Structures and Transformational Rules , IBM Watson Research Center ~ Research Report , 
July (196~).
J . R . Ross (1967) , Constraints on Variables in Syntax , Ph . D . 
dissertation , M.I.T.
N . Sager (1967) , Syntactic Analysis of Natural Language , Advances in Computers , Academic Press , Vol .  8 . 
M . P . Sch~tzenberger (1961) , Some remarks on Ch~nsky's Context-free Languages , M . I . T . Quarterly Progress Report , October 1961 . 

