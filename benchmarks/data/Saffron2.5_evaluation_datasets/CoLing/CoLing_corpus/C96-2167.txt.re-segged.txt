The Power of Words in Message Planning
Michael Zock
Language & Cognition
LIMSI-C.N.R.S ., B.P . 133
91403 Orsay , France

Abstract : Before engaging in a conversation , a message must be planned . While there are many ways to perform this task , I believe that people do this in the following way  , in particular if the message is going to belong : first an outline is planned  ( global , or skeleton planning ) , which is then filled in with details ( local planning , elaboration ) . Planning proceeds thus from general to specific ( breadth first )  , that is , sentences are planned incrementally by gradual refinement of some abstract thought rather than in one go  ( one-shot process ) where every element is planned own to its last details  . 
While global planning is largely language independent  , local planning can be language dependent : the dictionary acts a media-tor  , interfacing language and thought . Given the fact that words can be used to specify nonlinguistic thought  , there is feedback from the lexical to the conceptual component  . This being so , dictionaries may play a fundamental role in guiding and potentially modifying nonlinguistic thought  . If my view is correct , this could have implications on the design of generation architectures : instead of separating message planning and realization  , viewing the process as being strictly sequential , we could allow for feedback loops ( interleaved process )  , whereby the linguistic component could feedback to the conceptual component  . 
1 Introduction
A major step in natural language-generation ( NLG ) consists in choosing content words for expressing the planned message  . While this sounds self evident , it contains at least two assumptions that are easily overlooked :  ( a ) thought precedes language ;   ( b ) thought is entirely encoded or specified before lexicalization takes place  . My contribution i this paper consists in providing evidence for the following three claims  :   ( a ) thought is underspecified at the onset of lexicalization  ; ( b ) language can feedback on thought , i . e . 
words can specify the conceptual component ;   ( c ) our mental dictionaries are the interface between language and thought  . 
NLG has often been viewed as a two step process.
During the first ( deep generation ) conceptual choices are made ( content determination , discourse planning ) , during the second ( surface generation ) linguistic ope-rations are performed ( word choice , determination of syntactic structure ) . While this kind of decomposition has proven useful for practical purposes  , ---dividing the process into separate components increased the control  , -- it has also encouraged researchers to build into their systems wrong assumptions : content is ge-nerally determined in one go  ( one-shot process )  , and information flow is one-directional , going downwards from the conceptual level to the linguistic level  . As I will show by taking an example from the lexicon  , both these conclusions are ill-lbunded , as they suggest that there is no feedback between the different components  . 
2 A naive view of generation
NLG can be viewed as the process of finding a linguistic form for a given conceptual fragment  . 
Obviously , there are certain dangers with this view . 
First of all , the order of thought , i . e . the order in which conceptual chunks become available  , and the utterance order , i . e . the order in which words have to be uttered in a given language is not necessarily the same  . Second , words cannot be directly mapped on their conceptual counterpart  , that is , there is no one-to-one correspondance btween concepts and words : a given word may express more than a single concept : leave vs  . go away ; unhappy vs . not happy ( for more detail see Nogier & Zock ,  1992) . Third , there is no feedback from the linguistic to the conceptual component  . In the remainder of this paper Ishall concentrate precisely on this latter problem by showing the interaction between these two components  . 
3 How is content planned ?
Suppose we wanted to produce the following sentence : <  , ~clentheold mansaw the little boy drowning in the river  , he went to his canoe in order to rescue him . >> . Figure 1 here below can be considered as the underlying planning tree  . But how is such a tree built ? succ
EVENT-IEVENT-I ....., 1.....I
GOAL DIRECT F . DACTION
GOAl,/\ItImallAGE.DROWNGOTOR~CUE
I/\/\/\ old PERSON-IPLACE PERS gl N-IMEANS OF'ERSON-IpERoSON-I/\II  . . . . . . . . . /\ II bnySIZE riverman can ~ BELONGTOmanL ' ~ ) Y . , , L . Imall
Figure 1 and linguistic , -- to believe that this sentence has not been planned from left to right and in one go  . 
p~ychological re!sons : The sentence is simply too long for a speaker to hold in short-term-memory all the information to be conveyed  . It is highly unlikely that the speaker has all this information available at the onset of verbalization  . The need of planning , that is , the need to lookahead and to plan in general terms  , increases with sentence length and with the ntnnber and type of embeddings  ( for example , centereml ~ xtded sentences ) . There is also good evidence in the speech error literature for the chtim that people plan in abstracterms  . False starts or repairs , like << I ' veturned on the stove switch , I mean the heaters witch >> suggest hat the temperature increasing device has been present in the speakers mind  , yet at an abstract level ( see Levelt , 1989; Fromk in 1993) . 
Linguistic reasons : as mentionned already , tile otr/er of words does not necessarily parallel the order of thought  . For example , the generation of the first word of the sentence here above  , --tile temporal adverbial " when " , -- requires knowledge of the fact that there is another event taking place  . Yet , this information appears fairly late in the sentence  . 
Figures 2 and 3 here below illustrate a reasonable way to plan such a message  . Starting with something fairly generalike , -- there are two temporally related events : EVENT-I preceding  EVENT-2   ( st@p-i )  , -- the speaker expands gradually each element ( steps 2-8 )  . 1 Step 1: The are two temporally related events
EVENT-1 PRECEDING EVENT-2
Step 2: When PERSON-I saw EVENT-3
Figure 2 t 1 will use the following conventions in the figures : text with gray background in white box : currently expanded element  ; viile o inverted question mark : not yet fully specified element  ; graybox : processed elements ; pointer : element obe elaborated . 
My comments under the figures should be read in the following way : underlined element : currently obtained result  ; capital letters : variable , hence not yet fully specified element . 
Step 2: Since there are two events , the speaker lifts to choose . Let's assume he wants to begin with EVENT-I . This allows the generation of the first element " wheW '  , and the fact that there is a PERSON who saw some EVENT  . Both person and event are still unspecified elements  , hence written in capital letters . 
Having two unspecified elements ( PERSON , EVENT-3) we have to choose . 
Step-3: Suppose we decided to elaborate PERSON.
This could yield something like man+ATTRIBUTE , meaning , that the person whose es the event is a man ( a terminal element ) whom we want to describe further by providing a elmmcterizing attribute  . Pleaseuote , that I consider both man and the variable ATTRIBUTE as sister nodes  , hence , in principle there could be a linearization problem  . Whether predicates ( in our case , the attribute ) can , or are determined before the argument they qualify  ( here man ) remains an empirical question . The situation seems clearer during lexieali -zation where a head noun may constrain an adjective  , hence the noun has to be generated first ( colloeational constraint )  . 
S tep-4 : During this step we decide on the attribute , the result might be " old " . One could object that an intermediate step is necessary in order to decide on the kind of attribute  ( size , age , etc , ) . This is correct , but lot reasons of economy ( size of the figures )  , we've skipped this step . 
Step-S : During this step we elaborate the node EVENT-3 which yields : someone drowns somewhere , where the person and the place are still unspecified  . 
Again we have to choose which element oelaborate.
Suppose we started with PERSON-2.
Step 6: This could yield boy + ATTRIBUTE . Boy being a terminal element it needs no fnrther refi-nement  , but we do still need to specify its attribute . 
S tep-7 : If we were to characterize the boy in terms of size  , we might get " small " . 
Step-E : The instanciation of the variable ( PLACE ) might yield river . 
Having completed the description of EVENT-1 we still have to specify EVEN'r-2  . We will leave this as nexercice l br the motivated reader  ( bencourage ! )   4 Possible implications Letus see some of the advantages of our approach  . 
Top-down , left-to-right expansion gives the speaker a good control over the whole process  , minimizing tile danger of forgetting some information because of memory overload  . Of course , the tree can be built in different ways , topdown , bottom-up , or by combining both methods . 2 For related appl ' oaches on 2I believe , that the way how the tree is built depends on whether tile speaker has at the onset of message planning a clear picture of the object or scene to describe  , or whether he has to build it from scratch . In the first case he could build the tree from top to bottom  . 

Step 3: When theman+ATTRIBUTE saw ...
Step 4: When the old man saw ...
Step 5: When the old man saw
PERSON-2 drowning in PLACE-X , EVENT-2
Step 6: When the old man saw the ~+ ATTRIBUTE drowning in PLACE-X  ,   EVENT-2 Step 7: When the old mansaw the little boy drowning in PLACE-X  ,   EVENT-2 chosen node for elaboration Step 8: When the old mansaw the little boy drowning in the river  , EVENT-2

Figure 3 grammar ( de Smedt & Kempen 1991), or 7? ee
Adjoining Grammar ( Joshi 1987).
If my line of reasoning concerning message planning is correct  , -- namely that planning is basi- ( ' ally a two-step process where l'irst a skeleton is planned  ( general plan )  , and then its constituents ( pe-cific plan ) , -- then this should have consequences on the overall architecture  o1' generators , as well as on the infornmtion flow ( control , process ) . We shall see this in the next section on lexical choice  . The basic question that arises in this context is the following : when do we process what ' ? This suggests the corrolary questions : Is all information pertaining to a given module processed in one go  ( one shot )  , or am objects gradually refined ( several passes ) ?
For example , l . is everything related to meaning processed entirely and once and for all --- hence messages can neither be changed not " be refined --- or  2  . are the objects to be talked about only specified to the degree to which they need to beat this stage of the process  ( limited commitment planning ) ? Actually , it is quite easy to find arguments in favor of this second hypothesis  . Why should we cam at an early stage of the process about details  , if we aren't sure at that point , whether the global message will meet the goal defined ? Put differently  , why camat that stage about the specificity of a word or a relY-rent  ( how great a detail to give in order to ch~u'ac -lcriz can object  ) if we areffl even sum whether the planned message contains all and only the inlor-nmtion we wish to convey ? In a similar vein  , why both er about style , spelling and punctuation , and so forth , if syntactic structure is likely to hechang txl ? The point  1 amtrying to make is that , people probably start by planning things globally  , filling this plan with details at a later stage ( local planning )  . 
We cycle through the same kind of process but at different levels of detail  . Having built a global plan we Iles hit out with details as soon as this becomes necessary  . The speech error literature abounds with examples supporting this point of view  . Blends , substitutions , or speech repairs like'tie conquered Babylon , the great Alexander ' , seem all to suggest , that the speaker plans his message in abstract erms  . 
For details see(l , evelt 1989; Fromk in , 1993).
Genuine examples , as the l bllowing from Maclay and Osgood ( 1959:25 ) clearly show that the speaker has not necessarily everything planned at the onset of articulation : kruger stretches of spontancous discourse are full of pauses  , stutters and mistakes : < < As far as lknow , no one yet has done the/in a way obvious now and interesting problem of I pausel doing a/in a sense a structural frequency study of the alternative\[pause\]syntactical\[uhl/ina given language  , say , like English , the alternative \[ uhl possible structures , and how/what their hierarchical I pause l probability of occurrence structure is  .  >>  5 Lexical choice as paltem matching Having planned the underlying content  , let's see how the dict kmary may feedback on the conceptual component  . The process of finding words for conceptual structures can be viewed as lexically nrediated  , hence indirect structure mapping : conceptual li ' agments ~ ue mapped onto words via the lexicon  ( see figure 4 )  , the latter serving as an interface between thought  ( concepts ) and language ( words )  . 
This view raises a number of interesting problems :   ( a ) What shall we do if not all of the planned message can be expressed by the words available at a given moment ? Should we backtrack  ( try to lind another word )  ; change the underlying meaning ( replan Figure 4: The lexicon ( I , L ) as mediator between the conceptual level ( CL ) and word level ( WIO . 
the content by adding or deleting some inlbrnmtion  )  ; or carry over to the next cycle ( word or sentence ) the specific parl that could n'l be expressed ( cany-over phenomenon ) ' ? For an atl : cmp to solve this problem , see Nicolov et al (1996) .   ( b ) On what basis do we choose among a set of potential candklates ?  ( c ) What information is available at the onset o1' lexicalization ( all or only part )  , i . e . at what moment is the word's underlying meaning fully specified ? In order to answer these questions  , let me take an example . Suppose we warned to express the fact that a person moves on a given surl hcein a given direction  ( see GI in Figure 5 next page , or , the left branch of second EVENT of our example in section  3 on message phmning: . . . he went to his canoe . . . ) . 3 Obviously , there is more than one way . According to the input specifications we could consider either ' to move  , to swim , to walk ' , or ' to run ' . All these words express the notion of movement . Yet , not all of them fit equally well the initial message  , and lor quite different reasons . While the second cmldidate ( '1 oswim ' ) is simply in contradiction with tmrt of thc initial specification  ( location : ground )  , the last one ( ' to run ' ) expresses more than the initial message phnmcd . Now , what cot , klmotivate the choice between the two remaining candidates  , ' to move ' ~ u ~ l ' to walk "? Both of the mm'e subgraphs of the utterance graph  , that is , both of them express part of the message planned . Yet ' to walk ' expresses more of : ~ Figure 5 is to be read counter clockwise . 

GI : Initial Utterance graphilh .   G2 : New Utterance graphi :: ~: ii ~: ii ~: i ~? : i ~ i ~ i ~i : ~~:' i ~ i ii ii ! i ~ i ~ i ! iii ! ~ i ~ / ~ i `  . i ~ ii ~ / ii ` ~ i ~ . ~i ! ~ ii ! i ~ i ~ ! ~ i i ~ i : : ~ , i i i ~ i ~ : ~ : : : i : i i : i : i : ~ i i i ~ i i i i ~! ii ; i ~: ii:~:i~i:ii::~i:VERB:"tomove"?VERII : " to move " Correlation factor:  2 ? VERB : " to swim " IP , ~ . ~?,' . '~ . ?l--<~--I . o ~, ~ . ~ . : . ~? lr-finn~?VERB : " to swim " Correlat ion factor :  2 VERB : " to walk " ? VERB : " to walk " Correlation factor:  4 ? VERB:"torun"?VERB:"tarun " Correla tion factor :  4 message ( concept ) planned before the lexicalization phase not matched  , hence unexpressed concept
Figure 5 matched , hence expressed concept concept added after the lexicalization phase will be preferred  . 
Actually , the choice of a specific word will depend to a large extend on pragmatic factors like speaker's goals  , time and space constraints , hearer's expertise , and so forth . Of course , all these factors can be interrelated . If concisenessi what we are looking for , then the most specific word ( ' to walk ' ) is to be preterred to the more general term ( ' to move ' )  . The reason is simply economy : more of the message is expressed by using the given resources  , hence time and space is gained . There is a limitation though . The words chosen have to match the user's expertise  . A cooperative speaker uses dense words 4 or technical terms ( ' computer ' , ' space shuttle ' ) only for people whose lexical competency allows them to understand their meaning  , otherwise he will decompose these words . 
Now let me get back to the last candidate ( ' to run ' )  , as it raises an interesting problem . The word's underlying meaning is not in contradiction with the initial message  . Yet it does not express exactly what was planned . Actually , it expresse something more : the notion of speed . 5 This being so , the question arises , whether ' to run ' can be considered as a valid candidate  . I believe that it does , provided that the additional information ( speed ) is consistent with some belief about the state of the world  , and that the speaker considers it worthwhile mentioning  , if that is so , then we have here evidence for feedback of the lexical component to the conceptual component  . The described situation may seem somehow artificial  , yet ,   1 believe it occurs quite often in spontaneous discourse  , even if we are not aware of it . When we get to the point of choosing a word , it is the power of the language that drives us to say something that was not initially planned  . Of course , we are ti ' ee not to mention the additional piece of information  , but this is not really the point . The point is , that not all information ultimately expressed by a word has been available in the speaker's mind at the onset of lexicalization  . 
6 Discussion
The approach taken here raises an interesting problem  . When choosing words we express not only a given meaning  , but we may end up adding to the conceptual structure  ( message ) meanings thin initially we had not planned . While there are good reasons to believe that at an early stage of processing the tm derlying meaning of words is underspecified '  , rod 4 Dense words are generally abstract words like inflation-rate  , superstition , belief . They carry a lot of information . 
Please note that this example serves only for illustrative purposes  . Actually , ' to run ' and ' to move fast on the ground " do not refer exactly to the same kind of locomotion  . For more details , see Nogier & Zock (1992) . 
abstract , hence language independent , the question arises whether the information added during the expansion phase is not language specific to a large extent  . Much of the information to be ~: tedis precisely intbrmation required by the lexicon  . While it is possible that for syntactic and other reasons we cannot use or retrieve the word planned  , it is less obvious why one would want to add at this stage information for which we don't have words  ( see also Meteer ,  1990) . Obviously , subscribing to our reasoning is taking a stance with regard to the language-thought debate  ( Whorl ,  1956) , namely , language may drive thought . Surprisingly , this is all the more likely as we get close to the surface  , that is , relatively late in the process . 
7 Conclusion
In this paper I have tried to give evidence for three claims  , namely that thought is not completely specified at the onset of lexicalization  ; that there is feedback from the lexical to the conceptual component  ; and that the dictionary plays aflmdamental role in guiding and potentially modifying nonlinguistic thought  . Hence , it is during the lexicalization phase that language can play this important role over thought  . This is what I meant to say , when I wrote in my title : the power of words in message planning  . 

K . de Smedt&G . Kcmpen : Segment grammar : al ' or ma-lism for Incremental Sentence Generation  , In , Paris , C . & W . Swart out & W . Mann ( Eds . ) . Natural Language Generation in Artificial Intelligence and Computational Linguistics  , K\[uwer Academic Publishers , 
Boston , 1991
V . From kin : Speech Production . In J . Berko , Gleason & N . Bernstein Ratner ( eds . ) Psycholinguistics . Fort Worth , TX : Harcourt , Brace , Jovanovich . 1993 A . Joshi : Tree Adjoining Grammars and their Relevance to Generation  , in : Kempen ( Ed . ) . Natural Language Generation : New Results in Artificial Intelligence  , Psychology and Linguistics , Martinus Nijhoff Pbs , 
Dordrecht , 1987
W . Levelt : Speaking : From Intention to Articulation  . 
Cambridge . Mass .: MIT Press ; 1989
M . Meteer : The ' Generation Gap ': the problem of expres-sibility in text planning  . , BBN Rep . n ? 7347, 1990 . 
J . F . Nogier J . F . & M . Zock : Lexical choice by pattern matching . In Knowledge Based Systems , 5(3), 1992 . 
N . Nicolov , C . Mellish and G . Ritchie , Approximate Generation from Non-Hierarchical Representations  ,   8th International Workshop on Natural Language Generation  , Herstmonceux Castle , 1315 June 1996 . 
B . Whorf : Language , thought , and reality . Cambridge . 
Mass ., MIT Press , 1956
