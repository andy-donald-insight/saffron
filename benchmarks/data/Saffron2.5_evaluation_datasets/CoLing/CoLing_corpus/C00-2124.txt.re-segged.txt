Applying System Combination to Base Noun Phrase Identification 
Erik F . Tjong Kim Sang " , Walter Daelemans ' ~ , Herv 6D 6jean ~ , 
Rob Koeling T , Yuval Krymolowski / ~ , Vasin Punyakanok ' ~ , Dan Roth "
~University of Antwert)
Uifiversite its plohl 1
13.-26 1.0 Wilrijk , Belgium

rUnive . rsitiil ; Tiil)ingen
Kleine Wilhehnstrat . / e113
I)-72074T/il)ingen , Germany
(lejean((~sl:q,ni ) hil.ulfi-l ; uebingen.de,
7S 1, I Cambridge
23 Millers Yard , Mill Lane
Cambridge , CB 2ll Q , UK

; ~ Bal'-Ilan University
lbunat Gan , 52900, Israel
yuwdk(c ~) macs.1)iu.ac.il
" University of Illinois
1304: W . Sl ) ringfield Ave.
Url ) ana , IL 61801, USA
lmnyakan , ( lanr((~cs.uiuc.edu
A1) stract
Weus (' . seven machine h ; arning algorithms t brone task : idenl ; it ~ yingl ) as e holm phrases . The results have 1 ) eent ) rocessed by ditt'erent system combination methods and all of these  ( mtt ) er-formed the t ) est individual result . We have ap-t ) lied the seven learners with the best ( : omt ) in a-to t , a majority vote of the top tive systenls , to a standard ( lataset and lllallage (1I ; Oilnl ) rov (' ,  1 ; 11('t ) estpul ) lished result % r this ( lataset . 
1 Introduction
Van Haltor ( meta\] .   ( 1998 ) and Brill and Wu ( 1998 ) show that part-of st ) ee ( : h tagger l ) erfor-mance can 1 ) eiml ) roved 1 ) y ( : oml ) ining ditl'erent tatters . By using te (: hni ( tuessu (: has majority voting , errors madel ) y1 ; 11( ; minority of the taggers can 1) er ( ; moved . Van Ilaltere , net al ( 1998 ) rel ) ort that the results of such a ( ' oml ) in edal ) -proach can improvell \] ) Oll the a C cllracy error of the best individual system with as much as  19%  . 
T impositive ( ; tl'e ( : t of system combination t br non-language t ) ro ( : essing tasks hast ) een shown in a large l ) o ( ly of mac \] finelarning work . 
In this 1 ) a per we will use system ( : omt ) ination for identifying base noun 1 ) hrases ( 1 ) aseNt ) s )  . 
W ( ; will at ) l ) lyseven machine learning algorithms to the same 1 ) as eNP task . At two l ) oints we will al ) plyconfl ) ination methods . We will start with making the systems process five out-trot representations and combine thel ' esults t  ) y ( : hoosing the majority of the outtmttL ' atures . 
Three of the seven systems use this al ) l ) roaeh.
Afl , erthis w ( ; will make an overalleom l ) ination of the results of the seven systems . There we will evaluate several system combination meth-  ( ) ( Is . The 1 ) est l ) er forming method will 1 ) eat ) -t ) lied to a standar dataset t brbase NP identi -tication  . 
2 Methods and experiments in thisse ( : tion we will describe our lem:ning task : recognizing  1  ) ase noun phrases . After this we will ( tes ( :ril ) e the data representations we used and them a ( ' hinelearning algorithms that we will at ) l ) ly to the task . We will con ( : ludc with an overview of the ( : ombination metllo ( ls that we will test . 
2.1 Task description
Base noun \] ) hrases ( 1 ) as eNPs ) aren ( mn phrases whi ( : h do not ( : ontain another noun l ) hrase . \]? or cxamt)le , the sentence In \[ early trading \] in\[IIong Kong \]\[ Mo  , l , tay\] , \[ g , ,la \] was q , loted at \[$366 . 0\]\[a . o1, , , . (; \]  . 
contains six base N1 ) s ( marked as phrases between square 1 ) rackets )  . The phrase $266 . 50 a nounce ix a holm phrase as well . However , it is not a base NP since it contains two other noun phrases  . Two base NP datasets haw . ' been put forward by Ramshaw and Marcus (1995) . The main dataset consist of t bursections of the Wall Street Journal  ( WSJ ) part of the Penn Treebank ( Marcus et al ,  1 . 993) as training material ( sections 15 18 , 211727 tokens ) and one section a Stest material ( section 20 , 47377 tokens ) 5 . 
The data contains words , their part-of-speech 1This Ramshaw and Marcus ( 1995 ) basc NP dataset is availal ) leviaffp://fti )  . cis . upe,m . edu/pub/chunker / their base NP segmentation as derived from the %' eebank  ( with some modifications )  . 
In the base NP identitication task , performance is measured with three rates . First , with the percentage of detected noun phrases that are correct  ( precision )  . Second , with the 1 ) ercentage of noun phrases in the data that were found by the classifier  ( recall )  . And third , with the F#=~rate which is equal to ( 2*preci-sion*recall ) / ( precision + recall )  . The latter rate has been used as the target for optimization  . 
2.2 Data representation
In our example sentence in section 2 . 1 , noun phrases are represented by bracket structures  . 
It has been shown by Mufioz et al ( 1999 ) that for base NP recognition , the representation with brackets outperforms other data representations  . One classifier can be trained to recognize open brackets  ( O ) and another can handle close brackets ( C )  . Their results can be combined by making pairs of open and close brackets with large probability scores  . We have used this bracket representation ( O+C ) as well . 
However , we have not used the combination strategy from Mufioz et al  ( 1999 ) trot instead used the strategy outlined in Tjong Kim Sang  ( 2000 ) : regard only the shortest possible phrases between candidate open and close brackets as base noun phrases  . 
An alternative representation for base NPs has been putt brward by Ramshaw and Marcus  ( 1995 )  . They have defined base NP recognition as a tagging task : words can be inside a base NP  ( I ) or outside a base NP ( O )  . In the case that one base NP immediately follows another base NP  , the first word in the second base NP receives tag B  . Example:
In oearly 1 trading 1 in oHongiKongi
Monday B , ogold 1 was o quote do a to $ I3 66 . 501 anuounce 1 . o This set of three tags is sufficient for encoding base NP structures since these structures are nonrecursive and nonoverlapping  . 
Tjong Kiln Sang ( 2000 ) outlines alternative versions of this tagging representation  . First , the B tag can be used for tile first word of every base NP  ( IOB2 representation )  . Second , instead of the B tag an E tag can be used to nlark the last word of a base NP immediately before another base NP  ( IOE1 )  . And third , the E tag call be used for every noun phrase final word  ( IOE2 )  . He used the Ramshaw and Marcus ( 1995 ) representation as well ( IOB1 )  . We will use the set burtagging representations and the O+C representation for the system -internal combination experiments  . 
2. a Machine learning algorithms
This section contains a brief description of tile seven machine learning algorithms that we will apply to the base NP identification task : AL -Li S  , c5 . 0, IO ~? ee , MaxEnt , MBL , MBSL and

ALLiS2 ( Architecture for Learning Linguistic Structures ) is a learning system which uses theory refinement in order to learn nonrecursive NP and VP structures  ( Ddjean ,  2000) . ALLiS generates a regular expression grammar which describes the phrase structure  ( NP or VP )  . This grammar is then used by the CASS parser ( Ab-hey ,  1996) . Following the principle of theory refinement , tile learning task is composed of two steps . The first step is the generation of an initial wa  , mmar . The generation of this grmn-mar uses the notion of default values and some background knowledge which provides general expectations concerning the immr structure of NPs and VPs  . This initial grammar provides an incomplete and /or incorrect analysis of tile data  . The second step is the refinement of this grammar  . During this step , the validity of the rules of the initial grammar is checked and the rules are improved  ( refined ) if necessary . This refinement relies on the use of two operations : the contextualization  ( i which context such a tag always belongs to the phrase  ) and lexicalization ( use of information about the words and not only about POS  )  . 
05 . 0 a , a commercial version of 04 . 5 ( Quinlan ,  1993) , performs top-do , vn induction of decision trees ( TDIDT ) . O , 1 the basis of an instance base of examples ,  05 . 0 constructs a decision tree which compresses the classification i-formation in the instance base by exploiting dif-t brences in relative importance of different features  . Instances are stored in the tree as paths 2A dem of the NP and VP ctmnker is available at ht ; t:p://www . sfb441 . unituebingen . de/~dejan/chunker . html a Available fl ' om http://www . rulequest . comtain classification information . Nodes are connected via arcs denoting feature w flues  . Feature inff ) rmation gain(nmt ; ualinforniation 1 ) etween features and class ) is used to determine the order in which features aremnt  ) loyed as tests at all levels of the tree ( Quinlan ,  1993) , With the full in lmt representation ( words and POS tags ) ~ we were not able to run comt ) let experiments . We therefore xperimented only with the POS tags ( with a context of two left ; and right ) . We have used the default parameter setting with decision trees coml  ) ined with w flue groul ) ing . 
We have used a nearest neighbor algoritlm l(IBI . -1G , here listed as MBL ) and a decision tree algoritlm i ( llG\[lh:ee ) from the TiMBL learning package ( D a ( flmnans et al ,  19991)) . Both algorithms store the training data and ( ' lassi ( y new it ; eros by choosing the most frequent ( : lassiti ( : a-lion among training items which are closest to this new item  . l ) at a it ( unsrarerel ) resented as sets of that ure-vahu ; 1) airs . Eachti ; a ture recc'ives a weight which is t ) a sed on the amount of information whi ( : hitt/rovidesfi ) r comtmting the classification of t ; t1( ; items in the training data . 
IBI-IG uses these weights t br comt ) uting the dis-lancel ) etween at ) air of data items and IGTree uses them fi ) r deciding which feature-value decisions shouMt ) e made in the top nod (  ; s of the decision tree ( l ) a ( ; lenJans et al ,  19991)) . We will use their det , mltpm : a met ( ' a : sexcel ) t for the IBI-IGt ) a rameter for the numl ) er of exm nine ( tm ' , are stn ( , ighl ) or s(k)whi('h weh~ves ( , t to 3 ( Daelemans et al , 1999a ) . The classifiers use a left and right context of four words and part-of sl  ) eech tags . t ~ i ) r ; lie four IO representations we have used a second i  ) rocessing stage which used a smaller context lint which included information at  ) out the IO tags 1 ) redicted by the first processing phase ( Tjong Kim Sang ,  2000) . 
When /) uilding a classifier , one must gather evidence ti ) r predicting the correct class of an item from its context  . The Maxinmm Entropy ( MaxEnt ) fl : mnework is especially suited t brintegrating evidence tiom various in ti  ) rmal ; ion sources . Frequencies of evidence/class combi~nations ( called features ) are extracted fl'om a sample corlms and consider e ( t to be t ) roperties of the classification process . Attention is constrained to models with these l ) roperties . The MaxEntt ) rinciph ; now demands that among all 1 ; 11( ;  1 ) robability distributions that obey these constraints  , the most mfi form is chosen , l ) ur-ing training , features are assigned weights in such a way that , given the MaxEnt principle , the training data is matched as well as possible . 
During evaluation it is tested which features are active  ( i . e . a feature is active when the context meets the requirements given by t  ; 11(' , feature ) . 
For every class the weights of the active features are combined and the best scoring class is chosen  ( Berger et al ,  1996) . D ) r the classi-tier built here the surromlding words  , their POS tags and lmse NP tags predicted for the previous words are used its evidence  . A mixture of simple features ( consisting of one of the mentioned information sources  ) and complex features ( combinations thereof ) were used . The left context never exceeded 3 words , the right context was maximally 2 words . The model wits ( : ah : ulated using existing software ( l ) e haspe ,  1997) . 
MBSL ( Argalnon et al ,  1999 ) uses POS data in order to identit~yt/ase NPs , hffere nee relies on a memory which contains all theo  ( :- cm:rences of P ( )S sequences which apt ) ear in the t ) egimfing , or the end , of a 1) ase Nl ? ( in-(: hiding complete t ) hrases ) . These sequences may include a thw context tags , up to a 1) re-st)ecifi('dmax_(:ont <~: t . \]) uring in ti ' , rence , MBSL tries to ' tile ' each POS string with parts of noun-l  ) hrases from l ; he memory . If the string coul ( 1 l ) efully covered t ) y the tiles , il ; becomes l ) art of a (: andidate list , anfl ) iguities 1 ) etween candidates are resolved by a constraint ) ropa-gation algorithm . Adding a ( : on text extends the possil ) ilities for tiling , thereby giving more opportunities to 1 ) etter candidates . The at ) t ) roaeh of MBSL to the i ) rot ) lem of identifying 1 ) as eNPs is sequence -1 ) ased rather than word-based , that is , decisions are taken per POS sequence , or per candidate , trot not for a single word . In addition , the tiling l ) rocess gives no preference to any ( tirection in the sentence . The tiles may 1) e of any length , up to the maxima length of a 1 ) hrase in the training ( ILl ; L , which gives MBS La generalization power that compensates for the setup of using only POS tags  . The results t ) re-seated here were obtained by optimizing MBSL parameters based on  5-fold CV on the training data . 
SNoW uses the Open/Close model , described in Mufioz et al (1999) . As is shown there , this




O+C 97.63% 97.80% 97.72% 97.72%

Majority 98.04% 98.20%
CF fl = l 97 . 97% 91 . 68 97 . 96% 91 . 79 97 . 92% 91 . 54 97 . 94% 92 . 06 98 . 04% 92 . 03 92 . 82

OC97 . 90% 98 . 11% 97 . 81% 98 . 14% 97 . 88% 98 . 12% 97 . 84% 98 . 12% 97 . 82% 98 . 15% 97 . 94% 98 . 24%
Ffl=l 92.14 92.37 92.13 92.26 92.60

OC96 . 62% 96 . 89% 97 . 27% 97 . 30% 95 . 88% 96 . 01% 97 . 19% 97 . 62% 96 . 89% 97 . 49% 97 . 70% 97 . 99%
F\[~=187 . 88 90 . 03 82 . 80 89 . 98 89 . 37 91 . 9 2 Table 1: The effects of system-internal combination by using different output representations  . A straightforward majority vote of the output yields better bracket accuracies and Ffl = lrates than any included individual classifier  . The bracket accuracies in the cohm msO and C show what percentage of words was correctly classified as base NP start  , base NP end or neither . 
model produced better results than the other paradigm evaluated there  , the Inside/Outside paradigm . The Open/Close model consists of two SNoW predictors  , one of which predicts the beginning of base NPs ( Open predictor )  , and the other predicts the end of the ptlrase ( Close predictor )  . The Open predictor is learned using SNoW ( Carlsonel ; al . , 1999; Roth ,  1998 ) as a flmction of features that utilize words and POS tags in the sentence and  , given a new sentence , will predict for each word whether it is the first word in the phrase or not  . For each Open , the Close predictor is learned using SNoW as a function of features that utilize the words ill the sentence  , the POS tags and the open prediction . It will predict , t breach word , whether it Call be the end of " the I ) hrase , given the previously predicted Open . Each pair of predicted Open mid Close forms a candidate of a base NP  . These candidates may conflict due to overlapping ; at this stage , a graphbased constraint satisfaction algorithm that uses the confidence values SNoW associates with its prediction sieln ployed  . This algorithl n ( " the combinator ' ) produce stile list of " the final base NPs fbr each sentence  . Details of SNOW , its application in shallow parsing and the combinator % Mgorithm are in Mufioz et al  ( 1999 )  . 
2.4 Combination techniques
At two points in our noun phrase recognition process we will use system combination  . We will start with system-internal combination : apply the same learning algorithm to variants of the task and combine the results  . The approach we have chosen here is the same as in Tjong Kim Sang  ( 2000 ) : generate different variants of the task by using different representations of the output  ( IOB1 , IOB2 , IOE1 , IOE2 and O+C ) . The five outputs will converted to the open bracket representation  ( O ) and the close bracket ; representation ( C ) and M'ter this , tile most frequent of the five analyses of each word will chosen  ( in a jority voting , see below ) . We expect the systems which use this combination phase to perform better than their individu M members  ( Tjong Kim Sang ,  2000) . 
Our seven learners will generate different classifications of tile training data and we need to find out which combination techniques are most appropriate  . For the system-external combination experiment , we have evaluated it fi ; rent voting lllechanisms ~ effectively the voting methods as described in Van Halteren et al  ( 1998 )  . 
In the first method each classification receives the same weight and the most frequent classification is chosen  ( Majority )  . The second nmthod regards a stile weight of each individual classification algorithm its accuracy on solne part of the data  , tile tuning data ( Tot Precision ) . 
The third voting method computes the precision of each assigned tag per classifer and uses this value as a weight for tile classifier in those cases that it chooses the tag  ( Tag Precision )  . 
The fourth method uses both the precision of each assigned tag and tile recall of the competing tags  ( Precision Recall )  . Finally , tile fifthl nethod uses not only a weight for tile current classification but it also computes weights t brother possible classifications  . The other classifications are deternfined by exalnining the tun-  (  ; very pair of classitie results ( pairwise voting , see Van Halteren et al ( 1998 ) t brane laborate explanation )  . 
Apart from these five voting methods we have also processed the output streams with two clas -sifters : MBL and IG % ' ee  . This approach is called classifier stacking . Like Van Halteren et al .  (1998) , we have used diff'erent in tmt versions : olle containing only the classitier Otltl  ) ut and another containing both classifier outlmt and a compressed representation of the data item tamer consideration  . \]? or the latter lmr-pose we have used the part -of-speech tag of the carrent word  . 
3 Results 4
We want to find out whether system combination could improve performmlce of base NP recognition and  , if this is the fact , we want to seJect the best confl ) ination technique . For this lmrpose we have pertbrmed an experiment with sections  1518 of the WSJ part of the Prom %' ee-bank as training data  ( 211727 tokens ) and section 21 as test data ( 40039 tokens )  . Like the data used by Ramshaw and Marcus (1995) , this data was retagged by the Brill tagger in order to obtain realistic part of speech  ( POS ) tags 5 . 
The data was seglnent e . d into base NP parts and non-lmse NP t ) art sill a similar fitshion as the data used 1 ) y Ramshaw and Marcus ( 1995 )  . Of the training data , only 90% was used for training . The remaining 10% was used a slaming data for determining the weights of the combination techniques  . 
D ) r three classifiers ( MBL , MaxEnt and
IGTree ) we haw ; used system-internal coral)i-nation . These learning algorithms have processed five dittbrent representations of the output  ( IOB1 , IOB2 , IOE1 , IOE2 and O-t-C ) and the results have been combined with majority voting  . The test data results can 1) efimnd in Table 1 . In all cases , the combined results were better than that of the best included system  . 
Tile results of ALLiS , 05 . 0 , MBSL and SNoWhavetmen converted to the O and the C  repre-4Detailed results of our experiments meavailable on http : // lcg-www  . uia . ae . be/-erikt/np('oml , i / S There tagging was necessary to assure that the performance rates obtained here would be similar to rates obtained for texts for which no Treebank POS tags are available  . 
section 21

ALLiS05.0





Simple Voting



Precision Recall 97 . 05% 97 . 70% 97 . 94% 98 . 04% 97 . 27% 97 . 78% 98 . 08% 98 . 08% 98 . 08% 98 . 08%
CFS = j 98 . 08% 92 . 15 97 . 76% 89 . 97 97 . 99% 91 . 92 98 . 24% 92 . 60 98 . 20% 92 . 82 97 . 66% 90 . 71 97 . 68% 91 . 87 98 . 21% 92 . 95 98 . 21% 92 . 95 98 . 21% 92 . 95 98 . 21% 92 . 95
Pairwise Voting
TagPair 98.13% 98.23%

Tags 98.24% 98.35%
Tags 4-P () S 98.14% 98.33%
Deeision Trees
Tags 98.24% 98.35%
Tags + POS 98 . 13% 98 . 32% 93 . 07 93 . 39 93 . 24 93 . 39 93 . 2 1 Table 2: Bracket accuracies and Ff~=l scores for section WSJ  21 of the Penn ~15'eebank with seve , n individual classifiers and combinations of them  . Each combination t ) er forms t ) etter than its best individual me , tuber . The stacked classi-tiers without COllte , x t intbrmation perform best . 
sentation . Together with the bracket ; ret ) resen-tations of the other three techniques , this gave us a total of seven O results and seven C results  . 
These two data streams have been combined with the combination techniques described in section  2  . 4 . After this , we built base NPs from the , O and C results of each combinatkm technique , like , described in section 2 . 2 . The bracket accuracies and tile F~=I scores tbr test data can be found in Table  2  . 
All combination siml ) rove the results of the best individual classifier  . The best results were obtained with a memory -based stacked classi-ter  . This is different from the combination results presented in VanIlalteren et al  ( 1998 )  , in which pairwise voting pertbrmed best . How-eves , in their later workstacked classifiers out -per Ibrmvoting methods as well  ( Van Halteren et al , to appear ) . 
8 61 section 20 accuracy precision recall Best-five combination 0:98  . 32%C:98 . 41% 94 . 18% 93 . 55% Tjong Kim Sang (2000) O : 98 . 10%C:98 . 29% 93 . 63% 92 . 89% Mufioz et al (1999) O : 98 . 1% C : 98 . 2% 92 . 4% 93 . 1% Ramshaw and Marcus (1995) IOB 1:97 . 37% 91 . 80% 92 . 27%
Argamon et al (1999) - 91.6% 91.6%
F/3=1 93.86 93.26 92.8 92.03 91.6
Table 3: The overall pertbrmance of the majority voting combination of our best five systems  ( selected on tinting data perfbrnmnce ) applied to the standard dataset pntt brward by Ramshaw and Marcus  ( 1995 ) together with an overview of earlier work . The accuracy scores indicate how often a word was classified correctly with the representation used  ( O , CorIOB1) . The combined system outperforms all earlier reported results t br this dataset  . 
Based on an earlier combination study ( Tjong Kim Sang ,  2000 ) we had expected the voting methods to do better . We suspec that their pertbrmance is below that of the stacked classifiers because the difl hrence between tile best and the worst individual system is larger than in our earlier study  . We assume that the voting methods might perform better if they were only applied to the classifiers that perform well on this task  . In order to test this hypothesis , we have repeated the combination experiments with the best n classitiers  , where n took vahms from 3 to 6 and the classifiers were ranked based on their performance on the tnning data  . Thet ) est pertbrmances were obtained with five classifiers :  F/~=1=93  . 4 4 for all five voting methods with tile best stacked classi-tier reaching  93  . 24 . With the top five classifiers , tile voting methods outpert brm the best ; combination with seven systems G . Adding extra classification results to a good combination system should not make overall performance worse so it is clear that there is some room left for improvement of our combination algorithms  . 
We conclude that the best results ill this task can be obtained with tile simplest voting method  , majority voting , applied to the best five of our classifiers . Our next task was to apply the combination apt ) roach to a standard dataset so that we could compare our results with other work  . For this purpose we have used 6V~re are unaware of a good method for determining the significance of F~=I differences but we assume that this F~=I difference is not significant  . However , we believe that the fact that more colnbination methods per-tbrm well  , shows that it easier to get a good pert brmml ce out of the best  ; five systems than with all seven . 
tile data putt brward by ll , amshaw and Marcus (1995) . Again , only 90% of the training data was used tbr training while the remaining  11  ) % was reserved t brranking the classifiers . The seven learners were trained with the same parameters as in the previous experiment  . Three of the classifiers ( MBL , MaxEnt and iG %' ee ) used system-internal combination by processing different output representations  . 
The classifier output was converted to the O and the C representation  . Based on the tuning data performance , the classifiers ALLiS , 
IGTREE , MaxEnt , MBL and SNoW were selected for being combined with majority voting  . After this , the resulting O and C representations were combined to base NPs by using the method described in section  2  . 2 . The results can be found in Table 3 . Our combined system obtains an F/~=I score of 93 . 8 6 which corresponds to an 8% error reduction compared with tile best published result t br this dataset  ( 93 . 26) . 
4 Concluding remarks
In this paper we have examined two methods for combining the results of machine learuing algorithms tbrid entiicing base noun phrases  . Ill the first I nethod , the learner processe different output data representations and tile results were combined by majority voting  . This approach yielded better results than the best included classifier  . Ill the second combination approach we have combined the results of seven learning systems  ( ALLiS , c5 . 0, IG Tree , MaxEnt , MBL , MBSL and SNOW) . Here we have tested different confl ) ination methods . Each coilf l ) inationing algorithm and a majority vote of the to l  ) five systems peribrmed best . We , have a tilie , d this approach of system-internalnd system -external coral nation to a standar dataset for base noun phrase identification and the  1ertbr-mance of our system was 1  ) etter than any other tmblished result t br this dataset  . 
Our study shows that the c , omt ) ination meth- ( Is that we have tested are sensitive for the inclusion of classifie results of poor quality  . This leaves room for imt ) rovement of our results tyevaluating other comlinators  . Another interesting a pl ) roach which might lead to a letter t ) er-frmance is taking into a-com~t more context inibrmation  , for example by coral ) in rig complete 1hrases instead of indetendent tra:kets . 
It would also be worthwhile to evaluate using more elaborate me  , thods l br building base NPs out of oten and close tra:ket  ( : antitates . 
Acknowledgements l ) djean , Koeling and ' l?jong Kim Sang are funded by the TMII  . 1\]et work Learning ( Jompu-tational Grammars r . 1unyakanok and Rothare SUl ) torted by NFS grants IIS-981638 ant SBR-9873450 . 
References
Steven Alm ', y .  1996 . Partial t)a\]'sing via finite-state cascades . Inl'n , l~wce , di'ngs of the/~ , gS-LLI'95 l ? , obust1) arsi'n9 Worlcsh , op . 
SMomo Argam(m , Idol ) agan , an ( lYll V~t \] Kry-mo low sld .  1999 . A memory-1ased at proach to learning shalhwnatura language patterns  . 
Journal of E : rperimental and Th , eovetical AL 11(3) . 
Adam L . Berge , r , Ste Ihen A . l ) ella Pietra , and Vincent J . Della Pietra .  1996 . A in a ximument rol ) yapI ) roach to natural language processing . Computational Linguistics , 22(1) . 
Eric Bri\]l and , lun Wu .  1998 . Classifier combination tbrim proved lexical disaml  ) iguation . 
In P~vcceding so . fCOLING-A 6'15'98 . Association for Computational Linguistics . 
A . Carlson , C . Cunfl)y , J . Rosen , and
D . l /, oth .  1 . 999 . The SNoW learning architecture . Technical Report UIU CDCS-11 , -99-2101 , UIUC Computer Science Department , 

rhttl ): // lcg-www.ui',,.ac.be ~/
Walter Daelemans , A . ntalvan den Bosch , and Jakub Zavrel . 1999a .  \] ) brgetting exceptions is harmflll in language learning  . Machine
Learning , 34(1).
Walter Daelemans , Jakub Zavrel , Kowm der Sloot , and Antal van den Bosch . 1999b . 
TiMBL : Tilb ' argMemoryBusedLearner , version 2 . GRq fi ; rence Guide . ILKT e(:hnicalth ', port99-01 . http://ilk . kub . nl/ . 
Luc Dehaspe .  1997 . Maximum entropy modeling with clausal constraints  , in PT vcecding soJ'th , c7th , 1 l , ternational Workshop on ind ' uctivc
Logic Programming.
Hervd Ddjean . 200 ( I . Theory refinement and natural language processing  . In Proceedings of the Coling EO00 . Association for Computational Linguistics . 
Mitchell 17 . Marcus , Beatrice Santorini , and Mary Aim Marcinkiewicz .  1993 . Building a large mmotated corpus of english : the penn treebank  . Computational Linguistics , 19(2) . 
Marcia Munoz , Vasin Punyakanok , l ) anll , oth , and Day Zimak .  1999 . A learning ap-tro a (: h to shallow t ) arsing . In P~vceedings of EMNLP-WVLC'99 . Asso (' iation for Coml ) u-tational Linguisti(:s . 
J . Ross Quinlan .  1993 . c/t . 5: Programs for Ma-th , he Learning . Morgan Kauflnann . 
Lance A . Ramshaw and Mitchell P . Marcus.
1995 . Text chunking using transformation-l ) a set learn Jig . In 1 roceedings o\[the Th , i'rd ACL Worksh , op on V e , r  ~ . lLacTic Corpora . Association for Comlmtational Linguistics . 
D . Roth .  1 . 9!t8 . Learning to resolve naturalan-guage amliguities : A unified approach  . In

Erik F . Tjong Kim Sang .  2000 . Nmn phrase recognition by system : ombination . In Proceedings of th , eANLP-NAACL-2000 . Seattle,
Washington , USA . Morgan Kauflnan Publishers.
Hans van Halteren , Jakub Zavrel , and Walter Daelemans .  1998 . Iml ) roving datadriven word class tagging by system corotnation  . In P~veeedings of COLINGACL'98 . Association tbr Computational Linguistics . 
Hans van Halteren , Jakub Zavrel , and Walter Daelemans . to appear , hn proving accuracy ill nlp through coati ) nation of machine learning systems . 

