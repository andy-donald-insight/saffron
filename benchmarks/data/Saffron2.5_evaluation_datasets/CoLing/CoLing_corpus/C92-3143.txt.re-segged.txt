COUPLING ANAU TO MATICDICTATION SYSTEMWITHA GRAM MAR CHECKER 
Jean-Pierre CHANOD , Marc EL-BEZE , Sylvle GUILLE MIN-LANNE
IBM France , Paris Scientific Center
Automatic dictation systems ( ADS ) are
nowadays powerful and reliable . However,
some Inadequacies of the underlying
models still cause errors . In this paper , we are essentially interested in the language model implemented In the linguistic component  , and we leave aside the acoustic module . More precisely , we aim at Improving this linguistic model by coupling the ADS with a syntactic parser  , able to diagnose and correct grammatical errors . 
We describe the characteristics of such a coupling  , and show how the performance of the ADS improves with the actual coupling realized for French between the Tangora ADS and the grammar checker developed at the IBM France Scientific Center  . 
Description of the Tangora system
The Tangor a system is implemented on a personal computer IBM  PSI2 or IBM RS/6000  . A vocal I/O card is added , as well as a specialized card equipped with two micro-processors  , which provide the needed power for the decoding algorithms  . The programs are written In assembly or C . 
The multilingual aspect of the Tangora system ( DeGennaro91 ) constitutes a major asset . Indeed , It was Initially conceived for English ( Averbuch , 87) by the F . Jellnekteam ( IBM T . J . Watson Research Center) , but It was adapted since to process Italian , German and French Inputs . As a whole , the average error rate is close to 5% . But problems specific to each language require adapted solutions  . 
The user is required to train the system by uttering  100 sentences during an enrollment phase , and to manage slight pauses between two words . For the French system , liaisons at this time are prohibited . 
Architecture of the system
The voice signal is submitted to a chain of signal processing  , in order to extract acoustic parameters from the sound wave  . 
Thus , the data flow is reduced from 30 , 000 to 100 bytes per second . Two passes of acoustic evaluation are performed : a relatively gross pass  ( so called Fast Match ) selects a first list of candidate words ( around 500 words )  ; this list is further reduced thanks to the language model  ( see below ) ~ so that only a small number of remaining candidates are submitted to a second  , more precise , acoustic pass ( socalled Detailed Match ) . Storage constraints as we ! las the methods used to provide the language model explain that the size of the dictionary is limited to about  20  , 000 entries . 
The decoding algorithm
This algorithm determines the more likely uttered sequence of words  . It works from left to right by combining the various scores estimated by the acoustic and linguistic models  , according to a socalled stack decoding strategy . At this stage , the elementary operation consists tn expanding the best existing hypothesis which Is not yet expanded  , i . e . It consists In keeping the sentence segment , which , followed by the contemplated current word , Is rated with the highest likelihood . 

If one formulates the problem of speech recognition according to an Information theory approach  , one naturally chooses probabills tic models among all available language models  ( Jeltnek ,  76) . The trlgram ( Cerf ,  90) , trlPOS 1 ( Derouault ,  84) , or trile mma ( Derouault ,  90 ) models offer ways of estimating the probability of any sequence of words  . For instance , formula of the trlgram model : flP ( W  ~ ) = P ( wl ) ? P ( w2/wO?HP ( wj/wI_ = , wl_1 )   1~3 The analysis of decoding errors show that half of them are due to the acoustic model  , the other half being associated with the IModel baled on triplets of parts of AOooeh  ( POS )  , ACTESDECOLING-92 , NANTI'S , 2328 AoOr 1992940 PRO\[: . OFCOLING-92, NA rcr~s . AUG . 2328, 1992 language model . Actually , the number of homophones being quite high (2 . 6) In an inflected language such as French , it Is clear that no acoustic model , as perfect as It may be , can produce a satisfactory decoding without the support of a language model  . 
Power and limitations of probabilistic language models Probablll stlc language models are powerful enough to considerably reduce ambiguities that the acoustic model alone cannot solve  . 
However , they suffer from punctual Imper-fections that are bound to their formulation  . 
This Is clearly shown by testing a probablll stlc model on the lattice formed by the set of the homophones of the words of every sentence  . The decoding obtained by searching for the max lreum likelihood path  ( Cerf , 91) gives an error rate close to 3% , thus showing some of the Inadequacies of the probablll stlc language models  . 
Besides , and agatn for reliability reasons , statistics need to be gathered from large learning corpora  ( tensor even hundreds of millions words )  . In spite of all the preliminary cleaning that may be done  ( automatic correction of typos , tripled consonants for Instance ) , such a huge corpus contains a certain number of grammatical errors  , that Introduce noise In the model . 
Probablll stlcestlmatlons are produced by counting triplets of words or grammatical classes  , tn any of the trt gram , triPeS or trllemma models , a word Is generally predicted according to the two preceding words  , classes or lemmas only . However , grammatical rules may apply to larger frames . Not only the rules often apply to words located out of the window used by the probabtll stlc model  , but also grammatically significant words are to be found either In previous or In posterior position  . Letus mention , as Illustrations , some phenomena for which the probablllstlc model does not fit : ? Adverbs and complements constitute an obstacle to tile transfer of information on gender  , number and person , while this
Information Is needed to choose between different homophones  , as In:
I~COMMISSION charg ( ied ' 6tabllr unplandea outlenglobal auxpopulot lone des terrl to lresoccup ~ ms " estRdUNIE dlman che  , 
Appositions and interpolated clauses
Increase the distance between elemeuts which must agree : 
Plusloun=PARTI5d'oppo=lUo , degaucho , not ammantIopaHl commu = nlate , PARTAGENT copoint derue . 
Predicting a word thanks to tim preceding words does not allow the system to appropriately control person agreement when the subject follows the verb  . Example:
Quoaont DEVENUS los prlnel paux
PROTAGONtSTES de lavl ctolredu on zenovombre ?
Moreover , some confusions due to homophony induce changes of grammatical category  , that require a complete Interpretation of the sentence to be properly diagnosed  , as in " et "/' est ~ ( conjunction/verb ) or "&" l " a ~ ( preposition/verb )  . 
Coupling the ADS with the grammar checker
To bring a solution to the problems described above  , we propose to perform a grammatical analysis after the decoding operation  . The grammatical analysis applies to the best of the hypotheses selected by the ADS  . It serves as a basis to diagnose grammatical errors and te suggest corrections  2   . 
The syntactic parser must prove powerful and reliable enough to effectively Improve the performance of the ADS  . It must provide a broadcoverage , In order to cope with a large variety of texts , the source and the domain of which are not known In advance  . 
It must also compute a global analysis of the sentence In order to fill the deficiencies of the probablll stlc model  . 
Description of the syntactic parser
The syntactic parser we use meets the requirements described above  ( Chased el )  . 
It is actually conceived to provide the global syntactic analysis of extremely diversified texts  . 
It is based on an original linguistic ~ rategy developed by Karen Jonson for US English  ( Heldorn 132 , Jonson , 8G ) . The parser Initially eA similar approach was tested in English  , but only to detect grammatically in corre ~ ct ~ nionce B  ( Bellegarda92 ) AcrEsDECOLING-92 , NANTES , 2328 AO~r1992941 PROC . o = : (; OI . ING-92, NANTES , AUG .  2328 , 1992 compute 8 a syntactic sketch , which represents the likeliest syntactic surface structure of the sentence  ; at this stage , such phenomenas coordinations , ellipses , interpolated clauses , If not totally resolved , do not block the parsing . The analysis Is based on the socalled relaxed approach  , which consists in rejecting linguistic constraints which  , aspertinent as they may be In descriptive linguistics  , are rarely satisfied strlcto sansu In the surface structures of freetexts  . This strategy proves to broaden the coverage of the grammar as well as it allows the parser to deal with erroneous texts  . 
Architecture of the parser : .
The system is written in PLNLP ( Programming Language for Natural Language Processing  , G . Heldorn , 72) . It
Includes : ? A morphologic dictionary (50 , 000 lemmas plus their Inflection tables ) , = * A morpho-syntact lo dictionary , which describes the subcategorizations attached to each temma  , ? A set of more than 300 PLNLP production rules , which produce the syntactic sketches , ? A set of procedures built to reinterpret the syntactic sketches and to diagnose errors  , ? A form generator , which provides corrected forms . 
Indeed , some other techniques are also used . Strong syntactic constraints are relaxed during a second pass  ; It allows the system to detect errors which induce major syntactic changes  ( for Instance confusion " et/est " )  , whim forbidding undesired or too numerous parses . Fitted parses are computed In case the global analysis falls  ( Jansen ,  83 ) and multiple parses are ranked thanks to specific procedures  ( Heldorn ,  76) . 
This last point allows the system to automatically select the strongest hypothesis  , according to the linguistic features ( Including the grammar errors ) of the syntactic trees . 
Adaptation of the parser to the ADS
As mentioned above , many grammatical errors In written French are actually caused by homophones  ( gender , number agreement , confusion between Infinitive and past participle , " chantez/chanter ' , % t/esf " , etc . ) . The parser , Initially built for written French , Is thus well prepared to detect errors produced by an ADS  . 
It can however be adapted to the specific needs of the ADS  , by adding specific procedures ( detection of ill-recognized frozen phrases , etc . ) , and by filtering out non-homophonic or rections , or corrections which do not belong to the list of candidates initially proposed by the ADS  . 
Indeed , postprocessing procedures are largely used to diagnose errors after the syntactic tree has been computed  . This offers the Immense advantage of making the system evolutionary : It can be easily modified  , In order to Improve the scope of the detections . This made the adaptation of the grammar checker to the ADS quite straightforward  . 
Description of the processing chain
In case of the ADS , the coupling Is done by a simple call to the parser for each sentence  . In case of the homophone scheme , the diagram of the processing chain Is shown In the following figure := The = e  50  , 000 lemma e produce about 350 , 000 inflected forms , which largely exceeds the 20 , 000 forms uemd by the Tangora system . 
ACTESDECOLING-92 , NANTES , 2328 AOI ) T1992942 Pr~oc . OFCOLIN'G-92, NANTES , AUG .  2328, 1992
Figure 1. Coupling Diagram

Our tests were carried on the following texts : corplAFP dispatches  ( 1000 words ) corp2AFP dispatches ( 3221 words ) corp3 email notes ( 1909 words ) corp 4 grammar books ( 1337 words ) Only the CORP1 file was obtained through a real decoding ; the other corpora were processed by automatically generating their homophones  . 

The experiments were made at an early stage of the coupling  . They could certainly be improved with more extensive tests  , as the adaptation of the grammar checker to the ADS would gain In accuracy  . 
Percentage of erroneous words left uncorrected
LM without parser with parser corpl 4 . 5% 3 . 6% corp 24 . 6% 3 . 6% corp 36 . 3% 6 . 1% 4 corp 47% 5 . 8% Given the high performance of the ADS and the difficulty to Improve It In the frame of the probablll stlc model  , the improvement of around 1% observed on three of the test corpora is very promising  . 
Samples of corrected sentences :
Example 1: Subject-predicate , attributive adjective-noun , subject verb agreement Lee conditions on ttr ~ durs rollie pays  , devenus Ind 6 fendable , les acceptee LA fter parsing , the suggested correction Is:
LUScond Wonssont ~ DURE Small ; le pays , DEVENUInd 6 fendeble , les ACCEPTE . 
Example 2: subject . verb agreement ; contusion between the conjunction " st " end the verbal form " est ": Le felt que le I ~ ros de chscundes bols romans solent dlff drent sel : rGv ~lateers  . 
After parsing , the suggested correction Is : Le felt quale h6ros dechscundesb ~ lsromans SOIT DIFF6RENT EST

Example 3: Confusion between the verbal form " e ~ and the preposition " A "  ; Confusion between the past participle and the Infinitive form of the corresponding verb  . 
Ce document est a falro sign6 rectoet versoparle propdGtal rost parle gesUon-nalro  . 
After parsing , the suggested correction Is : Ce documentest & falro SIGNER rectoet verso parle  proprl6talro et parlegest lon-nalro . 

Coupling the ADS and the syntactic parser meets the Initially assigned objectives quite satisfactorily : broad coverage of the texts parsed by the grammar  , meaningful percentage of justified corrections , adequacy of the syntactic parser to the types of errors specifically generated by the decoder  . 
The tests that we performed on various corpora are all the more encouraging  , since a great deal of the remaining errors result from semantic ambiguities that no grammar checker based upon a syntactic analysis of the sentence can detect  . 
4 The bad results of the CORP3 file are due Ingreet part to the difficulties of e-mall  , that make parsing less accurate . 
ACTESDECOLING-92 , NANTES , 2328 AOt ~ T1992943 PROC . OFCOLING-92, NANH'ES , AUG .  2328 ,   1992 L ' ~ gedola MERl uplusfr ~ luent ~ I'accou -chementest dev lngt-slxans  . 
A subsidiary advantage of the coupling would be to detect errors that would not be produced by the ADS but by the speaker him/her self  ( punctuation , stylistic in felicities , mood of subordinate clauses , etc . ) . Not only we may contemplate transcribing as accurately as possible the words of a speaker  , but also offering him/her a stylistic aid . 

Averbuch A . et al , 1987: Experiments with the TANGORA2 0 , 000 word Speech Recognizer , Proceedings of ICASSP , Dallas , pp .  701-704 . 
Bellegarda J . , Braden-Harder L . , Jensen K . , Kanevsky D . , Zadrozny W . ,  1992: " Post-recognizer language processing : applications to speech  , handwriting " , submitted to

Cerf-Danon H . , de La Noue P . , Dlrlnger L . , EI-B ~ ze M . , Marcad et J . C . , 1990: " A 20 , 000 words , automatic speech recognizer . Adaptation to French of the USTANGORA system " , Nato 1990 . 
Cerf-Danon H . , EI-B ~ ze M . ,  1991: " Three different Probablllstlc Language Models :
Comparison and Combination ", ICASSP 1991.
Chanod JP . , 1991: Analyse automatlque d'erreurs : strat ( ~gie Ilngulstlquet computatlonnelle , Colloque Informatlquet Langue naturelle , 2324 janvler 91 , Liana
Univ . de Nantes.
DeGennaro S . , Cerf-Danon H . , Ferrettl M . , Gonzales J . , Keppel E . ,  1991: " Tangora-a large vocabulary speech recognition system for five languages "  , EuroSpeech 1991 , 

Derouault AM . , M ~ rialdo B . ,  1984: " Language modeling at the syntactic level " 7th International Conference on Pattern
Recognition , August 1984, Montreal.
Derouault AM ., EI-B ~ ze M ., 1990:"A
Morphological Model for Large Vocabulary
Speech Recognition ", ICASSP 1990.
Heldorn , G . E . ,  1972: Natural Language Inputs to a Simulation Programming System  , Ph . D . 
dissertation , Yale University.
Heidorn G . E . , Jensen K . , Miller L . A . , Byrd R . J . , Chodorow M . S . , 1962: "3"he EPISTLE Text-Critiquing System " , IBM system Journal , vol . 21, n ? 3 . 
Heidorn , G . E . ,  1976: " An Easily Computed Metric for Ranking Alternative Parses "  , Presented at the Fourteenth Annual Meeting of the ACL  , San Francisco , October 1976 . 
Jellnek F ., 1976: " Continuous Speech
Recognition by Statistical Methods ",
Proceedings of the IEEE , Vo/64, April 1976.
Jensen , K ., Heldorn , G . E ., 1983: " The Fitted
Parse : 100% Parsing Capability In a
Syntactic Grammar of English ", Prec . Conf.
on Applied Natural Language Processing,
Santa Monlca , California , pp . 93-98.
Jensen , K . 1966:"A Broad-Coverage
Computational Syntax of English ",
Unpublished documents , IBMT.J . Watson
Research Center , Yorktown Heights , N.Y.
ACt'ES DECOLING-92 , NANTES , 2328 AO~V 1992 944 PROC . OFCOLING-92, NANTES , AUG .  2328, 1992
