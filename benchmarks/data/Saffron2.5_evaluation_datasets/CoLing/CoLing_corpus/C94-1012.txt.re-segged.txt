Coping With Ambiguity in a Large-Scale Machine Translation System 
Kathryn L . Baker , Alexander M . Franz , Pamela W . Jordan,
Teruko Mitamura , Eric H . Nyberg , 3rd
Center for Machine Translation
Carnegie Mellon University
Pittsburgh , PA 15213
Topical Paper : machine translation , parsing

In an interlingual knowledge-based machine translation system  , ambiguity arises when the source 1 . qn-guage analyzer produces more than one interlingua expression for a source sentence  . This can have a negative impact on translation quality  , since a target sentence may be produced from an unintended meaning  . In this paper we describe the , nethods nsed in the KANT machine translation system to reduce or eliminate ambiguity in a largescale application domain  . We also test these methods on a large corpus of test sentences  , in order to illustrate how the different disambiguation methods redtuce the average number of parses per sentence  ,   1 Introduction The KANT system\[Mitamura et al . , 1991\] is a system for Knowledge-basexl , Accurate Natural-language Translation . 
The system is used in focused technical domains for multilingual translation of controlled source language documents  . 
KANT is an interlingua-based system : the sonrce language analyzer produces an interlingua expression for each source sentence  , and this interlingua is processed to produce the corresponding target sentence  . The problen3 el ' ambiguity arises when the system produces more that ~  ( ) tie interlingua representation for a single input sentence  . If the goal is to automate translation and produce output hat does not require postediting  , then the presence of ambiguity has a negative impact on translation quality  , since a target sentence may he produced from an unintended meaning  . When it is possible to limit tile interpretations of a sentence to just those that are coherent in the translation domain  , then the accuracy of the
MT system is enhanced.
Ambiguity can occn rat different levels of processing in source analysis  . In this paper , we describe how we cope with ambiguity in the KANT controlled lexicon  , grammar , and semantic domain model , and how these : ire designed to reduce or eliminate ambiguity in a given translation domain  . 
2 Constraining the Source Text
The KANT domain lexicon and grammar area constrained subset of the general source language lexicon and gra  , nmar . 
The strategy of constraining the source text has three main 

Il-:igurc 1: The KANT System goals . First , it encourages clear and direct writing , which is beneficial to both the reader of tile source text and to the translation process  . Second , it facilitates consistent writing among tile many authors who use the system and across all document types  . And third , the selection of unambiguous words : 111 ( I constructions to be used during authoring reduces the necessity for ambiguity resolution during the auto  , natic stages of processing . It is important to reduce the processing overhead associaled wilh amhiguity resolution in order to keep tile system fast enough for online use  . 
2.1 Thel)omain Lexicml
The domain lexicon is built using corpt , sanalysis . Lists of terms , arranged by part of speech , are automatically extracted from the corpus \ [ Mitamura et al  . , 1993\] . " File lexicon consists of closed-class general words  , open-class general words , idioms , and nomenclature phrases . Closed-class general words ( e . g . the , with . should ) are taken from general English . Open-class general words ( e . g . drain , run , hot ) are limited in the lexicon to one sense per part of speech with some exceptions ~  . Idioms ( e . g . on and off ) and nomencl > tn rephrases ( e . g . summing valve ) are domain-specilic and are limited to those phrases identilied in the domain corpus  . 
Phrases , too , are delined with a single sense . Special vncab-tFar example , in the heavy-equipment lexicon , there are a few hundred terms out of 60 , 0 00 which have more than one sense per part of speech . 
90 ulary items , including symbols , abbreviations , and the like ,   , are restricted in use and are chosen for the lexicon in collaboration with domain experts  . Senses for prepositions , which are highly ambiguous and context-dependent , are determined ( luring processing using the semantic domain model  ( of . Section 4) . 
Nominal compounds in the domain may be several words long  . Because of the potential ambiguity associated wit h compositional parsing of nominal compounds  , nonproductive nominal compounds are listed explicitly illtile lexicon as idioms or nomenclature phrases  . 
2.2 Controlled Grammar
Some constructions in the general sourcel , ' nlgtmge that arc inherently ambiguous are excluded from the restricted grammar  , since they may l~td to multiple analyses during processing : ? Conjunction of VPs  , ADJs , or ADVse . g . * Extend and retract the cylinder . 
? Pronominal reference, . g . * Start the engine and keel ) it running . 
? Ellipsis , e . g . reduced relative clauses : * the tools ! ~ t for the procedure ? Long-distance dependencies  , snch as interrogatives and object-gap relative clauses  , e . g . The parts which the service representative ordered  . 
? Nominal compounding which is not explicitly coded in the phrasal lexicon  . 
On the other h , ' md , tim grammar inchules the following constructions : ? Active  , passive and imperative sentences , e . g . Start the engine . 
? Conjunction of NPs , PPs or Ss . Sentences may be conjoined using coordinate or subordinate conjr  , notions , e . g . 
If you are on the last parameter , ~ zenl he program proceeds to the lop . 
? Subject-gap relative clauses , e . g . The service representative can determine the parts which are faulty  . 
Tile recommendations itile controlled grammar include guidelines for authoring  , such as how to rewrile a text from general English into the domain language  . Authors are ad-'vised , for example , to choose the most concise terms available in the lexicon and to rewrite long  , conjoined sentences into short , simple ones . The recommendations are useful both for rewriting old text and creating new text  ( set l : igure 2 for examples )  . 
Example 1: Rewrite Anaphnric Use(1t ' Numerals
Problematic Text:
Suggested Rewrite:
Loosentile smaller ( me first.
Loosen the smaller boltftrst.
Example 2: Use Concise Vocabulary
Problematic Text : The parts must be put ba_ck to get h !' L  . 
Suggested Rewrite : The parts must be ( easse~t bl#d . 
Figure 2: Grammar Recommend atiml Examl ) les2 . 3 SGML Text Markup q'he grammar makes use of Standard Generalized Markup Language  ( SGML ) text markl , p tags . The set of markup tags for our applicatiou were developed in conjunction with do-  , nain experts . A set of domain-specific tags is used not only to demarcate tile text but also to identify tile content of potentially ambiguous expressions  , and to help during vocabl , lary checking . For example , at the lexical level , number tags identify numerals as diagram call outs  , part munbers , product model numbers , or parts of measurement exl ) ressions . At the syntactic level , rules for tag combinations restrict how phrases rnay be constructed  , as with tagged part rmmbersan ( lpart names ( see Figure 3 for an example )  . 
'\[' tie < p ~ l / " t ; no > 4S152-1 </ parL no > < par Lr ~ amo > Hose A ~ sornt ) \]y </ parL name><Cd\]IouL > l</cal lout : > elt  . he < paltrlo > 5'\['65-'\] q </\[ ) El #' LNO > < f ) /l\[\[lID , Ill (-"\ [ ~ i ~ E lk ( . ~COl"tL ro\[GlTOklp < ~/ ~ ) ~ I/~LEI glmQZ > IIILI ~ ; LnOWk ) ( ) connOcLed LoLho<parL no > 4K2986 </ part:no > < partzname >
Arl (: ! lOiTOO </ D ~ lrt.r/,lm~?:,.
t . ' igure 3: Sample S( ; ML Text Mark-Up 3 Granun'w Design Issues The parser in KANT is based on the " Universal Parser "\[ Tonfit and Carbonell  ,  19871 . " Filegram nmr consists of contextfree rules that define tile input's constitt  , entsruc-ture ( c-structure ) and these rules are annotated with constraint equations that define the input's functional structure  ( f-structure )  . ' l'omita's parser compiles the gratnnmr into an l  . R-table , and the constraint equations into L is p code . Although this compilation results in f . ' lstruntime parsing , the need to minimize ambiguity still exists . 
One source of ambiguity is the attachment site for a prepositional phrase  , l lowever , many of the PP attachments are encode directly . in the gramma , " because tile syntactic on-text indicates an unanfl  ) iguous attaclunent site . For example :+ A partitive where the PP attaches to the noun : a gallon of antifreeze  . 
)  )   ) ? A pre-sentential IP where tile I\[attaches to the sentence : For this test  , enst trethor a signal line is connected from lhe pump outpul to the pump compensator  . 
? API ' attaches to the verb be when there is no predicale adjective : The trm :' k is in the shop  . 
? A ditransitive verb where the PP attaches to the verb : 
Give y our suggestions to tile dealer.
, , A standalone PP inside ; mSGML tag such as QUAL-II"IER where tile PP attaches to tile MDL DESC tag contents : Inspect < mdl desc > all track-type tractors < qualifier > with hydraulic heads</qualifier > </ mdl desc >  . 
3 . 1l ' assive vs . Cnpt , l ' lr with Participial ? There are many adjectives in English that have tile same form  . as , ' m-ed participle , l : or example : 7" tieradius is poorly formed .   ( adjective ) The calibration mode is enabled by moving the rocker switch  .   ( participle ) i " R distinguish the qdjectival from the participial form we have added two heuristics to tile constraint rules of the grammar  . The litst is to use verb class mapping information  , If the passive reading is preferred . So , for example , an intransitive verb would indicate an adjectival reading : 
The display is faded . ( adjective )
The second heuristic uses the notion of " quasi -agents"  . 
There are several prepositions that can introduce " quasi-agents "\ [ Quirk et al  ,  197211 , such as : about , at , over , to , with . If the domain model indicates that the-ed verb is a possible attachment site for a prepositional phrase occurring in the sentence  , then the passive reading is preferred . 
These two heuristics are incorporated into tile constraints of rules involving predicate adjectives  . If the-edfer alis classified as active , or if there is at PP in the sentence that can attach to the-ed verb form  , tfientile adjectival reading is ruled out . In the constraints of rules for the passive , timpassive reading is ruled out if the-ed form is classified assmtive  . 
3.2 Adverb or Adjective ?
For tile most part , eacfi word in the system is limited to one meaning per part of speeclt  . So while we have nearly eliminated one source of lexical ambiguity  , there is still the l ) roblem of ambiguity between the various parts of speech for a par-ticuh lr word  . While ambiguity between , lbrexample , a noun and a verb is usually resolved by the syntactic context  , parts of speech that participate in similar contexts are still a problem  . 
For example , the content of the SGML tag , POSITION , can be an adjective or adverb phrase and " as\[ < adj > l < adv >\] as " can contain either an adjective or an adverb  . This means that an input such as " as fast as " would have two analyses  . We Imve found witllour domain that tile COt TeCt hingto do is to prefer the adverb reading  . We put this preference directly into the constraints of rules involving adjectives for which the same context allows an adverb  . If the word is also an adverb then tim adjective rule will fail  . This allows tile adverb reading to be preferred . 
4 Semantic Donmin Model
We have implemented a practical method for integrating semantic rules into an LR parser  . The resulting system combines the merits of a semantic domain n lodel with the generality and wide coverage of syntactic parsing  , and is fast and efficient enough to remain practical  . 
4 . 1 Interleaved vs . Sentence-final Constraints Some previous knowledge-l  ) ased natural hmgl mge analysis systems have constructed tile semantic represent ' ilion for the sentence in tandem with syntactic parsing  , lit this schenle semantic on str ; fints from tile domain model filter out semantically ill-lormed representations and kill tile associated pro'sing path  . Examples include AIISITYt Hirst , 19861 and KBMT-89\[Goodmananti Nireuburg ,  1991\] . Other inevious systems have delayed semantic interpretation adal  ) plicalion of semantic wellformedness constraints until aftertile syntactic parse  . 
Both of these schemes entail performance problems . The solution to this probleln lies ill importing the right type and right amount of semantic information into syntactic lmrsing  . 
IuKANT , the relevant knowledge sonrces are reorganized into data structures that arc optimized for ambiguity resolution during parsing  . 
4.2 Example of Attachment Ambiguity
Tile knowledge-based disambiguation scheme covers Prepositional Phrase attachment  , Noun-Not reconlponnding , and Adjective-Noun attachment . The remainder of this section discusses examples involving PP-attacl/m~nt  . The syntactic grammar contains two rules that allow these attachments : 
VP , ---- VP PP
NP , --- NP PP
Consider tim sentence Measure the voltage with the voltmeter  . 
Syntactically , the PP with the voltmeter can modify either tile verb measure  , or tile noun voltage . 
4 . 3 Slructure and Content of tile I ) omain Model We use knowledge a bol , t the domain to resolve ambiguities like PP -attachment  . Tile domain model cent ; fins all of the semantic oncepts in the domain . Leaf concepts , such as * O-VOLT METER , correspond closely to linguistic expressions . The concepls are . arranged in an inheritance hierarchy , and other concepts , uchas*O-MEASURING-DEVICE , represent abstract concepts . The domain model is implemented as a hierarchy of concepts  . Constraints on possible attributes of concepls , along with semantic on straints on the fillers , are inherited through this hierarchy . Figure 4 shows an example . 
?(" a-PlA61 ~ JSlI('- , ~ C'llO~"N )   ( IN glRtl MFN r~'-ME&~URDdE brr . \[&~' l(l :') & B . A Figure 4: Excerp ! t'rnml ) unutiu Model 4 . 4 Using Semantics in tile Syntax In ordert Okeel ) parsing traclable , the domain model is con-suited at the earliest possible stage during parsing  . Every grannna rule that involves an attachment decision that is subject oknowledge-based disamhigv'ltion calls a function that consults the domain model  , and allows the gramn/arrule to succeed only if the attachm cut is sclnantically licensed  . 
The grammar formalism allows procedural lsto be made directly fron/timgramnm rules  . The function that performs or deuies attachment based on the domaiu model is called sere-attach  . 
The inpttts to the sem-attach function are the functiomll structures  ( f-strttcturcs ) lk ) r the potential attachment site , tile structure to be attached , and the type of attachment ( e . g . , PP = t :' repositional Phrase) . sere-attach consults in lbrm , ' ltion from the domain model to decide whether the attachment is semantically licensed  . This process is described in the next subsection . 
4 . 5 Steps in Sem , ' mtleDisaml ) iguation IT here are three main steps in seln an lic disambiguation of possib\]e syntactic attachments  :   ( 1 ) mapping from syntaxtoing inform , 't tkm from the domain model ; and ( 3 ) determining semantic roles using tile semantic interpretation rules  . 
?7 v : iiii
Figure 5: Lexical Mapping Rules
Lexical Mapping Rules . The first step is to real I from syntactic structures to semantic oncepts  . The lexical mapping rnles associate syntactic lexicon entries with concepls from the Domain Model  ( Figure 5 )  . 
Domain Model . " File second step consists in looking up the appropriate concepts in the Domain Model  ( Figure 4 )  . 
Semantic Interpretation Rules . The third step consists of consulting the semantic interpretation rules to determine whether the concepts from tile sentence can lo  , ' mapprol ~ ri-ate modilication relationships . Semantic interpretation rules describe the mapping from the syntactic representation to the frmne-based semantic representation  , An interpretation rub consisls of a syntactic path  ( an index in totile f-structure )  , a semantic Imth ( an index in totile senmntic frame )  , and a nop . 
tional syntactic on straint on the mapping rule . For exmnple , belowism t interpretation rule for the INSTRUMENT role:  ( : : ~ yn-pat . hIPPOBJ):sem~path ZN . qTRUNENT : sys-consttraint ( ( pp ( ( root ( * OR*"wlth . . . . by ")) )) ) Eflicient Runtime Use . In order to make this process as efticient as possible  , amltominimize delays during parsing , the knowledge described in this section is reorganized offline I  ) cfore parsing . The result of this reorganization are data strtletn resknown as S&*  ; ' lalllic " restrictors . The SelllLIIlliL ' restrictors have three main properties :  1  . They are indexed by head concept , and provide a list of all approl ) riate modiiiers . 
2 . All inheritance in the Domain Model is performed offline  , so that the restrictors contain all necessary inform a  . .

3 . The semantic restrictors are stored in a Slmce -efficient structure+shared manne  ,  + . 
SAuthorl ) is ambiguatiot !
Once KANT has analyzed a source sentence and all l ) OS-sine disambiguations h ; tve been performed , there may still be more than one interlingua representation for tim sentence  . 
This occurs when the sentence is truly ambiguous , i . e . , it hns more than one acceptable domain interpretation  . I this case , KANT makes use of disambiguation by the author- -tile ambiguity is described to the author and the author is then pmml  ) ted to select the desired interpretation . The choice is " remembered " by placing extra in fomuttion in totile input text at the point of alnbiguity  . There are two types of ambiguity cnrrently addressed by author disambit ~ uation : ? Lexical Ambiguity  . When more than one interlingua is produced because a certain word or phrase eanbe in terpreted in more than one way  ( iv . as two different concepts ) , then the author is prompted to selec the desired meaning  . 
* Structuralkmbigt . tity . When more than one attachment site is possible for a phrase like aprel  ) o ~ ilional phrase , the different attachments are glossed for tile : luther  , who is then prompted to selectile desired in teq ) retation . 
Since author disambiguation is utilized only when the sentence cannot I  ) cd is ambiguated by other n teans , it will not occur very frequently once tile system is complete  . Ontile other hand , having such a mech , ' mismavailable during system development is very helpful  , since it helps to point out where there is residu -dambiguity left to be addressed by knowledge 
St t l r c e i e l i n e l t l e n t .
6 Testing l ) is aml figualion Methods When disambiguation methods are in t  , oduced , the number of parses per sentence can be reduced dramatically  . If we use a general lexicon and grammar to parse texts lro\[n  ~  . 1 specialized dolna in corpus ( rather than a general corpus )  , then more lmrses will be assigned than those thai are desired in the d Olna in  . Figure 6 illustrates how the successive introduction of disambiguation ntethods reduces the set of l  ) ossiblc parses to just those desired in tile domain  . The smallest set of interpretations is that remaining aftertile controlled lexicon  , gla\[nllrar , seln\[illlic restrictions , and author disambigtm tion have \[) cell applied ; in practice this sel , , viii contain just one interpretation , since the author will select only the intended interpretation  . 
 #Inlerprelalion ~
Ouin ~ l General
IN Inlell W Utaliot ~ U ~+ ing Dotu , ~ irl hlle lptelullolll\[i ~ ambi ~ ualiolL
Followia ~ A ~ Jlllo ? l : igure 6: Reducing the Set of Possible lnterl ) retatinns W c have experimented with tile KANT analyzer in order to determine the effects of the different disambiguation strategies mentioned above  . We used a test suite containing 891 sentences which is used fo , regression testing during system development . The sentences in the testsuite range in lenglh fronlt word to over  25 words . 
General lexicon entries were derived automatically from the online version of W cbster's  7th dictionary . Webster's includes 55 , 0 00 reels that are in at least one open class category  ( verh , ram , , adjective , adverb ) . One diclionary entry was created for each sense of one of these dalegories  , This resulted in 117 , 000 lexicon entries . The constrained lexicon consists of 10 , 000 words and 50 , 000 phrases talk ) red to the application 9 . 3 domain . For the results listed below , the " general lexicon " consists of the constrained lexicon plus the general entries from Webster's  . 
The constrained grammar has been tailored to the restricted source language for the domain  ( of . Section 2) . In , ' tddition , it includes a number of constraint annotations and parse preferences that limit the number of ambiguous parses  ( cf . Section 3) . A general grammar was derived from the constrained grammar by removing most restrictions and constraints on specific rules  , leaving only the most general constraints such as subject verb agreement  . 
When noun-noun compounding is allowed , sequences of nouns may form NPs even if the y~u ' e not listed as nomenclature phrases in the lexicon  . Each such sequence is only parsed one way ; the parser does not build different smmtures for the sequence of nouns  , but just reads them into a list . 
In order to reduce the exponential complexity of some of the longer sentences  , all test results were produced using the " shared packed forest " method of ambiguity packing for ambiguity internal to a sentence \[ Tomita  ,  1986\] . The results for " parses per sentence " is simply the average for all the sentences  . 
Test LEX GRANN DMP 1GENGENYESNO 27 . 02 GENGENNONO 10 . 23 GENCONYESNO 8 . 44 CONGENYES NO 1 . 75 CONGENNONO 1 . 66 CONCONNOYES 1 . 5
LEX : LexiconGEN : General
GILA : Grammar CON : Constrained
NN:Noun-Noun Compounding
DM : Semantic Restriction with l ) omain Model Figure 7: Testing Disambiguation Methods ( 12/17/93 ) The results of this testing ~ u'e shown in Figure  7  . Test 1 is the baseline result for parsing with a general lexicon  , general grammar , noun-noun compounding and no semantic restrictions  . As expected , the average number of parses per sentence is quite high  ( 27 . 0) . Limiting noun-noun compounding ( ' lest 2 ) cuts this number by more than half , yielding 1(/ . 2 parses per sentence . Note that a similar effect is achieved if we run the test with a controlled grammar and noun-noun compounding  ( Test 3 ,  8 . 4 parses per sentence ) . 
Constraining the lexicon seems to achieve the largest reduction in the average number of parses per sentence  ( Tests 4 ,  5 ,  6) , with elimination of noun-not recompounding yielding only slight improvements when the lexicon has already been restricted  . As expected , the best results are achieved when the system is run with constrained lexicon and grammar  , no noun-noun compounding , and semantic restriction with a domain model ( Test 6 )  . 
We expect that tile primary reason wily tile addition of semantic restrictions from a domain model does not have a greater impact is due to tile incomplete natt tre of the domain model we used in the experiment  . The domain model used in the experiment captures the domain relationships associated with prepositional phrase attachment to VP and object  N1  ; lint there are several areas of the domain model still under development  . When complete , these will further educe ambiguity by placing additional limitations on the following : ? The semantic lassification of words inside particular 
SGML tags ; , , Attachment of prepositional phrases to suhject NP  ; ? Attachment of inlinitive clauses ;   , , Attachment of relative clauses . 
This testing has proved extremely useful ill prioritizing the level of effort expended oil different disambiguation methods dnring system development  . As is often the case , theoretically interesting or difticult issues ( such as noun-noun com-ponnding ) are reduced in effect when other domain-related restrictions are put in place  ( such as a controlled lexicon )  . 
On the other hand , this type of testing can also identify Iheare as of the system  ( such as the semantic domain model ) which are not reducing ambiguity as much as expected  . In our ongoing work , we will complete the domain model for the KAN The , ' tvy-eqtfipment application in those areas mentioned above  ; in the process , we expect or ednce the average number of parses per sentence in the most constrained ease  . 
7 Acl ( now ledgements
We would like to thank Jaime Carbonell , Radha Rao , and Todd Kaufinann , ' rod all of ottr colleagttes on the KANT project  , in chtding James Altucher , Nicholas Brownlow , Mil-dred Galarza , Sue Hohn , Kathilannamico , Kevin 1 ( eck , Mar-ion Kee , Sarah Law , John Leavitt , Daniela Lonsdale , Deryle Lonsdale , Jeanne Mier , Venkatesh Narayan , Amalio Nieto , and Will Walker , our sponsors at Caterpillar Inc . , and onr colleagues at Carnegie Group . 
References \ [ Chevaliertal . , 1978\] Chevalier , M . , Danscre:m , J . , and Poulin , G .  (1978) . Tatm Hnetco : description dn systOne . 
Technical report , Groupe ( le recherches pour lat raduction automatique , Universit 6 de Montr S , ql . 
\[Goodman and Nirenburg , 19911 Goodman , K . and Nirenburg , S .  (1991) . The KBMT Project : A Case Study in Knowledge -Based Machine Translation  . Morgan Kauf-ulan \[1, S: . lnMated , CA . 
\[Hirst , 1986\] Hirst , G .  (1986) . Semantic Inlerpretation and tile Resolution of Ambiguity  . Cambridge University Press,

\[ Mitamura et al . , 1991\] Mitamura , T . , Nybcrg , E . , and Carbonell , J .  (1991) . An efficient interlingua translation system for multi-lingtml document prodtction  . In Proceedings of Machine Translation Summit I11 , Washington , DC . 
\[Mitamnra et al . , 19931 Mitamura , T . , Nyberg , E . , anti Carbonell , J .  (1993) . Automated corl ) uS analysis , ' rod the acquisition of large , multilingual knowledge hases for MT . In 5th International Cotlference on 771eoretical and Methodological Issues in Machine Translation , Kyoto , Japan . 
\[Quirk et al , 1972\] Quirk , R . , Grccnbaum , S . . Leech , G . , and Svartvik , J .  (1972) . A Grammar of Contemporary English . 
l_ongmanGroupUKLimited,EssexEngl,'md.
\[Suzuki , 19921 Suzuki , M .  (1992) . A method of utilizing domain and langnage-sl ) ecitic conslraints ill dialog translation . In Coling-92 . 
\[ Tonfita , 1986\] Tomira , M .  (1986) . Efficient Parsing for Natural Language . Kluwer Academic Publishers , Boston,

\[qk ) mit and Carbonell , 191"ll ) mita , M . and Carbonell , J . 
(1987) . " i'he Universal Parser archite curcRlrKm ) wledge-based Machine Translation . Technical Report CMU-CMT-87-101 , Center for Machine Translation , Carnegie Mellon


