Prepositional Phrase Attachment Through A Hybrid
Disambiguation Model
Haodong Wu and Teiji Furugori
Department of Computer Science
University of Electro-Communications
1-5-1, Chofugaoka , Chofu , Tokyo182,, JAPAN
wu , furugori Ophaeton , cs.uec.ac.jp

Prepositional phrase attachment is a major cause of stru  ( : turalaln biguity in natural language . Recent work has been dependent on corpus-based approaches to deal with this problem  . However , corpus-based approaches suffer from the sparse -data problem  . To cope with this problem , we introduce a hybrid method of integrating corpus-based approach with knowledge-based techniques  , using a wide-variety of information that comes from annotated corpora and a machine-readable dictionary  . When the occurrence frequency on the corpora is low  , we use preference rules to determine PP attachment based on clues from conceptual information  . An experiment has proven that our hybrid method is both effective and applicable in practice  . 
1 Introduction
The resolution of prepositional phrase attachment ambiguity is a difficult problem in NLP  . There have been many proposals to attack this problem  . Traditional propos Ms are mainly based on knowledge-based techniques which heavily depend on empirical knowledge encoded in handcrafted rules and domain knowledge in knowledge base : they are therefore not scalable  . Recent work has turned to corpus-based or statistical approaches  ( e . g . Hindle and Rooth 1993; Ratnaparkhi , Reynar and Roukos 1994 , Brill and Resnik 1994 , Collins and Brooks 1995) . Unlike traditional proposals , corpus-based approaches need not to prepare a large amount of handcrafted rules  , they have therefore the merit of being scalable or easy to transfer to new domains  . However , corpus-based approaches shffer fi'om the notorious parse-data problem : estimations based on low occur-renee frequencies are very unreliable and often result in bad performances in disambiguation  . To cope with this problem , Brill and Resnik ( 1994 ) use word classes from WordNet noun hierarchy to ( : luster words into semantic lasses . Collins and Brooks ( 1995 ) on the other hand use morphological analysis t ) oth on test and tr ~ fining data . Unfortunately , all these smoothing methods are not efficient enough to make a significant improvement on perforln ancc  . 
Instead of using pure statistical approaches stated above  , wc propose a hybrid approach to attack PP attachment problem  . We employ corpus-based likelihood analysis to choose most likely attachment  . Where the occurrence frequency is too low to make a reliable choice  , wc turn to use conceptual inforn lation froln a machine-readable dictionary to to make decision on PP attachments  . 
We use this disambiguation method to buihla disambiguation module in PFTE system  , lIn what follows we first outline the idea of using hybrid information to sui  ) plyp references for resolving ambiguous PP attachment  . We then describe how this information is used in disambiguating PP attachment  . We put the hybrid approach in and is ambiguation algorithm  . Finally , we show an experiment and its result . 
2 Using Multiple Information in

Like other work , we use fonr head words to make decision on PP attachment : the main verb v  , the head noun ( nl ) a head of the preposition ( p )  , and the head noun ( n2 ) of the object of the preposition . In the later discussion , the four head words are referred to as a quadrul ) le ( vn lp n2 )  . 
Analyzing the strategies human beings employ in PP attachment disambiguation  , wef ( mnd that a wide-variety of information supplies important clues for disambiguation  . It includes presuppositions , syntactic and lexical cues , collocations , syntactic and semantic restrictions , features of head words , conceptual relationships , and world knowledge . We use clues that are general and reliable 1PFTE stands for Parser for Free Text of English . 
PFTE system is a versatile parsing system in development which  ( : oversa wide range of phenomena in lexical , syntactic , semantic dimensions . It is designed as a linguistic tool for at ) plications in text understanding , database generation fi'om text and computer-based language learning  . 
1 070 so that they make the computation efficient and extensible  . The information or clues we use are the following  :   1  . Syntactic or lexical cues . If nlissame as n2 , for exaln ple , often nl TPP is a fixed t ) hr ; ~ sesu (: has . step by step . 
2 . Co-oee'wr'rences . The ( ; o-o ( : ( :llrrences of triples and pairs in ( vn lp n2 ) colnefrmn annotate de or l ) ora ( Se ( : tion 4 )  . 
3 . Syntactic and semantic features . Features of vorn ln2 sometimes in ( licate the " corre ( : t " attachment . For examt ) le , if v is a movement , pisto and n2 is at ) lace or direction , the PP teuds to be attached to the verb . 
4 . Conceptual relationships 1) etween v and n2 , or between nl and n2 . These relationships , which reflect the role-expections of the pre-1 ) osition , sut)l ) ly important chics for disambiguation . For example , in the sentence Peter broke the window by a , stone , we are sure that the PP by astone is att ~ u'hed to broke/v by knowing that  stone~n2 is an instrument for broke/v . 
V~feuse cooccurrence informatioi ~ in corl ) us-t ) ased ( lis ; mfl ) iguation and other information in rule-b , ~sedisambiguation . Later , we will discuss how to a c ( tuire above information and use it in disambiguation  . 
3 Estimation based on Corpora
In this section , we consider two kinds of PP attachment in our corlms-t  ) as edal ) l ) roaeh , nalnely , attachment to verb phrase ( VP atta ( ' lmmnt ) and to nmmi ) hrase ( NP attachment )  . Here , we use two ammtated corpora : EDR English Corpus 2 and Susanne Corpusato SUpl ) ly training data . 
Both of the ln ( - ( retaintagged syntactic structure for each sentence in the in  . That is , each PP in the corl ) or a has 1 ) een attached to an unique l ) hrase . 
RA(v , nl , p , n2) , a score fi'om0 to 1 , ix defined as a value of counts of VP attachments divided by the total of occurrences of  ( v , nl , 1) , n2) in the training data . 4RA(v , nl , p , n2) = f ( , ,vl , , , , , I , v , ,ce ) f ( v , nl , p , n2) , ~ f(vP lv , ,~ L , p , u2) -/( , , vl . . . . . I , v , -2)+y( , wl , , , , , 1 , v , , , u ) (1) In (1) , the symbol f denotes frequency of a par-ti ( ' ular tuple in the training data . For exami ) le , 2 FDR English Corpus , conq ) iled by JapanEhx'-tronic Dictionary Research Institute  , Ltd , e ont all lS1 60 , 000 sentences with annotated nmr phologie , syntactic m , d semantic information . 
a Susaxme Corpus , cOral ) ileal \]) y Oe off re . ySaml~so:n , is an amtotated corpus coml ) risilt gabout 130 , 000 words of written American English text . 
' l We assulue that only two kinds of PP att a ( : h-mer its : VP or NP attachment in the training data  . 
f(vl ) I share , apartment , with , friend ) is the numl ) er-of ~ . imes the quadruple ( share , apartlnent , with , friend ) is seelt with a VP attachment . Thus , we could choose a attae fimentactor ( ling to RA score = if RA > 0 . 5 choose VP attachment , otherwise choose NP attachment . 
Most of quadruples in test data are not in the training data  , however . We thus turn to collect triples of ( vd ) , nl) , (nl , p , n2) , (v , nl , l )) and 1) airs of ( v , t)) , (nl , p) , (l) , n2) like Collins and Brooks (1995) did , and coinpute RA score by (2) and (3) . 
RA(v,nl,p,n2) = f(vVl,,p,n2)+f(,~p\[,~l . p , n2)+f(op\[ , , , ul 4') f(v , p , n2) Tf(nl , p , n2) + f(v , n , p ) (2) or , 
RA(v , nl , 1) , n2) = f(vv lv , p ) + f ( , : v l , ~ ~  , P ) + f("ph) , n2) f(v , p ) Tf(nl , p ) + f(p , n2) (3) To avoi ( lusing very low frequen (: ies , we set two thr (' sholds for each one above . For triple-combimttion , the c(mditionis:fl , riple(v , Itl , 1) , n2) ~2 , and 12*RA(v , nl , p , n2)-ll*h)g(ftrip>(v , nl , p , n2)) < 0 . 5 here , flriple(v , Ill , p , n2) = f(v , 1) , n2)+f(nl , t) , n2)+f(v , nl , 1)) For 1) airs-(:oml)ination , the condition is : f pair ( v , nl , p , n2) > 4 , and 12*RA(v , nl , p , n2)-II*log(fp , ,i ,  . ( v , ul , p , n2)) < 0 . 5 here , fpair ( v , nl , 1) , n2) = f(v , p)+f(nl , p)+f(p , n2) With the first threshohl in ca , oh case , we can avoid using low frequency tul)les ; with the second one in each case , we throw away the RA score which is close to 0 . 5 ~ L stlfisw due is rather unsta-bh, . 
4 Conceptual Information and
Preference Rules
As we use only " relial ) le " data from corl ) or a to make decision on PP att a ( ' hlnellt based ( mRA score , many PPs ' attachlnents may be left undetermined due to sparse  . ( l ; t ta . We deal these unde-te . rlnined PPs with a rule-based approach . Here we use preference rules to determine PP attachments  1  ) y judging features of head words and conceptual relationships among them  . Tl , is information comes from a machine-readable dictionary 
EDR dictionary , s
SEDII electronic dietion m'y consists of a set of machine-readable dictionaries which includes Japanese and English word dictionary  , Japanese and English cooccurrence dictionary , concept dictionary , and Jal ) anese <> English l ) ilingualdle tio-nary ( EI ) R 1993 )  . 
1071 4 . 1 Features and Concept Classes We cluster words ( verbs or nouns ) ~hi~h haves ~ une feature or syntactical function into a  ( : ( ) n-cel ) t class . For exam I ) le , we classify verbs into active and passive , and ontologic Mcbusses of mental , movement , etc . Similarly , we group nouns into place , time , state , direction , etc . 
We extracte on cel ) t ( : lass from concept classification in EDR Concept Dictionary ~  4  . 2 Conceptua l Re la t ionsh ip Conceptual relationships between v and  n2  , or between nl and n2 predict PP attaehn lent quite well in many eases . We use EDR concept dictionary to acquire the concel  ) tual relationship between two concet ) ts . For examt ) le , given the two concet)ts of open and key , the dictionary will tell us that there may be a implement relationship  1  ) etween them , means that key may be act its an instrument for the action open  . 
4.3 Preference Rules
We introduce 1 ) reference rules to encode syntactic and lexical clues  , as well a ~ s clues from conceptual information to determine PP attachments  . We divide these rules into two categories : a rule whi  ( ' tl ( :nit be applied to most of 1 ) rel ) ositions is cM led global rule ; a ruletying to a particular prel ) osition , on the other hand , is called local rule . Four global rules used in our disambiguatioi : module are listed in Table  1  . 
1 . lexical ( passivized ( v ) + PP ) AND prep?'by'->vp_attach ( PP )  2 . nl : n2->vi)_attaeh(nl+PP ) 3 .   ( prep#'of'AND prep#'for ' ) AND ( time ( n2 ) OIldate ( n2 ) ) - > Vl ) _attaeh ( PP )  4 . lexicM(Adjeetive+PP ) -> adjp_attach(PP )
Table 1: Global rules
Local rules use ( : once l ) tual inforlnation to determine PP attachlnent . In Table 2 , we show sample h ) cal rules for preposition with . 
with-rules : iml ) lement(v , :)2)-> Vl )_~ tttach(Pl )) ( a-ol ) jeet(nl , n2) ( ) R possessor(nl ,  112))
ANDNOT ( implen:ent(v,n2)) -> np_~tttach(PP)
Default->vi )_ attach ( PP )
Table 2: Sample local rules
On the left hand of each rule , a one-atonlpre ( t-Concet ) tDiction m'y consists of al ) out 400 , 000 con:cepts , where , fbreolle et ) t classification , related con-eepts are orgmfized in hierm'chie Mar ( ' hitecture and a concept in h ) wer level inherits the f ~ atures from its upper level concepts  . 
icate Oil the lefthand presents tt subclass of concept ill thee on  ( : ept hierarchy ( e . g . tilne(n2)) , and a two-atom 1 ) redicate describes the COlWei ) t relation between two at ( nns ( e . g . implennult(v,n2)) . 
Since local rules emph ) y the senses of head words ( termed as concepts )  , we shouh l1) roject each of v , ul and n2 used by rules into one or several coicepts which denote  ( s ) " correct " word senses before apl ) lying local rules . The process is described in ( Wu and Furugori 1995 )  . 
5 Disambiguation Module
For each sentence with a ml ) igu< ) us PP ( both ill syntaeti ( ' and semantie ; d level ) , PETE system will produ <' e ; t structure with unattached PP ( s ) , and call the disambiguation 1nodule to resolve ambiguous PP ( s )  . The algorithm used in then n ) (hfle is shown beh ) w:\[ALGORITHM\]P has e1 .   ( disambiguation using gh ) bal rules ) : Try global rules on e1 ) yone . If a rule succeeds , use it to decide the attachment , and exit . 
Phase 2. ( statisties d ) ased dismnbiguation):
RA(v , nld) , n2) = -1 ( initial value ) f triple ( v , nl , 1)  , lt2): f(v , p , : t2) + f(nl , 1 )  , n2)T f(v , nl , p ) f pair ( v , Ill , t ) , n2) = f(v , 1)) + f(nl , 1)) + f(p , ll2) iff triph , ( v , nl , i ) , n2) > 2 , then llA(vdil , 1 )  , n2) = . f(vvl ~ , , r, . 2)+ . r(~,~,1,,,v,-~)q . f( , ,v \[ , , , ~ , : ' a , ) f(v , v , n2)-bf(~t , p , ~ 2) . 4-f(v , . . 4>) if \[2*RA(v,n 1,1),n2 )-11 * log(fi . riple(v,n1,1), n2)) < 0 . 5 then RA(v , nl , p , n2) = -1 if RA(v , nl , p , n2) < 0 and fpair ( v , nl , l ) , l~2) > 4 , then I1A(v , nl , I) , n2) = f ( . vplv , p ) + f(vp\[ , , 1 p)T f( , ,plp , , , 2 f(v , p ) + f(nI , p ) + f(p , 7~2) if \[2*RA(v , nl , p , n2)- II * log(fpair(v , l l l , p , n2)) < 0 . 5 then RA(v , nl , i) , n2) = -1 if IA(v , nld) , n2) > 0 , then if RA(v , nl , 1) , n2)<0 . 5 , then choose NP attachment other w is ( , choose VP attachment exit . Phase 3 .   ( concept-based disalnl ) iguation ) : 1 ) Project each of v , nl , n2 into its COIte el ) t sets . 
2) Try the rules related to the prel ) osition , if only one rule is applicable , use it to decide the attachment , and then exit . 
Phase 4 . ( attachment 1) y default ): iff(p ) > 0 , then if ~< 0 . 5 , then choose NP attachment ; f(~ , ) otherwise choose VP attachment  otherwise choose NP attachment  . 
This algorithm differs from the previous one de . -scribed ill ( Wu and Furugori 1995 ) in which preference rules were applied 1 ) efol'e statistical computing . We have changed the order for the following reasons : an experinlent has proven that using the \]  . 072 data of qua ( lrul ) les and triples , as well as tut)les with high occurrences i , sgood enough in success rate ( SecTal ) lc3) . and statistic models ha , veaground m ~ the mlttical 1) as is . 
6 Experiment and Evaluation
We did a nexl ~ eriment to test our l nethod . First , we prc l ) are ( ltest data of 3043 ambiguous PPs in texts randomly taken from a ( : Olnl ) uter manual , a . 
graalll nlarbook and Japan Time.s.
Phase ~ lobal rules_lriplcs_Dairs local rides
Total Number
Number Correcl
Stlccess rate , 96 . l % 91 . 8% 85 . 3% 84 . 1% others 2l 715 169 . 6%
Total 304 326 4486 . 9% ' Fable 3: Results of the test in PP attachment The results are shown ill Table  3  . We successfully disaln biguated 86 . 9% ofth (, test data . To reduces l ) ars (' data .  1 ) roblenland deal wilh undefined wor ( ls in the dictiol m . ry , we use al ) roc (! dure simih tr to th ; ttof Collins and Brook 11995 ) to pro- ( : esshead words both in training data and in test datm Tile  1  ) ro ( :c ( lure is shown as follows : ? All 4-digit lmmbersitretel ) laced with ' date ' . 
* All verbs are rel ) l~u:ed with their stems illlow-or ( : as ( ~S . 
eNouns starting with it calfital letter are replaced with ' lmme '  . 
? Personal 1) ronouns in then 2 field are r ( , lfiaced with ' perso\]t ' . 
As the result , we a (: quired all ac(:uraterate of 87 . 5% ( TM ) le4), an improve mell to f0 . 6% on the 1) r(' . violls OlI ( LPhase Total Number Number Correct Success rote ~ global rules  507   487   96  . 1% ll~es 659 601 90 . 9%_Amirs 113496 584,9% local rules 6285 2783 . 9% others 1158 170 . 4%
Total 3043 2661 87.5%
Table 4: Rest flts with processing head words The result is rather good  , COlnt ) aral ) h ' to the l ) erformance of all " averag ( '  . " hlIl\[la , ll looking at ( v , nl , p , n2 ) alone ( al ) out 85% to 90% according to Hindle ~ md Rooth 1993  , Collins and Brooks 1995) . 
We attribute this result to the hyl ) ridapl ) roach we used , in which preferences with higher rdiabilities are used  1  ) rior to other on ( 's in the disalnl ) iguation l ) rocess . We found that two thresholds are very hell ) fuliniml/roving the result . If we set the first threshohl as 0 ~md throw away the second threshold , then l . he success rates ill tril ) le- ( 'onfl ) ination will \] ) ( K: (  , llt ('89 . 1% (-1 . 8%), a , nd 81 . 2% (-3 . 7%) in l ) a Jr - (: ombilmtion . Moreover , using h ) ('al rules to tackle unattached PPs by statistical model is also hellfful in improving the overall su  ( ' cessrat (  , since loom rules in l ) hase 3 work nmch b ( , tterthan default(h , (: ision in Phase 4 . 
7 Conclusion
Pure statistic M models for disalnl ) iguation tltsksSll ~' ( ' l'fl ' Ollls parse-data 1 ) robh ' nL ~ V ( ' l to t ( ' ( l that even when ai ) plying smooth t ( ' chniques such as se-nuultics in filarity or ( : lustering , it is hard to avoid malting poorest ; ilnat . iol~sOillow OCCltrr(ulcesill corpora .   ( ) nqine dictionaries wlfich contain rich semantic or concel  ) tual information ml W be of help in improving the perforlnan  ( ' e . ( ) urexl ) erim cnt shows tha , t the hybridal ) proach we taken is both effectiv (  , and a . 1) l ) li('able ill practice . 

Brill , E . and l('snik , P .  1994 . Arul ( '-l ) i ~ sedal ) -pro~Lch to 1 ) relmsitional phrlmeat ; t ~ t ch n w n t d is - ambigua . tion . In Proc . ofth , e , 15th , Coling , 11981204 . 
Collins , M . and Brooks , J .  1995 . l ) rel/osition alllhrase attachment through a backed -offl node l  . 
httl,://xxx.lanl.gov/c,ni,-lg/9506021.
DM figr('n , K . and McDowell , a .  1986 . Using con > monsense knowledge/o ( lisaml ) iguatel/reposi-tionMt ) hrase modifiers . In Pr'oc . of the 5th,
AAAI , 589-593.
Japan Ehwtronic Dictionary Research institute , Ltd .  1993 . ED\]I electronic dictionarys l ) eciti-cations guide . 
Jensen , K . and Binot , J .  1987 .  1 ) is ambiguating prepositional phrase attachments by using online dictionary definition  . In Computational
Linyuistica . 1313-4):251-260.
Hindlc , D . and Rooth , M .  1993 . Structural mn-I ) iguity mM lexical rel ~ tions . In Computational
Linguistics , 1911):103-120.
Luk , A . K .  1995 . Statistical sense disand ) iguation with relatively sIn all corllora using dictionary delinitiol ~ S  . In Proc . of the , '\] ( h'dACL Meeting , 181-188 . 
Whittelnore , G . ; Ferrara , K . ; and l~runner , H . 
1990 . Empirical study of predictive powers of siml ) leattach lnents dtell ( ' sfort ) ost-modiliers preposition M phrases . In Proc . ofth , c28th
ACL Meeting , 2330.
Wu , H . , Takeshi , 1 . and Furugori , T .  1995 . A pre-ferential al ) proach for disambigmt tingil relmsi- . 
tional phrase modifiers . In Proc . of the 3th . Na-tural La'ng'u , age Processing I ) acific Rim Sympo- , si Um ,  745-751 . 

