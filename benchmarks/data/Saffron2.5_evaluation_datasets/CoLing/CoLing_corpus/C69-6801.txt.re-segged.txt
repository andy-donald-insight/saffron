MULTI-INDEX SYNTACTICAL CALCULUS
Hans Karlgren
Introduction
In our work on analyzing Swedish nominal phrases as they 
appear as document titles-particularly titles of articles in peri-odicals -we have primarily utilized context-f reerules  . In an endeavour to reduce the cumber someness of such rules  , we have used the notation : ( 1 ) ab ~ c for x = p , q , r and y = u , v x y x y as a shorthand for six substantia lly similar rules  . The gain is not merely that of avoiding scr ivener's palsy - and puncher's impatience  , since the analysis program also accepts th is short-hand-but also that of clari fying the parallelism between the rules  . 
The rule schema reads Ha syntagm of type a combines with one of type b to form one of type c  , each being respectively of subclass p , q or r and u or v ' ~ . If the subscripts are interpretable as l inguistic categories  , this notation seems quite natural . We might write a fundamental rule of Latin grammar  , by way of illustration , thus adJngcn?mngc~nOmngc which would mean that to a nominal group may be joined an ad-jective of the respective number gender  , and case without changing the syntactical ca tegory of the group  . 
KVAL , Fack , Stockholm 40.
The work reported in this paper has been sponsored by The Bank of Sweden Tercentenary Fund and The Swedish Humanistic Research Council This notational little device actually often reduces the intuitive need for- context-sensitive rhles  , since it performs what these rules are requ ired to do in the domain where we have a cho ice  , namely to bring out the common pattern and leave aside for later consideration the minor adjustments  . 
Now , in practice , we have for each word or syntagm not one subscr ipt but a set of alternative subscripts  . On the initia-tive of Gunnar Ehrling , who wrote the analyzer , we further re-duce the notation by giving a name to all such sets of alterna-tives and by specifying in a " multiplication tab le ' the name of the set of alternatives fo rming the intersection between any pair of such sets  . Thus , in place of ( 1 ) our rules actually read--4/c . ( Z ) aikbjliAj , knl where the values of if lj and kN1 are taken from the " multipli-cation tab le '  . ' We no wask what will happen if we general ize this index " multiplication " so that it will represent not intersection of in-dex sets but an arbitrary binary operat ion on these to find exsymbols  . Particularly , we are interested in the case where this mul tiplication is non-associative and the set of index sym-bols is not closed under mul tiplication  . This would mean that the restrictions imposed by the indexes on the sentence or part thereof could  , in their turn , be written as a context-free-not a fini te-state-grammar over the index symbols  . 
When the subscript multiplication rules are generalized so far  , they are of the same kind as the ""' on mult lphcation " the main level  , and we prefer to write a filk for aik and we define 
IKVAL , Interim Report No13,
Program fSr grammatisk analysav texter that is  , the corresponding elements are multiplied : a lilk bljfl-ablijTkl We note that  , in general , these rules cannot be reduced to a finite li st of common context-free rules  , as could rules like ( i ) and ( Z ) . For if we can replace abby c , we may well be unable to replace ij by anyth ing shorter than ij  , the multi-plication table being blank for i jor even having no rowior column j  , since i and j may , in turn , be strings and not ele-ments in the index set  . And if the well-formed sequences of indexes are defined by a general context-free grammar and not by a finite-state one  , we cannot remedy this by adding more symbols to the index set : the set of triples i  , j , ij may then be infinite . 
This paper is an attempt to investigate thi sproblem  , elaborating such a multi-index calculus a little  . First , however , we may be excused for making a summary of the background of the recognition grarn rnar problems for which such a calculus may be useful  . The reader who expects tD bebored by such a survey should turn directly to page  10 below . 
Reduction
We introduce some definitions . The terms employed largely coincide with those of current generative linguistics  , but some minor adaptions have been made to make the terms adequate for describing the kind of recognition grammars with which we are concerned  . 

We consider ~ over an a_~phabet S =\ [ a , b , c ,   .   . \] . 
We write a b for the string formed by concatenation of two letters a and b  , and o~\[3 for the concat@nation of two strings c ~ and  \[3  . 
Concatenation is considered a reflexive , associative but not commutative relation . 
We write M for the set of all concatenations of strings in a set M : A rewriting rule  . . . . . ._ , ex-~ \[3 is a rule which permits us to replace thes tring ~ in any string where it may occur by the string  \[3  . A reduction rule is a rewriting rule wh ich does not increase the number of words in the string  . A reductions \] ~ stem is a set of reduction rules : R = ~~ B\[~cala Z  .   .   . an,\[3~blbz .   .   . bn , ai ~ S , bj ~ S , m_<n \] By means of R we can defi neader i ' vab ility relation over S ~  . We say that c ~ is reducible to 6 ,  ~ -~ \[3 , according to K , if there is a succession of applications of rules in K by which c ~ can be rewritten as  \[3  . We include the case where no rule is applied soce ~ ~ for all ~  . Thus , " ~" is a ~ eflexive and trans-itive re lation  . 
We now define a reduction grammar G = , ~ S , K , I , T > as a specification of a set of str ings  , a ~ over an input alphabet IcS : L = L(<S , R , I , T >) = oI . EI ~, o ~ . ~ ~_T c S "\] where T is a set of-terminal o r  , to avoid diametrically opposite associa tions-target symbols  , We say ~ is an R-reduction o for . 
Finite Rewriting Systems
Constituent structure ~ ramrnars an __~d ~ rammar components We first consider grammars where S is a finite set  . 
We call these grammars constituent structure grammars  . 
If T contains one single element , says for sentence , the grammar is a decision grammar , which specifies for each input string whether or not it is grammatical  . 
Trivially , T can be extended to include a few elements , says for statement , q ~ or question , and so on . Naturally , we can reformulate a grammar with T = ~ t1 .   .   .   .   . tn\] , where n is finite , into a grammar with a unique target element , merely by adding one element , says , to S and incorporating a few rules ti-*sl i = II  .   .   .   .   . n to 1K . 
However , allowing T to be an infinite set is not neces-sarily a trivial extension  . 
Trivial but occasionally practical is to define a language L  ( S , K , I , A ~ where the targets are all the strings over an out-put alphabet AcS  . 
If T is some non-trivially defined subset set  , L ' of strings over a subset A of S , we have
L = L(S , R , I , L ' ) where L ' must be defined by some grammar GI = < S~I~k  , T > We say that G "= < S , R , I , A > is a ~ rammar component and note that G " and GI together completely specify L  . We shall come back to this concept later when we describe more com-plex grammars as combinations of simple ones  . 
With the restriction imposed on the rules of R that the right hand side should never be longer than the lefthand side  , it is obviously always possible in a fin itenumber of steps to decide whether or not a given finite string is reducible to some element in T  , i . e .   , whether or not it is an element in the set L . For if the given string o contains m symbols and $ contains n different symbo ls  , a can be shortened at most ( m-1 ) times and after the i'-th time it has been shortened  , ( i = O ,  1 ,   .   .   .   . m-1) , it can be rewritten without shortening at most  ( nm-i_l ) times without being rewritten as a , which can always be avoided by keeping a fin ite record of historical information  . 
Disjoint constituent ~ rammars 1 . A reduction rule where the right hand side contains ex-actly one symbol is called a context-free rule  . If all the rules are context-free we say the grammar and the language is context-free  . 
If the grammar is context-free we may give it the fol-lowing interpretation  . Let the letters of I be sets , " categories " , of strings of linguistic signs . Let a . _ . b b mean the set of strings consisting of one string contained in category a foltowed by one contained in b  . Let the reduction rules mean inclusion so that  , e . g .   , a bcc means that the set a ~ b is included in these tc  . 
A string o over I then represents a grammatic a l sentence of type t  , if and only if , Rm(yctsT . 
2 . A context-free constituent grammar , then , can be adequately described as a classifi cational system with finer and broader te rms where all classes can be written as cdn catena-tions-interpreted as the set of concatenations of the cartesian products-of a finite set S of categories  . The process of ana-lyzing sentences of such a language can be performed as a clas-sifi cational procedure and the result is adequately and exhaustively statable as the class adherence of sets of successive substr ings  , representable , e . g . , by a tree with no crossing branches . 
One may note that the character of a context-f reelanguage well conforms with what used to be defined as agglutinative lan-guages  , that is with the agglutinative languages as they were commonly defined  , not as any existing natural language of any particular group  . 
The assumptions behind an attempt to describe a real language by a context-free grammar  , therefore , are very strong . It is not astonishing that these attempts partially fail  ; it is astonishing that they have carried as far as they have  . For instance , there is no convincing empirical evidence that a deci-sion grammar for a naturall anguage cannot be written as a context-free grammar  , though there are ample theoretical rea-sons not to stake too much on the prediction that no practical counter-examples will turn up in the future  . 
3 . If we add to our context-free grammar rules of the type ab  . -* b cor , generally , permutation rules where the same elements recur on the right  , though in different order , we broadens of course , the family of languages under considerations and the interpreta-tion above under  2  . no more holds true . But all what was said about the highly spec ialized character of the languages remains t rue  , except that class adherence is now not conf ined to sets of successive substrings  ; the language is characterized by the exis tence of discontinuous constituents ~ and except that the tree drawn will have cross ing branches here and there  . But it is still possible to assign each substring to exactly one immediately higher order constituent and it is still poss ible to draw a tree  . 
We may summarize the constituents of arment ioned under the name ~- constituent grammars  , i . e .   , grammars where each constituent is either d is joint from or included in another and where  , accordingly , the constituents can be defined as a hie rarchial set of equivalence classes over the substrings of the given input string  . 
Such a classification of substrings is called ap-marker  . 
The hope of expressing the essence of the syntact ical structure of a sentence by one p- marker therefore implies strong as sump-t ions about the language  . 
Overlapping constituent grammar
If the rules of R do not obey the restrict ions mentioned for disjoint-consti tuent structure grammars  , that is , if rules occur of the type abc ~ de or abc -'* d c no equivalence classification of substrin ~ is obvious and no tree can be drawn without further assumptions  . 
The most natural would be to draw a graph of the fol-lowing kind : Unlike p-markers  , this graph attributes one and the same substring of the input string to more than one higher constitu-ent also when these h ig her constituents are disjoint  . Here abc belongs to d and to e , to k and to i . 
It is by no means an unnatural description of a sentence to let one segment have more than one function  , norisitim-practical to represent such st ructures as graphs  . On the cont-rary , that is what graphs are for , and in the special case where no two branches ever coalesce  , the graph seems to be so utterly simple that it is  , at any rate , rather a waste of paper to print drawings of it  . 
For a subset of the grammars now under discuss ion we can  , with some good will , construct p-markers , although the same rules contain more than as ingle right handed element  . 
If the rules are of the type abc-~d cor , generally , only one symbol on the right is different from the corresponding symbol to the left  , we may , by convention ; consider abto be a constituent of typed , whereas conly func-tions as a context . For these context-sensltive cases wethere- for e can agree to represent our reduction as fo llows : a/b c instead of a ~ c 
I d c d c
It might seem as natural to draw abcdcsay ing that d is a representation of C as well as of ab  , sinced could not have been rendered as a bun less chad been present  . 

Psychology , edited by Luce , Bush , and Galanter . 
One would then have overlapping constituents in cases such as Swedish gott  , reducible to godt : got tadj flexionale lement Nobody seems to be over-happy with th is attempt to " add conditions to guarantee that ap-marker for a terminal string can be recovered uniquely from its derivation " and for this and more serious reasons linguists turn away from these types of constituent grammars altogether  . But it is characteristic that one attempts to find " unique " equivalence classifications  , i . e . , tree graphs of the simple kind described . " We assume that such a tree graph must be a part of the structu-ral description of any sentence  ; we refer to it as a phrase-marker p-marker . A grammar must for adequacy provide ap-marker for each sentence "  . ~In other words , rather than modify the kind of graph employed , one replaces it , in transformational grammar , by an ordered set of such simple graphs . 
The multi-index notation permits an alternative mode of presentation  , as will appear in the next few paragraphs . 
In finite Rewriting Systems
We now consider the case where a grammar G = < S , i  ~ , I , T > contains an infinite alphabet S . 
In particular , We consider the set S of vectors over a finite set St of indexes : S = S'U\[si's zf  .   .   . \[ SnlSi 6Sl\]
Chomsky , op . cit . p.~.

For S we introduce the general multi-index multiplica-tion schema:i III  ( l )   ( SlSzI "'" Sn )   ( tlt2"''ltm )  -*  .   .   . J . ' t if n < m ( Slt )  ?  ( szt2 ) I ! ( Sntn ) ! tn?1 .   .   .   . m(sItl ), ( szt2), .   .   . I(Snt n ) if n = m .   .   . ii if n > mIst ) I ( Sztz ) II ( smtm ) ' Sm+'''"Sn that is , for i > n and j > m we considers . = t . : e , where eIj is a unit element such that a e = ea = e for all a  . 
I~l contains , except the general multi-index schema () , a finite set i ~ I of rules or rule schemata over $ Z  ) R '=\[ or "* Slet-alag .   . -an , B = blbz .   . , bm,n~m where a . and b . are elements in S or variables over $ or over x j specified subsets thereof  . 
T is given either explicitly or as an infinite subset of S 
T =\[ t'xltEAcS,xESi . e .   , as those elements in S which consist of an e lement in a finite set A  , arbitrarily subscripted . 
We note that every elements in S defines an in finite class of elements beginning with the vectors  , just as a decimal number defines a class of number with the same or a greater number of d igits  . 
The rules of R are such as i ab-~c
Zalxbly--~clz3a ' . x - . * b4a-*b'x + and so on . To make a language decidable it is obvious lysuf-ficient-by way of analogy with the reasoning above-to re-quire that ther ight-hand side should never contain more le t - 
Jters out of the alphabet SI than the left -hand side  , thus ex-cluding rules like rule 4 above . The fact that the letters are here distr ibuted over different levels  , so constituting one or more symbols of S , cannot invalidate that argument . 
The conclusion obviously also remains in tact if we accept rules with a longer right -hand side for rewriting symbols which never occur on the right-hand side of any ru le  , that is , if we make allowance for assignment rules . 
In the following we shall restrict ours e lvesto context-free multi-index rules  , that is , the rules shall a ) contain one element of ~ S on the right-hand side and wherever practical the rules shal lalsob  ) contain at most as many elements of Si on the right-hands ideas on the left-hands ide  , except where the left-hand side consists exclusively of elements which occur on the right-hand side of no rule  . 
Though each rule is a context-free rule , such a multi-index grammar is not a disjo int-constituent grammar  ; consti-tuents do overlap :
Let us consider a grammar where ab-*ddc~s xy~u 
UZ ~ V and where slvET . Let us consider the analysis of the string a ~ x btyclz :  t2 The second restriction is unnecessarily severe  . One may well include , e . g .   , rules which are not reductive with ref-e rence to S " but which are strictly reduct ive on the highest level they refer to and wh ich do not increase the number of levels refer red to by any rule  . 
or graphically : alxb~ycl . z dlxyclzs lxusly We see that segmentation is overlapping but that each level of : indexes represents one equivalence c lassification and one tree-shape graph  . 
In many cases , context-free multi-index rules are weakly equivalent to context-sensitive rules  , as Will appear from the following few examples of languages which notorious-ly cannot be described with ordinary context-freer u les  . Crude-ly , we may say that taking an index on another level into account is an implicit way of regarding context  . 

Example 1. The language " an bncn " .
~ I : a ~ xlpb ~ ylp
C~zIq"xy~sxsy~s
SZ ~ Sppq ~ e where e is the unit y element.
Illustration : aabbccx ' px ' py ' pz ' q z ' q x t p s l p p y l p z ' q z f q s i p p p p p p p p lqs ? ppziqsle = S 
T=s arbitrary string of a ' . s and b ' . s followed by the same string ' repeated . 
R : xy ~ xry for x = a , b and y = a , bxx~s for x = a , bs is ~ slllustration : abbababbab , a ' ( b ' ( b ' ( al-b )   )   ) al-ibl ( b\[ ( a\[b )   )   ) s ' ( s ' ( s ' ( s's ) ) ) s
Example 3. The language ( an bn ) m
R r : x x l y ~ x l(x t y ) for x = a , b and for all y ES ab - * t t l x t f x ~ t t x for all xESt-*s 
SIS "* S
T = s\]
Illustration : a a abbba a abbba ' ( a'b ) b ' ( b ' b ) al ( a ' at ' ( t't ' ) t ' ( t't ) t ' ( t't ) s ' ( s's ) $ b ' ( b ' b ) R ' : x x ' y - x ' ( bly ) for x =  b , candally ES ablx clx--blx for all xESb~s
SIs-~S
T : s\]
Illustration : aa abbbb bccccccccccc aab ' ( bi ( bib )   ) c' ( b ' ( b ' b )   ) ci ( b ' ( b ' b )   ) c' ( b ' ( b ' b )   ) aab ' ( b ' ( bib ) )ci ( b' . (bib ) )ci ( b ' ( b ' b ) ) b ' ( bI ( bib )   ) s ' ( ~'  ( s's ) )

Thus , the possibility to add further index leve ls at option provides arneans of performing arithmetical operations  . 
The context-free multi-index rules are powerful and cover many languages of what is known as the context-sensitive type  . 
We shall now turn to linguistic interpret a tions of such a calcuius  . 

Multi-index Calculus in Linguistics The multi-index calculus can be applied in l inguistics above all for two purposes : to replace context-sensitive rules and to provide a means of representing p-markers  . 
Context-free multi-index rules derived f rom context-sensitive rules It is possib le to replace many-all ?- context-sensi -tive rules by an equivalent set of context -free multi-index rules  . 
Thus , the rule a ~ b / ~ c can be replaced by a ~ b lp  , c-cIq and pq ~ e or , more cautiously by the assignment rules a-A lpc-CIq and the reduction rules 
AIp ~ A ~ r
Air ~ Bitrq-ep ~ eq ~ e where e is the unity element  . 
Let us consider the following little g rammar : j-i/g--hg"ghi"~d/h-gh-*c f-~a/--ccd-~bab'~si  7 thus With this grammar , the sentence ~ hgj will be analyzed
I '" d/c/J\/
We have here adopted a " mixed " tree represent at ion for context-sensitive structures  , with obvious significance . 
We can reduce the same sentence to s by the fol low-ing set of rules : j ~ i lkg ~ glllk -   . eh ~ gJ . rng-*gltg-~hlnrot- . rn rgln ~ ei ~ dlph ~ hlq qp--egh ~ cf ~ a '- r 
C ~ titrt--ecd-~bab ~ S
Thus , f h g j f h g f l i l k f h g i ' ( lk ) fglmhJnifght ( mn ) if g h f q d t p f g h d ' ( q p ) fcdaircltdac ' ( rt ) dabsGraphically , this means that we have a set of inter- connected tree graphs :  i!1   t9 In a transformational grammar , we interpret G " as a grammar component , adding to our grammar a component G'--<Sl , RI , I i , T '> where 1I-is the set T " of p-markers , T i is a subset there of and R ! is a set of multi -index rewriting rules such as alx ~ a ' yatxbly ~ clxa ~ x alxbly ~ a!x bly alxbty at x  . bly ~ bly . alx for specified sets of values for x , y , etc . , that is , substitution , reduction , expansion and permutation rules for which the conditions are not confined to one index level at a time  . 
Regarding the analysis as a syntactic tree , we may characterize transformational rules as such where the conditions for some symbol  ( s ) to be rewritten in a specified way refer to the " vertical " neighbours  ( not to the " horizontal " neighbours as in context-sensitive rules  )  . We might speak about pretext and post text sensitive rules  , or generally about " k in text sensitive " rules : Obviously and notoriously  , "k in text " must play a different role in generative and in recognition procedures  , since pretext in one case is post-text in another . 
Thus , one component may map the input strings on T "= \[tilxlti  6 T ; x 6 S"\] and ~ a transformation component may map I I  . = T " on T '=\[ tly lt 6A \] and y = a ! laz la31   . . . lai6B where B is a subset of S " and A___CT . Or we may define the target set for each component in other ways  . 

Multi-index calculus in a transformation a l grammar Given a constituent structure grammar G = < S  , R , I , T > we obtain an infinite grammar G " by replac ingS by S "= SUsI  Is2   ts3  ,   .   .   . \[ siES"\] and R by g "=\ [ a , a z .   .   . an ~ b'(a , a Z .   . , an ) l(a , az . -- an ~ b ) eR\]ifK is context-free and otherwise R "= \[ alaz  .   .   . an~b , ' ( aiaz .   .   . an)'bz'(aiaz .   .   . an ) .   .   .   . " bm'(a laz .   . : an )\ [( ala2 .   .   . an ~ blbz .   . , bm ) ER and replacing T = t1, tz .   .   .   .   . tk by
T"=ti'x\[tiETxES "\].
That is , we obtain a grammar * which maps given strings on an infinite set which may be considered as a set of p-mar-kers ~  . G " is then an interpretation grammar , corresponding to G . 
j\a decidable one , seep . i3 above , footnote . The number of levels does increase , but all rules refer exclusively to the uppermost level  . 

These multi-index expressions naturally contain all information that transform at ions operate upon  . Indeed , they will often contain too much , but superfluous indexes can easily beel iminated by multi-index rules  ; the point is that no side conditions for permiss ible transformational rewritings need be observed  . Every-thing needed for the calculus is in the string  . 

Thus , one-level reduction rules suffice for a decision grammar for a constituent-structure language and multi-index reduction rules suffice for an interpretation grammar for such languages  . Multi-index rules also suffice for a decision grammar for a transformationally defined language  . ~ The question remains if they suffice for an interpretation grammar for the latter  . 
A structural description of the sentence may be given as the sequence of p-markers obtained during the analysis  . 
Now , since the relative order of operations is not inherently fixed  , we would like to find a representation of such sequences such that equivalence can easily  , be defined . That is , we want to find an adequate interpretative grammar corresponding to GI  . Can multi-index rules serve those purposes ? The unified formalization  , provided by the multi-index represent at ion  , might prove an aid to finding an effect ive interpretative calculus for transformationally defined langua-ges  . 

The multi-index calculus seems promising for several  . 
linguistic purposes , especially where restrictions can be assigned to several  , weakly interacting levels . 
if this is decidable . They may also , incidentally , provide simple decidability criteria for a transform-ational grammar  . Cf . tile hints above(p .  13) . 
2Zr ? ~
