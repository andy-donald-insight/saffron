Machine Translation by Case Generalization
Hiroshi Nomiyama
IBM Research , Tokyo Research Laboratory
519 Sanbancho , Chiyoda-ku , Tokyo 102 Japan
E-Mail : no miyama@trl.vnet.ibm.com

Case-based machine translation is a promising ~ p -preach to resolving problems in rule-based machine translation systems  , such as difficulties in control of rules and low adaptability ospecific domains  . We propose a new mechanism for case-based machine translation  , in which a large set of cases is generalized into a smaller set of cases by using a thesaurus  . 
1 Introduction
Case-Based/Example-Based Machine Translation ( CBMT/EBMT ) has been proposed as a way of overcoming the knowledge acquisition bottleneck in machine translation  . This approach is based on the simple concept of translating sentences by analogy with similar case stored in a set of cases  ( a case-base )  \[1 ,  2 ,  3 ,  4\] . 
This ~ p proach has two advantages in terms of knowledge acquisition  . CBMT/EBMT ensures that ( 1 ) if the same case as the input exists in the case -base  , then the same result will be obtained , and ( 2 ) if a similar case exists in the case-base , then a similar result will be obtained . In the first instance , which eases are regarded as the same depends on the equality metrics of the system  . In the second instance , which cases axe regarded as similar depends on the similarity metrics  . Rule developers or users can control the system on the basis of equality and similarity without understanding the global flow of controls  . 
In applying this idea to practical machine translation systems  , there are still two serious problems . One is that CBMT/EBMT requires a great deal of computation because of its inherent need to retrieve a huge number of cases and calculate their similarities to the input  . For practical systems , several hundreds of thousands of cases must be accessible  . 
CBMT/EBMT system should not impose any restrictions on cases to be added to the case -base in an effort to keep the case-base small  , since the similarity metrics depends on the frequencies of cases  . If cases are restricted , sufficient information to control the rules is not acquired  . 
The other problem of CBMT/EBMT is the difficulty of defining a semantic distance  , Though thesauri are used as bases for semantic distance calculation in CBMT/EBMT  , it may be impossible to define a general semantic distance by using thesauri alone  . 
Semantic distances between words are defined according to which specific words axe related to their translations  . For example , in translating the word "~ t : " ~" ( eat , feed ,  . . .  ) , "9 ~( dog ) -; b ~ : " c , Y ~" is equivalent to " a do geats , ""-'~( cow ) -7) ~-~ :"? , 7 ~'' is equivalent o " a cowfeeds , " and " . ~  ( horse ) -7 ) e-~:"v-Yd''is equivalent to " a horse feeds . "In these cases , " ~ i:"(cow ) is closer to " , ~" ( horse ) than ": : ~"( dog) , because different words are selected for each transla  , tion of "~: " ~ ~" with " t ~'( cow ) and " Y ~" ( dog ) . But in translating " ~7z " ( run , gallop, .   .   . ),": J~(dog)-:6? . ~ . 7 o " is equivalent to " a do gruns , "  , ,-~ t = ( eow) . : ~_:~=7~" is equivalent to " a cowruns , " and " . ~  ( horse ) -Z~L::i~--zo " is equivalent to " a horse gallops . "In these eases , " t\[='(cow ) is closer to "9~"( dog ) than " , ~" ( horse ) . 
If such incomplete semantic distances calculated by thesaurial one are used for CBMT/EBMT  , exceptional cases may be interpreted as general ones  ( over-generalization )  . Overgeneralization is a major problem in translating idiomatic expressions  . For exanl-pie , "\[ t\[I ( head ) -z ) ~ AJ/J~L7o " has two translations : " hurt one's head " or , idiomatically , " besmart . "But " ~\] i ~ ( head ) -~?-~-~" has only one interpretation , " hurtone's head , " though the word " ~ jl ~\[ ~'' has almost the same meaning as "  . U  ~ . " . 
It is obvious that "~-~': ~ . ~ tt:~TJ ; tl . ~" can be translated correctly by adding this translation pair into the case-base  . The addition , however , cannot prevent ACRES DECOLING-92 , NANTES , 2328 ao6-r19927!4 PRec . OFCOLING-92, NANTES , AUG .  2328 , 1992 the idiomatic expression " ~ J~-7 ) ?-~7o " from being interpreted generally . The idiomatic interpretation still may be ' adopted for " X  -~5?-~7~" if X is more similar to the word "~ j ~" than the words in the case-base whose pattern is " X-z~-~ /LTo  . " Sato \[3\] and Sumita \[4\] weigh each slot depending on how much it affects the translation  . However , since such weights are calculated only for each slot  , the overgeneralization that occurs inside of a slot is not resolved  . To avoid overgeneralization , we need some mechanism to encapsulate x ceptions rather than to adjust the semantic distance  . 
2 Machine Translation by Case
Generalization
A case-base , in contras to a set of rules , has inherent redundancy , because cases are collected without preselection . In the simplest case , if the sentence " A " has only one translation equivalent " a  , " then the single ease " A "~" al ' is enough to translate " A ? ' But if we view the case-base as a collection of sentences  , the santo sentences rarely seem to occur 1 . Sentences can , however , be divided into smaller fragments which are meaningful units for translation according to the some linguistic models  , which we call translation patterns . 
These fragments are combined for use in translating sentences  . Fragments divided on the basis of translation patterns are obviously more effect lvc than sen -fences  , because smaller fragments are more likely to match than full sentences  . 
We generalize such fragments extracted according to each translation pattern  , using a thesaurus , by replacing the words that occur in cases by more general concepts in the thesaurus  . The words to be replaced are determined by their frequencies in the case-base  . 
Frequent occurring fragments should be assigned more weight than less frequent by occurring fragments  . The frequencies of fragments axe used to weigh generalized cases in generalization  . 
Semantic distances are calculated for each translation pattern as the importances of generalized cases  . 
Only meaningful categories for the translation patteruare stored as generalized cases  , except that the most meaningful category is taken as a default  . For example ,   1The ease-bane should contain natural sentences rather than examplt ~ which ~ reonly the smallest fragments effective for translation  . We distinguish CBMT from EBMT in accordance with this view paint  . 
the word "9~" ( dog ) may be generalized into the cou-cept < dog > 2 for translation of , qrJj <" (" a dog barks ") , whereas it may be replaced by t be more general concept < animal >  , for other translation patterns in which the concept < dog > is not ineaningful  . 
While generalizing cases , we can identify exceptional cases as those which cannot be generalized  . Once we identify exceptions , then we can prevent such exceptions from being interpreted generally  . 
In this way , cases are generalized according to t be translation pattern into generalized cases with concepts as the values of their variables  . 
Inddition to generalized cases , rules can be form u-latcd according to translation patterns  . Generalized cases and manually written rules are assumed to be the same as objects in CBMT  . It is valuable to have rules available as well as cases  , especially when the case-base contains iusnfficic nt cases  . If rules are not available , there must be sufficient cases from the time the system is first used  . h~creinental development of any domain is possible only if general rules are available  . 
In accordance with these basic ideas , we propose a method of machine translation in which cases are generalized  . In our approach , we define linguistic patterns in translation . According to these patterns , the cases in the case-base are divided into smaller fragments and are generalized  . Botl L rules and generalized cases are used to translates enteuces  . 
CBMT is divided into two subprocesses : ( 1 ) best matching , to search for the nmst similar cases in the case -base  , and (2) application control , to control the combinatim ~ of similar cases for translation  . Application coutrol is a general problem in machine translation  , whereas best matching is a problem unique to CBMT  . If the best matching process returns certainty factors  , the system is controlled using these factors on the basis of the some other model such as Watanabe's  \[5\]  . 
In tiffspaper , we concentrate on best matching using a thesaurus . 
2 Concepts are enclosed between arrow heads ( < and > ) in this paper . 
ACTESDECOL 1NG-92 , NANTES , 2328 AO(ff 19927 I5PROC , OFCOLING-92 , NANTES , AUG ,  2328 , 1992 3 Generalizing Cases 3 . 1 Division and Linearlization of

At first , we define a translation pattern ( TPi ) as follows . 
TP ~=\[ P ,, V ,, P ,, Vt\]
P ,: Structural Pattern in Source Language ( SL)
V , : List of Lexical Variables in SL
Pt : Transformation i to Target Language ( TL )
Vt : List of Variables in TL
We call the number of variables in V , the term number ( Mi ) of TP ,  . 
Next , we extract translation pattern causes ( TPC , ) from the case-base by applying the pattern matches described in TPI to all cases in the case -base  . 
TPC i =\[ L,,C ,, L,\]
L ,: List of Values of Lexieal Variables in SL
C , : List of Constraints in SL
Lt : List of Values of Variables in TL
If some patterns other than those specified in P , are related in translation , those patterns axe described in constraints ( C , ) . 
These TPC , s are finearllzed into linear lized translw-tlon pattern cases  ( LTPCi )  . 
LTPCi : L.--*(Co , Lt)
We call the right hand part of LTP Ci the value ( V )  . The examples in Fig . 1 are extracted LTPC , s in Japanese-to-English translations of " NOUN ni VERB  , " where we assume a translation pattern in which an English preposition is determined by a binary relation of a Japanese noun and a Japanese verb  . 
In the following section , we show how to generalize LTPC is into generalized linear translation pattern cases  ( GLT PCI ) by replacing words with more general concepts in the thesaurus  , and calculate degrees of importance for them . 
\[" Sangatu " ( March) , " Kowasu " ( destroy )\ [" Sigatu " ( April) , " Gironsnru " ( discuss )\[" Gogatu " ( May) , "Saiketusuru " ( vote)\["Rokugatn"(June) , " Hieru " ( cool )\[" Getuyou " ( Monday ) , " Arau'(wash )\[" Kayon " ( Tuesday ) , " Kimaru " ( decide )\[" Sy .   .   .   .   .   . tu " ( weekend ) , " Agarn " ( raise )\[" Higasi " ( east ) , "Uturu ' ( move )\[" Touk you " ( Tokyo) , "Idousuru " ( move )\[" Sitigatu " ( July) , "Idonsuru " ( move )\] ~(\[\] , \[" in"\])l~(\[\] , \[" in " l)\]~(\[\] , \[" in"l ) ~(\[ I , \[" in " D(H , \[" on " D(\[\] , \[- on " D(\[H"on'D~(\[\] , \[" to " D(\[ , \[" to "\]) ~(\[\] , " in "\] ) Figure I : Translations of " NOUN ni VERB "3 . 2 Case Genera l i za t ion by Means o f a Thesaurus  3  . 2 . 1 Creat ion of N-Term Part ia l Thesaur i We create working thesauri  , PTH~(j ) (1 < j < Mi) , for each term . The yiuclude every word in the jth term , and set pairs of values and their frequencies in each word node  . 
Here we definettle importances used to weigh generalized cases  . 
Importance of a Link ( . rL ) The importance of a link ( IL ) is the probability of occurrence of eases that occurred in the subtree of PTH  , ( j ) . IL is defined as follows . 
SIL = -- c , where S is the total number of cases in the subtree connected with the link  , and C ~ is the total number of LPTCIs extracted from tile case-base according to 

Importance of a Node ( IN ) The importance of node ( IN ) shows the degree of variance of values in a subtree  . IN is defined as follows . 
where Pk is the probability of each value in the subtree  3  . 
Importance of a Value ( IV ) The importance of a value L ( IV ) in the node k is defined as follows . 
If node k is a word node , then \[ Vkt = frequency of value Lin node ka We adopt the s~m expre ~ ion as that used by Stanfill  \[6\] and Sumita \[4\]  . 
AcrEsDECOLING-92 , NAN'IXS , 2328 AO0"r1992716 PROC . OFCOLING-92, NANTES , AUO .  2328 , 1992 else\[V ~ , t = INj , t ~__ , ( IL , , x IV , ,i ) where m is a node linked to node k , and /14 , a is the importaatce of value L in node m . 
Importance of a Generalized Case ( IC ) The importance of a GLTPCi ( IC ) is defined a . s follows . 
Mij = l where IVj tistile importance of value L , which is the same as the value of the GLTPCi . 
3 . 2 . 2 Subd iv is ion of Conceptua l Leaf Nodes According to the definitions given in the previous section  , at first ILs and INs are set in all the links and nodes in PTHI  ( j )  , and IVs are calculated m conceptua leaf nodes in PTHi  ( j )  . 
If IV is not the maximum value in a conceptual leaf node and is greater than the prc-defined threshold value and its frequency is greater than  2  , the node is subdivided into more specific concepts  . 
Subdivision occurs because a specific category which doesn't exist ill the thesaurus is effective for a specific translation pattern  . Only the difference from tilettle-saurus is kept a  . s the translatlou pattern thcs an rusi(TPTHI ) . 
3 . 2 . 3 Propagation of Importance of Values Next , we calculate IV in all nodes other than CO lt -ceptuale af nodes by propagating IV  . The propagation is done by multiplying the importances of values by the importances of links  , and the sum of all the propagated values is multiplied by the importance of the node  . At first , the propagation is done upward , starting from the conceptual leMnodes . During upward propagation , downward propagation is done if a child node is a conceptual node and a propagated value is greater than the maximum importance of values in the child node  . Downward propagation prevents over generalization . 
We show examples of results of importnnce calculation in Fig  . 2 and Fig . 3, fortile first and second terms respectively . In Fig .  2 , the subdivision occurred in the node < Time > and the new node <* X *> was created  . A downward propagation occurred in the node < Concrete > in Fig  .  2 . Tile word " in " was made more important hanthe word " to " in the node < Concrete >  . 
\[<> , <Destruction>\]-~([\] , \[" in " l)\[<> , < Speech >\]~(\[\] , \[" iil "\])\[<> , " Salk et . . . . . . . "( decide)\]~(\[\] , \["\[ n "\])\[<> , <>1 ~ (\[\] , \[" in "\])\[<* X*> , < Action>\]~(\[\] , \[" on"\])\[<*X*>?'Kinlaru"(decide)\]-"(\[I , \[" on " l)\[<*x*> , < Up-D .   .   .   . > l~(\[\] , \[" ? n " l)\[<Location > , < Abstract >\]-*(\[\] , \[" to "\])\[< Directlon > , < Abstract >\] -"(\[ l , \[" to "\])\[<> , "Id .   .   .   .   .   .   .   .  "(  .   .   .   .   .   . ) l~(\[\] , \[" t ? "\] ) Figure 4: Result of the lntra-Term Generalization 3  . 2  . 4 I n t ra - Term Genera l i za t ion of LTPCi According to importances calculated according to the method described in the previou section  , LTPC is are generalized in the jail term . If the value with the highest IV in tile child node is the same as the value with tile highest I Vintin > parent node  , then tile word in the term is generalized by the concept in the parent nodE  . ' . This process of generalization is repeated until no further generalization is possible  , and only the most generalized cases are kept . If identical c~es are obtained as a result , only one case is kept . 
We show an ex~tmple of intra-term generalization of \[" Kaymz "  ( Tnesday )  , " Ki . . . . . . . "( decide)\]~(\[1,\[" on"\]) . 
Initially , the firts term " K ~ vou " ( Tuesday ) is gener-Mized . T1 .   .   .   .  1  .   .   .   . f(hi .   .   .   .   . (\[\], " on "\]) is th .   .   .   .   .   .   . 
a stile vMue with tile highest IV in the parent node <* X *>  ( see Fig . 2), so " Kayou " ( Tuesday ) is replaced by <* X *> . The value (\[\] , \[" on"\] ) is not tile value with tile highest IV in the parent nede of <* X *>  , and therefore generalization stops at the first term  . Next , the second term " Kimaru " ( decide ) is generalized . Intt~eparent node < Decision > of " Ki-maru " ( decide )  , tile value that is the same a stile value of the e a  . se is one of the values with the higtlest IV . Consequently , parent nodes are checked to determine which value is more important  . In tile root node ,  (\[\] , \[" on "\]) is less important l . . . . (\[\],\[" in '\]) .   .   .   . 
no generalization occurs for the second term . Finally , \[<* X *>, " Ki .   .   .   .   .   . "( decide)\]~(\[\] , \[" on"\] ) is obtained a stile result of intra-term generalization  . 
Tile result of intra-term generall zatiml for all tile 
LTPC , s in Fig . 1 is slmwn in Fig . 4.
3 . 2 . 5 In ter - Term Genera l i za t ion of LTPCi Next we generalize cases over terms  . Inter-term generalization takes ICs into consideration  . If M ,  = 1 , ACRESDE COLING-92 , NANTES , 2328 AOIT 199 2717 PROC . OFCOLING-92, NANTES , AUG . 2328, 1992 o . 1" Rokugll U " , l , (fl , p + ln ~ " 0 etu you " , l , (~\] , Fon++\])-SmOaW ' , 1 . (fl , FIn "\]) " KJ y ~", l + (~,\ [" o . +\]) - sangltu + + . l,(D , t'ln+J ) "$ yuuma ~ u ", 1, ( a,p+o . + l ) Figure 2: First-Term Partial Thesaurus : : : :=+ :+ :+ , +++ , , . , . ++ . ++++ . I +, . ,,  . , r , : ? . u , .   . , ! ? : : ? : , : ? + , , o . , o , + . , ~- ~ o . 1o , +-+ ~ . , +'+:+'?+" ~ lketusum",l,(\[l,\["ln"l) . Glron ~ ru , ,,( Q,\[ . ,in . l ) " KImMu " , l , (D , r ' on " l ) Figure 3: Second-Term Partial Thesaurus ACTESDE COLING-92  . NANTES , 2328^oI3"r1992718PROC . OFCOLING-92 . NANTES , AUG .  2328 .   1992 then the result of intra-term generalization with ICs is the generalized linear translation pattern case i  ( GLTPCi )  . If M ,  > 1 , jth term ma~ximum generalization ( 1 ~ j < M ~ ) is done for e ~ . ch term . In jth term maximum generalization , terms other than the jth term are fixed first and the jth term is generalized  . as much a . spossible . Then , the maxinm ni possible generalization is done for remaining of terms in turn  . 
If Mi > 1 , then M , x(Mi-1)GLPTC , saxe obtained . 
If identical cases are obtained as a result , only one case is kept . 
We show a nexz~mple of inter-term generalizatlnn of \[< Directiou >  , < Abstraet >\] -"(\[\] , \[" to "\]) . Initially , first-term ma . ximum generalization is done . IVs in the node < Abstract > are shown be to w ( see PTHi ( 2 ) in
Fig . 3).
( N,\["to"l):0 . 027(~,\[" in"\]):0 . 020 ( N,I"on")):0 . 006 IVs in the node < Abstract > , which is the parent node of < Direction > , are shown below ( see PTHi (1) in Fig . 

( l \],\[" in"\]):0 . 192 (\[\],\[" on'l ) : 0 . 035 (\[\],\[" to"\]):0 . 007
Their totals are ms follows.
(~,\ [" to "\]):0 . 027 + 0 . 007 = 0 . 034 ( H,\["in"\]):0 . 020 + 0 . 192 = 0 . 212 (\[ l,\["on"\]):0 . 006 + 0 . 035 = o . 04 ~ Since(\[I , \[" to " l ) doesn't have the highest importance , the case is not generalized any further in the first term  . 
Next , the second term is generalized . The IVs in the node < Direction > are shown below  ( see Fig .  2) . 
(\[\],\ [" to " l ) : 0.1
IVs in the node < > , which is the parent node of < Abstract > , axe shown below ( see Fig .  3) . 
(~,\[" in'l ) : 0 . 011 ( H , \[" to " l ) : o . o0 s(N,i"on"I ) : 0 . 006
Their totals are as follows.
\[<>,<>\]-,(\[,\[" in"\])0 . 11 s\[<*X*>,<>\]-~(\[\],\[" on"\])0 . 306 < C . . . . . . . . . te >, < Abstract>\]-~(\[\],\[" to"l ) 0 . 037\[<Location>,<>\]-"(\[\],\[" to"\])0 . 108\[<Direction>,<>\]~(\[\],\[" to"l ) 0 . 1 08 Figure 5: Result of the Inter-Term Generalization d\] , \[" to"\]):0 . 1 + o . 0 os = 0 . 10s(\[\],\['in"\]):0+0 . 011 = 0 . 011 ( I\],\['~on"\]):0+0 . 006 = 0 . 006 Since(\[\] , \[" to '\]) has the highest import . . . . . . th .   .   .   .   . 
end term is gener Mized into the root node < > , and the generalization stops because there are no nlore parent nndes  . 
Therefore\[<Direction >, <>\]~(\],\[" to'\])0 . 1 08 is the result of first-term nlax inlutn generalization of \[< Direction >  , < Abstract >\] -"(\[\] , \[" to "\]) . 
The result of inter-tcrm generalization for all the 
LTCP is in Fig . 1 is shown in Fig . 5.
3 . 2  , 6 Addition of Translation Rules F in Mly , translation rules ( TR is ) are added to the set of GLTPC , s . TR is a redescriptions in which concepts are specified as the values of variables of L  . of LTPC , s . 
If the same case Mready exists in the set of GLT PC  , , then it is not added . If only the wJue of the ease is different from TRi  , then it is replaced by TR ,  . Ottier-wise , TR , is added with its IC . The ICs for TR is are e~dcnleAed in the same way as for GLTPC  , s . 
4 Best-Matching Algorithm
The Tl'is , the set of GLTPC , s , the TPH is , audtile thesaurus are used in hest matching . The values of vaxi ~ bleu in V . z . reextracted from the input sentence by applying pattern matching according to the description of TPi  . The best-matching process retrieves the most similar case frmn the set of GLTPC  ,  . 
If M '~ = 1 , words which are equivalent 1o the word that is a value of the variable in l ; axe first searched for in the value of the corresponding wriable in L  , of GLTP Co . If none are found , upper concepts retrieved in either TPTHI or the thesaurus are searched in turn  . The GLTPCI which is found first is the shortest -distance GLTPCi  ( SDGLT PCI )  . If C ; in GLTPC i is not null , then it is also evaluated , whether it is true or false . 
AcrEsDECOLlNG-92 , NANTES , 2328^Ot')q1992719PROC . OFCOLING-92, NANTES , AUG .  2328 , 1992 If Mi > 1 , the jth term shortest-distance GLTPC , s(SDGLTPCj ) of each term are searched for . If Mi = 2 , SDGLTPC ~ holds the shortest-distance word or concept in the first term  , and SDGLTPC2 holds the shortest-distance word or concept in the second term  . 
If 2!4 ,  > 1 ,   ( M ~ -1 ) SDLTPCjs are obtaiued for each jth term . A total of Mix(Mi-1) SDL TPCjs are obtained . The SDGLTPCj with the highest importance is selected as the SDGLTPC  . 
We will show an exmnple in retrieving the most similar example for " Getuyou  ( Monday ) ni-Huru ( rain )  . " Suppose the parent node of " Huru " is < Climate  >  . At firs LSD GLT PCI will be searched for iu GLTPC is  ( see Fig .  5) . " Getuyou " does not exist in any first terms in the set of GLTPC~s  . Therfore <* X *> which is the parent node of " Getuyou " is searched for and \[<* X *>  , <>) ~ (\[\] , \[" on'\])0 . 306 is found . T1 .   .   .   .   .   . 
ond term of this GLTPC i is a upper concept of " Huru  , " so this is SDGLT PC1 . Next ,   SDGLTPC2 is searched for and is found to be the same as SDGTPC1  . Consequently , the most similar GLTPC i is \[<* X *> , <>\] ~ (\[\] , \[" on"\])0 . 306, and the word " on " is set as a preposition . 
5 Discussion
In the CBMT approach , the linguistic model , which is a set of translation patterns , is important both for the compaction ratio of a case-base and for similarity metrics  . If the model is not appropriate , most cases remains ungeneralized , and unnatural cases are retrieved as similar eases to the inpnt  . The problems of constructing linguistic models axe the same as in rule-based systems  . 
However , our approach assumes that the linguistic nmdel does not include controls of rules and generalized cases  . Whether or not this assumption is correct , it is very ditfieult to define controls in such a way that any exceptional cases axe encapsulated properly  . Our approach provides a ~ lengineering solution to these difficulties  . 
In our approach , the quality of translations depends on the quantity of cases rather than the quality of the thesaurus  . Therefore , it is important o explore ( semi- ) automatic case acquisition from bilingual corpora . 
To construct a huge case-base is easier than to construct a well-defined thesaurus  , because cases are con-strueted locally without taking account of side-effects  . 
To define an effective thesaurus for translation , every effective category for translation must be included  , and every intermediate category that is effective for translation must be included in order to calculate semantic distances properly  . 
If , on the other hand , thesauri can be developed independently from the case-base  , developers or users can select the most appropriate thesaurus for the domain  ,   6 Concluding Remarks This paper has descrlhed a framework for a machine translation using a mixture of rules and cases generalized by means of a thesaurus  , whict ~ is much smaller than the ease-base itself  . Since the importances of rules and generalized cases are calculated in advance by generalization  , it is not necessary to calculate them during the best-match lng  , which is done by exact matching of words or upper concepts in the thesaurus  . 

I would like to thank Masayuki Morohashi and the members of Japanese Processing Group of Tokyo Research Laboratory  , IBM Japan , for their valuable suggestions and encouragement , and Michael McDonald for his helpful advice on the wording of this paper  . 
References\[1t Nagao , M . , ~ A Framework of a Mechanical Translation between Japanese and EngSsh by Analogy Principle  , " Elithorn , A . and Banerji , R . ( eds . ): Artificial and
Human Intelligence , NATO , 1984.
\[2\] Sadler , V . , " Working with Analogical Semantics : Disambiguation Techniques in DLT  , "FORIS Publications ,  1989 . 
\[3\] Sato , S . , and Nagao , M . , " Toward Memory-based
Translation , " Proc . of Coling'90.
\[4\] Sumita , E . , lida , H . , and Kohyarna , ti , " Translating with Examples : A New Approach to Machine Translation  , " Proe . of the 3rd Int . Conf . on Theoretical and Methodological Issues in Machine Translation of Natural Languages  ,  1990 . 
\[5! Watanabe , H . , ~ A Similarity-Driven Transfer System , "
Proc . of Coling '92.
\[6\] Stanfill , C . and Waltz , D . , " Toward MemoryBased Reasoning , " Comm . of ACM , Vol . 29, No . i2, pp .  1213-1228, 1986 . 
AcrEsDECOLING-92 , NANTES , 2328 hOWl " t992720 PROC . OFCOLING-92, NANTEs , AUG .  2328, 1992
