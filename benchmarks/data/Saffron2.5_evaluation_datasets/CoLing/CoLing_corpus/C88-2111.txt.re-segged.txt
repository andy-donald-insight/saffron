Using a Logic Grammar to Learn
a Lexicon
Manny Rayner , ~sa Hugosson , G6 ran Hagert
Swedish Institute of Computer Science
Box 1263
S-I6428 KISTA

Tel:+46-8-752 1500

It is suggested that the concept of " logic grammar " as relation between a string and a parse tree can be extended by admitting the lexicon as part of the relation  . This makes it possible to give a simple and elegant formulation of the process of infering a lexicon from example sentences in conjunction with a grammar  . Various problems arising from implementation and complexity factors are considered  , and examples are shown to support the claim that the method shows potential as a practical tool for automatic lexicon acquisition  . 
Keywords : Logic programming , Prolog , logic grammar , learning , lexicon . 
Topic Area : Theoretical issues 1 . Introduction The basic idea is as follows : a logic grammar  \[1\] can be viewed as the definition of a relation between a string and a parse tree  . You can run it two ways : finding ' the parse -trees that correspond to a given string  ( parsing )  , or finding the strings that correspond to a given parse tree  ( generating )  . However , if we view the lexicon as part of this relation , we get new possibilities . More specifically , we can compute the lexicons that correspond to a given string  ; this can in a natural way be viewed as a formalization of " lexicon learning from example sentences "  . In terms of the " explanation-based learning " paradigm  , this makes the associated parse tree the " explanation "  ( See diagram 1 )  . 
lexicon learning j ~ ~ , ~y\]~explanationstr'gL grammar ~ ---- parse tree parsing w  4 generating
Diagram If ollowing questions : 1 ) We are learning from positive-only examples ~ What can't be learned like this ?  2  ) The basic structural constraint , the thing that makes it all work , is the assumption that a word can usually only be interpreted as one part of speech  . If we assume that this is always going to be true  , then things really go pretty well ( Section 2) . However , this rule is broken sufficiently often that a realistic system has to able to deal with it  . How ? 3 ) How important is the order in which examples are presented ? Can the system select a good order itself  , if it is important ? 4 ) What kind of complexity features are there ? How scalable is it in terms of number of sentences  , number of gramma rules , number of words to learn ?2 . Learning with the " one entry per word " assumption  . 
This is the simplest variant of the idea : assume that there is one entry per word  , and represent the lexicon as an association-list ( a list ) with one entry for each word . 
Each sentence now constrains the possible values of these entries to be ones  . which allow it to be parsed ; the hope is that a conjunction of a suitably large number of such constraints will be enough to determine the lexicon uniquely  . 
In concrete Prolog programming terms , what this means is the following . In the initial lexicon , the entries are all uninstantiated . We use this to parse the first sentence , which fills in some entries ; the resulting partially instantiated lexicon is sent to the second sentence  , which either refutes it or instantiates it some more  , and the process is repreated until we get to the end  . If at any stage we are unable to parse a sentence  , we just backtrack . If we want to , we can continue even after we've got to the end , to generate all possible lexicons that are consistent with the input sentences and the grammar  ( and in fact we ought to do this , so as to know which words are still ambiguous ) . This procedure can be embodied as a one-page Prolog program  ( see diagram 2 )  , but despite this it is still surprisingly fast on small examples  ( a grammar with 1530 rules ,   1015 sentences with a total of 3040 words to learn )  . We performed some experiments with this kind of setup  , and drew these i conclusions : 1 ) Certain things can't be learned from positive -only examples  . For example ( at least with the grammars we have tried )  , it is impossible to determine whether belongs is a verb which takes a PP complement with preposit ionto  , or is an intransitive verb which just happens to have a PP modifier in all the sentences where it turns up  . However , things of this kind seem fairly rare . 
2) Order is fairly critical . When examples are presented at random , a runtime of about 100 seconds for a 1012 sentence group is typical ; ordering them so that not too many new words are introduced at once drops this to about  5 seconds , a factor of 20 . This gets worse with more sentences , since a lot of work can be done before the system realizes it's got a wrong hypothesis and backtracks\]  . earn(Sents~L):-start lex(SentsvL ) , learn :\[( Sents ~ L) . 
learn 1 ( JILL).
learn I(\[FIR\]~L):-parse(F , L ) r learn \] ( RgL) , parse(gent ~\]- . ):-s(Sent ~\[\] , L ) start lex(Sents ~ L ) :- seto ?(\ [ W , \] vS^(member(SvSents ) , member ( W , S )) , L ) . 
lexlookup ( WordvLex , Class ) : ~" member(\[Word , Class \] , Lex ) . 
% Example grammar : s(L)---~>np(L ), vp(L).
np(L )....> det(L ), noun(L).
vp(L )....> iv(L).
vp(L)-.->tv(L ), np(L).
det(L ).~->\[ D\], lexlookup(D,Lr det).
noun(L)-->\[N\], lexlookup(N , Lr noun).
iv(L ) ~ . ->\[ V\]r lex . lookup(V , L , iv) . 
tv(L ) ~->\[ V\], lexlookup(V,L,tv).
Diagram 23 ) A mo ~: e important complexity point : structural ambiguities needn't be lexical ambiguities  ; in other wo ~' ds , it is quite possible to parse a sentence in two distinct ways which still both demand the same lexical entries  ( in practice , the most common case by far is NP/VP~l' . : tachment ambiguity ) . Every such ambiguity introduce : ; a spurious duplication of the lexicon , and since these . , , multiply we get an exponential dependency on the number of sentences  . We could conceivably have tried to construct a grammar which doesn't produce this kind of ambiguity  ( cf . \[2\], pp .  6471) , but instead were organized the algorithm so as to collect aftex ' each step the set of all possible lexicons compatible with the input so far  . Duplicates are then eliminated from this , and the result is passed to the next step . 
Although the resulting program is actually considerably xnore expensive for small examples  , it wins in the long run . Moreover , it seems the right method to build on when we relax the " one entry per word " assumption  . 
3? ~ . emov;\[ng the " one curry per word " assumption . 
We doxft actually remove the assumption totally , but just weaken it ; for each new . sentence , we now assume that , of tlle words already possessed of one or more entries  , a ' ~ most one may have an unknown alternate . 
.Multiple entries are sufficiently rare to make this reasonable  .   9o we extend the methods from the end of section 2  ; first we try and parse the current sentence by h ~kingup known entries and filling in entries fox " words we so fark now nothing about  . If we don't get a ~ y result this way , we try again , this time with the added possibility of once assuming that a word which already has known entries in fact has one more  . 
Tidsist ~ sually OK , but sometimes produces strangei'esults , as witness the following example . Suppose the first three sentences are John drives a car  , John drives well , and Johndrives . Aftex ' the first sentence , the system gaesses that drives is a transitive verb  , and it is able to maintain this belief after the second sentence if it also assumes that well is a pronoun  . However , the third sentence forces it to realize that drives can also be an intransitive verb  . Later on , it will presumably meet a sentence which forces well to be an adverb  ; we now have an anomalous lexicon where well has an extra entry  ( as pronoun )  , which is not actually used to explain anything any longer  . To correct situations like this one , a two-pass method is necessary ; we parse through all the sentences a second time with the final lexicon  , keeping count of which entries are actually used . If we find some way of going through the whole lot without using some entry  , it can be discarded . 
4. Ordering the sentences
As remarked above , order is a critical factor ; if words are introduced too quickly , so that the system has no d~ance to disambiguate them before moving onto new ones  , then the number of alternate lexicons grows exponentially  . Some way of ordering the sentences automatically is essential  . 
( ) urinitial effort in this direction is very simple  , but still seems reasonably efficient ; sentences are pre-ordered so as to minimize the number of new words introduced at each stage  . So the first sentence is the one that contains the smallest number of distinct words  , the second is the one which the smallest number of words not present in the first one  , and so on . 
We have experimented with this approach , using groups of between 20 and 40 sentences and a grammar containing about 40 rules . If the sentences are randomly ordered , the number of alternate lexicons typically grows to over  400 within the first 6 to 10 sentences ; this slows things down to the point where further progress is in practice impossible  . 
Using the above strategy , we get a fairly dramatic improvement ; the number of alternates remains small , reaching peak values of about 30 . This is sufficient obeable to process the groups with insensible times  ( less than 15 seconds per sentence average )  . In the next two sections , we discuss the limitations of this method and suggest some more sophisticated alternatives  . 
5. Increasing efficiency
It is rather too early to say how feasible the methods described here can be in the long term  . As far as we can see , scalability is good as far as grammar . ~ size is concerned ; we have increased the number of rules from 15 in the first version to about 40 in the current one with little performance degradation  . Scalability with respect to number of sentences is more difficult to estimate  . Using the methods described in sections 3 and 4 , we have sucessfully processed groups of up to 50 sentences ( about equally many words )  , with runtimes typically in the region of 1015 minutes . An example is shown in the appendix . It is reasonable to suppose that the system as it stands would be capable of dealing with groups up to four or five times this size  ( i . e . 200250 words to learn ) , but it has a limit ; the problem is that there are always going to be a few words in any given corpus which occur insufficiently often for their lexical class to be determinable  . Although these words are typically fairly rare , the ambiguities they introduce multiply in the usual way  , leading to an eventual represent some approaches to this problem which we are currently investigating  . 
What appears to be necessary is to find some intelligent way of utilising the fact that the various alternate lexicons all agree on the majority of entries  ; typically , less than 10% are ambiguous after any given step in the processing  . The current system completely ignores this , representing each lexicon as a separatentity . If we are to improve this state of affairs , we can envisage two possible plans . Firstly , we could simply remove the " difficult " words , hoping that there are sufficiently few for this not to matter  . More ambitiously , we can try to share structure between lexicons , so that the common part is not duplicated . We now expand on these two ideas in more detail . 
5.1. Removing " difficult " entries
At regular intervals the group of alternate lexicons is analyzed : the normal state of affairs is that they are identical excepting the entries for a few words  , the potential " trouble makers " . What one could do would be simply to remove these entries  , making them once again uninstantiated ; then all sentences containing the offending words would be removed from the subgroup marked as already having been processed  , and saved for possible future use . The overall effect would be to reduce the group of alternate lexicons to a single " lowest common denominator "  , which ~ would represent the " reliable " informations of aracquired  , this at the expense of losing some partial information on the " dubious " words  . 
We have carried out a few simple experiements along these lines  , using a variant of the , dea which at each " checkpoint " removes all ambigous words for which there are no further sentences a waiting processing  . This seems at first sight very reasonable , but unfortunately it turns out that there are problems  . Although one might easi Iy think that an ambiguous word is going to stay ambiguous if it doesn't occur in any of the remaining sentences  , in actual fact this is not so ; a word can be disambiguated " indirectly " , as a result of other words being disambiguated . To give a simple example : suppose that the first sentence is The zebral aughed  . 
This can give rise to a number of possibilities : for example  , the and laughed could be pronouns , and zebra at ransitive verb . If the word zebrad idn't occur again , one would thus wrongly conclude that there was no way of determining whether it was a common oun or a transitive verb  . But this can easily be accomplished if the or laughed are later assigned to their proper classes  , which will then remove the incorrect interpretation and indirectly make zebra unambiguous too  . Clearly , a more sophisticated implementation is required if this idea is going to work  . 
5 . 2 . " Lexicon compaction " using Prolog constraints Here  , we discuss the idea of exploiting the similarity between different alternate lexicons to " merge " or " compact " them  . The technical tool we will be using to perform this operation is the Prolog " constraint " mechanism  \[3\]  ,  \[4\] . What we propose is illustrated in diagram 3 , which shows two alternate lexicons , differing in a single entry . These can be combined into the third lexicon without any loss of information  . 

Simple compaction of two lexicons
Two alternate lexicons for the sentence : the dog belongs to theman\[\[the:d\]  , \[ dog:n\] , \[ belongs : v(intrans)\] , \[to:prep\] , \[man:n\]\]\[\[ the:d\] , \[ dog:n\] , \[ belongs : v(prep(to ))\] , \[to:prep\] , \[man:n\]\] These can be compacted into the following single lexicon\[\[the:d\]  , \[ dog:n\] , \[ belongs : < X : X = v(prep(to) ; X = v ( intrans ) > \] , \[to:prep\] , \[man:n\]l
Diagram 3
The technique is potentially very powerful , and infavourable circumstances can be used to compact together large numbers of alternates  , as diagram 4 illustrates . 
Compacting four lexicons into one in a twostage process  . 
lexl :\[ .   .   . \[ belongs : v(intrans)\], .   .   . 
\[ plays:v(intrans)\], .   .   . \] lex2:\[ .   . . \ [ be longs : v ( p rep ( to ) )\] r ? ? . 
\[ plays:v(intrans)\], .   .   . \] lex3:\[? . . \ [ be longs : v ( in t rans ) \]~ . . . 
\[ plays:v(prep(with ))\], .   .   . \] lex4:\[ .   .   . \[ belongs : v(prep(to ))\], . . . 
\[ plays:v(prep(with ))\], .   .   . \] In the first stage , we compact lexl and lex2 to make lex12 , and lex3 and lex4 to make lex 34 . 
lex 12:\[ .   .   . \[ belongs : < X : X = v(prep(to) ; X = v ( intrans ) > \] ,   . . . 
\[ plays:v(intrans)\], .   .   . \] lex34:\[ .   .   . \[ belongs : < X : X = v(prep(to) ; X = v ( intrans ) > \] ,   .   .   . 
\[ plays:v(prep(with ))\], .   .   . \] Then we compact lex12 and lex34 to get the final result . 
\[  .   .   . \[ belongs : < X : X = v(prep(to) ; X = v ( intrans ) > \] ,   . . . 
\[ plays : < Y : Y = v(prep(with) ; Y = v ( intrans ) > \] ,  ?  . .\]
Diagram 4
What makes the " compaction " method so attractive is that it appears to get the best of both worlds : no information is lost  , but substantial efficency gains can be attained . The method raws its power from the fact that it is " intelligent " about divergences between lexicons : if the sentence to be parsed contains none of the " constrained " words  , then the compacted lexicon will behave as though it were a single  , unambiguous , lexicon ; but if " constrained " words are present , then the lexicon will be " split " again , to exactly the extent required by the various parsings of the sentence  . It is to be noted that all this of course requires a Prolog constraint mechanism which is both efficient and logically complete  , something that has only recently becossible \[4\]  . We are currently in the process of in ~ plementing the method within our system  . 
6 o Conclusio as and further directions
We have described a series of experiments which investigate the feasibility of automatically infering a lexicon fror a a logic grammar and a set of example sentences  ; this stands in fairly sharp contrastomost work done so far within the field of automatic language acquisition  , where the emphasis has been either on grammar induction e  . g .  \[51 ,  \[6\] ,  \[7\] , or learning of word senses \[8\]: I a view of the fact that much recent linguistic research has been moving towards unification -based formalisms where the bulk of the information is stored in the lexicon  , we think that ideas like the ones we propound here should have a rich field of application  . 
For example , Pollard and Sag's HPSG framework \[9\] has at only a couple of dozen grammatical rules , all of which are extremely general ; the rest of the information is lexical in nature . 
Although we think that progress to date has been extremely encouraging  , it is still a little too early to make any firm claim that our methods are going to be usable in a practical system  . As discussed above , there are some nontrivial efficiency problems to be overco-ae : it also seems likely that we will need a more sophisticated ordering algorithm than that described in section  4  , probably incorporating some notion of giving higher priority to sentences containing ambiguous words  . Other importan topics which we so far have not had time to devote attention to are the use of morphological information and the development of some way of handling incorrect sentences  ( may be just ignoring them is enough ; but our feeling is that things will be a little trickier  )  . These and other related questions will , we hope , provide fruitful ground for continued research in this area  , 
References\[1\]F . C . N . Pereira , Logic for Natural Language Analysis
SRI Technical Note 275, 1983\[2\]F . C . N . Pereira & D . H . D . Warren , Definite Clause Gramn , ars Compared with Augmented Transition Networks , Research Report , Dept . of AI , Edinburgh University 1978 ( also in Artificial Intelligence , 1980) 113\]A . Colmerauer , Prolog-II , Manuel de reference t model theorique , Grouped ' Intelligence Artificielle , 
Universite Aix-Marseille , 1982\[4\]M . Carlsson , An Implementation of " dif " and " freeze " in the WAM  , SICS Research Report , 1986\[5\] S . F . Pilato & R . Berwick Reversible Automata and Induction of the English Auxiliary System  , Proc . 
23rd ACL , Chicago , 1985\[6\] R . M . Wharton , Grammar Enumeration and Inference , Information and Control , Vol 33 ,  253~272 , Based on General Learning Principles , Proc . 7th
IJCAI , Vancouver , 1981\[8\] R . C . Berwick , Learning Word Meanings From
Examples IJCAI 1983\[9\] C . Pollard & I . Sag Information-Based Syntax and
Semantics , Vol . 1, CSLI 1987
We enclose two appendices . The first shows some sample runs ; the second , the grammar used in the examples . 
Appendix 1
SICStus V 0.5-July 31, 1987
Copyright(C ) 1987,
Swedish Institute of Computer Science.
All rights reserved.
I ? ~-\[' start.pl'\].
\[ consulting/khons/asa/learning/start . pl .   . \]\[ compiling/khons/asa/learning /xg proc  . pl .   .   . \]\[ x g proccompiled in 14480 msec . \]\[ consulting / khons/asa/learning / xgrun  . pl .   .   . \]\[ x grun reconsulted in 159 msec . \]\[ consulting/khons/asa/learning/ut ilities  . pl . \]\[ utilities . plreconsulted in 1360 msec . \]\[ compiling/khons/asa/learning/prettyprint . pl . \]\[ prettyprint . pl compiled in 4680 msec . \]\[ consulting/khons/asa/learning/top . pl . . . \]\ [ top . plreconsulted in 5920 msec . \]\[ consulting/khons/asa/learning/sent . pl . .  . \]\[ sent . plreconsulted in 2340 msec . \]** Grammar from file grammar . pl : 0 words **\[ consulting/khons/asa/learning/read -file  . pl . l\[read-file . plreconsulted in 1420 msec . \]\[ start . ple on sulted in 32 100 msec . \] %  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
% A simple test with six sentences.

yes1?-test qroup (5).
Order before sorting : \[1 , 26 , 2 , 3 , 4 , 5\] Order after sorting : \[1 , 2 , 26 , 3 , 4 , 5\] %  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
% The format of each line is : % Sentence number ( in test sentence )  , % sentence , number of lexicons left . 

i . the cat saw the dog 82 . the dogs awacat 226 . that mans aw the dog 33 . a mansaw the nice dog 24 . the nice dog likes the man 25 . the man likes the dog that the cat saw 1 Runtime = 13420  . Compiling statistics . . . 

% The system asks the user which of the % al ternate lexicons is the correct one  . 
% Here there is only one possibility left.

a : detcat:noun ( _48268 ) dog : noun ( 48270 ) likes : verb ( trans ) man:noun ( _48273 ) nice : adj saw : verb ( trans ) that : detrel prothe : det
Is this correct ? yes.
No mistakes yes % .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
% A rather more complicated example.


I?-test_grouP (0) "
Order before sorting : \[ i , 2  , 3  , 4  , 5  , 6  , 7  , 8  , 9  , 10  , 11  , 12  , 13  , 14  , 15  , 16e17 , 18  , 19  , 20  , 21  , 22  , 23  , 24  , 25  , 26  , 27  , 28  , 29  ,  30  , 31  , 32  , 33  , 34  , 35  , 36  , 37  , 38  , 39  , 40  , 41  , 42  , 43 \ ]
Order after sorting : \[1 , 2  , 3  , 4  , 5  , 26  , 27  , 13  , 14  , 6  , 15  , 39  , 11  , 9  , 19  , 18  ,  21  , 20  , 10  , 12  , 17  , 7  , 23  , 33  , 16  , 8  , 22  , 28  , 29  , 30  ,  31  , 32  , 25  , 24  , 35  , 38  , 34  , 36  , 37  , 40  , 41  , 42  , 43 \ ]
I . the cat saw the dog 82 . the dogs awacat 23 . a mansaw the nice dog 24 . the nice dog likes the man 25 . the man likes the dog that the cat saw 126 . that mansaw the dog 127 . the man has a cat 113 . the dog belongs to the man 414 . the doglikes most men 86 . most men like the dog 415 . the men like john 439 . them an hoped that john likes the dog 24 ii . the doghoped that them an read the newspaper 16   9  . them an read the newspaper 1619 . john has read the newspaper today 1618 . john read the newspaper today 1621 . them an read the newspaper before john saw the cat  16   20  . john has not read the newspaper 1610 . the dog brought them an the newspaper 1612 . john threw the newspaper to the dog 1217 . john threw the newspaper on the table 127 . the dogsaton the table 2023 . the catsaton the car 2033 . johns a wag lass on the table 1616 . the dogs at with john 88 . the table belongs to the man who owns the dogB 22  . the man who owns the cat drives the car 828 . the man who has a cat has no dog 829 . the cat atea fish 8~30 . johnate the beans 831 . the manate a can of beans 1632 . the man brought the cat a can of cat food 1625 . the man candrive the car 7224 . the dog cannot drive the car 1635 . them and rank the whisky 1638 . john hoped the dog drank the water 434 . john drank a glass of water236 . john poured the water on the cat 237 . john poured a can of water on the cat 240 . mary knows that john owns a dog 241 ; john believes that mary drives a car 242 . mary believes John knows that peter has a eat 4   43  . peter cannot believe that mary ate the fish 2 Runtime = 949120  . Compiling statistics ~ .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  ~  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
% This is the first lexicon of two . The % divergences are summarized by the system % further down  . Note that " can " and " has "% are correctely assigned to two different % classes  , and " that " to three . 

% Nouns can be classified as either % " count " or " measure "  . Most of them % could be either , but nouns occuring % in partative construct ions  ( " can of % cat food " , " glass of whisky " ) are % forced to be " measure " . 

e : detate f verb ( trans ) beans : noun ( measure ) before:sub_conJ believe:verb ( s_comp ) believes : verb ( scomp ) belongs : verb ( in trans ) can:noun ( 342148 ) verb ( aux ) car : noun ( 342150 ) cat : noun ( 342152 ) cat food : noun ( measure ) dog : noun ( 342155 ) drank : verb ( trans ) drive:verb ( trans ) drives : Verb ( trans ) fish:noun ( 342160 ) glass : noun ( 342162 ) has : verb ( trans ) verb ( aux ) hoped : verb ( scomp ) john : name knows : verb ( s_comp ) like : verb ( trans ) likes : verb ( trans ) man:noun ( 342170 ) mary:namemen:noun ( 342173 ) most : detnews paper : noun ( _342176 ) nice:adjno:detnot:negator of : part at ive marker on : prepowns : verb  ( trans ) peter : name poured : verb ( trans ) read : verb ( trans ) sat:verb ( in trans ) saw : verb ( trans ) table:noun ( 342189 ) that : rel prodet comp the:detthrew:verb ( trans ) to : prep today : advwater:noun ( measure ) whisky : noun ( 342197 ) who : tel prowith : prep
Is this correct ? yes.
belongs : 1 mistakes \ [ verb ( pobj ( \[ to ~45\] )   ) \] yes
J?-halt.
user time 983.60 0000
Appendix 2 % Here is the grammar to the learning system~s v -> np rv p  . 
np-->det,npl(_).
. np--> name.
npl(Type)-->adJs,n(Type ), optional_lop , tel . 
adjs --> .\[\].
adjs --> adJ , adJs.
vp-->v(Verb ) , lex ( V erb , verb ( V type)) , v_comps(V type) , vmods . 
vcomps ( intrans)-->\[\].
v_comps(trans)-->np.
v_comps ( doubly trans)--> np , np.
v_comps(pobj(Prep )) --> pp(Prep).
v_comps(s_cOmp ) --> comp , s.
v_comps(scomp)-->s.
vmods --> pp ( Prep).
v ~ mods --> adv.
vmods --> sc.
v-mods -->\[\].
sc --> subconJ , s.
optional _ p p ~-> p p(_).
optional pp --> partative marker , npl ( measure ) ? optional_iop-->\[\]?pp ( Prep ) -->\[ Prep\] , lex ( Prep , prep ) , np . 
rel~->\[\].
tel-->relpro,s.
det-->\[Word\],lex(Word , det).
adv-->\[Word\],lex(Word , adv).
adj-~->\[Word\],lex(Word,adj).
sub_conj-->\[Word\],lex(Word,subconj).
n(Type)-->\[Word\],lex(Word,noun(Type)) . 
name-->\[Word\],lex(Word,name).
oomp-->\[Word\],lex(Word,comp).
partative_marker -->\[ Word\] , lex(Word , partative_marker ) . 
telloro . . . np-->\[Word\],lex(Word,rel_pro) . 
v(Verb ) -->\[ Verb\] , lex ( V erb , verb ()) . 
v(Verb ) --> aux , \[ Verb\] , lex ( V erb , verb ()) . 
aux-->\[Verb\],lex(V erb , verb(aux)).
aux -->\ [ V erb , Negator \] , lex ( V erb , verb ( aux )) , lex(Negator , negator ) . 

