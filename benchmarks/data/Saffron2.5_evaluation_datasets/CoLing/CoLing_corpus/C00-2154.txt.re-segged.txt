WebDIPLOMAT : A Web-Based Interactive Machine Translation 

Christol)her Hogan and Robert Frederking
I , anguag c Techliologies \] institute
Pittsburgh , \] ~ ennsylva.nia , USA
chogan ~ e-l?ngo , cm , ref@cs , cmu.edu
Abstract
We have implenlented a . n interactive , Wel)-based , chat-style machine translation system , SUpl ) ort ; ing speech recognition and synthesis , local-or third-party correction of speech recognition and machine tra  . nslation output , a . nd online learning . The underlying client-server architecture , implemented in . la . vaTM , pl : ovides remote , distributed computation for the translation and speech sut  ) systems . We further describe our Web-based user interthces  , wh Mi can easily produce different us cflfl e on figll rartions  . 
1. Introduction
The World Wide Web ( Berners-l , e e ,  11989 ) seems to be all ideal environment for machine translation : it is easily accessible around the world using freely-available  , easy-to-use tools which are ava . ilable to persons speaking a . nlyria d of langua . ges , all of whom would like to I ) eable to communicate with one another without language barriers  . Il L . is therefore not too surl ) rising that a few companies have attempted to make machine translation available in this medium  ( Alta Vista , 1999; Free Translation ,  1 . q99; hlt . erTran , 1999) .  ' . l'hel ) riinary use identified for these tra . nslators has been that of translating Web pages or amusing oneself with the inadequa  . -cies of ma . d fine translation ( Yang and l , ange , 1998) . 
What these systems cannot be used for is realtime , speech-to-speech ommunication with translation . 
leal-time communication over the hiternet has more properly been the  ( lomain of ' < chat"l ) roto-eels : primarily Interact Relay Chat ( 11 ( 3 )   ( Oikari-nen and Reed ,  1993) , and similar instant messaging protocols developed commercially  ( America Online Inc . , 2000; Microsoft Corp . , 2000; ICQ Inc . , 1999) . 
While some portals have been developed to permit access to chat using the Web  ( iTRiBE lnc . , 1996) , the primary point of accesseems to be chat -specific client software  . Although chat defines protocols and provides infrastructure  , it is limited ill the kind of data that it can transl  ) or t , and client software is tightly focussed oil the text domain  . Such limitations have not , however , prevented researchers fi'o mexl ) erilnenting with the possibilities of incorporating machine translation or speech into tile chat experience  ( 1 , enzo , 1998; Seligma . net al , 1998) . The outcome of these experiments has been to show that comn-mrcial machine translation systems may  1  ) ereasonably integrated into the chatroom , and that commercial speech software ca . n be connected to existing chat software to provide the desired experience  . 
We have taken a difl~rentroad . It has been noted ( Seligman , 19 . ( . ) 7; l " rederking et al ,  2000 ) that broadcoverage machine translation and speech recognition cannot now be usefldm dessusers can interact with the system to improve results  . While Seligman et al .   ( 1998 ) were able toet Dct user editing of speech recognition by editing text before submitting it for translation  , they were unable to do the same fortile translation system  , prilnarily due to limitations of commercial software  . Additional imitations are encountered in the communication medium : chat is not amenable to non-text interaction with translation agents  , and commercial chats of tw are does not , in any case , support such interaction . 
To deal with these limitations , we have developed a fully interactive , Web-based , chat-style tra . nslation system , supportings l ) eech recognition and synthesis , local-or third-1 ) arty correction of speech reeognitioi , and machine translation , and online learning , which ca . n be used with nothing lllore than a Well browser and some simple add-ons  . All intensive processing , including translation and speech recognition is performed a  . t central servers , permitting access for those with limited computational resources  . In a . d dition , tile modular design of t . he system and interface permit computa . tional tasks to be easily distributed and different dialog configurations to be explored  . 
2 Interface Design
The design of the Webl ) IPLOMAT system is intended to facilitate the following kind of interaction :  ( numbers correspond to Figure 1 )  1 . Speechfl'om the user is recognized and displayed in an editing window  , where it may be edited by respeaking or using the keyboard  . 
2 . When text is acceptable to the user , it is submitted tbr translation and transfer to the other  . . . . . . . . I ' -- - v ) Figure 1: User-level perspective on information flow . 
See text for explanation of labels.

3 . Text to be translated is optionally presented to a human expert  , who is able to translate , correct and teach the system a correct translation  . 
4 . Upon machine translation of tlLe text , or acceptance by the expert , a translation is delivered to the other pa . rty and synthesized . 
5 . 13 oth sides of the conversation are tracked a . u-tomatically for all users , and displayed on their interfaces . 
Although the above is the original vision fortihe system  , other configurations are easily imagined . 
Configurations with more than two participants , or where one of the users is also simultaneously all expert a restra  . ig htforwardly handled . International-ization of the interfaces , for use in different locales , is also easily handled . Many changes of this nature are handled by easy modifications to the HTMI  , code for given \? ebpages . More COml ) licated tasks may be accomplished by modifications of underlying code  . 
In order to produce the above configuration , the current system implements two user interthces  ( UIs ) : the Client UI , which provide speech and text input capabilities to the primary end-users of the system  ; and the Editor UI , which provides translation editing capabilities to a human translation expert  , in the rest of this section , we describe in detail certain unique aspects of each interface  . 
2.1 Client User Interface
In addition to speech-input and editing capabilities  , the Client UI is able to track the entire dialog as it progresses  . Because the Central Communications Server (@ ~ a . l ) forwards every message to all connected clients , every component of the system can be aware of how the dialog turn is proceeding  . Illtile Client UI , this capability is used to l ) rovide a running transcript of the conversation as it occurs  . By noting the identifiers on messages ( cf .  ~,3 . 4) , the U1 can assign appropriate labels to each of the following : our original utterance  , translation of our utterance , other person's utterance , translation of their utterance . In ~ d dition , we use knowledge about the status of the dialog to prevent the user from sending several utterances belbre the other party has responded  . 
2.2 Editor User Interface
The F , ditor UI provides tools which make it possible for a human expert to edit translations produced by the machine translator betbre they are sent to the users  . As mentioned earlier , the editing step is optional , and is intended to improve the quality of transla . tions . The Editor UI may be configured so that either of the two users  , or a remote third party can act as editor . On rmotivations for providing an editing capability are twofold : ? Although our MT system  ( @ ~3 . 2) dots not always produce the correct answer , the correct answer is usually available a . mong the possibilities it . considers . 
t . alQ ? , H~MT system provides for online updates of its knowledge base which a  . llows tbr translations to improve over time . 
In order to take advantage of ' these capabilities  , we have designed two editing tools , the chart editor and a . lways-active larning , that enable a human expert to rapidly produce an accurate tlJaills latiol laud to store tha  . t translation in the MT knowledge base for future use  . 
As discussed in ~ a . 2, our MT systemma . y produce more than one translation for each part of tile input  , from which it attempts to se\]ect the best translation  . 
The entire set of translations i available to the Web-I  ) IPLOMAT system , and ix used in the cha . rteditor . 
By double-clicking on words in the translation , the
Original English
My name is John . . . . . .
Edited Frenclllinennoraest Jehn
Figure 2: Popup Chart Editortiretra . nslations beginning a . t a particular location in the sentence ( seel ? igure 2 )  . When one o\[' the alternative sissek ; cted , it replaces the original word or words . In this way , a . sentence may be rapidly edited to an acceptable sta  . te . 
In order to reduce develol mmnt\]line , our MT system can be used in ara . pid-del ) loylnent style : afl ; era . 
minimal knowledge base is constructed , the system is put into use with a huma . n expert supervising , so that domain-rel(:va . nt datama . y be elicited ( lui(:ldy . 
In order to supl ) or t this , all uttera . nces a . reconsidered for learning . When the editor presses the ' Ac-c citt/Learn'l ) utton , the original utterance and its tra . nslatiot lare exa . ntined to determine if they are suital ) le for learning .   ( Turrently all utterances for which the forward tra  . nslation has 1teen edited are subrat\]ted\['or learning , a . l though other criteria ma . y also be entertained . More detail about online lea . r > ing may 1) e found ill ~3 . 2 . 
Although the editor UI is primarily i \] lte\]l ( ledt bruse by a . tra . nslation expert , it , will sometimes also 1) eu , qed 1) ytl lose who are not as expert . For this situa-ti : ) n , we ha . reintroduce ditlta('ktra . lisla . l . ion capal Jil-ity which retra . nsla . to sthe edited forward trai/sla . tioll into the language of the input . Althoughi , ~ iperl'ect , baek translatio \] l can often give the user an idea of whether the forward transla  . tion was suits \] ant \] ally(:O\]:l:eot, . 
3 System_Design h , this section , we describe 1 . hee Oml ) ut a , l , io \] alarchi-t () etur ("\ [ lll derly in , ,g the W(;b I ) 11) I , OMA'I'sys , elll . 
3.1. Ar (: hite('t ; m'(~.
The underlyil\]garel\]itecture of the\?obl)II)I , OMAT ' system is shown in Figure 3 . The system is organized arotllld three servel : s : The We  . ItServ <' . rservesI1T\]Vll,l ) ages to <: lients . 
We used an unmodified version of th < ; Apachell'l " l'l ) Server ( Apache Softwa . rel:oundation , 1999) . 
Tim SI ) eech Recogniz ( : r ( s ) l ) erform speech recognition for clients . 
The Central Commmfications Server allows comrmmica  . tion between clients , l , hicapsulate doh . jeers sent to this server are forwarded to all connected clients  . With the exception of speech and HTTP , all communications between clients use this server  . 
The servers are designed to be small , and a . rein~tended to coexist on one lnachine . 1 Currently , however , the speech server in chides a full speech recog-l This is necessary due to security restrictions on  . \] ~ t wt'I'M

nizer , a . nd therefore consunies a greater amount o1' resources than the other servers . 
Most processing is intended Cobe perforumd by clients  , which haw ~' no loca . lity requirements , and may therefore I ) e distributed across nm . chi\]les and networks as necessary . The User and Editor Clients were described in i?2  . 1 and 2 . 2 . We will now examine the most important l ~ rocessing mechanisms  , ilmluding machine translation and speech recogni -tion/synthesis  . 
3 . 2 Machine Translation l " or Machine Transla . tion , we rely on the l ) anliteMdti-lgl\]gine Machine Translation ( MEMT ) Server ( l : rederking a . ndlh:own , 1996) . This system , which is outlined in Figure 4 , makes use of several translation engines at once , combining their output with a . sta . tistica \] language model ( Brown and l : rederk-ing ,  1995) . Each trai is la . tion engine makes use of a dill'erett transla . tion technok ) gy , and produ(:es multi-t ) 1% possibly overlal ) ping , l . ra\]mlations for every part of t it ( ; in l ) ut that it can translate . All of the translations I ) roduced 1 ) 3: the various engines a , repla . ced in a chart data struci ; ure ( Kay , 1967; Winograd ,  1983) , indexed by the ' Jr position i \]\] the input utter -a  . nce . A statistical huiguage model is used , together with scores provided I ) y the tra . nslation engines , to determine the optima . l path through the set of translated segments , which in form a , tion is also stored i \]\] the chart . Upon completion of tra . nslation , the chart data structre is made a . vailable For use by the resto\[7 the WeM)II)I , OMA : I'system . 
(;urrently , ween q ) loyl , exica.l Transfer and Ex-
Source Target
Language Language
Morphological I Analyzeri ~\[ User Interthce-i ~ ii ' ransfer-Based MT-i ~ Example-Based MT Statistical Modeller 
Knowledge-Based MT
Expansion slot
Figured : Multi-Engine Machine3h : ansla . tion Architecture


Interface i Speech Synthesizer ' , Central Web'Recognizer ( s ) Serveri Interface Server . . . . . i-'"3"r ": q~'-'7"~"~i'--\]';77~'-'--" .   .   .   .  "  . . . . . . . . . . . . . . . . . . . . . . "':':' i ; :":\]:):'):'ii"':":":':i:i::" ; ":':\]'17' ii'i . . . . . . . . . . . Ill\[el'net . , . '" /  . . . . . . ",,  . . . . . . . . . . . . . . . .  . . . . . "  .   .   .   .   .   .   . , . 

Speech Userl Speech Speech User2 Speech/Plugin Client Synth . Plugin Client Synth . Editor Client1/Editor Client2
Figure 3: Serverample Based Machine Translation ( EBMT ) engines ( Na . gao , 1984; Brown , 1996) . Lexical Transfer uses bilingual dictionaries and phrasal glossaries to provide phrase-for-phrase translations  , while EBMT uses a fllzzy matching step to produce translations froln a bilingual corpus of matched sentence pairs  . 
Because the knowledge bases for these techniques are simple  , they both suI ) port online augmentation . As mentioned in ?2 . 2 , the Editor UI attempts to learn from utterances that have been edited  . Pairs of utterance submitted for learning to the translator are placed in a Lexical Transfer glossary if less than six words long  , and in an EBMT corpus if two words or longer . Higher scores are given to these newly created resources  , so that they are preferred . 
The MT server is interfa . ced to the Central Server through MT interfa . ceclients , which handle , inter alia , character set conversions , support for learning and conversion of MT output into an internal object representation usable by other clients  . It also ensures that outgoing translations are staml  ) ed with correct identifiers ( cf .  ~3 . 4) , relative to the incoming text , to ensure that translations are directed to the appropriate clients  . 
a . a Speech Recognition and Synthesis
In the current system , speech recognition is handled as a private communication between a browser plugin  , running on the user's machine , and a speech recognition server , and is not routed through the central server . Speech is streamed over the network to the server  , which performs the recognition , and returns the results as a text string . This configuration permits most of the computational resources to be offloaded from the client machine on topowerful remote servers  . The speech may be streamed over the network as - is  , or it may be lightly preprocessed into a feature stream for use over lower-bandwidth connections  . The recognized text is returned di-
Architecture rectly to tile user client for editing and validation by the user belb reheing sent for translation  . Our speech server is a previously implemented esign  ( Issar ,  1997 ) based on the Sphinx II speech recognizer ( Huang et al . , 1992) . As mentioned earlier , the speech server and recognizer are not currently designed to run in a distributed fashion  . 
Unlike speech recognition , which is handled by the User Client , speech synthesis does not require human interaction  , and can therefore be connected directly to the central server  . Currently , Synthe-sizer Interfaces unpackage internal representations and send utterances to be synthesized on a speech synthesizer unning locally on the user's machine  . 
Future plans call for speech to be synthesized at a centralocation and transported across the net  . work in standard and io formats . 
3.4 Implementation
All components of the Webl ) IPLOMA'\]'except the speech components and Web Server were implemented in JavaTM  ( Gosling et el . , 1996), in clnding the Central Server . Messages between clients are implemented as a Java class Capsule  , containing a String identifier and any number of data  . Objects . 
Object serialization permits simple implementation of message streams  . User Interface clients are developed as Applets , which are embedded in HTML pages served by the Web Server  . 
4 Future Work and Conclusion
The most significant change we would like to make to the current system is the way that speech is handled  . We firmly believe that the best speech input device is the one people are already familiar with  , namely the telephone . A revised system would allow users to call specific phone numbers  ( connected to the central server ) in order to access the system , which would then recognize and synthesize speech terfaces  . This , of CO tlrse , takes us closer to the grand AIChallenge of the translating telephone  ( OAIAE , 1996; Kurzweil , 1999; Frederking et al ,  1999) . We contend that by using interactive machine translation  , the goal of a broad-domain translating telephone Call be more easily brought of ruition  . 

Alta Vista .  1999 . Babel Fish : ASYSTIAN translation system , http://babelfish . altavista . com/ . 
America Ojflit \ eInc .  2000 . AOI , Instant Messengert Sm) . http://www . aol . com/aim/home . 

The Apache Software Foundation .  1999 . The Apache H'I'TI ) Server Project . http://www . 

Tim Berners-l , ee .  1989 . Informa . tion management : A proposal , http://www . w3 . org/History / 1989/proposal . html , March . CI !; RN . 
l~ . alf Brown and Robert Frederking .  1995 . Applying statistical English language modeling to symholic machine translation  . \] n Proceedings of the , 5'ixlh International Uo~dbrence on 7'heorctical and Methodological Issues in Machine Trcms lation ( TMI-95 )  , pages 221-239 . 
Ralf Brown .  1996 . Example-based in a chine translation in the Panglos system  . In Proccedirtg . s of the l ( ith International Co ~@ rencco1 ~ Computational
Lingttistics ( COIJNG-96).
Robertl , ' rcderking and lalfIh'own .  1996 . The Pangloss-lAte machine translation system . In Proceedings of the Col~ference of the Association for Machine  7  ) ' anslation in the Americas ( AMTA )  . 
Robert Frederking , Christol ) hel:logan , and Alexanderludnicky .  1999 . A new approach to the translating telephone . Inl ) wcc  cdiltfls of the Mac\ira : 7 ) ' anslalion 5' ummit VII : 1147'i ~ ti , hcG'tvat7)' ans-lationI';ra , Singapore , September . 
lb ) bertFrederking , Alexander Rudnicky , Christopher Hogan , and Kevin Lenzo .  2000 . Interactive speech translation i the DIPLOMAT project  . MT
Journal . To appear.
l " ree'lS : anslation .  1999 . Free'l'rm Mation : A Transparent l , anguage translation system , http://www . 

James Gosling , Bill . loy , and ( luy L . Steele , Jr .  1996 . 
7' he Java " pMLa , ~( luage , 5' pcci Jication . Addison-
Wesley Publishing Co.
Xuedong Ihmng , Fileno Alleva , Hsiao-Wuen Hen , Mei-Yuh Hwang , and Ronald losenfeld .  1992 . 
The SPHINX-II speech recognition system : An overview  . ' l'echnic Mlel ) or tCMU-CS-92-112 , Carnegie Mellon University School of Computer

ICQ Inc . 1999. ICQIRC Services . http://www.icq.

Inter ' Dan . 1999. Anlnter Tran translation system.

Snnil Issar .  1997 . A speech interface for forms on WWW . In Proceedings of the 5th European Con-ferenccon , 5' peech Communication and 7' echnol-ogy , September . 
iTRiBE Inc .  1996 . .lilC . http://virtual . itribe . net/jirc / . 
Martin Kay .  1967 . Experiments with a power fil parser . In Proceedings of the 2~ Mlnternatio ~ ml
COLING , Angust.
Ray Kurzweil .  1999 . The Age of , 5'piritual Machines : I~Tten Computers Exceed tluman h~telli-flence  . Viking Press . 
Kevin Lenzo . 1998. personal conmmnication.
Microsoft Corp . 2000. MSNT MMessenger Service.

M . Nagao .  1984 . A\['ramework of an lechanical translation between Japanese and English by analogy principle  . In A . Elithorn and l . 13 ane I:ii , editors , Artificial and \]\]' uma ~ Intellig c~cc . NN . I ' Olhlblications . 
( ) \[\[ ice of Arti\[icial Intelligence Analysis and F  , vahm-lion OAIAE .  1996 . Artificial intelligence-An executive overview , http://www . ai . usma . edu : 8080/overview/cover . html . 
Jarkko Oikarinen and l ) arrenl / . eed .  1993 . Internet relay chat protocol , ftp://ftp . demon . co . uk/pub/doc/rfc/rfc 1738 . txt , le qucst for Comments 1459,
Network Worldng (- lroup.
Mark Seligman , Mary Flanagan , and Sophie Toole.
1998 . Dictated input ' or broadcoverage speech tra . nslation . In Clare Voss and Fie Reeder , editors , Workshop on Embedded MT ' , h ' fl stems : Design , Consh'uclion , and l ' J vahtatiol ~ of 5'9slcms ' with an 1147' Component , l , anghorne , Pennsylvania , October . AMTA . 
Mark Seligman .  1997 . Six issues in speech translation . In Steven Kra . uwer et al , editors , Spoken Language Translation Workshop , pages 83--89 , 
Madrid , July.
Terry Winograd .  1 . 983 . Langua 9easa Co . qnitive Process . Volume 1: Syntax . Addison-Wesley . 
Jin Yang and Elke1) . Lange .  1998 . SYS TllAN on Alta Vista . : A user study on realtime machine translation on tile Intcrnet  . Inl ) avid Far-well et al , editors , Proceedings of the Third Conference of the Association for Machine  7  ; r(msla-lionin lheAmericas(AMTA'98) , pages 275-285 , Langhorne , Pennsylvania , October . Springer-


