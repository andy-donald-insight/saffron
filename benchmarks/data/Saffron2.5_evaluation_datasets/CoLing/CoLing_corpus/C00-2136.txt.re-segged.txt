Automatic Acquisition of Domain Knowledge for Information 

Roman Yangarber , Ralph Grishman Past Tapanainen
Courant Institute of Conexoroy
Mathematical Sciences Helsinki , Finland
New York University
roman\[grishman@cs , nyu . edu Pasi . Tapanainen@conex or . f i
Si ! ja It ut tunen
University of Helsinki
Finland


In developing an Infbrmation Extraction tIE ) system t branew class of events or relations , one of the major tasks is identifying the many ways in which these events or relations may be expressed in text  . This has generally involved the manual analysis and  , in some cases , the annotation of large quantities of text involving these events  . This paper presents an alternative approach , based on an automatic discovery procedure , ExDIsCO , which identifies a set ; of rele-wmt documents and a set of event patterns from unannotated text  , starting from a small set of " seed patterns . " We evaluate ExDIScO by comparing the pert brmance of discovered patterns against that of manually constructed systems on actual extraction tasks  . 
0 Introduction
Intbrmation Extraction is the selective x trac-tion of specified types of intbrmation from natural language text  . The intbrmation to be extracted may consist of particular semantic classes of objects  ( entities )  , relationships among these entities , and events in which these entities participate . The extraction system places this intbrmation into a database t br retrieval and subsequent processing  . 
In this paper we shall be concerned primarily with the extraction of intbrmation about events  . In the terminology which has evolved ti'om the Message Understanding Conferences  ( muc , 1995; muc ,  1993) , we shall use the term subject domain to refer to a broad class of texts  , such as business news , and tile term scenario to refer to tile specification of tile particular events to be extracted  . For example , the " Management Succession " scenario for MUC6 , which we shall refer to throughout this paper , involves information about corporate executives tarting and leaving positions  . 
The fundamental problem we face in porting an extraction system to a new scenario is to identify the many ways in which intbrmation about a type of event may be expressed in the text  ;  . Typically , there will be a few common tbrms of expression which will quickly cometon find when a system is being developed  . However , the beauty of natural language ( and the challenge t br computational linguists ) is that there are many variants which an imaginative writer cast use  , and which the system needs to capture . Finding these variants may involve studying very large amounts of text  ; in the subject domain . This has been a major impediment to the portability and performance of event extraction systems  . 
We present ; in this paper a new approach to finding these variants automatically fl'om a large corpus  , without the need to reador amLo-tate the corpus . This approach as been evaluated on actual event extraction scenarios  . 
In the next section we outline the strncture of our extraction system  , and describe the discovery task in the context of this system  . Sections 2 and 3 describe our algorithm for pattern discovery ; section 4 describes our experimental results . This is t bllowed by comparison with prior work and discussion in section  5  . 
1 The Extraction System
In the simplest terms , an extraction system identifies patterns within the text  , and then mat ) s some constituents of these patterns into data base entries  .   ( This very simple descrip-lion ignores the problems of anaphor and intersentential inference  , which must be addressed by any general event extraction system  . ) AI-though these l ) atterns could in principle be stated in terms of individual words  , it is muchtic constituents , uc has noun phrases and verb groups . Consequently , extraction or mally consists of an analysis of the l  ; e . x t in terms of general linguistic structures and dolnain-specifio constructs  , t bllowed by a search for the scenario-specific patterns  . 
It is possible to build these constituent structures through a flfll syntactic analysis of the text  , and the discovery procedure we describe below woul  ( 1 be applicable to such an architecture . Howe , ver , for re&sellS of slme , ( t , coverage , and system rolmstness , the more ( : ommon ap-t ) roa ( : hat present is to peribrn i at ) artial syntactic analysis using a cascade of finite-state transducers  . This is the at ) t ) roa (: h used by our e . xtraction system ( Grishman , 1995; Yangarber and Grishman ,  1998) . 
At ; the heart of our syslx ' an is a regular expression pattern matcher which is Cal  ) al ) le of matching a set of regular exl ) ressions against a partially-analyzed text and producing additional annotations on the text  . This core draws on a set of knowledge bases of w ~rying degrees of domain - and task-specificity  . The lexicon includes both a general English dictionary and definitions of domain and scenario terms  . The concept base arranges the domain terms into a semantic hierarchy  . The predicate base . de-s('ribes the , logical structure of I ; he events to be extracl ; od . ' Fire pattern \] ) ase consists of sets of patterns ( with associated actions )  , whi ( ; hmaker ( ; feroll CO to information Kern the other knowl-e ( lgebases . Some t ) at torns ots , su (: has those for n ( mn and verb groups , are broadly apl ) licable , wl file other sets are spe(:ifio to the scenario . 
V  ~ Z e , have previously ( Yangarl ) er and Grishman ,  1 . 997 )   ( lescrit ) eda user interface which supt ) or ts the rapid cust ; omization of the extraction system to a new scenario  . This interface allows the user to provide examples of role-wmt events  , which are automatically converted into the appropriate patterns and generalized to cover syntactic variants  ( passive , relative clause , etc . ) . Through this internee , the user can also generalize l ; he pattern semanti ( ' ally ( to ( : over a broader class of words ) and modify the concet ) t base and lexicon as needed . Given an appropriate set ; of examples , there ibre , it ; has become possible to adapt the extraction system quiteral  ) idly . 
However , the burden is still on the user to find the appropriate set of examples  , which may require a painstaldng and expensive search of a large corpus  . Reducing this cost is essential for enhanced system portability  ; this is the problem addressed by the current research  . 
I low can we automatically discover a suitable set ; of candidate patterns or examples ( patterns which at least have a high likelihood of being relevant to the scenario  ) ? The basic idea is to look for linguistic patterns which apt  ) ear with relatively high frequency in relevant documents  . 
While there has been prior research ollide ai -lying the primary lexical t  ) atterns of a sublanguage or cortms ( Orishman et al 1986 ; Riloff ,  1996) , the task here is more complex , since we are tyt ) ically not provided in advance with a subcorpus of relevmlt passages  ; these passages must themselves betbund as part of t  ; t1( ; discovery i ) rocedure . The difficulty is that one of the l ) estimlic ~ tions of the relevance of the passages is t  ) recisely the t ) resence of these constructs . Bo-(:ause of this (: ircularity , wel ) ropose to a (: quire . 
the constructs and t ) assagos in tandem.
2 ExDISCO : the Discovery Procedure
We tirst outline ExDIsco , our procedure for discovery of oxl , raction patterns ; details of some of the stops arc l ) rcse , nted in the section which follows , and an earlier t ) ~q ) eronour at ) l ) roach ( Yang ~ u : b crotal . , 2000) . ExDI scO is miml-supervised 1 ) rocedure : the training ( : or tms does not need to t ) e amlotated with the specific event int brmatkm to be  . e . xtracted , or oven with information as to whi ( ; h documents in the ( ' or pus are relevant o the scenario . ' i7 tlo only intbrmation the user must provide , as described below , is a small set of seed patterns regarding thes ( :enario . 
Starting with this seed , the system automati-(: ally pert bnns a repeated , automatic expansion of the pattern set . This is analogous to the process of automatict ; ennexpansion used in s ( )me information retrieval systems , where , the terlns Dora the most relewmt doculn cnts are added to the user query and then a new retriew fl is imr formed  . However , by expanding in terms of 1) at l ; erns rather than individual terms , a more precise expansion is poss it ) le . This process pro-coeds as t bllows : 0 . We stm : t with a large , corlms of documents in the domain ( which have not been an ne-"seed " of scenario patterns selected by the user--a small set of patterns whose presence reliably indicates thai  ; the document is relevant o the scenario . 
. The pattern set is used to divide the cor-tins U into a set of relew mt documents  , R ( which contain at ; least one instance of one of the patterns ) , and a set of nonrelevant documents R = U-R . 
2 . Search tbrnew candidate patterns : ? automatically convert each document in the e or Ims into a set of candidate patterns  , one for each clause ? rank patterns by the degree to which their distribution is correlated with docmnent relevance  ( i . e . , appears with higher frequency in relevant documents than in non-relew mtones  )  . 
3 . Add the highest ranking pattern to the pattern set  . ( Optionally , at this point , we may present he pattern to the user for review . ) 4 . Use the new pattern set ; to induce a new split of the corpus into relevant and nonrelevant documents  . More precisely , documents will now be given a relevance confidence measure  ; documents containing one of the initial seed patterns will be given a score of  1  , while documents which arc added to the relevant cortms through newly discovered patterns will be given a lower score  . I / , epeat the procedure ( from step 1 ) until some iteration limit is reached , or no more patterns can be added . 
3 Methodology 3 . 1 Preprocessing : Syntactic Analysis Before at ) plying ExDIsco , we pre-proeessed the cortms using a general -purposed pendency parser of English  . The parser is based on the FDG tbrmalism ( Tapanainen and Jgrvi-hen ,  1997 ) and developed by the Research Unit for Multilingual Language Technology at the University of Helsinki  , and Conexor Oy . The parser is used ibrreducing each clause or noun phrase to a tuple  , consisting of the central arguments , ms described in detail in ( Yangarber et al ,  2000) . We used a corlms of 9 , 224 articles from the Wall Street ; Journal . The parsed articles yielded a total of 440 , 000 clausal tuples , of which 215 , 000 were distinct . 
3.2 Normalization
We applied a name recognition module prior to parsing  , and replaced each name with a token describing its  ( : lass , e . g . C-Person , C-Company , etc . We collapsed together all numeric expressions , currency w flues , dates , etc . , using a single token to designate ach of these classes  . Lastly , the parser performed syntactic normalization to transtbrm such variants ms the various passive and relative clauses into a common tbrm  . 
3 . 3 General izat ion and Concept Classes Because tuples may not repeat with sufficient frequency to obtain reliable statistics  , each tuple is reduced to a set of pints : e . g . , a verb-object pair , a subject-object pair , etc . Each pair is used as a generalized pattern during the candidate selection stage  . Once we have identitied pairs which are relevant o the scenario  , we use them to gather the set ; of words for the missing role(s ) ( tbrexample , a class of verbs which occur with a relevant subject-ot@ct pair : " company hire/fire/expel  . . . person ") . 
3.4 Pattern Discovery
We ( -onducte ( 1 exi ) eriments in several scenarios within news domains such as changes incorporate ownership  , and natural disasters . Itere we present results on the " Man~geme . nt Succession " and " Mergers/Acquisitions " cenarios  . 
ExDIs cow as seeded with l ninimal pattern sets , namely :
Subject Verb Direct Object
C-Company C-At ) point C-Person
C-Person C-Resign ibr the Mmmgement task , and
Subject Verb Direct Object * C-Buy C-Conlt ) any
C-Company merge * for Acquisitions . Here C-Company and C-Person denote semantic classes containing named entities of the corresponding types  . C-Appoint denotes the list of verbs appoint , elect , promote , name , nominate , C-Resign = re-sign , depart , quit , and C-Buy = buy , purchase . 
942\]) uring ~ single iter ~ tion , we conqmt (; the score , See're(p ) , for each cm~(lidate 1) attern p , using (; he fornmla ~:
S , : o ', ',@) = IH nl ~ l
IHI-1,, ~ IH n ~ . 1 (: t ) where 12 . ( Ic notes ( ; h(' , l'clew mtsubsc(; of documents , midIt = It(p ) the , (locmnent simttching p , as above ; the Iirst ( ; erma ( : ( : ounts for the con- ( lition ~ flt ) robability of relev ; m('e oilp ~ and ; 11( ; second t brits support . We further impose two support criteria : we distrust such frequent pat-  (  ;  , ~ . ,- . ~ w\]le , : eI1~nUI > , ~ IUI ,   , ~ uninforn , ,~tive , midrare patte . rns\['or which I1\]r-I\]~ . 1 < fl as noise . 2 At the endot '( . a ehil ; eratiol ~ , the sysl ; em selects the pal ; tern with the highest Sco'/'d(p ) ~ and adds it ( ; o ( ; lie seeds cl ;  . The ( to (: un~enl ; s which t ; he winning t ) ~( ; t ; ern hits are added ( ; ot ; 111( ; relevant set . The t ) al ; l ; (; r n s ( ; are h is then r ( ; s l ; m : l ; ( ; d . 
3.5 Document Re-ranking
Th(:above is a simt ) lifi ('; ~ l;ion of (; hea , (: tual pro-ced lll '( ~ in severa \] r (' , st)e('(;s . 
Only generalized t ) nt l ; ernsare(:onsideredfi)r (: audi(t ~ my , with one or mot (' , slol ; s fill (: (1wi (; h wihl-cm'd s . In computing the score of th (' , ge , n -(; raliz(:d\]); tttern , w (: do not take into (' on si(h:r-;i , 1; i () 11 all possible va , hw , s of the , wil(1-('m:d role . 
\? einstea . d ( : ( ) llS ( ; raJll ( ; he wild-(:ar(lto thos(~wd-u(:swlli(:hl ; ht' , llls(;lv (; sill ( ; llrH\]l ; tV (: high scores . 
Th(:sev ~ du (: sl ; lw , n ) e(:on~elllClll\])(;l'S of/ . II(:W (: lass , whi (: hisl)rO du ( : edin ( ; : tlldClll with the wimfing1) att(:rn . 
\]) o('umel~tSreh:wm('eiss(-ored(m~s( ; ah : l)e-( ; ween 0 and 1 . Tlm seed t ) atterns a . rea . (: cet)ted ~ , strut \] ~; the do (' mlw , nts(;heymat(:\]1hnvercle-vmme1 . Oni(;er ; ~ tioni+1 , e~mht ) a (; tern p is assigned a precision measure , t ) ase ( lont here l -(': Vall ( ; e of ; 11( ; (locllnlelfl ; si ; 111 a , l ; ( ; ll (' , ,q : ~ " . d ~( d )(~) ff , , : d + ~( v)--IH(v ) l,~ . ( , ,) where l~ , eli(d ) is there , levmlce of '1; 11 (: doeunmn(;fi'omt ; t1(' , previous iteration , ~ mdlI ( p ) is the set of documents where p matched , in general , if K is a classifier ( : on sisting of ~ set of l ) al ; terns , w (' , define H(K ) as the st:l ; of documents where all ~ similar to that used in ( liiloff , 1996) ~ W(:used , :-- 0 . 1 and fl = 2 . 
oft ) ~ d ; terns pCKm~l ; (: h , mid the " cunmlative " precision of K as 1~1~4 ~ ( a , ) (3) P ~ . ~d + ~(1() = IHU()I < . ( K ) Once the wimfing pa , l ; l ; ern is accepted , the rel-ewmee of the documents is read justed . For ( ; ~ m h document d which is matched by some subset of l  ; he currently accet ) t('d pnt terns , we can view thai ; sul ) s(' , t ; of l ) ~ t terns as ~ classitier K d = pj . These patterns ( tel ; ermilm the newreh ; wm ce score of the document as J ~ , " ~ l , ~ " (  , 0:111 ~ x (: tc , , . 1,*(, O , v, . ,;,  . ~"( K ,)) (~:) This ensures tha . (; l ; her clewm ce score grows monotonically , and only when there is sufliei ( mt positive evidence , as ( ; hei ) ntternsine tl ' e(:I ; vote " conjmmtively " on the ( loculn cnl ; s . 
We also tried an alternative , :: disjun(:tive " voting scheme , with weights wl fich accounts t brvm : intion in support of the p~tt terns  , J ,  . , . 1, ( d) .   .   .   . ~" ~ II(1-~', . ~, . c ~( p )) "" , '(5) ~ cK(d ) where t ; 11(' , weights , wparc(tetint ; d using the tel-ewm (: (: of the ( loeuments , a , s the total SU l ) l ) or (; which the pa , I ; I ; ern preceives : %= log~l; . d , ( d)dE11 ( p ) and ; , 7 is ( ; 11 (' largest weight . The r (' , cursive for-nmb~s('apl ; m : e( ; hemul ; u ~ fl dependency of t ) ~ t-terns ~ md documents ; this re-computation ~ md growing of precision and relevml cermlks is the core of the t  ) rocedure . : ~4 Results 4 . 1 Event Extraction'l'he,mostnal;m'a . lmeasm'e of efl'ecl ; iveness of our discovery procedure is the performmme of ml extraction systmn using the  , discovered t ) ~ tterns . 
However , i l ; is not 1) ossil ) le to apply this reel ; -riodireei ; ly because the discovered t ) al ; terns lack some of the information required tbr entries ill:\V  ( ' . did notel ) serve a significam ; difl'erenccin1) crfi)r-lIiHl\[CO , bet , ween the two tormulas 4alt ( t5 in o111" experi-in ( mrs ; the results whit : ht bllow use 5 . 
9 43 the pattern base : information about the event type  ( predicate ) associated with the pattern , and the mapping from pattern elements to predicate arguments  . We have evaluated ExDIs coby manually incorporating the discovered patterns into the Proteus knowledge bases and running a full MUC -style evaluation  . 
We started with our extraction system , Pro-tens , which was used in MUC6 in 1995 , and has undergone continual improvements since the MUC evaluation  . We removed all the scenario-specific clause and nominalization patterns  .   4 We then reviewed all the patterns which were generated by the ExDIsco  , deleting those which were not relewmt to the task  , or which did not correspondirectly to a predicate already implemented t br this task  ) The remaining pat ; terns were augmented within tbn nation about the corresponding predicate  , and the relation between the pattern and the predicate al'guments  , a The resulting variants of Proteus were applied to the formal training corpus and the  ( hidden ) formal test corpus for MUC6 , and the output evaluated with the MUC scorer . 
The results on the training corpus are :
Pattern Base Recall Precision
Seed 3883
ExI ) Isco 62 80
Union 69__ 79
Manual-MUC ~71L~1.9 ~
Manual-NOW 6 ( 3 ~79L 7! ~ z\[ ) _t_j and on the test cortms : 4There are also a few noun phrase patterns which can give rise to scenario events  . For example , " MrSmith , former president of IBM " , may produce an event record where l % edS mith left IBM  . These patterns were left in Proteus for all the runs  , and they make some contribution to the relatively high baseline scores obtained using just the seed event patterns  . 
~ ExD~scofund patterns which were relevant to the task lint could not be easily ace omodated in Proteus  . 
For instance " X remained as president " could be relevant  , particularly in the case of a merger creating a new corporatentity  , but Proteus was not equipped to trun-dle such i Ifformation  , and has not yet been extended to incorporate such patterns  . 
6As with all clause-level patterns in Proteus , these patterns m-eautomatically generalized to handle syntactic wn'iant such as passive  , relative clause , etc . 
Pattern Base Recall Precision F
Seed 2774 39.58
ExDIsco 5272 60.16
Union 5773 63.56
Manual-NOW--56756404.
The tables show the recall and precision measures for the patterns  , with Fmeasure being the harmonic mean of the two . The Seed pattern base consists of just the initial pattern set  , given in the table on the previous page . ~ ib this we added the patterns which the system discovered automatically after about  100 iterations , producing the pattern set called ExDIs co . For comparison , Manual-MUC is the pattern baseln anually develot ) ed on the MUC6 training corpus-1 ) repared over the course of 1 month of full-time work by at least one computational linguist  ( during which the 100-document training corpus was studied in detail )  . The last row , Manual-now , shows the current pertbrmance of the Proteus system  . The base called Ultiolt contains the union of ExDIScO and Manual-No'w  . 
We find these results very encouraging : Pro-teus performs better with the patterns discovered by ExI  ) IscOth an it did after one month of manual tinting and development  ; in fact , this perfi)rmance is close to current levels , which are the result of substantial additional devel-opmeut  . These result sumst be interpreted , however , with several caveats . First , Proteus performance depends on many fimtors besides the event patterns  , such as the quality of namer e , cognition , syntactic mmlysis , anaphora reso~lution , inferencing , etc . Several of these were improved since the MUC formal evaluation  , so some of the gain over the MUC formal evaluation score is attritmtable to these factors  . How ~ ever , all of the other scores are comparable in these regards  . Second , as we noted above , the patterns were reviewed and augmented manually  , so the overall procedure is not entirely automatic  . However , the review and augmentation process took little time  , as compared to the manual corpus analysis and development of the pattern base  . 
4.2 Text filtering
We can obtain a second measure of pertbr-mance by noting that  , in addition to growing the tmttern set , ExDIs co also grows the rele -0 . 8 0 . 7 0 . 6 0 . 5 _  . r-~H .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . r .   .   .   .   .   .   . T~~::~T ;!\> . g~t:-'il % i\[!\]

Management/Test?.-~......
Managemen Vl-raie-:*:--
MUC6 ? 0.2 0.4 0.6 0.8

Figurel : Management Suc('cssion 0 . 9 0 . 8 0 . 7 0 . 6 0 . 5


Acquisition 0.2 0.4 0.6
Recall 0.8
Figme 2: Mergers/A ( : quisitions vance rankings of documents . The latter cnn beevahlate directly , wil ; hollthuman intervention . 
We tested Exl ) Is C , o ~ tgains two cor \]) or n:th ( ; 100 documents from MUC6 tbrmal training , a:nd the 100 documents from the MUC6 formal test ( both are contained an long the 10 , 000 ExDIs oO training set ) r . Figure 1 shows recall t ) \] otted against precision on the two corpora , over 100 iterations , starting with the seed pat-te , nls in section 3 . d . This view on the discovery procedure is closely related to the MUC % ext-till  ; ering " task , in which the systems are jlulged at the \] evel of doc  , wm , e , 'nt . s rather thmt event slots . 
It ; is interesting to ( : omt ) m : eExl ) IsCO's results with how other MUC6 part\]t it ) ants performed on the MUC-b'test cortms , shown anonymously . 
ExDIscO attains values within the range of the MUC participal d  ; S , all of which were either heavily-supervised or m ~mually coded systems  . 
II ; is important to bear in mind that ExI ) Is coh adno benefit of training material , or any in-t brmation beyond the seed pattern set . 
Figure 2 shows the 1)ert brmance , of text filtering on the Acquisition task , again , given the seed in section 3 . 4 . ExDisco was trained on ; lie same WSJ e orlms , and tested against a set of 200 documents . We retrieved this set using keyword-based IR , search , and judged their relevance by halId . 
r The scjudgements constituted the truth which was used only for evaluation  , not visible to ExDISCO 5 Discussion The development of aw ~ riety of information extra  ( : tion systems over the last decade has demonstrated their feasibility but also the limitations on their portability and t  ) erformance . 
Prcl ) aring good t ) atterns t br these syste , ms requires (: onsiderable skill , and achieving good (: overage requires ; lie analysis of a large amount of text . The set ) rol ) lemsh ~ vet ) een imped in mnts to the-wide \] . ' use of extraction systenls . 
The sedit\[iculties have stimulate . dresear (' hon1) attel . ' na (: ( luisition . Solne of this work has enl-i ) hasized il \] teractive tools to ( : onvert examples to extractioi ~ t ) atterlls ( Yangarber and Grishman , 1997); nmchot :' there , search has focused on methods for automatically converting a cortms annotated with extraction examples into patterns  ( Lehnert et al , 1992; Fisher et al , 1995; Millerel ; al . , 1998) . These techniques may reduce the level of systeln expertise required to develop a new extraction N  ) plieation , but they do not lessen the lmr den of studying a large cor-lms in order to  . find relevant candidates . 
The prior work most closely related to our own is that of  ( R . i lotf ,  1996) , who also seeks to lmild pattenls automatically without the need to annotate a corpus with the information to be extracted  . I to we ver , her work ditfers t'rom 01217 own in severaliln portant respects . First , her patterns ident it ~ y phrases that fill individual slots in the template  , without specifying how these slots may be combined at a later stage into complete templates  . In contrast , our procedure discovers complete , multi-slot event pat-in which ; tie documents have been classified for relevance by hand  ( it was applied to the MUC3 task , tbr which over 1500 classified documents are available )  , whereas ExDI score quires no manual relevance judgements  . While classifying documents t br relevance is much easier than annotating do cunlents with the information to be extracted  , it ; is still a significan task , and places a limit on : tie size of the training corpus that can be effectively used  . 
Our research as demonstrated that for the studied scenarios automatic pattern discovery Call yield extraction per fi  ) rmance colnt ) a rabh ~ to that obtained through extensive corpus analysis  . There are many directions in which the work reported here needs to be extended : ? nsing larger training corpora  , in order to find less frequent exanlplcs , and in that way hopefully exceeding the i ) erfornlancc of our best hand-trained system ? cat ) luring the word classes which are generated as a by product of our pattern discovery  1  ) rocedure ( in a manner similar to ( Riloff and , Jones ,  1999 ) ) and using them to discover less frequent ) atterns in subsequent iterations - evaluating the effectiveness of the discov-cry procedure on other scenarios  . In par-titular , we need to be able to identi\[y top-its which cast be most effbctively characterized by clause -level patterns  ( as was the case t br the business domain )  , and topics which can be better characterized by other means  . We . wou M also like to understand how the topic clusters  ( of documents and patterns ) which are developed by our procedure line up with prespecified scenarios  . 

David Fisher , Stephen Soderland , Joseph McCarthy , Fangfang Feng , and Wendy Lelmert . 
1995 . Description of the UMass system as used fbr MUC6 . In Prec . Sixth Message Un-dcr stand in 9Conf . ( MUC6), Columbia , MD,
November . Morgan Kauflnann.
R . alph Grishman .  1995 . The NYU systenlt br MUC6 , or where's the syntax ? IllPrec . 
Sixth Message Understanding Conf . ( MUC6) , pages 167176 , Columl ) ia , MD , November . Morgan Kauflnann . 
W . Lehnert , C . Cardie , D . Fisher , J . McCarthy , E . Riloff , and S . Soderland .  1992 . University of nlassachusetts : MUC4 test results and analysis . IllP , ' oe . Fourth Message Un-der . standing Con . \[ . , McLean , VA , June . Morgan Kauflnaml . 
Scott Miller , Michael Crystal , Heidi Fox , Lance II , amshaw , R , ichard Schwartz , Rebecca Stone , Rall ) h Weischedel , and the Annotation Group .  1998 . Algorithms that learn to extract intbrmation ; BBN : Description of the SIFT systen las used for  MUC7  . In PTve . 7th Mc . ssagcUnderstanding Co ~: f . , FMrfax , VA . 
1993 . Proceedings of the F'~ifth Message UTz . -derstanding Confer(race(MUC-5), Baltimore,
MD , August . Morgan Kauflnann.
1995 . PT veeedings of the Sixth Message U~I , -derstav , ding Conference ( MUC6) , Colmnt ) ia , 
MD , November . Morgan Kauflnaml.
Ellen Rilotf and Rosie Jones .  1999 . Learning dictionaries for infbrmation extraction by multilevel bootstrat  ) ping . In Prec .   16th Nat'l Cord'erenee on Art ' ~ i \ [ icial Intelli9enee   ( AAAI99 )  , Orlando , Florida . 
Ellen Riloff .  1996 . Automatically generating extraction patterns from m~tagged text  . In Prec . I3th Nat'l Co ~ ~: f . on Art ~ ificial Intelligence ( AAAI-96) . The AAAI Press/MIT

l?asi '\]) ~ panainenadTime . J/h:vinen .  1997 . A non-t ) rojectiv c dependency parser . In P'mc . 
5th Conf . on Applied Nat'aral Language P~v-cessiu9 , pages 6471 , Washington , D . C . ACL . 
Roman Yangarber and Ral I)h Grishman . 1997.
Customization of intbrmation extraction systems . In Paola Velardi , editor , I ~ tt'l Workshop on Lexically Driven I~7:forrnation Extraction , Frascati , Italy . Universith di Roma . 
Roman Yangarl ) er and Ralph Grishman . 1998.
NYU : Description of thcProtens/PET system as used tbr  MUC7 ST . In 7th Message Understanding Conference , Columbia , MD . 
Roman Yangarl ) er , Ralph Grishman , Past
Tapanainen , and Silja Huttunen .  2000 . Unsupervised discovery of scenario-level patterns tbr information extraction  . IllPTve . 
Co~@on AppliedNat'aralLang'aagePr'ocess-tug ( ANLP-NAACL )  , Seattle , WA . 

