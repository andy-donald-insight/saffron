LINGUISTICS ANDAU TO MATED LANG UAGE PI~OCESSING 1
0 . 1 Th is paper is concerned with natura l l anguage  , computers , 
and two groups of people interested in natural language : \] inguists  , and
persons engaged in computer processing of natura l language data  . 
There is some intersection of the latters e ts  , but the intersection is quite small relat ive to the size of the sets themselves and is thus in-adequate to provide linguists with a proper perspective on automated language processing  , or computer scientists with a proper per spec -tive on linguistics  . 
Although both groups of persons have a mutual interest in natur-allanguage  , their conceptualizations of the nature of language and their approaches to processing language data are very different  . To present a somewhat over simplified view of these differences : linguists tend to be theory-oriented--they are concerned with interesting but sometimes quite es oterlcp roblems  , counter-examples , and the infinite set of sentences of competence  ; on the other hand , persons engaged in auto-mated language process ing tend to be data-oriented  , and are concerned with statistical sign ificance and with some finite subset of the sentences of performance  . The question therefore arises as to whether these different perspectives are to be in terpreted as incompatible or comple-r : ~ entary  , and if complementary , whether some research concept might provide the means for a unified approach to analysis of natural language  . 
In this paper , Section 1 deals with the perspective of linguists on automated language processing and computers c ientists on linguistics  ; Section Z discusses their respective concepts of natural language and lIarn indebted to Paul GarTin for his valuable comments on this paper  . 
and their approaches to analysis of natural language  , and explores the questions raised above ; Section 3 presents some concluding remarks . 
1 .   1 It is appropriate to begin this discuss ion with a brief inquiry into the sources of the common focus of linguists and computers c ientists on natural language  . The interest of linguists in naturall anguage is given by definition  ; the interest of non-linguistically o riented computer specialists in naturall anguage derives not from a concern with language per se  , but from the function of language as the pr imary vehicle for communicating information in human society  . Whether or not one accepts the idea of the so- called " information explosion  , " the processing of natural language text is an important challenge for both linguist i cs and computer science  . The sheer volume of natural language in form a -tionistaxing manual systems to the point where most organizations which engage in la rgescale information processing a return ing to automation of operations on naturall anguage text  . While most linguists are speculating on the theory of language  , computer scientists with little or nol in guistic background are attempting to construct systems for analyzing the content of natural language materials  . Obviously , lin-guists should become involved in th is development  , but to date , few linguists have been motivated to part i cipate  . It appears that there are two basic reasons for the current lack of involvement  . 
1 .  1 .   1 In the first place ~ among linguists there is little appreciation of the fact that in essence  , all processing of natural language info rmation -- whether scientific  , technical , or literary -- is a linguistic prob lem  . 
Basically , the processing of natural language informat ion for indexing  , abstracting , fact retrieval , translation , or any other purpose requires an analysis of the content of the text and the represent at ion of it in some standard form  . Ideally , content analysis consists in determining the concepts present in the material and the in ter relations existing among those concepts  ; the former is based on some form of semantic analysis  , and the letter implies syntactic analysi s ~ although the two forms of analysis are interdependent to a considerable degree  . 
The concepts and relations which have been identified are then translated into a set of canonic sentences representing ~ he content of the document  . From this representation of the content of the document  , all document surrogates -- such as strings of index terms or thesaurus groups  , abstracts or extracts or translations - -are produced  . In the case of fact retrieval or question - answering systems  , the canonic sentences represent the beliefs of the system and serve as the base for generat ing factual answers to specific queries  . Thus , although most existing automated content an a lysis procedures are at best low level approx imations of this ideal  , it is clear that analyzing the content of natural language text must be based on semantic and syntactic princl-ples and is hence an obvious object of linguistic endeavor  . It is unfor-tuante that the signifi cance of this fact is not appreciated by the majority of linguists  . 
I . I . ZA further -- and not unrelated -- reason for non -participalion linguists in automated language processing is a basic lack of knowledge about computers ~ in the sense of realizing when a computer is a handy tool ~ and when it isn't so handy  . By this I don't mean a lack of knowledge about hexa decimal systems  , bits and bytes , or serial and parallel processors , but very simply knowledge of what a computer is good for  . 

The fact is that for many of the operations characteristically per * formed in l inguistic research  , the computer is an invaluable--if not an indispensable -- tool  . This is a very strong claim for the utili ty of the computer in linguistics  ; therefore , the grounds on which it is based are worth examining in some detail  . 
The operations which the linguist performs in carrying out research on a language or languages are essentially the following : he collects data  , organizes and analyzes them , formulates hypotheses and verifies them . There is of course , a great deal of feedback analysis and recyc ling through all these operations  , which are highly interdependent . 
It is therefore impractical to examine the applicability of computer pro-cessing individually to each of the operations l is ted above  . Since the important concept of " organizat ion " applies equally to data and hypotheses  , in the following the linguistic operat ions for which computers can be used will be grouped into these two categories  . Where these oper-ations are differently interpreted or valued by linguists of d if ferent schools  , divergent points of view will be noted . 
Data collection and organization , operations on the database . 
There are two senses in which data is collec ted in linguistic analysis  . 
The first sense refers to the initial co llection of data for inclusion in the corpus or database  . For a linguist working with a language unknown to him  , this generally means eliclting such data from an infor-cannot proceed in a haphazard manner  , but for the traditional descrip-tivel in guist at least  , is one subcornponent of a heuristics tra tegy for discovering the basic elements and relations of a given language  . Be-tion for a computer is a formidable undertaking  . Thus far , there has been only one attempt at automating paradigmelicitation for unknown languages  ( Garvin 1969 ) : since this project also involves analysis and hypothesis formulation  , a more detailed discussion will be presented below  . 
A second sense of data collection is these lection of particular data items from a previously collected database  . -When working with a language in which he does not have native or near native competence  , operations on the database--that is to say , organizing , searching , retrievhlg , and refiling data -- assume a dominantro le  . This is because the linguist cannot rely on himself as a source of data which he can organ ize and analyze in terms of his own competence  ( this procedure presents another type of prob lem  , which is discussed in Section Z ) . 
The anthropological linguist thus must devote a disproportionate amount of times imply to operating on the database  , and especially to organ-izing his data . He typically records his data items on smal l slips of paper  , which he then sorts and cross-files according to various criteria  . 
The problem is that he can only cross-file a data item as many ways as he has duplicates lips  , an original and three carbons being about the limit of legibility in recording data with a penorpencil  . The four copies allow him , for instanc 4' , alphasorted files of English/Language L , Language L/English and two morphological classifications  . If the language is at one language other than I raq w -- an african language in which tone and morphological classes coincide--four files are in suffi-cent even for morphological analysis  ; for syntactic and semantic analysis , There are two major problems inherent in these traditional data-handling methods  , which may provide at least a partial explanation for the wellknown inadequacies in the descriptions of the socalled " exotic " languages  ( Uhlenbeck 1960 )  . In the first place , the operations involved in the creation of these files  , retrieval of relevant data from them , and replacement of the data in the files require a great deal of the llnguist ts time  , which might be more profitably spent in analysis and in hypothesis formulation and verification  . Secondly , because in a taxonomic approach , classifications contained in the files in effect form the basis of the grammar  , and because syntactic and semantic analysis requires a highly sophisticated and extensive organization of the data  , these aspects of linguistic research inevitably suffer when data handling is limited to traditional manual techniques  . 
Now , the clerical operations of sorting and listing data rapidly and variously are just those at which the computer excels  . The computer can speedily present a variety of arrangements of large volumes of data  , which may expose underlying patterns not ident if iable--or identifiable only with di fficulty -- by means of traditional card filing techniques  . The possibilities for automating these types of operations have yet to be fully explo ited  ; however , programs for generating morpheme concordances have been developed by Grimes and by 

Formulation , organization , and verification of hyp0theses : analytic and synthetic operations . Although a computer cannot spontaneously generate hypotheses  , it can assist the linguist in recognizing patterns in the data  . Moreover , in organizing and verifying hypotheses , the computer may well be an indispensable too lIn order to test a hypoth-es is  , it should be stated as explicitly as possible  ; use of the computer forces the investigator to be explicit  . In computertes liug of hypotheses , loose formulations become obvious rather qu ickly  , as the computer performs all and only the operations specified in the program--of ten to the dismay of the investigator  . 
In addition to the stringent requirement for explicitness  , use of the computer necessitates a logical o rganization of hypotheses in order to provide for systematic ~ gandele J ~ r tracing  . Such require-ments apply equally to formal grammars and the somewhat more loosely organ ized descriptive grammars  . 
Transformational grammars , however , present a particularly convincing case for the ne~cessity of computer testing  . It is difficult to envision how the l inguistic researcher can possibly keep t rack of ZAlthough some difficulties are inevitable in converting linguistic materials to machine-read a bLe form  , the initial investment of time , energy , and funds are well worth ~ effort . At present , whether a key punchor an optical character reader is used as a conversion device  , linguistic diacritics and special characters must be recoded in terms of the avai lable character set  . However , fully automatic conversion by means of an opt ical character reader is a development which can be expected within the next few y ~ ars  . Some existing models can read a varinty of type styles with the combined error rate of the reader and the typist being lower than that of key punched material  , and the recognition of handprinted characters with an acceptable error rate is not far off  . 
the tortuous ramifications of order edru les within a single component of the grammar- -let alone across components -- without the aid of an automated grammar tester  . Several computer programs for testing grammar rules have in fact been designed  . These include a phonolog-ical rule tester ( Bobrow and Fraser 1968 )  , several versions of syn-?tactic ruletes ters based on the MITRE grammar  ( Friedman 1968 ; Gross 1968 ; Gross and Walker 1968) , the Transformational Grammer Tester ( TGT ) developed by Londe and Schoene ( 1968 ) for the Air Force UCL A English Syntax Pro ject  , and a system constructed by IBM to test the grammar of English II  ( Rosenbaum 1967 )  . Although these programs all operate through a synthesis procedure  , the on-line system described in Gross and Walker also has an analytic capability through the MITRE Syntactic Analysis P rocedure  . 
In addition to these largely synthetic test devices  , many analytical algorithms exist . These include algorithms for morphological as well as syntactic analysis  . The design of certain types of morphologica lanalysis algorithms for particular languages is in fact fair i  ) well understood . Reasonably successful suffix analysis a lgorithms have been designed for Russian  ( Ramo Wooldridge 1960 ) and for English
Chapin 1967; Earl 1967.
Numerous computer programs with various theoret ical bases have been designed for analyzing syntax  . These include various ver-sions of the Cocke algorithm--a bottom-to-top parsing logic which uses a table of binary IC grammar ru lesto develop simultaneously all possib leanalyses of an input string  ( for a discussion of the Cockelogic , see Hays 1966 , pp .  75-7 ; for recent applications of the CockeAtop- to-bottom predictive equivalent of the Cocke algorithm is the Kuno-Oettinger Syntactic Analyzer  ( Kuno 1965 )  . Both these algorithms , however , suffer from the disadvantage of producing mul tiple analyses  . 
More effective procedures for syntactic analys is incorporate trans-formational rules  ; these include the MITRE Syntactic Analysis P ro-cedure and that described by Martin Kay  ( 1967 )  . Another approach to syntactic analysis is the " fulcrum " method  , reported in Garvin (1968) , in which the grammar and the parsing logic are both incorporated into the analysis algori thm  . 
Although the synthetic rule testing systems d is cussed above are useful only for testing fo rmal grammars  , the analytic algorithms might also be used to test traditional descriptive grammars  . In the case of descriptive grammars , criteria for ordering and exhaustiveness are somewhat less rigorously specified than informal grammar  ; a descriptive grammar is nevertheless in in tricate network of complexly interrela ted statements in which some  . inconsistency is probable if not unavoidable . It would appear that the most effective means of pre-eluding such a possibility is through systematic omputer testing  . 
At present , the most versatile device for testing a descr iptive grammar is probably some version of the Cocke algorithm  , which could be used as a morphological an a lyzer with a set of morphological rules  , and as a syntactic analyzer with a set of syntactic rules  . In morphological analysis , the input string would consist of codes repre-senting the morphs occupying the success ive position classes which form the part i cular word  . In syntactic analysis , the input string would
I 0 of course consist of codes constituting the grammatical labels of the words which form the particular sentence  . 
Finally , it is appropriate to discuss a computer application which is noteworthy not only by virtue of the fact that it is in the descriptive tradition  , but also because it constitutes a substantial departure from the abovementioned algorithms in several important respects  ( Garvin 1969 )  . First , both the analytic and synthetic computer systems discussed above are mechanisms for testing a grammar of a particular language  ; hence , they accept test data and hypotheses in the form of grammatical rules as input and produce as output various diagnostics showing how the data were analyzed by the rules  . On the other hand , Garvin's program collects unanalyzed data in an ordered manner by means of its elicitation subcomponent  , applies theoretical assumptions to the data , and outputs a hypothesis about the morphological structure of the language represented by the data  . Second , rather than testing a grammar of a particula r language  , the immediate objective of the pro-gram is to test a theory of linguistic analysis as represented by a dis-covery procedure and the ultimate objective is to explicate the un iver-sal and near universal assumptions  ( linguistic universals ) " that are implicit in the operations of the linguistic analys L Third  , the program thus includes all the operations which a descriptive linguist performs  , except for hypothesis verification . Fourth , t ~ e computer program is constructed on heur is tic  , rather than algorithmic , principles . 
I .   2 The linguist Js failure to recognize the significance for linguistics of natural language information is paralleled by the failure to recognize that the problem is essentially a linguistic one  , More-over , the linguist's lack of knowledge about the computer as a versatile language processing tool is complemented by the lack of linguist ic knowledge of his computationally - or iented counterpart  . 
Examples of non-linguistically or iented computer processing of natural language data in the guise of content analysis are too nurner oustomention in detail--the class ical example is Luhnls " KWICI ~ concept  ( Luhn 1959 ) and its multitudinous misapplications ( for an exhaustive listing of these through 1964  , see Stevens 1965) . Examples of somewhat more sophisticated approaches include the various attempts to identify concepts and the relations obtaining between concepts without recourse to a systematic syntactic analysis of the given text  . Charac-teristically ; the text is segmented into " chunks " or " f ragments " by an adhoc recognition procedure based on lists of prepositions  , conjunctions , introductory adverbs , and the like ( e . g .   , Kochen 1969 , Bohnert 1966 , Briner 1968 , Wilks 1968) . 
1 . 3 From all the foregoing , the conclusion is inescapable that essential ly  , the majority of linguists do not have a proper perspective on automated language process ing and the majority of non-linguists engaged in automated language processing do not have a proper per-spective on linguist i cs  . Nevertheless , these two groups of persons have a common in terest in natural language  . It is therefore approp-priate to examifle the ir perspectives on the nature of language  . Gen-erally speaking , their viewpoints tend to be dichotomous ; these oppositions Underlie the problems d is cussed above  . 

Z . 0In essence , linguists ( especially those of the formal de-scrip tive school  ) are theory-oriented ; persons engaged in automated language processing are data-oriented  . Moreover , most linguists would agree that a linguist ic theory can be disproved by a single counter-example  , no matter how unlikely ; whereas researchers in automated language process ing are not disturbed by an incompatible p iece of data unless its probability of occurrence threatens the practical objec-t ive of the application  . Linguists search the infinite set of a natural language for their counter-examples while persons engaged in auto-mated language processing pare natural language down to an often skeletal subset  , just to exclude data which will perturb the i r system  . 
Linguists are concerned with the ideal of competence  ; automated language processing researchers must deal with the facts of perfor-mance--' the adulterations of the ideal "  ( Katz 1967 )  . 
If one takes a negative point of view , these dichotomies repre-sent irre concilab le differences in the basic conception of language  ; more positively , they may be regarded as complementary perspect ives on the nature of language  . The initial issue is thus one of determ in ing which view is correct  . Should the positive view be adopted , there is a more fundamental question as to the potential for unifying the two approaches to provide a balanced attack on problems of natural language analysis and descript ion  . 

In answer to the first question , it is reasonable to consider the two approaches as complementary  , since the specific weaknesses of the data- or lented position are offset by cor responding strengths in the theoretical or ientation  , and conversely . In the following discussion ,   13 /the respective deficiencies of the two approaches will be examined and potential unifying Concepts will be explored  . 
2 . 1 The data - or iented view of natura l language is genera l ly characterized by a bias toward the data  , a reliance on statistics , an interest in subsets of natural language , and thus a concern with some particular inventory of sentences of performance exclusive of any notion of the infinite inventory of sentences of competence  . 
There are two general directions in which this weakness is exhibited  , depending on the size of the natural language subset that is  in3 volved . With extremely large subsets , data orientation is mainly due to data in undation  , and computer processing substitutes for theory . 
In a system of this type , it is possible to perform a great deal of computer processing without knowing quite what it all means  . Content analysis may be attempted by statistical techniques  , but if the definition of the statistical word is not correlated with an actual word stem--or more relex rantly  , with a concept which may be represented in natura l language text by a number of different words and phrases -- then all that has really been performed is a frequency count of unique character strings  . The actual process of content analysis remains to be per-formed  . 
Another variety of data-orientation weakness involves extremely small subsets of natural language  . In this case , the defect consists in the testing of the or ies on very limited amounts of data--of ten  0nly   3In this context , a large subset , is defined as the entire information store in a particular system for process lng-- say  , scientific mater lals--where the data base consists of over  100  , 000 documents . 
1 4 ? on the very sample from which the theory was originally derived  . 
Claims for the generality of techniques der ived by such means must thus be viewed with a certain amount of skepticism  . Unfortunately , many of the more interesting activities in automated language pro-Z  . Z On the other hand , there are the weaknesses of the opposite perspective  , which is characterized by a preoccupation with theory  , counter-examples , and the infinite set of sentences of a speaker Ws competence  . The deficiencies of this approach become apparent in considering a few passages from Katz  , excerpted from a polemic between Katz and the philosophers Quine and Wilson  . 
Referring to a paper in which Quine criticizes Carnap's treatment of analyticity  , Katz supports Qulne's criticism of Carnap , stating that the Katz-Fodor theory does not require " such ad hoc devices as meaning postulates and semantic rules " to characterize an analytic sentence but rather defines it as " a sentence whose semantically interpreted underlying phrase marker  ( generated by the optimal grammar for the language  ) is such that every semantic marking in 4It is interesting to note in passing that as imilar cirticism has frequently been leveled at traditional linguistic descriptions by linguists espousing the generative approach  . According to this criticism , the descriptive linguist suffers from an exaggerate dependence on his " corpus "-- the body of linguistic material constitut ing his database  . 
IH is description of the language -- info rmal terms  , his theory of the language -- is thus a descr iption of the corpus  , and its validity is a function of the adequacy of the corpus as a representative sample of the language  . 
1 5 the reading for its predicate also occurs in the reading for its subject "  ( Katz ,  1967) . Katz thus defines " S is analytic for L " in terms of the o-retical constructs for which he claims universality  ; he further states that for each language , " for each L 1 that is a possible value of " L " , it is possible to differentiate the ana lytic from the nonanalytic sentences in L  1 o . u the basis of predictions that follow f rom this definition in con-ju : ct  ;  . ,, . ~ with the semantic descriptions of the sentences in L  1 provided by the ,   . Irammar of LI " (1968) . 
UnfortuJ~ . ately , the impact of Kat~s arguments is substantial l y reduced by the fact that--although there exists a definition of analyticity which has been postulated by Katz in terms of the theoretical constructs " underlying phrase marker  , "" semantic interpretation , "" reading , "" subject of , " etc .   , -- there exists no grammar for any Lltop rovide the semantic descriptions of L  1 which must be conjoined with Katz's def inition to provide for the differentia tion of analytic from non-analytic sentences  . 
Moreover , if Katz were to state that he had actually produced a grammar of some L  1 complete with semantic descriptions and presumably capable of generating the set of sentences of a speaker's competence in L  1  , no one could prove that this was or was not an empty claim  . Katz himself has affirmed the necessity of behavioral tests as a means of val-id a ting the empirical adequacy of his theoret ical formulations  ( Katz 1967 ,  1968) . However , previous attempts to investigate various syntac-tic phenomena through behavioral experiments have not been spectacul-arly successful  , and since the investigation of semantic phenomena of L  1 appears impossible . 
This difficulty derives from tw ~ sources  , one of which involves the nature of meaning , and the ~ ther , the present state of knowledge about linguis tic performance  , or speech behavior . 
The semantic problem lies in the fact that a great deal of meaning is situationally der ived  ; the physical and soci ~ cultural situation to a considerable extent controls the semant ic interpretation of sentences  . In the narrow sense , the c : ~ neep to faphysical and sociocul-tu ral context can be limited to those situat ions which are participated in by a majori ty of the speakers of the language : say  , a school , a city . 
an airport . In the broader sense , however , physical and s ~ ci : ~ cultural context in c ludes such factors as the entire history of an interaction between two persons--ino ther words  , all the occasions on which they have in teracted and the content of those instances of interaction  . Without such information , an ro~er interpretation of innuen does , jokes , allusions , and so forth , would not be possible . Also , in the sense of an interaction between persons , the context is dynamic ; it grows from the inception of the interact i onto its conclusion  . 
Thus , the speech event is actually performed in an environ-ment consisting of the entire range of physical and s ~ ciocultural phenomena which are relevant to its in terp retation  . For this reason , semantic interpretation presents problems of considerable magnitude  , some of which may be inherently in soluble . 

Setting the semantic problem aside for the moment  ,  -  . we consider the second source of difficul tyen countered in attempting to validate a grammar of L  1 through behavioral testing : the present lack of an adequate theory of performance  , or speech behavior . A grammar is a m~del of a speaker V sinnate capac ity  , and not of the ways he uses this capacity t ~ produce and understand sentences  . Although experi . -ments suggest the psychological reality of some features of the struc-tural descr ipti  , ns generated by the competence model org rammar  ( Fodor and Garrett 1967 )  , a speaker demonstrates his competence thr ~ ughh is ~ erformance  , and the relation between a speaker ls competence and his performance has yet to be explicated  . Assuming that a speaker of L 1 will produce and understand only sentences for which the grammar of L  1 can supply structural descriptions , the problem is reduced to determining how the speaker behaves in terms of the struc-tura l description  , which is not trivial to begin with . 
However , reintroducing the semantic problem d is cussed above  , it is clear that the explication of perfo rmance involves specification of " the speaker Js behavior in composing and in terp reting sentences with respect not only to s tructural descriptions  , but also to the total envir-onment of the speech event  . Thus speakers can and do process sentences which the grammar is not capable of generating  ; in other words , the relation between the sentences of competence and those of perform-ance is n~t ~ ne of simple inclusion  . As noted by Kasher ( 1967 ) and developed in detail by Watt ( 1968 )  , there are certain features of the sentences of performance which cannot be replicated in a comvetence model--these include those wh ich are derived in some way from the deletabi lity  ; the sentences of performance are character i zed by dele-tions which are not recoverable from the immediate linguistic context  . 
but must be supplied from the physical and soci ~ cultural environment  . 
Unfortunately , formal grammars tend t ~ be based on isola ted examples ~ f the performance of the lingu istic investigator  , rather than on spontaneous sneech . This practice has the disadvantage of ef fectively elim-inating examples of speech which depend for their interpretation on the total environment of the speech ex:ent  . For instance , the cryptic statement IISumber Five once " is not mysterious at a race track  , where the numerous deletions are recovered f rom the environment  ( the SZW in window of a thorough bredrace track ) to provide something like the following : ( a ) ' ~ I would like to wager two dollars of the five dollars in my hand that lhehorse which is starting at Post Position Firswil lw in then extrace  .   , iBecause the sentences of performance are la rgely context-dependent  , and because there is as yet no explication of how speakers behave in terms of structura l descriptions -- let alone in terms of the total en-vironment of the speech event  , it is apparent that the majority of sentences produced by speakers of L  1 could not be generated by the gram-r ~ ar of L 1  . Thus , a grammar of Ll--assuming the existence of such -- could not be validated by behavior a ltests  , and there would be essen-
Itially no way of relating the sentences actually performed by speakers of L  1 to th ) sespecified by the grammar . It is therefore approuriate to inquire what such a grammar might be good for  . 

From the data-oriented point of viewitis c learly inadequate  , because it does not deal with the sentences ac tually produced by speakers of the language  ; from the theory-oriented point of view it is also unsatisfactory  , since it is incomplete . Yet , because of the improbability of explicat ing the total environment as defined above of the speech event  , there is little hope that a complete semant ic theory will ever be developed  , and full understanding of how a speaker uses the competence which the grammar represents is not likely to be acquired in the foreseeab le future  . It therefore seems worthwhile to consider some concepts and strategies which might serve as working hypotheses and provide at leas t an interir ~  . 
solution to problems of the theories of mean ing and speech behavior  . 
Z .   3 One concept which might prove useful in this regard is that of " semantic equivalence "  . Returning to the context-dependent example of race track parlance presented above  , it is clear that given the physical envi ronment of the track  , past experience in that environment , and other relevant socio cultural phenomena  , the speaker of American English accepts " Number Five once " as in some way equivalent o the explicit propositi  , n presented in a . The two examples belong to a set of sentences which might be described as " semantically equivalent perfor-mances " for the purposes of this presentation  . These sentences are thus defined on the assumpt i on that speakers of American English would judge them to function as semantic equiva lents in the appropriate environment provlded that the speakers were knowledgeable about the particular environment  , either vicariously or through personal experi -" I want to bettwo dollars on Number Five  . t ' " I want Number Five once . "" Give meatwo dollar bet on the Number F ive horse  . "" Put two bucks on Five . "" Two on Number Five .   v0 Note that some of these sentences would be judged syntactically dev-iant by speakers whose experience does not include partic ipation in the milieu of a race track  . Moreover , the majority of the sentences would be judged semantically deviant in a non-betting envi ronment  . Those sentences which would be judged semant ically appropriate in other en-vi ronments  , however , derive their appropriateness not from member-ship in the set presented above  , but from membership in some other equivalence set which is semantically appropriate for the given en-vironment  . For example , " Two on Number Five " might also be used in an airport  ; but in this case , it would belong to an equivalence set in-c luding the following sentences  , among others : " I want two seats on Flight Number Five  , which leaves Great Falls at 6:05 a . m . and arrives in Salt Lake City at 8:49 a . m . " " Give metwo tickets on the flight that leaves here at  6:05 a . m . "" I want two seats on Number Five to Salt Lake City  . ~ u " Two tickets on the next flight to Sal t'LakeCity  , please . ' ~ In considering the notion of equivalence set as a possible working hypothesis  , a few operating difficulties should be noted  . One such since it must include all there levant features of the physical and so ciocul tural environment  . A second problem consists in defining a p-p ropriate equivalence sets for more abstract contexts  , where the notion of equivalence is more diff icult to specify than in the examples presented above  . 
However , this notion -- which defines sets of in s tances of behavior in terms of their funct ion as semantic equivalents in particular phy-sical and socioculturalen vi ronments -- is useful for two reasons  . In the first place , it provides a means for dealing systematic a lly with the elusive concepts of speech behav ior and situationally derived meaning  . Secondly , the notion of an equivalence set provides an approximate definition of a relations in the sense of symbolic logic j and is thus a means of approaching a formalism in an induct iveway  . 
The difficulties which in here in the expl ication of meaning and of speech behavior make it rather unlikely that such theories will springfully developed from the brow of some linguistician  . Therefore , if complete explication of meaning and speech behavior is possible at all jit would seem more likely to be achieved by working from the explicit to the in explicit than conversely  . 
Accordingly , it is suggested that a reasonable approach to problems of the theories of meaning and of speech behavior would be the construc-tion of an experimental model for analysis of natural language in terms of sets of semant ically equivalent performances as defined above  . The initial model would be developed from a database consisting of sentences would thus represent a restricted subset of the natural language  . The environment selected for the original model might be a race track  , an airport , a market , or some other type of structured situation , in order to reduce problems of defining semantically equivalent sets of sentences  . 
Successive versions of the model would be capable of processing mater-ials of inc reasing complexity with respect to contextua l variables -- e  , g . 
the various subsets of " present-day American English " represented in 
Ku~era and Francis 1967).
Assuming a restricted automatic thesaurus and a database in machine-readable form  , a first cut at equivalence sets could be provided by separ-atelists sorted in ternally by number of thesaurus group as s ignments  ) of sentences containing words or phrases from the same thesaurus groups  , and words and phrases from the same group as we llas more general or more specific g roups  . These lists could then be studied in detai l to isolate potential equivalence sets  . The elements of the basic member or defin iens of each set would be identified in the course of this study  , and the set membership validated by behavior a ltests  , which would also serve as a means of elic iting add it i ~ a almembers of the set not represented in the database  . 
The final step in construction of the model consists in represent-ing the definiens in the notation of formal logic  , and representing the other members of the set in terms of the definiens  . Analysis of a sentence presented to the model is thus accomplished through a decision procedure for membership in a particular equivalence set  , by association
Z 3 with a particular definiens or its converse  . 
3  . 0 The proposed mode l is p resented as an approx imate solution to problems of theory and data orientation  . It overcomes the respec-tive weaknesses of the two approaches  ( see Sections Z . 1 and 2 . Z by providing a means of arriving at theories of meaning and speech be-haviorth rough exploitation of databases which are subsets of an at-ural language containing instances of speech behavior used in parti cular physical and so cioculturalen vi ronments  . Moreover , the concept of equivalence set provides a data defined approximation of the theoretica l notion of a relation  , in the sense of symbolic logic . This is of par-ticular interest because symbolic logic has been used as a system of semantic representation both in computer p rocessing of natural lan-guage data  ( Montgomery 1969 , especially question-answering systems ) and in linguistics ( McCawley 1969 ) o Some convergence of linguistic and computational viewpoints is thus already in evidence  . If progress toward the explication of natura l language and the operations involved in p rocessing it  ( whether by menor machines ~ is to continue , linguistic science and automated language processing must increasingly share theories and data  , objectives and methods . 

BIBLIOGRAPHY
BOBROW , DANIELG . ; FRASER , J . BRUCE . A phonological rule tester . Communications of the ACM , II:II ( November 1968) 766-77 Z . 
BOHNERT , HERBERTG . ; BACKER , PAULO . Automatic English-to-logic translation in a simplified model  . A study in the logic of grammar . 
Final report , 1961-1966 . IBM Watson Research Center , Yorktown Heights , N . Y . , March \] 966, 117 p . ( AD-637227) . 
BRINER , L . L . : CARNEY , G . J . SYNTRAN/360 , a natural language processing system for preparing text references and retrieving text information  . IBM Corp . , Gaithersburg , Md .  , 1968 . ( Preprint ) CHAPIN , PAULG . On the syntax of word-derivation in English . 
IVIITRE Corp . , Bedford , Mass . , September 1967, 191 p . ( Information system language studies , no . 16) ( MTP-68) ( MITRE Project 1117) EARL , LOISL . Automatic determination of parts of speech of English words  . Mechanical Translation and Computational Linguistics  , Vol . 
I0, nos . 3 and 4, September and December , 1967 . pp .  53-67 . 
FOD OR , J , A ,; GARRETT , M . Some reflections on competence and performance . In : Lyons , J . ; Wales , R . J . , eds . Psycholinguistics papers . Chicago . 1967, p . \]35-154 FRIED MAN , JOY CE . A computer system for writing and testing transformational grammars  . Final report . Standord University , Department of Computer Science . Stanford , Calif . , September 1968 . 
14 p . ( CS-I09)
GARVIN , PAULL . Simulation and analysis of intelligent behavior . 
Preprint for Wenner-Gren Symposium on Cognitive Studies and Artificial Intelligence Research  , University of Chicago , March Z-8 ,  1969 . 

GARVIN , PAULL . The place of heuristics in the fulcrum approach to machine translation  . Lingua . Zl (1968) 162-182 . 
GROSS , LOUISN . A computer program for testing grammars online . 
MITRE Corp ., Bedford , Mass ., July 1968, 63p.
GROSS , LOUISN . ; WALKER , DONALDE . Online computer aids for research in linguistics . To appear in Proceedings of the IFIP Congress , Edinburgh ,  1968 . North Holland Publishing Co . , Amsterdam . In press . 
HAYS , DAVIDG . Readings in automatic language processing . 
American Elsev~er , New York , 1966.202p.
KASHER , ASA . Data-retrieval by computer : a critical survey  . In : Kochen , Manfred , ed . The growth of knowledge : Readings on organization and retrieval of information  . Wiley , New York , 1967 . pp .  292 . 

KATZ , JERROLDJ . Some remarks on Quine on analyticity . Journal of Philosophy , 64 ( February 1967) 35-5 Z . 
KATZ , JERROLDJ . Unpalatable recipes for buttering parsnips . 
Journal of Philosophy , 65:2January 1968) 2944.
KAY , MARTIN . The computer system to aid the linguistic field worker  . 
Presented at the annual symposium of the Interamer ican Program on Linguistics and Language Teaching  , Sao Paolo , Brazil , January 914 ,  1969 . 
KAY , MARTIN . Experiments with a powerful parser . RAND Memo ~ randum RM-5452-PR , the RAND Corporation , Santa Monica , California , 
October 1967.28p.
KOCHEN , MANFRED . Automatic quest lon-answering of English-like questions about simple diagrams  . Journal of the Association for Computing Machinery  , 16:1 ( January 1969) 26-48 ( AD-670545) KU~ERA , HENRY ; FRANCIS , W . NELSON . Computational nalysis of present-day American English  . Brown University Press , Providence,
R . I ., 1967, 424p.
KUNO , SU SUMO . The predictive analyzer and a path elimination technique  . In David G . Hays , Readings in automatic language processing . 
American Elsevier , New York , 1966 . pp .  83-106 . 
LONDE , DAVE b . ; SGHOENE , WILLIAMJ . TGT : Transformational grammar tester . In : AFIPS conference proceedings , vol . 32,1968 Spring Joint Computer Conference . Thompson , Washington , D . C . , p .  385-~93 . 
LUHN , H . P . Keyword-ln-Context index for technical li terature  ( KWIC Index )  . Report no . RG 127 , International Business Machines Corporation , Yorktown Heights , Newyork ,  1959 . 16 p . 
MCCAWLEY , JAMESD . Semantic representation . Preprint for Wenner-Gren Symposium on Cognitive Studies and Artificial Intelli-gence Research  , University of Chicago , March 28 ,  1969 . 30 p . 
MONTGOMERY , CHRISTINEA . Automated language processing . In Annual Review of Information Science and Technology  , vol . 4, Carlos A . Cuadra , ed . Encyclopedia Britannica , Inc . , Chicago . ( In press ) . 
RAMO-WOOLDRIDGE , a Division of Thompson Ramo Wooldridge , Inc . 
Machine translation studies of semantic techniques  . ( AF30 (60Z)-Z036) Technical Report No . 1 to Rome Air Development Center , Griffiss AFB , New York . Los Angeles , California , 22 February 1960 . 142 p . 
ROSENBAUM , PETERS . Specification and utilization of at rans for-mational grammar  . Scientific report no . 2, October 1966-September 1967 . IBM Watson Research Center , Yorktown Heights , N . Y . , October 1967, 272 p . ( AFCRL-68-0070) ( AD-667800) STEVENS , MARYELIZABETH . Automatic indexing : a state-of-the-ar t report  . N'BS Monograph 91 , National Bureau of Standards , U . S . 
Department of Commerce , March 30, 1965. Z20p.
UHLENBECK , E . M . The study of the so-called exotic languages and general linguistics  . Lingua 9, 1960 . pp .  417-34 . 
WATT , W . C . Habitability . American Documentation , 19:3(July 1968) 338-351 . 
WILKS , YORICK . Computable semantic derivations . Systems Devel-opment Corp . , Santa Monica , Calif . 15 January 1968, 160 p . ( SP-3017)
