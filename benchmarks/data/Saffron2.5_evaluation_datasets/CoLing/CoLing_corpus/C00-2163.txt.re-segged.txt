A Comparison of Alignment Models for Stati stical Machine 
Translation
Franz Josef Och and Hermann Ney
Lehrstuhl fiir Informatik VI , Comlmter Science Department
RWTH Aachen-University of Technology
D-52056 Aachen , Germany
och , ney ~ informatik . ruth-aachen , de
Abstract
In this paper , wet ) resent and compare various align-nmnt models for statistical machine translation  . We propose to measure tile quality of an aligmnent model using the quality of the Viterbi alignment comt  ) ared to a manually-produced alignment and describe a refined mmotation scheme to produce suitable reference alignments  . We also con , p are the impact of different ; alignment models on tile translation quality of a statistical machine translation system  . 
1 Introduction
In statistical machine translation ( SMT ) it is neces-sm'y to model the translation probability Pr  ( flaIc ~ )  . 
Here . fi '= f denote stile ( 15' ench ) source and e = e denotes the ( English ) target string . Most SMT models ( Brown et al , 1993; Vogel et al ,  1996 ) try to model word-to-word corresl ) ondences between source and target words using an alignment nmpl  ) ing from sourcel ) osition j to target position i = aj . 
We can rewrite timt ) robal ) ility Pr(fille ~) t)3 , introducing the ' hidden ' alignments ai1:=al . . . aj . . . a . l(ajC0, .   .   .  , / ) :
Pr(f ~ lel ) = ~ Pr(f i ', a ~ le) . 1 ? j-1I ~= EHPr ( fj ' ajlfi'-"al'el ) q , j = l To allow fbr French words wl fich do not directly correspond to any English word an artificial ' empty ' word  c0 is added to the target sentence at position i=0  . 
The different alignment models we present provide different de coInt  ) ositions of Pr ( f~ , a ~ le () . An alignnlent 5~ for which holds a ~= argmax Pr ( fi ' , a'l'\[eI ) at for a specific model is called Viterbial ignment of " this model  . 
In this paper we will describe extensions to tile Hidden Markov alignment model froln  ( Vogel et al ,  1 . 996 ) and compare tlmse to Models 1-4 of ( Brown et al ,  1993) . Wet ) roI ) ose to measure the quality of an alignment n lodel using the quality of tlle Viterbi alignment compared to a manually-produced alignment  . This has the advantage that once having produced a reference alignlnent  , the evaluation itself can be performed automatically  . In addition , it results in a very precise and relia . bl evaluation criterion which is well suited to assess various design decisions in modeling and training of statistical alignment models  . 
It , is wellknown that manually pertbrming a word aligmnent is a COlnplicated and ambiguous task  ( Melamed ,  1998) . Therefore , to produce tlle reference alignment we use a relined annotation scheme which reduces the complications and mn biguities occurring in the immual construction of a word alignment  . As we use tile alignment models for machine translation purposes  , we also evahlate the resulting translation quality of different n lodels  . 
2 Alignment with HMM
In the Hidden Markov alignment model we assume a first-order dependence for tim aligmnents aj and that the translation probability depends Olfly on aj and not Oil  ( tj_l:-~-'el ) = p ( ajl . j - , ,Z)p(J~l %) Pr(fj , ( glf ~' , %  , Later , we will describe a refinement with a dependence one  , ,j_ , iu the alignment model . Putting everything together , we have the following basic
HMM-based modeh . 1*'(flJl~I ) = ~ II\[~,(-jla ~ . -,, z ) . p ( fjl % ) \]  ( 1 ) at j = l with the alignment I ) robability p ( ili' , I ) and the translation probability p(fle ) . To find a Viterbi aligninent for the HMM-based model we resort to dynamic progralnming  ( Vogel et al ,  1996) . 
The training of tlmHMM is done by the EM -algorithm  . In the E-step the lexical and alignment c(flc ; f , e ) = EP"(alf'e ) ~5(f , f ~) 5 ( e , c ~) ai , j ,  . : ( ill ' , z ; f , e ) = E /' , ' ( air , e ) aj ) aj In the M-step the lexicon and translation probabilities are : p  ( fle ) o < ~- ~ c ( fle ; f('~) , e(~)) a , ( Vogel et el . , 1996 ) use the maximum a pllroxima-tion where only the Viterbi alignlnent  ) at his used to collect counts . We used the Baron-Welch-algorithm ( Baum ,  1972 ) to train the model parameters in out'ext ) eriments . The ret/y it is possible to t ) erti ) rm an efl-iciellt training using ; all aligmnents . 
To make the alignlnenl ; t ) arameters in do , 1 ) en ( lent t ' ronlabsolute wordi ) ositions we assmne that the alignment i ) robabilities p ( i \[ i' , I ) ( lel ) end only Oil the jmnp width ( i-i') . Using a set of nonnegative t ) arameters c ( i - i ' )   , we can write the alignment probabilities ill the fl  ) rm : ~' ( i - i ' )   ( 2 ) p ( i li ' , I ) = c ( , ,:" - i ' ) This form ensures that foreadlword posilion it , i ' = 1 ,   . . . , I , the aligmnent probat ) ilities at is ( yth ( , normalization constraint . 
Extension : refined aligmnent model
The count table e(i-i ') has only 2 . 1  . . . . . . . . . -1 entries . This might be suitable for small corpora , but fi ) r large corpora it is possil ) le to make a more re-fine ( 1 model of Pr ( aj ~ i-Ii-IJi , %  , c'~) . Est)ecially , we analyzed the effect of a det ) endence on c , b_~or . fj . 
As a dependence on all English words wouht result illahuge mm flmr of aligmnent  1  ) arameters we use as ( Brownetel . , 1993 ) equivalence classes G overtlle English and the French words  . Here G is a mallping of words to (: lasses . This real ) ping is trained au-tonm tically using a modification of the method de-scrilled ill  ( Kneser and Ney ,  1991 . ) . We use 50 classes in our exlmriments . The most general form of alignment distribution that we consider in the ItMM is p  ( aj-a . +_, la (%), G(f ~), h-
Extension : empty word
In the original formulation of the HMM alignment model there ix no'empty ' word which generates Fren  ( : h words having no directly aligned English word . A direct in chlsion of a neml/ty wor ( till the HMM model by adding all coasin ( Brown et al ,  1 . 993 ) is not 1 ) ossit ) leif we want to model the junlp distances i-i  '  , as the I ) osition i = 0 of time mt ) ty word is chosen arbitrarily . Therefore , to introduce the eml ) ty word we extend the HMM network by I empty words ci +  1  . '2 I The English word ci has a colrest ) on dingeml ) ty word el + I . The I ) osition of the eml ) ty word encodes the previously visited English word  . 
We enforce the following constraints for the transitions in the HMM network  ( i _ < I , i'_<I ): p(i+I li' , I ) = pff . 5(i,i')V ( i + Ill'+I , I ) = JJ . 5 ( i , i ') p(ili'+I , 1) = p(iIi ' , 1 ) The parameter pff is the 1 ) robability of a transition to the emt ) ty word . In our extleriments we set pIl = 0 . 2 . 
Smoothing
For at ) etter estimation of infrequent events we introduce the following smoothing of alignment  ) rob-abilities : in our exlleriments we use ( t = 0 . 4 . 
3 Model 1 and Model 2 l~cl ) lacing the ( l(~ , t ) endence on a j-lint he HMM alignment mo ( MI ) yadel ) endence on j , we olltain a model wl fich ( : anlie seen as a zero-order Hid ( l ( m-Markov Model which is similar to Model 21 ) rot ) ose ( t t / y ( Brown et al ,  1993) . Assmning amfiform alignment prol ) ability p ( i l j , I ) = 1/1 , we obtain Model 1 . 
Assuming that the dominating factor in the alignment model of Model  2 is the distance relative to the diagonal line of the  ( j , i ) plane the too ( telp ( il j , I ) can 1) estructured as t bllows ( Vogel et al ,  1996):  , '( i - , -(3) v(i l j , 5 = Ei , = tr ( ' i'l  This model will be referred to as diagonal-oriented 
Model 2.
4 Model 3 and Model 4
Model : The fertility models of ( Brown et el . , 1993) explicitly model the probability l , (? lc ) that the English word c ~ is aligned to 4 , , = E
J \] ~ rench words.

Model 3 of ( Brown et al ,  1993 ) is a zero-order alignment model like Model 2 including in addition fertility paranmters . Model 4 of ( Brown et al ,  1993 ) is also a first-order alignment model ( along the source positions ) like the HMM , trot includes also fertilities . In Model 4 the alignment position j of an English word depends on the alignment position of tile previous English word  ( with nonzer of ertility ) j ' . It models a jump distance j-j' ( for consecutive English words ) while in the HMM a jump distance i-i ' ( for consecutive French words ) is modeled . Tilefull description of Model 4 ( Brown et al , 1993) is rather complica . ted as there have to be considered tile cases that English words have fertility larger than one and that English words have fertility zero  . 
For training of Model 3 and Model 4 , we use an extension of the program GlZA ( A1-Onaizan et al ,  1999) . Since there is no efficient way in these models to avoid tile explicit summation over all alignments in the EM-algorithin  , the counts are collected only over a subset of promising alignments  . It is not known an efficient algorithm to compute the Viterbi alignment for the Models  3 and 4  . Therefore , the Viterbi alignment is comlmted only approximately using the method described in  ( Brown et al ,  1993) . 
The models 14 are trained in succession with the tinal parameter values of one model serving as the starting point t br the next  . 
A special problein in Model 3 and Model 4 concerns the deficiency of tile model . This results in problems in reestimation of the parameter which describes the fertility of the empty word  . In nor-real EM-training , this parameter is steadily decreasing , producing too many aligmnents with tile empty word  . Therefore we set tile prot ) ability for aligning a source word with tile emt ) ty word at a suitably chosen constant value . 
As in tile HMM we easily can extend the dependencies in the alignment model of Model  4 easily using the word class of the previous English word E = G  ( ci , ) , or the word class of the French word
F = G(Ij ) ( Brown et al , 1993).
5 Including a Manual Dictionary
We propose here a simple method to make use of a bilingual dictionary as an additional knowledge source in the training process by extending the training corpus with the dictionary entries  . Thereby , the dictionary is used already in EM-training and can improve not only the alignment fox " words which are in the dictionary but indirectly also for other words  . 
The additional sentences in the training cortms are weighted with a factor Fl~x during the EM -training of the lexicon probabilities  . 
We assign tile dictionary entries which really cooccur in the training corpus a high weight Fle  . ~ . and the remaining entries avex ' ylow weight . In our experiments we use Flex = 10 for the cooccurring dictionary entries which is equivalent to adding every dictionary entry ten times to the training cortms  . 
6 The Alignment Template System
The statistical machine translation method descri -bedin  ( Och et al ,  1999 ) is based on a wordaligned traiifing cor Ims and thereby makes use of single-word based alignment models  . Tile key element of tiffs apt/roach are the alignment emplates which are pairs of phrases together with an alignment between the words within tile phrases  . The advantage of the alignment emplate approach over word based statistical translation models is that word context and local reorderings are explicitly taken into account  . We typically observe that this approach produces better translations than the single-word based models  . The alignment templates are automatically trailmd using a parallel trailxing corlms  . For more information about the alignment template approach see  ( Ochetat . , 1999) . 
7 Results
We present results on the Verbmobil Task which is a speech translation task ill the donm in of appoint-nxent scheduling  , travel planning , and hotel reservation ( Wahlster ,  1993) . 
We measure the quality of tile al ) oveinentioned aligmnent models with x ' espect to alignment quality and translation quality  . 
To obtain a refereuce aligmnent for evaluating alignlnent quality  , we manually aligned about 1 . 4 percent of onr training corpus . We allowed the humans whopert brmed the alignment ospecify two different kinds of alignments : an S  ( sure ) a , lignment which is used for alignmelxts which are unambiguously and a P  ( possible ) alignment which is used for alignments which might or might not exist  . The P relation is used especially to align words within idiomatic expressions  , free translations , and missing function words . It is guaranteed that SCP . Figure 1 shows all example of a manually aligned sentence with S and P relations  . The hunxan-annotated alignment does not prefer rely translation direction and lnay therefore contain many-to-one and one-to-many relationships  . Them motation has been performed by two annotators  , producing sets $1 ,  1~ , S2 , P2 . 
Tile reference aliglunent is produced by forming the intersection of the sure aligmnents  ( S=$1 rqS2 ) and the ration of the possible at ignumnts ( P = P1UP'2 )  . 
T im quality of an alignment A = ( j , aj ) is measured using the following alignment error rate : 
AER(S,P;A ) = 1-IAoSl+IAoPl
IAI+IS lat .   .   .   .   .   .   .   .   .  \ [ \ ]  .   .   .   .   .   .   . V1 V1 . 
leave .   .   .   .   .   .   . \[---' l\[-"~" .   .   .   .   .   .   . liE\] . 
let .   .   .   .   .   .   . Cll-1"e .   .   .   .   .   .  ?  .   .   .   . 
say . . . . . ? . . . .
would "? . . . . . . .
T . . . . ? . . . . .
then "" ? . . . . . . .
? \ [ \ ]  .   .   .   .   .   .   .   . oyes ? .   .   .   .   .   .   .   .   .   . 
-rn I:I'13 O??-~t~1
J ~ o
Figure i : Exm nple of a manually annotated alignment with sure  ( filled dots ) and possible commotions . 
Obviously , if we colnp are the sure alignnlents of every sitigle annotator with the reference a  . ligmnent we obtain an AEI of zero percent . 
~\[ if l ) lel . : Cort ) us characteristics for alignment quality experiments  . 
Train Sentei H : ( is


Dictionary Entries

Test Sentences

German IEnglish 34   446   329   625  /  343   076   5   936  \]  3   505   4   183   4   533 I 5   324 Tal ) le 1 shows the characteristics of training and test corlms used in the alignment quality ext  ) eri-inents . The test cortms for these ext ) eriments ( not for the translation exl ) eriments ) is 1 ) art of the training corpus . 
Table 2 shows the aligmnent quality of different alignment models  . Here the alignment models of IIMM and Model 4 do not include a dependence on word classes . We conclude that more sophisticated alignment l nodels are crtlcialt brgood alignment quality  . Consistently , the use of a first-order aligmnent model , modeling a nelnpty word and fertilities result in better alignments  . Interestingly , the si in l ) ler HMM aligninent model out t ) erforms Model 3 which shows the importance of first-order alignment models  . The best t ) er formanee is achieved with Model 4 . The improvement by using a dictionary is small eomI  ) ared to the effect of using 1 ) etter a . lignmellt models . We see a significant dill'erence in alignment quality if we exchange source and target languages  . This is due to the restriction in all alignment models that a source language word can  1  ) e aligned to at most one target language word . If German is source language the t'requelltly occurring German word coml  ) ounds , camlot be aligned correctly , as they typically correspond to two or more
English words.
WaNe3 shows the effect of including a det ) endence on word classes in the aligmnent model of It MM or Model  4  . By using word classes the results can be Table 3: Eft'cot of including a det ) endence on word classes in the aligmnent model . 
AER\[%\]
Det ) endencies - IIMMI Model 4 no 8 . 0 6 . 5 source 7 . 5 6 . 0 target 7 . 1 6 . 1 source ? target 7 . 6 6 . 1 improved by 0 . 9% when using the ItMM and by 0 . 5% when using Model 4 . 
For the translation experiments we used a different training and an ill detmndent test corpus  ( Table 4 )  . 
Table 4: Corlms characteristics for translation ( tual-it ;  . ), exlmriments . 

S ~ e , t



Sell tellees

PP ( trigram LM)
I German English 7940 4673 (40 . 3) 28 . 8 For tile evMuation of the translation quality we used the automatically comlmtable Word Error Rate  ( WE ll . ) and the Subjective Sentence Error Rate ( SSEll , ) ( Niefien et al ,  2000) . The WEll , corre-spomls to the edit distance t ) etween the produced translation and one t ) redefined reference translation . 
To obtain the SSER the translations are classified by human experts into a small number of quality classes ranging from " l  ) ertbet " to " at ) solutely wrong " . In comparison to the WEll , , this criterion is more mean-ingflfl , but it is also very exl ) ensive to measure . The translations are produced by the aligmnent template system mentioned in the previou section  . 

Table 2: Alignment error rate ( AER\[%\] ) of dit l~rent alignment models t br the translations directions English into German  ( German words have fertilities ) and German into English . 
English -+ German German - ~ English
Dictionary no yes no yes
Empty Wordnol Yes yes noly es
Model 1 17.8 16.9 16.0 22.9 21.7 20.3
Model 2 12.8 12.5 11.7 17.5 17.1 15.7
Model2(diag ) 11.8 10.5 9.8 16.4 15.1 13.3
Model 3 10.5 9.3 8.5 15.7 14.5 12.1
HMM 10.5 9.2 8.0 14.1 12.9 11.5
Model 49.0 7.8 6.5 14.0 12.5 10.8
Table 5: Effect of different alignment models on translation quality  . 
Alignlnent Model in Training WER\[%\]SSER\[%\]
Model 1 49.8 22.2
HMM 47.7 19.3
Model 4 48.6 16.8
The results are shown in Table 5 . We see a clear improvement in translation quality as measured by SSER whereas WER is in ore or less the same for all models  . The imwovement is due to better lexicons and better alignment templates extracted from the resulting aliglunents  . 
8 Conclusion
We have evaluated vm ' ious statistical alignment models by conlparing the Viterbi alignment of the model with a human-made alignment  . We have shown that by using in ore sophisticated models the quality of the alignments improves ignificantly  . Further improvements in producing better alignments are expected from using the HMM alignment model to bootstrap the fertility models  , fronlmaking use of cognates , and from statistic allignment models that are based on word groups rather than single words  . 

This article has been partially supported as part of the Verbmobil project  ( contract n mnber01IV 701T 4 ) by the German Federal Ministry of Education , Science , Research and Technology . 

Y . A1-Onaizan , J . Cur\]n , M . Jahr , K . Knight , J . Lafferty , I . D . Melamed , F . a . Och , D . Purdy , N . A . 
Smith , and D . Yarowsky .  1999 . Statistical in a-chine translation , final report , JHU workshop . 
http://www . clsp . jhu .   edu/ws99/proj ects/mt/final_report/mr-final-report , ps . 
L . E . Baum .  1972 . An Inequality and Associated Maximization Technique in Statistical Estimation for Probabilistie Functions of Markov Processes  . 
In equalities , 3:18.
P . F . Brown , S . A . Della Pietra , V . J . Della Pietra , and R . L . Mercer .  1993 . The mathenlatics of sta-tistical machine trml slation : Parameter estimation  . Computational Linguistics , 19(2):263-311 . 
R . Kneser and H . Ney .  1991 . Forming Word Classes by Statistical Clustering for Statistical Langm~ge Modelling  . In 1 . Quantitative Linguistics Conf . 
I . D . Melamed .  1998 . Manual mmotation of translational equivalence : The Blinker project  . Technical
Report 9807, IRCS.
S . Niegen , F . J . () ch , G . Leusch , and H . Ney . 
2000 . An evaluation tool \]' or machine translation : Fast evaluation for mt research  . In Proceedings of the Second International Conference on Language Resources and Evaluation  , pages 3945 , Athens , 
Greece , MayJune.
F . J . Och , C . Tilhnalm , mid H . Ney .  1999 . Improved alignment models for statistical machine translation  . In In Prec . of the Joint SIGDAT Co~?on Empirical Methods in Natural Language Processing and Very La Tye Corpora  , pages 2028 , University of Marylmld , College Park , MD , USA , June . 
S . Vogel , H . Ney , and C . Tilhnann .  1996 . HMM-based word alignment in statistical translation  . 
In COLING'96: The 16th Int . Conf . on Computational Linguistics , pages 836-841 , Copenhagen , 

W . Wahlster .  1993 . Verbmobil : Translation of face-to-falogs . In P~vc . of the MT Summit IV , pages 127-135 , Kobe , Jat ) an . 

