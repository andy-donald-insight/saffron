EBER HARD PA USE
ACLASS OF TRANS FOK MATION AL
RECOGNITION GRAMMARS
1 . PET mCK considers transformational grammars ( T-grammars ) of
a special * form which essentially have the properties described by N  . 
CHOMSKY (1965).
a ) The base grammar is contextfree . One recursive element S is distinguished . The base trees in general have the forms sor in linear notation Consequently each base tree consists of a finite set of subtrees or kernel trees each of the form S  ( @ $1 (  . . . )@ ) where x is a string Overi I shall assume the reader somewhat familiar with the theory of generative transformational grammar  . :-:46EBERHARDPAUSEV -@ . ~ A string in which maximally n kernel trees stand one above the other has the depth  ( of embedding ) n . 
b ) Transformational rules ( T-rules ) are singulary or binary . The singulary ones operate on a subtree , called constituent tree , whose initial node has the label St and whose terminal string contains no sentence boundary symbol @  . The binary T-rules work on a constit-uent tree and the kernel tree  ( called the matrix tree ) which dominates it directly . 
c ) The transformational rules are linearly ordered and are applied cyclically in this order from bottom to top  . That is , a cycle is completed after the singulary and binary rules have been applied to a constituent tree  .   ( In the process the sentence boundary symbols of this subtree are removed  )  . 
Now Petrick defines a class of T-grammars generating recursive languages by first stating the condition of the " recoverability of deletions "  . That is , only ? terminal node or a subtree which is identical with another subtree that remains in the resulting tree after the application of the T -rule can be deleted  . He states further condition so that there is an upper bound for the depth of embedding of a base tree underlying a sentence of the grammar  . In his case that means , that a base tree that underlies a sentence of length n can have maximally depth n  . 
A recognition grammar for a T-grammar of this class is constructed by Petrick roughly in the following way : Transformational derivations are generated  , and starting with the trees that constitute these derivation she determines contextfree rules  , socalled " auxiliary rules " , reflecting the structure of the derived trees . By means of these auxiliary rules a given string can be attributed as much structure as is necessary for applying the " inverse " T-rules  . If the string is a sentence of the given grammar one can obtain the underlying base tree  ( s ) by this procedure . 
2 . The following problems arise in connection with the class of transformational grammars defined by Petrick : a  ) To my knowledge there is no finite procedure to determine whether a given T-grammar has the defining properties of the class or not  , which represents a solution to the problem whether there exists V means the entire vocabulary  , Y  ~ the terminal , ~ the nonterminal vocabulary of the base . 
ACLASSOFTRANS FOR MATION ALRECOGNITION GRAMMARS 47 in principle some recognition procedure for the grammar  . There also remains the question of whether this problem is recursively solvable at all  . 
b ) In general there is no finite number of auxiliary rules implied by the derivations of a T-grammar of this form  . For that reason Pe-trick can only construct auxiliary rules for finitely many derivations  . 
These rules can then be used only for the analysis of sentences whose underlying base trees have maximally depth n  ( for a given n ) whose length is therefore smaller than or equal to n  . For sentences containing more than n words a new recognition grammar has to be construc-ted  . There may also be sentences of length smaller than or equalt on which cannot even be analysed because the depth of their underlying base trees exceeds the specified boundary  . 
c ) The set of trees accepted by the auxiliary rules is larger than the one generated by the original grammar  . As a consequence spurious trees result at the end of the analysis process and these must be discard -ed by an additional synthesis phase  . 
These problem suggest hat it might be reasonable to look at the following requirements when using a grammar for the recognition of sentences  . It should belong to a ( nontrivial ) class of grammar having the following properties : a  ) All generated languages are recursive . 
b ) It is decidable whether a given grammar belongs to the class or not  . 
c ) There should be a general procedure which cost ructs for each grammar of this type a practicable recognition grammar  . That is , analysis with such a grammar should be as efficient as possible  . 
I do not wish to claim that these requirements have all been met for the type of grammar that I worked with  .   8 But I want to show now what results I obtained with a different approach to the matter and what difficulties one obviously faces when dealing with transform-ational recognition  . 
3 . In what follows I will first of all illustrate a general method by which the set of base trees  , given by some arbitrary contextfree grammar can be decomposed into a finite set of kernel trees  . This construction serves ( in section 4 ) as a basis for the definition of a class of T -grammars that generate recursive languages  . A hierarchy of types of 3 For detail seemy dissertation ( E . PAUSE , 1972) . 
48 EBERHARD PAUSE grammar will be characterized , included in this class , such that for each type membership of a given grammar is decidable  . Section 5 deals with recognition grammars . 
The whole matter is discussed with respect oT -grammars of a generalized form : a  ) Every contextfree grammar can serve as base grammar  . 
b ) Transformational rules are unordered . There is no distinction between singulary and binary rules  . 4 We may assume that a contextfree grammar P-~ ( V , Y , , R , S ) where V-lg = ~ , the sentence symbol S in ~ , is reduced and has a standard form . sThat is , R contains only rules of the form ( I ) S~~ , ( II)A~D1 . . . D , , n _> 2 , A in ~ , D  ~ inl~-S , otherwise , if S~~ . is in Re(III)A ~ a , ain \] g . 
There is no loss of generality on considering only contextfree grammars of this form since for every contextfree grammar an equivalent standard form grammar could effectively be given  . 
A recursion sequence ( of length k ) of a standard form contextfree grammar P is defined as a sequence of rules from R 
Ao~uxAxvx
A1 ~ u ~ A2v ~
Ak . 1-~u , Akv , where A ~ is in ~ . u , , v , in V * , vAo = A , and A ~: ~ Ai ( for i ?: j ) otherwise . Each symbol Ai occuring in the sequence is a recursive lement in P  . Since there are only finitely many elements in ? every recursion  4 In E . PA USE ( 1972 ) I also investigate T-grammars that c?ntain generalized transformations of roughly the same form as discussed by N  . CHOMSK'Y (1957) . Concerning the form of the T-rules I refer the reader to the sample grammar in section  4  . 
For detail see for instance S . GrNSBURG (1966).
e ~. denotes the empty string.
V * denotes the free semigroup ( generated by V).
Itf ~
ACLASSOFTRANS FOR MATION ALRECOGNITION GRAMMARS ~   49 /sequence of P can maximally have length m ~-/ O /s and since ! R is a finite set  , the number of recursion sequences of P is finite . : Two recursion sequences are equivalent if they could be ideni ~ ified by cyclical permutation of the rules  . This leads to the concept o ~: the equivalence class or recursion cycle of a recursion sequence  . Exactly k recursion sequence of length k which could be transformed into one another : constitute a recursion cycle  . Therefore each recursion cycle is uniquely determined by specifying one recursion sequence belonging to it  . 
Now all recursion cycles of a standard form contextfree grammar P =  ( V , ~ g , R , S ) , where t = /0/ , could be enumerated in the following way : Let us consider all sequences of rules from R of the forms = Aou  , AI , , ri ~ : A1 -> u2A~v ~ r ~ , : Ak~l-->uk X , v , where r ~ , is in R , As in ? and Aj ~ A , ~( for-j~m ) , then after maximally k_~t steps either a ) X , is in ~ gorb ) X , is equal to Aj for some j smaller than k . 
In case ( b ) the sequence of rules r ii . . . . . ri , , noted as above , obviously represents some recursion sequence of P  . Clearly , there are only finite-ly many sequences as given above in P and it is easy to see that in all these sequences  ( which correspond in some sense to all derivations in P of length smaller than or equal to t  ) there is to be found at least one representative of each recursion cycle of P  . 
No we quivalent recursion sequences are identified until there re--mains exacdy one representative for each cycle  . Furthermore , one arbitrary recursive lement of each recursion cycle is chosen  . Let C1, . . . . Cs  be the set of these symbols each of which is called a base symbol of P together with the sentence symbol S  . Then consider all occurences of base symbols on the right hand side of the rules of Pasterminal elements which could not further be expanded by some rule  . Constructs / ~/ denotes the cardinality of ~ . 
, tk 50 tEBERI-IARD PAUSE taeriv ~ tion trees by taking the set Z = G  . . . . . C , uS ) as start symbols : you will obtain a finite set of trees B with terminal string either in ~  , ~" or in I guZ * having the following properties : a  ) every base tree corresponding to some sentence derivation in : P can be uniquely decomposed into elements of B  ( in the obvious man . ner) . 
b ) If elements of B are embedded into one another by identifying each time some initial node with some terminal node having as label the same base symbol the resulting tree is always a subtree of a tree as s ?  , ciated with some sentence derivation in P . 
Hence the elements of B are kernel trees in almost he same sense as are those occuring in base trees considered by Petrick  . I will not give here a proof of my main statements but will illustrate them by an example  . 
Let P = ( V , Z , R , S ) where Ig~-(a , d , f , i , j , n , v , x , y , =( C , D , E , F , F ' , H , LJ , K , M , N , Q , and R = S~CF'EI , F ' ~ X Y , C  ~ MJ , M~KI-t , K  ~ DF , H~QH , Q-~-AF , H~NF , A  ~ a , D ~ d , F ~ f , E  ~ v , I ~ i , J  ~ j , N ~ n , X  ~ x , Y ~ y . 
TakenPas base grammar the base trees in general have the forms c ~ 
M--~ui
Y\?\&Y\\\!i\[df af .   .   . af , , f . Ix\]'vi Now all rule sequences of length smaller than or equal to  12  = \[~\[ , ( of the form (~_)) , starting with the sentence symbol S are ACL ASS OF TRANS FOR MATION ALRECOGNITION GRAMMARS  51   ( 1 ) S :- . CF'EI(2) S--+CF'EI(3) S---' . CF'EI
C-+MJC-+MJC-+MJ
M~KHM ~ KH"M ~ KH
K ~ DF H --> QH H~NF
D ~ d ( or F-+f ) N ~ n ( or F ~ f ( 4 ) S-->CF'EI ( 5 ) S-+CF'EI ( 6 ) S-+CF'EI
C~MJF'-+XYE~v(orI~i)
J ~ j X ~ x ( or Y ~ y)
It can be immediately observed that there is only one recursion sequence  ; namely the rule H~QH in ( 2 ) which represent simultaneously the only recursion cycle of P  . Now H , S is taken as the set of base symbols of P . Further following the given construction finally the kernel trees  ( a )  , ( b ) ,   ( c ) result : ( a ) S ( C ( M ( K ( D ( d ) F ( f )   ) H ) J ( j )   ) F ' ( X ( x ) Y ( y )   ) E ( v ) I ( i )   )   ( b ) H ( Q ( A ( a ) F ( f )   ) H )  "  ( c ) H ( N ( n ) F ( f )   ) It is easy to see that for instance taking the embedding sequence 
H/q . .."
AFQHtt/Xa)AFiI , , f there is a tree associated with some sentence generation in P such that the sequence is a subtree of it  . From the construction equally follows that each base tree can be decomposed into elements of B in the opposite manner as contructing trees using the members of B  . 
Since there are three kernel trees in ~ embedded into one another we speak in exactly the same sense as above of the depth of a tree  . 
Thus 0~ has depth 3 . In the following we will also call every tree built up only of kernel trees a complex  . 
52 ~ B~vAus ~4 . In this section , I will first deal with some relevant implications of the foregoing construction and introduce the required terminology  . 
Suppose , some T-rule , r of a T-grammar G is applied to a base tree 0~: Let ~ be the resulting tree . Then ~ can also be decomposed into kernel trees , taking as cutting-points again those nodes labeled with base symbols  . Some of the resulting kernel trees will perhaps have been deleted or will have been modified by the application of ' r  . In the latter case we get derived kernel trees . In any case , each tree that could be generated in G can be decomposed into  ( base or derived ) kernel trees . I will call the set of all those kernel trees , thus obtained of all trees occuring in the derivations of G  , the decomposition set B * of G . 
Suppose further that there are k terms in the structural description of -: which have been related to k nodes of  0~  . Now the sequence of all and only those kernel trees  ( from left to right ) in which these nodes lie will be called the characteristic domain of ' r  . 
The complex which is the smallest subtree of 0c such that it contains exactly the nodes , characterized by % ( see the dashed line ) is said to be a minimal complex of -~ ( rel : / tive to 0 t )  . 
Obviously only the minimal complex of a T-rule ( relative to some tree ) is relevant for the observation of the structural change produced by the rule  , because all structure beyond it ( above and below in the tree ) is not directly concerned . To examine certain properties of transformational derivations  , it could therefore be sufficient to construct derivations consisting of such complexes rather than of the whole trees  . 
This can be done nearly in the following way : a ) Relative to all T-rules of G , at first all possible minimal complexes of depth 1 are built up of the elements of B . The set of kernel trees , obtained after the decomposition of the complexes resulting from ACLASS OF TRANS FOR MATION AL RECOGNITION GRAMMARS  53 the application of the rules , yields together with set B set B1 , 1 . This procedure can be repeated for minimal complexes over B of depth  2  ,  3 ,   . . . which gives the sets Bz , 1, B3, , , . . . 
b ) Now continuations of the foregoing derivations ( of length 1 ) could be constructed taking as basis each time the corresponding set Bi  , z , Bi , z .   .   .   . According to the resulting derivations of length 2  ,  3 ,   . . . the sets B1,2, B1,3, . . . , B ~, z , B ~, 3 . . . . of kernel trees will be obtained . 
By this procedure , which I cannot describe in detail here , the decomposition set B * of G can be enumerated as the union set of the sets Bp  , q(p , q > 1) . 
For our purposes , it is relevant o consider what happens with some kernel tree yor some node of a tree in the course of a derivation : performing some transformation  , y is either deleted or there are some derived kernel trees  ( at least one ) in the resulting tree which are the images of y , either identical or modified by the rule . Again the associated images of these in the following derived tree  ( which are also images of y ) could be identified , and so on . This procedure could be carried out along the whole derivation starting with an element of B  , called the origin , in the base tree . The same is valid for a node in a tree . It is either deleted or copied or only transferred by applying a T-rule  , where in the latter cases it has some images ( at least one ) in the resulting tree 13 called the occurrences of the node in 13  . 
Now let us consider some derivation in G . It starts with a base tree ~ , and we are looking at some kernel tree y that is a subtree of  0c   , and some derived tree 13 occurring in the derivation : a ) All occurrences of terminal nodes of y in 13 , labeled with terminal elements , Or occurrences of nodes in 13 , inserted in y or an image of it by T-rules introducing new terminals  ( or morphemes )  , are called the rest-nodes of y in ~ . 
b ) Each terminal node of y labeled with a base symbol is called a base-node  , and all occurrences of such nodes of y in 13 are said to be base-nodes of y in 13  . 
After these remarks we are ready to outline the class of structurally bounded T-grammars  . For a grammar G to be structurally bounded in particular the following conditions must hold : a  ) The condition of recoverability of deletions . 
b ) If a rest-node of some kernel tree . ~ in the characteristic domain of a T-rule $ relative to a tree  13 is deleted , the number of rest-no-des of 0~ in 13 must be greater than 1  . 
c ) If a subtree y is deleted by performing " ~ , then each base-node $4 EBERHARDPAUSE occurring in % and lying in some kernel tree of ~  , may be an occurrence or a base-node of the origin of y  . 
d ) Let the number of terminal nodes of the origin of a kernel tree occurring in the characteristic domain of ": bem  . Then this subtree , following its changes under the rules up to ~ by considering its " trace " along its images in the given derivation  , may not have occur-red more than m1 times in the characteristic domain of-r . 
For this class of grammars , say G1 , the following theorem can be proved : ( A ) If G is structurally bounded , then the length of each sentence derived from some base tree ~ of depth n cannot be shorter than n  , n the member of kernel trees contained in 0~ could maximally be ~ ; k~-1i = l(where k is a constant depending on G ) . 
Suppose G is structurally bounded , and m is the maximum of subtrees which could be deleted on account of their identity by one T -rule of G  . Lei . j be the number of T-rules of G , and r the length of the longesterminal string of members in the set B of G  , then let j . m . r = k . 
n ~---1: If 0~ is a base tree of depth 1 , then every tree ~ that could be derived from 0c may contain a rest-node of e . Thus the length of the terminal string of ~ is greater than or equal to n =  1  , and the number of kernel trees in ~ is 1 = ~ k ~ - ~ . 
Now suppose ( A ) is true for all trees of depth h smaller than n ( h greater than 1 )  . 
Let ~ be a base tree of depth n . Without loss of generality , we may assume that 0~ has the form , where ~ is some kernel ~ tree , Y 1 ,   . .- , ~' ~ subtrees maximally of depth n-l , and let us further assume thats does not exceed k  . Then k1 of these subtrees could be deleted maximally . Some rest node of ~ in a tree \[~ derived from 0~ must also survive . From this and by induction it ACLASSOF TRANSFOR MATION ALRECOGNITION GRAMMARS  55 follows that the length of the terminal string of  \[3 must be greater or equal to n1  +  1 = n . Hence the number of kernel trees in ~ has as maximum value k  . ( ~ kiq)+1 = 2fkiq . 
i = 1i = l
Obviously a decision procedure for the language generated by some grammar of  G1 could be given . However , it can be proved that there is no recursive solution to the problem whether in general a given grammar belongs to  G1 or not . 
In the sequel I shall go on to sketch some properties of grammars in  G1 for which this problem is decidable . 
In considering the construc . tion of the decomposition set B * of a given T -grammar G and of the corresponding derivations of complexes  ( see page 52 and 53 )  , there might exist some point where the following requirements are fulfilled : Suppose that all derivation starting with complexes up to a certain depth p have been constructed  , that the length of these derivations has as yet reached some q  , and that they are " structurally bound-ed " . Suppose further that by continuing the construction for some p'greater than pnone w derivation  ( beginning with complexes over /3 ) could be started . Then G is structurally bounded and is said to be in class Gp  , ~ , if the given derivations become periodical . That is , if they have the same continuations in the q + 1th step as in the q-n + 1th step ( for some n )  , in the q+2-th step as in the q-n+2-th step ,   . . . , in step q+n as in step q , and so on . This in particular means , that at those points in the derivations always the same minimal complexes appear periodically  , and that therefore the decomposition set B * of
G is finite . 9
Since there are grammars for which these properties hold for arbitrary_p and q  , there exists an infinite hierarchy G2 of types of grammars Gp , q(p , q > 1) in G1 . For each p and q obviously membership of a given grammar in Gp  , q could be determined in a finite number of " steps  . 
The following example should help in understanding these brief remarks : Let G be a T-grammar with base given by the  ab0ve-mention-ed contextfree grammar P , and let G contain the following obligatory T -rules : There is great evidence in the assumption that every < ~ kernel sentence * of a sentence of a natural anguage can undergo only a finite number of transformations  . 
V 56EBILRHAI~DPAUSE rl : ( ~ , y , v , i ) 1 ,  2 ,  3 -+ 3 ,  2 , 01?" r2:(~ , j , x , i , v ) 1 ,  2 ,  3 ,  4 -+ 0 , 1 ,  3 , 4% : ( K , H , F' , v ) 1 , 2 , 3 , 4 -+ l + 3 , 2  , 0  , 4" r4:(d , f , F ' , ~ e ) 1 ,  2 ,  3  ,  -+ 1  , 3  , 3  , " rs:(~ , F ' , F ' , n , f ,  ~)1 ,  2 ,  3 ,  4 , -+ l ,  0 ,  3 , 2" re:(M , F' , F ' , Q , H ,  ~) 1 ,  2 ,  3 ,  4 ,  ~ 1  , 3  , 3  , " rT:(M , a , f , F ' , ~) 1 ,  2 ,  3 -+ 1 , 3  , 3 Now the following derivations could be constructed : ~  ) o ~= S ( C ( M ( K ( D ( d ) F ( f ) )H ) J ( j ) )F' , (X ( x ) Y ( y ) )E ( v ) I ( i ) ) ~ S ( C ( M ( K ( D ( d ) F ( f ) )H ) J ( j ) ) F ( X ( x ) Y ( O ) E ( v ) ) S ( C ( M ( K ( D ( d ) V ( f! ) n ) ) F ( X ( j ) Y ( i ) )E ( v ) )  ( ~ o ~ , o ~ 5 S ( C ( M ( K ( D ( d ) F ( X ( f ) Y ( i ) )H ) ) ) E ( v ) ) _~ = S ( C ( M ( K ( D ( d ) F ( F' ( X ( j ) Y ( i ) ) ) )F' ( X ( j ) Y ( i ) )H ) E ( V ) )y ~ ___>t ?:: -~ S ( C ( M ( yIF' ( X ( j ) Y ( i ) )H ( N ( n ) F ( f ) ) ) )E ( v ) ) == S ( C ( M ( y~H ( N ( n ) F ( F ' ( X ( j ) Y ( i ) ) ) ) ) )E ( v ) ) I ~ t ~ s = S ( C ( M ( y ~ F ' ( X ( j ) Y ( i ) )H ( Q ( A ( a ) F ( I ) )H ) ) ) E ( v ) )  ( ~= S ( C ( M ( y~H ( Q ( A ( a ) F ( f ) ) F ( X ( j ) Y ( i ) )H ) ) ) E ( v ) ) -- t ~ ) ~ o = S ( C ( M ( y~H ( Q ( A ( a ) F ( F' ( X ( j ) Y ( i ) ) ) )F ( X ( j ) Y ( i ) )H ) ) ) E ( v ) )
Y ~ --~ l~1 ~= H ( y2F' ( X ( j ) Y ( i ) )H ( N ( n ) F ( f ) ) ) ? ~= H ( y~H ( N ( n ) F' ( X ( j ) Y ( i ) ) ) ) ) I ~3 = H ( y2F' ( X ( j ) Y ( i ) )H ( Q ( A ( a ) F ( f ) ) H ) )  ( ~ ) o ~4 = H ( y~H ( Q ( A ( a ) F ( f ) )F' ( X~j ) Y ( i ) ) H ) ) Q ) o ~ S--H ( y~H ( Q ( A ( a ) F ( F' ( X~ ) Y ( i ) ) ) )F' ( X ( j ) Y ( i ) ) H ) ) There is no difficulty in verifying that the continuations which could follow always start with the minimal complexes ~ u and  ~18  . G is obviously structurally bounded and lies in G2  , 6 . The following graph representing the order in the possible applications of the T-rules of G makes perhaps the periodicity of the derivations more transparent :  10 The symbol Af means almost the same as variables like X in the usual notation of 

n ( ~ ) means that he T-rule i is applied to the foregoing tree  . The arrow \['-~ denotes some continuation f the derivation where it leads out  . 
ACLASSOFTRANS FOR MATION ALRECOGNITION GRAMMARS 57  ~  '~6-  - - -  .   .  -~ 7 . J__~~/56-"--~7-~65 . As indicated above , there is a recognition grammar for each grammar G of the class Gm  , namely G itself , using the general decision procedure for the language generated by G  . This is , however , obviously not an efficient procedure but represents some general way of analysis by synthesis  . 
I will now sketch a way of constructing recognition grammars for the class of grammars considered here which in most cases are more practicable  . This will mainly be done by examining our sample grammar  . 
I will finish with the discussion of some problems involved in the described procedure  . 
Let us consider the T-grammar G given above : Analysis should start with some given string over V  , say " djinjiv " . Now by reversing the generation process , the last transformation that has been applied in generating this sentence  , " rs:(~ , F ' , F ' , n , f ~) 1 ,  2 ,  3 ,  4 --+ 1 ,  0 ,  3 ,  2 , has now to be performed first . The inverse transformation ":5-1 ( which can mechanically be constructed from ~5 ) would have the structural description ( M , F ' , n , F ' ,  ~ , 1) . However , there are no rules to attribute some structure to the given string such that there were nodes labeled with F which could be related to the corresponding terms in this inverse structural description  . Base rules cannot do this work because the base structure has been modified by the applica fon of 

Now by inspecting the derivations of complexes a term A of a structural description  , could be ' expanded ' in this way : the sequence of labels of the nodes which are dominated by a node related to A  , such that the string of these labels is accepted by the inverse base rules  , 1 ~ is substituted for A in . . This will be done , if possible ( see below ) and necessary , for each term and each T-rule relative to the different rees to which it has been applied in all derivations  . In general , for each T-rule more than one'expanded'rule results  . 
,s For each base rule of the form A -+ x , the rule x-~A is the inverse . 
58 ~ B~.m~DI'AUS ~.
Since there are only finitely many different derived  ( minimal ) complexes in the derivations of a grammar G of Gp , q , one obtains a grammar G ' ( called reversible ) containing a finite set of expanded T-rules . G'is by construction equivalent to G . A recognition grammar G is obtained from G ' by computing the corresponding inverseT-rules  . Then analysis will be performed by ' intermixed parsing '  , that is , by alternating the application of base rules and T-rules  .   ~3 In order to preven the expanded T-rules being applicable at some point in a derivation  , where the original rules could not have been applied  , auxiliary symbols are inserted in the rules to control their correct application  . 
To illustrate these remarks , let us look at the expanded inverse
T-rules of our sample grammar G : ? i1:(~ , i , v ) 1 , 2-+ y ,  2+1  . r ~:(~, jd3,~, i , ~)) 1, 2, 3, 4-+1, x , 3, 4 . r ~ :( K,j , d , , ~, i , H , v)l, . . . ,6-+ l ,  0 , O , O ,  5  , 2+d3 , x+4+6"r\]~:(d , j , dsi , i , j , d52 , i , ~) t -~"( d , j , d  ~ , i , j , c\[6 ~ , i , ~) t1 . . . . .  7~ 1 , 0 , O , f ,  5 , d4x ,  7 ~742 ?  ,   ,  -~: (~ , j , i , n , j , i ,  ~) 1 ,  2 ,  3 ,  4 ,  5~1 , d5 , 1+2 , 4 + d 5 , 2+ +5+3 , o , f " ra ~ : ( ~ , j , i , Q , j , dT , ~ , i , H , ~) l . . . . ,7 ~ 1, de . 1+2,4+d6,~++6+3,0,0,0,7-~ .  (?~ , a , j , ds , x , i , j , ds , 2 , i , ~)l " rT"~i (? ~ , a , j , d 6 , ~ , i , j , de , ~ , i , ?~) 1 ,   . . . , 7---~1 , O , O , f ,  5 , d~x ,   7   ~'72 ? The construction should be clear in considering the original rules and the derivations given above  . The symbols d ~, , ~ denote auxiliary symbols . 
For the rules % and " rv two expanded rules have been constructed be--cause "  r4 and " r7 precede the application of either the rule " r6 or xe . 
The recognition procedure will be illustrated by the analysis of the sample sentence " dj in jiv  "  . Let t ~ ~ i , ttR denote the appliCation of the rule-rior of the inverse base rules respectively  . Notice that the inverse T-rules are not true inverse rules  , since they apply to sequences of trees , so ~ alled " terminal rest-trees " x3 It can be shown that the set of context-semitive languages i properly included in the set of languages generated by grammars of G  ,  . Furthermore , for each context-sensi-tive grammar are versible T-grammar can effectively be given  . 
ACLASSOFTRANS FOR MATION ALRECOGNITION GRAMMARS dj in jivdjds  , 1ij d ~ , 2 in fv df jd 4 , ~ infv
DF
IIdfjd , , ~

NF
II inf v
KH(Y (", : df , , . fjg ~. ~ iv
DFNF
IIIIdfnfjxiv/\/\dfn./'jxvvi
S/\/\~/\KIDFNFlX'YI\[
DIIII . IIIId . fnfj xyvi
In addition the following condition is important : the final derived tree of the input string  ( with respect o the generation process ) could be reconstructed in the course of the analysis process  . It must then be checked if some obligatory T-rule of G'is applicable to this tree  . If this is not the case , the input string is a sentence of the grammar . 
The problems which arise out of the foregoing construction are the following : a  ) There are cases in which no reversible grammar G ' for a given grammar G could be constructed  , because , for instance , some auxiliary symbol could not be removed in the course of a sentence derivation  . 
b ) Another source of not obtaining a reversible grammar is  , that there could occur subtrees of arbitrary depth which have to be considered for the exp = ms ion of some  . term in a structural description . 
In this case a partially reversible grammar could be constructed  . The recognition grammar then works with base rules  , T-rules , and so called " predictions " associated to the T -rules  .   14 Analysis with these grammars will without doubt be much less efficient  . 
The advantage in using reversible grammars appears to be a  ) that there is no additional synthesis phase necessary when the analysis tep has been carried out  , b ) that the different possible paths which must be pursued in parsing a sentence could be reduced to a minimum  , in using auxiliary symbols whenever it is possible  , c ) and that the recognition grammar could effectively be given ' for the whole set of generated sentences  . 1514 Seemy dissertation ( E . PA us E , 1972) . 
15 At page 54 , Theorem ( A ) , the number k must correctly be taken as the maximum number of base symbols occurring in a kernel tree of the set B  . 

N . CHOMSKY , Syntactic Structures , The
Hague , 1957.
N . CHOMSKY , Aspects of the Theory of
Syntax , Cambridge ( Mass .), 1965.
S . GINs BuaC , The mathematical Theory of ContextFree Languages , New York ,  1966 . 
S . GINSBt ~ G , B . P . ~ a ~ TEE , A mathematical model of transformational grammars  , in < ~ Information and Control , , XV (1969) , pp .  297-334 . 
A . KRATZER , E.PAUSE , A.g . STECHOW,
E in fiihrung in Theorie und Anwendung der generative n Syntax  , Frankfurt a . 
M ., 1973.
G . H . MATTHEWS , Analysis by Synthesis in the Light of recent developments in the theory of grammar  , in < ~ Ky be mefica ~ , 
I(1965), pp . 271-280.
E . PA USE , Transformations syntaxen , generative Kraft-Entscheid barkeit-Analyse , 
Diss ., Konstanz , 1972.
ST . R . . PETRICK , A Recognition Procedure for Transformational Grammars  , Ph . D . 
Thesis , M.I.T ., 1965.

