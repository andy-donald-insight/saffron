Semantic Network Array Processor as a
Massively Parallel Computing Platform for 
High Performance and Large-Scale Natural Language Processing * 
Hiroaki Kitano
Center for Machine Translation
Carnegie Mellon University
Pittsburgh , PA 15213 U.S.A.

This paper demonstrates the utility of the Semantic Network Array Processor  ( SNAP ) as a massively parallel platform for high performance and largescale natural language processing systems  . SNAP is an experimental massively parallel machine which is dedicated to  , but not limited to , the natural language processing us-hag semantic networks  . In designing the SNAP , we have investigated various natural language processing systems and theories to determine the scope of the hardware support and a set of micro -coded instructions to be provided  . As a re-suit , SNAP employs an extended marker-passing model and a dynamically modi-fiable network model  . A set of primitive instruction simicro-coded to directly support a parallel marker-passing  , bit-operations , numeric operations , network modifications , and other essential functions for natural language processing  . This paper demonstrates the utility of SNAP for various paradigms of natural anguage processing  . We have discovered that the SNAP provides milliseconds or microsec-onds performance on several important ap-plicatiou such as the memory -based parsing and translation  , classific at lon-based parsing , and VLKB search . Also , we argue that there are numerous opportunities in the NLP community to take advantages of the comlmtational power of the SNAP  . 
1. Introduction
In order to accomplish the high-performance natural language processing  , we have designed a highly parallel machine called Semantic Network Array Processor  ( SNAP ) \[Lee and Moldovan ,  1990\] . The goal of our project is to develop and test the validity of the massively parallel machine for high performance and larg-scale natural anguage processing  . Thus , the architecture of the SNAP was determined reflecting extensive analysis of basic operations essential to the " This research is Bupported by the National Science Foundation under grant  MIP-9009111 and MIP-9009109  , and conducted as a part of IMPACT ( Internation MC on sortium for Massively Parallel Advanced Computing 

Dan Moldovan
Department of Electrical Engineering Systems
University of Southern California
Los Angeles , CA 90089-1115 U.S.A.
natural language processing . As a result of the investigation , we have decided to employ an extended marker -passing model and a dynamically modifiable network  . Also , a set of primitive instruction simicro-coded to directly support essential operations in natural language systems  . 
Several approach can be taken to use SNAP as a platform for natural anguage processing systems  . We can fully implement NLP system on SNAP , or we can speedup existing systems by implementing computationally expensive part on SNAP  . We have hnple-mented some of these approaches on SNAP  , mid obtained extremely high performance ( order of milliseconds for given tasks )  . 
In this paper , we describe the design philosophy and architecture of SNAP  , and present several approaches toward high performance natural anguage processing systems on SNAP  . 
2 . SNAPA rchitecture 2 . 1 . Design Philosophy of SNAP The Semantic Network Array Processor  ( SNAP ) is a highly parallel array processor fully optind zedt br semantic network processing with a marker-passing mechanism  . The fundermental design decisions arc ( 1 ) a semantic network as a knowledge representation scheme  , and ( 2 ) parallel marker-passing as an inference mechauism . 
First , the use of a semantic network as are presem tation scheme can be justified from the fact that most of the representation schemes of current AI and NLP theories  ( such as frame , feature structure , sort hierarchy , systemic hoice network , neural network , etc . ) can be mapped onto semantic networks . Also , tlmreare numbers of systems and models which directly use semantic networks\[Sown  ,  1991\] . 
Second , the use of marker-passing can be justified from several aspects  . Obviously , there are many AI and NLP models which use some form of marker-passing as the central computing principle  . For example , there are significant number of research being done on word sense disambiguation as scene in Waltz and Pollack  1985\] It endler ,  1988\] , \[ Hirst ,  1986 , \[Charniak ,  1983\] , \[ Tomabechi ,  1987 , etc . All of them assume passing of markers or values among nodes interconnected via some types of links  . There are studies to handle syntactic on-ACRES DE  COLING-92  . NANaXS , 2328 AO~"1992813 Paoc . ov COLING-92 . NAI , rVES , AUG . 2328,1992 tsmlttamtm 4~ettmmant NAP . 1 ~ Cam ~ oan@~a ? c . J ~ t~s s^p
Figure I: SNAP-1 Architecture straints using some type of networks which can be mapped onto semantic networks  . Recent studies on the Classification-Based Parsing\[Kasper  ,   1989\] and the Systemic Choice Network\[Carpenter and Pollard ~  1991\] assume hierarchical networks to represent var -ions linguistic constraints  , and the search on these networks can be done by marker-passing  . Also , there are more radical approaches to implement entire natural language systems using parallel marker-passing as seen in \[ N or vig  ,  1986\] , \[Riesbeck and Martin ,  1985\] , \[ Tomabechi ,  1987\] , and \[ Kitano ,  1991\] . There are , however , differences in types of information carried in each marker-passing model  . We will describe our design decisions later . 
As reported in \[ Evett , at . al . , 1990\] , however , serial machines are not suitable for such processing because it causes performance degradation as a size of semantic network increases  . There are clear needs for highly parallel machines  . The rest of this section provides a brief overview of the SNAP architecture  . 
2.2. The Architecture
SNAP consists of a processor array and an array controller  ( Figure 1 )  . The processor array has processing cells which contain the nodes and hnks of a semantic network  . The SNAP array consists of 160 processing elements each of which consists of a TMS320C30 DSP chip , local SRAM , etc . Each processing elements stores 1024 nodes which act as virtual processors . They are interconnected via a modified hypercube network  . The SNAP controller interfaces the SNAP array with a SUN  3/280 host and broadcasts instructions to control the operation of the array  . The instructions for the array are distributed through a global bus by the controller  . Propagation of markers and the execution of other instructions can be pro-ceased simultaneously  . 
2.3. Parallel Marker-Passing
In the SNAP , content of the marker are : (1) bit vector , (2) address , and ( 3 ) numeric value ( integer or floating point )  . In SNAP , the size of the marker is fixed . According to the classification i\[Blelloch ,  1986\] , our model is a kind of Finite Message Pass-ing . There are types of marker- , or message- , pa~ing that propagates feature structures ( or graphs ) ~ which are called Unbounded Message Passing . Although we have extended our marker-passing model from the traditional bit marker-passing to the complex marker-passing which carries bits  , address , and numeric values , we decided not to carry unbounded messages . 
This is because propagation of feature structures and heavy symbolic operations at each PE are not practical assumptions to make  , at least , on current massively parallel machines due to processor power  , memory capacity on each PE , and the communication bottleneck . Propagation of feature structures would impose serious hardware design problem since the size of the message is unbounded  , which means that the designer cannot be sure if the local memory size is sufficient or not until the machine actually runs some applications  . Also , PE a capable of performing operations to manipulate these messages  ( such as unification ) would be large in physical size which causes assembly problems when thousands of processors are to be assembled into one machine  . Since we decide not to support unbounded message passing  , we decide to support functionalities attained by the unbounded message passing by other mean such as sophisticated marker control rules  , dynamic network modifications , etc . 
2.4. Instruction Sets
A set of 30 high-level instructions specific to semantic network processing a reimplemented directly in hardware  . These include associative search , marker setting and propagation , logical/arithmetic operations involving markers , create and delete nodes and relations , and collect a list of nodes with a certain marker set  . Currently , the instruction set can be called from C language so that users can develop applications with an extended version of C language  . 
From the programming level , SNAP provides data-parallel programming environment similar to C * of the Connection Machine \] Thinking Machines Corp  . , 1989\] , but specialized for semantic network processing with marker passing  . 
Particularly important is the marker propagation rules  . Several marker propagation rules are provided to govern the movement of markers  . Marker propagation rules enables us to implement guided  , or constraint , marker passing as well as unguided marker passing  . This is done by specifying the type of links that markers can propagate  . The following are some of the propagation rules of SNAP : eSeq  ( rl , r  ~ ) : The Seq ( sequence ) propagation rule allows the marker to propagate throughrlonce then to r ~  . 
? Spread(rl , r2 ) : The Spread propagation rule allows the marker to travel through a chain of rl links and then r ~ links  . 
* Comb(rl , r  ~ ) : The Comb ( combine ) propagation rule allows the marker to propagate to all rl and r ~ links without limitation  . 
2.5. Knowledge Representation on SNAP
SNAP provides four knowledge representation elements : node  , link , node color and link value . These elements offer a wide range of knowledge representation schemes to be mapped on SNAP  . On SNAP ) a concept is represented by a node . A relation can be represented by either a node called relation node or AcrEs DE  COLING-92  , NANTES . 2328 AOt ) r1992814 PROC . OFCOLING-92, NANTES . AUG .  2328 . 1992 a link between two nodes . The node color indicates the type of node . For example , when representing USC is in Los Angeles and CW0 ie in Pittsbnrgh ~ we may assign a relation node for IN  . The IN node is shared by the two facts . In order to prevent the wrong interpretations such as USC in Pittsburgh and CSllin Lea Angeles  , we assigu IN  #I and IN#2 to two distinct IN relations , and group the two relation odes by a node color IN  . Each lhlk has assigned to it a link value which indicates the strength of interconcepts relations  . This link value supports probabilistic reasoning and connectionist-like processing  . These four basic elements allow SNAP to support virtually any kind of graphbased knowledge representation formalisms such as KL-ONE\[ Braehman and Schmolze  ,  1985\] , Conceptual Graphs \[ Sown ,  1984\] , KODIAK\[Wilensky ,  1987\] , etc . 
3. The MemoryBased Natural
Language Processing
Memory-baaed NLP is an idea of viewing NLP as a memory activity  . For example , parsing is considered as a memory o search process which identifie similar eases in the past from the memory  , and to provide interpretation based on the identified case  . It can be considered as an application of Memory -Baaedl ~  . ea-soning(MBR)\[Stm ~ fill and Waltz , 1986\] and Case-Based Reasoning ( CBR ) \[Riesbeck and Schank , 1989\] to NLP . This view ~ however , counters to traditional idea to view NLP as arl extensive rule application process to build up meaning representation  . Some models has been proposed in this direction , such as Direct Memory Access Parsing ( DMAP ) \[Riesbeck and Martin , 1985\] and q~DMDIALOO\[Kitano ,  1991\] . For arguments concerning superiority of the metnory-based approach over the traditional approach  , ace\[Nagao ,  1984\] , \[Riesbeck and Martin ,  1985\] , and \[ Sumit and \]\[ ida ,  1991\] . 
DMSNAP is a SNAP implementation of the ( I ) DMDIALOG speech-to-speech dialogue translation system which is based on  , in part , the memory-based approach . Naturally , it inherits basic ideas and mechanisms of the ~ DMDIALOG system such as a memory-based approach to natural language processing and parallel marker-passing  . Syntactic on straint network is introduced in DMSNAP whereas ODMDIAL OG has been assuming unification operation to handle linguistic processing  . 
DMSNAP consists of the nlemory network , syntactic constraint network , and markers to carry out inference . The memory network and the syntactic on-straint network are compiled from a set of grammar rules written for DMSNAP  . 
Memory Network on SNAP The major types of knowledge required for language translation in DM -SNAP are : a lexicon  , a conceptype hierarchy , concept sequences , and syntactic on straints . Among them , the syntactic constraints are represented in the syntactic on straint network  , and the rest of the knowledge is represented in the memory network  . The memory network consists of various types of nodes such as concept sequence class  ( CSC )  , lexical item node * ( LEX ) , concept nodes ( CC ) and others . Nodes are connected by a number of different links such as concept a hstraction links  ( ISA )  , expression links for both source language and target language  ( ENG and JPN )  , Role links ( ROLE ) , constraint links ( CON-STRAINT ) , contextual llnk ~ ( CONTEXT ) and others . A part of the menmry network is shown in Figure 2 . 
Markers The processing of natural anguage on a marker-propagation architectu requires the creation and movement of markers on the memory network  . 
The following types of markers are used : ( 1 ) A-Markers indicate activation of nodes . They propagate ttlrough ISA links upward , carry a pointer totile source of activation axtd a cost measure  ,   ( 2 ) P-Markers indicate the next possible nodes to be activated  . They are initially placed on the first element nodes of the CSGs  , and move through NEXT link where they collide with A-MARKERs attile element nodes  ,   ( 3 ) G-Markers indicate activation of nodes in tile target language  , They carry pointers to the lexi-eal node to he lexicalized  , and propagate througtl ISA links upward ,   ( 4 ) V-Markers indicate current state of the verbalization  . When a V-MARKER collides with the G-MARKER , the surface string ( which is specified by the pointer in the G -MARKER  ) is verbalized , (5) G-Markers indicate contextual priming . Nodes with C-MAItKERs are contextually primed . AC-MARKER moves from the designated contextual root node to other contextually relevant nodes through contextual links  , and ( 6 ) SC-Markers indicate active syntax con-attaints , and primed and/or inhibited nodes by currently active syntactic on straints  . It also carries pointer to specific nodes . There are some other mark-eraused for control process and tinting  ; they are not described here . 
The parsing algorithm is sinular to the shift -reduce parser excep that our algorithms handle ambiguities  , parallel processing of each hypothesis , and topdown predictions of possible next input symbol  . The generation algorithm implemented on SNAP is a version of the lexically guided bottom-up algorithm which is described in Kitano  1990\]  . Details of the algorithm is described in Kitano et  . al . , 1991b . 
DmSNAP can handle various linguistic l ) he nomena such as : lexical ambiguity , structural ambiguity , referencing ( pronoun referenee ~ definite noun reference , etc ) , control , and unbounde dependencies . Linguistically complex phenomena are handled using the syntactic constraint network  ( SCN )  . The SCN enables the DmSNAP to proces sentences involving unbounded dependencies  , controls without passing feature structures . Details of the SCN is described in \[ Kitano et . 
ah , 1991h\] . One notable feature of DmSNAP is its capability to parse and translate sentences in context  . 
In other words , DmSNAP can store results of previous sentences and resolve various levels of ambiguities using the contextual information  . Examples of sentences which DmSNAP can handle is shown below  . 
it should he noted that each example consists of a set of sentences  ( not a single sentence isolated from the context ) ill order to denm natrate he contextual processing capability of the DMSNAP  . 
ACRESDE COLING-92 , NANTES , 2328 Ao~r 19928 15 P Rec . OFCOLING-92, NANTES . AUO . 2328,1992;'~ln,~,nc . Nod . 
c-e.m ?- : ~ oq:'-co~-J
Figure 2: Part of Memory Network
Sentence Length Timeat ( words ) 10MHz ( .   .   .   .   . ) s2; He is at . . .  4 0 . 65 s3: He said that . . .  10 1 . 50 sS : Eric build . . . ' 5 0 . 55 s 6: Junt as found . . 6 1 . 00s 8: Juntae solved . . .  7 1 . 65
Table 1: Execution times for DmSNAP
Example IslJohn wanted to attend Collng-92.
m2 He is at the conference.
s3 He said that the quality of the paper is superb . 
Example II s4 Dan planned to develop a parallel processing computer  . 
s 5 Eric built a SNAP simulator.
s 6 Juntae found bugs in the simulator.
s 7 Dantried to persuade Eric to help Junta emodify the simulator  . 
s8 Juntae solved a problem with the simulator.
s 9It was the bug that Junta entioned.
These sentences in examples are not all the sentences which DMSNAP can handle  . Currently , DM-SNAP handles a substantial portion of the ATR conference registration domain  ( vocabulary 450 words , 329 sentences ) and sentences from other corpora . 
The following are examples of translation into Japanese generated by the DmSNAP for the first set of sentences  ( sl , s2 and s3 ) : tlJonhakoringu-92 nisankashitakatta . 
t2 Kate hak algin ii ru.
t3K are haron bunnos hitsuga subarns hlitoitta.
DMSNAP completes the parsing in the order of milliseconds  . Table 1 shows parsing time for some of the example sentences  . 
F3 gendermale number singular person 3rd

Igende , male\[numbv ~ singular person 3rd Figure 3: A part of a simple example of classification lattice  4  . Classification-Based Parsing Classification-Based Parsing is a new parsing model proposed in \[ Kasper  ,  1989\] . In the classification-based parsing , feature structures are indexed in the hierarchical network  , and an unifiability of two feature structures are tested by searching the Most Specific Subsumer  ( MSS )  . The unification , a computationally expensive operation which is the computational bottleneck of many parsing systems  , is replaced by search in the lattice of pre ~ indexed feature structures  . 
For example , in Figure 3 , the feature structure F3 is a result of successful unification of the feature structure  F1 and F2   ( F3 = F1tAF2 )  . All feature structures are pro-indexed in a lattice so that the unification is replaced by an intersection search in the lattice with complex indexing  . To carry out a search , first we set distinct markers on each feature structures  F1 and F2  . For example , set marker M1 on F1, and M2 on F2 . Then , markers M1 and M2 propagate upward in the lattice . M1 and M2 first coexist at F3 . 
The most simple program ( without disjunctions and conjunctions handling ) for this operation follows : sot_marker ( M 1 , ~t ); n ~_ marker(M2 , f2); propagate(M1 , M 1 , UP , I/P pSPREAD ); propagate(I(2 , M2 , UP , UP , SPREID ); marker_and ( M1 , M2j M3); propagate(M3 , re_trap , UP , UP , SPREAD ); cond_clear marker(m_tmp , M3); collect nodes ( M3); Of course , nodes for each feature structure may need to be searched from a set of features  , instead of direct marking . In such a case , a set of markers will be propagated from each node representing each feature  , and takes disjunction and conjunction at all nodes representing a feature structure root  . This operation can be data-parallel . 
There are several motivations to use classification-based parsing  , some of which are described in \[ Knsper ,  1989\] . The efficiency consideration is one of the major reasons for using classification-based parsing  . Since over 80% of parsing time has been consumed on unification operations  , replacing unification by a faster and functionally equivalent method would substantially benefit the overall performance of the system  . 
The classification-based parsing is efficient because  ( 1 ) it maximize structure sharing , (2) it utilizes indexing dependencies , and (3) it avoids redundant computations . However , these advantages of the classification-AcrEsDE COLING-92  , NANTES , 2328 hO'J'f 199281 fiPROC . OFCOLING-92, NANTES , AUG .  2328, 1992
Time ( uaec .) 7$??
Time(~see .) 320 4128 256

Figure 4: Retrieval Performance on Classification Network based parsing cannot be fully obtained if the model was implemented on the serial machine  . This is because a search on complex index lattice would be computationally expensive for serial machines  . Actually , the time-complexity of the sequential classification algorithm is O  ( Mn2 )  , and that of the retrieval algorithm is O(R , ,~JogM ) , where M is a number of concepts , n is an average number of property links per concept  , R ,   . c is an average number of role set relations for one concept  . We can , however , circumvent his problem by using SNAP . Theoretically , time-complexity of the classification on SNAP is O  ( loggo~ , M ) , and that of the parallel retrieval is O(F in Da . , + 17~) , where Fo~t is an average fanout ( average number of suh concepts for one concept )  , J ~ is an average fan-in ( average number of superconcept for one concept )  , and D . ~ . is an average depth of the concept hierarchy\[ Kiln and Moldovan  ,  1990\] . 
In our model , possible feature structures are precomputed and indexed using our classification algorithms  . While a large set of feature structures need to be stored and indexed  , SNAP provide sufficiently large memory/processor space to load an entire feature structure lattice  . It is analogous to the idea behind the memory -based parsing which pre-exp and all possible syntactic/semantic structures  . Here again , we see the conversion of tlme-complexity into space-complexity  . 
Figure 4 shows performance of retrieval of clas-sitleation lattice with varying fanout and size  . The clock cycle is 10 MH z . It demonstrates that we can attain micro-seconds response for each search  . Given the fact that the fastest unification algorithm  , even on the parallel machines , takes over few milliseconds per unification , the performance obtained in our experiment promises a significant improvement in parsing speed for many of the unification-baaed parsers by re~placing unification by classification -based approach  . 
5 . VLBK Search : Integration with the Knowledge -Based Machine q_?anslation Language processing is a knowledge-intensive process  . 
Knowledge-Based Machine Translation ( KBMT ) \[Goodman and Nirenberg ,   1991\] has been proposed and developed baaed on the assumption that intensive use of linguistic and world knowledge would providel figh quality automatic trmmlation  . 
One of the central knowledge sources of the KBMT is the ontological hierarchy which encodes abstraction hierarchies of concepts in the given domain  , prop~erty information of each concept , etc . When a parser creates ambiguous parses or when some parts of the meaning representation  ( as represented in an interlin-gun ) are missing , this knowledge source is accessed to disambiguate or to fill-in missing information  . 
However , as the size of the domain scales up , access time to the knowledge source grows to the extent hat cost-effective bulk processing would lint be possible  . 
For exmaple ,\[ Evett , el . al . ,  1990\] reports that access to large frame systems on serial computers have a time-complexity of O  ( MxB't ) where M is the number of conjuncts in the query , B is the average branching factor in the network , and d is the dept b of the network . Thus , even a simplest form of search takes over 6 seconds on a VLKB with 28K nodes measured on a single user mode VAX super n fini-computer  . Since such search on a VLKB must be performed several times for each parse  , the performance issue would be a major concern . Considering the fact that VLKB projects such as CYC\[Lenat and Guha  , 1990 and EDR\[EDR ,   1988\] aim at VLKBs containing over a million concepts , the performance of VLKB search would be an obvious problem in practical use of these VLKBs  . Intile massively parallel machine such as SNAP , we should be able to attain time-complexity of
O(D+M)\[Evett , et . al ., 1990\].
We have carried out experiments to measure KB access time on SNAP  . Figure 5 shows the search time for various size of VLKBs ranging from  800 to 64K nodes . Performance was compared with SUN-4 antithe CM2 connection machine . SNAP-1 consistently outperformed other machines ( performance curve of SNAP-1 is hard to see in the figure as it exhibited execution time far less than a second  . 
6. Other Approaches
One clear extension of the currently implemented modules is to integrate the classification-baaed parsing and the VLKB search  . The classification-baaed parsing carry out high performance syntactic analysis and the VLKB search would impose semantic on straints  . 
Integration of these two would require that the SNAP-1 to have a multiple controller because two different marker control processes need to he mixed and executed at the same time  . Currently SNAP-1 has only one controller . This would be one of the major items for tile up grade of the architecture  . However , the performance gain by this approach would be significant and its in  , pact can be far reaching because a lot of current NLP research as been carried out on the ACflLS DE  COLING-92  , NANTES , 2328 AOt ~ rr 19928 17I'ROC . OFCOLING-92, NAN-t ~ S , Autl . 23-2g , 1992
VLKII Retrieval in PACE Benchmark ++ + alooo .   .   .   .   .   .   .   .   .   .   .   .   .   .  - . -- i ~00 .  - -
I '.
Iso00 .   .   .   .   .   .   .   .   . ~--12 O O O .   .   .   .   .   .   .   .   .   .   .   . : --+ tloooo ~ .   .   .   .   .   .   .   . 710000 + I .   .   .   .   .   .   . _,,' L- .   .   .   .   .   .   . , mm .   .   .   .   .  ~  .   .   .   .   .   . 
m0 0........:.......
7OO0................
+0 . +0 ~  .   .   .   .   .   .   .   .  ,"  .   .   .   .   .   .   .   .  :+\] :+7'"+ -~ ) + am--+--~------:+oal .   .   .   .   .   .   .   .   .   .   .   . + m .   .   .   .   .   .   .   .   . NAP-1o oolm2 o ++ ~4 oo+?~+ix,
Figure 5: Retrieval time vs . KB size framework of the unification-based grammar formalism and use VLKBs as major knowledge sources  . 
A more radical approaclh however rooted in the traditional model is to fully map the typed unification grammars \[ Emele and Zajac  , 1990 on the SNAP . The typed unification grammar is based on the Typed Feature Structure  ( TFS ) \[ Zajac , 1989\] and HPSG\[Pollard and Sag ,  1987\] , and represents all objects in TFS . 
Objects includes Phrasal Sign , Lexical Sign , general principle such as the " Head Feature Principle "  , the " Subcat Feature Principle " , gramma rules such as the " Complement Head Constituent Order Feature Principle  , " the " Head Complements Constituent Order Feature Principle  , " and lexical entries . The lexical entries can be indexed under the lexical hierarchy  . 
In this apporach , all linguistic knowledge is precompiled into a huge network  . Parsing and generation will be carried out as a search on this network  . We have not yet complete a feasibility study for this approach on SNAP  . However , as of today , we consider this approach is feasible and expect to attain single-digit millisecond order performance on an actual implementation  . The dynamic network modification , address propagation , and marker propagation rules are especially useful in implementing this approach  . 
Natural language processing model on semantic networks such as \[ N or vig  ,  1986\] , SNePS\[Neal and Shapiro ,  1987\] , and TRUMP , KING , ACE ~ and SOISOR at GE Lab . \[ Jacobs ,   1991\] should fit well with the SNAP-1 architecture . For\[Norvig ,  1986\] , SNAP provides floating point numbers to be propagated  . As for SNePS , the implementation should be trivial , yet we are not sure the level of parallelism gain by the SNePS model  . When the parallelism was found to be low , the coarse-grain processor may fit well with this model  . Although we do not have space to discuss in this paper  , there are , of course , many other NLP and AI models which can be implemented on SNAP  . 
7. Conclusion
In this paper , we have demonstrated that semantic network array processor  ( SNAP ) speeds up various natural anguage processing tasks  . We have demon-atrated this fact using three examples : the memory-based parsing  , VLKB processing , and Classification-based parsing . 
in the memory-based parsing approach , we have attained the speed of parsing in the order of milliseconds without making substantial compromises in linglfistic analysis  . To the contrary , our model is superior to other traditional natural anguage processing models in several aspects  , particularly , contextual processing . 
Next , we have applied the SNAP architecture for a new classification-based parsing modellter e  , SNAPiB used to search tile MSS to test tile unifiability of the two feature graphs  . We have attained , again , sub+milli seconds order performance per uniflability test  . 
In addition , this approach exhibite desirable scalability characteristics  . The search time asymptotically researches to 450 cycles as the size of classification network increases  . Also , search tinm decreases as average fanout gets larger ? Thee are natural advantages of using parallel machines ? SNAP is not only useful for the new and radical approach  , but also beneficial in speeding up traditional NLP system such as KBMT  . We have evaluated the performance to search VLKB which is the major knowledge source for the KBMT system  . We have attained sub-milli seconds order performance per a search  . Traditionally , on the serial machines , this process has been taking a few seconds posing the major thread to performance on the scaled up systems  . 
Also , there are many other NLP models ( Typed Unification Grammar\[Emele and Zajae ,  1990\] , SNePS\[Neal and Shapiro ,  1987\] , and others ) which may exhibit high performance and desirable scaling property on SNAP  . 
Currently , we are designing the SNAP-2 reflecting various findings made by the research with  SNAP-1  . 
S NAP-2 will be built upon the state-of-the-art VLSI technologies using RISC architecture  . At least 32K virtual nodes will be supported by each processing element  , providing the system with a minimum of 16 million nodes ? SNAP-2 will feature nmlti-user supports , intelligent I/O , etc . One of the significant features in SNAP-2 is the introduction of a programmable marker propagation rules  . This feature allows users to define their own and more sophisticated marker propagation rules  . 
In summary , we have shown that the SNAP architecture can be a useful development platform for high performance and largescale natural language process-rag  . This has been empirically demonstrated using SNAP-1  .   SNAP-2 is expected to explore opportunities of massively parallel natural anguage processing  . 
References\[Blelloch , 1986\]Blelloeh , G . E .   , " CIS : A Massively Par-a Uel Concurrent Rule -Based System  , " Proceeding of AClT ~ DECOLING-92 , NA ~ rEs . 2328 hOt'q1992818 Paoc . OFCOLING-92, NANTES , AUG .  2328, 1992
AAAI-86, 1986.
\[Bzachman and Schmolse , 1985\]tlrachmau , R . J . and Schmolze , J . G . , " An Overview of The KL-ONE Knowledge Representation System  , " Cognitive Science 9 ,  171-216 , August 1985 . 
\[Charniak , 1983\] Charniak , E . , " Passing markers : A theory of contextual influence in language comprehension  , " Cognitive Science ,  7(3) ,  1983 . 
\[ Carpenter and Pollard , 1991\] Carpenter , B , and Pollard , C . , " Inclusion , Disjointness and Choice : The Logic of Linguistic Classification  , " Proc . of AcbgJ ~1991 . 
\[ EDR ,   1988\] Japan Electric Dictionary Research Institute , EDR Electric Dictionaries , Technical Report , Japan Electric Dictionary Research Institute ,  1986 . 
\[Emele and Zajac , 1990\]Emele , M . and Zajac , R . , " Typed Unification Grammars , " Proc . of Coting-90, 1990 . 
\[Fahlman , 1979\] Fahhnan , S . , NETL : A System for RepT~-sen*in 9 and Using Real-World Knowledge , The MIT
Press , 1979.
\ [ Evett , st . a L , 1990\]Evett ~ M . , ttendler , J . , and Spector , L . , PARKA : Parallel Knowledge Representation on the Connection Machine  , UMIACS-TR-90-22 , University of Maryland ,  1990 . 
\[ Headier , 1988\] Headier , J . , ln~egrating Marker . Passing and Problem-Solving , Lawrence Erlbanm Associates ,  1988 . 
thirst , 1986\] Hirst , O . , Semantic Interpretation and the Resolution of Ambiguity  , Cambridge University
Press , Cambridge , 1986.
Is , cobs , 1991\]Jacobs , P . , " Integrating Language and Meaning , " Sown , J . ( Ed . ) Principles of Semantic Networks , Morgan Kauflnann ,  1991 . 
\[Kn . sper ~1989\] Kasper , R . , " Utfilicatlon and Classification : An Experiment in Infonuation-B~sed Parsing  , " Proceedings of the International Workshop on Parsing Technologies  , Pittsburgh ,  1989 . 
\[Kim and Moldovan , 1999\] Kim , J . and Moldovan , D . , " Parallel Chmsification for Knowledge Representation on SNAP " Proceedings of the  1990 International Conference on Parallel Processing ,  1990 . 
\[Kit . no , 1991\]Kit . no , It . , "~ DmDialog : An Experimental Speech-to-Speech Dialogue Translation System  , "
IEEE Computers June , 1991.
\[Kitano and Higuclfi , 1991a1K it . no , H . and Higuchi , T . , " Massively Parallel MemoryBased Parsing " , Proceedings of IJCAI-9J ,  1991 . 
\[Kit . no and Higuclfi , 1991 hiKit . no , H . and Higuchi , T . , " High Performance MemoryBased Translation on IXM2 Massively Parallel Associative Memory Processor " , Proceedings of AAAI-91 ,  1991 . 
\[Kit . nost . M . , 1991a \] Kit . no , ti . , Headier , J . , Higuchi , T . , Moldovan , D . , and Waltz , D . , " Massively Parallel Artificial Intelligence , " Proc . of lJCAI-91, 1991 . 
\[Kitano et . al . , 1991b \] Kit . no , H . , Moldovan , D . , and Cha , S . , " High Performance Natural Language Processing on Semantic Network Array Processor  , " Prve . 
of IJCAI-91, 1991.
\[Kit , no , 1990\] Kitano , H . , " Parallel Incremental Sentence Production for a Model of Simultaneous Interpretation  , " Dale , R . , Mellish , C . , and Lock , M . ( Eds . ) Current Research in Natural Language Generation t 
Academic Press , London , 1990.
\[Kit , nost . al . , 1989\] Kitnno , H . , Tomabechi , H . , and Levln , L . , " Ambiguity Resolution in DmTrans Phm , " Proceedings of the European Chapter of the Association of Computational Linguistics  ,  1989 . 
\[Lee and Moldovan , 1990\] Lee , W . and Moldovan , D . , " The Design of a Marker Passing Architecture for Knowledge Processing "  , Proceedings of AAAI-90 ,  1990 . 
\[Lenat and Guha , 1990\] Lea . t , D . B , and Guha , R . V . , Building Large K~towledge-Based Systems , Addison-
Wesley , 1990.
\[Nagao , 1984\] Nag . o , M . , " Ab ~ ramework of . Mechanical Translation between Japanese and Engllnhby Anal-  . 
ogy Principle , " Artificial and Human Intelligence , Ehthorn , A . and Banerji , R . ( Eds . ), Elsevier Scieuce
Publishers , B.V . 1984.
\ [ Nealaud Shapiro , 1987\] Neal , J . and Shapiro , S . , " Knowledge-Based Parsing , " Bole , L . , ( Ed . ) Natural Language Parsing Systems , Sptinger-Verlag ,  1987 . 
\[Goodman and Nirenberg , 1991\]
Goodman ~ K ,, and Nirenberg , S . Knowledge-Based Machine Translation Project : A Case Study  , Morgan
Kauimann , 1991.
\[Norvig , 1966\] Norvig , P . , Unified Theory of Inference for Test Understanding  , Ph . D . Thesis , University of California Berkeley , 1986 . 
\] Pollard and Sag , 1987\]
Pollard , C . and Sag , I . , b~formation-Based Syntaz and Semantics , Vol . L " Fundamentals , CSLI Lecture Note Series , Chicago University Press ,  1987 . 
\[Quilllian , 1968\] Quillian , M . R . , " Semantic Memory , " Seomastic Information Processing , Minsky , M . ( g d . ), 216-270, The MIT press , Cambridge , MA , 1968 . 
\[Riesbeckanti Martin , 1985\] Riesbeck , C . and Martin , C . , " Direct Memory Access Parsing " , Yale University
Report 3S4,1985.
\[Riesbeck and Schank , 1989\] Riesbeck , C . and Schank , R . Inside Case-Based Reasoning , Lawrence Erlbaum
Associates , 1989.
\[Sown , 1991\]S .   .   .   . J . F . ( Ed . ), Principles of Semantic
Networks , Morgan Kaufmann , 1991.
\[Sown , 1984\] Sown , J . F . , Conceptual Strueturen , Reading,
Addison Wesley , 1984.
\[St , still and Waltz , 1986\] Stnnfill , C . , aud Waltz , D . , " Toward MemoryBased Reasoning , " Communication of the ACM ,  1986 . 
\[Surt dtandlid ,, 19911 Sumita , E . , and Iida , 1I , " Ex-perinmnts and Prospects of Example ~ Bnsed Machine Translation  , " Proceedings of ACL-91 ,  1991 . 
\[ Thinking Machines Corp . , 1989\] Thinking Machines Corp . , Model CM-~Technical Summary , Technical
Report TR-89-1~1989.
\[ Tomabechi , 1987\] Tomabechi , lI . , " Direct Memory Access ~ l~anslation ' , Proceedings of the IJCAI-87 ,  1987 . 
\[Waltz and Pollack , 1985\]Waltz , 1) . L . and Pollack , J . , " Massively Parallel Parsing : A Strongly Interactive Model of Natural Language Interpretation " Cognitive 
Science , 9(1):51-74, 1985.
\[ Wilensky , 1987\] Wilensky , R . , " Some Problems and Proposals for Knowledge Representation "  , Technical Report UCB/CSD 87/361 , University of California , Berkeley , Computer Science Division ,  1987 . 
\[ Zajac , 1989\] Zajac , R . , " A Transfer Model Using a Typed Feature Structure Rewriting System with Inheritance  , " Proc . of ACL-S9, 1989 . 
AL~SDECOLING-92, NA ~ riazs . 2328 no ( rr 1992819 Paoc . OFCOLING-92 . NAN-rE/I , AUG .  2328 .  1992
