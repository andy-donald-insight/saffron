Coordination in an Axlomatl Grammar *
David Milwa . rd
University of Cambridge
Computer Laboratory
New Museums Site , Pembroke Street , Cambridge , CB 23 QG , England


For sometime there has been interest in the idea of parsing as deduction  . Here we present a grammatical tbrmalism , ' Axiomatic Grammar ' , which is based upon a small number of linguistically motivated ax--toms and deduction rules  . Each axiom or rule combines a ' category ' with a string of words to form a further category  . This contrasts with the usual'tree structure ' approach to syntactic analysis where constituents are combined with each other to form a further constituent  . 
We describe a grammar for English which has a good coverage of ' nonconstituent ' coordination  . 
The grammar has been integrated with a to y semantics  , and has been implemented in a left-to-right parser with incremental semantic interpretation  . The parser does not suffer fi'om spurious ambiguity  . 
I Introduction
Coordi : uation is a particularly trouble some phenomenon to account for in theories of syntax based upon phrase structure rules  . Acceptable xamples of ' nonconstituent ' coordination such as:  ( 1 ) Jolhngave Maryabook and Peterapaper ( 2 ) Benlikes and Fredadmires Mary have led some to abandon a single level of grammatical description  , and others to abandon phrase structure rules . 
An example of the former approach is Modifier Structure Grammar  ( Dahl and McCord ,  1983) , which was justified as t bllows: . . . it appears that a proper and general treatment must recognise coordination as a " metagrmn matieal ' construction  , in the sense that metarules , general system operations , or ' second-pass'operation such as transformations  , are needed for its formulation . 
Modifier Structure Grammar embeds its rules for coordination into the parsing algorithm  ( there are close * This research was supported by an SE\[ICresem'ch studentship  . 
parallels with the SYSCONJ system ( Woods , 1973)) . 
In order to parse sentence (2) , the state of the parser at the point immediately before ' Fred ' is matched to the state immediately before ' Ben '  . ' Fredadmires ' is then parsed , and the resulting state is merged with the state after parsing ' lienlikes '  . 
The alternative approach to dealing with coordination uses a single level of grammatical description  , but uses a weaker notion of constituency than phrase structure grammar  . It is presently exemplified by proposals to extend Categorial Grammar with Forward Composition  , the Product operator , Subject
Type-Raising etc.
Categorial Grammar , just like phrase structure grammar , is based upon the combination of one or more constituents to form a further constituent  . 
In order to deal with coordination , the category ( X\X ) /X1 is assigned to the conjunction , or , n \] or e usually , a phrase structure rule is invoked of the form :
X-~X conj X
In either case , each conjunct has to be assigned a category . Extensions to Categorial Grammar provide a greater coverage of coordination phenomena by allowing a greater number of strings to form categories  . For example , to accept both (2) and (3) ,   ( 3 ) Benlikes Mary and admires Jane an extended grammar must allow ' B enlikes ' to form a category which can combine with ' Mary ' to form a sentence  , and ' likes Mary ' to form a category which can combine with ' Ben'to form a sentence  . The consequence of this is that the simple sentence ' Benlikes Mary ' can be assigned at least two different syntactic structures :  ( Ben ( likes Mary ) ) or ( ( Ben likes ) Mary )  , which both correspond to the same read i , g ( the sentence is spuriously ambiguous according to the grammar  )  . 
Axiomatic Grammar avoids the problem of spurious ambiguity by avoiding the need to assign categories to conjuncts  . Although the formalism was develope during research into extended Categorial Grammar  , the separation of grammatical information into axioms and rules makes its treatment of coordination look similar to that in a metalevel approach such as Modifier Structure Grammar  . '\]' his 1 Capita \] letters will be used to denote variables througl ~ out this paper  . 
l 207 similarity is easies to show if we introduce the central notion of ' category transition ' through the idea of state transition  . 
Consider a left-to-right parse of the sentence'a mans its ' based upon a phrase structure grammar including the rules : s--~npv pnp--+detn Initially we start in a state expecting a sentence  ( which we can encode as a list ( s ) ) . After absorbing the determiner , ' a ' , we can move to a new state which expects a noun followed by a verb phrase  ( encoded as a list ( n , vpl ) . Following the absorption of ' man ' , we can move to a state expecting just a verb phrase  , and following the absorption of ' sits ' we have a successful parse since there is no more input and nothing more expected  . The transitions between the encodings of the states are as follows:  ( s ) +" a "--* ( n , vp ) where a : det(n , vp+"man "-+ ( vp where man:n ( vp ) +" sits " ~0 where sits : vp ( ' a : det'means lhat the word " a' is a determiner  ) Instead of deriving these transitions from the phrase structure rules  , consider directly supplying axioms of the form : < s >+" w "--+ < n  , vp ) where W : det(n , vp > -- :' W "---+ ( vp > where W : n < v p + " W "--+ <> where W : vpIf constituent names are replaced by category specifications  , generalisations become possible . The three axioms : < s)+"W "--* < n , s\np ) where W : np/n(n , s\np ) +" W "--+ ( s\np ) where W : n ( s\np ) +" W "--* ( > where W : s\np ( ' np/n'is an np requiring a noun on its right , and ' s\np ' is a sentence requiring an upon its left  ) are instantiations of the axioms : < X ) ? R + " W "-+ < Z , X\Y ) ? R where W : Y/Z ( X ) ? R + " W "--+ R where W : X ( ' X ' is the head and ' R ' , the tail of the list encoding the state .  '  . ' denotes concatenation , so '( n , s\np ' is equivalento ' ( n ) ? < s\np >' ) The ' encoded states ' will roughly correspond to ' principal ' categories in Axiomatic Grammar  , and the axioms above to the axioms of Prediction and 

The rule for coordination in Axiomatic Grammar is stated in terms of principal category transition  . 
For example , the acceptability of sentence ( 2 ) is dependent upon a proof that the two strings " Benlikes " and " Fred admires " both take us from the initial category  ( corresponding to a parsing state expecting a sentence  ) to a second category ( corresponding to a state expecting a noun phrase )  . The rule will be stated formally after a general description of the formalism  . 
2 The Basics
Axiomatic Grammar is mainly lexically based , with lexical entries containing both subcategorisation adorder information  . An association of a word with a ' lexical ' category is given by an expression of the form : word:LEX-CATE ach lexical category is a feature valued structure  . 
The features of interest are ' cat ' , which gives the base type of the category (' s ' , ' np ' , or ' n') , and ' left ' and ' right ' which contain lists of ' arguments '  . Each argument is itself a lexical category . Categories are complete if the argument lists are empty  . As an example , consider the lexical entries for the determiner ' the ' and the transitive verb ' likes ':\[\[ cat = npleft =  0 the : right = ( " ca%--8 left = ( likes : right = ( \[ca%-~n\]I left=0 ) righZ = 0\] cat = npleft=0 ) right = 0 cat = ~ p\]left=0J ) right = 0 We can read the category for ' likes ' as follows : given a complete noun phrase on the left and a complete noun phrase on the right  , we can form a complete sentence . It is Worth comparing this category with the category generally assigned to ' likes ' by a Categorial Grammar:  ( S\NP ) /NP The categories differ in two respects . Firstly , the Categorial Grammar category not only provides information as to what is on the left  , and what is on the right , but also determines the order in which each argument is to be absorbed  ( in the above , the argument on the right must be absorbed first , followed by the argument on the left ) . Secondly , whereas the Categorial Grammar category would be regarded as having the syntactic type ' np ~- ~  ( np--+s ) ' , the Ax-iomatic Grammar category is regarded as having the base type's'  . This difference has a bearing on the treatment of modifiers  ( discussed later )  . 
When a string of words is absorbed it causes a transition between principal categories  . A principal category is again a feature structure  , the feature of interest being the ' right ' feature i  . e . the list of argmnents 2 required on the right . A parse of a sentence consists of a proof that , starting with a principal category which requires a sentence  , we can end 2 Arguments are again lexical categories . 
2082 up with a complete principal category . I'b rexample , Lo prove that ' Bens its ' is a sentence we prove the statement  3   1   (   ) " Bensits " r=04 r ( ) llenceforth , the convention is adopted that left or right argument lists which are not specified are empty  . This allows us to rewrite the statement above rather more compactly as : A proof of a parse is performed using rules and axioms  . An a ? aom declares that a string of words per-brms a transition between two principal categories  . 
Axioms are either simple statements , or restricted ~ tatements of the form :
CoString C1 where ....
Three axiorns will be discussed here 5 . The first , Iden-i ; ity , merely declares that an empty string performs the identity transition i  . e . 
Co ";; C0
The other axioms , Prediction and C , omposition , work on strings consisting of a single word . They have the format :
Co " W " C1 where W : LEX-CA TrF heflfll definitions , given in Figure 1 , should become clearer as we work through an example  . 
A deduction rule in Axiomatic Grammar declares that a string of words performs a transition between t ~ vo principal categories provided that certain sub-st  . rings perform certain transitions i . e . rules have the format 6:
CoString 0 C1, . . . , C ~ String , C,~+1
CaString C ~ ( subscripted strings are substrings of ' String ' ) The consequent of a rule ( the statement t in der the line ) can be proved by proving all the antecedents ( the staternents above the line )  . 
3Feature names arc abbreviated in an obvious manner  . 
Simple statements have the general form :
CoString C1 ( ' Co ' and ' C1' are principal categories , and ' String ' is a string 4 The corresponding state transition would be :   ( s ) +" Bensits "-+ 0   5A fourth axiom is used for topicalisation . 
6 This is actually the form of simple rules . As with a ximr~s , rules may be restricted using a ' where ' clause . 
3 An Example Proof
In order to prove that ' Bensits ' is a sentence , we need to use all the axioms , and two rules , Sequencing and Optional Reduction . The relevant proof tree is given in Figure 27 . 
The Prediction Axiom is restricted in English to the case where a category requires a sentence on the right  , and the word encountered has a lexical category of base type noun phrase  . Thus starting with the principal category : we can absorb the proper name ' BeeF  , which has the lexical category , \[c = upl , to form a principal category , ' c0' , which requires first an optional noun phrase modifier  ( e . g . a nonrestrictive rlative clause ) , and then a sentence which requires a noun phrase ( a verb phrase ) i . e . 
=  ,   , p\]l'np\]/I ( the use of parenlheses around the base type of the noun phrase modifier denotes optionalilys  ) Writing this as a statement in the logic , we have a proof that :\[ r = ( \[ c=s\] ) \] " Ben " cO The Sequencing Rule 9 is used to combine the effects of the absorption of two strings  . The rule declares that if one string defines a transition from  Category0 to Category1  , and another defines a transition from Category1 to Category2  , then the combined string defines a transition from  Category0 to Category2 i . e . 
CoString 0Ca , CI String 1C2
CoString0 ? String1C ~ ( here'e'denotes concatenation of word strings e  . g . 
" Ben "?" sits " is equivalent to " Bensits " ) For this example , we can instantiate the Sequencing Rule as follows : ij  , \]" eo"cO , co\[\]
It : , ,  B0o  \[ \]  7At this stage no restrictions have been imposed upon the ordering of the rules  , and more than one proof tree is possible . 
However , it is relatively trivial to prove the existence of an olwnal proof strategy which supplies a single proof tree for a given sentence and a possible semantics  ( Milward ,  1990) . 
8Parentheses are used as a shorthand . The lexical categories ill argument lists actual ly include a feat m'e'opt '  , which is set to an uninstantiated variable when the argument is op  . 
tional , to ' true ' if the argument is compulsory . 
9The name ' Sequencing Rule ' is due to a loose correspondence between the grammar and the Floyd Iloare I hlles for Axiomatic Semantics of p rogramming languages  3   209 
COMPOSITION : r = (1L) . r = R ' , ( rR"11c = ( X)\]) , R "\[ where JJ != xW := LRoR'
PREDICTION '1(c = Y)) . R "(' . ' denotes concatenation of lists . Optional arguments have the value of the ' cat ' feature in parentheses  . 
X may be instantiated to the base types's' , ' np ' , or ' n';L , I~ , R ' and R " lo lists of categories)
Figure 1: Axioms . . . . . . . . . . . . . . IDENTITY \[\]'"' \[1 . . . . . . . . . . . . . . . . . COMPOSITION . . . . . . . . . . . . . . OPTIONAL REDN i - . 1
Ld . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . SEQUENCING cl " sits "\[\] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . PREDICTION . . . . . . . . . . . . . . . . . . . OPTIONAL REDN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . SEQUENCING (" cO' , ' cl ' and ' c2' are principal categories mentioned i ' a the text ) 
Figure 2: Proof Tree for ' Bens its '
We can thus obtain a proof of the whole sentence by proving the antecedents to the rule  . The first , has already been proved , so we are left to prove:cO"sits"\[\] The head of the argument list of cO is an optional noun phrase modifier  , Optional categories at the head of the argument list of a principal category can be deleted by the use of the Optional Reduction Rule which is as follows :\[ r = R "\] String Cr =  ( 1 = L ) * String Cr = R We instantiate the Optional Reduction Ruleto:cl " sits "\[\]  c0"s its "\[\] in which'el'iscO without the optional modifier i  . e . 
r = (( c = np ))
Tile proof now consists of proving the antecedent of tile Optional Reduction Rulei  . e . 
r = ((\[ c :, p\]/)
This can be proved using first the Composition Axiom  , then tile Sequencing Rule followed by Optional Reduction  , and finally the Identity Axiom . 
The Composition Axiom 1? absorbs a word which has the same base category as the head of the a ~ r-gument list of a principal category  . Since the word's its ' has the following category :\[ c_-s\]i =  ( \[ c:np the Composition Axiom can be used to absorb's its ' and get us to the category '  c2" l ? The name ' Composition ' is due to the s in filarity with the rule of generalised I ~ rward Composition in a Catcgorial 
Gr & mlll & r.

Using the Sequencing Rule once more , we can prove the whole given a proof of r : li (  \ [~:~\ ]  )   )   .   .   .   . 
which can be proved by first invoking the Optional Reduction Rule  . The optional sent cntial modifier is then deleted , leaving , is with a proof of \[\] . . . . \[\] which is true by the Identity Axiom . 
4 tgul . es and Lexical Items
Sotar we have introduced three axioms which are used by the grammar  , and two rules . Before considering further rules it is worth discussing the grammar as it stands  . 
The effect of the axioms , Prediction and Composition , is to absorb a word and to predict an optional modifier for the base type  . For exarn ple , in parsing ' the girl'a noun phrase modifier is predicted after parsing ' the ' and a noun -modifier is predicted after parsing ' girl '  . Thus , given a treatment of nonrestrictive relatives , we could parse something like : ( 4 ) The girl outside , who has been waiting a long time , looks frozen Moreover , alter parsing a noun modifier , another noun modifier is predicted ( the base type of a noun modifier is , after all , a noun ) . Thus we could also parse ( 5 ) The girl outside in the red dress with the large man  . . . .
Although the treatment of noun and noun phrase modification looks reasonably traditional  , the treatment of verbal modification is less so . Since the base type of a verb is a sentence , a modifier for the verb has the same type as a sentential modifier  . For example , in: ( 6 ) John hit the ball with a racket the action of the Composition Axiom is to add an optional sentential modifier on totile end of the subcategorisation list of the verb'hit '  , and then to add this list onto the list of expected arguments i  . e . after absorbing " hit " the principal category becomes : " := I~= np  , i: ( \[~= s\]lA successful proof of the sentence is achieved by giving ' witl falexical entry : Sentence such as ' John decided to sack Mary in secret ? are correctly treated as being structurally ambiguous  , since ' in secret ' may modify the ' s ' introduced by ' decided ' or the %' introduced by ' sack '  . 
The grammar which has been described so farira = .
poses a strict notion of word order . This seems particularly inappropriate fbr relative clauses which can be extraposed from a position following the subject noun phrase to after the verb phrase  . Consider the sentence : ( 7 ) Children arrived who only spoke English The present grammar treats this case by allowing heavy noun and noun phrase modifiers to swa  . pplaces with categories having a base type ~ s ' . Thus the principal category created af Ler absorbing " Children ":\[\]\[ can be transformed into : i <\[ ~:  . ,~ p \]> ) r:/ 1 /It:':/The possibility is being considered of replacing lists of arguments by sets of arguments associated with linear precedence constraints  ( along the lines of work done on bounded discontinuous constituency  ( R cape ,  1989)) . 
Finally , let us consider the particular restriction which was made to the Prediction Rule for English  . 
The effect of the restriction is that the only acceptable lexical entries with left arguments are either of the form  1  =  ( c = np ) or 1= ( c = X ) r = Rr = Ri . e . verbs ( which require a noun phrase subject on their left )  , or modifiers of the base types . 
5 The Coordination Rule
The Coordination Rule is as follows:
CoString 0C1, CoString 1C1
CoString0?"W"?StringIC1 where W6 and , or , but \] This contrasts with the phrase structure rule: 
X - - , X conj X which can be expressed in deduction rule format as: 
String 0: X , String 1: X
String 0g " W "? String I : X where W 6 and , or , but Both rules allow nested and iterated conjunction  , 5211 however , whereas the phrase structure rule enforces that conjuncts are of the same category  , the Coordination Rule enforces that each conjunct defines the same transition between principal categories  . 
We can show the expressive power of the Coordination Rule by considering some examples  . The first is an example of ' unbounded ' Right -Node Raising:  ( 8 ) John admires , but Mary thinks heloves , the new teacher This can be proved by separately proving that both " John admires " and " Mary thinks heloves " perform a transition between the initial principal category  , \[ r = ( \[ c=s\] ) \] and the category : r = ( ~ = np ,  1  ( \[?= s\] )   ) The proof is completed by proving that " the teacher " defines a transition between this category and the complete principal category  ,  \[\] . 
The second example involves sharing on both the right and the ! eft :  ( 9 ) Helent Johnabook , and Mary a paper , about subjacency . 
This example , which has been used to argue for the addition of recta-rules to Categorial Grammar  ( Mor-rill ,  1987) , is of interest when the required reading is where the noun modifier ' about subjacency ' applies to both the book and the paper  . To prove the sentence we first prove that " He lent " performs a transition between the initial principal category and the category : We then prove separately that " John a book "  , and " Mary a paper " perform a transition between this category and the category : \[  1\[   1\] r:I/:nil='\ ]1 /Finally we prove that the string " about subjacency " takes us from this category to the complete category  ,  \[\] . 
The basic grammar does accept some sentences which are generally regarded as unacceptable  , and extra features are needed to constrain the rules  . The situation with the basic grammar is not , however , as bad as with many extended Categorial Grammars . The Coordination Rule enforces a parallelism between conjuncts in a similar manner to the parallelism enforced by the phrase structure rule mentioned above  . This can be contrasted with assigning conj unctions the polymorphic category  ( X\X ) /X , which allows sentences like : ( 10 ) Johnlikes Mary and , or Peterlikes Joan and

Further parallelism is enforced by tile particular treatment of wh-movement n which  , for example , predicts the acceptability of ( 11 ) but not of ( 12 ) :  ( 11 ) The book arrived which John had shown Mary and given to Peter  ( 12 ) * The book arrived which John had shown
Mary and to Peter 6 Conclusion
This paper has introduced Axiomatic Grammar , and has given some justification for particular axioms and rules chosen for English  . The formalism itself has been left very much underspecified  , and further research is required both into its applicability to other languages  , and into its formal properties . 
A larger grammar for English has been implemented , including a treatment of wh-movement and verbal ellipsis  ( gapping )  . The parser works word-by-word from left-to-right , and was designed so that incorporation of the coordination rule does not slowdown parsing in general  . 
Axiomatic Grammar fits in naturally with an incremental approach to semantic interpretation  , or with semantics based upon state change . The present , grammar is integrated with a toy semantics based upon the incremental  ( but nonmonotonic ) accumulation of constraints . 

Dahl , Veronica and McCord , Michael C . (1983).
Treating Coordination in Logic Grammars.
Computational Linguistics , 9(2):69-91.
Milward , David R .  (1990) . Ph . D . Thesis . Forthcoming . 
Morrill , Glyn (1987). Meta-Categorial Grammar.
In Haddock , Nicholas , Klein , Ewan , and Mor-rill , Glyn ( eds . ) , Categorial Grammar , Unification Grammar and Parsing , Centre for Cognitive
Science , University of Edinburgh.
Reape , Mike (1989) . A Logical Treatment of Semi-Free Word Order and Bounded Discontinuous Constituency  . In European ACL , pages 103-110 . 
Woods , W .  (1973) . An Experimental Parsing System for Transition Network Grammars  . Inl % ustin , R . 
( ed .), Natural Language Processing , Algorithmics

1 1 The rules for wh-movement involve the use of a featm'e on principal categories which's tacks ' extracted elements  , and the use of further features to controlext raction sites  . 

