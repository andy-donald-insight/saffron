Analysis of Scene Identification Ability of Associative Memory with 
Pictorial Dictionary
Tatsuhiko TSUNODA *, I-Iide hiko TANAKA
Tanaka Hidehiko Laboratory , Departlnent of Electrical Engineering
Faculty of Engineering , University of Tokyo , 7-3-1 Hongo , Bunkyoq Cu , Tokyo 113 , Japantsunoda , tanaka Qmtl . t . u-tokyo , ac . jI )
Abstract
Semantic disambiguation depends on a process of defining the appropriate knowledge context  . Recent research directions suggest a e on nectionist approach which use dictionaries  , but there remain problems of scale , analysis , and interpretation . II ere we focus on word disambiguation as scene selection  , based on the Oxford Pictorial English Dictionary . We present a results of a spatial-scene identification ability using our original associative mcmor ~ j  , We show both theoretical and experimental nalysis  , based on a several different measures including information entropy  . 
1 In t roduct ion ' the difficulty of semantic disambiguation in natural language processing originates with the complexity of defining disambiguating knowledge contexts  ( Barwise J . and Perry J . , 1983) . These knowledge contexts must provide unique interpretations for codependent words  , and help resolve " semantic garden path " sequences  . For example , in " Johnshot some bucks , " aunique reading require semantic agreement on " shot " and " bucks  , " suggesting either a hunting orgambling context . The semantic garden path can be illustrated by prefixing the above sentence with " John travelled to the woods  , " which might suggest he hunting context , but then appending " The illegal csmino was hidden far from town  , " to dramatically change the interpretation suggested by the first two sentences  . 
The core of the problem is the disciplined and dynamic construction of a disambiguating kvowledge context  . While it might be possible to write static rules which provide disambiguating iformation i the context of complete knowledge  , such rulm hased models are both time and space inefficient  . 
Recognizing these problems , Waltz D . L . and Pollack J . B . (1985) and Cottrell G . W . (1989) proposed af , ~sci-hating connectionist approach , which uses early ideas from semantic networks to resolve semantic ambiguity * Supported by the Fellowships of the Japan Society for the Promotion of Science for Japanese Junior Scientists by dynamic spreading activation  . This spreading acti-wt tion construction of disambiguating context is based oil a high density associative cognitive model  , but still has problems : ( 1 ) no automated learning method to adaptively construc the model  , (2) non-scalable , and ( 3 ) no method of confirming hypothesized is -ambiguation  . Shastri L . (1988) proposes a similar structure , which uses st statistical semantic network . 
Sharkey N . E .   ( 1989 ) has proposed a system for processing script-based narratives based on combining local representation adrelaxation techniques with ImrM lel distributed learning and mapping mechanisms  . Mi-ikkulainen's system DISCERN ( Miikkulainen R . , 1993) is also suggestive ofadaptive processing , and uses self-organizing representation fwords and memory depending on semantics  . However , all of these models share the problems enumerated above  . 
Research directions for improvements suggest the use of existing collections of machine-read M~le dictionaries  . Ilecently , Nishlklmi M . et al ( 1992 ) has proposed a new relationship between language acquistion and learning based on scene analays is  . Furthermore , Bookman L . A . (1993 ) has proposed a scalable architecture for integrating ~ tq sociative and semantic memory using a thesaurus  . Based on this idea of using existing sources of word meanings  , Veronis and Ide ( Veronis . 1 . 
and Ide N . M . , 1990; Ide N . M . and Veronis J . , 1993 ) use sew ~ ral dictionaries and to improve the ratio of words disambiguated to ambiguous words  . 
In addition to ideas for the source of disambiguating knowledge  , many researchers have incorporated some kind of preference heuristics for improving tl  , eefficiency of determining disambiguating constraints  . 
Although these methods are essential for semantic processing they lack any coherent method for  ( 1 ) evaluating performance , and ( 2 ) acquiring new disaml ) iguat-ing knowledge from realworld sensors . 
Of course all of these l ) roblems result from the complexity of defining appropriate disambiguating knowledge contexts  . To help control and reduce this complexity , Kohonen T . (1984) has suggested the cla . ssifica-tion of dlsambiguating iformation i to flmr types :  ( 1 ) spatial contact , (2) ten qmral contact , (3) similarity , (4) contrast . Kohonen also emphm sizes the existence tions occur  , but we clMm that this kind of information <: an be expressed in the existing four types  . 
The previous approaches noted above can all be interpreted as using a complex mixture of the information types proposed by Kohonen  . This coml > lex-ity makes it very difficult to identify or create a stable mo < lel of learning the appropriate < l is an  , biguating knowledge from the real world . 
Our original contribution here is to propose a lm sie method of word disambiguation b~med on spatial scene identification  , and to provide a detaile < lanalysis of its performance  . The disambiguating knowledge is represented in the form of a stochastic ~ msociative memory  , constructed fi-om the ( ) xford Pictorial English Dicti<>-nary ( OPED )  . This l > ie torial dictionary claims to l > ro : vide word sense meanings for most ordinary lift  . ' scenes . 
The process of disambiguation is modelled as < leter-mining a unique mapping fi'om ambiguous input wor<ls to a particular l > ie torial < lictionary scene as modelle < l in the ~ msociative menmry  . The simple represent a timl of pietorial knowledge . I ) ~ med ( m the OPED makes analysis simpler , and provides a potentially smooth ( : on nee-tion to visual sensory data . 
2 Scene Identification
In order to identify spatial scene slmsed on in l ) uts en-tenees , some kind of information <> f detining each seell  ( ~ must exist . As exph'dned in the OPE l) , " The dictionary is edited regarding the depiction of  ( wery day objects and situations , in order to allow greater scope for the treatment of these  , objects and situatiovs in the context of English -speaking countries "\[ from l  ; ' of ward in OPED\] . Each scene or pictorial entry i ~ , the OPED accompanied by a word list of entries f , ' om the scene ( see next section ) . This bu , ldleof in fi ) rmation is the basis for organizing our associate memory model  . 
2.1 Constraints
Here we ~ m sume some constraints on the method of representing and using the OPED scenes : ? Only ordinal livivg scenes  ( 384 scenes in ( :lu ( ling thousands of subseenes ) are handled . All scenes are hypothesized to bee on structable by combinations of these scenes  . 
? Most of the words in OPE l ) are noun terms ae-e oml ) anied by adjective terms . In this system , spatial-seenes are identified by using only these words  . No syntactical information is used . 
? Compound words are dec <) mposed into primit iw'.

? The associative memory luus the ability to incrementally learn  , but our analysis here uses a tixed set of scenes and words  . 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , Saqu ~ tlal mymbol Direct Logical 1\[r .   .   .   .   .   . t .   .   .   . uo
I\[/0I12 I~tmcconadoon .   .   .   .   .   .   .   .   .   .   .   .  "  ,  "~ " " ~ _ _ _ _ \[3 , Changafo ~: ut "? Z~-?oglcal process l -- UK\  ]=   1 --? : ? r
Figurel : PI ) AI&CD architecture
Ambiguous Dlsamblguated
Figure 2:, q trueture of OPE Dan1 diagram of
PDAI&CD*Morphoh>gicalnalysis is done by using the elec-tronie dictionary of Japatl Electronic Dictionary 
Resear <: hinstitute ( EDR).
2.2 PDAI&CD and WAVE
The spatial scene identification system analyzed in this paper is one moduh ' of a general in fi ' rence architecture called l ' aral Ml  ) istributed Associatiw . " Inference and Contradiction / ) etection ( PDAI & CD ) (Tsunoda '\[' . and ' Fanak ; tl\[ . , 1993), which uses an : msociatiw ~ . 
memory WAVE ('\[' sunodaT . an (\[ Tanaka H . ) lmsed on neural networks and a logical veritieation system  . We haw ~ previously presented it ll application of that architecture to semantic ? lisambiguation  ( Tsunoda T . and Tanalat II . , 1993) . It features a eognitive model of fast disambiguation depending on context with bottom -up associatiw :  , memory together with an mreprecise top- ( lown feedba ( : k process ( Fig . l ) . After one scene is selected by previously in lmt words  , the system can disambiguate meaning of following words  ( as in the right side of Fig . 2) . In the . future , we plan to combine natural language proce . ssing with visual image from sensory data . Our representation f the spatial data fi'om the OPED is considered to be a simplest approximation of such visual sensory images  . 

Table 1: Examples of semantic disambiguation
Ex .
1 word ( Context ) scene of word ball Billiards lead ( a )   ( a )   ( b ) 


Atom I globedance cord metal 2 . 3 Semantic Disambiguation Words in OPED have ditferent meanings corresponding to their use in ditferent scenes  . When a set of ambiguous words uniquely determines a scene  , we conclude that the words have been successfully disambiguated  . We acknowledge that many other processes may be involved in general word sense disambiguation  , but use this scene-selection sense of word sense ( lisain-biguation from here on . 
We illustrate typical two examples below . The system with OPED and our associative memory canre  ( :-ognize these sentences and classify into each scene in the dictionary  . Once a scene is identified , it assigns each ambiguous words uniquely . We call it semantical disambiguation of words here  . The correspondances of the sentences and each meaning of word is summarized in Table  . 1 . 
1. ball ( a ) ( b)
Tom shot a white cue ball with a cue . The ball hit a red object ball and he thought it ' slucky if it will  . . . 
Judy found that she was in a strange world . Devils , dominos , pierrots , exotiegirls , pirates, . ?, where amI?'Oh !', she said to herself , a . s she found she wandered into a ball , 2 . lead: ( a ) It's not sufficient os hield only by the lm-thick concrete ? The fission experiment requires additional  10cm-thick blocks of lea < l . 
Fission fragments released by the chain reaction of  .   .   . 
(b ) He said to his son , " Please pull out the plug of the coffeegrinder from the wall socket  . Becareful not to pull by the lea < l . Ituum . . . here
I found the kettle . " ...
Our system is able to disambiguate each meaning in these examples actually  . 
3 Representation and Processing Theory ~::: .   .   .   .   .   .   .   .   .  :  .   .   . x , . . . . . .
: : ~ i ~ : : ~, g !: : ~+ ~ zi ~; ~: ~; : iL . ' ~ i :: ,,', ~ if : t . . . . . . . . . . :~  . :2:?:'~ "> . ':"5-% 11711 words , 384 scenes wall 0 , 01\ unit so . o04 ~ N , side 0 . 008 ~----~ wall O . Ol--~all ' ~', :, ~; ~ I bookself 07251//row0 . 7/// . . . : ~--~ l ?: . . . ' : ? i . : Figure 3: laving room scene and link example on the associative memory WAVE Figure  4: Weight of links and category selection 3   . 1 Representat ion o f OPED The Oxford Pictorial English Dictionary  ( OPED ) h , ~s very simple form of text and picture ( Fig . 3) . In this example , the upper part is a picture of a living room scene  , and the lower part consists of words of corresponding parts as follows : iw all units  2 sidewall 3 bookself OPP ; I ) has originally a hierachl cal structure of catego rization  ( as in the left side of Fig . 2) , but we use the middle level of it ( shaded part in the figure )  , which is most easily interl ) retal ~ h ! . 
Tollrovide the associative memory model for l ) ro-cessing words and selecting scenes , we , encode the OPED entries in tile WAVE model ms depicted in Fig  . 3 . The weights between scene elements are automatically learned during tile constructiou of the associative memory  . 
3.2 Simplified Model of Associative
Memory WAVE
The aim of using m~sociative memory for identification is to select tile most likely scene based on incomplete word data from sentences  . Ii and Ci are set to be elements of input space SI  , scene space So: , respectively , in an ideal state , the approl ) riate scene Ci is vector : Ii ACi . 
In the typical situation , however , the complete index is not provided and we require a way of ranking cam-peting scenes by defining a weighted activation value which depends on the i  ) artial in lmt , or set of ambiguous words , as follows:
Ci = f(EW if lJ ) (1)
J(a ) where the weight of each compone . nt is given by the conditional probability value
W ~ j-P ( C i l 6) (4)
A maximum-likelihoad scene is selected by a winner -take-all network : c  .  =  .   , filed ( 5 ) This type of assaeiative meinory has following fea-t ttres:?Unlike correlative models  ( Amari S . and Maginu K . , 1988) , neither distortion of pattern nor pseudolocal minimum solutions arise from memorizing other patterns  . 
? Memory capacity is O ( mn ) compared to O ( n " 2 ) of correlative I node l , where m is average immber of wards per scene , and n is the total number af possible words . 
? Unlike backpropagation learning algorithms , increment a learning is l ) ossilf l cat any time in

3 . 3 Recalling prol ) ability and estima-tion of required quant ity of infofmation Tileme ` a sure of scene selectivity is reduced totile condition whether given words are unique to the SCelle  . If all input words are cOln lnontol ) lura \] scenes , they cannot determine the original scene uniquely  . For exam-pie , tile system cannot determine whether to choose category CA ar CB only by seeing element q ' in Fig  . 4 . 
If ' a ' or tile set a , b is given , it is able ta select CA . 
Here we estimate the selectivity by the ratio of suc-cess fld cases to all of possible cases  , as follaws ( n is the mlmler of total elements , k is the number of elements related to each scene  , aimm is the total number of scenes ; incomplete information is dellned as a partial vector of elements numbers  ( 0 < s < k ) ) . 
Tilepral ) ability that selements are shared si , nulta-neously by two patterns is kCs-tn-kCk . - . s-1v ( , ,  , k ,  ~ )  =  ( ~ ) nCkT a extend this probal ) ility to generalized cases of m patterns , we use them unbers of elements of the ( 1 ) artial ) input vector . It can be estimated by counting the negative as e where illore thallone pattern shares elelllents  . 
1'( . , ~, k ,, ~, , )0(r ) = (~ v ( , , , <, .  ) )  . . . . . '- r ( , ~  , k , ~-~ ,   ,   , 0(s)m-2 = ( v , - p~)(~7 , ~ I , :"'-~-~) (9) q~0m--2 = vo , ~)(m)q=:0 v , = v(n ,  < ,  . ), 7, ~= v ( , , k , , . ) r : : l r = l The results using this formula are shawn hit he next section  . 
3.4 Infornmtion Entropy
As an alternative method of ewduation of spatial -see  . he information of a PED , we consider here self-information entropy and mntual-informatian etropy along with the information theory of Shannon 

* Self-lnformation entropy:
Fig . 5 illustrates a talking scene . Although sentences involving many ambiguous wards are handed fr <> m the speaker to the listener  , the listener can disambiguate them with some kind of knowk edge common to these people  . Conversely , the listner can determine scene 1 ) y the h and e < l sentence s . The entropy of scene selection a in biguity is reduced by the interaction  . We can define a concept of self-infarmation ( SI ) af the spatial-sceneidetification module as the entropy of a in biguous words or scenes  . Assuming equal probal fility to the scene selection with no harmed ward  , the entropy of the spatial-scene identitication can be cal-cualted  . 
Slo---EI ) ( CJ ) l " g2I ) ( CJ ): log: ,  38 , 1 = 8 . 59bits

After the identiticatian , the meaning of eact , word can be selected according to each a selection dis-tril  ) ution flmctian updated by the Bayesian rule . 
S . \[1 = CE(CIX ) (11) = <-~ rj~l ,   , ~l ' j ~ > ( 12 ) jir ' ji = r ( CjI"i ) = P ( ~' iI @ )   ( 13 ) Each P , j is equal to W ij as in Eq . (2) . <> represents ensemble average over each xl . 
31,3 sentences
Listener I__L_._

Scene common knowledge
Figure 5: Common knowledge between speaker and listener to disambiguate smantics of handed sentences  . 
Table 2: Mutual-information fOPE l )
Scene entropy Mutual-inform.
Without input 8 . 59 bits 1 word input 0 . 80 bits 7 . 79 bits 2 words in l ) ut 0 . 32 bits 0 . 48 bits
Mutual-lnformation entropy:
Mutual-information etropy ( MIE ) canlye defined as the contribution of additional words to identify a scene  , and consequently , tile selectiveness of the target word or scene . In order to select a word meauing or scene fi'om the possible space Y  , the space C of M1 other words are considered in the calculation of conditional entropy  ( CE )  . Mutual-information entrot > y per word is calculated by following formula: 
MIE(O;O')=CU(ClO)-CE(CIO')
Here , 0 is a set of previou state parameters , and 0~ is that of next one . Mutual-inforamtion can lye interpreted , as the reduction from a previous conditional entropy to corresponding updated conditional entroly y with additional words  . Wel ) ro-vide a theoretical estimation of sclf -informatio  , l of spatial-scenes with the dictionary in Table 2 . 
Tile result suggests that it has the spa . tial-scene identification ability with a few words  1  ) rese , ' va-tion . It also supl ) or ts the consequence of a h ) gical-summation algorithm shown in next section . 
4 Ana lyses of ident i f icat ion modu le Here we propose analyses of OPED and results of theoretical simulations  . As formula (9) is expensive (11711 ! times ) , we use a Monte-Carlo simulation to abstract is characteristics  . Iteration thnein each case is 1,000 . 
* Fig . 6  ( a ) shows a distribution of number of elements involved in each scene in OPED  . It approximated a Gaussian distribution and has a average  #Elemem sim  .   .   .   .   . to g(el .   .   .   . IS ? nesperel?merit\]", o, . . . . . . :2 o , Figure 6: ( a ) Distribution of number of elements per scene and ( b ) Distribution of number of scenes per elements w due of  184  . 2 . This value is used ill the theoretical simulations  . 
? Fig . 6  ( b ) shows a distribution of number of scenes which are related to one element  . The region where more than 100 scenes are related to one word are those for trivial words like ' a '  , ' the ' , ' of ' , ' that ' , ' to ' , ' in ' , ~ and ' , ~ for ' , ' with ' , ' s ' . Although we could ignore these words for an actual application  , we use them for fairness . 
? Selection probability in the case that partial words of scenes arc input to thems soeiative men > cry is illustrated in Fig  . 7 . The recall rate in-cre`ases ` as the input vector  ( set of words ) becmnes more similar to c : omplete vector ( set of words ) pattern . Only about tlve words are enough to identify each scene at recognition rate of  90 percent . 
Compared to the average , number of 184 words ill each scene , this required mlmber is sufficiently small . It proves good performance of the ` associative memory used in this module  . ' l ~ heoretical re-suits of a random distribution model is also shown in Fig  . 7 . The cause of the discrepancy between the experiment and theory is describe < l latter  . The dotted line ' EXACT ' ill the tlgure is a result il S-ing logical-smnmation  . " File crossing point <> f the ' OPED ' line and the ' IgXACT'line  . is remarkable . 
Tileformer has the adwmtage of expecting with relatively high-probM fility  ( likelihood ) using input words of small number . Though with more additional words , the algorithm is de Dated by the simple logical -sumination  . As our architecture PDAI&CD uses dual-phase of expectation and evaluation  , we can get a solution with maximum-likelihood slttisfying constraints automatically  . 
? Fig . 8 shows tile distribution of mnnber of elements contributing to identify each scene uniquely  . 
? In order to clarify tile discrepancy of tlle experimental an ? l theoretical results  , tile number of ele-lnents overlal ) lm dill any twost : ones are connted . 

Recalling ratio . o1 . 64 ) . 4~ ) . 21 " I\[II 5 10 15 20
Number of elements of partial match
Figure 7: Recalling prollahility to number of partial input elements 
Recalling ratiot.(~_i3.1 3.1 3., 0.:0 J
I '\ [ Tr ; h ~
II 5 10 15 20
Number of elements of partial match
Figure 8: Distribution of mmfller of partial inlmt elements to identify scenes As in Fig  . 9 , tit(' , number of overlal ) ping ( , lernents in the . the . oretieale ~ dculation is very small compared to the exper hr  , ents with Of ) El ) . OPfi ' , D-2 ill tile figure illustrates the same , ? alue without using trivial words like ' a ' , ' the ' , ' of ' , ' that ' , ' to ' , ' in ' , ' and ' , fief ' , ' with ' , ' s ' . But the . existence of these words cannot explain the whole discrepancy  . This will be deserilled in the next section ill more detail  . 
* As filrther investigation in order to explain tile discrepancy of ' EXACT '  ( logical-sunn nation ) and ' OPED ' ( with our associative memory )  , distrilm-tion of weight v ~ tlues is shown in l , 'ig . 10 . I , ~) /'; ical-surnmation me . tho disachieved by a spe ( : ial algorithm similar to the associative memory . Only tile ditferenee is that it uses equal weight value with-log  ( number ) Figure 9: Distribution of number of elements comnmn to two seelles  10g  ( number )  0 . 4
Distribution of weighl value 0 . G 0 . 8 1 . 0 Vigure 10: Distribution of weight value out anyw trianee , l lut in practic ~ t l , the experimental result of ' OPED ' as ill \]' ~ ig  . 1 0 show same xistence of enormous w triance illtile distrilm tion of weight value  . Thoughtile varimme helps the selectivity with it few words  , it disturhs the expectivity with lll Ol'e thall l \] lrt!ew  ( )rds eol ivers ( q y , l\[el'e we sum nmrize the interl ) ret ; t tion of the gaps ~ tmonF , the theoretical expectation , the rest , It of logic ~ tl-summalion ('\]'; XAC' . l "), and the system (' OPl ~, l )') : 1 . l'~x sistem : e of trivial words in most of tile seelle S  . 
2. Variance of weight distribution.
3 . l ) ilference of characteristics hetwee . n algorithms . 
? Abstracted results are summarized in Tabh . ' . 3 . In this table , the number of re . gistered words ill dictionary itself is ditferent from the nurn ber of the total words analyzed hy our systern  . The diserep-alley arises mainly Dora the fact that we analyze demn pound words into simple words  ( e . g . ' research laboratory'to'research '~' ~ ittl ' laboratory '  )  . 

Table 3: Summarized results
Total ~ of scenes 384 scenes
Registered  #of words 27,500 words
Total  #of words 11,711 words
Average  #of words/scene 184.2 words
Mm , ~#of words in one scene 478 words
Required  #of words to 5 words identify scenes at 90% ratio
Required  #of words to 4 words identify scenes at 90% ratio by exact match algorithm
Theoretical estimation of 2 words required  #of words to identify scenes at 90% ratio 5 Summary We analyzed the selectivity of our 384 living scenes with many sets of words which are part of  11  , 711 words used in the dictionary OPED . The average munber of words in one scene is about  184  . The probability of re-calling correct scenes with input partial words is difl'er-ent from the theoretical simulation of random assignment constructed with v Mues of these parameters  . Unlike random generation of arbitrary symbols , semantics of natural anguage consists of highly -correlated meanings of words  . Although the theoretical simulation of the simplified model suggests a rough estimation of disambiguation requirements we should analyze the dictionary itself as in this paper  . 
Another suggestive analysis is using Shannon's information or entropy  , which gives us more accurate . 
information depending on prol ) ability of each phenomenon . It shows how to estimate the amount of semantic ambiguity  . 
Spatial-scene identification is one of the simplest kind of context necessary to disambiguate meaning of words an  ( \[ offer a new method for future integration of natural language processing and visual pattern recognition  . 
6 Acknowledgements
The authors acknowledge Randy Goebel , Nancy Ide , Jean Veronis , Hiroaki Kitano , Koiichi II ashida , Katashi Nagao and Lawrence A . Bookman for helpful discussions and suggestions . Also the authors thank Kazuhiro Nala ~ tdaind Satoshi Murakami for transformation of the pictorial dictionary into machine-readable one  . This research is supported by Fellow-ships of the Japan Society for the Promotion of Science for Japanese Junior Scientists and Grant-in-Aid for Scientific Research on Priority Areas by the Ministry of Educations  , Science and Culture , Japan . 
References\[1\]AmariS . and Maginu K .  (1988) . Statistical Neu-rodynamics of Associative Memory . Neural Networks , Vol . 1-I , pp . 63-73 . 
\[2\] Barwise . \] . and Perry J .  (1983) . Situation and
Attitudes , MIT-Prcss.
\[3\] Bookman L . A .  (1993) . AScMable Architecture for Integrating Associative and Semantic Memory  . Connection Science , Vol .  5 . 
\[4\] Cottrell G . W .  (1989) . A Connectionist Approach to Word Sense Disambiguation  , Pitman , Morgan
I ( aufmann Pub.
\[5\]IdeN . M . and Vcronis J .  (1993) . Extracting Knowledge Bases from Machine-Readal ) le Dictionaries : Have We Wasted Our Time ? In KB ~ KS  93  , pp . 257-266 . 
\[6\] Kohonen T .  (1984) . Self-Organization and Associative Memory , Springer-Vcr lag . 
\[7\] Miikkulainen R .  (1993) . Subsymbolic Natural Language I ) rocessing : An Inteyrated Model of Scripts , Lea:icon , and Memory . , MIT-Press . 
\[8\]N is hikimiM . , Nakashima II . and Matsubara II . 
(1992). Language Acquisition , ' us Learning . In
Proceedings of COLING-92, pp . 707-713.
\[9\] Shannon C . E .  (1948) . A Mathematical Theory of Communication . Bell System 7~ch . J . , Vol . 27, pp . 373-423, 623-656 . 
\[10\] Sharkey N . E .  (1989) . APDP Learning Approach to Naural Language Understanding  . In Alexm~-der I . Ed . , Neural Computing Architectures : The Design of Brain-like Machines  , MIT-Press , pp . 92-116 . 
\[11\]S hastriL .  (1988) . Semantic Networks : An Evidential Formalization and its Connectionist Realization  , Morgan Kauflnann . 
\[12\]Tsu nod~tT . and Tanal ~ tIt .  (1992) . Semantic Ambiguity Resolution by Parallel Distrit ) uted Associative Inference and Contradiction Detection  . In Proceedings of LICNN-Nagoya93, Vol . I , pp . 163-166 . 
\[131 Tsunoda T . and Tanata't H .  (1993) . Winner As-sociatiw ; Voting Engine ( WAVE) . In Proceedings of LlCNN-Beijing 92, Vol . 3, pp . 589-594 . 
\[141 Veronis J . and Ide N . M .  (1990) . Word Sense Disambiguation with Very Large Neural Networks Extracted from Machine Readable Dictionaries  . 
In Proceedings of COLING90, pp . 389-394.
\[15\]WaltzD . L . and Pollack J . B .  (1985) . Massively Parallel Parsing : A Strongly Interactive Model of Natural Language Interpretation  . COGNI-
TIVESCIENCE , Vol . 9, pp . 51-74.


