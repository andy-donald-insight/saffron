An Experimental Parser for Systemic Grammars
Robert T . KASPER
USC/information Sciences Institute
4676 Admiralty Way , Suite 1001
Marina del Rey , CA 90292 U.S.A.

We descrl be a general parsing method for systemic grammars  . Systemic grammars contain a paradigmatic analysis of language in addition to structural information  , so a parser must assign a set of grammatical features and functions to each constituent in addition to producing a constituents ruc-ture  . Our method constructs a parser by compiling systemic grammars into the notation of Functional Unification Grammar  . The existing methods for parsing with unification grammar shace been extended to handle a fuller range of paradigmatic descriptions  . In particular , the PATR-II system has been extended by using disjunctive and conditional information in functional descriptions that are attached to phrase structure rules  . The method has been tested with a large grammar of English w : hich was originally developed for text generation  . This testing is the basis for some observations about the bidirectional m~e of a grammar  . 
1 Introduction
Many computational linguists have found systemic grammar  ( SG ) to be quite useful , because it provides an explicit representation of features that determine how a sentence functions in the context of communication  . SG has been used directly as the basis for several computer tex ~ generation programs\[ Mann  82\]  , but it has only been used indirectly for computational parsers  . Winograd used principles from SG in designing SHRDLU\[Winograd  72\]  , a successful natural language understanding program  , but his program did not contain an explicit representation of the grammar's system network  . Instead , he used a special purpose programming language to encode grammatical knowledge in a procedural form tailored specifically to the language understanding task  . Another procedural implementation of SG was developed by McCord\[McCord  77\]  . Both of these methods would require a significant progranmfing step before a parser could be produced for a different grammar  . Our goal has been to develop a general parsing method using a declarative representation of SG  , and to determine to what extent a grammar that is adequate for text generation can also be used for text analysis  . Our parser has been developed and tested using Nigel\[Mann  83\]  , a large grammar of English that has previously been used as part of a text generation system  . 
Systemic l ; nguistics builds on the foundation of Hailiday's con  . .
cept of the system Setwork\[Halliday 76\] . A systemic grammar is organized around choices between grammatical features that reflect the structure and content of a constituent  . Each choice between features is called a system . Thus , a systemic grammar has two major components : I . a system network of feature choices , and 2 . structur M realization statements corresponding to each feature  . 
The feature Choices define the options available to be expressed in 
RANK-Clause ~-...

TYPE a language , and may be regarded as " hooks " into a semantic component  . The realization statements determine the constituent structure  . There are realization statement so decl are the presence of constituents  , conflate constituents , pecify feature constraints on constituents , and specify ordering constraints among constituents  . 
Consider , for example , the fragment of a grammar of English clauses shown in Figure  1  . There are two systems , labeled by Mood-type and Indicative-type . Each system has an input condition to its left , specifying when its options are applicable . The input condition for Indicative-type is the single feature  , Indicative , but input conditions may also be expressed by boolean combinations of features  . In each system , exactly one of the features to the right of the vertical bar must be chosen  . For example , in the Indicative-type system , either Declarative or Interrogative must be chosen  . Under each feature are realization statements , such as SUBJECTAFINITE under the Declarative feature  . This statement specifies that the SUBJECT constituent must precede the FINITE constituent in declarative clauses  . Each realization statement is associated with a particular feature  , so that structural constraints are distributed throughout the system network  . The distributed nature of structural information in SG presents a challenge to the design of a parser  , which we will address in Section 3 . 
In addition to building a constituent structure for a sentence  , as do most syntactic approaches to natural anguage parsing  , a parser for SO must also perform the following tasks :  1  . determine the set of systemic features for each constituent  ,  2 . assign grammatical functions to each constituent . 
Other theories of grammar also make use of features and grammatical functions  , however they have a distinct significance in system ic theory  . The feature set associated with a constituent plays an important role in specifying its meaning  ( i . e . , the features are not simply discarded after syntactic analysis  )  , so a relatively I ~ , rgenumber ( e . g . , over 50 ) of features may need to be assigned to eac ! , constituent . 
Each constituent may also be assigned to several grammatical functions  , because of the multifunctional nature of systemic analysis  . For example , it is common to describe a single constituent simultaneously as SUBJECT  , ACTOR and TOPIC . Therefore , in order to determine that a clause has an ACTOR , it may be necessary to check whether the clause has a SUBJECT and whether the SUBJECT of the clause is conflatable with the  . ACTOR function . 
An example of the type of output produced by the parser is shown in Figure  2  . This example shows only the functional structure that the parser assigns to the sentence  . In addition , each constituent is assigned a set of grammatical features  , such as Indicative and Declarative . These features are also accessible in the data structures produced by the parser  , but they are too numerous to display in this short paper  . 
t-Imperative
NONFINITIVE ~ Stem ~- Declar atlve SUBJECTAFINITE -Indicative-INDICATIVE TYPE 
SUBJECT : Nomin at lve-Interrogative
Figure I : The Mood-type and Indicative-type Systems  . 
309/TOPICAL/SUBJECT/MEDIUM GOAL 7, . /, DEICTIC - - - - thlsdet / ~" . THING----document // TEMPO0 /VOICEIFINITE-~-~--b ~ . ~ uxII , PROCESS/LEX VERB/VOICEDEPENDENT---v--crQate --/ eFD --~""' AGENT/ACTOR--  . -(-' wAGE-'-/--r,sw ~,' . , SUBJECT/J/<"ON'TE////~PREDIOATOR-- . ./ VOIOEI / "' . LEX VERB Figure 2: Functional Structure of : " This document was created by a new computer  . "2 Comp Uatlon into Functional Unification

The basic method used to construct the parser has been to develop a compiled representation f systemic grammars in the notation of Functional Unification Grammar  ( FUG )  . The parsing process itself is then derived by extending methods already developed for parsing With FUG\[Kay  85\]  . In FUG , a grammar can be regarded as a special kind of logical formula \ [ Rounds  87\]  , and the parsing problem is reduced to finding the set of feature structures that satisfy the formula subject othe constraints of the words in a particular sentence  . Using the feature description logic ( FDL ) of Kasper and Rounds\[Kasper86\] , the types of formula used to define a grammar include :  1 
NIL denoting noi ~ formatloa ; a where a EA , to describe atomic values ; l : ~ b where IEL and ~ EFDL ~ to describe structures in which the feature labeled by l has a value described by ~  ; qlorl : ANY where lEL , to describe a sliructure in which I has a substantive  ( non-NILI value ; < p > where pEL * , to describe a structure that shares a common value with the path p  ; \[~ bl . . . ~\] where ~ b ~ EFDL , denoting conjunction ; ~ bl . . . ~ b , ~ where ~ b ~ EFDL , denoting disjunction ; ~1--*~ where ~ b ~ EFDL , denoting classical implication . 
The last type of formula , denoting implication , is an extension to FUG that enables a more efficient modeling of systemic descriptions than is possible in Kay's version of FUGIK as per  87d\]  . 
The compilation of systems into FUG is relatively straightforward  . Each system is represented by a disjunction containing alter  . 
natives for each feature that can be chosen in the system  . These alternatives also contain attributes that represent constraints on grammatical functions imposed by realization statements  . For example , the Mood-type and Indicative-type systems can be represented by the description shown in Figure  3  . System input conditions are bidirectional : they are represented by the embedding of descriptions  , and also by feature xistence conditions . 
In the FUG representation there is one functional description  ( FD ) corresponding to each m ~ i or constituent category of the systemic grammar  . Major constituent categories for English include clause  , nominal-group , and prepositional-phrase . The method of representing a systemic grammar as a set of FDs in FUG is described in greater detail in \[ Kasper  87b  , Kasper 87 d\] . A program has been implemented to automatically translate any system network into FDs  , verifying the effectiveness and generality of this compilation procedure  . This program has been used to compile the entire Nigel grammar  , which contains over 500 systems , into FUG many different times as changes to the grammar have been made  . 
: Let A and L be sets of symbols used to denote atomic value J and feature labels  , respectively . 
Rank : Clause
Mood-type : Imperative
NONFINITIVE :\[ Form : Stem\]1
Mood-type : Indicative
SUBJECT:\[Case:Nominative\]pattern : ( .  , . SUBJECTFINITE . . . ) \[ Indlcatlve-type : Interrogative \] 3 M-cod-type----*\[Rank:Clause\] 3 Indicative-type ~\ [ Mood-type : Indicative \] Figure  3: The Mood-type and Indicative-type Systems in ex -tended-FUG notation  . 
3 Parser Implementation:
Extending PATR-II
Our early experiments using the Nigel grammar showed that the existing methods for parsing with FUG had several shortcomings when applied to a large grammar  . Kay's method for parsing with FUG\[Kay 85\] cannot be applied directly to our grammar because it requires :  1  . expanding the grammar FD to disjunctive normal form  ( DNF )  ;  2 . creating a disjunct for each possible ordered combination of constituents hat is compatible with pattern features  . Each of the sedls junets can be regarded as equivalent to an annotated phrase structure rule  . 
In bath cases our grammar contains too many alternatives to carry out the procedure :  1  . Our grammar of English clauses contains over 100 systems . 
Since each system is represented by a disjunction in PUG  , the DNF expansion of the clause grammar might require over  2100 disjunets l 2  . Our grammar contains many optional grammatical functions  . 
A particularly striking example concerns the large number of optional adjunctypes that may be used to modify an English clause  .   2 These adjuncts occur most frequently at the end of the clause  , although other orders are possible . Assuming that there are at least 10 optional adjunctypes , " we have 2 l ? different combinations of adjuncts , not counting any additional combinations resulting from order variation  . 
The first problem has been solved by a new unification algorithm for disjunctive descriptions that does not require expansion to DNF\[K asper  87c  \] . The second problem has been solved by adding a small phrase structure component to the grammar and using the PATR-II active chart parsing algorithm  , which was developed by
Shieber et al at SRI\[Shieber 84\].
3 . 1 Ske le ta l Phrase S t ructure Component The role of phrase structure  ( PS ) rules in our parser is similar to their role in Lexical Functional Grammar \ [ Kaplan  83\]  , however they have less theoretical significance in our parser  , We use the PS component ore cognize possible patterns for each major constituent category  , but the unification component builds the functional structure and assigns a feature set to each constituent  . The PS component is something like a skeleton that cannot be seen in the final descril ~  . 
tions produced by the p~ser . Not very many PS rules are required , because they only need to encode broad category distinctions  . Fine category distinctions are encoded by the FDs that are attached to rules  . Each major constituent category of the grammar has a special rule that is annotated with the FD produced by compilation from the systemic grammar for that category  . For example , the category
CLAUSE has a rule of the form := A part lalilt of adjuncty peslnclude ~: MANNF_~CAUSE  , ACCOMPA-NIMENT , SPACE-LOCATIVE , SPACE-EXTENT , TIMF ~ LOCATIVE , TIME-
EXTENT , MATTER , ROLE , ATTITUDE.

CLAUSE--~CLAUSE ~ PS:<CLAUSE >= < OLAUSF_ , - PS fd><CLAUSE >=\[ compiled FD for CLAUSE\] . 
CLAUSF ~ PS is a non-tarminal that can derive any valid constituent pattern for cl ~  . uscs . The first unification of this rule identifies any features that are known from the constituents derived by CLAUSF ~' PS with features of the CLAUSE nontermin a L The second unification provides the functional description that must be satisfied for any clause  . 
Consider again the problem of optional adjuncts . Instead of producing a distinct disj ' unct for each combination of adjuncts  , it is much more efficient odescribe all possible combinations using a single recursive PS rule  . This rule is annotated with a disjunctive description that contains a single alternative for each adjuncty p e : 
CLAUSE-PS~--* CLAUSE-PS2 ADJUNCT : < CLAUSE-PS-I >=\[ MANNER : < ADJUNCT >  1 \[CAUSE : < ADJUNCT >\] .   .   . other alternatives . 
The PS component is the only part of the grammar used by the PATR-II parser that is not produced automatically from a systemic grammar  . The pars ! ng grammar for Nigel currently contains about  6D PS rules . 
3.2 Extensions to PATR-H
The PATR-II system has been extended in several significant ways to carry out c ~ ur implementation  :   1  . handling disjunctive and conditional descriptions \[Kasper  87c  , Kasper 87 d\];2 . using t ~ bles compiled from the realization statements of SG  . 
These tables include the possible confiations for each grammatical function  , and lexical items that are associated with particular features in the grammar  . 
The compiled tables and skeletal phrase structure component enable the parser to directly deduce structural information about a sentence  , despite the distributed nature of structural constraints in SG  . 
grammar that require an inordinate amount of time to resolve  . Systemic grammars can exhibit ambiguity between grammatical features  , in addition to the wellknown types of lexieal and structural ambiguity  . 
Unintended ambiguities between grammatical features often arise from underspecified parts of the grammar  , i . e . , the grammar contains an alternation between two or more features within sufficient realization information to determine which features apply in many eases  . 
Usually the solution to this problem is to add realization information for those features  . Sometimes the realization of those features may depend on other features and the modification is somewhat complex  . 
In such cases , it is possible to temporarily disable the underspeeifiad alternatives while parsing until a more complete solution is developed  . 
Some features may have realizations that are formally adequate and efficient for generation  , but quite inefficient for parsing . For example , the Nigel grammar for nominal groups contains the Pronomi-nal feature to indicate that the head constituent is a pronoun  . There is no explicit realization statement associated with this feature  , but the system network contains more specific features for each of type of pronoun  . These more specific features have realizations that specify particular lexical items for the head constituent  . Since English pronouns are a closed class , there is a finite number of features that need to be examined to determine whether a nominal group is pronominal  . 
However , it is quite inefficient o consider each member of the class individually  . Obviously , we can improve the parsing efficiency of the grammar by adding a realization to the Pronominal feature that constrains the head to be a member of the class of pronouns  . We have found a significant number of similar cases  , where the grammar was adequate for generation , but was missing some useful generalization for analysis  . 
It seems reasonable to expect hatmost grammars that are originally developed specifically for generation or parsing tasks will need similar kinds of tuning before they can be used effectively for the inverse task  . A bidirectional grammar seems to be a reachable goal  , but it will probably have some specifications that are superfluous for either parsing or generation  . These specifications can be marked if necessary for efficiency  , so that the parser or generator does not have to examine unnecessary information  . 
5 Conclusions 4 Bidirectional Grammar Bidirectional grammar , i . e . using the same grammatical knowledget brboth parsing and generation of a language  , has been a real but sometimes elusive goal in computational linguistics  . The goal of bidirectional grantmar was clearly a motivation for Kay's formulation of FUG\[Kay  85 I . Kay has shown that if a declarative representation is used to encode the grammatical knowledge of a language  , then it should be possible to compile that knowledge into appropriate data structures for parsing or generation  . We have followed this method in constructing ~ parser for systemic grammars by compiling the grammar into a notation like FUG  . Our discussion in this section tb cuscs on other issues besides compilation that have been identified in our effort to dew  . 'lop a bidirectional systemic grammar . 
Our experience with the Nigel grammar has indicated that it is possible to develop a bidirectional grammar within the systemie -functional framework  , although a substantial amount of effort may be required to tune the grammar for both parsing and generation  . 
In other words j the framework of systemic grammars is potentially invertible  , bui ; particular grammars may require some modification before they cunbe used effectively for both parsing and generation  . 
Generally , parsing places greater demands on the realization component of the grammar  , while generation places greater demands on the systems of choice  . The Nigel grammar was originally developed for use instext generation program  , so our observations deal mostly with problenm that can arise when inverting a grammar that is adequate for gem ~ ration but untested for analysis  . 
Most pnodifications that we have made to enable parsing involve eliminating u~dntended ambiguities or disjunctive alternatives in the We have developed a general method for parsing systemic grammars by extending the techniques of FUG and the PATR-II system  . The parser is reasonably efficient for grammar testing and use as a linguistic research tool  , but further refinement would be necessary for applications demanding realtime performance  . Using the full Nigcl grammar , it currently requires less than a minute to parse simple single-clause sentences  , and several minutes to parse more complex sentences  . It should be noted that parsing speed depends heavily on grammar size  , and we are using a graznmar that is significantly larger than most grammars that have been implemented to this date with unification-based methods  . 
We have only investigated an exhaustive bottom-up strategy  , in which the parser produces all possible parses for a sentence  . This Strategy is well-suited to gramm~testing , but other strategies should be developed for applications demanding more selectivity and efficiency  . We have not yet attempted to incorpora textra -grammatical  ( i . e . , semantic and pragmatic ) information for ambiguity resolution , but this would also be necessary for most practical applications  . 
It would be very desirable to discover a way to produce the phrase structure component of the parsing grammar  , or some functionally equivalent mechanism , automatically from a systemic description . 
If accomplished , this would make it possible to fully automate the production of a parsing grammar  , but this appears to be a difficult problem . It is currently much easier to 15reduce a small phrase structure component manually from one's knowledge of the grammar  . 

I would like to thank Bill Mann for originally suggesting and eneouroaging this topic of research  . I would also like to thank Christian Rounds for helpful comments on the design of the parser  , and Stuart Shieber for providing help in the use of the PATR-II system  . 
This research was sponsored in part by the United States Air Force Office of Scientific Research contract  F49620-87-C-0005  , and in part by the United States Defense Advanced Research Projects Agency under contract  MDAY03-81-C-0335  ; the opinions expressed here are solely those of the author  . 
References \[ Kaplan 83\] \[Kasper 87a \]\[ Kasper 87b1 \[Kasper 87c \]\[ Kasper 87d \]\[ Kasper 86\] Kaplan , R . and J . Bresnan . Lexical Functional Grammar : A Formal System for Grammatical Representation  . In J . Bresnan , editor , The Mental Representation of Grammatical Relations  . MIT Press , Cambridge , Massachusetts , 1983 . 
Kasper , R . Feature Structures : A Logical Theory with Application to Language Analysis  . PhD dissertation,
University of Michigan , 1987.
Kasper , R . Systemic Grammar and Functional Unification Grammar  . In J . Benson and W . Greaves , editors , Systemic Functional Approaches to Discourse , Norwood , New Jersey : Ablex ( in press ) . Also available as USC/Information Sciences Institute Reprint 

Kasper , R . A Unification Method for Disjunctive Feature Descriptions  . In Proceedings of the 25 ~h Annual Meeting of the Association for Computational Linguistics  , Stanford University , Stanford , CA , July 69 ,  1987 . Also available as USC/Information Sciences Institute Reprint  RS-87-187  . 
Kasper , R . Conditional Descriptions in Functional Unification Grammar  . USC/Information . Scienees Institute Research Report RR-87-191 , November ,  1987 . 
Kasper , ~ . and W . Reuncls . A Logical Semantics for Feature Structures . In Proceedings of the 24 ~h Annual Meeting of the Association for Computational Linguistics  , Columbia University , New York , NY , June
I0-13, 1986.
\[Kay 85\] \[ Halliday 76\] \[ Mann 82\] \[ Mann 83\] \[ McOord 77\] \[ Rounds 87\] \[Shieber 84\] \[ Winograd 72\] Kay , M . Parsing in Functional Unification Grammar . 
In D . Dowry , L . Karttunen , and A . Zwicky , editors , Natural Language Parsing . Cambridge University Press , Cambridge , England ,  1985 . 
G . R . Kress , editor . Halliday : System and Function in Language . Oxford University Press , London , England , 1976 . 
Mann , W . C . Text Generation . Section of Applied Computational Linguistics in Perspective : Proceedings of the Workshop  , In American Journal of Computational Linguistics , Vol .  8:2, 1982 . 
Mann , W . C . mad C . Matthisssen . Nigeh A Systemic Grammar for Text Generation . USC/Information Sciences Institute , RR-83-105 . Also appears in R . Bunsen and J . Greaves , editors , Systemic Perspectives on Discourse : Selected Papers Papers from the Ninth International Systemics Workshop  , Ablex , 
London , England , 1985.
McCord , Michael C . Procedural systemic grammars.
In International Journal of Man-Machine Studies,
Vol . 9, pp . 255-286, 1977.
Rounds , W . C . and Manaster-Reaner , A . A Logical Version of Functional Unification Grammar  . In Proceedings of the 25 th Annual Meeting of the Associa . 
tion for Computational Linguistics , Stanford University , Stanford , CA , July 69 ,  1987 . 
Shieber , S . M . The design of a computer language for linguistic information  . In Proceedings of the Tenth International Conference on Computational Linguistics : COLING  8  . ~, Stanford University , Stanford,
California , July 27, 1984.
Winograd , T . Understanding Natural Language , New
York : Academics Press , 1972.

