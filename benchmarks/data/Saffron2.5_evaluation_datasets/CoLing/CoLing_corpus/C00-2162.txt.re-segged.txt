Improving SMT quality with morphosyntactic analysis 
Sonja Nieflcn and Hcrmann Ney
Lehrstuhl fiir hflbrl natik VI
Computer Science Department
RWTH University of Technology Aachen
D-52056 Aachen , Germany
Email : niessen@in?ormatik , rwth-aachen , de
Abstract
In the framework of statistical machine translation  ( SMT )  , correspondences between the words in the source and the target language are learned from bilingual corpora on the basis of socalled alignment mode  , Is . Many of the statistical systems use little or no linguistic knowledge to structure the underlying models  . In this paper we argue that training data is typically not large enough to sutficiently represent the range of different phenomena in naturalangua-ges and that SMT can take advantage of the explicit introduction of some knowledge about the lmlgnages under consideration  . The improvement of the translation results is demonstrated on two ditferent German-English corpora  . 
1 Introduction
In this pal)er , we address the question of how morl ) hological and syntactic analysis can help statistical machine translation  ( SMT )  . In our apl ) roach , we introduce several transtbrmations to the source string  ( in our experiments the source language is German ) to demonstrate how linguistic knowledge can improve translation re-suits especially in the cases where  , the token-type ratio ( nmn ber of training words versus n mn be r of vocabulary entries  ) is unth vorable . 
After reviewing the statistical approach to machine translation  , we first explain our motivation for examining additional knowledge sources  . We then present our approach in detail . 
Ext ) erimental results on two bilingual German-English tasks are reported  , namely the VERBMOBIL and the EUTRANS task . Finally , we give an outlook on our fllture work . 
2 Stat i s t i ca l Mach ine Trans la t ion The goal of the translation process in statistical machine translation can l  ) efornmlated as tbl-lows : A source language string  . f ~ = fl .   .   . f . ! is to be translated into a target language string c\[=-el  .   .   . el . In the experiments reported in this paper , the source language is German and the target language is English  . Every English string is considered as a possible translation for the intmt  . If we assign a probability P'r ( e\[lfi / ) to each pair of strings ( el , fi /) , then according to Bayes'decision rule , we have to choose the English string that maximizes the I  ) roduct of the English language model Pr ( c ) and the string translation model r'r ( fff\[e )  . 
Many existing systems tbrSMT ( Wang and
Waibel , 1997; Niefien et al , 1 . (/98; Och and Weber ,  1998 ) make use of a special way of structuring the string translation model  ( Brown et al ,  1993 ) : ' l ? he correspondence bt ween the words in the source and the target string is described by aligmuents that assign one target word position to each source word position  . The probability of a certain English word to occur in the target string is assumed to depend basically only on the source word aligned to it  . It is clear that this assumption is not always valid t br the translation of natur M languages  . It turns out that even those approaches that relax the word-by-word assumption like  ( Och et al ,  1999 ) have problems with ln any phenomena typical of natural languages in general and German in par -titular like ? idiomatic expressions  ; ? coln pound words that have to be translated by more than one word  ; ? long range dependencies like prefixes of verbs placed at the end of the sentence  ; ? ambiguous words with different meanings dependent on the context  . 

Tile parameters of the statistical knowledge sources nlentioned above are trained on bilingual corpora  . Bearing ill mind that more than 40% of the word tbrms have only been seen once in training  ( see q ~ , bles 1 and 4) , it is obvious that the phenomena listed above can hardly be learned adequately from the data and that the explicit introduction of linguistic knowledge is expected to improve translation quality  . 
The overall architecture of the statistical translation approach is depicted in Figure  1  . hit his figure we already anticipate the t'a et that we will transt brm the source strings in a certain manner  . If necessary we can also apply the inverse of these transfbrmations on the produced output strings  . Ill Section 3 we explain in detail which kinds of transtbrmations we apply  . 
Source Language Text 1'fl
Global Search : maximize Pr(el ) . Pr(f~lel ) over eI1 Il
Target Language Text lJI ~ Lexicon Model Pr ( l1\]e , ) \[
Alignment Model \]
Language Model
Figure 1 . : Architecture of the translation 31 ) -preach based on Bwes'decision rule . 
3 Ana lys is and Trans format ion of the Input As already pointed ou L we used the inethod of transforming the in l  ) ut string in our experiments . The advantage of this approach is that existing training and search procedures did not have to be adapted to new n lodels incorporating the information under consideration  . On the other hand , it would be more elegant to leave the decision between different readings  , t br instance , to the overall decision process in search . 
Tile transtbrmation method however is nlore 3 ( t-equate t br the preliminary identification of those phenon mn a relevant brim proving the translation results  . 
3.1 Analysis
We used GERTWOL , a German Morphological Analyser ( Haap alainen and M~@ ) rin ,  1995 ) and the Constraint Grammar Parser Ibr German GERCG tbr lexical analysis and in or pho-logical and syntactic dismnbiguation  . For a description of the Constraint Grammar approach we refer the reader to  ( Karlsson ,  1990) . Some prel ) rocessing was necessary to meet the input format requirements of the tools  , hithecases where the tools returned lnore thalt one reading  , either simple heuristics based on domain specific pret brence ruh  ; s where at ) plied or an lore general , non-mn biguous analysis was used . 
In the following subsections we list some transtbrmations we have tested  . 
3.2 Separated German Verb prefixes
Sortie verbs in German consist of a main part and a detachable prefix which can be shifted to the end of the clause  , e . g . " losfahren " ( " to leave " ) in the sentence " Ich fahremor genlos . " . 
We extr~cted all wordforms of separable verbs fl : omth  . etraining corl ) us . The resulting list contains entries of the tbrm prefix lmain  . The entry " los\[t : ' ahre " indicates , f i ) rexaln ple , that the prefix " los " ( : anl ) e detached flom the word tbrm " fahre " . In all clauses containing a word matching a main part and a word matching the corresponding prefix part occuring at the end of the clause  , the prefix is prepended to the beginning of the main part  , as in " Ichlos fah remorgen . " a . a German Compound Words German comt ) (mnd words pose special 1 ) roblems to the robustness of a translation method , because the word itself must be represented in the training data : the occurence of each of the coin-t  ) onents is not enough . The word " I ~' iichtetee " t brexample cannot be translated although its coml  ) onents " Friichte " and " Tee " appear in the training set of EUTRANS  . Besides , even if the coml ) ound occurs in training , tile training algo-rithm may not be capable of translating it properly as two words  ( in then lentioned case the words " fl ' and " tea "  ) due to the word alignment assumption mentioned in Section  2  . We (: Oml ) onents . 
3 , ,4 Annotat ion w i th POS Tags ( ) he way of hell ) rig the disanfl ) iguation of gill-t ) Jguous words is to annotate them with their t ) m : l ; of Sl ) eech(POS ) in l'()rmation . We (: hosel ; het bllowing very ti'equent short words that often  ( : ; rased errors in translation fi ) rVERBMO\]3 IL : " aber " can1 ) e adverb or ( : on jun ( 'tion . 
" zu " can l ) ead verb , pret ) osition , sepnrated verb prefix or infinitive marker . 
% ler ' , " die " and " das " cnn 17 edefin item : ti-
CIosel'\])1" Ol1Ol111S.
' . \[' he difficulties due to l ; heseaml ) iguities m : e illustrated by the f i ) lh ) wingexmnt ) les : The sentence " D as wiird ( ' mirse hrgut 1 ) ~ssen . '' is often trnnslnted 1) y " Th , e would suit mevery well . " iltsl ; e;~(l()\["5l'h , at would suit mevery well . " and " Daswin : zus (: lmcll . " is trnnsl ; ~ tedby " Th ~ Lt was to t ' ~ lsl; . " instea , ( tof " Theft ; was to of ; ~ st ; . " . 
We alTpended the POS l ; ~ g in training a , mtt(;st corpus fiTr the VERB MOBII , task ( see 4 . \]) . 
3.5 Merging Phrases
Some multiword phrases as ~ whole rel ) r ( ; sent a distine ( ; synta . 7" tierob ; in (; hes(mtenT : e . The 17 hra . se " irg end (' . t ; w ; ls " (% nything ") for exa , m-t ) 1(;m~y form (' it , l , (' a:a . nin(h't init ; (' . ( h ' . t;(' . rmino . r ( ): can in ( lelinil ; e pronoun . Like 2\] other mull ; i-wordtThrases " irg(:nd-et ; wa . s " is merged in order t ; of or monesing levoca , bulary (' nl ; ry . 
3 . 6 Treatment of Unseen Words l " or sl ; atist ; i (:: flma(:hin ( ; tr ; mslation it is difficult1 ; () handle woi'ds not seen in training . \] ~ brm>kllOWlli ) l ; O1)el ; ll & llIeS ~ i\[ ; is normally ('( TrreT't to t ) bme the word un ( ; h~mge(t into th ( ; transl~fl ; ion . 
We have t )( ; ( ; n working on the l ; 17ea~l ; nlen I ; of 1111-kll () Wll words of other types . As ~ flr(;~dymen-l ; ioned in Se(:l ; ion 3 . 3 , thest ) litting of e omt ) ound words cml reduce ; henmn ber of unknownCl(:r-man words . 
In addition , we have examined methods of r ( > pl ~ ( ' ing a word\['ullforml ) y ~ more ; O ) stra('l ; wordform nnd ( -heek whether this fi ) rm is kn ( )wn and ( : ; ~ml)eI ; ranslnted . Th('l ; rml slat , ioll of the s in > ) lifted word tbrm is generally not the prec is ( ' trml slai ; ion of the original on (' , 17 ul ; sometimes the intended semantics is conveyed , e . g . : " kaltes " is ~ m adjective in the singular neuter fOl  ; lll & lid . c3~11 bet , l ' a , nst : ' ornled to the less specilic form " kalt " ( " cold " )  . 
" Jahre " ( " years " )   ( : ~ m be replaced by the sin-gulm:form"J~fln : " . 
" beneidest " ( % oenvy " in tirst person singular ) : if the infinitive tbnn " beneiden " is not known  , it might hell ) . just , to remove timle a dingt ) artiele " be " . 
4 Translation Results
We use the SSER ( sul ) jectiv c sentence error rat ( ' )   ( N i ( ' fien et al ,  2000 ) as evaluation cri-t ( ' rion : E ~ wh translated senten ( : e is judged by ~ tmmmi exmniner according 1 ; (7nn error scale ti'om 0 . 0  ( semantically and syntaeti ( : ~ flly colreef ) to 1 . 0 ((: onlt ) l ; elywrong) . 
4 . 1 Translation Results for VEm~MOmLT h ( , VEIBM ( ) BII , corpus consists of st ) on ttme-ously spoken dialogs in t ; heal ) t ) oint ; mentsch(>(hfling domain ( Wtflflster ,  1993) . German sen-t ; ences ; ~ rel ; ra . nsl ; ~ lx ; dinl ; oEnglish . The output of the st ) ee ( ' hre ( : ognizer ( Ibr example th (  ; single-best hyl ) othesis ) is used as in t ) ut to the tr ; ms-lation moduh ' , s . For resem : ehtmri/oses the original l ; ( ; x tst ) oken 1) yth ( , users cant ) 7 , t)r ( ; sented t () the translal ; ion system t ; (7ev ~ flm~te the MT (: omponent set ) er ~ ti ; ely from l ; hc , re(:ognizT ~ r . 
' l'h (' . tra . ining set (: onsist ; s(Tfd 5680s ( ; nl ; o . n (: e pairs . Testing was carried out on ~ tseper ~ te set of 14:7 senl ; eneesl ; h ~ f l ; ( to not contain any ml seen words , hi Table 1l ; heehara ( ' teristics of the training sets are summarized for l  ; he originale or t ) ns and after l ; heai ) plication of the des(:rit)edtr ~ Lns for nlat ; ion . sont ; he Gerll ~ tll part of l ; he colpus . \[ l . ' hetM ) le shows that ont ; his cou ) us Ill (' , splitting of (: Oml ) OUll(tsi in l ) roves l ; hcl ; oken-tyl)erntiotiom 59 . 7 t (765 . 2 , lint th (' , mmfl ) er of sing h ; -tons ( words s ( ; en only on ( ' eintt ' nhfing ) does not go down by more than 2 . 8% .  ' . l ' heoth . ertrans-fi)rm ~ tions(i)r ( ; 1) ending separated verb 1) refixe , ~" t ) ref " ; mineral ; ionwi ; h1) OS t~gs " i ) os " ; merging of phrases " merge " ) do not at \[ be these co > pusst ;  , l ; isl ; ies much . 
The translntion l ) erformmme results are given in rl2~fi ) le2t brtra . nslat ; i on of text and in ' l ~ f i ) le3 for translation of t ; he single-best hyl ) oth ( ! s is given t ) yasl ) eech recognizer ( a ( ' ( :m:a . ('y 69%) . 
For t ) oth cases , l;r ; mslation on textml(tonst)ee(:hint ) ut , s t ) litting ( : oml ) oml ( twords doesing ( " baseline "= no preprocessing )  . 

English 465 143
Gerlnan baseline verb prefixes split compounds pos pos+mergepos+merge+prefno  . of no . of single-tokens types to ns 438 237 . 6% 437968 7335 44 . 8% 435 686 7370 44 . 3% 442938 6794 42 . 0% 437972 7 344 44 . 8% 437330 7363 44 . 7% 435055 7397 44 . 2% notiml ) rove translation quality , but it is not harmful either . The treatment of separable prefixes helps as does annotating some words with part of speech inibrmation  . Merging of 1 ) hrases does not improve the quality much further . The best translations were adfieved with the combination of POS-annotation  , phrase merging and prepending separated verb prefixes  . This holds t brt ) oth translation of text and of speech input . 
Table 2: Results on VERBMOBIL text in tmt.
preprocessing SSER\[%\] baseline verb prefixes split compound spos+merge pos+merge+pref  20  . 3 19 . 4 20 . 3 19 . 7 19 . 5 18 . 0 The fact that these hardcoded transtbrma-tions are not only hclpflflontext input  , but also on speech input is quite encouraging . As an example makes clear this cannot be taken for granted : The test sentence " Dann fahren wir dannlos  . " is recognized as " Dam1 fahren wird an nuns . " and the tact that separable verbs do not occur in their separated form in the training data is mf favorable in this case  . The figures show that in gener M the speech recognizer output contains enough information for help fl fl preprocessing  . 
Table 3: Results on VERBMOBIL speech in lmt.
preprocessing baseline verb prefixes split compounds split+pref pos+merge+prefssEa  \[%1   43  . 4 41 . 8 43 . 1 42 . 3 41 . 1 4 . 2 Translat ion Results for EUTRANS The EUTRANS corpus consists of different types of German -English texts belonging to the tourism domain : web pages of hotels  , touris-tic brochures and business correspondence . The string translation and language model parameters were trained on  27   028 sentence pairs . The 200 test sentences contain 150 words never seen in training . 
Table 4 summarizes the corpus statistics of the training set for the original corpus  , after splitting of compound words and after additional prepending of seperated verb prefixes  ( " split + prefixes " )  . The splitting of compounds improves the token -type ratiof lom  8  . 6 to 12 . 3 and the nmnber of words seen only once in training reduces by  8  . 9% . 
Table 4: Corpus statistics : EUTRANS.
preprocessing no . of tokens
English 562 264
German baseline split compounds split + prefixes 499   217   535   505   534   676 no . of single-types tons 338 2347 . 1% 58317 58 . 9% 43 405 50 . 0% 43 407 49 . 8% Tile mlmber of words in the test sentences never seen in training reduces from  150 to 81 by compound splitting and can further be reduced to  69 by replacing the unknown wordforms by more general forms  .   80 unknown words are encountered when verb prefixes are treated in addition to compound splitting  . 
Experiments for POS-annotation have not been pertbrmed on this corpus because no small set of ambiguous words causing many of the Comt  ) ared to ; it (' , VERB MOBIL task , this tort ) us is less homogeneous . Merging of 1) hrases did not help much on VEI/ , BMOBIL and is the ret bren ottested here . 
Tal ) le5 shows that the splitting of comt ) ound words yields an improvement in the subjective sentence rror rate of  4  . 5% and the treatment of unknown words ( " unk " ) improves the translation quality by an additional  1%  . Treating SO l ) arable verb 1 ) refixes in addition to splitting compounds gives the be  , st result so far with an improvement of 7 . 1% absolute COml ) ared to the l ) as eline . 
Table 5: Results on EUTRANS.
1) ret ) rocessing SSER\[%\]1) as eline 57 . 4 split comi ) ounds 52 . 9 sl ) lit+lmk 51 . 8 split + prefixes 50 . 35 Conclusion and Future Work In this paper , we have presented some methods of providing morphological im syntactic intbr-matont br improving the  1  ) ertbrmance of statistical machine tralls lation . Firstext ) eriments prove their general aplflical fility to reMistic and comI  ) lex tasks such as spontaneously spoken dialogs . 
We are .  1 ) lamfing to integrate the al ) t ) roach into the search process . We are also working on language models and translation models that use mort  ) hological categories for smoothing in the case of unseen events  . 
Acknowledgement . This work was partly supported by the German Feder M Ministry of Education  , Science , Research and Technology under the Contract Number  01 IV 701   q_'4   ( VERB MOBIL ) and as part of the EUTRANS project by the European Comnmnity  ( ESPRIT project number 302 68 )  . 
The authors would like to thank Gregor
Leuscht brhis support in implementation.

P.F . Brown , S.A.Della Pietra , V.J.
Della Pietra , and ILL . Mercer . 1993.
Mathematics of Statistical Machine %' ansla-tion : Parameter Estimation  . Computational
Linguistics , 19(2):263311.
Mariikka Hapalainen and Ari Majorin . 1995.
GERTWOL und Morphologische Disambi-guierung fiir das Deutsche  . URL : www . lingsoft . fi/doc/gercg/NODALIDA-poster . html . 
Fred Karlsson .  1990 . Constraint Grmnmar as a Fraineworkt br Parsing Running Text  . In PT vecedings of th , e13th , hzternational Confer-cnce on Computational Linguistics  , volume 3 , pages 168-173 , Helsinki , Finland . 
Sonja Niefien , Stephan Vogel , Hermann Ney , and Christoph Tilhnann .  1998 . ADP based Search Algorithm tbr Statistical Machine Translation  . In Proceedings of the 36th Annual Con : ferencc of the Association for Computational Linguistics and the  17th International Conference on Computational Linguis -ties  , pages 960967 , Montrdal , P . Q . , Canada,

Sonja Niefien , Franzloser Oeh , Gregor Leusch , and Hermaml Ney .  2000 . An Ewfluation Toolt br Machine % ' anslation : Fast Evaluation for MT Research  . In Proceedings of the 2nd International Conference on Language Rc-so ' arccs and Evaluation  , pages 3945 , Athens , 
Greece , May.
Franz . losef Och and Hans Weber .  1998 . hn-t ) roving Statistical Natural Language ~: ans-lation with Categories and Rules  . In Pro-eccdings of the 36th Annual Con . fcr cnc cofth , e Association for Computational Linguistics and the  17th international Conference on Computational Linguistics  , pages 985-989 , 
Montrdal , P.Q ., Canada , August.
Iq : anz , loser Och , Christol)h Tillmmm , aim Her-maml Ney .  1999 . hn proved Alignment Models tbr Statistical Machine Translation  . In Proceedings of the Co~:ference on Empirical Methods in Natu ~ nl Language Processing and Very Large Corpora  , pages 2028 , University of Maryland , College Park , Maryland , June . 
Wolfgang Wahlster .  1993 . Verl ) mobih Transla-lion of Face-to-Face Dialogs . In Proceedings of the MT Summit IV , pages 127-135 , Kobe , 

Ye-Yi Wang and Alex Waibel .  1997 . Decoding Algorithm in Statistical %' anslation . In Proceedings of the ACL/EACL'97, Madrid,
Spain , pages 366372, July.

