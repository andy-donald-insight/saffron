Morphological Analyzer as Syntactic Parser
G ~ ibor Pr 6sz 6ky

Ndmctv Olgyi0t25, lhtdapcst , 11-112611 ungary

Abstract . We describe how a simple parser can be built on tile basis of nmr phology and a morphological analyzer  . Our initial conditions have been tiletccl miques and principle sol : Humor  , a reversible , shing-bascdt mification tool ( Prdszdky 1994) . Parsing is perlorlngd by the Sillll cengine as morphological analysis  . It is usefld when the rc is not enough space to add a new engine to an existing morpl\]of ogy -based application  ( e . g . a spellchecker ) , but you would like to handle sentence-level information  , its well ( e . g . a gramnlar checker ) . The morpim logical analyzer breaks up words into several parts  , all of which storedit \] tile main lexicon , l : , a ch part has a feature structure and the validily of tile input word is checked by unifying them  . Thc morphological analyzer returns various information about a word including its categorization  . In a sentence , the category of each word ( or morphcme ) is considered a recta-letter , and the sentencc itself can be transformed into a recta-word that essentially behaves like a real one  . Thus timset of sentences recognized by tile parser called  Hum0rESl   ( can form a lexicon of recta-words that are processed much rite same way as lexicons of real words  ( morphology )  . This means that algorithmic parsing step are substituted by lexicon lookup  , which , by definition , is pcrforn ~ cd following tilest lrJ ' a ceorder of string elements  . Both the finitizer that transfimns for nml grammars into finite lexicons and timtun-tinm parser of the proposed model have running im -plementations  . 11 INTROI ) UCTION\[ , exical entries in a morphology-lmsed system are words  . 
Because of tile similarity , syntactic onstructions occurring as entries in a mct aqcxicon can be called recta-words  . 
Mcta-letters , that is , letters o1" are cta-word arc morphosyntactic categories having an internal structure that describes syntaelic behavior of the entry in higher level con?structions  . The system called Hum0rE , ~K(Humorl '; nhanced with Syntactic Knowledge , where Humor stands l brIligh-speed Unification Morphology  ) to be shown here consistsel : nulner ous recta -lexicons  . Each o1: them has a name : lhesyntactic category it describes  . Categories like S ', S , NP , VI < etc . are described in separate lexicons . Meta-lexicons l'o rnla hierarchy , that is , letters in alneta dexicon can refer to other ( but only lower level ) lexicons . Parsing on each level , therefore , can be realized as lexical h)ok-up . Neither backtracking , look-ahcad , tier other tiln c-consuming parsing steps arc needed in order to get the analysis of a sentence  . The only online Ol ) eratit misaunit \] ability check for each possible lexical entry that matches lhe sentence in question  . 

This work was partially supported by the Ihmgmtan National 
ScientificFund(()TKA).
Gramnmrs are compiled into an mtti-lcvel pattern slrttchtrc  . () n a lower level , parsing a word results in a recta-letter , that is , part of a recta-word on a higher level . 
Such structures , lbrexample , NI ' and VP , are recta-letters coming from lower levels and for marecta-word that can be parsed as a sentence  , because of the existence of a rule S-~NP VP in the original gratl tlllar  . A COtlIpIcx set liellce gratllt/lar can be broken up into non-rectlrsiv c  , gralnt tlars describing smaller grammatical units on different levels  . 
These granlmars are , of course , nmch simpler than the original one . Recursive transition et works ( P , TN ) can also be made according to similar principles , but their recursivcn attu'e cannot be Ionndin our method  . In other words : the output symbol of any level does not occur in the actual or low cr level dictionaries  . 
Tile whole lexicon cascade can be generated front arbitrary grmn mars writ/en in any usual  ( for the time being , CI: , but in tile near furore anyfcahne-based ) tbrnmlism . 
We call this step grammar learn in L < The sotl\wue tool we have developed for this reason lake stile grallllllar ~ tsinpttt  , creates the largest regular subset of tile language it describes regarding the string -completion limit of Kornai  ( 1985 )  , then lbrms it finite pattern structure by depth limit and length limit fronlthe above I'egtliar description  . 
2 PARSING WITH PATTERNS l ' arsers are ( conlputational ) tools that read and analyze a sentence , and return a wide range of information ~ tl ) ( , lttt it , that is , they recognize ( 1 ) if the input is a valid sentence ( according to the yules of the object hmguage )  ,   ( 2 ) segmen the input sentence as tn anyways its possible  , tlld(3) providestone custon linfornmtion . 
The latter custom information can be a simple ' ( ) I <' sign indicating that tile sentence is wellformed  ( grammar checker )  , but it can also be the same sentence in another language  ( translation tool )  , or , in case of a ( granunatically ) incorrect sentence , it cat \] b calistel suggestion show it nl W be corrected  ( ~ , , rammar correcter ) . In the present implementation we use morphosyntactic categories as output it \ ] lormation every level  ( parser )  . 
I : or the input sentence
The dogs in Rs.
tilel ' ; nglish module of Humor returns the following morphological categorization : The \]  1  ) 1:/\['\] dog\[N\]S/hA , IV\]t\[3S(;I . IENI ) Il , ctus now strip offtile actual words fronlthe nmrphologi-calinformation  ( from now on we call them morphological codes or mo  , 7) h-codes ) . Wriling only the morph-codes , wegel
I ) ETNV3S(;I';NI).
The problcnlis now how wc recognize this as a sentence  . 
This sequence musts m ne how b c stored in another lexicon that in the above string  , DET , N , and V are simple symbols that can easily be encoded as single letters liked  , n , v , x and e . Transforming the sequence of morph-codes we get the word dnvxe  . Earlier we said thai the I'tum0r engine is lexicon-independent , so if we have another lexicon , we can easily switch to it and instruct Humor to analyze the actual word  . Humo returns something liked nv xe\[S\]where'S' is now the category of the input word indicating that it is a sentence  . 
The meta-lcvel , of course , can be splittip to further levels . Let us use , for the sake of simplicity , a simple to y grammar of two levels for the nominal phrase and the sentence :  ( Level 2 ) S-~NPS , S - ~ , SNP , S-+V (3SG ) ( t , evel ) NP--~DETNG , NG-~ADJNG , NG-+N Now we feel a need for a tool that generates a set of finite patterns out of this grammar description  . We , therefore , developed a tool that finds the largest regular subset of a contextfree language  ( regarding a special parameter set ) and then uses a recursive generator to produce the finite patterns  . \] For the above toy grammar a possible lexicon can be the following :  ( Level 2 ) : VEND , V3SGEND , NP VEND . NP V3 SGEND , NP VNP END , NP V3 SG NP END , VNPEND , V3SGNPEND . . . .
( Level1): DETN , DETADJN , DETADJADJN ....
If we use letters v , m , x , n , a and d for V , NP , 3SG , N , ADJ and DET , respectively , we get the following lexicons : (1 , evel S ) re , vx e , mve . mvxe,mvme,m~xme , vine , vx me . . . .
( Level NP ) dn , dan , daan . . . .
If the appropriatelxicons are built from the pattern lists for grammars of both levels  , the parser is ready to run . The parsing algorithm can be outlined as follows . \]' he parser runs a morphological analysis on each word in the input sentence and encodes the morph-codes into meta-letters  . 
Using our example , The dogsings ( DET NV3 SGEND ) the parser will find that the string ' DETN ' forms a noun phrase  , becaused n can be found in the NP lexicon . 
The meta-morphological analysis ( a search in the lexicon of the patterns of Level 1  ) returns dn\[m\] , that is , DET N\[NP\] . For level 2 , the parser exchanges the substring ' DETN ' with the meta-letter ' NP'  . So the new recta-word is mve , that is , ' NP VEND'which is accepted by the Level 2 grammar ( sentences )  . In fact , we have another meta-word here , namely , a single n ( =' N' ) that can also be categorized as a noun phrase ( m )  ; and this yields dmve , that is , ' DET NP VEND'which is not accepted by the Level  2 grammar . 
Giving these two as input to the Level 2 meta-morphological analysis , the system will reject dmve'I ) ETNPVEND ' but will accept mve ' NP VEND'by returning mve\[S\]  , that is , NP VEND\[S\] . 
It is clear that no backtracking is possible in our runtime system  , that is , a meta-word cannot be categorized by a symbol that is a recta-letter of meta-words on the same or lower level  . It is an important restriction : category symbols must be recta-letters used only on higher levels  . This constraint provid csus with another advantage : any set of category symbols  ( higher level meta-letters or meta-morph-codes ) is disjoint from the set of lower level meta -letters  ( or recta-letters used on the level of morphology )  , therefore , parsing lexicons can be unified : meta-words ( morphological or any set of phrase structure patterns  ) for all levels can be stored in a single lexicon . 
In the explanation of the parsing techniques we have excluded one aspect until this point  , and this is unification . 
Without feature structures and unification , however , numerous incorrectly formed sentences are accepted by the parser  . If a meta-word is not ~ bund , it is rejected and the process goes onto the next meta-word  . If the meta-word is found , then it may still be incorrect . This is checked through the unifiability-checking of the feature structures of its ineta-letters  . For instance , in a noun phrase ' DETN' , the unifiability of the feature structures assigned to I  ) ET and Nischecked . If they are not unifiable , the recta-word is rejected and the process goes onto the next recta-word  . 
If they are unifiable , the output is passed onto the next level . The last level is responsible for providing the user with the proper analysis  , that is , all the information coblected so far . 
3 FROM GRAM MARS TO LEXICAL

All in finite structures generated by recursion can be restricted by limiting the recursion depth  . This means a constraint of the depth of the derivation tree of a sentence in a language  . We can also restric the direction of branching in the derivation tree  . '\[' his means that we could generate ( finite ) patterns directly fi'om the original ( contextfree ) language imposing various limits on embedding ; but these methods can be too weak or too strong and  , most of all , irrelevant to the ol~iect language . There is , however , a slighter constraint that helps transfbrming contextfree grammars  . According to Kornai's hypothesis ( Kornai 1985) , any string that can be the beginning of a grammatical string can be completed with k or less terminal symbols  , where k is a small integer . This k is called the string completion limit ( SCL )  . A grammar transformation device can be instruct cd to discard sentence beginnings that have a minimal SCL larger than specified  ( by the user )  . SCL limits center-embedding but allows arbitrary deep right-branching structures  ( easily defined by right regular grammars )  , l , eft branching is also limited , but this limitatibn is less pronounced than that of center-embedding  . 
Our special tool , GRAM2LEX , takes a CF grammar as input . As a first step , it reads the grammar and creates the appropriate RTNs from it  . Goldberg and Kfilmfin ( 1992 ) describe an algorithm unifying recursive transition networks  . We have improved their algorithm . Its implementation is incorporated into the GRAM21  , EX tool as a second processing phase . The algorithm creates the largest regular subset of a contextfree language that respects the SCI  ,  . In terms of finite state autonmta , SCL is the number of branches in the longest path fi'oma non-accepting state to an accepting one  ( regarding all such pmhs )  . The process re-stilts a finite state automaton . In order to get a finite dc-scription , from the FSA we introduced two independent parameters  . The length of the output string ( in terms of terminal symbols ) If the current string reaches the maximum length , the recursion is cut and the process immediately tracks back a level  . The maximum number of passing the same branch during the generation of an output string can also be specified  . In the current implementation , this ever , another approach : this number can be related to the current recursion level  , so if a certain iteration occurs at more than one position in a sentence  , the maxinmm length of the iteration is the same at both positions and the act ttallengths are independent  . 
The GRAM2IJ . iX tool takes all thc three parameters ( the S('I , , the maximum string length and the maximum iteration length  ) as user-defined ones . The set of finite patterns can be compiled into a compressed lexicon with Morphol  , -ogic's lexicon compiler . The GP ,   AM21J!X tool produces a file in the input format required by this compiler  . 
l , evels of the parser are individual processes that communicate with each other  . The most important medium is the internal pmwing table that represents the parsing graph described below  . Based on lhat graph , the process of a particular level is able to execute its main Rmction all nodnles  , namely to create the appropriate input to call the morphology engine  , ? switcht n the phrase pattern lexicon of the current level  , run the morphology engine and process the output of the morphology engine  , and ? if possible , insert new branches into the parsing graph lbr the next level  . 
Each level is an independent process communicating with the others  ( including level 0 , the morphological naly-sis ) . The medium of commtulication is the parsing graph of which there is only one copy and is generally accessed by all levels  . The parsing process on each level can be decomposed into three layers  . All levels have the same functionality ; it is nnly the internal operation of the first layer that difl crs in the case or ' the lowest level  ( morphology ) alld tile highest one ( sentences ) : ? preprocess that based on the current structure of the parsing graph  ( if it exists )  , produce stile set of the pos-sine phrasc slructur cs  , + search that checks all the elements of the set generated by l  , ayer 1 if they are acceptable by the eurrcnt level using the ttumor engine equipped with the current levcl 's parsing lexicon  , ? postprocess that based on the patterns accepted by l  , ayer 2 , inserts new nodes and branches into the parsing graph  . 
The different levels are cnnnected to each other like tile layers of a single level  . The structure of our present ( demonstrational )   0-1-2-level parser for llungarian is the tbllowing : ? Morphology  ( Preprocess Words , Search Morphologyl + cxicon , Create/Modify Parsing Graph) , ? Noun Phrases ( Create Patterns , Searchl , ev el1l ' atternl , exicon , Modit ~? Parsing Graph) , ? Sentences ( Create I ' atterns , Search I , evel2 l'attcrnl , exicon , Modify Parsing Graph) . 
4 IMPLEMENTING THERUN-TIME

In the current implementation , the parsing levels are executed sequentially , but they can be made concttrrent : during one session  , level (/ reads a word from the input sentence , analyzes it and inserts the appropriate nodes and branches in totile parsing graph  . Further on , tile system has a self-driving structure : tile level that made changes to the parsing graph sends all indication to the next level which then starts the same processing phase  , The changes in the parsing graph are thus spread upwards in the level structure  . When the last level ( usually the highest ) finished updating the graph , its ends a'ready for next'signal to level 0 which starts the next session . 
Termination is controlled by level 0: if it finished am > lyzing the htst word ( morpheme ) of the sentence , its ends a'ternainate ' signal to the next level  . Receiving this signal , intermediatelvels pass it to the next level after finishing the processing the changes that were made to the parsing graph  . The last level ( usually the highest ) th cn terminates all levels and passes the parsing graph totile output generator  . 
I , ctussee an example:
Patterns : s : NI'VI'END
Nit NINNID : , TNIDE TAI ) JNIl ) l'I'ADJAI ) JNVP:VIV3 SG\]VNPI 131 , 2 VING\[FH : , VING
ADV IV NP
END : . I ! lnpnt:Pro/bss'orSmi this coming home . 
Output : S-,\[NI'VP t';NDI
NP->IN NI
N - -+ Professorl NI
N - ~, Smith\[PROP\]
VP ->\[ lie VINGAI)VI
BI , 2> isll W\]
VING-+>eeme\[V\]t-ing\[lNGI
ADV +. home\[AI)V\]
END ->.
This is the inherentagging of the sentence built from the information stored directly in the phrase structure patterns  . 
We have begun , however , the development of another type of tagging where phrases correspond to the source grammars ' nonterminal symbols  , like this: ( S ( NP ( N professor )   ( NS mith ) )  ( VP ( BE is )   ( V ( J ( V\[N (  ; ( Veome ) ( INGing )) ( ADV home )))) The cur , ent average speed of this multilevel system ( even for dictionaries with 100 . 000 entries ) is a rot nld 50 input / see for each module on a Pentium/75 machine , where input can mean either sentence or phrase or word to b canalyzed  . 
5 USERINTERFACE
The current implementation of the Humotl : $ K parser allows the run-li  , ne expansion of the user-defined lexicon file . 
This was achieved by developing a small user interface that performs the following functions : ? Users can review all the different taggings of a sentence  . 
? Users can view the internal parsing table from which the parser output was generated  . This means the review of the analysis of each morpheme and the recta-words generated from them  . 
? Uscrs can view both the morpholexicalnd the syntactical part of the user-defined lexicons  . 
? The user can acid new entries to the user -defined lexicon file on any level  . The changes take effect suddenly , that is , when processing the next sentence or reparsing the last one  . 
6 CONCLUSION
We have developed a parser called-lum 0 rl : Sl ( that is quite powerful ( even in its present format , without feature structures ) and has several important features : 1 . unified processing method of every linguistic level  2  . possible parallel processing of the levels ( morphology , phrase levels , sentence lvel , etc . ) 3 . morphological , phrasal and syntactic lexicons can be enhanced , even in runtime 4 . easy handling of unknown elements ( with reanalysis )  5 . easy correction of gramnmtical Errors 6 . reversible ( generation with the ' synthesis by analysis ' )  7 . the same system can be used both for corpus tagging and finE-grained parsing l " eature I seems important if th crc is not enough space to add a new engine to an existing lnorphology-ascd application  ( e . g . a spellchecker ) , but you must handle sentence-level information , as well ( e . g . a grammar checker ) . Real parallelism indicated in 2 has not yet been implemented . Usefulness of attributes 36 are going to bcproven in practice , because we have just finished the first version of the first Ilungaria ngramma  , " checker called Hely-es ebb . It uses the spelling corrector and morphological na-lyzcr/gcnerator modules relying on the Humor morphological system-  . the basis of Hurn 0 rE , ~ l ( that are widely used by tens of thousands of both professional and non-professional End-users  ( Prdszdky 1994 , Prdszdky et al 1994) . We have results in proving the first part o1' \[' catur c 7  , namely corpus tagging . Fine-grained parsing would need the extended use of features  . This system . -aswcmentioned earlier-is under development . 
7 REFERENCES\[1\]Goldbcrg , J . and I, . K/dmf in , ? The First BUG Report ' , Proceedings of COLING-92 , Nantes (1992) . 
\[21Kis , B . ' Parsing Based on Morphology ' , Unpublished Master's Thesis , Budapest Technical 1 Jniversity ,  1995 . 
131 Kornai , A . ' Natural , anguages and the Cholnsky Ilie , -archy ' , Proceedings (? f the 2nd Conf . of the I:ACL , Geneva , 17 .  (1985) . 
1411 Prdsz6ky , G . ' Industrial Applications of Unification Morphology '  , Proceedinjzs()/ANLP-94 , Stuttgart (1994) . 
\[5\] Prdszdky , G . , M . Pal and I, . Tihanyi , ' Hum0r-bascd Applications ' , Proceedings o/C'OLING-94 , Kyoto (1994) . 
\[12\]A Dunaut & naT is za alegnagy obhfoly 6nk.
\[i/\]\]0:00:02.9\]Hum or ESK2.0 REV\[F,W
SS->\[DPC as DPDPEnd\]
DP ->\[ Det N\]
Det->a\[Artic\]e\]-A
N->Duna\[ProperNoun\]
Cas -> ut6n \[ Post Position \] 13P - >\[ Det N\]
Det->a\[Article\]
N->T isza\[Noun\]
D\])->\[DetAdj\Adj\AdjNPSfx\]
Det->a\[Article\]
Adj\->leg\[Superlative\]
Adj->+nagy\[Adjective\]\Adj->+obb\ [ Comparative \] 
N -> fo \] y6\[Noun\]
PSfx->+nk\[PersSuffPlurFirst\]
End ->
First\[^HOME\]Last\[^END\]\[G\]o to Syntax exceptions\[A\]t+S\]\[P\]arse again Accept\[AENTER\]JR\]ejectWord except ions\[Alt ~ W\]Exit\[ESC\]Internal pars ing table\[FlO\]Fi gulc  1  . Humor ESK-analysis of thc sentence " A Dun aut dna T is zaalegnagy obb foly dnk  . "( After the Danube , our biggestrive t " is T is za . )
