TTP : AFAST ANDROBUST PARSER FOR NATURAL LANGUAGE 
TO MEK STR ZA LK OWS KI
Courant Institute of Mathematical Sciences
New York University
715 Broadway , rm704
New York , NY 10003


In this paper we describe TI ~ , a fast and robust natural language parser which can analyze written text and generate regularized parse structures for sentences and phrases at the speed of approximately  0  . 5 sec/sentence , or 44 word per second . The parser is based on a wide coverage grammar for English  , developed by the New York University's Linguistic String Project  , and it uses the machine-readable version of the Oxford Advanced lw ~ arner's Dictionary as a source of its basic vocabulary  . The parser operates on stochastically tagged text  , and contains a powerful skip-and-fit recovery mechanism that allows it to deal with extragrammatical input and to operate effectively under a severe time pressure  . Empirical experiments , testing parser'speed and accuracy , were performed on several collections : a collection of technical abstracts  ( CACM-3204 )  , a corpus of news messages ( MUC3) , a selection from ACM Computer Library database , and a collection of Wall Street Journal articles , approximately 50 million words in total . 
1. INTRODUCTION
Recently , there has been a growing demand for fast and reliable natural language processing tools  , capable of performing reasonably accurate syntactic analysis of large volumes of text within an acceptable time  . A full sentential parser that produces complete mmlysis of input  , may be considered reasonably fast if the average parsing time per sentence falls anywhere between  2 and 10 seconds . A large volume of text , perhaps a gigabyte or more , would contain as many as 7 million sentences . At the speed of say , 6 sec/sentence , this much text would require well over a year to parse  . While 7 million sentences i a lot of text , this much may easily he contained in a fair-sized text database  . Therefore , the parsing speed would have to be increased by at least a factor of  10 to make such a task manageable . 
In this paper we describe a fast and robust natural anguage parser that can analyze written text and generate regularized parse structures at a speed of below  1 second per sentence . In the experiments conducted on variety of naturallangauge texts  , including technical prose , news messages , and newspaper articles , the average parsing time varied between 0 . 4 sec/sentence and 0 . 7 see/sentence , or between 1600 and 2600 words per minute , as we tried to find an acceptable compromise between parser's speed and precision  . lIt has long been assumed that in order to gain speed  , one may have to trade in some of the purser's accuracy  . For example , we may have to settle for partial parsing that would recognize only selected grammatical structures  ( e . g . noun phrases ; Ruge et al ,  1991) , or would avoid making difficult decisions ( e . g . 
pp-attachment ; Hindle , 1983) . Much of the overhead and inefficiency comes from the fact that the lexical and structural mbiguity of natmal anguage input can only be dealt with using limited context information available to the parser  . Partial parsing techniques have been used with a considerable success in processing large volumes of text  , for example AT&T's Fidditch ( Hindle and Rooth ,  1991 ) parsed 13 million words of Associated Press news messages , while MIT's parser ( de Marcken ,  1990 ) was used to process the 1 million word Lancaster/Oslo/Bergen ( LOB ) corpus . In both cases , the parsers were designed to do partial processing only  , that is , they would never attempt a complete analysis of certain constructions  , uc has the attachment of pp-adjuncts , ubordinate clauses , or coordinations . This kind of partial analysis may be sufficient in some applications because of a relatively high precision of identifying correct syntactic dependencies  . 2 However , the ratio at which these dependencies are identified  ( that is , the recall level ) isn't sufficiently high due to the inherently partial character of the parsing process  . The low recall means that many of the important dependencies are lost in parsing  , and t These results were obtained on a 21 MIPSS parc Stafion ELC . The experiments were performed within an information retrieval system so that he final recall and precision statistics were used to rnealurc effectiw mess of the panmr  . 
a Hindle and Rooth ( 1991 ) and Church and Hanks ( 1990 ) used partial parses generated by Fidditch to study word ~ urrt  . nc ? patterns m syntactic contexts . 
ACRESDE COLING-92 , NANTES , 2328 AOr ~1992198 PROC . OFCOL 1NG-92 . NANTES , AOO .  2328 ,   1992 the relore partial parsing may not be suitable in applications such as information extraction or document retrieval  . 
The alternative is to create a parser that would attempto produce a complete parse  , and would resort to partial or approxim ~ analysis only under exceptional condition such as an extragrammatical input or a severe time pressure  . En countering a construction that it couldn't handle  , the parser would first try to pro-due can approxinm teanalysis of the difficult fragment  , and then resume normal processing for the rest of the input  . The outcome is a kind of " fitted " parse , reflecting a compromise between the actual input and grammar-encoded preferences  ( imposed , mainly , in rule ordering )) 2 . SKIP-ANI ) -FITRECOVERY INPARSING A robust parser must deal efficiently with difficult input  , whether it is a nexUa-gmmmatical string , or a string whose complete analysis could be . 
considered too costly . Frequently , these two situations amnot distinguishable , stmcially for long and complex sentences found i u free running text  . The parser must be able to analyze such strings quickly and pro-due cat least partiMstractures  , imposhlg preferences when necessary , and even removing or inserting small input fragments  , if the datadriven processing falters . 
For example , in the following sentence,
The method is illustrated by the automatic on -struction of both recursive and iterafive programs operating on natural numbers  , lists , and tree . s , ht order to construct a program satisfying certain specifications a theorem induced by those specifu : ationsi proved  , and the desired program is extracted from the p too M the italicized part is likely to cause additional complications in parsing this lengthy string  , and the parser may be better off ignoring the fragmental together  . To do so successfully , the parser must close the constituent which is being culrenfly parsed  , an ( ll Yossibly a few of its parent constituents , removing correspumling productions from further consideration  , until an appropriate production is r cactivate x l , The parser then jumps over the iutervening in a tedal  . so a store . start processing of the remainder of the sentence usia grite newly reactivated production  . In the example at hand , suppose that the parser has just read the word specifications and is looking at the following article a  . 
Rather than continuing at the present level , the parser reduces the phrase a program satiyfying certain The idea of parse " fitting " was partlyials pired by the UIM parser  ( Jen~en et al ,  1983) , as well as by the sumdard errorm covely techniques used in shift-reduce parsiug  . 
specifications to NP , and then traces further reductions : SI-- ) to VNP ; SA-~SI ; S . --) NP VNPSA , until production S--*S and S is reached . 4 Subsequently , the parser skips input to find and , then resumes normal processing . 
As may be expected , this kind of action involves a great deal of in determinacy which  , in case of natural language strings , is compounded by the high degree of lexical ambiguity  . If the purpose of this skip-and-fit technique is to get the purser smoothly through even the most complex strings  , the amount of additional backtracking caused by the lexical level ambiguity ks certain to defeat it  . Without lexical disambigaation of input , the purser's performance will deteriorate , even if the . skipping is limited only to certain types of adverbial adjuncts  . The most common cases of lexical ambiguity are tho ~ of a phwal noun  ( nns ) vs . a singular verb ( vbz ) , a singular noun ( nn ) vs . a plmal or infinitive verb ( vbp , vb ) , and a past tense verb ( vbd ) vs . 
a past participle ( vbn ) , as illusWatod in the following exarnple . 
The notation used ( vbn or vl~l ?) explicitly asse . ci-ates ( nnsorvbz ? ) a data structure ( v born n ) shared ( vb nor vbd ? ) by concun-ent processes ( nn . ,~ or vbz ? ) wiflt operatim Ls defirm d ( vb nor vbd ? ) cut it . 
3. PARTOFSPEECHTAGGER
Oue way of dealing with lexical ambiguity is to use a tagger to preproccss the input marking each wurti with a tags that indicates its syntactic ategoriza  . -tion : a part of speech with selected morphological feature such as nunther  , tense , mode , case and degree . 
The following are tagged sentcoces from the CACM-3204 collection : s
The ( dr ) papei ' ( nn ) pre~nts ( vbz ) a ( d t ) proposal ( on ) lor ( / n ) stmctured ( vbn ) representation ( nn ) of ( in ) multipm granuning ( vbg ) in ( in ) a ( d t ) high ( jj ) level ( t i n ) language ( nn )   . ( per ) The ( t i t ) notation ( nn ) used ( vbn ) explicitly ( rb ) associates ( vbz ) ~ dt ) data 0 m . v ) struct me ( nn ) shared ( vbn ) by ( in ) concmrent ( /j ) prc ~ esses ( nns ) with ( in ) t ) peratit ) ns ( mJs ) defined ( vbn ) on ( in ) it ( pp )   . ( per ) The tags are underst ( x xl as follows: ( It-determiner , nn-singular 1 ~ oan , nn s-plural noun , in-preposition , jj adjective , vbz-verb in present tense third person " lhe decision to force ? reduct i  ( m rather than to backup co~ld be triggered by various means  . Inclte of TTP parser , it iJ always induced by the thne-cittlignal . 
Tagge du ~ ing the 35-tag Penn'ft , zebank Tags etcmmed at the
University of Pemts ylwmia.
Acq~ . s DECOLING-92 , NA ~' I ~ , 23?28Ao ( rr 1992199 PROC . OFCOLlNG-92, NAN rF . s , AUo .  2328 , 1992 singular , to-particle " to " , vbg-present participle , vim-past participle , vbd-past tense verb , vb-infinitive verb , cc-coordinate conjunction . 
Tagging of the input text substantially reduces the search space of a topdown parser since it resolves most of the lexical level ambiguities  . In the examples a hove , tagging of presents as " vbz " in the first sentence cuts off a potentially long and cosily " garden path " with presents as a plural noun followed by a headless relative clause starting with  ( that ) a proposal . . . . In the second sentence , tagging resolves ambiguity of used ( vim vs . vbd ), and associates ( vbz vs . nns ) . 
Perhaps more imlx mantly , elimination of word-level lexical ambiguity allows the parser to make projection about the input which is yet to be parsed  , using a simple look a bead ; in particular , phrase boundaries can be determined with a degree of confidence  ( Church ,  1988) . This latter property is critical for implementing skip-and-fit recovery technique outlined in the previous section  . 
Tagging of input also helps to reduce the number of parse structures that can be assigned to a sentence  , decreases the demand for consulting of the dictionary  , and simplifies dealing with unknown words . Since every item in the sentence is assigned a tag  , so are the words for which we have no entry in the lexicon  . Many of these words will be tagged as " np " ( proper noun )  , however , the surrounding tags may force other selections . In the following example , chinese , which does not appear in the dictionary , is tagged as " j . j ": ~ this ( dOpapca ' ( nn ) dates ( vbz ) back ( rb ) the ( d0 genesis ( nn ) of ( in ) binary ( j / ) conception ( nn ) circa ( / n )  5000 ( c d ) years ( nns ) ago ( rb )   , ( corn ) as ( rb ) derived ( vbn ) by ( m ) the ( d0 chinese ( if ) ancients ( nns )   . ( per ) We use a stochastic tagger to process the input text prior to parsing  . The tagger is based upon a bigram model ; it selects most likely tag for a word given cooccurrence probabilities computed from a small training SgL  7   4  . PARSING wITHTTPPARSERTTP ( Tagged Text Parser ) is a topdown English parser specifically designed for fast  , reliable processing of large amounts of text . 
6 We use the machine wadable version of the Oxford Advanced Learner's Dictionary  ( OALD )  . 
7 The program , suppfiod to us by Bolt Benmck and Newman , open ttes in two almmative modes , either telocting ? single most likely tag for each word  ( best-tag option , the one we use?t prcaen O , or supplying tsliontanked list of alternatives ( Mercer et al ,  1991) . 
TTP is based on the Linguistic String Grammar developed by Sager  ( 1981 )  . Written in Quintus Prolog , the parser currently encompasses more than 400 grammar productions , TIP produces a regularized representation feach lmrsed sentence that reflects the sentence's logical structure  . This representation may differ considerably from a standard Imrse tree  , in that the constituents get moved around ( e . g . , de . 
passivization , de--dativization ) , and the phrases are organized recursively around their head elements  . An important novel feature of TIP parser is that it is equipped with a timeout mechanism that allows for fast closing of more difficult subconstituents after a preset amount of time has elapsed without producing a parse  . Although a complete analysis is attempted for each sentence  , the parser may occasionally ignore fragments of input to resume " normal " processing after skipping a few words  . These fragments are latex analyzed separately and attached as incomplete constituents to the main parse tree  . 
As the parsing ixoceeds , each sentence receives a new slot of time during which its parse is to be returned  . The amount of time allotted to any particular sentence can be regulated to obtain an acceptable compromise between parser'speed and precision  . In our experiments we found that 0 . 5 see/sentence time slot was appropriate for the CACM abstracts  , while 0 . 7 see/sentence was more appropriate for generally longer sentences in  MUC3 articles .   9 The actual ength of the time interval allotted to any one sentence may depend on this sentence's length in words  , although this dependency need not be linear . Such adjustments will have only limited impact on the parser's speed  , but they may affect the quality of produced parse trees  . 
Unfortunately , there is no obvious way to evaluate quality of parsing except by using its results to attain some measurablends  . We used the parsed CACM collection to generate domain-specific word correlations for query processing in an information retrieval system  , and the results were satisfactory . For other applications , such as information extraction and deep understanding  , a more accurate analysis may be required , m * See ( Strzalkowski , 1990) for Prolog implementation details . 
Giving the parser more time per sentence doesn't a l ways mean that ? belmr  ( more accurate ) parse will be obtained . For complex or extragrammatical structures we are likely to be better o  ( fif we do not allow the parser wander around for too long : the molt likely inteq~mtation of an unexpected input is probably the one gcn-cnlted early  ( the grammar rule ordering enforce some preferences  )  . 
JoA qualitative method for par~crevaluation has he ~ apro-\[me  . edin ( ihrrison et al ,  1990 , and it may be used to mike ? rd?-tire comt xtrison fpurser's accuracy  . What is not dear is how ? oeu-atea par~er needs to be for may particular pptic  . iticct . 
ACTESDECOLING-92 , NANTES , 2328 AOt3T 1992 200 PROC . OFCOLING-92, NANTES , AUG .  2328 , 1992 Initially , a full analysis of each sentence is attempted . If a parse is not returned before the allotted time elapses  , the parser enters the timeout mode . 
From this point on , the parser is permitted to skip portions of input to reach a starter terminal for the next constituent to be parsed  , and closing the currently opea one ( or ones ) with whatever partial representation has been generated thus far  . The result is an approximate partial parse , which shows the overall structure of the sentence  , from which some of the constituents may be missing  . The fragment skipped in the first pass are not thrown out  , instead they are analyzed by a simple phrasal postprocessor that looks for noun phrases and relative clauses and then attaches the recovered material to the main parse structure  . 
The timeout mechanism is implemented using a straightforward parameter passing and is at present limited to only a sub~et of nonterminals used by the grammar  . Suppose that X is such a nonterminal , and that it appears on the righthand side of a production S---> X Y Z  . The set of " starters " is computed for Y , which consists of the word tags that can occur as the leftmost constituent of Y  . This set is passed as a parameter while the parser attempts to recognize X in the input  . If X is recognized successfully within a preset ime  , then the parser proceeds to parse a Y , and nothing else happens . On the other hand , if the parser cannot determine whether there is an X in the input or not  , that is , it neither succeeds nor fails in parsing X before being timed out  , the unfinished X constituent is closed with a partial ~ rse  , and the parser is restarted at the closest element from the sta~er set for Y that can be found in the remainder of the input  . If Y rewrites to an empty string , the starters for Z to the right of Y are added to the starters for Y and both sets are passed as a parameter to X  . As an example consider the following clauses in the TIP parser :  ~1 sentence ( P ) :- assertion ( \[ \ ]  , P ) . 
assertion ( SR , P ) :- clause(SR , Pl ) , scoord(SR , PI , P ) . 
clause ( SR , P ) :- sa(\[pdt , dr , c d , pp , ppS , Jj , Jjr , jJs , nn , nns , np , nps\] , PAl ) , subject (\[ vbd , vbz , vbp\] , Tail , P1) , verb phrase ( SR , Tail , PI , PAl , P ) , subtail ( Tail ) . 
thats(SR,P ) :- that , assertion(SR,P).
In the clause production above , a ( finite ) clausen The clauses arc slightly simplified , and some arguments are removed for expository reasons  . 
rewrites into an ( optional ) sentence adjunct ( SA )  , a subject , a verb phrase and subject's right adjunct ( SUBTAIL , also optional ) . With the exception of sub-tail , each predicate has a parameter that specifies the list of " starter " tags for restarting the parser  , should the evaluation of this predicate xceed the allotted portion of time  . Thus , in case sa is aborted before its evaluation is complete  , the parser will jump over some ele-menUs of the unparsed portion of the input looking for a word that could begin a subject phrase  ( either a predeterminer , a determiner , a count word , a pronoun , an adjective , a noun , or a proper name ) . Likewise , when subject is timed out , the parser will restart with verb phrase at either vbz  , vbd or vbp ( finite forms of a verb ) . Note that if verb phrase is timed out , then subtail will be ignored , both verb phrase and clause will be closed , and the parser will restart at an element of set SR passed down to clause from assertion  . Note also that in the toplevel production for a sentence the star-ter set for assertion is initialized to be empty : if the failure occurs at this level  , no continuation is possible . 
When a nonterminal is timed out and the parser jumps over a nonzero length fragment of input  , it is assumed that the skipped part was some subconstituent of the closed nonterminal  . Accordingly , a placeholder is left in the parse structure under the node dominated by this nonterminal  , which will be later filled by some nominal material recovered from the fragment  . The examples given in the Appendix show approximate parse structures generated by TIP  . 
There are a few caveats in the skip-and-fit parsing strategy just outlined which warrant further explanation  . In particular , the following problems must be resolved to assure parser's effectiveness : how to select starter tags for nonterminals  , how to select nonterminals at which to place the starter tags  , and finally how to select nonterminals at which input skipping call occur  . 
Obviotlsly some tags are motelikely to occur at the leftmost position of a constituent than others  . 
~ ly , a subject ~ can start with u word tagged with any element from the following fist : Ixlt  , d t , c d , ji , jjr , j j s , pp , ppS , nn , nns , np , nps , vbg , vbo , rb , in 2In practice , however , we may select only a subset of these , as shown in the clause production above . 
Although we now risk missing the lefthand boundary of subject p ~ rases in some sentences  , while skipping an adjunct otheir left , most cases are still covered and the chances of making a serious misinterpretation fuThit list it  . ot comphac . In addition to the tal ~ explthled before : pdt- \[ n ~ de ~ trniner  , jjt-compamt lve*dj cctiv ? , j ~- mpcda-tire ~ . ie O~c , pp-pronoun , ppS-s~nitiv ? , rlp npl-p , x~l , er noun . r'o-~verb . 
ACTESDI~;COLING-92 . NANTES . 2328 nor\]r199220 lPROC . OFCOLING-92 . NANTES . AUG . 2328,1992 input are significantly lower . 
We also need to decide on how input skipping is to be done  . In a most straightforward design , when a nonterminal X is timed-out , the parser would skip input until it has reached a starter element of a nonterminal Y adjacent to X from the right  , according to the topdown predictions , t3 On the other hand , certain adjunct phrases may be of little interest  , possibly because of their typically low information contents  , and we may choose to ignore them altogether . Therefore , if X is timed out , and Y is a low contents adjunct phrase , we can make the parser to jump fight to the next nonterminal Z  . In the clause production discussed before , subtail is skipped over if verb phrase is timed ou L  14 Finally , it is not an entirely trivial task to select nonterminals at which the input skipping can occur  . If wrong nonterminals are chosen the parser may generate rather uninteresting structures that would be next to useless  , or it may become trapped in inadvertently created dead ends  , hopelessly trying to fit the parse . 
Consider , for example , the following sentence , taken from MUC3 corpus of news messages :
HONDURANNATION ALPOLICE ON MON-
DAYPRESENTEDTOTHEPRESSHON-
DURANJUAN BAUTIST ANUNEZ AMADOR
ANDNICARAGUAN LUISFERN ANDO OR-
DON\[~REYES , WHOTOLD REPORTERS
THAT COMM ANDER AURELIAN OW ASAS-
SASSINATEDONORDERS FROMJOSEDE
JESUSPENA , THENICARAGUANEMBASSY
CHIEFOFSECURITY.
After reaching the verb PRESENTED , the parser con-salts the lexicon and finds that one of the possible subcategorizations of this verb is \[ pun  , to \] , that is , its objects uing can be a prepositional phrase with ' to ' followed by a noun phrase  . The parser thus begins to look for a prepositional phrase starting at " TO THE PRESS  . . . " , but unfortunately misses the end of the phrase at PRESS  ( the following word is tagged as a noun )  , and continues until reaching the end of sentence . At this point it realizes that it went too far ( there is no noun phrase left )  , and starts backing up . Before the parser has a chance to back up to the word PRESS and correct the early mistake  , however , the timeout mode is turned on , and instead of abandoning the current analysis , the parser now tries hard to fix it by skipping varying portions of input  . This may take a considerable amountime if the skip points are badlyi ~ Note that he topdown predictions are crucial for the skipping parser  , wheah cr the paner's processing is topdown or bouem-up  . 
t 4 : mbta // it the remainder of a discontinued subject phrase  . 
placed . On the other hand , we wouldn't like to allow an easy exit by accepting an empty noun phrase at the end of the sentence I  \]5 One of the essential properties of the input skipping mechanism is its flexibility to jump over varying-size chunks of the inputs Uing  . The goal is to fit the input with a closest matching parse structure while leaving the minimum number of words unaccounted for  . In TIP , the skipping mechanism is implemented by adding extra productions for selected nonterminals  , and these are always tried fast whenever the nonterminal is to be expanded  . We illustrate this with rnproductions covering fight adjuncts to a noun  . 
rn(SR , P ):- timedout ,  ! , skip ( SR ) , store ( P ) . 
rn(_ , \[\]) :- la(\[\[pdt , d t , vbz , vbp , vbd , rod , eom , ha , rmr\]\]) , \+ is (\[\[ C0~\] , \[ wdt , wp , wps\]\]) . 
rn(SR,P ) :- rnI(SR,P).
In the rn predicate , SR is the list of starter tags and P is the parse tree fragment  . The first production checks if the time out mode has already been entered  , in which case the input is skipped until a starter tag is found  , while the skipped words are stored into P to be analyzed later in the purser'second pass  . Note that in this case all other rnproductions are cutoff  ; however , should the first skip-and-fit attempt fail to lead to a successful parse  , backtracking may eventually force predicate skip ( SR ) to evaluate again and make a longer leap . In a topdown left to right parser , each input skipping location becomes potentially a multiple buck-tracking point which needs to be controlled in order to avoid a combinatorial explosion of possibilities  . This is accomplished by supplementing topdown predictions with bottom-up  , datadriven fragmentation of input , and a limited lookahead . For example , in the second of the rnproductions above , a right adjuncto a noun can be considered empty if the item following the noun is either a period  , a semicolon , a comma , or a word tagged as pdt , d t , vbz , vbp , vbd , or md , but not a comma followed by a relative pronoun . ~6  , 2 In the present implementation , when the skipping mode is entered , it will stay on for the balance of the first pass in parsing of the current sentence  . "\[~ his way , o ~? skip-and-fit atempt may lead to anc4her before any backtracking is considered . An altema five is to do time out on a nonterminal by nonterminal basis  , that is , to timeout processing of selected nonterminals only and then resumergular parsing  , qhis design leads to a far more complex implementation and somewhat inferior performance  , but it might be worthcomic ~ ring in the fumre . 
t6 md-mod alve to ; vbp-plural verb ; wdt , wp , wps-t tladve pronouns . 
ACq'ES DECOLING-92 , NANTES , 2328 AOt3T1992202 PROC . OFCOLING-92, NANTES , AUG .  2328, 1992 5 . ROBUSTNESSTIP is a robust parser and it will process nearly every sentence or phrase  , provided the latter is reasonably correctly tagged  .   17 The lmrser robustness is further increased by allowing for a gradual degradation of its performance rather than an outright failure in the face of an unexpected input  . Each sentence or phrase is attempted to be analyzed in up to four ways :  ( 1 ) as a sentence ,   ( 2 ) as a noun phrase or a preposition phrase with a right adjunct  ( s )  , (3) as a gemn dive clause , and if all these fail , (4) as a series of simple noun phrases , with each of these attempts allotted a fresh time slice  ) s The purpose of this extension is to accommodate some infrequent but still important con -strnctions  , uchasdries , itemizations , and lists . 
6. DISCUSSION
In this paper we described TIP , a fast and robust parser for natural language . In the experiments conducted with various text collections of more that  50 million words the average parsing speed recorded was approx  .  0 . 5 sec/sentence . For example , the total time spent on parsing the CACM-3204 collection was less than 1  . 5 hours . In other words , TIP can process 100 , 000 words in approximately 45 minutes , and it could parse a gigabyte of text ( approx . 150 million words ) in about 40 days , on a 21 MIPS computer . 
The parser is based on a wide coverage grammar for English  , and it contains a powerful skip-and-fit recovery mechanism that allows it to deal with unexpected input and to perform effectively under a severe time pressure  . Prior to parsing , the input text is tagged with a stochastic tagger that assigns part-of-speech labels to every word  , thus resolving lexical evel ambiguity . 
TIP has been used as frontend of a natural language processing component to a traditional document-based information retrieval system  ( Strzalkowski and Vauthey ,  1992) . The parse structures were further analyzed to extract word and phrase dependency relations which were in turn used as input to various tatistical and indexing processes  . The results obtained were generally satisfactory : an improvement in both recall and precision of document retrieval have been observed  . At present , we are also conducting experiments with large corpora of technical computer  , science texts in order to extract domain -specific  , 7 Some sentences ( 1 in 5000 ) mmy still fail to parse if tagging errors are . compotmded in In unexpected way . 
ts Although parsing of some sentences may now approach four drnes the allotted time limit  , we noted that heaverage parsing tinmper sentence  at0  . 745 sec . is only slighdy above the timeout limit . 
conceptual taxonomies for an even greater gain in retrieval effectiveness  . 
7. ACKNOWLED GEMENTS
We wish to thank Ralph Weischedel and Heidi Fox of BBN for assisting in the use of the part of speech tagger  . ACM has generously provided us with the Computer Library text database  . This paper is based upon work supported by the Defense Advanced Research Project Agency under Contract  N00014-90-J-1851 from the Office of Naval Research , the National Science Foundation under Grant IRI-89-02304  , and by the Canadian Institute for Robotics and
Intelligent Systems ( IRIS).
8. REFERENCES
Church , Kenneth Ward .  1988 . " A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text  . " Proceedings of the Second Conference on Applied Natural Language Processing  , pp . 

Church , Kenneth Ward and Patrick Hanks . 1990.
" Word association or ms , mutual information , and lexicography . " Computational Linguistics ,  16(1) , MIT Press , pp .  2229 . 
De Marcken , Carl G .  1990 . " Parsing the LOB corpus . " Proceedings of the 28th Meeting of the
ACL , Pittsburgh , PA . pp . 243-251.
Harrison , Philip , et al 1991 . " Evaluating Syntax Performance of Parser /Grammars of English  . " Natural Language Processing Systems Evaluatiou
Workshop , Berkeley , CA . pp . 71-78.
Hindle , Donald .  1983 . "User manual of Fidditch , a deterministic parser . "Naval Research Laboratory Technical Memor andum 7590-142  . 
Hindle , Donald and Mats Rooth .  1991 . " Structural Ambiguity and Lexical Relations . " Proceedings of the 29th Meeting of the ACL , Berkeley , CA . 
pp . 229-236.
Jensen , K . , G . E . Heidorn , L . A . Miller , and Y . Ravin . 
1983 . " Parse fitting and prose fixing : Getting a hold of ill-formedness  . " Computational Linguistics , 9(3 . -4), pp .  147-161 . 
Meteer , Marie , Richard Schwartz , and Ralph Weischedel .  1991 . " Studies in Part of Speech Labelling . " Proceedings of the 4th DARPA
Speech and Natural Language Workshop,
Morgan-Kaufman , San Mate D , CA . pp . 331-336.
Ruge , Gerda , Christoph Schwarz , Amy J . Warner.
1991 . " Effectiveness and Efficiency in Natural Language Processing for Large Amounts of Text  . "Journal of the ASIS , 42(6), pp .  450-456 . 
Sager , Nanmi . 1981. Natural Language Information
Processing . Addison-Wesley.
Strzalkowski , Tomek .  1990 . " Reversible logic grammars for natural language parsing and ACRESDE  COLING-92  . NANTES , 2328 AOI3T 1992203 PROC . OFCOLING-92, NANTES , AUG . 2328, 1992 generation . ' " Computational Intelligence , 6(3),
NRC Canada , pp . 145-171.
Strzalkowski , Tomek and Barbara Vauthey . 1992.
" Information Retrieval Using Robust Natural Language Processing  . " Proceedings of the 30th Annual Meeting of the ACL , Newark , Delaware , 
June 28-July 2.
APPENDIX : Sample parses
A few examples of nonstandard output generated by TTP are shown in Figures  1 to 3  . In Figure 1 , " ITP has failed to find the main verb and it had to jump over much of the last phrase such as the LR  ( k ) grammars , partly due to an improper tokenization of LR ( k )   ( notes kipped nodes indicating the material ignored in the first pass  )  . In Figure 2 , the parser has initially assumed that the conjunction in the sentence has the narrow scope  , then it realized that something went wrong but , apparently , there was no time left to backup . Note , however , that little has been lost : a complete strncture of the second half of this sentence following the conjuction and is easily recovered from the parse tree  ( varpoints up to the dominating rip )  . Occasionally , sentences may come out substantially truncated , as shown in Figure 3 , where although has been mistagged as a preposition  . 

The problem of determining whether an arbitrary contextfree grammar is a member of some easily parsed subclass of grammar such as the LR  ( k ) grammars i considered . 
APPROXIMATEPARSE :\[\[ verb , \[\] \] , \[ subject , \[ np , \[n , problem \] , \[ t_pos , the \] , \[ of , \[\[verb , \[determine\]\] , \[subject , anyone \] , \[ object , \[\[verb , \[ be\]\] , \[ subject , \[np , \[n , grammar\] , \[t_pos , an \] , \[ adj , \[arbitrary\]\] , \[adj , \[ contextfree J\]\]\] , \[ object , \[np , \[n , member\] , \[t_pos , a \] , \[ of , \[np , \[n , subclass\] , \[t_pos , some \] , \[ apos_v , \[\[ verb , \[parse , lady , easily \] I\] , \[ subject , anyone \] , \[ object , pro\]\]\] , \[ of . \[ np,\[n , grammar\],\[rnwb,\[\[verb,\[such\]\] . 
\[subject , var\]\]\]\]\]\]\]\]\]\]\] , \[ sub_urd , Ias , \[\[verb , \[ be\]\] , \[ subject , pro\] , \[ object , \[np , \[n , kl , \[t_pos , the \] , \[ adj , \[" lr C\]\]\]\]\]\]\] , \[skipped , \[\[np , \[n , grammar \]\]\]\]\]\]\]\] , \[skipped , \[\[is\] , \[ whrel , \[\[verb , \[ consider \]\] , \[ sabject , anyone\] , \[object , var\]\]\]\]\]\] . 
Figure 1.

The TX-2 computer at MITL in coln Laboratory was used for the implementation fsuch a system and the characteristics of this implementation are reported  . 
APPROXIMATEPARSE :\[\[ bc\] , \[\[verb , \[ usc\]\] , \[ subject , anyone \] , \[ object , \[np , \[n , compster\] , \[t_pos , the\] , \[adj , \[tx_2\]\]\]\] , \[ for , \[ and , \[ np , \[n , implementation \] , \[ t . _pos , the \] , \[ of , \[np , \[n , system \] , \[ tpos , \[such , a \]\]\]\]\] , \[ np , \[n , characteristics\] , \[t_ . pos , the \] , \[ of , \[np , \[n , implementation \] , \[ tpos , this \]\]\] , \[skipped , \[\[ are\] , \[ wh_rel , \[\[verb , \[ report \]\] , \[ subject , anyone \] , \[ object , var\]\]\]\]\]\]\]\]\] , \[ at , \[np , \[n , laboratory\] , \[adj , \[mitl\] , \[ npos , \[np , \[n , lincoln\]\]\]\]\]\] . 
Figure 2.

In principle , the system can deal with any orthography , although at present i is limited to 4000 Chinese characters and some mathematical symbols . 
APPROXIMATE pARSE:\[\[can_anx\],\[\[verb . \[deal\]\] . 
\[suhject,\[np,\[n,system\] . \[ tpos , the \]\]\] , \[ sub_oral , \[with , \[\[verb , \[ limit\]\] , \[ subject . anyone\],\[object,\[skipped . 
\[\[ np.\[n , orthography\],\[tpos,any\]\].

\[np . \[n , present \]\] , \[ np , \[n , it \]\] , \[ is\]\]\]\] , \[ to , \[np , \[n , character \] , \[ counl , \[4000\]\] , \[ a_pos , \[ chinese\]\] , \[skipped , \[\[ and \] , \[ np , \[n , symbol\] , \[t~pos , some \] , \[ adj , \[ mathematical \]\]\]\]\]\]\]\]\]\]\] , \[ in , \[np , \[n , principle\]\]\]\] . 
Figure 3.
AcrEsDECOLING-92 , NANTES , 2328 hotzr 1992 204 PROC . OFCOL1NG-92, NANTES , AUG .  2328, 1992
