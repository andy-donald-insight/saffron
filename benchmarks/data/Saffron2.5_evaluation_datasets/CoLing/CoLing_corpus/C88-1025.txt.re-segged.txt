English Chinese Machine Translation System IMT /EC 
Chert Zhsoxlong and Gee Qingshi
Institute of Computing Technology
Chinese Academy of Science
BelJlng , PRC.

IM'I/EC is an EnglishChinese machine translation system ~  , hich integrates some outstanding features of the case grammar end semantic grammar ln to a uniform frame  , LISeS various kuowledgo In the disamblguation , and tries to modify the object language by it self  . In this poF , er , we first introduce IMT/EC's design motive-t i or l and overall architecture  , then describe the deslgn philosophy of its t ranslation mechanisms and the lr procesging algorithms  . 
J , The design n lotivation \]' he design of the IMT/EC system are motivated to develop new approaches to the Engllsh-Chinese machine translation  , such as , to provide the system with powerful analysis meohan is nlsend MT knowledge base menagonler it system  , as well as some exceptional processing and learning meohan lsms  , that is , to make the system baintelligent . In addition , it also tries to inregret9 as many advantages of conventional machine translation systems into a single system as possible  , such as , to provide the system with powerful mechon- . 
Isms for the processing of various ambiguities and context u  , ~l relations . The design of the IMT's translation mechanisms are based on the following consl-derQtion ~  ;  ,   ( 1 ) St-analysis In the development of machine translation system  , in order to disambiguato the source language , we have to molyze the input deeply to get the in ternal meonlng representation of the source language  . 
However , the deeper we aaalyze the input , the more we lose the clues about how to express the translation  , also , th ( it it results in extremely poor or no translations ef sentences for which complete analyses cannot be  ( h~rlved\[Slocum85\] . To find a suitable analysis depth so as to get both clues about how to express the trorl ~  ; lation of the input and to disombiguate the input conlpletely Is almost impossible  . In the IMT/EC , we try t ( , design a simple grammar analysis mechanism--SC -gr'  ( ~mmarauuly sls mechanism to inherit both the outstanding features of case grammar analysis and semantic grammar analysis so as to produce a high quality translation  ,   ( 2 ) Multl-language translations oriented In present technical conditions  , it is impossible to design a general internal meaning representation for all natural languages  . Thus , the knowledge based multl-language oriented machine translation system is difficult to be marketed in the near future  . A feasl-bleway ~ or designing mult l--longuage oriented machine translat Jorl systems might be to separate the processing mechanisms from the language specific rules as Kinge to I  .  ~5\] , the tie , tO apply the same processing meot lonlsm with different language specific rules for d ~ff Erent natural language pair translations  . In the 1NI'/EC , we develop a general rule representation form for the representation of various knowledges used in the translot lon  . Knowledges for different language palr t ranslations are stored in the differ-ant packages of the knowledge base IMT-KB  . The knowledge base are organized In multi- package end multi-level way so as to store ru les for the translation of different language pairs and different phases of the processing  . Thus , the system can be easily extended for ' multi -language trarls latlon purposes  . 
(3) Diversity processing
As the dlsemblguation rules are rather words specific  , ?% is difficult to manage them in the same way . To deal wlth this problem , we store these rules in their respected word entries end classify themes several categories in the IMT/EC  , Each category cor-responds tO 0 general subroutine epplleatlon mechanism , which apply the word specific rules and subrout -ines in the processing of translation  . The subrout-ines are stored in a natural language specific sub-routine package  . Some word specific subroutines are direct ly stored in the respected word entry  . 
( ~) Powerful exceptional processing
Since the natural language phenomena ore so abund -ant that any existed machine translation system cannot process all the phenomena  , it is essential to provide an exceptional processing mechanism in the system to deal wlth exceptional phenomena  . As IMT/EC incorporates some learning mechanisms , thus , it is more powerful in dealing with the exceptions than others  . 
(5 ) Automatic modification of the translat i on Generally speaking  , machine translation system can only producer igid translatlons  , it is a desire that MT systems be able to modify the output by itself so as to produce more fluent translations  . IMT/EC tries to apply same common sense knowledge and linguistic knowledge of ob ject language to disamblguate the input end modify the translations  , thus , to improve the translatlon quality . 
In the following paragraph , we focus on the trans-lation procedure of the system end the algorithms related to it ignoring the knowledge base organiza-tion and management mechanisms  . 
2 . The overall architecture of the system The architecture of the IMT/EC system is as follow  , \] knowledge base management
Engllsh Input System IMT-KB\[~f Knowledge ~ Morphological Analysis l  . II ~ Applicatz on J&Dictionary Retrlving ~ / p  . _I_T_T .   . ~1~tI~;n:l ;;";' s'L\~/___B?se . ~_  7 \[--~~/~/ Augmentation - ~_/ Dlsambigu ~ on r/I \ k&Modifiootio ~ f * ~& Transfer L/I\ ~ '   .   .   .   . ', , I
I-Acquisitioo )
I the Tren ? lot lonJ / t //
Fig . The architecture of the IMT/EC trenslatlon system is so vast that it ls impossible for human beings to find the confllotion end implication among the rules  . To modify a rule in the knowle-dgebase often results In many side effects on other rules  . Thus , it Is necessary to provide a self re-organ ization and refinement mechanisms in the knowle-dgebose  . 
In the IMT/EC , we design a special knowledge base management system IMT-KB to manage ell the knowledge used In varlous processing phases of the transla-t ion  . In addition , IMT/EC also provides o knowledge bose augmentation and knowledge acquisition envi ron-ment for the system to augment system performance by itself and for the users to improve the knowledge base  . 
The col1 relations connected by dotted llnes in the f igure above or e executed only when the user sets the learning mechanisms in working status  . These mechanisms can acquire new knowledge in the dynamic interactive  , static interactive , or disconnected ways . 
Theyore primarily used to resolve the exae Dtlenel phenomena in the translation  . 
Dynamic Interactive Learning ( DIL ) : Whenever the system encounters c sentence out of its processing range  , it produces various possible translations for each segment of the sentence and interacts with human beings when necessary to select on appropriate translation of the segment and combine them togetocorrect translation of the sentence  . At the some time , it also creates ' some new rules to reflect the selections  . That is , it learns some new knowledge . 
Static Interactive Learning ( SIL ) : Whenever the system encounters a sentence out o fits processing range  , it records down the sentence and its appearance context inefile  . After the text has been translated , it begins to analyze the sentence in detail to get various possible translations for each segment of the sentence and interacts with human beings when necess-ary to get appropriate translations of the segments and combines them to get a correct translation of the sentence  . At the same time , it also creates some new rules to reflect the selections  , thus , to learn new knowledge . 
Disconnected Learning ( DL ) : Whenever the system encounters o sentence out of its processing range  , it analyzes the sentence in detail to get al the possible translations  , and then evaluates these translations according to the preference rules stored in  . the IMT-KB to select on appropriate translation and modify the related rules used in the ana lysis to reflect the selections  . It skips over sentences which the translat ion connot be determined by the prefe-rence rules Instead of interacting with human beings  . 
5. The translation procedure
IMT/EO's tronslatlon procedure is divided into several phases  , i . e . ,morphology onalysls and diction-cry retrlvlng , SC-grammor anolysls , dlsambl guotlon and transfer , modification of the tronslatlon etc . 
The communl cotions between tronslot lon mechanisms and the knowledge bose ore performed by the knowledge base management system IMT-KB  , these operations includes getting as e ~ of related rules and returning some Information for the modification as well a S augmen totlon of the MT knowledge bose  . 
5 . 1 . Morphology analysis and dictionary retr iving In the IMT/EC  , words in most common uses conbere trived by e it her their baseforms or their surface forms  , whlle most of the other words can only be re- trieved by their baseforms  . The tasks of the morphology analysis or e to process the prefix  , suffix , and compound words . Since these processlng so recomplete-ivnatural language specific  , in order for the proce-ssing mechanisms to be language independent  , we deve-lopa language independent morphology analysis mechanism to opply the language specific morphology rules In the morphology analysis  , 
The morphology analysis rule form is < surface pattern >-> < conditions > I < result > < surface pattern > is the surface form of the word to be analyzed  , < conditions > is the oppll cotlon condlt lons of . the rule , < result > Is the definltlon of the word base form analyzed  . 
For example , (1) (" s ) -> ( verb-)I(def(") , SV ) (2)(" s)->(noun*)I(clef(*) , PN )   ( 3  )   (  -1 - "2 )  ->  ( word-1 )   ( word " 2 ) 1  (   ( def ( morphologv w1 )  , def(morphologv " 2)) , CaM ) Here ,  * ,   -1 and *2 are variables Indl cating that it conbe bounded to any sub-character string of the word to be analyzed  , def(X ) is the definition of X in the IMT-KB , SV , PN , cam are surface ' features of the word . 
Rule ( I ) Indl cotes that when the last character of the surface form of a word is ' s ' and the remained character string * in the word is o verb  , then its surface feature is the slngulor verb form  ( SV ) of the verb * . Thus , It returns the value of ( def (*) , SV ) as result . 
Rule ( 2 ) indicates that when the lost character of the surface form of a word is ' s ' and the remained character string * in the word is o noun  , then its surface feature is the plural noun form  ( PN ) of the noun * . Thus , it returns the value of ( def (*) , PN ) as result . 
Rule ( 5 ) indicates that when the character string of o word comprises a character '-'  , the left pert ~1 and the right part w2 of '-' or e both words , then it lso compound word of ~ I and w2 . Thus , it applies morphology rules to analyze the word ~1 and *2  , and returns the value of (   ( f ( morphology-1 )   , f(morphology w2)) , COM ) as result , 
Suppose that,
SX indicates that X is ovariable ,  #X returns the characterlls t of X , & X returns the lost character of X , > X returns the first part of rule X or the f irst element of a list  , < X returns the remained port of X which ( > X"<X oX )  , f(X , V ) returns the first different item palr of
X ond Y , lookup ( X ) looks up the dictionary and returns the defl nltlon of the word X  , search ( X ) returns the morphology rules which leclu- . 
descharacter X , check ( X ) tests whether two elements of the item pair X is uniflable or nag  , null(x ) tests whether llst XIS empty , apply(g , x ) returns the result of g(X ) , t ( X ) tests whether result X needs further onolysls and performs recurslve analysis when necessary  . 
The algorithm for morphology analysis and d iction--erv retrievl nq is as follow  . 
INITIALIZE$X <- #word;
SP <- search(&SX) ; $ P < -$ PU search (>$ X) ; $ result <-() ; for $ rule mSP do MATCH
SPAT <=> S rule ; $ COND <->"<$ rule ; $ RES <-<=<$ rule ; 
Loop $ patr <-- f(SPAT , SX ) ; if ( null($polr )) go to TEST ; if ( not(check($pair ))) break ; 
SPAT <-$ PAT ~ Spelt ; iPAIR . I .  <- . iPAIR l . U($polr ; gate Loop ; rEST for $ CONDI e$COND , do ($ PROP <- lookup(>e <($ CONDL)) ; if ( not ( apply (> $ CONDI , SPROP )) brook ; : ~ ESUI . TiPROP < -- lookup(>($RES~'$PA) ; RL )) ; i result <-- i result U($RES ~ iPA:\[RL , iPR(IP ) ;   ) if ( pull ( $ res~it ) ) re turn word e l se re tur r l t ( $ resu\] . t );
El~ll ), 3.2. St--Grammar Anulys : Ls
The St-grammar enolysis mechanism of IMT/EC U  ) plle~th ( SC--ro loss to redill thei MT-KB to dl sumbl-gL late the ~  . true turolem bigultles of the input senten--cos end predm  ; es the structural description for them . 
" ihegrammar lOS some outstending features of the case grommet on d semuntic gr ' ommor  . The rule form ls cs follow , <S-STRUCTURE > ~> < S-ENVIRON MENT > I < R = SI ' RUCTURE >  , < I~-ENVIRON MEN i > < TRANSFER > . 
Itore , < S- . SIIRUC rUI~E>mid<S-ENVIRON MENT > are rule cond i-tions which defines the current strtl ctLIr  ( \] l form end contextual fo attlres of the input  , < R- . STRUCTURE > und < R-ENVIRONNiENT > ore results true turulform ~ nd corltextuel features of the input  , < TRANSFER > ere the trens formot lo ~ Is rela ted to the rule  . 
lhostructural forms , <S-SI'RUCTURE > end<R-STRUCTURE > or e represented os strings of syntogmos arid words  . \] he contextuelen vlronments , <S-ENVIRON~ENT > and < R-EN ViRON MENT > or e represented os vectors  , of which each element corresponds to on inter -sentent tal reletion or especla\] eeoc  , their values ere used to resolve the ell ipsi  . s , d nephore , tense and espocts etc . 
it is the principal contextual processing mochenisms in the IMI/EC  . 
Since the contextual vector is used only os a supplo * ~ lent to the pure semantic grammar on a \ ] vs ls  , espeele\] . \] . y in the processing of contextual relations , it is riot necessary to analyze the Irl put to the extent the  . one congetell the semantic relations of the input  . Thus , the vector processing formalism is completely acceptable  . 
Two example rules or e as follow,
NP VP->AIS , change(B1, ?), INPIVP.
in NP->A1IPP , chonge ( B2 , X ) , zel INP nuei . 
St-grammar onelysis mechanisms receive the results of morphology analysis or prev ious SO-reduction  , send the messages to the IMT-K8 to get releted rules , end apply these rules to , reduce . the input until on on terminal symbol S is reduced  , thus , to produce the structural description o1' the input . 
The SO-grom metanalysis algorithm of the system is:  . 
( I ) \] in the entries of ' the\[MT-KB dictionary , we stored not only the word meanings and their disembi--guotlon conditions  , but ole oSO-phrase endsement l crules specJ floto the entry word  . When onuly zlnge sentence , the system first retrieves the SC-phrose rules specific tethe words appeare dirl the sentence  , end ~ pplim these rules to find a list o f possible phrases of the sentence from the context of the words in the senl  ; eneo . 
The phr~selist returned is os follow,
X , ( i , , J , )
X ~(?~, J :) x ~( i ., j ~).
Here , XI , X ~ . ,  . . . , X more phrase syutogmaIdent if $ ers , i , ~) .   .   .   .   . J . ~ arid J ~, Jz .   .   .   .   . J ~ ere ending posi-trons of the phrases in the input sentence  . 
(2  ) Find a list of expectation path os from the phrase \[ List as follow  ,  . 
"'~') X~;(J , ~ lk , ! X ~ l(m , 4tm ) X , ( i , J , ) v l ~) , ? ~/( l , JmiX ~)( Jm?l , k ) ~ U " ~+ I , n#)
P ( w~)P ( w~+L) . ,, p(w~z . #( Here , P ( w ) is the word w itself or its property , t is the current on aly slsposition which initial veluo is ~  , I is the expect sleelength defined by the user  ) end order them by means of the phrase ending post--tlons n =  , n  ~ .   .   .   .   . n ~ from lerger to smeller . These pothes are used as heuristics in the a no \]  . ysisef the sentence . We try one new pattiot one becktrecking . 
(3) Send the a no \]. y zed component
M = V , ( .   .   . ) V ~( .   .   .  )  .   .   . V ~( .   .   .   ) cnd Ii ihecurrent expecte tion path to the IIMT- - - KB to retrleve the ' SC-ruIes ' which heed pc terns contain sub-string of ~  ,  (  .   .   .  )  .   .   . v ~( .   .   . ) x ~( .   .  : )  .   .   . xz ( .   .   . ) ~1Path = or ( . ) v~()P ( w ~) .   .   . P ( w  ~ . ~ ) and organize these rules in a list accord ing to their preferences from higher " Lo lower  . Then , it tokes one rule from the rule llst at one buck firecklng and go to  ( ~ ) to appl V the rule to reduce the input . 
If no rule in the llst conbe successfull y applied to reduce the input  , the system gets the next expec-tation path f rom  ( 2 ) end repeet ( 3  )   . If all the expec-tation pethes have been tr ied end no successful rule has been appl ied  , it returns 1 ; othel astanalysis position to re-ana lyze the input  . If the currenter la--lysis position Is the beginning of the sentence  , the system coils the exception processing , lechenism to deal with this un--analyzab le sentence  . 
( l  ~ ) Match the rule head pattern with the current form of the input sentence  . If there is a sub-pattern of the current sentence pettern that can match the rule heed  , then go to ( 5  ) else get the next rule from ( 3 ) endtries to re- . match them . 
(5) First , odd some newly formed phrases into the phrase l is t in order For the backtracking of the one lysls  , then coll the ceseenely s?s mechanism to check the eurreet analysis results und the cur rent form of tile sentence ' to Fill in the rose freme A  , B in the rule end the context vector . The case anelysis algo-rithmis descr ibed In the following paragraph  . 
(6  ) CheckAend the context vector to see whether the ir values are unlfleble  . If they are unifieble , then goto (71 , else get the next rule from ( 3 ) and returns to ( 4  )   . 
(7  ) Store the backtracking informetion into the temporary stock  , substitute the reducing part of the cur rent sentence form with the reduced form  , change the current analysis position to the last word oF the newly reduced syntagma  , cnd change the related element values o ? the context vector aecording to the element values of B  . 
If the current position is not the endofo sentence  , then go to (2) , If the current position is the end of a sentence end the current form of the sentence i snetS  , ~ hongo to (2) , If the current position is the end of e sentence end the current form of the sentence is S  , then go to (8) ,   ( 8  ) C all the semantic processing mechanism to check the result of then n slysls to see whether ~ t violates the English collocet lonrules  . If the result violetes the collocation rules  , the system recovers to the status before the last reduction and gets'ther lext rule f rom  ( 5 ) to r'e-onoiyze the input . Otherwise , the rewll be two cases , a , If the user only needs the most adequate ? trensletlon  , the system proceeds to analyze the next sentence . 
b . If the user needs ell possible trcnslat ions  , the system records down ~ he current result endrose-vers to the stetus before the Zest reduction end gets order to get other onolysls results  . 
AS we have mentioned before , the case analysis in the SC-analysls is on ly a complement to the semantic analysis  . It is mainly used to des1 with the context relation and a ? pect , tense , modal etc . Thus , the system only needs to analyze those cases which can be used in those purposes  . Itls much simpler than the case analysis in the case grammar analysis  . 
The case analysis in the SC-enalysls ls performed by the following algorithm  ,   ( 1 ) Get the case expressions defined in the el ' emerita of " vector A and B  . The form of the element expressions of A and glss~\[i \]: E Here  , S~\[I\] indicates the element case C dent l fler  ( S # ) of the case frameAorg is corresponded to the case identifiers ill of the system case frame  , l . e . , system context vector . E is the expression used to get the value of the respected case  . 
(2 ) Retrieve the definition of the case ident if i-ers from the system case frame and organ ize these case identifier into a  1 let according to their prefe-rences from h ig her to lower  . The form is , ( S\[il\] . subject : EI , S\[12\] . obJect : E2 . . . . . S\[lm\] . Em . . . .  )   ( 5 ) Evaluate the value of the elements in the case identifier llst  , and flll them Into the respected position in the case frame A end B  . There are many cases in the evoluatlon . 
a . Elsa constant , returns E , b . Elsempty , evaluate the case value according the definit ion of the case identifier  , c . If the case identifier ls a syntagmaidet lfl - er  , then finds the v clue of the identifier from the analyzed input according to the heuristics p rovided by the expression E  , d . If the ease identifier is osement lc identifier , then call the semantic mechdnlsm to get the va lue which can be filled into the case ident ifier from the input according to the heuri stics provided by the expression E  , e . For other case identifiers , call the lrrespec-ted Subroutines to get the value of the case  . 
These subroutines are defined by the rule des igner  . 
The case analysis in the SC-analysis consolve the elll psls  , anaphora , and other contextual problems . 
5 . 5 . Semantic dlsambiguatlon and transformation The SO -rules define not only the relations for the syntagma reduction  , but also contextual vector value changes with respect to the reduction of o sentence  , and the rules related transformations . 
The transformation operation defined in the SC ~ rule is in the follewlng forms  , 
IXIX . . . IX
Here , IX , IX .   .   .   .   , IX are translations of the syntagmas X , X ,   .   .   . , X in the rule head . Their positions indicate the position so f the translations of the syntogmas  . There will also be some indicators In the string which are used to indicate positions of the translations for inserting tense  , voice , modal modiflers . These indl cotors are used as the heuristics of the semantic processing  . 
The transformet lonin the IMT/ECls relatively slmple  . It travels over the whole anolysls tree from top to down  , left to right , transfer every node when the node is ? raveled . J ' he result of the transformation is the Chinese utterance of the sentence  . 
Rules with same head patterns may have different case frames A and B  , in this case , they may correspond to different trans formation operations  . These rules or e defined as two different rules by the rule deslg-ne'r  . Wh fle in the IMT-KB , the system stores them as one rule wlth many candidate right patterns  . Whenever the head pattern is successfully matched  , the system sequentially checks these c and idates until one of them is satisfied and records down the current successful position so that backtracking mechanism can The tasks of the semantic processing in the IMT/ECoreto check the results of the analysis to see whe-ther they satisfy the syntax or semantic collocation rules defined in the IMT-KB  , to produce the suitable modifiers for expressing the tense  , volce , aspects and so on In the Chinese . In some cases , lt also apply the wellformed world knowledge deflned in the IMT-KB to eliminate some  11 legal expressions and extend the meanings of some ambiguity words  . 
Slnce the SC-analysls is based on the semant ic grammar analysis  , most of the syntax and semantic ambiguities are solved in the reduction operations  . 
Even though the case analysls in SC-analysls ls aimed mainly to resolve the contextual problems  , they can also solve some ambiguities among o sentence  . That is , the semantic processing in the IMT/ECls or lented to specl flc ambiguities and lnter -sentent lalcase value evaluations  . Though the processtngs are different in di fferent phases of the  trons1otlon   , they can be categorized as ,   ( 1 ) determining the value of ospecific semantic identifier  , such as tl mead verbial , placeed verb lal , anophoro etc . 
When o specific semantic identifier is concerned  , the semont lc , processlng mechanisms first finds the key word which conmatch the semantic identifier from the sentence  , such as word wlth tlme , plaoeproperties , then get the phrase which comprises the keyword in the sentence  , and return the phrase as the value of the ident i fier  . 
Only simple anaphorophe nomen are considered in the IMT/EC  . They are processed in two different ways . 
One is to compare the synonyms to flnd the . anaphorn words , the other Is to flnd the suitable anaphoro content through the position relations  , such ca , in some specific context the word ' which ' can refer to the noun phrases immed lotely before i t  . 
(2) checking the collocation of syntogmas.
There ore three possible categories of col location 
In the analysls results , <1 > XW -> ( W => CI ) <2> WY -> ( W => C2 ) <5> XWY -> ( w => C3 ) Here , X , Y may be strings of words or syntagmos , WIs a specific word . The above expressions means that ,   <1> W appears after string X and functions as speech CI  ,   <2> W appears before string Y and functions as speech C ~  ,   <5> W appears between strlngX and Y and func-t ions as speech C ~  . 
The related word definition in the IMT-KBd iction-ary is as follow  , 
W := C , ( E , => MI)(E~:>M ~) c:(E~=>M~)
Cm(E~=>M ~)
Here , C is the speech category , E is the context structure of word W , MIs the meaning of word W . 
The semantic processing mechanism retrieves the collocatlon rules specific to words of the sentence from the IMT-KB  , and applies these rules to check the analysis result to see whether there is any Violation between the analysis result and collocation rules  . If therels , returns fell . 
(5) cheoklng the distant contextual relatlons.
There are also three possible categories of distant contextual relations appeared in o sentence  , 
X . . . W\[m\]->(W = > C ~)
W . . . Y\[n\]->(W => C~)
X .   .   . W .   .   . Y\[m , n\]->(W=>C ~) Here , X , V , W , C have the same meanings as in the (2) . n , mare optional , they defines the relative position between the word W and XIY  . When n , m = 0 , the yore the cases described in (2) , When n , misnot defined , they indicates any position before/after the word ~ V  . These distant contextual relation rules are defined lathe It~-I'--Kg In the same way as in  ( 2  )   . 
If m and/or u are present , the semantic processing mochen is dl find sm/rl word before/after tile word W in the sentence  , and tries to reduce that word and its ad jacent words in caX or ' Y  . If they can be reduced , end tile word W functio as as the same category as defined in the rule  , trlen Successes , e18 oe liminates tlm analysis , if . i aud n are not ~ efined , then try to find the word before/after ti le word W which conbereduced into X or Y together with its adjacent words  . If there ere no such element in tile sentence  , then returns f(lil . 
( ll ) cre , 3 ting Chinese modifiers to express the tense . 
voice , modal arid so on Grid insert these modifiers intiletr  ( 3 J is lot icn accord ing to t i le pos i t ion mark 
Ip ' pear ociiu the rule.
the 9 recessing procedure is as follow , a . GeLCl I Oniorks of the tense , voice , modal etc . 
b . Coll . trio'correspelld/ngsabrautines defined by the rule designer to del  . or lidtle on appropriate modifi--or 1-'or tilem clrk . This is b clsod mainly on tile so a-texi ; llul structure of the analysis result . 
C . Ins ( ~rttri ( ) modifier in trlo position of tile truns-lati~ ) nmarked by the niarker . 
For " exalll Jilo , if a very is in the '- leg'form and tile re & sI:etime od vorbiol in the i ~ lput  , the tease of tho contoxt are all progress ive  , then ignore strletimer Hark . IF the predicate or e ' begoing to ' , then trans-lates it as ' dashuang'ign or ing trlotime mark  . 
The world knowledge rules are defined in the same form as ihe semantic rules  . " lhe application of these rules ( Jr ( to test tile context to find the semantic f'o ( ~ ttlresOf the sltLIotIonend coIdpQrethese to the world mo  ( i e l d e f i n i t i o n d e i " i ~ l c , dif ~ the world knowledge rule to \[ el ; or miue the sit < lotion of " the utterance , and thO~l detormi do the correch translation or exterlct them ounlllg SOf related words  . 
Every semuntlc processing n leChOnlsm mentiorled  . b <) veco , ~ responds to uspecific processing subrout . - irle . rtie ; ~ . ~s abroatines are called ill the grammar one -lysls Ulid transformation processing to perform the related  \[~911tantic processing .   ( 1 ) Is primarily a sod in the case qnalysls ,   ( 2  ) and ( ~ ) are pr'Imarlly used in checking c be analys is result and disembiguations in the analv :   ; Is and tronsfortlla Lion , (4) is primarily used ill the tr , ms for motlon . 
The gr~muner and word trnns format lonqlg or $ thm is  ,   ( 1  ) CH rrent = node < -- root of tile enalyslst ree  , (2)) Z '? the curron t-InOd O isoloaf node , go (4) , (~) The current--node is not a leaf node , the process in ! j are as follow , a . iI ' ~ ll the elemerlts in the transformation e ~: pression of the node c ~ reconstant  , go (5) , b . Ji ~ till the variables letriotrans formation expression of the node are substi tuted by c  ( ~n stants , the ecall semantic processing mechanism to c reate suitable modifiers  . Go (5) . 
a . if ' there are scale unsubstituted variab les in the expression of the node  . set these varla- . 
bias r~scurrent-node er ) e by one , aed uses the results returned by each subnode to replace the vari  ( lbles . 
(l ~) Whet ! the current = node Jsa leaf node , that is , it is nspec~flc word or a rll dlol ~ , then retrieves its defint t ; lonl = l " Onl the IM'I'- , KB , cell the semanticire (: osslu\[I , lecheli I Sill to determine on appropriate moaning farit according to the tree structure  . 
(5) I'L heeurrent-aode is root node , then returns trio curron ; for nl of the transfermatiou expreseiones the t ranslation of the sentence  . Otherwise , return stile expr'ession to the parent uode  , ree overs the parent nod ~ rJs curre et node . Go(2) . 
~  . t , The modification of : the translation The objective of " the automatic modifica tion of the tr ' auslGtlo ~ ii St Oili l prove the roadability of the transl ~ L : lorl  , but tilts so crlflces part of the accuracy  . 
It is more suitable for the non-sctell t if l cliterature tdanslatlon  . 
The main tasks comprises : a . Change the order of the phrases and words of the translation  , b . Substitute some words which collocotion is not commonly used in the Chinese utterahce for the syno-inymous words  , c . lnsert some conjunctive words when necessary , d . E11m ~ . nate some redundant wards . 
The algorithm for these processing is ,   ( I ) According to the Chinese oollocotion rules defined in the IMT-KB  , changes the words and phrases order of the tranelatlon which are not in accord with the col locat ? on conventions in Chinese  , such as , 
Bud on . . . . Erchia . . .
(2  ) According to the co-occurrence rules of the Chinese words defined in the IMT-KB  , check the uses of the Chinese words in the t ranslation  . If they are not in accord with the cooccurrence rules  , then replaces these words with the Chinese synonymous words until they ape accord to the rules  . If there is no suitable synonyms . then tries to extend the meaning of some words . The meaning extending rules are defined in the word entries  . Its form is as follow , < word >:-< condition 1> < extension I > < condition 2> < extension 2> < condition n > < extension n > Here , < word > indicates the word appeared in the sentence  , < condition > defines the extending cond it ions  , < extension > is the utterances extended . 
i ? the word cannot be replaced or extended , tilen just returns the source translat ion  . 
(5 ) Check the translation to find the redundant words and eliminates them  . The form of doletior l rule is,
X VXZ->p(X ) , p(V ) iXVZ such as , ' NP de NP de -> NP NP de ' . 
Since the modification has no absolute standard and requires a large amount of wor ld knowledge  , it is rather dlffl cult to solve this problem in one day  . In the ZMT/EC , we only deal with the most simple eases . 
More complex situations can be solved with the appli-cation and improvement of the system  . Thus , the system is designed to be easily extended w ith the applica-tion  . 
if the user needs high quality translat ion  , he may call the postediting subroutine to modify the translation by human beings or with the aid of human beings  . Attile same time , we can also set the learning mechanisms in work ing status to trace the modifica-tion procedure oF human beings and produce some use-fu l rules For the system  . 
I ~. Summary
In conclusion , we hovelntroduce ~~ translation process ing procedure  9 f the English-Chinese machine translat ion system IMT/EC  , and describe its principal processing a lgorithms  . 
A knowledgement : We would like to thank Hang Xiong  , Zharlg Yujie , Ye Yimln , Tong Jioxion , Zong Llyi , Zhong Zife , Chen Z1 zong , Chen Zizeng and FuWei For their cooperation in the implementation of IMT/EC  ,  5 . Reference\[1\]Axelbiewer , Christian Fenneyrol , Johannes Rltzke , Er Wirlitegentrltt (1985) , ASCOF-A modular multilevel system for French -German translation  , OL , Voi . 11, No . 
25, p'157-'154, 1985.
\  [2 \] Bernard Vauquois and Christian ~\] oi tet  , Automated p28-36 ,  1985 . 
\[5\] galen a Henlsz-Dostert et el .   , Machine Transla-tion , Mouton publishers , Hague , Paris , New York ,  1979 . 
\[4\] Harrytennant , Natural Language processing , Pe-trocelli books , New York ,  1981 . 
\[5\] Hiroshl Uchida , Fujltruma chine translation system : ATLAS , FGCS , Vol . 2, No . 2, p95-1~0,1986 . 
\[6\] Jaime G . Carbonell and Masaru Tomita , New approaches to Machine Translation , TR-CMU-CS-85-143 , 
Carnegie Mellon University , 1985.
\[7\] Jonathan Slocum , A survey of machine translation : its hlstory , current status and future perspect-ives , CL , Vol . 11, No . 1, p1-17, 1985 . 
\[8\] Kazunori Muraki , VENUS : Two-phrase machine translation system , FGCS , Vol . 2, p121-124, 1986 . 
\[9\] Martin Kay , The MIND system , Natural Language processing , edited by Rustin , Algorithmics press , New
York , 1975, p155-189.
\[10\] Makota Nagao , Current Status and future trends in machine t ranslation  , FGCS , Vol . 2, No . 2, p77-82, 1986 . 
\[11\]M . Nogao , J . Tsujil and J . Nakamura , Science and Technology agency's machine trans lation proJect  , FGCS , 
Vol . 2, No . 2, p125-14~, 1986.
\[12\] Murlel Vasconcellos and Mar Jorie Leon , SPANAM and ENGSPAN:machine translation at the PAN American health organization  , CL , Vol . 11,No . 2-5, p122-156, 1985 . 
\[15\]Paul L . Garvin ( ed . ) , Natural Language and the Computer , McGraw Hillbook , New York , London ,  1979 . 
\[14\] Perelra F . and Warren D . , Definite clause grammar for language onalvsls , Artlf ~ clol Intelllgen-ce , Vol . 15,p251-278,198~ . 
\[15\] Pierre Isabelle and Laurent Bourbeau , TAUM-AVIATION : Its technlcal features and some experimental results  , CL , Vol . 11, No . 1, p18-27, 1985 . 
\[16\] Richard E . CulZing for d , Word-meaning selection in multiproces ~ language understanding  , IEEE Trans . 
on Pattern analysis and m~chlne intelligence , Vol , 
PAMI-.6, No . 4., July 1984, p493-509.
\[17\]R . F . Simmons , Technologies for machine translation , FGCS , Vol . 2, No . 2, p85-94, 1986 . 
\[18\] Rod Johnson , Maghi Kinq , end Louis des Tombe , EUROTRA : A multilingual system under development  , CL , 
V 01.11, No . 2-3, p155-169, 1985.
\[19\] Roger Se hank , The condeptuel analysis of natural language , Natural Language processing , edited by R and all Rust ln , Algorithmics Press , New York , 1975 , p291-511 . 
\[20\] Rozena Hennisz-Dostert , R . Ross Macdonald and Michael Zarechnak , Machine translotion , Mouton Publi-sher , Hugue , Paris , New York ,  1979 .  ~ . 
\[21\]S . Amano , The Toshiba machine translation system , FGCS , Vol . 2, No . 2, p121-124~11986 . 
\[22\] Terry Wlnograd , Language as a Cognltlve ( Vol1) process , Addison-Wesley Publishing Company , 
California , London , 1985.
\[25\] Vtnfield S . Bennett and Jonathan 61 ocum , The LRC machine translation system , CL , Vo 1 . 11, No . 2-5, p1?1-121, 1985 . 
\[24\]Y . Wilks , The stanford machine translation project , Natural Language Processing , edited by R and all Rust in , Algorithmics Press , New York ,  1973 , p245-291 . 
\[25\] Yoshlhiko Nltta , Problems of machine transla-tion systems -effect of cultural differences on sent-ence structure  , FGCS , Vol . 2, No . 2, p117-120,1986 . 

