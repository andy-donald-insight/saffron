Structural disambiguation of morpho-syntacti c categorial parsing 
for Korean *
Jeongwon Cha and Geunbae Lee
Department of Computer Science & Engineering
Pohang University of Science & Technology
Pohang , Korea
himen , gblee@postech.ac.kr

The Korean Combinatory Categorial Grammar ( KCCG ) tbrmalism can unit brmly handle word order variation among arguments and adjuncts within a clause as well as in complex clauses and across clause boundaries  , i . e . , long distances crambling . Ill this paper , incremental parsing technique of a morpheme graph is developed using the KCCG  . We present echniques for choosing the most plausible parse tree using lexical information such as category merge probability  , head head cooccurrence heuristic , and the heuristic based on the coverage of subtrees  . The performancer sults for various models for choosing the most plausible parse tree are compared  . 
1 Introduction
Korean is a nonconfigurational , t ) ost positional , agglutinative language . Postpositions , uc has noun-endings , verb-endings , and prefinal verb-endings , are morphemes that determine the fnnctional role of NPs  ( noun phrases ) and VPs ( verb phrases ) in sentences and also transform VPs into NPs or APs  ( adjective phrases )  . Since a sequence of prefinal verb-endings , auxiliary verbs and verb-endings can generate hundreds of different usages of the same verb  , morpheme-based grammar modeling is considered as a natural consequence for Korean  . 
There have been various researches to disambiguate the structural ambiguities in parsing  . Lexical and contextual information has been shown to be most crucial for many parsing decisions  , such as prepositional-phrase attachment ( Hindle and Rooth ,  1993) . ( Charniak , 1995; Collins ,  1996 ) use the lexical intbrmation * This research was partially supported by KOSE Fspecial basic resem'ch  1  ) rogram ( 1997 . 9 ~ 2000 . 8) . 
and ( Magerman and Marcus , 1991; Magerman and Weir , 1992) use the contextual information for struct ; nral disambiguation . But , there have been few researches that used probability in tbr-marion for reducing the spurious ambiguities in choosing the most plausible parse tree of CCG formalism  , especially for morphosyntactic parsing of agglutinative language  . 
In this paper , we describe the probabilistic nmthod ( e . g . , category merge probability , head head cooccurrence , coverage heuristics ) to reduce the spurious at n biguities and choose the most plausible parse tree for agglutinative language such as Korean  . 
2 Overview of KCCG
This section briefly reviews the basic KCCG formalism  . 
Following ( Steedman ,  1985) , order-preserving typeraising rules are used to convert nouns in grammar into the functors over a verb  . The following rules are obligatorily activated uring parsing when case-marking morphemes attach to  nora1 stems . 
? Type Raising Rules : np + case marker feature \] ) v / ( v\np\[case-This rule indicates that a noun in the presence of a case morpheme becomes a functor looking for a verb on its right  ; this verb is also a flmctor looking for the original noun with the appropriate case on its left  . Altertile noun functor combines with the appropriate verb  , the result is a flmctor , which is looking for the remaining arguments of the verb  . ' v'isaw ~ ri-ablet braverb phrase at all y level  , e . g . , the verb of a matrix clause or the verb of an embedded clause  . And ' v ' is matched to all of Since all case -marked ilouns in Korean occur in front of the verb  , we don't need to e , mp loy the directional rules introduced by ( Hoffman ,  1995) . 
We extend the combinatory rules ibruncm'-ried flmctions as follows  . The sets indicated by braces in these rules are order-free  . 
? Forward Application ( A > ) : x / ( argsu Y ) Y X/Args ? Backward Application ( A < ) :
YX\(ArgsUY ) == 4-X\Args
Using these rules , a verb can apply to its arguments in any order , or as in most cases , the cased narked noun phrases , which are type-raised flmctors , can apply to the , al)t ) roi ) riate verbs . 
Coordination constructions are moditied to allow two type-raised noml  1  ) hrases that are looking t br the sax never b to combine together  . 
Since noun phrases , or a noun phrase and adverb phrase , are fimctors , the following composition rules combine two flmctions with a set vah leal'gulnents  . 
? Forward Composition ( B >):
X/(X\Ar . q . sx)Y/(Y\Arg . sy ) == ~ x/(X\(A , . : j < , : u )),
Y = X\Arq sx ? Backward Comi ) osition(B <):
Y\Arg.syX\(Ar.q.sxUY ) ===>
X\(A'rgsxUArosy ) ? Coordination(~):
XCONJ X ~ X 3 Basic morph-syntactic chart parsing Korean chart parser has been developed based on our KCCG modeling with a  10  (  , 0()0 morpheme dictionary . Each morpheme entry in the dictionary has morphological category  , morphotactics connectivity and KCCG syntax ( : at-egoriest br the morpheme . 
In the morphological analysis stage , a unknown word treatment nmthod based on a morpheme pattern dictionary and syllable bigrams is used after  ( Cha et al ,  1998) . POS ( part-of speech ) tagger which is tightly coupled with the morphological analyzer removes their rele-wmt morpheme candidates from the lnorpheme graph  . The morpheme graph is a compact representation method of Korean morphological structure  . KCCG parser analyzes the morpheme graph at once through the morpheme graph embedding technique  ( Lee et al ,  1996) . 
The KCCG parser incrementally analyzes the sentence  , eojeolby eojeol :1 Whenever a neojeolis newly processed by the morphological n-alyzer  , the morphenms resulted in a new morpheme graph are embedded in a chart and analyzed and combined with the previous parsing results  . 
4 Statistical structured disambiguation for KCCG parsing Th  ( ' statistics which have been used in the ex -per inlents have been collected fronlthe KCCG parsed corpora  . The data required for training have been collected by parsing the standard Korean sentence types  2  , example sentences of grammar book , and colloquial sentences in trade interview domain  3 and hotel reservation domain 4  . We use about ; 1500 sentences for training and 591 in dq ) endent sentences for evaluation . 
The evaluation is based on parsewfl method ( Blackel , a \] . , 1991) . In the evaluation , " No-crossing " is 1 ; 1 1o number of sell tellces which have no crossing brackets between the result and  ; tie corresponding correct trees of the sentences . "Ave . crossing " is the average number of crossings per sentence  . 
4.1 Basic statistical model
A basic method of choosing then lost plausible parse tree is to order the prot  ) abilities by the lexical preib , rences 5 and the syntactic merge probability . In general , a statistical parsing model defines the conditional probability  , 1"(71S ) , for each candidate treert brasentence S . A generative model uses the observation that maximising P  ( % S ) is equivalent to maximising P ( rIS )  6 . 
1Eojeol is a spacing unit in Korean and is similar to an English word  . 
2 Sentences of length <11.
a Sentences of length <25.
4 Sentences of hmgth_<13.
5The frequency with which a certain category is associated with a morpheme tagged for part-of -speech  . 
c'P ( S ) is constmlt.

Thus , when S is a sentence consisted of a sequence of morphemes tagged for part-of-speech  , ( w  ~ , t ~) , ( w2 , t2) ,   . . . , ( w , , , tu ) , where wi is a ith morpheme , ti is the part-of-speech tag of the morpheme wi , and cij is a category with relative position i , j , the basic statistical model will be given by : r *= arg  , ~ xP ( rl , S ') (1) (2) = argn~xP ( S) , ~ argmaxP(T , S ) .  (3)

The r * is the probabilities of the optimM parse tree  . 
P ( r , S ) is then estimated by attaching probabilities to a bottom-up composition of the tree  . 
P(r , S ) = IIP ( cij )   ( 4 ) cij ~ T = H ( P ( ei il cik ' ck + ' J ) cijET xP ( cik ) P ( cl ~+ lj ) ) , (5) i < k < j , if cij is a terminal , the , P ( cj ) = and frcquency(cij , ti , wi ) frequency(ti , wi ) ' (6) frequency ( eli , cik , Ch+lj ) (7) P ( eijleik , C~+lj)~frequency(cik , ck + lj ) The basic statistical model has been applied to morpheme/part-of-speech/category  3-tuple  . 
Due to the sparseness of the data , we have used part-of-speech/category pairs 7 together , i . e . , collected the frequencies of the categories associated with the part-of-speeches assigned to the morpheme  . Table 1 illustrates the sample entries of the category probability database  . In table , ' nal(fly ) ' has two categories with 0 . 6375 mid 0 . 3625 probability respectively . Table 2 illustrates the sample entries of the merge probability database using equation  7  . 
frequency ( old , tl ) 7 We define this as P ( cljltl ) ~ fvcq .   .   .   .   .   . y(tD "
Table 3:

Results fl ' om the Basic Statistical
Total sentences

Ave . crossing
Labeled Recall
Labeled Precision 1.00 77.02 79.15
Figure 1: Sub-constituents for head head cooccurrence heuristics Table  3 summarizes the results on an open test set of 591 sentences . 
4 . 2 Head-head co - occur rence heur i s t i cs In the basic statistical model  , lexic M dependencies between morphemes that take part in merging process cannot be incorporated into the model  . When there is a different morpheme with the same syntactic category  , it can be a miss match on merging process . This l in fita-tion can be overcome through the cooccurrence between the head morphemes of left and right subconstituent  . 
When Bh is a head morphenm of left subconstituent  , r is a case relation , Ch is a head morpheme of right subconstituent as shown in figure  1  , head head cooccurrence heuristics are defined by : p  ( B , LI ,  .   , Ch ) ~ frequency ( Bh , r , Ch ) frequency ( r , Ch )  "  ( 8 ) Tile head head cooccurrence heuristics have been augmented to equation  5 to model the lexical cooccurrence preference in category merging process  . Table 4 illustrates the sample entries of the cooccurrence probability database  . 
In Table 4 , a morpheme'sac(means'bird')' , which has a " MCK ( common noun ) " ms POS tag , has been used a nominative of verb'hal ( means'fly ' ) ' with 0 . 8925 probability . 

Table 1: Sample entries of the category probal ) ility database ( ' DII ' I neans an'1' irregular verb . )
P () S , morpheme category probability
DII , nalv\[D\]\np\[noln\]0.6375
DI1, halv\[D\]\np\[noln\],nl)\[acc\]0.362, 5
DI1v\[D\]rip\[nora \] 0.3079
DI1v\[D\]\np\[llOm\],np\[acc\]0 . 2 020 Table 2: Sample entries of ' syntactic merge probability database left  ; category ~ ,  / ( ~ \ , u , \[ , ,o , ,l \]) ~ , /(~ ,  \  , place \]) right category v\[D\]\np\[noml , np\[acc\]v\[D\]\ , , p \[ , lo , , , \] , ,u , \[ acdinerged category v\[D\]\ , ,p\[acd  v\[D \]\  ni)\[nonl \]  probability 0 . 0473 0 . 6250 nl , ( v/(v\nont ))\ nt , v/(v\np\[nom\])I ) . 2 197 The modified model has been tested Oil the same set of the open sentences as in the  1  ) asic model ext ) eriment . ' l~f l ) le5smnmarizes the result of these expcwiments . 
? Ezperim cnt : ( linear combination afth , c basic model and the head-h , cad cooccurrence heuristics ) . 
P (% s ) eijr +/ ~ p(\]/'I , , . , c *')) ? P(~ , ik)~'(~ , k + , ;)) , (9) i < k < j , if cij is a terminal , ~ J ,  . , ;', ~ p(c#i ) = P ( c . ~: iI~g , td . 
Ta , b h ; 5: Results from the Basic : Statistical Model t ) lnshead head cooccurrence heuristics
Total sentences 591
No-crossing 81.05%
Ave . crossing 0.70
Labeled Recall 84.02
Labeled Precision 85 . 30 4 . 3 The coverage heur is t ics If " there is a case relation or a modification relation in two constituents  , coverage heuristics designate it is easier to add the smaller tree to the larger onet tlantomerge the two medium sized trees  . On the contrary , in the coordination relation , it is easier to nmrge two medium sized trees . We implemented these heuristics using / ; tiet bllowing coverage score :
Case relation , modification relation :
COV_scorc = left subtreccoverage+riqh , tsub/roecoverage . ( j_()~4?~7~,~,, bt, . ~, . , ~ o , , , , ', , e ; <', ' i : jl , , i ~ , , b > ' . eeo ,, ~',',, . ~,' .  "

COV_sco'rc='exx/left . ~, a , l . , ' ~ c . ~ o . ,,, . ~, . ,, . :, . . x ,'# lht . ~, O , l , , . , , , : o . ,,~, . , , , ~1 ~ leJ't subtree cove, . aqe+R~~b~r (' . e ~; . ~ t . 
A coverage heuristics are added to the basic : model to model the structural preferences  . Table 6 shows the results of the experinlents on the same set of the open sentences  . 
? Ezp criment : ( the basic model to th , c
COV_s corcheuristics) . We have used (; tie COV_ . sco're as the exponent weight feature for this experiment since the two nmnl  ) ersarc ; in the different nature of statistics . 
P(7- , S ) = H(P ( ciJ\]cik , Ok+lJ ) l-COV-'s c?rceijCT ? p(~k)p(c ~ + , j )) ,  (1~ , ) i < k < j , if Ciji Saterminal , o , :  ,   , P ( ~ . j ) = 1)(c ~ . jl ~, ~, ~ d . 

Table 4: Sample entries of cooccurrence probability database  . 
head head cooccurrence probability ( MCC < ganeungseong > , np\[nom\] , HIl . < nob >) 0 . 8932 ( MCK<sae>,np\[nom\],DIl<nal>)0 . 8925 ( MCK < galeuchim >, np\[acc\],DIeu<ddaleu >) 0 . 8 743 Table 6: Results from the Basic Statistical model plus Coverage heuristics 
Total sentences 591
No-crossing 80.13%
Ave . crossing 0.81
Labeled Recall 82.59
Labeled Precision 83.75 5 Summary
We developed a morphosyntactic categorial parser of Korean and devised a morpheme-based statistical structural disambiguations  (  ; henles . 
Through the KCCG model , we successthlly handle difficult Korean modeling problems  , in-chtding relative free-word ordering , coordination , and case-marking , during the parsing . 
To extract he most plausible parse trees ti'om the parse forest  , we have presented basic statistical techniques using the lexical and contextual information such as morpheme-category poba-bility and category merge probability  . 
Two different nature of heuristics , head head cooccurrence and coverage scores , are also developed and tested to augment the basic statistical model  . Each of them demonstrates reasonable t ) ertbrmance increase . 
The next step will be to devise more heuristics and good combination strategies t br the different nature of heuristics  . 

E . Black , S . Abney , D . Flickenger , C . Gdaniec , R . Grishman , P . Harrison , D . Hindle , R . Ingria , F . Jelinek , J . Klavans , M . Liberman , M . Marcus , S . Roukos , B . Santorini , and T . Strzalkowski .  1991 . A Procedm'e for Quantitatively Comparing the Syntactic Coy-erage of English Grammars  . In Prec . of
Fourth DARPA Speech and Natural Language Workshop.
Jeongwon Cha , Gcunbae Lee , and Jong-Hyeok Lee .  1998 . Generalized unknown morpheme guessing for hybrid pos tagging of korean  . 
In Pwceedings of Sixth Workshop on Very
Large Corpora in Coling-ACL98, Montreal,

E . Charniak .  1995 . Prsing with ContextFree Grammars and Word Statistics  . Technical
Report CS-95-28, Brown University.
M . Collins .  1996 . A New Statistical Parser Based on Bigram Lexical Dependencies  . In Proceedings of th , e3/tth Annual Meeting of the
ACL , Santa Cruz.
D . Hindle and M . Rooth .  1993 . Structural ambiguity and lexical relations . Computational
Linguistics , 19(1):103-120.
B . Hoffman .  1995 .  ~7~ , c Computational Analysis of the Syntax and Interpretation of ' if  ; roe " Word Order in Turkish . Ph . D . thesis , University of Pennsylwmia . IRCS Report 95-17 . 
Wonil Lee , Gennb : mLee , and Jong-Hyeok Lee.
1996 . Chart-driven connectionist categorial t ) arsing of spoken korean . Computer processing of oriental languages , Vol 10 , No 2: 147--159 . 
D.M . Magerman and M.P . Marcus . 1991.
Parsing the voyager domain using t ) earl . In In Prec . Of the DARPA Speech and Natural
Language Workshop ~ pages 231-236.
D . M . Magerman and C . Weir .  1992 . Efficiency , robustness and accuracy in picky chart parsing . In In Prec . Of the 30th Annual Meeting of the Assoc . For Computational Linfluisties ( ACL-92) , pages 4047 . 
Mark Steedman .  1985 . Dependency and Coordination in the Grammar of Dutch and English  . Language , 61:523568 . 

