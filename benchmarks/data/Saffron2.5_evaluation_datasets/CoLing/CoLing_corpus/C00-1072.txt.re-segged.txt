The Automated Acquisition of Topic Signatures for Text 
Summarization
Chin-Yew Lin and Eduard Hovy
Information S(:i(umesIllstitute
University of Southern California
Marina del Rey , CA 90292, USA
cyl , hovy C~isi.edu
Abstract
In order to produce , a good summary , one has to identify the most relevant portions of a given text  . We describe in this t ) at ) era method for automatically training tel ) it , signatures -- sets of related words , with associated weights , organized around head topics and illustrate with sign at m'es we cre-  ; tt . ed with 6 , 194 TREC collection texts over 4 selected to t ) ics . We descril ) ethel ) ossible integration of ' tolli ( : signatures with on to h ) gies and its evaluaton on an automate ( l text summarization system . 
1 Introduction
This t ) a per describes the automated ( : reation of what we call topic signatures , constructs that can I ) lay a central role . in automated text summarization and information retrieval  . To I ) ic signatures can lie used to identify the t ) resence of a ( : omph~x conce . ptaconcep that consists of several related coinl ) onents in fixed relationships .  \]~ . c . sta'uvant-'uisit , for examph ~ , in voh , esath , as t the concel ) t slltCgFIt , t ' . ( tt , pay , and possibly waiter , all ( l Dragon Boat Pcstiva I ( in Tat-wan ) involves the Ct ) llC ( !l ) t , Scal(tlzt'lt , s(atalisman toward of fevil ) , rnoza ( something with the t ) ower of preventing pestilen ( : e and strengthening health )  , pictures of Ch , un 9Kuei ( a nemes is of evil spirits ) , eggs standing on end , etc . Only when the concepts cooccur is one licensed to infer the comph:x concept  ; cator moza alone , for example , are not sufficient . At this time , we do not c . on sider the imer relationships among tile concepts . 
Since many texts may describe all the components of a comI  ) lex concept without ever exI ) lic-itly mentioning the mlderlying complex concel /t--atol  ) ic--itself , systems that have to identify topic(s ) , for summarization or information retrieval , require a method of infcu ' ring comt ) h'x concelltSfl ' om their component words in the text  . 
2 Related Work
In late 1970's,\])e . long ( DeJong ,  1982 ) developed a system called I"t IUMP ( Fast Reading Understanding and Memory Program ) to skim newspaper stories and extract the main details  . FRUMP uses a data structure called sketchy script to organize its world knowh'dge  . Each sketchy script is what FRUMI ) knows al ) out what can occur in l ) articu-lar situations such as denmnstrations , earthquakes , labor strike . s , an ( tso on . FRUMP selects at ) artic-ular sketchy script based on clues to styled events in news articles  . In other words , FRUMP selects a neml ) t3~t ( uni ) late 1whose slots will be tilled on the flyast " F\[UMP reads a new sart Me  . A summary is generated ) a sed on what has been ( : al ) tured or filled in the teml ) Iate . 
The recent success of infornmtion extract k ) n research has encore ' aged the FIUM 1 ) api ) roach . The SUMMONS ( SUM Marizing Online Newsart Mes ) system ( McKeown and Radev ,  1999 ) take stem-l ) late outputs of information extra ( : tion systems de-vel of md for MUC conference and generating smn-maries of multit  ) le news art Mes . FRUMP and SUM-MONS both rely on t/rior knowledge of their domains  , th)wever , to acquire such t ) rior knowledge is lal ) or-intensive and time-consuming . I ~) rexam--l ) le , the Unive . rsity of Massa (: husetts CIRCUS sys-l . enluse ( lill the MUC3 ( SAIC ,  1998 ) terrorism domain required about 1500i ) erson-llours to define extraction lmtterns2 ( Rilotf ,  1996) . In order to make them practical , we need to reduce the know hxlgen-gineering bottleneck and iml  ) rove the portability of
FIUMI ) or SUMMONS-like systems.
Since the worhi contains thousands , or perhal ) smillions , of COml ) lex (: on (: et ) ts , it is important ; to be able to learn sketchy scripts or extraction patterns automatically from corpora-no existing knowledge base contains nearly enough information  . ( Rilotfaim Lorenzen ,  1999 )  1 ) resent a system AutoSlog-TS that generates extraction i  ) atterns and learns lexical constraints automatically fl ' omt  ) rec\]assified text to alleviate the knowledge ngineering I  ) ottleneck mentioned above . Although Riloffal ) plied AutoSlog-TSl\Veviewed sketchys ( :lil ) tS and teml ) lates as equivalent ( ollstrllct Sill the sense that they sl ) ec il ~ , high level entities and relationships for specific to t  ) its . 
2 A i i extra (: l ; iOll patt t!rlk is essentially ; t case fraine contains its trigger word , enabling conditions , variable slots , and slot constraints . CIRCUS uses a database of extraction patterns to t ~ alSe texts  ( lilol I ' ,  1996) . 
4 95 to text categorization and information extraction  , the concept of relevancy signatures introduced by her is very similar to the topics i  . q natures we proposed in this paper . Relevancy signatures and topic signatures arc both trained on preclassitie documents of specific topics and used to identify the presence of the learned topics in previously unseen documents  . The main differences to our approach are : relevancy signatures require a parser  . They are sentence-based and applied to text categorization  . 
On the contrary , topic signatures only rely on corpus statistics , arc docmnent-based a and used in text smnmarization  . 
In the next section , we describe the automated text smmnarization system SUMMARIST that we used in the experiments to provide the context of discussion  . We then define topic signatures and detail the procedures for automatically constructing topic signatures  . In Section 5 , we give an overview of the corpus used in the evaluation  . In Section 6 we present he experimental results and the possibility of enriching topic signatures using an existing ontology  . Finally , we end this paper with a conclusion . 
3 SUMMARIST
SUMMARIST ( How and Lin ,  1999 ) is a system designed to generate summaries of multilingual input texts  . At this time , SUMMARIST can process English , Arabic , Bahasa Indonesia , Japanese , Korean , and Spanish texts . It combines robust natural language processing methods  ( morl ) hologieal transformation and part-of-speech tagging  )  , symbolic world knowledge , and information retrieval techniques ( term distribution and frequency ) to achieve high robustness and better concept -level generaliza--tion  . 
The core of SUMMARIST is based on the following ' equation !: summarization = topic identification + topic interpretation + generation  . 
These three stages are:
Topic Identifie at lon:Identify the most imtmrtant  ( central ) topics of the texts . SUMMARIST uses positional importance , topic signature , and term frequency . Importance based on discourse structure will be added later  . This is tile most developed stage in SUMMARIST . 
Topic Interpretation : ~ i ~ - ) fllse concepts such as waiter , menu , and food into one generalized concept restaurant , we need more than the sin > piewordaggregation used in traditional information retrieval  . We have investigated concept a We would like to use only the relevant parts of documents to generate topic signatures in the future  , q kext segmentation algorithm such as TextTiling ( I learst ,  1997 ) can be used to find subtopic segments in text . 
ABCNEWS . cona : Delay in Handing Flight 990 \[' robe to FBIN'I' SI3 Cllaitnlan Jarlle Stlall says Egyptian clfficials  Iv811l to I , ~ viewrest llts of tile investigation int cllhe crasl l of llg gyptAir Flight  990 before tile case i ~ lurlled over Ic , tileFi31 , Ntlv . IG-US . i lxvestigl ~ lo\[~lLppear to be leat lill gi i Iorethgl leve Flow ~ trd tile possibili ty that one of the cc~-pilot ~ of Egypt Air F light  990 may have de\[i heralely crashed tile p lane last I laflllth  , killing all 217 people on board . 
flail'ever . US . officials saytile National Tran ~ por ' tation Safety Board will delay transferr ing tile invegtigalion of the Oct  31 crash totilt : FI31 -the agency that wotlid leadi ~ criminal p robe-for at least tt few days  . to MI ow Egyptian experts to review evidence illtile case  . 
gttsl ) iciot l ~ of foul play were raised after investigators listening to rttape f to ll lilt cockp it voice recorder isolated a religious prayer or statelllellt made by tile co-pilot just before tile p lane's autopilot was turned offslid the plane began its initial plunge into ti le Atlantic Ocean off Mas-srtchtt sett $' N all tucket \[ si all d  . 
Overtile ' past week . after mucil effort , tile NTSJB and tile Navy succeeded ill Io cat illg the plane's two " black boxes  , "th ~ cockp it voice recorder and lheflight data recorder  . 
The tape indicates tll at shortly after the plane leveled ~ f fatits cruising a ltitude of as  , 000 feet , tile cl ~ i ef pi lot of tile aircraft left the plane's cockp it  , leaving one of tiletwc ~ co-pilotsnIol letile reast heaircraft began its descent  . 
Figure 1: A Nov .   16   1999 ABC News page sumnmry generated by SUMMARIST . 
counting and topic signatures to tackle tilefll -sion problem  . 
Summary Generation : SUMMARIST can produce keyword and extract type summaries  . 
Figure 1 shows an ABC News page summary about Egypt Air Flight  990 by SUMMARIST . SUMMARIST employs several different heuristics in tile topic identification stage to score terms and sentences  . The score of a sentence is simply the sum of all the scores of content-bearing terms in the sentence  . These heuristics arc implemented in separate modules using inputs from preprocessing modules such as tokenizer  , part-of-speech tagger , morphological analyzer , term frequency and tfidf weights calculator , sentence length calculator , and sentence location identifier . \ Veonly activate the position module , tile tfidf module , and the . topic signature module for comparison . We discuss the effectiveness of these modules in Section  6  . 
4 Topic Signatures
Before addressing the problem of world knowledge acquisition head-on  , we decided to investigate what type of knowledge would be useflfl for summarization  . After all , one can spendalife time acquiring knowledge in just a small domain  . But whatistile minimum amount of knowledge we need to enable effective topic identification ms illustrated by the restaurant-visit example ? Our idea is simple  . 
We would collect a set of terms 4 that were typically highly correlated with a target concept from a preclassified corpus such as TREC collections  , and then , during smnmarization , group the occurrence of the related terms by the target concept  . For exam-pie , we would replace joint instances of table , inert ' u , waiter , order , eat , pay , tip , and so on , by the single phrase restaurant-visit , in producing an indicative 4Terms can be stemmed words , bigrams , or trigrams . 
496 sulnlllary . \ Vethus defined a to t ) it sign at . ure as a family of related terms , as follows : ~ I'S = topic , sifl ~ zutu . rc . = topic , <( t ,, wl), .   .   .   , ( t ,   ,   , w ,   , ) > (1) where topic is the target concet ) t and . , d . q ) zat ~ Lrc is a vector of related ternls . Eacht , is antermldghly correlated to topic with association weight w /  . The number of related terms 7z canties et empirically according to a cutot\[ associated weight  . We . describe how to acquire related terms and their associated weights in the next section  . 
4.1 Signature Term Extraction and Weight
Estimation ( ) n the assumption that semantically related terms tend to cooccur  , on ( ' can construct topic signatures fl'om preclassified text using the X  2 test , mu- . 
tual information , or other standard statistic tests and infornlation-theoreti  ( : measures . Instead of X'2, we use likclih . ood ratio ( Dunniug , 1993) A , sin(:eAi , ; more apI ) rot ) riate for si/arse data than X 2 test and the quantity -21o9A is a symi ) t ( /tically X ~ dis-tril ) ute ( 15 . Therefore , we Call ( letern dnc the ( : onti- ( lence level for a specific -21o9A valuel/ylookingut ) X : ~ ( tistril ) ution table and use tlm value to sel (  , ,ct an at)i)rot)riate cutoff associated weight . 
We have documents l )\[' e . classitied into a : ; ('~ t , " R . of relevant exts and a set ~ . of nonrelew m texl ; s for a given topic . Assuming the following two hyl ) othe , ' ~ es : t typothesis 1 ( If l ) : t ' ( ~ Pvlti ) = P = P ( ' PvltT/ )  , i . e . 
the r ( . , lewmcy of ad()(:lment is in(teI)en(hmt , of ti . 
I \]\ [ ypothesis 2 ( t t 2 ) : I ' ( ' Pv\[ti ) == lh~1 ) '2-t ) ('Pvlt , i ) , i . e . th(~t)r ( . ' : ;(; n(:(~oftiindi (: ~ Lt ( . ~ . ' ; strong r ( ~levan ( : y~ssunling\]h > >1 ) 2? and the following 2-10 = 2 contingency tabl (  ; : where Ol ~ is the fiequency of term ti occurring in the  . l'elev ; tntset , 012 is the\[r ( ! qu ( nlcy of Lermt it ) c-curring in the \] loll relevall t , set , O21 is the fle(lllell(:y of t t ; rnl\[i ? tioccurring in the rtdevant set , O . _, ~ is the fl'equ(mcy of term l . i ? tio (: curring in the non-l'elevai its eL . 
-kssmningal ) inomial distril ) ution :
C ;) b(~;,, . , :/ . ) = :,:~(1 -  . ~: ) (" " )   ( 2  )   5This assume shaltheratio is between the in a ximuni like >\[ ihoodest  , im & t . (! over a . qll ) part of l ; l(!i ) al at lllC't(~rsl ) a(:(~ ; tll(\]l . h(!ll laxill Ullll likelihood(sI . iIItlA~ov(!rthe(Hltill!i ) al ' aillt ~ tt!rsi) ; t(:e . 
Set ! ( Manning ; tnd Sch/itze , I999) t ) ag , es172 l . o175 for d(!t . ails . 
then the likelihood for HI is:
L(H ~) = b(Ot ~; 0~+ Ou , ,p)b(O : , ~; 0: , , + Om , ,p ) and for //2 is : L(H2) = D(OI 1 ; O11 Jr "(') 12 , Pl)b(O21 ; (') 21 Jr-( , )22 , 1)2) The-2 log , \ value is then computed ms follows : 1 . ( f/1) m--21 o9--
L(it2) b(O11; OI1+O12 , P ) IJ(021: O21+022 , P ) --21o91'((-)1l;()11+O1'-) , PI)h(O21; O21 q-()22 , P2 )  : - -2  (   ( Oll+021 ) lor_Jp + (   (   ) 12+022 ) lo 9 ( 1--l ~ )  - -  (  , ~1 )   ( ?  ) ll lo ' JP l + O l21 og ( l " t'1 ) +0211ogp2-~0221o0 ( 1-f~2 )   )   )  -- ' . 2 . ,~' x (~ ' i (7~) - ;~(~19- ) ) (4 ) = 2 , ' vxZ(P ~ ; T )   ( 5  ) whel'eN = Olt-F O12   -1-   O21 -I- 022 is the total llum- . 
her of t , ernl occurrence , in the corpus ,  7/ ( '/~ ) is the entropy of terms over relevant and nonrelevant sets of documents  ,  7/  ( ' felt ) is the entropy of a given term OVel " relev ; in L~/ndnonl '( . qev all tsets of do ellinellLS , ~ tll(1Z('R . ; T ) i : ; the inutual information between document relevancy and a given t  ( ' . rm . Equation 5 indicates that mutual inforntation 6 is an e ( tuiwdent mea-sur (  . ' t()lik ( . qiho ( idratio when we assume a binomial distribution and a  2-by-2   ( ' ontingency table . 
To crest (; topic . ~ dg nature for a given to t ) ic , we : 1 .   ( : lassify doctunents as relevant or nonrcl cwmt according t  ( ) tile given topic 2 . comt ) ut . e the -21oflA wdue using Equation 3 for each Lcrm in the document colle ( : Lion " . rankt , erms according 1 otheir-2 lo9~value 4 . select a c(mfid(mcel , velfi ' om the A ; : ( list ril ) utiot ltable ; ( leterm in (~ the cutotf associated weight , mid the numl ) (n " of t ( nms to he included i Il the signatures 5 The Corpus The training data derives Kern the Question and Answering summary evahmtion data provided l  ) yTIPSTEI / . -SUMMAC ( Mani et al , 1998) that is a sttb set of the TREC collectioliS . The TREC data is a collection of texts , classified into various topics , used for form a lew dua Lions of information retrieval systems in a seri  ( ~s of annual ( : omparisons . This dataset : contains essential text fragnients  ( phrases , (: I ausos , iuld sentences ) which must 1 ) e included in SU llltIlarios to ~ tns wer some TIEC tel  ) its . The sefl ' agments are each judged 1 ) yahmnan judge . As described in Se(:-tion 3 , SUMMAI~IST employs several independent nlo ( hlles to assign a score to each SelltA:llCe ~ and Chell C Olll  ) ille Sthest . ' or ( . ' . % L ( ) decide which sentences to extract from the input text  ;  . ( ) n 0 . can gauge the efticacy ( > l'hellll\[llain rormalion is defined according to chapter  2 of ( ( ; over and Thomas , i991 ) and is not tile i ) airwis ( ~mutual in for lnalion us ( ! din ( ( ; hur(:h and llanks ,  1990) . 

TREC Topic Da~crlption ( nun QNumber : 151 ( title Topic : Co , ping with overcrowded prisons ( dese Deserilltioll : The doeullaent will provide in f  , ~ rnlationol ~ jail and prison over crow diu K and how irlmates are forced to cope with th  , ~se conditions ; or it will reveal plan ~ to relieve tile over crowded ? ollditlon  . 
( nart ) Narrative:
A relevant docunaent will describe scene ~ of over cro~vdillg that have be colneall too crllllll Ollill jails and prisons arot tnd the country  , Tile document will identify how inmates are forced to cope with those over-crowded condi tion ~  , and/or whattile Cc lrreetional Systelll is doing  , or phlnning to do , to alleviate tile crowded collditiol l  . 

Test Questions
QIMe ' hatare name and/or location of tile cor rection faeililies where the reported ~ vercrowding exists ?  Q2 x ~ V hat negative experiences have there been at tile over crowded facilities  ( whether or not tile ) " are thought to have been caused by the overc row dl ng  ) ?  Q3 What measures have been taken/plaiailed / recommended  ( etc .   ) to a econll nod~te more illllaIes zlt pen a l facilities  , e . g .   , doublillg tip , Ile~yCOllStructlon ? Q , I ~ , V hat measures have been taken/planned/rec~mnlel , ded ( etc . to reduce tilellt lllber of De will li \ ] at e $  , e . g .   , moratoriums on admis Mon , alternative penalties , programe to reduce crime/recl divism ? Q5 What measures have been taken/planned / recommended  ( etc .   ) to reduce tile number of existing inmates at an overcrc ~ wded facility  , e . g .   . granting early release , trnnsfering to uncrowded facilities ?
Sample Answer Keys ( DOC NO ) AP891027-0063 ( /DOC NO )   ( FILE ID ) AP-NR-10-27-890615 EDT ( /FILE ID )   ( IST_LINE ) raPM-Chained Inmates 10 270 335 ( /IST . LINE ) (2ND-LINE ) PM-Chained lnmates , 0344  ( /2 ND_LINE )   ( IIEAD ) lnmates Chained to 1 . Vails in 13M timore Police
Stations ( /llEAD )   ( DATELINE ) BALTIMOITIE ( AP )   ( /DATELINE ( ' tEXT )   ( Q , q ) prisoner ~ are kept chained to the wall ~ of local policel cJekup ~ for as long as three days at at ln~eI  ) e cattse of over crowding ill regular jellcel ls  , police said .   ( /Q3 Overcrowding at the ( Q1 ) lqMtl rnore County Detention Center ( / Q1 ) h ~ forced pnllee tn .   . 

Table 1: TREC topic description for topic 151 , test questions expected to be answered by relewmt documents  , and a smnple document with answer key , s . 
of each module by comparing , for ditferent amounts of extraction , how many : good ' sentences the module selects by itself  . We rate a sentence as good simply if it also occurs in the ideal human-madextract  , and measure it using combined recall and precision  ( Fscore )  . We used four topics r of total 6 , 194 documents from the TREC collection .   138 of them are relevant documents with TIPSTER -SUMMAC provided answer keys for the question and answering evaluation  . Model extracts are created automatically from sentences contail fing answer keys  . Table 1 shows TREC topic description for topic 151  , test questions expected to be answered by relevant documents  , and a sample relevant document with answer keys markup  . 
7These four topics are : topic 151: Overcrowded Prisons , 1211 texts , 85 relevant ; topic 257: Cigarette Consumption , 1727 texts , 126 relevant ; topic 258: Computer Security , 1701 texts , 49 relevant ; topic 271: Solar Power , 1555 texts , 59 relevant . 
SA relevant : document only needs to answer at least one of the five questions  . 
6 Experimental Results
In order to assess the utility of topic signatures in texts ununarization  , we follow the procedure described at the end of Section  4  . 1 to create topic signature for each selected TREC topic  . Documents are separated into relevant and nom ' elevant sets according to their TREC relevancy judgments for each topic  . We then run each document hrough a part-of-speech tagger and convert each word into its root form based on the \\ h  ) rdNct lexical database . 
We also collect individual root word ( unigram ) fi'e-quency , two consecutive non-stop word 9 ( bigram ) fi'e-quency , and three consecutive non-stop words ( trigram ) fi'equeney to facilitate the computation of the -21ogA value for each term . We expect high ranking bigram and trigram signature terms to be very informative  . We set the cutoff associated weight at 10 . 83 with confidence level ~ t = 0 . 001 by looking up a X2 statistical table . 
Table 2 shows the top 10 unigrmn , bigram , and trigram topic signature terms for each topic m  . Several conclusions can be drawn directly . Terms with high -21ogA are indeed good indicators for their corresponding topics  . The -2logA values decrease as the number of words in a term increases  . This is reasonable , since longer terms usually occur less often than their constituents  . However , bigram terms are more informative than nnigrant erms as we can observe : jail // prison overervw ding of topic  151  , to bacco industry of topic 257 , computer security of topic 258 , and so lare'n , ergy/imwer of topic 271 . The semLto-matically generated signature terms closely resemble or equal the given short TREC topic descriptions  . 
Although trigram terms shown in the table , such as federal court order , philip morr is 7~r , jet propul . .
sion laboratory , and mobile telephones : q stem are also meaning flfl  , they do not demonstrate he closer term relationship among other terms in their respective topics that is seen in tlm bigram cases  . We expect that more training data can improve tile situation  . 
We notice that the -2logA values for topic 258 are higher than those of the other three topics . As indicated by ( Mani et al ,  1998 ) the majority of relevant documents for topic 258 have the query topic as their main theme ; while the others mostly have the query topics as their subsidiary themes  . This implies that it is too liberal to assume all the terms in relevant documents of the other three topics are relevant  . We plan to apply text segmentation algorithms such as TextTiling  ( Hearst , t997) to segment documents into subtopic units . We will then perform the topic signature creation procedure only on tile relevant units to prevent inchlsion of noise terms  . 
9\ , Veuse the stop word list supplied with the SMAIIT retrieval system  . 
l?q'he -2logA values are not comparable across ngram categories  , since each ngraln category has its own sample space  . 

Topic
I : llh~lall l-21 , ~ gX\]li ~ lall I-21 , ,9X j a i l t)3L I)1 , 1 e()tH~t2 , jail Dit ) 27:1c + , l l l l l . IIJN ~21 ea elyle +\] + . ~lSt ? N,'~:t;\],)v, . ),'~,, wdln ~; : ?12:1 . I ~ ~ tal, . Dl  ~ . , , n 7 . 1R 72 ill ln ? lt , "2: tl 7d 5 stal ,  " 1 , ) i  ~ ,   , n ,   . i 67, 3(~t ~ ~ h + . lif\[IF,I . i lo , 1: ~3 fill , " l ; lt ( ; 2" ) stale 151   9t t ~ iailrl % l ' lctr ~% vI\]lrldI ; 1 ~\[ iIll~tllil'lII ~" I " ; ~' C ( , tltI + , l , i " ttll . O !) li+tl-s,,rl 1,17,3t ), ih .   . aljail 56 tit+Cl ) y 133 177 pll .   , )D ( ) vcylcl ,   , ivt hll ~ 5537: + ,   ,   , v ,   . r , . r ,   , wd , + d12 NI ) t ) Si- ( * lllt:l\[facilit 3   52   9o9   10 Signatttro Torms of Tupic 151 Ovor crowdod Prisons " I'II ~ I al Il -21  , ,~11\ f - , It . l~tlc , , ul ~<, ltt, . l-I . ' ,  :) , ; 11C ,   , lllp\]yc + , ll ~ (' lll , \]+' c\[+++"3 , 512 L+l ,  . kali+i'i ) iIi , \[~'+ h , ' ll\[\[\[15121 ~ , 11 i , ) tl ; , nk : ; . 5L 21j , ) otlkIH ) li 5: ~ . ', . 1'21 pll ~ C , ll , ' rc+)ll:ll~lail:~512 191: if ,   . \]) ll~t ) lli21 ) llltl~~Nt ) . l\[\]t putplis +, ll . 2t ~: t-IIc + ~ uuly jaiL ~ l ; ll , . 2t ~ 31 lh , ,hl l , ~ e~ljail 2d : lIITopic 10 Sigllnt tlre Ternls of Topic 257  -  ( ligar ~ tt ~ Colslll ) l ) t loll:ni < rt un21 ogXI+i ~ . rarll--2/,,f/ . \' iri4 ~ am-21,, ~ A clgrtl, . It ? + . 171 ; \[: i N ~ tlb:xt'c + ) LIt ( \] ll~ll~~il7 ) iNI , hilip IIl , ) l l i + t j l 2 . ~ ~ DSIl()htlcc ~): ll ; l0 17 hnt-lg/ll , -llt-t ; 7 t2IIr)l\]ilIlallsbeDs ~ , llh < . (\[~ f . 211 ~) t ~\[ lsIIIOkill ~28 . t19 ~ philiptll ( , l\[i ~ 5 t()7 ; ~\[1111 ~ L'ikll('e\[d'+\[llll 2221 . t ~ nl ~, ke 159 13 . 1 clarxl <' t1,:%,'att 80 . t 5 q t t i r i l l n c l l ~ ' . 2'1 IISI , ~ lhlllall ?156 . ) 375 tolhllllll ~ itlY , ' lIlatlt ) llgkl-t . t . 13 . 1 qtlqttfi~ln21-IlS ,, ~ haI . tS372 to bac ? , ) elll()k . ~112) Ibllb\[ibll2022tis , ~ ila12) i . 121 ~ ilpatrickt 0 . t55c +) llst llllllollbnclgar, . lte2022 dIlltll11 ~+1~ ) cl ~ at +' ll ~ " c ~ lllpall V : ID\[$1 ) D ~\ [ t + gttalll . r\[iCttll ~ llI , lk?'(llt20226 alll , ) k('l10 . 1 Ii 0 ( ' elllllllalk+'l 36223 \[ llll~Call t'e\[ht:gl\[I 2  ( ~22 ib\[~t 79 . 90:1 ? ~ IN illt + ll + il + + t:1t; . 22:1illa\[ay ~ iall + illk ~\[ tl > , ll+et'4) lllpill IV2(I . 22 t\]TopicI0Signatur . " I'~r ) ns of Topic 258--Co ) nputorSecurityI ~ llial/lilt"2IoniaIti+/ , rall l21 , QIX " I'1i ~ ratn--21o9 , X (:+ llll ) lltOr 115!~:151 C4 , lllpIlll'tael'tllly213331 ) el Iltt/pll\[~i ( ) l l \ ] l th t ) hlt ( lly\[~~5 . tvirus 927 . G7-1~\[;id tlgtl , " sltl\[tl ' lll17~5NNIllh . ' llIlilt ) 9 R85, thacker 867 . 377 FOll ptlt,'t+ySlell 1-16 . 32  ~ C , + ltl++\]l IllliVet ~ il ~ , ' ~ ladll\[tle7)IJNI in , ) lrl ++ i +; + ~2i 13' . !) l , . ~+- archc , + ulte\[l;i2 . lI : i law tell cl " b , ' rk , '*' j ~ lall , ) lal + , l , , .  79 . 0 N\[c ,   , rn , ' ll3P+56+4c ,  :  , ml , ut , ' rwrus12~k033I ~+ , ++ , jet ptOl , tlL + iot + 79 . 0 ~1 unlv+'l?ity31) 5 . 95 ~ corneli UlXi Veleity 1 (1~47-tl Ul ; iV , q+i)y ~; radulxt ,   . + txldt . lll79U~1 + ysl+'lll2 90 . 3"17 Iltl(:l , P ; ll % t + + npl ) ll 107 . 283 lawtllle , + liv+:rtn ( . te Iigtli () llali\]\[)l\[I ; ~ I/tb , . ralL :) ly 2N 7521 inilitary t '( , lllp , ll . : r106 . 522 liv ~ qlll , ) l?"ilu)i , maLluboralory 59 195\[ab 225 . 51); vitu ~ plo~t <' llll 1U6522c , ) lllpllI(~rS , ~ CUlilye Xpetl 66 . 19 GmecLaly 128 . 5 15 % vesl ~ et ll all 82   2  \  [0 ~ ecu\[it ? , ' cenl ~\[ 13ethesda   -19423 Topic 10 Signature Terlns of Topic 271 Solar Power I'l ligtal n- -21oqX tiigt ~ ltn --2logX " I'ri ~ ; rhill--21 o ! ~ A solar-1S-l . 315 e , ~la ~ eltet l4y2Di52 1 divi ~ i , mInullipl , ~ acress 313-17) tlazdit:10Pt0IY)s < , lall , tlw , ' t 9 , 1210 nl , ) bil , : l ,   , l , -ph ,   , n ,   .  #civic ,, 313 . 17 le ,) 271; . 932 (' hri ~ tiallaid 8 fi . 211 blill sh It . cllllilll)R'g\[ ,   , llp23510 it JtLiItlll2 . 5N . 71): "+ l ++ , aS3'Sl , * III 711   5:5 elll Ilhei Nhtll Xile 23+5111 pax + lh ,   , n213381 Iill++tlllt . Ieit'j ) lll ) lle (115 ; l + iI ' illllllCilllIlackill + ; IlJdllll 22i+51 (1i ) (~ tltld12/ , 121 it i , liunlpl ,   , j ,   . cl112 . 697 ~ l , ~llalInr ) hil , + sal , ' llite 235 11 Jt , lw ~ r12G . 35:1leili<+,,,d-61 . ~111 halldlleldIIled~il , " t , ' leph ,   , ll ,  : '23510 \ [  ,   ,   ,   , k ,   , ut 125 . ll3t ; scie . llc ,, palk ~'> . 1NS ) ill ( , hile ~ at elll .  ,  . v > tetn 235 10iil\[lllilSRl 1O 9728 ~ ( ) llkl t ' i l l l t ' l ' l l t l i l I l , l 51t   ~5 I l l l l l l l t l l l l l i l l i l l i l l i l i d i l l n l I > l , lject 23 , 510 hc , ydsh , tl 7N : 173 l ) pslllal ? +1 ; /17 activt-s + , la\[*ystern 15673 Tattle2: Top10 signat . m'et . erm . ~; of m figram , bigram , and trigram for for e " TREet . opics . 
6.1 Comparing Summary Extraction
Effectiveness Using Topic Signatures +
TFII ) t ", and B as ( , line Algorithms
In orde ) " I ( )( ~ vahla ( . ( ~ the ( d\[+:ct . iv(,im . ~ snfl(>l)i (: . ~ dgna-l ; lll'(~SllS(~(\]illSllll  lIIN/l'y(~X tl'it(:t ; iOll , W , ~ Ct Illll ) ~ ll ' ( ~+ flit ! Sllltlll ~ tl'y StHII ~011 ( ' CSex ( ~ract , ( ~ d1)y the tol)icsi ~ I lil\[lll'0 , module + , basulin ( . ' module , and tfidfl not hll(~s with lm-nta'nannot , at ( ~( llllo(lo , \] Sllllllll ' ios . \VCIII(+~/SIlI'(++l ; h ( ; l ) c'rfl ) rmanc ( ~' using a c ( )ml ) in eduma sure of l'n'call ( I ~ ) and pr ( ~cisi ( m ( P )  , F . Fscore is defined by:
I"--(1+H'2) I'l ? where /3-' P+I~t ) 2\7 .  ) , . 
f ' ~ rlnfVln ~\ ,,  #of . sc , tcncc . ~c : rtratcdth , tol so at qwar in . timmodel , s . mn)?lr!l#ofsc+lt(!ncc,si11timnlo,h:l . ~ um . tav!l#of , s(' . /It clw csc : rlv?lcl cdt ) 1, tll*c . Sll . Sl cln rclatic ' ciml , ortancc of l~aml1:'(6) (7)\ V eas . ~ um(~( , ( lual importance of re ( : all iIIld precision aim set H to 1 in our ( + , Xl ) ('+ rimtml ; s . The Imselitm ( I ) ositi ( m ) module scores ( ' at : hS ( !llt ( ': ll Chy its I ) osi-ti ( > n in the text . The first sent ( race gets the high-escs ( : or tL the last S ( HIt ( H1 Cothelo west . Thel ) as ( ~ liIl(~methodiseXlmC tedtolm (' . f\[ectiv ( ~ for newsgem'e . 
The tfidf module assigns a score t . o att++rllItiat:cord-ing to the product ; of its flequc , ncy within a dot:-lllll(Hlt . j ( tfij ) and its ill V ( ~ I'S ( doctmmntt ? equoncy ( idfilo . q , ~) . N is the total mmfl ) or of document . s in the (: () rlms and dfj is the , numl)er of ( Io (: HnloAll; . q(:OlH:niningtermti . 
The topic sigjlla ( . lll (+ + module scili is each , q(~llt ; (H1C ( ~: assigning to ( ' ach word that occurs in a topic signa- ( ure thu weigh (  , of that , keyword in t . hc'tol)ic signa-tl tl'tLEit'hs(++llt( , + ItC(~Ill(illl'(:c(:ive . q a topic signature score equal to tlm total of all signature word scores it  ( : Olllailis , normalizc'd1) 3' the . highest sentence score . 
This s (: ol (3 indical . esl ; h(~l'(!l(wall(:(~of l . h(;S(!llt . t ~ n(:(!tot , lwsigmml retopic . 
SU . ~\[ . MAt/ISTIn'oduced(!xttat:ts of tlmsamul(~xI . qsui ) aralely for each , , lodul0 , for as ( ~ l'i ( , so fextracts ranging from () cX ; to 100% of the . originall ; ( xI . 
Althot tghm any rel < want docttments are avaita ) l + , for each t01>ic , Ollly SO lll0 o\[\[h0111 htlv ( ~ allSWOlkc ! ykeys are listed in the row labeled :"  #of Relevant Does Used in Training "  . To ensure we utilize all the available data and conduct a sound evaluation  , we perform a threefold (: rossvalidation . We reserve one-third of documents as test set , use the rest as training set , and ret ) eat three times with non-overlapl ) ing test set . Furthernmre , we use only unigram topic signatures fin " evaluation  . 
The result is shown in Figure 2 and TaMe 3 . We find that the topic signature method outperforms the other two methods and the tfidf method performs poorly  . Among 40 possibh , , test points fl ) r four topics with 10% SUml nary length increment ( 0% means select at least one sentence ) as shown in Table 3 , the topic signature method beats the baseline method  34 times . This result is really encouraging and indicates that the topic signature method is a worthy addition to a variety of text summarization methods  . 
6.2 Enriching Topic Signatures Using
Existing Ontologies
We have shown in the previous sections that topic signatures can be used to al  ) I ) roximate topic identification at the lexieal level  . Although the automatically acquired signature terms for a specific topic seem to  1  ) ebound by unknown relationships as shown in Table  2  , it is hard to image how we can enrich the inherent fi at structure of to l  ) ie signatures as defined in Equation 1 to a construct as complex as a MUC template or script  . 
As discussed in ( Agirre et al ,  2000) , we propose using an existing ontology such as SENSUS  ( Knight and Luk , 1994) to identify signature term relations . 
The external hierarchical framework can be used to generalize topic signatures and suggest richer representations for topic signatures  . Automated entity recognizers can be used to ( : lassify unknown entities into their appropriate SENSUS concept nodes  . 
We are also investigating other approaches to at tto-matieally learn signature term relations  . The idea mentioned in this paper is just a starting point  . 
'7 Conclusion
In this paI ) erwel ) resented at ) rocedure to automati- ( : ally acquire topic signatures and valuated the eflk ~ c-tiveness of applying to l  ) i ( : signatures to extract ot ) i ( : relevant senten ( : es against two other methods . The tot ) ie signature method out t ) erforms the baseline and the tfidf methods for all test topics  . Topic signatures cannot only recognize related terms  ( topic identifi- ( : ation )  , but grout ) related terms to get lm runder one target concept ( topic interpretation )  . ' IbI ) i ( : identification and interpretation are two essential steps in a typical automated text summarization system as wel  ) resent in Section 3 . 
'\])) pic : signatures (: an also been vie . we d as an inverse process of query expansion . Query expansion in tends to alleviate the word mismatch ln ' oblenlin infornmtion retrieval  , since documents are normally written in different vocabulary  , t to w to att to mati- ( ally identify highly e ( n related terms and use them to improve information retrieval performance has been a main research issue since late  19611's   . Recent advances in the query expansion ( Xu and Croft ,  1996 ) can also shed some light on the creation of topic signatures  . Although we focus the ltse of topic signatures to aid text summarization i this paper  , we plan to explore the possibility of applying topic signatures to perform query expansion in the future  . 
The results reported are encouraging enough to allow us to contimm with topic signatures as the ve-hMe for a first approximation to worht knowledge  . 
We are now busy creating a largen mnber of sign a -ture  . s to overcome the world knowledge acquisition problem and use them in topic interpretation  . 
8 Acknowledgements
Y Vethank the anonymous reviewers for very use -tiff suggestions  . This work is supported in part by
DARPA contract N66001-97-9538.

Eneko . ~ girre , Olatz Ansa , Edum'd Hovy , and David Martinez .  2000 . Enriching very large ontologies using the www . In Proceedings of the Work , , ; hop on Ontology Construction of the European Con -fl:rencc of AI  ( ECAI )  . 
Kenneth Church and Patrick Hanks .  1990 . Word association IIO rll lS , mutual information and lexicography . In Proceedings of the 28th Annual Meeting of the Association for Computational Lingui  . vtic . ~"(, 4CL-90), pages 76~-83 . 
Thomas Cover and Joy A . Thomas .  1991 . Elcment . ~ of Information Theory . .John Wiley & Sons . 
Gerald DeJong .  1982 . An overview of the FRUMP system . In ~2 mdyG . Lehnert and Martin H . 
Ringle , editors , Strategies for natural language processing , pages 149-76 . Lawrence Erlbaum A . s-so(lares . 
Ted Dunning .  1993 . A ~ i : eurate methods for the statistics of surprise and coincidence  . Computational Li'nguistics , 19:61--7'4 . 
Marti Itearst .  1997 . TextTiling : Segmenting text into nmlti-l ) aragraph subtopic passages . Computational Linguistics , 23:33-64 . 
Eduard Hovy and Chin-Yew Lin .  1999 . Automated text summarization i SUMMAIRIST . In Inder-jeer Mani and Mark T . Maybury , editors , Advances in Automatic 71 xxt Summarization , chapter 8 , pages 8194 . MIT Press . 
Kevin Knight and Steve K . Luk .  1994 . Building a large knowledge base for machine translation  , ht Proceedings of the Eleventh National Coy@re ' nee on Arti\]icial Intelligence  ( AAAI-9/~ )  . 
500 -~  . .~:, . ,  . ;~ ,5 .  " ' - -=-" _ . . _  .   . & ass050000n ~ . ~  .   .   .   .   .   .   .   .   .   .   .   .   .   . n  ~ .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  ~  .   .   .   .   .   .   .   .   .   . 
- - ' -  . , , q , ~ .   .   .   .  + + . , x . o + ~? .   .   .   .   .  1,* '+  . ~ *+-  .   .   .   .  - - .   .  ; -5; , :~:;  .   .   .   . h  ~ . :~ . 7~ . ~ ~ ~ ^' - -~-  .   . 
.  .   .   .   .   .   .   . , ?-- g2 .   .   .   .   .   .   .   .   .   . o400OOf , '"+-~-"+~-,"~2x-+,\[? .   .   .   .  :  .   .   .   .   .   .   .  : \[ -  . . . . . . ; ""7  . . . . . . . . 2,=_ ~ 0 =0000 j ' + J " J j 1" " . , : : i'ff "4 . 4" A- . I-i + ~ .  : 4"  . , ~ t . -a+-a---# .  -  .  -~-- -  . a ~' . 
0 ~ o00 o'd-;9~7~-7'+5~:7~:=-+':; : ~ .   .   .   .  =-~++:7:: ~ -:'~ +--~  . . . . . . . " ~5_~Ztt::~:ll ;:; iI",; . A '/,-?~-< F"~ . "" ~" ~25744" ? o ; oo ~ . _~- . c_-__~/000000
I000005010015020025030 , 3 35   040   045   050   055   060   065   070   o75   050   085   090   095   ~00   . ~ um rn~i - ~ Len qth Figure 2: F-measur(:w; . summary length for all fimr topics . ~ bi ) ic signature cl ( mrly outperforint fidf and baselin ( ' , ex ( :ei ) t for t i t ( : case of topic 258 where t ) (~rforman ( : (  ; for timth r ( ; emethods are roughly equal . 
I__I - - - - - - ~ ~ g-lO % I___~o ~ a-a o ~ ~ a - - -  -   4o ~ I ~0%- -\[~ o ~\[ ~ , o ~ ~ o % I9o ~ Il OO % I\[~ . +,_~ . , ~ dl . . . . i .   . : mso . a-~9 Io . .~ . oo . aa4o . , ~: c-I . . . ao=,\['__2:~r'I~o . araoar , ; I .   . at , , I e . a . ~ w-I+4 . 58 +7 . 48 +15 . 6 a+14 . 17 +8 . 66 +3 . I51_toplc . si~I-2, 7d-2 . 19--\[257-h , ,*,, li . . . . r --- (1 . 1-98 ~ . 15 . __ . 5 Ic , , , , , . is . , " . ' ~ LIo . , ~~--F--,~ . ~,, I--ot , lo . 1 ~ , I ? . !s ~\['_, . ~ r_,a ,, r\[-55 . 11- -38 . 56I -'" . 5U ~"> ' ~" . 0' ; ''"'+' IS'~:''I ~ ~"" I+r0'~t .   .   .   .   . , 257_, ~ i , ic . ~ ig + 45 . 5~ +64 . 06 +31 . 88 ~ +20 . 40 \[ +20 . 60 \[ 4_-~01 +12 . 4&-I14 . 24-O . ( h . ~\]\[_25 u_h ~, ~ . , li .   .   .   . L_olt k_o270I"'4'-'2~'*'~:~I , , ~ , r_ , L_"47 t_J . 4r , , 1--~-'1 o . ~,'__,+~os'_,Z . _J\[271_l , aseli .   .   .   . I <, attT_ . ._,~ . :,, ~; T --, Ta 77 - - - . . a :~ _L ,, : s:,r , . L . . . . ~~~~:~- i ~- T - o . ae ~\],) .  :~:~~\[--~  .   .   .   .   .   .   . + a ~ . lOj__+4~_~~s . ro .  ~ +~ . a , ~ I + ~ . ~ o_ll0 . , ~,\] Table 3: F . .measul'e t ) erformanc ( ~ differen ( : e compared to 1 ) asel in ( ~ nt ( : thodint ) ercentage . Cohmms indicate at diffe . rent summary lengths related to fldl length docum ( mts . Values in the 1) ase lin ( , . rows are Fmeasures (: or es . Vahms in the tfidf and to t ) i ( : signatur ( ~ rows arc i ) (' . r formml c ( ~ increase or ( h, . crease divide ( l by their (: or r ( . ,sI ) ontling baseline scores and shown in I ) er ( : ( mtag ( ! . 
Inderje(?t Mani , David House , Gary K Mn , Lyn(~tt(~ttirschman , Leo () brst , Thdr 6se Firmin , Micha(d
Chrzanowski , and Beth Sundheim . 1998.
The TIPSTERSUMMACt~xlsmmnm'iza-tion evaluation final r  ( :t ) or t . % ~(: hnical I/, ol ) or l;
MTR98W0000138, The MITRE Corporation.
Christopher Manning and Hinrich Schiitzc . 1999.
t'm datious of Statistical Natural Language Pro ~ cessi'ng  . MIT Press . 
Kathh ~( mM(:K (! own and l ) rag(mfirR . Iladev .  1999 . 
(' TO . II(rat , illg Sllllll ; ll'i(:s of Iltlllt , i\[)l\[~ll(!~vs articles . 
In hMtu . iet ~ tMani and Mark T . Maybury , edit , ors , Admm . cesi'nAutomatic TextSv, . mmarization , chapter 24, pagc+s 381:/89 . MiT Press . 
Ellen Riloff and Jeffrey Lorenzen .  1999 . Ext:raction-t ) a : ; e , d text cate I , dorization : Generating donmin-qm citic role relationships atttonmtically  . In Tomek Strzalkowski , editor , Natural Language Information , Retrieval . Kluwer Academic Publish c , r . q . 
Ellent lilolf .  1996 . An ompirical study of automated dictionary construction for information extraction in three domains  . Artificial Intelligence , Journal , 85, August . 
SAIC .  1998 . Introduction to information extraction . 

Jinxi Xu and W . Bruc (! Croft .  1996 . Query ex-pal > ion using local and gh ) baldocument analysis . 
Inl'rocee . dings of the 17th Annual Inter'national A ( JM SIGIR Co't@rence . on Research and Development in Information let ' rieval  , pages 4-11 . 
50I
