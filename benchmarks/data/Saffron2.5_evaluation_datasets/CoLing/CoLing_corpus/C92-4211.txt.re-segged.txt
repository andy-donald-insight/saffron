KNOWLED GEACQUISITION ANDCHINES EPARSING BASED
ONCORPUS
Yuan Chunfa , Huaug Chaugning and Pan Shimei
Dept . of Computer Science
Tsinghua University , Beijing , China
Fax : 861-256-2768

In Natural Language Processing ( NLP ) , one key problem is how to design a robust and effective parsing system  . In this paper , we will introduce a corpm-based Chinese parsing system  . Our efforts are coucetrated on : ( 1 ) knowledge acquisition and representation ; and (2) the parsing scheme . The knowledge of this system is principally extracted from analyzed corpus  , others are a few grammatical principles , i . e . 
the four axioms of the Dependency Grammar ( DG ) . In addition , we also propose the fifth axiom of DG to support he parsing of Chinese sentences  . 
1. Introduction
The traditional approaches of natural anguage parsing are based on rewriting rules  . We know that when the number of rules have already increased to a certain level  , the performance of parsing will be improved little by increasing the number of rules further  . So using corpus-based approach , i . e . extracting linguistic knowledge with t'megrain size from corpus directly to support natural language parsing is more impressive  . 
In this paper we will introduce the work on Knowledge acquisition and Chinese parsing based on corpus  . Our work includeds : ? Takeout a total of 500 sentences from geography text book of middle school to form a small Chinese corpus  . 
? Because Dependency Grammar ( DG ) directly describes the functional relations between words  , and s dependency tree has not any nonterminal nodes  , DG is suitable for our Corpus-Bused Chinese Parser  ( CBCP ) particularly . We marked the dependency relations of every sentence in our corpus manually  . 
? Input the analyzed corpus into the computer and for mumatrix f'de for every sentence in the corpus  . 
? Extract he knowledge from the matrix f'de and for maknowledge base  . 
? Implement the CBCP system for parsing input sentences and assigning dependency trees to them  . 
2 . Construction of the knowledge base ( I ) Thl . project is supported by National Science Fundation of China under grant No  . 6 9073063 AcrEs DECOLING-92 , NA rerES , 2328 AOL-r 19921300 Proc . OFCOLING-92, NANTES , AUG .  2328 , 1992 At first , we marked the dependency relations of every sentences in our corpus manua Uy  . 
An example of analyzed sentence i .s as follows :

DET ACDEATRA/ADVA ~ OBJ ( each )   ( river )   ( of )   ( middle and low reaches )   ( mostly )   ( ate )   ( flat lands ) Most of the middle and low reaches of each river are fiatlauds  . 
Fig 2.1
Here : DETA ( DE Terminntive Adjunct ) , CDE ( Complement of ~( DE )') , ATRA(ATtRibuteAdjunct ) , SUBJ(SUBJeet) , ADVA ( ADVerhial Adjunct) , OBJ(OBJect) . 
Then we run a program to input the dependency relations of every sentence to the computer and form a matrix file as bellow : M  ( 0 1 ) = DETAM ( 1 2 ) : CDEM ( 2 3 ) = ATRAM ( 3 5 ) ~SUBJ
M(45) = ADVAM (65) = ORJ
In order to expound the knowledge representation , we give some definitions as below . If there are four words w l , w2 , w3 and w4 with dependency relations RI , R2 and R3:
RIR2 R3
Fig 2.2
Then for the word ~ w3" , its d-relation LsR2 ; its g-relatinn is R1 ; and its s-relation is R3 . 
We extrac the knowledge from the matrix file to form a frame as below : word-name : :=\[ < govfreq >  , < govlLst > , < linklLst > , <: patlLst >\]
The slots of the frame are : governor frequency ( gov freq ) : It indicates that wltether the given word can be a governor of a sentence and how many times it has been in our corpus  . 
governor list ( gov lLst ) : It indicates which word can be the parent node of th c given word  , and what is the dependency relation between the word and its parent node  . In other words , what is the word's d-relation and how many times it has occurred in the corpus  , i . e . 
gov list ::=\[< governor-name>\[<d-relation :>  , < frcqncncy >\]**\] dependency link list 0inkli~t   ) : The d-relation and g-reintion of the given words can form a pair of relations described as d-relat ion <  .   .   .   . ~- relatiou . The information on iink list includes : how many kinds of dependency links the given word have in our corpus ? And what are they ? how many times it has occurred ? what Ls the position of the word's parent node  ( to the right or to the left of the word ) i a a sentence ? i . e . 
Attir Es DECOLING-92 , NAtCrEs , 2328 AOtI1992l301 PROC . OFCOL , ING-92 . NAtCr ~ S , Ann .  2328 ,   1992 llnklist : :=\[< d-relatinn>\[<g-relation  >  , < position > , < frequency >\]** I pattern list ( patlist ) : The given word and its s-relations constitute a pattern of the word as:  ( s-relation 1 s - - relation 2 s-relation 3 . . . ) . This pattren information describes the rationality of the syntactic structure in a dependency tree  . The pat list knowledg extracted from the corpus includes : how many patterns can the word act in our corpus ? What is each pattern ? how many times has it occurred ? What Ls the position  ( to the right or left of the word ) of the children node in a sentence in our corpus ? i  . e . 
patlist : :=\[\[ pattern\[<frequency > , \[< s-relation > , < posit in n >\]*\]\]*\] ( notes : the content inside the "*" can be repeated n times  , where n > 1) 3 . The parser In our CBCP system , the knowledge base will first be searched for all the possible link list information of each word pair  , according to the words in the input sentence . We use this information to construct a Specific Matrix of the Sentence  ( SMS )  . Sccond , remove impossible links in the SMS , and form a network . Third , we search all the possible depcndcncy trees in the network  , using the pruning algorithm . Finally , the solutions will be selected by evaluating the dependency trees  . The process of removing and pruning is based on the knowledge base and the four axioms of Dependency Grammar  ( Robinson , J . J . 1970) . The four axioms are : I . There is only one independent element ( governor ) in a sentence . 
\]\] . Other elements must directly depend on one certain clement in the sentence  . 
l\[I . There should not be any element which depends on two or more elememts  . 
IV . If the element A directly depends on element B , and clement C is located between A and B in a sentence  , element C must be either directly dependent on A or Boran element which is between A and B in the sentence  . 
According to our Dcpend cncy Grammar practice in Chinese  , we populate the fifth axiom as follows : V . There is no direct dependent relation between two elements which one is on the lefthand side and the other is on the right hand side of a governor  . 
3 . 1 Comtruet a specifieal matrix of a sentence Suppose there are k words in a sentence marked as S =  ( wlw2w3 . . . wi . . . wk ) , CBCP searches the link list information of every word in the sentence  . For example , ff one link of w i is ATRA <---- OBJ , and the link of wj is OBJ <---- GOV ( GO Vernor ) in the knowledge base , CBCP can construct the link between wi and wj as ATRA < - - - OBJ  . The SMS will be constructed by searching all the links of words in the input sentence  . 
3 . 2 Remove impossible governors and links Since an input sentence may form a large number of dependency trees based on the SMS  , it is necessary to remove the impossible links before connecting every node to a network  . Suppose in a SMS , the word A is dependent on the word B and the link between them is ACIF ~ DE  COLING-92  , N^r zff~s , 2328^o ( rr 19921302l )) ~ oc . OFCOL1NG-92, NANTES , AUG . 2328, 1992 Ra < -- Rb . If there exists a ( RIR2 . . . Ra . . . Rk ) in B's pat list , the dependent relation of Ra <-- Rb is reasonable  . Otherwise , the Ra<--Rb relation is impossible , and should be removcdo The CBCP system looks for the gov freq information of each word in an Input sentence  . If the gov freq of a word is greater than zero , the word can be a governor . The rules of removing impossible governors arc : ? If a word has no parent node in SMS  , the word must be the governor ( based on axiom ~\[ )  . Other words which can also act as a governor must be removed  . 
? If a word A has only one rink to word B with the link Ra < -- GOV  , and the word B cannot heagover nor , the word A will not depend on any word in the dependency tree ? According to axiom I \] this is impossible  , therefore word Bmus the the governor . Other words which also can act as a governor must be removed  . 
? When n word A has only one link to word B with the link Ra <-- Rb  ( Rb <> GOV )   , and the d-relatinn of the word B is not Rb , the word A will not depend on any words in the dependency tree  . According to axiom \]\] this is impossible . So the d-r clatinu of the wordB must not be the governor  . Then this kind of link in which the word B is used as a governor must he ~ mov cd  . After removing all the impossible governors and links  , the SMS of the sentence in
Fig 2. i is as follows:
M ( 0 1 ) ~ DETA < -- CDEM ( 0 5 ) = ADVA < -- GOVM ( I 2 ) = CDE<--ATRAM ( I3 ) = ATRA < -- SUBJ'M ( I5 ) = SUBJ < ~- GOVM ( 2 3 ) = ATRA < -- SUBJM ( 3 5 ) ~SUBJ < -- GOVM ( 4 5 ) = ADVA < -- GOVM ( 6 5 ) = OBJ <---GOV 3?3 Search the possible integrated tree from the specific tree Let the governor be the root node  , connecting nil the nodes in order . If a node have n(n > 1) parent nodes , we can sprit this node to nsame nodes . Let the sensame nodes depend on then parent nodes respectirely  . Thus Specific Tree ( ST ) will be constructed . The ST of the sentence in Fig-2 . 1Ls as bellow:
ADVA--~fr w0
UBJ - ~ - - ~. 4n ' ~ j " wl ATRA
Gov Isu . Jy - - - - ~ wlwS~t\[l ' ~ . ~ w3,~ATRA . , CDE DETA w2- - - - -~ wl 

A(zrf , sDECOLING-92, NANTEs . 2328^o (; r19921303 PROC . of : COLING-92, NANTES , At ; 6 . 23-28 , 1992 If a node appears m times in the ST , we may say the degree of freedom of this node is 2 m . If there is only one word , whose ~ equal atom in a ST , then m dependency trees may be constructed . If the degree of freedom of the word-i equals to n  , the degree of freedom of the word-j equals to m then the n*m dependency trees will be constructed  . If there are many words with ~ greater than one , the number of dependency trees being formed will be very large  . 
Therefore , in the process of seaching an integrated ependency tree  , the pruning technology must be taken . The pruning technology derives from axiom V . 
After the integrated dependency trees have been produced  , we use the numerical evaluation to produce the parsing result  \[1\]  . 
4. Experimental result and future work
When CBCP analyzed Chinese sentences in a closed corpus  , it has an approximately 90% success rate ( comparing with the result of manual parsing )  . If each word in a sentence can be found in our corpus and the corresponding dependence rlation can also be found in our know-tcdgebase  , it is also feasible for CBCP to perform syntactic parsing in an open corpus  . 
As our research is advancing , we will enlarge the scale of our corpus and make it work on open corpus more effectively  . On the other hand , we have great interests in how to retrieve more information from different aspects  . For example , we want to acquire grammatical category information and semantic features for our system or equip complex feature set for each word to support corpus-based as well as rule-based system  . We want to add a few rules to our system , in order to replace the frames of the words which frequently appear in our corpus  . The frame of such a word is very large , but it is easy to describe its dependency relations by rules  . 
We plan to do furthere search in this field.
In addition , our work can be easily expanded to set up a Chinese Collocation Dictionary  . 
It is very difficult to make this kind of dictionary by man power  , beacuase it is impossible to seek all the possible collocations of a particular word just by thinking  . But it is easy to achieve this with corpus-based approach like our work  . The more refined analyzing of the texts in the corpus  , the more knowledge can be acquired from the corpus  . 
References 1\] van Zuillco , Job M .   ( 1990 ) : ~ Notes on a Probabilistic Parsing Experiment ' . 
BSO/Language Systems , Utrecht , The Netherlands . 
\[2\]van Zuljlcn , Job M . (1989 ) : " The Application of Simulated Annealing in Dependency Grammar Parsing '  . BSO/Language Systems , Utrecht , The Netherlands . 
\[3\]\]~l ~'-~(1991): ((4 , ' ~ t\[t ~'-~ i ~ SO) , ~~ t  ~ . _~ . .
I41~,~(1987):((~o ~,~? ~ R~?.
ACTESDECOLING-92, NANFES . 2328 hOt':I'19921304 PROC . Ol : COIANG-92 . NANTES , AUG .  2328 .  1992
