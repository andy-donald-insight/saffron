Processing Homonyms in the Kana-to-Kanji Conversion 
Masahito Takahashi
Fukuoka University
8-19-1, Nanakuma,
Jonan-ku , Fukuoka,
814-01, Japan
taka has i@helio.tl.
fukuoka-u.ac.jp
Tsuyoshi Shinchu
Fukuoka University
8-19-1, Nanakulna,
aonan-ku , Fukuoka,
814-01, Japan


Kenji Yoshimura
Fukuoka University
8-19-1, Nanakuma,
Jonan-ku , Fukuoka,
814-01, Jal ) an
yosilnura < ? ~ tlsun , tl.
fukuoka-u.ac.jp
Kosho Shudo
Fukuoka University
8-19-1, Nanakuma,
Jonan-ku , Fukuoka,
814-01, Jut ) an
shudo(~tl sun.tl.


This paper I ) roI ) oses two new meth-
ods to identify the correct meaning of
Japanese honmnyms in text based on tile iloun : verb co-occ I lrrenc  (  ~ , illa sentence which ( : an be obtained easily from corpora . The first method uses the near cooccurrence data sets  , which are constructed from the above ( : o-occurrence relation , to select the most fe~Lsible word among homonyms in the s  ( :ol ) e of a sea > tence . Tilese ( : ond uses the flu'co occurrence datasets , which are con-strutted dynamically fl'om the near cooccurrence datasets in the course of processing input sentences  , to select the most feasible word among homonyms ill thes  ( : ope of a sequence of sentences . An experiment of kana-to-kanfi ( phonogran > to-ideograph ) conversion has shown that the conversion is carried out at the accuracy rate of  79  . 6% per word by the first method . This accuracy rate of our method is 7 . 4% higher than that of the ordinary method based on the word occurrence frequency  . 
1 Introduction
Processing hontonyn Ls , i . e . identifying the correct meaning of homonyms in text  , is one of the most important phases of kana-to -kanji conversion  , currently the most popular method for in t ) utting Japanese characters into a computer . Recently , sever Mnew methods fi ) r processing homonyms , based on neural networks ( Kol ) ayashi , 1992 ) or tile cooccurrence relation of words ( Yamamot< )  , 1992)  , have been proposed . These methods apl ) ly to the cooccurrence relation of words not only in a sentence but also illa sequence of sentell C  ( ~s . 
It appears impra <: ticat ) let oprepare a neural network for co-oe curren ( : ed at a large enough to handle 50 , 000 to 100 , 000 Japanese words . 
In this 1) aper , we propose two uew methods for processing Japanese homonyms based on the  ( : o-occurrence relation between a noun and a verb illa sentence  . We have defined two cooccurrence datasets . One is a set of nouns ~ companied by a case marking particle  , e ~: h element of which has a set of cooccurring w ~ rbs in a sentence  . The other is a set of verbs accompanied by a case marking part Me  , each element of which has a set of cooccurring nouns in a sentence  . We ( : all the set v~oco-occllrrence datasets near cooccurrence datasets  . Thereafter , we apply the datasets to the 1 ) ro < : essing of holuonylns . Two strategies are used to al>l ) roach the problem . The first uses the near cooccurrence datasets to select the most feasible word among homonyms in the scope of a sentence  . 
The aim is to evaluate the possible existen <- e of a near cooccurrence relation  , or cooccurrence re-lation betweeu a noun and a verb within a sentence  . These condewfluates the possibh'existence of a far cooccurrence relation  , referring to a cooccurrence relation among words in different sentences  . This is achieved by constructing fitr cooccurrence datasets from near cooccurrence datasets in the course of processing input sentences  . 
2 Cooccurrence datasets
The near cooccurrence datasets are ( lefined.
The first near cooccurrence dataset is the set EN  . . . . . . . . each element of which ( n ) is a triplet consisting of a noun , a case marking part Me , and a set of w ~ r l ) s which cooccur with that noun and l ) art Mepair in a sentence , as follows : n = ( noun , particle , ( Vl , kl ) , ( v2 ,  ~;2) , "") Ill this description , particle is a Japanese case marking particle , such as 7)'-'; ( nominative case ) , ( ac(:usative case ) , or tC(dative case ) , vi(i = 1 , 2  ,   .   . -) is a verb , and ki(i - - - - 1, 2, .   .   .   ) is the frequency of occurren ( : e of the combination noun , particle and vl , which is del ; ermined in the course of constructing EN . . . . . . fi'om corpora . The following are examl ) les of the elements of EN . . . . . .  . 
( g\[~(rain ) , 7) ~( nominative case) , ( ~7~( fall ) , 10) , ( lk~2 e(stop ) , 3)  ,   .   . )( ~( rain ) , ~( accusative case ) , ( ~ JT~-~Xa(take precautions ) , 3) ,   .   . ) set By, . . . . . . each element of which ( v ) is a triplet consisting of a verb , a case marking part Me , and a set of nouns which cooccur with that verb and particle pair in a sentence  , as follows : v = ( verb , particle , ( nt , ll ) , ( n2 , 12) , "'") In this description , particle is a Japanese case marking particle , ni ( i = 1 , 2 ,   .   .   . ) is a noun , and li(i:1 , 2  ,  " " ) is the frequency of occurrence of the combination verb  , particle and hi . The following are examples of the elements of Ev ,   . . . . .   . Ev , ~, ~, . 
can be constructed fi'omE ~ . . . . . , and vice versa . 
( Yo ( fall ) , 7 ~( nominative case ) , ( ~\] ~( rain ) , 10)  , (~( snow ) , 8)  ,   .   . )(~( fall ) , C(dative case ) , ( JIL'J'\]'\](Kyushu ) ,  1) ,   .   . )  3 Processing homonyms in a simple sentence Using the near co-occurr cncc dataset  . s , the most feasible word among possible homonynls can  1  ) eselected within the scope of a sentence . Our hypothesis tates that the most feasible noun o1' combination of nouns has the largest nuln ber of verbs with which it can cooccurill a sentence  . 
The structure of an input Japanese sentence written in kana-characters can be simplified as follows : N ~  . P ~, N2 . P = , .   .   . , N , , , . p , , , , v where N i ( i = 1, 2, .   .   . , m ) is a noun , l'i ( i = 1, 2, .   .   . , m ) is a particle and V is a verb . 
3.1 Procedure
Following is the procedure for finding the most feasible combination of words for an input kana -string which has the above simplified Japanese sentence structure  . This procedure can also accept an input kana -string which does not include a final position verb  . 
SteplLet m = 0 and Ti = e(i = 1, 2, ...).
Step 2If an input kana-string is null , go to Step 4 . 
Otherwise read one block of kana-string , that is N ? P or V , fi ' omtile left side of the input kana-string . And delete the one block of kana-string fi'om the left side of the inlmt kana-string  . 
Step 3 Find all homonyinic ka , q/-variants Wk(k = 1 , 2 ,   .   .   .   ) fortile kana-string NorV which is read in Step2  . 
Increasem by 1.
For each Wk(k = 1, 2, .   .   . ) : 1 . If W ~ is a noun , retrieve ( W  ~ , P , V  ~ , ) from tile near cooccurrence data , set ~ N .   .   .   .   .   .   . 
and add the double t(W ~, V ~) to T , ~.
2 . If W ~ is a verb , add the double t(w ~ , ( w  ~ , 0)) to T , , ,  . 
Go to Step 2.
Step 4 From Ti ( i = 1, 2, .   .   . , m ), find the combination : ( W l , V i ) ( W ~ , V . 2), . -', ( Win , Vm ) ( w , ~) ~ T ~( i = 1, 2, .   .   . , ,, ~) which has the largest value of IN(v , , v . ~, . . . , < , , ) I . Where the function f-\](v ,, v2, .   .   . , v , , , ) is deiilled as Mlows . 
('\] ( Vl , v . ~, . . . , v . D = ( v,y ~ . k ~) I i=1 (~, k , ) ev , A .   .   . A(v , k , , , ) cv , , , And\]\["1(1/1, Vx, . . . , V , , <) i is defined:
IN(vl , v . ~, . . . , v , , , ) I--~k ( ~ . k ) 6 n(v , , v . 2  . . . . . vm ) The sequence of words WI , W2, .   .   .   , W , ~ is the most feasible conibination of homonymic ka'aji-w  , riants for tile in i ) ut kana-string . 
3 . 2 An example of p rocess ing homonyms in a s imple sentence Following is an example of homonynl processing nsiug the abow  , , procedures . 
For the input kana-string " 7 ~ a ~ C_l ~ b , ~ e(kawani hashio)""D~(~a . ~a ) " means ariw ' . rdud < ' ~ b(ha~h0"nleans abridge . "\]0 ~ ( kawa ) " and " ~1_ ,   ( hashi ) " both have honionyn iick anji-variants : holl lonynls of  "7~a  ~\] "  )   ( \] gawa ) " :  ) \[\]  ( river )   ) 59 .   ( leather ) honlouy uls of "' k'\[1~ ( hashi ) " : ~  ( bridge )  ~  ( chopsticks ) The near cooccurrence data for " ) i l ( river ) " and " ~ ( leather ) " followed by the particle " ~:- ( dative case ) " and tile near cooccurrence data for " ~ ( 1 , ridge ) " and " . ~  ( chopsticks ) " followed by tile t ) article " ~ ( accusative case ) " are shown below . 
() ll ( river ) , C , (-~<( go ) , 8 )  , (~-~70 ( build ) , 6 )  , ('\] ~: J-(drop) , 5)) (~( leather) , ~Y - , (" ~ Xa(paint ) , 6 )  , ( ~\] ~7 o ( touch) , 3)) (~( bridge ) ,  "~ , ( ~7 o ( walk across ) , 9 )  , ( ~( build ) , 7) , (' ~ j-(drop) , 4)) (~( chopsticks ) ,  ~  , ( ~( use ) , 7) , (' ~ J -( drop) , 3)) Following tile procedure , the . resultant frequency values are as follows : ) i l ~ c ~8 i ~9-~-~0 Therefore , then lost feasible combination of words is ") , l(river ) :-~( bridge ) ~ . " homonyms in a simple senten (: e4 . 1 Prepar ing a d ic t ionary and a cooccurrence data file  4  . 1 . 1 a noun file A noun file in <: luding 323 nOUllS , whi(:h consists oi " 190 nouns extra . l-ted front text concerning ( : urrent topics ~ til ( their 133 holnolly lns , was pret ) ~ m'd . 
4 . 1 . 2 a cooccurrence data file i ( : o-occurrence ( l  ~ (  ; ;~ ill (' , was l ) repa . r (' d . The record format of the file is specitied as folh  ) ws:\[I1 ( )1111 , C~:K'-le marking1) ~ Lrticle , verl ) , tlw frequency of occurrence \] wher ( ; case marking t ) ~trti ( : leis ( : hosen from 8 kinds of particles , i ~ mlely ,  "7)~" , " ~"  , " ~"  ,  "~'-"  , " &"  , " 7) ~ 5" , " J : .  9","'~" . 
It includes 25,665 re . cords of co-o (: curr(mcere-l~d ; ion (79 records per noun ) for ( ; he nouns in the noll Il file by inerging 11 , 294 re ( : ords fron ~ EDRCo-o ( : ( : urrence Di ( :tionary ( EDR . ,1994) with 15 , 856 records from handmades im I ) le sentences . 
4 . 1 . 3 an i nput f i le and an answer f i le An intmt fileform lexl  ) erilnent , whi(:hin(:hules1 , 1 . 29 silnple sentences written in k s ' as a . ll ) haJ ) et , and an ~ ms wertile , which includes the same 1 , 129 sentences written in kanji (: hzL ra(:l;ers , were l ) re-pared , ilere , every noun of these l~ten ( : es in the files was chosen fl'om then OUl~file . 
4.1.4 a word dictionary
A word dictionary , which consists of 323 lmuns in the llOUll file ; tlld 23 , 912 verbs in a ,   , \] at ) a Jlese dictionary for kana-to-kanfi conversion ' , w~Lsl ) re-1) ~ r(~(1 . It is use (1 to find all honmnymi(:ka , nji-varim d ; s for each noun or verb of the Sellt ( Hices in the input lilt . 
4.2 Experiment results
An exl ) eriment on processing homonylns in at sim-1 ) le sentence was carried out . In this experiment , kana-to-kanji conversion was N ) plied to e . ach of tim sentences , or the inlmt kana-striugs , ill the al ) oveinput file ~ md the ' neareo-occ wrrc'ace data sets wer  ( ' . (: onstrlt(:t ; ed froll ~ I ; he ~ d ) oveco-o (: currence ( la . t ; till ( . ' . Tal ) lel shows the resul ( , sofkana-to-ka'aji ( : on version in the f of h ) wing two cases , intile first(n~s e , ~ LIIinl ) utks , us-string does not include ~ L fired position ver \]  )  . ItlIl(~a . llSI ; haJ ; each verl ) of the kana . .strings ill the input file ix neglecte(l . In the s(~, COll(l CILS e , a . lltill ) Ill . \] go , '// , a-string includes a final position verb . The (' . xl ) eri-Ill ( Jilth ; tsshowlltfia ? the (: onversiouix carried Olll ; ~ t the accura . (: yra . te of 79 . 6% per word , wher(~the('onversion r~teis 93 . 1% per word , in the first ~ This dictionary was m ~ Me by A1 Soft ; Co . 
(:a . s e . \[ n the stone way , the a (: curacy rate is 93 . 8% 1) (' r word , where the conversion r ~ Lte is 14 . 5% perword , intiles e(: ond (: a . s e . And then , we . ~ flso ( : on- ( lu ( : ted the sCL me experiment by using the method 1 ) ase ( lonthe . word oc ( : un'ence frequency to ( : om-1 ) ~m  ~ ouriue (  ; hod with a nor ( lin ~ ryinethod . It has show u that the accuracy rate is 72 . 2% per word in the tirst case , ~ md 77 . 8% per wo M in the sec-on ( l (: ~ Lse . We(:a , nlindtileac(:ur;~cyr;LteI ) yourmet ; ho(lis7 . 4% higher it , the first case ~ md 16 . 9% higher ill these colM case ( ' oml ) ~ u'ed with the or- ( lilmrym ( ~ thod , it is clarified th ~ Lt our method is lnore et lective than the ordim Lry method based on the word O  ( ' Clll'rel H: ( * . fre(l/tell cy . 
5 An approximat ion of the far cooccurrence relation W  (  , (: ~ ma , 1) l ) roxilua ? etile farco-occ ' arrc , ncere-at'ion , which is ( : o-o ( :curren ( : e relation among words ill ~ L seqllellce of Sell t  ( ~ll ( zes , frolil ' li , C(l , ' Fco-occu ' rrc'nce datasets . The fivr cooccurrence datasets m'c descril ) ed~s follows : EN ,   . . . . =  (,,,,, t , ), (',,,~, t ~) , .   .   . , (', <, t, .  ) ~,5  . . . . = ~(~,, . , ' ,,), ( '~ , ' , ,~) ,  .   .   . , (<, ' a , ~) where ni ( i = 1, 2, .   .   .   ,  1 , ,) is a noun , ti is the 1) ri-orityw due of hi , vi(i = 1 ,  2  ,   .   .   .   , Iv ) is ~ tverb and ui is the priority w due of vi . 
Thel ) ro ( : ( ~ ( lure for 1 ) roducing the fiwco-oceur re'n , c (' , data . sets is : Step lClem : the fa , ' rco-oceu'r'rcnce data . sets . 
E ~ #.... = e
Step 2 Aftere ~ tch fixing of noun N , mmnghomonyms in tim process of ka'ua-to-kanji conver-sioll  , rClll:W the fivr co-occu ' rrencc data 8?; t , s2Nj . . . . ~ md Ev ~,, . by folh ) wing these steps : 1 .  (' , ha , lJ ge all priority values of ti ( i = 1 ,  ~ ,   .   .   . , t , , ) i , ~~ h ,, ~ t ~ , , , , . ~,, f(td(forexmnl)le,f(tl ) = 0 . 95 ti ) . This process is intended to de ( : rease priority with the 1 )  ; tss~tge of time . 
TM ) le1:Exl ) erinmnt results oi1 pl'o ( : essing homo-llylll Silla . silnl)h ~ SlHltellce,
Coll version r~t l , e1) erSel it ( ~ llC(~
Ac(:ur~t(:yra.te1)el:S(~lltellce
Conversion r~d ; el ) er word
A(:cura . (: yrzd ; el ) er word
For sell ( ; el Ices Forsent ellces without a verb with a verb 1053/1129   1661~9   ( 93 . 3%) (14 . 7%) 663/1053 1361~66 (63 . 0%) (81 . 9%) 215502315 500/3444 (93 . 1%) (14 . ~%) 1716/215 5469/~O (79 . 6%) (93 . 8%) 1, 2~,- . -, 1, ) in the set Evj , , , to f(ui ) as well . 
3 . Let N be the noun determined in the process of kana-to-kanji conversion  . 
Find M1k , )( i = 1, 2, .   .   .   , q ) which cooccur with the noun N followed by any particle  , in the near cooccurrence dataset EN . . . . .   . Add new elements ( v , g(k ,)) ( i = 1, 2, .   .   . , q ) to the set Evj , , , . If an element with the same verb vial ready exists in E vs ~  , , . , add the value g(k , ) to the priority vMue of that element instead of the new element  . 
Here , g(k , ) is a function for converting fl'equency of occurrence to priority value  . 
For example , g(ki ) = 1-(1/k ,) 4 . Let vi be the verb described in the previous step  . Findall(nj , lj ) ( j = 1, 2, .   .   .   , q ) which cooccur with the verb v , and any particle in the near cooccurrence data set P~v  . . . ~ . Add new elements ( nj , h(ki , lj )) ( j=1 , 2  ,   .   .   . , q ) to the set ENj . . . . If an element with the same noun nj already exists in Egs ~  , ~ ,   , add the value h(ki , lj ) to the priority value of that element instead of the new element  . Here , h(ki , lj ) is a flmction for converting frequency of occurrence to priority value  . For example , h(k , b ) = g(k , ) ( 1 -  ( 1/lj ) )  6 Processing homonyms in a sequence of sentences Using the Jarco occurrence datasets defined in the previous section  , the most feasible word among homonyms can be selected in the scope of a sequence of sentences according to the following two CaSeS  . 
Casel An input word written in t ~ a na-characters is a  1101111  . 
C ase2 An input word written in kaua-characters is a verb  . 
6.1 Procedure for easel
Stepl Find set Sn :
S ,= ( N , , Tt ), ( N2, T2), .   .   . where Ni(i:1, 2, .   .   .   ) is a homonyn ficl ~ a'nfi-variant for the input word written in kana-characters and T  , is the priority vMue for homonym N , , which can be retrieved from the Jar cooccurrence dataset EN id  ,  . .
Step 2 The noun Ni which has the greatest T , priority value in Snistile most feasible noun for the input word written in kana-chara ~ ters  . 
6.2 Procedure for case 2
Step 1 Find set S , : sv =
Here , Vj ( j = 1, 2, .   .   . ) is a homo , tymick anji-variant for the input word written in kana-characters and Uj is the priority value for homonym Vj  , which can be retrieved from the far cooccurrence dataset Evj  . . . .
Step 2The verb Iv ) which has the greatest Uj priority w flue in S , is the most feasible verb for the input word written in kana-characters  . 
7 Conclusion
We have proposed two new methods for processing Japanese homonyms based on the cooccurrence relation between a noun and a verb in a sentence which can l  ) e obtained easily from corpora . Using these in ethods , we canev Muate the cooccurrence relation of words in a simple sentence by using the near cooccurrence datasets obtained from corpora  . We can M so evaluate the cooccurrence rla-tion of words in different sentences by using the far cooccurrence datasets constructed from the near cooccurrence datasets in the course of process -iug input sentences  . The far cooccurrence datasets are based on the proposition that it is more practical to maintain a relatively  smM1 amount of data on the semantic relations between words  , being changed dynamically in the course of processing  , than to maintain a huge universal " thesaurus " database  , which does not appear to have been built successfldly  . 
An experiment of l ~ ana-to-kanji conversion by the first method for  1  , 1 29 input simple sentences has shown that the conversion is carried out in  93  . 1% per word and the accuracy rate is 79 . 6% per word . It is clarified that the first method is more effective than the ordinary method base ~ l on the word occurrence frequency  . 
In the next stage of our study , we intend to ewfluate the second method based on the  . far cooccurrence datasets by conducting experiments  . 
References
Kobayashi , T . , et al 1992 . Realization of Kana-to-Kanji Conversion Using Neural Networks  . Toshiba Review , Vol . 47, No . ll , pages 868-870, Japan . 
Yamamoto , K ., et al1992. Kana-to-Kanji
Conversion Using Cooccurrence Groups . Proc.
of 4\]~th Confi : reuce of IPSJ , 4 p-ll , pages 189-190 , 

EDR . 1994. Cooccurrence Dictionary Vet.2,
TR-043, Japan.

