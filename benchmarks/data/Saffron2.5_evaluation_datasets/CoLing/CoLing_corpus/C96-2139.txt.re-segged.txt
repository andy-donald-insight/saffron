Full-text processing : improving a practical NLP system 
based on surface information within the context
Tetsuya Nasukawa.
IBM Research Tokyo Resem~h Laborat 0ry
t623-14 , Shimotsurum ~ , Yimmt ; 0?sli;I < alm gawa < kbn 2421 , , J a imn
? nasukawa@t , rl:,vnet ;:: ibmicbm

Rich information f l ) r resolving ambigui-tiesm sentence ~ malysis ~ including vari-ous context- dependent  1  ) rol ) lems . can be ob-tained by analyzing a simple set of parsed ~ rces of each senten  ( ' e in a text with om constructing a predse model of the contex ~ tl  ( rough deep senmntic . an Mysis . Th . us . pro-text . Without constructing ai ) : recige filodel of the eoh text through , deep sema~nfiCamtly s~is , our frmne="work-refers . to a set ( ff:parsed trees .  ( . r ~ sltlt ~9 fsyn-:tacti ( " miaiys is ) of each sexitencd in t . li~;~i'extas(:on-textilf formation , Thus . our context model consists of parse ( f trees that are obtained 1 ) y using miexlst-il!gg?l wral syntactic parser  . Excel ) t for information ( ) It the sequence of senl ;  , en('es , ol Ir framework does nol consider any di scourses tru  ( : ~: urem w has the discourse cess mg a gloup of sentem  ( stoge the l makes ? , ! , ' " '  . ., '~,'  . i': . '?" segmenm , focus space stack , or dominant hierarclty it . ,p . ( , ) sst ? ! e . t . 9! ~ npl:ovel-t\]le ~ ccui'a ~' Y(?fa ::: . it ~ . ( . fi . ii~idin: . (cfi . 0 szufid , Sht/!er , dgs6)i . Tli6refbi . e , om <, ~~ ~ t . ehi-sii ~1" ~ g ; ~- ni ~ chin ?'' ti-mslatb~t '@~--" .   .   .   .   .   .   .   .   .   .   .  ":  .   .   .   .   .   .   .   .   .   .   . '?"" :' le,~- .  -  .   .   .   . t .  ; , -  .   .  :  . ;-  .   . ? ?  .  :  . . . . . . , ' , ; -  . preaches ' to-context pr0cessmg , , and . mtier-randat . 
tern Int hina(rwed , es(tib ~, a . , ~ in qfl 6? ~ .   .  '  . : " :  .   .   .   .  : : " " ' ' ~  .   .   .   .   .   .   .   .   . ?; ::' Li : i .   . j . ;' P' .   . p ) ~; . ! i: . %  . . i -!: .   .   .   .   .  ,  . . . .  . .-  . , . . '  .   . obtmnm ~ .   . ~:  . pei'iectaimly , ~ ls . Howevr ,: by9xtel~dc:co3!te ~/~ ~ . g0dc\[ . ~ . Ofi!si . ~ tiln g . - ef:p~fs . edt'Imcs . 6!- . :  . ~, . .,2, ' .   . in ~/ t , ii ~, . ~ifit . .of . tile . iJl : oces ~ i ~ / g6bji , bt . fr0ih'-0ne ' . smt ~: ~ tch ' ~: n~q ~ ce:: . in: . a . text , 4~a ? ~ fit ~'!, ~ ven ? ~ s :> L# . .:::' ti;iic ~ .  ~6  . r f i i f l t i i f l 6 s g i ~ t d l t ? : e s n : . ~k 0 if i ' e e , f , 6 X V x n d . by finh and hng various l ~ roblems mNLP such "- : " " " : ' ' ! ? " : ' " "   .   .   .   .  (' " "  ; using syntaciic information on all tl i e  0 the riwSr ( lsas the resolutien of stru ~: tural ambigui ties  , i . n the whole text . Snch , ~ snm difiee-modifie relation-p ronoun referents  , and the focus of focusing ships and their I ) ositions in the text . our framework subjuncts ( e . g . also and only ) , as well as improves the over M1 a e ( ' uraey of a natural language for ? adding SU l ) plemen:t ~ try phrases t . oseine pro('essing system . 
elli ) ti(alsen:fences . . " .  " " "  .   .  '  . . . . . . :  .   .   .   .   .   .   .   . 
<: . : ?-:-'2";",:-q . : '  .  < ;  .  :-  . :'~  . v : ' . .-::  . ' : :" .  ' . -::'' C " .   . : We , imp\]et ne ~ i . M this II : a mework : on : an Englisl ~- to-? ,  * " - ' "~ ' '<- " :~  .   .   .   .   .   .   .  ' .  " . ',' '  .  " " ,  .  " , " , ' , ' " - "  . cOnllith , erlllallu ~ tts .  ,  .  ? . tt . : xtood . ~, )  . ~, ?~ v . .  .   .   .   .  -  .   .   .   .   .   .   .   .   .   .   .  , -~:  . ' key , ' ~ . eclimot . ogy . for : . . mH)r . 0 y!ng"t lie . ac(;nra(:y?(ff,h~xt . -  . : : :  .  < :  .  : . ~G ,': .  ;  . : . :  . . ", - , . ;-' , : ' ;  . . . . .  ',' : : - : : - ; :';  . . . . : t : .   .   .   .   .   .   . " q ""' .  '  .  " '  .   .   .   .   .  '  .   .   .   .   .   .  " " , "  .   .   .   . "" mr Duiid : i ~/ lowledge . , t , hd . ( l ( , el > iltfo1'( , ll(e!n(~cllal)isi ~ ls , C'O'tt ' ~ X~-:~ ; : ~ l ' ;  ! :  ; ltet(:::~:~:1~ ;  \ ]~ ' : ~ ~ (  . 2;1\]I>!;;0'~y ~ . ~;" - ' " " "  .  , ' " "  . o ';'"'' eS ~ JiobSllInlng ? . '" s .  : 1~, , ' " , \ [ :  .   . ' ,< ; 7 . is true : . that . We . canm Waysnn . dex~mq ) l . , ' ot 1' .  -  .   .  :  .   .  '  . ~ x , , , , , ; , ' ?' .  " ;  .  ; (  .   .  ' " ,  . ' lems thai requir . ec6mmoil'sei,g~mM . ilff ? 4 rence ~ lnech . r:: .  , . "; u . ~ w~i ~: ~ d:h;na::P ;' . lYSo:::~lg . : ~:; n : ~' l' . < w3!-n\[;a2ls;ta~lisI~lS;':s~rch . : as : t . ti(class'iei)t : 6 if lems\]ne . nt loned . it\[' .  - ' , ,  .  " : " ! .  :  .  ' .  '  .  ' "  .  , !  .  :  .  '~ ' '  .  , -< , : ' " ' :  . 
(C lan l l i a i ( "1973 ~ il \] whietltl\[ire . firents ( if ' l: , ' ou on ns result of Word semse ( tiszmt blgua ~ mn mone sentenc . eY::--': . .:  .  - " ," , : ?,  .  - <-' ," " ; ; ; ; - ' - "  . Wit-ir'M ~ the(W6i'd ~ . /c " S di ~ lis ~ iou ' ~( ~ t . fih ~: SlXl '( ~: . ttie"arendt,<exlw ~ it ls % ~ L15P?t . l . li\[;lle~l;(x  ~ ;, nowexer . . m a . .' .   . . . . , . .  . : ~  .   .  : : " ":,~ . .:~:  .   .   .  : :  .  '  .  ,,:-:; . . . ': : . ':, . ; . :,:  . :' . , . ., . . " :  .  - ? < . . . . . < : . .  .   .   . P .   . . ~ z - . ,  . % ~,  .  :: . :  .   .   .  ; - : "  .  -  .   .  ;  .   .  - ,~  .   .  , ,  . :- z-el . "" satl w . ld ~ ill n ~ L : 2F ff rt lt e1 ' i ii or ( , : , . .:I~ . ~asstntlin'g;W . fllS . C(~Ml ~ Se:t ~ . X  ~ .   . Wit'l'I llT ~ ur ( , sZl'l (% e;(l(i Olllai , n " .   . : p&rr,l('lnarlyAn\[,e11:" .  : * . . : --: - (  .   .  '  .  ?  .   .   .   .   . . ? , , ,  . ' ? : ? : ' , ,  .  -  .   .   .   .   .   . 
'abSerxre . .t'ti/~i~3~ ( mi) ; x ( id ~ - i lenderlt:tfi:obloniS ; ' tht ~( Art !' ; :: )  ;   . .6 . y ' . ',: ';-,- . :  .  ,  .   .  -!  . . . . .  ; . . Y -;! : - i ~:- "<: . .' .  ? . , i ~ : !, . : . ,!!~?: . ! . .>"- . .,':'~ . : . .,' *  . ~? : i "; ~; .  ' " , - ," "  . -/," v (: ~;- . , < i- .  - "  . . " e ~ .  ?  . _:SL : . ? t : . ' W/~,"(; all " O\])t ,, ~ kil I : . 6"l . l l ~ C , ~" t , ~ , U ~' l ; ergllllltg :\[ , tiell ~ Detl Ileog . oIs(MgaDlg .   . Wll;nOt'lt- . Ille ! lS ( . DI . a ( Lee pll lier once ille ( lt7 .   .  ' '~ " ' ,  .  ' " ,  .  ' ' -1  .  '  .   .   .   . i .   . ~  . :  , ? ~ t " ei mismo ~ Cal ( full " haiid ( od ( d data su ( h~scl , i- ) ts'sm ~ ( ~ nr ~ uyftmolguous1 ) nrases Iroms H ' . ltcurai . mlor:"?""~'y .  - : ' ' "  .   .  ' " ' " " 1 ' ? : ? ' ,  .  " - '  . - ?  , :''':''\[ Schhnk and Rdsti6k1 ) 9 81~ Wc therefore tried t0 matnmon all words w~th the same : lemma wlth m the  . ~,~ . . . ~, - . ' i < . . , ,  .  '  .   .   . ~ . , ' . . . ,-, . ,~,!,- . ; . . . .  . ~,,;,~, i', . ~, . '~ . .:~; ' di,~(:a~r:;'e ~, . ' . M6r~ovel ',, p~;O . c~siilg . :,~-MiOle . ~ . xt :: ~ . a ~ i ~: , d /) VelOp ' a-praY(tl (-' . \[tl ~, ile ~ no (\[- tllaL . wolll(lSOlV . O'lllOS, .   .  , - ' - , ,  . .,  .   .   .   .  ' - ?  .   .   .   .   .   .   .  "  .   . . . . .  ' : -  .  - ' " ? " " -  . . . . t in le ltmkes :- it . po ~ ibto ~6, . refer::totl ~ erdn . f(*rm~ti61 ~ abntexV ddpenden . tpx ' obl0, nls . and , m~t)r . o ' ~ e theace u- .   .  , ' ' ,~,-  . . , - ; , '  .   .  , ?  .  ,  .   .  - , , : ; - . : .  :,  . , .  " ; . . ? ; ?  .  ,,- . : .  ' :  .  '  .  ; ; " , ' :  .   .   .   .   .   .   . , i ":-," i "'; .  ' : ' " "  .  , , " - , ,~ : ' ," " : ;  . ' S ' li(;\[Fa . , ~ wor(IIreqi'fOn(~I~d ~, 1 ~ e . poslr lo~z : ot . e~ten , WO l'(r , ? . racy , oI ~ ex . b , all & lysls : Dy , U , qlnga . stlnp telne cP2a , nlstD .  :  .  , ,  . ~ ~ ? :  .   .   .   .   .   .   .   .   .   .  :  . . . . . . :  .   .   .   .   .  :  .   .   .   .  , " , , : , : : , : " , '  .  ,  .   .   .   .   .   .   .  - "<  .  " :  . . ~  .  :  .   .   .   . ~  .   .  ;  .   .  : , . i , .  '  .  ,  .  ;  . - .  "  .   .   .   .   .   .   .  -  . "  . , w f i i e h , c . anbe . lmedf0rgesoban ~ i ) ron . em~ref ~ tetl cdund ' and - , eXlSldl\]g1i13 ~ llllle-l'l , ~a (13 A ) leoara .  , , ? ' ,  .   .  - _ . ., .  :  .  ;, :  .  ' , -  .  , : '- .  ',  .  ; - : " < , " - : ,  .  '  ,  " -? -  , --" T6t ~ e~h ~ , w : it ~ ~ e't tevel 6 , ;~ ( \[ ~ ( f t a h ~ 4 v 6 t k ' f ( fi"~i@6':/tlii ~' ~0 ( ' us<ot-m~ash~gsnla'imictq:stidi . .it ~ a . l . ~ o , and -0 nt : y , ?""-"~-~ . -  .  ~ , ,  .  '~ - ~  .  ' : ' -  . r """ ; :', "<'','-"'' ::" .  " ' - : ' : ' " ' " - ' :  .  ? 2 ' * ,  .   . ?" ' :  .  " : '  .  ' : ; ) - ' ,  . , ': ~ essi . ng . all_:se\]~te . n ~ : 8 ~ . g . .a ': t;eXt ; si imflt~n(' . 0 i / sk 6! s ( ; that .   . i : ? . Ii / : ~ hi's . : p~p"h'i : ,, ~$! . / . d'eScti ' . t~9 . )d3ii: . . . . . a ! ob ) is t . . (> O~\,tgx , t ~ ~ e'a(-hsent . endee ~ u(b'ed~s~nb'~gu ~ ded by its ingi~ffo~mia- . ( proce S ~ ingl ~ ett ! od , . m ~ mely ~" fill- . t(~x ~: processlng , , f6 - t io i ~ ex~rgcted f rom other senten ( ' es within tlm same ( : using Onits effects on ttie . output of an mehine trails-tim framework of our method  , which uses a siml ) le context model ; tl , (` n , in the followings (' etions , we illustrate itseffe ( : tiveness with some actual outl ) uts of our English-to-JCL 1 ) an eselna ( ' hine translation system . 
2 Framework
Full-text processing consists of thr (' esteps : 1 . G(`neratil , ga context model tlmt consists of 1 ) arsed trees of each selt t ( 'n ( `eillas our ( ' et ( ` xt2 . Refining the context model by assigning a single raft-fled parse tree to  ( ` a <' h senten <' e in the text 3 . Resolving the prol ) lems in - ; t <' h sentence in the <' < m-text n to de lan<l generating a  . final analysis for ea <' h sentence in tit ( . text Theresl ) ective procedures fl ) r these steps are ( It '- scribed in the tolh ) wing thre (  , subs(`ctions . 
2 . 1 Generat ion o f a s imp le context mode l In order to refer to  ( ' on text information that consists of dat ; to n multiple senten (' es in at text , it is esseu-tim to constru ( ' tsomeeollt ( ` : ~ t model ; the tirst st ( ' 1 ) of the full text 1 ) ro ( ' essing n wth odix therefore to ( ' on-stru ( ' t a context l node l by amalyzing ( ` a ( ' h senten ( ' ( ` in an inlmt text . To avoid any ( , rrors that may o ( ' curduring transforlm Ltioni to any other rel ) r ( `s ( ' ntations , su(:hasah)gicMrel ) resentation , we stayed with surface structures , and to i ) reserve the robust n ( 'ss of this framework , we used only a . set of l ) arsedtr('es as ; t(:ontext model . Thus , ea (: hsent . enc ( ` of an inl ) Uttextix pro ( ' ( ` ssedt ) y a syntactic lmrs ( ' r in the first st ( ' I )  , and the positi(mofe act instance of every h'mma . , its morphological information , and its l no ( lifiee-modifier relationships with other content words are extracted from the parser output  , and stored to construct a context model , ; ~ s shown in Figure 1 . In addition , if any online knowledger ( `sourc ( ' s are ~ tv Mbd ) l ( ` , infl ) r-mation extracted frolnt it ( , resour <: esi also stored in the context model . For examl)le , infl ) rmation on symonyms extra . ('te ( t from a non-lilw thesaurus dictionary and information  ( mwor ( l sense all ( \[ structural disambiguation extracted D ( )m an examl ) lel ) ~ ts ( ` , such as < me describe < lin ( Urmnoto , 1991) and ( Nagao ,  1990) , mayl ) ead < led to the cont('xt model . 
2 . 2 Ref inement o f the context mode l In the first step  , a syntactic l ) ~trser may not always generate a Mngl ( ` unified parse It ( ` ( ` for e ~ wh sentence in tiw source text . A syntact i ( ' parser with general grammar uh's is often mml ) leto analyze not only se . ntences with grammatical errors and ellipses , but also h)ngs(`nten(:es , owing to their comi ) lexity , l Thus , it : ix indispensable to ( `stablisha ( ' or rect analysis for l In texts front a restricted  ( lomain , suelt as compltter manu ~ tls , most sentences are g1:mmm~tic~tl\[ycorrect , t to w -( wer , even a well-established syntaetie parser usually fails to generate a ratified parsed structure for a \]  ) out 10 to 201 ) (~rc ( : nt of all the sentences in such texts , and the failn rein syntactic analysis leads to a failure in the filt ~ tloutl  ) l/t of a , , NLP system . 
Context = Sentence l , Sentence 2, . . . , Sentence n \] Stenence i = \[ Word i-I , Wordi2 ,   . . . , Wordij
John likes apples . Sentence 1
Word 1-1\[John \]
POX:NBASE : John ...
. . . . . . . . . . . . . . ub/~ohn ~ Word1-2\[llktm\] . . . . . . . . . . . . . . . . ~ POX : V BASE : like .   .   . 
POX:NBASE : apple . ~.
Tomah ' olikes apples.
Sentence 2
Word 2-1\[Tom\]
POS:NBASE : Tom ...
Word2-2\[also\[
POS : ADVBASF .: also.,
Word 2-3\[likes\]
POS:VBASE : like , . .
Word 2.4\[apples\]
POS:NBASE : apple..
He also likes oranges . Sentence 3
Word 3-1\[He\]
POS : PNBASE : he ...
Word3-2\[also\]
POX : ADVBASE : also.,
Word 3-3\[likes\]
POS:VBASE : like , . .
Word 3-4\[oranges\]
POS:NBASE : oranse , .,
Figm'e1: Example of ~ t context mod ( ' lsu ( ' has ( ' ntenee , hfformation extracted front COln-pl ( ` t e1 ) arses of w ( `ll-formed sentences 2 in a context model ( ' all b ( ` us ( ' ( l to cOlnlflete in colnl ) lete parses , in the f ( )rm of partially parsed chunks that a bottom-up 1 ) ars (  , routlmts f l ) rill-formed sentences by using a previously des ( ' ribed method ( N~Lsukawa ,  1995) . 
On the other hand , fl ) r some sentences in a text , such as Time \] lies like a narrow , a syntactic t ) arserll taygent , ratenlore that lolle parse tree , owill g to the 1 ) r ( `sen ( -e of words that Call \] ) e ; Lssigned to more than one part of st ) eech , or to the l ) resen ( 'e of complicated coordinate structures , or for w trious other re ~ L sons . In attempting to select the correct 1 ) arse of such as en-t ( ` nee , on ('( ; an use the tyt ) es of the l ) revious and sub-se ( \[lleltt sentences or 1 ) hras ( ` s ( Sll ( ' has sentence , ll Olll phrase , verb1) hrasc , antiso ( ) It ) an ( l the modifier-modifiee 1 ) atterns in the context model . 
Therefore , in the second step , tit(:context model g(`nerat(`d in the firs ; s t ( ' 1 ) is refined by referring to information in the context model  . First , the most l ) referable candidate parses are selected for sentences with mult it  ) le parses by referring to information one a ( ' h sentence in the context model for which a parser lent'rated a single unified parse  . Then , partiM parses of ill-for lned sentences are ( ' ompleted by referring to information on well-h ) rmed senten ( : es in the context model . 
The algorithm for multiple parse selection based on "' Ill this paper  , a " well-for nwd senten (- e " life , Ill S ( ) It ( ' that is 1 ) arsed as one or lll Ol'e than Ol1 ( ` l l l l i ~ i ( ' dstrll ( ' tllre ~ and an " ill-formed sent ( me ( `" means one that c ; mnot be pm'sed as a unified strncture . 
825 the context model is as fi ) llows : 1 . In each candidate 1 ) arse of a sentence with nmMph'candidate i ) arses , assign a score for each l nodifier-modifiee relationship that is fl  ) und in the context model , and add uI ) the scores to assign a 1 ) reference value to the ( : and i date l ) arse . 
2 . Selecthe 1 ) arse or 1 ) arses wilh the highest preference value . If more than one l ) ; ~ rse has the highest ) ref-ereneew due , go to the next ste1) with those lmrses ; otherwise , leave this i ) ro (' edure . 
3 . Assign a 1 ) reference value to each remaining candidate parse that has the same tyl  ) e of root node ( su ( ' has noun phrase , verb l ) hrase , or sentence ) as the parse of the 1 ) receding sentence or the next senten ( 'e . 
4 . Selec the parse or 1 ) arses with the highest 1 ) reference w due . If more than on ( ' parse has the highest 1 ) ref-erence value , go to tit ( , next steI ) with d to se1) arses ; otherwise , leave this procedure . 
5 . As sign a preference w fiue to e a ( ' h remaining ( ' and i-date parse based on heuristic ruh's that assign scores to structures according to their grammatical prefer-ability  . 
6 . Select the parse or parses with the highest preference value  . If more than one t ) arse has the highest 1 ) reference w fiue , select the first parse in the list of the remmning candidate parses  . 
Tile procedure of conq ) leting l ) art i a \]\] ) kLl'ses of a . nill-formed sentence consists of two steps : 1 . Inspecting and restrnet . uring of each 1 ) artial parse The part of st ) ee ( ' hmid the modifiee-modifier rela-tionshil ) s with other words are inspe ( ' ted for each word in a 1 ) artiall ) arse . If the part of speech and tit ( " modifiee-modifier relationships with other words are different from those in the eont  ( ' x : t model , the 1 ) aerial parse is restructured a ( 'eor ( ling to the information in the context model . 
2. Joining of partial pmses
If the 1 ) artial ) arses were not ratified into a singh " structure in the previous step  , they arc , joined together on tit ( " l ) as is of modifier-modifieer lations hil )  1 ) atterns in the ( ' on text model so that a unified i ) arse is obtained . 
2 . 3 P rob lem reso lut ion for each sentence in the context model Finally  , in the third stel ) , e a , ' h senten ( ' e in the ( ' Oll text l node lism mlyzed individually , and its mnl ) iguities and context-dependent prol ) h'ms are resolved by referring to information on other sentences in the context model  . The next section des ( ' ribesthe 1 ) roce-dures for problenl resolution , and explains lheir ef-fectivene , ssinlint ) roving nmehine transla . don output . 
3 Effectiveness
The a ( :cura ( ' y of syntactic analysis m ~\ yl ) e improved by refinement of the ( ' on text nn ) delintlt ( ' second step of the procedure . For ex~mlple , in a nexl ) eriment on 244 sentences from a . chapter of a COml ) uter manual , in which we attempted to select the correct parse of a sentence from multiple candidate l  ) arses , (' or re('t parses were sele('ted for 89 . 1% of 110 multiple pa . rsed sentences by using infbrmation in the ( ' on text model , where ~ us the success rate obtained when the ( ' on text model ?' ontmned no ilf formation was 74 . 5% . In our experiment on ill-f ( mned sentences ill technical do ( '- ulnents , in more than h ~ f lf of the incoml ) letely 1 ) ~tr sed sentences , the lmrt . iMparses were joined into a singlestru ( ' ture by using ilf formation in the context model . 
However , after the second step , ambiguities in each sentence are kept unresolved in the context model  . 
Thus , we need to resolve problems in each sentence in the context model ill  ( lividuMly . 
In this section , we describe how the accuracy of senten ( ' emtalys is in other probh'nls is improved by referring to the siml  ) lecontext model , and how the results are refiect e ( lin improved machine translation outlmts . 
3 . 1 Resolving the focus of focusing subjuncts I h , solving the focus of f i ) cusing sul ) junct such as also ; rod only is at yl ) ieal context-del ) endent prob-l ( ' mtha . t requires ilf fornmtion on the 1) revious context . Fo('using sul)jnncts(lr~twm . tention to a part of ; tsenten ( -eth ~ tt often represents new information . 
Consider these (: ond senten (' e , Tom also like sapples , in Figures 1mM 2 . Ill this sentence , the scope of also can 1) eTo'm , likes , the entire predicate ( the whole sen-t . enee except the subject Tom ), or apple . % acc(trding to the it revious context . In this (' as (' , the preceding senten (' e , Joh , nlikes apples , has the structure , Alikes B , where a sentence (2) has the structure , X also likes B , where B and the predi (: a tefib , s are identical . Theeoml ) arison of these two structures indicates that the new intbrmation X  ( Tom ) is the scope of also in sentence ( 2 )  . 
The fl ) ('us of focusing sul ) jun ( ' tsix resolved by means of the following algorithln :  1  . Find among the 1 ) revious sentences in the context model one that contains expressions morphologically identical with those in the sentence containing the focusing suhjunet  . 
2 . Contpare each candidate focus word or phrase in the sentence containing the tl  ) ('using subjunct with words or phrases in tit ( " senten ( ' e extracted in stel )  1 . 
3 . Dropanymori ) hologieally i ( hmtical words or I ) hrases as candidates for the focus , and select the remainder as the focus of the fo (- , tsingsu ) junct . If more than one candidate remains , take the defaul , interpretation that wouhl be used if there were no context iuformatiol t  . 
Figure 2 shows the translation outputs of our sys-te , n with and without information 1 ) rovi ( h ~ d by context pr ( t ( : essing . As shown in this figure , with ( tarthe context information , also modifies the 1 ) redicate likel ) y default in l ) oth senten ( ' es ( 2 ) and ( 3 )  . In contrast , when context pro('essing is apt ) lied , the focus of also ix determined to I ) eTom in senten ( : e ( 2 ) and orange in sentence ( 3 )  . 
In our amtly sisof (' omlmter manuals , most nouns were repeated with the same expressions unless they were repla  . ('ed by 1 ) ronouns or definite expressions su ( hasth , is , that , and tit (' . . () n the other hint(I , predi- ( -ates were sometimes repeated with different expressions  . For exanlple:
A has B . ~ A also includes C .
A contains B.--~C is also included in A.
826 (1) John like sal ) l '.' s.
\[ With and ' v Viihou (.(: ott <, xi \]
I ) ep ( qidency SIrtl ( ' liil ' ( q'l'ranslaiioll : " ~! i ~'+ & , ~ J "/:-: ~: ~ . t'-g*~-51"< ,   , lOhgL\]t?+'l'i~tylO'lllokOrtLOlltiilZ?LR ' IL  , (2) Tom Msolikes a . l)l)l,,s . 
\[ wiu , , ..~<', ., , , .'x , l(-~----"
L~-_'l'ranslalh)n:I"ACJ . , i ) " t : : : , I . J 4 < > ~ : : ~ :& ~ :- g , : I'0711 , \]DfL/'Zll , ? / OllJof\[OTL'!J(JII , ILI ~; OII , OIlLIll lfL , '47 + ( a ) H(:a , lsolik ( , so ranges . 
\[ Wit , hour . ('<'"" ? tIQi , , ,)
Translation : ~ t & , 7~+1/;/5) g: , I , iJd , ~ V ?" ai&'t'j , , \[ ( ( Zl ' ( ~ Jt ( ~ 01' ( Z ~ II ( :'+ Ill ) C\]OttlIO'IZTtZ 7L ( 'Z ( )HZi Iltf~N'lg . 
\[ With ( : ontexi\]'l~o~t~~ltO~'itZ\[lO"~llO/ , : Ol ~ O ~ ttiltZ(t , ~'a . 
Iwi , , , (:(>. ~, (, ~ qQa'_).
i)op<,, . I,,,,, . ys , , . ., . ,  . , . .: p, . iaV,'~ . .-) . : ?,, 7; < a ~,> q + aa --' X :- : ~ . . . . . . . . . . . . . . v . , . oATi'al , sl ~ tiioti:~2 , >\]" I/F'S ) ~'&~-~' ,   , t((tl't:\]l , ( Z09'(tlZg(' . 11 t0 ~;01 tCl#tti7tt(t . S'll, . 
Figure 2: l ~ ; xaml ) h'of translation ( I)\[11 this case , infornlltl : io non , ~3" il Ollyill Sa , lld deriva-tiv (' s( , xtr+t('t ( , dfi'omon-line ( li ( 'tionari ( ' scant ) (' us ( ' dl ; oex all lille the ( : OH'eS\[ ) Oll ( h'n ( ' e\] ) etw ( ' ell two words . 
3.2 Resolving pronoun referents
Pronoun resolution is a . noth( , r typical (' on t ( , xl-(h'l ) (' nd('nt1) rol)h'nJ , sin ( ' ( ' ther ( 'fcr ( ' nl of al ) ronoun is not Mwa . ysin('lud('dinlh('sam(, smlt:(,n('(, . Our('ou-l:ex:l:n ) . o ( lelisus ( ' d to s ( qe ( ' t ( +u Midat ( ' noun l ) hras ( 's for a 1 ) ronoun r ( ' fl'rent . \] qlrthermore , information on word fr ( 'qu ( m ( ' y and moditi ( ' r-moditi ( ' ( ' rel+t ( ionships extr ; tc tedfi ' om the ( : on text 1 no ( \[ elinll ) roves the a (  . ( . u-racy with whi('hth('('orre('trcf('r ( , ntiss(q ( , (' to dfrouithe ('; m(lid~t('nounl)hri~s( , s , a . s shown in a . pr('vious pap('r ( Nasukaw ; t , 199, i ) . By applying h ( mrisii ( ' rules according to which a , c and i ( lat ( , that hash (' imfre-qu (' ntlyr ( , pe~m ~ ( linth( ,  1 ) re ( ' eding sent ( m ( ' es and it candidate th ~ t tmodifi (  , s them or l ) h o h ) g i (' a . llyid ( 'nti-- ( : al predicat ( ' s as tho 1 ) rollollllini ; he same context are t ) referred , w ( , obt . Mn (' dasu ('(:(, ssi'~'L(,O\[,0 . '~ . 8 ( Z , ill pronoun r ( , solution . 
However , the results of pronoun resohlii On may not be explicitly r  ( 'th' ( 't ( ' dinth (  , out . put of : tma . (' hin ( , tral , sla . tion system , sin ( (' most languag ( 's have ( ' or reSl ) onding a n+q ) hori ( : expressions , ~tndus('ofth( , corre-Sl ) onding a . naphori ( expression in lhetranslation oul-l ) ut : hi~s the adviLnt+tge of a . voi ( lingmisint('rl)r('ta . tions('a . used by misr ( ' solution of 1 ) ronoun ref ( 'r ( ' nts , (' v (' n if the probability of misim . (' rl ) r('tation is less than 10J ( . 
Thus , ill Figure 2, Hein . q('illrOll('(~(3) istra , nsl~Lt (' das the Ja , 1) anese1) ro noun ~; a'r (: , M though its ref ( , renl ; is correctly resolv ( , da , sTor ~ ,  . Even so , corr ( , ('t res-o lut ion of a 1 ) ronoun r ( 'f ( 'r ( ' ul : isiml ) ortanl for dis-ambiguating the word sense ( ) f a 1 ) r ( 'di ( ' al : ( ' modified 1 ) y t , hel ) roiiou 11 . " ~ Illad(lition , if the 1) ositions of a , a In fact , t . he result of pronoun r ( ' solution for s ( 'nl: ( ' nc ( '  ( 3 ) of Figure 2 , in whi('hTo ~ ,  . is s(%('t (, das( . hor of e > t ) t ' ( ) l l l i / , tl(i1: , % l'('f('l'O lll ; llOlln1)hra , s ( '& l ? ( ' reversed ill thell:~ulsllt /: ion of a . (: Oml ) h , xsenten (' e where a nini-timma in (' lause illa , sour ('( , -lm tgmt ges ( , nt( , n ('( , (' om ( , safl ( , rth ( ' sul ) ord in + tte ( 'l + ms ( ' inth ( ' target language , the r('t'('r(mt , noun phr~ts ( ' shou hl be repbt ( ' ed with th ( ' I ) ronoull , to avoid (' at a . phori('refer(,n ('( , . For (' xaml/h ' , the t"m ~ , ,lish S('lll , ( qlc('Th , (: dog ' will eat you , ' rc . ,k ?' , if youd cm , ' tho , v ? : q ' et i (: kly , should bc translatod as Kiw ~ . i\[v , , , , \] ~/ a . ~onokeiki\[th < < . . kq wo ,~' tq/'~?,~,i \[ q,,i, . ~ l . \]  ~ a . l~?'":~,?ri\[,10,,'~< . ~1 ~ , (1, ' r a . ,  , ,~ o'n , oi ~ tu\[~h , d , ,~\]  , qa , I : a , hetc:_sD , i ? r ~ , a , ' i ? ~/ o\[ , , , i . ., q . 
S in ('(' in the t,r;m slated . \] ai ) ~ uwse ( , nt ( , n ('( , the sub-o Minate clause , i , fyoudo'u ' I have it quickly , (' om ( , s1)e for (' th('mainel+rose , The dog ' will , at your " (: ai ; e , the pronoun it in th ( , sUbol ' dinat ( , claus ( , must l ) er ('- solved in order to g('n ( , r ; tte a natura . 1  . \]iq)an(,s(,sen-t(m('(, . Mioreover , the word sense of h , avein the subor-dinar (' claus (' cannot 1) esch , ('t( , d without in f l ) rm a . tio nonth('ret ' orent of the pronoun it . 
3 . 3 Lex ica l and St ructura l d i sambiguat ion In a  . consistentext ,  1 ) olyseln OUS words with iua discourse tend ( o have the sam (  , words (' ns (' ( Gale et a , l . , 1992; N ; tsukawa , 1993) . Thus , \]) yal ) plyiug discours (!(' ovstra . int in such a , n lanner that 1 ) olysemous words with the slune lemma within a context ha  . veth (' same ( , nt of He , isr('tle(q ; ( ~ din (: he translation of the predicate like . lh ' (' ~ mse of the l , ~(:kofttscnmnti('f (' ature ?' lt~t ~ , an forth ( , h'xi (' alenl ; ries '/' o ~ , a . nd , loh'uin our ( ti ( ' tion~try atth ( ' tinio of this transla , tion , diti'eront word senses for animate sul ) jc ( ' tsmidnolt-aalinla ; (! sul)je('ts weres ( , lectcd fortl , cverb like , and the verb like was r ( , n(h , r (' d(lit\[( , r ( ' nllyinth ( ' translations with mM withon t context . 
< lT his translation was not 1) roduced by our syst ( , m . 
827 word sense , a result of word sense ( lisambiguation aI ) -plied in one sentence caube shared with all ( ) tiler words in tile context hat have the same lemma  . Furthermore , by assuming dis('ourseI ) reference , namely , a tendency for each word to modify or be modified by similar words within a discourse  , structural infornm-tion on all other words with the same lemma within the discourse  1  ) rovides clue for determining the modifiees of structurally mnl  ) iguous 1 ) hrases ( Nasukawa and Uramoto ,  1995) . This method can 1 ) e used to solve context-dependent t ) rol ) leuls such as the wellknown examt ) le shown in Figure 3 . 
(1) John saw a girl with a telescol ) e.
\[ Without (\] on tcxt\]
Translation : ~! J ~/ t ~ t . ~ N,~<3:o< .  ~'/ . 0 . ' '5~ ~ b/do John haboucnky ouniyottes houjowo ~ nimashita  , \[ With Context \]) el ) endency Structure : '<) 0 ,   .   .   .   .   .   .   .   .   .   .   . 
.......( with
John habouenkyou wo mots us houjo womimashita.
(2) The girl witl , a telescope was walking on the street . 
\[ With and Without Context \]
Dependency Structure : v , ? a-D ... .....
Translation : ~, ~"% ~) ~ J ~' ' . 0,'I2v,~i')"~'\]J . Z~ , ,Z'V , $ bt:o Houenkyouwomo rans houjoh aloor idearu ~ tcimashita  . 
Figure 3: Translation with context ( II )
In sentence (1) of tile figure , the mo ( lifiee of the prel ) ositional phrase with a telescope can be either saworgirl  , depending on its context . In this case , information in sentence (2) , where the identical t ) repo-sitional t ) hra . semodifies girl , provides a clue that with a telescope in sentence  ( 1 ) is likely to modify girl . 
In this way , modifier-m < ) difiee relationships extracted from a context model provide clues for disambiguating structurally ambiguous phrases  . Needless to say , the effectiveness of this method is highly dependent on the s < mr ce text  , and it may seem too optimistic to expe ( : t such useful information ill the same context . 
However , as shown i ~ 1 Figure 4 , which is a translation output of an actual <: Oml ) uter manual , we can often find modifier-modifieer lationships that  ( lisam-biguate structurally anlbiguous phrases in tiles lt me context  , at least in technical documents . In Figure 4 , the ambiguous prepositional 1 ) hrase of a job 5 in sentence ( 2 ) is disamt ) iguated and attached to the flowl ) y ~ of + noun may modify verb , as in Herobbed alady of her money . 
using the information provided by the unamt ) iguous 1 ) rel ) ositional phrase in The flow of a job in sentence ( 7 )  . Similarly , tile information on the unaml ) iguous prepositional phrase in placed on an output queue in sentence  ( 11 ) disaml ) iguates the aml ) iguous I ) rel ) osi-tional t ) hrase on a job queue in sentence ( 9 )  , alh ) wing it to be attached to places . 
3 . 4 Supplementing phrases for elliptical sentences Supplement a timlo felliptical phrases is another typical context-dependent prol  ) lem . In spite of the sin > t ) lM ty of our context model , some elliptical phrases can be supt ) lelnented by using information extracted h'om the context model  . For example , if a group of words ending with a cohm is not a complete sentence  , as in the ease of (3) in Figure 4 , 
This allows youto : our system adds either do the following or the following t  ) y referring to the tyl ) e of the next sentence or phrase in the context model  . If verb phrases follow , do the following is added , and if noun l ) hrases folh ) w , the following is added . Thus , in (3) in Figure 4 , do the following is added 1 ) ecause a verb phrase follows this sentence . 
3.5 Resolving modality
The modality of itemized sentences or phrases is of_ten ambiguous as a result of the  1  ) resence of ellipses . 
For example ,  (4) ,  (5) , and ( 6 ) in Figure 4 couhl be imt ) erative sentences in certain contexts . In this ease , however , they are itemized phrases , and by reference to (3) , they (: all be identified assupl ) lementary w , rb phrases to be attached to (3) . Thus our system analyzes them as verb phrases and nominalizes them in the translation  . 
4 Discussion
We . have described how a simple context model that consists merely of a set of parsed trees of each sentence illatext provides rich information for resolving amt  ) iguities in sentence analysis and various context -dependent prol  ) lems . The greatest advantage of our coutext-processing method is its rolmstness  . Storing information on a large number of sentences requires a relatively large memory space  , which has become available as a result of progress in hardware technology  . Our fl'amework is highly practical , since it does not require any knowledge resources that have been specially handcoded for context processing  , or a deep inference mechanism , yet it improves the accuracy of sentence analysis and the quality of a practical NLP system  . The basic idea of our method is to improve the accuracy of sentence analysis simply by maintaining consistency in word sense and nmdifiee-modifier relationship among words with the same lemma within the same text  , on the basis <> ftile following as sun , pti < ms : ? Vo calmlary is relatively small in a consistent text  , and words with the Sanlelemma are repeated in a relatively small area of a text  . 
828 (1) Tracking Your Job : ~ . --%-m2 ~ , 7 ~ i!~aM7~:_~:\[U , ~ e'rv , ojob , ~ ot . v~l , i , ~ eX:iaur'ukoto )   ( 2 ) It isiml ) ortant to knowth (  , flow of a job so that you can track it through thv system and display or change its status  . 
tj , ' ek ' ~8 to , , & . Sv,l:t~i ~,, J0P , t~<k5~::, g~-f a)j,f . ~L4 . ~fl-,-Cu , 7o ~>: ~: tili:'~:-(*'~<>\[Uaerga, . system , wo too , ~ hih: , so rewot au-ise kidekite , , oyobi aono , jouk you wohyo'wide kiruka , aruih , a henkouk a nouna youni , jo Dnonay/are ? ~ osh , it-teir uko*oh , aj ' ml ~ , yo ' , , dear ,  . 1 (3) This allows you to : t * t t : l ,  :~---~'- -~< ~ ~>< , 1:2 V~:~fr . ; 5<~4"J(lP,~:L:~g . ( Koreh , a , usernitotte , ikawoo\]~: on a , , u , A : otowo ); : a'nouni . ~ himasu . \] (4) Endor hold a batch job . 
~ , ~-7- ? "~ ~-74 , ~ , j"?Z , t ~ ~ v , ~t ~' i , - ~ ~ ~ _ ~ :\ [ Batch job woahuur you . ~ , ar , l  ~ , ko to ar , ltih , a hoji , ~ urltkoto\] ( 5 ) Answer message sent by the system . 
9 , x~-&~<2<>'(~( , ttT~ , g'7-k-715~)7~12&\[~y , < 4te'm , r ~ i yot teok , lt , vareru~n , esaa Slewi \] cota , c'r'lthoto\](6) Control print('r output . 
l~l . !llil\]~??,' . ~') ill)J'kliil J~11"?"7~Ck\[bt, . sat , ~'u , so ' lt , ch , i ' nod ~ , ut-suryoku woseigyo*ur , uhot < ) \]  ( 7 ) Tit ( ! flow of ~ tjob can have lip LOfi VCStCl ) S:gu-fa ) ~ ; ~ t  ~ , l ~) ,  . ; r ) o ) x -) ~, ~7' lfide > b ' ~! J , ~ J ' :\ [ . Jobrl , o " nafta'l ' ~: hi, . ~ aidai5 no . ~tep gaa . riemn , v ~ u \] (8) 1 . Anser or 1) rogram sutm dtsa jol ) to 1) erun . 
~t ; flb~-j'o\[1 . U . serar . u , iha program ha , jikko'u , an r crlttame no job woj it , : ko'niro , iddmas , la .  ) (9) 2 . The system places timjo bona job queue . 
2 . ~ x-ye ,), t , "7 ~ . 7"?,~Aj:YUV,"2,'~-/~:?~3'2 q'o\[2 . Hy , ~ te'm , ha , jobmachi . q youret , ~' lthi , . ) lrO/)IDOokim , s . , vlt .  \] (10) 3 . The systean takes tit ( , job fi ' om the job(l , t <' ue and rlltSit . 
J '<> (3 . System h , a , jobma , chigyov ~ rct , vakara , job , wo to ri , sorewojik kou . ~hima . ~' u , . \] (11) 4 . If this job create some inforlnation ( output ) that needs to be 1 ) tinted , th("printer output is placed on ~ l ~ I\[Ollt ; \[)1 l , ( Ill Cll C . 
4 . ~_a ) gu " fib ~,\[ itJ tiltJc ~\] ? c ~ . ' g ~? o ~> ~ t , , < <) do , ?)'I)'i ~# , ( tllJJ)"P~J~1-~ , ~ , ,::~;J : , ~l ~ lNitta ) tl ~) o ~; t , tl ' , Jj~ , 7 ~ , qi-#~j ~ c~gi?t . ~* t~t-?<>\[4 . 
Konojobga , in satsu , ~ are'r'lth , it , v ~ yo ' u , gaaruikut , , , l & anojouho'u(ah , ,~ttauryok , u ) um , ~akuseisur'ltbaa . in ih a , in a atsu souchino shuts , ~ryok , ~ ha ,   , ~ h ,  . ~d,~,l ~, ryoka machi-gyouretauni haichisaremas,l ~, .  1 (12) 5 . The system takes printer output fl'om the out-1 ) ut qlte U e and s ends it ; to t ; h ( , desired 1) rint ~ wtol ) eprinted . 
5 . "NXg : J , IJ ~, tllJJ , 6, ~ j : ~/ IJJ'G , lill t 6~@, < . o)~qlJd~l\[~O'~_g ~ , f ~ r l ? ll ~ 7 ote ~? ~" ~? lilJliliJ ~' t . ~:, ~ a~'l-~b2-j'o\[5 . Sy . ' ~ temh , a ,, ~ h'l~t . ~,aryok'lt . m , ach , igyo'u'rc't , ~ ukara , i ' ~ t , ~at , ~rlt , ~ o'l~chino , ~ h , utsu? , ,qoku wo torikomi , in . sat . ~'u, . ~arcr'u , tam ( no hitsuy ounain aatsuso , ~ chin , sm'ewooX:'arimasu . 1 Figure 4: Translation wil : h context ( III ) I Polysmnous words within a discourse tend to h ; tvethe Sa , lllP wordS (' llS (" . 
? Words with th ( ' same h'nnnaten ( \[ to modify or 1 ) (' modi f ied by s imi lar words . 
? Topical words t('nd to I ) e repeated frequently.
Therefore , the effectiveness of this l nethod is highly ( h'p ( qid ( ' nt on the source text . th)wever , at least in mos\[l : ( ' ( ' hnic & do ( 'uln ( ' titsStl ( ' h~ts (  ' ( ) i l i \ [ ) llt ( ' l'Il I&IIII&S , th('above ; mSUml ) tions hohl true , and weh ~ we had encouraging results . 

I wouhllike to thm , k Mi (' hael McDonald for his in wdnabh , help in l > roof r (' ading this paper . I wouhl also like to thank Taiji roTsutsumi , Masayuki Morohashi , I'~oichi Takeda , Iliroshi Maruyam ~ h Hiroshi Nomiyamn , Hid(x )\ Vatanabe , Shiho () gino , Naohiko Uramoto , and the anonymous re-vi ( 'w ( ' rs for their ( : omnlents a , nd suggestions . 

IP ~ ltlg~('tt("Chm'niak .  1973 . Jack and . an ( , i ; illSearch of a ' l~h (' ory of Knowledge . In Proceedings of IJCAL7,7,
Img('s337343.
William A . Gale , I':emwth W . Church , and David Yarowsky . 
119(,)2 . ( ) n (' Sense per D is (' on rse . In Proceedi' , 41 , ~ ofth , e4th DARPA Speech and Naturo , lLanq'uagcWork:ahop . 
Barbara , 1 . Grosz and C and mt('eI, . Sidner .  1986 . AI . -tentions , hL tentions , and the Structure of Discourse . 
Compatational Linquiatic , %12(3):175204.
Dm del Lyons and Gracme Hirst . A Compositional Se-ma , ntics for Focusing Sul ) juncts . In Procceding , q of ACL-90, pages 5461, 1990 . 
I(atashi Nagao .  1990 . Dependency Amdyzer : Al ( imwh'dge-Bas ( ' dApi ) roach to Stru ( ' tural Dismnl ) iguation . In Pro-ceeding a of COLING90, pages 282287 . 
~\['(' tsuya Nsukawa .  1993 . Discourse Constraint in Com-lmt (' r Manuals . In Procecding . ~ of TMI-93, pages 183194 . 
Tetsuya Nasukawa .  1994 . Ilo ) ust Method of Pronoun Resolution Using Full-Text , Information . In Proceedings of COLING , 94, pages 11571163 . 
Tctsuya Nasukawa , 1995 . Rol ) ust Parsing Based on Discours ( ~ Inform ~ ttion:Coml ) leting Partial Parses of Ill-Forlned S ( ?nten ( -es on the Basis of Discourse Infor-ln~ttion , litfb'oceedingao\]"ACL-95 . 
T ( , tsuya Nasuk ~ w~tmM Naohiko Uramoto . Discours(~asaI , \ [ nowledge Resourc ( ~ for Senten ( ' eD is a ml ) iguatiom
In Proceed in 9.s of \[ JCAL 95, 1995.
Roger C . S(:tmnkm , dChristot ) her K . tiesb(x : k .  1981 . 
I'n . ~ideComputer Under at and ing : Five Pro . qram . ~ plu , ,~ Miniature , < Lawrence Erlbauln Associates , tlill sdah ' , 
New Jersey.
Koichi Take & t , Naohiko Urmnoto , T ( , t , suya Nasukawa , and Taijiro Tsutsumi . Shalt2: Symmetric Machine Trm , slation System with Co , reel ) rUM'\]'ransf ( , r . htPro~ceed in . q , ~ of COLING-92, pages 10341038, 1992 . 
Naohiko Uramoto .  1992 . Lcxical and Structural Disambiguation Using an Exauq  ) le-Base . In Procecdings of the 2rid , lapan-Au , ~tralia , loint Sympoaiu ) non Naturo . l
Lauguage Proce , ~ sin.q , pages 150160.

