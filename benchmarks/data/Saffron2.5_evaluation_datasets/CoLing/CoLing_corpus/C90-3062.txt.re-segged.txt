Repair Work in Human Computer Dialogue
Alison Cawsey *
Department of Artificial Intelligence , University of Edinburgh , Scotland

Pirkko Raudaskoski
English Department , University of Oulu , Finland

Abstracl ; : If humancomputer interaction is to be effective , it is vi~alth at there are opportunities to check on understanding  , and repair that understanding when it fails . 
This paper discusses this idea of repair in humancomputer interaction  , and provides a number of examples of different types of repair work in an interactive x planation system  . 
1. Introduction
The importance of repair in human interaction is increasingly recognised  . If a dialogue is to proceed smoothly it is vital that there are opportanities for checking understanding and providing clarification when misunderstanding does occur  . Everyday interaction is full of such checks and repairs  , though these may be so au ~ ; omatic as to be almost transparent , rarely dis-turbing ~ heflow of the interaction . 
In humancomputer interaction , providing opportunities for clarification may be even more important  . If the communication is to be robust and effective  , then there must be opportunities for both parties to ' repair ' the interaction when it fails  . If the user is communicat?ing in natural anguage  ( or even in a complex command language ) then there are many cases where the system may not ' understand '  . If the system is giving complex instructions or explanations  , then there are many cases where the user may not understand  . 
These checks and repairs have been studied by people working in the field of conversation analysis  ( CA ) for many years . For example , people have analysed preferences for different ypes of repair  \[7\]  , and typical sequences of repair moves . 
Recently , there has been some interest in checks and repafi " within Cognitive Science  ( though the approach * Supported by a postdoctoral fellowship from the Science and 
Engineering Research Council to the subject is often very different from that of CA  )  . 
This includes work by Ringle and Bruce\[5\] , who analyse checking moves and conversation failure  , and Clark and Schaefer\[2\] , who have recently proposed a model of dialogae based on contributions rather than single communicative acts  . These are the sections of discourse through which the participants arrive at the mutual knowledge that the conveyed message is understood  , and may involve checking and repair work . 
Despite the prevalence of checks and repairs in human interaction  , there has been very little work within computational linguistics on these essential components of conversation  . The rest of this paper will discuss the problem in more detail  , and present some examples of differentypes of repair work in an implemented interactive explanation system  . 
2. Repair in Human Interaction
In human conversation there are continual implicit acknowledgements that communication is proceeding smoothly  . The speaker is monitoring the hearer in different ways to see if they understand  ( for example , using checking moves such as ' Do you know what I mean ?'  )  , and the ' hearer ' is often giving verbal acknowledgement to the speaker  ( e . g . , ' yes ', ' uhuh ') . If the hearer takes over the conversation , she may acknowledge the last utterance implicitly by  , for example , continuing the topic\[2\] . However , if the utterance is not understood , ~ repair may be initiated . We can examine this repair from several perspectives : Sequencing : A typical repair sequence may consist of a repair initiator by the hearer  , a repair by the original speaker , and an acknowledgement by the hearer . However , repair sequences in general may be much more complex  . For example , the speaker may do a third turn original utterance was not understood  . These different types of repair have been discussed in  \[7\]  . 
ttepal r Initiators : Repair initiators may take many forms in human interaction  , including : facial expression ; verbal signals ( ' huh ?' ) and clarification questions . 
In human dialogue , the speaker may frequently self-correct without hearer intervention  . 
Source of Trouble : Communication may break down for many reasons  , such as from lack of hearing , reference failure or from general misunderstanding of complex material  . Although the form of the repair ini-tiator may indicate the source of the trouble  , this is not always the case . It may therefore be necessary to guess at the likely source of trouble  , possibly using discourse context or assumptions about the hearer's knowledge to reason about likely problems  \[3\]  . Repair work both relies on , and shapes the context of the interaction . However , whatever the source of the problem , the basic interactional mechanism is the same \[6\]  . 
3. Example Repair Work
In order to illustrate some of these different aspects of repair  , this section will give a number of examples of types of repair work in an interactive x planation system  ( the EDGE system , described further in \[1\]) . These include repairs when the user fails to understand the explanation  , as well as repairs when the system fails to understand the user  . These latter are adapted from \[4\] . 
The EDGE system plans explanations of the behaviour of simple circuits  , depending on assumptions about the user's knowledge  . These are interactive , with many opportunities for repair work when the user fails to understand the explanation  . The user input to the system consists of one or two word commands or questions  , rather than arbitrary natural language utterances  . However , even with this restricted input therein an obvious need for repair work which addresses the systems lack of ' understanding ' as well as the users  . 
3.1 User Misunderstandings
First , we will illustrate how the system may repair user misunderstandings  . We must consider both how to structure the dialogue  , and how to plan the content of a specific repair sequence  . 
Clarification Questions : Whenever the system pauses the user may ask a clarification question  ( using a restricted command language )  . The system will normally reply to this question , then try and get back to what it was in the middle of explaining  . This is achieved using discourse ' plans ' to structure the clarification subdialogue  , and a simple notion of focus to attemp to resume the previous discussion in such a way that it follows on from the topic introduced by the user  . 
The following example illustrates this :
S : The light detect or circuit's components are : A light-dependent-resistor and a fixed-resist or  . 
U : What-is-alight-dependent-resistor ?
S : A light-dependent-resistor is a kind of resis -tor  . Its function is to provide an output resistance which depends on the input light intensity  . 
S : Anyway , when its input light intensity is high , its output resistance is quite low . . . .
In this example the system was planning to describe the detailed behaviour of the light detector circuit's components  . Because of the interruption/clarification , the system chooses to first describe the behaviour of the light dependent resist or  . 
Signalling Misunderstanding : The user may also signal that they are not following without mentioning the exact problem--may be they don't know why they don't understand  . The system must then ' guess ' at the likely source of trouble  . This is done by maintaining a model of the discourse so far which includes any assumptions made about the user's knowledge  . In attempting a repair the system identifies an assumption which may have been mistaken  , then tries to fill in missing knowledge or explain something another way  . For example:
U : Huh ?
S : Don't you know what sort of circuit alight -detector-circuitis ? 
U : N o.
S:OK , A light-detector-circuit is a kind of potential -divider circuit  . Anyway . .
System initiated remediation : Sometimes the system can deduce that the user has a misunderstanding from the user's utterances  ( e . g . , replies to questions ) . 
Then a remediation sequence is initiated by the system using strategies based on work on tutorial dialogues  ( e . g . , \[8\]) . For example : S : What's the output voltage of the light-detector-circuit ? 
U : High.

S : No , a light-detector-circuit is like a heat-detector . circuit except its output voltage depends on the input\]ight-intentitynstead of hear -intensity  . So , what's the output voltage of the light-detector -circuit ?' Fhese examples illustrate different ways repairs may beiniated  , how repair sequences may be structured w : ithinan ongoing dialogue  , and how the system may tress at problems or use standm'd remediation strategies  . 
3.2 System ~ Misunderstandlng ~
Within the dialogue there are also places where the user may ask a question  , but the system may not be able to in ~; er preti . (\[' he system must then choose an app , ' opri . -at ~ repair initiator . In these examples the user's input is in the form of a simple command hmguage---fornat-urnl language input it is even more important o give helpful repair initiators  . 
Object mimm derstood : If the object of the question is misunderstood  , the repair initiators t muld direct attention to that ~ missing ' object : 
U : What-is-alight-circuit ?
S : What . d , ~- ~ what ?
U : light-detector-circuit.
S : OK , A light-detector-circuit is a kind of . .
Ql : ms tion type misunderstood : If the question type is misunderstood  , attention should be directed to that :
U : What is a light-detector-circuit ?
S : What about the light-detector-circuit ?
U : What-is-alight-detector-circuit.
Both misunderstood : If the question is of the right form but both parts are not understood  , the system simply says ' what ?' . 
Wrong form : If the utter ~ nce is not of a recognisable form  ( e . g . , it cannot be . ' parsed ' ) j the system informs the user of acceptable forms ( e . g . , question-type question-obj ) . 
Repeated errors : Repair initiators for repeated errors give : further information  , such ~ lists of relevant object and question types  . 
These simple examples illustrate tile importance of nshtgan appropriate repair initiator when the system fails to understand  . This is important for both command and natural language based input  . 
4. Conclusion
This paper has illustrated ~ tle importance , and some of the problems of repair work in humancomputer dialogues  , hnportant issues include repair sequencing , se~lecting and responding to different repair iniators  , and reasoning about the possible source of the problem and helpful'remediation'strategies  . The example system is fairly simple , though in an evaluation of an early version with menu-based user input  , the interactive/repair based approach to explanation generation proved useful  . Future work on any practical natural anguage di -Mogue system should consider these issues  . 
References\[1\]A . Cawsey . Generating explanatory discom'se . I 11 R . Dale , C . Mellish , and M . Zock , editors , Current Research in Natural Language Generation , Academic Press ,  1990 . 
\[2\]tI . Clark and E . Schaefer . Contributing to discourse . 
Cognitive Science , 13:259-294, 1989.
\[3\] J . D . Moore . A Reactive Approach to Ezplanation in Expert and Advice-Giving Systems  . PhD thesis , Information Sciences Institute , University of Southern California ,  1989 . ( published as ISI-SR-90-251) . 
\[4\]P . Raudaskoski . Repair work in humancomputer interaction . In P . Luff , D . Frohlich , and N . Gilbert , editors , Computers and Conversation , Academic
Press , 1990.
\[51 M . Ringle and B . Bruce . Conversation failure . In W . Lehnert and M . Ringle , editors , Strategies for Natural Language Processing , Lawrence Earlbaum , 
Hillsdale , New Jersey , 1981.
\[6\]E . Schegloff . Some som'ces of misunderstanding in talk-in -interaction  . Lecture to the Cognitive Sciences program , University of California , Berkeley . 
(71 E . Schegloff , G . Jefferson , and H . Sacks . The preference for self-correction i the organisation of repair in conversation  . Language , 53:361-382, 1977 . 
\[8\]B . Woolf and T . Murray . A framework for representing tutorial discourse . In Proceedings of the lOth International Conference on Artificial fntelligence ~ pages  189-192  ,  1987 . 

