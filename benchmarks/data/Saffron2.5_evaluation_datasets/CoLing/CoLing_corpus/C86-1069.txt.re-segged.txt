MACHINELEARNING OF MORPHOLOGICAL RULES
BYGENERALIZATION AND ANALOGY
Klaus Wothke
Arbei LssLe\]le Linguis Lische Da Lenverarbe i Lung 
INSTI\[UIFORDEU TSCHES PRAI ; HE
Mannheim , West . Germany
ABSTRAI:T : 1h is paper describes an experi-menLal procedure For Lheinduc Liveau Loma Led learning of morphological rules From examples  . At First a nou L\] . irle of L he problem is given . Then a Formalism for L here presen-t . arian of morphological rules is defined . 
This Formalism is used by Lheau Loma Led procedure  , whose anaLomy Js subsequently present , ed . Finally t . he performance of t . hesys Lemis evaluat , ed and Lhemos L important . 
unsolved problems are discussed.
l . Ou Lline of Lhe Problem
Learning algorithms for Lhedomain of na Lurai languages were in Lhep as L mainly developed to model Lheacquisition of synLax and Lo genera Lesyn LacLJc descrip Lions flrom examples  ( eL . Pinker 1979~ Cohen/Feigenbaum \ ]982:   494-5  \ ] \ ]  )   . There exist also some sys-Lems which learn rules for Lheau Loma Liephonetic Lranscrip Lion of for Lhographic LexL  ( eL . Oakey/Cawt:horn 1981, Wolf 1977) . Like the system presenLed in L his paper all L hese systemss Lillare exporimen Lalsys Lems  , the inductive auLoma Lic learning of morphologi ~ cal rules has Lill now been inves Liga Ledon ly Loa small degree  . Research on Lhis problem was carried out by Ring  ( 1978 )  , 3snsen-WJnkeln(\]985) and W of hl < e (1985) . 
The task of ' Lhesys Lem described here is Lo learn rules f ' or inflecLion a \] and der iva Lional morphology  . The system is naL designed as as Landard program  , but as an experimen Lal system . It\]s used For Lheex-perimen La \] deve lopment and t  , he Lesling of fundamen Lala \] gori Lhmic learning st  . rat . egies . 
Lat . ertheses L rategies could perhaps become necessary components of a standard \]  . earning program devised For LheinteracLive develop-men L off \] ingu is LJ c algorithms For Lhedomain of morphology  . 
Input : Lo Lhesys Lemisase L of exam-plesca lled a learning corpus  . Each example is an ordered pair of words . We call the f'irs L word of each pair L he source  . \[ he second word is called Lhet . argeL . Be Lween the source and Lhe Large L of each given pair L here musLexist : an infllect  , ional or a derivational morphological re la Lion  . By ap- . 
plying t . he processes of generallza Lion and de LecL ion analogies Lhesyst  . em has to con-sLruc Lase L o6 insLruc Lions which describe on a purely graphemic basis how Lhe Large L of each pair is genera Led From the source  . 
(SemanLic feaLures o f morphemes are aL presenL ignored by Lhesys Lem  . ) Such a seL of inskrucLions should not only genera Le correcLLarge LsFor the sources given in the learning corpus : The insLrucLions should also genera Le correcL targe Ls for Lhemajor-iLy of L he sources not in L he corpus which part  . icJ paLe in L he same inflectional or der Jva Lionalrela Lienshipas Lhesource-Large L -pairs JnL he learning corpus  . Suppose For example LhaLL he Following learning corpus is FedJnLoLhesysLem : " assembly '" baLh " box " " boy " " bus " " bush " buzz " cal f " copy " " door " Field "' house '" knife " " lady " " moL her " " swi Lch ' " un iversiLy " " assemblies " " baLhs " " boxes "" boys " buses " bushes buzzes calves copies cr ies " doors " " fields " houses " knives " lad les"moLhers'"swiLches'"unJversiLJ es " 
Figure \].
Int . his case kilo learning algori Lhm has Lo consLru clase t  . of finst . rue Lions which gener-ales fior each singu larnoun  ( = SO Lirce ~ in Lhele FL column ) of : L his corpus as Lring which is iden L ic alw  . tL ht . he corresponding plural Form (= Large L , in the righ L column ) . 
Fur Lhermore , Lheinst . ruc Lions should also gener at , eLhecorrecLpluralFormForL be majoriLy of English singu\]  . arnouns which are not , members of fL hel ~ arnirlg corpus . For in-seance , Lheinslrucl , ions should also gener-aLe " flies " f ' rom " fi\[y '  , " Lables " f ' rom " Lable " , " foxes " from " fox " , " lays " from " Lay " , " classes " From "( ; lass ' , and " thieves " From " Lhief' . Of course L here will also be singular nouns For which Lhe  . tnsL rucLions will no L be a dequa Le . These will include all nouns whose paLLer n off pluraliza Lion is not represenLed by examples in Lhelearning cor-pus  . WiLht . he given learning corpus one to be adequat , e e . g . For the pluralizations " ox "->" oxen ' , " LooLh "->" tee Lh ' , " index "->" indices ' , " foot " -> " feeL " ~ and " add end um " ->" addenda '  . As Lhis example illustrates , the linguistic adequacy of " the insL rucL ions does not only depend on the quall Ly of the automated learnings L rategies but also on the representativity off a given \] earn ing corpus for a morphological pattern  . 
2, Formalism for the ReE resentation of
Mer~ho~ical Rules \] here are two main types of instruction the learning algorithm uses for the formulation of morphological rules : Prefixal substitution in struct ions change the beginning of a source in order to generate the corresponding target  . \] heyhave Lhegener a \]\]' armX->Y/# ( Z ( 1 ) l .   .   . IZ(i )  f .   .   . ~ Z(n )) . 
Such an instruction means : If a source begins with Lhestring X and J fiimmed J  , ately on the right of X follows the str ingZ  (  \ ]  . ) or .   .   . or Z(i ) or .   .   . or Z(n ) ~ then substitute X by Y .   ( '#" signifies the word-boundary and marks the position where X must occur in order Lobe substi  . Lutable by Y , namely at L he beginnings l ' a source ( right off "#" ) and immediate . y before Z (1) or .   .   . or
Z(\].) or . . . at " Z(n)).
~ufflixa . l substJ , tuLion \] nstruc LJ ons change the end of a source in order to generate the corresponding target  . I heyhave the form X->Y/(Z(\])I . . . IZ(J)I . . . IZ(n )) # . 
rhe meaning off such an instruction . is : IF a source ends with the string X and if imme  ( liaLely on L heleft : of X is the str . tngZ (1) or . . . or Z(i ) or . .  . or Z(n ), then substitute X by Y . 
Each seE of " instructions constructed by the learning algorithm Js ordered  , i . e . the later application of the instruct ions to a given source mus ~ be tried in af ixed sequence in order to generate a target : The first applicable prefiix a \] instruct i on in the sequence of prefixal substitut ion instructions must be determined and the f irst applicable suffixal instruct Janin the sequence of suffixal subsLitution in s tructions must be determined  . Then , both must be applied to the source concurrent ly  , thus generating the target . 
the order and application of sets of inst ructions may be illustrated by a small example : Suppose the learning algorithm has consLructed Lhe Following set of instruct ions for the negation of English adject ives  ( these Lislinguistically no LFully adequate  ; "" is the nulls\]ring , i . e . 
the string wiLh the length 0 )  : 2 )  -> ~ ) _> a )  -> 5 )  ->
Figure 2.
il '/#" l " i r '/#--' r " in "/#-~ ( " m " I " p " ) in "/# . __"/#Then the negation of " perfect ' is Formed by First determining tile fJrsL applicable preflJxa \] substitu Lion instruct i  . on : ( l ) is not applicable , since " perfect " does no Lbegin with "1" . 
(2) is not applicable , since'perfect : " does not begin with " r  "  . 
(3) is opp\] . Jeable , since " perfect " begins with " p " , The first applicable sufflixal subst:it : ut Jon instruction Js the only suffixal : instrun LJ on at  . hand , namely (5): " perfect " ends wiLh "' . 
By the concurren Lapp . IJ cation of ( 3  ) and ( 5  ) to " perfect " the target'imperfect " Js generated  , which \] st:henega Lion of " perfect " . 
3, Anatomy of the System for the Aufomalnd Lea . ? ni r?~_9 fi_Mo ~_tip~11 p?icslRu\]es lhesys LemJs written J  . n the programming language PL/I . It has the name PRISM , which is an acronym for " PRogram Fortile In ferennc and SJmula Lion of ' Morphological ru \]  . es' . 
PRISM has the macro structure shown Jn Figure 3  . At an act J vation of PRISM , its main procedure MONITOR at first activates GETOPTN ~ lhJchreads\]:heuser's options For  111o control of PRISM and checks them for synLact Jc we\]\]  . -Formedness and For plaus : ihilJ tyo\[hen MONIIOR activafes L he component indica Led by the user " SCOl/ire\]options  . ~ here are three alternative components : - A learning component which infers sels of Jnst ruel Jons From a \] earning corpus gJ veeby the user of PRISM  . Th : is component comprises the procedures I : It KCRPS  , DISCOV , STMT\[UT , TODSE \] , and others . \] he learning process is performed by DIS ( ' OV . The other procedures perform peripheral functions  . 
A componen LF or the appl : ication of inst ructions ~ hich were inferred by the \]  . earning component , lhis component comprises the procedures FRODSE  \]  , APPLY , 
DERIVE , and others.
A third , marginal component which prepares instract ionsFor their print out  . 
IL consists of FRODSE\[ , SIM\]OU\] , and other procedures . 
The aet : Jvat\]on of the learning algorithm starts with a call of CHKCRPS by MONITOR  . CHK ( RPS cheeks a given learning corpus for formal errors  . The procedure activated next . is DISCOV ~ which performs the learning processes  . DISI ' OV first determines Lhe different types of substitution patterns in the qiven \] earn in q corpus  . Types of "1 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 4"- I . . . . . . . . . . . . . I "! M0NII0R ! .   .   .   .   .   .   .   .   .   .   .   .   .   . > tGETOPTN 4 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . fIr ++ .   .   .   .   .   .   .   .   .   .  +
VVV .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  <  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  + ! +  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  >  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  ~_
VV V\] . earn . i . ng of " app\] . ica Lion of " prin Leut of Lnsl : ruc LJ one i net : rLICt:J  . one ir/sl : ruu Liona !+ .   .   .   .   .   .   .   .   .   . +!- J .   .   .   .   .   .   .   .   .   .   .  + +  .   .   .   .   .   .   .   .   .   . j . !+->! CIIt < CRPS!+->!FRODSFT!!PRODSEI ! <-+ ! +   .   .   .   .   .   .   .   .   .   .   .  +<====/ / ! +  .   .   .   .   .   .   .   .   .   . F <=== //==>+ .   .   .   .   .   .   .   .   .   . +!!/ I . EARN1NG/!/KNOWLEDGE/!!-P .   .   .   .   .   .   .   .   .   . , -/ CORPUS /! ~ .   .   .   .   .   .   .   .   .   .   .  ~ . /BASE /+ .   .   .   .   .   .   .   .   . +!+->\[ DISCOV !<=/+->! APPLY !<==//! SIM IOUT ! <--  , !- P .   .   .   .   .   .   .   .   .   .   .   .   . i ~+ .   .   .   .   .   .   .   .   . F + .   .   .   .   .   .   .   .   .  + ! +  .   .   .   .   .   .   .   .   . + V +-> ! SIMTOUT ! //+ .   .   .   .   .   .   .   .   .  + / / !  . i .   .   .   .   .   .   .   .   .   . +/SOURCES /=>! DERIVE !=> ITARGE r S/!//+ .   .   .   .   .   .   .   .   . +// !" l .   .   .   .   .   .   .   .   .   .   . F+->!IOI ) SET !=> KNOWLEDGE /+ .   .   .   .   .   .   .   .   .   .   .   . +/ BASE /// F . igure , 3 . Macroe Lruc L Lireel PRI SM .   ( For rease llso FlueJdi Ly some macro FeatLI res of PRISM have been  . ignored in L his chart . ) subst , i Lu L:ien psi : barn sace Ehe di Fferen L ( X , Y ) -pairs which are iml ) liciLly presen L in L he learn J , og carpus .   ( For Lhee Labus of ` X and Y cemp are L hede F : in i Liono F the formal  . Jam I ' or L here preeen Lation oF merpholag Jc :a  . lruJeso ) \[ tie second st:ep of \[ ) IS ( ~ ( \] V cemp Li Les L he frequency ef ` each subst .   . i Lu Lionp at Lernin I : heeort Jas . D\]SI~E\]V's learning st . raLegy presur ) poses L ha LL he subsbJl Llt : . ierl pa\[:~:ern soeetlrrJng more I requenf\]  . yJna \] anguage also eecur more Frequently J nLbe\]earn:ing corpus  . Iheref ' or eD1 SCOV creates more general J . nst . rue Liona Per Lhemaref ' requent poLLerna of " ale arrliog corpus and more specific \] liSP  . surE:bOllSfopL he\] . ensf'requenLpatLernsoFo learning corpue ~ J  . o . the conLex Luo\]s bringe Z(i ) of " an Jn , <;Lrue: . i . or ~ X-->Y/#(Z(\])\] . . . 
i Z (: i ) ! .   .   . IZ(n )) or X->Y ~( Z(\] . ) I .   .   . 
tZ (: i ) l .   .   . IZ ( n )   ) ttare l : he more general L he more frequer l t  , ly L heeubs L~t:ul::i , on pat : LeFr ~ ( X  ~ Y ) aee Ur So They are b be more speel f ' . i e\[- . hemerer arely t . heaubs LJt . uL . i . on pal:t , ern occurs . Provided Lha Lalearn : in goo?pus JS represen l  . at : \] veof " L he morpholaqical SUb-at J t  . uLJ on pal:terns of ` a\] . anguage and LheconLexLua \] at . ringsZ(J ), t : hie genera \] . 
sLrat , egyFarLhe de LeaLJon of't . he Z(J ) ' a increases t . he probab JlJLy tha L the inferred : insf . rue I :: ions generate correct targe Ls For sue h sour  (  '  , es as are not . elements oF t , he giver l \] . earrling corpus . D\[SCOV arranges L he subs Lil : ut J nn in a Lructton  , s in such a way t . bat . 
Lhemo renpee if ' J . einst . rue LJ on s precede t : he more general odes . rh is order of ` the in-st . rue Lionsguarant , ees dur J . ngt , he Jr \] alerap-p\]ica LionLhat: pot  , erl Lia \] . ly each tn sl . cL~et , iol/can be applied . SIHTOU \] L rans forms subst:itu-t . ion in strhl cL:ions inferited by I ) IS ( : OV From Lheir in Lerrlal , rel Dresent , a LJen ~ whJc baliens lheir easy and f as L aubomabie brea Lmen L  , into an external represerl La Llon and prin Ls then lou L  . For Lh . tsext , ernaire presen La Llon Lheno Lat , ion is used which was : int : raduced above : in Lhedef ' in Jl : ionsoff thel:wot  . ypesoFsubst , iiu Lionin,s Lruc Lions . F . tna\]\]y TOI ) SE\[slates Lhe ~ I\]a\[~?ill ? ~ , Jone in an exber ns\]knowledge base , From i ~ hieh Lhey can Islet be read by t . heoLher . wo componen Lsoff PRISM ( In Lhel < r loll/led qe base L he J . nsbrLicLJ , ons are seared J . rl the J . rinLet'na\]t'e presenLaLion ) . 
The spp\]l ca Llon component , sLarLs ~/ Jth EROI ) SEI , ~h Jehloads a set . of " insbruc Lions I-obenpp Jied From Lhe knowledge baselo Lheeen Lral memory  . Then l . he Ewe procedures APPLY and DERIVE apply L be in s t  , I . ' uet : ionsLo ~/ or degives by L he user and L here by genera Le Largel  . si ~ / hJchare ~ lJrit : Lento a nou L puL data set :  . \[ heI < i . nd of morphological rela LJ , en be L ween bhe generabed Larget-s and t . he given wards depends on l . heapee if J , csee af ` Jn--sL\['ucl , Jonawhich is applied . 
4 . ~_ La Lu ~ LL ~ n ~_ rL ??_ Sy , ,~Lem \ [ he per f ` ormanee of " PRISM ~ J/as eva luaLed Llnder the Fo\]  , J . u wing cond it . : ions . 
\ ]  . Aseeo Fins Lrucl . Jonestlou . '\ [ dalways generat , ecorrect . Lai ~ gef . sif'iL laapplledLot . hesouz'ces of " L he learning corpus
Fromu/bichi L was inferred.
2 . The larger L he learning corpHs JsF or a given morphoJogical rela Lion  , the hlghar should be on average t . hepercen Lage of " correcl : \] y genet'abed t  . acget : sf ' or such sources as are not : e\ ]   . emenbs of ` the learn Lng carpu , q(buLnevert , heless relation ) . 
3 . A set of instructions inferred From a linguist ically representative learning corpus should generate correct targets for at \]  . east 90% of the sources which are not elements off the learning corpus  ( but which nevertheless participate in the morphological relationship under discussion  )  . 
4 . If a linguistically representative learning corpus is given  , the learning algorithm should classify as regular those morphological patterns which l inguists also usually classify as regular  . 
Condition i is fulfilled . This could be proved deductively with reference to the structure of the learning algorithm  . ( The proof is given in Wothke 1985, 144-154 . ) The fulf i lment of condit ions 24 could only be tested inductively by applying PRISM's learning algorithm to different learning corpora and evaluating the results  . 
Condition 2 was tested by applying the learning component to learning corpora of different sizes compiled For two morphologi-cal relations : derivation of nomina action is from verbs in German  ( e . g . :" betreuen "->"8et reuung') , derivation of Female nouns from male nouns in French  ( e . g . :"spectateur "->" spectaLrice') . With the sets of instructions inferred from these learning corpora PRISM's application component generated targets for a set of words not in the learning corpora  . The statistical results of these tests showed that the percentage of correctly generated targets For such sources as are not elements of the learning corpus is  , on average , the higher the larger the learning corpus is . A Further important result was that the percentage of correctly generated targets is the higher the more regular the morphological relat ion is : The tests yielded better results For the more reguiar derivation of Female nouns from male nouns in French than Fortheless regular derivation of nomina action is Form verbs in German  . 
To test the Fulfilment of the third condition representative learning corpora were manually compiled For the derivation of nomina act ion is From verbs in German  ( 9 . 167 source-target-pairs ) and For the derivation of female nouns from male nouns in French  ( 89 source-target-pairs )   . The two sets of instructions automakieally inferred from these two corpora were applied Lo large sets of sources which were not members of the learning corpora  ( 4 . 793 sources for German , 211 sources for French) . In both cases the percentage of correctly generated targets was iOO ~  . 
Condition 4 was tested with learning corpora for the plural ization of English nouns and For the derivat ion of female nouns from male nouns in French  . An exact quanti-fication of the degree of accuracy is not vague expressions such as " regular " and " usually " My subjective judgement is that the instructions constructed by the learning algorithm For  ( approximately ) representative corpora are quite similar to the morphological regularities described intrad Jtiona I grammars  . This may be illustrated by an example : The learning corpus shown in Figure is approximately representative for the regular pluralization patterns of English nouns  . From this corpus PRISM inferred the
Following set of instructions which represent the most important pluralization rules :  ( l )  " -> " / #  ( 2 ) " f "->' yes '/# ( 3 ) " re " -> " yes .  ' / #  ( 4 ) " y "->" ies '/ ( " d'l " l'i " p'i'r ' ~" t' )  #  ( 5 ) ''-->" ca'/ ( " oh'i " sh't"s'l"x'\["z " ) #  ( 6 ) "'->" s'/#__I
Figure 4.
5 . Unsolved Problems - The Formalism which PRISM uses For the representation of the instructions is designed For the description of graphemie changes at : tile beginning and/or at the end of a word  . Thus this Formalism Js inadequate For the descr iption o ? changes in the interior of a word  . These , however , occur more rarely t_hant ~ he changes at : the beginning or at the end  . A solu-tion to this problem , which could consist . 
in the design of a new Formalism whose express ions could also be \]  . earned automatically , has not as yet : been Found . 
PRISM cannot recognize exceptions in a learning corpus and treat them adequately  . If , for instance , the learning corpus in Figure 1 would also contain the pair ( ' goose ' , " geese ) , PRISM would infer the prefixal substitution instruction " goo " -> " gee '/  #and insert it in the set of instructions shown in Figure  4 before instruction ( 1 )  . 
Furthermore PRISM would infer the suf-
Fixal instruction "'->'"/' ose "  #and insert it before instruction  ( 3 )  . IF this new set of instructions is applied to the nouns " good '  , " goodness " and " goon " the incorrect plurals " geeds '  , " geednesses " and " gowns ' are generated . -It would be preferable for PRISM to identify exceptions as such and store them in a list of exceptions instead of inferring over generaliz ing instructions from them  . 
If a set of instructions is linguisti-cally inadequate  , the user of PRISM must
First make the learning corpus more represent at ive by adding suitable exam-plea  . Then he must activate the learning component of PRISM ~ hich infers a totally new set of instructions  . Perhaps it ~ ould be better if PRISM could infer new instructions only From then e ~ examples and then synthesize the sene ~ instruc-Lionswi Lh the fiormerly inferred and lJnguis Lieal ly in a dequa LeJns Lrue Lions Lo give a new  , more a dequa Lese Loffin-struc Lions . 

Cohen , P . R . /Feigenbaum , E . A . ( Eds ,   )   (  \ ]982 ) : lhe handbook of actiflieia \] Jn-
Lelligence . Vol . 3. London.
Jansen-Winl<eln , R . M . (1985): Induk LJ veskez'nenvanq\['ammaL:i . l < i regeln aus ausgew ~ i ~ . \[- Len Beispielen . In : Savory , S . E . ( Ed .   )   ( 1985 ) : K~nstliche InLel Jigenz und Exper- Lensystome  . \[_ in Porschungsber Jch Lder NJ . x dor FAG , 2nd ed,M\[inchcn/WJ . en ,
PP . 211223.
Oakey , S . / Cawlhorn , R .  \[: .   ( \]981 ) : Inductive \] earning of pronuneiaf . /on rules by hypot , hesLsI . esLing and correct , ion . In : Proceedings of Lhe 7Lh In Lez'na Lian algpint : \[: on Ference on ArLJfJcLal\[n-Lel\]igence  . AugusL 1981 . Vol .  1 . 
PP .\]09-114,
Pinkez "9 S .   (  \ ]979 ) : Formal models of f\]anguage\[earn in cl . In : (: ogni Lion 3 . PP .  217-283 . 
Ring ~ II . (1978): PEI . IKAN-eJnLe\['nsyslemfdr\[ingu JsLi schel < lassi Ftka Lions-a \] gori Lhmen  . In : Nach\]'ie ht-enfldz " Dokumen-
Lat.ion 6. PP . 224-226.
Woif ~ E . (\]977): Vom Buchs Labenzum Laut .   . 
Maschine L\]e Erzeugung und Erpt'ebungy on UmseLzau Lonla Lenam Oeispiel Scht ' JF Leng-l Jsch Phono  . logJse hest . ~ nglisch . 
Braunsehl ~ eig.
WoLhke ~ K , (1984: PRISM User's Gu:ide . Bonn.
( = IKP-A ~ beit . sbe\]~iellLNo . 5) Wot . hke , K . (1985): Maschinel \] . e?rlernung und Simu . \[ aLi ( ~ n morpho . \[ ogischer Ab\]ei Lung . sre-geln . Bonn . (DocLora \] dissel~ta Lion ) . 
A det . aJledt:reaL menLoffLhe\[heme deal L ~ JLbi rlfi his pape L " is given in Wot : hke  ( 1985 )   . 

