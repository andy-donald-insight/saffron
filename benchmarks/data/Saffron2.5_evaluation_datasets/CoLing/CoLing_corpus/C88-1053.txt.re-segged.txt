CI % XT ~' EI ~: a translation : syst ~ fo ~'
agricultural market ~ epo ~:' ts
Pierre \] ~ sabelle
Marcl ) ymetman
Elliott Macklovitch
Centre Canadien de Recherches sur
\] ~ Informatisation du Travail
157.5 Boul ? Chomedey
Laval ~ Quebec
CANADAY TV2 X2
ABS'II~CT
The CRF lq'I~R system is being developed to translate agricultural market reports between English and French  . It is based on a transferm c ~ lel , and designed to be reversible . The source and target language texts are described by means of : a  ) a surface syntactic representation consisting of a tree annotated with feature structures  , built by an extraposition grammar ; and b ) a semmttic representation exhibiting predicate argument structures and constrained by type checking  , builtin parallel with the syntactics tn~cttn'e in compositional fashion  . CRrVIqERS's implementation is still incomplete , but results obtain exts of a rare promising . 
"IOPICAREAS : Machine translation , Logic Cn ' ammars . 
1 . Oural ) pro~tch to the translation problem We are currently developing a translation system with two main objectives in mind :  ( a ) to effectively translate from English to French ( and conversely ) are allife corpus of texts in a restricted sublanguage < Kittredge & Lehrberger  ,  1982> ; and ( b ) to provide a test bed for a theoretica Uymotivated translation model : insofar as possible  , design choices should integrate recent advances in linguistic and semantic theory  . 
The corpus that we are using for our current experimentation is comprised of weekly reports produced by the Canadian Delmrtment of Agriculture  , describing the situation of the livestock and meatrade market in the different Canadian provinces  . 
The following excerpts provide a short sample of the language of these reports : Imports of slaughter cattle from the United States lm't week dropped  62% compared to tire previous week , totalling 334 steers and 50 heifer , < litse maine dernidre , les importations debovins d ' at mttage outchutg de  62% en regard de lase main epr ~ c ~ dente , otalisant 334 bouvillomet 50 taures . 
Inte~ms of its general structure , our translation model may be viewed as being composed of three abstract relations :  ( i ) the source analysis/synthesis relation : an a synt s  ( TS , Surf SynS , SentS ) which defines a set of well of ormed triples , where T . S is a scarce language text , SnffSy~t . S and and Sem_S arems pc clivcly a surface syntactic strnctaru and a semantic structure for this text  , both being source language dependent ;   ( ii ) the target analysis \] synthesis relation : atta syntt  ( T_T , SurfSyn_T , SemT ) which is the attalogue of an asynt_st br the target hmgt mge  ; and ( iii ) the tnms f e , r relation : tr(Sent . S , Sere_T ) which defines a set of couples , whore Seres and ScmT arc respectively source and target senmntic structures that are considered to be translationally equivalent  . 
The an asynt_s and an a syntt relations arc formally and computatioually described using the-framework of extraposition grammars < Pereim  1981>  , while the ~' relation is defined through a set of definite clauses  . An important featm'c of our approach is that each of these an asynt relations is in fact reversible  ( cf the reversibility condition of < L ands bergen 1987>  )  . Practically speaking , this means that a single system is usable for both English to French and French to English translation  . From a theoretical viewpoint , reversibility is a strong criterion of linguistic adequacy for a grammar  . Typical existing parsers are based on granmmrs that  ( sometimes grossly ) overgenerate : the grammar writer assumcs a high degree of well-tonnedness in the input text  . Conversely , typical existing generators tend to undergenerate : the grammar writer makes arbritrary choices in the parapt ! rasc system of the language  . A reversible grammar is of necessity closer to observational adequacy  . 
2. Representations
The CRITTER system assigns each textual unit a representation that describes both its form  ( graphological , morphological , syntactic ) and its semantic content . 
2.1 Syntactic Representations
The syntactic representation associated with a textual object is a fairly standard surface structnre tree which may include traces in places where a  ( long-distance ) dependency holds between some displaced phrase and a gap  . Since we adopt a monostratal view of syntax , no other level of syntactic representation is tn ' ovided for  . 
The representation scheme is based on a variant of the feature structure approach  ( Sag & al . , 1986) . Each node of the smfi~cetree is represented as a feature structure which includes  , among others , cat ~ m daughters attributes . 
Using familiar tree notation , our current grammars would assign sentence (2 . a ) the representation (2b ) : (2 . a ) Last week , hog prices in S ask at chewanic reased 5% at $69 . 00 . 
2gl (2 . b ) odv_pad plast tueek'$np<NI3R:plur, . . . :> up
Phogi < NI 31R : plur,
TENSE : pasl , 8UI\]CKf: . . > ~ .  '~,_  . , : NBR:plur , TEN . qE:pasl , SO . AT . .,> ,~ ~"~-~'~"- b . 
illeas_p"1nP<NBR:plur,<TYPE:proNr . .:> TENSE : past , $ UBCAT : . .:> n
IIYPE : proNr, . . . > peicenl prices in S as katche wan increased 5%
PP pme~s_p price
This structure is more or less in line with current syntactic theories  . 
Note that it reflects a three-level X bar convention  . Occasionally , idiosyncratic features are adopted so as to account for the peculiarities of the sublanguage we are dealing with  . This is the case for the complements measw and pp under v '  , which do not correspond to the usual subcategorization pattern for the verb ' increase '  . 
2.2 Semantic representations
Formally , our semantic representations are trees--or more exactly  , directed acyclic graphs , for structure-sharing is allowed in cases of coreference -- in which nodes are labelled with semantic units that often  , but need not , correspond to the lexemes of the language represented  . We introduce abstract semantic units to account for some lexical gaps  , morphologically marked semantic notions , etc . The arcs are labelled either by argument numbers ( 1 )  ,  (2) ,  (3)  . . . . . or by " inverse " argument numbers ( inv-1) , ( inv-2) . . . .
The interpretation of this notation is made easier if one considers as an example the semantic structure in Figure  ( a )  , which is associated with sentence (2 . a ) : " Last week , hog prices in
Saskatche wanicreased 5% at $69": increase ( inv-l )  13 )  11 ) 695 last week ~5% price . 
i ) ( inv-l ) hogAt
I(2) saskatche wan
Figure ( a ) -' A t ' ,  '5%' , '695' are abstract semantic units ; -' last week ' is treated as a single unit , which is justified by the fact that it plays the role of a frozen in dexical in our sublanguage  ( as ' yesterday ' does in the standard language )  ; - the (1) ,  (2) , (3) labels correspond to argument positions , either of predicates ( like ' increase ' , treated as ; a 3-place predicate ) or of functions ( such as ' price ' , which takes a commodity as first argumen 0 ; the ( inv-1 ) labels correspond to " inverted " argument relations  , which implies that ' increase ' is in first argument position relative to ' last week '  , and that ' price ' is in first argument position relative to ' At '  ,   ( ' Saskatche wan ' being the second argument of ' A t '  )  . 
Labels of the " inv " kind are a notational device which makes it possible to simultaneously read two representational levels of fasingle semantic structure : a first level which expresses predicate-argument relations  ; and a second level which is reminiscent of the subordination of syntactic groups  . Thus ' last week ' is a syntactic dependent of ' increased '  , and ' in Saskatche wan'is a syntactic dependent of ' prices '  . There are two reasons for choosing to reflect subordination in the semantic structure : first  , we want to maintain a treelike character for the semantic structure  ( unique root , no cycles ) . This is technically related to the fact that transfero'ucially depends on a root-to-leaves recursive traversal of semantic structures  . Second and much more important is the fact that subordination does have semantical import  , although in a way which is note un'ently very well understood  . 
Semantic structures have to obey a wellformedness criterion  , which consists of the checking of semantic type agreement between a predicate  ( or functional ) node in the stract nr ( ~ and its argument nodes . Defining semantic wellformedness involves a semantic lexicon  , a semantic type subsumption hierarchy , and semantic well-Jbrmedness rules . The seax ~ briefly described in sections 3 . 3 and 4 . 3 below . 
3. ~ Ilae lexicon
CRITI'ER's lexical component is made up of a basic dictionary of morpho-syntactiel xieal units  ; a rule component which extends the morphosyntactic dietion my  ; and a diction ea'y of semantic-level units . 
3, 1 The morgho-syntacfic detion m-y
This dictionary lists lexical items in citation form and assigns them morphological nd syntactic properties  . It is also resptmsible for effect hlgthetrmpping of these lexical milts onto these manfie devel units  , whose properties are describe diu a sepm ~ ate dictionary  . Moq , hological p ; operties include an inflectional class and an indication of any morpho-  . synct actic idiosyncrasies . 
Syntactic W ~ Perties ~ tft ~ etn N ~ rised of a subcategorization fra ~ tw mida collection of syntactic feattu'es  . The subcategorization frame of a lexical head describes the number and syntactic type of the phrases governed by that head ? These fiames refer directly to positions in serrates ~ ructm'e ~ sim  ; c this is the only level of syntactic representation admitted in our systen LV crbs  , for example , can henlarked fbra maximum of three positions : a subject and up to two eo/npleme ilt :  ;  . 
The mapping onto sematltic units is effected by associating each lexi  ( : a ) ~mtry wilh a semantic schema . This schema is made up ~ Ja semantic refit ( represented as a\[imcto:\['with a fixed arity )  , and a ~ i ~ Micatio ~ of the ~ elatiom ; hip of the arguments to lhele xi ca\]unit's syntae  , i(:dependents . 
hieach lcxical cnhy , this complex of morphological , syat actiemd set nantie:infi ) rmation is specified as a features ttue ttue . ' it'~f is feature st ~ uetm giscucoded as a Prolog term that wc deserx be indirectly  , by means of predicates which access the relevam athibute values  . For example , the syntactic and semantic properties el the verb ' promise ' coukt be represented as a term T  , described as \[ bllows : (3 . a ) eitat , on . tbnn(T , promise ) , subcat(T , \[ NPI , NP 2 , VCOMP\]) , cat ( NP l , up ) , sereform ( NP l , A ) , cat ( NP . 2 , up ) , serefonn ( NP2 , B ) ~ cat(VCOMP , vp ) 0 vfo ~: Jn(VCOMP , infinitive ) , sere . folm(VCOMP , C ), conyol(VCOMP,NPI)~sere . .term(T , promise '( A ~ B , C )) The predicates citadon form , ca 6 subcat and semform simply acce : ; : ; the value of an attribute of the same name in the term T  . The subc:q attribute h ~ Ls a value of the list type  , asi ~ , < Poll , ' u'd & Sag ( 1988 ) : ~ Syntactic ~ ules will unify the elements of this list with the complements of the lexical head  , therebyent brcing the appropriate ~ uh categorization restrictions  ( e . g . the " cat " of the sceond complement of ' promise ' is vp  )  . 
'\[' ak ~ n together the subcat and sen ( form attributes account fi ) ran essential part of the syntax/semantics mapping  . According to the description given for ' pronrise  '  , the semantic objects associated with the sut ~ iect  , he object and the infinitival complement are respectively mapped onto the first  , second and third argument of the semantic predicate promise '  . 
All I he resources of clausalogic can be invoked to enforce complex relationships between seven fl feature structures  . For example , the predicate conCrolused in (3 . a ) above is defined in such a waya ' . ; to ensur ~ that these re . jbrm and agree values of the controller mttch those of the subject slot in the subcat of the commlled w : ~ b phrase:  ( 3 . b ) com ? ~ fi(CONTROLI . EE , CONTROL\[ , ER ) :-: ~ ubcat(CONTROIA , EE , \] ISUJ , X , Y \]) , : ~ em . .~ brol(SUJ ~ SF ) , : ~ emform ( CONTROLLER , SF ) , agree ( SUJ , AG ) , agrce ( CONTI~_OLLER , AG ) . 
The ?' ont ~ ol statement of (3 . a ) will thereby ensure that the . ~mbject of'p ~ omise ' and the understood subject of its infinitival eomt  ) lemcnt me the same ~ ntity . 
3.2 Morphologicalnd lexical roles
The rnorpho-synt actie dictionary is extended by three sets of rules that handle inflection  , derivation and lexical transformations . Our description of French inflection is based on the work of Bourheau & Pinard  ( 1986 )  , which provides an exhaustive speeifieation f the inflectional properties of more than  50  , 000 French lexieal items . We have also developed a parallel description for English inflection  . 
We currently employ a rule-based treatment of derivafional morphology only for the most productive classes  , such as comparative and superlative adjectives , '- ly'adverbs , etc . On the other hand , we make extensive use of lexieal transformations to handle phenomena such as passivization  , subject-to-subject and subject-to ~ object raising , in transitivation , dative-shift , etc . Given the scheme described above for lexical subcategorization  , most lexical transformations can be seen as simply altering the subcategorization pattern of the lexical entry  . 
For example , given the lexical specification (3 . c ) for the object-raising verb ' believe ' , ride (3 . d ) has the effect of generating the two " virtual " dictionm3r entries ( 3 . e ) and (3 . 0 . 
(3 . c ) diet(T ) :- citation form(T , believe ) , suj to obj_raising_verb(T , A , B ) , serefolm ( T , believe ( A , B)) . 
(3 . d ) subj to_obj raising yerb(T , A , B ) :-% standard t0rm subcat(T , \[ NP , S ,  \[ \]\]) , cat ( NP , np ) , sem_forIn(NP , A ) , cat(S , sbar ) , complementizer ( S , that ) , semform ( S , B ) . 
subj . _to obj raising_ . verb(T , A , B ) : ~% raising form subeat(T , \[ NP 1 , NP 2 , VCOMP\]) , cat ( NP1 , up ) , sereform ( NP1 , A ) , cat ( NP2 , np ) , sereform ( VCOMP , B ) , cat ( VCOMP , vp ) , form ( VCOMP , infinitive ) , control ( VCOMP , NP2) . 
(3 . e ) (3 . 13 citation_form(T , believe ) , subeat(T , \[ NP , S ,  \[ \]\]) , cat ( NP , np ) , sereform ( NP , A ) , eat(S , sbar ) , complementizer ( S , that ) , sereform ( S , B ) , sern . form(T , believe(A,B )) . 
" Tom believes that Billis dishonest . " citation_form(T , believe ) , subcat(T , \[ NP 1 , NP 2 , VCOMP\]) , eat(NP l , up ) , serefonn ( NP1 , A ) , cat ( NP2 , up ) , sem_form ( VCOMP , B ) , eat(VCOMP , vp ) , form ( VCOMP , infinitive ) , e outrol(VCOMP , NP2) , sereform ( T , believe ( A , B)) . 
" Tom believes Bill to be dishonest."
The semantic lexicon defines a set of semantic units for each language  ( whether directly realized by a lexeme or more abstract  )  ; describes a subsumption hierarchy of semantic types  ( a partial order of types < So wa ,  1983>) ; and associates with each semantic unit SU an initial semantic type  , this having the consequence that SU belongs implicitly to all higher types in the hierarchy  . The semantic lexicon also defines a set of validating predicate-argument schemas  , of which valid predicate-argument structures have to be instances  . An example of such a schema is : MOVEMENT ( MEASURE-FUNCTION , INCREMENT , MEASURE ) where MOVEMENT , MEASURE-FUNCTION , INCREMENT and
MEASURE are semantic types.
The use of the semantic lexicon to test semantic structure wellformednessi briefly explained in section  4  . 3 . 
4. The Grammars 4.1 Syntactic Rules
CRITTER's grammars assign textual units a feature structure describing both their syntactic form and semantic ontent  . 
As an example , consider rule (4 . a ) : (4 . a ) vbar(VBAR)-->vb(VB ) , complement ( CO1) , complement ( CO2) , cat ( VBAR , vbar ) , subcat(VB , \[SUJ , CO1 , CO2\]) , head of ( VBAR , VB ) . .
The constituent vbar is expanded as a verb and two possible complements  . 
Generally speaking , a complement can be any of a wide range of phrases :  ( 4 . b ) complement(\[\])->\[\] . 
complement ( NP)->np(NP).
complement ( PP)->pp(PP).
complement ( VCOMP)->vp(VCOMP).
Most of the syntactic rules that we use are , like (4 . a ) , based on the simple contextfree skeleton of definite clause grammars  , with the same augmentation mechanisms : nonterminals have arguments and additional PROLOG goals  ( enclosed in braces ) can be stated . The nonterminals in our rules are uniformly assigned a single argument  , whose content is a feature structure , and the PROLOG goals are used to state mutual constraints between these feature structures  . 
In example (4 . a ) , the two complements of the verb are unified with the second and third elements of the subcat list of the verb  , thereby enforcing its lexical subcategorization requirements  . 
The head_of predicate is defined so as to unify the head features of ' the lexical head with those of the larger verb phrase  . Since sem_form is a head feature , the lexical value of sem_form for the verb will be assigned to the verb phrase  . In the process , arguments of the semantic predicate associated with the verb will become instantiated to the semantic objects associated with the complements of the verb  . 
In older to deal with certain more complex syntactic phenomena  , such as unbounde dependencies , we take advantage of the special facilities built into the extraposition grammar formalism  . 
4.2 Syntactic processing
Although the format of our grammatical rules closely resembles the format of definite clause grammars  ( DCGs ) and extraposition grammars ( XGs )  , there are some important differences . 
Because of their direct relationship with clausal logic  , DCGs and XGs have two distinct interpretations : on the one hand  , a declarative interpretation in which they can be viewed as defining a relation between strings and structural descriptions  ; and on the other hand , a procedural interpretation i which they may be viewed in differently as parsers or synthesizers  . 
However , given the standard compilers for these formalisms  , the procedural interpretation f any given set of rules can rarely be used for both analysis and synthesis tasks  . For example , any DCG contaiuing : left-recursive ruls will produce in finite loops when applied to analysis tasks  , although the same grammar may well be suitable for synthesis tasks  . Moreover , in order to obtain reasonably efficient parsers and synthesizers  , it is necessary to control the order in which goals are called in each mode  . 
Our solution to these problems i to retain the use of DCG-like rules which have a well-defined declarative semantics  ; however , we enrich these rules with control annotations which  , while not affecting their semantics , provide a rule compiler with the information eeded to produce both an analysis-oriented and a synthesis-oriented vrsion of the rule  . Left-recursion is el infinated in the analysis version  , and both versions typically display a different ordering of the goals  . The result is that we can actually derive fairly efficient parsers and synthesizers from one and the same grammar  . 
For furtber details on this double-compilation approach  , see Dymetman & Isabelle (1988) . 
~ . 3 Checking of semantic wellformedness In order for a semantic structure built by this compositional process to be accepted as valid  , it must pass a semantic wellformedness check , which involves semantic constraints and the type subsumption hierarchy  . 
This check can be briefly described as follows : for each predicative  ( or functional ) node pn in the semantie structure , having an 1 , an2 . . , as argument nodes , one tries to find a validating schema ( see ?3 . 3) PT(AT1, AT2, . . . .) such that PT is a type subsuming pn , AT1 a type subsuming an l , AT2 a type subsuming an 2 . . . .
For instance , given the semantics lract tne of section 2 . 2~ partially annotating it with the types of each node yields  ( 4 . c) . 
264 (4 . c ) increase MOVEMENT , EVENT ( inv-l )   ( 31  ( i )  ~ " ~ ' " ~ 9 *  ( PRICE-MEASURE , MEASURE ) last week ~5% PERCENTAGE , INCREMENT ) WEEK , TIME-POINT ) p~'ice/~PRICE , MEASURE-FUNCTION ( i )   ( inv-l ) hogAt LOCATIVE , STATE )   ( COMMODITYI ( 2 ) saska~tcheLvan ( MARKET , LOCATION The checking of this structure then involves looking for : - a validating schema for ' last week '  , in this case the schema
TIME-POINT ( EVENT ) -avalidating schema for ' increase ' , in this case the schema MOVEMENT ( MEASURE-FUNCTION , INCREMENT , MEASURE ) - avalidating schema for ' At ' , in this case the schema
AT(PRICE , MARKET ) 5. Transfer
As we have seen , the transfer component implements a relation between two language-dependent smantic structures  . The decision to restric the input and output of transfer to such semantic structures is motivated by a number of considerations  . Pre-theoretically , the very notion of translation implies a linguistic reformulati  ( m which preserves essential meaning . Such abstract intermediate structures also have the practical advantage of simplifying the transfer component  . That is to say , we assume that the analysis component is powerful enough to neutralize certain source language transformations and that a fullfledged synthesis component can take care of such details of target language realization ~ governed prepositions  . 
The transfer component itself is essentially exieal  , with all relevant knowledg expressed in a transfer lexicon  , a sample of which appears in (5 . a ) : (5 . a ) ( i ) eat < -> manger . 
( ii ) miss (1: X , 2: Y ) <-> manque *' (1:Y' , 2:X ') . 
( iii ) walk ( inv-l:a cress ( 2:X )   ) <-> traverser ( 2:X ' , inv-l : $ manner (2: apied )) . 
entry(i ) is straightforward ; entry 0i ) expresses an " argument conversion ": john missesmary <=> mary manqued john  ; entry ( i ai ) expresse a more complex corresl ~ on dane e : john walks across the str  , n : t <=> john traverselarued This lexicon is compiled into a set of Prolog clauses  . The transfer algorithm then performs a simultaneous reeursive root-to-leaves travta'sal of source and target semantic structures  , making use of these clauses to maintain translational equivalence of the source and target structures  . Practically speaking , the result is that when translating from English to French  , for example , as the transfer algorithm traverses the English semantie structure  , the Freneh semantic structure is constructed in parallel  , by progressive instontiations . 
In this way , the transfer process may effect certain restructurings  , but these are lexically triggered : we do not foresee the need for an independent sructural transfer component  , as in ARIANE-78 for example < c . f . Boitet & Nedobejkine , 1981> . 
6. Conclusion
CRI TrER is currently being implemented in QUINTUS Prologon  SUN-3 workstations . At the time of writing , the status of t be prototype is as follows : - morphological descriptions for both English and French are running  , including exhaustive descriptions of the inflectional sysU  , ' ms ; the dictionaries include approximately 500 lexemes in each language , and are expected to go beyond the 1000 mark ; -syntactic descriptions already cover a significant part of the constructions found in the sublanguage  , although much work remains to be done to deal adequately with ellipsis  , complex coordination , etc . ; furthennore , the grammars of English and French are actually used in a reversible manner  , although at the time of writing , they tend to overgenerate in the synthesis mode ; -a simple version of type checking has been implemented  , but work remains to be done on defining an adequate hierarchy of scmantie types  ; -an initial implementation f the transfer component  ( dictionary and programs ) is underway and the first translations should be produced within a few weeks  . 
7. Acknowledgments
The authors wish to thank Lucie Cusson , Bruno Godbout , Francois Perreault and Michel Simard , who have made important contributions to the work reported here  . 


Boitet , C . & Nedobejkine , N : ( 1981 ) " Recent developments in Russian-French machine translation at Grenoble "  . In : 19, 199-271; Bourbeau , L . & Pinard , F .  (1986) . Dictionnaire Micro-informafis ~ du francai ~ . Montreal , Canada . 
Dymetman , M . &Isabelle , P .  (1988) . " Reversible Logic
Grammars for Machine translation ". In
I nternati0ns1 Conference on Thg or ~ tical 8nd Methodological Issues in Machine Translation of No~tral Lan  . L . ~Eg!l . 0 ~, Carnegie Mellon Uiversity . 
Gazdar , G . , Klein , E . , Pullum , G . , Sag I . (1985) Generalized Phrase Structure G . .rammar . Oxford : Blackwell . 
Isabelle , P . & Mackloviteh , E . (1986) " Transfer and MT Modularity " . In Proceedings of Coling 86, Bonn , FRG . 
Kittredge , R . & Lehrberger , J . (1982) eds . : Sublanguage : studies , of language in restricted semantic domains . 
Berlin : de Gruyter.
Landsbergen , J . (1987) Montague Grammar and Machine Translation . Philips Research M . S .  14 . 026, Eindhoven,
The Netherlands.
Pereira , F . (1981) " Extraposition Grammars " . In : Computational Linguistics 7 . 4, 243-256 . 
Pollard , C . , Sag , I . (1988) Information-Based Syntax and Semantics , vol , 1: Fundamentals , CSL Ilecture Notes no 13 , CSLI , Stanford University . 
Sag I . , Kaplan R . , Karttunen L . , Kay M . , Pollard C . , Shieber S . , Zaenen A . (1986) " Unification and Grammatical Theory " , Proceedings of the West Coast Conference on Formal Linguistics  , Stanford Linguistics Association , 
Stanford Unversity.
Sowa , J .   ( 1983 ) Coneeotual Structures : Information Processing in Mindond M~chine  , Reading , Mass : Addison-Wesley . 

