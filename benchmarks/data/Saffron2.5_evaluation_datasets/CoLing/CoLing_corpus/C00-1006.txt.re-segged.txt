The Effects of Word Order and Segmentation on Translation 
Retrieval Performance
Timothy Baldwin and Hozumi Tanaka
27 okyo\]nstil;ul ; e()I " ~ I ethnology
2-1 . 2-1Ooka , yama , Meguro-ku , qlbkyo1 . 52-8552, JAPANtim , tanaka@cl , ca . tite ch , ac . jp
Abstract
This research looks attim cIt'ccts of word order mL  ( tscgm ( mtation onl ; ra . nslation retri(~valt )( ~ r for-III ~\[ . 11C ( ~ . lot " ~ . 111 eXl)erim(:nta . 1 Jal > an(>s(>English(;rm>-lation memory system . Weiml ) lem (' . nt a number of both bag-of-words and word order-s ( msitiv ( ~ s ; imilarity metrics , and test each over charact ( u-l/ased m~d word-based indexing . Tim translation r ( % rieval ) elt ' or mmm ( ~ of ca ( : hsysi ; em ( : ontiguration is ( ~ valuat ( ~ ( 1  ( mq ) iri ( : ally throught lmn ( )ti ( > n of word edit distan ( : ( ~ \] ) ( (  ; W (( IL translation (: ml ( li(lal ; ( ~( ) ul ; lml ; smidtimmo(hd translation . Ore resull ; sin(li (' . at (~( ; hat ( ;   ( : hm'act ( !r-l ) as ( ! d indexing is ( : ( ms is lxmtly sup ( > riot (  ; ( ) wor(l-bas(:din(l(:xing , sugg(:sl ; ing ( ; hal ; s(:glncn-l ; al ; ionis ; mmm (' . cessary luxury in th (', giv(m domain . 
\? or (1 ord (: r-s(:nsi(;iv(:al)i ) roach('sat(:do . monsl ; rat ( : d to generally OUtlt ( ~ r form bag-of-words methods , with som ' ( : cbm guagc segment-lev ( deit distan ( : o , proving th (: most ; (: fl'(:( ; l ; iv ( ~ similarity m ( , ,l;ric . 
1 Introduction
Transla( . iollm ( unorio , q(TM's)m'caw(~ll-(!slal ) lished I , (: (:\] uloliigy wil , llilL ( , h(!hlunal L and na (: hilmld ' an , qla(;iont'rat(' . rnii;i(:s,duo . to the high ( raiLs lat ; ionlit(!-( ; isio IL ( ; lmyafl brd . Esstml ; ially , TM's mealist of translation records ( source la . nguage strings paired with a unique target language translation  )  , which the TM system accesses in sugg csl ; ing a list of target languag (' , translation candidates which may l )( ,  . hell ) t iff to ( ; h ( : translator in translating a given source language input JNaturally  , TM systems h~w (' ~ no way of accessing the (; a . rgcl ; la . nguag cquiv ; fl(m ( ; of t it (: solt r (: (: language input , and hence (; lm list of taut c . l , lanquagct nmslation cmMi ( lat ( : s is det ( : rntined base ( lonsource language similarity between tim ( : urr ( mt input and trml slation examples within the TM , with translation equivalent ( s ) of maximally similar source language string ( s ) given as the translation candidate ( s )  . 
This is based on the assumption that structural att  ( t semantic similarities 1 ) etwe ( mtarg ( : t language translations will be reflected in the original source language cquivalenl  ; s . 
One reason tbr the popularity of TM's is the low operational burden they t  ) (LS ( ~totim user , in that translation pairs are largely acquired automatically  1See  \] ) lanas ( 1998 ) for a thorough review of commercial
TM systems.
from observai ; ion of l ; lm incremental ( ; rmlsl & Lion pro-(:(:ss , and translation cml ( lidates cml\]ml ) roduced on ( hun and almost insf ; ani ; ancously . To suppor this low () v trlma (1 , TM systems must allow first access into the l ) Oixmtially la . l'g(, . - s(:a hTM , lint at the stone time I ) eal ) lc to 1) rc(lict . ranslation similarity with high accuracy . Ilere , th ( n ' ( ~ is clearly a tradeoff between ac- ( : ess/retric valspeed antipredictive accuracy of  (  , here triew flm ( ,  . ctmnism . 2 haditiomflly , resemch on TMr ( ~trieval nmthods has focused on Slme ( l , with lit-( ; 1(~(: ross-(~vahml ; ionf ( ; he accuracy of differ ( mrm clh-ot is . \ Vct > r(~t ' ( uto focus on a c(:tlracy , and t ) r(~s(~ll ( ;   ( ~mlfi Lical data ( ~ vid ( ! ncingtim relative l ) r ( ~di ( :l ; ivcl > O- ( (u~iial of difl'<u' ( mt similarity metrics over different l ) aram ( :t (  ,  . risations . 
In tiffs l ) almr , we focus on comparison of differ ( mr retrieval algorithms for non-segmenting la . nguag(~s,1) ascd around a TI~,Isysi ; cm from . \] alm nese to English . Non-s(!gm(ml ; ing languages are those which ( Io not involved ( :limii ; er s(e . g . spaces ) tmtwe(mwords , and in (: lude . lapmms (:, ( Jhines (: and Thai . W ( : are tmrticularly in t ( ~'r ( ~st ( : ( l in the part timor lhog ( mal1 m-rmnet ( ~ rsofs (  . ,gmentnl ; ion and word order play in the st ) (!cd/a ( : ( : uracy trad ( !-oti ' . That is , 1) 3" doing away with segnl(:ntai ; ion in relying so Myonch\[/t'lc\[ ( l-h~v ( ~l comparis ( m ( character -1 ) ased indexing )  , dow ( : signiti ( :mitly degrade matchtmrt ' ormance , as com-pared to word-level comparison ( word-based indexing ) ? Similm ' ly , by ignoring word order and treating eachs our ( : elanguage string as a " bag of words " , do \ regenuinely lose out over word order-s ( msitive apl ) roacho . s ? The . In ; f in objective of this research is thus ( ; o(te J ; ermine whether the COmlmi , a-tioim loverlmad associated with more stringent approaches  ( i . e . word-based indexing and word order-sensitive al H ) roaches ) is commensura . te with the per-form anccgains they ott'er . 
Tol ) rc cmp t what tollows , the major contrilmtions of this research are : ( a ) empirical evaluation of dif-thrcnt comparison methods over actual JapaneseEnglish TM data  , focusing on four orthogonal re-triew fl paradigms ; ( b ) the finding that , overtile target ; data , character-based indexing is consistently superior to word-based indexing in identii \[ ying the translation candidate mosts in filar to tile optimal translation for a given in lmt  ; and ( c ) empirical verification of timsup remacy of word order-sensitive exhaustiv  ( : string comparison methods over booleaninal ; ch methods . 
In the % llowing sections we discuss the effects a number of both bag-el  ; words and word order-sensitives in filarity metrics  ( ? 3 )  , before going onto evaluate the difl'crent lnethods with character-based and word-based indexing  ( ? 4 )  . We then conclude the paper in Section 5 . 
2 Segmentation and word order
Using segmentation to divide strings into component words or nlori  ) helnesh a stile obvious advml-tage of clustering characters into senlantic units  , which in the case of ideogrmn-based language such as Japanese  ( in the fern 1 of kanji characters ) and Chinese , generally disatn biguates character tnean-ing . The kanji character ' J\[' , for example , can be used to mean any of " to discern /discriminate "  , " to speak/argue " and " avalve " , but word context easily resolve such mn biguity , hit his sense , our intuition is that segmented strings should produce better results than non-segmented strings  . 
Looking to past research on similarity metrics for TM systelns  , a hnost all systems involving a al ) an ese as the source language rely on segnlentation  ( e . g . 
( Nakanmra , 1989; Sulnita and Tsutsumi , 1991; Ki-talnura and Yamamoto , 1996; Tmtaka ,  19971) , with Sate ( 1992 ) and Sate and Kawase ( 1994 ) providing rare instances of character-based systeln S  . 
By avoiding tile need to segment text; , we : ( a ) alleviate computational overhead ;   ( b ) avoid the need to commit ourselves to a particular analysis type in the case of ambiguity  ;   ( c ) avoi ( 1 the issue of ' how to deal with unknown words ; (d ) avoid the need for stemming/lenlmatisation ; a d ( e ) to a large extent get around problems related to the nornmlisa-tion of lexical alternation  ( see Baldwin and Tanaka ( 1999 ) for a discussion of problems related to lexical alternation in Jal  ) anese )  . Additionally , we can use the conml only anl biguous na . ture of individual kanji characters to our advantage  , in modelling seinan-tic similarity between related words with character overlap  . With word-based indexing , this would only be possible with tile aid of a thesaurus  . 
Similarly for word order , we would expect hat translation records that preserve the word  ( segment ) order observed in the in Imt string would provide closer-matching translations than translation records containing those stone segnlents in a different order  . Natur ~ dly , enforcing preservation of word order is going to place a significant burden on the matching mechanism  , in that a number of different substring match schenlat are inevitably going to be produced between rely two strings  , each of which nmst be considered on its own merits  . 
To the authors ' knowledge , there is no TM system operating from Japanese that does not rely on word/segment/character order to some degree  . 
Tanaka ( 1997 ) uses pivotal content words identified , by the user to search through the TM and locate translation records which contain those same content words in the stone order and preferably the stone segment distance apart  . Nakamura ( 1989 ) similarly gives preference to translation records in which the content words contained in the original input occur in the same linear order  , although there is tile scope to back off to translation records which do not I  ) re-serve the original word order . Sumita and Tsutsmni ( 1 9911 take the opposite tack in iteratively filtering out NPs and adverbs to leave only functional words and n latrix-level predicates  , and findtrml sla-tion records which contain those same keywords in the same ordering  , preferably with the same segment types between them in the same numbers  . Nirenburg et al ( 1993 ) propose a word order-sensitive metric based on " string composition discrepancy "  , and increlnentally relax the restriction on the quality of match required to inehlde word lenmlata  , word synonynls and then word hyt ) ernylns , increasing the match penalty as they go . Sate and Kawase ( 1994 ) employ a more local model of character order in modelling similarity according to Ngrams fashioned from the original string  . 
The greatest advantage in ignoring word/segnlent order is computational  , in that we significantly reduce the search space and require only a single overall comparison per string pair  . Below , we analyse whether this gain in speed outweighs any losses in retrieval perfbrmance  . 
3 Similarity metrics
Dueto o111" interest in the efli~cts of both word order and seglnentation  , we must have a selection of similarity l netrics compatible with the various permutations of these two  1  ) arameter types . We choose to look at an unlber of bag-of-words and word order-sensitive methods which are compatible with both character-based and word -based indexing  , and vary the intmt to model tile et l~ects of the two indexing paradigms  . The particular bag-of-word approactles we target a retlm vector space model  ( Manning and Schiitze ,  1 . 999 , p300) and " token intersection " , as ilnple ratio-based similarity n letric . For word order-sensitive approaches , we test edit distance ( Wagner and Fisher , 1974; Planas and Furuse ,  1999) , " sequential correspondence " and " weigllted sequential correspondence "  . 
Each of tile similarity metrics eill pirically describes the sintilarity between two inlmt string stmimidi ~  . ,  2 where we define tmi as a source language string takenfl ' om the TM and i ~  . as the input string which we are seeking to 1hatch within the TM . 
One featnre of all similarity metrics given here is that they have finegraine discriminatory potential and are able to narrow down the final set of translation candidates to a handfld of  , and in n lost cases one , outlmt . This was a deliberate design decision , and aimed at example-based machine translation applications  , where human judgement cannot be relied upon to single out the most appropriate translation from multiple system outputs  . In this , we set ourselves apart from the research of Sunlita and Tsut-sumi  ( 1 . 991) , for example , who judge the system to have been successful if there are a total of  100 or less outputs , aud a useful translation is contained within them  . Note that it would be a relatively simple pro-2Note that the ordering here is arbitrary , and that all the similarity metrics described hereinare commutative for the given implementations  . 
36 cedure to fall ( ) lit the 11111111 ) e1" of Olltt ) llt S to it il loll r case , tly taking tim top n ranking outputs . 
For all silnitarity metrics , we weight different . \] ai ) mm segment tyl ) es according to their exl ) ected impact on translation , in the form of the sweigh , tfllnctioll :
Segmentypes , w cight punctuation 0 other segments 1W ( ' exl ) erinlentally trialled intermediates w cight settings tbrditt'erent characterty l  ) es ( in the case of character-based indexing ) or segment yl ) eS ( in the case of word-based indexing )  , none of which was fomt d to a pl ) reciat ) lyiml ) rove performance . : ~ a . 1 Similarity metrics used in this research
Vector space model
Within our imt ) lenmntation of the reactor space I nodol ( VSM )  , the segment content of each string is ( lescril ) (' . ( lasa vector , ma ( leul ) of 3 single dimension for each segment to k (  , n occurring with intmior in . The . value of each vector eolnt ) onent is given as the weighted frequen ( -y of that token accor ( ling to its sweiqht vahle , such that any nuln ber of 3 given i ) un ( :tuation mark will produce afl'e ( luen ( : y of 0 . The strings in filarity of t ? H , i and in is then detined sistim cosine of the anglel / etween vectors t\[\[~  . i and iT\[t , re-
Sl ) ective ty , calculated as : tT ~ , i , i ~ 5 , cos(t , fi , , , i ; 4-It , lll0 ) where dot l ) roduct and vect ( )r length ( : oin ( :i ( lewil ; hl ; he standard detlnitions . 
The string stmi of maximal similarity are th ( )se whi ( : hi ) roduce then mx in u unv 3h w , for th(!v(~ctorcosine . 
Not (; that VSMc(msi(lers(inlys(' . gmentfre ( tueney and is insensitive to word order . 
Token intersection
The token intersection of tmi 3nd in is defined as the cumulative intersecting fl ' equency of tokens appearing in each of the strings  , normalised according to the combined segment lengths of tm  , i and in . For-really , this equates to : tint(tm ~ , in ): e ? ~_ ~ , l ' lill(f , '?( htnl(\[) , frc qilz ( , )) " m ~( l , , , ~)+> . , , ( i , ,) (2) where each t is a token ( iccurring in e . ithertmior in , freq,(t ) is detined as theswei . qht-l ) ased fi'equency of tokent occurring in strings , and Ion(s ) is tlmaIf anything , weighting downhi , agana characters , fin " example , due to their common occurrence as intlectional suffices or particles  ( as per Fujii and Croft ( 1993 ) ) led to a significant drop in 1 ) eribrmanee . Simihwly , weighting downstop word-like flmetional parts-of -sf  ) eech in , lat ) anese had little eltiect , unlike weighting downstop words in the case of English  ( see below )  . 
segment length of strings , that is the sw cight-1 ) ased COlllltOfseglllellts ( : ( nltained ill . s ' . 
Ast br VSM , the string ( s)tmi most similar t ; ( iinarcthos ( ; which general ; e then laximum value t brtint(tmi , in ) . 
Note that word order does not take any part in calculation  . 
Edit distance
The first of the word order-sensitive methods is edit  dist3nce   ( Wagner and Fisher , 1974; l?hmas and Furuse ,  1999) . Essentially , the segment-lms edit distance 1 ) etwecn strings t'ln , i and in is the minimun l numl/er of prilnitive edit operations on single segments required to transtbrmt mi into in  ( and vice versa )  ,  1 ) as edUl ) On the ol ) erations of segment equality ( segment stmi , m and in , are identical ) , segment deletion ( delete segment afl ' Ol Ila given 1 ) osition in string . s ' ) and scgmc'nt insertion ( insert segmen ~ ( t into a given position in string . s ) . The cost associated with each ol ) eration on segment a is defined ~/ S : 4
Operation Cost segment equality ( ) segment deletion swcigh , t(a)s(;gment insertions w cigh , t ( a ) Unlike other similarity metrics , smaller v31ues indicate greater similarity for edit distance , and identical strings have edit distmme 0 . 
The woMorder sensitivity of edit distance is per- \]ml  ) St ) est exeml ) litie ( ltly way of the following exam-1 ) le , where segment delimiters are given as: . ' . 
(1) E-SN-14-': winter r3 in " (2a)2F-$51 . l + " summerrain " ( 21 ) ) 1+" SN - 2F " a rainy summer " Itere , the edit distance from ( 1 ) to ( 2a ) is 1-t-1 = 2 , as one deletion ol/e ration is required to remove E\[\]: uyu\]"winter " and one insertionol  ) eration required to 3dd2F\[natu\]"summer " . The edit distance from (1) to (21/) , on the other hand , is 1+1+1+1 = 4 despite ( 2b ) being identical in segment content to ( 2a )  . In terms of edit distance , therefore , (23) is adjudged more similm " to (1) than (21)) . 
Sequential correspondence
Sequential corres I ) ondence is 3 measure of them 3x-in nunsubsl ; rings in lilarity lmtweentmi and in , normalised acc ( irding to the comt ) ined segment lengths h' . n(tmi ) and len(in ) . Essentially , this method requires th3t all substring matche submatch ( tmi , in ) between tmi and in be calculated , and the maximum scq corrratio returned , where scq corr is delined as: ,   . , 2?max\[su?,mateh(tml,in)\[~~"m~It . ,, . ) + t  ~ . (~ , )  ( 3 )   1Note that dm costs for deletion and insertioil must be equal to maintain commutativity  . 

IIer e , tile cardinality operator applied to submatch ( tmi , in ) return stile combined segment length of matching substrings  , weighted according to sw cight . That is : I ~, ~ . . . . . t ~( ~ . , ,~ . ~, ~) I = ~, j ~ . . . . igl~t(s , ~ j , ,~) (4) for each segment ssj , t ~ of each matching substrings s jG submatch ( tmi , in ) . 
Returning to our exmnple from above , the similarity for ( 1 ) and ( 2a ) is 2x22 whereas that for ?3+3--g ( 1 ) and ( 2b ) is ' ) x  ~ ,  3+3 ~ :~"
Weighted sequential correspondence
Weighted sequential correspondence -- the last of the word order-sensitive methods --~ is an extension of sequential correspondence  . It attempts to sut ) plement the deficiency of sequential correspondence that the contiguity of substring matches is not taken into consideration  . Given input string a ~ a2a . ~ a / , , for example , sequential correspondence would suggest equal similarity  ( of ~ ) with string sa ~ ba ~ ca : ~ da/ , and a jap . a3 a 4cfg , despite the second of these being more likely to produce a translation at  ; least partially resembling tlmt of the intmt string  . 
We get around this by associating all incremental weight with each matelfing segment assessing the contiguity of left-neighl  ) our ing segments , in the manner ( Inscribed by Sato ( 1992 ) for chaxact cr-based matcl fing . Namely , the kth segment of a matched substring is given the multiplicative weightrain  ( k , Max ) , where Max was set to 4 in evaluation after Sato . I submatch , (tmi , iu , ) lfi'om equation (3) thus t ) ecomes : ~ s s j ~ t , rain(k?sw cight( . ssj,~ . ) , Ma , z ) (5) t breach sul ) strings s j ~ submatch ( tmi , i77 , ) . \? esiln-ilarly modifytile definition of the leaflmction for a strings to : lea  ( s ) =- Ejmin ( j xs weight (  . , ' j ), Max ) (6) for each segment . sj of s . 
3.2 Retrieval speed optirnisation
While this paper is mainly concerned with accuracy  , we take a moment outhere to discuss the potential to accelerate the proposed methods  , to get a feel for their relative speeds in actual retrieval  . 
One immediate and effective way in which we can limit the search space for all methods is to use the current op-ranking score in establishing upper and lower t  ) ounds on the length of strings which have the potential to better that score  . For token intersection , for example , fi ' om the fixed length lea ( in ) of input string in and current top score a , we can calculate the following bounds based on the greatest possible degree of l natch between in and tmi : Upperbout  , d : le , ~(t . ~ d </ ( ~-~ ) ~ n ( ~'~ ) J ( 7 ) LCZ_Falen ( ' in ) 7 Lowerbound : len ( tmi )  > ,  2 - (  ,   , (8) In a similar fashion , we can stipulate a corridor of allowable segment lengths for t in i  , for sequential correspondence and weighted sequential correspondence  . 
For edit distance , we make the observation that tbracurrent minimum edit distance of a  , the following inequality over Icn ( tmi ) inust be satisfied for tmi to have a chance of bettering ct : len  ( in ) - ~< len ( tmi ) < len ( in ) + a ( 9 ) We can also limit the numl ) er of string comparisons required to reach the optimal match within  , by indexing eacht mi by its component segments and working through the component segments of in in ascending order of global fi'equency  . At each iteration , we consider each previously unmatched translation record containing the current segment token  , adjusting the upper and lower bounds as we go , given that translation records for a given iteration caiulothm recontained segmen tokens already processed  . The maxinmm possible segment correspondence b tween the strings is therefore decreasing on each iteration  . 
We are also able to completely discomlt strings witl no segment component conunon withiTt in this way  . 
Through these two methods , we were able to greatly reduce the number of string comparisons in word-based indexing evaluation for VSM  , token intersection , sequential correspondence and weighted sequential correspondence methods in particular  , and edit distance to a lesser degree . The degree of reduction for character-based indexing was not as marked  , due to the massive increase in numbers of l ; ranslation records sharing some character content within  . 
There is also considerable scope to accelerate the matching mechanisms used by the word order -sensitive approaches  . Currently , all approaches are implemented in Perl5 , and the word order-sensitive approaches use a naive  , highly recursive method to exhaustively generate all substring matches and de-tern fine the s in filarity for each  . One obvious way in which we could enhance this implelnentation would be to use an Ngram index as proposed by Nagao and Mori  ( 1 . 994) . Dynamic Programming ( DP ) techniques would undoubtedly lead to greater efficiency  , as suggested by Crmfias et al (1995 , 1997) and also
Planas and Furuse ( this volume).
4 Evaluation 4 . 1 Evaluation specifications Evaluation was partitioned off into character-based and word -based indexing for the vm ' ious similarity methods  . For word-based indexing , seginentation was carried out with ChaSenv2 . 0 b ( Matsmnoto et al . , 1999) . No attempt was made to postedi the segmented outtmt  , in interests of maintaining consistency in the data  . Segmented and non-segmented strings were tested using a single program  , with segment length set to a single character for non-segmented strings  . 
As test data , we used 2336 unique translation records deriving fi'om technical field reports on construction machinery translated from Japanese into English  . Translation records varied in size from
BASEl ) 1NI ) EXING\~)~()1/J)-


Similarity metric
Vector space model (0.5)
Token intersection (0.4)
Edit distance (/ cn(in )) -
Sequential corr . (0.4)
Weighted seq . (: or r . (0.2)
Vector sllace model (0.5)
Token intersection (0.4)
Edit distmme(h,n(in~-
Sequential corr , (0.4)
Weighted seq . corr . (0.2)
Accuracy 44.0 44.3
Edit diserep.

Ave , outputs 1 . 04 (0 . 97) 1 . 01 (0 . 99) 1 . 39 (0 . 80) 1 . 02 (0 . 98) 1 . 04 (0 . 97) 50 . 2 46 . 6 45 . 6 43 . 7 (-0 . 8%) 43 . 0 (-2 . 9%) 47 . 3 (-5 . 9%) 43 . 1 (-7 . 4%) 40 . 7 (-10 . 7%) 5 . 21 3 . 12 2 . 03 3 . 06 3 . 30 1 . 17 (0 . 91) 1 . 01 (0 . 99) 1 . 90 (0 . 69) 1 . 01 (0 . 99) 1 . 14 (0 . 92)

time 2 . 14 2 . 24 4 . 75 3 . 20 4 . 10 0 . 76 0 . 88 1 . 00 1 . 10 1 . 2 4 Table 1: Results for the different similarity metri ( :s under character -1 ) ased and word-based indexing single-word technical terms taken  f1'Ol12 SI~technical glossary , to multiple-sentence strings , at an averages e . glnent length of 13 . 4 and average character length of 26 . 1 . All . lapane , sestrings of length 6 chara (: tersor more ( al ; ol ; al of 1802 strings ) were extracted fl ' om the Ix ; stda . ta , leaving are si(hlegh ) ssary ofte(:hni(:al1 ; erltls ( 533 strings ) as wew ( nfld not CX l ) e ( ' t to find use , hllnlat (: hesin the TM . The retrie , vala (: curacy()\ , or the 1802 hmger strings was then v critied t ) y\]0-fokt ( : ross w flidation , including the glossary in the test TM on each iteration  . 
Not ( ; that the test data was llre-1 ) artitioned into single technical terms , single sentences or sentence clusters , each constitut ; i21 gasingle translation record . Partitions were taken as given in evaluation , whereas for reM-worhlTM systems , timautomal ; i(m of this i ) 2"() cess ( ; Oltll ) l'ises ; tllil 211) or tall l ; CO lill )( ) ll(1Ilt of the (/ veralls ysI ; ( mL1) re (' , eding translation rel , ri(;val . 
While ackn ( ) wh ; ( lging the ilnl ) or t ; an (: ( ; ( ) f this step and its in t ( ; ra(:l ; ion with r(?ri ( ; val 1) or \[ ormall (: ( ;  , we (: boost , to sidestel ) it for the lmri ) os ( ~s of this pal ) c . r , and leave it for hltm (; resc . m(:h . 
In an effort to make evaluation as ol ) je ci ; ive and empirical as l ) os sibh ;  , apl ) r ( )i ) riatencss of translation candidate ( s ) lrOl ) OSed by the different metri ( : s was evahmted according to the mil2inlunl edit dis-tahoe between the translation candidate ( s ) and the unique model translation . In this , we transferred 1 , t2(; edit distance , method described M ) ovedirectly across to the ta . rg ( % langust ge , ( English ) , with segments its words and the fl ) lh ) wings ' weight schema :
Segmenty pet mnctuations top\VOl'dS other words sw cight SMART  ( Salton ,  197\] . ) stop word l ist ) The system output was judged to be correct if it contained a translation optimally close to the model trmMation  ; the average ol ) timal edit distance h ' onl the model translation was  4  . 73 . 
'5\[tp://fl , p . corne , ll . cs . edU/l ) Ub/smart/english , stop We set ; the additional criterion that the difl'erent metric should be able to determine whether the top-ranking translation  ( :m Mida . teis like Jy to be use fl fl to the translator , and that no outlmts houhllm given if ' the chlsestnmt  ( ' hing translation record was outside a certain l ' ~/ Ilg  (  ~ . Of " transla . ti(muscflflness ' . Inp2"ac-tice , this was set to the , edit distance between the model translation and the empty string  ( i . e . thee . dit(:()st ; of creating th ( ; model translation fl ' ( nns (: ratch ) . 
This cut ; off'1 ) oin tvlts realised for the different similarity metrics by thrcs hohling over the similar it  . yscores . The ditferent hreshold settled Ull ( m experimentally for all similarity metrics are given illt  ) ra ( : k-cts in the second column of Table 1 , with the thresh-ohl for ( ; ( lit , distance dynamicMly sett (/ the edit dis-lane ( ; l ~ etween the input and time ml ) ty string . 
\ Veset(mrs ( ; \] vesal ) art \]' IX ) 211 COIlV ( ; 21I ; i ( ) II sll 2 '( ~ S ( ; D . l'('h () nTMr ( ; hievall mrl'o2unan(:( ; in a ( lol ) ting this ( ) l / - . i(;(:li\'(;mmmrical(~vahmti()n method . Traditionally , r(:i . ri(~vall ) erformalm(~has1)(!e , ngauged 1) ytlm sub-j ( ~(: t ; iv ( ; usef lfln ( ; ss of the closest matching e . lenmnt of the syst ; (~ lllOUtlmt(asjudged1) ya . hunm , d , mid described by way of a dis (: reteset ; of transla . tion(lualit ; ydes('ril ) tors((; . g . ( Nakm2mra , 1989; Smnita and Tsut-smni , 1991; Sato ,  1992)) . Perhaps the closest evaluation a . tte2nt ) t so what we prol ) ose are those of ' Planas and Nn'use ( 1 . 999 ) in s ( ! tting a mechanical cutoff for " translation usability " as the al/ility to generate the model translation from a given translation candidate  1  ) yediting less than half the component words , and Nirenburg et al ( 1993 ) ill calculating the weighted mmt be r of key strokes r  (  ; quire xl to conver the system outllut into ; map l ) ropriate translation for the original inllut . Tile method of Nirenburg et al ( 1993 ) is certainly more indicative of t : rue target language usefll ll ness  , but is dependent 022 the coml ) etence of the translator editing the TM system output  , and not automated to the degree our method is . 
4.2 Results
The results for the different similarity metrics with character-based and word-based indexing are given in Tal  ) le1 , with the two bag-of-word sal ) t ) roaches partitioned off from the three word order -s  ( msitive al ) I ) roaches to rea ( : h indexing paradigm . " Accuracy " is an indication of the prol ) or tion of intmtsf br whi ( : hbased indexing accuracies in bold indicate a significant ~ advantage over the corresponding wprd-based indexing accuracy  , and figures in brackets for word-based indexing indicate the relative pert ' or maime gain over the corresponding character-based indexing configuration  . " Edit discrep . " refers to the mean minimum edit distance discrepancy between translation candidate  ( s ) and optimal translation ( s ) in the case of the translation candidate set contain iuguo optimal translations  . "Ave . outputs " describes the average number of translation candidates output by the system  , with the figure in brackets being the proportion of int  ) uts for which a unique translation candidate was produced  . "Ave . time " describes the average time taken to deterl nine the translation era > didate  ( s ) for a single output , relative to the time takent br word-based edit distance retrieval  . 
Perhaps the most striking resultisttmt character -based indexing produces a superior match accuracy to word-based indexing t brall similarity metrics  , at ; a significant margin tbrall three word order -based methods  . This is the complete opposite of what we had expected  , although it does fit in with the findings of Fujii and Croft  ( 1993 ) that character-based indexing performs comparably with word-based indexing in Japanese information retrieval  . 
Looking to word order , we see that edit distance outperforms all other methods for t  ) oth character - and word-based indexing , peaking at just over 50% for character-based indexing . Tile relative performance of the remaining methods is variable  , with the two bag-of-words methods being superior to or roughly equivalent to sequential correspondence and weighted sequential correspondence t br word-based indexing  , but tile word order-based methods having a cleat ' advantage over the bag-of-words methods for character-based indexing  . It is thus difticult to draw any hard and fast conclusion as to the relative merits of word order-based versus bag-of words methods  , other than to say that edist distance would appear to have a clear advantage over other methods  . 
The figures for edit discrepancy in the case of non-optimal translation candidate  ( s ) are equally interesting , and suggest hat on the whole , the various methods err more conservatively for character-based than word-based indexing  . The most robust method is ( source language ) edit distance , at all edit discrepancy of 1 . 82 and 2 . O3 for character-based and word-based indexing , respectively . 
All methods were able to produce just over one translation candidate on average  , with all other than edit distance returning a unique translation candidate over  90% of the time . The greater number of outtmts for the edit distance method can certainly be viewed as one reason for its inflated performance  , although the lower level of mn biguity for character-based indexing but higher accuracy  , would tend to suggest otherwise . 
Lastly , word-based indexing was found to be faster than character-based indexing across the board  , for the simple reason that the immber of character seg-~As determined by the paired t test  ( p < 0 . 05) . 
ments is always going to be greater than or equal to the number of word segments  . The average segment lengths quoted above (26 . 1 characters vs .  13 . 4 words ) indicate that we generally have twice as many characters as words in a given striug  . Additionally , tile acceleration technique described in ?3 . 2 of sequentially working through the segment component of the input string in increasing order of global frequency  , has a greaterett > ct for word-tmsed indexing than character-based indexing  , accentuating any speed disparity . 
4.3 Reflections on the results
An immedia texl flanation tbr character-based in -dexing's empirical edge over word-basediudexing is the semantic smoothing effects of individual kanji characters  , alluded to above (?2) . To take an example , the single-segment ouns A ': n\[ s6sa \] and: ng0 \[sadS\]both mean " operation " , but would not match under word-based indexing . Character-based indexing , on the other hand , would recogifise the overlap in character content  , and in the process pick upon the semantic or resi ) on deneebt ween the two words . 
To take tile opposite tack , one reason wily word-based indexing may have been disadvantaged is the we did not stem or lemmatise words in word-based indexing  . Having said this , the . output fl'om ChaSen is such that stems of inflecting words are given as a single segment  , with inflectional morphemes each presented as sel ) a rate segments . In this sense , stem-ruing would only act to delete the inflectional morphemes  , and not add ally thing new . 
Another way in which the outlmt of ChaSen could conceivably have atlbcted retrieval perfor -iilance is that technical terms tended to be over segmented  . Experilnentally combining recognised technical terms into a single segment  ( particularly in the case of contiguous katakana segments in the manner of Nljii and Croft  ( 1993 ) ) , however , degraded rather than lint ) roved retrieval performance for both character -based and word-based indexing  . 
As such , this side-etfect of ChaSen would not appear to have impinged on retriew fl accuracy  . 
One other plausible reason for tile unexpected results is that the test data could have been ill some way inherently better suited to character -based indexing than word-based indexing  , although the fact that the results were cross -wtlid at cd would tend to rule out this possibility  . 
A surprising result was the lacklust reperformance of the weighted sequential correspondence method as compared to simple sequential correspondence  . We have no explanation for the drop in accuracy , other than to speculate that either the proposed formulation is in some way flawed or contiguity of match does not impinge on translation similarity to the degree we had expected  . 
To return to the original question posed above of retrieval speed vs  . accuracy , the word order-sensitive edit distance approach would seem to hold a genuine edge over the other methods  , to an order that would suggest he extra computational overhead is warranted  , ill both accuracy and translation discrepancy . It must be said that the TM used in evalua-t ) ul ; ational overhead that would 1) ecxp ( , ,ri(;ncc , din ~ realworld TM system context of t ) ot ; entially millions rath ( ; r than thousands of translation records . 
AC the saint ' , ( tim ( ; , however , coding Ul ) the c(lit dis-tan(:(; l ) roc(' , dure in a language fasto , r than Perl using chara (; l;(?r~d ; h(~ , r\[ ; \] lall SI ; t ' i llg COI lq ) arisol ~1 ) roc ( ? ( hlrcs midai ) l ) lying ( lynami ( " 1 ) rogl ' amming t ( whni ( lu (  , ,s or similar , may well o Il~set h(' . large \] nero . as (; in number of comparisons dcm and (' , d of the system . 
5 Concluding remarks
This research is concerned with l ; mr ( ; lativ ( ~ iml ) or l ; ot 7 word order and segm(mta . 1 ; ionn translation re-l ; rievali ) er formml c(~t braTM system . Wcmo ( Ml ( ' xl the elthcts of word orders ( msitivity vs . 1) ag-of-wol'dS word order in s(ms it ; ivity 1) yiml ) l(mmnl , ing a total of live similarity mcla'ics : two bag -of-word sal  ) proach ( ' , s(lhev (' , (: torspa (:(; model and " tol?(' . nint(us(!(:tion ") and t in '(' . (' , w () r(lord(' , r-s(;nsitive al ) l ) roach(' , s((' , (lit ; dis-tan(:(' . , " s(;quential corr(' , Sl)ond(' , nce " and " w cight (' , d sequential corr(~st ) on denc (?') . Ea (: hofth(;s(;nw , tri (' , s was then l ; (~sl ; e(tHll(ler(:har ; ~cl ; ( ; r-1) as ( ~(\ [ al ~( tword-based in(h ' ~ xing , to de to , rmin ( , ~ what ( ; tt'c(:ts(~gm (' , nta-l ; i on wouhl have , on r (' . trieval 1 ) (~rl'orman ( : ( hEml ) iri-c~d evaluation ) asc , dll ' Olllld\[ , h(~ , l ; alg ( ! l , languag(' , ( ; ( tit distance of t ) rot ) osed trai Ma . tion can(lidal(' , sr ( ~ vcaicd that ( : hara ( :tcr-1 ) as cd indexing consist ( mtly produ ( : edgr ( ' ~ atcr accuracy than word q ) ased in ( lexilt g ; and thai ; the word or ( l(~r-s('atsitivo ~( ; (lit distain : (' , m (; tri (: clearly outl ) (' , r forme (1 all other methods un(h ' , r1) othin(l(' , xing paradigms . 
The main area in wlfi (' , h w e , fc!dthisr(~s(!ar(:hc(mht1)c ,   ( mhan ( : ( ~ distovalidate th ( ~findings of this 1 ) a-perin ( ~ Xlmn ( linge vahlati ( )n 1o olh ( w domains mid l ; esl ; Set , q , whi (: hwch'av (' , as ; lllil:(?lll1'()1t'ulm(~re-s(mr(:h . We also skirl ; edm ' ( mnd liraissu ( ~  ( ) f lrmls-lation record partitioning , and wish11) inv (! stigale how difl '( ; r(mt1) mtitioningm(~'tho(lslmrfl)rm againsl ; c , ; mhother . One important area in which w ( ; hop ( ~ toe Xl ) and our resem'ch is to look at time tl ' ( ~ ( : ts of character type on chm ' act ( ' , r-bas (~ dinexing , t ( anji would a , ppear to be helping the case of character-based indexing at t  ) rc , s(mt ,   ; rodit woul(\[1) e highly r ( ; v caling to look at wh (' , th(' , rCOml ) ara , 1) l(' , ro , sultstot\]losc1)r(:s(;nt('dh(;r(~would1)(' , t)ro(ht(:ed\[orfullkaim-basc'd(alphal)c , ti (:) , lal ) an (' , sc input , or otlmrall ) hal ) ct-1 ) as edn ( m-s ( ~gm ( ulting languages such as


Vital input into this research was rcc ( ~iv cdt?om Francis Bond ( NTT )  , Emmanu(;1Planas(NTT ) , and three anonylll OUS reviewers . 
References % Baldwinmul Ill . Tanaka .  1999 . The applications of unsul ) crvised learning to , I ~ t l ) m m s cg ral )\] m m c , -1) honcin(~aligmnent ,  . Inl'roc , ofth . e . AULI . Vortc . d~opoa Uu-supervised Learning in Natu'ral Language l ~ roccs  . s in 9, pages 916 . 
L . Cranias , H . Ibqmgr . orgiou , and S . Pilmridis .  1995 . 
A Matching Technique in Example-Based Machine
Translation . cmp-lg/9508005.
L . Cranias , H . Papageorgiou , and S . Piper\]dis .  1997 . E ?- amt ) h ~ retrieval from a trmls lation memory . Natwral Language \]' Jngine . ering , 3(4):25577 . 
1t . Fuji \] and W . B . Croft .  1 . 993 . A comparison of indexing tc(:lmiqu(~sfl)r . lal ) ancsct ; c . x;r (' . trieval . In Proc . 
of 161 h International ACM-SIGH ~ , Cot@fence on Research and Dc'v clopm cnt in Information Ib : tricval  ( SI-
GIR'93), pages 23746.
It ; . Kitamura and II . " ~ Smmmoto .  1996 . Translation retrieval systo . musing alignment data flom parall c . l texts , in P ~ w c . of the 5&'d Annual Mccting of tit("II'S , I , volmne2 , pages 3856 . ( Ill Ja . t ) ancsc ) . 
C . Manning and II . S(:hiil ; ze .  1999 . Foundations of Statistical Natural La'ngurt gcP ~ vccssing  . MIT Press . 
Y . Matsmnoto , A . I(i /, auchi , T . Yamashita , and Y . IIi-rano .  1999 . , \] apancsc Moudtolo . qical Analysis S?/s-l , cmUttaScn Version 2 . 0 Manual . ~lt ' ~ chnicall / . eporl;
NAISqUIS-Tl 199009, NAIST.
M . Nagao and S . Mort .  1994 . A new method of N-grant statist ; its tbr large mm flmr of N and ; mtonmtice x-\[ ; ra( ; 1 ; ion of words and l ) hrases front large text ; data of . lapanese . In Proc . of the 15th , lntc ~' ~ u ~ tioual Con-J crcnccon Computational Linguistics  ( COLING '9/~ )  , pages 611-5 . 
N . Nakamma .  1989 . ~l ? ~ mslat , ionsupl ) or f by retrieving bilingual texts . Inl ' ~ w c , of the 38th Annual Mcct in 9 of the IPSJ , volume 1 , pagt ; s3578 . ( In Jai)ancs (;) . 
S . Nirelflmrg , C . l ) om as hnc . v , and \]) . J . Gramms .  1993 . 
Two apt ) roa (: hestomat ; thingine Xaml ) h > bas(~drim-chin(' , translation . In Proc . of the 5th International CoT@:rc'nccon 771corctical and Mcthodologic ( dlasucsi'tl . Math , inc . 7! ransl , , tio'a151'M1-93), pages d757 . 
E . Planas and () . l : uruse .  1999 . F ( wmalizing translation m(m,n'ies . Inl ) Twc , o . fMath\]n (: Translation , %m'mit
VII , pages 3319.
1'2 . Planas .  1998 . A Case , Study on MemoryBased Machine ~' anslation 7 bols . Phi ) Felkm ~\ Vorking1)al)c . r,
Unil ; ed Nations University.
G . Salton .  1971 . The SMAR , TIt , err\]ovalSy . stevt:E:rpcr-ime . nt . s in Automatic Document Processing . Prentice-

S . Sato and 3' . Kawase .  1994 . Altigh-Spc . edB (: stMatchie . tricval Method fin ",\] apancs c ~ :' a ; t . Tct : lulical Rctmrt ; 1S-11R-94-9I , JAIST . 
S . Sato .  1992 . CTM : An exam lfl('A ) ased translation aid system . Inl " ~ vc , of the 141h International Confcrc . nccon Computational Linguistics ( COLING'92) , pages 125963 . 
E . Smnit ; ~ mtdY . Tsutsumi .  1991 . A1) ract , ical method of retrieving similar examples 1or trm Mation aid . 
7Yansaction , softheIEICE , J74-D-II(10):143747 . ( In

It . Tanaka .  1 . 997 . An efficient way of gauging siinilar-itylmtw cen hmg  . lalmnc , so , expressions . In Information l ~ roccss in 9 , % ciety of Japan SIG Notes , vohun (! , 1t7 , no . 85, 1) ages 6974 . ( In . l ~ q ) ane so , ) . 
A . Wagner and M . Fisher .  1974 . The ' string-to-string correction 1) robl cm . Journal of the ACM , 21(1):16873 . 

