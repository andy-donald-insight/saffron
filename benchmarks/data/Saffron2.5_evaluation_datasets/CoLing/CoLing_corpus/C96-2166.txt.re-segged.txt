Fast Generation of Abstracts from General Domain
Text Corpora by Extracting Relevant Sentences
Klaus Zechner
Computational Linguistics Program
Department of Philosophy 135 Baker Hall
Carnegie Mellon University
Pittsburgh , PA 15213-3890 , USA zechner @ and rew , cmu . edu

This paper describes a system for generating text abstracts which relies on a general  , purely statistical principle , i . e . , on the notion of " relevance " , as it is defined in terms of the combination of tf*idf weights of words in a sentence  . The system generates abstracts from newspaper articles by selecting the " most relevant " sentences and combining them in text order  . Since neither domain knowledge nor text-sort -specific heuristics are involved  , this system provides maximal generality and flexibility  . 
Also , it is fast and can be efficiently iln-plemented for both online and offline purposes  . An experiment shows that recall and precision for the extracted sentences  ( taking the sentences extracted by human subjects as a baseline  ) is within the same range as recall/precision when the human subjects are coin pared amongst each other : this means in fact that tile performance of the system is indistinguishable from the performance of a human abstractor  . Finally , the system yields significantly better results than a default " lead " algorithm does which chooses just some initial sentences from the text  . 
1 Introduction
With increasing amounts of machine readable information being available  , one of the major problems for users is to find those texts that are most relevant otheir interests and needs in as short an amount of time as possible  . 
The traditional IR approach is that the user inputs a boolean query  ( possibly in a natural language-like formulation ) and the system responds by presenting to the user the texts that area " best match " to his query  . In corpora where abstracts are not already provided it might facilitate the retrieval process a lot if text abstracts could be generated automatically either offline to be stored together with tile texts  ( e . g . , as ranked sentence numbers ) , or online , in accordance with the user's query . 
So far , there have been two main approaches in this field  ( for overviews on abstracting and summarizing see , e . g . , (?) or (?)) . One is oriented more towards information extraction  , working with a knowledge base in a limited domain  ( " topdown " , see e . g . , (?; ?; ?)) , tile other type relies mainly on various heuristics  ( " bottom up " , see e . g . , (? ;  ? ) ) which are less dependent on the domain but are still at least  ; tuned to the text sort and thus have to be adapted whenever the system would have to be applied outside its original environment  . Combinations of these methods have also been attempted recently  ( see e . g .  (?)) . 
The focus of this paper will be the description and evaluation of an abstracting system which avoids the disadvantages coming along with most of these traditional approaches  , while still being able to achieve a performance which matches closely the results of an identical abstracting task performed by human subjects in a comparative study  . 
The results indicate that it is indeed possible to build a system relying on a simple and efficient algorithm  , using standard tf*idf weights only , while still achieving a satisfying output 2 A System for Generating Text

Kupiec et al ( ? ) present the results of a study where 80% of the sentences in manmad e abstracts were " close sentence matches "  , i . e . , they were " either extracted verbatim from the original or with minor modifications "  ( p . 70) . Therefore , we argue that it is not only an easy way but indeed an appropriate one for an automatic system to choose a number of the most relevant sentences and present  1By " satisfying " we mean at least indicative for the content of ~ he respective text  , if not also informative about it . 
986 these as a " text ; abstract ; " to the user . ~ We further argue that ; coherence , although certainly desirable , isimi ) ossible without a largescale knowledge based 1 ; extml dersl ; an ( ling syst ; em which would not only slowdown dml ) erformance signiticantly but necessarily could not be domain inde  , 1)endent . 
Our design goal was to use as simple and effl -cleat an algorithm as t  ) ossibh ' , , avoiding " hem(s-tics " and " fe , al ; ures " emph)yed by other systems ( e . g . ,  ( ? ) ) wlfich may be hell ) tiff in a specific text domain but would have to be redesigned whenever it we reported to a new domain  , a In this respect , our system can be compared with the approach of ( ? ) wit ( ) also t ) resent an abstracting system for general domain texts  . However , whereas their focus is on the evaluation of abstracl  ; readability ( as standalone texts ) , ours is rather on abstract relevance . A flirther difference is the ( nonstandard ) method of tf*idf weight ( ' ah : ulation timy are using for their system . 
Our sysl ; em was deveh ) ped in C + . t - , using libraries for dealing with texts marke ( lut ) in SGML format . The algorithm performs the following sl ; et ) s : 41 . Takeanarl ; Mefl'om the corl ) uS5 and lmild a word weight ; matrix for all con-tellt words across all sentences  ( l ; f*idf (: omputal ; ion , where the idf-vahms ttter ( > trieved fl'om a preconqmted file )  .  ( ; I ligit fre-(tuency closed class words ( like A , THE , ON etc . ) are excluded via a stoplist file . 
2 . Determine the sentence weights for all sen-ten ( : esintimarl ; Me : Compltt ; e the sum over 2Clem ' ly , there will be less ( : oherence than in a manmad e abstract , but , the extracted passage scant ) e presented in a way which indicates their relative position in tim text  , thus avoiding a possil ) ly wrong in ti ) ression of adjacency . 
aln fact , , it t , urned out that fact , or s which couh l1 ) e thought of as % l ) ecitic for newspaper articles " , su ( : has increased weights for title words or sentences in the beginning  , did not have a sign(titan ( eriect ( m thesy s ; elll~sper\['orntance ,   . 
4Due to space limitations , we cannot , give all tilt ; details here . The reader is ref('xredt , O(?) for the reinformation on this algorithm , various odternte , thotls that were tested and their respective result  , s . ( Tiffspaper can I ) eel ) rained Kernt , imauthor'sheine1)age whose URL is : http://www . h:l . cmu . e(lu/~zechner/klaus . htnfl . ) '~' We used the Daily Telegral ) h Corpus which comprises approx .  44 . 000 articles (15 million words ) . 
(~tt*idf=term frequency in a document ( tfk ) times t , he logarithm of then unlber of documents in a collec-l  ; ion(N ) , divi(ledI ) y the IlnI\[lber of do ( ; untents where this term oc ( : nrs ( Ilk ) : tfk*log~_NT his formulank yields a high numl  ) er for words which are frequent in oned neument but  ; api)e . ar in very few documents only ; hence , they can be considered a . s " indicative " f br the respective document . 
all tf*idf-values of the ( : on ( eat words 7 for each sentence , s3 . Sort the sentences according to l ; heir weights and extract the N highest weighted sentences in text order to yield  (  , he abstract of the doc-ll Hleltt . 
To r(~th t ce the size of the vocabulary , our system (; ( ) nv (' , rts every word to Ul ) I ) er ( : as e and ( runt : ales words after the sixth character . This is also rout : it faster than a word stemming algorithm which has toper h  ) rmain or phological analysis . For our ex-periment ; s , the , amount of new ambiguities thereby introduce did not cause specific problems for tim system  . 
For the test set , we (: host ' , 6 articles fl ' om the cor-ires whi (: hare (: los ( ; t ; otimgh ) bal cortms a , verage of \]7 senl ; en (: esperard cl ( ; ; these artich' , s (: ontain approx . 550 word salt ( l22 sentences on the , average ( range : 1923) . All the seart Mesareat ) out a single topic , i ) robably becmme of our choi ( : eal ) out are t ) resenl ; ative txt , lengdLW e ( lo not address ttm issue of multi-topicality here  ; however , it is well known that texts with more ( hallolletel ) it are . hm'd to deal wit ; it for all kinds of Ill . systelt lS . 
E . g . , the ANES system , describedi)y ('?) , tries to i(lenl ; i i l y l ; hese texts beforehand to 1 ) eex ( : luded fl'om abstracl ; ing . 
The system's rlll-til\[te ( ) It a SUN St ) arc worksta-l ; ion(UNIX , SUNOS4 . 1 . 3) is appro ? . 3 seconds for an article ofth (; test , set . 
3 Experiment : Abstracts as
Extracts Generated by Human

In order to b cable to ewfluate the quality of tim abstracts t  ) rodueed by our system , we , conducted an experiment where we asked 13 human subjects to choose the " most relevant 57 sentences " from the six articles Dom the test set  . 9\] bt ; ~ cilitate their ( ; ask , the subjects should first give each of the sentences in an artMea " relewmce score " from l  ( " barely relew mt " ) to 5 ( " highly relevant ; ") and finally choose tit (' , trust scored sentences for th (; ir abstracts . The subjects were all native speakers of English ( since we used an Englist l cortms ) and were . paid for their task . Compared l ; o about 3 set : - ends for the machine system , the hmnans nee(h ; dr This provides a bias towards longer sentences . Ex-periment , s with methods that normalized for sentence length yiehled worse results  , sodt is bias appears to be a pI)roI)riate . 
SWords in the title and/or appearing in t , ln ! first , /last few sent , enees ( : all be given I nore weight by tneans of an editable parame  . l;e . rtilt ; . It turns out , , however , that , these weights do not , lead to an improvement , of the syst , em's performance . 
9This number corresponds in fact , well to the observation of ( Y ) that , the opt , ilnal smnmary length is be-t ; we en 20% and 30% of the original document length . 
987 about 8 minutes ( two orders of magnitude more time ) for determining the most relevant sentences for an article  . 
4 Results and Discussion 4 . 1 Automatical ly created abstracts Table 1 shows the precision/recall values for the tf*idf -methodes cribed in section ?? and for a default method that selects just the first N sen-fences fi ' om the beginning of each art Me  ( " lead "- method )  . Where a stile lead method most likely provides a higher readability  ( see Brandow et al ( ? ) ) , tile data clearly indicates that the tf*idf method is superior to this default approach in terms of relevance  , l ? The computation of these precision/recall values is based on the sentences which were chosen by the human subjects from the experiinent  , i . e . , an average was built over the precision/recall between the machine system and each individual subject  . 
4 . 2 Abstracts produced by human subjects The global analysis shows a surprisingly good correlation across the hunmn subjects for the sentence scores of all six articles  ( see table ?? ) : in the Pearson-r correlation matrix , 71 coefticients are significant at the 0 . 01 level (***), 5 at the 0 . 05 level (*), and only 2 are nonsignificant ( n . s . ) . This result indicates that there is a good intersubject agreement about the relative " relevance " of sentences in these texts  . 
4 . 3 Comparison of machine-made and hurnan-Inade abstracts We computed precision/recall for  (  ; very human subject , compared to all the other 12 subjects ( taking the average precision/recall )  . From these individual recall/precision values , the average was computed to yield a global measure for inter-huin an precision/recall  . Depending oil the article , these values range from 0 . 43/0 . 43 to 0 . 58/0 . 58, the mean being 0 . 49/0 . 49 . As we can see , these results are in the same range as the results for the machine system discussed previously  ( 0 . 46/0 . 55, for abstracts with 6' sentences) . This means that if we compare the output of the automatic system to the output of an average human subject in the experiment  , here is no noticeable ditference in terms of precision/recall the machine l  ) er for lns as well as human subjects do , given the task of selecting the most relevant sentences from a text  . 
1?The tf*idf nmtho<t proved itself better than all the other methods of weight computation which we tested  ( see ( ? ) ) ; in particular , those using a combination of w ~ rious other heuristics  , as proposed , e . g . , in (?) . 
5 Suggestions for further work 5 . 1 Dealing with mult i - topical texts It can be argued that so far we have only dealt with short texts about a single topic  . It is not clear how well the system would be able to hand h  ; texts where multiple threads of contents occur ; possibly , one couhl employ the method of text-tiling here ( see e . g . , (?)) , which helps determining coherent sections within a text and thus could " guide " the abstracting system ill that it would be able to track a sequence of mult it  ) le topics in a text ,  . 
5.2 Online abstracting
While our system currently produces abstracts offline  , it is feasible to extend it in a way where it uses the user's query in an IR environment to determine tile relevant sentences of the retrieved documents  , tIere , instead of producing a " general abstract " , the resulting online abstract would reflect more of the " user's perspective " on the respective text  . However , it would have to be investigated , hownmch weight-increase the words from the user ' s query should get in order not to biastile resulting output into o strong away  . 
Further issues concerning the human-in a ehine interface are : ? highlighting passages containing the query words ? listing of top ranked keywords in tile retrieved text  ( s ) ? indicating the relative position of the extracted sentences in the text ? allowing for scrolling in the main text  , starting at an arbitrary position within the abstract  6 Conclusions Ill this paper , we have shown that it is possible to implement a system for generating text abstracts which purely operates with word frequency statistics  , without using either domain specific knowledge or text  , sort specific heuristics . 
It was demonstrated that the resulting abstracts have the same quality in terms of preci-sion /recall as the abstracts created by human subjects ill an experiment  . 
While a simple lead-method is more likely to produce higher readability judgments  , the advantage of the tf*idf-method for abstracting is its  , superiority in terms of capturing content relevance  . 

Tile major part of this work has been drawn froln the author's dissertation at the Centre for Cognitive Science  , University of Edinburgh , UK . I wish to thanklily supervisors Steve Finch and Richard  3-   .   .   .   .   .  6 . agfi) . 
so . ss/o . sl0 . 45/0 . a 8100 . 37/0 . 62  0 . 41/0 . 74 12 0 . a4/0 . ( 9  0 . ag/0 . sa 140"33/0"79 l0 . 37/0 . 9 1 Table 2: Significance of sentence score correlation between human sul  ) jeet , s : All 6 articles











H S14 height tlS4   IIS3   IIS8   ItS9   IIS1   HS5   ITS12   I1S11  \[  IS13   HS10   HS14   IIS15 gg *#~ #g#g g * gg    #gg ** g**g#g * gg * g *#* * g * ggg ? g #** g#gg * **#*@? gg #$** g#*#*       gg ** g#*~~**g*gg*#%*g ***#$ * g#*#* gg#g*ggg#**g#~g*$gg#g **#   %* g*#\]L  , S . 
IL.S . **** gg
Shillcock for vahlal ) le discussions , uggestions and advice . . Also , I am grateful to Chris Manning for his comments on an  ( ~arlier draft ;  , as well as t , othet ; WO allOllyi\[lOllSr(wieweI'8 whose , reillarks gre . al ; ly helped in improving t , hisl ) aper . 
The author has l ) eealsupi ) orted in part by grants from the Austrian Chamber of Commerce and ~ Dade  ( l h l n d e s w i r t s e h a f l ; skammer ) and the Austrian Ministry of Science and Research  ( BMWF )  . 

Brandow , R . , Mitze , K . , Ibm , L . F .  1995 . Auto-mat ; it Condensation of Electronic Publications by Se , ntence Selection . In : Information P , ,vccss-ing 84 Management ,   , 71( , 5) . pp . 675685 Edmundson , H . P .  1969 . New Methods in Automatic Extracting . In : Journal of the ACM , 16(2) . pp . 264285 Hearst , M . A . , Plaunt , C .  1993 . Subt ; opie Sl ; ruc-luring for Pull-Length Docmn(mt Access . In : Proceedings of the 16th ACM-SIGII~Confl ; r-trice , t ) p . 5968 Hobbs , , I . R . , At ) I ) elt , D . E . , Bear ,, 1 . S . , Israel , l) . J . , Tyson , W . M .  1992 . FASTUS : A System for Extra ( : tingInt'ormation h'oln Natural Language Text . SRI International , Technical Note 519,
Menlo Park , CA
Jaeobs , P . S . , Rau , L . F .  1990 . SCISOR : Extracting Informal ; i on D or a Online News . ht : Communications of the ACM, . 73 (11) . pp . 8897 Kupiec , J . , Pedersen , J . , (\] hen , F .  :1995 . A Train-al)le , Docmne . nt Summarizer . In : l'r'oce ?' . dings of the . 18th ACM SIGIR Confe ~ w ~, cc . . t)p . 6873 Mauhlin , M . L .  11989 . Information l/ . etrievall ) y Texl ; Skimming . CMU-CS-89-193, Carnegie
Mclhm University , Pittsbllrgh , PA
Miike , S . , It ; oh , E . , Ono , K . , Sumita , K .  1994 . 
A Full-Text Retrieval System with a Dynamic Abstract  ; Generation Funct ; ion . In : Proceedings of the 17th ACM SIGIRUm~fl : ~ v . ' nce . t ) t ) . 152 The Effects and Limitations of Automated T ( ' ~ xt ; Condensing on Reading Comi ) rehension Per-form aime . In : Information Systems l , esea ' rch , 3(1) . 1) t ) . 1735 Paice , C . I ) .  1990 . Constructing l , il ; era-lure Abstracts t ) yComlmter :\[\[> ( : hniques and Prost ) ecl ; s . In : Information Processing 84 Man-ageme . nt , 26(1) . t ) 1) . 717186 Salt(m , G . , Allan , J . , Buekley , C .  \]993 . Ap-proa (- hesto Passage Ret , rieval in Full ~ l ~ , xt Information Systems . TR93-1334 (1993), Cornell
University , \[ thaca , NY
SparckJones , K . , En(lres-Niggemeyer , i3 .  :1995 . 
Automal ; i (: Summarizing . In : Information P~v-cessing I " i Management ,  31(5) . pp . 625630 Zeehner , K .  1995 . Automatic Text Abstracting by Selecting Relewmt Passages  . M . Se , i ) is ser-ration , Centre for Uognitive Science , University of Edinburgh , UK
