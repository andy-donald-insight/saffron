VERBAL CASL FRAME ACQUISITION FROMABIIAN(? , UALC () RPUS:
GRADUALKNOWI , EDGEACQUISITION
ltideki Tanaka-t
NHK Science and Technical Research Laboratories
hanakah@strl.nhk.or.jp

This paper describes acquisilion of English still ace case flames from a corpus  , based on a gradual knowledge acquisition approach  . To acquire and unambiguously accumulate precise knowledge  , the process is divided in ln three steps which are assigned to the most appropriate processor : either a human or a computer  . The data is prepared by human workers and the knowledge is acquired and accumulated by a leaning program  . By using this method , inconsistent hunmn judgement is minimized . The acquired case frames basically duplicate Imman work  , but are more precise and intelligible . 
1 Gradual Knowledge Acquisition
We have been developing an English-to-Japanesenut -chine translation  ( MT ) system ( i ~ t news reports in l-nglish ( Aizawa T . , 1990) ( Tanaka II . , 1991 ) and have so far stud-ted the translation selection problem for common English verbs  ( Tanaka I1 . , 1992) . Recently , we examined the problem of multiple translatkms for COllll/lOl\]English verbs  ( Tanaka\[1 . , 1993) . Our MT system uses surface verbal case flames ( simply written its case frames ) to selccla Japanese translation for an English verb  . The need to acqtuir c and accumttlate case frames leads directly to three problems  . 
(1 ) How to obtain detailed case frames which are accurate enough to mm slate highly polysemous verbs ?  ( 2 ) l to w to accumn late a number o1' case frames in an unambiguous way . 
(3 ) Manual case frame acquisition tends to yield inconsistent result since human judgements are changeable  . \[Iow can we maintain cousistency ? We need to devise a cleat ' methodology lor acquiring suf- -ficient case flames and accuum lating them in a way that is unambiguous and consistent  . 
In this paper , we propose a gradually building up a knowledge base from a bilingual corpus to cope with these three problems  . The knowledge base is a collection of case fiames  . Fig . 1 shows an overall view of otn approach . 
The process is divided into three steps which arc assigned to the most appropriate processor : a hm nanora computer  . 
Using this method , detailed knowledge is obtained fiom the Fig . 1: Case-Frame Tree Acquisition from a
Bilingual Corpus target &) maintents , unstable hm nan judgement is confined , and case I Yames are accumt dated unambiguously b using a lemning algorithm  . 
We begin by preparing a tagged bilingual corpus seeking detailed knowledge in target domain texts  . The annotation described in the corpus is tile syntactic information of tile texts and tile translaliot ~  . They are assigned manually since hnman translators can do such jobs as syal acticlagging and translation with far more cousistency than writing case frames directly  . 
Next , tile corpus is converted into an intermediate data form called the primitive case-flame table  ( PCI'T )  . Finally a stalistical learning algorilhm is used to extract he case frames from the PC\['T and accuuuulate hemina clear cut fashion  . 
While this approach let us avoid writing case flames directly using linguistic on templation  , human activity plays an important role in designing and constructing the corpus and converling it into the PCI q'  ( Fig .  1) . 
The case frames are represented in a discrimination tcee  , which has sev01al attractive features lor word sense selection ( Okunmra M . , 1990) . The biggest attraction of the learning algorithm , we think , is its intelligibility ; compared with the algorithms for neural networks , for example , it produces highly intelligible results if the inpul is appmpri-Knowledge acquisition by machine learning from a corpus has recently been getting more attention thanever in some natural anguage processing fields  . Cardie (1992 ,  1993 ) applied this approach to predict heantecedent of relative pronouns and attributes of unknown words  . 
Utsuro ( 1993 ) introduced a methodology for autonmtically acquiring the verbal case frames from bilingual corpora in a different way than our methodology  . 
2 Case Frames for Translation
Ore " machine translation system uses case frames for the translation of English verbs  . Fig .   2 shows illustrative case frames for the word take . 
SN\[man\]takeON\[boy\]~ . .~  ( select ) SN\[I\]takeON\[him\]PN\[to\]PNc\[BUILD \]~ tL-C b ~ <  ( escort ) SN\[HUMAN\]takeON\[CON\]PN\[to\]PNc\ [BUILD\]~-~-  ( L , ~< ( bring ) Fig .   2: Example of Case Frames for take We write case categories  ( SN ( subject noun ) and PN ( preposition ) here ) and specify their restrictions . The restriction can be a semantic category like tfUMAN or a word form itself like boy  . There may be several hundred case frames for the most common English verbs  . 
The translation selection is performed after the parser produces a syntactic structure for the input sentence  . The system compares the syntactic structure with the case frames and selects the translation from the best-matching case frame  . Translation selection is performed without considering the context  . Our new case fiames are designed to follow the same protocol  . 
There are three factors to consider at this point.
(1 ) How many and what kinds of case categories should be used ?  ( 2 ) In which order should the system compare the syntactic structure and the case categories in a case fl'ame ?  ( 3 ) What kind of restriction should we use ? In this paper  , we will deal mainly with the first two factors . Our solution is to use a discrimination tree for the case-flame representation adastatistical algorithm for learning  . The necessary case categories are selected and stacked in a tree form  , one by one , according to their contribution to the translation selection  . We call the obtained tree the case-flame tree . Fig . 3 a is an example of a case frame tree for take . 
ON him//O ~ oxbring escort select .   .   .   .   .   .  , . . .   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  .   .  ,  .   .   .   .  ,  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
Fig . 3a : Example of a Case-Frame " Free
ON\[box\]?"t,
ON\[him\]~,~
ON\[him\]PN\[to\]Z~tLTb,<
Fig . 3b : Linear Case Franles for Fig .   3a Comparison with the syntactic structure is made fi ' om the root node to the leaf nodes of the case frame-tree and no backtracking is allowed  . The comp , ' u ' is on is executed deter-ministical \[ y . If we read the tree fiom the root to the leafs , it can be expanded into a line arease fiame , as shown in Fig . 
3b . This increases the intelligibility of the case -fiametree enabling a human lexicographer to evaluate it from a linguistic viewpoint  . 
3 Learning from the PCFT
A case-fralnetree can be regarded as a decision tree  . 
l ) ecision-lreelarning has a long research is tory and many algorithms have been developed  . Among them , the ID 3 group ( Quinlan J . , 1993 ) of programs and its descendants satisfy our solution in Sec  .  2 . We apply the latest program , C4 . 5 ( Quinlan J . , 1993), to our problem . This algorithm learns a decision tree from an attribute-value and class table  . 
An exatnple of such a table is shown in Table 1.
Tal)le 1: Examplen fa Primitive Case Franle Table
SN VO NP NP Nc translation
I take him to the ater you take him to school you take him to park you take box to the ateryou take box to park 
I take box to school 1 take him 0   0 you take him 0   0 ~g - ( ~ , '<( escort ) ~ q~:~Z't , , < ( escort ) ~ gZ ' b ' < ( escort ) ~ . ffo-Ct , ~< ( bring ) , ~~-( t , ~< ( bring ) ~ o-('t , ~/- , ( bring )
N ~ ,,~( select)
L ~ , S ~ ( select)
The first row of the table represents he attributes or the case categories  . The values of the attribntes arc the restrictions of the case categories  . Wordforms are used in this . 
Since the algorithm produces a case-liame tree f i ' om this table  , we term the table a " Primitive Case-fl'ame Table  ( PCI q' )  . " under a root node then recursively selects one case category and pmtitions the translations according to the wordforms of the selected category  . For the case category selection , a criteria based on the entropy reduction of translations gained by the partition in gix used  . See ( Quinlan J . , 1993) for more details . In a word , this algorithm places case categories from the root node to the leaf nodes according to the category'sability for translation discrimination  . The case frame tree in Vig . 3 a was produced fl'om Table 1 . It does not have a node corresponding to a subject  . This simply means the subject information is redundant in selecting the translation  o1' take in ' fable I . 
4 Data Preparation 4 . 1 Construction of the Bilingual Corpus As mentioned in Sec  . l , the data for nmchine learning is prepared in two steps : construction of a bilingual corpus and its conversion into a PCITF  . l " ollowing are the factors consklered and the steps taken to put together our corpus  . 
? Sollrce
Since we couMnot find a readily awfilable bilingual corpus from the news domain  , we decided to make one ourselves by using the Associated Press  ( AP ) wire service news text and adding a Japanese translation to it  . 
? Target
We selected 15 verbs known to be problematic verbs form a cl fine translation : come  , get , give , go , make , take , run , call , cut , f i , ll , keep , look , put , stand , and turn . 
Since case frames correspond to simple sentences , we did not deal with long sentences . The maximum sentence length was set at 15 words . 
? Quantity of Data
To estimate the necessary amount of data , we investigated the monthly frequency of each verb appearing over six months  . The\[equency showed a fixed tendency over the measurement periods  , suggesting that the data for one monthix a good starting point  . We decided to use two months , January 1990 and January 1991 , for the English sentence xtraction . 
? Construction ( 1 ) Preparing the English text Sentences up to 15 words long which contain one or more of the 15 target verbs were autonmticatly extracted fi'om I he two-mont hAP so nr ce text  . 
(2 ) Identifying the range governed by the verh The range which the target verb directly governs in the English text was manually identified  . The two lines starting with FNG in Fig . 4 are an example . 
(3) Constructing the English case data
The a priori-defined category labels for each part of the ENG data were manually marked and the head word and functional word in each category were identified  . The lines stm'ting with CASF , in Fig . 4 correspond to this data . 
We had defined 34 category labels beforehand . Twelve of them ( sentence category labels ) were assigned to verbs to identify the sentence category from which the verb was extracted  . Example categories are : V ( declarative sentence )  , PVQ ( polm question ) , IMV ( imperative sentence) , PASV(passive sentence) , and IV ( to-infinitive clause ) . Twenty-two of the category labels ( case category labels ) identify the surface cases or the syntactic a tegories of other compo~nents in the sentence  , l , ~xamples are : SN ( subject noun clause ) , SIN ( subject to-infinitive clause) , and PN ( prepositional phrase I modifying the target verb \] )  . 
(4) Constructing the Japanese data
Japanese translations were assigned to each of the F  , nglish head words and functional words . When translation was not possible simply reading the English sentence  , its context was given to the translators . The two lines starting with JAP in Fig . 4 show the translations . 
The complete corpus took about 12 nmn-months of labor to construct . Table 2 shows the corpus statistics for seven verbs . Row ( 2 ) shows the percentage of sentences thal required the context for translation  . This figure indicates the limitations of manual translation without context  . Most of these sentences had pronotms like it and the translators needed the context oclarify the referents  . 
1 9 : " I just know I'm going to take those rubles and buiklanother restaurant  , " he said . 
ENG : I'm going to take those rubles ( ' ASE:SN < II\]>AX <\[ hegoing tel > V < I take  1>   ( ) N<those \[ ruble \]> JAP : SN< , ~Y ' , \]~> AX < IBliGOINGTel > 20 : " I take everybody seriously " Graf said . 
ENG : l take everybody seriously
CASE : SN <\[ I\]>V <\[ takel > ON < le very body \] >
DD < I seriously \] > , lAP:SN < I~/ , \[~:~> V <\[' ~ l0I\[-~" ) ~l > <> category label , \[\] head word , functional word Fig . 4: Part of a Tagged Bilingual Corpus 4 . 2 Conversion into a PCFT The bilingual corpus must be converted into a PCVF become get give go make  ( 1 )  795 867 635 1204 1024  ( 2 )  3 . 4% 5 . 2% 4 . 1% 3 . 7% 6 . 6%  ( 3 )  782 849 637 941 1020  ( 1 ) Number of English sentences run take ( 2 ) Percentager quiring context to translate 440   1062   ( 3 ) Number of obtained quadruplets 6 . 0% 4 . 0% 303 1067 for e a case fiame can be learned . We can now directly control the information used l br learning  . We followed the principals below . 
? Develop one case-fi'ametreefi'om each sentence category This was intended to observe how the sentence category affects the appearance of case frame trees  . 
? Use all case categories in the corpus as attributes This was to select effective case categories without any bias  . 
? Use head words and functional words as values for case categories These words are the primary elements representing each case category so it is reasonable to use them as the value  . 
5. Case frame Tree Learning Experiments
Several learning experiments were conducted on the PCFT obtained from each sentence category of the target verbs  . Complete results fiom the experiments are not presented here due to space limitations  . Table 3 shows the statistical results for seven verbs . 
Table 3: Statistics of Case-Frame Trees ( from declarative sentences )   ( 1 ) come get give go make ( 2 )   ( 3 )   ( 4 )   ( 5 )   ( 6 )  398 274 292 225 367 30 28 31 20 33 10 9 9 8 8 6 5 5 6 ' 6  . . . .
10 . 1% 5 . 5% 13 . 0% 10 . 2% 6 . 2%  ( l ) Verbs ( 2 ) Number of training data ( 3 ) Number of case categories appearing in the PCbT ( attribute size )   ( 4 ) Number of translations ( class size )   ( 5 ) Number of case categories appearing in the case frame tree  ( 6 ) Error rate when the tree was used to re-classify the training data run take  68   285   15   21   3   10   3   5   0  . 0% 6 . 0% We are now increasing the corpus for give , make , and take by 4 , 000 sets . 
Translations occun'ing less than ten times were not included in the PcIq ' for this experiment  . The overall error rate in Table 3 was quite low . Part of lhetake tree is shown in Fig .  5 . The figures at the end of each lines how the result of the reclassification of the training PCIq " by the learned tree:  ( nnmber o1' data items which fell on this leaf/number of errors  , if any ) . As is shown , the case frame tree is highly intelligible . 
D <>= over : J\[,:~\[g : ("(12. ( I)
D <>= up:\]IY , ~(3.0/1.0)
D <>= O : need time
ON <>=0: ?)'73, Z , (5.0/1.0) ~ A
ON <>= action : ~7 ~ (8.0)
ON <>= bronze : ~'\[~:'~-7j (9.0)
ON <>= hour:7~,7~,7~(11.0/3.0)
ON <>= measures : k&(10.0) join
ON <>= part:@JJIF~-7~(33 . 0/1 . 0) -  . 91---B
ON <>= while : J'o'Y0"~(6.0)
ON <> = place : ~ l : ~, . _', SN <>= SergeiShupletsov:~J~f,J ' ~ Z~(I . 0)', SN <>= attack : ~\] a ~) avt . 7 o(4 . 0) win , ~? q\
ON <>= time : happen " ~
AX <>=0:7~"/0'70 (4.0/2.0) C
AX <>= may : ' ~, :') ~:-~ I ; 5(1.0)
AX <>= could:;0"~~(1.0)
Fig .   5: Part of Case-Frame Tree for Take ? Similarity The number of case categories actually used in the ease-flame tree was drastically smaller than the number used in the PCFF  , ( row (3) vs . row (5) of Table 3) . In the case-fi'ametreet brlake , for example , the following case categories were used : AX ( adverb equivalents )  , D ( adverbial particles) , ON ( object noun clause) , SIN(subjecto-infinitive chmse) , and SN ( subject noun clause ) . The top node , i . e . the most important node , became D , the adverbial particle , following the description in an ordinary dictionary  . Most of these syntactical categories are usually used to describe the verb patterns in ordinary dictionaries  . The case frame tree basically duplicates the verb patterns found in an ordinmy dictionary  . 
? Precision
From the line marked A in Fig .  5 . the translation be came ka karu ( need time ) under the condition of ( ON = 0 ) though lake is usually used as a transitive verb , so the lack of an object noun looks nn natural ; this part of the tree , however , corresponds to time expressions like " take long " and " take a while " which do not have object nouns  . This is reasonable learning . 
From the line marked B , the idiomatic expression " take to be redundant and thus an ineffective lement  . While our corpus did reveal one example thal did not have in it still had the same translation : " sankasuru  . " T tf is learning is more precise than the description i an ordinary dictionary  . 
? Complementary learning
The lines marked C in Fig .   5 show an exan@e of what we call complementary learning  . The case frame tree surprisingly distinguished " kakutokustlrtf '  ( will ) from " okolmwareru " ( happen )  . The former was learned from " lakettfird place . " The latter corresllonds to an idiomatic expression  , " take place " . Timway tile algorithm learns ist miquc . The key to discrimination was found in SN , the subject noun , which sounds reasonable . Discrimination is done in terms of the subject's nature : person vs  . actioun ot ll , l lowever , this could also be distinguished by the existence of the modifier to place  , since in the idiomatic sense , no modification is allowed between take and place . In our PCbT , modi-tiers were not iocluded and the system found complementary knowledge to distinguish the translations  . The same phenomenon was fotmd in many paris of the flees  . The learning algorithm does its best to subcategorize the translations within the given case categories  . While this can yiekllinguistically-skewed case frames  , tttey are still effective , at least in the corpus . 
? Differences among sentence categories
The results flom other sentence categories had a mttch different appearance  . Trees for make and take which were obtained from the PCFT fortile to-infinitive chmse contained only one case category  , ON ( object noun clause) . 
The case categories effective ill the declarative sentence  , like the adverbial particle , were not effective for this sentence category . This strongly suggests that translations should be selected by using lhecase frames for the sentence type  . 
6 Conclusion
We proposed the ideaef gradual knowledge acquisition from a bilingual corpus  . The knowledge addressed in this paper was the surface verbal case frames for the Japanese translation of English verbs  . The process consists of three steps : corpus construction  , data conversion , and macl fine learning . 
The case-fiame trees we obtained were highly intelligible : they can be interpreted from the linguistic viewpoint  , They basically matclled linguistic intttition and more precise knowledge was sometimes acquired  . Tree analysis showed that in some cases comlllementary learning occurred even wllen neccs smy knowledge was no lawlilable  . 
The trees successfully distinguislled tile translations of the training data  . 
Our approach basically fulfills our primary goal : acquit'-ing detailed knowledge and accunlt dating it in a way that is consistent and unambiguous  . 
There are several areas for future work . The work in lhispaper used tile word forms as tile restrictions for tile case categories  , resulting ill case frame trees with limited traus -lation power for open dala  . To increase the lranslation power , we are generalizing the corllus by using semanlic codes and plan to produce case frame trees with then l  . 

I would like Io thank Prof . Makoto Nagaoo F Kyoto University and Prof . lloztuniTatla kaoft be Tokyo Institute of Technology to r their vahtable suggestions  . I would also like to tl/ank my supervisors Dr . Yuichi Ninomiya , 1) r . 
Teruaki Aizawa , and I)r . Terumasa Ellara , and my colleagues whose discussions helped clarify this work  . The allonyl not ls reviewers in a devery COllStl ' uclive COllllnelll Swhich gave us vahlable pointers for ottr future work  . 

Aizawa , T . , Ehara , Uratani and Tanaka (1990) . A Machine Translation Syslem for l , ' oreign News in Satellite Broadcasting , t ' roc , o / Coling - 90 , Vol . .5', pp .  308-310 . 
Cardic , C .  (1092) . l ~ eartfing to l ) is ambiguate Relative Pro-notms . Pro<o /' AAAI92, pp .  38-43 . 
Cardie , C .  (1993) . A Case-Based Approach to Knowledge Acquisition for Dotnain-Specil'ic Sentence Analysis  . 
l'roc , of AAAI .93, pp . 798-803.
Oktllllura , M , and Tanaka (1990) . Towards htcremental I ) is ambiguation with a Generalized Discrimination Network  . Proc , o /' AAAI-90, Vol . 2, pp .  990-095 . 
Qttinlan , J , R .  (1993) . C4 . 5 programs for machine learning,
Morgan Kauflnalul.
Tanaka , 11 .  ( 1991 ) . The MTUser Experience . Proc . o/MT
Summit I11, pp . 123-125.
Tanaka , I1 . , Aizawa , Kin/and Ilatada .  (1992) . A Method of Translating English I ) e lexical Structures into Japanese . 
l'roc,q/'Coling-92, Vol . 2, pp . 567-573.
Tanaka , 11 . and Ellara (1993) . Automatic Verbal Case Frame Acquisition l'rom Bilingual Corpora  ( in Japanese )  . 
lb ' oc . 47th Anmml Convention IPSJapan , Vol , 3, pp .  195-196 . 
\[_Jtstlro , T . , Malsumo Io and Nagao . (1993) . Verbal Casel : rame Acquisition flom Bilingual Corpora  . l ' roc , qf the
I , ICAl .93, Vol . 2, pp , 1150-1156.

