Modeling Topic Coherence for Speech Recognition
Satoshi Sekine
Computer Scion(:(;\])eI)ai'tmcnt
New York University
715 Broadway , 7th floor
New York , NY 10003, USA
sekine@cs , nyu.edu
Abstract
St , a tist , icalangmt ge models play a major role in current spee ~  ( : hre . cognition systems . Most of these models have ti ) -cussed on relatively local interactions between words  . R ( . ' (: ently , however , her (' . 
have been sev cr ; d attempts to incorporate other knowlcdg ( ; source . s , in particular long ( x-range word ( tet ) ( ; nden (: ies , in order to improve . Sl ) ( . ~ echr(;(:ognize . rs . 
We will 1) rcs(~ . nt one . such m (' . t ; ho(l , which tries to autonmticatly utilize t ) rolm ri ; ics of topic continuity . Whimal ) asc-linc . 
spee . chre . ( x)gnil ; ionsysl ; emgencra , l ; (' . sa . \[-ternativ (', hypothe . s(~s for a senl ; enc ( L we will ul ~ ilize the word prefer cn ( : ( ~s based on topic coherence to sele ( : ttimb (  ; sthy ~ pothesis . In our experiment , weach i(weda 0 . 65% imI ) roven mn ; in the wor (1ei-rorrat(' , on top of t ; h (; base-lin(!sysi ; em . 
It corre . sponds to 10A0% ( if tlmposs it ) leword error improvement . 
1 Introduction
Statistical anguage models play ~ major role . in current language i ) rocessing applications . Most of these models have fbcussed on r('~lative . lyocal interactions betwe . en words , int ~ articular , large . 
vocabularys l ) eech recognition systems have . used primarily bigram and tri~grmn language mod (' . ls . 
Recently , howev (; r , there have been several at-te . mt)t,s to incorl ) or ate other knowl(~dg e . SOlll ' C(~,8~ and in pa . rticular longer-range word ( tepe . nd(mcies , in order l ; o improve speech recognizers , th ' . rc , 'loi~ger-ranged(~tienden(:ics'me , ms dependencies extending beyoiM several words or beyond sen-l  ; ( mceboundmies . 
There have be . en severalal ; l ; eml)l ; s in the last few years to make use of these prot ) erti ( ' ~ s . One of them is the " cache language mode . l"(Kulm , 1988) ( aelinek et al , 1 . 991) ( Kul , icc , 1989) . This is a dynamic language model which ul , ilizes the partially dictated document (" cache . ") in order to predict the next word . In essence , it is based on the ol)se . rvation l ; ll & ( ;   ; ~ wor ( t  whi ( : h ha sah'cadyal ) -1 ) care ( 1 in a ( locum (  . ,nt has ; mincr ( ; ased i ) rol ) ability of r ( ; at ) ticaring . Jelind ? showed timuse fuhmss of this method in terms of spe  (  ; chre . (: ognii ; ionquality . 
For sllor I ; ( locllIll ( . ~II ~, s ~ how (' . v(w~SllCh ~) ~ slieWSt ) 3I ) crf ~ rl ; icl(;s , th(' . mnnl ) cr of words whi ( ; hcan 1) ea (:-- cunml~t ( ; (t fi'om tim l/rior text will be small and accordingly the b  (  ; nelit of ; tienie tho d will gen (' x-ally tie small . 
l~os(' . nti ' M proliosed t ; he % rigger model " to try toov (' . r (: om (~' this limitation ( Rosentb M , 1992) . lie used a large (: or pusto build as (' . to f " trigger tmirs " , each of which consists of it l ) a . ir of word sal)t ) (' . ar-big in a single ( to ( :um ( m to t : aliir g ( ~ corpus . Th(~se pairs ar (' . used as a (: om I ) on cnl ; inth('~t ) rot ) nt ) ilisti(:mo(M . If a particular word wapt ) (' . ars in the 1) re-ceding t('~xt of do (: mn cnt , the model will 1) red (: ( a . 
l mightened t ) rot ) al ) ility not just for wt ) ut also for all th (  ; wor ( ls related to w through a trigger I/a . ir . 
Our apt ) roa (: h can b ( ; briefly summarize ( las follows . The topic or sut ) jecl ; matter of ; mm-title influcn(:( ; sits linguistic l ) rot ) eri ; i( ; s , su(:hasword ( ; hoic(~and(:o-oc(:m'ren(:epatt(~rns ; inctl '( ~ ctitgiv (' . srise , oaverySl)ccializc(l " sublmlguag(~"forth ; tt topic . We try to find the sul ) languag(~to which t , h(' , artel ( ; 1 Mongs based on the sentences already recognized . Atacert ; finstag ( ; of the st ) ee ( : h recognition processing of an artel ( ' . , words in ; hi ; pr ( ; viotlsll ; ;(2r~rlic(?s & ro s(~ . le(;i ; ( Rt ~) ~ skeywords . Then , based on the keywords , simi-lm'arti (' . h . ' s are retri (' . ved from a large corpus t ) y an mth od similar to that used i il information retrieval  . They are asseml ) l ('~ d into a subla . nguag (', " mini-cortms " fortimmt i(:h ', . Then w canalyze the mini- ( : orlms in or ( lcr to d ( ~ tc , rminc word l ) rcf ( ; rcn ( : c whi ( : h will l ) e used in analyzing the following sen-t ( mcc . The & ; tails(if e , a chstet ) will be described lat ( ~ u ' . 
Our work is similar to I ; ll ~ I ; using triggert ) ~ firs . 
l to wever , the triggea '); fir approach does a . v(uybroads('~a . rch , retrieving m ' t i (: h ; s which have any word in common wil ; h the , 1) rior discourse ' . ( ) llrap-pro ~ , ch , in contrast , makes a Inll chlnor cfOCllSSe(tsear (: h , taking only a small set of articles most similar to the prior discourse  . This may allow us to make , sharper t ) redictions in the case of well-problems due to homographs by searching for a  ( : on junction of words .   ( Rosenfeld has indicated that it may bet ) ossible to achieve similar results by an enhancement to trigger pairs which uses multiple triggers  ( Rosenfeht ,  1992) . ) In addition , our approach needs less machine power . This was one of tile major problems of Rosenfeld 's approach  . 
Sekine has reported on the effectiveness of sublanguage identification measured in terms of the Dequency of overlapping words between an article and the extracted sublanguage corpus  ( Sekine ,  1994) . In this paper , we report on its practical benefits for speech recognition  . 
2 Speech Recognition System
This research is being done in collaboration wittl SRI  , which is providing the base of the combined speech recognition system  . ( Digalakis et . al . , 1995) . We use the Nbest hypotheses produced by the Sill system  , alon G with their acoustic and language model scores  . There are two acoustic scores and four language scores  . Language scores are namely the word trigram model  , two kinds of part of speech 5gram model and the number of tokens . Note that none of their language models take long -range dependencies into account  . We combine these scores with the score produced by our sublanguage  ( : omponent an ( 1 our cache i node l score , and then select the hypothesis with the , highest combined score as the output of our system  . The system structure is shown in Figure 1 . 
The relative weights of the eight scores are determined by an optimization procedure on a training dataset  , which was produced under the same conditions as our evaluation dataset  , troth as no overlap with tile evaluation data set  . The actual conditions will be presented later . 
SRI Speech ~__ ~ YUI
Recognizer 1Nbest/hi (
Ii-grain scores
Combinescoic
Best hypothesis
Languag(t
Models /, anguage score
Figure 1: Structure of the system 3 Sublanguage Component The sublanguage component performs the following four steps :  1  . Select keywords from previously uttered sen -tellces  2  . Collects ilnilar articles flom a large corlms based tm the keywords  3  . Extract sublanguage words fl ' om the similar articles  4  . Compute scores of Nbest hypotheses based on tile sublanguage wor  ( lsAsublanguage analysis is performed separately for each sentence in an artieh  ; ( afl ; er the first sentence ) . There are several parameters in these pro ~ eesses  , and the values of the parameters we use tl for this experiment will be summarized at the end of each section below  . We generally tried several parameter values and tile vahles shown in this paper are the best ones on our training dataset  ;  . 
We used a large corpus in the experiment as the source for similar articles  . This corpus includes 146 , 000 articles , or 76M tokens , from January 1992 to . hfly 1995 of North American Business News which consists of Dow Jones Information Services  , New York Times , Reuters North American Business Report , Los Angeles Times , and Washington Post . This corpus has no overlap with the evaluation dataset  , which is drawn from August 1995 North American Business News . 
Now , each step of our sublanguage component will be described in detail  . 
Select Keywords
The keywords which will be used in retrieving similar articles are selected from previously dictated sentences  . Tile system we will describe here is an incremental adal  ) tation system , which uses only the inlbrmation the syst ; em has acquired from tile previous utterances . St ) it does not know the correct transcriptions of prior sentences or any information about subsequent sentences in the article  . 
Not all of l , he words from the prior sentences are used as keywords for retrieving similar articles  . As is the practice in information retrieval , we filtered out several types of words . First of all , we know that closed class words and high frequency words appear in most of the documents regardless of the topic  , s t ) it is not usefl fl to include these as keywords . On the other hand , very low frequency words so inetimes introduce noise into the retrieval process because of their peculiarity  . 
Only open-class words of intermediate flequene y ( actually frequency from 6 to 100000 in tile corpus of 146  , 000 articles ) are retained as keywords and used in finding the similar article mAlso  , because the Nbest sentences inevitably contain errors  , we set at threshold for the appearance of words in tile Nbest sentences  . Specifically , we require that a senten ( ; es ( as rank e , ( l/ySl . \[' s (: or e ) 1 ; o(luali(y as a keyword for retriew d . 
~ Pat " an mq , er?-Vahm
Max freqnen (: y of a keywor ( l100000I
M infrequene y of a keyword ( i0/
Nbest for ke.ywor (1 sele(:tion
M in word ai ) pear a nees in N-1) est i15 ?
Collect Similar Articles
The sex of keywords is used in order to retrieve similar art Mesa  . c (: ording to the folh ) wing formulas . Ilere Weigh , ; (' w ) is the weight of word w , F ' (' w ) is the , frequency of w ( ird ' W in the 20N best senten ( : es , M is the total I tumb ( _!\]'  ( )\[' t ( )kens in the corpus , t/(w ) is the Dequen (: y of word w in the corpll S , AScorc(a ) is art Meseorc of a . rt Mea , which indicates the similarity between the set of keywords an  ( l the art M e , and n(a ) is the mmfl ) er of tokens in article a . 
Mw , . , : : j h ~ . ( . ,,,) : 1 . '( . , , , ) ? 1, , : j (~76, , ~) (0mgoo, . (~( . ) -- F . , , , ~ , , w,@h . 4, , , ) lo . ( , ,(  . )) (2) Fm , ch keyword is weighted by t ; hel ) rodu (: t of two factors . One ( if them is the fr ( ; (luen ( : y of the wor ( t in the 20N-1 lest senten ( : es , and the other is the log of the inverset ) robability ( ) f the wor ( l in the large e or t m s . This is a standard metric ( ) f infer mation retrieval based on the assumption dm t the higher fre  ( luency w ( irds provide less intormation about topics ( Si ) arck-Jones ,  1973) . Article scores ( A S co re ) for all articles in the large ( : or tms are ( : o Inputed as the sum of the weighted scores of the select e  ( t keywords in each art i ( : le , an ( 1 aren ( ir-realized t ) y the log of the size of each article . This s ( : orein ( li ( : ates the similarity b ( ! tween the set , of keywords and the article . We ( : olleet the most similar 50 artMes D ( )m the corpus . These for ln the . " sift ) language . set " , whi ( : h will I ) e use ( l in analyzing the f ( )llowing sentenc4 ; in the test m'ti(:le . 
Iwl " e Iumber of art Mesill sublanguage set
Extract Snb language words
Sublanguage words are extra ( : ted from the collected sublangua geart Mes . This extraction was done ill order to filter out to t  ) i ( :- um'elated words . 
ltere , we exeht defl metion WOl'dS , as we did for keyword selection , 1) et a , useflm ( : donwords are generally coIn Ill Oll throughout ( ti\[threntsul ) languages . 
Next , to find strongly to t ) ie related words , we ex-tracl ; ed words which a pl/ear in at least 3 ( lilt ( if the 50 sublmlguage articles . Also , the do ( : tnnentDe-quen ( : y in sublanguage articles has to be at least 3 times the word Dequency in the large corpus :
Dt/('w)/50>3 (3)
F ( w)/M
Itere , DF ( w ) is the number of do ( : uments in whi ( : h the wor ( lapl ) ears . We (: m~expe (: that the seme ; h-e(Iseliminate , less top i (: relate ( l words , s ( ) dtat only str ( mgly to t ) i ( : related wor ( tsare extra ( : ted as the sul ) language words . 
I'al'a,~,ete,'-\[~il.~\]
Min'lum of ( l ( /euments with the w ' ) 7 '  ( l\[33 l
Thr ( !shol ( 1 ratio of wor ( 1 in the set and in general Compute Scores of N - best Hypotheses Finally  , we (' omput ( ,  . scores of the Nbest hypothe-s(;sgen (' . rnted l ) y the speech recognizer . ' Fhetop100 N-t )( ; st hypotheses ( ae ( : ording to SIH's score ) arer ( >s ( :or ( ~ ( l . The sul ) language score we assign t ; ( ) each word is the logarithm of the ratio of d ( )cu-nlent h'e ( lueal ( : y in the sublanguage m'ticles to the word frequen ( : y of the word in tile large corpus . 
The larger this s (: ore of a word , tile more strongly the word is related to the sublml guage we found through the tirior discourse  ,  . 
Thes (: or e\['orea (: h sentenc ( ; iseal ( : ulated by a ( :- ( : unmlating the score of 1 hesele ( :te ( lwor ( lsill the hyt ) othesis , tlere l\[Sco'rc ( h ) is the sut ) language score of hypothesis h . 
,  . ./ oF (, . O/so , tls '( ~ . o, . ( , ( h ) = ~ , ( , ~ F  ~; , ) ) X 7  ~ ( 4 ) winh This formula can be motivated by the fact that die sublanguage score will be combilm  ( t linearly with general anguage nlo ( Ms ( : or es , wh Ml mainly consist of the logarithm of the trigram  1  ) robabil-ides . The denominator of the log in Formula 4 is the unigram probability of w or ( t  w . Sin(:eit is the(h ! nonlinator () falog arithm , it ; winks to reduce the effect of the general laltgl iage model whMl may be  ( : ; robed(led in the trigranl language mo(M score . 
Then mner at ( )r is a pure sublanguage score and it works to ad ( ltims (  ; or ( ~ of the sublanguage mo ( M to the ( ) ther s ( :ores . 
4 Cache model
A cache model was also used in o/lr ( ; xpetilll ( ! ilt . 
We ( lid not use all the words in tile previous ul > teran  ( : e , but rather filtered out several types of words in order to retain only lopi  ( : relate ( 1 words . 
We , actually used all of the " selected keywor ( ls " as explained in the last section for our ca ( : he model . 
Seo ~' es for the words iil (: ~ ehe(CS , : o , ' , < , , , )) a , e(xmq ) ut ( ; d in a similar way to that for sublanguage words . Here , N ' is the number of tokens in the previously uttere  ( tN best sentences . 
1,"(,,,)/:v'cs ', ~ o . , . , . .(1, . )--_ . ~, lo ~( .   .   .   . ) Is ), , , i , .   .   .   .   . I . . F ( w ) /M 5 Experiment The speech recognition experiment has been conducted as a part of the  1995   AI1  , PA continuous sion of NIST ( NIST ,  1996) . The conditions of the experiment are : ? The input is read speech of unlimited vocabulary texts  , selected from several sources of North American Business  ( NAB ) news from the period 131 August 1995 ? Three non-close talking microphones are used anonymously for each article ? All speech is recorded in a room with background noise in the range of  47 to 61 dB ( A weighted ) ? The test involves 20 speakers and each speake reads 15 sentences which are taken in sequence from a single article ? Speaker genderivun known The SRI system  , which we used as the base system , produces N-bent ( with N = I . 00) sentences and six kinds of scores , as they are explained before . 
We produce two additional scores based on the sublanguage model and the cache model  . The two scores are linearly combined with SRI's six scores  . The weights of the eight scores are determined by minimizing the word error on the training data set  . The training dataset , has speech data recorded under the same conditions as the evaluation dataset  . The training dataset consists of 256 sentences , 17 articles ( a part of the ARPA 1995 CSR " devtest " data distributed by NIST ) and does not overlap the evaluation dataset . 
The evaluation is clone with the tuned parameters of the sublanguage component and the weights of the eight scores decided by the training optimization  . Then the evaluation is conducted using 300 sentences , 20 articles ,   ( the ARPA 1995 CSR " evaltest " distributed by NIST ) disjoint fl ' om the devtest and training corpus . The evaluation of the sublanguage method has to be done by comparing the word error rate  ( WER ) of the system with sublanguage scores to that of the SRI system without sublanguage scores  . 
Inevitably , this evaluation is affected by the performance of the base system  . In particular , the number of errors for the base system and the min-immn number of errors obtainable by choosing the Nbest hypotheses with minimm n error  , are important .   ( We will call the latter kinds of error " MNE " for " minimal Nbest errors "  . ) The difference of these nmnbers indicates the possible improvement we  ( : an achieve by restoring the hypotheses using additional components  . 
We can't expect our sublanguage model to fix all of the  375 word errors ( non-MNE )  . For one thing , there are a lot of word errors unrelated to the article topic  , for exmnple function word replacement ( " a " replaced by " the " )  , or deletion or insertion of topic unrelated words  ( missing
Num . of error WER
SRI system 1522 25.37%
MNE 1147 19.12%
Possible hnprovement 375 6.25%
Figure 2: Word Error of the base system and MNE " over " )  . Also , the word errors in the first sentence of each article are not with ii ~ our means to tlX  .  \]  6 Result The absolute improvement using the sublanguage component over SRI's system is  0  . 65%, from 25 . 37% to 24 . 72%, as shown in Table 3 . That is , the number of word errors is reduced froin 1522 to 1483  . This means that 1 . 0 . 40% of the possible improvement was achieved ( 39 out ; of 375) . The





Num . of

Improve exel . MNE 10.40%
Figure 3: Word Error Rate absolute improvement looks tiny , however , the reJ-ative improvement excluding MNE ,  10 . 40 % , is quite impressive , becmlse there are several types of error which cannot be corrected by the sublanguage model  , as was explained before . 
The following is an example of the actual outtmt of the system  . ( This is a relatively badly recognized example . )  . . . . Example . . . .
in recent weeks hyundai corporation and fujits u limited announced plans for memory chipplants in oregon at projected costs of over one billion dollars each in recent weeks CONTINENT ALVERSION SUGGESTSONLY limited announced plans for MEMBERSHIP FINANCING FORITHAD projected 
COST of one DAY each in recent weeks CONTINENTAL VERSION SUGGESTSONLY limited announced plans for memory chipplants in WORTHINGTONPROJECT 
COST of one MILLION each 1Note that , in our experiment , a few errors in tat-tim sentences were corrected , because of the weight optimization based oil the eight scores which includes all of the SRI's scores  . But it ; is very minor and these improvements are offset by a similar number of dis-improvements caused by tile same reason  . 

The first sentence is the correct transeri I ) tion , the second one is SRI's best scored hypothesis , and the third one is the hypothesis with the highest combined score of SRI and our models  . This sentence is the 15th in an article on memory chipproduction . As you can see , a mistake in SRI's hypothesis , membership nstead of memory and chip , was replaced by the correct wor(ts . I lowever , other parts of the sentence , like hyundai corporation and fujits u , were not amended . V ~ Telkmnd that this particular error is one ( If the MNE , for which there is no ? ' orre et candidate in the Nbest hypotheses  . Another error , million or day instead of billion , is not a MNE . There exist some hypotheses which have bill i on at the right spot  ,   ( the 47 the an ( lidate is the top candidate which has the word )  . Our sublanguage model works to replace word day by million  , but this was not the correct word . 
7 Discussion
Although the actual improvement in word error rate is relatively small  , partially because of f a ( :- tors we ( : ould not control , of which the probleni of MNE is the most important  , the results suggest that the sul ) language technique may lie useful in improving the si  ) eeeh recognition system . One of the methods for increasing the t ) ossibility ( if improvement is to make N ( of Nbest ) larger , thus including more . corre(:thypo theses in the . Nbest . 
We tried this , becmlse SRI actually provided us with 2000 Nbest hypotheses . However , parameter optimization showed us that 100 is the o i ) ti-real numl ) er for this parm neter . This result can be explained by the folh ) wing statistic . Table 4 describes the nuin ber of MNE as a function of N for the training dataset  ; and evaluation ( lataset : . 
Also in parentheses , the numl ) er of poss it ) leim-proveinents for each case is shown . A e (' or ( ling to
NMNEMNE ( evaluation )   ( training )  1 1522 50 1163  ( 359 )  100 1147  ( 375 )  200 \] 134  ( 388 )  500 1116  ( 406 )  1000 1109  ( 41 . 3) 2000 1107 (415) 960 (298) 947 (311) 935 (323) 93() (328) 929(329)
Figure 4: N and Word Error the table , the number of MNE decreases rapidly for N up to 100  ; however , after that point , the number decreases only slightly . For example , in the ewduation dataset , increasing Nfl'om 500 to 2000 introduces only 9 new possible word error improvements . We believe this small number gives our colnponent greater opt  ) ortunity to include errors rather than improvenlents  . 
Improvements will no doubt be possible through better adjustment of the parameter settings  . 
There are parameters involved in the similarity calculation  , the size of the sublanguage set , the ratio threshold , etc . To date , we have tuned them by manual optimization using a relatively small mnnt  ) er of trials and a very small training set ( the 20 articles for which we have Nbest transcrit ) -dons )  . We will need to use automatic optimization methods and a substantially larger training set  ;  . Since we do not have a much larger set of articles with speech data  , one possibility is to optimize the systeln in terlns of perplexity using an nlch larger text corpus for training  , and apply the optimized parameters to the speech recognition system  . With regard to the size of sublan-guagcset , a constant size may not be optimal . 
Sekine ( Sekine ,  1994 ) reported on a next mriment which selects the size automatically by seeking the ininimum ratio  ( )\[ the docunlent set , perple . xity to ; lie estimated t ) erplexity of randomly schooled oc-ument sets of that size  . This approach can be applit ' abh ' ~ to our systeln . 
Wc may also need to reconsider the strategy for incorporating the sublanguage component into the speech recognition system  . For example , it might be worthwhile to reconsider how to mix our score with SRI's language model score  . SRI provides language model scores for each hyi ) othesis , not for words . However , we can imagine that , if their language score can be computed with high confidence for a particular word  , then our model should have . relatively little weight . On the other hand , if the language model has low confidence , sublanguage should have strong weight . In other words , the combination of the scores should not be done by linear combination at the sentence level  , but should be done at the word level . 
Also there are several things we need to re -ewduate regm:ding our sublanguage model  .   ( ) lie of thenl is the threshold method we adopt here  , which introduces undesirable discontinuities into our la  . nguage model . The method for retrieving similar articles may also need to be modified  . We . 
used a silnple technique whit : his conunoil in information retrieval research  . However , the pur~pose of our system is slightly different from that of information retrieval systems  . So , one fllture direction is to look for a more suitable retrieval method for our purpose  . 
in closing , we wish to mention that the sublanguage technique we have described is a general approach to enhancing a statistical language model  , and is therefore applicable to tasks besides speech recognition  , such as optical ( : haracter recognition and machine translation . For exam-lfl C , if a machine translation system uses a statistical model for target language word choice  , our more topic related words . 
8 Acknowledgment
The work reported here was supported by the Advanced Research Projects Agency under contract  DABT63-93-C-0058 from the Department of the Army . We would like to thank the collaboration partners at SRI  , in particular Mr . Ananth Sankar and Mr . Victor S . Abrash . Also we thank for useful discussions and suggestions Pr of  . Grishman and Slava Katz . 

Satoshi Sekine , John Sterling and Ralph Grish-mail 1995 NYU/BBN 1994 CSR evaluation In Proceedings of the ARPA Spoken Language 
Systems Technology Worksh,op
R Kuhn .   1988 Speech Recognition and the Frequency of Recently Used Words : A Modified Markov Model for Natural Language In Proceedings o : f  I2th International Conference on
Computational Linguistic
FJelinek , B Merialdo , S Roukos , and MStrauss.
1 991 A Dynamic Language Model for Speech Recognition In Proceedings of Speech and Natural Language DARPA Workshop JKupiec  .   1989 Probabilistic Models of Short and Long Distance Word Dependencies in Running Text In Proceedings of Speech and Natural Language DARPA Workshop Ronald Rosenfeld and Xuedong Huang  .   1992 Improvements in Stochastic Language Modeling In Proceedings of DARPA Speech and Natural 
Language Workshop
Satoshi Sekine 1994 A New Direction for Sublanguage NLP In Prvcecdings of International conference on New Mcthods in Language Processing KS parck Jones  .   1973 Index Term Weighting In Information Storage and Retrieval  , Vol . 9 , p619-Sankar , Horaeio Franco , Leonardo Neumeyer , and Hy Murveit 1995 Continuous Speech Dic-tation on ARPA's North Business News Domain in Proceedings of the ARPA Spoken Language 
Systems Technology Workshop , p88-93
David S . Pallett et . al , to appear 1995 Benchmark Test for the ARPA Spoken Language Program In Proceedings of the ARPA Spoken Languagc 
Systems Technology Workshop
