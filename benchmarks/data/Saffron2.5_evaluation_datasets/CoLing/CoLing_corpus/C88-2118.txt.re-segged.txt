Parsing Noisy Sentences
Hiroaki SAITO
Center for Machine Translation
Carnegie Mellon University
Pittsburgh , PA 15213, USA

ATR Interpreting Telephony Research Laboratories
Twin21 MID Tower , 2-1-61 Shiromi
Higashiku , Osaka 540, Japan
Masaru TOMITA
Center for Machine Translation
Carnegie Mellon University
Pittsburgh , PA 15213, USA
Abstract
This paper describes a method to parse and understanda " noisy " sentence that possibly includes errors caused by a speech recognition device  . Our parser is connected to a speech recognition device which takes a continuously spoken sentence in Japanese and produces a sequence of phonemes  . The output sequence of phonemes can quite possibly include errors : altered phonemes  , extra phonemes and missing phonemes . The task is to parse the noisy phoneme sequence and understand the meaning of the original input sentence  , given an augmented contextfree grammar whose terminal symbols are phonemes  . A very efficient parsing method is required , as the task's search space is much larger than that of parsing un-noisy sentences  . We adop the generalized LR parsing algorithm , and a certain scoring scheme to select the most l ikely sentence o~t of multiple sentence candidates  . The use of a confusion matrix , which is created in advance by analyzing a large set of input/output pairs  , is discussed to improve the scoring accuracy . The system has been integrated into CMU's knowledge-based machine translation system  . 
1. Introduction
There have ~ been a few attempts to integrate a speech recognition device with a natural anguage understanding system  . Ita ~, eset . al / Hayes86/ adopted the technique of case frame instantiation to parse a continuously spoken English sentence in the form of a word lattice  ( a set of word candidates hypothesized by a speech recognition module  ) and produce a frame representation f the utterance  . Poesio and Rullemt/Poesio 1987/ suggested a modified implementation f the case frame parsing to parse a word lattice in : italian  . Lee et . al/Lee 1987/developed a prototype Chinese ( Mandarin ) dictation machine which takes a syllable lattice ( a set of syllables , such as\[guo-2\] and\[tieng-:l\] , hypothesized by a speech recognition module ) and produces a Chinese character sequence which is both syntactically and semantically sound  . 
In this paper , we try to parse a Japanese utterance in the form of a sequence of phonemes  . 1 Our speech recognition device , which is a high-speed speaker-independent system developed by Matsushita Research Institute/Mori i  1985/  , / Hiraoka 1986/ takes a continuous peech utterance , for 1 . Phonemes ( e . g . /g\],/ed,Is /, etc . ) are even lower level units than syllables . 
2 . We distinguish noisy from ill-formed . The former is due to recognition devic errors , while the latter is due to human users . 
example " megaitai " (" I have a pain in my eye . ") , from a microphone and produces a noisy phoneme sequence such as " ebaita ai  . " 2 The speech recognition device does not have any syntactic or semantic knowledge  . More input/output examples of the speech device are presented in Figure  11  . 
< correct sequence > < recognition output > igarn uka muka suru ---> i gangu ka mukusjuru ig a muka monk as juru kubigako wabaqteiru ---> kurigakoogateiruazubigako abaq ciir uatamagaitai- -- :> otomogaitai at amogeita in  Figurel-1: Input and Output of Recognition Device Note that the speech recognition device produces a phoneme sequence  , not a phoneme lattice ; there are no other phoneme candidates available as alternates  . We must make the best guess based solely on the phoneme sequence generated by the speech device  . Errors caused by the speech device can be classified into three groups : ? Altered Phonemes -- Phonemes recognized incorrectly  . 
The second phoneme/b/in"ebaitaai " is an al tered phoneme  , for example . 
? Missing Phonemes -- Phonemes which are actually spoken but not recognized by the device  . The first phoneme/nd in " megaitai " , for example , is a missing phoneme . 
? Extra Phonemes -- Phonemes recognized by the device which are not actually spoken  . The penultimate phoneme/a/in " ebaitaai " , for example , is an extra phoneme . 
To cope with these problems , we need : ? A very efficient parsing algorithm , as our task requires much more search than conventional typed sentence parsing  . And ? A good scoring scheme , to selec the most likely sentence out of multiple candidates  . 
In sections 2 and 3 , we describe the parsing algorithm and the scoring schelhe  , respectively . 
2. The Parsing Algorithm
The grammar we are using is an Augmented ContextFree Grammar whose terminal symbols are phonemes rather than words  . That is , the grammar includes rules like instead of
Noun -->' watasi '
The grammar has ? been developed primarily for CMU's knowledge-based machine translation system / Tomita  1987/and consists of more than 2000 rules including lexical rules like One above . 3 2 . 1 . Generalized LR Parsing Tomita/Tomita 1985/ , / Tomita 1987b /introduced the Generalized LR Parsing Algorithm for Augmented ContextFree Grammars  , which ? can ingeniously handle nondeterminism and ambiguity with a graph-structured ? stack  . Tomita also showed that it can be used for a word lattice parsing from it a  1986/  . Our algorithm here is based on Tomita's parsing algorithm  . 
A very simple example grammar is shown in Figure 21  , and its LR parsing table , compiled automatically from the grammar , is shown in Figure 22 . 
(1 ) S-->NPPD ( 2 ) S - -> N ( 3 ) S-->PD ( 4 ) NP-->NP ( 5 ) N - -> me ( 6 ) N - -> i ( 7 ) P-->ga ( 8 ) PD --> itai
Figure 21: An Example Grammar
State a emgt$NNP PPDS .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
0s 4s 523 161 r32 s7 , r283s9 104 r6s 11 , r 6   5   s12   6 acc 7   s13   8   r4   11   s14   14   s15 rl r5   r5   r8 Figure 22: LR Parsing Table with Multiple Entries Grammar symbols of lowercase characters are terminals  . 
The Generalized LR parsing algorithm is a table driven shift-reduce parsing algorithm that can handle arbitrary contextfree grammars in polynomial time  . Entries " sn " in the action table ( the left part of the table ) indicate the 3 . The runtime grammar , which contains both syntax and semantics , is compiled automatically from more abstract formalisms : the Functional Grammar formalism for syntax and frame representation for semantics  . For more discussions on this Universa IParser A chitecture  , see from it a 1987 a\] . 
action " shift one word from input buffer onto the stack and go to state n "  . Entries " rn " indicate the action " reduce constituents on the stack using rule n "  . The entry " acc " stands for the action " accept  "  , and blank spaces represent " error " . The go to table ( the right part of the table ) decides to which state the parser should go after a reduce action  . 
While the encountered entry has only one action , parsing proceeds exactly the same way as LR parsers  , which are often used in compilers of programming languages  . When there are multiple actions in one entry called conflicts  , all the actions are executed in parallel with the graph-structured stack  . We do not describe the Generalized LR parsing algorithm in greater detail  , referring the reader to/Tomita 1985/ , / Tomita 1986/ , from it a 1987b/ . 
2 . 2 . Handling altered , extra , and missing phonemes To cope with altered , extra and missing phonemes , the parser must consider these errors as it parses an input from left to right  . While the algorithm described in the previous subsection cannot handle these noisy phenomena  , it is well suited to consider many possibilities at the same time  , and therefore , it can be relatively easily modified to handle such noisy phenomena as the following  . 
? Altered phonemes -- Each phoneme in a phoneme sequence may have been altered and thus may be incorrect  . 
The parser has to consider all these possibilities  . We can create a phoneme lattice dynamically by placing alternate phoneme candidates in the same location as the original phoneme  . Each possibility is then explored by each branch of the parser  , Not all phonemes can be altered to any other phoneme ~ For example  , while / o / can be m is recognized as / u / , / i / can never be m is recognized as / o / . This kind of information can be obtained from a confusion matrix  , which we shall discuss in the next section . With the confusion matrix , the parser does not have to exhaustively create alternate phoneme candidates  . 
? Extraphonemes -- Each phoneme in a phoneme sequence may be an extra  , and the parser has to consider these possibilities  . We have one branch of the parser consider an extra phoneme by simply ignoring the phoneme  . The parser assumes at most one extra phoneme can exist between two real phonemes  , and we have found the assumption quite reasonable and safe  . 
? Missing phonemes -- Missing phonemes can be handled by inserting possible missing phonemes between two real phonemes  . The parser assumes that at most one phoneme can be missing between two real phonemes  . 
2.3. An Example
In this subsection , we present a sample trace of the parser . 
Here we use the grammar in Figure 21 and the LR table in Figure 22 to try to parse the phoneme sequence " ebaitaai " represented in Figure  23  .   ( The right sequence is " megaitai " which means " I have a pain in my eye  . ")
T . ir I , l , , : J ,
Figure 23: An input sequence of phonemes altered and Z aissing phonemes  . 
?/ i/may possibly be misrecognized as/e/.
?/ e/may posvibly be misrecognized as/a/.
. / g/may possibly be misrecognized as/b/.
? / m/may be missed in the output sequence with a higher probability  . 
Now we begin parsing : first an initial state 0 is created . 
The action table indicates that the initial state is expecting " m " and ' T '  ( Figure 24 )  . Since the parsing proceeds strictly from left to right  , the parser looks for the missing phoneme candidates between the first time frame  1  -  2  . ( We will use the term T1, T2 . . . . for representing the time 1, time 2 . . . . in Figure 23 . ) Only the missing phoneme " m " in this group is applicable to state  0  . The new state number 5 is determined from the action table ( Figure 25 )  . 
The next group of phonemes between T2 and T3 consists of the %" phoneme in the phoneme sequence and the altered candidate phonemes of " e "  . In this group %" is expected by state 5 and ' T ' is expected by state 0  ( Figure 26 )  . After " e " is taken , the new state is 12 , which is ready for the action " reduce 5" . Thus , using the rule 5(N-->me ) , we reduce the phonemes " me " into N . From state 0 with the nonterminal N , state 2 is determined from the go to table . 
The action table , then , indicates that state 2 has a multiple entry , i . e . , state 2 is expecting " g " and ready for the reduce action  ( Figure 27 )  . Thus , we reduce the nonterminal N into S by rule 2 ( S - -> N )  , and the new state number 6 is determined fl ' om the go to table ( Figure 28 )  . The action table indicates that state 6 is an accept state , which means that " me " is a successful parse . But only the first phoneme " e " of the input sequence " ebaitaai " is consumed at this point  . Thus we discard this parse by the following constraint ?\[ Constraint  1\] The successful parse should consume the phonemes at least until the phoneme just before the end of the input sequence  . 
Note that only the parse S in Figure 28 is ignored and that the nonterminal N in Figure 27 is a live . 
Now we return to the Figure 26 and continue the shift action of ' T ' . After " i " is taken , the new state 4 is determined from the action table . This state has a multiple entry , i . e . state 4 is expecting " t " and ready for the reduce action  . Thus we reduce " i " into N by rule 6 . Here we use the local ambiguity packing technique  , because the reduced nonterminal is the same , the starting state is 0 for both , and the new state is 2 for both . Thus we do not create the new nonterminal N . 
Now we go on to the next group of phonemes between  T3 and T4  . Only " m " is applied to the initial state ( Figure 29 )  . 
The next group of phonemes between T4 and T5 has one applicable phoneme , i . e . an altered phoneme candidate " g " to state 2 . After " g " is taken , the new state 7 is determined from the action table ( Figure 210 )  . 
The next group of phonemes between T5 and T6 has only one applicable phoneme ; a missing phoneme candidate " m " to state O . Here we can introduce another constraint which discards this partial-parse  . 
\[ Constraint 2\] After consuming two phonemes of the input sequence  , no phonemes can be applied to the initial state 0 . 
i0* i*m ,
Figure 2412: ~."5* e
Figure 251 23* i5*m " e12 o ":: ; ::: "7""7" - "::'" 4 " . :: . 
..., m
Figure 21012* i\[5* m1~3* e\[rS\]
I2*i*moz . . . . . ~0"(':::: m', . :; : : : : : : g * a " ~* e " 7" i % , * i * m0; ; '"" , * t


Figure 21123*e..m..
Figure 27'12'4'2
Jr2\]i*g !"7 . . . . \[ rT \] * a \[ r4\] * mo "::::::* i*m'e 12   , i4\[r61*t$6aec
Figure 282,:::::.

N*i*mo".):'~34,
N '* t , , . ., ~5 mI * e13
NP\[13 i
Figure 212 mm::::::..
3e~4'i ....* t~mi2*gi
Figure 29*i*m0""::" . : .  ~ . , , :" i2'53* eme
N4"Y(*eg"Y ""* R , i
Figure 213/*i*i*m0""::'" . .~'::: i 3   4 e than two phonemes are recorded before the actua l beginning phoneme for our speech recognition device  . 
The next group of phonemes between T6 and T7 has two applicable phonemes , i . e . the output phoneme " a " to state 7 and the altered phoneme candidate " e " to state 5  . After " a " is taken , the new state 7 is ready for the reduce action . 
Thus , we reduce " ga " into P by rule 7 ( Figure 211) . The new state 8 is determined by the go to table , and is also ready for the reduce action . Thus we reduce " NP " into NP by rule 4 ( Figure 212 )  . The new state is 3 . In applying " e " , there are two " state 2"s : one is " m " between T1 and T2  ; the other one is " m " between T3 and T4 . ' Here we can introduce a third constraint which discards the former partial-parse  . 
\[ Constraint 3\] A shift action is not applied when , the distance between the phoneme and the appl ied  ( non ) terminal is more than 4 .   ( This distance contains at least one real phoneme . ) Figure 213 shows the situation after " e " is applied . 
The parsing continues in this way , and the final situation is shown in Figure 214 . As a result , the parser finds two successful parses ; " megaitai " and " igaitai " ( which means " I have as to machache . ") 3 . Scoring and the Confusion Matrix There are two main reasons why we want to score each parse : first  , to prune the search space by discarding branches of the parse whose score is hopelessly low  ; second , to selec the best sentence out of multiple candidates by comparing their scores  . Branches of the parse which consider fewer altered/extra/missing phoneme should be given higher scores ? Whenever a branch of the parse handles an altered/extra/missing phoneme  , a specific penalty is given to the branch . Scoring accuracy can improve with the confusion matrix  . 
Figure 31 shows a part of the confusion matrix made by the manufacturer of the recognition device from the large word data  . This matrix tells us , for example , that if the phoneme/a/is inputed , then the device recognizes it m
M " ! t , . .
Figure 2-14"2"
I 15.16 ~15\[r 81
I\Olal Io/lullil ~ elIjllwl . . . (I ) ( ll ) la /
Iollul / i / ~ el/j /
I w l ( m ) 93 . 8 1 . 1 1 . 3 0 2 . 7 0 0  . . .  0 . 9 5477 2 . 4 84 . 3 5 . 8 0 0 . 3 0 0 . 6  . . .  6 . 5 7529 0 . 3 1 . 8 79 . 7 2 . 4 4,6 0 . 1 0  . . .  9 . 7 5722 0 . 2 0 0 . 9 91 . 2 3~5 0 . 7 0  . . .  2 . 9 6158 1 . 9 0 4 . 5 3 . 3 89 . 1 0 . 1 0  . . . . 1 . 1 3248 0 0 1 . 1 2 . 3 2 . 2 80 . 1 0 . 3  . . .  11 . 4 2660 0;2 5 . 1 5 . 8 0 . 5 0 2 . 6 56 . 1  .   .   .   .  11 . 2  428   327   176   564   512   290   864   212 rate of missing phonemes ( ii ' ) number of extra phonemes total number of samples Figure  3  . I : A Confusion Matrix ( portion ) correctly 93 , 8% of the time ; mls-recognizes it as/o/1 . 1% of the time , as/u/1 . 3% of the time , and so on . The column ( I ) says that the input is missed 0 . 9% of the time . 
Conversely , if the phoneme/o/is generated from the device , there is a slight chance that the original input was / a /  , / u / and / w / , respectively , but no chance that the original input was / i / , / e / or / j / . The probability of the original input being / a / is much higher than being / w /  . Thus , an altered phoneme/w/should be given a more severe penalty than / a /  . A score for altered phonemes can be obtained in this way  , missing phonemes should be Even a negative score , and extra phonemes should be given a zero or a negative score  . With this scoring a score of a partial parse is calculated by summing up the score of each constituent  . 
Therefore , the more likely parse has a higher score . 
Two methods have been adopted to prune partial parses by a score : ? Discarding the low-score shift-waiting branches when a phoneme is applied  . 
? Discarding the low-score branches in a local ambiguity packing  . 
The former method is very effective when strictly applied  . 
The confasion matrix only shows us the phoneme-to -phoneme f  ; ransition , therefore a broader unit transition should also be considered  , such as a tendency for the / w /: phoneme ia ' ow a ' or ' owo ' to be missed or for the very first/ h/sound of an input to be missed  , and the frequent transformation to'h@'of the ' su ' sound in ' desu ka  . ' 4 . Conclu , ,dons The parser has been implemented in Common Lispona Symbolics Lisp Machine and is being integrated into CMU's knowledge-based machine translation system to accept a spoken Japanese sentence in the domain of doctor patient conversation and generate sentences in English  , 
German and Japanese.
The parser has been tested against five persons . Each person pronounced 27 sentences in which long sentences are not include due to the limits of the speech recognition device  .   84 % of the inputs are parsed correctly and the right sentence appears as the best-score candidate in  88 % out of the correct ~ lyparsed inputs . The average parsing time for one sentence is82 seconds . 

The authors would like to thank Shuji Morii for giving us the opportunity ouse the speech recognition device and to thank other members of the Center for Machine Translatioa for useful comments and advices  . We are also indebted to ATR Interpreting Telephony Research Laboratories for providing the computational environment  . 
Appendix . Sample Runs
Two actual outputs of the parser are shown on the next page  . The first input phoneme sequence is " ebaitaai " and the correct sequence is " megaitai "  ( which is the same sentence as in the example in Section  2  . ) , which is produced as the top-score sentence of all parses  . The second input sequence is " kurigakoogateiru = " and the correct sequence is " kubigakowabaqteiru " which means " I have a stiff neck  . " The frame-structure output after each parse is the meaning of the sentence  . This meaning is extracted in the same way the CMU 's machine translation system does  . 
Namely ,  ~ ; a ch rule of the contextfree grammar has a function which is executed each time the rule is applied  ( i . e . 
when the reduce action occurs . ) If tale function returns nil , this partial parse is discarded because the parse is not correct semantically  . If the function returns a non-nil value , the value becomes the semantic of the right-hand -side of the rule and is forwarded to the left -hand-side nonterminal symbol  . The details are described in from it a 19870/ . 
References/Hayes 1986/Hayes , P . J . , Hauptmann , A . G . , Carbonell,
J.G ., and Tomita , M.
Parsing Spoken Language : A Semantic Case frame Approach  . llth International Conference on Computational Linguistics  ( COLING 86 )  . Bonn , August , 1986 . 
/Hiraoka 1986/Hiraoka , S . , Morii , S . , Hoshimi , M . , and
Niyada , K.
Compact Isolated Word Recognition System for Large Vocabulary  . IEEE-IECEJ-ASJ International Conference on Acoustics  , Speech , and Signal Processing ( ICASSP86) . 
Tokyo , April , 1986.
/Lee1987/Lin-shan Lee , Chiu-yu Tseng , K . J . Chen , and
James Huang.
The Preliminary Results of AM and arin Dictation Machine Based Upon Chinese Natural Language Analysis  . 
Proceedings of the Tenth International Joint Conference on Artificial Intelligence  . Milan , August , 1987 . 
/lVlorii1985/Morii , S . , Niyada , K . , Fujii , S . , and Hoshimi,

Large Vocabulary Speaker-independent Japanese Speech Recognition System  . IEEE International Conference on Acoustics , Speech , and Signal Processing ( ICASSP85) . 
Tam Pa , March , 1985.
/Poesio 1987/ Poesio , M . and Rullent , C.
Modified Case frame Parsing for Speech Understanding Systems Based Upon Chinese Natural Language Analysis  . 
Proceedings of the Tenth International Joint Conference on Artificial Intelligence  . Milan , August , 1987 . 
from it a 19851 Tomita , M.
Efficient Parsing for Natural Language : A Fast algorithm for Practical Systems  . Kluwer Academic Publishers . 
Boston , MA , 1985.
/Tomita 1986/Tomita , M.
An Efficient Word Lattice Parsing Algorithm for Continuous Speech Recognition  .   1EEE-IECEJ-ASJ International Conference on Acoustics , Speech , and Signal Processing ( ICASSP86) . Tokyo , April , 1986 . 
from it a 1987a/Tomita , M . and Carbonell , J . G . 
The Universal Parser Architecture for Knowledge -Based Machine Translation  . Proceedings of the Tenth International Joint Conference on Artificial Intelligence  . 
Milan , August , 1987.
/Tomita 1987b/Tomita , M.
An Efficient Augmented-Context-Free Parsing Algorithm  . 
Computational Linguistics . 1987.

Command : input = ebaitaa ~'
Co~n and : ( parse-s)
Evaluation of ( PRRSE ) took 31o522721 seconds of elapsed t in s inoludin9   7  . 183 secondsuaitin 9 for the disk for 39 faults . 
245,861 li~t .  51 , 644 structure ,  22 , 287 stackuor daoonaed in HORKIMG-BTORRGE-RRER . 
2 04 structure words consadin * MRME SPRCE-OOJECT -RRER*  . 
7 parsee Found.
1:  ( 185 ) M < l-2#-lO>E < 2-3#38 > G < 4-5#1 O )   R<6-7#32>   I<B-9#OO  >  T<IO-11#31>   R<12-13#32>   I<16-17#3g  >  ( ( MOOD ( ( ROOT DEC ) ) )   ( SEM*HRVE-R-PRIM 1802 )   ( OBJ ( (: NH - )   ( ORSEOR )   ( SEM * EYE )   ( ROOT ME ) ) )   ( CRUBRTIUE- )   ( OBJ-CRBEOR )   ( SUBJ-CRSEOR )   ( SUBCRT 2 RRG-GR )   ( COTRDJ )   ( TIME ( ( ROOT PRESEMT ) ) )   ( ROOTITRI ) ) 2:  ( 172 ) 1 < 2-3#7 > O ( 4 -5#10>   R<6-?#32>   I<8-9U39>   T<1@-11#31>   R<12-13#32>   I<16-1?#50>   ( ( MOOD ( ( ROOT DEC ) ) )   ( SEM*HRUE-R-PRIM 810 )   ( OBJ ( (: NH - )   ( CRSEOR )   ( SEM*STOMROH )   ( ROOTI )   )   )   ( ORUSRTIUE- )   ( OBJ-CROEOR )   ( SUBJ-ORSEOR )   ( SUBCRT 2 RRG-fiR )   ( COTRDJ )   ( TIME ( ( ROOT PRESENT ) ) )   ( ROOTITRI ) ) 3:  ( 115 )   I<2-3#?>   T<4-5#1>   R<6mT#32>   I<8-9#30>   K<IO-11#13>   R<12-13#32>   ( ( SEM * HRVE-R-PRIM930 )   ( TIME ( ( ROOT ( * OR~PRESEM TFUTURE ) ) ) )  ( MOOD ( ( ROOT gUE8 ) ) )   ( OBJ-CRBESR )   ( 8 UBJ-OROEOR )   ( SUBCRT 2 RRG-GR )   ( CRTRDJ )   ( ROOTITRI ) ) 4:  ( 119 )   H<4-5#S  >  R<6-7#32>   I<O-g#38>   K<IO-11#10>   R<12-18#32>   ( ( SEM * HRUE-R-FEUER46 )   ( TIME ( ( ROOT ( * OR*PRESEMT FUTURE ) ) ) )  ( MOOD ( ( ROOT QUES ) ) )   ( 0 OJ-CRBEOR )   ( EUBJ-CRSEOR )   ( CRUSRTIVE- )   ( PRBSIUE- )   ( SUBCRT STRT )   ( MESRTIOM ( ( ROOT HITEI ) ) )   ( CRTU )   ( ROOT RRU ) ) 5:  ( 70 ) I < 2-3#7>T < 4-5#1>R < 6-?#92 > I < D-g#SS > ( ( MOOD ( ( ROOT DEC ) ) )   ( OBJ-CRSEOR )   ( 6 UBJ-CREEOR )   ( SUBCOT2 RRG-GR )   ( ORTROJ )   ( BEM*HRUE-R-PRIM 9@ )   ( TIME ( ( ROOT PRESEMT ) ) )   ( ROOTITRI ) ) 6:  ( 65 ) M < 4-5#3>R < 6 - ? I < Bm9 #SO > ( ( MOOD ( ( ROOT DEC ) ) )   ( OBJ-CRSEOR )   ( SUBJ-CRSEOR )   ( CRUSRTIUE- )   ( PRBSIUE- )   ( SUBORTSTRT )   ( BEM*HRUE-R-FEUER1 B )   ( TIME ( ( ROOT PRESEMT ) ) )   ( MEGRTIOM ( ( ROOT HITEI ) ) )   ( CRTU )   ( ROOT RRU ) ) ?:  ( 43 ) R < 2-3#6>R < 4-5#3>R < 32>U < B-9#2> ( ( MOOD ( ( ROOT DEC ) ) )   ( OBJ-CRSEO )   ( SUBJ-CRSEGR )   ( CRUS@TIUE- )   ( PRSBIUEm )   ( SUBCRTTRRMO )   ( SEM*MRKE--CLERM 248 )   ( TIME ( ( ROOT ( * OR*PRESEMT FUTURE ) ) ) )  ( CRTU )   ( ROOTRI~FIU ) )

Command:
I ~-~-;; ,   , - w~:-----~ , IIIIIII
Dynamic Lisp Listener 12
SampleRun125: " KURI*RKOOIRTEIRU=' .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
Evaluation of ( PRRSE ) took 95 . 719693 seconds of elapsed time includ in 910 , 550 seconds walt ln9 for the disk for 142 faults . 
The 9arbage collector has flipped j so oonstn9 wm a not neaaurad . 
8 parsee found 1: ( 393 ) K < 2-3#2 B > U ( 4 -5#29>   B<6-?we  >  I<B-9#B  @>  O<18-11#33>   R<12-18#62>   K<lq-15#28>   0<16-17#24>   N<1?-18#O  >  R<18-19#2>   B<2@-21#9>   R<22-23#32>   0<23-24#-10>   T<24-25#31>   E<26-27#30>   I<28-29#36>   R<30-31#31>   U<32-33#29>   ( ( MOOD ( ( ROOT DEC ) ) )   ( SEM*HRUE-R-BTIFF MESE 1268 )   ( OBJ ( (: HH - )   ( OROEOR )   ( SEM*MECK )   ( ROOTK UBI ) ) )   ( CRUSRTIUE- )   ( OBJ-ORBEOR )   ( SUBJ-CRSEOR )   ( PRSSIVE- )   ( BUBORTSTRT )   ( TIME ( ( ROOT ( * ORs PREO EMT FUTURE ) ) ) )  ( PROOREGBIUE * )   ( ORTU )   ( ROOTKO MRBRRU ) ) 2:  ( 372 )   K<2-3#28>   0<4-5#10>   R<6-?#31>   E<8-9#2>   O<1@-11#33>   R<12-13flO2>   K<14-15#28>   0  ( 1 6-17fl24>   N<17-18#O  >  R<18-19#2>   B<2g-21#9>   R<22-23#32>   0<23-24#-10>   T<24-25f191>   E<26-27#3O > I ( 28-29#30>R < 86-31#91> U < 32-33#29> ( ( MOO0 ( ( ROOT DEC ) ) )   ( OBJ ( (: WH - )   ( CRSEOR )   ( ROOTKORE ) ) )   ( CRUSRTIVE- )   ( OBJ-ORBEOR )   ( 6 UBJ-CRSEOR )   ( PRSBIUE-7 ( BUOORTST ? T )   ( BEM*HRUE-R-BTIFF MESS 214 )   ( TIME ( ( ROOT ( * OR*PRESEHT FUTURE ) ) ) )  ( PROGRESSIVE ? )   ( CRIU )   ( ROOTKOHRBRRU ) ) 2:  ( 372 ) K < 2-9#28>0 < 4-5fllO>R < 6-7#31 > E ( B-9#2>G ( 18-11#33 > R ( 12-19#32 > K ( 14-15#28> 0<16-17424> M<l~-lB#@>R < 19#2> B ( 28-21~9>R < 22-23f102 )   Q<23-24#-18>   T<24-25#31>   E<2G-27#OO  >  I<28-29#3@>   R<30-31#31>   U<32-OO  #~>  ( ( MOOD ( ( ROOT DEC ) ) )   ( OUBJ ( (: NH - )   ( CRBEOR )   ( ROOTKORE ) ) )   ( BUBJ-CRSEOR )   ( OBJ-CRBEOR )   ( CRUBRTIUE- )   ( PRBBIUE- )   ( SUBCRTETRT )   ( SEM*HRUE-R-BTIFF MERB 214 )   ( TIME ( ( ROOT ( * OR*PREBEHT FUTURE ) ) ) )  ( PROgREBSIYE ? )   ( CRTU )   ( ROOTKO ~ RBRRU ) ) 4:  ( 279 ) K < 2 - 3 #28 > U ( 4 -5#29>   B<6-7#5> I < B-O#Og > G<1@-11#33>   R?12-18M32>   K<14-15#28>   0  ( 1 6-17#24>   N<17-18#g  >  R<18-19#2>   B<28-21#9>'   R<22-23#32>   Q<23-24#-19>   T<24-25#31>   R<26-27#G  >  ( ( MOOD ( ( ROOT DEC ) ) )   ( SEM*HRUE-R-BTIFF MEBB 1264 )   ( OBJ ( (: HH - )   ( SRSEOR )   ( SEN~HEOK )   ( ROOTK UBI ) ) )   ( CRUORTIUE- )   ( OBJ-CROEGO )   ( SUBJ-CRSEDR )   ( PRBBIVE- )   ( BUBCRT STRT )   ( TIME ( ( ROOT PRST ) ) )   ( ORTV )   ( ROOTKO WRB RRU ) ) 5:  ( 256 )   K<2-3#28>   0<4-5#1D  >  R<6-7#31>   E<8-9#2>   g<18-11#33> R ( 1 2-13#32>   K<14-15#28>   0<16-17#24>   M<1~-18#8>   R<10-19#2>   B<20-21#9>   R<22-23#32>   O<23-24#-10>   T<24-25#31>   R<26-2?#G  >  ( ( HOOD ( ( ROOT DEC ) ) )   ( OBJ ( (: WH - )   ( CRBEGR )   ( ROOTKORE ) ) )   ( CRUBRTIVE- )   ( OBJ-ORBEOR )   ( OUBJ-CRBEOR )   ( PRSSIVE- )   ( BUBORTBTRT )   ( SEM*HRUE-R-BTIFF MEBSOB )   ( TIME ( ( ROOT PRST ) ) )   ( CRTV )   ( ROOTKO MRBRRU ) ) 5:  ( 258 )   K<2-3#20>   0<4-5#10>   R<S-7#51>   E<B-9#2>   O<10-11#33> R ( 12-13#32>K < 14-15#28>0<16-17#24> M < 17-16 #O ) R < lB-19#2>B <28-21 #9> R < 22-23#32 > O < 24#-18>T ( 24-25#51>R < 26-2?#fi > ( ( MOOD ( ( ROOT DEC ) ) )   ( BUBJ ( (: HH - )   ( CROESO )   ( ROOT ~ DRE ) ) )   ( BUBJ-CRBEOR )   ( OBJ-CRBEOR )   ( CRUORTIVE- )   ( PRBBIVE- )   ( BUBCRTOTRT )   ( SEM*HRVE-R-BTIFF MESBOB )   ( TIME ( ( ROOT PRST ) ) )   ( CRT rf ~/ )   ( ROOTKO WRB RRU ) ) 7:  ( 232 ) K < 2 - 3 #2 B > 0 < 4 - 5 #10 > R < 6-7~31 )   E<B-9#2>   G<lS-11#33>   R<12-13#B2>   K<14-15#28>   0<16-17#24>   N<26-21#5>   R<22-23#32>   1<26-27#7>   ( ( MOOD ( ( ROOT DEC ) ) )   ( BUBJ ( (: NH - )   ( ORSEOR )   ( ROOTKORE ) ) )   ( SUBJ-CRGEOR )   ( CAUSATIVE- )   ( PROBIVE- )   ( OUBCRTINTRRNB )   ( SEM*PTRRH SBBO )   ( TIME ( ( ROOT PRESENT ) ) )   ( MEORTION ( ( ROOT HITEI ) ) )   ( CRTV )   ( ROOTKURU ) ) ** MORE**I
I !
Dynamic Lisp Listener 12
