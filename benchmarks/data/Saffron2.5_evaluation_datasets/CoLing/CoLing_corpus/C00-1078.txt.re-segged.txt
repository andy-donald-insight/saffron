Chart-Based Transfer Rule Application in Machine Translation 
Adam Meyers
New York University

Michiko Kosaka
Monlnouth University

Ralph Grish Inan
New York University
grishman@cs.nyu.edu

3 5"ansfer-based Machine Translation systems require a procedure for choosing the set  ; of transfer rules for generating a target language translation from a given source language sentence  . In an MT system with many com I ) eting transfer rules , choosing t ; hebest , set of transferules for translation may involve the evaluation of an explosive number of competing wets  . We propose a so hltion t ; oth is problem l ) ased on current bestfirst chart parsing algorithms . 
1 Introduct ion ri~'ansfer-based Machine ' Kanslation systenls require a procedure for choosing the set of trans-tier rules for generating a target language I  ; rans-lation from a given source language sentence . 
This procedure is trivial t brasy stem if , given a (: on text , one transtb . rule . can l ) eselected un-~m fl ) iguously . O ; herwise , choosing the besl ; set ; of transferules may involve the . evaluation of mmmrous competing sets . In fact , the number of l ) ossible transferule combinations increases exponentially with the length of the source  , language sentence ,  . This situation mirrors the t ) roblem of choosing productions in a nondeterministic parser  , in this paI)er , we descril ) ea system for choosing transferules , based on statistical chart parsing ( Bol ) row , 1990; Chitrao and Grishman , 1990; Caraballo and Charniak , 1997; Charniak et al ,  1998) . 
In our Machine %' anslation system , transfer rules are generated automatically from parsed parallel text along the lines of  ( Matsulnotoel ; al , , 1993; Meyers et al , 1996; Meyers et al , 1998b ) . Our system tends to acquire a largen mn be r of transt ~ r rules  , duelna inly to 3 , 1terna-tive ways of translating the same sequences of words  , nonliteral translations in parallel text and parsing e  , rrors . It is therefore crucial that our system choose the best set of rules efficiently  . While the technique discussed he . reobviously applies to similar such systems , it could also apply to handcoded systems in which each word or group of words is related to more than one transferule  . D ) r example , both Multra ( Hein ,  1996 ) and the Eurotra system described in ( Wayel ; al . , 1997 ) require components for deciding which combination of transtbrules to use  . The proi ) . osed technique may 1) e used with syst ; emslike these , t ) rovided that all transferules are assigned initial scores rating th cqrat  ) propriateness for translation . The seal ) t ) rol ) riateness ratings couhl be dependent or independent of context  . 
2 Previous Work
The MT literature deserib ( ; several techniquest brderiving the appropriate translation  . Statistical systems l ; hal ; do not incorporate linguistic analysis ( Brownel : al . , 1993 ) typically choose the most likely translation based on a statistical mode  . l , i . e . . , translation probability determines the translation  . ( Hein , 1996) reports a set ; of ( handcoded ) fea ; ll restructure based prefi~r-ence rules to choose among alternatives in Mu\]-tra  . There is some discussion about adding some transtbrules automatically acquired flom corpora to Multra ? Assuming that they overgenerate rules  ( as we did )  , a system like the one we propose should 1 ) ebeneficial . In ( Way et al ,  1997) , many ditDrent criteria are used to dloose trmlsi ~ ; rules to execute including : pretbrmlces for specific rules over general ones  , and comt ) lex rule nol , a tion that insures that tb . w rules can 21)-ply to the same set , of words . 
The Pangloss Mark III system ( Nirenburg ~ This translatiol l procedm'e would probably comple-men I~not  ; replace exist , ing procedures in these systelns . 
2 http://stp . ling . uu . se/~corpora/plug/reports/ansk_last / is a report on this  1  ) reject ; for Multra . 
537 and Frederking ,  1995 ) uses a chart-walk algorithm to combine the results of three MT engines : an example-based ngine  , a knowledge-based engine , and a lexical-transfer engine . 
Each engine contributes its best edges and tile chart-walk algorithm uses dynamic program-ruing to find the combination of edges with the best overall score that covers the input string  . 
Scores of edges are normalized so that the scores fi ' om the different engines are comparable and weighted to favor engines which tend to produce better results  . Pangloss's algorithm combines whole MT systems . In contrast , our algorithm combines output of individual transfe rules within a single MT system  . Also , we use a bestfirst search that incorporates a probabilistic-based figure of merit  , whereas Pangloss uses an empirically based weighting scheme and what appears to be a topdown search  . 
Best-first probabilistic chart parsers ( Bo-brow , 1990; Chitrao and Grishman , 1990; Caraballo and Charniak , 1997; Charniak et al , 1998) strive to find the best parse , without exhaustively trying all possible productions  . A probabilistic figure of merit ( Caraballo and Charniak , 1997; Charniak et al , 1998) is devised for ranking edges . The highest ranking edges are pursued first and the parser halts after it produces a complete parse  . We propose an algorithm for choosing and applying transth rules based on probability  . Each final translation is derived from a specific set of transferules  . If the procedure immediately selected these transfer rules and applied them in tile correct order  , we would arrive attile final translation while creating the minimum number of edges  . Our procedure uses about 4 tinms this minimum number of edges . 
With respect ochart parsing , ( Charniak et al ,  1998 ) report that their parser can achieve good results while producing about three times tile min in mm number of edges required to produce the final parse  . 
3 Test Data
We conducted two experiments . For experimen-t1 , we parsed a sentence-aligned pair of Spanish and English corpora  , each containing 1155 sentences of Microsoft Excel Help Text . These pairs of parsed sentences were divided into distinct training and test sets  , ninety percent for training and ten percent fbr test  . The training
Source Tree Target Tree
D = volvcrD '= recalculates , , I , J
A = Excel E = calcular
Obj ~ enA '= ExcelIC '= work book
B '= values/C = librok ,
B = valores\ae
F = trabajo
Excelvuel vea calcular Excelre calculates valores enlibro de traba jo value siu work book Figure  1: Spanish and English Iegularized
Parse 2?ees set was used to acquire transferules ( Meyers et al , 1998b ) which were then used to translate tile sentences intile test set  . This paper focuses on our technique for applying these transfer rules in order to translate the test sentences  . 
The test and training sets in experiment1 were rotated , assigning a different enth of the sentences to the test set in each rotation  . In this wwwe tested tile program on the entire corpus  . 
Only one test set ( one tenth of the corpus ) was used for tuning the system ( luring development . 
~: ansfer rules , 11 . 09 on average , were acquired t'rom each training set and used for translation of the corresponding test set  . For Experiment 2 , we parsed 2617 pairs of aligned sentences and used the same rotation procedure for dividing test and training corpora  . The Experiment 2 corpus included the experinlent l corpus . An average of 2191 transferules were acquired from a given set of Exper in mnt  2 training sentences . 
Experiment lisor chestrated in a carefld manner that may not be practical for extremely large corpora  , and Experiment 2 shows how the program performs if we scale up and elilniuate some of the finetuning  . Apart from corpus size , there are two main difference between the two experiments :  ( 1 ) the experiment l corpus was aligned completely by hand  , whereas the Experiment 2 corpus was aligned automatically using the system described ill  ( Meyers et al , 1998a ) ; and ( 2 ) the parsers were tuned to the experi-ment l sentences  , but not the Experiment 2 sentences ( that did not overlap with experinmnt l )  . 
5381) A=Excel2) B=valores
C = librov
A '= Excel
B '= values . ~) r
C '= work book
F = trabajo
D = volvcrS.IJ.i~4) 1E = ealcular
Ob.\]~enl231)'= recalculate 123
Figure 2: AS ( ' t of %- ansfer Rules 4 Parses and Transfer Rules Figure 1 is a pair of " regularized " parses tbra corresi  ) on ding pair of Spanish and Fmglish sentences fi'om Microsoft Excelhell  ) text . The seat '( ; F-structure-like dependency analyses of sentences that represent  1  ) redicate argument structure . This representation serves to neutralize some ditfbrences between related sentence tyt  ) es , e . g . , the regularized parse of related active and t)a , ~sive senten (: es are identical , except tbrthei ' . ature value pair Mood , Passive . Nodes ( wfl-ues ) are labeled with head words and arcs ( features ) are labeled with gramma ~ ; icalthnetions ( subject , object ) ,  1 ) repositions ( in ) and subordinate conjunctions ( be N re )  . a For demonstration purposes , the source tree in Figure 1 is the input to our translation system and the target tree is the outl  ) ut . 
Thet ; ransfer rules in Figure 2 can be used to convert the intmt ; tree into the out-1) at tree . These transtbrrules are pairs of corresponding rooted substructures  , where a substructure ( Matsumoto et al , 1993) is a connected set of arcs and nodes . A rule a Morphologieal features and their values ( Gram-Number : plural ) are also represented as ares and nodes . 
consists of o , ither a pair of " open " substructures ( rule 4 ) or a pair of " closed " substructures ( rules 1 , 2 and 3) . Closed substructures consist of single nodes ( A , A' , B , B' , C ') or subtrees ( the lefthand side of rule 3) . Open substructures contain one or more open arcs , arcs without heads ( both sul ) structures in rule 4 )  . 
5 Simplified Translation with
Tree-based Transfer Rules
The rules in Figure 2 could combine by filling in the open arcs in rule  4 with the roots of the substructures in rules 1  , 2 and 3 . The result would be a closed edge which maps the left  ; tree in l , ' igure , 1 into the right tree . Just as edges of a chart parser are based on the contextfree rules used by the chart parser  , edges of our translation system are , based on these trans~L'rules . 
Initial edges are identical to transtb , r rules . Other edges result from combining one closed edge with one open edge  . Figure 3 lists the sequence of edges which wouhl result from combining the initial edges based  ( mR ules 14 to replicate , the trees in Figure 1 . The translation proceeds by incrementally matching the left hand sides of Rules  14 with the intmt tree ( and insuring that the tree is completely covered by these rules  )  . 
The right hand sides of these comt ) atil ) le rules are also ( : ombined t ; o1) reduce the translal ; iolLThis is an idealized view of our system in which each node in the input tree matches the left  ; -hand side of exactly one transfer rule : there is no ambiguity and no combinatorial explosion  . 
The reality is that more than one transferules may be activated t breach node  , as suggested in Figure 4 .   4 If each of the six nodes of the source tree corresponded to five transfer rules  , there are 56  =  15625 possible combinations of rules to consider . To produce tlm output in Figure 3 , a minimum of seven edges would be required : four initial edges derived ti ' om the original transfer ules plus three additional edges representing the combination of edges  ( steps 2 , 3 and 4 in Figure 3) . The speed of our system is measured by the number of actual edges divided by this minimul n  . 
4The third example listed would actually involve two trm~sfer rules  , one translating " volver " to " ret ) cat " and the second translating " calcular " to " calculal  ; e" . 

D = volver
Su~1E = calcular
Obj ~ n23
D = volver
A = Excel E = calcular
Obj~n23 vv
D '= recalculate
I 23
D '= recalculate
A '= Excel 233)
D = volver
A = Excel E=caleular
B = valores 3
D '= recalculate
A '= Excel/3g '= values 4)
D = volver
A = Excel E = calcular

B = vaioresC = librode
F = trabajov
D '= recalculate
A '= Excel\C '= work book
B '= values
Figure 3: An I dealized Translation Procedure 6 BestFirst Translation Procedure The following is an outline of our bestfirst search procedure for finding a single translation :  1  . For each node N , find TN , the set of compatible transferules2 . Create initial edges for all TN3 . Repeat until a " finished " edge is tbund or an edge limit is reached :  ( a ) Find the highest scoring edge E ( b ) If complete , combine E with compatible in coml ) let edges ( c ) If incomplete , combine E with compatible complet edges ( d ) Incompletedge+complete edge=new edge The procedure creates one initial edge for each matching transfer rule in the database  5 and puts these edges in a ' ~ The lefthand side of a matching transfer rule is compatible with a substructure in the input source tree  . 

D '= recalculate
D = velvet 12 3/%
Sub , i / ~ a !) '= calculate /\/ E = \'4 . '+"3 again
D = repeat
Sabj ~ bj1E = calculation
Figure 4: Multiple\[lYansfer Rules for Each Sub-structm : e queue prioritized by score  . The procedure iteratively combines the bests ( : oring edge with some other comt ) al ; ilfle edge to t ) roduce a new edge . and inserts the new edge in the queu (' . . The score for each new edge is a function of the scores of the edges used to produce it :  . The process contimms m ~ tile it her an edge limit is reache  ( l ( the system looks like it ; will take too long to terminate ) or a complete edge is t ) roduced whose lefthand side is the input tree : we  ( : all this edge a " finished edge " . 
We use the tbllowing technique for calculating the score t brinitial edges  . 6 The score tbreach initial edge E rooted at N , based on rule / ~ , is calculated as follows : 1 . SCO 17 . F = I(S ) "" F, . c . , ~( n ) = ~' ? . q ' ~ D ~ ( ~a ~ tN ~ ) Where the fl'equency ( Freq ) of a rule is then mn be r of times it matched an exmnple in the training corpus  , during rule ~ cquisition . 
The denominator is the combined fl'equen-cies of all rules that match N  . 
a This is somewhat det)cndent on the way these ; rans-fer rules are derived . Other systems would t ) robably have to use some other scoring system . 
Ezperiment 1: 1155 sentences
Norm No Norm
Total Translations
Over Edge Limit
Actual Edges
Miniature Edges
Edge Ratio
Accuracy 93,719 22,1253 . 3 70 . 9 579,278 20,125 1 . 4 . 8 70 . 9
Ezpcriment 2: 2617 sentences
Norm No Norm
Total Translations
Over Edge Limit
Actual Edges
Minimum Edges
Edge Ratio
A (: curacy 262,172 48,570 4 . 0 62 . 6 1,398,796 42,770 15 . 5 61 . 5
Figure 5: Result : s2, Ss ) = s , o, . (; . l(S)-No , . ,  ,   ,   , Where the Norm ( normalization ) t ~ ctor is equal to the highest SCORE1 for any rule matching N . 
Since the log . 2 of probabilities are necessarily negative , this has the effect of setting the E of each of the most t  ) rol ) able initial edges to zero . 
The scorest brnon-initial edges are calculated by a d  ( linguI ) the scores of the initiale ( tges of which they are comt ) osed .  7
Without any norm Mization ( Score(S ) =
SCORE1 ( , 9)) , small trees are favored over large trees . This slows down the process of finding the final result  . The normalization we use insures that the most probable set  ; of transih rules are considered early on . 
7 Results
Figure 5 gives our results for both experiments 1 and 2  , both with normalization ( Norm ) and without ( No Norm )  . " Total Translations " refer to the number of sen ; ences which were translated successfully 1 ) y the system and " OverEdgeLimit " refers to the numl  ) er of sentences which caused the system to exceed the edge limit  , i . e . , once the system produces over 10 , 000 edges , trm ~ slation failure is assmned . The system cur-7Scoring for special cases is not ; included in this paper . 
These cases include rules for conjunctions and rules ibr words that do not match any transfer ules in a given context  ( we currently leave the word untranslated . ) tion for any input if the edge limit is exceed - ed  . " Actual Edges " reibrs to the total number of edges used t brattempting to translate very sentence in the corpus  . " Minimum Edges " refer to the total minimum number of edges required for successful translations  . The " EdgeRatio " is a ratio between : ( 1 ) " Total Edges " less them nnber of edges used in failed translations  ; and (2) The " Minimum Edges " . This ratio , in com-l ) ination with , the number of " OverEdgeLimit " measures the efficiency of a given system  . " Accuracy " is an assessment of translation quality which we will discuss in the next section  . 
Normalization caused significant speedup for both experiments  . If you compare the total number of edges used with and without normalization  , speedup is a factor of 6 . 2 for Experiment I and 5 . 3 for Experiment 2 . If you compare actual edge ratios , speedup is a factor of 4: . 5 tbr Experiment 1 and 3 . 9 tbr Experiment 2 . In addition , the number of failed parses went down by a fhctor of  10 for both experiments . As should be expected , accuracy was virtually the same with and without normalization  , although normalization < lid cause a slight improvemen-t  . Normalization should produce the essentially the same result in less time  . 
These results suggest that we can probably count on a speedup of at least  4 and a significant decline in failed parses by using norm M-ization  . The ditferences in performance on the two corpora are most likely due to the degree of hand-tuning for Experiment  1  . 
7 . 1 Our Accuracy Measure " Accuracy " in Figure 5 is the average of the tbllowing score for each translated sentence : 
ITNYu ~ TMSI1/2x ( ITNYu I+ITMsl)
TNZU is the set of words in NYU's translation and TMS is the set of words in the original Microsoft translation  . If TNYU="ABCDE " and TMS="ABCF" , then the intersection set " ABC " is length 3 ( the numerator ) and the average length of TNZU and TMS is 41/2 ( the denominator )  . The accuracy score equals 3+41/2 = 2/3 . This is a Dice coefficient comparison of our translation with the original  . It is an inexpensive nmthod of measuring the pertbr-mance of a new version of our system  , hn prove-ments in the average accuracy score for ours an > pleset  ; of sentences usually reflect an improvement in over all translation quality  . While it is significan that the accuracy scores in Figure  5 did not go down when we normalized the scores , the slight improvement in accuracy should not be given nmch weight  . Our accuracy score is flawed in that it cannot account for the following facts :  ( 1 ) good paraphrases are perfectly acceptable ;   ( 2 ) some difl brences in word selection are more significant hanothers  ; and ( 3 ) errors in syntax are not directly accounted tbr . 
NYU's system translates the Spanish sentence "1 . Selection lacel da en la que desea introdu ci run a rethrencia " as  "1  . select the cel-l that you want to enter a reference in "  . Microsoft translates this sentence as "1 . Select the cell in which you want ; to enter the reference " . 
Our system gives NYU's translation an accuracy score of  . 7 5 due to the degree of overlap with Microsoft's translation  . At ruman reviewer wouhl probably rate NYU's translation as completely acceptable  . In contrast , NYU's system produced the following unacceptable translation which also received a score of  . 7 5: the Spanish sentence " Elijal afuncidnque desea pegarenla  f6rmula enelcuadrodedi ~ logoAsistente paraflm ciones " is translated as "" Choose the flmc-tion that wants to paste Function Wizard in the formula in the dialog box "  , in contr , ~st with Mi-crosoft's translation " Choose the flmction you want to paste into the tbrmulafl'om the Function Wizard dialog box "  . In fact , some good translations will get worse scores than some bad ones  , e . g . , an acceptable one word translation can even get a score of  0  , e . g . ,"SUPR " was translated as " DEL " by Microsoft and as " Delete " by NYU  . Nevertheless , by averaging this accuracy score over many examples  , it has proved a valuable measure for comparing different versions of a particular system : better systems get better results  . Similarly , after t weaking the system , a better translation of a particular sentence will usually yield a better score  . 
8 Future Work
Fnture work should address two limitations of our current system :  ( 1 ) Bad parses yield bad transihr rules ; and ( 2 ) sparse data limits the size of our transfer rule database and our options for " bad parse " problem  , we are e on sideriug using our MT system with less -detailed parsers  , since these parsers typically produce less error -prone output  . We will have to conduct exl ) erim cnts to determine the minimum level of detM1 that is needed , a Previous to the work reported in this paper , we ran our MT system on bilinguM corpora in which the sentences were Migned manuMly  . The cost of manuM aligmnent limited the size of the corpora we could use  . A lot of our recent MT research as bo . entbcused on solving this sparse data prol ) lemthrough our develoi ) ment of a sentence alignment progrmn ( Meyers et al , 1998a ) . 
We now have 300 , 0 00 automatic Mlyaligned sentences in the Microsoft help text domain t br future experiinen i  ; s . In addition to provi ( tingus with many more transferules , this shouhl M low us to colh ' . ct transfer rule cooccurrence information which we c ~ m then use to apply tr  ; mst br rules more effectively , perhaps improving trans-b ~ tion quality . In a preliminary experime , nta-hmg these lines using the Experiment1 . tor t ) us , cooccurrence information had no noticeable f feet  . However , we are hot ) eflfl that flltm ' e ex-t ) eriments with 300 , 000 Migned sentences ( 300 tinies as nnlch data ) will 1 ) e more successful . 
References
Robert J . Bobrow .  1990 . S1; ~ Ltistical agenda parsing . In I ) ARPA Speech and Lang'uagc
Workshop , pages 222-224.
Peter Brown ~ Stephen A . Delb~t ) ietra , Vincent J . Della Pietra , and Robert L . Mercer .  1993 . The Mathematics of Statistical M~z chine'h ' anslation:  1  ) aramet crEstimation . 
Computational Lin . quistics , 19:263-312.
Sh ; ~ ronA . Caraballo and Eugene Chm'niak.
1997 . New figures of meritt brbest-tirst prot ) -M ) ilistie chart parsing . Computational Linguistics , 24:275-298 . 
Eugene Ctmrniak , Sharon Goldwater , and M~rk Johnson .  1998 . Edge-Based BestFirst Chart Parsing . In Proceedings of the Sixth Annual Workshop for Very Lawc Corpora  , Montreal . 
SOne could set u1 ) a contimmm from detailed parser-slike Proteus downto shallow verb-group/noun-grouI  ) recognizers , with the Penn treetmnk based parsers lying somewhere in the middle  . As one travels downt , hee on Linlm Int ; ot ; he lower detail parsers , time rrorrate naturally decreases . 
Mahesh V . Chitrao and R Mph Grisunan . 1990.
St ; ~ tisti('alpn rsing of messages . In \]) AIIPA Speech and La'n , g'uagcWorkshop , pages 263266 . 
Annn Sggvallltein .  1996 . Pretbrence Mechanisms of the Multra Machine %' ansb ~ tionSystem  . In Barbara H . Partee and Petr Sgall , editors , Discourse and Meaning : Papers in 11onor of Eva 11aji~ovd   . John Benja . mins Publishing Company , Amsterdam . 
Y . Matsumoto , H . Ishimoto , T . Utsuro , and M . Nagao .  1993 . Structural Matching of Parallel Texts . In 31st Annual Meeting of the Association for Computational Linguistics : " Proceedings of the Uo ~@ rencc "  . 
Adam Meyers , Roman Ymlgm'ber , a .nd Ralph
Grishman . 1996. Alignment of Shared
Forests fi ) r Bilingu M Corpora . In Proceedings of Coliw . I 1996: The 16th International Con-fercnccon Computational Linguistics  , l ) ages 460465 . 
Adam Meyers , Miehiko Kosak ~, and Ralph Grishman . 1998m A Multilingual Procedure for Dict ; ionary-B ; ~sed Sentence Aligmnent . In Proceedings of AMTA '98: Machine Translation and th , cht:fo'rmationSoup , t)~ges187 . 

Adam Meyers , R , om ~ mYm~g ~ rber , Ralph Gr-ishmml , Cn the rine Macleod , m M Antonio Moreno-S ~ m dow ~ l .  1998) . l ) eriving ~ l ~ : a . ns-fin:Rules from Domimmce-Preserving Alignments  . In I ) ' rocccdim . lso . fColing-ACL 98: Th . c 171h International Conference on Computational Ling , uistics and the 36th , Meeting of the Association for Computational Linguistics  . 
Sergei Nirenlmrgm M Robert E.l ~: ederking.
1995 . The Pangloss Mark III Machine'l?nms-lt ~ tion System : Multi-Engine System Architecture  . Te(:hnical report , NMSU Oil , L , USC
ISI , ; rod CMUC MT.
Andrew Way , Ian Crookston , and Jane Shell ; on.
1997 . A Typology of ~ I Yanslation Prol ) lems for Eurotra Translation Machines . Machine\[l'anslation , 12:323374 . 

