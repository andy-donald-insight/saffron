CHART PARSING ACCORDING TO THES LOT AND FILLER PRINCIPLE 
Peter HELL WIG
University of Heidelberg
P.O . Box 105760
D-6900 Heidelberg , FRG
Abstract
A parser is an algorithm that assigns a structural description to a string according to a grammar  . It follows from this defini-tion that there are three general issues in parser design : the structure to be assigned  , the type of grammar , the recognition algo ~ rithm . Common parsers employ phrase structure descriptions  , rule-based grammars , and derivation or transition oriented recognition  . The following choices result in a new parser : The structure to be assigned to the input is a dependency tree with lexical  , morpho-syntactic and functional-syntactic information associated with each node and coded by complex categories which are subject to unif ication  . The grammar is lexicalized , i . e . the syntactical relationships are stated as part of the lexical descriptions of the elements of the language  . The algorithm relies on the slot and filler principle in order to draw up complex structures  . It utilizes a well-formed substring table ( chart ) which allows for discontinuous segments . 
1. Dependency Structure
The structuring principle of constituency trees is concatenation and the part-whole- relationship  . The structuring principle of dependency trees is the relationship between lexemes and their complements  . Note : It is not correct ( or at least misleading ) to define dependency as a relationship between words  , as it is often done . The possibility and necessity of complements depend on the lexical meaning of words  , i . e . a word which denotes a relationship asks for entities which it relates  , a word which denotes a mo-dification asks for an entity which it modifies etc  . While it is awkward to associate functions ( deep cases , roles , grammatical relationships ) with phrase structures , it is not difficult to paraphrase the functions of complements on a lexical basis  . For example , the argument of the predicate " sleep " deno-tes the sleeper  ; the meaning of " persuade " includes the persuader  , the persuaded person and the contents of the persuasion  . In a next step , one can abstract from the concrete function of dependents and arrive at abstract functions like subject  , object , adjunct etc . 
Of course , the complements covering these roles can be single words as well as large phrases  ; for example " John " , " myfather " , " the president of the United States " can all fill the role of the sleeper with respect to the predicate " sleep "  . However , phrases need not be represented by separate nodes in dependency trees  ( as they do in phrase mar-kers ) because their internal structure is again a quest ion of dependency between lexe-mes and their complements  . In a dependency tree , phrases are represented directly by their internal structure  , which results in an arc between the superodinated head and the head within the complementary phrase  . 
Nevertheless , the real principle of depen-structures , or , formally , between single nodes and trees . Taking this into account , dependency trees are much more appealing than has been recognized so far  . 
In order to restrict linguistic structures according to syntactic and semantic requirements  , the use of complex categories is state of the art  . Complex categories are sets of parameters ( attributes ) and values ( features )  . Agreement between entities can be formulated in a general way in terms of parameters  ; the assignment of actual feature values is achieved by the mechanism of unification  . If dependency J . s the relationship along which the catagories are unified  , functional = syntactic and mo ~ ho-syntactic features can be handeled completely in parallel  , as opposed to the two-phase mechanism which , for example , characterizes Lexical Functional Grammar . Each element in the dependency tree carries three labels : a role  ( which applies to the ( sub ) tree of which the element is the head )  , a lexeme , and a set of grammatical features . 
Constituency and dependency both have to be represented somehow or other in the syntactic description  . As a consequence , recent developments have led to a convergence of formalisms of both origins with respect to their contents  .   ( A good example is the similarity between Head -Driven Phrase Structure Grammar/Pollard  , Sag 1987/ and Dependency Unification Grammar/Hellwig 1986/  . ) If phrase structure trees are used , the difference between governor and dependent must be denoted by the categories that label the nodes  , e . g . by ax-barnotation . If dependency trees are used , the concatenation relationship must be denoted by positional features which are part of the complex morpho-svntactic category  . 
2 . Chart parsing based on a lexicalized grammar The structure to be associated with a wellformed string can be defined in two ways : either by a set of abstract rules which describe the possible constructions of the ~ language or by a descr ip tion of the combi-  . 
nation capabilities of the basic elements.
The latter fits with the dependency approach . Given a lexical item and its morphosyntactic properties  , it is relatively easy to give a precise descript ion of its possible complements  . The main advantage of this lexicalistic approach is the fact that augmenting or changing the description of an item normally does not interfere with the rest while any change in a rule-based grammar might produce unfore seen side effects with regard to the whole  . 
The prerequisite for a lexicalized dependency grammar are trees that comprise slots  . A slot is a description of the head of a tree that fits into another tree  . Formally , a slot is a direct dependent of a head with a role associated to it  , with a variable in the lexeme position , and with a categoriza-tion that covers all of the morpho-syntactic properties of the apper taining complement  . 
If cross categorization does not allow all of the p~ssible properties of a complement w it hin one category to be stated  , a disjunc-tion of slots is used to express the alter-natives  . The only mechanism needed for draw--ingup complex structures is the unification of slots and potential fillers  . 
The control of the parsing process is achieved by means of a well-formed substring table  ( (\] hart )  . It is widely accepted that chart parsing is superior to backtracking or to parallel p rocessing of every path  . A common version of a chart can be vizual i zed as a network of vertices representing po ints in the input  , linked by edges representing segments . The edges are labelled with the cate-gories that the parser has assigned to the consti tuents concerned  . Alternatively , each edge is associated with a complete structural descrLption  , including the information which is carried by the covered edges  . In this case , a chart is simply a collect \] on of trees ( implemented as lists ) projected on the various segments in the input  . The inno-vation with regard to chart parsing th ~vt is proposed in this paper is a label  . ling of edges by trees that comprise slots . 
At the beginning , an edge for each word is entered into the chart . Each edge is label \] o~ed with a tree . The head of this tree contains the lexeme that is associated with the word according to the \]  . exicon ; it carries a morpho-syntactic category accord ing to the morphological properties of the word in question : it normally contains a variab\]  . e as a role l ~ arker , since the syntagmatic func-tion of the cor responding segment is still unknown  . A slot is subordinated to the head for each e lement that is to be dependent in the result ing structure  , if any . Slots are added to a lexical item according to c ~> mple-tion patterns refered to in the lexicon  . ( We cannot qoin to details here . ) Subsequently , each tree in the chart looks for a slot in a " tree that is associated with annother edge  . If the head of the searching treefitn the descr iption in the slot then a new edge is drawn and labelled with the compound tree that results from inserting the first tree into the second  . The categories of the ~ ew tree are the result of unifying the categories of the slot tree and the filler tree  . Special features state the posi-tional re ~/ i rements  , e . g . whether the segment corresponding to the fil ler has to pre-ceed or to follow of the segment corresponding to the element dominating the slot  . This process continues until no new tree is produced  . Parsing was successful if at \] . east one edge covers the whole input . The dependency tr~e associated with this edge is the desired structural description  . 
The fo\] . lowing example illustrates the me-chanism . 
(I ) Flyir , gplanes can be dangerous.
The lexicon lookup leads to the initializa -tion of % he chart in figure i  . 
I%? , -noun re ) un---Ivu ~ b-f~n IveT binfladje ) lassert $ on\[ ( ATr . _I ( ~v_I ( eA_II--~Iadjela ) ) I verb I ndje ra ) )l I verb I l ~ f ~~ ) Ii If in ~ a ) )\[
Flying planes can be dangerous
Fig . 1 The chart at the end of the lexicon phase ( The notation is simplified and we have omit teda detailed categorization  . The dependency structure is represented by the bracketing  . Lexemes are underlined ; roles are in capita \] letters ; slots are marked by the underscore in the lexeme position  . " re " means right adjacent , " la " means left adjacent with respect to the head  . ) At the end of the slot fi\] . \] . ing process the chart looks like figure 2 . 
(ILLOC assertion ( ILLOC assertion ( PRED cgl ~ verb fin ( PRED . can verb fin(MV !) f verb in f(MV be . verb in f ( \[~ A ( lal ) gero ~ l_sadje )   )   ( PA da Dqerousad \]e )   )   ( SUBJ flying , noun ( SUBJ planes noun ( OBJp\]anes noun )   )   ( ATR f~ffl~\[\[adje )   )   )   )   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . mc~nverb fin ( ca ! ~ verbfin ! ( MV be verb inf ( MV be_verb infI ( PA dan ~ erotj sadje ) )  ( PA_d . a! ) ~erqu ~ adje ) 1SUSJ flyilj ~_ ~ loUn ( SUBJ\]31 anes noun\]OBJ\]/la~es\[loun ) )  ( ATRf\]~in!\[ddje ) ) ) ) I ( p_lanes noun ~ ( E~n verb-in ( ATR fl~i\qadje )   )  \ [  ( MV\]pc verb ~ l~f ( OBJ ~ lanes noun re ) ) I I f g~nq \[  l ( be verb infIno\]?n ~ ~ ( PA dan ? ierousacie ' ' < . . . . . I .   .   .   .   .   .   . I . . . . . . . . .   , ,\[ i t ( fl~\[lql ( / ~ lanes\[ ( cn  ~ ( bel ( danqerous ILLCI a Ti~e ) -" \[ , ~-6un'-veT bfinI , ' Trrblnfla<\]e\]~asse~t ~ on I
I(A'r~-(MY_(PA . I ~ aEo--~i Iad\]ela ) verba . ~ ij er e ) ) I verb I  inf re ) If in ! a ) )i / I ( suBJ_ . / Ii
Flying planes can be dangerous
Fig . 2 The ch ~ Lrt at the endoft be pn rsl : ~ g process 3 . A chart for discontinuous segments Inf igure  2  , the vertices represent left and right margins of segments  . Adjacency is the inherent positional relat ionship in this model  . As a consequence , this chart does not allow for discontinuous constituents  . This is a serious deficiency considering the phenomena of unbound dependencies which occur in many languages  . The representation of po-sition by categor ies j however  , opens up the possibility to state various kinds of posi-tional relationships between heads and dependents  . In order to form discontinuous segments , the control of positions in the chart must be altered  . The solution which we adopt is to represent the extensions of seg--ments by bit strings cons is ting of one bit  21  , 3 for each word that is part of the segment and a zero bit for any word that is not within the segement  ( cf . fig . 3, trailing zeros are omitted ) . Discontinuous segements are depicted by the alternation of ones and ? zeros in the bit string  . The intersection of the appertaining bitstrings is formed before a filler is compared with a slot  . This intersection must be empty , because otherwise both segments contain overlapping portions and one cannot be a dependent of the other  . After a filler is inserted into a slot , the union of both bitstrings is form-ed and associated with the new tree  . This amounts to island extension of the parsed substrings  . Other operations on the bitstrings allow for calculating the specific positional relat ionships stated within the categories of slots  . The parser runs through alternate cycles : It tries to build continuous segments first  . Then it uses these segments to form discont inuous segments  . From the results it tries to build continuous segments again and so on  . The input is accepted if a bitstring can be obtained that contains as many bits as there are words in the input  . 
The example in figure 3 roughly illustrates the device .   ( Integers among the categories represent the sequence of dependents belonging to the same head  . Lines separate the cycles . )  ( 2 ) What does Gud run feed to her cat ? The parser is fully implemented within the system PLAIN  ( Programs for Language Analysis and Inference )  , developed at the University of Heidelberg . So far , it is applied to German ( Heidelberg , Kiel ) , French ( Paris ) , and
English ( Surrey/UK , Pisa , Hawaii).

Peter Hellwig:"PLAIN-A Program System for Dependency Analysis and for Simulating Na-tural Language Inference "  . In : Leonard Bolc ( ed . ): Representat ion and Processing of Na-tural Language  . Wien : Hanser ; London , Basing stoke : Macmillan 1980 , pp .  271-376 . 
Peter Hellwig : " Dependency Unification Grammar  "  . In : llth International Conference on Computational Linguistics  . Proceedings . 
Bonn , August , 25th to 29th ,  1986 , University of Bonn , pp .  195-198 . 
Carl Pollard , Ivan A . Sag : Information-Based Syntax and Semantics . Vol . I . Fundamentals . 
CSLI Lecture Notes , No .  12 . , Stanford Uni-versity 1987 . 
Position : Tree: ( i )  1  ( what pron )   ( 2 ) Ol ( do verb fin ( SUBJ-noun rai )   ( MV_verb in f2 ) )  ( 3 )  001  ( Gudrunnoun )   ( 4 )  0001  ( feed verb in f ( DOBJ-15 ( IDOBJ_tora2 ) )  ( 5 ) OOO01 ( to (  . _nounra ) )  ( 6 )  000001  ( her poss )   ( 7 ) GO 00001 ( cat noun ( DET_possla ) 5  ( 85 00000001  ( ILLOC ~ uestion ( PRED_do verb finla ) )  ( 95 Oll ( do verb fin ( SUBJ Gudrun noun raI )   ( MV_verb inf 25 )   ( I0 )  0000011  ( c  ~ at ( DE Therpossla ) 5  ( ii )  0000111  ( to ( cat noun ra ( DE Therpossla S )   )   ( 12 ) OO Olll ( feed verb in f ( DOBJ-l )   ( IDOBJ t . ~ ora2 ( cat noun ( DE Ther poss I~55)) .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
(13 ) I001111 ( feed verb in f ( DOBJ what i )   ( IDOBJ t__oora2 ( cat noun ( DE The_rr poss La ) )5 )   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
(I ~ 5 lll l l l l ( d  ~ overbfin ( SUBJ Gudrun noun raI )   ( MV feed verb inf ( DOBJ wha___t15 ( IDOBJ t_~ora2 ( cat noun ( DE Therposs Ia5 ) 5 )  5
I15 ) II iiiii ( ILLOC~n ( PRED do verb fin ( SUBJ Gudrun noun raI )   ( MV feed verb inf ( DOBJ what i )   ( IDOBJ tora 2 ( ca-~--noun ( DE Therpossla ) ) ) 5 ) Fig .   3 States of a chart including discontinuous segments 
