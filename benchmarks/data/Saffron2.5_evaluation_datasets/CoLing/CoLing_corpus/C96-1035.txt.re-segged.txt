Chinese Word Segmentation
based on Maximum Matching and Word Binding Force
Pak-kwong Wong and Chorkin Chan
DeI ) artment of Computer Scien(;(~
The Univ (; rsil ; y of Itong Kong
l ) okfulamih ) a , d
thmgKong
pkwong((~cs.hku.hk and (: chan ? ~ cs.hku.hk
Abstract
A Chinese word Seglnentation algorithm
based on forwardic naxinnll n matching
and word binding force is t ) roposed in
this pai)er . This algorithm Iilaysakey role in postprocessing the outtmt of a character or st /eech recognizer in determining the proper word sequence c  ( /rre-st ) onding to an input line of cha . raeter images or a speech wav ( ~, fol'tn . ~ FO support this algorithm , a text ;   ( : orims of over 63 millions characters i employed to enrich an 80  , O00-words lexi ( : on interlns of its word entries and word binding forces  . 
As it stands now , given an input line of text , the word segment or can proce , ss on the average 210 , 000 characters per se ( : - ond when running on an IBM RISC Sys-tem/6000   3BT workstation with a colrect word identitication rate of  99  . 74% . 
1 Introduction
A language model as at ) ost-processorisesse , ntial to a recognizer of speech or characters in order to determine the approi  ) riate words e , que , n (: e and henc . e the semantics of an in I ) ut line of text or utterance . It is wellknown that an Ngram statistics language model is just as effective as  , t ) ut nmch more eificient than , a syntact k :/ semantic analyser in determining the correct word sequence  . A necessary condition to successflfl collection of Ngram statistics is the existence of a coIn prehensive l  , x-icon and a large text corpus . The latter must tielexically analysed in order to identify all the words  , from which , Ngram statistics can be derived . 
About 5 , 0 00 characters are being used in modern Chinese and they are the building blocks of all wor  ( ls . Ahnost every character is a word and i nost words are of one or two characters long but there are also abundant wor  ( ls longer than two characters . Before it ; is seginented into words , a line of text is just a sequence of characters and there are numerous word segmentation alternatives  . Usually , all but one of these alternatives arc syntactically and/or semantically incorrect  . This is l ; he case because unlike texts in English , Chinese texl ; s have no word n larkers . A tirst step towm ds buiht-ing a language model based on Ngram statistics is to de  , vek ) panet IMent lexical analyser to id ( ! ntify all the words in the , corpus . 
Word segmentation algorithlns behm g to one of two types ill general  , viz . , the structural ( Wang et al . , 1991) and the statistical type ( Lua , 1990) ( Lua and Gan , 1994) ( Sproat and Shih , 1990) rt ; spec-tively . A structural algorithm resolve segmenta-tion mn biguities by examining the structural rcla -tionships between words  , while a statistical algo--rithm compares the usage flequencies of the words and their ordered combinations in ste  , a d . Both approaches ln ~ veserious li in it at ; ions . 
2 Maximum Matching Method for
Segmentation
Maximum matching ( l , iu et al ,  /994 ) is one of the most I ) opular structural segmentation algorithms for Chinese texts  . This method favours long words an ( 1 is agree ( ty algorithm by ( lesign , hen(:e , suboptimal . Segmenl ; ation may start from either end of the line without any difference in segmentation results  . In this paper , the forward direction is adopted . The major advantage of inaximum matching is its et H ciency while its segmentation accuracy can be expected to lie around  95%  . 
3 Word Frequency Method for
Segmentation
In this statistical approach in terms of word frequencies  , a lexicon needs not only a rich repert oire of word entries  , lint also the usage frequency of e , a ch word . To segmentaline of text , each possible segmentation alternative is ewduated according to the product of the word fi ' equencies of the words Seglnented  . The word sequence , with the highest fi'equency product is accepted a . scorrect . 
This method is simple but its a (: curacy ( h , ,lmnds heavily on the accuracy of the usage fi 'equencies  . 
The usage frequency of a word differs greatly from of world news as a  , ga , hlsl ; a , t (' , (: hnical r ( ~ , port . Sil ~ c (' ~( , here , a . r (' . I ; ( ulso\[l,h(/llsa . Ii(lso\[wordsa , cl ; ivelyus(' . ( l , Oil (' , nc ( ; dsagiganti ( :  ( : oll ( ~ ( :ti ( ll : ( ) f texts to mak ( ~  ; ma , (' , (: urat , ( ~ estimal ;( ~ , lint t ) yt ; h(~ . u , the (~ stimat ; (~ is jusl , an averag ( ~ a , n(lit ; ma . y not ; t )( , , suital ) le for any tyt ) (!  ( /\[  ( h ) (:mn ( mt at all . /noth(n ' words ,  1 , mvariml(:(~ofml(:h&ll(~st ; i l l l ~ t l ; ( ~ is to () great making
I ; h(;(~stiirlat(!list less.
4 The Lexicon
Most Chines (; linguists ac (' , ( ; 1) the ( h ' , : linition of a wor (1 as thc minimum unit tha , tisscmanticMly (' , omt/h ' , t(~and (' , all lie , I ) Ut ; tog ('% herast/uihting t ) lo('ks to form a , sent(ulc(ullow(:vex , in Chines (: , wor ( lscant ) (~ unit ( : d t ( / fi ) rm ( : Oml ) ( ) mM words , a . n(l they in turn , (',;/ . ): (: oral/in(:furth(',r1:()rm3,(' . 1, higher (> r(lcr('d(:omt ) (/ und words . As ; 1ma . tt(~roft~lC\[;~COlllI ) o1111 ( lWOl'ds , ~ LI '( ; ~ , xtr(un(~lyC (/ Illlll lOIl ; /11 (~ they exist in large numbers . Risim I ) ossit ) h' , t ; (/ in (: lud (' , all (: Olil\[)() lllld words into the , h!xi (: ( mt ) ut just to k cct )( , host : which are\['re(tu(;nt ; lyUso(la , n(iha . v (', the word (: omtl(mcntsunit('dclos (', ly . A lexicon was at : quirt ; (1 from th ( ; Inst ; il ; ulx ' ~ o\[\[nf()rm ; l-t ; i ( ) i iS ( ; i(~ , ll ( : ( ~ , , Acad(' , nlia , Sini (: a . in Taiwan . Th cr ( ' ~ are 78410 word ( mtri ( : sinl : hish ~ xi ( : ( tn , ( ~ n (: hassociated with a usage frextu(;n(:y . A(:O:'lnls(/t:over63 million(:hara (' . t(:rso\[news lines was acquired\[romChina . l ) u ( ~ t ( /  ( : ulturaldifl ' ( :r ( m ( : ( : softim two st ) - ( :i ( 't ; ios , there arc many words en ( : ( nmt ( ~r ( : ( 1 inth ( :  ( : ( ) rpllS t ) lltII ( )t in t:h ( ~lexi ( : on , rl'h(!lal;t(!rmustt , here t brelieem ' i c h c d 1 ) e for ( ~ it can 1 ) eat ) pli ( : d1: ( / t ) (wt'orln the lexical a . nalysis . The tits ( st , el/t()-wa , r ( ls this end is to merge a h ~ x i ( : ( ml/ut ) lish cd in China into this one , in (: r (' , asing the numt ) ( u ' of word ent ; ries to 85 , 855 . 
5 The Proposed Word
Segmentation Algorithm
Tllct ) rot/os ( : d algorithm of this t ) al> ( :rmakes use ( t\['af ( /rwardma . ximmn matchings t , ra . t (; gy to i ( hultify w()r(\[s , In this r(:sl ) ( ~(: l ; ~ this algorithm is a structural atll ) roa(:h . ( hMer this sl ; ratcgy , errors are , usually a . ssot ; iated with singh ' , -(: haract(~r words , illth('~first(:hm'a , (:ter ( if a lit misi ( hmtili ( ~ dnsa single- ( :haract ( ~ r word , what it nl cans is that ; ther ( ~ is no multi-character word entry in the l ( ~xi ( : onth ; d ; starts with such a chara (: tcr . In that case , there is not much on ( , can do about it ,  . On the other hand , when a characterisk hmtifie , d as a single-cha . ra ( : tcr word fl following another word ( tinth ( : line , one (: annothe , ltl wond ca . ' ing whether tim solechm ' acter ( : omt ) osing/~shouhlnot1 ) (' , combined with th ( ' suffix of ( t to form another word instea . d , even il that metals ( ' hanging ( ~ int ( ) a shorter w ( tr ( \[ . In that case , every t ) ossil/h ~ w(/rdsO , ( lll(~n ( ; (? a l ternat ive ( : or - responding to the Sllt ) -s ( : qilo , iicc of ( ; hari-l ( :t ( ws fr ( )ill c ~ and /3 together will 1 ) e evaluated according to the produ ( : to \[ its constituent word binding for ( ' , es . 
Ttlebinding force of a . wor(l is a . rues . sure of how strongly the charact (' , rsconll ) osing th ( , , word are bound t()g(~ther as a single unit ; . This for ( x : is oLten equated to tim usage fr ( ~qu ( mcy of the word . 
In this l'(!S l ) (:(; l; , the pr()l >() s(;(1 algoritlun is a , sta . tis-ti (: alapl ) roach . It is as ( , , tti (: i (: n tastim maximum lna . t ching moth (/(1I )(~( ; aus(!wor(lbindingf()r(:(!s ; u '( ~ utilized only in ( , x(:(~pti(malcases , th)w(wer , much of the word amt/iguities are climilmt (~ d , h  ~ a ( ling to avc'ry high word identification accuracy  . S ( 'g-m ( :ntation errors as s ( /ciat ( 'd with multi-cha . ract( , ,r words can 11 ( : r ( ~ ( h: ( : cd1 ) y adding or ( leh ~ ting wo Ms to or from the h' , xi (: on as well as adjusting word t ) in ( ling forces . 
6 Structure of the Lexicon
Words in the h:xi ( - ( in are divided into 5 groups a , ccording to woMh ; ngths . They corr(:spond to words ( ) t'l ,  2 ,  3 ,  4 , and more than 4 cha , ra (> ters with group sizes equal t () 70 25 ,  53532 ,  12939 ,  11269 , and 1090 rt ; stmctively . Since i il OS t of t l w , l ; iule spent illmm , lyzing a line , o\[text is illlinding a match among the h ; xicon (' , ntries , a chw cror-ganization o\[the lexiconSlmcdsup thes  ( ' , m ching 1) rot '(~ sstr clnc , l Mously . Most Chin ( , a *, words are o\[(mr : or two cha . racJx ; rs ( ) lily . Searching for l ( mg ( ! rWOl:dSI ) (~\['Ol ( : sholt ( wOliOS ~/ sln'at:tise diuma . xi-mum nu:t ching recalls Sl ) en ( ling a greatile al of times (  , ,arching for ram-existent ; argets . To overcome this problem , I ; 11(' , following measur (' , sarc , takc , n to organize timh : xi confor fasts ( :m' ( : h : ? All s in p ; h ; (: ha . la . c . t , (: rw()t'ml . O,sI;or (; dill ; -/ I ; a-ble of 32768 bins . Since tilt ; itll ; Cl ' llld cod(:O fach a . rat't cr takes 2 bytes , bits l-15 m'e used as th (! b in address for the , wor : l . 
? All2-charat't (' , r words are stored illase , parat (; tabh : of 655"6 bins . ' I ' ll (' , two low order bytes of the two ( : hara ( : ttn's arc used as a shortiwt: ( :g ( ' , l " for bin address . Should t\]mrt ~ be other words (: ont (' , sting for the , same biu , they a , rekept in a linked list . 
? Any 3-ttha . ra , cl ; t ; r word is split into a 2-(', ha . ra,(' . t(;rpe\[ixanda,i\[-chara (: tersutlix . The prt ! lix will tmsi , ored in the bintabh : for 2-('\] lar~l(:t(' , r words with ( : lear in di ( : a tion of its l ) rcfixst & ( liB . ThcSill\[ix will bcs to red in the bintable for l-  ( : harac , t (: r words , again , wiLh clear indication of its suffix status . All ( tut/li-(;ate entries are coral ) trier1, i . e . , if (~ is a word as well as a suflix , tilt ; two entries arc combined into one with a , n indication that it ; can serve as a word as well as a suffix . 
? Anyd-t : haract ; exword is divided up into a 2-chara (' , ttu " prefix and a2-(:haract(n'suffix ,  1 ) oth stored in tile bintable : \[ or 2-character words , with ch:ar indications of tll ( ; irr (' ~ spc(:tivc status . Each prefix points to a link ( ; dlist of as-sociated suffixes . 
2 01 ? Any word longer than 4 characters will be divided into a 2-character prefix , a 2-character infix and a suffix . The prefix and tile infix are stored in the bin table for  2-character words , with clear indications of their status . Each prefix points to a linked list of associated infixes and each infix in turn  , points to a linked list of associated suffixes . 
Maximum matching segmentation of a sequence of characters "  . . . a b c d e f g h i j . .  2' at the character " a " starts with matching " ab " agains the  2-character words table . If no match is found , then , " a " is assumed a 1-character word and maximum matching moves onto " b " . If a match is found , then , " ab " is investigated to see if it can be a prefix  . 
If it cannot , then " ab " is a 2-character word and maximum matching moves onto " c " . If it can , the none examines if it can be associated with an infix  . If it can , the none examines if " cd " can be an infix associated with " ab "  . If the answer is negative , then the possibility of " a bed " being a word is considered  . If that fails again , then " c " in the table of 1-character words is examined to see if it can be a suffix . If it ; can , then " abe " will be examined to see if can be a word by searching the  1-chara  ( q ; er suffix linked list pointed at by " ab " . Otherwise , one has to accep that " ab " is a 2-character word and moves on to start I natching at " c " . If " cd " can be an infix preceded by " ab " , the linked list pointed at ; by " cd " as an infix will be searched for the longest possible sutfix to combine with " a bed " as its prefix  . If no match can be found , then one has to give up " cd " as an infix to " ab ':  . 
7 Training of the System
Despite the fact thai ; the lexicon acquired from Taiwan has been augmented with words fl'om another lexicon developed in China  , when it is applied to segment 1 . 2 million chm ' acter news passages in blocks of 10 , 0 00 characters each randomly selected over the text corpus  , an average word seg-inentation error rate ( IZ ) of 2 . 51% was found with a standard deviation ( c , ) of 0 . 57% , mostly caused by uncommon words not included in the enriched lexicon  . Then it is decided that the lexicon should be fllrther enriched with new words and adjusted word binding forces over a number of generations  . 
In generation i , n new blocks of text are picked randomly from the corpus and words segmented using the lexicon enriched in the previous generation  . This process will stop when I * levels off over several generations  . The 100 ( 1- a ) % confidence interval of t*in generation i is: tz to  . a~ , ~ , __l ~ r/v ~ where a is the standard deviation of error rates in generation i-  1  , and n is the number of blocks to be segmented in generation i  . to . 5 ~, n-1 is the density function of (0 . 5 a , n-1) degrees of free-dom ( Devore , 1991) . Throughout he experiments below , n is always chosen to be 20 so that the 90% confidence interval ( i . e . , ( t = 0 . 1) of tz is about : k0 . 23% . 
8 Experimental Results
The lexicon has been updated over six generations after being applied to word segment  1  . 2 million characters . Tile vocabulary increases from 85855 words to 87326 words . The segmentation error rates over seven generations of the training process are shown in the table below : 



Error Rate 1~, over a text of 200000 Characters
Max . Mat ; .
5.71% 5.20% 4.66% -4U~Sg-0--2.60% 2.4:7%
Max . Mat . ~
Word Bind . t ~ brce2 . 32%- -2 . 16070------1 . 88% 1 . 69,%---0 . 43% 0 . 30% 6 2 . 44% 0 . 2 6% Most of these errors occur in proper nouns not included in the lexicon  . They are hard to avoid unless they become l ) opular enough to be added to the lexicon . The CPU time used for segmenting a text ; of 1 , 200 , 000 characters i 5 . 7 seconds on an
IBM IISC System/60003 BT computer.
9 Conclusion
Lexical analysis is a basic process of analyzing and understanding a language  . The proposed algorithm provides a highly accurate and highly efficient way for word segmentation of Chinese texts  . 
Due to cultural differences , tile same language used in different geographical regions and difl'crent applications can be quite diffferent causing problems in lexical analysis  . However , by introducing new words into and adjusting word binding threes in the lexicon  , such difficulties can be greatly mit-igated . 
This word segment or will be applied to word segment the entire corpus of  63 million characters before Ngram statistics will be collected for postprocessing recognizer outputs  . 

Jay L . Devore .  1991 . Probability and Statistics for Engineering and Sciences  . Du : rbury Press , pages 272276 . 
Ynan Liu , Qiang Tan , and Kun Xu Shen . 1994.
The Word Segmentation Rules and Automatic Word Segmentation Methods for Chinese Information Processing  ( in Chinese )  . QingHua University Press and Guang Xi Science and Tee\]t-nology Press  , page 36 . 

Kim-Teng Luamid Kok-Wcc Gan . 1994. An
Applicat ; ion of \] nibrmal ; i on Theory in (\] hincso . 
Word Segmental : ion . Comp ' ttterl ' ~' oce , ,ssi'lzg of Ch , in csc and Or'i enlal Languages , Vol . 8, No . 1, pages 115123, 2unc ' . 
K . T . lm a .  1990 . From Chm'a clx ' , rl ; oW ordAnAt)plication of hfformai ; ion Theory . Computer Proccss in 9 of Chinese and Oriental Languages , 
Vol . 4, No . 4, pages 304313, March.
Limtg-Jyh Wm~g , Tzushengl'ei , Wci-(\]huanIA , and Lih-Ching11 ,  . Ilmmg .  1991 . A Parsing Method for hh ' , ntit ~ yingWords in Mandarin Chi-nes ( , , S('m~( , am( , ~ s . Inl'roccs siugs of 121 , hlnt (:>' national , loin / , Conference on Artificial httellig cncc , pages 10181 . 023 ~ l ) ~ rrling II arl ) our , Sydney , Austr~dia , 24-30 August . 
lictmrd Sproat ~ md Chilin Shih .  1990 . ASt , ads-deal Method for Finding Word Boundaries in Chinese Text  . Computerl ' rocess in . q of U hinese and Oriental Lo , n . q,tta . qes , Vol . 4, No . 4, pages 336349, Mm'ch . 

