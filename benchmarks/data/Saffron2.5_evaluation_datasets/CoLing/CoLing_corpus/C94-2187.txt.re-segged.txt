ADISCOURSEGRAM MATICO-~TATISTICAL APPROACH TO

Tadashi Nomoto and Yoshihiko Nitta
Adwmced Research Laboratory , II it a chiLtd.*
cmMl : nomoto , nitta?harl , hitachi , co . jp
Abstract
The paper presents a new approach to text segmentation --  . which concerns dividing a text into coherent discourse units  . The approach builds on tilettle-ory of discourse segment  ( Nomoto and Nitta ,  1993) , incorporating ideas from the research on information retrieval  ( Salton ,  1988) . A discourse segment has to do with a structure of Japanese discourse  ; it could be thought of as a linguistic unit delnar cated by wa  , a Japanese topic particle , which may extend over several sentences . The segmentation works with discourse segments and makes use of coherence measure ba~sc dontf idf  , a standard information retrieval measurement ( Salton , 1988; II earst ,  1993) . Experi , nents have been done with a Japanese newspaper corpus  . It has been found that the present approach is quite suce cssfld in recovering articles fronl tile unstructured corpus  . 
Introduction
In this paper , we describe a method for discovering coherent texts from the unstructured corpus  . The method is both linguistically and statistically motivated  . It derives a linguistic motivation front the view that discourse consists of what we call discourse segments  , minimal coherent mt its of discourse ( Nomoto and Nitta ,  1993) , while statistically it is guided by ideas from int brmatiou retrieval  ( Salton ,  1988) . Previous quantitative approaches to text segmentation  ( Hearst , 1993; Kozima , 1993; Youmans ,  1991 ) have paid little attention to a statistically important structure that a discourse might have and detined it away ~ Ls a lump of words or sentences  .   1'art of our concern here is with explicating possible effects of a discourse segment on the quantitative structuring of discourse  . 
In what follows , we will describe some important features about discourse segment and see how it can be incorporated into a statistical analysis of discourse  . 
Also some comparison is made with other a pl ) roaches such as ( Youmans ,  1991) , followed by discussion on the results of the present method  . 
Theory of Discourse Segment
The theory of discourse seF,ment ( Nomotoa . ndNitta , *2520 tatoyama Saitama 350-03 Japantel . +81-492-9 C~6111 fax .  +81-492-9 ( ~-6006 1993 ) carries with it a set of empirical hypotheses about structure of Japanese discourse  . Among them is the claim that Japanese discourse is constructed from a series of linguistics units called discourse segment  . The discourse segment is thought of a za topic comment structure  , where a topic corresponds to the subject matter and a comment a discussion about it  . In particular , Japanese haz a special way of marking the topic : by sutllxing it with a postposition Mp article wa  . Thus in Japanese , a topic comments ructure takes the form : topic comment where "*" represents a word  . The comment part could become quite long , extending over quite a few sentences ( Mikami ,  1960) . Now Japanese provides for a variety of ways to mark off a topic comment sructure  ; the wa-marking is one such and a typographical device such as a line-or a page-break is another  . For the present discussiou , we take a discourse segment to b ca block of sentences bounded by a text break and/or awa -marked element  . 
I T1   ~'1   5'2 "'' Sn\[~ t~2   Sn-F1   Sn+2 '"" Sn-Frn\] , 
Discourse Segment Discourse Segment where " T " denotes a boundary marker  , " S " a sentence , and "\[" a segment gap . For the semantics of a discourse segment , Nomoto and Nitta ( 1993 ) observes an interesting tendency that zero ( elliptical ) an apl , or a occurring within the segment do not refer across the segment boundary  ; that is , their references tend to be resolved internally 1   . 
Now we take a very simple view about tile gk ) bal structure of discourse : syntactically , discourse is just lller c and throughout we use  01 for a subject ( NO Minative ) zero ; 02 for a object ( ACCusative ) zero ; TOP for a topic case ; I ) AT fox " a dative ( indirect object ) c~me ; PASS for a passive mor-\] . )heIIle . 
I'l'aro <,>- wa01<i > rojin<i>-his eki
TO Poldman DAT seat-wo yuzutte-age ta node , 01 < i > 0 2 < j >
ACC give help because or ei-wo iwaret,~ . \[ thank say PASS"l\]e cause ~\] hro gave the old man a favor of  9iv-im  . lase at , he thanked Taro . " Note that all the instances of01 a a ~ d 02 have internal antecedents :
Taro and rojin.
114 . 5 a chronological juxtaposition of contiguous , disjoint blocks of sentences , each of which corresponds to a discourse segment ; semantically , discourse is a set of anaphoric is lauds set side byside  . Thus a discourse should look like Figure 1 , where G denotes a discourse segment . Fnrthermore , we do not intend the dis-

Figure 1: Discourse Structure course structure to be anything close to the ones that rhetorical theories of discourse  ( tIovy , 1990; Mann and Tholnpson , 1987; Itobbs , 1979) claim it to be , or inteu-lional structure ( Grosz and Sidner ,  1986)  ; indeed we do not assmne any functional relation , i . e . causation , elaboration , extension , etc . , among the segments that constitute a discourse structure  . The present theory is not so much about the rhetoric or the function of discourse as about the way anaphor are interpreted  . 
It is quite possible that a set of discourse segments are no taggregated into a single discourse but may have diverse discourse groupings  ( Nomoto and Nitta ,  1993) . 
This happens when discourses are interleaved or embedded into some other  . An interleaving or an embedding of discourse is often invoked by changes in narrative mode such as direct/indirect speech  , quoting , or interruption ; which will cue the reader/hearer to suspend a current discourse flow  , start another , or resume the interrupted is course . 
A Quantitative Structuring of

Vector Space Model
Formally , a discourse segment is represented as a lerm vector of the form: 
Gi = ( gil , gi2, gi3 .   .   .   . , git ) where a . .qi represents a nominal occurrence in Gi . Ill the information retrieval terms , what happens here is that a discourse segment Gi is indexed with a set of terms gll throught it  ; namely , we characterize Gi with a set of indices gil ,   .   .   . , tit . A term vector can either be binary , where each term in the w~'ctor takes 0 or 1 , i . e . , absence or presence , or weighted , where a term is assigned to a certain importance value  . In general , the weighted indexing is preferable to the biuary indexing  , as the latter policy is known to have problems with precision  ( Salton ,  1988) 2 . The weighting policy that we will adopt is known as If  . idf It is an indicator of term importance Wij defined by: 
Nwij . = tfij*log~j 2 Precision measures the proportioi1 of correct items retrieved agains the total number of retrieved items  . 
where tf ( term frequency ) is the number of occurrences of a term Tj in a document Di  ; df ( document frequency ) is tile number of documents in a collection of N documents in which  7  ) occurs ; and the importance , wlj is given ~ s the product of if and the inverse df factor  , or idf , logN/dfi . With the tfidf policy , high-frequency terms that are scattered evenly over the entire documents collection are considered to be less important than those that are frequent but whose occurrences are concentrated in partic nlar documents  3  . Thus the tf . idf indexing favors rare words , which distinguish the documents more effectively than common words  . 
With the indexing method in place , it is now possible to define the cohercnce between two term vectors  . For term vectors X = ( xl , x ~, .   .   . , x ~) and Y = ( Yt , Y2, . .  . , Yt ), let the coherence be defined by : t/=1
C(X,Y ) = tti- . ~14 = 1 where w ( xi ) represents a tfidf weight assigned to the term xi  . The measure is known as Dice coefficienl 4 . 
Experiments
Earlier quantitative approaches to text part it ioning  ( Youmans , 1991; Kozima , 1993; I learst ,  1993 ) work with an arbitrary block of words or sentences to determine a strneture of discourse  . In contrast , we work with a block of discourse segments . It is straightforward to apply the tfidf to the analysis of discourse  ; one may just treat a block of discourse segments as a document unit by itself and then define the term frequency  ( tJ )  , the document fi'equency ( dJ ) , and the size of docmnents collcction ( N ) , accordingly . Coherence would then be determined by the number of terms segment blocks share and tf  . idf weights the terms carry . 
Thus one pair of blocks will become more cohesive than auother if the pair share more of the terms that arc locally frequent  . 
The partitioning proceeds in two steps . We start with the following : 1 . Collect all the nominal occurrences found in a corpus  5   2  . Divide the collection into disjoint discourse seg -lrlents  . 
3 . Compare all pairs of adjacent blocks of discourse segments  . 
3 Precision depends on the size of docmnents coLLection  ; as the collection get , s smaller in size , indexternls become less extensive and more discr iminatory  . The id\]factor could be dispensed with ill such cases  . 
4Other measures s tandard ly avai lable in the in format ion ren ' ieval include inner product  , cosine coefficient ~ and Jaccard co-eJficient . 
5 Thlsis ( tone by JUMAN , a Japanese morphological naly zer ( Mat . sumoto et al , 1993) . 

Omn Joo
SEGMENTS
Figure 2: A coherence curve 4 , Assign a coherence/similarity w due to each pair . 
Next , we examine the coherence curve for hills and valleys and partition it manually  . Valleys ( viz , low coherence val , es ) are likely to signal a potential break in a discourse tlow  , whereas hills(viz , high coherence values ) would signal local coherency , l , ' igure 2 shows how a coherence curvel night appear . 
Coherence is measured at every segment with a paired comparison window moving along the sequence of segments  . Or more precisely , given a segment dj and a block size n , what we do is to compare a block Sl ) am'ing dj-t~4-1 throughdj and ones l ) anning dj+l throughdj+n-1 . The lneasnrement is l ) lotted at the jth position on the x-axis . If either of ; lie comparison yl , ' igure 3: A Moving Paired Window windows is underiilled , no measure lnent will be made . 
The graph that the procedure gives out is smoothed  ( with an appropriate width ) to bring out its global trends . The length of a single segment , i . e . , noun counts , w tries from text to text , genre to gem : e , ranging from a few words ( a junior high science book ) to somewhere around 60 words ( a newspaper editorial )  . 
We performed experiments on at bur-week collection of editorials fi'om Niho  , Keizai Shimbun , a , lapanese conomics newsl ) al)er , which contains the total of 1111 sentences with some 10  , 000 nouns , and 556 discourse segments . The corpus was divided into segmental sets of nouns semi-autolnatically  6   ( k ) herence was measured ff ) reach adjacent pair of segments , using 6The lll ~ lllllill part consists in tumd-liltoering the corpus to eliminate non-topic marking htstem ccs of tl ~ e particle wa  , i . e . , those that are suffixed to case particle such a . st0(C ; ONmNCTIVI . ;) , de ( LOcATIVF , /IN'rI'~UM~:NTAL ) , he(F:ImnCrlONA\[ , ) , kara ( SO Ult CP , ) , nl(DATIVE ) , ere . , or to & part icular form of verbM inflection ( renyou-kei , i . e . intinitive ) ; thus wais treated as nontopical unless it occm * as a postpo ~ itlon to the bare noun  . 
the Dice coefficient . It wa~s found found that the block size of 10 segments yiehls good results . Figure 4 shows a coherence graph covering a hmltaweek's amount of the corpus  , The graph is smoothed with tile width of 5 . 
We see that article boundaries ( verticalines ) coincide fairly well with major minima on the graph : with only one miss at  65  , which falls on a paragraph boundary . 
o ? -=05'
OA'03'
O2202:
I 6O   80   100   120   :140   160 l : igure 4: A Dice Analysis Experinmnts with w ~ rious block sizes suggest hat the choice of block size relates in some way to the strucoture of discourse  ; an increasing block size would extract a more global or general structure of discourse  . 
Youmans ( 1991 ) has suggested a information measurement b~sed on word frequency  . It is intended to measure the ehb and flow of ' new information ' in dis?coarse  . The idea is simply to count them mlber of new words introduce dow'x a moving interval and  1  ) roduce what he calls a vocabulary managemenl profile  ( VMI ' )  , or lneasurements at intervals . Now given a discourse 1) = wl , .   .   .   , w ,   ,   , tile kth interval of the size A is defined by lk : : wt  . , .  ? . , w , . where : k + A-I if k < n-Avn otherwise Measurements are made at interwfls  I1 through/n-l . 
11 o 71 . 60"140"\] 2o 100"80"60"40-=0 ? ? . 1 "  .   . N"-'~"",,,r' . u .  -  . ' T ', . -I ,,- I-, u - , , u ', u 200 400 600 8001 . 0001200140016001800
WORDS ( TOKENS )
Figure 5: AVMP Analysis
What we like to see is how the scheme ( ' Omlmres with
OD8-0D7-0D6-0D5-004-003--0 D2-0D1--
O ' , o ? ,   , ?iaigtiinaaIoiii!!i!lIlII IIiIIIII I':  ; I : i iff ii !^ ,  -
Ii ; Ii
IIll , ,, o:i'\[!~::..
aiii Jialti
III"I''IIIII 100200,.i

Iq
Jll:\[''I ! a 4OO ii ' I the same nominal collection as above . The interval is set to 300 words , or the average length of a paired window in the previous analysis  . The y-axis corresponds to the number of new words  ( T Yro , :) and the x-axis to an interval position ( TOK ~ ; N ) . As it tnrns out , the VMP fails to detect any significant pattern in the corpus  . 
One of the problems with timanalysis has to do with its generality  ( Kozima ,  1993) ; a text with many repetitions and/or limited vocabulary would yield a flattened VMP  , which , of course , does not tell us much about its inner strncturings  . Indeed , this could be the case with Figure 5 . We suspect hat the VMP scheme fares better with a short term coherency than with a long term or global coherency  . 
Evaluation l , ' igure 6 demonstrates the results of the Dice analysis on the nikkei collection of editorial articles  . What we see here is a close correspondence between the Dice curve an  ( l the global discourse structure . Evaluation here simply consists of finding major minima on the graph and locating them on the list of those discourse segments which comprise the corpus  . The procedure is performed by hand . 
Correspondences valuation has been l ) roblemati-cal , since it requires human judgment so ~ how discourse is structnred  , whose reliability is yet to be demonstrated . It was decided here to use copious boundary indicators such as an article or paragraph break for evalnating matches between the Dice analysis and the discourse  . For us , discourse structure reduces to just an orthographic structure  7  . 
In the figure , article boundaries are marked by dashes .   7 out of 27 local minima are found to be incorrect , which puts the error rate at around 25% . We obtained similar results for the Jaccard and cosine coefficient  . A possible improvement would include adjusting the document frequency  ( d\] ) factor for index terms ; the averaged ffactor we had for the Nikkei cor -pns is around  1  . 6, which is solow as to be negligibles . 
; ' Yet , there is some evidence that an orthographic structure is liuguislically significant  ( Fujisawa et al , 1993; Nunberg ,  19(00) . 
8I Iowever , the averag cdf factor would increase in proportion Another interesting possibilty is to use an alternative weighting policy  , the weighled invet~se documenl frequency ( Tokunaga and Iwayama ,  1994) . A widf value of a term is its frequency within the docmnent divided by its frequency throughouthe entire document collection  . "\[' he widf policy is reported to have a marked advantage over the idf for the text categorization task  . 
Recall and Precision
As with the document analysis , the effectiveness of text segmentation appears to be dictated by recall/precision parameters where : number of correct boundaries retrieved 
Fecall = total number o /' correct boundaries number of correct boundaries retrieved precision = total number of boundaries retrieved A boundary here is meant to be a minimum on the coherence graph  . Precision is strongly affected by the size of block or intervalg  ; a large-block segmentation yields less boundaries than a small-block segmentation  . 
( Table 1) . Experiments were made on the Nikkcicor-
Block Size 510 1520 2530 35
Boundm'ies 522 524 2021 1912
Tableh Block size ( in word ) and then nmber of boundaries retrieved . 
pus to examine the effccts of the block size parameter on text segmentation  . The corpus was divided into equMly sized blocks , ranging from 5 to 35 words in length . The window size was kept to 10 blocks . Shown in Figure 7 are the results given in terms of recall and precision  . Also , a partitioning task with discourse segments , whose length varies widely , is measured for recall and precision , and the result is represented as G . 
Averaging recall and precision values for each size gives to the growth of corpus size  . It is likely , therefore , that with aft T-0 . ( r0 . ~
O4-0~(LI-th'ecision+$++2010++5+0 . 1 0 . 2 113 0 . 4
Recall "1I'J 0.7 (1.8 0.9
Figure 7: Rec . all and Precision an ordering : 35<25<20<5<30<15<10<  (   ;   . 
Orankshighest , whose average value , 0 . 66, is higher than any other . ~10' comes second (0 . 61) 1?  .   ( It is an interesting coincidence that the average length of dis = course segments is  \[3  . 7 words . ) The results demon : strate in quantitative terms the significance of dis-eot lrse segments  . 
It is wortht ) ointing out that l , he method here ix rather select lw ' ~ about a level of granularity it detects  , namely , that of a news article . It is possible , however , to have a much smaller granularity ; as shown in Table 1 , decreasing the block size would give a segmentation of a smaller granularity  . Still , we chose not to work on finegrained segmentations I  ) ( ; cause they lack a reliable evaluation metric ~ t . 

In this l ) a per , we haw ; described a method for I ) art , ition-ing , qllun structure deorlms into coherentextual milts  . 
We have adopt c~d the view that discourse consists of contiguous  , non-overlal ) ping discourse segments . We have referred to a vectors l ) acc model for a statistical representation f discourse seglnell t  .   ( Joherenceb ( > tween segments is determined by the Dice coefficient with the If  . idf term weighting . 
We have demonstrated in quantitative terms that theme  . thod here is quite suce ess fl din discovering articles fi'om the eort  ) us . An interesting question yet to be answered is how the corpus size affects the doculmnt larger corpus  , we might get , bettere sults . 
? Blocks here a . reine lided 1; olll ( all minlntall . extll ; t units into which a discourse is divided and fro ' which c  ( )hcrellCe is lttetmure ( l . 
1 ? In general , recall is inversely proport . i(mate o precision ; a high precision implies a low recall and vice versa  . 
11 Passonneaundl , itman (199 . '0 reports a psychological study on the htlnt ; I . n reliability of discourse segmental . ion . 
frequency and coherence measurements . Another problem h~s to do with relating the present discussion to rhetorical analyses of discourse  . 

Sl , inji Fujisawa , Shigeru Masuyama , and Shozo Naito . 
1993 . An Inspectionoll Effect of Discourse Contraints pertaining to l  , ' , llips is Supplement in Japanese Sentences . In Kouen-Ronbun-Shuu3 ( conference papers 3) . Inforn\]ation Processing Society of Japan . In Japanese . 
Barbara Grosz and Candance Sidner .  1986 . Attention , Intentions and the . Structure of 1) is e ours e . Computational Linguistics , 12(3):175--204 . 
Mart A . Hearst .  1993 . TextTiling : A Quantitative Approach to l ) iseom'se Segmentation . Sequoia 2000 93/24 , University of California , Berkeley . 
Jerry R . l\[obbs .  1979 . Coherence and Corefernce . 
Cognitive 5' cicncc , 3(l ): 67-90.
F , duard II . l\[ovy .  1990 . I ) arsimonious and Profligate A1 ) proaches to the Question of l ) is course Structure I ( elations . In 5th ACI , Workshop on Natural Language Geucralion , l ) aws on , Pemnsylwmia . 
l lide ki Kozima . 19 ! i ) 3 .  3\' . xt Segmentation Based on Similarity Between Words . In Proceedings of the 31st Annual Meelin . g of the ACL . 
W . C . Mann and S . A . q ' hom I ) son .  1987 . Rhetorical Structure Theory . luL . Polyani , editor , The S'truc-ture of Discourse . Ablex Publishing Corp . , Norwood , Nil . 
Yuji Matsmnoto , Sadao I(urohashi , Takehito Utsuro , Yutaka Tack , and Makoto Nagao ,  19 . q3 . Japanese Morphological Analysis System JUMAN Manual  . 
Kyoto University . In Japanese.
Akira Mikami .  1960 . Zouwatlanaga Nagai ( 7' heelephant has a long trunk . ) . Kuroshio Shuppan,

Tadashi Nomoto and Yoshihiko Nitta .  1993 . Resolving Zero Anaphora in Japanese . In AC\[ , Proceedings of Sizlh European CoT@r'ence , pages 315321 , 
Utrecht , The Netherla , lds.
( ~ eotl'rey Nunberg .  1990 . The Lingui Mics of Fuuctua-lion , volume 18 of (/ SLI Leclure holes . CSLI . 
ll . ebecca J . Passotmeau and Diane J . I , itman . i\[9 !) 3 . 
Intention-based Segmentation : lluman Relial ) ility and ( Jorrclation with Linguistic Cues . In Proceedings of the 3lst Annual Meeting of the Associalion for Computational Linguistics  . The Association for Computational I , inguistics . Ohio State University , (~' oluln bus , Ohio , USA . 

Gerald Salton .  1988 . Automatic Text Processing : the " l ~ ' ansfovmalion  , Analysis , and Retl % val of Information by Compuler . Addison-Wesley , Reading,

Takenobn Tokunag and Makoto Iwayama .  1994 . Text Categorization based on Weighted Inverse Document Frequency  . unpublished manuscript , submitted to ACM SIGIR 1994 . 
Gilbert Youmans .  1991 . A New Tool for Discourse Analysis : The Vocabulary Management Profile  . Language , 67:763-789 . 

