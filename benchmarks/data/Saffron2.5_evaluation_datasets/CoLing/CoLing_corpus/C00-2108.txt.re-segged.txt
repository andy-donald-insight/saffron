Chlstering Verbs Semantically
According to their Alternation Behaviour
Sabine Schulte im Walde
Institut f/it Maschinelle S1) rach vera , r l w . itung
Univ crsitSA : Stuttgart
Azenbergstral ~ e12, 70174 Stuttgart , ~ ermmW
schulte@ims,uni-stuttgart , de

Verbs were clustered seInantically on the basis of their alternation behaviom :  , as characterised I ) y their syut ; acticsul ) caI ; e . gorisation franms extra el : ed from lllll Xillllll proba  . bili (; y parses of a robu , stsI ; at isl ; i calpa . rser , a alde Oml ~ leted by assigning \' V or dNe ( ; classes as se\]ecl , ional preferences ( ; othefl : a mearl ~ uments . 
The clustering was achieved ( a ) iteratively by mea-su ) : ing the lelal ; iveenl ; rol ) yb ( , tween (; he verbs'l ) rOl ) - ability dis(; ribut , ions ( ) vet ' the . franle ( , yl ) eS , and (1)) l ) yul ; ilising a lateni ; (: lassm/a . lysist ) ased on the joint frequencies of verbs and flmne . (, yl ) eS . 
1 Introduction
This paper eml ) irieally investiga ( ; es the proposition that ve , rl ) scan 1) eseman ( ; ically classilied according to their synl ; a(:( ; icalterna . tion1)e haviour(:()n(:ernint,;subca . ( ; (% orisation frames ; rod theirseleetional i ) ref-er ( ; ncest br the , arguments within the frames . The idea isl ( ; lal ; edIx )( lx ' . vin , 1993) who de . lined verl > classes on the basis of verl ) atterl ) al ; ionbeh ~ aqour . 
For exm nl ) le , (; hese man(;ic (: lass of l&h , icle Namesconi , ains verbs likelml loo'n , bicycle , ca . ' n , oe , skate , ski which agree in ( ; he prol ) erties (1)-(4) below . 
(1) 1NT ltAN . qlTIVI . ; IJSI , :, possibly followed by ; tpath : a . ' l Pheyskated . 
1) . They skated a\] (   ) ngLllecanal/overt:lel > ri ( lge . 
(2 ) INI ) UCI'H ) ACTIONAI : rEIuqA'rIoN ( ~ omeverl > s ) : a . It eskated Pennyaround the rink . 
( causing the aetiol tnanled 1) y the verb ; tyl ) ie a leau see ism ~ alfimal ; evolitional entity ) b . Pennyskated a . round the )' in l ? . 
(3) LO(3A'riv I , ; PI . 1,; I'OSITION \]) lOl>A~:r ), m~A-
TION ( some verbs ): a . They skated along the canals . 
b . They skated the canals.
( ~) I.I ,; S1.11" IWI'IVI,;IqlIIASE :
Pem~yskated her skate blades bhmt ( an XI ) describing (  , hesl : a ~ eachieved by lhereferent of ( ; l ) ( ~ nora ) l ) hrase as are su\]l ; of the acl , ioummw . , . l by the verb ) Levin's work rel ) resenCsth ( ~ basis fo catani , ; e <) f , e-cent invesl ; ig ; d , ions veril ) qng(\]) or r:m(1 . lone . %\]996), evaluating ( SI ; e . \, ensollaud Merl % 199 ! 0 or ut Ji ; :: . 
ing(\]mpata . , 1999) the propose delas . qitlcation -, ~ well as transferring i (, 1 . oother lanw , ta . ge ', ~ tha:l ~; u-glish(Jones et al , 7199 . \[) ~ Generally , the definition of a verl/ssellla Iii . i (: (:\]; /: ~ . q can be considered as part of its lexic . al entry , next io idiosyncratic intinmation : the Sell la , lll ; icCI ; ts ~; gell-eralises as a . l . ypedefinition over ~ trangeo\[s . yn-l,acl . icnnds(mmnl:ic\])tOl)ertie:;,Lo . qUl ) por(;Nai . u . ': dl ~ a . nguat , ; e Process in p ; in V ;/\['\] . () lI~4 . ~II'(~;/S like . h ' , xic or ; c~t-phy(llapl)ai > or tl\]ov'av and I , ev in , t99~;) , wo ) I : ; (: it ~: edisaml ) igual : i(m(l ) or raml . \] one ea , ? l !)!) i ; ), or ()' . ~+-nlelll ; cla , ~ silh:al . ion(Klavm ~ . ~; and Kaa ,  199 , ~0 o I al ; l ; enl pLedl ; o aul ; oma Lica \] lych , sicr verb > ~ h ~ i ; oselna . lti , ie el as . '-; c ~; Olll . beb; . tsi ' AOfi , \] evel\]) , -;~~ll ; (~ P , ; I-tion I)e haviol tr . ' l ) lmiulm 1 ; into i : heat/i ; (ii\[Nti ; it ; iIJ(!!!(:tionpr()(:e , ~ q:4 w;m characi:eri:;ed1) y(J ~ e\;erl ) ' , 4' di>:l . ~; Im-(,ioneve\]", qyJil,;tc,\](;~;ul>ca . l ; egori >;; tl;i(m' . : ~; I ! ~1 . U . ' A ~!\] K-Lrael ; ed from ) u : tx in nlmpvol > alfilt5'(Vil . crlfi ) ! : , ~ c~e:-' , ( ) f ~ / l'O ) ll , ql ; ' r ; I ; t , ll;i'At , \] C~!\]l ); / l':;?;!'~;ll!(tc:()i(l\]~i(;i , , . , d . ,\- ; t!;-siff lt i l l ~ \ Vor (\[)~ , :;(;(: l:is' , ' , ( z : ; ; ~ . ~;;(~\]('~(:; i . o~l,lJl ~ i:eI'ei'~!;,:c:;:o the frame a . rg~m ~ e ** i ; : ', . ' F b e , clmd:eti~i ~ a ~;~:' ,  ; , el , :  , 4 d(a ) iteratively 1) yme;mminigL herelai , ive , ;~ , ~ , ') p3' . m-l , ween t , he verbs ' probability dist ): it ) c , i , io , ~:~ ;  , , , (: , the frametyl)e , % m~d(I )) l ) 3 , uLi/i ' . -;inga . Ld : e , tcD ; ;; . ic , : tal . -3' s is ba , q(:don(, l)ejoi . i ; J ' requen (: ies of verl > ~ sa: , > d  ~ , ;:: , 1~'~?'~tyl)eS . U , ~; itu ~ Ii , ev in ':;\ , c ) ' belas , ' , if ic : d;\]o ~); ' ,  . ~' ~ c , ,ai~;~;ion basi , q , 61% of the \ , ert ) ~ ; were classified ( ; o1 ; ( ; <5 ; 13 ~>! ; o  ~ ; emm ~ ticcla : ; 5 ; e ; l > y met , l: , ut(a ) , ; rod 540/0b3:~ . ~ i . ! . .~d (1,) . 
Section 2 de :; cribe ', ; ( ; l ) e three . : de , !, : ~ h~i!w,~:~i . ,')--marie aC(luisit;ion of , qen ) an ( ; i < verb cla : : ; sc ~;; i . l ) e ~ . , h > ation takes l)\]a(:e , in , ~ eel ; io Jl 2 , ; lAd . ~; oel . ioild(tJ : , , . l ~>; ~; ~; ( , here : mll : s . 
747 2 Automatic Acquisition of
Semantic Verb Classes
Tile first step was the induction of purely syntactic subcategorisation fi'ames for verbs from the heterogeneous British National CoTpus  ( BNC )  . I used the robust statistical head-entity parser as described in  ( Carroll and Rooth ,  1998 ) which utilises an English contextfree grammar and a lexicalised probability model to produce parse forests  , and extracted the maximum probability ( Viterbi ) parses , for a total of 5 . 5 million sentences . The trees were mapped to subcategorisation frame tokens consisting of ainain verb and its argmnents  . Each syntactic category was accompanied by the lexical head  , the pret ) ositional phrase by the lexical prepositional head plus the head noun of the subordinated noun phrase  . Proper names were accompanied by the identifier pn  . The head information in the frames was lemmatised  . For example , the sentence Sam-routh and led the plaud its during the awards ceremony would be represented by the frame token handle subj*pn*sammutobj*plaudit pp * during * ceremon y  . 
To generalise over the verbs ' usage of subcategorisation frames  , I defined as 88 frame types the most frequent frames which appeared at least  2  , 000 times in total in the BNC sentence parses , disregarding the lexical head information . On the basis of the frame types I collected information about the joint frequencies of the verbs in the BNC and the subcategorisation frame types they appeared with  . These frequency counts then represented the syntactic description of the verbs  . 
Tim next step was to refine the subcategorisation frame types by a preferential ordering on conceptual classes for the argument slots in the fl ' ames  . The basis I could use for the selectional preferences was provided by the lexical heads ill the fi'anm tokens  . 
For example , the nouns appearing in the direct object slot of the transitive frame for the verb drink included coffee  , milk , beer , indicating a conceptual class like beverage tbr this argument slot  . 
If ollowed ( Resnik , 1993)/(Resnik ,  1997 ) who defined selectional preference as the amount of information a verb provides about its semantic argument classes  . He utilised the WordNet taxonomy ( Beck-with et al ,  1991 ) for a probabilistic model capturing the cooccurrence behaviour of verbs and conceptual classes  , where the conceptual classes were identified by WordNet synsets  , sets of synonymous nouns within a semantic hierarchy  . Referring to the above example , the three nouns coffee , milk , beer are in three different synsets-since they are not synonyms -  , but are all subordinated to the synset beverage , drink , potable . The goal in this example would therefore be to determine the relevant synset as the most selectionally preferred synset for the direct object slot of the verb drink  . 
Redefined fbriny usage , the selectional preference of a verb vt bra certain semantic lass c within a subcategorisation franm slots was deternfined by the association ass between verb and semantic lass := desPl  , C , lV ~ pOg ~ ( 5 ) with the probabilities estimated by maxin mnl likelihood : f  ( v , ,
P ( C*lVs)-f(vs ) (6) p(Cs ) = f(c . , ) _f ( cs )   ( 7 ) f ( c's )  / ( 8 ) and the following interpretation : 1 . f(v , , c , ): number of times a semantic lass appeared in a fi'ame slot of a verb's fi'ame type  2  . f(v , ) : frequency of a verb regarding a specific fi 'ame type  , i . e . the joint Dequency of verb and frame type 3 . f ( Cs ) : numl ) er of times a semantic class appeared in a fi'ame slot of a frame type d is regarding tim verb  4  . ~?' c , ~'** , ,s f(c '~) equals f(s ) , the frequency of the argument slot within a certain frame type  , since summing over all possible classes within a subcategorisation fl'ame slot equals the lmlnber of tinms the slot  ; appeared 5 . f(s ): uuln ber of times the franletype appeared , since the frequency of a . frame type equals the frequency of that frame with a certain slot marked The fi'equencies of a semantic class concerning an argument slot  , of a frame type ( dependent or independent of a verb ) were calculated by all approach slightly difl ' erent to Resnik's  , originally proposed by ( Ribas , 1994)/(Ribas ,  1995) . For each noun appearing in a certain argument position its fi'equency was divided by then mnber of senses the noun was assigned by the WordNet hierarchy  , t to take account of the uncertainty about the sense of the noun  . The fi'action was allocated to each conceptual class in the hierarchy to which the noun belonged and accumulated upwards until a top node was reached  . Tile result was a numerical distribution over the Word- 
Net classes :/( noun ) (8) s(c , /-- E1 For example , when considering the noun coffee isolated from its context  , we do not know whether we are talking about the beverage coffee  , the plant coffee or a coffee be an . Thero . -for e , a third of the frequency of the noun was assigned to each of the three classes  . 

I restricted tlmpossible ( : onceptual classes within 1 ; hefl'ames ' argmnent slots to 23Wor(tNet nodes ,  2 1 ; of a cilitate generalisation adcomI ) arison of the verbs'seleetional preference behaviour  . 
On the basis of the inforlnational ) out subcategorisation frame types and their arguments ' concet  ) tual classes I clustered 153 verbs from Levin's classitica- (  ; ion . I chose ( i ) some l ) olysemous verbs to investigate how this l ) he nome noncould be handled 1 ) y the clustering algorithms , and ( ii ) high and low frequent verbs to see the intluence of frequency on th  (  ; algorithms : the 1~3 verbs had 226 verb senses which belonged to 30 different semantic lasses . D ) ur of the verbs were low-Dequeney verbs with a total corpus frequency below  100  . 
To cluster the verbs I applied two different algorithms  , and each algorithm clustered the verl ) s bot , h ( h ) according to only the syntactic information about tlm subcategorisation frames  , and ( B ) according to the intbrmation at ) out the subcategorisation ti'ames including their selectional  1  ) referelmes . 
, . lterative clustering based on adcfinition by ( Ilugh , es ,  109/ , ): In the l ) eginning , each vert ) represent ; eda singleton cluster . Iteratively , the distances between tim clusters were lneasure ( l and the closest chls-ters merged to gel ; her . 
For the rel ) resentation of the . verbs , each verl ) v was assigned a distribution over the ditfere . nttyl)es of subcategorisatiol lfl'anmsi , according 1; othe . maximum likelihood estimate , of ( k ) the . 
verbapl ) earing with the frametyl)e:f(v , / , ) f ( , , , ) (9) with f(v , t ) the joint fi'equency of verb and frmne type , and f(v ) the fl'e(tuency of the verb , and ( B ) the verb appearing with the framety t ) emid a selectionally t ) refe . rred ( : lass coml ) ination C for the m'gmnent t ) osil ; ions . sint : i , (~ , , e ly ) = , , ef p(tl v ) * J , ( Clv , t ) (10) with p(/ , lv ) defined as in equation (9) , and p(C\]v , t ) = &/ Ec : 6 , : l , , . ~,\[ Iscta . s . s'(v . ~ , c' )   ( 11 ) which intuitively estimates the probability of a certain class combination by comparing its association value with the sum over all possible class combinations  , concerning the respective verb and frame . 
2 I chosel . he 11tel ) level nodes of the 11 WordNet l , ierar-chies as conceptual classes . ' Phetoplevel node Entity seemed too general as concel  ) tual class , so it was replaced by its 13 sulml'dinal , ed synsets . 
Starting out with each verb representing a singleton cluster  , I iteratively determined the two closest chlsters by applying timinformation-theoretic measure relative cutropy : ~  ( Kulll ) ackmidLeibler , 1951) to comi ) are the distributions . 
The nearest clusters were merged into one cluster , and their distributions were merged 1 ) y calculating a weighted average . Based on test runs I defined lleuristics about how many elusl  , eriug iteral ; ions were pertbrmed . In addition , ilira-ire ( 1 the maximum mnuber of verbs within one ( : luster to four elements because otherwise the . 
verbs showed the tendency to cluster together in a few large clusters only  ; so after the overall clustering process was finished  , each cluster with more tlmn four members initialised a fllr-ther clustering pass on itself  . 
Unsupervised latent , classaualy s is as described in ( l ~ ooth ,  1998) , based on the cxp cetation -' maximisational . qorithm : The algorithm identified categori ( : altypes among indirect , ly observed multinomial distributions 1) 3 , apl ) lying the EM-algorithm (\]) elnp-ster et al . , 1977 ) to maximise the joint prol ) a-bility of ( h ) t ; he verb and frmnet yl ) e:p(v , t ) , and ( B ) the verl ) and frame type considering the selectional I ) referenees : p ( v , t , C ) . 
\] TUl ) Ut to the algorithm were absolute , frequencies of the verl ) sat ) l ) earing with the sul ) categori-sation frames . Test runs showed that 80 clusters modelled the semantic verl ) classes best . To 1) eable to comI ) a . rethe analysis wit ; h the iterative clustering al ) proach , I also limited tim numb(~r of verbs wit ; hina (: lus ; er1 ; of our considering that ; generally all verbs ai ) l ) ear within each (: lus-l ; er when using this apl ) roach , the verbs wil ; hl : he highest l ) rol ) abilities where chosen . 
D ) r version(h ) the frequencies were provide . d by the joint frequencies of verbs and framety I ) es , for version ( B ) I used the association va . lues of the verbs with tile frametyl ) eS considerings eleetional preferences , as described 1) y equation (10) . 
The unsupervised algorithm then classified joint events of verbs and sube a tegoris ~ tion frmncs with  200 iterations of the EM-algorithm into 80 clusters r , based on the iteratively estimated vahles v(v , 0=v , l , ) =
TT ( 12 ) a Concerning the two typical prol ) lems one has with this measure , ( i ) zero frequencies were smoothed 1) y adding 0 . 5 to all frequencies , and ( ii ) since the measure is not symmetric , the resl ) ective smaller vahm was used as distance . 



SFs + Pretls
Clusters Verbs
Total Correct Total Correct Recall Precision 31   20   90   55   36%   61%   30   14   81   31   20%   38% Figure 1: Evaluation based on Iterative Clustering hfformation Clusters ~ lbtal Correct 
SFs 8036
SFs ~1-Prefs 80 22

Total Precision 107 (159) 153 (226)
Correct Recall 58 (9O ) 38 (4O )% 47 (56) 31 (25) 0/o , 54 ( 57 ) % 31 ( 25 ) % Figure 2: Evaluation based on LatentClasses
I , ( , , , t , c ) = v , c ) = Cl)
TT (13) for versions ( h ) and ( B) , respectively . 
3 Evaluation
The evaluation of the resulting clusters was based on Levin's classification  . Figures 1 and 2 present he success of the two clustering algorithms  , considering timtwo difl'erent informational versions  ( /~ ) and ( B )  . 
They contain the total mnnber of clusters the algorithms had formed  ( clusters containing between two and four verbs in the iterative algorithm  , and the fixed immber of 80 clusters in the l&l ; ent (: lass rarely-sis ) , the prol ) or tion of correct clusters ( non-singleton clusters which were subsets of a Levin  ( : lass , for example the cluster conl ; aining the verl ) sneed , like ,   , want , desire is a subset of the Levin ( : lass Desire )   , and the numl ) er of verbs w M l in those clusters . In figure , 2 then ulnl ) er of verbs in brackets rethrs to the respective number of L heir senses  , since a verb could be clustered several times according to its senses  . 
For examl ) le , the verl ) want could t ) ememl ) er  of the ( : lasses Desire and Declaration . 
Recall was define ( l by the I ) ercentage of verbs ( verb senses ) within the correct clusters compared to the total munber of verbs  ( verb senses ) to be clustered :
I , , e,'bs . . . . . . . . .  , , . ,, . ,,  . . . . . I ?* C'C=153 ( Iv, . b .   .   .   .   .   .   .   .   .   .  ,  . . . . . . . . . . . l ) .   226 and precision was defined by the percentage of verbs  ( verb senses ) apl ) earing in the correct clusters compared to the numl  ) er of verbs ( verb senses ) apl ) earing in any cluster : \[ ve . rbs . .o, . .~, . , t  ~ . t , ~ t , ~, . ~\[ wee=Ive, . r , s , , , ~ , , . ,,~, . , I(iv-+ . . . . . . . . . . . . . . . . . . , . . . . . . . . . . . I ) Concerning t ) recision , the assign ntent of verbs into semantic lasses was most success fifl when using the il  ; erative distance clustering method ;   61% of all verbs were clustered into correct classes . Clustering the verbs into latent classes was with  54% less success-tiff . With both clustering methods the results became worse when adding information about the selectional preferences t br the arguments in the subcategorisation fl ' ames  . 
A baseline ext ) eriment was performed in order to determine how hard the task of verb clustering was : each verb was randomly assigned another verb as " closest neighbour "  , which resulted in only 5% el the , verl ) s being paired with a verb D on 1 the same Lev in ( : lass . Performing the same experiment by assigning the closest neighbour on the basis of moasm'ing the relative entropy between two verbs ' distributions over subcategorisation fl'ames resulted in  61% of the verbs pointing to a verb flom the same Levin class  . 
4 Discussion d
The classitications of both clustering approaches illustrate the close relationship between alternation behaviour and semantic classes  , l Y or exaln ple , the common preferences of verbs ( see the tlve most probable frames ) ill the iteratively crea . ted Desire ( : lass were towards a sul ) ject followed by an infinitival phrase ( subj:to )  . Alternatively al ; ransitive subj : objflame was used , partly followed by an additional infinitival phrase indicated by to : s  4For a more detailed discussion seetile original work  ( Schulte im Walde ,  1998) . 
Note that the ( wrongly chosen ) intransitive fl : ame is listed as well . This is Ill (' . t , ounderlying sentences containing an NP ellipsis , parsing mistakes and Dame extraction . 

Verl ) need desire
Framel ) rol ) ability subj : to 0 . 38 subj:ol)j(I . 32 subj 0 . 10 subj:obj:to 0 . 05 subj:obj:pp . for 0 . 02 sul ) j : to 0 . 34 subj:ol)j 0 . 34 subj 0 . 14 sul)j:obj:adv 0 . (14 sub . i:obj:obj0 . 03 subj:to 0 . 53 subj:obj 0 . 15 subj 0 . 11 sul ) j : ol ) j : to (1 . 10 subj:to:adv 0 . 02 subj:obj 0 . 25 subj 0 . 24 sul ) j : to 0 . 20 sul~j:obj:to 0 . (17 sul ) j : sent(I . 0 2 Adding ilf formation about the selectional prefer -enees of the verbs ' argmnents hell  ) stogel ; a deeper idea about their lexical semantics . D :) rexaln ple , mar ~ , ' n , er of Motion verbs 1 ) referably appeared with a subject only , sometimes with a following adverl ) . 
The subject was an inanimate ol ) ject , for move it might also be a part ( such as a body part like fin_ger ) or a grout )  , roll and fly alternatively used the transitive frmnetype subj:obj  , preferal ) ly with a living entity as subject , followed by an inanimate ob . iecl ; : rollfly
Fl'it llle sub . i ( l ' hysObject ) subj ( l ' hysObject ) : advsubj ( Agent ) : obj ( lq~ys Object ) subj ( IJ fel , ' or m ): ol ) j ( lqC , 's Object ) subj ( Agent ) : obj ( lhu't ) subj ( l ' hys OI ) ject ) subj ( l ' hys OI ) j cct ) : advsub . i ( Lifel , ' orm ): obj(l'hysObjcct ) subj(l , illa Form ): pp . to (1Afel " or n0subj ( Lifeleorm ): l)p . to ( Agent ) sul ) . i ( l ' hysObject ) subj ( l ) hysOl~ject ) : advsul ) j ( 1' re'i , ) sul~j ( Groul ) ):adv subj ( Part ) : advl ' rob~dfility 0 . 24 0  . 10 0  . 07 0  . 07 0  . 05 0  . 3 d 0 . 12 0 . (17 0  . 05 0 . 0,1 0  . 20 0 . 11 0  . 09 0 . 0,1 (1 . 0 , 1 Parallel examples created by the latent class analysis present he clusters with the most probable verbs and frmnes  , according to cluster members hiI )   ( first column )  . The dot indicates whether the verb-fi'mne combination was seen in the data  , the mmt bernext to the verb frame gives the probability of the verb-frmne combination  . 
Some verbs of Telling were clustered mainly according to their similar transitive use combined with an infi if itival phrase : ~?_ go '? g 
Clusi ; er do cboo =, , oo 9.
( . 17 advise ? ? ? ? 0 . 12 teltch ? ? ? ? 0 . 12 instruct ? ? ? ? The verl ) s of Aspect alternate between a subject only , realised by an action , an inanimate subject followed by an infinitiw fl phrase  , and a living subject followed by a gerund : g' , ~ gg
ClHstero doo ? b0 <; ~; 5 < 0 . 3, 1 start ? ? ? ? 0 . 19 finish ? ? ? 0 . 18 stop ? ? ? 0 . 1 6 begin ? ? Both approaches established a relationship between alternation behaviour and semantic lass by only considering information about the syntactic usage of the subcategorisation Dames  . The refinement by the frames's electional preferences allowed fllrther demarcations by the identifying  ( : on ceptual restrictions on tile use of the frames . 
Since timlatent class analysis is a soft ; clustering method , it additionally distinguishes between the dith ; rent verbs ' senses and the resl ) ective uses of subcategorisation Dames . For example , the verb play was clustered with meet 1 ) ecause of tile common strong tendency towards a transitive ti " ame illustrating agen  (  ; ralmeeting , and it , was clustered with figh , tt ) eemlse of their colnmon preference for an intransitive fi'ame together with a prepositional phrase headed  1  ) y against , illustrating a more aggres-six '(; me . eting like a fight :
Cluster 0.49 meet 0.2 0 l ) lay
Cluster
I ~ ggg55 oobO~L0 . 22 fight ? ? ? ? 0 . 2 0 play ???? An extensive investigation of tile linguistic reliability of the clustered verbs and frames showed that l  ; he character ( singusages could be under \] ( ned by corpus data , for example the above cited transitive use with a living subject and ml inanimate object can be illustrated by the BNC-sentence In March them an -ufacturer's test pilot flew the aircraft for its annual inspection checkflight  . The clusters were therefore created on a reliable linguistic basis representing  ( a selective part of ) the verbs ' properties . 
Comparing the two informational versions , however , showed that refining the fralnes with selectional preferences points to a problem caused by data sparseness in the verb description  . Investigating the automatically created distribution of the verbs over the enriched fl ' ame types revealed that  , for example , even the high fl'equent , alternating verb move contains 97% ( smoothed ) zeroes within its distribution . In accordance with this fiuding even subtle similarities  , e . g . the sole fact that two verbs have nonzerow flues for certain fl ' ame types  , highly correlates the two verbs . For example , a semantic lus-ter contained the two verbs promise and love  , because both have nonzero attribute values for the subj : to frame  , demmlding an agent for the subject slot ; in their alternation behaviour ( including selectional preferences ) the two verbs differ , however , so they should not be packed into one cluster . A possible suggestion to handle the problem of data sparseness could be to formulate the conceptual class types in a way which ensures an increase data potential for each type  . 
Concerning the polysemy of verbs , the ( hard ) iterative distance clustering failed to model verb senses  ; a polysemous verb was either not at all assigned to any cluster  , or assigned to a cluster describing one of the verb's senses  . The ( soft ) latent ( : lass analysis was able to filter the multiple senses and assign them to distinct  ( : lusters , but tended to split senses . 
Low-frequency verbs presented another problem , because the verbs ' distributions contained mostlyze-roes  . They were assigned to clusters nearly randomly . 
An investigation of selected WordNet conceptual classes revealed that the selectional preferences within the subcategorisation frames were donfinated by a few WordNet classes  , mainly Life Form and Agent . The demarcation between these two concepts was not obvious when referring to actually appearing nouns within the frames  , since both contain a large number of common subordinated nouns  . In contrast , some WordNet classes were not chosen at all , e . g . Unitor Anticipation . Since the WordNet hierarchy in general had turned out to define intuitively corrects eleetional preferences  , an improved classification utilised form y conceptual classification should be substituted by finer synsets  , i . e . one should consider using a different cut through the 
WordNet hierarchy.
5 Conclusion
I proposed two algorithms for automatically class i -f~  , ing verbs semantically , based on their alternation behaviour . Taking Levin's classification as a standard for 153 manually chosen verbs with 226 verb senses and their assignment into 30 semantic lasses , the iterative distance clustering succeeded for 61% of the verbs considering the syntactic usage of the fl ' ames only  , and for 38% when adding information about the frmnear guments ' electional preferences  . 
The latent class analysisucceeded for 54% and 31% , respectively . 
An investigation of the resulting clusters showed that the assignment of the verbs was actually based on their shared linguistic properties : the verbs in a cluster presented common alternation behaviour  , refined by adding selectional preferences to the syntactic description of the subcategorisation frmnes  . 
It is impressive that as little lexical idiosyncratic verb information as the syntactic use of subcategorisation fl'ames like subj:to or subj:pp  . against suffices as a basis for a semantic lass distinction towards Levin's narrow classification system including fine concepts as Desire or Manner of Motion  . The potential is partly characterised by specific frames  , but in the majority of cases by successflflly combining the frames in order to define the syntactic alternation  , hnproving the definition and demarcation of conceptual classe should provide further potential concerning the inclusion of selectional preferences into the syntactic description  . 

Richard Beckwith , Christiane Fellbaum , Derek Gross , and George A . Miller .  1991 . Wordnet : A Lexical Database Organized on Psycholinguistic Principles  . In Uri Zernik , editor , Lcxical Acquisition-Exploiting OnLine Resources to Bnilda Lczicon  , chapter 9 , pages 211232 . Lawrence Erl-bar on Associates , Hillsdale-New Jersey . 
Glenn Carroll and Mats Rooth .  1998 . Valence Induction with a Head-Lexicalized PCFG . In Proceedings of the 3rd Confcrcnccon Empirical Methods in Natu ~ nl Language Processing  , Granada , 

A . P . Dempster , N . M . Laird , and D . B . Rubin .  1977 . 
Maximum Likelihood from Incomplete Data via the EM algorithm  . Journal of the Royal Statistical
Society , 39(B):1-38.
Bonnie J . Dorr and Doug Jones .  1996 . Role of Word Sense Dismnbiguation i Lexical Acquisition : Predicting Semantics from Syntactic Cues  . In Proceedings of the 16th International Conference on Comp ' utational Linguistics  , Copenhagen . 
John Hughes .  1994 . Automatically Acquiring Classification of Words . Ph . D . thesis , University of
Leeds , School of Computer Studies.

Douglas A . Jones , Robert C . Berwick , Franklin Cho , Zeeshan Khan , Karen T . Kohl , Naoyuki No-mura , An and Radhakrislman , Ulri('h Sauerlan(1 , and Brian Ulicny .  1994 . Verb ( , ' lasses and Alternations illBangla , German , English , and Korean . Technical el ) or tMIT AIMEMO 1517 , Massachusetts Institute of Technology . 
Judith L . Kla . vans and Min-Yen Kan .  1998 . The Role of Verbs in D Oeulnent Analysis . In Pwceed-ings of thc 17th Intcrnational Co ~@ rcnccon Computational Linguistics  , Montreal , Canada . 
S . Kullback and R . A . Leibler .  1951 . On Infl ) rmation and Sufficiency . Annals of Mathematical Statistics , 22:79-86 . 
Maria Lapata .  1999 . Acquiring Lcxical Generaliza-tions from Corpora : A Case Study for Diathesis Alternations  . In Proceedings of the 37th Annual Mccting of the Association for Computational Linguistics  , pages 397404: . 
Beth Levin .  1993 . English Verb Classes and Alternations . The University of Chi (: ago Press,
Chicago , 1st edition.
Malka Rat)i ) al ) ort Hovav and Beth Levin . 1998.
Building Verb Meanings . In M . Butt and
W . Geuder , editors , Lcxical and Compositional Factors , pages 97-134 . CSLI Publications , Stanford , CA . 
Philip Resnik .  1993 . Selection and Information : A Class-Based AppT vach to Lexical Relations h  , i ps . 
Ph.D . thesis , University of Pennsylvania.
Philip Resnik .  1997 . Selectional Preference and Sense Disambiguation . I Proceedings of the ACL SIGLEX Workshop on ~ hflg in fl ~:: ct with  , Lcxical
Semantics : Wh , y , Wh , at , and llow ? l~5"ancescRibas .  1994 . An Experiment on Learning Appropriate Selection M Restrictions fi'om a Parsed Corpus  . In Procecdings of the 15th International Conference on Computational Linguistics  , pages 769774 . 
Francesc Ribas .  1995 . On Learning Mot'e Appropriate Selcctional Restrictions  . In Pwcccdings of the 7th Conference of the Eurot ) e an Chaptcr of the Association for Computational Linguistics  , Dublin , 

Mats Rooth .  1998 . Two-Dimensional Clusters in Grammatical Relations  . In Inducing Lexicons with th , cEM Algorithm , AIMS Report 4(3) . Institutffir Maschinelle Si ) raehver arl ) eitung , Univer-sitgt Stuttgart . 
Sabine Schulte im Walde .  1998 . Automatic Se-nmntic Classification of Verbs According to Their Alternation Behaviour  . Master's thesis , Institutffir Maschinelle Sprachverarbeitung , Universit St

Suzamm Stevenson and Paola Merlo .  1999 . Auto-Inatic Verb Classification Using Distributions of Grammatical Features  . hiP ~ vcccdings of the 9th Conference of thcEuropean Chaptcr of the Association for Computational Linguistics  , pages 4552 . 

