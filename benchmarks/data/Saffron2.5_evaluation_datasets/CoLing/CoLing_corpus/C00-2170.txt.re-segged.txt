Jurilinguistic Engineering in Cantonese Chinese :
An N-gram-based Speech to Text Transcription System 
BKT ' sou , KKS in , SWK Chan , TBY Lai , C Lun , KTKo , GKK Chan , LYL Cheung
Language hfformation Sciences Research Centre
City University of Itong Kong
Tat Chee Avenue , Kowloon
Hong Kong SAR , China
Email : rlbtsou@nxmail.cityu.edu.hk

A Cantonese Chinese transcription system to automatically converts tenograph code to Chinese characters ix reported  . The major challenge in developing such a system is the critical homocode problem because of homonymy  . The statistical Ngram model is used to compute the best combination of characters  . Supplemented with a 0 . 8 5 million character corpus of d on min-specific training data and enhancement measures  , the bigram and trigrmn implementations achieve 95% and 96% accuracy respectively , as compared with 78% accuracy in the baseline model . The system perforlnance is comparable with other adwmced Chinese Speech-to-Text input applications under development  . The system meets an urgent needo1' the . ludiciary ot : post-1997 Hong Kong . 
Keyword : Speech to Text , Statistical
Modelling , Cantonese , Chinese , Language
Engineering 1. Introduction
British rule in Hong Konglnade English the only official language in the legal domain for over a Century  . After the reversion of Hong Kongs overeignty to China in  1997  , legal bilingualism has brought on an urgent need to create a Computer-Aided Transcription  ( CAT ) system for Cantonese Chinese to produce and maintain the massive legally tenable records of court proceedings conducted in the local majority language  ( T ' sou ,  1993 , Sin and T'sou ,  1994 , Lun et al ,  1995) . With the support fl ' om the Hong
Kong Judiciary , we have developed a transcription system for converting stenograph code to Chinese characters  . 
CAT has been widely used for English for many years and awlilable R~r Mandarin Chinese  , but none has existed for Cantonese . Althongh Cantonese is a Chinese dialect , Cantonese and Mandarin differ considerably in terms of phonological struclure  , phouotactics , word morphology , vocabulary and orthogral ) hy . Mutual intelligibility between the two dialects is generally very low  . For example , while Cantonese has lnole than 700 distinct syllables , Mandarin has only about 400 . Cantonese has 6 tone contours and Mandarin only 4 . As for vocabulary , 16 . 5% of the words in a 1 million character corpus of court proceedings in Canlonese cannot be found in a corlms consisting of  30 million character newspaper texts in Modern Written Chinese  ( T ' sou el al ,  1997) . For orthography , Mainhmd China uses the Simplified Chinese character set  , and Hong Kong uses the Traditional set l~lus4 , 702 special local Cantonese Chinese characters ( Hong Kong Government ,  1999) . Such differences between Cantonese and Mandarin necessitate the Jtnilinguistic Engineering undertaking to develop an independent Cantonese CAT system for the local language n vironment  . 
The major challenge in developing a
Cantonese CAT system lies in the conversion of phonologically-based stenograph code into Chinese text  . Chinese is a logographic language . 
Each character or logograph represents a syllable.
While the total inventory of Cantonese syllable types is about  720  , the mamatle ast 14 , 000 Chinese character types . The limited syllabary creates many homophones in the language  ( T ' sou ,  1976) . In a one million character corlms of court proceedings  , 565 distinct syllable types were found , representing 2 , 922 distinct character types . 
Of the 565 syllable types , 470 have 2 or morn homophonous characters . In the extreme case , zi represents 35 homophonous character types . 

Coverage of llomophonous and Non-homophous Characters  100  . 00% ?' oo ~4: ~~ ~ os 4: e 80 . 00% # 40 . 00% c ~20 . 00% 0 . 00% ? No . of High Freq . Characters % ~ t ~ p\[EJ Ho In ophonous Charact crs \[\] Non-hona ophonous chaliact crs \] Figure I  . Covcragcof Homonymous Characters These 470 syllables represent 2  , 8 10 homophonous character types which account for 94  . 7% of the text , as shown in Figure \] . The homocode problem nmst be properly resolved to ensure successful conversion  . 
2 . Computer-Aided Transcription ( CAT ) ~ dJlt ? I co2 F2L . 
Stcnoma ~ hcode Ii
Slzg?2E
I Transcription \ [/ ! EIt ? ill C ; h Trigranl , , Big , an , i ~'9 = , E )!
Proofreading\[i'I'Bigram/Trip , rami Statistical Dala
Chinese Textill : ~!
Figure 2 . Automatic Transcription Process Figure 2 outlines the transcription process in the Cantonese CAT system  . Following typical courtroom CAT systems , our process is divided into three major stages . In Stage 1 , simultaneous to a litigant speaking , astenographer inputs speech , i . e . a sequence of transcribed syllables or stenograph codes  , via astenograph code generator . 
Each stenograph code basically stands for a syllable  . In Stage 2 , the transcription software converts the sequence of stenograph codes \[ Sl  .   .   .   .   . 
s ,, into the original character text q .   .   .   .   . c , , . 
This procedure requires the conversion component to be tightly bound to the phonology and orthography of a specific language  . To specifically address homonymy in Cantonese , the conversion procedure in our system is supported by bigram and trigram statistical data derived from domain-specific training  . In Stage 3 , manual editing of the transcribed texts corrects errors from typing mistakes or his-transcription  . 
3 . System Architecture 3 . 1 Statistical Formulation To resolve massive ambiguity in speech to text conversion  , the Ngram model is used to determine the most probable character sequence q  .   .   .   .   . ck given the inputs tenograph code sequences ~   .   .   .   .   . Sk . The conditional probability ( 1 ) is to be maximized . 
(1) P ( q .   .   .   .   . c ~ lsl .   .   .   .   . sk ) where q .   .   .   .   . c ~ stands for a sequence of N characters , and sl .   .   .   .   . sk for a sequence of k input stenograph codes . 
The cooccurrence frequencies necessary for computation are acquired through training  . 
However , a huge amount of data is needed to generate reliable statistical estimates for  ( 1 ) if N > 3 . Consequently , Ngram probability is approximated by bigram or trigram estimates  . 
First , rewrite(1) as (2) using Bayes ' rule.
P ( c, . . . . . c)xP ( s , . . . . . slc , . . . . . c , ) (2)
P ( s , ... . . sk)
As the value of P ( sI .   .   .   .   . st ) remains unchanged for any choice of q .   .   .   .   . ct , one needs only to maximize the numerator in (2) , i . e .  (3) . 
(3) P ( cl . . . . . Ck ) XP ( sl . . . . . s,\[cl . . . . . ck )   ( 3 ) can then be approximated by ( 4 ) or ( 5 ) using bigram and trigram models respectively . 
(4) FL =, . . . ., ( P(c,lq_,) x P(s, . Iq ) )  ( 5 ) ? P ( silci ) ) The transcription program is to compute the best sequence of q  .   .   .   .   . c , so as to maximize (4) or (5) . The advantage of the approximations in ( 4 ) and ( 5 ) is that P ( s , lc , ) , P ( c , lc ,  . ,) and P(c , lc , _2c , _ , ) can be readily estimated using a training corpus of manageable size  . 
3.2 Viterbi Algorithm
The Viterbi algorithm ( Viterbi ,  1967 ) is implemented to efficiently compute the max in mm value of  ( 4 ) and ( 5 ) for different choices of computing tile values for all possible character sequences  , the algorithm only keeps track of the probability of the best character sequence terminating in each possible character candidate for a stenograph code  . 
In the trigram implelnent at iou , size limitation in the training cortms makes it impossible to estimate all possible P  ( cilci_2ci . i ) because some ci_2 , ci_l , q may never occur there . Following Jelinek (1990), P(cilci . 2ci_i ) is approximated by the summation of weighted lrigram  , bigram and unigram estimates in (6) . 
(6 ) p ( ciIci_2ci_1 ) f ( ci_2ci-Ici ) f ( ci_1ci ) f ( ci ) = w3X+w2X+w1X-f ( ci_2ci_1 ) f ( ci_I ) Zf ( cj ) where ( i ) w , , w2 , w-s_>0 are weights , ( ii ) wl-l-w2--H ; 3=1 , and ( iii ) Zf ( q ) is the stun of frequencies of all characters . Typically lhebest results can be obtained if w :~  , the weight for trigram , is significantly greater than the olher two weights so that the trigram probability has dominant effect in the probability expression  . In our tests , we so tw l = 0 . 01, w2 = 0 . 09, audu ; 3= 0 . 9 . 
The Viterbi algorithm substantially reduces the computational complexity flom O  ( m " ) to O ( m . - ~ n ) and O ( nr~n ) using bigram and trigram estimation rc:spectively where n is the number of stenograph code tokens in a sentence  , and mistile upper bound of the number of homophonous characters for astenograph code  . 
To maximize the transcription accuracy , we also refine the training corpus to ensure that the bigram and trigram statistical models reflect the comtroom lauguage closely  . This is done by enlarging tile size of tile training corpus and by compiling domain-specific text corpora  . 
3., 3 Special Encoding
After some initial trial tests , error analysis was conducted to investigate the causes of the mis-transcribed characters  . It showed that a noticeable amount of errors were due to high failure rate in them triewtl of seine characters in the transcription  . The main reason is that high fiequency characters are more likely to interfere with the correct retrieval of other relatively lower frequency homophouous characters  . For example , Cantonese , hal ( ' to be ' ) and hal ( ' at ' ) are homophouous in terms of seglnent almake up . 
Their absolute fiequcucies in our training corpus are  8  , 695 and 1 , 614 respectively . Because of the large fi'equency discrepancy , the latter was mis-transcribed a stile former 44% of the times in a trial test .   32 such high fi'equency characters were found to contribute to about  25% of all transcription errors . To minimize the interference , special encoding , which resulted flom shallow linguistic processing  , is applied to the 32 character so that each of them is assigned a uniques tenograph code  . This was readily accepted by the court stenographers  . 
4 . hnplementation and Results 4 . 1 Compilation of Corpora In our expreriments , authentic Chinese court proceedings from the Hong Kong Judiciary were used foxtile compilation of the training and testing corpora for the CAT prototypes  . To ensure that tile training data is comparable with tile data to be transcribed  , the training corpus should be large enough to obtain reliable estimates for P  ( silc ,  . ), P ( cilcij ) and P ( cilci_2ci_l) . in our trials , we quickly approached the point of diminishing return when the size of the training corpus reaches about  0  . 85 million characters . ( See Section 4 . 2 . 2 . ) To further enhance training , the system also exploited stylistic and lexical variations across different legal domains  , e . g . tra\[ . ' fic , assauh , and fraud offences . Since different case types show distinct domain -specific legal vocabulary or usage  , simply integrating all texts in a single training corpus may obscure the characteristics  o1' specific language domains , thus degrading the modelling . 
Hence domain-specific training corpora were also compiled to enhance performance  . 
Two sets of data were created for testing and comparison : Generic Coqms  ( GC ) and Domain- , specific Cmpus ( DC ) . Whereas GC consists of texts representing various legal case types  , DC is restricted to traffic offence cases . Each set consists of a training corpus of 0 . 85 million characters and a testing corpus of 0 . 2 million characters . The training corpus consists of Chinese characters along with the corresponding stenograph codes  , and tile testing corpus consists solely of stenograph codes of the Chinese texts  . 
4.2 Experimental Results
For ew fluation , several prototypes were set up to accuracy . They included ( i ) use of bigram vs . 
trigram models , ( ii ) the size of the training corpora , ( iii ) domain-specific training , and ( iv ) special encoding . To measure conversion accuracy , the output text was compared with the original Chinese text in each test on a character by character basis  , and the percentage of correctly transcribed characters was computed  . Five sets of experiments are reported below . 
4.2.1 Bigram vs . Trigram
Three prototypes were developed : the Bigram Prototype  , CAT va2 , the Trigram Prototype , CAT va . ~, and the Baseline Prototype , CA To . CAT va2 and CATvA . ~ implelnent he conversion engines using the bigram and trigram Viterbi algorithm respectively  . CA 7 o , was setup to serve as an experimental control . Instead of implementing the Ngram model , conversion is accomplished by selecting the highest fiequency item out of the homophonous character set for each stenograph code  . GC was used throughout the three experiments . The training and testing datasets are 0 . 85 and 0 . 20 million characters respectively . The results are summarized in Table 1 . 
Corpus GC GCG C
Accuracy 78.0% 92.4% 93.6%
Table 1. Different Ngram Models
The application of the bigram and trigram models offers about  14% and 15% improvement in accuracy over Control Prototype , CATo . 
4.2.2 Size of Training Corpora
In this set of tests , the size of the training corpora was varied to determine the impact of the training corpus size on accuracy  . The sizes tested are 0 . 20, 0 . 35, 0 . 50, 0 . 63, 0 . 73 and 0 . 85 million characters . 
Each corpus is a proper subset of the immediately larger corpus so as to ensure the comparability of he train in texts  . CAT vA2 was used in the tests . 
Training Corpus GCG CGC
Accurac ~ 89.5% 91.2% 91.8%
Training Corpus GCG CGC
Accuracy 92.1% 92.3% 92.4%
Table 2. Variable Training Data Size
The results in Table 2 show that increasing the size of the training corpus enhances the accuracy incrementally  . However , the point of diminishing return is reached when the size reaches  0  . 85 million characters . We also tried doubling the corpus size to 1 . 50 million characters . It only yields 0 . 8% gain over the 0 . 85 million character corpus . 
4.2.3 Use of Domain-specific Training
This set of tests evaluates the effectiveness of domain-specific training  . Datafi ' oln the two corpora , GC and DC , are utilized in the training of the bigram and trigram prototypes  . The size of each training set is 0 . 85 million characters . The same set of 0 . 2 million character testing data from DC is used in all four conversion tests  . Without increasing the size of the training data , setups with domain-specific training consistently ield about  2% improvement . A more comprehensive set of corpora including Tra . lfic , Assault , and Robbeo ~ is be in ) iled and will be re ) or tcd in future . 

Training Data
CAT vA ; CAT vA3 CAT vaz CA TvA 3
GCG CD CDC
Testing Data DCD CD CDC
Accuracy 92.6% 92.8% 94.7% 94.8%
Table 3 . Application of Domain-Specificity 4 . 2 . 4 Special Encoding Following shallow linguistic processing  , special encoding assigns unique codes to 32 characters to reduce confusion with other characters  . Another round of tests was repeated , identical to the CATvA2 and CATvA 3 tests in Section 4  . 2 . 1, except for the use of special encoding . The use of training and testing corpora have 0 . 85 and 0 . 20 million characters respective
S ~ i ~ I ; : ~ : : : NO fA ~ I ~ I i ~ :
Prototypes CAT w ~ CA TvA ~ CAT w2 CA TvA 3
Corpus GC GCG CGC
Accuracy 92.4% 93.6% 94.7% 95.6%
Table 4 . Application of Special Encoding Table 4 shows that the addition of special encoding consistently offers about  2% increase in accuracy . Special encoding and hence shallow linguistic processing provide the most significant improvement in accuracy  . 
4.2.5 Incorporation of Domain-Specificity and
Special Eneoding
As discussed above , both domain-specific training and special encoding raise the accuracy of transcription  . The last set of tests deals with the integration of the two features  . Special encoding which have 0 . 85 and 0 . 20 million characters respectively . 
~raining/Testing , Data DCDC
IS . Encoding Applied Applied/zcuracy 95 . 4 % 96 . 2% Table 5 . Integration of D . Specificity and S . Encoding Recall that Domain-Specificity and Special Encoding each offers  2% improvelnent . Table 5 shows that combining BOTH features offer about 3% improvement over tests without them . ( See non-domain-specific tests in Section 4 . 2 . 3) The 96 . 2% accuracy achieved by CATvA 3 represents the best performance of our system . 
The result is cona parable with other relevant advanced systems for speech to text conversion  . 
For example , Lee ( 1999 ) reported 94% accuracy in a Chinese speech to text transcription system under develop lnent with very large training corpus  . 
5. Conclusion
We have created a Cantonese Chinese CAT system which uses the phonologically-based stenograph machine  . The system delivers encouragingly accurate transcription in a language which has many hon\ ] ol ~ honous characters  . To resolve problematic ambiguity in the conversion fi'on-iaI  ) honologically-based code to the logograt ) hic Chinese characters , we made use of lheNgram statistical model . The Viterbi algorithm has enabled us to identify the most probable sequence of characters from the sels of possible homophonous characters  . With the additional use of special encoding and domain-specific training  , the Cantonese CAT system has attained 96% transcription accuracy . The success of the Jurilinguistic Engineering project can further enhance the efforts by the Hong Kong Judiciary to conduct trials in the language of the majority population  . Further improvement to the system will include ( i ) more domain-specific training and testing across different case types  ,   ( 2 ) firm-tuning for the optimal weights in the trigram formula  , and ( 3 ) optilnizing the balance between training corpus size and shallow linguistic processing  . 

Support for the research reported here is provided mainly through the Research Grants Council of 
Hong Kong under Competitive Earmarked
Research Grant ( CERG ) No . 9040326.

Hong Kong Govennnent . 1999. Hong Kong
Szq ~ plemenmry Character Set . hfformation Technology Services Department & Official 
Languages Agency.
Jelinek , F .  1990 . " Self-organized Language Modeling lbr Speech Recognition  . " In A . Waibel and K . F . 
Lee , ( eds . ) . Readings in Speech Recognition . San Mateo:CA : Morgan Kaufmann Publishers . 
Lee , K . F .  1999 . " Towards a Multimedia , Multimodal , Multilingual Computer . " Paper presented on behall ' of Microsoft Research Institute  , China in the 5th Natural Language Processing Pacil ' icRim Symposium held in Belling  , China , November 57 ,  1999 . 
Lun , S . , K . K . Sin , B . K . T ' sou and T . A . Cheng .  1997 . 
" l ) iannao Fuzhu Yueyu Suii Fangan . "  ( The Cantonese Shorth and System for Computer-Aided Transcription  )   ( in Chinese ) Proceedings o . f the 5th lntermt tional Confere , ce on Cantonese and Other Yue Dialects . B . H . Zhan ( ed) . Guangzhou : Jinan
University Press . pp . 217--227.
Sin , K . K . and B . K . T ' sou .  1994 . " Hong Kong Courtroon \] Language : Some Issues on Linguistics and Language Technology  . " Paper presented at lhe Third International Conference on Chinese 
Linguistics . Hong Kong.
T'sou , B . K .  1976 . " Homophony and Internal Change in Chinese . " Computational Analyses of Asian and
African Lauguages 3, 67--86.
T ' sou , t3 . K .  1993 . " Some Issues on Law and Language in the ltong Kong Special Administrative Region  ( HKSAR ) of China . " Language , Lawattd Equality : Proceedings of the 3rd International Conference of the International Acaden G of Language Law  ( IALL )  . 
K . Prinsloo et al Pretoria ( cds . ): University of South
Africa . pp . 314-331.
T'sou , B . K . , H . L . Lin , G . Liu , T . Chan , J . Hu , C . H . 
Chew , and J . K . P . Tse .  1997 . " A Synchronous Chinese Language Corpus fi'om Different Speech Communities : Construction and Applications  . " Computational Linguistics and Chinese Language
Ptwcessing 2: 91--104.
Viterbi , A . J .  1967 . " Error Bounds for Convolution Codes and an Asymptotically Optimall  ) ecoding Algorithm . " IEEE 7' rans actions on htformation
The oG13:260--269.

