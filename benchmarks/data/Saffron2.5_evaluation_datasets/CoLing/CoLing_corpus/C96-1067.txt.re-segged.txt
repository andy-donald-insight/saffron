Word Completion : A First Step Toward
Target-Text Mediated IMT
George Foster , Pierre Isabelle , and Pierre Plamondon
Centre for hfformation Technology Innovation ( CITI ) 
1575 Chomedey Blvd.
Laval , Quebec , Canada , H7 V2 X2
foster , is a belle , plamond on@citi , doc.ca

We argue that the conventional pproach to Interactive Machine ~ Ih-anslation is not the best way to provide assistance to skilled translators  , and propose an alternative whose central feature is the use of the target text as a medium of interaction  . We describe an automatic word-completion system intended to serve as a vehicle for exploring the feasibility of this new approach  , and give results in terms of keystroke saved in a test corpus  . 
1 Introduction
Machine translation is usually significantly inferior to human translation  , and for most applications where high-quality results are needed it must be used in conjunction with a human translator  . There are essentially three ways of organizing the process by which a person and a machine cooperate to produce a translation : prccdition  , in which the person's contribution takes the form of a source-text analysis and occurs before the MT system is brought to bear  ; postedition , in which the translator simply edits the system's output  ; and interactive MT ( IMT ) , which involves a dialog between person and machine  . Of the three , IMT is the most ambitious and theoretically the most power flfl  . It has a potential advantage over postedition in that information imparted to the system may help it to avoid cascading errors that would later require much greater effort to correct  ; and it has a potential advantage over preedition in that knowledge of the machine's current state may be useful in reducing the number of analyses the human is required to provide  . 
Existing approaches to IMT ( Blanch on , 1994; Boitet , 1990; Brown and Nirenburg , 1990; Kay , 1973; Maruyam and Watanabe , 1990; Whitelock et al , 1986; Zajac ,  1988 ) place the MT system in control of the translation process and for the most part limit the human's role to performing various source language disambiguations on de-man & Although this arrangement is appropriate for some applications  , notably those in which the user's knowledge of tile target language may be limited  , or where there are multiple target , languages , it is not well suited to tile needs of professional oi ' other highly skilled translators  . The lack of direct human control over the tinal target text  ( modulo postedition ) is a serious drawback in this case , and it is not clear that , for a competent translator , disambiguat , ing a source text , is much easier than translating it . This conclusion is supported by the fact that true IMT is not  , to our knowledge , used in most modern transla-tor's support environments  , eg ( Eurolang , 1995; I , ' rederking et al , 1993; IBM , 1995; Kugler et al , 1991; Nirenburg , 1992; ~ li'a dos ,  1995) . Such environments , when they incorporate MT at all , tend to do so whole sale , giving the user control over whether and when an MT component is invoked  , as well as extensive postediting facilities for modifying its outtmt  , but not the ability to intervene while it is operating  . 
In our view , this state of affairs should not be taken as evidence that IMT for skilled translators is an inherently bad idea  . We feel that there is an alternate approach which has the potential to avoid most of the problems with conventional IMT in this context  , : use the target ext as a medium of communication , and have the translator and MT system interact by making changes and extensions to it  , with the translator's contributions serving as progressively informative constraints for thesys -te  , n . This arrangement has the advantage of leaving the translator in full control of the translation process  , of diverting his or her attention very little from the object of its natural focus  , and of necessitating a minimum of interface paraphernalia beyond those of a word processor  . It can in principle accomodate a wide range of MT proficien-be called ut  ) onto propose entire translations and In oditly them in response to changes In a de by the translator  ; to very low , in which its chief contri-l ) ution will be the reduction of typing labour . 
The aim of this paper ix to explore the feasibility of this target-tezt mediated style of IMT in one part i  ( : ularly simph ; form : a word-(: on q ) h' , tion system which ai ; temltts to fill in the sut lixes of target-text words from manually typed prefixes  . tWe describe a prototype completion system for English to l ~? ench translation which is based on simple statistical MT techniques  , att ( t give mea-Stl Fenlents el : its performance ill terms of  (  ; larac-ters saved in a test cortms . The system has not yet been integrated with a word processor  , s t ) we ( ; annot qltantify the an lollnt of a ( : tual time and (  ; fl ' or tit woul(ts ave a translator , t ) nt it seems reasonable to expect this to lie faMy well correlated with total characters avings  . 
2 Word Completion
Our scenm ' io for wor ( 1 completion SU l ) t ) oses that a translator works on some designated segment of the source text  ( of att proxinm tely sentence size )  , and elaborates its ( ; ranslation from left to right . 
As each target-text characteristylted , at ) rot ) osed (: omttletion for t it ( ; currenl ; word is ( tist tlayed ; if this is (' , or reet , the translator n taya (' , ceptitatt ( ll ) cg in typing the next word . Although in ore elaborate comi ) lel ; ion schemes are imaginable , in (: lud-ing ones that involve the use , of alternate hyI ) othe-so sor 1 ) revisions form or l ) hologieal repair , we have ot ) ted against these for the time t ) eing because they necess it a test ) eeial commands whose benetit in terms of characters saved would t  ) ediilic ult to estimate . 
The hear to fore " system is a comlt letion engine for English to t ~' ench translation which finds the best completion for a \[  , ? e neh word prefix given the current English source text segment ut nler translation  , attd the words which precede the prefix in the corresponding l~?e neh target text segment  . 
It comprises two main components : an cvalua-to t which assign scores to completion hypotheses  , and a generator which produces a list of hyp ( t the-sos that match the current prefix and picks the one with the highest score  . 
1 This idea is similm to existing work on tyl ) in gae ( : elerators for the disabled ( Demasco and McCoy ,  1992) , but our methods differ signitieantly in many aspects  , chief among which is the use of bilingual context . 
3 Hypothesis Evaluation
Each score produced by the evaluator is an es -tilnate of p  ( tl , s t , the probability of a target . -language wordt given a preceding target text t , antia source texts . For etticiency , this distribution is modeled as a silnple linear combination of SO l  ) re ' a tetn'edie tions fl'om tit (  ; target text and the sottree text : p(tlE , s ) = Ap(tl ) + (1-A)p(tls ) . 
The vahte of /~ was chosen so as to maximize e , ot npletion lter for In a nee over a test text ; ( sees (! c-tion 5) . 
3.1 Target-Text Based Prediction
The target-text based prediction p ( tlt ) comest?om an interpolated trigranl language model for l %: ench  , of the type commonly used in speech recognition ( Jelinek ,  11!190) . It ; was trained on 47M words fiom the Canadian Hansard Corpus , with 750/oused to make relative-fl'equency I ) arameterest intates and 25% used to reestimate interpolation coefticients . 
3.2 Source-Text Based Prediction
The source text prediction p ( t\[s ) comes fl'om a statistical model of English-to-l , ? ench translation which is based on the IBM translation models  1 and 2   ( Brownel ; al . , 1993) . Model 1 is a Hid . -den Markov Model ( HMM ) of the target language whose states correspond to source text tokens  ( see figure l )  , with the addition of one special null state to account for target ext words that have no strong direct correlation to any word in the source text  . The output distribution of any state tie the set of probabilities with which it generates target words  ) deitends only on the correspond it ~ g source text word  , and all next-state transition distributions are uniform  . Model 2 is similar to model 1 except that states are attgmented with a target -tokent  ) osition cotn ponent , attd transition probabilities depend on both source and target token positions  ,   '2with the topographical constraint that a state's target-token t  ) ositioll component must always match the current actual position  . Because of the restricted form of the state transition UA long with source and target text lengths in l/town et als for nmlation  , lint these are constant for arty particular HMM . The results 1 ) resented in this pa-lter are optimistic in that the target text lengl  ; h was assumed to be known in advance , which of course is unrealistic . I Iowever , ( Dagan et al ,  1993 ) have shown that knowledge of target-text length is not crucial to the model'si  ) ertbrmanee . 

J ' aid ' autresc x cmplcs d ' autres pays 3 c  ~ 1   :4   5 counlrics 8   8 Figure 1: A plausible state sequence by which the HMM corresponding to the English sentence I have other cxamples from many other countries might generate the French sentence shown  . The state-transition probabilities ( horizontal arrows ) are all 1/9 for model 1 , and depend on the next state for model 2 , egp((froms , 6I ') = a(516) . 
The output probabilities ( vertical arrows ) depend on the words involved , egp(d ' I from ~ , 6) = p(d'I from ) . 
matrices for these models , they have the property that-unlike HMM's in general they generate target-language words independently  . The probability of generating hypothesis tat position i is just : 
Islp(tls , i ) = EP ( t l s i ) a ( jli ) j = 0 where sj is the jth source text token ( so is a null token )  , p ( t l s j ) is a word-for-word translation probability , and a ( jli ) is a position alignment probability ( equal to 1/ ( M + 1 ) for i node l1 )  . 
We introduced a simple enhancement to the IBM models designed to extend their coverage  , and make them more compact . It is based on the observation that there are ( at least ) three classes of English forms which most often translate into Fk'ench either verbatim or via a predictable transformation : proper nouns  , numbers , and special at phanuineric codes such as C-~5 . We found that we could reliably detect such " invariant " forms in an English source text using a statistical tagger to identify proper nouns  , and regular expressions to matchimmbers and codes  , along with a filter for frequent names like United States that do not translate verb at im into French and Immberslike  10 that tend to get translated into a fairly wide variety of forms  . 
When the translation models were trained , invarian tokens in each source text segment were replaced by special tags specific to each class  ( different invariants occuring in the same segment were assigned serial numbers to distinguish them  )  ; any instances of these tokens found in the corresponding target text segment were also replace  ( \] by the appropriate tag . This strategy reduced then mn-ber of parameters in the i node ls by about  15%  . 
Whenew fluating hypotheses , as iu filar replacement operation is carried out and the translation probabilities of paired invariants are obtained from those of the tags to which they map  . 
Parameters for the translation models were reestimated fl ' om the Hansard corpus  , automatically aligned to the sentence level using the method described in  ( Simard et al ,  1992) , with no none-to-one aliglmmnts arid sentences longer than  50 words filtered out ; the ret ~ fine ( l material consisted of 36M English words and 37M Fren ( : h words . 
4 Hypothesis Generation
The main challenge in generating hypotheses i1 ; obalance the opposing requirements of completion accuracy and speed the former tends to increase  , and tile latter to decrease with tilen mn be r of hypotheses considered  . We took a number of steps in art effort to achieve a good compromise  . 
4 . 1 Act ive and Pass ive Vocabu lar ies A well -established corollary to Zipf's law holds that a minority of words account for a majority of tokens in text  . To capitalize on this , our sys-tem's French vocabulary is divided into two parts : a small active component whose contents are always used for generation  , and a much larger passive part which comes into play only when the active vocabulary contains no extensions to the  ( : urrent ) refix . 
Space requirements for the passive vocabulary were minimized by storing it as a special trie in which conlnlon Srl\[~cix patterns are represented only once  , and variable-length coding techniques are used for structural information  . This allows us to maintain a large dictionary containing over  380  , 000 forms entirely in memory , using about 475k bytes . 
The active vocabulary is also represented as a trie  . For efficiency , explicit lists of hypotheses at '( ; not generated ; instead , evaluation is performed during are eursive search over the portion of the trie below the current coinpletion prefix  . Repeat searches when the prefix is extended by one character areol  ) viatedininost situations by memo \] z-ing the results of tile original search with a best-child pointer in each trie node  ( see figure 2 )  . 
4.2 Dynamic Vocabulary
To set the contents of the active vocabulary , we borrowed the idea of a dynamic vocabulary from  ( Brousseau et al ,  1995) . This involves using Figure 2: Menioized port ; io noft ; \] l ( ; a(:i , ive vocal ) u-lary trie for i ; hel~i'en ( ; h preiix parh J v hea , vyliues show 1) esl;-child links and sha , ded nodes rcpr (' , scnt vidid word ends . The , currelii : best ; (: and idal mispa'dc'co ' ~ Z ; if a na is ap1) cndedl)yi , h ( ; t : rans lal ; or ~ ; he new 1) esl ; can-didal ; ( ; po , rlc ' rait(:~ui1)er (' , t;ri(;vedfrolni , het ) esl ; -( ; liild links wii ; houi ; having 1 ; oi'e-evahlai ; call 61) ossil ) le hy-l ) oi ; heses . 
l ; rmislai ; ionrood ( ; 11 Ix ) ( ; olnl ) ul ; ( ;   ; ~\] isl , of tim'n , n losl:prob~fl ) leI ; arg ( , t : l ; (; xl ; words ( in (' hl(lingt , rm is la . lJoninvm ' ianl ; s) , given th (; curr ( ; nl ; sour (' , (;l ; (; xt ; s(;gli Cieilt . 
As figur (; 3 illusl ; r; . rlx ; s , (: ompar('(lto ; l~lt~c\[l : (; ril~d , ( ~ reel:hod of sl ;; tl;i (:; dly (' . hoosing t , henm ( ) st ; frequenl : torn is in l ; heti ; IJning (: or lms , use of a , ( lyna , micvo--(' , abul ~ ry(h'amal;i(:a , llyr(;(lu(:(;sl;h(;av(!rage , a(:l , iv('~vo (' , ~l ) ulm ' ysizer (' , ( tuir ( ; (1t;oiu ' , hi(w ( ! a , given lev c , lofi ; a , rgel:ix~xi:covcra , g ( ; . Mol : ival x xl by t:he Im:i , th ; ~ tr ( ; ( ; (! nl ; words l ; en(l1 ; ore curinl : cxt ;  , wc~d so a , d(led all t ) reviously ( ; ncounl ; eredl ; m'g( ; l ; -t ; ( ; xl ; t , ol(ens1; oi ; hodynami (' , vo (: ttl ) ul < % y . 
4.3 Case Handling
Thel ; re . ~l ; nlcnl : of \](; l ; lx ; rca . s( ; L ' - ;   ; ~1Mckyl ) r()/)i ( ! ni for hyi ) oi ; l/( ; s is general ; ion midonetlta . l ; c i l ~ l l l l ( ) l ;  )( ; ig ; llor ( ; (\]\ 11killinl ; (~ra . (' . l;iv (; al)l ) li(:id ; ion . I Vlt ) st ; words canal ) pc , arin ; Llllllli ) (! l'()\['( liffer ( ; nl ;  (' . ; / os(!-v ; r li ; l , Iil , \[' orllt , ~ gbll(l\[;h(~l'(!~%1'c , llOsit\[It ) l(' , ; ) d l (1; d ) solul , ( ~ l/l\[(' , ,q l;lii~t spec , i \ [ i7 which iSal ) t ) rot ) ria , l;ci/lat ); u'l ; ic , ula , r(:onlx ' . xl ; . To(x ) pew ii , hI ; his , sil:ll ; d;i ( ) n~w (; axh)l)ix ; da . \]i (; urisl;i(:sl , ra , 1 ; (% yI ) as ( ; ( tonani dealiz ( ; ( lnl ( )( l ( ; I of Fr ( ; n (: t i case c ( ) i iv ( ~ , ll ; iOllS in which w(irdsm'edi-rt(led into l ; wo (: lass ( ; s : (: lass ; I words m '( ; those which are normally wrii:l:en in low ( we ; me ; (: lass2words are t , hoseH/t (' , h ;; ~ S\]) rOl ) (' , rl to itt ls whi (; hlior-nm lly1;~dcea , Sl ) e(:i ; fl caselml ; Ix ; rn (' , onl ; a , in in/r ~ d ; \](\]~- I oS/ ; ()IICllt)\])(~I'CktS(~c , tmra , c , l ; er . Class 1 words gO , If . 
(' r ; m ; (' . ai ) it aliz (' dhyt ) ol;i . (; s(! , ~;i J : Lhe\[)el , ; in nillgo\['gtS(' , Ill~(' , it ( ; (' , O1'wh (' , lll ; h(;(;Olll)\](' , I ; iOlll)r('fixis(;;~l)-ita , liz( , d ; llI)I )(; rt : ; tsohyi ) othos(; , q when the ( : oml ) l e-1 oo a6 t~o--g-- 1 _J 200O   4OO0   6000 average aciive voc ; a hulafy size oy- , '  . . . . . . . . . . . i ; ; ? i : l . ,? dyna ln ic * dynamic wilh histoly 14 slatic with his loly , ~ . .
static x

Boo0100 o0\[?i ~ ur (' , 3: Targel ; I : e?t coverag ( ; versus a cl ; ive vocal ) , olary size , lots t ; at , it and ( tynmni (: met ; hods . The wiU ~, hi , ~4, o'qq(:urv (, . sreilex : i ~( ; headdiiii on of previously cn--(:om d ; ( u(~d(:aq4(' , I , t(~xl , tokens l ; () the act ; ivevoc ~ l ) ulary , l ; ionl ) r(~tixisupt )( ; r (: ics ( ; midal :\[( ; as l ; i , wo(:l ; rra , cix ~ rsl on G and \]() w (' . F (;; t,q(;hyl ) ot ; hesc,~ol ; h(!rwis(, . (7 lass2w()rds~(',II(!I'IJ,Cupl ) (' . r ( ; as ( ; hyl ) ol , hes(; , ~ml(h;r1; h(' , ~mn(;con(lilJolis~ts(' , lass I words , ol ; h('mwise ver-lml ; inihyt ) ol ; hcses . 
5 l . \[ esults\?elx ~ stx ~ dill ( ; (Ximl ) letfion ( ; ligiii ( , , ( m \[ ; wo differ ( ; ni \]\[ mism'dlx ; xl is nol : in ( ) ill ' l ; raJnlng (' , or tms . Texl , A , (: Olll ; ~inint\[786 (\[ ~ lll ; onlld ; it ; il Jly ) iciEll ( ; (lpa . il's ~19/157 English ; aid 21 , \]30 Frent : hix ) kens , w~m used 1 , odel ; e , rufil ~ col ) lJ nu unlia , rmnt;lx' , rsel , i ; ings ; t ; exl:\]1 , (: onl;~lJning lid0(mtlxmiatica . lly ) aligned tmirs ,  29 , 886 English and 32 , \]38 Frcncii1;okens , was used I , ot x ) rrol ) or ; iAx ~ the . l '(; Sltll ; s . Tests wcr ( . ' CO lith l('l ; (, . tiwiiJl~3000-word dynmnicacl ; ivt , vocabulm'ymlg-Ili ( ; tit( ; dwilJiallen (: ount ; er(xtl ; m'get ; - l , cxl ; t7) rlns . 
Fourlil(~SUl'C , so \["(' , o in t ) lelJont ) p , r\['orlna , lic , (! w (; l () used . Allll , SSllllOl ; tl~l , i ; iic1; ra , lisl~tl ; or will a , c , c , epl ; a (' . or r(;(' . l ; ?' . Oml ) letion prot ) os a . 1a . sSOOli ? i . sitismad(;(it , , wil;houl : l ; yping \[ l lr l;hc , l ) . Th(~lll()~ql ; direcl:iu-(lexisl ; iu ' , l ) roporlJonof(Jl0d~%(;t(!rsin (: or l(!t' . t;ly-coiui ) lcix ; d , quflix ( ; s .  \[/ , cla , t;ed1:o this isi ; lmpro-portion of (: or rc , (:l;ly-mll;icip~tt , dchltl'~K ; l;(;i'S:l;i()S(~ittCOI'I'(W . I ; sutIix esphls rely /; h ; d ; ln;~t ; cli/ . it (' . lICK , ch ~ racl ; erthel , rmisl ; ~ l ; or will tiavel ; otyl)c . The fi-lilt . l ; WOlll(~ ; tsur(!s ; IAoinlxmd cdIx ) ~ t)prt)xiim d , t~i , hcIIIIlHI ) CFo\["\]?eysl ; rokess ; tved within words . The firsl ; oo SSIll liCSl\]ud ; l , he , lirlmslal ; () rTlS (' , S ~ SlmcialCOllil\[igblid >(' . OS l , iugOIICk(;ysi;rok (' , lx ) ~ r(:c(;i)t ;; Lprot )() S ;- I\[ , r ~ h(\]s(' , COlI(t0~S , Slllll CS ; h0ol;~t(;(;(' , t)l ; ;~ll (:(~ COll-sisl ; smerely illl ; yping l ; h(' , chm ' ~ mlx ; r whit : h follows i , he word either ast ) ~ meorapunci;ua , I ; ion\[ll~l'k . 3 Complel ; ionsm'e free in this i ~ ccoIlltl ; hlt , ~>:; S()lneIDri!nchlirt!lixessi1ch & , q . jusqu'\vhichelide39 V ; o , /Sa '"" anticipated characters ~ , -- completed characters -*-- . 
keystrokes saved 2, . ::  . . . . . ~ e . t , o ~ .   .   .   .   . edld : ~" . . . . . . ~  . . . . . . . . . . . . . . . . . . x .  ?  .   .   .   .   .   .   .   .   .  ~  .   .   .   .   .   .   .   .   .   .  ~  .   .   .   .   .   .   .   .   . x .   .   .   .   .   .   .   .   .   .  ~  .   .   .   .   .   .   .   .   .   .   .   .   .   . x ?_ . . . . . 

l 0.2 0.4 0.6 0.8 trlgram weight
Figure 4: Combined trigram/translation model performance versus trigram weight  1  . 
but all punctuation must be manually typed , and any spaces or punctuation characters in hand -typed prefixes are assessed a one-keystroke escape penalty  . 
Figure 4 shows the performance of the system for various values of the trigram coefficient A  . A noteworthy feature of this graph is that interpolation improves performance over the pure trigram by only about  3%  . This is due in large part to the fact that the translation model has already made a contribution in nonlinear fashion through the dynamic vocabulary  , which excludes many hypotheses that might otherwise have misled the language model  . 
Another interesting characteristic of the data is the discrepancy between the number of correctly anticipated characters and those incompleted suffixes  . Investigation revealed the bulk of this to be attributable to morphological error  . In order to give the system a better chance of getting inflections right  , we modified the behaviour of the hypothesis generator so that it would never produce the same best candidate more than once for a single token  ; in other words , when the translator duplicates the first character of a proposal  , the system infers that the proposal is wrong and changes it  . As shown in table 1 , completion performance improve substantially as a result  . Figure 5 contains a detailed record of a completion session that points up one further deficiency in the system : it proposes punctuation hypotheses too often  . We found that simply suppressing punctuation in the generator led to another small increment in keystroke savings  , as indicated in table 1 . 
letters are not normally followed by either spaces or punctuation  . We assume the system can detecthese and automatically suppress the character used to effect the completion  . 
nleasure ( % chars ) anticipated completed keystrokes l keystrokes2 method text A text B s t d PB HRP+NPP+NP 77  . 2 80 . 0 79 . 2 78 . 9 67 . 1 73 . 6 72 . 6 72 . 2 65 . 1 71 . 8 72 . 3 71 . 9 49 . 8 54 . 6 55 . 1 55 . 1 Table 1: Final performance figures . PBHR stands for previous-best-hypothesis rejection  , and P+NP for
PHBR without punctuation hypotheses.
6 Conclusion
The work described in this paper constitutes a rudimentary but concrete first step toward a new approach to IMT in which the medium of interaction is simply the target text itself  . In contrast with previous interactive approaches , the translator is never expected to perform tasks that are outside the realm of translation proper  ( such as advising a machine about common sense issues  )  . In line with the spirit of truly interactive approaches  , the translator is called upon early enough to guide the system away from a " raw machine translation " he or she would rather not have to revise  . And in fact the machine is now the one required to revise its own copy  , making use of every keystrokentered by the translator to steer itself in a useful direction  . 
This strikes us as the " proper place " of men and machines in IMT  , and we intend to contiime exploring this promising avenue in our future research  . 
References
Hervd Blanch on .  1994 . Perspectives of DBMT for monolingual authors on the basis of  MDIA-1  , an implemented mock-up . In COLING-9/~, pages 115-119, Kyoto , August . 
Christian Boitet .  1990 . Towards personal MT . In COLING90, pages 3035, Helsinki , August . 
J . Brousseau , C . Drouin , G . Foster , P . Isabelle , R . Kuhn , Y . Normandin , and P . Plamondon . 
1995 . French speech recognition in an automatic dictation system for translators : the TransTalk project  . In Eurospeech 95 , pages 193-196 , Madrid , Spain , September . 
Ralf D . Brown and Sergei Nirenburg . 1990.
Human computer interaction for semantic disambiguation  . In COLING90, pages 42-47,
Helsinki , August.
Peter F . Brown , Stephen A . Della Pietra , Vincent Della J . Pietra , and Robert L . Mercer .  1993 . 
3 98 gous+/Nousrfialisonsr ~ al +/ avonsr/endre rfi/aliser  r4a/lise   r4al/isons toust+/dest/ousqueq+/lesq/uele+/le
Canada C +/ gouvernement C/a nadaco ~ e ~+/ , clothebienbi+/unb/eaucoupbi/end '+/ d ' autres +/ autrespays p +/  , p/ays +/ , riches r +/ , r / i e h e s
OU+/OU pauvres +/ pauv resaa +/ les beau coup b +  /6t ~ b/eaucouptropt+/det/rop de+/des esse +/ tempss/ervicesse/scitoyensc +/ tropc /itoyen squiq +/  . q/ui Figure 5: A sample completion run Ibr the English source sentence We all realize that like many other countries  , rich or poor , Canada has too many citizens who cannot afford deeenthousing  . The first column contains the French target sentence  ; the second the prefix typed by the translator , followed by a plus sign ; and the third the record of successive proposals for each token  , with a slash separating prefix from proposed completion  . 
The mathematics of machine translation : Parameter estimation  . Computational Linguistics , 19(2):263-312, June . 
hto Dagan , Kenneth W . Church , and William A.
Gale .  1993 . Robust bilingual word alignment for machine aided translation  . Ill Proceedings of the Workshop on Very Large Corpora  ( ACL93 )  , Columbus , Ohio . 
Patrick W . Demasco and Kathleen F . McCoy.
1992 . Generating text froin coin pressed input : An intelligent interface for people with severe motor impairments  . CACM , 35(5), May . 
Eurolang .  1995 . Eurolang Optimizer , product description . 
Robert Frederking , Dean Grannes , Peter Cous-seau , and Sergei Nirenburg .  1993 . An MAT9 tool and its etfectiveness . In \ [ roceedings of th , e
DARPA HLT Workshop , Princeton , NJ.
IBM .  1995 . IBM35" anslation Manager , product description . 
F . Jelinek .  1990 . Self-organized language modeling for speech recognition  . \[ nA . Waibel and K . Lee , editors , Readings in Speech Recognition , pages 4505)6 . Morgan Kaufmaim , San Mateo,

Martin Kay . 1973. Tile MIND system . In
R . Rustin , editor , Natural Language Processing , pages 155-188 . Algorithmics Press , New York . 
M . Kugler , G . Heyer , R . Kese , B . y on Kleist-Retzow , and G . Winkelmann .  1991 . The Trans-lator's Workbench : An environment for multilingual text processing and translation  . In Pro-eeedings of Mr1'Summit IH , pages 8183 , Washington , July . 
Hiroshi Maruyama and Hideo Wataimbe . 11990.
An interactive Japanese parser for machine translation  . In COLING90, pages 257-262,
Helsinld , August.
S(xge , Nirenburg .  1992 . Tools for machine-aided translation : The CMU TWS  . META , 37(4):709720 . 
Michel Simard , George F . Foster , and Pierre Isabelle .  1992 . Using cognates to align sentences in bilingual corpora  . In TMI-4, Montreal , Canada . 
Trados .  1995 . 3\]'a dos~lk'anslators Workbench , product description . 
P . , l . Whitelock , M . McGeeWood , B . J . Chandler , N . Itolden , and H . J . Horsfall .  1986 . Strategies for interaetiw ~ . machine translation : the experience and implications of the UMIST Japanese project  . In COLING-86, pages 329334, \] ~ Oliil . 
ldl ni Zajae .  1988 . Interactive translation : A new approach . In COLING-88, pages 785790, Budapest . 

