Generalizing Dimensionality in Combinatory Categorial Grammar 
Geert-Jan M . Kruijff
Computational Linguistics
Saarland University
Saarbru?cken , Germany

Jason Baldridge
ICCS , Division of Informatics
University of Edinburgh
Edinburgh , Scotland


We extend Combinatory Categorial Grammar ( CCG ) with a generalized notion of multidimensional sign  , inspired by the types of representations found in constraint-based frameworks like HPSG or LFG  . The generalized sign allows multiple levels to share information  , but only in a resource-bounded way through a very restricted in dexation mechanism  . This improves representational perspicuity without increasing parsing complexity  , in contrast to full-blown unification used in HPSG and LFG  . 
Wellformedness of a linguistic expressions remains entirely determined by the CCG derivation  . We show how the multidimensionality and perspicuity of the generalized signs lead to a simplification of previous CCG accounts of how word order and prosody can realize information structure  . 
1 Introduction
The information conveyed by linguistic utterances is diverse  , detailed , and complex . To properly analyze what is communicated by an utterance  , this information must be encoded and interpreted at many levels  . The literature contains various proposals for dealing with many of these levels in the description of natural language grammar  . 
Since information flows between different levels of analysis  , it is common for linguistic formalisms to bundle them together and provide some means for communication between them  . Categorial grammars , for example , normally employ a Saussurian sign that relates a surface string with its syntactic category and the meaning it expresses  . Syntactic analysis is entirely driven by the categories  , and when information from other levels is used to affect the derivational possibilities  , it is typically loaded as extra information on the categories  . 
Head-driven Phrase Structure Grammar ( HPSG )   ( Pollard and Sag ,  1993 ) and Lexical Functional Grammar ( LFG )   ( Kaplan and Bresnan , 1982) also use complex signs . However , these signs are monolithic structures which permit information to be freely shared across all dimensions : any given dimension can place restrictions on another  . For example , variables resolved during the construction of the logical form can block a syntactic analysis  . This provides a clean , unified formal system for dealing with the different levels  , but it also can adversely affect the complexity of parsing grammars written in these frameworks  ( Maxwell and Kaplan ,  1993) . 
We thus find two competing perspectives on communication between levels in a sign  . In this paper , we propose a generalization of linguistic signs for Combinatory Categorial Grammar  ( CCG )   ( Steedman , 2000b ) . This generalization enables different levels of linguistic information to be represented but limits their interaction in a resource-bounded manner  , following White (2004) . This provides a clean separation of the levels and allows them to be designed and utilized in a more modular fashion  . Most importantly , it allows us to retain the parsing complexity of CCG while gaining the representational advantages of the HPSG and LFG paradigms  . 
To illustrate the approach , we use it to model various aspects of the realization of information structure  , an inherent aspect of the ( linguistic ) meaning of an utterance . Speakers use information structure to present some parts of that meaning as depending on the preceding discourse context and others as affecting the context by adding new content  . 
Languages may realize information structure using different  , often interacting means , such as word order , prosody , ( marked ) syntactic constructions , or morphological marking ( Vallduv ?? and Engdahl , 1996; Kruijff ,  2002) . The literature presents various proposals for how information structure can be captured in categorial grammar  ( Steedman , 2000a ; Hoffman , 1995; Kruijff ,  2001) . Here , we model the essential aspects of these accounts in a more per-spicuous manner by using our generalized signs  . 
The main outcomes of the proposal are threefold : ( 1 ) CCG gains a more flexible and general kind of sign  ;   ( 2 ) these signs contain multiple levels that interact in a modular fashion and are built via CCG derivations without increasing parsing complexity  ; and ( 3 ) we use these signs to simplify previous CCG?s accounts of the effects of word order and prosody on information structure  . 
2 Combinatory Categorial Grammar
In this section , we give an overview of syntactic combination and semantic construction in CCG  . We use CCG?s multimodal extension ( Baldridge and Kruijff ,  2003) , which enriches the inventory of slash types . This formalization renders constraints on rules unnecessary and supports a universal set of rules for all grammars  . 
2.1 Categories and combination
Nearly all syntactic behavior in CCG is encoded in categories  . They may be atoms , liken p , or functions which specify the direction in which they seek their arguments  , like(s\np)/np . The latter is the category for English transitive verbs  ; it first seeks its object to its right and then its subject to its left  . 
Categories combine through a small set of universal combinatory rules  . The simplest are application rules which allow a function category to consume its argument either on its right  ( > ) or on its left ( < ) :  ( > ) X / ? Y Y ? X ( < ) Y X\?Y ? X Four further rules allow functions to compose with other functions :  ( > B ) X / Y Y / Z ? X/Z ( < B ) Y\ZX\Y ? X\Z ( > B ? ) X / ? Y Y\?Z ? X\?Z ( < B ? ) Y / ? Z X\?Y ? X/?Z The modalities ? ,  and ? on the slashes enforce different kinds of combinatorial potential on categories  . For a category to serve as input to a rule , it must contain a slash which is compatible with that specified by the rule  . The modalities work as follows . ? is the most restricted modality , allowing combination only by the application rules  ( > and < )  .  allows combination with the application rules and the order-preserving composition rules  ( > B and < B )  . ? allows limited permutation via the crossed composition rules  ( > B ? and < B ? ) as well as the application rules . Additionally , a permissive modality ? allows combination by all rules in the system  . However , we suppress the ? modality on slashes to avoid clutter  . An undecorated slash may thus combine by all rules  . 
There are two further rules of typeraising that turn an argument category into a function over functions that seek that argument :  ( > T ) X ? Y/i ( Y \ iX )   ( < T ) X ? Y \ i ( Y / iX ) The variable modality i on the output categories constrains both slashes to have the same modality  . 
These rules support the following incremental derivation for Marcel proved completeness :  ( 1 ) Marcel proved completeness np ( s\np ) / np np > Ts / ( s\np ) > Bs/np>s This derivation does not display the effect of using modalities in CCG  ; see Baldridge ( 2002 ) and Baldridge and Kruijff ( 2003 ) for detailed linguistic justification for this modalized formulation of CCG  . 
2.2 Hybrid Logic Dependency Semantics
Many different kinds of semantic representations and ways of building them with CCG exist  . We use Hybrid Logic Dependency Semantics ( HLDS )   ( Kruijff ,  2001) , a framework that utilizes hybrid logic ( Blackburn ,  2000 ) to realize a dependency-based perspective on meaning  . 
Hybrid logic provides a language for representing relational structures that overcomes standard modal logic?s inability to directly reference states in a model  . This is achieved via nominals , a kind of basic formula which explicitly names states  . Like propositions , nominals are first-class citizens of the object language  , so formulas can be formed using propositions , nominals , standard boolean operators , and the satisfaction operator ?@? . A formula@i ( p ? ? F ? ( j ? q ) ) indicates that the formulas p and ? F? ( j ? q ) hold at the state named by i and that the state j is reachable via the modal relation F  . 
In HLDS , hybrid logic is used as a language for describing semantic interpretations as follows  . 
Each semantic head is associated with a nominal that identifies its discourse referent and heads are connected to their dependents via dependency relations  , which are modeled as modal relations . As an example , the sentence Marcel proved completeness receives the representation in  ( 2 )  . 
(2 ) @ e ( prove ? ? TENSE ? past ? ? ACT ? ( m?Marcel ) ??PAT? ( c ? comp . )) In this example , e is a nominal that labels the predications and relations for the head prove  , and m and c label those for Marcel and completeness  , respectively . The relations ACT and PAT represent the dependency roles Actor and Patient  , respectively . 
By using the@operator , hierarchical terms such as ( 2 ) can be flattened to an equivalent conjunction of fixed-size elementary predications  ( EPs ) :  ( 3 ) @ e prove ?@ e?TENSE ? past ?@ e ? ACT ? m?@e ? PAT?c ?@ mMarcel ? @ ccomp  . 
2.3 Semantic Construction
Baldridge and Kruijff ( 2002 ) show how HLDS representations can be built via CCG derivations  . 
White ( 2004 ) improves HLDS construction by operating on flattened representations such as  ( 3 ) and using a simple semantic index feature in the syntax  . 
We adopt this latter approach , described below.
EPs are paired with syntactic categories in the lexicon as shown in  ( 4 ) ? ( 6 ) below . Each atomic category has an index feature , shown as a subscript , which makes a nominal available for capturing syntactically induced dependencies  . 
(4 ) prove ` ( se\npx ) /npy:@eprove?@e?TENSE?past?@e?ACT?x ?@ e ? PAT ? y  ( 5 ) Marcel`npm:@m Marcel ( 6 ) completeness ` npc:@c completeness Applications of the combinatory rules coindex the appropriate nominals via unification on the categories  . EPs are then conjoined to form the resulting interpretation  . For example , in derivation (1) ,   ( 5 ) type-raises and composes with ( 4 ) to yield ( 7 )  . 
The index x is syntactically unified with m , and this resolution is reflected in the new conjoined logical form  . (7) can then apply to (6) to yield (8) , which has the same conjunction of predications as  ( 3 )  . 
(7 ) Marcel proved ` se/npy : @ e prove ?@ e?TENSE ? past?@e ? ACT ? m?@e ? PAT ? y?@m Marcel  ( 8 ) Marcel proved completeness`se:@e prove ?@ e ? TENSE ? past ?@ e ? ACT ? m?@e ? PAT ? c?@mMarcel ?@ c completeness Since the EPs are always conjoined by the combinatory rules  , semantic construction is guaranteed to be monotonic  . No semantic information can be dropped during the course of a derivation  . This provides a clean way of establishing semantic dependencies as informed by the syntactic derivation  . In the next section , we extend this paradigm for use with any number of representational levels  . 
3 Generalized dimensionality
To support a more modular and perspicuous encoding of multiple levels of analysis  , we generalize the notion of sign commonly used in CCG  . The approach is inspired on the one hand by earlier work by Steedman  ( 2000a ) and Hoffman ( 1995 )  , and on the other by the signs found in constraint -based approaches to grammar  . The principle idea is to extend White?s ( 2004 ) approach to semantic construction ( see ?2 . 3) . There , categories and the meaning they help express are connected through coindexation  . Here , we allow for information in any ( finite ) number of levels to be related in this way . 
A sign is an n-tuple of terms that represent information at n distinct dimensions  . Each dimension represents a level of linguistic information such as prosody  , meaning , or syntactic category . As a representation , we assume that we have for each dimension a language that defines wellformed representations  , and a set of operations which can create new representations from a set of given representations  . 1 For example , we have by definition a dimension for syntactic categories  . The language for this dimension is defined by the rules for category construction : given a set of atomic categories A  , C is a category iff ( i ) C ? A or ( ii ) C is of the form A\m B or A/mB with A , B categories and m ? ? ,   ? ,  ? . 
The set of combinatory rules defines the possible operations on categories  . 
This syntactic category dimension drives the grammatical analysis  , thus guiding the composition of signs . When two categories are combined via a rule , the appropriate indices are unified . It is through this unification of indices that information can be passed between signs  . At a given dimension , the coindexed information coming from the two signs we combine must be unifiable  . 
With these signs , dimensions interact in a more limited way than in HPSG or LFG  . Constraints ( resolved through unification ) may only be applied if they are invoked through coindexation on categories  . This provides a bound on the number of indices and the number of unifications to be made  . 
As such , full recursion and complex unification as in attribute-value matrices with reentrancy is avoided  . 
The approach incorporates various ideas from constraint-based approaches  , but remains based on a derivational perspective on grammatical analysis and derivational control  , unlike e . g Categorial Unification Grammar . Furthermore , the ability for dimensions to interact through shared indices brings several advantages :  ( 1 ) ? parallel derivations ? ( Hoffman , 1995) are unnecessary ; (2) non-isomorphic , functional structures across different dimensions can be employed  ; and ( 3 ) there is no longer a need to load all the necessary information into syntactic categories  ( as with Kruijff ( 2001 ) ) . 
1In the context of this paper we assume operations are multiplicative  . Also , note that dimensions may differ in what languages and operations they use  . 
4 Examples
In this section , we illustrate our approach on several examples involving information structure  . We use signs that include the following dimensions  . 
Phonemic representation : word sequences , composition of sequences is through concatenation Prosody : sequences of tunes from the inventory of  ( Pierrehumbert and Hirschberg ,  1990) , composition through concatenation Syntactic category : wellformed categories  , combinatory rules ( see ?2 ) Information structure : hybrid logic formulas of the form@d[in]r  , with radiscourse referent that has informativity in  ( theme ? , or rheme ? ) relative to the current point in the discoursed ( Kruijff ,  2003) . 
Predicate-argument structure : hybrid logic formulas of the form as discussed in  ?2  . 3 . 
Example ( 9 ) illustrates a sign with these dimensions . The wordform Marcel bears an H*accent , and acts as a type-raised category that seeks a verb missing its subject  . The H*accent indicates that the discourse referent m introduces new information at the current point in the discoursed : i  . e . the meaning@mmarcel should end up as part of the rheme  ( ? ) of the utterance , @d [?] m . 
(9) Marcel
H*sh/(sh\npm)@d[?]m@mmarcel
If a sign does not specify any information at a particular dimension  , this is indicated by > ( or an empty line if no confusion can arise )  . 
4.1 Topicalization
We start with a simple example of topicalization in English  . In topicalized constructions , a thematic object is fronted before the subject . Given the question Did Marcel prove soundness and completeness ?  ,   ( 10 ) is a possible response using topicalization : ( 10 ) Completeness , Marcel proved , and soundness , he conjectured . 
We can capture the syntactic and information structure effects of such sentences by assigning the following kind of sign to  ( topicalized ) noun phrases : ( 11 ) completeness > si / ( si/npc ) @d [?] c@c completeness This category enables the derivation in Figure  1  . 
The type-raised subject composes with the verb , and the result is consumed by the topicalizing category  . 
The information structure specification stated in the sign in  ( 11 ) is passed through to the final sign . 
The topicalization of the object in ( 10 ) only indicates the informativity of the discourse referent realized by the object  . It does not yield any indications about the informativity of other constituents  ; hence the informativity for the predicate and the Actor is left unspecified  . In English , the informativity of these discourse referents can be indicated directly with the use of prosody  , to which we now turn . 
4.2 Prosody & information structure
Steedman (2000a ) presents a detailed , CCG-based account of how prosody is used in English as a means to realize information structure  . In the model , pitch accents and boundary tones have an effect on both the syntactic category of the expression they mark  , and the meaning of that expression . 
Steedman distinguishes pitch accents as markers of either the theme  ( ? ) or of the rheme ( ? ) : L+H * and L*+Hare?-markers ; H * , L * , H*+L and H+L * are ?- markers . Since pitch accents mark individual words , not ( necessarily ) larger phrases , Steedman uses the ?/?- marking to spread informativity over the domain and the range of function categories  . 
Identical markings on different parts of a function category not only act as features  , but also as occurrences of a singular variable . The value of the marking on the domain can thus get passed down  ( ? projected ? ) to markings on categories in the range . 
Constituents bearing not une have an ?- marking , which can be unified with either ? , ? or ? . Phrases with such markings are ? incomplete ? until they combine with a boundary tone  . Boundary tones have the effect of mapping phrasal tones into intonational phrase boundaries  . To make these boundaries explicit and enforce such ? complete ? prosodic phrases to only combine with other complete prosodic phrases  , Steedman introduces two further types of marking ?? and ?? on categories  . 
The ? markings only unify with other ? or ? markings on categories  , not with ? , ? or ? . These markings are only introduced to provide derivational control and are not reflected in the underlying meaning  ( which only reflects ? , ? or ?) . 
Figure 2 recasts the above as an abstract specification of which different types of prosodic constituents can  , or cannot , be combined . 2 Steedman?s 2There is one exception we should note : two intermediate phrases can combine if a second one has a downstepped accent  . 
We deal with this exception at the end of the section  . 
completeness Marcel proved si / ( si/npc ) s j / ( sj\npm )   ( sp\npx ) /npy@d[?]c@c completeness@mMarcel@pprove ?@ p?ACT?x ?@ p ? PAT ? y>B sp/npy@pprove ?@ p ? ACT ? m ?@ p ? PAT ? y?@m Marcel > sp@d [?] c@ pp rove ?@ p ? ACT ? m ?@ p ? PAT ? c ?@ mM  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  ccompleteness Figure  1: Derivation for topicalization . 
system can be implemented using just one feature pros which takes the values ip for intermediate phrases  , cp for complete phrases , and up for unmarked phrases . We writes pros = ip , or simply sip if no confusion can arise . 
Figure 2: Abstract specification of derivational control in prosody First consider the top half of Figure  2  . If a constituent is marked with either a ?- or ?- tune  , the atomic result category of the ( possibly complex ) category is marked with ip . Prosodically unmarked constituents are marked as up  . The lexical entries in (12) illustrates this idea . 3 (12) MARCEL proved COMPLETENESS
H*L+H*sip/ ( sup\np )   ( sup\np ) /npsip $\ ( sup$/np ) This can proceed in two ways . Either the marked MARCEL and the unmarked proved combine to produce an intermediate phrase  ( 13 )  , or proved and the marked COMPLET ENESS combine ( 14 )  . 
(13) MARCEL proved COMPLET ENESS
H*L+H*sip/ ( sup\np )   ( sup\np ) /npsip $\ ( sup$/np ) > sip/np 3The $?s in the category for COMPLETENESS are standard CCG schematizations : s$ indicates all functions into s  , such as s\np and ( s\np)/np . See Steedman (2000b ) for details . 
(14) MARCEL proved COMPLET ENESS
H*L+H*sip/ ( sup\np )   ( sup\np ) /npsip $\ ( sup$/np ) < sip\np For the remainder of this paper , we will suppress upmarking and writes up simply as s  . 
Examples ( 13 ) and ( 14 ) show that prosodically marked and unmarked phrases can combine  . However , both of these partial derivations produce categories that cannot be combined further  . For example , in (14) , sip / ( s\np ) cannot combine with sip\np to yield a larger intermediate phrase  . This properly captures the top half of Figure 2 . 
To obtain a complete analysis for (12) , boundary tones are needed to complete the intermediate phrases tones  . For example , consider ( 15 )   ( based on example ( 70 ) in Steedman ( 2000a ) ):  ( 15 ) MARCEL proved COMPLET ENESS
H*LL+H*LH %
To capture the bottom-half of Figure 2 , the boundary tones L and LH % need categories which create complete phrases out of those for MARCEL and proved COMPLETENESS  , and thereafter allow them to combine . Figure 3 shows the appropriate categories and complete analysis  . 
We noted earlier that downstepped phrasal tunes form an exception to the rule that intermediate phrases cannot combine  . To enable this , we not only should mark the result category with ip  ( tune )  , but also any leftward argument ( s ) should have ip ( down step )  . Thus , the effect of ( lexically ) combining a downstep tune with an unmarked category is specified by the following template : add marking xip $\ yip to an unmarked category of the form x $\ y  . 
The derivation in Figure 5 illustrates this idea on example ( 64 ) from ( Steedman , 2000a ) . 
To relate prosody to information structure , we extend the strategy used for constructing logical forms described in  ?2  . 3, in which a simple index feature
MARCEL proved COMPLET ENESS
H*LL+H*LH % sip/ ( s\np )   ( scp/scp $ ) \? ( sip/s $ )   ( s\np ) /npsip $\ ( s$/np ) scp$\?sip$<<scp/ ( scp\np ) sip\np < scp\np > scp Figure 3: Derivation including tunes and boundary tones ; (70) from ( Steedman , 2000a )
Marcel PROVED COMPLET ENESS
L+H*LH % H*LL % np ( sip : p\npx ) /npyscp$\?sip$sip\ ( s/npc )   ( scp\scp $ ) \? ( sip\s $ ) @d [?] p@d[?]c@mMarcel@pprove ?@ p?ACT ? x?@p ? PAT ? y@c completeness > T < sip/  ( sip\np ) scp\ ( scp/npc ) @d [?] c@m Marcel@c completeness > B sip/np@ d [?] p@p prove ?@ p ? ACT ? m ?@ p ? PAT ? y ?@ mMarcel<scp/npy@d[?]p@pprove ?@ p?ACT?m ?@ p?PAT?y ?@ mMarcel<scp@d[?]p ?@ d[?] c@p prove ?@ p ? ACT ? m ?@ p ? PAT ? c?@mM  Marcel ? @ccompleteness Figure  4: Information structure for derivation for ( 67 ) - ( 68 ) from ( Steedman , 2000a ) on atomic categories makes a nominal ( discourse referent ) available . We represent information structure as a formula @ d[i]r at a dimension separate from the syntactic category  . The nominal r stands for the discourse referent , which has informativity i with respect to the current point in the discoursed  ( Kruijff ,  2003) . Following Steedman , we distinguish two levels of informativity , namely ? ( theme ) and ? ( rheme ) . 
We start with a minimal assignment of informativity : a the me-tune on a constituent sets the informativity of the discourse referent r realized by the constituent to ? and arheme -tune sets it to ?  . This is a minimal assignment in the sense that we do not project informativity  ; instead , we only set informativity for those discourse referents whose realization shows explicit clues as to their information status  . 
The derivation in Figure 4 illustrates this idea and shows the construction of both logical form and information structure  . 
Indices can also impose constraints on the informativity of arguments  . For example , in the down-step example ( Figure 5) , the discourse referents corresponding to ANNA and SAYS are both part of the theme  . We specify this with the constituent that has received the downstepped tune  . The referent of the subject of SAYS ( indexed x ) must be in the theme along with the referents for SAYS  . This is satisfied in the derivation : a unifies with x  , and we can unify the statements about a ? s informativity coming from ANNA  ( @d [?] a ) and SAYS ( @d [?] x with x replaced by a in the > B step )  . 
5 Conclusions
In this paper , we generalize the traditional Saus-surian sign in CCG with an n-dimensional linguistic sign  . The dimensions in the generalized linguistic sign can be related through indexation  . Index-ation places constraints on signs by requiring that coindexed material is unifiable  , on a per-dimension basis . Consequently , we do not need to overload the syntactic category with information from different dimensions  . 
The resulting sign structure resembles the signs found in constraint-based grammar formalisms  . 
There is , however , an important difference . Information at various dimensions can be related through coindexation  , but dimensions cannot be directly
ANNASAYS he proved COMPLETENESS
L+H*!L+H*LH % npip:a ( sip:s\npip:x ) / sys/ ( s\np )   ( sp\np ) /np@d[?]a@d[?]s ?@ d[?]x@d[?] ( pron ) @ d[i]p > T sip/ ( sip\npip ) @d [?] a > B sip/s  ?] s ?@ d [?] a > B sip /  ( s\np ) @d [?] s ?@ d [?] a ?@ d [?] ( pron ) > B sip/np@d[?]s ?@ d[?]a ?@ d[?] ( pron ) ?@ d[i]p Figure 5: Information structure for derivation for ( 64 ) from ( Steedman , 2000a ) referenced . As analysis remains driven only by inference over categories  , only those constraints triggered by indexation on the categories are imposed  . 
We do not allow for reentrancy.
It is possible to conceive of a scenario in which the various levels can contribute toward determining the wellformedness of an expression  . For example , we may wish to evaluate the current information structure against a discourse model  , and reject the analysis if we find it is unsatisfiable  . If such a move is made , then the complexity will be bounded by the complexity of the dimension for which it is most difficult to determine satisfiability  . 

Thanks to Ralph Debusmann , Alexander Koller , Mark Steedman , and Mike White for discussion . 
Geert-Jan Kruijff?s work is supported by the DFG SFB  378 Resource-Sensitive Cognitive Processes , 
Project NEGRAEM 6.

Jason Baldridge and Geert-Jan Kruijff .  2002 . Coupling CCG and Hybrid Logic Dependency Semantics  . In Proc . of 40th Annual Meeting of the ACL , pages 319?326 , Philadelphia , Pennsylvania . 
Jason Baldridge and Geert-Jan Kruijff .  2003 . MultiModal Combinatory Categorial Grammar . In Proc . of 10th Annual Meeting of the EACL , Budapest . 
Jason Baldridge .  2002 . Lexically Specified Derivational Control in Combinatory Categorial Grammar  . Ph . D . 
thesis , University of Edinburgh.
Patrick Blackburn .  2000 . Representation , reasoning , and relational structures : a hybrid logic manifes to  . 
Journal of the Interest Group in Pure Logic ,  8(3):339? 365 . 
Beryl Hoffman .  1995 . Integrating ? free ? word order syntax and information structure  . In Proc . of 7th Annual Meeting of the EACL , Dublin . 
Ronald M . Kaplan and Joan Bresnan .  1982 . Lexical-functional grammar : A formal system for grammatical representation  . In The Mental Representation of Grammatical Relations  , pages 173?281 . The MIT
Press , Cambridge Massachusetts.
Geert-Jan M . Kruijff .  2001 . A Categorial-Modal Logical Architecture of Informativity : Dependency Grammar Logic & Information Structure  . Ph . D . thesis , Charles University , Prague , Czech Republic . 
Geert-Jan M . Kruijff .  2002 . Formulating a category of informativity . In Hilde Hasselgard , Stig Johansson , Bergljot Behrens , and Cathrine Fabricius-Hansen , editors , Information Structure in a Cross-Linguistic Perspective  , pages 129?146 . Rodopi , Amsterdam . 
Geert-Jan M . Kruijff .  2003 . Binding across boundaries . 
In Geert-Jan M . Kruijff and Richard T . Oehrle , editors , Resource Sensitivity , Binding , and Anaphora . Kluwer
Academic Publishers , Dordrecht.
John T . III Maxwell and Ronald M . Kaplan .  1993 . The interface between phrasal and functional constraints  . 
Computational Linguistics , 19(4):571?590.
Janet Pierrehumbert and Julia Hirschberg .  1990 . The meaning of intonational contours in the interpretation of discourse  . In J . Morgan P . Cohen and M . Pollack , editors , Intentions in Communication . The MIT Press,
Cambridge Massachusetts.
Carl Pollard and Ivan A . Sag .  1993 . Head-Driven Phrase Structure Grammar . University of Chicago
Press , Chicago IL.
Mark Steedman . 2000a . Information structure and the syntax-phonology interface  . Linguistic Inquiry , 31(4):649?689 . 
Mark Steedman . 2000b . The Syntactic Process . The
MIT Press , Cambridge , MA.
Enric Vallduv ?? and Elisabet Engdahl .  1996 . The linguistic realization of information packaging  . Linguistics , 34:459?519 . 
Michael White .  2004 . Efficient realization of coordinate structures in Combinatory Categorial Grammar  . Research on Language and Computation . To appear . 
