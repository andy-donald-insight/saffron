Hybrid Neuro and Rule-Based Part of Speech Taggers
Qing Ma , Masaki Murata , Kiyotaka Uchimoto , Hitoshi Isahara
Communic ~ tions lese a . rch Labora.tory
Ministry of Postsa .nd Telecommm~ications
588-2 , lwa , oka , , Nishi-ku , Kobe 6511-2/192 , 3a , pa , n
qma , murata ., uchimoto , isa.hara )) crl.go.jp

A hybrid system R ) r tagging part of speech is descril ) ed that consists of an euro tagger and a rule -based correcter  . The neuro tagger is an initia . 1--state a . nnotator tha . t uses difl ' ertnth_ , ,ngths of contexts based on longe , st context l ) ri-ority . Its inputs a . reweighted 1) y information gains tha . t are obtained by information ma . xi-mization . The rule-1) ased correcter is constructed by a . sol ; of trm~sfc)rma . tion rules to xna . keUl ) for the shortcoming so\['thenou17o tagger . Corn-puter experiments show that a hnost 20% of the errors ma . de by the neuro tagger a . recorrect-ed by the , st trans\[orma . tion rules , so tha . t the hybrid system ca . nreach a . na , tcura . cy of 95 . 5% counting only the ambiguous words and 99 . 1% counting all words when a . small Thai corpus with 22 , 311 ambig ; uous words is used t )) vtra . in-ing . Thisa ( ; curacy is far higher than that using an IIMM and is also higher tha  . n that using a . 
rule-1) ased model.
1 Introduction
Manypa . rt of speech ( POS ) tatters proposed so far ( e . g . , Brill , 1994; Meria . l do , 1994; l ) aele-marls , el . al . , 1996; and Schmid , 1994) ha . reachieved a . high accura . eypartly because a . very large amount of dal , ~ was used to 1; rain them ( e . g . , on the order of 1 , 000 , 000 words for \]' hl-glish ) . Forma . nyother la . nguages ( e . g . , Thai , which we treat in this paper ) ~ however , it is not as easy to cremate \] a . rge corpora from which lm:geamounts of tr~fining data can be extra  . cted . It is therefore desirable to construct a practic ; d tagger tha . t needs as little training da . t;a ~ as possible . 
A multi-neurotagger ( Maa . ndls~hara ,  11998 ) and its slimmed-down version called the ela . s-tic neuro tagger ( Ma , el ; al . , 1999), which have high genera . lizing ability and therefore are good at dealing with the problems of datasp~u:se-hess  , were proposed to satist ~ y this requh:ement . 
These taggers perform POS tagging using difl'er -ent lengths of corl texts I  ) ~ . ~sed on longest context prk ) rity , and each element of tile input is weight-ed with information gains  ( Quinla . n ,  1993 ) for retlecting that tile elements of the input h ~ve different rtle vances in t~Gging  . Theyha . datagging accuracy of 94 . 4%  ( counting only the ambiguous words in part of speech  ) in computer experiments when a . small'l'ha . i corpus with 22 , 311 ambiguous words was use ( l for tr~fining . This ~(:-curacy is bu " higherthmlt\]lat ; U Sillgtile hidden Marker model ( IIMM ) , the main approach to \]) arto\[speech tagging , ~ n d is ~ d so higher t , \] lantha . t using a . rule-based mode \] . 
Neurotaggers , however , htwe several crucial shortcomings . First , even in the case where the POS of a word is uniquely determined by the word on its left  , for example , a neural netwill also try to perl brnl tagging based on tile complete context  . As a result , even for " when the word on tile left ; is the same , the tagging result~s will be difl'erent if the complete contexts are different  , rl'ha , t is ~ then eurotagger car lhardly acquire the rules with single inputs  . Furthermore , although lexica . lin\[brma . tion is very ilnport ~ ultint ~ gging , it is difficult for : neural nets to use it becmmedoing so would make the network enorlnous  . That is , then eurotagger ca . n not acquire ( ; lit rules with lexical informs > tion . Additionally , Imca . use of convergence and not adv is M ) le to train neural nets to an a . ccura , - cy of 100% . The training should be stopped at an appropriate level of a  . ceuracy . Consequently , neural nets may not acquire some usefnl rules . 
To make up for these shortcomings of the neuro tagger  , we introduce in this pa . pera rule-based correct or a stile postprocessor and construct a hyl  ) rid system . The rule-based cot-rector is constructed by a set of transformation rules  , which is acqnired by transform a ? i on-based error -driven learning  ( Brill ,  1 . 994: ) from training corpus using a set of templates . The templates are designed to SUl ) l ) ly the rules that the neurot agger can hardly acquire  . Actually , by examining the transformation rules acquired in the computer experiments  , the 99 . 9% of them are exactly those that the neuro tagger can hardly acquire ~ even when using a template set including those for generating the ' rules that then eurotagger can easily acquire  . This reinforces on rexpectation that the rule -based approach is a well-suited method to cope with the shortcomings of the neurot ~ gger  . Computer experiment shows thai ; about 200/0 of errors made by the neurotagger can be corrected by using these rules and that the hybrid system ca  . n reach an accuracy of 95 . 5% counting only the aml ) ign-ous words and 99 . 1% counting all words in l , he testing corpus , when tile same corpus described above is used for training  . 
2 POS Tagging Problems
In this paper , suppose there is a lexicon V , where the POSs that can be served by each word are list  . ed , and tiler ( ;  is a set of POSs , l ? . That is , unknown words that do not exist in the lexicon are not dealt with  . The POS tagging problem is thus to find a string of POSs T =  T172  . .-% ( ri C F , i = 1 , - .   .   , s ) by following procedure ~ o when sentence W = wl w2 . . . w . ~( wiCV , i = 1, .  -  . , s ) is given . 
#: W~-+rt ,   ( 1 ) where t is the index of the target word ( the word to be tagged )  , and Wt is a word sequence with length l+1+r ( : entered on the target word : liet : wt_1 .   .   .   . iot ? .   . Wt+r ~ (2) where t-1 > 1, t + r_<s . ' l ' agging ca . n thus be regarded as a classification problem 1 )  3 , replacing the POS with ( ; lass and can therefore be handled by using neural nets  . 
3 Hybrid System
Our hybrid system ( Fig . J ) consists of a neurotagger , which is used as an initial-state annota-i ; or , ~nda rule-based corrector , which corrects the outputs of the neurotagger . When a word seque , ~ ceWt\[seel ~ q . (2)\] is given , then euro tagger out l ) ut a tagging result rN ( Wt ) for tile target word wt at first . The rule-based correct or then corrects the output of the neurot agger as a finetuner and gives tile final tagging result 
NcuroTagger Rule-Based

Figure 1: Hybrid neuro and rule-based tagger.
3.1 Neurotagger
As shown in Fig .  2 , the neurotagger consists of a three-layer I ) erceptron with elastic input . 
This section mainly descril ) es the construction of in l ) ut and output of the nenro tagger , and the elasticity by which it ; becomes possible to use variable length of context for tagging  . For details of the architecture of l ) erceptron see e . g . , Haykin ,   1994 and for details of the features of the neuro tagger see Maandisahara  , 1998 and
Ma , et aJ ., 1999.
lnl ) ut IPT is constructed fi ' om word sequence Wt\[ Eq  .  (2)\] , which is centered on target word wt and has length l +  1 + r:IPT = ( iptt_l ,   .   . ', iph, .   .   . , iph + . , . ) ,   ( 3 ) provided that input length l+J+r has elasticity  , as described a , ttile end of this section . When woMw is given in position x(x = t-l , .   .   . , t+r ), iptt_I . . . . . . i l ) \[ t_ I ipl t 11"1" il)lt+l . . . . . . i\]Ht+r
Figure 2: Neuro tagger.
elementipt , of input IPT is a . weighted pattern , defined as ipt . ,: = :/ . ,, . ( e , , , , ('- , ,' e, . "  , q , ,~) , (4) where g; , ; is the inIbrmation gain which can be obtained using information theory  ( for details see Ma and lsahara . , 11998) and 7 is the number of tyl)es of POSs . l\['w is a word that a pl ) ears in the tra . ining data , thenea . ch bite , , , i can be obtained := P , ,ot , (/ I ,   ,   , )  ,   ( s ) where l > ' rob ( ril'w ) is a prior l > robal ) ility of rith a . t (; he wo M'w can take, . It is estitnated from the training ( la , ta :
C_(< , "') c'( , 4' where C'(r ( , w ) is the number of l fimes both r : at ++ d wal ) pea , r , a , ndC ( w ) is the number oi ' times w appears in the training data  . 1\[ w is a word that does not at ) pear ill ( , he training data ~ then each t ) it c , , , ,i is obtained : ~ i\['r i is a . candidate (7) e . , , , , "= ( otherwise , where 7 , , is the number of P()Ss that the word ' w Call ta . k e . Output OPT is defined as
OFT = , o +) ,   ( s ) provi < led that the output OI ) T is decoded as
Sr / if Oi = l & O /= 0 for j ? i
YN(Wt ) Unknown otherwise,( . 9) where rN(W , ) is the ? a . gging result obtained by then eurotagger . 
There is more inforlnation available for constructing the input for words on the left  , because they have already been tagged . In the tagging phase , instead of using (4:)-(6) , the input can be constructed simply as i / ,   , _4 =  . oPT (- i ), (1()) where i = 1, .   .   .   , 1 , and OI ) T ( - i ) means the output of the tagger for the ith word before the target word  . l to wever , in the training process , the out ; put of the tagger is not alway . a correct a . nd cannot beted back to the inputs directly . 
Instead , a weighted a werage of the actual output a . ndtlm desired output is used : iptt_i = 9t-i' ( wol , T"0PT(-i ) + WlOJ , : s " I ) liS ) ,  (1 . 1) where 1) l': , q ' is the desired output , o: ,  :  , 5 ' : (&  ,  / )2  ,   .   .   .   , whose bits are defined as \] iI'ri is a desired answer 
I ) i = 0 otherwise , (la ) and WOl , ' r and w /) l , \] , q ' are respecLh : elyde\[(nedas1'\]013J ~ , : o1' ~ .   .   .   .  ( . 14) 1 JACT'a , nd'w>l , ;  , s , = : 1-wopT , (15) where \]@ , uo and \]' JAC'T are the objective and actual errors  . Thus , at the beginning of training , the weighting of the desired output is largo . 
It decreases to zero during training.
Elastic inputs are used in the neurot aggers o that the length of COll text is variable in tagging based on longest context priority  . In(te~tail , ( l , r ) is initially set as large as possible for tagging  . If rN('Wi ) = Unknown , then (1 , r ) is reduced by some constant interval . Thisl ) ro-cess is repeated until rN ( W  ~ ) 7k Unknown or ( 1 , r ) = (0 , 0) . On the other hand , to nmke the same set of connection weights of the neurotagger with the largest  ( 1 , ' r ) ava . ilable a . sl nuch as training phase the neuro tagger is regarded as a neural network that has gradually grown fi'om small one  . The training is therefore performed step by step from small networks to large ones  ( for details see Ma , et al 1999) . 
3.2 Rulebase deorreetor
Even when the POS of a word can be determined with certainty by only the word on the left  , for example , tilen euro tagger still tries to tag based on the complete context  . That is , in general , what tile neuro tagger can easily acquire by learning is the rules whose conditional parts are constructed by all inptttsiptx  ( x = t-l ,   .   .   . , t+r ) that are . joined with all AND logical operator , i . e . , ( iptt-t&"'"iptt&? . . iptt +~, -+ OPT ) . In other words , it is ( lit : ticult for tile neuro tagger to learn rules whose conditional parts are constructed by only a single input like  ( ipt ,  . --+ OPT ) ~) . Also , although lexical information is very important in tagging  , it is difficult for the neurot agger to use it , because doing so would make the networkeu of mous  . Tha . t is , then eurotagger cannot acquire rules whose conditional parts consist of lexical information like  ( w-4OPT )   , ( w&r-4OPT ) , and ( w~w2--+OPT ) , where w , Wl , and w2 are words and 7-istile POS . Furthermore , because of convergence and over training 1 ) rol ) lems , it isiml ) ossible and also not advisable to trainnet > ral nets to all accuracy of  100%  . The training should be stopped at an apl ) rol ) riate level of a . c-curacy . Thus , neural net may not acquire some useful rules . 
The transfbrmation rule-based corrector makes up for these crucial shortcomings  . 
The rules are acquired Dora a training colpus using a set of transformation templates by transformation based rror-driven learning  ( Brill ,  1994) . Tile templates are constructed using only those that supply the rules that tilenen rotagger can hardly acquire  , i . e . , are those 1 ) Then eurotagger can also learn this kind of rules because it can tag tile word using only ipt  , ( the input of tile target word ) , ill the case of reducing tile ( I , r ) to (0 , 0) , as described in Sec . a . l . The rules with single input described here , however , are a more general case , ill which the input call be ipt , ~( ~ := t-1 ,   .   .   . , t+r ) . 
for acquiring the rules with single input , with lexical information , and with AND logica . 1 input of POSs and lexical information . The set of templa , tesi shown in Table 112) . 
According to the learning procedure shown in Table  2  , an ordered list of transformation rules are acquired by applying the template set to a training corpus  , which had a h'eady been tagged by the neuro tagger  . After tile transformation rules are acquired , a corl ) us is tagged as t bllows . It is first tagged by then eurotagger . The tagged corpus is then corrected by using the ordered list of transformation rules  . 
The correction is a repetitive process applying the rules ill order to the corpt lS  , which is then updated , until all rules have been applied . 
4 Experimental Results
Data : For our computer experiments , we used tile same Thai corpus used by Ma et al ( 1999 )  . 
Its 10 , d 52 sentences were randomly divided into two sets : one with  8  , 322 sentences for trail > ing and the other with 2 , 1 . 30 sentences for test-int . The training set contained 12 d , 331 words , of which 22 , 311 were ambiguous ; the testing set contained a 4 , 5 ~ 14 words , of which 6 , 717 were ambiguous . For training tile neuro tagger , only the ambiguous wor ( ls in the . training set were used . For training the HMM , all tilt words in the training set were used . In both cases , all the words in tile training set were used to estimate Prob  ( rilw )   , tim probability of " ci that wor ( Iw can be ( for details on the HMM , see Ma , et al ,  1999) . In the corpus , 4:7 types of POSs are defined ( Charoenporn et al , 1997); i . e . , 7 = 47 . 
Neurotagger : Then eurotagger was constructed by a three-layer perceptron whose input-middle-out I  ) ut layers had pz , 27 units , respectively , where p = 7 ?(1 + I + r) . The ( l+1+r ) hadtile following elasticity . In training , tile(I , r ) was increased step by step as (71 , 1)-+( u , 2) ( a , 2) ( a , a ) a , dgra , dual training fl'om a small to a large network was pertbrmed  . Ill tagging , on the other hand , the 2) To see whether this set is suitable , aimmloer of additional experiments were conducted using various sets of templates  . The details are described in Sec .  4 . 
512 r ~ I a , 1) lc1 : Seto\['templa . tes for tra . ns\[orln;~tion rules
Chang et ; agvatot ; agv ? when : ( single in lm ; )( input('onsists of a POS ) 1 . left(right ) word is tagged v . 
2. second left ( right ) word is tagged r.
3. third left ( right ) word is ta.ggedr.
( in I ) n ; consist ; s of a word ) 4 . ta . rget word is ~ . 
5. left ( right ) word is w.
6. second left , ( right ) word is w.
( AND logical in pu?ot " words ) 7 . l , arget word is ' UO1 ~ tlld left ( right ) word is wu . 
8 . left ; ( right ) word is u , 1 and second lcfl ,  ( , ' ight ) word is w2 . 
9. left , word is w ~ a . ndright , word is ' wu.
( AND logical in . lint ; of POS and words ) 10 . ta . rget word is uq and left ( right ) word is l laggo dr . 
:11 . left(righl ;) word is . w ~ and left . ( right ) word is tagged r . 
12 . ta . rget word is w ~, left(right ) word is , w . , , and left ( right ) word is tagged r . 
Ta , 1) le2: l ) roet dure for learning transi'orma , tion rules 1 . Apply neurot aggtr to training corpus , which is then updated . 
2 . Compare tagged results with desired ones and find errors  . 
3 . Ma . teh templates l ' or all errors and obtain set of tra  . nsformation rules . 
d . Select rule in corpus with the maximum value of '   ( cnl , _qood-h . cnl , _bad ) , where cnZ_qood:number that transforms in correct ags to correct elli S:c'nl  . _bad : number that transforms correct tags to incorrect ones  , h : weight to control the strict , hess of generating 1; he rule . 
5 . Apply select td rule to training corpus , which is then updated . 
6 . Append selected rule to ordered list o1" trausl ' or ma . tion rules . 
7 . Ih'4)eal ; steps : 2 through ( j until no such rule can I ) eselected , i . e . , c'n , t_good-h, . cnl,_bad<O . 
( l , ' r ) was inversely reduce ( lstel ) by step as ( 3 , 3) -+ (3 , 2) (2 , 2) (2 , : 1) O , : l ) (: l , o ) (0 , 0) a . sneeded , provided tJlat the number of units in the middle layer was kept a  . t them a . xi-
Illlllllvahle.
Rule-based correttor : The parameter hin the tw ~ Juat  ; ion function ( cnl , _9 ood-h ,   . c'M . _bad ) used in 1 ; he learning procedure ( Table 2 ) is a weight to control the strictness of generating a  . 
rule . IF It is large , the weight of cnt_bad is la . rge and the possibility of generating incorrect rules is reduced  . By regarding the neurot agger as ~ d-ready having high accuracy and using tile rule--based correcter as a finetuner  , weight h . was set to a . large vahm , 100 . Applying ; lit templates Co the training corptm , which had already been tagged 1) 5 , the neurot a . gger , we obta . in eda . nordered list ; of 520 transfbrmation rules .  ' . l'~d)le3 shows the first 15 transfbrmation rules . 
Results : Table 4 shows the resull ; s of I )() S tagging for the testing data . . In addition to the accuracy o \[" the neuro tagger and hybrid system  , the ta . ble also show stile accuracy of a , bast-line model , the IIMM , and a rule-based model \[' or comparison . The baseline model is one that performs tagging without using the contextual in lorm a  . tion ; instead , it performs ta . gging using only f ' requency in form a . tion : the proba . bility of P () S that ; tach word can be . The rule-based model , to be exact , is also a hybrid system con-
No . From To Condition 1 PREL 2 PREL 3 Unknown 4   XVHI4   5 VATT 6 Unknown 7   NCI4N   8 VATT
OPREL i0 VST ~ ii VfiTT 12 NCMN 13 NCHN 14 Unknown 15 NCNNRPRE left word is punctuation and right tuordis  5~gu 
RPRE left yard is ~
RDVN left ~ or dLs tagged XV fiE
XVBH left word is II~D fl DVN left word is ~
VRTT left word is tagged PREL
RPRE left word isua
VST fileft word is ~ q ~
RPRE right word is ~ gu and second right word is a ~ q  ; J
RDVN target word is ~ t~4
ADVN target word is ~4 ~
RPRE target word is n14 and left word i seent luu RPRE left word is ~ t t and leftward is tagged NCHN fiDVN third left word is tagged WCT 
CNIT taPget ~ or disnn~where PREL : Relative Pronoun  , RPRE : Preposition , fiDVN : fid verb with normal form .   .   .   . 
Tabled : Results of POS ta , gging for testing data * model baseline IIMM H rule -based lleuro hybrid accuracy  0  . 836 0 . 891 0 . 935 0 . 944 0 . 9 55  *  Accurac9 was determiued only for aml figuous words . 
sisting of an initial-state annotator and a set of transformation rules  . As the initial-state an no-b ~ to r , however , the baseline model is used in-stea . d of ' then euro tagger . And , its ruleset . has 1 , 1 77 transformation rules acquired h'om a more general teml  ) late set , which is described at the end of this section . The reason for using a general template set is that the sol  ; of tra . nsibrma . tion rules in the rule-based model should be the main annotator  , not a fine postprocessing tuner . For the same reason , the parameter to control the strictness of generating a rule  , h , was set to a small value ,  \] , so that a larger number of rules were generated . 
As shown in the table , the accuracy of the nenro tagger was far higher than that of the HMM and higher than that of the rule-based model  . The accuracy of the rule-based model , on the other hand , was also far higher than that of the IIMM , ~ l though it was inferior to that of the neuro tagger  . The accuracy of the hybrid system was 1 . 1% higher than that of the neurotagger . Actually , the rule-based correct or corrected 88 . 4% and 19 . 7% of the errors made by the neuro tagger for the training and testing data  , respectively . 
Because the template set shown in Table 1 was designed only to make up for the shortcomings of the neurotagger  , tile set is small compared to that used by Brill ( 1994 )  . To see whether this set is la . rge enough for our system , we perlbrmed two additional experiments in which ( \] ) as ol ; constructed 193' adding the templates with OR logical input of words to the original set and  ( 2 ) a , set constructed 1 ) 5' fnrther adding the templates with AND and OR logical inputs of POSs to the set of case  ( 1 ) were used . The set used in case ( 2 ) inclnded the set used by Brill ( \]994 ) and all the nets nsed in our experiments . It was also used for acquiring the transformation rules in the rule-based model  . 
The experimental results show that compared to the original case  , the accuracy in case ( 1 ) was improved very little and the accuracy in case  ( 2 ) was also improved only 0 . 03% . These results show that the original set is nearly la  . rge enough for our system . 
To see whether tile set is snitable tbrour system  , we performed ~ tn additional experimen-t using the original set in which the templa  . tes with OR logical inputs were used instead of the templates with AND logical inputs  . The accuracy dropped by 0 . 1% . Therefore , tile templates with AND logical inputs are more suitable than We also performed an experiment using a template set without lexical intbrmation  . In this case , l ; he accuracy dropl ) ed by 0 . 9% , indicating that lexical informatiol l is important in tagging  . 
To determine the effect o1' using a . large h , for generating rules , we per\['ormed an experiment with h = 1 . In this case , the accuracy dropped by only 0 . 045%, an insignifica . nt difference compared to the case of h , = 100 . 
By examining the acquired rules that were obtained by al  ) plying the most COml ) lete template set , i . e . , the set used in case (2) described above , we found that 99 . 9% of them were those that can be obtained by a . pl ) lying the original set of templates , rl'ha . t is , the acquired rules were almost those that are dif \[ i cult\['or the neu-re tagger to acquire  .  ' . l'h is reinforced our expec-t at ; ion that the rule-based al ) l ) roach is a well-suited method to cope with the shortcoming of the neurotagger  . 
Finally , i l , should 1) enoted that ill the literatures , tile tagging a . ccuracy is usua . lly delined by counting a . lltile words regardless of whether they area . nl biguous or not . If we used this dell-nil : ion , t\]le accura . cy of our hybrid system would be 99 . 1% . 
5 Conclusion
To collstruct a 1 ) tactical tagger that needs as little training data  . a . spossible , neurotaggers , which have high generalizing al ) ility and therefore a . regood at dealing with the problems of da~ta . sl ) a , rseness , have been proposeds of a . r . Neu-retatters , however , have crucial shortcomings : they ca . n not utilize lexical information ; they have trouble learning rules with single inputs  ; and they cannot learn training data to an ac ~ curacy of  100%  . To make up for these shortcomings , we introduced a rule-based correcter , which is constructed by a . set of trans\[brma . tion rules obtained by error-driven learning , for post 1 ) recessing and constructed a hybrid tagging system , ly examining the transt brma . tion rules acquired in the computer experiments , we found that 1; he 99 . 9% of them were those that ; the neu-re tagger can hardly acquire , even when using a . 
template set including t ; hose for generating the rules that the neuro tagger can easily acquire  . 
This reinlbrced our expect a . tion that the rule-based approach is a well-suited method to cope with the shortcoming of the neuro tagger  . Computer experiments showed that 19 . 7% of the errors made by the neuro tagger were corrected by the tra  . nslbrmation rules , so the hybrid system rea . chedan accuracy of 95 . 5% counting only the ambiguous words and 99 . \]% counting all the words in the testing data , when a small corpus with only 22 , 311 ambiguous words was used tbr train in t . ~l'his indicates thai ; our tagging , qystem can nearly reach a pra . ctica . l level in terms of tagging accuracy even when a small Thai corpus is used t brtra  . ining . This kind of tagging system can be used to constructs multilingua  . 1 corpora that include languages in which large corpora have not yet been constructed  . 
References l ~ rill , E . : Transfornmtion-based rror-driven lca . rn-ing and natural language processing : ~ cases -tudyill  1  ) art-of-sl ) eech tagging , Computational Li~g'uistics , Vol . 21, No . 4, pp .  543-565, 199~1 . 
Cha . roenporll , T . , Sornlertlanlva . nich , V . , ~ mdIsahara , 11 . : Buildingala . rgeThaitext corpus parl ; of speech tagged corpus : OICIlll ) , Pro < Natural Language Processi ~ fl Pacificl Nm , 5'gn~-po . du'm\[997, Phuket , Thailand , pp .  509-5\]2, 1997 . 
I ) a elemans , W . , Z~wrel , a . , Berck , P . , and C,i/lis , S . :  MI3'I ': Am<mlory-based pm-t of speech tagger-genera . to t,P'roc . / tl . h Workshop on Very Large Co , ' po~zl , Copenhagen , l)emna . rk , pp .  1-1+1, 99(5 . 
l\]aykin , S . : Neural Nchvorlcs , Macmillan College
Publishing Coral ) any , Inc ., 199/t.
Ma , Q . and lsahm ' a . , H . : A multi-neurot agger using variable lengths of contexts  , Prec . COLING-
ACL'g8, Montreal , pp . 802-806, 1998.
Ma , Q . , Uchimoto , K . , Mura . ta , M . , and 1sahara H . : F , lastic neural networks t br part of speech tag : ging  , Prec . IJCNN'99, Washington , \]) C . , pp . 

Meriaklo , B . : Tagging English text with a probabilistic model , Computational Linguistics , Vo \] . 
20, No . 2, pp . 1.55-171, 19(.)4.
Quinla . n , 3 . : G ' ~ . 5: Programs Jot Machine Learning , San Mateo , CA : Morgan Kaufinann ,  1993 . 
Schmid , 1t . : l ' art-of-speech tagging with neural networks , Prec . COLING'94, Kyoto , Japan , pp . 


