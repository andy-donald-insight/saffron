Word Sense Disambiguation of Adjectives
Using Probabilistic Networks
Gerald Chao and Michael G . Dyer
Coinl ) uter Science Det ) artment,
University of California , Los Angeles
Los Angeles , California 90095
gerald@cs.ucla.edu , dyer ~ cs.ucla.edu
Abstract
In this paper , word sense dismnbiguation ( WSD ) accuracy achievable by a probabilistic lassifier , using very milfimal training sets , is investigated . \ Ve made the assuml ) tiout hat there are no tagged corpora available and identified what information  , needed by an accurate WSD system , can and cmmot be automatically obtained . The less on learned can then be used to locus on what knowledge needs malmal annotation  . Our system , named Bayesian Hierarchical Disambiguator ( BHD ) , uses the Internet , arguably tile largest corlms in existence , to address thest ) arse data problem , and uses WordNet's hierarchy tbr semantic contextual features  . In addition , Bayesian networks are automatically constructed to represent knowledge learned from training sets by l nodeling the selectional i  ) retbrence of adjectives . These networks are then applied to disaml ) iguation by per-tbrming inferences on unseen adjective-noun pairs  . 
We demonstrate that this system is able to disambiguate adjectives in um'estricl  ; edtext at good initial accuracy rates without tile need t br tagged corpora  . 
The learning and extensibility aspects of the model are also discussed  , showing how tagged corpora and additional context can be incorporated easily to improve accm'acy  , and how this technique can be used to disambiguate other types of word pairs  , such as verb-noun and adverb-verb pairs . 
1 Introduction
Word sense disambiguation ( WSD ) remains an open probleln in Natural Language Processing  ( NLP )  . Being able to identify tile correct sense of an mn bigu-ous word is iln portant for many NLP tasks  , such as machine translation , information retrieval , and discourse analysis . The WSD problem is exacerbated by the large number of senses of colmn only used words and by the difficulty in determining relevant contextual features most suitable to the task  . Tile absence of semantically tagged corpora makes probabilistic techniques  , shown to be very effective by speech recognition and syntactic tagging research  , difficult to employ due to the sparse data problem  . 
Early NLP systeins limited their domain and required manual knowledgengineering  . More recent works take advantage of machine readable dictionaries such as WordNet  ( Miller , 1990) and Roget's Online Thesaurus . Statistical techniques , both supervised learning from tagged corpora ( Yarowsky ,  1992) , ( Ng and Lee ,  1 . 996) , and unsupervised learning ( Yarowsky ,  1995) , ( Resnik ,  1997) , have been investigated . There are also hybridinod cls that incorporate both statistical and symbolic knowledge  ( Wiebe et al ,  1998) , ( Agirre and Iigau ,  1996) . 
Supervised models have shown promising results , but the lack of sense tagged corpora often requires the needt brlaboriously tagging trailfing sets manually  . Depending on the technique , unsupervised models can result in ill-defined senses  . Many have not been evaluated with large vocabularies or flfll sets of senses  . Hybrid models , using various heuristics , have demonstrated good accuracy but are ditfi -cult to compare clue to variations in the evahlation procedures  , as discussed in Resnik and Yarowsky (\]997) . 
In our Bayesian Hierarchical Disambiguator ( BHD ) model , we attempt to address some of the main issues faced by today's WSD systelns  , namely : 1) the sparse data problem ; 2) the selection of a fi ; a ture set that can be trained upon easily without sacrificing accuracy  ; and 3 ) the scalability of the sys-te into disambiguate um'estricted text  . The first two problems can be attributed to the lack of tagged corpora  , while the third results from the need for ll and -annotated text as a method of circumventing the first two problems  . We will address the first two issues by identiflying contexts in which knowledge can be obtained automatically  , as opposed to those that require minimal manual tagging  . The effective-hess of the BHD model is then tested on unrestricted text  , thus addressing the third issue . 
2 Problem Formulation
WSD cant ) e described as a classification task , where the ith sense ( W#i ) of a word ( W ) is classified as the correct tag , given a word and usually some surrounding context  . For example , to disambiguate the adjective " great " in the sentence " Tile tem should disambiguate " great " as left  . q(:in . s ' iz c rather than the good or c : cc cllent meaning . Using l ) robability notations , this t ) rocedure can best~ted as max i ( Pr ( great#i \ [" great " , " i he " , " lnn'-ricane " , " devastated " , " the " , " region ")) . That is , given the word " great " and its context , elassit ~ y the sense great #/ with the highest probability as the correct  o11e   . However , a large COllteX\[ ; ~sll(:has the whole sentence , is rarely used , due to the dilliculty in estimating the 1 ) robability of this particular set of words oceurring  . Therefore , the context is usually narrowed , such as , z number of surrom Ming words . 
Additionally , surrollnding syntactic t batures aim semantic knowledge are sometimes used  . The difficulty is in choosing the right context , or the set of features , that willol ) timize the classification . A larger (: on text int l ) rovest ; 11 ( ! classiti ( : ationa ( : ( :ura ( : y althe exl ) ense of increasing the mlml ) er of l ) arameters ( typically learned fr ( nn large training data )  . 
in our BHI ) model , a minimal context ( : Oml ) OSe ( l of only the adj e ( : tive , noun and the llOllll ; SSelllall-tie features obtained fl ' ( )m \ VordNel is used . Using the al ) ove examl ) le , only " great " , " hurri ( : ane " and hun'i cane'st ) atures encoded in WordNet's hierarchy , as in hurricanel ISA cyclonel ISA wind-storm ISA violent storm  . . . , are used its (; Oll text . 
Therefore , the classitieation 1 ) ertbrn md1 ) yBill )   ( : ant ) e written as n laxi ( lh ( great ? ~ i \ [" great " , "\] nlrri-cane " , cyt : lolt c , winds lorm . . . )) , or more generi-cally ,   , m ( , ,:~( l ' r ( , dj  #il ( , dj ,   , ,> , , . , , , < N \] , ' , ; >)) ,   , vher ( , < N/Z s > denotes then ( mn features . By using the Bayesian inversion for nmla , this equati ( ) nl ) e(:onw . s . ,,, . <,:, . ~( Pr ( , . 4i,'l, . o , . , . , < N\],' . s > I . , ! i  #i ) xP , ( , , 4 i  #i)) . 
Pr(,d:i,'no'u , ., < Nt ; '. s ">) (1)
This e onte?t is chosen because it does not ; need an annotated training set , and these semantic fe . atures are used to l ) uih tabelief about the nouns , : ill adjective Sell Se typically l nodifies , i . e . , these \] ectional preferences of a ( ljectiv (' . s . For examlfle , having learned about lmrrieane , the system can infer the most probable dismnbiguation of " great typhoon "  , " greattor-nado " , or lt lore distal concept such as earthquakes and tloods  . 
3 Establishing the Parameters
As shown in equation 1 , BH 1 ) requires two parameters : 1 ) the likelihood term Pr ( adj , noun , < NFs > ladj#i ) and 2 ) the prior term Pr ( adj#i )   . The prior term represents the knowledge of how frequently a sense of an adjective is used without any contextual infornmtion  . Dn " example , if great#2 ( sense : 9 ood , excellent ) is nsed frequently while great  #lisless commonly used  , then Pr ( great#2 ) wtmld be larger than Pr ( great  #l )   , in l ) rOl ) or tion to the usage of the two senses . Although WordNet orders the senses of at ) olysenl ( ms word according to usage , the actual t ) rot ) or tions are not quantified . Therefore , to (: omtmte the priors , one can iterate over all English nouns and sunl the instmlces of great  #l-noun versus  great#-2-noun t ) airs . But siilce we assume that no training set exists ( the worst possible ease of the sparsed at al ) rol ) lem )  , these counts need to 1 ) eestinmted from il Mire et sources . 
3.1 The Sparse Data Problem
The techuique used to address datas I ) arsity , as first proposed by Mihalcea and Moldovan (1998) , treal ; s the Internet as a cortms to automatically ( lisam-biguate word 1 ) airs . Using the previous examl)le , to disambiguate he adjective in " great hurricane  "  , two synonym lists of (" great , large , t)ig ") and (" great , neat , good ") are retrieved from V ? or dNet . ( SO llle synonyms ~111 (1el ; her SellSeSi/reoll litted here for 1) revity . ) Two queries ,   ( " great hurricane " or " large hurrit : an e ? ' or " t  ) ighurricane " ) and ( " great hurricane " or " neat hurricane " or " good hurriemm "  )  , are issued to Altavista , which reporl , s that 1100 and 914:1 ) ages contain the seterlll S , respectively . The query with the higher count ( #1 ) is classitied its the correct sense . For fllrther details , please refer to Mihalecaanti Moldovau (1998) . 
In our luo(lel , the (: omd ; s front Altavista are im:or-l ) orated as \[ ) arall tel ; erstilllatiollS within our proba-bilislh : frlt111  ( ~ work . Jill addition to disaml ) igualing lhead jectives , we also need to estimale lheusage of the a(ljec ; ive#i-noml pair . For simt ) licil ; y , the counts fronl Altavista are assigued whole sale  1o the disambiguated adjective sense , e . g . , the usage of great#l-hurr icane is 1100 times and great#2-hurricane is zero times . This is a great simplification since in many adjective-noun pairs nmltil  ) le meanings are likely . For instance , in " greatsl ; eak " , both sense of '" great " ( largest eak vs . tasty steak ) aree , qually likely . However , given no other information , this sinlt ) lification is used as a gross ap-t ) roximation of Counts ( adj  #i-noun )  , which be coines Pr ( adj  #i-noun ) by dividing the counts by a norn ml-izing constant  , ~ Com~ts ( adj  #i-all nouns) . These prolmbilities are then used to compute the priors  , described in the next section . 
Using this technique , two major probleins are addressed . Not only are the adjectives automatically disambiguated  , but the number of occurrenees of the word pairs is also estimated  . The need loth aud-annotated semantic or pora is thus avoided  . However , the statistics gathered by this technique are at ) proxinmtions , so the noise they introduce does require supervised training to n finimize error  , as will lm described . 
153 3.2 Computing the Priors
Using the methods described above , the priors cats be automatically computed by iterating over all nouns and smnnfingtile counts t breach adjective sense  . Untbrtunately , the automatic disambiguation of tim adjective is not reliable enough and results it  , inaccurate priors . Therefore , manual classification of assigning nouns into one of the adjective senses is needed  , constituting the first of two manual tasks needed by this model  . However , instead of classifying all English nouns , Altavista is again used to provide collocation data on  5  , 000 nouns for each adjective . The collocation frequency is then sorted and the top  100 nouns are manually classified . For example , the top 10 nouns that collocate after " great " are " deal " , " site " , " job " , " place " , " time " , " way " , " American " , " page " , " book " , and " work " . They are then all classified as being modified by the  great#2 sense except for tile last one , which is classified into another sense , as defined by WordNet . Timprior for each sense is then coinputed by smmning the counts D on  , t ) airing the adjective with the nouns classified into that sense and dividing by the sum of all adjective-noun pairs  . The top 100 collocated nouns fbreach adjective are used as anal  ) proxima-tion for all adjective-noun pairs since considering all nouns would be impractical  . 
To validate these priors , a Naive Bayes classifier that comt ) utes v ,  . aziPr(adj ,, !, o'l,r@,dj#i)xPr(,,dj#i)
Pr(a4i , ~ o, .  , . ) is used , with the noun as the only context . This simpler likelihood term is approxinm ted by the same Internet counts used to establish the priors  , i . e . , Counts ( adj  #i-noun)/normalizing constant . In Table 1 , the accuracy of disambiguating 135 adjective-noun pairs Dora the br-a01 file of the semantically tagged corlms SemCor ( Miller et al , 1993) is compared to the baseline , wl fich was calculated by using the first WordNet sense of the adjective  . As mentioned earlier , disambiguating using , simply the highest count Dot ** Altavista ( " Before Prior " it , Table 1) achieved a low accuracy of 56% , whereas using the sense with the highest prior ( " Prior Only " ) is slightly better than the baseline . This result validates the fact that the priors established here preserve WordNet's ordering of sense usage  , with tile improvement that tim relative usages between senses are now quantified  . 
Combining both the prior and the likelihood terms did not significantly improve or degrade tile accuracy  . This would indicate that either the likelihood term is uniformly distributed across tile i senses  , which is contradicted by the accuracy without the priors  ( second row ) being significantly higher than the average number of senses per adjective of  3  . 98,

Before Prior 56.3%
Prior Only 77.0%
Combined 77.8%
Baseline 75.6%
Table 1: Accuracy rates from using a Naive Bayes classifier to wflidate the priors  . These results show that the priors established in this model areas accurate as the WordNet's ordering according to sense usage  ( Baseline )  . 
or , more likely that this parameter is subsumed by the priors due to the limited context  . Therefore , more contextual infbrmation is needed to improve tim model's peribrmance  . 
3.3 Contextual Features
Instead of adding other types of context such as the surrounding words and syntactic features  , tlm semantic features of tim noun ( as encoded in the WordNet ISA hierarchy ) is investigated for its effectiveness . These features are readily available and are organized into a well-defined structus'e  . Tim hierarchy provides a systematic and intuitive method of distance measurements between feature vectors  , i . e . , the semantic distance between concepts . This property is very important for in thrring the classification of the novel pair " great flood " into the sense tha  . t contains hurricane as a member of its prototypical nouns  . These prototypical nouns describe tile selectional preferences of adjective senses of " great "  , and the semantic distance between them and a new noun in easures  1  ; 11o " semantic fit " between the concepts . Tile closer the . y are , as with " hurricane " and " flood " , the higher the prot ) ability of the likelihood term , whereas distal concept such as " hurricane " and " taste " would have a lower value  . 
Representing these prototy t ) ical 110 112 18 prot ) a bilis-tically , however , is difficult due to the exponential number of 1 ) robal ) i lit , ies with respect othen mn ber of features . For exm nl ) le , ret ) resenting hurric mm1 ) e-ingI ) resent in a selectional t ) reference list requires 2 s probabilitie since there are 8 features , or ISAl ) arents , in the WordNet hierarchy . It , addition , tiles parsed at at ) roblem resurfaces because a chone of the 2 sprobabilities hastol ) equantified . To address these two issues , belief networks are used , as described it , detail in the next section . 
4 Probabilistic Network's
There are many advantages to using Bayesian networks over the traditional probabilistic models  . The most notable is that the mlmber of probabilities needed to represent he distribution can be significantly reduced by making independence assumptions between variables  , with each no decondition-P ( h , B , C3)3? , l~)=l'(All~ , C)xl'(BIb , i ; ) xP ( Cl )) xP ( \]) llV , ) xl ) ( l~)xl ) ( F ) Figure : 1: Ane Xamlih ; of a Bayesimlnel ; work and the t ) rolialiilities at (' a(:h node , thai ( h ' lin ( ; lhere htl . ion-shills1) (' tweeuano(h ; and its parents . '\]' h equational ; thel ) ott ( ) m shows how t . h ( ,   ( listrilmtion across all ( if the variat ) lesis ( : Oml ) Ut ( ' , (l . 
all yd ( , l/endenl ; ltl ) on only il ; st ) arenls(\]'earl ,  1988) . 
\]Pigllr(!\] shows all ( LxCallll)\]( ; \] ayesialll(H:Woll(rel)-r ( ; senl ; ingl ; h('disl ; ribul ; i ( ) n\])( ; \ , B ; (' , ,1);F , ,\]") . \] nsl ; (' a ( l of having oue large ( , able wilh 2" lirol ) al ) i lit . i(~s ( with all \] o()\](; annod(!s) , the ( lisl ; ribution is rel ) resenl ( ; ( t by the (: onditional I ) rolial ) ility tal)les(C , \]) Ts ) atea('hnod( , , su(:h as I>(B I l ) , F ) , requiring a ( olal of only 2d prol ) al ) ilitie ~ s . Not only ( loth ( , saving she ( : ome more significant with larger networks , lmi ; ( . he sparse data t/r ( ) l ) h ; mb (!(: omesm()r ( ; manag ( ; abh , as well . Th(!I ; l' ; /illitlg ~ s(!l ; 11 olollg : erlice ( is Ix )   ( : ( ) v ( ! rall l ) (!l'lllllta-l ; ions(if l ; hef(!a ( ; m'esets , lml only smaller sul ) sets dictated l ) yl . he sets of Valial ) h!s ( if lira CPTs . 
Then (; l . w(/rk shown in Figure 1lo () kssimi-hn to any pOll ; ion of th ( ~\ V or (1N(~l ; hierar (: hy for a reason . In BII\]) , belief networks with the same stru (: tur ( ; as the \ V or ( tNet hierar ( : hyareau-tomatically ( : onstru ( :t ; ed to rel ) l " esen the seh'cl ; ional I ) reference of an a (1 . iective sense . S1)ecifically , the network rei ) resents the prol ) aliilistic ( tistribu-l ; i on overall of the i ) rotol ; yl ) i ( : alnouns of an a ( 1-jective ~ i mid the nouns ' semanti ( : t'ealures , i . e . , P(v , . ot , , , , , , , . ., . , < v , . o ~, oNF , > I , -! i  #i) . ' rh(; , , s( , of Bayesian networks for WSI ) has I ) eenl ) rop ( )sed by others such as Wiebe eL al ( 1 . 998) , but a different fl ) rmulation is used in this mod ( ' l . Th ( , construction of the networks in BHD can be divided into three steps : defining  1  ) the training sets , 2) the structure , and 3) the probabilities , as described in the tbllowing sections . 
4.1 ~ lYaining Sets
The training set for each of the adje (: tives (' , nses is ( ; on structed by (' . xi ; ra(:l ; ingl ; heexenll ) lary adje ( : tive-noun pairs from tile WordNet glossary . The glossary contains the examlih ; usage of the a(lje(:tiv (' ~ s , and l;\]l (' , nouns from the in are taken as the training sets "  />   , t ' " il , -\/'\'""@ t:': ,  (? . * ib , , ~",' . .,,, . , : p , .   .   .   .   .   .   .   . H / , ( , , , , , , @ , , . 

\/ a ~", '"')( . ,,,5 ( . ,,,4- .   . . . . .  ~  . . . . . . . . . . . . . . . 
Figure 2: The stru(:ture ( if the belief n ( , l;w(/rk that i'el ) resenls the , s(~h  ~ ctionall ) refer(!n ( :( ~( iff lrcal , #\[ . 
The leaf nodes are 1 . he nouns within the training set , midlheint ( ~ rm('xlial . ( ; no ( lesr (' th ; (: l ; the ISA hierar (: hyfr ( ) m\\ ; () r(1Nel ;  . The 1) rol ) ahilities al each node at (' , usedi;o(lisanfl ) iguat(!novela(lj ( , (: l ; ive-noun 1) airs . 
for th ( , a (1 . i (' (: iives . For exmnl ) h! , the nouns " auk " , " oak " , " steak " , " delay " and " amount " ( : ompose the training set fl ) r great  #l ( SellSC " lalT/eiv , size , ) . Notel \] lal ; WordNet in (: huh'd"sl ; e ~ al ~" illl ; he glossary of greal ; #\] , l ) ul : il ; al ) l ) ears thai1 ; \]le9oodore:ccelhe'H , l , 5 (! lise would lmlliOl ' (! aplWol ) rial ; e . Neverlheh~ss , the is is of exelnl ) lary mmns are sysl : ( ; malit : aily rel ; rh'vcd and nol('dile(l . 
Th ( " sets ( if l/r ( )tolypi ( : aln ( /mlSf ( /reach a ( lj ( ~ ( : liv ( ~sense have to lie ( lisaml ) igual ; edlie (: ause , the S ( ~lllall-li ( : features ( lifter 1 ) etween ambiguous nouns . Since these n(m nscmmol ; lieautonmti ( : ally disamlAguated with high accuracy , lhey have to be done mamm\]ly . 
This is the second t ) art of ( , liemmmal process need ( ; d1)3 " BIIDsitl(:(! the W (/ rdNel ; gh ) ssary is not seln all ti-(:ally tagged . 
4.2 Belief Network Struetm'e
The belief networks have the same structure as the \ VordNet  1SA hierarchy with the ext ; et ) tion that the edges are direcl ; ed from the child nodes to their parents . Il hlstrated in Figure 2 , the BItD-eonstructed network represents the selectional t  ) referelme of the to I ) level nod (  ;  , great  #l . The leaf nodes are tile evi- ( len ( : e nodes from the training set mM the internm ( li-aleilo ( les are ; t1( ; sema . n t i e f e a t m ' e s ( if the leaf nodes . 
This organization emd ) les the belief gathered from the leaf nodes 1 ; olietirot ) a gated uI ) to the tol ) level node during inferencing , as described in a later sec-LioIl . 111; first , th ( ' l ) robability tableae ( :oml ) anyiuge a ( : h node needs to be constructed . 
155 4.3 Quantifying the Network
The two parameters the belief networks require are the CPTs tbreach intermediate node and the priors of the leaf nodes  , such as P ( great  #l , hurricane ) . The latter is estilnated by tile counts obtained fronl Altavista  , as described earlier , and a shortcut is used to specit ~ y the CPTs . Normally the CPT sill aflflly specified Bayesian etwork contain all instantiations of the child and parent values and their corresponding probabilities  . For example , the CPT at node D in Figure 1 would have four rows : er ( D = t l E : t )   , Pr(D = tlE =  f) , Pr(D = flE = t) , and Pr(D = flE =  f ) . This is needed to perform flfll inferencing , where queries can be issued for any instantiation of the variables  . However , since the networks in this model are used only for one specific query  , where all nodes are instantiated to be true , only the row with all w ~ riables equal to true , e . g . , Pr(D = tlE = t ), has to be specified . The nature of this query will be described in more detail in tile next section  . 
To calculate the probability that an intermediate node and all of its parents are true  , one divides the number of parents present by the number of possible parents as specified ill WordNet  . hi Figure 2 , the small clotted nodes denote the absent parents  , which detern fine how the probabilities are specified at each node  . Recall that tile parents in the belief network are actually the children in the  . WordNet hierarchy , so this probability can be seen as the percentage of children actually present  , hltuitively , this probability is a form of assigning weights to parts of the network where more related nouns are present in the training set  , silnilar to the concept of semantic density . Tile probability , in conjunction with the structure of the belief network  , also implicitly encodes the semantic distance between concepts without necessarily  1  ) enalizing concepts with deep hierarchies . A discount is taken at each ancestral node during inferencing  ( next section ) only wlmn some of its WordNet children are absent in the network  . 
Therefore , the semantic distance can be seen as the number of traversals  11I   ) the network weighted by the number of siblings present in tile tree  ( and not by direct edge counting )  . 
4.4 Querying the Network
With the probability between nodes specified , the network becomes a representation of the selectional prefbrence of an adjective sense  , with features from the WordNet ISA hierarchy providing additional knowledge on both semantic densities and semantic distances  . To disambiguate a novel adjective-noun pair such as " great flood "  , the great  #l and great #2 networks ( along with 7 other great #/ networks not shown here ) infer the likelihood that " flood " belongs to the network by comtmting the probability Pr  ( great , flood , < flood NFs > , protonouns , < l ) rot oNFs > I adj#i ) , even though neither network has ever encountered the noun " flood " before  . 
To perform these inferences , the noun and its features are tenlporarily inserted into the network according to the WordNet hierarchy  ( if not already present )  . The prior for this " hypothetical evidence " is obtained the same way as the training set  , i . e . , by querying Altavista , and the CPTs are updated to reflect this new addition  . To calculate the probability at the top node , any Bayesian network inferencing algorithm can be used  . However , a query where all nodes are instantiated to true is a special case since the probability can be comlmted by multiplying together all priors and the CPT entries where all variables are true  . 
Ill Figure 3 , tile network for great  #l is shown with " flood " a stile hypothetical evidence added on the right  . The CPT of the node " natural phenomenon " is updated to reflect the newly added evidence  . The propagation of the probabilities from the leaf nodes up the network is shown and illustrates how discounts art taken at each intermediate node  . Whenever more related concepts are 1 ) resent in the network , such as " typhoon " and " tornado ' ~ , less discounts are taken and thus a higher probability will result at the root node  . Converso . ly , one can see that with a distal concept , such as " taste " ( which is illa completely different branch )  , the knowledge about " hurricane " will have little or no influence on disambiguating " great taste "  . 
The calculation above can be computed in linear time with respect to the det/th oftlle query noun node  ( depth = 5 in the case of flood  #l ) and not the then mnber of nodes ill the network . This is important for scaling the network to represent the large nuin ber of nouns needed to accurately model tile selectional preferences of adjective senses  . Tile only cost incurred is storage for a summary probability of the children at each internlediate node and time for ut  ) dating these values when a new piece of evidence is added  , which is also linear with respec to the depth of the node  . 
Finally , the probabilities comt ) uted by the inference algorithn l are combilm d with the priors established in the earlier section  . Tile combined probabilities represent P ( adj#i \] adj , noun , < NFs >) , and tiltone with the highest probability is classified by BHD a stile most plausible sense of the adjective  . 
4.5 Evahmtion
To test the accuracy of BHD , the same procedure described earlier was used . Tile same 135 adjective-noun pairs from SelnCor were disambiguated by BHD and compared to the baseline  . Table 2 shows the accuracy results froln evaluating either the first sense of the nouns or all senses of the nouns  . The results of the accuracy without the priors Pr ( adj#i ) in-'I'?i?al )  2/-$  , S/cLm stx1/~
Illka , d1/8t tlood ) -1770 ~ x1/7xI/I Figure 3: ( ~ll2ryof ; he flr crtt#-I 1eliefnetw ) rl(t(infe . rl ; h ', probalility of tlood being mlifiedly . q ' reat#l . . The left branch of the network has 1' . enomitted for clarity . 
dicate ~ the imIrovements lrovided by the likelihotterm alone  . The it nlr(vement gain(~l from the ad-dii . ional conl ; extual featm : e shows th ( ~ ell ' ~: livm~ss of the belief networks , l !' ~ v ( m with only 3 trol ) tyt)-ica . lm mnslera(ljecl , ives e . nse ( navu ' ag ~ ( hardly a COml ) lete deseril ) tion of these l ( B ( : tional pr ( ff ( w ( u\]: ; s ) ; the gain is very encouraging . Wit ; h the 1) ri(rst'a:-toredin , 13 IIDim lr(ved even flu:ttmr (81%) , signifi-('antly surl lassing the baseline (75 . 6%) , a feata::om-plished 1) 3 ; rely ( me ( the rm del that we are aware ( f ( airi Sl ; el ; iIla and Nagao ,  1998) . Not ; ethai ; l ; h!l ) esl ~/ . C ; lll ; / ; y\v~lsa'hieved by evaluating all senses of th ~ ll  ( llllSISexi ) e:ted , since the sele : l ; iollalt ) r ~ . fer , Jl'e is model et l ; hrmghsenmnti (: feai ; mes(t " the glossary nouns , not just their word forms . The . r ; as m for the good accuracy from using only the tirst noun sense is because  72% of them halpen to be the first ; S0 , Il Se . r \]_ ~ heso results are very (' JH ; our agillg si\]lco11 otagged corl ) us and minimal training data were . used . 
\? e believe that with a bigger training set , \]3 HD'st ) erf(rnlance will imlrove even further . 
4 . 6 Colnl ) arison with Other Moh , JsrE ( ) our knwledge , there are rely two oLhers ysl ; enls that ( lisanfl ) iguate a . ( lj ~: tive-nomll lairs from unre-st . ri : l ; ell ; ex; . Results fl'om both models were evaluated against SemCor and thus a comparison is meaningful  . In Table 3 , each model's accuracy ( as well as \' Vithoutlh ' ior
With 1 l . ir
Context 11 Ol 111 only + SP 11 Ol 111 olly + SP 1 . stIIOlll
SOIISO 56.3% 6O . O % 77.8% 80.% all noun
SBIIH(~S 53.3% 60.0% 77.8% 81.4%
Baseline 75.6% 75.6%
Ta . 1le 2: Accuracy results from these leetional preference model  ( + SP )   , showing the improvements over the baseline by either considering the first llOll Il sense or all noun senses  . 
Model Results \ [ Baseline
HII I ) 81.4% 75.6%
Mihah:ea and Moldovan 79.8% 81.8% (1999)
SW.tinael ; al . (1998) 83.6% 81.9%
Table 3: Colnt/arison of at ljectiv ( ~ disaln liguation at : - curay with otheri node ls . 
lhebaseline ) is provided since different adjet:tive-noun pairs were e  , valuated . We find t ; he BIt \]) re-suits conlpa . ralfle , if not bel ; ter , espcc , ially when i he Illl Olll ; Of in q ) roven w , nl ; () vetth 0 , \]) ase lineise on si(l-ered . The Ino < lel1)3,, SI ; e , l ; in a(1 . 998) was , rai\]md tmSemCor that was merged with a flfll senl  ; ential parse tree , the determination of which is considered a difficult l  ) rolflem of its own ( Collins ,  1997) . \ Vebelie , rethai ; by int : or ioral ; ing tim data from SemC(n(dis-(:llSse(lillI ; hefllI ; llreworks c , ct;ion ) ~; 11 o , \] erforlllllCe(ffoursysi ; em will surpass Stetina's . 
5 Conclusion and Future Work
We have 1) resenl ; et lat ) rol~flilistic disanfliguation model that ixsys l ; e , ln~l;i , , a(tcllral;e , all ( l requirell Hlll-ual intervention ill only ill two places  . The more l ; illle(:OllSlllllill ~ of timl ; wo manual l ; asks is to ( :\] as-sitS'th ( ~ toll100 nouns needed for the priors . The el ; her task ~ of disanfl ) igual ; ingl ) rol ; olTpicallOllllS , is relal ; ively simple due to the limited nunfl ) er of glossary nouns per sense . I Iowever , it would le straightforward to incorporate semantically tagged corpora  , such as SemCor , to avoid these mamml tasks . The priors are the number of instances of each adjective sense divided by all of the adjectives in the corpus  . 
The disambiguated adjective T~i-noun # . \] pairs from the corpus e an be used as training sets to build bet-e  , rret/resental ; ion of selectional preferences ly inserting tim noun T ~ j node mid the ac  ( : omfany feat m'es into the lelief network of aljective gfii  . The insertion is the same prot:c/hue used to add the hyllo the  ; ical evidence dm ' ing the infer oncing stage . The Ul ) ( lated belief networks could then be , used tbr disambigua-lionwii ; him prove . dat:curacy . Furthernlore , the performance of BIID (: ( mida . l so be improved by exl ) and-such as the EM algorithln ( DemI ) ster et al ,  1977) . 
Using Bayesian networks gives the model ttexibility to incorporate additional contexts  , such as syntactical and morphological features , without incurring exorbitant costs . 
It is l ) ossible that , with an extended model that accurately disambiguates adjective-noun pairs  , the selectional preference of adjective senses coutd be automatically learned  . Having all improved knowledge al ) out the selectional 1 ) references would then provide better parameters for disanfl  ) iguation . The model can be seen as a bootstrapping learning process tbr disambiguation  , where the information gained from one part ( selectional preference ) is used to improve tile other ( disambiguation ) and vice versa , reminiscent of the work by Riloff and Jones (1 . 999) and
Yarowsky (1995).
Lastly , the techniques used in this paper could be scaled to disambiguate not only all adjective-noun pairs  , but also other word pairs , such as subject verb , verb-object , adverb-verb , y obtaining most of the paraineters from the Internet and WordNet  . If the information fi'olnSemCor is also used , then the system could be automatically trained to pertbrm disambiguation tasks on all content words within a 

In this paper , we have addressed three of what we believe to be the main issuestimed  1  ) y current WSD systems . We demonstrated the effectiveness of the tecl miques used  , while identii ~ ying two mmmal tasks that don't necessarily require a semantically tagged corpus  . By establishing accurate priors a . nd small training sets , our system achieved good initial disambiguation accuracy  . The salne methods could 1 ) eflfly automated to disami ) iguate all content word pairs if infbrmation from semantically tagged corpora is used  . Our goal is to create a system that can disambiguate all content words to an accuracy level sufficient for automatic tagging with tummn validation  , which could then be used to improve or facilitate new probabilistic semantic taggers accurate enough for other NLP applications  . 

Eneko Agirre and German Rigau .  1996 . Word sense dismnbiguation using conceptual density  . In Proceedings of COLING96, Copenhagen . 
Michael Collins .  1997 . Three generative , lexicalised models for statistical 1) arsing . In Proceedings of the 351h Annual Meeting of the ACL , pages 1623 , Madrid , SI ) ain . 
A . P . Dempster , N . M . Laird , and D . B . Rubin .  1977 . 
Maximum likelihood from incomplete data via the EM algorithm  . Journal of the Royal Statistical
Society , 39(B):138.
Sadao Kurohashi Jiri Stetina and Makoto Nagao.
1998 . General word sense disambiguation method based ollafl flsentential context  . In Proceedings of COLINGACL Workshop on Usage of WordNet in Natural Language Processing  , Montreal , 
Canada , . July.
Rada Mihalcea and Dan Moldovan .  1998 . Word sense disambiguation base ( ! on semantic density . 
In Proceedings of COLINGACL Workshop on Usage of WordNct in Natural Language Proecssing  , 
Montreal , Canada , July.
G . Miller , C . Leacock , and R . Tengi .  1993 . A semantic concordance . In Procccdings of ARPAI\]u Tnan
Language Technology , Princeton.
G . Miller .  1990 . WordNet : An online lexical database . International Journal of Lexicography , 3(4:) . 
Hwee Tou Ng and Hian Beng Lee .  1996 . Integrating inultiple knowledge sources to disambiguate word sense : An exemplar-based approacl LIn Proceedings of the  3/tth   , Annual Meeting of ACL , Santa
Cruz , June.
Judea Pearl .  1988 . Probabilistic Reasoning in Intelligent Systems : Networks of Plausible Inference  . 
Morgan Kaufmalm , San Mateo , CA.
Philit ) Resnikan (1 David Yarowsky .  1997 . A perspective ellword sense disambiguation methods mid their evaluation  . In ANLP Workshop on Tagging Text with , Lexical Semantics , Washington , 
D . C ., June.
Philip Resnik .  1997 . Selectional preference and sense disambiguation . In ANLP Worksh . op on Tagging Text with , Lcxical Semantics , Wash , ing-ton , D . C . , June . 
Ellen Riloff and Rosie Jones .  1999 . Learning dictionaries fbr information extraction by multilevel bootstrapping  . In Proceedings of AAAI-O9, Oflando , Florida . 
aanyce Wiebe , Tom O'Hara , and Rebecca Bruce.
1998 . Constru ( : tingbayes ia networks from WordNet for word sense disambiguation : I/  . el ) resent a-tional and I ) rocessing issues . In Proceedings of COLINGACL Workshop on Usage of WordNct in Natural Language Processing  , Montreal , Canada , 

David Yarowsky .  1992 . Word-sense disambiguation using statistical model of Roget's categories trained on large corpora  . In Proceedings of
COLING-92, Nantes , France.
David Yarowsky .  1995 . Unsupervised word sense disambiguation rivaling supervised methods  . In Proccedings of the 33rd Annual Meeting of the


