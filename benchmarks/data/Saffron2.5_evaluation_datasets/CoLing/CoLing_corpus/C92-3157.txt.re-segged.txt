From Detection/Correction to Computer Aided Writing 
Damien GENTHIAL , Jacques COURTIN
Laboratoire deg ~ nie informatique-ImagCampus- BP53X 
F~38041 GRENOBLE CEDEX-France
Phone : (33) 765 14878
FAX:(33) 764 466 75
E-Mail : genthial@imagfr
court in@imagfr

Laplup art destextes actuel sont produits ous form e  61ectronique hl ' aide de syst ~ mes informatiques qui four nissent des  facilit6s demanipulation dechMnesma is aussides out ils linguistiques : correcteur d ' orthographe  , dictionnaire voire v Erificateur grammatical . 
Nouspensons qu ' unsyst ~ med ' aide ~ tlared action dolt  6tre conqucomme unenvironnement complet pour la production  , lama intenance , l ' Edition et la communication destextes . Cecisuppose par exemplel ' utilisation d ' un gestionnaired'id Eeset de dictionnaires pour la production  , d ' un 6diteur detexteset dev Erifi cateurs linguistiques pour lama intenance  , d ' untraitement detextes pour l ' Edition et d'une lbrme normal is depourla communication  . 
Alasuite denostravaux surla detection et la correction deserreurs  , nous proposon sune architecture Iogicielle capabled ' in t fgrer demanibre uniforme no sout ils linguistiques  ( analyse etgEnE ration morphologique , techniques decorrection lexical e , analyseet verification syntaxique ) ainsique des out ils detraitement detexte , d ' Edition et d ' exportation de documents . Cesoutils sont conqus comme des modules sp ~cialis Esdisposes autourd'une structure de donn Ees unique qui constituela representation interned utexte  . Cette structure est untreillis multidimensionnel quitraduitla  linEarit6 maisaussila structure tlesambigu'ft~sdu text e  . Elleest comp Mt Eepa run lexique ba ~ surdes structures detraits typEesquicontiennentles informations morphologiques  , syntaxiquests Emantiques asoci Ees auxmots . 
La distribution de la competence globaled usyst ~ medans des module spfcialis~s facilites a maintenance et  , surtout , permetle partage descompE tences locales entre les modules  , cequies ttr~s important pour les modules linguistiques  ( lev Erifi cateur syntaxique , pare x emple , requiert presque to usles autres modules linguistiques : morphologie  , phon~tique , syntaxe ) . 
AcrEsDECOLING-92 . NAI qlE . S . 2328 AOt ~' r 1992 1013 PROC . OFCOLING-92 . NANTES , AUO .  2328, 1992

Most texts nowadays are produced in an electronic form by the use of systems which provide text processing facilities but also linguistic facilities such as spelling checkers  , online lexicons and even syntactic heckers . 
We think that a computer-aided writing system must be designed as a complete environment for the production  , maintenance , dition and communication of texts . This implies for example the use of an ideas manager and online lexicons for production  , a text editor and linguistic verifiers for maintenance  , a text processor for edition and a standardized form for communication  . 
Following our work on detection and correction of errors  , we propose an architecture of a system able to integrate in a uniform way our linguistic tools  ( morphological parsing and generation , lexical correction techniques , syntactic parser and verifier ) as well as tools for text processing and document editing and exporting  . Tools are designed as specialized modules disposed around a unique data structure  , which is the intemal representation of the text . This structure is a multidimension all attice , coding the linearity but also the structure and the ambiguities of the text  . It is completed by a lexicon based on typed feature structures encoding morphological  , syntactic and semantic information on words . 
The distribution of the competence of the system in specialized modules permits an easier maintenance of the system itself but  , moreover , allows competence sharing among the modules , which is very important for the linguistic ones ( for example the syntactic verifier needs to use a hnost every linguistic module : morphology  , phonetic , syntax ) . 
1, Introduction
In their life cycle from creation to publishing , all texts nowadays take an electronic form . Most of them arc directly produced in this form and take the paper form only for publishing  . Thus a lot of services can be provided to the writer who uses a computer to produce his texts  . This idea is not new but , following our work on detection and correction of errors  , we think it must be investigated more deeply than it has been  . 
We first introduce what we mean by computer aided writing  . We then propose an architecture for a computer aided writing environment and quickly describe its modules  . We outline one of its main characteristics ( limited at a structures )  , and finally justify the second one ( distribution of services ) in the light of our work on detection and correction of errors  . 
2. Computer Aided Writing ( CAW)
A computer system for a writer is basically a personal computer which runs a text processor  , the power increase of personal computers has been followed by the growth of services provided to the user  . Some of these services aim to increase the writers productivity but most of the maim to obtaining a better quality of produce documents  . We will distinguishere between two categories of services : presentation services and production services  . The fwst ones concern the way the paper form of the text looks : justification  , formating , multicolumn . . . 
They are very powerful in modem systems , especially if you add to your text processor a graphic processor and a page maker  , but they have little to do with linguistics and so we will not discuss them here  . 
The second ones concern the text itselt , in its content and in its form . The best known and most achieved service in this category is the spelling checker  , which can be found in every modern text processor  . Recently , other services have emerged : ? online lexicons with synonym and antonym links  ; ? idea managers which help the user to build the plan of his document  ; ? syntactic heckers in the spirit of the IBM system CRITIQUE  \[6\]  . 
In most cases , these new services are add-ons to an existing text processor and CAW systems are stacks of tools  , lacking the coherence of an integrated approach . 
Our idea is that CAW must be thought of as a goal in itself and our aim is to build an environment for the production  , maintenance , edition and communication of texts . Such a system will be based on a coherent set of software tools reflecting the state of the art in string manipulation and linguistic treatment  . At a first glance , the system should include classic and wellknown tools such as those cited above and more sophisticated tools like : ? morphological nalysis and generation  , which can for example be used for lemmatization f words or groups of words  . The idea here is to use these lemmatized groups askeys to access external knowledge bases or document bases  \[91  . 
? syntactico-semantic analysis and generation to allow operations like : changing the tense of a paragraph  , changing the modality of a sentence , help in detecting ambiguous phrases and in disambiguation by proposing paraphrases  . There is also the possibility of generating a definition of a word on the basis of its formal description i the lexicon  . 
ACRESDECOLING-92, NANTES . 2328 A OtYr 1992 l0i4PROC . OFCOLING-92, NANTES . AUG .  2328 , 1992 ? lexical and syntactic checkers , which must also be able to propose corrections , by the use of all the linguistic knowledge included in the system  . 
? structural manipulations of the text in the spirit of idea managers but also some verifications on the structure by the use of a grammar of the text  , which depends on the type of document created . For example , a software documentation will include a user manual and a reference manual  , the user manual will include an installation chapter  , a tutorial introduction chapter . . . . . 
? interface with the outside world : that includes of course the production of a paper form of the text but also  , at least as important as the former , the production of the text in some standardized form  ( for example the form caracteristics are the use of a minimal number of data structures and a distributed architecture  . 
We will here quickly describe the role of each module  , leaving for the next two sections the discuss ion about data structures and architectural choices  . 
The proposed system is primarily built for French but every module has been designed to be as general as possible  , and is completely configurable , so that it can be used for other languages . 
Each module is viewed as a server which is able to provide some service  . Following our work on detection and correction of errors  , many modules are dedicated to this sort of task . 
Given an incorrect word , the similarity key module is able to produce a list of correct words Fi \ [ ure  1: Architecture of a CAW environment recommended by the TEl  \[8\]  ) which can travel on networks and be legible by most software  . This lorm can also be used to store the text in databases or top assit onto other software  . A very interesting type of software could be an automatic translator  , so that a text could be created in one language and published in one or more other languages  . 
Such a system is a long term objective and we will see in the next section an architecture which makes possible a short term full implementation  , while being open for future extensions . 
3 . Architet ~ ure of a CA Wenvironment Figure 1 describes the architecture of tile CAW system under development in our team  . Its which are possible corrections of the incorrect one  . It is well-suited for typographic errors . 
The phonetic graphic transducer plays the same role by using the phonetic invariant of words  . It is well-suited for spelling errors . 
The morphological module can also be used for lexical correction  \[3\] but its main purpose is to produce an input for the syntactico-semantic parser  , which is in charge of building a decorated structure of the sentences of the text  . 
The parser we use is a dependency-tree transducer designed as a robust parser  \[4  ,  5\] . 
The syntactic hecker is in charge of verifying agreement rules in sentences  \[7\]  . 
The multipurposelxicon contains all lexical information and furnishes access tools  ( see next section )  . 
ACRESDE COLING-92 , NAMES , 2328 hOt~q19921015PROC . ov COLING-92, NAr ~' rl . ;s , AUG .  2328 ,   1992 The text processor provides string E very module can read or write in this lattice  ; manipulations while the edition communication for example  , the corrections prOduced by lexical module gives a paper or communicable form of correctors can be added as multiple the text  . 
The structure manager is in charge of global interpretations of a word  . 
manipulations on the surface structure of the text  ( chapter , sections ,  . . . ) and of the much more difficult task of verifying the internal coherence  ( there is an introduction , a development , a conclusion ,  . . . ) . 
Finally , the control and user interface module assumes the synchronisation and communication between modules and the transmission of user orders  . 
The correctors , the syntactic checker , the morphological parser and generator , the syntactico-semantic parser are all operational on micro-computers  . At the moment , the lexicon is a roots and endings dictionary (35 , 000 entries , generating 250 , 000 forms ) with only morphological information on words , but its extension is under development . Figure 2: Example of a lattice 4 . Data Structures 4 . 2 . Lexicon 4 . 1 . Blackboard Amain caracteristic of our system is the use of an internal representation f the text in the form of a multidimension all ttice  ( inspired by \[2\] ) which play the role of a blackboard for all the modules  . 
Each node of the lattice bears information on a piece of text  , and we propose that they all have the same structure : each node bears a tree  ( sometimes limited to the root ) and each node of the tree bears a typed feature structure  ( a ~ t '- term , see ?4 . 2) . We can imagine that the lattice is initiated by the flow of characters which come from the text processor  , thus the word " Time " will become : For performance problems  , it seems more reasouable to initiate the lattice with the lexical units resulting from the morphological parsing of the text  . With the sequence of characters " Time flies . . . " , we will obtain the bottom four nodes of the figure  2 lattice . 
We can see two dimensions of the lattice on this example : a sequential dimension  ( " time " is the first word and is followed by the second word " l\]ies "  )  , and an ambiguity dimension ( both words have two possible interpretations )  . 
A third dimension appears when the syntactic parser starts its work  . It produces new lattice nodes which bear dependency trees  . With the lattice above , the syntactic parser will add the two top nodes ( figure 2 )  . 
We think it is very important , for the coherence of the knowledgembedded in the system  , that all lexical information be contained in a unique dictionary  . Multiple access and adapted software tools will extract and present the information to the user in different forms  , for example the natural language form of a formal entry may be computed by the syntactic generator  . 
To represent knowledge associated with words , we have chosen typed-feature structures called w -terms  \[1\]  . With these structures , basic concepts are ordered in a hierarchy which can be extended to whole structures  . Thus we can determine if a ' e-term is less than another and the unification of two hU-temls is the biggest ~ t'-term which is less than both unified ones  . In other words , the unification of two terms is the most general term which synthesizes the properties of both unified ones  . This caracteristic is very interesting for the implementation f paradigms : a paradigm is the representative of a class of words and contains the information which describes the behaviottr of a word  . We distinguish three types of paradigms : morphological  , syntactic and semantic . 
Morphological paradigms bear the category of the word and a few linguistic variable such as gender and number  . Syntactic paradigms contain information about the function of the word within its context  . The aim is to code subcategorization f words , and it is very important for verbs but also for nouns and some Ac'r~DE  COLING-92  , NAN rES . 2328 Ao(;r 1992 1016 Ptoc . OFCOLING-92 . NANTES . AUG .  2328 . 1992 adjectives . A semantic paradigm is the semantic concept associated with the word or the logical structure in the case of predicate words  . 
Examples of paradigms :
I , Ust and for Lexical Unit , NP for Nominal
Phrase and Ptar Proposition.
baby : morphological
LU(cat->cnoun ; gender=>masuculin ; feminine \] ; number > singular ) baby : syntactic
LU(syn => NP ) baby:semantic
LU(sent > HUMAN ) choose : morphological
LU(cat=>verb ) choose:syntactic
LU(syn :> P ( subject = >
NP(sere=>ANIMATE ); object ->
NP(sere->OBJHCT )) choose:semantic
LU(sere->CHOOSE(agent=>ANIMATE ; choice => OBJECT )) For a verb like rain , we can be more precise in the syntactic paradigm : rain : syntactic hUsyn => P  ( subject : ->
NP(cat->\[~ers pronoun ; person : > 3 ; nun Joer -> singular ; lex->"it " )   ) Each entry in the lexicon contains a key , which is used to access the entry , and a reference to a paradigm of each type . In order to allow information sharing between " v -terms  , we add to the entry an optional list of equational constraints  . For example , for ehoose , we have : syn . subject , sere-sem . agent : and syn . object . sem=sere . choice saying that usually the subject of the verb is its agent and the object is the choice  . The result of morphological parsing of a form is the unification of the three paradigms of each lexicon entry used  . For example , for the form chooses , we use the root choose and the endings ( which add the features person and number to the paradigms of the verb  ) thus we obtain :
LU(cat=>verb ; person->3 ; number > singular ; syn > P ( subject : ->
NP(sem>@S:ANIMATE ); object ->
NP(sem=>@O:OBJECT) ; sere->CHOOSE(agent :=>@ S ; choice =>@ O ) ) where the notation @ X is used to write reference links  ( equational constraints )  . 
The idea behind paradigms is to allow a great factorization of knowledge : it is obvious for morphological paradigms  ( in the actual dictionary , we have only 400 paradigms for 250 , 000 forms ) and for syntactic paradigms ( the number of possible subcategorizations for verbs is far less than the number of verbs  )  . It is less obvious for semantic paradigms , especially if you want a very f'me description of a word : in this case  , there is almost a paradigm for each word . 
So the lexicon is essentially built around three , v-term bases , one for each set of paradigms . 
The bases are accessed by the roots and endings dictionary used by morphological tools  ( parser and generator )  , and we can easily add synonym and antonym links to this dictionary  . The key-form correspondence table , required by the similarity key correction technique cannot easily be embedded in this lexicon structure  , but we propose to append it to the lexicon so that any module requiring iexical information must use the multipurpose lexicon module  . This constraint is imposed in view of coherence : ach time a root is added to the main dictionary  , all key-form pairs obtainable from this root must be added to the table  . 
5. Distribution
Each module in our system must be viewed as a server which responds to request sent by any other module  . Such an architecture has the classical advantages of modular Stl Uctures : you can add or remove a module very easily  , you can modify a module in a transparent manner as long as you do not change its interface  . . . .
But this structure has another advantage which is very important in the context of linguistic treatments : the linguistic competence of each module can be exploited by the others  . We will use two examples to illustrate our purpose  . 
First , in detection and correction of lexical errors , we have implemented classical tools ( similarity key and phonetic )  . Then we decided to implement syntactic hecking , so we needed the services of a morphological parser  . We added to the system ( a prototype called DECOR ) our morphological tools , and the availability of these tools gave the idea of using them for detection and correction  , so we inrplemented a third technique of correction : morphological generation  . 
Example of correction using morphological g , ~ mmm:loots , although incorrect , may be parsed as foot+s , and the root foot , plus the variables ( plura / ) associated with the s , when passed onto the morphological generator , give the correct form feel . 
ACRESDECOLIN'G-92 , NANTES , 2328 AObq'1992 l0I7PROC . OFCOLING-92, NANTES , AUG .  2328 , 1992 As a second example , consider the problem of proposing correction for agreement errors : when an error occurs  , it means that at least two words do not agrees o there are at least two possible corrections depending on which of the two words you choose to correct  . The solution for the system is to propose both corrections to the user and let him choose one  . Even this simple method requires linguistic service : a morphological generator is necessary to produce each correction  . 
But we think that in most cases the good correction can be choosen automatically  , according to criterions I such as those considered by \[  10\]: ? number of errors in a group : little cat are funny pets must be corrected little cats are funny pets rather than little cat is funny pet  ; ? it is better to correct in a way which does not modify the phonetic of the phrase  , We give here a French example2: Leschiens dress ~ es .   . , will be corrected Leschiens dresses . ., rather than Les chiennes dress~es .   . .
? one can give priority to the head of the phrase : cat which are  . ., becomes cat which is . . . ; ? writer laziness : a writer sometimes omit an s where one is necessary  , but rarely add one where it is not . 
Such criterions are sometimes contradictory and we propose to use an evaluation method which gives a relative weight to each criterion so that each possible correction has a probability of being correct  . The user is asked for a choice only in cases where both corrections have equivalent probability  . 
But , whatever strategy is implemented , it needs the cooperation of various linguistic modules in order to perform the evaluation : phonetic transducer  , morphological parser and generator , and our architecture permits the use of the available ones  . 
Finally , beyond linguistic justifications , one can find computational justifications : each module of the system can work in parallel with the others and they can even work on different computers  , putting the distribution at a physical level . 
INote that these criterions are pertinent for French  , where there are a lot of agreement rules ( between oun , adjectives and detenniner , between subject and verb ,  . . . )  2An similar english example might be The skiss lides wich is corrected The skislides rather than The skisslide  . 
6. Conclusion
As sophisticated linguistic treatments are expens we in time and space  , we think it is very important , that a CAW system should integrate all treatments and knowledge in a uniform way  . 
It makes it easier to take advantage of the whole knowledge in each service involved in order to provide very powerful services  . This power of the services is a mean to compensate  , for a potential user , the lack of ergonomy due to poor performance : a system which can build the multidimension all ttice in realtime does not seem a realistic goal for the near future  . 
As a typical application for our system , we think of the production of the technical documentation f an industrial product : as there are for example software engineering envi ronments  , we propose linguistic engineering ones . In such a context it is possible to add structure services  , more powerful services at the semantic level and interface with other software such as an automatic translator  . 
References\[1\]AitKaci(H . ) , A Lattice-Theoretic Approach to Computation Based on a Calculus of Partially-Ordered Type Structures  . Ph . D . Thesis-Computer and Information Science , Univ . of Pennsylvania,
Philadelphia , USA , 1984\[2\] Boitet(C . ) , Representation ad computation of units of translation for Machine Interpretation of spoken texts  . GET A&ATR Tech . Report TR-1-0035, Auguster reurs lexicales . Th~seCNAM , Grenoble , Mars 88\[41 Genthial(D . ), Courtin(J . ), Kowarski ( I . ) , Contribution of a Category Hierarchy to the Robustness of Syntactic Parsing  . 13th CoLing , Helsinki , Finland , August 1990 , Vol . 2, pp 139-144\[5\] Genthial(D . ) , Contribution dla construction d ' unsyst dme robusted ' analysedu franfais  . Th ~ sede I ' universit ~ Joseph Fourier , Grenoblei , Janvier 1991\[61 Richardson(S . D . ) , Enhanced Text Critiquing using a Natural Language Parser : the CRITIQUE System  . 
IBM Research Report RC11332, Yorktown Heights,
USA , 1985\[7\] Strube de Lima(V . L . ) , Contribution d 1'ttude dutraitement deserreurs a univeau lexico -symaxique donsuntexte  6crit enfranfa is . Th~sedel ' Universitt ~ Joseph
Fourier , Grenoble I , Mars 1990\[8\]TEl(TextEncoding Initiative) , Guidelines for the Encoding and lnterchange of Machine Readable Texts  . 
Computer Center MC 135 , University of Illinois at Chicago and Oxford University Computing Services  . 
\[9\] Tomasino(1 . ) , ODILE : UnOutild ' lnt~grationExtensible de Dictionnaire set de Lemmatiseurs  . 
CNAM . Grenoble , l~c . 90.
\[10\]V ~ ronis(J . ) , Morphosyntactic correction in natural language interfaces  . 12th CoLing , Budapest , Hungary,
August 1988, pp 708-713
AC'TES DECOLING-92 . NANTES , 2328 AO~q'1992 1018 PROC . OFCOLING-92 . NANTES , AUG .  2328, 1992
