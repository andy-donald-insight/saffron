On compositional semantics
WIodek Zadrozny
IBM Research
T . J . Watson Research Center
Yorktown Heights , NY 10598
WLODZ@WATSON . 1BM . COM
Abstract . We prove a theorem stating that any semantics can been coded as a compositional semantics  , which means that , essentially , the standard definition of compositionality is formally vacuous  . We then show that when one requires compositional semantics to be " systematic "  ( that is the meaning function cannot be arbitrary , but must belong to some class ) , one can easily distinguish between compositional and non-compositional semantics  . We also present an example of a simple grammar for which there is no " systematic " compositional semantics  . This implies that it is possible to distinguish " good " and " bad " grammars oll the basis of whether they can have compositional semantics  . 
As a result , we believe that the paper clarifies the concept of compositionality and opens a possibility of making systematic omparisons of different systems of grammars and NLU programs  . 

Compositionality is defined as the property that the meaning of a whole is a function of theme -aning of its parts  ( cf . e . g . Keenan and Faltz (1985), pp . 24-25) ? This definition , although intuitively clear , does not work formally . For instance , Ilirst (1987) pp . 27-43 claims that the semantics of Woods ( 1967 ) and ( Woods ,  1969) , is not compositional , because " the interpretation of the word depart varies as different prepositional phrases are attached to it ": 
AA-57 departs from Boston=>depart ( aa-57 , boston ) . 
AA-57 departs from Boston to Chicago => connect ( aa-57 , boston , chicago ) . 
AA-37 departs from Boston on Monday=>d day ( aa-57 , boston , monday ) . 
AA-57 departs from Bostonat8:00a,m.
=> equal(dtime(aa-57, boston ), 8:00 am).
AA-57 departs from Boston after 8:00 a.m.
=> greater(dtime(aa-57, boston ), 8: l10am).
AA-57 departs from Boston before 8:00 a.m.
=> greater(8:0Oam , dtime(aa-57, boston )).
Although this semantics does look like noncompositional  , it is easy to create a function that produces the meanings of all these sentences from the meanings of its parts -- we can simply define such a function by cases : the meaning of departs ~ from / is connect  , the meaning of departs/from/on isdday , and so on . Hirst therefore changes the definition of compositionality to " the meaning of a whole is a Ly stematic me-aning of the parts "  ( op . cit . p . 27 . ; tile emphasis is ours ) , but without defining the meaning of the word " systematic  . " in this paper we show that , indeed , tlirst was right in assuming that the standard efinition of compositionality has to be amended  . Namely , we prove a theorem stating that any semantics can been coded as a compositional semantics  , which means that , essentially , the standard efi-nition of compositionality is formally vacuous  . 
We then show that when one requires composi-An equivalent definition  , e . g . Parte et al .  (1990) , postulates the existence of a homomorphism from syntax to semantics  . 
ACTESDECOLING-92 , NAN rEs , 2328^Ot~T 1992 260 PROC . OFCOLING-92, NANTES , AUO .  2328 , 1992 tional semantics to be " systematic " ( i . e . theme-aning function must belong to some class ) , one can easily distinguish between compositional and noncompositional semantics  . We also give an example of a simple grammar lor which there is no " systematic " compositional semantics "  . 
This result implies that it is possible to distinguish " good " and " bad " grammars on the basis of whether they can have a compositional semantics with a meaning function belonging to a certain class  . As a result , we believe that the paper finally clarifies the concept of compositionality and opens a possibility of making systematic comparisons of different systems of grammars and NLU programs  . 
2 . Some compositional meaning function can always be found Compositional semantics  , or CS , is usually defined as a functional dependence of the meaning of an expression on the meanings of its parts  . One of the first natural questions we might want to ask is whether a set of NL expressions  , i . e . a language , can have some CS . 
This question has been answered positively by van Benthem  ( 1982 )  . t to wever his result says nothing about what kinds of things shouk l be assigned e  . g . to nouns , where , obviously , we would like nouns to be mapped into sets of entities  , or something like that . That is , we want semantics to encode some basic intuitions  , e . g . 
that nouns denote sets of entities , and verbs denote relations between entities , and so on . 
So what about having a compositional semantics that agrees with intuitions ? That is  , the questions is whether after deciding what sentences and their parts mean  , we can find a function that would compose the meaning of a whole from the meanings of its parts  . 
The answer to this question is somewhat dis -turbing  . It turns out that whatever we decide that some language x pressions should mean  , it is always possible to produce affmction that would give CS to it  ( see below toramore precise formulation of this fact  )  . The upshot is that compositionality , as commonly defined , is not a strong constraint on a semantic theory . 
The intuitions behind this result can be illustrated quite simply : Consider tile language of finite strings of digits from  0 to 7  . Let's fix a random function ( i . e . an intuitively bizar refunction ) from this language into 0 , 1) . Let theme-aning function be defined as the value of the string as the corresponding number in base  8 if tile value of the function is 0  , and in base 10 , otherwise . Clearly , the meaning of any string is a composition of the meanings of digits  ( notice that the values of the digits are the same in both bases  )  . But , intuitively , this situation is different fi'om standard cases when we consider only one base and the meaning of a string is given by a simple l brmu larelizrring only to digits and their positions in the string  , The theorem we prove below shows that however complex is the language  , aqd whatever strange meanings we want to assign to its expressions  , we can always do it compositionally . 
One of the more bizar reconsequences of this fact is that we do not have to start building compositional semantics fbr NL beginning with assigning meanings to words  . We can do equally well by assigning meanings to phonems or even LETTFRS  , assuring that , for any sentence , the intuitive meaning we associate with it would be alhnction of the meaning of the letters from which this sentence is composed  . 
PROVINGEXISTENCEOFC ( ) MPOSI-
TIONAL SEMANTICS
Let S be any collection of expressions ( intuitively , sentences and their parts ) . Let M be a sets . t . for any seS , there is m = m(s ) which is a member of Ms . t . n , is the meaning of s . We want to show that there is acmn positional semantics for S which agrees with the function associating m with re  ( s )   , which will be denoted by re(x ) . 
Since elements of M can be of any type , we do not automatically have ( for all elements of S ) ACqESDECOL 1NG-92 , NANTES , 2328 AO~r1992261 Pgoc . OFCOLING-92 . NAN rES . AUG . 2328, 1992m(s . t ) = m ( s ) #m ( t )   ( where  #is some operation on the meanings )  . To get this kind of homomorphism we have to perform a typeraising operation that would map elements of S into functions and then the functions into the required meanings  . We begin by trivially extending the language S by adding to it an ~ end of expression H character  $  , which may appear only as the last element of any expression  . The purpose of it is to encode the function re ( x ) in the following way : The meaning function tz that provides compositional semantics for Smaps it into a set of functions in such a way that l ~  ( s . t ) = t~(s)(#(t )) . We want that the original semantics be easily decoded from p  ( s )  , and therefore we require that , for all . s,I~(s . $) = re(s) . Note that such a typeraising operation is quite common both in mathematics  ( e . g . 1 being a function equal to 1 for all values ) and in mathematical linguistics . Secondly , we assume here that there is only one way of composing elements of S--by concatenation  2 but all our arguments work for languages with many operators as well  . 
THEOREM . Under the above assumptions.
There is a function ~ ts . t , for all s , #( s . t ) = #( s ) ( t t ( t )), and l~(s . $) = re(s) . 
Proof . See Section 5.1.
3 . What do we really want from compositional semantics ? In view of the above theorem  , any semantics i equivalen to a compositional semantics  , and hence it would be meaningless to keep the definition of e ompositionality as the existence of a homomorphism from syntax to semantics without imposing some conditions on this homomorphism  . Notice that requiring the computability of the meaning function won't do  . s Proposition . If the original function re(x ) is computable , so is the meaning function/~( x ) . 
Proof . See the proof of the solution lemma in
Aczel (1987).
3.1 What do we really want ?
We have some intuitions and a bunch of examples associated with the concept of compositionality  ; e . g . for NP->Adj N , we can map nouns and adjectives into sets and the concat-enation into set intersection  , and get an intuitively correct semantics for expressions like " grey carpet "  , " bluedog " , etc . 
There seem to be two issues here : ( 1 ) Such procedures work for limited domains like " everyday solids ~ and colors  ;   ( 2 ) The function that composes the meaning should be " easily " definable  , e . g . in terms of boolean operations on sets . This can be made precise for instance along the lines of Manaster-Ramer and Zadrozny  ( 1990 )  , where we argue that one can compare expressive power of various grammatical formalisms in terms of relations that they allow us to define  ; the same approach can be applied to semantics , as we show it below . 
3 . 1  , 4 s imple grammar without a systematic semantics If meanings have to be expressed using certain natural  , but restricted , set of operations , it may turn out that even simple grammars do not have a compositional semantics  . 
Consider two grammars of numerals in base 10:
Grammar ND ? N < -- ND ? N <-- D ? D <-0111213141516171819\  [
And the second grammar 2 We do not assume that concatenation is associative  , that is ( a . (b . c )) = (( a . h) . c ) . Intuitively , this means that we assign semantics to parse trees  , not to strings of words . But the method of proof can be modified to handle the case when concat-enation is associative  . 
Also , note that in mathematics ( where semantics obviously is compositional ) we can talk about noncomputable functions , and it is usually clear what we postulate about hem  . 
AL-TRSDECOLING-92, NANTES . 2328 AOUT 1992 262 PRoc . OFCOLING-92, NANTES , AUG .  2328, 1992
Grammar DN ? N < -- DN ? N < -- D * D < - -01112131415161718191 For the grammar ND , the meaning of any numeral can be expressed in the model  ( Nat ,  + , x ,  10 ) as # ( ND ) = 10x # ( N ) + u ( D ) that is a polynomial in two variables with coefficients in natural numbers  . 
For the grammar DN , we can prove that no such a polynomial exists , that is Theorem . There is no polynomial p in the variables #( D ) , ~(N ) such that#(DiV ) = p(p . ( D ) ,  # ( N ) ) and such that the value of # ( D N ) is the number expressed by the string DN in base  I0  . 
Proof . See Section 5.2.
But notice that there is a compositional semantics for the grammar DN that does not agree with intuitions : #  ( D N )  = 10 ? # ( N )  +/~ ( D )  , which corresponds to reading the number backwards  . And there are many other semantics corresponding to all possible polynomials in #  ( D ) and/I ( N )  . 
Also observe that ( a ) if we specify enough values of the meaning function we can exclude any particular polynomial  ;   ( b ) if we do not restrict the degree of the polynomial  , we can write one that would give any values we want on a finite number of words in the grammar  . 
Themoral is that not only it is natural to restrict meaning functions to  , say , polynomials , but to further restric them , e . g . to polynomials of degree 1 . Then by specifying only three values of the meaning function we can  ( a ) have a unique compositional semantics l br the first granmaar  ;   ( b ) show that there is no compositional semantics tbr tile second grammar  ( directly from the proof of the above theorem )  . 
4 . Conclusions 4 . 1 . Relevance for theories of grammar 4 . I .  1 . On reduction of syntax to lexieal meanings T . Wasow on pp . 204-205 of Sells ( 1985 ) writes : It is interesting that contemporary syntactic theorie seem to be converging on the idea that sentence structure is generally predictable from word meanings\[  . . . \] .  \[ . . . \] The surprising thing ( to linguist ) has been how little needs to be stipulated beyond lexical meaning  .  \[_ . \] The reader should notice that the meaning function minour main theorem is arbitrary  . In particular we can taker e ( s ) to be the preferred syntactic analysis of the strings  . The theorem then confirms the above observation : indeed  , the syntax can be reduced to lexical meanings . 
At the same time , it both trivializes it and calls out for a deeper explanation  . It trivializes the reduction to lexical meanings , since it also says that with no restriction on the types of meanings permitted  , syntax can be reduced to the meaning of phonems or letters  . The benefits of the reduction to lexical meanings would have to be explained  , especially if such meanings refer to abstract properties such as binding features  , BAR , or different kinds of subcategorization . 
It is the view of this author ( cf . Zadrozny and Manaster-Ramer (1997)) and , implicitly , of Fillmore et al (1988) , that such a reductionist approach is inappropriate  . But we have no room to elaborate it here . 
4.1.2. Ongood and bad grammars
By introducing restrictions on semantic functions , i . e . demanding the systematicity of semantics , we can for the first time formalize the intuitions that linguists have had for a long time about " good " and " bad " grammars  ( cf . Manast-er-Ramcr and Zadrozny (1992)) . This allows us A CrF~DECOLING-92 . NANTES , 2328 AOI3T 1992 263 PROC . of COLING-92 . NANTES , AUO .  2328 ,   1992 to begin dealing in a rigorous way with the problem  ( posed by Marsh and Partee ) of constraining the power of the semantic as well as the syntactic omponents of a grammar  . 
We can show for instance ( ibid . ) that some restrictions have the effect of making it in principle impossible to assign correct meanings to arbitrary sets of matched singulars and plurals if the underly in grammar does not have a unitary rule of reduplication  . Thus , grammars such as wrapping grammars ( Bach (1979)) , TAGs ( e . g . , Joshi (1987)), head grammars , LFG ( e . g . , Sells ( 1985 ) ) and queue grammars ( Manaster-Ramer ( 1986 ) ) , all of which can generate such a language , all fail to have systematic semantics for it . On the other hand , we can exhibit other grammars ( including old-fashioned transformational grammars  ) which do have systcm-atic semantics for such a language  . 
4.2. What kind of semantics for NL ?
In view of the above results we should perhaps discuss some of the options we have in semantics of NL  , especially in context of NLU by computers . To focus our attention , let's consider the options we have to deal with the semantics of depart as described in Section  1  . 
? Donothing . That is , to assume that the semantics is given by sets of procedures associated with particular patterns  ; e . g . " X departs from Y " gets translated into " depart  ( X , Y)" . 
? Give it semantics alaMontague , for instance , along the lines of Dowry (1979) ( see esp . Chapter 7) . Such a semantics is quite complicated , not very readable , and it is not clear what would be accomplished by doing this  . However note that this doesn't mean that it would not be computational--t to bbs and Rosensche in  ( 1977 ) show how to translate Montagovian semantics into Lisp functions  . 
Restric the meaning of compositionality requiring for example that the meaning of a verb is a relation with the number of arguments equal to the number of arguments of the verb  . If the PP following the verb is treated as one argument  , there is no compositional semantics that would agree with the intended meanings of the example sentences  . This would formally justify tile arguments of t lirst  . 
? Recognize that depending on the PPs the meaning of " X departs PP " varies  , and describe this dependence via a set of meaning postulates  ( Bernth and Lappin ( 1991 ) show how to do it in a computational context )  . In such a case the semantics is not given directly as a homomorphism from syntax into some algebra of meanings  , but indirectly , by restricting the class of such algebras by the meaning postulates  . 
* Admit that the separation of syntax and semantics does not work in practice  , and work with representations in which form and me-aning are not separated  , that is , there cannot be a separate syntax , except in restricted domains or for small fragments of language  . 
This view of language has been advocated by Fillmore et al  ( 1988 )  , and shown in Zadrozny and Manaster-Ramer (1997) , Zadrozny and Manaster-Ramer ( 1997 ) to be computationally feasible . 
? tiope that the meaning will emerge from non -symbolic representations  , as advocated by the " connectionists . " 5 . The proofs 5 . 1 . The Existence of compositional me-aning functions Let S be any collection of expressions  ( intuitively , sentences and their parts ) . Let M be a sets . t . for any s which is a member of S , there is m = m(s ) which is a member of Ms . t . m is the meaning of s . We want to show that there is a compositional semantics for S which agrees with the function associating m with m  ( s )   , which will be denoted by rn(x ) . To get the ho-Afzr~:s DECOLING-92, NANTES . 2328 AO13T 1992 264 PROC . OI~COLING-92 . NANTES , AUO .  2328 ,   1992 momorphism from syntax to semantics we have to perfbrmaty per aising operation that Would map elements of S into fhnctions and then the functions into the required meanings  . 
As we have described it in Section 2 , we extend S by adding to it the " end of expression " character $  , which may appear only as the last element of any expression  . Under these assumptions we prove : THEOREM . There is a function ~ ts . t , for all s , #( s . t ) = #( s ) ( t t ( t )), and ~( s . $) : m(s ) . 
Proof . Let /(0), 1(1) . . . . , t(a ) enumerate S . We can create a bigtable specifying meaning values for a U strings and their combinations  . Then the conditions above can be written as a set of equation shown in the figure below t  , ( t(0)) ~<$ , m(t(0)) > , < it(t(0)) , /t(t(0) . t(0)) > .   .   .   .   . <#( t(u )), it(t(O ) . t(a )) > . . . .  #( t(I )) ~  < $ , m(t(1)) > , < ~ t(t(0)) , /~(t(1) . t(0)) > .   .   .   .   . </~( t(~)), tt(t(I ) . t(a )) > . . . .  tt(t(a )) =  < $ , m(t(a )) > , <#( t(0)) , ~(/( a ) . t(0)) > .   .   .   .   . <#( t(a )), #( t(~) . t(a )) > . . . .  Continuing the proof : By the solution lemma ( Aczel ( 1987 ) and Barwise and Etchemendy ( 1987 ) ) this set of equations has a solution ( unique )  , which is a function . 
To finish the proof we have to make sure that the equation #  ( $ ) = $ holds . Formally , this requires adding the pair <$ , $> into the graph of tt that was obtained from the solution let mna  . 

We have directly specified the function as a set of pairs with appropriate values  . Note that that there is place for recursion in syntactic atego-ries  . Also , if a certain string dues not belong to the language  , we assume that the corresponding value in this table is undefined  ; thus  #is not necessarily defined for all possible concatenations of strings of S  . 
Note : The above theorem has been proved in set theory with the anti-loundation axiom  , ZFA . 
This set theory is equicon sistent with the standard system of ZFC  , thus the theorem does not assume anything more than what is needed for " standard mathematical practice "  . Furthermore , ZFA is better suited as foundations for semantics of NL than ZFC  ( Barwise and Etchemendy ( 1987 ) ) . 
5 . 2 . A grammar without compositional semantics Vor the grammar DN  , we can prove that no such a polynomial exists , that is 1qaeorem . There is no polynomial p in the variables #( D ) , #(N ) such that#(DIV ) = p(la(D) , I ~ ( N )   ) and such that the value of # ( D P0 is the number expressed by the string DN in base  10  . 
Proof . We are looking for ~(~~0 = p(u(~ ,  ~ ( O ) ) = # ( D ) x ( 1 ( ) tength ( ~ ) + p ( N ) where the function p must be a polynmnial in these two variables  . But such a polynomial does not exist , since it would have to be equal to # ( N ) for p ( N ) in tile interval 0 . .9, and to /~( D ) ? 10+/~(N ) for /~( N ) in 10 . .99 , and to #( D ) ? 100 + ~ t(N ) for ~ t(N ) in 100 . .999, and so on . And if the degree of this polynomial was less than l ~  , lbrsomen , it would have to be equal identically to / ~ ( D )  ? 10" +/~ ( N )   , since it would share with it all the values in l@ . .10 ~ - 1 , and therefore could not give correct values on the other intervals  . 
AcrEsDECOLING-92 , NANTES , 2328 AOl\]'r 1992 265 PROC . OFCOL 1NG-92 , NANTES , Au(L 2328 , 1992 Acknowledgements . A lexis Manaster Ramer brought to my attention the need to clarify the meaning of compositionality  , and commented on various aspects of this work . I also benefited greatly from a discussion with John Nerborme and exchanges of email with Feruando Pereira and Nelson Correa  . ( Needless to say , all the remaining faults of the paper are mine ) . 
Parts of this paper were written at the University of Kaisers lauter n  ; I'd like to thank Alexandery on Humbold tStiftung for supporting my visit there  . 
6. References
P . Aczel (1987) . Lectures on Non-Well-Founded Sets . 
Stanford , CA : CSLI Lecture Notes.
E . Bach (1979). Control in Montague Grammar.
Linguistic Inquiry , 515-531.
J . Barwise & J . Etchemendy (1987) . The Liar . New
York , NY : Oxford University Press.
A . Beruth & S . Lappin (1991) . A meaning postulate based inference system for natural anguage  . 
RC 16947, York townlteights , NY:IBMT.J.
Watson Research Center.
D . R . Dowry (1979) . Word Meaning and Montague Grammar . Dordrecht , Holland:D . Reidel . 
C . J . Fillmore , P . Kay , & M . C . O'Connor (1988) . 
Regularity and idiomatieity in grammatical constructions  . Language , 3, 501-538 . 
G . tlirst (1987) . Semantic interpretation and the resolution of ambiguity  . Cambridge , Great
Britain : Cambridge University Press.
J . llobbs & S . Rosenschein (1977) . Making computational sense of Montague's intentional logic  . 
Artificial Intelligence , 3, 287-306.
A . K . Joshi (1987) . An Introduction to Tree Adjoining Grammars : In A  . Manaster-Ramer ( Ed . ),
Mathematics of Language ( pp . 87-114).
Amsterdam/Philadelphia : John Benjamins.
E . L . Keenan & L . M . Faltz (1985) . Boolean Semantics for Natural Language . Dordrecht,
Holland : D Reidel.
A . Manaster-Ramer (1986) . Copying in Natural Languages , Context-Freeness , and Queue G-tam-mars . Proc . ACL'86, 85-89 . 
A . Manaster-Ramer & W . Zadrozny (1990).
Expressive Power of Grammatical Formalisms ( Proceedings of Coling-90 )  . tlels in k i ,
Finnland : Universitas ltel singiens is.
A . Manaster-Ramer & W . Zadrozny (1992) . Systematic Semantics . in preparation . 
B . H . Partee , A . t . Meulen , & R . E . Wall (1990) . 
Mathematical Methods in Lingusitics . Dor-dreeht , The Netherlands : Kluwer . 
P . Sells (1985) . Lectures on Contemporary Syntactic Theories . Stanford , CA : CSL Ilecture Notes (3) . 
J . van Benthem (1982) . The Logic of Semantics : In
Fred Lanman & Frank Veltman ( Eds.),
Varieties of Formal Semantics . Dordrecht,
Holland : Foils.
W . A . Woods (1967) . Semantics for a question answering system . Harvard University . 

W . A . Woods (1969) . Procedural semantics for a question answering machine  . AFIPS conference proceedings , 33, 457-471 . 
W . Zadrozny & A . Manaster-Ramer (1997a ) . The Significance of Constructions . ubmitted . 
W . Zadrozny & A . Manaster-Ramer (199~) . As sem-bling Constructions . ubmitted . 
ALT ~ DECOLING-92 , NANT ~ , 2328 AOt3"r1992266 PROC . OFCOLING-92, NANTES , AUG .  2328, 1992
