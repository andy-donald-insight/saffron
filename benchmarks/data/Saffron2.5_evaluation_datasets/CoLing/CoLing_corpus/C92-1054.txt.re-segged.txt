Redundancy in Collaborative Dialogue
Marilyn A . Walker
University of Peimsylvania , Computer Science Dept . *
Philadelphia , PA 19104
lyn@linc.cis.upenn.edu
1 Introduction
It seems a perfectly valid rule of conversation ot to tell people what they already know  . Indeed , Grice's QUANTIT Yll laxim has often been interpreted this way : Do not make your contribution more informative than is required\[f  \]  . Stalnaker , as well , suggests that to assert something that is already presupposed is to attempto do something that is already  done\[14\]  . Thus , the notion of what is informative is judged against a background of what is presupposed  , i . e . propositions that all conversants assume are mutually known or believed  . These propositions are known as the COMMON GROUND\[10  ,  5\] . 
The various formulations of this ' no redundancy ' rule permeate many computation alnalyses of natural language and notions of eo operativity  . However consider the following excerpt from the middle of an advisory dialogue between II arry  ( h )  , a talks how host , and Ray(r ) his caller 1 . 
Example 1: (6) r.u h2 tax qunstion u.
on u : since April 81 we have had an 85 year old lother living ~ it hus . 
her only income has been social security plus approximately  $3000 from a certificate O ~ deposit and i wonder what Js the situation as far as claiming her as a dependent or does thag in come from the certificate of deposit rule her out as a dependent ?  ( 7  ) h . yes it does . 
(8) r . ITDOES.
(9) h.?UPTHATKHfl CKSHEROUT.
In standard information theoretic terms , both (8) and (9) are REDUNDANT . Harry's assertion in ( 9 ) simply paraphrases what was said in ( 7 ) and ( 8 ) and so it * This researcll was partially funded by AltOgrmat  DAAL03-89-00031PRI and DARPA grant N00014-90~J-1863 at the Uni-vernity of Pem~ylvania , by Hewlett Packard , U . K . , and by art NSF award for 1991 Summer\[rmtitute in Jalmn 1 Thee examples comeft ~ m the talks how for financial advice  , 6' peaking o/Y our Money , on WCAU in Philadelphia . This col~pusw~s collected and transcribed by Marth~t Pollackanti Julia 

cannot be adding beliefs to the cmnmon ground 2 . Furthermore , the truth of (9) cannot be in question , for instead of 19) , \[ larry could not say Yup , but lhat doesn't knock her out . Sowhy does Ray ( r ) in ( 8 ) RF ~ PEAT Harry's ( h ) assertion of it does , and why does l farry
PARAPHRASE himself and Kayin (9) ?
My claim is that m formationally redundant utterances  ( IRU's ) have two main discourse functions : ( 1 ) to provide EVIUENCI~to supporthe assumptions underlying the inference of mutual beliefs  , (2) to CENTER a proposition , is . make or keep a proposition salient\[6\] . This paper will focus on ( 1 ) leaving ( 2 ) for future work . 
First consider the notion of evidence . One reason why agents need EVIDENCE for beliefs is that they only have partial information about :   ( 1 ) the state of world ; (2) the effects of actions ; (3) other agent's beliefs , preferences and goals . This is especially true when it comes to modelling the effects of linguistic actions  . Linguistic actions are different hanp hysical actions  . An agent's prior beliefs , preferences and goals cannot be ascertained by direct inspection  . This means that it is difficult for the speaker to verify when an action has achieved its expected result  , and so giving and receiving evidence is critical and the process of establishing mutual beliefs is carefully monitored by the conversants  . 
The characterization fIRU's ms informationally redundant follows from an axiomatization of action in dialogue that I will call the DETERMIniSTICMODEL  . 
This model consists of a number of simplifying assumptions such as:  ( I ) Propositions are are either believed or not believed  ,   ( 2 ) Propositions representing beliefs and intentions get added to tim context by the unilat-eral action of one conversant  , (3) Agents are logically orm fiscient .   ( 4 ) The context of a disconrse is an und if -ferentiated set of propositions with no specific relations between them  . I claim that these assumptions nmst be dropped in order to explain the function of IRU's in dialogue  . 
Section 2 discusses assumption (1) ; section 3 shows how assmnption ( 2 ) can be dropped ; section 4 discusses (3) ; section 4 . 1 shows that some IRU's facilitate the inference of relations between adjacent propositions  . 
2\[8 ) is not realized with a rising question intonation  . This will be discussed in sectiot t6 . 1 . 
A~\]~s DECOLING-92 , NAIN rFES , 2328 AO~"1992345 PROC . OFCOLING-92, NANTES , AUG . 2328, 19922 Mutual Beliefs in a Shared
Environment
The account proposed here of how the COMMONGROUND is augmented  , is based is Lewis's SHAREDEN-VIRON MENT model for common  knowledge\[10  ,  2\] . In this model , mutual beliefs depend on evidence , openly available to the conversants , plus a number of underlying assumptions . 
Shared Environment Mutual Belief In-duction Schema It is mutually believed in a population P that qlif and only if some situation ~ q holds such that :  1  . Everyone in P has reason to believe that , q holds . 
2 .   3 indicates to everyone in P that everyone in P has reason to believe that  8 holds . 
3. S indicates to everyone in P that@.
The situation ~ q , used above in the mutual belief induction schema , is the context of what has been said . 
This schema supports a weak model of mutual beliefs  , that is more akin to mutual assumptions or mutual  suppositions\[13\]  . Mutual beliefs can be inferred based on some evidence  , but these beliefs may depend on underlying assumptions that are easily defensible  . 
This model can be implemented using Gallier's theory of autonomous belief revision and the corresponding  system\[4\]  . 
A key part of this model is that some types of evidence provide better support for beliefs than other types  . The types of evidence considered are categorized and ordered based on the source of the evidence : hypothesis < default < inference < linguis tic < physical  ( See\[2 ,  4\]) . This ordering reflects the relative defeasibility of different assumptions  . Augmenting the strength of an assumption thus decreases its relative defensibility  . 
A claim of this paper i8 that one role of IRU's is to ensure that these assumptions are supported by evidence  , thus decreasing the defensibility of the mutual beliefs that depend on  them\[4\]  . 
Thus mutual beliefs depend on a defensible inference process  . All inferences depend on the evidence to support them  , and stronger evidence can defeat weaker evidence . So a mutual belief supported as an inference can get defeated by linguistic information  . In addition , I adopt an an assumption that a chain of reasoning is only as strong as its weakest link : We akest Link Assumption : The strength of a belief P depending on a set of underlying assumptions al  ,  . . . an is MIN ( Strength(a , , . . . 4 , ) ) This seems intuitively plausible and means that the strength of belief depends on the strength of underlying assumptions  , and that for all inference rules that depend on multiple premises  , the strength of an inferred belief is the weakest of the supporting beliefs  . 
This representation of mutual belief differs from the common representation i terms of an iterated e on junction \[ ll \] in that:  ( 1 ) it relocates information from mental states to the environment in which utter-anees occur  ;   ( 2 ) it allows one to represent the different kinds of evidence for mutual belief  ;   ( 3 ) it controls reasoning when discrepancies in mutual beliefs are discovered since evidence and assumptions can be inspected  ;   ( 4 ) it does not consist of an infinite list of statements  . 
3 Inference of Understanding
This section examines the assumption from the DETER-MINISTICMODEL that:  ( 2 ) Propositions representing beliefs and intentions get added to the context by the unilateral action of one conversant  3  . This assumption will also be examined in section 5  . 
The key claim of this section is that agents monitor the effects of their utterance actions and that the next action by the addressee is taken as evidence of the effect of the speaker's utterance  4  . That the utterance will have the intended effect is only a hypothesis at the point where the utterance has just been made  , irrespective of the intentions of the speaker . This distinguishes this account from others that assume it her that utterance actions alway succeed or that they succeed unless the addressee previously believed othecwise \[ ll  ,  8\] . 
I adopt the assumption that the participants in a dialogue are trying to achieve some  purpose\[7\]  . Some aspects of the structure of dialogue arises from the structure of these purposes and their relation to one another  . 
The minimal purpose of any dialogue is that an utterance be understood  , and this goal is a prerequisite to achieving other goals in dialogue  , such as commitment to future action . Thus achieving mutual belief of understanding is an instance of the type of activity that agents must perform as they collaborate to achieve the purposes of the dialogue  . I claim that a model of the achievement of mutual belief of understanding can he extended to the achievement of other goals in dialogue  . 
Achieving understanding is not unproblematic , it is a process that must be managed , just as other goal achieving processes are \[3\] . Inference of mutual understanding relies upon some evidence  , e . g . the utterance that is made , and a number of underlying assumptions . 
The assumptions are given with the inference rule below  . 
say ( it , B , u , p ) -- A -> a This is an utterance action version of the STRIPS assumption  . 
4Except for circumstances where it is clear that the flow of the conversation has been interrupted  . 
AcrEsDECOLING-92 , NANTES , 2328 AOI~T1992346 Pgoc . OFCOLING-920 NANTES , AUG .  2328, 1992
Next Assumption
Utterance addressed
PROMPT attention
REPEA Thearing ., attention
PARAPHRASE realize , hearing , attention
INFERENCE license , realize , hearing , attention IMPLICATURE license , realize , hearing , attention
ANY Next copresence linguistic
Utterance license , realize , hearing , attention default ~
Evidence qype ~ lingu ~ linguistic I linguistic\ ] linguist  ) c ~ linguistic \] Figure 1: How t be Addressee's Following utterance upgrades the evidence underlying assumptions understand  ( B , u , p)\[evidence-type\]
Assumptions = e o present ( h , B , u )\ [ evidence-type\]attend(B , U )\ [ evidence-type\]hear(B , u )\ [ evidence-type\]bel(B , realize ( u , p ) ) \[ evidence-type \] This schema means that when A says u to B intending to convey p  , that this leads to the mutual belief that B understandsuasp under certain assumptions  . The assumptions are that A and B were cn present , hat B was attending to the utteranc event , that B heard the utterance , and that B believes that the utterance urealizes tim intended meaning p  . 
The \[ evidence-type J annotation indicates the strength of evidence supporting the assumption  . All of the assumptions start out supported by no evidence  ; their evidence type is therefore hypothesis . It isn't until after the addressee's next action that an assumption can have its strength modified  . 
The claim here is that one class of IRU's addresses these assumptions underlying the inference of mutual understanding  . Each type of IRU , the assumption addressed and the evidence type provided is given in Figure  1  . Examples are provided in sections 3 . 1 and 3 . 2 . 
It is also possible that A inteuds that BY saying u  , which realizes p , B should make a certain inference q . 
Then B's understanding of u should include B making this inference  . This adds an additional assumption : bel(B , license(p , q ) ) \[ evidence-typeJ Thus assuming that q was inferred relies on the assumption that B believes that plicenses q in the context  . 
Figure 1 says that prompts , repetitions , paraphrases and making inferences explicit all provide linguistic evidence of attention  . All that prompt such as sh huhdo is provide evidence of attention  . However repetitions , paraphrases and making inferences explicit also demonstrate complete hearing  . In addition , a para ~ phrase and making an inference xplicit provides linguistic evidence of what proposition the paraphraser believes the previous utterance realizes  . Explicit inferences additionally provide evidence of what inference stile inferrer believes the realized proposition licenses in this context  . 
Ill each case , the IRU addresses one or more sumptions that have to be made in order to infer that mutual understanding has actually been achieved  . 
The assumption , rather than being a hypothesi ~ or a default , getup graded to a support type of linguistic as a result of the IRU  . The fact that different II~U's address different assumptions leads to the perception that some  1KU's are better evidence for understanding than others  , e . g . a PARAPHRASE i8 stronger evidence of understanding than a REPEAT\[3\]  . 
In addition , any next utterance by the addressee can upgrade the strength of the underlying assumptions to default  ( See Figure 1 )  . Of course default evidence is weaker than l inguistic evidence  . The basis for these default in thrences will be discussed in section  5  . 
3.1 Example of a Repetition
Consider example 1 ill section 1 . Ray , in (8), repeats II arry's assertion from (7) . This upgrades the evidence for tile assumptions of hearing and attention associated with utterance  ( 7 ) from hypothesis to Xinguistic . 
The assumption about what proposition p7 is realized by u7 remains a default . This instantiates the infer-ACRES DECOL1NG-92 , NANTI~S , 2328 Aotrr 1992347 Paoc . OFCOLING-92, NAIV rr~s , Auc ; , 2328 . 1992 ence rule for understanding as follows : say ( harry , ray , uT , pT)--I->understand(Ray , u7 , p7)\[default\]
Assunption a:e oprseant ( harry , ray , u7)\[ linguistic \] strand(ray , u7)\[ linguistic \] hear(ray , uT )\ [ linguistic \] bel(ray , realize ( uT , pT ) ) \[ default \]  Because of the WEAKEST LINK assumption  , the belief about understanding is still a default . 
3.2 Example of a Paraphrase
This assumption is challenged by a number of cases in naturally occurring dialogues where inferences that follow from what has been said are made explicit  . I restric the inferences that I discuss to those that are  ( a ) based on information explicitly provided in the dialogue or  ,   ( b ) licensed by applications of Gricean Max-ims such as scalar implicature  inferences\[9\]  . 
For example the logical omniscience assumption would mean that if l  ( a ) and ( b ) below are in the context , then ( c ) will be as well since it is entailed from ( a ) and ( b )  . 
(1) a . You can buy an IIt A if and only if you do
NOT have an existing pension plan , b . You have an existing pension plan . 
c . You cannot buy an IItA,
Consider the following excerpt :
Exawple 2: (18) h . is e e . are there any uther children beside your gi la ?  ( 19 ) d . no (20) h . YOURWIFEISANOILYCHILD(21) d . right , and uh wants to give her some security .   .   .   .   .   .   .   .   .   . 
Harry's utterance of ( 20 ) is said with a falling intonational contour and hence is unlikely to be a question  . 
This utterance results in an instantiation of the inference rule as follows : say  ( harry , ray , u20 , p20) - - l -> understand(Ray , u20 , p20)\[ linguistic\]
Assumptions = copretent(haxry , ray , uT )\ [ linguistic \] ateend(ray , u7)\[ linguistic \] hear(ray , u7)\[ linguistic \] bel(ray , realize ( . 7 , pT ))\ [ linguistic\]In this ease , the belief about understanding is supported by l inguistic evidence since all of the supporting assumptions are supported by linguistic evidence  . Thus a paraphrase provides excellent evidence that an agent actually understood what another agent meant  . 
In addition , these IIt U's leave a proposition salient , where otherwise the discourse might have moved on to other topics  . This is part of the CENTERING function of IKU's and is left to future work  . 
4 Making Inferences Explicit
This section discusses assumption ( 3 ) of the determistic model , namely that : Agents are logically omniscient . 
The following excerpt demonstrates this structure . Utterance (15) realizes la , utterance (16) realizes lb , and utterance ( 17 ) makes the inferenc explici that is given in lc for the particular taxyear of  1981  . 
Example 3: (18) h . oh no.
IEA'e were available as long as you are not a participant in an existing pension  ( as ) j . ohise e . 
well ididu or kidouork for a company that has a pension  ( 17 ) h . ahh . THENYOU'RENOTELIGIBLE
FOREIGHTYONE (18) j . is e e , butiam for 82 After (16) , since the propositional content of ( 17 ) is inferrable , the assumption that Harry has made this inference is supported by the infarance evidence type : bel  ( H , lieense(p16 , p17 ) ) \[ inference \] According to the model of achieving mutual understanding that was outlined in section  3  , utterance ( 17 ) provides linguistic evidence that I larry ( h ) believes that the proposition realized by utterance  ( 16 ) licenses the inference of ( 17 ) in this context . 
hal(H , license(pl 6 , p17))\[ linguistic \] Furthermore , the context here consists of a discussion of two tax years  1981 and 1982  . Utterance (17) selects * igh Ly one , with a narrow focus pitch accent . This implicates that there is some other tax year for which Joeise ligible  , namely 198219\] . Joe's next utterance , but I am for 82 , reinforces the implicature that Harry makes in ( 17 )  , and upgrades the evidence underlying the assumption that  ( 17 ) licenses ( 18 ) to linguistic . 
ACIES DECOLING-92 , NANTES , 2328 AO~r1992348 PROC . OFCOLING-92, NANTES , AUG .  2328, 1992 4 . 1 Supporting Inferences A subcase of ensuring that certain inferences get made involves the juxtaposition of two propositions  . These cases challenge the assumption that : ( 4 ) The context of a discourse is an undifferentiated set of propositions with no specific relations between them  . While this assumption is certainly not made in most discourse models  , it is often made in semantic models of the context\[14\]  . In the following segment , Jane ( j ) describes her financial situation to Ii arry ( h ) and a choice between a setthment and an annuity . 
Example % : ( l)j . hello harry , my name is jane (2:) h . welcome jane (3) j . i just retired december first , and in addition to my pension and social securi t y  , I have a supplemental annuity (4) h . yes (5) j . which i contributed to while i was employed ( 8  ) h . right (7) j . from the state of IJ mutual fund . 
and IS mentitled to a lump sumsettlement which would be betueen  i6  , 800 and 17 , 800 , or a lesser life annuity , and the choices of the annuityum would be $128 . 45 per month . 
That would be the maximum with no beneficiaries ( 8 ) h . You can stop right there : take your money . 
(9) j . take the money.
(10) h . absolutely.
YOU'REONLY GETTING 1500 AYEAR.
at 17 , 000 , no trouble at all ~ oget 10 percent on 17 , 000 bucks . 
I iarry interrupts her at ( 8 ) since he believes he has enough information to suggest a course of action  , and tells herlake ~ lonr money . To provide SUPPORT for this course of action he produces an inference that follows from what she has told him in  ( 7 )  , namely You ' reonly gelling 1500 ( dollars ) a year . SUPPORT is a general relation that holds between beliefs and intentions in this model  . 
Presumably Jane would have no trouble calculating that  $125  . 4 5 a month for 12 months amounts to a little over $1500 a year , and thus can easily accep this statement that is intended to provide the necessary SUP-PORT relation  , i e . the juxtapt ~ ition of this fact against the advice to lake the money conveys that the fact that she is only getting  1500 dollarsay ear is a reason for her to adopt the goal of taking the money  , although this is not explicitly stated . 
5 Evidence of Acceptance
In section 3 , I examine the assumption that : ( 2 ) Propo-sitions representing beliefs and intentions get added to the context by the unilateral action of one conversant  . 
I suggested that this assumption can be replaced by adopting a model in which agents ' behavior provides evidence for whether or not mutual understanding has been achieved  . I also discussed some of the effects of resource bounds  , is . eases of ensuring that or providing evidence that certain inferences dependent on what is said are made  . 
Achieving understanding and compensating for resource bounds are issues for a model of dialogue whether or not agents are autonomous  . But agents ' autonomy means there are a number of other reasons whyA's utterance to B conveying a proposition p might not achieve its intended effect :  ( 1 ) p may not cohere with B's beliefs , (2) B may not think that p is relevant ,   ( 3 ) B may believe that p does not contribute to the common goal  ,   ( 4 ) B may prefer doing or believing some q where p is mutually exclusive with q  , (5) If p is about an action , B may want to partially modify p with additional constraints about how  , or when p , Therefore it is important odistinguish an agent actually ACCEPTING the belief that por intending to perform an action described by p from merely understanding that p was conveyed  . Other accounts legislate that helpful agents should adopt other's beliefs and intentions or that acceptance depends on whether or not the agent previously believed ~ Pill  ,  8\] . But agents can decide whether as well as how to revise their  beliefs\[4\]  . 
Evidence of acceptance may be given explicitly , but acceptance can be inferred in sonm dialogue situations via the operation of a simple principle of cooperative dialogue S : 
COLLABORATIVE PRINCIPLE : Conversants must provide evidence of a detected is crep-ancy in belief as so on as possible  . 
This principle claims that evidence of conflict should be made apparent in order to keep defaul t inferences about acceptance or understanding from going through  . 1 RU's such as PROMPTS pREPETITIONS ~ PARAPIRASES , and making an INFERENCE explicit cannot function as evidence for conflicts in beliefs or intentions via their propositional content since they are informationally redundant  . If they are realized with question intonation , the inference of acceptance is blocked . 
In the dialogue below between tiarry ( b ) and Ruth ( r )  , Ruthin (39) , first ensures that she understood Harry correctly  , and then provides explicit evidence of non -acceptance in  ( 41 )  , based on her autonomous preferences about howher money is invested  . .
ST iffs is a simplification of the COLL ABOn ATIVE PLANNING 
PRINC ~ PLE ~ described in\[15\].
Ac'rEs DECOLING-92 , NANTES , 2328 Ao~-r1992349 PROC . OFCOLING-92, NANTES , AUG .  2328 .  1992
Exa ~ le 5: (38) h . and I'd like 1K thouw and in a 2 and a half year certificate ( 39 ) r . the full 18 in a 2 and a half ? (40) h . that's correct (41) r . GEE . NOT ATMY AGE In the following example , Joein ( 14 ) makes a statement that provides propositional content hat conflicts with Harry's statement in  ( 13 ) and thus provides evidence of non-acceptance . 
Exmaple 6 (13) h . and -- there's no reason why you should n ' ~ have an IIth for last year  ( 14 ) j . WELLITHOUGHTTSEYJUSTST?RTED
THISYE aR
Joe's statement is based on his prior beliefs . In both of these cases this evidence for conflict is given immediately  . However when there is no evidence to the contrary s  , and goals of the discourse require achievement of acceptance  , inferences about acceptance are licensed as de fault  . They can he defeated later by stronger evidence . 
Without this principle , a conversant might not bring up an objection until much later in the conversation  , at which point the relevant belief and some inferences following from that belief will have been added to the common ground as dtafanlts  . The result of this is that the retraction of that belief results in many beliefs being revised  . The operation of this principle helps conversants avoid replanning resulting from inconsistency in beliefs  , and thus provides a way to manage the augmentation of the common ground efficiently  . 
6 Other hypotheses
The first point to note is that the examples here are only a subset of the types of IRU's that occur in dialogues  . I use the term antecedent to refer to the most recent utterance which should have added the proposition to the context  . This paper has mainly focused on cases where the IRU:  ( 1 ) is adjacent oits antecedent , rather than remote ;   ( 2 ) realizes a proposition whose antecedent was said by another conversant  , (3) has only one antecedent . It is with respect oth is subset of the data that the alternate hypotheses are examined  . 
A distribution alnalysis of a subBet of the corpus  ( 1 71 IKU's from 24 dialogues consisting of 976 turns )  , on the relation of an IRU to its antecedent and the context  , shows that 35% of the tokens occur remotely from their antecedents  , that 32% have more than one antecedent , that 480? consist of the speake repeating something that he said before and  52% consist of the speakere-peating something that the other conversant said  . So s Thls displaying of evidence to the contrary was called sat interruption i  \[15\]  . 
the data that this paper focuses on accounts for about  30% of the data . 
6.1 Indirect Question Hypothesis
In example (1) of section 1 , an alternative account of Ray's repetition in ( 8 ) is that it is a question of some kind . This raises a number of issues : ( i ) Why doesn't it have the form of a question ? , (2) What is it a question about ? , and (3) Whyisit never denied ? . 
Of 171 IRU's , only 28 are realized with rising question intonation . Of these 28 ,   6 are actually redundant questions with question syntax  , and 14 are followed by affirmations . 
If these are generally questions , the none possible answer to what the question is about is that Ray is questioning whether he actually heard properly  . But then why doesn't he use an intonational contour that conveys this fact as Ruth does in example  5? On an efficiency argument , it is hard to imagine that it would have cost Ray any more effort to have done so  . 
Finally , if it were a question it would seem that it should have more than one answer  . While 50 of these IRU's are followed by an affirmation such as that's cot  . 
reef , right , yup , none of them are ever followed by a denial of their content  . It seems an odd question that only has one answer . 
6.2 Dead Air Hypothesis
Another hypothesis i that IRU's result from the radio talks how environment in which silence is not tolerated  . 
So agents produce IRg's because they cannot think of anything else to say but feel as though they must say something  . 
The first point to note is that IRU's actually occur in dialoguestimt aren't on the radio\[l \]  . The second question is why an agent would produce an IRU  , rather than some other trivial statement such as I didn't know thai  . Third , why don't these utterance correlate with typical stalling behavior such as false starts  , pauses , and filled pause such a suhhh . 
The dead air hypothesis would seem to rely on an assumption that at unpredictable intervals  , agents just can't think very well . My claim is that IRU's are related to goals , that they support inferencing and address assumptions underlying mutual beliefs  , is . they are not random . In order to prove this it must be possible to test the hypothesis that it is only important propositions that get repeated  , paraphrased or made explicit . This can be based on analyzing when the information that is repeated has been specifically requested  , such as in the caller's opening question or by a request for information from Harry  . It should also be possible to test whether the IRU realizes a proposition that plays a role in the final plan that Harry and the caller negotiate  . However this type of strong evidence AcIxsDE COLING-92  , NANTES , 2328 Aour 1992350 PROC . OFCOLING-92, NANTES , AUG .  2328 ,   1992 agains the dead air hypothesis i left to future work  . 
7 Discussion
It should be apparent from the account hat the types of utterances examined here are not really redundant  . 
The reason that many models of belief transfer in dialogue would characterize them as redundant follows from a combination of facts :  ( 1 ) The representation f belief in these models has been binary  ;   ( 2 ) The effects of utterance actions are either assumed to always hold  , or to hold as defaults unlcss the listener already believed otherwise  . This means that these accounts cannot represent the fact that a belief must be supported by some kind of evidence and that the evidence may be stronger or weaker  . It also follows from ( 2 ) that these models assume that agents are not autonomous  , or at least do not have control over their own mental states  . 
But belief revision is surely an autonomous process  ; agents can choose whether to accept a new belief or revise old  beliefs\[4  ,  8\] . 
The occurrence of IRU's in dialogue basmany ramifications for a model of dialogue  . Accounting for IRU's has two direct effects on a dialogue model  . First it requires a model of nmtual beliefs that specifies how mutual beliefs are inferred and how some mutual beliefs can be as weak as mutual suppositions  . One function of IRU's is to address the assumptions on which mutual beliefs are based  . Second the assumption that propositions representing beliefs and intentions get added to the context by the unilateral action of one conversant must be dropped  . This account replaces that assumption with a model in which the evidence of the hearer must be considered to establish mutual beliefs  . The claim here is that both understanding and acceptance are monitored  . The model outlined here can be used for different ypes of dialogue  , including dialogues in which agents are constructing mutual beliefs to support future action by them jointly or alone  . 
l to w and when agents decide to augment the strength of evidence for a belief has not been addressed in this work as yet  . Future work includes analyzing the corpus with respect o whether the IRU plays a role in the final plan that is negotiated between the conversants  . 
8 Acknowledgements
Discussions with Aravind Joshi , Ellen Prince and Bonnie Webber have been extremely helpful in the devel-oprnent of these ideas  . In addition I would like to thank Herb Clark , Sharon Cote , Julia Galliers , Ellen Germa in , Beth Ann Hockey , Megan Moser , Hideyuki Nakashima , Owen Rainbow , Craige Roberts , Phil Stenton , and Steve Whittaker for the influence of their ideas and for useful discussions  . 
References\[1\]Jean C . Carletta . Risk Taking and Recovery in Task-Oriented Dialogue  . PhD thesis , Edinburgh
University , 1991.
\[2\] Herbert H . Clark and Catherine R . Marshall . Definite reference and nmtual knowledge . In Joshi , Webber , and Sag , editors , Elements of Discourse Understanding , pages 10-63 . CUP , 1981 . 
\[3\] HH . Clark and Edward F . Schaefer . Contributing to discourse . Cognitive Science , 13, 1989 . 
\[4\] Julia R . Galliers . Cooperative interaction as strategic belief revision  . In M . S . Deen , editor , Co-operating Knowledge Based Systems ,  1991 . 
\[5\]H . P . Grice . William James Lectures .  1967 . 
\[6\] Barbara J . Grosz , Aravind K . Josbi , and Scott Weinstein . Towards a computational theory of discourse interpretation  . Unpublished Manuscript , 1986 . 
\[7\] Barbara J . Grosz and Caudaee L . Sidner . Atten-tions , intentions and tile structure of discourse . 
Computational Linguistics , 12:pp . 175-204, 1986.
\[8\] Barbara J . Grosz and Candace L . Sidner . Plans for discourse . In Cohen , Morgan and Pollack , eds . 
Intentions in Communication , MIT Press , 1990.
\[9\] Julia Iiirschberg . A Theory of Scalarlmplicature . 
PhD thesis , University of Pennsylvania , Computer and Information Science ,  1985 . 
\[10\] David Lewis . Convention . llarvard University
Press , 1969.
\[11\]Diane Litman and James Allen . Recognizing and relating discourse intentions and task-oriented plans  . In Cohen , Molyan and Pollack , eds . Intentions in Communication , MIT Press , 1990 . 
\[12\] Martha Pollack , Julia Hirschberg , and Bonnie Webber . User participation i the reasoning process of expert systems  . In AAAI , 1982 . 
\[13\] Ellen F . Prince . On the function of existential presupposition i discourse  . In Papers from l~th Regional Meeting . CLS , Chicago , IL , 1978 . 
\[14\] Robert C . Stalnaker . Assertion . In Peter Cole , editor , Syntax and Semantics , Volume 9: Prag-mattes , pages 315-:\]32 . Academic Press , 1978 . 
\[15\] Marilyn A . Walker and Steve Whittaker . Mixed initiative in dialogue : An investigation i to discourse segmentation  . In ACL , pages 70-79, 1990 . 
ACRESDECOLING-92, NARI~S . 2328 nOt\]T 1992 351 PROC . oF COLING-92, NAntES , AUG .  2328, 1992
