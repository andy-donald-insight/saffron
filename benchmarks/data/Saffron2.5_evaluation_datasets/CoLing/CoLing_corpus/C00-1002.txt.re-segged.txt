Learning Word Clusters from Data Types
Paolo Allegrini , Simonetta Montemagni , Vito Pirrelli
Istituto di Linguistica Comlmtazionale-CNR
Viadella Faggiola 32, Pisa , Italy
allegrii ), simo , vito@ilc.pi.cn r.it
Abstract
The paper illustrates a linguistic knowledge acquisition model making use of data types  , infinitenlenlory , and an inferential mechanism t br inducing new intbrmation Doraknown data  . 
The mode \] is coln pared with standard stochastic l nethods applied to data tokens  , and tested on a task of lexicosemantic lassification  . 
1 Introduction and Background
Of late , consideral ) leinterest has been raised by the use of local syntactic contexts to automatically in & me lexicosemantic classes from parsed corI  ) ora ( Pereira and Tishby 1992 ; Pereiractal . 1993; Rooth 1995; Rooth et al 1999) . This family of approaches takes a 1 ) air of words ( usually a verb plus a noun )  , and a syntactic relation holding 1 ) etween the two in context ( llSll-ally theol ) ject )  , and calculates its token distribution in a training corI  ) us . These ( : omits de-line the range of more or less tyi ) ical syntactic collocate selected by a verb . The semat > tic similarity between words is then delined in terms of sul  ) stitutability in local contexts ( see also Grefenstette 1994 ; I . ,in 1998 ) : two verbs are semantically close if they typically share the same range of collocates  ; conversely , two nouns are semantically close if they takel ) art in the same tyl ) e of selection dependencies , i . e . if they arc selected t ) y the same verbs , with the same function . \] ~ q ' onl this perspective , a syntactically asymmetric relation ( a dependency ) is reinterpreted as a semantic co-selection , where each term of the relation can be defined with respect to the other  . 
This symmetric similarity metric is often ac-( ; omi ) anied by the nontrivial assuml ) tion that th , c , semantic classification of both vcrb , s and nouns be symmetric too . This is enforced by maximizing I 7? tj ) , with to 1--1 where p ( Ck ) is the probability of class Ck1 ) e-ing tbund in the training corpus , and p ( vi\[Ck ) and p ( nj\[Ci ~ ) define the probability that verb vi and noun nj be associated with the semantic dimension  ( or meaning component ) of class C/~ . 
Intuitively , the joint distribution of fimction a . llymmotated verb-noun pairs is accounted for t ) y assuming thai ; each l ) airmeml ) er in del ) endently correlates with the same semantic dimension  , or selection type ( Rooth 1995) , a concel ) tual pair de . fining all pairs in the class : < g . " scalarmotion ", " communicative action " etc . 
The al ) proach has the potential of dealing with polysemous words : as the same word can in principle belong to more than one  ( -lass , there are good reasons to expect hat the corresponding selection type positively correlates with one and only one sense of polysemous words  . A further t ) omls of the al ) I ) roach is that it makes it ex-i ) licit the perspectivizing factor underlying the discovered similarity of words in a class  . 
On a less positive side , poorly selective verbs ( i . e . verbs which potentially combine with any 1101111 ) Sllch as give , find or get tend to stick together in highly probable classes  ,  1 ) utapl ) ear to stake out rather uI finl brmative senlantic dimensions  , relating a motley collection of 11011118 , such as part , way , reason and problem ( Rooth 1995) , whose only cominonality is the property of being freely interchangeable in the context of the abovementioned verbs  . 
Another related issue is how many such di-nlens ions are necessary to account br the entire variety of senses attested in the training corpus  . 
This is an empirical question , but we contend an inipor ~ antone , as the usal ) ility of the result ; -lag (: lasses heavily dot ) ends ( mit . It is (: ommon knowledge that verbs can1)c , exceedingly ( -hoosy illtile way they select their collocates . Hence , one is Mlowed to use the class Ck to make t ) re-dictions about the set of collocates of a verb v ~  , only if P ( v , :\] C ~) is sufficiently high . Conversely , if CI~hal ) penstopoorly ( : or relate with any verb , the set of nouns in Ck is unlikely 1 ; or eflect any lexical selection . This coml ) ounds wii ; h the 1 ) rol ) len that the meaning of a verb vi can significantly involve more lihalt Olte Selltall - tic  ( timension : at i ; heples enl ; stage of research in (: Olnlmt at ; iollal lexical SO , lnanti('s , Irescholar has shown what fun (: tion relal ; esl ; lmnmaning components of vi to its sehx : tional behaviom '  . 
There is wide room for flu'therresear ( : h in this area , but truly ext ) lorative tools are still needed . 
Finally , the des(:ribe(t method is a (: ul ; c , lyt ) rone to the 1) roblem of si ) arse data . All ; l ) oughi , ( cl , , , ) is rightly ext ) e(:ted to converg ( , faster , : ha : , p( , , l . ,) , still (: o , ,vergcu(:e of , ( Cl ' ,   ,  )  , : al , b ( , ex(:(; edinglysh ) w with low frequen (' y nouns . It is moo ; i ; ll ; ~ I ; sieving more and more ( : ( ) rims ( tat~is a solution in all ( : as es , its word fl'cquen ( : y is highly sensitive to changes in text genre , topic and domain ( S (: hiitze and Pede , rsen 1993) . 
2 The approach
Ih ~ reweillu stratea ( lifl'er(mt ; at ) l ) roa('ht () a(>(isring lexicosemant ; i (" (: lasses from sy ~ , ta('t;i-(:ally lo(-al('on texts . Like the family of s to ( : has-tieme tho ( ts of se ( : tion 1 , we make use of ~ tsimibu : ityntel ; ric1) ase donsul ) stitui ; ability ill(ve , rb , noun , flntction ) tril ) les . We also share the assumption that lexi ( : o semantic lasses are inherently multidimensional  , as they heavily depend on cx is ; ence of a perspectivizing factor . 
Yet , we depart from other assmnt)tions . Classification of verl ) san ( ln ( mns is a symmetric : two IIOIIIISL l'e similar if (  ; heycollo ( : ate with as many semantically diverse vcrl ) s as possible in as many ( t if li : rent syntactic on texts as l ) ossit ) le . 
The converse apl ) lies to verbs . In other words , semantic similarity of nom:s is not conditional on the similarity of their ac  ( :oml ) anying verbs , and vice vcrsa . In a sells (' , , classification brc , aksth , csymmetry : maximization of the silnilarity of nouns  ( verbs ) may cause minimization of the similarity of i ; heir accoml ) anying verbs ( nouns ) . 
A ( : lass where a maximum of noun similarity correlates with alni ~ ximmn of verb similarity cm ~ be uninforniative  , as exeml ) litied above by the ease of t ) oorly selective verbs . 
Secondly , we assmne ( following Fodor 1998 ) that the number of t ) erst ) ectivizing factors governing lexieal selection may have the order of magnitude of the lexicon itself  . The use of global semantic dimensions may smooth out lexical t  ) refcrences . This is hardly what we need to semantically annotate lexicall  ) reti ; rences . A more conservative al ) proa (: h to the t ) rol ) lem , inducing local semantic (' lasses ,   ( : an ( : oml ) in eal ) -1 ) licability to real language 1 ) recessing l ) roblen ~ s with the fln ' l ; lmrt ) omls of exploring a relatively mm harted territory . 
Thirdly , p(vi , nj ) ai ) t ) ears to be too sensitive to changes in text genre , to l ) i clind domain to be eXl ) ect cd to converge reliably . We prefer to ground a similarity metric oIx measuring the correlation among verb noun  , type , sratlw , r thane-ke , as , t br two basic reasons : i ) verl ) noun types arc ( t is ( : retc ,   ; m(tlessl ) ronet ; or and om variation in it ( parsed ) (: or pus , ii ) verl ) nount yl ) eS ( : ml reliably l ) e a ( : ( tuir ( xl from highly int brm~t tive trothardly redundant knowledge source such as h~xi  ( : an ( 1 encyclot ) aedias . 
Finally , our information refitt br measuring wor ( t similarity is not a ( : Oul ) le of context sharing pairs ( e . g . ( set , sta . ndard , obj ) and ( sct , re . cord , obj )) but a q v , ad'r'uplc , of such con-text ; s , tbrme(t1) y (: ombining two verbs with two .  ( ,  . )) s(, .  ,  . 
a . d ) , such that the yenter an av , a h)gical proportion . 
2.1 The analogical proportion
In the t ) resenl ; conl ; ext , an anah ) gieal prot ) or tion ( hereafl ; erAP ) is a quadrui ) leofflmctionally mmotated t ) airs resulting from tile combination of any two ltOll lS'l ~  , i and ~3 . j wit ; hany two verbs v /, . and vtsu (: has (2) holds : ( v ~ . , n i , f , , , ) : ( v ~ . ,nj , L , ,)= ( v , ,ni , fn ) : ( vt , nj , fiz ) ,   ( 2 ) where terms along the two diagonal scansw~pt ) lace in the 1 ) rot ) ortion , and identity of sub-s ( :riptindi ( : ates identity of w flues . Three aspects of ( 2 ) are worthem l ) hasizing in this context . 
First , it does not require that the stone syntactic timeion hold  1  ) etwen all pairs , but only that timeions be pair wiscidentical . Moreover ,   ( 2 ) does not cover all possible syntactic on texts where hi  , uj , " vk and vt may coral ) he , but only th , ose where verb and . function values covary . 
( . set , standard , obj ) : ( , set , record , obj ) = ( meet , standard , obj ) : ( , , ,  . tet: , record , x )   ( 3 ) We call this constraintile " same-verb-same flmction " principle  . As we will see in section 2 . 3 , the principle has important consequences on tile sort of similarity induced by  ( 2 )  . Finally , if one uses subscripts as t brmal constraints on type identity  , then any term can be derived from ( 2 ) if the values of all other terms are known . For example giventile partially instantiated propoftion in  ( 3 )  , the last term is filled in unambiguously by substituting x = fn = obj  . 
AP is an important generalization of the inter -substitutability assumption  , as it extend stile assumption to cases of flmctionally heterogeneous verb-nonn pairs  . Intuitively , an AP says that , for two nouns to be taken as systematically similar  , one has to be ready to ' a set h , cm interchangeably in at lea , s two different local contexts . This is where the inferential and the classificatory perspectives meet  . 
2.2 Mathematical background
We gave reasons for defining the similarity metric as a flmction of verb-noun type correlation rather than verb noun token correlation  . In this section we sketch the mathematical framework underlying this assumption  , to show that , t braset of verb nonn pairs with a unique syntactic function  , AP is the smallest C that satisfies eq . (1) . 
Eq . (1 ) says that v i and n j are conditionally independent given C  , meaning that their correlation only det ) ends on the probability of their belonging to C , as t brmally restated in eq . (4) . 
p(n , vlC ) = p(nlC)p(vlC ) (4)
In passing from token to type frequency , we assume that a projection operator simply assign sam fit brmtype probability to each event  ( pair ) with a nonzero token probability in the training corpus  . From a learning perspective , this corresponds to the assumption that an in finite memory filters out events already seen during training  . The type probability pT(n , v ) is defined as in eq . (5) , where Np is the number of different pairs attested in the training corpus  . 
pT(n , v ) = 1/Np if the pair is attested , pT(n , v ) = 0 otherwise . (5) Byeq . (4) , pT(n , vlC ) ?0 if and only if pT ( nlC ) ~0 and pT ( vlC ) ~ O . This amounts to saying that all verbs in C are freely interchangeable in the context of all nouns in C  , and vice versa . We will here afte refer to C as a substitutability island  ( SI )  . AP can accordingly be looked at as the minimal SI . 
The strength of correlation of nouns and verbs in each SI can be measured as a summation over the strength of all APs where they enter  . Formally , one can define a correlation score or ( v , n ) as the probability of v and n being attested in a pair  . This can be derived from our definition of pr(v , n ) , as shown in eq . (6) , by substituting pT(n , v ) = pr(v)pT(nlv ) and pT(nlv ) = 1/w(v) , where w(a ) is tile type fi'e-quency of a(i . e . number of different attested pairs containing a ) . 

G (6) N ,, G
Eq . (6) , after simplification , yields the tbllowing o < (7) By the same token , the correlation flmction c7 ( AP ) relative to the 4 poss it ) le pairs in AP is calculated as cr ( d P )  = 1 ) 7' ( '/ ) 11~3 , 1) PSF (~? , 2\[V \]) pT(V2I'rl , 2) PT(7~l\[?)2) (3(\[C0(~%1)C0(Vl)C0(~'1 , 2) C0('02)\]-1 . ( g ) Eq . (8 ) captures the intuition that the correlation score between verbs and nouns in AP is an inverse function of their type frequency  . 
Nouns and verbs with high type frequency occur in many different pairs : the less selective they are  , the smaller their semantic contribution to cr(AP ) . 
Our preference tbra(AP ) overel(v , n ) underlies the definition of correlation score of SI given in eq  . (9) ( see also section 4) . 
-_-Z(9)
APESI 2.3 Breaking the symmetry
In section 2 . 2 we assumed , for the sake of simplicity , that verbs and nouns are possibly related through one syntactic function only  . Ination is allowed to wtry . Nonetheless each r clal ; edS\]contains nouns which always combine with a given verb with one and the  . same syntactic . /: unction . Clearly , the Sallle is no ; true of verbs . 
Suppose that an S1 contains two verbs vk and vt ( say drive and pierce ) and two nouns ni and nj ( say nail and peg ) that ~ rerespecl ; ivelyel ) jeer and subject of ' v l ~ and y r . The type of similarity in the resulting n ( mn and verb clusters is of a completely ditti ; rent nature : in the case of n(mns , we acquire dist'rib , utionally parallel words ( e . g . nail and peg ); in the case of verbs , we get distrib'ution a Ily correlated words ( say drive and pierce ) which are not interchangeable in the same conl ; exl ;  . Mixing the two types of distributional similarity in the same class makes little sense  . Hereafter , we will aim at maximizing the similarity of disl ; ributionally parallel nouns . In doing so , we will use functionally hel ; erogencous contexts as in (2) . This breaks classitication symlne , ry , and there is no guarantee I ; hal ; semantically coher(mt verb clust ; ersber cl ; m'ncd . 
3 The method
The section illusl ; ratcs an at ) plication of the principles of section 21 ; () 1 ; t 5o task of clustering the set of object ; sot ! avo , r l ) on t ; he basis of a repository of flmctionallymmol ; al ; edcont ( ; xts . 
3.1 The knowledge base
The training evidence is a Knowledge . Base ( KB ) offlm (' tionally anno ; ated verb noun 1) airs , in s ; mltiating a widerall g ~ e of syntactic relations : a  ) vert ) objecl ;  , e . g . (, ~' a , , , . ~ , , , ' c ,  ~ , ' ol , lc , , z , obj ) ' cause-1) roblen l '; b ) verb subject , e . g . ( capit are , pwblcmasubj ) ' occur-problem ' ; c ) verb prepositional_complement , e . g . ( recap-pare , probIcma , in , ) ' run_into-problenl ' . 
The KaY contains 43 , 000 pair types , automatically extracted from different knowledge sources : dictionaries  , both bilingual and monolingual ( Montemagni 1995) , and a corpus of ti-nancial newspapers ( Federicistal .  1998) . The two sources rettect two ditt'erent modes of lexical usage : dictionaries give typical examples of use of a word  , and rmming corpora attest actual usage of words in specific enfl  ) edding domains . These differences have all impact on the typology of senses which the two sources  1  ) rovi ( le evidence for . General dictionaries tes-titly all possible senses of a given word  ; tyl ) ical word collocates acquired from dictionaries tend to cover the entire range of possible senses of a head word  . On the other hand , unrestricted texts reIlect actual usage and possibly bear wit-hess to senses which are relevant to a specific domain only  . 
3.2 The input words
There is abundant psycholinguistic evidence that semantic similarity between words is em-inently conI  ; exl ; sensitive ( Miller and Charles 1991) . Moreover , in many language processing tasks , word similarity is typically judged relative to an actual context  , as in the cases of syntactic disambiguation ( both structural and fulwtional )  , word sense disambiguation , and selection of the contextually approt ) riate transla-1 ; i one quiw flent of a word given its neighl ) our ing words . Finally , close examination of real data shows that ( titl'erellt word sense select classes of complements according to different dilnensions of semantic similarity  . This is so pervasive , that it so on be ( : omes imposs it ) let ot ) rovide an efl'ec-live account of these , dimensions independently of the sense in question . 
Ewduation of botll accuracy and usability of any autontatic classitication of words into semantic clusters cammtlint artificially eludeth  (  ; 1) asic question " similar in what respc , ct ; ?" . Our choice of input words retlects these concerns . 
\ ? e automatically clustered the set of objects of a given verb  , as they arc attested in a test colpus . This yields local lexicose man ; i classes , i . e . conditional on the selected verb head , as opposed to global classes , i . e . built once and t brall to accomlt t br the collocates of any verb  . 
Among the practical advantages of local clas -sitication we should at least mention the following two  . Choice of a verb head as a perspec-tivizing factor considerably reduces the possibility that the same polysemous object collocate is used in different senses with the same verb  . 
Fnrthermore , the resulting clusters can give in-tormal ; ion about the senses , or meaning facets , of the verb head . 
a . a Identification and ranking of noun clusters For the sake of concreteness  , let us consider the tbllowing object-collocates of the Italian verb 
FLESSIONE , RIAL ZOCRE SCITA , FLESSION ECRESCITA , GUAI0CRESCITA , PROBLE MACRE SCITA , RITARD 0 FLESSIONE , PROBLE MAFLESSIONE , RIAL ZO GUAI 0 , PROBLE MARIDIMENSION AMENT 0 , RITARD 0
Figure h Some S is head word caus arc.
: CAUSARE/O , REGISTRARE/O:CAUSARE/O , EVIDENZIARE/S , 
MEDIARE/O , MOSTRARE/O ~
PRESENTARE/S , PRESENTIRE/O
REGISTRARE/O , REGISTRARE/$:CAUSARE / 0 , PROVOCARE / 0
AVERE/S~CAUSARE/0,EVIDENZIARE / 0
PORRE/S , PRESENTARE/S
CAUSARE/O , USARE/S
CAUSARE /0, PRESENTARE/S,STARE/S
CAUSARE/0, REGISTRARE / 0
REGISTRARE/S , SUBIRE / 0
CAUSARE/0, CAVARE--SI/S , INCAPPARE/S
CAUSARE/O , GIUSTIFICARE/O relative to the collocates of the causare ' cause '  , as they are found in a test corpus: appcs antimento ' increase in weight '  , crescita ' growth ' , flession c ' decrease ' , guaio ' trouble ' , p ~ vblcma ' prol)lem ' , rialzo'rise ' , ridimension am cn to ' reduction ' , ritardo'de lay ' , turbolenza ' turbulence ' . 
Clustering these input words requires preliminary identification of Substitutability Islands  ( Sis )  . An example of SI is the quadruplet brmed by the verb pair caus are ' cause ' and in-eap parc'rnn into ' and the noun pair guaio'trouble ' and problema ' problem '  , where menfl ) ers of the same pair are intersubstitutable in context  , give :: the constraints entbrced by the AP type in  ( 2 )  . Note that guaio and problem a are objects of eaus are  , and prepositional complements ( headed by in ' in ' ) of in cappare . This makes it possible to maximize the s in filarity of trouble and problem across fimctionally heterogeneous contexts  . 
Bigger S is than the one just shown will form as many APs as there are quadruples of col: -textually interchangeable nouns and verbs  . We consider a lexicosemantic cluster of nouns the projection of an SI onto the set of nouns  . Fig . 1 illustrates a sample of noun clusters ( between curly brackets ) projected from a set of S is , together with a list of the verbs tbund in the same S is  ( the suffix ' S's t and s t br subject , and ' O'f or object ) . Due to the asymmetry of classification , verbs in S is are not taken to tbrm part of a lexicosemantic cluster in the same sense as nonns are  . 
7 . 04509e-O5 GUAIO , PKOBLEMA 7 . 01459e-O5RIDIMENSIONAHENTO,RITARDO 4 . 65858e-O5CRESCITA,FLESSIONE
I . T5699e-O5FLESSIONE , RIALZO9 . 49509e-O6APPESANTIMENTO , CRESClTA , FLESSIONE , RIALZO1 . 88964e-O6 CRES CITA , GUAIO 1 . 19814e-O6 CRES CITA , RITARDO 8 . 84254e-OTCRESCITA , PROBLEMA 6 , TI41e-OTFLESSIONE , PROBLEMA Figure 2: Nine topmost scored noun clusters Not all projected noun clusters exhibit the same degree of semantic oherence  . Intuitively , the cluster appes an time n to crescit a flession one riaIzo ' increase in weight  , growth , decrease , rise ' is semantically more appeMing tlmn the cluster crescita problema ' growth problem '  ( Fig . l) . 
A quantitative measure of the sen : antico he-sion of a noun cluster CN is give:: by the con'e -lation score ~  ( SI ) of the SI of which UN is a projection . In Fig . 2 noun clusters are ranked by decreasing vahms of cr  ( SI )  , calculated according to eq . (9) . 
3.4 Centroid identification
Noun clusters of Figs . 1 and 2 are admittedly considerably finegrained . A coarser grain can be attained trivially through set union of inte : '- secting clusters  . In fact , what we want to obtain is a set of mazimally orthogonal and semantically coherent noun classes  , under the assumption that these ( : lasses highly correlate with the principal meaning components of the verb head of which input nouns are objects  . 
In the algorithmew fluated here this is achieved in two steps : i  ) first , we select the best possible centroids of the prospective classes among the noun clusters of Fig  . 2; secondly , ii ) welm np outstanding clusters ( i . e . clusters which have not been selected in step i ) ) around the identified centroids . In what t bllows , we will only focus on step i ) . Results and evaluation of step ii ) are reported in ( Allegrini et al 2000 )  . 
In step i ) we assume that centroids are disjunctively defined  , maximally coherent classes ; hence , there exists no pair of intersecting centroids . The best possible selection of centroids will include nonintersecting clusters with the highest possible cumulative score  . In practice , the best centroid corresponds to the best centroid is the cluster with the second highest o-  ( SI ) and no intersection with the first ; centroid , and so on ( the ith centroid is 1; 11(' , i . -th highest chlster with no intersection with the tirsti-  1  . centroids ) until all clusters in the rank are used Ill )  . Clusters selected as centroids in the caus are example above ~ tre : GUAIOPROBLEMA  , RIDIMENSION AMENTORITARDO , CaP . SCITAFL ~ . SS-rONE . 
Clearly , this is not the only t ) ossible strategy t ' or centroid selection , lint certainly a suitabh ; one giv ( ; nour assulnl ) tionsmM goals . To stunUl ) , the targeted classification is local , i . (' . , conditional on a specific verl ~ head , and orthogonal , i . c . it aims at identifying maximally disjulmtive classes with high correlation with the principal meaning  ( ' Oral ) orients of the vert ) head . This strategy h ; adsto identifical fion of the different senses , or possibly me , ruing facets , of avert ) . 
In tl teir turn , noun clusters may capture sul ) -tlesemm~tic distinctions . For instance , , a distinction is made between incremental eveni ; sor results of incrt ' an entale , vents , which 1 ) resut ) l ) OSe~scalar dimension ( as in the ease of cre , ,s'cita , /lcs sione ' growth , decrease ') and re , scheduling eve , nts , where a change occurs with respect to a previously planned event or object  ( see the centroid ri dimensiov , ament or itardo : reduction debw') . 
4 Experiment and evaluation
We , were able to extract all Sl's relative to the entire  K\]3  . However , we report here an intrinsic evaluation of the accuracy of acquired ce  . ntroids which involves ( ) lily a small subset of our results , since provision of a refhrence class tyl ) ology is extremely labour intensive .   1 We consider 20 Italian verbs and their object collocates . g The object collocates were automatically extracted fi'om the " Italian SPAIIKLE Reference Corpus "  , a corpus of Italian financial 1For an extrinsic evahlation of the proposed similarity measure the reader is referred to  ( Montemagni et aI . 
1996; Briscoectal . 1999; Federicictal . 1999a ) . 
2 Thex , ' st verbs are : a . q giung crc ' add ' , aiutare ' hell ) ' , a , sl ) cttarc ' expect ' , cambiarc'change ' , C(t * ta O , ?' t:t(:tllSe:~chic dcrc'ask' , consid c . rarc ' consider ', d are . ' give ' , dc-cider c ' decide ' , for nive'provide ' , muover c . ' move ', pcrm ~' . -ttere ' allow ' , portarc ' bring ' , p ~ wlurrc ' produce ' , sccglicrc ' choose ' , sentir c ' feel ' , stabilire ' establislF , tagliarc'cut ' , terminate ' end ' , trovarc ' find ' . 
newspapers of about one million word tokens ( Federicic tal .  1998) . 
l ? or each test verb , an indetmndent classification of its collocates was created lnanually  , by partitioning the collocates into disjoint sets of semantically coherent lexical preferences  , each set pointing to distinct senses of the test ; verb , according to a reference monolingual dictionary ( Garzanti 1984 )  . This considerably reduces the anlount of subjectivity inevitably involved in the creation of a reference partition  , and minimizes the probability that more than one sense of at  ) olysemous noun can appear in the same class of collocates  . 
The inferred centroids , selected from clusters ranked by c ~ ( SI ) defined as in ( 9 )  , are t ) rojected ~ gains the reference classification . Precision is delined as the ratio between 1 ; t1( ; mm flmr of con-troidst ) roperly in chlded in one reference class and l ; henmn ber of inferred centroids . Recall is defined as the ratio between the number of relhr-time classes which properly in chlde at least one centroid an  ( t then mn be r of all reference classes . 
Fig . 3 shows results for the sets of object collocates of  1  ) olysemous ; est verbs only , as lttOltOSe-mous verbs trivially yMd 100% precision recall . 
An average , w flue over the sets of object collocates of all verbs is also shown  , with 86% 88% of precision recall . Another average value is also l ) lotted ( as a blackul ) right triangle )  , ol ) -l : ained\] ) y ranking n ( mn clusters l ) y  ~ ( S\] ) calculated as ill ( 10 )  . This average w flue ( 53% 53% precision recall ) provides a sort of baseline of the difliculty of the task  , and sheds considerable light on the use of APs , rather than simple verb noun pairs , as inforlnation unit sibrme a suring internal cohesion of centroids  . 
( si ) =_(10) ( n,v)G9 15 Conclusion
We described a linguistic knowledge acquisition model and test edit  ; on a word classification task . 
The main points of our prot ) os alare : ? classification is asymmetric , grounded on principles of machine learning with intinite memory  ; ? the algorithm is explorative and non -reductionist  ; no a priori model of class dis-!AIUTARE
IICAMBIARE 0.9 CHIEDERE
CONSIDERARE ?- bARE',?DECIDERE 0.8 PORTARE
PRODURRE?SCEGLIERE~SENTIRESTABILIRE ~ TAGLIARE\[  :1~ ? ~: TFIOVARE 0  . 6 ~' AVERAGE(AP)~AVERAGE(pai0i?io . 5 :: . i ?'1
Ii 0.3 0.4 0.5 0.6 0,7 0.8 0.91
PRECISION d < ~0.7
Figure 3: Centroid precision and recall for object collocates of polysemous verbs  . 
tril ) ution is assmned ; ? classification is modelled z~s the task of forming a web of context dependent semantic associations among words  ; ? the approach uses a context--sensitive notion of semantic similarity  ; ? the approach rests on the notion of analogical proportion  , which proves to t ) ea reliable intbrmation refit for measuring semantic similarity  ; ? analogical t ) roportions are harder to track down than simple pairs  , and interconnected in a highly complex way ; yet , reliance on data types , as opposed to token frequencies , makes the proposed method comtm-rationally tractable and resistanto data sparseness  . 

Allegrini P . , Montemagni S . , Pirrelli V .   ( 2000 ) Controlled Bootstrapt ) ing of Lexico semantic Classes as a Bridge between Paradigmatic and Syntagmatic Knowledge: Methodology and Evaluation  . 
In Precccdings of LREC 2000, Athens , Greece
MayJune 2000, pp . 601-608.
Briseoe T . , McCarthy D . , Carroll J . , Allegrini P . , Calzolari N . , Federici S . , Montemagni S . , Pir-relli V . , Abney S . , Beil F . , Carroll G . , Light M . , Prescher D . , Riezler S . , Rooth M .   ( 5999 ) Acquisition System for Syntactic and Semantic Type and Selection  . Deliverable 7 . 2 . WP7 , EC project SPARKLE " Shallow Parsing and Knowledge Extraction for Language Engineering "  ( LE-2111 )  . 
Federici , S . , Montemagni , S . , Pirrelli , V .   ( 1999 ) SENSE : an Analogy based Word Sense Disambiguation System  . In M . Light and M . Pahner ( eds . ) , Special Issue of Natural Language Engi-neer in 9on Lexical Semantic Tagging . 
Federici , S . , Montemagni , S . , Pirrelli , V . , Calzolari , N .   ( 1998 ) Analogy-based Extraction of Lexical Knowledge from Corpora : the SPARKLE Experience  . In Proceedings of LREC1998, Granada,
SP , May 1998.
Fodor , J . A . (1998) Concepts . Where Co . qnitiv c Science Went Wzvng . Clarendon Press , Oxtbrd , 1998 . 
Garzanti (1984) ll Nuovo Dizionario Italiano
Garzanti . Garzanti , Milano , 1984.
Grefenstette , G .   ( 1994 ) Explorations in Automatic Thesaurus Discovery . Kluwer Acadenfic Publishers , Boston , 1994 . 
Lin D .   ( 1998 ) Automatic Retrieval and Clustering of Similar Words  . In Proceedings of COLING-ACL'98 , Montreal , Canada , August 1998 . 
Miller , G . A . , Charles , W . G .   ( 1991 ) Contextual Cor-relates of Semantic Similar iW . In Language and
Cognitive Processes , 6(1), pp . 128.
Montemagni , S .  (1 . 995 ) Subject and Object in Italian Sentence Processing  . PhD Dissertation , UMIST,
Manchester , UK , 1995.
Montemag Ifi , S . , Federici , S . , Pirrelli , V .   ( 1996 ) Resolving syntactic ambiguities with lexico semantic patterns : an analogy-based apl  ) roach . 
In Proceedings of COLING96 , Copenhagen , August 1996 , pp .  376 381 . 
Pereira , F . , Tishby , N . (1992) Distributional Similarity , Phase Transitions and Hierarchical Clustering . In Working Notes , Fall Symposium Series . 
AAAI , pp . 5464.
Pereira , F . , Tishby , N . , Lee , L .   ( 1993 ) Distrilmtional Clustering Of English Words . In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics  , pp .  183 190 . 
Rooth , M .   ( Ms ) Two-dimensional clusters in grammatical relations  . In Symposium on 12epresenta-tion and Acquisition of Lcxical Knowledge : Polysemy , Ambiguity and Gcncrativity , AAAI 1995 Spring Symposium Series , Stanford University . 
Rooth , M . , Riezler , S . , Prescher , D . , Carroll , G . , Bell , F .   ( 1999 ) Inducing a Semanticallt Annotated Lexicon via EM -Based Clustering  . In Procccdings of the 37th Annual Meeting of the Association for ' Computational Linguistics  , Maryland , USA , June 1999 , I ) P .  104-111 . 
Schfitze , H . , Pedersen , J .   ( 1993 ) A vector model for syntagmatic and paradigmatic relatedness  . In Proceedings of the 9th Annual Confcrcncc of the UWC entrcfor " the New OED and Text  12cscarch  , 
Oxford , England , 1993, pp . 104-113.

