COMMUNICATING WITH MULTIPLEAGENTS *
Elizabeth A . Hinkelman and Stephen P . Spackman
Deutschesl'~orschungszentrumf / itKfinstl ichelntelligenz 
Sl ; uhls at zenhausweg 3, 66123 Gerlmmy
hinkelman@dtki.uni-sb.de,stphen@_acm.org

Previous dialogue systems have focussed on dia.
logues betwe (: n two agents . Many ~ q ) plications , however , require conversations between severall ) articipants . This paper extends speech act deft-nitions to handle multiagent conversations  , based on a model of multiagent belief attr ibution with some unique properties  . Our approach as , lie advantage of capturing aln n nlmr of interesting phenomena in a straightforward way  . 
Motivation
The rise of spoken language NI , P applications has le . d to increased inte . rest in such issues as realtime pro--cessing and online error recovery  . But dialogue is an inherently online process ; this manifests in such linguistic phenomena as turntaking\[Sacks et al  ,  1974\] , repair \ [ Schegt offetel . , 1977\] , and content grounding \[ Chu:k and Schaefer ,  1989\] . Grounding is the phenonlenon that establishes shared beliefs  , lbr which simply making or hearing an utterance does  ) to t suffice , It makes hearers into hill participants who actively signal success or failure of communication  , as in this excltange :
Steph : ; hat's friday at seven then.
Lgnn : at , seven.
Our long term goal is to show how , Ji ' om the perspective of a pattieperil , one plans and acts in an environment with other communicating individuals  , even when those other individuals are not perfectly reliable  , and ewm when the groups in volw ~ . d may be large enough that it is impractical to model all participants  . 
For examl ) le , consider this familiar exchange , from the point of view of someone whore members that  ; tienext grouI ) meeting is on tuesday : Jan : so we should dro I ) the ram . cancelt it (' . 
meeting on thursday.
Lestuesday
All , ; tuesday
Louyeah.
Jan \[ yes , right.
Ilere both our subjeer , and another participant of_fera correction , which is confirmed by l , ou and by the original speaker . Other participants may I ) e pre . sent . 
In this paper , we focus on the elfects of comnm-nicative actions on the particil  ) ant's model of the situ-at , ion . In contrast with previous di Mogue work , we are * The wm'k underlying this paper was suppovlx  ,  . d by a re-si ! al ' (: hgratl(; , \])' KZI'FW 9002 0 , fl ' omt , he Gel'tn & nthm des-n finisterium ffir 1 , ' or schung mid Technologie to the 1 ) FK1 project DISCO . 
interested ill czuses whe . rethere are more than three agents , in a group often or more , it is hard to imagine . 
how a participant can track the beliefs and disbeliet~s of others accurately  ; it , may not even be practical to track who they all are  . 
The advantages of analysing natural language utter -elites ~ us coilimnnicative actioi  , s are by now well unde > stood ; they serve to slmnnarise conversations for long term storage \[ Schupeta  , t993\] , as a basis for generation \[ Moore and Paris ,  1989\] , in top--down prediction of utterance flmction and structure \[ Alexanders souelel  . , 1!)94\] , and most importantly , to provide a representation of natural language utterances that is uniform with that used in general facilities for planning and action \[ Allen  ,  1)83\] . 
We tollow \[ Traum and llinkehn an ,   1992\] in regarding speech acts as fully joint actions between conversational participants  . Not only are joint speech acts co . .operatively undertake . n , but they have at least nor a- . 
nelly . jointetDcts : if they complete but still fail to result in shared goals or shared beliefs  , this should be attributable to politeness , dishonesty ( of . \ [ Perrault , 1991)\]), or other social funelions . 
This perslmctiw ; on speech act processing forces us to deal with issues of jointly helgoals and beliefiqata w  . ' ryb ~ usic level . These matters are by now quite well-studied , but analytic solutions from logical tirst prim cipies tend to be relatiw  ; ly complex , yielding neither perspicuous notations nor plausible computational or cognitive models  . In short , normative analyses are not necessarily descriptive  , ones . 
Aside from relatiw ~ ly involved calculations , there are sew : ral sources of dilliculty : ? when n rultiple participants are involved  , then nm-I ) er of ' belief spaces )   ( patterns of modal embedding ) tends to blowul ) rapidly ; ? when the actual state of at l ; ~ irs regarding the extent of others ' knowledge is unknown  ( a ~ s is the ease \[' or an online converse ( renal participant ) then mn be r of cases to be considered can become large  ;   , , when dealing with large organisations , ome form of aggregate modelling I ) ecomes an absolute necessity . 
Consider , for instanee ,  ( ; lie case in which you believe that the governnie ut knows yourilt come  , frol-nlash year . 
What you believe is not that each individnal govern-menmnl  ) loyee knows it , bnt that anyone from tile tax department , wl , ose1) usiness it is to know , and who actually wants to , will . Thus we would typically as -~' ; il nie that an employee of the tax department who , in a professional capacity , l nakes contact , with your accountant , would actually have this information to hand . We want to abstract away from the commuui-the availability of the conclusion  ; and we would ideally like to do so in a manner consistent with the needs of online dialogue processing  . 
In the next section we describe a method of representing the information ecessary for processing multicarticipant speech acts  , one which treats groups as agents in their own right  , and does so in such a way that speech acts can operate on them naturally and directly  . 
Corporate Agents and Attitude
Propagation
The basis of our model is the corporate agent . These ' agents ' represent groups , but , like individual agents , they may have beliefs ( which we write B agent P ) and goals ( Gagent P ) ascribed to them directly . Thus , they can be thought of as intermediate in status between sets of component agents and prototypical group members  . They differ from simple sets in three striking ways : first  , they are intensional structures that may be distinct even when coextensive  ( as , for example , when the members of the marketing department form a vol-leyball team on tuesday nights  )  ; second , attitudes are ascribed to them directly , and potentially at variance with any attitudes we might a  . scribe to their members , or other subagents ( see the discussion section ) ; and third , that ( other than perhaps in the case of a ' real ' , singleton agent ) subsethood is not a sufficient condition for subagency -- some in tramural volleyball teams are clearly  , associal entities , agents of the company , and others rather the reverse . 
While not in a position to make detailed psychological claims  , we believe that structures of this kind are compatible with what we know about the linguistic and cognitive handling of aggregates in other contexts  . 
These corporate agents will be used to represent both long term social groups and transient groups of conversational participants  . 
(sfe~ve Ja~y ~ S also a subagent ~17 ery on c
D_J = tU'UU
Figure 1: Agents
In the remainder of this paper we illustrate relationships between agents with diagram such as that in figure  1  . Here the playing-card shapes represent agents and the heavy lines connecting them the subagent relation  ( _ ) : the agents include the system itself ( sec . Jan ) , the system's boss ( Jan ) , Jan's office , their coworker Les , their common corpora temployer ( Widget Corp ) , and another ' random ' person , Steph , who does not belong to Widget Corp . Later we will represent attitudes ascribed to agents by smalls tlapes within the playing cards and their propagation by thin curved arrows between them  . 
Note that since we are discussing the system's own representation of the world  , the double-bordered playing card really represents the system'self-model and the whole diagram the system  ; but we shall not be-labour the point here , assuming that information pass-es freely between the two  . 
The model we use to compute the transfer of attitudes between agents is approximate  , partly to simplify computation and partly because it is in any case unusual to have enough empirical data to compute an exact solution  . The same model ( with parametric variation in the domain knowledge  ) is applied to all the attitudes the system ascribes to agents  ; in our present implementation , these may be either beliefs or goals ) Unlike representations based on conventional logics of belief  , it does not introduce nested contexts unless they are explicitly represented in the content of utterances  ( as would be the case with a sentence like " But Lynn thinks we should have the meeting anyway  . ") , though extended reasoning processes may compatibly do so  . 
In this simplified model , the propagation of attitudes is performed lazily , as determined by their semantic relevance to the varions agents involved  . Ideally , this judgment would derive from social world -knowledge and information about the purposes of groups  ; in our current implementation it is approximated using a simple classification of corporate agents  , participant roles and message topics into the domain ontology  . Delays and chance are not modelled ; all relevant attitudes are presumed to propagate between agents  , subject to the following constraints : idgetCor p "'"/\] ~ i '"'"'"'"> ' x  . , impossible -/// .   . ",,7L27"?"~_~' sec'JanUJ an OSteph
Figure 2: Common context constraint 1Since our n lodel is not analytic we do not want or need a notion of ' knowledge ': the system lacks direct access to empirical truth and to social consensus  , and does not have the cognitive sophistication to validate argmnents against stone independent notion of rationality  . In short , none of the usual theories of truth can in principle be made to apply  . 
1192 l . Attitudes propagate only between superage ut and subagent  ( or vice versa )  . This stipulation anlounts to saying that comnmnication only occurs between agents in the presence of some common social context  . Of course , new corporations can be introduced when new social groups form  . 
Thus in ligure 2 , beliefs ascribed to Widget Corp can propagate to the subagents  , Jan and Jan's electronic secretary ; but they do not reach Steph , who is not a subagent of Widget Corp . ~ We use the convention that attitudes are drawn filled in if they are known by direct evidence  , hollow otherwise ; and that dotted structures are ' negated'---they do not arisems drawn because they violate some constraint under discussion  . 
~ifile t ' Jan '''' conflicting prior J ~ blocked- belief ~____~sec'Jau WJan 
Figure 3: Propagation as default 2 . Attitude propagation is only a default ( the particular choice of default logic need not concern us here  )  . 
If there is direct evidence for a scribing a contrary attitude to an agent  , propagation from an external som:ce is inhibited . This property is crucial to modelling dishonesty , negotiation , compromise , and a typical group members in general . 
Such blocking is illustrated in figure 3 . In this ease our model of Jan fails to inherit a goal from otfice  . Jan because it conflicts with another goal ( the square box ) for the ascription of which to Jan we have prior independent evidence  . 
3 . The system may never assume that its own attitudes antomatically propagate upwards to a snperagent  . 
The ut ) ward attitude propagation path models tt , e effect of external agents independently attending to their various communicative goals  , but the system nmst still plan--and execute-its own actions  . 
Thus , in figure 4 the system--see . Jan--is prohibited from simply assuming that its own beliet ~ are shared by its employer  , though those of fellow employees would be propagated when otherwise consistent  . ( Some hmnans seem to relax this constraint . )  2In order to place some limit on the promiscuity of attitude propagation  , it seems best to insist that indirectrans-fer must occur through as iligle agent that is a transitive Sllper - or Sill  ) -agellt of both terniinal agents , Thus , even if Jan and Steph both belonged to some peer of Widget-Corp with a similar seniantic domain  , propagation would still be not permitted along the resulting N-shaped path  . 
Gonlmon membership nE very one will not transmit beliefs eithe  . r , because its relewuice tilter is maximally restrictive  . 
/ffice . Jan //, //\ require sxplicit action 2

Figure 4: The exceptional natnre of self ~ office . Jan
Figure 5: The need for speech 4 . Noncecorporations , it roduce dynamically to represent the temporary grouping of participants in an active conversation  , ever inheritatitudes from their subagents , but must acquire them < as the effects of observable actions  . The idea here is that while participating in ( or directly observing ) a conversation , the system is in a position to observe the construction of the public record of that conversation \[ Lewis  , 1983\] directly , and this record consists exactly to the attitudes we wish to ascribe totile conversational group itself  . In conversation even a new ' unspoken understanding ' should be based on inference fi ' om observed communication  , and not just the sys-tem's private beliefs about other participants ' views  . 
The fact that we still permit conversational groups to inherit from superagents allows us to place a discussion within a social context that supplies shared background a  , ssumptions . The fact that we permit their subagents t , oinher it from them models the actual adoption of information from the public record by individual participants  , including the system itself , without additional mechanism . 
Figure 5 depicts this situation : noncel , the coll-versational grouping , represents a shared social con-strnct distinct from our understanding of Jan's private views  . This allows us to deal gracefully with the situation in which we  , see . Jan , catch ( or perhaps even conspire with ) Jan in telling alie . 
The most important property of this model of attitude ascription is that the only belief spaces it imtroduces are those that are independently motivated tual conversations in which the system participates  . 
This reduces the chance that the system will become mired in irrelevant structural detail  , and specifically avoids the'spy novel'style of belief space nesting that is characteristic of cla  , ssic alnormative models . Attribution by default inference allows an individual to be represented as a member of several different groups holding conflicting beliefs  , and inheriting only those beliefs consistent with those represented as being held privately  . 
The results are thus substantially different from those obtail  , edin classicalogics\[Allen , 1983; Kraus and Lehmann , 1988; Appelt , 1985; Cohen and Levesqne ,  1990\] . They differ from other pathbased algorithms \ [ Ballim and Wilks  ,   1991\] in the provision of semantic relevance conditions and in addressing the need for shared attitudes by a scribing them directly to groups  , rather than by maintaining complex accounts of which agents believe what  . This allows us to describe and process conversational mechanics with on trecourse to nested  ( x believes that y believes that .   .   . ) belief spaces , though snch structures may remain necessary for other  , less routine feats of cognition . 
In the next section we show how our model of attitude a scription can be used to implement multipar-ticipant speech act processing  . 
Multiparticipant Speech Acts
As in \[ Traum and Hinkelman ,  1992\] , we assume that a core speech actisultimately realised by a sequence of utterances thatern body the grounding process  . The model requires thai ; the definitions of the speech acts themselves abstract away from grounding and provide high level actions that can be integrated with nonlinguistic domain actions in planning  . Using our multiagent attitude attribution mechanism  , we can simplify matters fllrther , defining speech acts as joint actions whose effects apply directly to the conversational group being modelled  . 
Consider the generalised action operator representing one simple core speech act : 
Informal ) conditions : BbPAbKaA live a effects : Bap This In form is a true joint action  . Agent a is the nonce corporation representing all the participants taken jointly  ( the live predicate requires that this nonce correspond to an a ongoing conversation  )  . Though the singleton subagent b is the source of the information  , the action has its effect directly on our model of the group  . From that point propagation downwards to the individual participants is a function of the attitude as-cription model  , and is subject to the constraints given above .   ( The system effectively assumes that corresponding updates actually take place in the minds of the conversational participants  . ) The correctness of this formulation relies on two facts  . The first is that the grounding structure realis-3Our current implementation actually deals with ( mail rather than live speech , and must cope with mul ( . ip leacl ; ivedialogues . 
ing the core speech act operator ensures the content is successfully conveyed  . The second is that if a speech act that has an efl~ct on the conversational gronp is flflly realised and properly grounded  , then any hearer who dissents from those effects must explicitly act to cancel them  . That is , acknowledgement of receipt of a message stablishes a presumption of assent to the content  . Note , however , that when the speech act remains unchallenged this means only that the conversational participants will let its t and as part of the public record  ; it does not mean that they are tn dypersuaded of its content  , and the rules we have given only predict that they adopt it if there is no evidence to the contrary  . 
St , ecessful requests have effects on the goals rather than the beliefs of the group  . It is crucial that both communicative and noncommnnicative are introduced  . 
The first goal below is noncommunicative and represents simply that the requested action be performed  . 
Note that although the requested action's ( possibly corporate ) agent participates in the dialogue , there is no restriction that it not include the requester  . Writing Bifap for Bop VBa~p and O for eventually  , we have
Request ae conditions : agente Ea Alivea effe . cts : ( ~ a < ~ eAG a B if a@e The second goal in the effects is a communicative one  ; the group acquires the goal of finding out whether the requested action will be performed  . The consequence of this is that the requester gets an indication of whether the request was successful : evenlm der the assun rption of cooperativity  , goal conflicts and plan constraint sometimes lead to the rejection of a successfully communicated request  . 
In tile next section we describe how OOSMA , our implemented calendar management system , processes all actual exchange . 
Processing an N-Way Speech Act
Speech acts like the above can now fignre in the plan-and inference-based algorithms of communicative intelligent agents  . Since dialogue may include unpredict-ed events , such agents must be able to react to changing circumstances rather than relying completely on advance planning  . As each incoming speech act arrives , the agent updates its beliefs and goals ; these beliefs and goals are the basis for subsequent action  . This is not only appropriate for the interface between task and dialogue  , but absolutely crucial for the grounding process . 
A typical application task for Noway speech acts in a multiagent environment is appointment scheduling  , with dialogue system serving as personal appointment secretaries to human agents  . Our implemented system , COSMA , operates in this domain . We model a human/secretarial pair as a kind of corporate agent in which beliefs about appointments propagate up and down from both members  , and in which goals about appointments propagate fl ' om the hnman up to the pair and from there down to these cretary  . 
When this example begins , the dialogue system retary to a human agent ( Jan )  , forming the hu-man/secretarial corporation of liee . .hm . Jans ends sec . a a a email text ; referring to a preexisting appoint-
Inent :
Jau : Cancelt it (' , meeting with the hardware group . \[--', sec . aan \]'\]_' he COSMA system interprets this input by first constructing a noncecorporation for the new dialogue  , nonce 1 , with dan , see . Jan Enonce/E of l~ce . a an Q = GO cancel ~ e ~ . ja . meeting 2~ office . Jani = GBl rn ~* l ~ can c ? l ~' l = " meeling 2-: ~ . Transmission by core al~ee chacti ~ L_~ec . Jatl Jan
Figure 6: Making a request
All members of a noncecorporation inherit belief ~ and communicative goals from it  ;  . The interpretation of the first utterance as a speech act is : Request Jan  , sec . Jan Cancelsec . d anmeeting2 This interpretation is checked for consistency with context according to the method of \[ l linkel mau  ,  1992\] , and forms an acceptable reading . Its effects on the group are asserted ( Q , @ in figure 6):
Gnorn : el ~ caheel see . dan meeting 2
Gnoncel B if noncel 0 cancel sec . 3 an meeting 2-_~ officc .   . lau ~= ( y ~' cancol8ec,l ~ nlteetllg2
I = GBrO cancel . meethlg 2
A = O can col~ea anltlem hng2//g,
Figure 7: t /. esponding
When it has finished processing all inputs , the system exal nines its own goals in order to determine what actions  , if any , it will perform . It finds no immediate priwttegoals , but there are two that it inherits . Because it is a participant ; in the ongoing discussion with J an it inherits the nom'e's communicative goalgif  .   .   . 
(@ in figure 7) . It also inherits the goal to ensure that the cancellation actually does happen  ( @ ) 4  ( A less compliant agent thau the current COSMA wouhl not acquire non-communicative goals directly from the nonce  , but would obtain the cancellation goal indirectly through office  . Jan . The implementation could be w . 'ry similar , because the indirect inheritance path can be compiled out when the nonce is initially constructed  . ) The dialogue system thus retrieves the following goals : 
Gsec . Jan ~ cancel sec . Janmeeting 2
Gsec . , lanBif noncel0 cancel sec . d anmeeting2 These goals become input for the planning process . 
The first goal can be achieved in the current context by ltr stopening the appointment file  , then performing a stored subplan \[' or cancelling appointment shat includes modifying the databas entry and notifying the participants  . Our reactive algorithm allows com-nlunicative phms to be freely embedded within domain actiotls  , and vice versa . 
l taving found this sequence of actions , the system now knows that the ~> . . . part holds . It is therefore able to plan to Informnoncel(O . . . ), satisfying the second goal (@) . The output for the second goal is : hfform noncel ( Ocaned see . dan meeting 2) see . , lan:Ok,I'll cancelit . \[--~-3 all \]

Figure 8: Informing the group
Finally , it must conlph . ' te the execution of its plan to satisfy the first goal by updating the appointment file and notifying MI participants  . The notification step involves constructing a suitable conversational I:t Oltce  , this time a descendant of Widget Corp itself ( in spoken dialogue this requires , aside front setting up the necessary internal data structures  , meeting the addressees and greeting them ; when communicating via email the analogous requirement is just composing a suit ~ blemail message header  )  . Then , as show in figure 8 , the system initiates a further Informaction of its 

Inform nonce 4(- , 7 ) meeting 2 ) whk : h ( : an be verbalised as follows : see . dan : The meeting of Monday , Feb . 13 at 3I ' M will not take place . 
\[~sec . aan , Jan , gou , LeG Lee\]4 Nol . e that if the system were asked , it could now in flw that , Jan also has these goals , but to hath is is not part of the speech act interpretation algorithm itself  . 


An important property of the corporate agent model presented in this paper is its scaling behaviour  . Although the number of ' agents ' in a nontrivial world model may be large  , we only introduce belief spaces corresponding to ' actual ' objects about which the system has knowledge  . In particular , the corporate agents that are used correspond to either durable social gronp-ings or records of actual conversations  . Individual speech act definitions , though they acconnt for all the agents in the dialogue  , need make reference to at most two agents . 
In contrast with normative models , our speech act processing model at no point requires that individual addressees be modelled  . Of course , dialogue is typically motivated by the desire to modify the addressees ' mental states  , but our system is free to make these updates on demand  . Thus , so long as constructing detailed partner models is not independently necessary  , the effort required to plan and respond to speech acts remains almost constant as the number of conversational participants grows  . 
We have thus achieved the extension of speech acts to multiagent environments  , a step beyond other speech act based models \[ Dols and van der Sloot  , 1992; Meyer , 1992; Bunt , 1989; Traum and I linkehn an ,  1992\] . In the process , we have reduced the complexity of the task /dialogue interface  . 
Widget Corp ~~~'- In once 5
Figure 9: Widget Corp expands
An interesting consequence of not needing to n lodel all members of a conversational group is that it becomes unnecessary to identify them  . While in some circumstances this may be an advantage  , it does leave the door open to an interesting litch : without an independent check  , the system's model of who it is addressing may turn out to be inaccurate  . A related thing can happen when the system plans on the basis of attitude propagation : it can perform an action that ' ought ' to result in a given agent's coming to hold some view through social processes  , but since social channels are quite imperfect , the message never gets through . Human agents are at times more cautious , and may model delays in the grapevine , but this ' losts heep ' phenomenon occurs sufficiently of l  ; en in real life to make the utterance " O h , I'msorry , I guess you were n't at the meeting . " sound very familiar . 
Generalisatiou remains a hard problem , of course.
Our system has no special advantages when faced with a question like " A reconservatives porcupine-lovers ? " Vague questions about large groups require extensive search or some independent theory of generalisation  , and seem to be difficult even for hunians . 
Related to this is the Nixon diamond anomaly faced by many default inference systems  . In our case , when we find propagation paths that will support the ascription of contradictory attitudes to a single agent  , how should we choose between them ? It turns out that selecting whicheve result we first discover we would like to use is a surprisingly good solution  . Such ' arbitrary ' judgments tend to facilitate the conversation by using the inference mechanism not to seek a reliable proof but to find the most convenient supportable argument  , regardless of actual truth . 
Perhaps the most interesting deviation of our model from the behaviour of systems founded on mutual belief is the social fiction anomaly : one can fairly e~i-ly reach a state in which an attitude is a scribed to a corporation which is held by none of its members  . In-credibly , this also corresponds to a familiar situation in everyday life  . Three example should serve to illustrate the point  . In the first place , consider this exchange , in which Janasks Les to compile a tedious report : Jan : I'll need that on my desk by friday  . 
Les : friday , no problem.
Such a dialogue may occur even when Jan will not have time to look at the report until the middle of the following week  , and Lesknows that the work cannot possibly be completed before the weekend  . ' ~ Secondly , we propose the example of a couple who are jointly but not severally on a diet  . When together , neither part nerever takes dessert , and this policy is verbally reinforced . Yet either of ' them will happily join you in eating a large slice of strawber rycheese cake  , if they are apart . 
Finally , imagine that you are alone bicy clist approaching a Very Large Hill  . You might now say to your self--a conversational nonce of one --" It's not far to the top !" Processing this speech act results in another unsupported belief  . You can now try to be convinced . 
In light of all of tile above anomalies , it begins to appear that human agents may be struggling with limitations similar to those of our own model  . 
It may still be objected that on r model falls short in failing to support the detailed'spy novel ' reasoning used in conventional logics of belief  , keeping track of whether Loll believes that Lee believes that p  , and whether or not common beliefs are truly mutual  . Our response is threefold : * Reflective l ) rol ) lem solving is always an option , but in humans appears to be an independent process  . Responsiveness demands make it unsuitable for mandatory online usem dialogue processing  , though it may be important to use models ( like ours ) with which it can be integrated simply . 
* Conversational mechanisms have evolved to cope with the cognitive shortcomings of humans  , qb the S The authors disagree as to whether t , his par ~ , i culm ' pattern is more likely to a rise througla malice or opt in lism  . 
7 196 extent that the pert Brman cerrors of a dialogue agent mirror huin an failings  , co-operatiw . ' recovery performance wil ; hhlltrla\[lcommunicative tools should be enhanced  . 
? Even given access to an ideal normative dialogue model  , a fltll system would be net it li'om running a less precise and lnore descriptive model in parallel  . 
This would a ~ ssistinisolating those parts of a com-municative plait where confllsiollontim part of other agents is predictable  . 
Corporate agents are an alternative to normative logics of belief which capture amind  ) or of interesting social and commtmicative phen on mna straightforwardly  . With their help , we can refornmlate core speech act delinitions cleanly and seahd  ) lyt br the case of n rany agents . The level of planning abstraction that results seems well-suited to the needs of intelligent communicative agents operating in an environment that in-  . 
(: htdesI/laity lnlnlall all agents.
References\[Alexanderssonctal . , 1994\] Jan A lexandersson , l '; lis-almth Maier , and Norbertleithinger . A robust and eflicient three-layeredia log component for a speech-to-speech translation system  , subm .   ( Jon-ference on Applied Natural Language Processing  , 
Stuttgart , 1994.
\[Allen , 1983\] James Allen . ll . eeognizing intentions from natural angm~ge utterances  . In Michael Brady and lobert C . Berwiek , editors , Computalioual
Models of Discourse . MIT Press , 1983.
\[Appelt , 198'5\]D . E . Appelt . Planning English S'en-tences . Cambridge Universityl ' ress , Can , bridge , 1985 . 
\[Ballim and Wilks , 1991\] At ~ al Ballim and Yorick Wilks . Arti\]icial Believers : The Aseriplion of He -lief  . Lawrence I '; rlbaum Assoeiates ~1991 . 
\[Bunt , 1989\] II . C . lhmt . Information dialogues as communicative action in relation to t  ) art ner modelling and inforntation l ) roees sing . In M , MTaylor , 1" . Neel , and 1) . G . llouwhuis , editors , 7' he Struetm'e of Multimodal Dialogue . Elsevier Science Publishers
I /. V .,:1989.
\[Clark and Schaefer , 1989\]flerbert\[1 . (' lark and l '; dward F . Schaefer . Contrilmting to discourse . (,' oqui-live Science , 13:259294, 1 . 98!/ . 
\[Cohen and Lew ' . sque , 11990\]Phillip R . Cohenaud Hector J . Levesque . I'ersistence , intention , and eoln-mitment . In P . R . Cohen , , / . Morgan , and M . E . 
Pollack , editors , Intentions in Communication . MIT
Press , 1990.
\[ l ) ols and van der Sloot , 1992\]I,' . J . I 1 . l ) ols and K . van der Sloot . Modelling mutual el fi ~ et , ; in beliet : based interactive systems . In W . J . Black , G . Sabah , and T . J . Wachtel , editors , Abduetion , Beliefs and ( ; on text : Proeeedings of these eotM1'2 , S'111117' PLUS'workshop in computational pra . qmatie . s , 1992 . 
\[llinkehnan , 1992\]Elizabe . thA . llinkehnan , intonation and the Request /( , ~ uestion l ) is tine tiou . In Proceedings of the h~ternational Co , fi ~ reuce on , ~ , ' poken Language Processing , P , an lf , Canada ,  19!12 . 
\[Kraus and l , ehmann , :1988\] Saritgraus and Dau Ml , ehmann . Knowledge , belief and time . In "\[' hcore & ical(Jomputer , 5' cieuce , vohune 58 , pages 155-174 ,  1988 . 
\[Lewis , 198:t\]I) . Lewis . Scorekeeping in a Language Game , volume 1 , chapter .  13 . Oxford University Press , Oxford , 1983 . l ) hilosophical Papers . 
\ [ Meyer , 1992\]lt . alphMeyer . Towards a conceptual model of belief and intention in dialogue situations  . 
In W . J . Black , G . Sabah , and T . J . Wachtel , editors , Abduction , Beliefs and Context : PT veeedings of the second E , qPRITPLU , q workshop in computational pragmatics ,  1992 . 
\[Moore and Paris , 1989\] J . D . Moore and C . L . Paris . 
Planning text for advisory dialogues . In Proe . Conf of the 27th Ammal Meeting of the ACL , pages 203-211 , Varmouver , l !/8!) . 
\ [ Perrault , 1!)90\]C . II . l ' erranlt . Anal ) plication of default logic to speech act theory . In P .  \[ . Cohen , J . Morgan , ~ tnd M . E . Pollaek , editors , Intentions in
Communication . MIT Press , 1990.
\ [ Sacks et al ,: 1974\]11 . Sacks , E . A . Schegloff , and ( I . A . 
Jef\[hrson . A simplest systematies for the organization of tin : n-taking in conversation  . Language , 50:6967 a 5, 1974 . 
\[Schegloff el al . , 1977\]E . A . Schegloff , G .   . letfers on , and II . Sacks . The preference for self correction in the organization of repair in conversation  . Language , 5:t:36 l,'t 82,1977 . 
\[Schnpeta ,:199:\] A chinl W . Sclmpeta . Cosma : F , inverteilter term in plauerals fidlstudieder verteilten ld  . In Jucrgen Mueller andl ) on ald , q teinel: , editors , lk ' o opericrende A . qenten , Saarbriieken , Get:-many , 1!19:t . 
\[Tranln and llinkehnan , 19!12\]I ) avid 11 . . Traum and Elizabeth A . Ilinkehnan . Conversation acts in task-oriented spoke u dialogue  . Computational Intelligence , 8(:11:, 575 .  99, 1992 . Special Issue on Nonliteral language . 

