Proceedings of the 23rd International Conference on Computational Linguistics ( Coling 2010), pages 1137?1145,
Beijing , August 2010
Towards a Unified Approach to Simultaneous Single-Document and
Multi-Document Summarizations

Xiaojun Wan
Institute of Compute Science and Technology
The MOE Key Laboratory of Computational Linguistics
Peking University
wanxiaojun@icst.pku.edu.cn

Abstract
Single-document summarization and multidocument summarization are very closely related tasks and they have been widely investigated independently . This paper examines the mutual influences between the two tasks and proposes a novel unified approach to simultaneous single-document and multidocument summarizations . The mutual influences between the two tasks are incorporated into a graph model and the ranking scores of a sentence for the two tasks can be obtained in a unified ranking process . Experimental results on the benchmark DUC datasets demonstrate the effectiveness of the proposed approach for both single-document and multidocument summarizations.
1 Introduction
Single-document summarization aims to produce a concise and fluent summary for a single document , and multidocument summarization aims to produce a concise and fluent summary for a document set consisting of multiple related documents . The two tasks are very closely related in both task definition and solution method.
Moreover , both of them are very important in many information systems and applications . For example , given a cluster of news articles , a multidocument summary can be used to help users to understand the whole cluster , and a single summary for each article can be used to help users to know the content of the specified article.
To date , single-document and multidocument summarizations have been investigated extensively and independently in the NLP and IR fields . A series of special conferences or workshops on automatic text summarization ( e.g.
SUMMAC , DUC , NTCIR and TAC ) have advanced the technology and produced a couple of experimental online systems . However , the two summarization tasks have not yet been simultaneously investigated in a unified framework.
Inspired by the fact that the two tasks are very closely related and they can be used simultaneously in many applications , we believe that the two tasks may have mutual influences on each other . In this study , we propose a unified approach to simultaneous single-document and multidocument summarizations . The mutual influences between the two tasks are incorporated into a graphbased model . The ranking scores of sentences for single-document summarization and the ranking scores of sentences for multidocument summarization can boost each other , and they can be obtained simultaneously in a unified graphbased ranking process . To the best of our knowledge , this study is the first attempt for simultaneously addressing the two summarization tasks in a unified graphbased framework . Moreover , the proposed approach can be easily adapted for topic-focused summarizations.
Experiments have been performed on both the single-document and multidocument summarization tasks of DUC2001 and DUC2002. The results demonstrate that the proposed approach can outperform baseline independent methods for both the two summarization tasks . The two tasks are validated to have mutual influences on each other.
The rest of this paper is organized as follows : Section 2 introduces related work . The details of the proposed approach are described in Section 3. Section 4 presents and discusses the evaluation results . Lastly we conclude our paper in
Section 5.
1137 2 Related Work
Document summarization methods can be either extraction-based or abstraction-based . In this section , we focus on extraction-based methods.
Extraction-based methods for single-document summarization usually assign a saliency score to each sentence in a document and then rank and select the sentences . The score is usually computed based on a combination of statistical and linguistic features , such as term frequency , sentence position , cue words and stigma words ( Luhn , 1969; Edmundson , 1969; Hovy and Lin , 1997). Machine learning techniques have also been used for sentence extraction ( Kupiec et al , 1995; Conroy and O?Leary , 2001; Shen et al , 2007; Li et al , 2009). The mutual reinforcement principle has been exploited to iteratively extract key phrases and sentences from a document ( Zha , 2002; Wan et al , 2007a ). Wan et al (2007b ) propose the CollabSum algorithm to use additional knowledge in a cluster of documents to improve single document summarization in the cluster.
In recent years , graphbased ranking methods have been investigated for document summarization , such as TextRank ( Mihalcea and Tarau , 2004; Mihalcea and Tarau , 2005) and LexPageRank ( ErKan and Radev , 2004). Similar to PageRank ( Page et al , 1998), these methods first build a graph based on the similarity relationships between the sentences in a document and then the saliency of a sentence is determined by making use of the global information on the graph recursively . The basic idea underlying the graphbased ranking algorithm is that of ? voting ? or ? recommendation ? between sentences.
Similar methods have been used for generic multidocument summarization . A typical method is the centroid-based method ( Radev et al ., 2004). For each sentence , the method computes a score based on each single feature ( e.g.
cluster centroids , position and TFIDF ) and then linearly combines all the scores into an overall sentence score . Topic signature is used as a novel feature for selecting important content in NeATS ( Lin and Hovy , 2002). Various sentence features have been combined by using machine learning techniques ( Wong et al , 2008). A popular way for removing redundancy between summary sentences is the MMR algorithm ( Carbonell and Goldstein , 1998). Themes ( or topics , clusters ) in documents have been discovered and used for sentence selection ( Harabagiu and Lacatusu , 2005). Hachey (2009) investigates the effect of various source document representations on the accuracy of the sentence extraction phase of a multidocument summarization task.
Graphbased methods have also been used to rank sentences in a document set . The methods first construct a graph to reflect sentence relationships at different granularities , and then compute sentence scores based on graphbased learning algorithms . For example , Wan (2008) proposes to use only cross-document relationships for graph building and sentence ranking.
Cluster-level information has been incorporated in the graph model to better evaluate sentences ( Wan and Yang , 2008).
For topic-focused multidocument summarization , many methods are extensions of generic summarization methods by incorporating the information of the given topic or query into generic summarizers . In recent years , a few novel methods have been proposed for topic-focused summarization ( Daum ? and Marcu , 2006; Wan et al , 2007c ; Nastase 2008; Li et al , 2008; Schilder and Kondadadi , 2008; Wei et al , 2008).
The above previous graphbased summarization methods aim to address either single-document summarization or multidocument summarization , and the two summarization tasks have not yet been addressed in a unified graphbased framework.
3 The Unified Summarization Approach 3.1 Overview Given a document set , in which the whole document set and each single document in the set are required to be summarized , we use local saliency to indicate the importance of a sentence in a particular document , and use global saliency to indicate the importance of a sentence in the whole document set.
In previous work , the following two assumptions are widely made for graphbased summarization models : Assumption 1: A sentence is locally important in a particular document if it is heavily linked with many locally important sentences in the same document.
1138
Assumption 2: A sentence is globally important in the document set if it is heavily linked with many globally important sentences in the document set.
The above assumptions are the basis for Pag-eRank-like algorithms for single document summarization and multidocument summarization , respectively . In addition to the above two assumptions , we make the following two assumptions to consider the mutual influences between the two summarization tasks : Assumption 3: A sentence is locally important in a particular document , if it is heavily linked with many globally important sentences in the document set.
The above assumption is reasonable because the documents in the set are relevant and the globally important information in the document set will be expressed in many single documents.
Therefore , if a sentence is salient in the whole document set , the sentence may be salient in a particular document in the set.
Assumption 4: A sentence is globally important in the document set , if it is heavily linked with many locally important sentences.
The above assumption is reasonable because the documents in the set are relevant and the globally important information in the whole set is the aggregation of the locally important information in each single document . Therefore , if a sentence is salient in a particular document , the sentence has the potential to be salient in the whole document set.
In brief , the local saliency and global saliency of a sentence can mutually influence and boost each other : high local saliency will lead to high global saliency , and high global saliency will lead to high local saliency.
Based on the above assumptions , our proposed approach first builds affinity graphs ( each graph is represented by an affinity matrix ) to reflect the different kinds of relationships between sentences , respectively , and then iteratively computes the local saliency scores and the global saliency scores of the sentences based on the graphs . Finally , the algorithm converges and the local saliency score and global saliency score of each sentence are obtained . The sentences with high local saliency scores in a particular document are chosen into the summary of the single document , and the sentences with high global saliency scores in the set are chosen into the summary of the document set.
Note that for both summarization tasks , after the saliency scores of sentences have been obtained , the greedy algorithm used in ( Wan et al , 2007c ) is applied to remove redundancy and finally choose both informative and novel sentences into the summary.
3.2 Algorithm Details
Formally , the given document set is denoted as D={di|1?i?m }, and the whole sentence set is denoted as S={si|1?i?n }. We let Infosingle(si ) denote the local saliency score of sentence si in a particular document d(si)?D , and it is used to select summary sentences for the single document d(si ). And we let Infomulti(si ) denote the global saliency score of sentence si in the whole document set D , and it is used to select summary sentences for the document set D.
The four assumptions in Section 3.1 can be rendered as follows : ?? j jglejiAigle sInfoWsInfo )()()( sinsin (1) ?? j jmultijiBimulti sInfoWsInfo )()()( (2) ?? j jmultijiCigle sInfoWsInfo )()()( sin (3) ?? j jglejiDimulti sInfoWsInfo )()()( sin (4) where WA , WB , WC , WD are n?n affinity matrices reflecting the different kinds of relationships between sentences in the document set , where n is the number of all sentences in the document set . The detailed derivation of the matrices will be presented later.
After fusing the above equations , we can obtain the following unified forms : ? ? ?+ = j jmultijiC j jglejiAigle sInfoW sInfoWsInfo )()()1( )()()( sinsin ? ? (5) ? ? ?+ = j jglejiD j jmultijiBimulti sInfoW sInfoWsInfo )()()1( )()()( sin ? ? (6) However , the above summarization method ignores the feature of sentence position , which has been validated to be very important for document summarizations . In order to incorporate this important feature , we add one prior score to each computation as follows : )()()( )()()( sin sinsin iglej jmultijiC j jglejiAigle spriorsInfoW sInfoWsInfo ?++ = ? ? ?? ? (7) )()()( sin imultij jglejiD j jmultijiBimulti spriorsInfoW sInfoWsInfo ?++ = ? ? ?? ? (8) where ?, ?, ??[0,1] specify the relative contributions to the final saliency scores from the different factors , and we have ?+?+?=1. pri-orsingle(si ) is the prior score for the local saliency of sentence si , and here priorsingle(si ) is computed based on sentence position of si in the particular document d(si ). priormulti(si ) is the prior score for the global saliency of sentence si , and we also compute priormulti(si ) based on sentence position of si.
We use two column vectors ur =[ Infosingle(si)]n?1 and vr =[ Infomulti(si)]n?1 to denote the local and global saliency scores of all the sentences in the set , respectively . And the matrix forms of the above equations are as follows : gle
TT ???
CA sin pvWuWu rrrr ++= (9) multi
TT ???
DB puWvWv rrrr ++= (10) where 1sinsin )]([ ?= niglegle spriorp r and 1)]([ ?= nimultimulti spriorp r are the prior column vectors.
The above matrices and prior vectors are constructed as follows , respectively : WA : This affinity matrix aims to reflect the local relationships between sentences in each single document , which is defined as follows:
Otherwise 0, ji and ) d ( ) d ( if ),,( )( cos ?? ?? ? ? = = jijiine ijA sssssim
W (11) where d(si ) refers to the document containing sentence si . simcosine(si,sj ) is the cosine similarity between sentences si and sj.
ji ji jiine ss ss sssim rr rr ? ? =),( cos (12) where is r and js r are the corresponding term vectors of si and sj . Note that we have ( WA)ij = ( WA)ji , and we have ( WA)ii =0 to avoid self loops.
We can see that the matrix contains only the within-document relationships between sentences.
WB : This affinity matrix aims to reflect the global relationships between sentences in the document set , which is defined as follows:
Otherwise 0, ) d ( ) d ( if ),,( )( cos ?? ? ? = jijiine ijB sssssim
W (13) We can see that the matrix contains only the cross-document relationships between sentences.
We do not include the within-document sentence relationships in the matrix because it has been shown that the cross-document relationships are more appropriate to reflect the global mutual influences between sentences than the within-document relationships in ( Wan , 2008).
WC : This affinity matrix aims to reflect the cross-document relationships between sentences in the document set . However , the relationships in this matrix are used for carrying the influences of the sentences in other documents on the local saliency of the sentences in a particular document . If we directly use Equation (13) to compute the matrix , the mutual influences would be overly used . Because other documents might not be sampled from the same generative model as the specified document , we probably do not want to trust them so much as the specified document . Thus a confidence value is used to reflect out belief that the document is sampled from the same underlying model as the specified document . Heuristically , we use the cosine similarity between documents as the confidence value . And we use the confidence value as the decay factor in the matrix computation as follows:
Otherwise 0, ) d ( ) d ( if )),(),((),( )( coscos ?? ?? ? ? ? = ji jiinejiine ijc ss sdsdsimsssim
W (14)
WD : This affinity matrix aims to reflect the within-document relationships between sentences . Thus we have WD=WA , which means that the global saliency score of a sentence is influenced only by the local saliency scores of the sentences in the same document , without considering the sentences in other documents.
Note that the above four matrices are symmetric and we can replace TAW , TBW , TCW and TDW by WA , WB , WC and WD in Equations (9) and (10), respectively.
priorsingle(si ): It is computed under the assumption that the first sentences in a document are usually more important than other sentences.
1)( 15.0)(sin + += i igle sposition sprior (15) where position(si ) returns the position number of sentence si in its document d(si ). For example , if is 1.
The prior weight is then normalized by : ?= i igle igle igle sprior sprior sprior )( )( )( sin sin sin (16) priormulti(si ): We also let the prior weight reflect the influence of sentence position.
)()( sin igleimulti spriorsprior = (17) And then the prior weight is normalized in the same way.
The above definitions are for generic document summarizations and the above algorithm can be easily adapted for topic-focused summarizations . Given a topic q , the only change for the above computation is priormulti(si ). The topic relevance is incorporated into the prior weight as follows : ),()( cos qssimsprior iineimulti = (18) ?= i imulti imulti imulti sprior spriorsprior )( )()( (19) In order to solve the iterative problem defined in Equations (9) and (10), we let TT ] [ Tvur rrr = ,
T ] [ Tmulti
T single ppp rrr ??= , ??? ? ??? ? =
T
B
T
D
T
C
T
A
WW
WWW ?? ?? , and then the iterative equations correspond to the following linear system : prWr rrr += (20) prWI rr =? )( (21) To guarantee the solution of the above linear system , W is normalized by columns . If all the elements of a column are zero , we replace the elements with 1/(2n ), where 2n equals to the element number of the column . We then multiply W by a decay factor ? (0<?<1) to scale down each element in W , but remain the meaning of W . Here , ? is empirically set to 0.61. Finally , Equation (21) is rewritten as follows : prWI rr =?? )( ? (22) Thus , the matrix ( I-?W ) is a strictly diagonally dominant matrix and the solution of the linear system exists and we can apply the Gauss-Seidel method used in ( Li et al , 2008) to solve the linear system . The GS method is a well-know method for numeric computation in 1 In our pilot study , we can observe good performance when ? is in a wide range of [0.4, 0.8].
mathematics and the details of the method is omitted here.
4 Empirical Evaluation 4.1 Dataset and Evaluation Metric Generic single-document and multidocument summarizations have been the fundamental tasks in DUC 2001 and DUC 2002 ( i.e . tasks 1 and 2 in DUC 2001 and tasks 1 and 2 in DUC 2002), and we used the two datasets for evaluation.
DUC2001 provided 309 articles , which were grouped into 30 document sets . Generic summary of each article was required to be created for task 1, and generic summary of each document set was required to be created for task 2.
The summary length was 100 words or less.
DUC 2002 provided 59 document sets consisting of 567 articles ( D088 is excluded from the original 60 document sets by NIST ) and generic summaries for each article and each document set with a length of approximately 100 words were required to be created . The sentences in each article have been separated and the sentence information has been stored into files . The summary of the two datasets are shown in Table 1.
DUC 2001 DUC 2002
Task Tasks 1, 2 Tasks 1, 2
Number of documents 309 567
Number of clusters 30 59
Data source TREC9 TREC9 summary length 100 words 100 words Table 1. Summary of datasets We used the ROUGE toolkit2 ( Lin and Hovy , 2003) for evaluation , which has been widely adopted by DUC for automatic summarization evaluation . It measured summary quality by counting overlapping units such as the ngram , word sequences and word pairs between the candidate summary and the reference summary.
The ROUGE toolkit reported separate recall-oriented scores for 1, 2, 3 and 4gram , and also for longest common subsequence cooccurrences . We showed three of the ROUGE metrics in the experimental results : ROUGE1 ( unigram-based ), ROUGE2 ( bigram-based ), and ROUGEW ( based on weighted longest common subsequence , weight=1.2). In order to truncate summaries longer than the length limit , 2 We used ROUGEeval-1.4.2 in this study.
1141 we used the ?- l 100? option in ROUGE toolkit.
We also used the ?- m ? option for word stemming.
4.2 Evaluation Results 4.2.1 System Comparison In the experiments , the combination weight ? for the prior score is fixed at 0.15, as in the PageRank algorithm . Therefore , we have ?+?=0.85.
Here , we use ?/(?+?) to indicate the relative contributions of the first two parts in Equations (9) and (10). We empirically set ?/(?+?)=0.4 in the experiments . The proposed unified approach ( i.e . UnifiedRank ) is compared with a few baseline approaches and the top three participating systems.
The graphbased baselines for single-document summarization are described as follows : BasicRank : This baseline approach adopts the basic PageRank algorithm to rank sentences based on all sentence relationships in a single document , similar to previous work ( Mihalcea and Tarau , 2004).
PositionRank : This baseline approach improves the basic PageRank algorithm by using the position weight of a sentence as the prior score for the sentence . The position weight of a sentence is computed by using Equation (15).
CollabRank1: This baseline approach is the ? UniformLink(Gold )? approach proposed in ( Wan et al 2007b ). It uses a cluster of multiple documents to improve single document summarization by constructing a global affinity graph.
CollabRank2: This baseline approach is the ? UnionLink(Gold )? approach proposed in ( Wan et al 2007b).
The graphbased baselines for multidocument summarization are described as follows : BasicRank : This baseline approach adopts the basic PageRank algorithm to rank sentences based on all sentence relationships in document set . Both within-document and cross-document sentence relationships are used for constructing the affinity graph.
PositionRank : Similarly , this baseline approach improves the basic PageRank algorithm by using the position weight of a sentence as the prior score for the sentence.
TwoStageRank : This baseline approach leverages the results of single document summarization for multidocument summarization . It first computes the score of each sentence within each single document by using the PositionRank method , and then computes the final score of each sentence within the document set by considering the document-level sentence score as the prior score in the improved PageRank algorithm.
The top three systems are the systems with highest ROUGE scores , chosen from the participating systems on each task , respectively . Tables 2 and 3 show the comparison results for single-document summarization on DUC2001 and DUC2002, respectively . Tables 4 and 5 show the comparison results for multidocument summarization on DUC2001 and DUC2002, respectively . In the tables , SystemX ( e.g . System28, SystemN ) represents one of the top performing systems . The systems are sorted by decreasing order of the ROUGE1 scores.
For single-document summarization , the proposed UnifiedRank approach always outperforms the four graphbased baselines over all three metrics on both two datasets . The performance differences are all statistically significant by using ttest ( p-value<0.05). The ROUGE1 score of UnifiedRank is higher than that of the best participating systems and the
ROUGE2 and ROUGEW scores of UnifiedRank are comparable to that of the best participating systems.
For multidocument summarization , the proposed UnifiedRank approach outperforms all the three graphbased baselines over all three metrics on the DUC2001 dataset , and it outperforms the three baselines over ROUGE1 and ROUGEW on the DUC2002 dataset . In particular , UnifiedRank can significantly outperform BasicRank and TwoStageRank over all three metrics on the DUC2001 dataset ( ttest , p-value<0.05). Moreover , the ROUGE1 and ROUGEW scores of UnifiedRank are higher than that of the best participating systems and the ROUGE2 score of UnifiedRank is comparable to that of the best participating systems.
The results demonstrate that the single-document and multidocument summarizations can benefit each other by making use of the mutual influences between the local saliency and proposed unified graphbased approach is effective for both single document summarization and multidocument summarization . However , the performance improvement for single-document summarization is more significant than that for multidocument summarization , which shows that the global information in a document set is very beneficial to summarization of each single document in the document set.

System ROUGE1 ROUGE2 ROUGEW
UnifiedRank 0.45377 0.17649 0.14328
CollabRank2 0.44038 0.16229 0.13678
CollabRank1 0.43890 0.16213 0.13676
PositionRank 0.43596 0.15936 0.13684
BasicRank 0.43407 0.15696 0.13629
Table 2. Comparison results for single-document summarization on DUC20013
System ROUGE1 ROUGE2 ROUGEW
UnifiedRank 0.48478 0.21462 0.16877
System28 0.48049 0.22832 0.17073
System21 0.47754 0.22273 0.16814
CollabRank1 0.47187 0.20102 0.16318
CollabRank2 0.47028 0.20046 0.16260
PositionRank 0.46618 0.19853 0.16180
System31 0.46506 0.20392 0.16162
BasicRank 0.46261 0.19457 0.16018
Table 3. Comparison results for single-document summarization on DUC2002
System ROUGE1 ROUGE2 ROUGEW
UnifiedRank 0.36360 0.06496 0.10950
PositionRank 0.35733 0.06092 0.10798
BasicRank 0.35527 0.05608 0.10641
TwoStageRank 0.35221 0.05500 0.10515
SystemN 0.33910 0.06853 0.10240
SystemP 0.33332 0.06651 0.10068
SystemT 0.33029 0.07862 0.10215
Table 4. Comparison results for multidocument summarization on DUC2001
System ROUGE1 ROUGE2 ROUGEW
UnifiedRank 0.38343 0.07855 0.12341
PositionRank 0.38056 0.08238 0.12292
TwoStageRank 0.37972 0.08166 0.12261
BasicRank 0.37595 0.08304 0.12173
System26 0.35151 0.07642 0.11448
System19 0.34504 0.07936 0.11332
System28 0.34355 0.07521 0.10956
Table 5. Comparison results for multidocument summarization on DUC2002 3 The summarization results for participating systems on
DUC2001 are incomplete.
4.2.2 Influences of Combination Weight
In the above experiments , the relative contributions from the first two parts in Equations (9) and (10) are empirically set as ?/(?+?)=0.4. In this section , we investigate how the relative contributions influence the summarization performance by varying ?/(?+?) from 0 to 1. A small value of ?/(?+?) indicates that the contribution from the same kind of saliency scores of the sentences is less important than the contribution from the different kind of saliency scores of the sentences , and vice versa . Figures 18 show the
ROUGE1 and ROUGEW curves for single-document summarization and multidocument summarization on DUC2001 and DUC2002, respectively.
For single document summarization , very small value or very large value for ?/(?+?) will lower the summarization performance values on the two datasets . The results demonstrate that both the two kinds of contributions are important to the final performance of single document summarization.
For multidocument summarization , a relatively large value (?0.4) for ?/(?+?) will lead to relatively high performance values on the DUC2001 dataset , but a very large value for ?/(?+?) will decrease the performance values.
On the DUC2002 dataset , a relatively small value (?0.4) will lead to relatively high performance values , but a very small value for ?/(?+?) will decrease the performance values.
Though the trends of the curves on the
DUC2001 and DUC2002 datasets are not very consistent with each other , the results show that both the two kinds of contributions are beneficial to the final performance of multidocument summarization.
5 Conclusion and Future Work
In this study , we propose a novel unified approach to simultaneous single-document and multidocument summarization by making using of the mutual influences between the two tasks.
Experimental results on the benchmark DUC datasets show the effectiveness of the proposed approach.
In future work , we will perform comprehensive experiments for topic-focused document proposed approach.
DUC2001 0.444 0.446 0.448 0.45 0.452 0.454 0.456 0.458 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 ?/(?+?)
RO
U
G
E-
Figure 1. ROUGE1 vs . combination weight for sin-gle-document summarization on DUC2001
DUC2001 0.14 0.1405 0.141 0.1415 0.142 0.1425 0.143 0.1435 0.144 0.1445 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 ?/(?+?)
RO
U
G
E-
W
Figure 2. ROUGEW vs . combination weight for single-document summarization on DUC2001
DUC2002 0.474 0.476 0.478 0.48 0.482 0.484 0.486 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 ?/(?+?)
RO
U
G
E-
Figure 3. ROUGE1 vs . combination weight for sin-gle-document summarization on DUC2002
DUC2002 0.164 0.165 0.166 0.167 0.168 0.169 0.17 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 ?/(?+?)
R
O
U
G
E-
W
Figure 4. ROUGEW vs . combination weight for single-document summarization on DUC2002
DUC2001 0.34 0.345 0.35 0.355 0.36 0.365 0.37 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 ?/(?+?)
RO
U
G
E-
Figure 5. ROUGE1 vs . combination weight for multidocument summarization on DUC2001
DUC2001 0.102 0.104 0.106 0.108 0.11 0.112 0.114 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 ?/(?+?)
RO
U
G
E-
W
Figure 6. ROUGEW vs . combination weight for multidocument summarization on DUC2001
DUC2002 0.374 0.376 0.378 0.38 0.382 0.384 0.386 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 ?/(?+?)
R
O
U
G
E-
Figure 7. ROUGE1 vs . combination weight for multidocument summarization on DUC2002
DUC2002 0.12 0.121 0.122 0.123 0.124 0.125 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 ?/(?+?)
RO
U
G
E-
W
Figure 8. ROUGEW vs . combination weight for multidocument summarization on DUC2002
Acknowledgments
This work was supported by NSFC (60873155), Beijing Nova Program (2008B03) and NCET ( NCET-08-0006).
1144
References
J . Carbonell , J . Goldstein . 1998. The Use of MMR , Diversity-based Reranking for Reordering Documents and Producing Summaries . In Proceedings of SIGIR1998, 335-336.
J . M . Conroy , D . P . O?Leary . 2001. Text Summarization via Hidden Markov Models . In Proceedings of SIGIR2001, 406-407.
H . Daum ? and D . Marcu . 2006. Bayesian query-focused summarization . In Proceedings of ACL06.
H . P . Edmundson . 1969. New Methods in Automatic Abstracting . Journal of the Association for computing Machinery , 16(2): 264-285.
G . ErKan , D . R . Radev . 2004. LexPageRank : Prestige in Multi-Document Text Summarization . In
Proceedings of EMNLP2004.
B . Hachey . 2009. Multidocument summarisation using generic relation extraction . In Proceedings of EMNLP2009.
S . Harabagiu and F . Lacatusu . 2005. Topic themes for multidocument summarization . In Proceedings of SIGIR-05.
E . Hovy , C . Y . Lin . 1997. Automated Text Summarization in SUMMARIST . In Proceeding of ACL?1997/EACL?1997 Worshop on Intelligent
Scalable Text Summarization.
J . Kupiec , J . Pedersen , F . Chen . 1995. A.Trainable Document Summarizer . In Proceedings of
SIGIR1995, 6873.
W . Li , F . Wei , Q . Lu and Y . He . 2008. PNR2: ranking sentences with positive and negative reinforcement for query-oriented update summarization . In Proceedings of COLING08.
L . Li , K . Zhou , G.-R . Xue , H . Zha , Y . Yu . 2009.
Enhancing diversity , coverage and balance for summarization through structure learning . In Proceedings of WWW-09.
C..-Y . Lin and E .. H . Hovy . 2002. From Single to Multidocument Summarization : A Prototype System and its Evaluation . In Proceedings of
ACL02.
C.-Y . Lin and E.H . Hovy . 2003. Automatic Evaluation of Summaries Using Ngram Cooccurrence Statistics . In Proceedings of HLTNAACL -03.
H . P . Luhn . 1969. The Automatic Creation of literature Abstracts . IBM Journal of Research and Development , 2(2).
R . Mihalcea , P . Tarau . 2004. TextRank : Bringing Order into Texts . In Proceedings of EMNLP2004.
R . Mihalcea and P . Tarau . 2005. A language independent algorithm for single and multiple document summarization . In Proceedings of IJCNLP05.
V . Nastase . 2008. Topic-driven multidocument summarization with encyclopedic knowledge and spreading activation . In Proceedings of EMNLP08.
L . Page , S . Brin , R . Motwani , and T . Winograd . 1998.
The pagerank citation ranking : Bringing order to the web . Technical report , Stanford Digital Libraries.
D . R . Radev , H . Y . Jing , M . Stys and D . Tam . 2004.
Centroid-based summarization of multiple documents . Information Processing and Management , 40: 919-938.
F . Schilder and R . Kondadadi . 2008. FastSum : fast and accurate querybased multidocument summarization . In Proceedings of ACL08: HLT.
D . Shen , J.-T . Sun , H . Li , Q . Yang , and Z . Chen.
2007. Document Summarization using Conditional Random Fields . In Proceedings of
IJCAI2007.
X . Wan . 2008. Using Only Cross-Document Relationships for Both Generic and Topic-Focused Multi-Document Summarizations . Information
Retrieval , 11(1): 2549.
X . Wan and J . Yang . 2008. Multidocument summarization using cluster-based link analysis . In Proceedings of SIGIR-08.
X . Wan , J . Yang and J . Xiao . 2007a . Towards an Iterative Reinforcement Approach for Simultaneous Document Summarization and Keyword Extraction . In Proceedings of ACL2007.
X . Wan , J . Yang and J . Xiao . 2007b . CollabSum : Exploiting Multiple Document Clustering for Collaborative Single Document Summarizations . In
Proceedings of SIGIR2007.
X . Wan , J . Yang and J . Xiao . 2007c . Manifold-ranking based topic-focused multidocument summarization . In Proceedings of IJCAI-07.
F . Wei , W . Li , Q . Lu and Y . He . 2008. Query-sensitive mutual reinforcement chain and its application in query-oriented multidocument summarization . In Proceedings of SIGIR-08.
K.-F . Wong , M . Wu and W . Li . 2008. Extractive summarization using supervised and semisupervised learning . In Proceedings of COLING08.
H . Y . Zha . 2002. Generic Summarization and Keyphrase Extraction Using Mutual Reinforcement Principle and Sentence Clustering . In Proceedings of SIGIR2002, 113-120.

