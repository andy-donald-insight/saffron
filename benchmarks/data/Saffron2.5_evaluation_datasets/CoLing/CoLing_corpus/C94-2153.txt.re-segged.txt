ANEFFICIENTSYNTACTICT AGGING TO OLFOR CORPORA@
Ming Zhou Changning Huang
Dept . of Computer Science , " l ~ inghua University,
Beijing , 100084, China.
ABSTRACT
The treebank is an important resources tbrMT and linguistics researches  , but it requires that large number of sentences be annotated with syntactic information  . It is time consuming and trouble some , and dil'ficult to keep consistency , if ' annotation is done manually . In this paper , wc presented a new technique for the semiautomatic tagging of Chinese tcxt  . The system takes as input Chinese text , and outputs the syntactically tagged sentence ( dependency tree )  . We use dependency grammar and employ a stack based shift/reduce context-dependent parser as the tagging mechanism  . The system works in human machine cooperative way , in which the machine can acquire tagging rules from human intervention  . The auto-mation level can be improved step by step by accumulating rules during annotation  . In addition , good consistency of tagging is guaranteed . 
KEYWORDS : syntactic tagging , treebank 1 . INTRODUCTION
In recent years , the corpora , either monolingual or bilingual , plays an important role in MT and linguistics rcs carches  ( Komatsu , jin & Yasuhara , 1993; Sato , 1993;\[sabcllc & Dymetman , t993) . This is because the corpora with large amount of running text is considered as an ideal resources of linguistic knowledge  . However , to acquire knowledge\['rom the corpora ( Watenabc , 1993; Mitamura , Nyberg , Carbon cll ,  1993) , or effectively use the scntcnces as examples , as in example based approach ( Nagao ,  1984 , O . Furusc & H . Iida ,  1992) , the corpora has to be annotated with certain inlbrmation which may be of morphological information  , syntactic in l'ormation and semantic information . 
Take Chinese monolingual corpora , For instance , the raw corpora , i . c . the text which has not bccnscgm cntcd into word strings  , can only be uscdt br statistics of Chinesc character  , howev cr , if you want to work out the frequency of words , the corpora has to bcsegm cnt cd into word strings  , i . c . , it has to be annotated with word boundary information  . Furthermorc , if you want to obtain the cooccurrence frc qucn cy of each two adjacent part of speeches  , which is helpful to the study of part of speech ( POS ) tagging , you must annotate the corpora with POS in Ibrmation  . And if " you want to extract the syntactic knowledge from corpus  , the corpus must be attached with syntactic information such as dependency relation and phrase structure etc  . , and such a corpora is called tree bank which is used as the rc sources for knowledge acquisition and cxampl cs in EBMT research  . 
There are usually five levels of annotation tbra corpora  , which includes word boundary tagging , POS tagging , sense tagging , syntactic relation tagging and semantic relation tagging  , with the depth of tagging increases . To improve the tagging auto-marion and keep good consistency  , a mechanism is rcquircd at each level of tagging to acquire knowledge fiom huna an intervention and the annotated corpus  . The knowledge acquired should be fed back to the tagging model to improve the tagging automation and correctness  . 
Our group has bcendoing the research on Chincse corpus for many years  , and has done successful experiments on word boundary tagging  , POS tagging ( Bai & Xia ,  1992) , sense tagging ( Tong , Huang & Guo ,  1993) . The syntactic relation tagging , however , has not been resolved well because of some reasons  . First , there is no clear answer about which grammar lbrmalism  , such as phrase structure granamar , or dependency grammar or any othcr grammar is suitable for largescale running text syntactic tagging ? Second  , how to save human Zslabor from tagging , and keep good ( i ) supported by National Foundation of Natural Science of China  . 
949 consistency ?
For the first question , some rescarchers adopt phrase structure grammar ( PSG ) as thc tagging formalisms ( Lecch & Garside 1991 )  , and some adopt dependency grammar ( DG ) 1993 , Komatsu , Jin , & Yasuhara ,  1993) . In comparison with PSG , the authors think , DG has some advantages . First , it is economical and convcnient to use DG for thc syntactic relation tagging of corpus because there is no nonterminal node in the parse tree o fDG  ; Scc-nd , DG stresses relations among individual words , the acquisition of collocation knowledge and syntactic relation among words is straight  ; Third , there is relatively straightmap bct ween dependency tree and case reprcsentation  . 
Based on the above discussion , the authors chosen dependency grammar as the syntactic formalism for corpora  , and defined 44 kinds of dc-pendency relation tbrChinese ( Zhou & Huang 1993 )  . 
For the second question , we must develop an efficic nt tagging tool , fbr which wcnccd tak caccount of two factors : ( 1 ) the power of acquiring tagging knowledge from the human intervention  , in order to improve the automation level ; (2) the ability ot " keep in good consistency . 
Simmons & Yu ( 1992 ) introduced the context-dependent grammar for English parsing  , in which the context-dependent rules can be acquired through an interactive mechanism  , the phrase structure analysis and case analysis were conducted through a stack based shift/shi ft parser  , with success ratio reached as high as 99% . Inspircd by their work , we designed a dependency relation tagging tool\[ ' or Chinese corpus  , called CSTT . 
CSTT takes the context-dependent grammar as well . It can learn the humants knowledge of tagging . In the initial stage , the tagging is mainly done by human , the system records the operation of human and forms tagging rules  , when the rules are accumulated to some number , the system can help human to tag , such as provides human with annotation operations which human did bel brein the same context  , or even do some annotation itself in some cases . The annotation automation gets higher and higher and good consistency is thus guaranteed  . It should be mentioned that since PSG nonterminal symbols are used in shift/reduce tagging process  , CSTT can produce syntactically tagged sentences of PSG version as well  . In addition , both versions of tree can be mapped into each other by providing with a set of transfcrules  . 
A small corpora of 1300 sentences of daily life is used for experiment , with the average length of 20 Chinese characters per sentence , For the first 300 sentences , 1455 rules were obtained , and for the whole corpora , totally 6521 rules was obtained . The tagging automation was improved continually with the rules increased  , and the automatic tagging ratio is above 50% after 1200 sentences were tagged . 
2 DESIGNOF CSTT 2 . 1 The context-dependent shift/reduce tagging m ech an isln The proccss of context-dependent tagging is that when a sentence is input  ( the input string is the sequence of part of speech  )  , we look up the rule base with the top two elements of the stack to see whether there exist rules coinciding with the current context  . If not , human operation is required to determine whether educe or shift  . If reduce , then further decides what phrase structure will be constructed  , and what dependency relation will be constructed bct we cn these top two elements  . The system records the current context and the operations to tbrms an cw rule  , and put it into rule base . 
Formally , context dependent rule is represented as : c~xyfl ~ s  ( Shif't ) c ~ xy\[l  ~ ( z , y , h ) ( Reduce Where x , y are the top two elements in the stack , and cqfl are the context on the lefthand of x and the context on the right hand of y respectively  . The context is represented as a sequence of part o1" speeches . There are two actions on the right hand of a rule  , shift action denoted as s , and reduce action denoted as ( z , ? , h) . For reduce action , z denotes the phrase structure after reduction , and ? denotes the dependency relation between x and y  , h denotes which clement is the head of the phrase structure and dependency relation  . By t t =' A ' means the top clement is the head , h = ' B ' means that the second top clement of the stack is the head  . Now let/ssce the tagging process for a simple sentence :  ( where , R : pronoun , VY : verb , ~ . u , USDE : ufl~ju , A : adj . , NG:general noun . )
Table 1 < Stack > ~ tk < Input string >
The contcxt-dcpcndent shift/reduce tagging process 
Action Phrase structure .   .   .   .   .  :/  c4:<R > < VY > < R > < USDE > < A > < NG > < +> shift .   .   .   . < R > : ; ~< VY > < R > < USDE > < A > < NG > < +> shift-- -< R > < VY > ~:< R > < USDE > < A > < NG > <  . > reduce----<SV>:~<R><US1)E><A><NG>< . > shift---<SV><R>:i~<USDE><A><NG>< . > shift--<SV><R><USDE>:~-<A><NG>< . > reduce---<SV > < I ) E>:~<A><NG><?>shift--<SV><DE><A>r\]$< NG > < ?> shift-<SV > < I  ) E > < A><NG>-t~<?+'+'> reduce--<SV><DE><NP > ~<+> reduce---<SV > < NP > :/:#-<?> reduce  .   .   .   .   . < SS>#:/k<o>shift---<88> < o>:~reduce .   .   .   . < SP > :/=/: pop
Dependency relation
SVSUB
I ) EDEP
NPATTA
NPATTA
SSOBJ
SPMARK
GOV(where , SV : subject-verb phrase , DE : ~/ II < J ~' structure , NP : noun phrase , SS : sub-scntcnce , SP : sentence . SUB : subject , DEP : u(( , j , , structure , ATTA:modifier , OBJ : object , MARK : punctuation mark , GOV : the predicate of sentence . ) l ) epcndency relation is represented as a triple of the form < modific r  , head , the dcpend cn cy rela-tion > . The tagging result is represented as asctel " triples : <  4  . ~,,~, SUB >, <~: .   , Nil , GOV > , <4 tf ~ ,   , f t < O , DEP > , < ~ I * , J , \])lJ . ~, ATTA >, <) f ,) I\]IJS . , A'FTA >, < Jl/l ~, ~ h ~, OBJ > . At each stcp , we can obtain a rule by recording the content of stack and input str-ing  , and the operation ( shift or reduce ) given by user . II ' the operation is a reduction , the phrase structure and dependency relation arc to be decided by user  . Ilere are two rulcs obtained : ---< R > < VY > - ~< R > < USDE > < A > < NG > <+>-~  ( SV , SUB , A ) --< SV > < R > < USDE>~4z<A><NG >< o>-~s After the reduction , the phrasc structur c formed rcplaces the top two elements in the stack  . 
And the head will reprcs cn this phrase in later pro+ccss  . Since scntcnecs varies with its length , we use t brcc elements on th cl cl't side of the top two cle-ments in the stack and the top I'ivc clem cnt sinth c input string as the context  . 
The input is a scqucnce ot + the part of speech of a sentence  , and the output is the depcndency treed cnotcd as a set of triple oF the form  ( modifier , hcad , the dependency relation ) , and as a by-product , context-dependent rules are acquired . It is obviously that we can work out the phrase structure trcc as well by modifying the algori thm  ( not de-tail cd in this pap cr )  . 
l , ctCDG be the context-dcpendent rule base which were acquired bct bre  , CDG is empty if " the system is just put into use  . NUMBER-OF-AC-TION records the number of total actions  ( either shift or reduce ) during tagging , 
NUMBER-OF-AUTOMATION is the number of actions ( given by the system itselt ) which are con-lirmed to b cright by human . The automatic tagging ratio is thereforesct as NUMBER-OF-AI  )  -
TOMAT1ON/NUMBER-OF-ACTIONS.
At present , the system is under supervision , human intervention is applied at each step either to confirm the actions given by the system or to append new actions  . Id cally , the tagging process should be nearly full automatic with minimum human intervention  . But it is a long term process . We believed that with the size of corpora tagged increases  , the automatic tagging ratio will be improved , and wh crt it reaches to a degree of high 2 . 2 The tagging algorithm enough , human intervention may be removed , or it may only be needed in the case that no rule is matched  . 
Table 2The supervised tagging algorithm

STACK = EMPTY
NUMBER-OF-AUTOMATION = 0
NUMBER-OF-ACTION = 0
DOUNTIL ( INPUT = EMPTYANDSTACK = EMPTY ) ) CONTEXT = APPEND ( TOP-FIVE ( STACK )  , FIRST-FIVE ( INPUT ) ) / * get the context * / RULE-LIST = CONSULT-TO -CDG  ( CONTEXT ) /* match with CDG*/RULE=CONSULT-TO-HUMAN ( RULE-LIST ) /* human intervention*/IF ( RULE = FIRST ( RULE-LIST ) ) / * the default operation is right * /
NUMBER-OF-AUTOMATION + +

IFRHS(RULE ) =/ S'
STACK=PUSH(FIRST(INPUT ), STACK)
ELSE
LET ( Z , y , h ) BERIIS OF THERULE
LETX = FIRST(STACK)Y = SECOND(STACK)
BUILDAPHRASESTRUCTUREZ VROMXANDY
STACK = PUSH(Z , POP ( POP ( STACK ) ) ) /* the phrase structurer cplace the top two clements of the stack */ 
IFh = ' A'
BUILD-DEPENDENCY-RELATION(HEAD(Y) , HEAD(X) , y ) /* build the dependency triple */

IFh = ' B'
BUILD-DEPENDENCY-RELATION(HEAD(X) , IIEAD(Y ) , 7 ) /* build the dependency triple */ IF ( INPUT = EMPTYANt ) NUMBER ( STACK ) = I ) STACK = POP ( STACK ) 


Function TOP-FIVE , FIRST-FIVE return the first five elements of the stack and input string respectively  . If there are less than five elements in the stack or in the input string  , then fills with blanks . APPEND merges two lists to obtain the current context  . 
CONSULT-TO-CDG looks up the rule base and returns a list of rules matching with the current context  . 
The list is empty when no rule is matched . If the list is not empty , rules are sorted in descending order of their usage frequency  . If human/s intervention is dcfault ( this may be available when the automatic tagging ratio reaches to some high degree  )  , the system will take a action according to the rule of the highest frequency  . 
CONSULT-TO-HUMAN returns only one rule by hmnan's inspection  . In this interactive process , human is asked to dctermine what action should be taken  , he first inspect the rule-list to see if there is already a rule correctly confirming with current context  , if not , he should tell the system whether " shift " or '/ reduce "  , if " reduce " , he is requested to tell the system what phrase structure and what dependency relation is to be built  , and which element , the top element of the stack , or the second is the head . A new rule will be acquired when human makes a different operation from existing roles  , by recording the current context and the operation  . 
NUMBER-OF-AUTOMATION records the times that the rule with the highest frequency coincides with human's decision  , which means that if the system works in automatic way  , the rule with the highest frequency is right . NUMBER-OF-ACTIONS records the total times of operation  ( shift or reduce ) during tagging . The PUS It means push an element into stack , and POP pops top element out of stack , FIRST and SECOND return t be first clement and second element of a list respectively  . 
In matching process , weighted matching approach ( Simmons & Yu , 1992) is used . Assmnc the set of CDG rules is R = RI , R2, . . , Rm , where the lefthand of each rule is Ri = ridri2 . .  , ril 0 , assume the context of the top two elements of the stack is CTM % ca  ,   . . , cs0 , where c 4 and csarc the top two elements in the stack , we set up a match function : lt(Ci , rii ) = 1 , if ei = rii ,   . u(ci , rii ) = 0, if cjI = rip
The score function is
Li 0
SCORE = it(cl , r , ) , i + ~ it(c , ,r , ) ( ll--i)l=i ~-6 some cases . CDG base is controlled dynamically so that to keep high efficiency of matching  . A rule will be removed from the CDG base if it is seldom used  . 
3 EXPERIMFNTAND ANALY SIS 3 . 1 The experiment A small corpora of 1300 sentences of daily life is prepared for experiment  , with the average length as 20 Chinese characters per sentence , the corpora covers main classes of Chinese simple declarative sentences  . The experiments is conducted in the following steps :  ( 1 ) input a sentence ; (2) word segmentation ; (3) part of speech tagging . 
The tagging model is a bi-grammod cl(Bai&Xia ,  1991) , and the correct ratio is about 94% , so human confirmation is needed . 
(4) tagging the dependency relation by CSTT.
A rule is preferred if and only if SCORE is greater than a threshold set in advance  . = 2l means full matching . In the beginning of the system , the full matching is recommended in order to deduce the conflict  . And after certain period of tagging , we may set the threshold smaller than 21 to overcome the shortage of rules in As shown in Table  3  ,   1455 rules was obtained from the first 300 sentences . In the whole experiment , totally 6521 rules was obtained . The more sentences tagged , the higher automatic tagging ratio may be . After 1200 sen-tenccs have been tagged , the ratio of automatic operation is above 50% . 
Table 3The experiment result
Sentence 1 - 300 400 500 600
No . of 1455 44738 4455 rules accquir cd
No . of 2072768776792 operation
No . of auto 487291336281 operation automatic 23 . 5 37 . 8 43 . 3 35 . 
ratio 70080 ? 4866 2885 18343 1712130 . 0 1000 1100 1200 1300 572 564 483 492 837 1153 1164 1111 210 572 641 580 25 . 1 49 . 6 55 . 1 52 . 2  ( 1 ) The rule conflict Although this system has some power for disambiguation due to the context -dependent rules  , it is difticult to resolve some ambiguities . The rel breit is easy to understand that a eonllict will occur if some ambiguity is encountered  . For example , the sequence of VGANG may be ( A , VG , COMPLEMENT ) , ( NG , VG , OBJ ) or ( A , NG , ATTA ) , ( NG , VG , OBJ ) , and the sequence NGING 2 may be ( NG2 , NG1 , COORDINATE ) or ( NGI , NG2 , ATTA ) as the following two pairs of sentence demonstrate :  ( i )   ( ii ) 
VGA treat well ~ J ~ form good
NGNG planegun wood table
NG relation ( A , VG , Complement ) 5 < l'\[i ~( A , NG , ATTA ) habit(NG , NGCOORDINATE ) ( NG , NG , ATTA ) Th crearc two kinds of ambiguities , one is contextual depcnd cnt ambiguity , another is contextual independent ambiguity . For the former , CSTT can resole some of them . For example , ~( VG ) ~ L , ( NG1) I'/ , J ( USDE ) ~'~  ( NG2 ) is an ambiguous phrasc ( which may be ( VG , nil , GOV ) , ( NG1 , USDE , DEP ) , ( USDE , NG2 , ATTA ) , ( NG2 , VG , OBJ ) which means " kill cd the hunter's dog ' , or ( VG , USDE , DEP ) , ( NG1 , VG , OBJ ) , ( USDE , NG2 , ATTA ) , ( NG2 , nil , GOV ) which means the dog which killed the hunter . However , if the context is considered , the ambiguity may be resolved :
VGN GUSDENG VGY
MQVGNGUSDENG
Un\[brtunately , CSTT can q resolve the ambiguity of the later , human-interv cntionise cessary . 
(2) The convergence of the CDG rule
According to the analysis of ( Simmons & Yu 1992) ,  25 , 0 00 CDG rules will be sufficient oc over the 99% phenomenon of English common sentences . In this sense , the CDG rule is convergent . If we are only for syntactic tagging , the convergence issues can be avoided temporally , if the automatic ratio reaches above 80% , we can stop acquisition , at this time the tagging can already provide lots help to the users  . Of course , if we make some effective attempts to CSTT , it may be developed into a nel'licicnt dependency parser as well  . 
4. CONCLUDING REMARK
In this paper , we presented that dependency grammar is a suitable formalism for syntactic tagging and presented a new technique for developing a syntactic tagging toollbr large corpora  , in which a simple shift/reduce mechanism was employed and context dependent rules were accumulated during tagging  . The supervised tagging algorithm is described . The experiment shows that automatic tagging ratio rises up continually with the number of sentence increases  , and good consistency is kept . 
This idea may be helpful for POS tagging and case tagging of corpora as well  . 
We hope the automatic tagging ratio will raise above  80% in the future by enlarging the size of rule base , so that it can be practically used l br syntactic tagging oF running text  . 

Bai , Shuan-hu , Yin Xia (1992) . A Scheme For Tagging Chinese Running Text . Prec . of NLPRS , p25-26, 1991, Singapore . 
Furuse O , II . Iida (1992) . An example-based mcthod For transl'cr-driv cn machine translation  . 
Prec . 4th TMI-92. Montreal , 1992.
Isabclle , Pierre , Marc Dymetmaneta 1. (1993).
Translation Analysis and translation automation.
Prec . of TMI-93, p201-217.
Komatsu , Eiji , Cui Jin , and Hiroshi
Yasuhara(1983) . A mono-lingual corpus-based machine translation of the interlingua method  . 
Prec . of TM\[-93, p24-46.
Leech , Geolt'erey and Roger Garside (1991).
Running a grammar factory , the production of syntactically analyzed corpora or " treebanks "  . In : English Computer Corpora , p15-32, Mouton de
Gruyter , 1991.
Mitamura , Tcrko , Erich . Nyberg , 3rd and lysis and the acquisition of large , multilingual knowledge bases lb rMT . Proc . of TMI-93, p292-301, Kyoto , Japan , July 1993 . 
Nagao , M . (1984) . A framework of a mechanical translation between Japanese and English by analogy example  , In : A . Elithorn , R . Benerji , ( Ed . ), Artificial and Human Intelligence , Elsevier :

Sato , Satoshi (1993) . Example-based translation of technical terms . Proc . of TMI-93, p58-68 . 
Simmons , F . Robert , Yeong-Ho Yu (1992).
The Acquisition and Use of Context-Dependent Grammars for English  . Computational Lin-guisties , Vol . 18, No . 4, 1992 . 
Tong , Xiang , Changning Huang , and
Chcngming Guo (1993) . Example-Based Sense Tagging of Running Chinese Text  . Proc . of the workshop on very large corpus , Academic and Industrial Perspectives , p102-112 , Columbus , Ohio , 
USA , June 22, 1993.
Watanabe , Hideo (1993) . A method for extracting translation patterns from translation examples  . Proe . of TMI-93, p292-301, Kyoto,
Japan , July 1993.
Zhou , Ming , and Changning Huang (1993).
Viewing the Dependency parsing as a statistically based tagging process  . Proe . NLPRS'93, Japan,
Dec . 67, 1993.

