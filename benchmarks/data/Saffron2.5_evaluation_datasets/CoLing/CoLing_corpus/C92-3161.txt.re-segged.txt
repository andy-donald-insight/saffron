Shal t2 -a Symmetric Machine Translation System with 

Shal l2 is a knowledge-based machine translation sys-
tem with a symmetric architecture . The grammar
rules , mapping rules between syntactic and conceptual ( semantic ) representations , and transferules for conceptual paraphrasing are all bidirectional knowledge sources used by both a parser and a generator  . 
1. Introduction
S halt2 is a research prototype of a knowledge-based , multi-domain/multi-lingual MT system . It has two predecessors , SHALT\[~31(1982-90) and KBMT-89131 (1987-89) , which brought us valuable less ons we reflected in the design and implementation f  Shalt2  . As a result , Shal l2 has been designed and implemented as a symmetric MT system with frame-based conceptual representation  . The advantages of asymmetric architecture coupled with a conceptual representation are obvious  . First , it allows us to maintain single knowledge sources for both parsing and generation  . We can automatically control the coverage and reversibility of these processes  . Second , conceptual structures are a desirable interface for representing the meaning of sentences  , machine-generated output ( such as diagnosis by an expert system )  , and expressions in graphical languages . AI-baeed approaches can provide powerful inference methods for identification of a  ( semi- ) equivalent class of conceptual representations , which corresponds to a paraphrasing capability . Unlike interlingual MT systems , our approach relieves the parser of the burden of generating a unique meaning representation fall equivalent sentences  , which becomes harder in proportion to the number of languages the system has to translate  . 
2 . Shal t2 Architecture and Knowl-edge Sources Shalt2 has five types of knowledge sources : a set G of syntactic gramma rules  ( including dictionaries )  , a set C of hierarchically defined conceptual primitives called concept definitions  , a set M of mapping rules between syntactic and conceptual structures  , a set P of conceptual paraphrasing rules , and a set E of cases ( a structurally and conceptually disambiguated set of sample sentences  )  . These knowledge sources are shared by three major processes : a parser  , a concept mapper , and a generator . G should be provided for each language , whereas the set C should be defined for each application domain  . M , P , and E should be provided for each pair of a language and a domain  . t Figure 1 shows an overview of the Shall2 architecture . 
* fOur theory of multi-domaln translation aims to compose a set of mapping rulese filclelxtly when Mever ~ ldoma  . lnn are combined . 
It it expected thffit wo~t J of mapping rules for  ?   , ingle language will differm ~ nly is lexieal mipping rules  . 
Conceptual Transfer
Koichi TAKEDA Nao hik oURAMOTO
Tetsuya NA SUK A WATM jiroT SUT SUMI
Tokyol ~ esearch Laboratory , IBM Research 519 Sanban-cho , Chiyoda-ku , Tokyo 102 , Japantakeda , uramoto , nasukawa , tsutsumi ~ rl . vnet . ibm . com . . . .
~ p  ~
Figureh Shalt 2 Architecture 2 . 1 Syntact ic Grammar Shalt2 currently has two English grammars ( PEG and a less competent English grammar ) and a Japanese grammar . The last two grammars are bi-direction aigrammars written in an LFG-llke formalism called a pseudo -unification grammar  ( PUG ) \[ x?\] , and were originally employed in KBMT-89 . t t PEG is not bidirectional , since it has too many destructive operations to build or encode record structures  , but it is our primary English grammar for three reasons :  ( 1 ) broadcoverage ,   ( 2 ) ability to encapsulate structural ambiguities in a compact parse tree  , and ( 3 ) compatibility with other NLP programs that use PEG to analyze English sentences  . Our bidirectional English grammar is following up PEG and will be able to replace it  . The symmetric architecture of Shalt 2 , however , allows unidirectional knowledge sources and processes to be hooked into the system  . Their coverage and ability to parse or generate sentences can be measured in terms of a set of conceptual representations that they can relate to syntactic structures  . 
Although the syntactic structures of PEG and PUG grammars differ  , they are integrated into a single syntactic representation called Dependency Structures  ( DSs ) \[ s\] . Roughly speaking , a DS is a treelike structure with a set of nodes and a set of ares  , which correspond to maximal projections of syntactic on stituents and gram-t-f The Eagfish version was originally written by GL teg et al  12l but wannot bi-directional . The Jap ~ mesegr ~ . n max was originally written by Mitamura and T~keda\[2\]  . The Shall2 verlions of these PUG graxama ~ have been modified conBiderably to allow them to handle coordinations  , compaxativ ~ , and so on . 
ACIES DECOLING-92 . NANTES . 2328 AOL rT1992 I034 PROC . OFCOLING-92 . NANTES . AUG .  2328 . 1992 tactical relationships , respectively . Some grammatical formalisms such as Constraint Dependency Grammar  14\] postulate DSs as syntactic representations to which a constraint satisfaction algorithm  \[~1 can be applied in order to resolve syntactic /semantic ambiguities efficiently  . 
In the following , we show a PEG parse tree and a PUG f-structure , which will have the same DS , for the simple sentence " Insertadiskette into the drive  . "" PEG Parse Tree: ( IMPR ( VERB*'Insert ' ( insert PS ) )  ( NP ( DET ( ADJ*'a ' ( a BS ) ) )   ( NOUN *' diskette ' ( diskette SG ) ) )   ( PP ( PREP ~ into ' )   ( DET ( ADJ *' the ' ( the BS ) ) )   ( NOUN ' drive ' ( drive SG ) ) )   ( PUNC' .  '  )   ) F-structure in the PUG English grammar : ( ( ROOT insert )   ( CAT v )   ( SUBCAT trans )   ( FOR Minf )   ( MOOD imp )   ( TENSE pros )   ( 0BJ ( ( ROOT diskette )   ( CAT n )   ( DET in def )   ( NUM sg ) ) )   ( PPADJUNCT ( ( ( ROOT drive )   ( CAT n )   ( DET def )   ( NUM sg ) ) ) ) ) 
DS : insert(CATv , SUBCAT traus,
MOODimp , TENSE pros)
DOBJECT diskette(CATn , DET ind of , NUMsg)
PPADJUNCT drive(CATn , PREP into , DET def , NU Mag ) The reader * nay no * leet hat the above sentence should really have ambiguities in prepositional phrase attachment  , which result in two conflicting dependencies " insert-PPADJUNCT-drive " and " diskette- PPADJUNCT-drkve " in a single DS  . We will discuss the handling of such ambiguities in Section  3  . 
2.2 Concept Definitions
A set of conceptual primitives is called a Natural Language  ( NL ) class system\[hi , and is maintained as an eIt 171 object-oriented knowledge base under l~ramK' . The NL class system consists of a set of constant classes  , three meta-classes , and virtual classeo with an exclusive inheritance mechanism discussed below  . 
Each class represcnts a concept in the realworld . A classhms zero or more slots , which describe the fillers it may use to represent a compound concept  . NL objects are particular instances of NL classes  . There are is a and parl-of relationships defined over the NL classes  . 
For example ,   ( de T class * insert ( is a ( value * action ) )  ( : agent ( sem * human * system ) )  ( : theme ( sem * physical-object ) )  ( : goal ( sem * location * physical-object ) ) ) defines a class * insert with an isa link to a class * action  , and three slots-:agent , : theme , and : goal . The ( value . . . ) facet shows an actual filler of the slot , while the ( see . . . ) facet shows the selectional restrictions on the slot  . 
A class inherits each slot definition from its super-class  ( on )  , that is , the fillers of the is a slot , uuless the slot is redefined . A class can have more than one immediate superclass  , but we restrict its inheritance to be exclusive rather than general multiple inheritance  . 
Tilatis , au instance of a claim c~s inher it slot definitions from only one of its imraediate superclaaqes  . The idea behind exclusive inheritance is to realize certain identity of verbal and nominal word senses without mixing the slot definitions of both  . For example , most verbs have nominal counterparts in a natural anguage  , such as ' ~ insert " and " insertion . "Such a pair usually shares slot definitions ( : agent , : tlmmc , and : goal ) and selectional restrictions , except that " insert " inherits tense , aspect , and modality from its " verbal " superclazs but not cardinality  , ordinal , and definiteness ( that is , the quality of being indefinite or definite ) from its " nominal " superclazs , although these features are inherited by " insertion  . " The following class definitions ( def class * physical-action ( is a ( value * predicate ) ) )   ( def class * mental-object ( is a ( value * object ) ) )   ( def class * action ( in-u ( value * physical-action * mental-object )   )   ) allow every instance of subclasses of * action to inherit slot definitions from either * physical -action or * mental-object  . Exclusive inheritance also contributes to performance improvement of the parser since it allows us to reduce the number of possible superclasses from an exponential number to a linear number  . 
There are three recta-classes in NL classes -* vat  , * set , and * fun-to represent concepts that are not in -eluded in the normal class hierarchy  . The first , * vat , is a variable that ranges over a set of NL classes  , which are constants . Pronouns and question words in natural languages usually carry this kind of incomplete concept  . 
The second , * set , is a set constructor that can represent a coordinated structure in natural languages  . The third , * fun , is a function from NL objects to NL objects . It captures the meaning of a socalled sentio function word  . 
For example , in some usages , the verb " take " does not really indicate any specific action until it gets an argument such as " a walk  , "" arest , "" alook . " It is therefore well characterized as a function . 
Since we allow only exclusive inheritance , the NL class system certainly lacks the ability to organize classe ~ front various viewpoints  , unlike ordinary multi-pie inheritance . Virtual classes are therefore introduced to compensate for this inability  . I ~ brexample ,   ( de ~ velass * option ( dsf ( * math-coprocessor * hard-disk * software ) ) )   ( ds ? v class * male-thing ( dsf ( equal : sex*male ) ) ) shows two types of virtual classe , * option and * male-thing . The * option consists of the classes * math -coprocessor  , * hard-disk , and * software . The * male-thing is a class that includes instances of any class with the : sex slot filled with * male  . Note that the maintainability of a class hierarchy drastically declines if we allow classe such as * option to be " actual " rather than virtual  , as we will have many is a links from anything that could be an option  . The second type of virtual class helps incorporate an-called semantic features into the NL class system  . Exist in ~ machine-readable dictionaries ( for example , LDOCE tel ) often have entries with semantic feature such as HUMAN  , LIQUID , and VF ~ HICLE that may not fit into a given ontological class hierarchy  . A virtual class definition AcrEs DECOL 1NG-92 , NAlVtES , 2328 ^ OUr 19921035 P Rec . ol . COLING-92, NAI VrES , Auo .  2328 .  1992  ( de:fv claos * haman ( def ( equal : haman * true )   )   ) with semantic restrictions ( : agent ( sere * human ) ) make it possible to integrate such entries into the NL class system  . 
The NL class system currently includes a few thousand concepts extracted from the personal -computer domain  . The word senses in the SHALT dictionary ( about 100 , 000 entries ) and the LDOCE ( about 55 , 000 entries ) have been gradually incorporated into the NL class system  . 
2.3 Mapping Rules
Mapping rules define lexlcal and structural correspondences between syntactic and conceptual representations  . A lexical mapping rule has the form ( emap * insert <= i => insert ( ( CAT v )   ( SUBCAT trans ) )  ( role = sQm ( * physical-action ) )  ( : agent=syn ( SUBJECT ) )  ( : theme=syn ( DOBJECT ) )  ( : goal=syn ( PPADJUNCT ( ( PREP into )   ( CAT n ) ) ) ) ) where a transitive verb " insert " maps to or from an instance of * insert with its exclusive superclass * physical-action  . The three slots for st , ' uctural mapping between concepts (: agent , : theme , and : goal ) and grammatical roles ( SUBJECT , DOBJECT , and PPADJUNCT ) are also defined in this rule . The : agent filler , for example , should be an instance that is mapped from a syntactic SUBJECT of the verb " insert  . " The : goal filler must be a prepositional phrase consisting of a noun with the preposition " into  . " The fragments of syntactic feature structures following a lexical word or a grammatical function in a mapping rule specify the minimum structures that subsume feature structures of candidate syntactic on stituents  . These structural mappings are specific to this instance  . 
The structural mapping rule ( emap * physical-action <= s=> ( : mood=syn ( MOOD ) )  ( : time=syn ( TENSE ) ) ) specifies that the conceptual sots : mood and : time map to or from the grammatical roles MOOD and TENSE  , respectively . Unlike the structural mapping in a lexical mapping rule  , these slot mappings can be inherited by any instance of a subclass of * physical-action  . The * insert instance defined above , for example , can inherit these : mood and : time mappings . Given a dependency structure ( DS ) , mapping rules work as distributed constraints on the nodes and arcs in the DS in such a way that a conceptual representation R is a uimage of the DS iffR is the minimal representation satisfying all the lexical and structural mappings associated with each node and arc  . On the other hand , given a conceptual representation K , mapping rules work inversely as constraints on 1% to define a minimal DS that can be mapped to 1%  . 
Thus , assuming that lexieal mapping rules are similarly provided for nouns  ( diskette and drive ) and feature values ( imp , pros , and so on ) , we will have the conceptual representation ~ ~ Conceptual representation fa sentence consists of instances of classes  . We use a hyphen and a number following ~ ca~s name  ( * insert-l , * imp-l ,   . . . ) when it is necessaxy to show instaJlces explicitly  . Otherwise , weidtntlfy class na~nes and instance names . 
(*insert-I ( : mood ( * imp-l ) )  ( : time ( * pros-l ) )  ( : theme ( * diskette-I ( : def ( * indef-l ) )  ( : ham ( * sg-l ) ) ) )  ( : goal ( * drive-i ( : d of ( * def-l ) )  ( : hUm ( * sg-2 )   )   )   )   ) for tile sample sentence and its DS shown earlier in this section  . 
2.4 Conceptual Paraphrasing Rules
We assume that a source language sentence and its translation into a target language frequently have slightly different conceptual representations  . An adjective in English might be a eonjugable verb in translation  . These differences result in added/missing information in the corresponding representations  . The conceptual paraphrasing rules describe such equivalence and seml-equivalence among conceptual representations  . These rules are sensitive to the target language , but not to the source language , since the definition of equivalence among conceptual representations depends on the cultural and pragmatic background of the language in which a translation has to be expressed  . An example of a paraphrasing rule is ( oquiv ( * equal ( : agent ( * X ( : hUm ( * V ) ) ) )  ( : theme ( * Y /* porson ( : def*indef )   ( : sum ( * W ) ) ) ) )   ( * Z /* ac % ion ( : agent ( * X )   ( : num ( * V ) ) ) )  ( such-that ( humanization * Z*Y )   ( sibling * V*W ) ) ) where * Y /* person specifies * Y to be an instance of any subclass of * person  , * equal is roughly the verb " be , " humanization is a relation that holds for pairs such ms  ( * singer , * sing ) and (* swimmer , * swim ) , and sibling holds for two instances of the same class  . Intuitively , this rule specifies an equivalence relationship between sentence such as " Tom is a good singer " and " Tomsings well  , " as the following bindings hold: ( * equal ( : mood ( * dec ) )  ( : time ( * pros ) )  ( : agent ( * tom ( : num ( * sg ) ) ) )  ( : theme ( * singer ( : property ( * good ) )  ( : d of ( * ind of ) )  ( : aura ( * sg )   )   )   )   )   ( * sing ( : mood ( * dec ) )  ( : time ( * pros ) )  ( : agent ( * tom ( : num ( * sg )   )   )   )   ( : property ( * good ) ) ) whore * X = * tom , * Y=*singer , * Z=*sing , * V=*sg , and * W = * sgAll the instances that have no binding in a rule must remain unchanged as the same slot fillers  ( e . g . , * dec and * pros ) , while some fillers that have bindings in a rule may be missing from a counterpart instance  ( e . g . , * in def and * W above ) . Note that * good has lexical mappings to the adjective " good " and the adverb " well  . " 2 . 5 Case Base A case base is a set of DSs with no syntactic/semantic ambiguities  . A conceptual representation for a DS can be computed by a topdown algorithm that recursively tries to combine an instance mapped from the root node of a DS with an instance of each of its subtrees  . The arc from the node to a subtree detern fiues the conceptual slot name  . 
We have already built a case base that includes about  30  , 0 00 sentences from the IBM Dictionary of ACRESDE COLING-92  . NANTES , 2328 AOUl19921036 PrisE , oF COLING-92 , NANTES . AUG .  2328 , 1992 te ATv , kete BPc ~ theme OBJECT ": location -- ln-- theme ECT~PPADJONCT ? "*'-  . . . /"( CATn ) diskette . . . . . .
ICATn ): io cat lon-n~-~--~
Only relevant hfformation is slmwn . Mapping constraints ( e . g . : Umme=DOBJECT ) are actually associated for each pall " of instances  . 
Figure 2: Sam I ) leDS with Mapping Constraints Computing\[x\] . Selected sentences in the \] , DOCE have also been added to the casebase . The sentences in the LDOCE define word senses or show sample usages of each entry  . Though composed of a limited vocabulary , they are often syntactically/semantically ambiguous and it is time-consuming for users to build the casebase completely manually  . Therefore , the Shalt2 parser is used to develop the case base . Starting with a small , manually crafted " core " ease base , e~chnew sentence is analyzed and disambiguated by the parser to generate a DS  , which is corrected or otodified by the user and then added to the case base  . As the size of the case base grows , timprot ) ortion of human correc-tions/modifications decreases  , ince the output of the parser becomes more and more accurate  . Wise process is called knowledge bootstrapping and is discussed by Nagao  \[6\] in more detail . Mapping coustraints , howev cr , are associated with only a part of the casebase , because the NL class system and the mapping rules arc not yet complete  . 
3. Pm'ser
The Shall2 parser first generates a DS with packed structural ambiguities for a given in lmt sentence  . It actually calls a PEG parser or ' lbmita's LR -parser  \[12\] for PUG , and then calls a DS converter to map a PEG parse tree or a PUG feature structur c ~ to a DS  . Next , mapping rules arc applied to the DS so that lexical and structural mappings are associated with each node and arc in the DS  . Figure 2 shows a DS with mapping constraints for the sentence " Keep the diskette in the drive  , " where the verb " keep " hastive word senses :* execute  , * guard , * hold , * employ , and * own . It is clear that we will end up with ten distinct conceptual representations if we evaluate all tim mapping rules  , and in general , combinatorial explosion could easily make the parser impractical  . Viewing the mapping rules as coo-stralnts rather titan procedural rules is the key to our parser  , and is called delayed composition of conceptual representation  . 
A sentence analyzer called SENA\[ x41 disambiguates the DS by using a constraint solver JAUNT\[S\]anda"~Tomlta~slucidamhigulty packing  \[12\] is used to obtain a feature structure with packed atructur M ambiguities  . 
case base . JAUNT applies grammatical constraints ( for instance , nlodifier-modifiee links betwee nodes do not cross one another  ) and semantic on straints ( such as selectional restrictions , t ~ functional control , and other NL object identity constraints detected by the context analyzer  ) uniformly to a DS that has ambiguities , and calculates pairwise consistency efficiently for each combination of nodes  . Finally , the casebase provides prefoerential knowledge to favor one pair of nodes over all other consistent pairs  . The disambiguation process call be summarized as follows:  1  . For each conflicting arc in the DS , calculate the " dl stauce " \[6\] between the two nodes in the arc by using a case base  . 
2 . Leavetile , xrc with the minimal distance and eliminate all the other conflicting arcs  . Each NL object associated with a matching node in the case base also gives a higher preference to the same class of instance over the other instances in a node  . 
3 . Propagate the deletion of arcs to other nodes and arcs in the DS  . Eliminate nodes and arcs that are no longer valid in the DS  . 
4 . Apply the above steps until there are no conflicting arc ~ in the DS  . 
The resulting 1) S has 11 ostructural ambiguity . B . e-madling lexical ambiguities are similarly resolved  , because we can also determine which pair of NL objects connected with an arc has the minimal distance in the case base  . Our casebase for cmn puter manuals would support the " diskette-PPADJUNCT-drive " arc and the *   hold-1 instance with diskette as its DOBJECT . 
Therefore , the parser will eventually return ( * hold-1 ( : ~ cheme ( * diske ~ ; te ( : location-in ( * drive )   )   )   ) as a disambiguated result . Nagao\[ediscusses no resophisticated techniques such as scheduling sets of arcs to bc disambiguated  , backtracking , and relaaation of case base matching by means of an isa hierarchy  . 
Finally , a context analyzer is called to resolve auaphora , identity of definit c nouns , and implicit identity between NL objects . It stores the DS in the working space , where references to preceding instances are represented by the links between instances in the DSs  . These intersentential links are used to determine the scopes of adverb such as " also " and " only "  . 
For example , if the phrase " role of an operator " appears in a text  , the word " operator " could be a person who operates a machine or a logical operator for computation  , but no sufficient information is available to resolve this ambiguity at this moment  . In such cases , creating referential links in a forest of DSs could lead us to find evidence for disamblguating these two meanings  . The scope of an adverb , such as " also , " is determined by identifying repeated NL objects and newly introduced NL objects  , where the latter are more likely to fall within the scope of the adverb  . 
The context analyzer uses a similar method to determine lexical ambiguities that were not resolved by the sentence analyzer wlmn the case base failed to provide enough information  . 
? ~ We use about 20 of the semantic features described in the LDOCE . The restrictions imposed by the features are rather " loose  , " and are used to eliminate only unlikely combinations of word senses  , Aches DECOL1 NG-92 . NANII ~ S , 2328 AO~r\[1992 l03'7 PRO: , O1: COLING-92 . NANTES , AUO .  23-280 1992 4 . Concept Mapper Given a conceptual representation , which is an output from the parser , and a target language , the concept map pertries to discover another conceptual represea-tation that has a well -defined mapping to a DS while keeping the semantic ontent as intact as possible  . This process is called conceptual transfer . If the given con-eeptual representation already has a well-defined mapping to a DS  , the concept mapper does nothing and Shalt2 works like an interlingual MT system . It is important hat conceptual transfer should be related with the mapping to a DS  , because there are generally many conceptual representations with a similar semantic on-tent  . The existence of well-defined mapping not only guarantees that the generator can produce a sentence in the target language  , but also effectively eliminates unsuccessful paraphrasing  . 
1 11 addition to the paraphrasing rules mentioned earlier  , the concept mapper uses the following genera \] rules for conceptual transfer J The paraphrasing rules are composed to make a complex mapping  . 
* Projection : MapanNL object with a filled slots to an instance of the same class with the unfilled slots  . Projection corresponds to deletion of a slot 8 . 
s Generalization : MapanNL object of a class X to an instance of one of the superclasses of X  . 
e Specialization : MapanNL object of a class X to an instance of one of the subclasses of X  . 
As an example , a projection rule is frequently used when we translate English nouns into Japanese ones  , as in the following examp : diskette ( * diskette ( : sum ( * st )   )   ) diskettes ( * diskette ( : num ( * pl ) ) ) a diskette ( * diskette ( : num ( * st )   )   ( : def ( * inde X ) ) ) the diskettes ( * diskette ( : num ( * pl ) )  ( : def ( * def ) ) ) ~4A~r 7~ ( * diskette ) Here , the four English noun phrases above are usually translated by the same Japanese noun phase f ~  ( the fifth one )  , which does not carry any information on mum and : def  . We provide a paraphrasing rule for translation in the opposite direction such that for any instance of the * object can obtain appropriate : sum and : deffillers  . The parser , however , is responsible for determining these fillers in most cases  . In general , the designer of semi-equivalent rules for translation in one direction has to provide a way of inferring missing information for translation in the opposite direction  . Generalization and specialization rules are complementary and can be paired to become quivalent rules when a specialization rule for any instance of a class z is unambiguous  . That is , without losing any fillers , one can always choose an instance of a subclas ~ V to which z can be uniquely mapped  . A generalization from e ~ ch ~ to z provides the opposite mapping  . 
~ Theee are ~ emi-equiv Ment rules . Equivalent rules have higher priority when the tulsaaxe to be applied  . 
~ fOne exception is that deictic noun phrases are translated when we use the ~ a panme counterpart  "-~?3 ~ for the determiner " the " . 
5. Grammar-Based Sentence Generator
Recent investigation of unification grammars and their bi-direetionality Its  ,  9 ,   \]0\] has enabled us to design and implement a grammar -based generator  . Our gen~crater uses a PUG grammar , which is also used by the parser , to traverse or decompose a feature structure obtained from a D $ in order to find a sequence of grammar rule applications  , which eventually lead to lexical rules for generating a sentence  . The generation algorithm is based primarily on We dekind's algorithm  , but hmer it-tied for PUG . 
The current implementation of our generator lacks subtle control of word ordering  , honorific expressions , and style preference . We are developing a set of discourse parameters to a ~ ociate preferences with grammar rules to be tried  , so that specific expressions are favored by the parameter settings  . 

Yutaka Tsutsumi built an initial version of conceptual definitions  . Katashi Nagao originally designed and implemented the disambiguation algorighm of the sentence analyzer  . His continuous efforts to build a largescale ease base and to improve the disambiguation algorithm have been continued by the  Shalt2 group . Hiroshi Maruyama enhanced his constraint solver for our project  , which has led us to a constraint propagation method with delayed composition of conceptual representations  . Michael McDonald read through an early draft of this paper and gave us many suggestions on technical writing  . We thank them all . 
References 1) IBM Corp . "Dictionary off Computing " ( gth Edition ) . SC20-1999-07, 1987 . 
2) D . Gates , K . Takeda , T . Mitamur &, L . Lev Ln , and M . Kee . " Anaby=i , and Generation Grammar " . M~ehine T ~, n = latio , , 4(1) 153-9 StMarch 1989 . 
3) K . Goodman and S . Nirenburg , editors . " The KBMT Project : A Coze Study in Kno~ledse-B ~ #ed Me  , chine ~ an  #allonn . Morgan Kaufmann Pubi~herw , San Matzo , California ,  1991 . 
4) H . Maruyama . " Structural Disambiguation with Constraint Propagation S  . In Prec . el the ?8th Anntml Meet in 9 of ACL , volume 31 pages 31-38 , June 1990 . 
5) H . Maruyama . " JAUNT : A Constraint Solver for Disjunctive Feature Structures "  . Technical Report PDfOO59, Tokyo ~ arch
Lab ., IBM Reaearch j 1991.
6) K . Nagao . "Dependency Analyzer : A Knowledge-Baaed Approach to Structural Dmambiguation "  . In prec . of I he 13th lnlern?t lonal Con\]erence on Comput?tional Ling , lille * , pagen 484-489 , Aug .  1990 . 
7) E . Nyberg . " The Frame Kit Uler % Guide Version 2 . 0" . Technical Report CMU-CMT-88-MEMO , Center for Machine Translation , Carnegie Mellon Univereity , March 1988 . 
8) Procter P . Lo , t  #man Dictionarpel Contemporar ~1 English . 
Longman Group Limited , Harlow and London ~ England , I 978 . 
9) S . M . Shieher , F . C . I "4 . Pereira , G . van Noord , and R . C . Moore . 
" Semantle-Head-Driven Generation " . Computational Linsni#-ic J ,  19(1):30-42 , March 1990 . 
1O ) K . Takeda . = Bi-Dire et lonal Grammarl for Machine Tranalation " . 
In Pros . of Seoul International Conference on Natural Lan . 
guase Proce , Jin ~ , page ~1~2~197 , Seoul , Korea , 1 November I9 90 . 
11) K . Takeda . UD~ign~ng Natural Language Objects n . In Prec . 
oJ?ndl nlernationglSFmpo*i ~ monDatabameS ~ /Jtem * for Ad  . 
vaneed Appll cationlt page m 444-448 , Tokyo , Japan , April 1991 . 
12) M . Tomlta . " Effleienl Parsln 9 for N?tural Language : AFtst Algor ~ th ~\] or Practical Sp * lemln  . Kluwer Academic Publi 0 here,
Beaten , MA , 198S.
13) T . Ttutgurnl . " A Prototype Engllsh-Japanene Machine Tr~nsi ~ -tips System for Tranalatln  8 IBM Computer Minuals " . In prec . 
of the llth lnternation ? lConJerenee on Computation ? lLigtt  . 
i/tie J , Auguut 1986.
14) N , Uramoto . " I~xical and Structural Disarn biguation Using an Example * B rute "  . In Prec . of the SadJa~n-A ~ Jtmlia Joint . qytnpo#iu ~ tonNLP , pages 1nO-160, Oct .  1991 . 
15) J , We de kind , = Generation as Structure Driven Derivatlon " . In P ~ e . of the l?th International Conference on Computational Ligui * iiem  , page=732-737 tAugust 1988 . 
ACRESDE COLING-92 , NANTES , 2328 AOt ~ T1992i038 PROC . OVCOLING-92, NANTES , AUG .  2328, 1992
