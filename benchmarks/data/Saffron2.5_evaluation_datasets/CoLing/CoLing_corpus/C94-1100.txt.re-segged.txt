BUILDING ALEXICAL DOMAIN MAP FROM TEXT CORPORA
Tomek Strzalkowski
Courant Institute of Mathematical Sciences , New York University
715 Broadway , rm ,  704 , New York , NY 10003 , tomek@cs . nyu . edu

In information retrieval the task is to extract from the database ~ dl  , and only the documents which are relevant to a user query  , even when the query and the documents use little common vocabul ~ u'y  . In this paper we discuss the problem of automatic generation of lexical relations between words  , and phrltses from large text corpora : rod their application to automatic query expansion ill information retrieval  . Reported here , are some preliminary resuhs and observations from the experiments with a  85 million word Wall Street Journal dalabase and a 45 million word San Jose Mercury News database ( piu'ts of 0 . 5 billion word TIPSTER/TREC datab`ase) . 

Tile task of information retrieval is to extract relevant documents from large collection of documents ill response to a user's query  . When the documents cont:dnprimm'ily unrestricted text  ( e . g . , newspaper ` articles , legld documents , etc . ) the relev , ' mce of a document is established through ' full text ' retriew d  . This has been usually accomplished by identifying key terms in the documents  ( the process known as ' indexing ' ) which could then be matched againsterms in queries  ( Salton ,  1989) . The effectiveness of , any such term-b ` ased approach is directly related to the accuracy with which a set of terms represent she content of a document  ,   , as well as how well it contrasts a given document with respect o other documents  . In other words , we , are looking for a represeutation R such that for any text items  D1 and D2  , R(DI ) = R(D2) iff meaning(D1) = meaning(D2) , at an appropriatelvel of abstraction ( which may depend on types and character of anticipated queries  )  . 
For all kinds of terms that can be assigned 1o the representation of a docmnent , e . g . , words , operator-m'gument pairs , fixed phrases , ~md proper n , ' unes , vl trious levels of " reguh'u ' ization " , are needed to , assure that syntactic or lexie , ' dv , ' u ' iations of input do not obscure underlying semantic uniformity  . Without actually doing semantic analysis , tiffs kind of normalization can be achieved through the following processes : ~  ( 1 ) morpbological stemming : e . g . , retrieving is reduced to retriev ; An altematlve , but less efficient method is to generate all variants  ( lexical , syntactic , etc . ) of words/phrases in the queries ( Sparck-
Jones & " Fail , 1984).
(2) lexicon-based word nonnldizntion : e . g . , retrieval is reduced to retrieve ;   ( 3 ) operator-argument representation fphr'tses:e . g . , information retrieval , retrievhlg of information , and retriever elewmt information , are , all assigned the slune representation , retrieve+bt formation ;   ( 4 ) conlext-blmed term clustering into synonymy classes and subsumption hierarchies : e  . g . , takeover is a kind of acquisition ( in business )  , luld
For tran is a programming language.
We have established the general architecture of a NLP-IR system that accommodates these considerations  . In a general view of this design , depicted schematic ~ dly below , an advanced NLP module is inserted between the textuld input  ( new documeuts , user queries ) and the datab ~ Jse search engine ( in our c ` ase , NIST's PRISE system ) . 
NLP:'FA\[~PARSER temls
This design has already shown some promise in producing signific ~ mtly better performance than the base statisti-cld system  ( Strz~dkowski ,  1993) . Its practical significance stems in no slnall part from the use of atkstand robust parser  , TI'P ,   2 which can process unrestricted text at speeds below  0  . 2 sec per sentence . TI'P's output is It regularized representation 1' each sentence which reflects logical prcdical c -argum clllsu ' u clure  , e . g . , Iogic:d subject and logical objects are identilic d depending upon the main verb subcategorization frame  . For example , I hever babide has , among others , a subcategorization frame in which the object is a prepositional p brase with by  , i . e . ,
ABIDE : subject NP object PREP by NP
Subcategorization in lbrmution is rend from the online Oxford Advanced Le`arner's Diction  , try ( OALD ) which
TTP uses.
TFP stands for Tagged Text Parser , and it has I:e en described in detail in ( Strzalkowski , 1992) and ev~duated in ( Strzalkowski &
Scheyen , 1993).
604 ltEAD-MODIFIERSTRUCTURES
TTP p , ' u'sestructures are p~ts sed to the phrase extraction module where head+modifier  ( including predicate + , ' u'gument ) pairs are extracted and collected into occurrence patterns  . The following types of head+modifier pairs m'e extracted :  ( 1 ) a head noun and its left adjective or noun adjunct  , (2) a head noun , and the head of its right adjunct , (3) them , ' finver b of a clanse and the head of its object pbrase  . 
These types of p , ' firs account for most of the syntactic vm'i~mts for relating two words  ( or simple phrases ) into pairs c , ' urying compatible semantic ontent . For example , the pair retrieve+information will be extracted frommty of the following fragments : information retrieval system  ; retrieval of it ~ rmation /) ' om databases ; and information that can be retrieved by a user -controlled interactive search process  .   3 Figure 1 shows TTP parse and head+modifier pairs extracted  . Whenever multiple-noun strings ( two nouns plus another noun or adjective ) are present , they need Iobe structurally disambiguated before any pair semt be extracted  . This is accomplished using statistically-based preferences  , e . g . , world+third is pt'etizn'ed to either country + world or cot  #ltry + third when extracted from third world country  . If such preferences cannot be cont-puted , all alternatives , ' u'ed is carded to avokl noisy input to clustering progrmns  . 
\[S ; mJose Mercury News 8/30/91 Busilmss Sectlonl For McCaw , it wouhl have hurt the company'stralegy of building a seamless national cellularilel Wolk  . 
\[ assell,\[\[ will auxl , llpeff,\[havell,
Ilvetb , lhmtll , \ [ sul ' , jeet , lnl' , ,lu , it111 , \[ ol~jeel , \[t'q , \[n , slnltegy\] , \[t_l?~s , the I , 
In ~ ms , lposs.tn , cornpanyIll.
\[ of , ll verb J buihlll , \[ subject , ~myouel , Idject , l . p,ln . l ~ etwozkl , \[ tf , os , aI , ladj , lse ; unless II , \[ adj , luational \] l , \[ adj . lcellularllll\]ll\]ll,
I for , lup , I name , lmcca wllll.
EX'I'I~ . AUIT 21I'A1RS : hall+sFate ~ ,   , yslFalegy + colnlally build+nelwork network +cchJlaruetwetk+llali ' ollalhe work+seamless F ' tgnre  1  . Extracting I lead+Modilier pairs from parsed sentences  . 
TERMCORRELATION SFROMTEXT
Head-modifier pairs serve as occurrence contexts for terms included in them : both single words  ( as shown in Fignre 1 ) and other pairs ( in case of nested pairs , e . g . , cottntry+\[world+third\]) . If two terms tend to be modilic d with a number of common modifiers but otherwise appear in few distinct contexts  , we assign them a simih ' uity coefficient , a real number between 0 and 1 . The similarity is determined by comparing distribution characler is lics for both terms within the corpus : in general we will credit high-content terms appem'ing in multiple identical elm-texts  , provided that these contexts are not too common place  .   4 Figure 2 shows exmnples of terms sharing a number of common contexts along with frequencies of occurrence in a  250 MByte subset of Wall Street Journal database . A head context is when two distinct modifiers , are attached to the same head element ; arood context is when thes , ' une term modilles two distinct heads . 
To compute term similarities we used a variant of weighted Jacc\[u'd's measure describedine  . g . , ( Grefen-
TFR MITERM 2 COMM CNTXT FRQIFRQ 2
IIE ADMOD vice delmty
I 1; 11) heyp resident 929529 chaiml , ' ml ( X ) 7  146 director 6   158 minisler 37   17 premier 7   8 sloly 9   3 chibfi 4 age 18   3 mother 4   5 bad 4   4 yot mg 258   12 ohler 18   , Ili'tgure2 . L : xample pairs of related re . ms . 
3 snbject+ved  pairs are also extracted but these are not used in the lexical clustering procedure described here  . 
4 It would not be appropriale to predict similarity I~  . ' tween language and logarithm on the basis of their cooccurrence with mztural  . 
stette , 1992):5
In another series of exf , or in mt~ts ( Swzalkowskl & Vauthey ,   1992 we used a Mtllnal lnfo0maliou I ased classill calion formula ( e . g . , Church and ttanks , 1990; lliudle ,  1990) , but wel ~ , unditless effeclive for diverse dalabases , uchas WSJ . 
605 ~__ , MIN(W(\[x , att\]) , W (\[ y , att\])
SIM(xt , x2) = att ~ . MAX(W(\[x,att\]),W(\[y,att\])~ltt with
W (\[ x , y1) = aEW(x ) * to g(f ., a)
GEW(x ) = I + nyv ~ nyj to g(N ) 1
In rite above , f  ~ , y stands for absolute fi'equency of pair \[ x , y \] in tile corpus , n y is the frequency of term y , and Nist tte number of single-word terms . 
hiorder to generate betters it nilarities , we require that words xt and x2 appear in at least M distinct conl-ilion contexts  , where It common context is a couple of pairs \ [ xt  , Y \] and \[ x2 , y\] , or \[ y , x1\] and \[ y , r 2\] such that they each occun'ed at legist K times . Thus , banana and Baltic will not be considered for similm-ity relation on the basis of tlteir occurrences in the common context of republic  , no matter how frequent , unless there are M1 other such common contexts comparably frequent ( there was n't any in TREC's WSJ database )  . For smaller or narrow domain databases M=2 is usually sufficient , e . g . , CACM d:ltab:t , ~ e of computer science abstracts . For large databases covering a diverse subject matter  , like WSJ or SJMN(S , ' mJose Mercury News ) , we used M >_5 . 6 This , however , turned out not to be sufficient . We would still genemle faMy strong simih'u'ity links between terms such as a erospace mid pharmaceutical where  6 and more coml noncontexts were found , even after a number of coml noncontexts , such , ' is company or market , have already been rejected because they were paired with tooms my different words  , and thus had a dispersion ratio too high . The remaining common contexts m'e listed in Figure  3  , ~dong with their GEW scores , all occurring at the head ( left ) position of a pair . 
CONTEXT ( ; EW frequency wilh a erospace idutr lnacetttical film  0  . 58922 induslry 0 . 518456 sector 0 . 6159 coneem 0 . 50130115 analyst 0 . 62238 division 0 . 533628 giant 0 . 6215 12 Figure 3 . Common ( head ) contexts for a erospace and idlarma eeutieal . 
6 For example & tnana mM Dominican were found to have two common contexts : republic and plant  , althought iffs second occurred in apparently different senses in Dominican plant and banatla ptatt t  . 
When analyzing Figure 3 , we should note that while some of the GEW weights are quite low  ( GEW takes values between 0 and 1 )  , thus indicating a low iln portance context , the frequencies with which these contexts occurred wilh both ter  , ns were high and balanced on both sides ( e . g . , concern ) , thus adding totiles lrength of association . To liher out such casts we established thres -holds for adlnissible values of GEW factor  , and disre-Du'ded contexts with entropy weights falling below the threshold  . In the most recent experiments with WSJ texts , we found that 0 . 6 is a good threshold . We also observed that clustering bead terms using their moditiers as contexts converges faster and gives generally n to re reliable links thai \] when rood terms are clustered using heads as context  ( e . g . , in the above example ) . In onr experiment with tile WSJ database , we fotm d that an occurrence of a common head context needs to be considered It seoulri-bttting less to the total context cotint than an occurrence of a common rood context : we used  0  . 6 and l , respectively . Using this form tda , terms man and boy in Figure 2 share 5 . 4 contexts (4 head contexts and 3rood contexts ) . 
hlilially , term similmities are organized into clusters around a cent midterm  . Figure 4 shows top 10 elements ( sorted by similarity w flue ) of tile chister for president . Note that in this caselhe SIM value drops suddenly after the second element of the cluster  . Changes in SIMvahle arensed to deternline cutoff points for clusters  . Tile role of GTS factor will be explg fined later . Sample clusters obtained fi'om approx . 250M Byte ( 42 million words ) snbset of WSJ ( years 1990-1992 ) are given in
Table 1.
It may be worth pointing out that the similarities arc calculated ilsing term cooccurrences in syntaclic rather than in document-size contexts  , the latter Ix:ing the usual practice it1 nonlinguistic hlstering ( e . g . , Sparck Jones and Batlx:r , 1971; Crouch , 1988; Lewis and Croft ,  1990) . 
Although the two methods ofte , ' m clustering in aybe COll-sidered mnt ttally complementary in certaitt situations  , we believe that more and slrouger associations can be obtained tllrough syntactic-context chlstering  , given sufliciental nonnt of data and a reasonably accnral csyu- 
CINTI(OII ) president
TI!RMSIM(Yl'g0 . 001 I director 0 . 2481 0 . /1017 chaim ~; m0 . 2,149 0 . 0028 office 0 . 1689 0 . 0010 m , ' ulage O .  1656 0 . 0007 executive 0 . 1626 0 . 0012 official 0 . 1612 0 . 0008 head 0 . 1564 0 . 0018 meml)er 0 . 1506 0 . 0014 lead 0 . 1311 ( I . 0009
Figure 4. A cluster for president.
6 06 word duster take over benefit capital staff " at lracl sensitive speetllate president __+ 
VICe outlookIlaw I earning sprffit , revemfe , income portfolio as set , invest , lo an inflate growth , deni and , earning situhts try business , eompatly , market growth increase , rise , gain firm bank , concern , group , tlniten viron climate , condition , siluation debtloan , sectire , botld lawyer attorney COltnse lattorney , administrator , secretary conlpule mac \] llne , software , eqtl O~ment competitor riwll , competition , bayer alliancei ~ artners Ii Ol , veotnre , eoosor tiunl big ktrge , major , bu . e e , significaot fight battle , attack , war , clallet gebase facile , source , reserve , stqqu ~ rtshareholder creditor , customer , client investor , stock hohler merge , bay-out , acquire , bM compensate , aid , espense cash , fitnd , money personnel , emfloyee , foreehire , draw , woo crucial , difficult , critical r timor , tln certainty , tension director , chairman deputy f i ) recast , t ~ rospect , trend rule , policy , leg&late , bill Tahle 1 . Selected chlsters & taiued fronl syntat : lic contexts  , derived from approx . 40 millio~l words of WSJ tcxl , wiih weighted Jace aid formula . 
tactic parser \] ? Nell-syntactic contexts cross sentetl celmundaries with no fuss  , which is hell ) fulwith shorl , succinct documents ( such as CACM abstracts ) , but less so wilh longer texls ; see also ( Grlshmalielal . , 1986) . 
QUERYI(XPANSION
Sitnilltl'ityrdaiionsaret , sed to expand user queries with new lernts , litan " tt telnp to make tiletinal Seluch tiuery more coln prehensive  ( adding synonytlis ) and/or more pointed ( adding specializalions )  .   11 follows that not all similiu'ily relatiolls will be equally useful ill query expansion  , liar instance , eomplemelltary antiaitlonymous relaliolts like Iheone between Australian and Catladitl#l  , ftCCel ; taildrejecl , or even gelier alizali OilSlike Iroill ( 1?'1"0X13 ( IC ( ~ tO industry may actually hllr in systeln's perlor-nialice  , Siliee we Ilia yend till retrieviiig many h ' relevaill documenls  . On the olher hand , dalal ) ase search is likely to miss relew till doctlnlenls if we overlook the fact that v h : e director Calla l so be depet y dit+et ? lor  , of that lt lkt ' ov('r cgln also be merge , buy-ottl , or acqtdsition . We noled that an average SOl of similarities generated from it lexl corpus conlah is a botit as many " good " relations  ( synottylny , spe-cializalion ) as " lind " r claliolts anlonyiny , coniple in orlla-lion , generalizalion ) , as seen froint he query exp ; lliSiO livie wpoinl . Therefore aiiy all einptIose pai~ile these two classes alid  1o hlerease I he proporlion o1 " good " relalions shot lld result in improved relrieval  . Tills has hldeed heellt Jonlirined in our exper in lenls where a relalively crlide filler has visibly hlcreased reirie wil precision  . 
hiorder It ) creale an appropriate liller , we devised a global lerm speciliciiy in easiiro ( ( ITS ) whidlis calculated for each lerilia cross all conic ? is iii which ii occiirs  . The general philosophy here is thaltiniore specilic word/phrase WOllldh/lYe  11 iilore I illliled use , i . e . , a illOle specilic term wotild appear iit fewer distinct contexts  , hit his respecl , GTS is similar it ) tile standardire'erredtlOCli-met#fi'eqttetu 7   ( id J ) measure excepl l haller n i frequency ix iltt3aStlie  ( lover syntactic tlilil SIather I hall doct ll lenl size unils  . TenliS with higher GTS vahies are generally coil -sidered more specilic  , but the specificily compa , ' is otlis only meanillgful for terms which are already kllown to be similar  . Web dieve that measuring lerm specilicily over doeumelli-size contexts  ( e . g . , Sparck Jones ,  1972)  , nayiiot fie appropriale iiithiscase . In particular , synllax-based contexts allow for process in t ~ lexls without any inlernal doct in lenls lriicl llre  , The new function is calculaled according to the fol-htwing forltiill'i : 
IIC t+(w ) * lC# , ,(w ) if bolll exist ( ; ' I'S(w ) = ~ lCte(w ) if otlly ICte(vv)e . vislsi
LIQ(w ) otherwise where ( wilhnw , el , , . > 0):#1w
ICt+(w ) = IC(Iw,_)=d w(nw+dw-1)
II w
IC1?(w ) = IC(I,wI)-dw(n , , + dw-1)
In the a hove , dw is di . ~7 ) ersion flerm wml der slood as I hemmd ~ er of distinct COll texls in which w is found  . For any two tern lsW1 all dw2 , all ( lit constant ~1 > 1 , ir (77" S(w2)_>8t*( ; TF ( w1 ) then w2 is considered more speciiic lhall w1 . hi addition , if SlM , , o, . ,n(Wl , W2) = fI > 01 , where 01 is a nelr li ) irically containing term wt with weight ~* to ,   8 where co is the weight w2 would have if it were present in the query . 
Simil , ' u ' ly , if GTS(w2) < ~2*GTS(wL ) , ' rodSIM , ,orm(wl , w2) = ~> 0 : ~( with 82 < 8 t , and 0t < 02 ) then we may consider w ~ as synonymous to w ~ . Allotherela-tions , are discarded . For example , the following were obtained from the WSJ training database : 
GTS(takeover ) = 0.0014 5576
GTS(merge ) = 0.00094518
GTS(buyout ) = 0.0027 2580
GTS(acquire ) = 0.00057906 with
SIM(takeover , merge ) = 0.190444
SIM(takeover , buy-out ) = 0.157410
SIM(takeover , acquire ) = 0.139497
SIM(merge , buy-out ) = 0.133800
SIM(merge,acquire ) = 0.263772
SIM ( buy-out , acquire ) = 0.109106
Therefore both take over and buy out can be used to specialize merge or acquire  . With this filter , the relationships between take over ~ md buy out and between merge ~ md acquire  , are either both discarded or accepted as synonymous  . At this time we are unable to tell synonymous or ne  , ' u " synonymous relationships from those which , are prim , wily complement ~ u-y , e . g . , matt , and womatt . 
Filtered simih'u'ity relations create a domain map of terms  . At present it may cont ~ f in only two types of links : equiv  , ' dence ( synonymy and near-synonymy ) , and subsumption ( specification ) . Figure 5 shows a small fragment of such map derived from lexic  , -d relation computed from WSJ datab`ase . The domain map is used to expand user queries with related terms  , either automatically or in a feedback mode by showing the user appropriate p~u'ts of the map  . 
cost number ease expnin ~' tigat__all'ge / w  . ' uit/\subsumption equivalence Figure 5 . A fragment of the domain map network . Note the emerging senses of ' charge ' as ' expense ' and ' allege '  . 
s For TREC 2 we used 0 = 0 . 2;,5 varied between l0 and 100 . 
We should add that the query exp~msion ( in the sense considered here , I bough not quite in the stone way ) has been used in information retrieval research befo*'e  ( e . g . , Sp , ' trck Jones and Tail , 1984; Harm\[m ,  1988) , usu-a Uy with mixed results . The main difference between the current approach , ' u ~ d those previous attempts is that we use lexico-sernantic evidence for selecting extra terms  , while they relied on term cooccurrence within the same documents  . In fact we consider these to methods colnple -mentary with the latter being more appropriate for automatic relevance feedback  . An alternative query expansion to is to use term clusters to create new terms  , " metaterms " , and use them to index the database instead ( e . g . , Crouch , 1988; Lewis , and Croft , 1990) . We found that the query exp ~ si on approach gives the system more flexibility  , for inst , ' mce , by making rooml br hypertext-style topic exploration via user feedback  . 

We discussed selected as pecL q our inlormation retrieved system consisting of an advanced NLP module and a'st~mdard'statistical core engine  , ht this paper we concentrated on the problem of automatic generation of lexical correlations among terms which  ( aloug with appropriate weighting scheme ) represent the content of both the dat : d ) ase documents : rod the user queries . Since it successful retrieval relies on actual term matches between the queries  , ' u ~ d the documents , it is essential tmt any lexical alternatives of describing a given topic  , are taken into account . In our system this is achieved through the expansion of user's queries with related terms : we add equiw dent  , and more specific terms . Lexical relations between terms are c ; dculate directly from the database and stored in t be form of a dom~d n map  , which thus acts as a domaln-specilic thesaurus . Query expansion can be done in the user-feedback mode  ( with user's assistance ) or automatically . In this latter c~s e , local context is explored to , assure meaningful exp ~ msious , i . e . , to prevent e . g . , exp , ' mding'charge'with'expense'when'allege' or ' blame ' is meant  , as in the following ex ~ unple query : Documents will report on corruption  , incompetence , on ' in efficiency in them . magement of the United N . ' ~ litm'sst'dT . Alleg ~ dions t~l'ln I ilageln elll railings , as well as Felofls Io Stl Ch charges ~ u'e relevanl  . 
Many problems remain , however , we attempted 1o demonstrate that the architecture described here is nonet be less viable and h ` as practiced significance  . More advanced NLP techniques ( including semantic , ' m~dysis ) may prove to be still more effective , in the future , however their enormous cost limits ~ my experimental evidence to small scale tests  ( e . g . , Mauldin , 1991) . 

We would like to thank Donna Har , n~m of NIST for making her PRISE system av , ' filable to us . We would , also like to thank R~dph Weischedel and Heidi Fox of BBN for providing and  , ' ts sisting in the use of the p~u't of speech tagger  . This paper is based upon work supported by the Adv  , ' mced Research Project Agency under Contract under Contract  N00600-gS-D-3717 from PRC Inc . , and the Nalional Science Foundalion under Gu~mt 1RI-93-02615  . We~d so acknowledge support from the Canadian lnstiule for Robolics and Intelligent Sysletns  ( IRIS )  . 

Church , Kenneth Ward and flanks , Patrick .  1991/ . " Word association or ms , mutual informal it m , and lexicography . " Computational Linguistics ,  1611) , MIT Press , pp .  2229 . 
Crotlch , Carolyn J .  1988 . "A cluster-based approach to thesaurus construction  . " Proceedings of ACM
SIGIR-88, pp . 309-320.
Grefcnsleue , Gregory .  1992 . " Use of Syntactic Coulcxt To Produce Term Association Lists Ik ~  , Text Reh'iew d . " Proceedings of SIGIR-92, Copenhagen,
Denmark . pp . 89-97.
Grishm , ' m , Ralph , Lynette Hirschman , and Nee T . Nhan . 
1986 . " Discovery procedures R ) rsn blangnag c selectional patterns : inilial experiments "  . Computatiot mll , inguistics , 12(3), pp . 205-215, Ilarman , Donna .  1988 . " Towards in leraclive query expansion . " Proceedings of ACM SIGIR-S 8, pp . 

ltindle , Donald .  1990 . " Noun classiticalion fi'om predicate-m'gument slructur cs  . " l ) roc . 28Meeliug of 1he ACI ,, Pittsburgh , PA , pp .  268-275 . 
Lewis , David D . and W . Bruce Croft .  1990 . " Term Clustering of Syntactic Phrases " . Proceedings of ACM
SIGIR-90, pp . 385-405.
Mauldin , Michael .  1991 . " Relrieval Perl Brmtmce in Ferret : A Conceptual Information Relrieval System  . " Proceedings of ACM SIGIR . -91, pp .  347-355 . 
Sallon , Gerard .  1989 . Automatic Text Processing . " the transformation , attalysis , ( tIM retrieval of infi ) rmalio . 
by computer . Addison-Wesley , Reading , MA.
Sl ) arck Jones , Karen .  1972 . " Slalistical interpretation of lcrm specilicity lindils application in retrieval  . " Journal of Documentation , 28(1), pp . I 120 . 
Sparek Jones , K . and E . O . P ~ arber .  1971 . " What makes at ltomatie keywordel assilicalion effective ? " Journal of the Americatz Society for In Jbrmatiotz Science  , 
MayJune , pp . 166-175.
SparckJones , K . : ulc . lJ . I . Tail .  1984 . " Aulomalic search terlnvm ' iant generatio a . " Journal qfI ) ocz  #nenlaliot L 40(1), pp .  50-66 . 
Strzalkowski , Tomek and Barbara Vaulhey .  1992 . " Iulo , '-malion Retric wd Using Robust Natt , ml Langnage Processing . " Prec . of Ihe301h ACL Meeting , Newark,
DE , June-July . pp . 1/)4-111.
Slrzalkowski , Tomek .  1992 . " TrP : A Fasla M Robust Parserlbr Natural L , -mguage . " Proceedings of the 14111 lnternalional Couference on C ( )mputational Linguistics ( COLING )  , Nantes , Frauce , Jnly 1992 . pp . 

Strzalkowski , Tomek .  1993 . " Robust Text Processing in Automated hfformation Relrieval  . " Prec . of ACI , -sponsored workshop on Very Lart , eCoq ) or a . Ohio
Slate Univ . Coh\]mbus , Julle 22.
Slrzalkowski , Tomek .  1994 . "Document Representation in Natural Language Text Relrieval  . " To appear in proceedings of ARP Alluman Language Technology 
Workshop , Princelon , NJ . March 811.
Slrzalkowski , Tomek and Jose Perez-Cm'ballo .  1994 . 
" Recenl Developments in Natural IAi JIgn , 3ge Text Retriewd . " To appem " in proceedings of Sectmd Texl Retrieval Conference  ( TREC2 )  , Gailhersbvrg , Md , 
August 30-Seplemberl , 1993.
Slrzalkowski , Tomek , and Peler Scheyen .  1993 . "Ewthla-lion of TI'PF'arscr:apreliminary report  . " F ' roceed-ings of lnterualional Workshop on Parsing Technologies  ( lWPT-93 )  , Tilburg , Netherlands and Durbny , 
Belgium , Angus (1013.
APPI~,NI)IX : An examlfle query
The li ) llowiug is an example infommtion requesl ( based on TREC'slOl ) ic 113 ) and file resulliug query . 
Except for its inverled document frequency score , each lerm has a " conlidence level " weight which is set Io  1  . 0 if I heterm is fou ad in then ser's query , and is less lhau 1 . 0 if the term is added Ihrough an expansion fl'om 1he domain map . Only non-negaled terms wilh idf of 6 . 0 or greater arc in clt lde(I . 
< title > New , Space Satellile Applicatim ~ s < desc > l ) ocument will repf ) rton nontraditional p-plicati ( ms of space satellite technol ~ gy . 
< hart > A relevant dO Ctll ncrll will discuss more recerl  (   ( ~ l " emerging applicalions of spaces at ellite technology  . NOT relewmlare such " traditional " arearly satellite age usages as INTELSAT transmission of voice il IIddilll cOtlllll lll liGatlollstel " telephone coin-panics or program feeds fro " established television net wm'ks  . AIs()N () Trelewm ( are such established US eSc , fsat?lliles as military ,  . .: omnnlllic . alilms , eaulhll litlel ' a\]i'e ~; tlrt:e . Illappillg , \[ tllds\[lppor(OF weathel " fi ~ rc casling . A few examples f~f newer applicati ~ ms are the I mikling of privates a tellitenel works f i  ) n ' transferff business dala , facsimile Irans mission t~l " newspapers to be printed in mulliple Iocalimls  , and directImmd casling of TV signals . Tile underlying purp ( ~s coflifts topic is ( o colleclinl brmalion on re-cenlor emerging trends in lheap plicalim of spaces at ellil c lechnology  . 
77 ? RMIDI . " WEIGIIT al)ply+cquip 18 . 402237 0 . 458666 satdlite+latest 18 . 402237 0 . 25, 1058 television + slgnal 18 . 402237 11 . 35 9777 television + dlrect 18/102 237 0 . 359777 apply + equip 18 . 402237 0 . 458666 broadcast . b-direct 16 . 4022371 + (100000 locatkm+mtultiple 16 . 402237 1 . 000000 b to adcasl+signal 16 . 080309 I . ( XI0 ( X ) 0 supim wF forecast 15 . 817275 1 . 000000 ( hda-tImsinessI5 . 817275 l . ( K'lO000 forecast + internal 15 . 402238 0 . 283029 transfea+infom'~15 . 232312 0 . 5119411
Iransfer + dala 14 . 817275 1 . 00 (11111 (1ligme+buslnessId . 594883 0 . 453631 transmit4 facsimile 14,402 2381 . 000000 exluip+satellite 14 . 2323 120,458 ( x66 signal+broadcast 13 . 70 179 70,441 993 signal+iv 13,7017 97I . IX ) O000 signal+television 13 . 594883 0 . 813987 news+business 13 . 495347 0 . 352 291 netwolk+satellite 13 . 154310 1 . 000000 develop+network 12 . 942806 0 . 409144 non+traditional 12 . 758382 1 . 000000 inform+business 12 . 729813 0 . 51 1940 apply + technology 12 . 471500 1 . ( X)O000 build+network I1 . 212413 1 . 000 C(Ofacsimile1 0 . 217362 1  . (~30~ . X ~ Ousage 9,902 391I . O00 ( X ) Onewer 9 . 306841 1 . 000000 elderly 8 . 202565 0 . 36 1246 feed 7 . 802325 1 . 000000 satellite7 . 567767 1 . 0, (30000 underly 7,370 1921 . 000000 transmit 7,299 606 1,000000 multiple 7 . 241736 1 . IkqO0()0 broadcast 7 . 019614 1 . ( X)O000 location 6 . 992316 1 . 000000 print 6,35170 91 . 000000 space 6,226 376 1 . 000000 transfer 6 . 15 54 97 1,000 000 collect 6 . 126113 1 . 000000 signal 6 . 080873 1  . (300000 phone 6,072 4410 . 6634 14tv 6 . 003761 1 . 000000
