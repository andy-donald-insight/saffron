Word Reordering and DP-based Search in Statis tical Machine 
Translation
Christoph Tillmann and Hermann Ney
Lehrstuhl fiir Informatik VI , Computer Science Department
RWTH Aachen-University of Technology
D-52056 Aachen , Germany
tillmann , ney@informatik . rwth-aachen , de

In this paper , we describe a search procedure for statistical machine translation  ( MT ) based on dynmnic programming ( DP )  . Starting from a DP-based solution to the traveling salesman problem  , we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm  . A search restriction especially useful fortile translation direction from German to English is presented  . The experimental tests are carried out on the Verbmobil task  ( Germm > English , 8000-word vocabulary ) , which is a limited-domain spoken-language task . 
1 Introduction
The goal of machine translation is tile translation of a text given in some source language into a tar-gel : language  . We are given a source string fJ = fl . . . fj . - . f . l of length J , wl fich is to be translated into a target string c \[= cl  . . . ei . . . el of length I . Among all possible target strings , we will choose the string with the highest probability : dI = argmax Pr  ( elff ) q--argmax Pr ( el )   . Pr ( fflel )    ( 1 ) The argmax operation denotes the search problem , i . e . the generation of the output sentence in the target language  . Pr ( c  ~ ) is the language model of tim target language , whereas Pr(fi'le*l ) is the translation model . Our approach uses word-to-word epen-dencies between source and target words  . The model is often further restricted so that each source word is assigned to exactly one target word  ( Brown et al , 1993; Ney et al ,  2000) . These alignment models are similar to the concept of hidden Markov models  ( HMM ) in speech recognition . The alignment mapping is j--+ i=aj from source position j to target position i = aj  . The use of this alignment model raises major problems if a source word has to be aligned to several target words  , e . g . when translating German compound nouns . As iuLple extension will be used to handle this problem  . 
In Section 2 , we briefly review our approach to statistical machine translation  . In Section 3 , we introduce our novel concept to word reordering and a DP-based search  , which is especially suitable for the translation direction fl ' om German to English  . 
This approach is compared to another reordering scheme presented in  ( Berger et al ,  1996) . In Section 4 , we present the t ) erformance measures used and give translation results on the Verb mobil task  . 
2 Basic Approach
In this section , we briefly review our translation approach . In Eq .  (1) , Pr(C ~ l ) is the language model , which is a trigrain language model in this case . For the translation model Pr(fille ) , we go on the as-sunlption that each source word is aligned to exactly one target word  . The alignment model uses two kinds of parameters : alignment probabilities p  ( a j laj_l , I , J ) , where the probability of alignment aj for position j de I  ) ends on tile previous alignment position aj-i ( Ney et al , 2000) and lexicon proba . -bilities p(\]~le~j ) . When aligning the words in parallel texts ( t br language pairs like Spanish-English , French-Englisll , Italian-German ,  . . . ) , we typically observe a strong localization effect  . In many cases , there is an even stronge restriction : over large portions of tile source string  , the alignment is monotone . 
2.1 Inverted Alignments
To explicitly handle the word reordering between words in source and target language  , we use the concept of the socalled inverted aligmnents as given in  ( Ney et al ,  2000) . An inverted alignment is defined as follows : inverted alignment : i -+ j = bi  . 
Target positions i are mapped to source positions bi  . 
What is important and is not expressed by the notation is the socalled coverage constraint : each source position j should be ' exactly once by the path of the inverted aligmnent b ~ = bL  . . . bi . . . bi . Using the inverted alignments in the maximum approximation  , / fli-Isn . v ( , Zl 5?ellki = l'?maxIIz, . 5 . v(f , , , le*)\]---hi i=1 = maxV(JII)-max
IiIel'hii = 1"p(bi\[bi-l , -\[ , '\]) ' P ( fbilCi)\] , where the two products over i have l ) een merged into ) i-1 a single product ( ) vet i . I ( cilei_~ ) is tim trigram language model probability . The inverted alignment probability p(bi\[bi-l , I ,   . 1) and the lexicon probability p(J ' ~ , ~led are obtained by relative fl'equency es-timal ; es fro sl the Viterbi alignment path after the final training iteration  . The details are given in ( Ochart (1Ney , 2000) . The sentence length probability p ( J\[1 ) is omitted without any loss in per-t brmance . For the inverted alignment probability p ( bi\[bi-~ , IJ ) , we drop the dependence on the target sentence length I  . 
2.2 Word Joining
The baseline alignment model does not pern fi that a source word is aligned to two or more target words  , e . g . % r the translation direction from German to \]? , nglish , the German ( : Oml ) ound IIOlStl'Zahnarztter-rain'causesira > blares  , because it must be translated by the two target words dcntist '  . sappoi'ntmcnt . We use a solution to this 1 ) roblenl similar to the one presented in ( ( ) ellel ; al . , 1999) , where target words are joined during training . The word joining is ( lot to on the basis of a likelihood criterion . An extended lexicon model is defined , and its likelihood is compared to a baseline lexicon model  , which takes only single-word ependencies into ae collnt  . E . g . when'Zahnarzt term in ' is aligned to dentist ' . s , the extended lexicon model might learn that ' Zahnarzttcrmin ' actually has to be aligned to both dentist's and appointment  . In the following , we assmne that this word joining has been carried out  . 
" IDP Algorithm for Statistical
Machine Translation in order to handle the necessary word reordering as & noptimization problem within our dynmnic programming approach  , we describe a solution to the traveling sales n m n problem  ( TSP ) which is based on dynamic programming ( Held , Karp ,  1962) . The traveling salesman problem is a noi ) timization problem which is defined as follows : given are a set of 
May of fourth the olly ouv is it not can colleague my case this 

O O O O O O O O O O ~_ . . . . O
O O O O O O O O/O ~ O O O
O O O O O O O O/O O O O
O O O O O O O I ? O O O O
O O O O O O O // O O O O O
O O O O O O // O O O O O O o o o o o o o O o O o OooOoOo Oooo??_  . . . o . . . . o . . . o . _ . . . o . . . . . ?
O O O O O/~O O O O O O
OOO9/7. O O O O O O O
O Of OO O O O O O O O O O O O O o O O o O O o O O
IIII 1 IIIIII 1I
Id FkrnK Sav Mnb . i aa eoimi ~ iee/ni/eei CssInn Irhueett Cmgehe I/an Figm'e  1: Reordering for the Gerlnan verb groul )  . 
cities S =  Sl , ---  , s , and t breach pair of cities si , s j the cost dij > 0 for traveling flom citys : to city . s j . We arc . ' looking for the shortest tour visiting all cities exactly once while starting and ending in citysl  . A straightforward way to find the shortest tour is by trying all possible permutations of then cities  . The resulting algorithm has a complexity of O ( n ! )  . I to we ver , dynamic progrmnming can be used to find tile shortest our in exponential time  , namely in O(n22'~) , using the algorithm by Ileld and Karp . The approach recursively evahlates a quantity Q(C , j ) , where C is the set ; of already visited cities and sj is the last visited city  . Subsets C of increasing cardinality care processed  . The algorithm works due to the fact that not all permutations of cities have to be considered explicitly  . For a given partial hypothesis ( C , j ) , the order in which the cities in ( 2 have beast visited cast be ignored ( except j )   , only the score for the best path reaching j has to be stored  . 
This algorithm can be applied to statistical machine translation  . Using the concept of inverted alignments , we explicitly take care of the coverage constraint by introducing a coverage set C of source sentence positions that have been already processed  . 
The advantage is that we can recombine search hypotheses by dynmnic programming  . The cities of the traveling salesman proble In correspond to source input : source string fl  . .-f j .   . . f . l initialization for each cardinality c = 1, 2, .  - ? , J do tb reach pair ( C , j ) , where jCC and ICl = c do tbreach tat'get word eEEmax  5  , et ! Q ~ , (e , C , j ) = p(fjle)p(jlj ' , J) . p(5) . pa(ele ' , e ") - O ~ , ,(e' , C\j , j ' ) jl EC\j words fj in the input string of length J  . For the final translation each source position is considered exactly once  . Subsets of partial hypotheses with coverage sets Cof increasing cardinality care processed  . For a trigrmn language model , the partial hyl ) otheses are of tile form ( c' , c , (2 , j ) , e ' , c are the last two target words , C is a coverage set fortile already covered source positions and j is the last position visited  . Each distance in the traveling salesman problem now corresponds to the negative logarithm of tile product of the translation  , alignment and language model probabilities . The following auxiliary quantity is defined : Qc  ~  ( (? , ~ C~j): . ~ . probability of tile best partial hypothesis ( c ~ , b ~) , where C = bt:\]k=1 ,  - -  . , i , bi = j , (2i~-CaIL dCi_1 ~ eI . 
The type of alignment we have considered so far requires the stone length tbr source and target sentence  , i . e . I = J . Evidently , this is an unrealistic assumption , therefore we extend the concept of inverted alignments as follows : Wtmn adding a new position to the coverage set C  , we might generate i-ther 5  =  0 or a = 1 new target words . For 5= 1 , a new target language word is generated using the trigram language model p  ( e\[e' , e ") . For 5= 0 , no new target word is generated , while an additional source sentence position is covered  . A modified language i node l probability pa(e\[c' , c ") is defined as follows : 1 . 0 if a = 0
Pa(ele"e ") = p(e\]e ', e ") if a = 1
We associate a distribution p ( 5 ) with the two cases 5=0 and 5=1 and set p ( 5 = 1 )  = 0 . 7 . 
The above auxiliary quantity satisfiestile following recursive DP equation : 
Qe , ( c,C,j ) = 4 . mein 5 . Kollege ~ ~, Q ~ V erb_ . ~Fin : l~--_JJ1 . In 7 . nicht 9 . Sie 2 . diesem 8 . besue hen10 . am3 . Fall 11 . vierten 6 . kann 12 . Mai 13 . .
Figure 2: Order in which source positions are visited tbr the example given in Fig  . 1 . 
P ( fJIe ) " maxP(JlJ' , '/) ' P (5) " ~ , cI ! i'e c\j ? pa(le ' , e ") - Q e , , c \  j , j ') . 
The DP equation is evaluated recursively for each hypothesis  ( e ' , e , C , j ) . TILe resulting algorithm is depicted in Table 1 . The complexity of the algorithm is O(E a?j 2 . 2  . 1)  , where E is the size of the target language vocabulary  . 
3 . 1 Word Re-Order ing w i th Verbgroup Rest r i c t ions : Quasi-monotone Search The above search space is still too large to allow the translation of ained ium length input sentence  . 
On the other hand , only very restricted reorderings are necessary , e . g . for the translation direction fi'om Predecessor e over a ~ e  , set \[ I Successor coverage set (1 ,  . . . , , , , , , , , l ') (1, . . .  , , , , ,0 ( \ ] , - -  .   ,   ,   , t\l , /1   , l ') -- (1 ,  ' ' '  , ' L  ~ , \/ l , /) \  , l ') (1 ,  . - - , , , , , \ , 0 ( I , .   .   . , , ,- J \ , l ') (1, -- . , , , ,  \  , m ) OerlnantoEnglish the monotonicity constraint is violated mainly with respect  ; to the German verb group . In German , the verb groui ) usually consists of a left and a right verbal brace  . , whereas in English the words of the verbgroul ) usually tbrma sequence of consecutive words . Our new al ) t ) roach , which is (' all e . dquasi-monotone search , proce . sses the source sentence monotonically , while explicitly taking into account the positions of the  ( -lel'l nanver b group . 
A typical situation is shown in Figure \] . When translating the sentence monotonically fl'om left to right  , the translation of the German finite verb'kmm ' , which is the left verbal brace in this case , is postponed mt til the German noun phrase'me in t  ( ollege ' is translated , which is the subject of the sentence . The . n , the . German infinitive ' be sucl mn ' and the negation particle'nicht  ; ' are translated . The trails \] at \ oil oferie position in the source sentence n my be postponed ti  ) rup to L = 3 source positions , and the translation of uI ) to two source positions link be anticittated for at most  1~  =  l0 sourcel ) osi-tions . To formalize the att l ) roach , we introduce four verb group stat ; es S : ? hfitial(Z ) : A contiguous , initial block <) fs < mr cel ) ositions is covered . 
? Skitlped(K ; ): The translation of up to one word may be l ) OStl ) oned . 
? Verl >( V ): The translation of Ul > ( ; otwo words may be ant Ml ) ated . 
, Final ( Y : ) : The rest of the sentence is processed monotonically taking accoull to ft it  (  ; al : ready covered positions . 
\ V hile processing the source sentence monotonically  , the i ifitial state Z is enter e . d whenever there are nommovered positions to the left of the rightmost covered position  . The sequence of states needed to carry out the . word reordering example in Fig . 1 is given in Fig .  2 . The 13 positions of the source sentence are processed in the order shown  . A position is presented by the word at that position  . Using these states , we define partial hypothesis extensions , which are of the following type : ( S' , C\j , j ') --9( S , C , j ) , Not only the cove . rage set C and the posit \ oil Sj , j ' , but also the verb group states S , S ' are taken into account . ~1~) be short , we omit the target words c , e ' in the t brinulation of the search hypotheses . There are 13 types of extensions needed to describe the verb group reordering  . The details are given in ( Tillmann , 2000) . For each extension a new position is added to the coverage set  . Covering the first lul-covered position in the source sentence  , we use the language model probat fility p(e\[$ ,  $) . IIer e , $ is the sentence boundary symbol , which is though to beat ; position 0 in the target sentence . Tile search starts in the hyl ) othesis ( Z , ~, 0) . ~ denotes the empty set , where , no source sentence t ) osition is covered . 
The following recursive quation is evaluated := ( 2 ) gj\[j ' ,  3) . p(5) . ( ld , e ") . p(fjlc)?ntax ~ , cII ? maxOc , ( c' , S ' , C\j , j ') ? ? . ( st , /)) ( St , C\tj , ff ) ~(? ,   , C , j ) j'cc\u The search ends in the hypotheses ( Z ,  1 ,   .  -  . , d , j) . 
1,  .   .   . , d de . notes a coverages e . t including all positions from the starting 1 ) osition I to position J and jCd-L ,  -  .  - ,  . \] . The final score is obtaiiled from : , naxP ($ l " , c') . G ' ( c , Z , 1, .   . -, d , . it , c , cIjca : . , . .  .   , a where p($lc , c /) denotes the trigram language model , which predicts the sentence boundary $ attimend of the target sentence  . The complexity of the quasi-monotone search is O ( \]' Ja- , l-(\[~2-t-L-1~)) . The proof is given ill ( Tilhnann , 2000) . 
3.2 Reordering with IBM Style
Restrictions
We compare our new api ) roach with timword reordering used in the IBM translation approach  ( Berger et al ,  1996) . A detailed descrit ) tion of tile search procedure used is given in this patent  . Source sentence words are aligned with hypothesized target sentence words  , where the choice of a new source word , which has not been aligned with a target word yet  , is restricted I . A procedural definitioll to restrict l In the approach described in  ( Berger et al ,  1996) , a morphological analysis is carried out and word morphenles rather thin  , fullform words are used during the search , ltere , we process only flfll-for in words within the trmmlation proce  . durc . 
8 53 the number of pernmtations carried out for the word reordering is given  . During the search process , a partial hyt ) othesis i extended by choosing a source sentence position  , which has not been aligned with a target sentence t  ) osition yet . Only one of the first n positions which are not already aligned in a partial hyt  ) othesis may be chosen , where n is set to 4 . Tile restriction can be expressed in terms of the nmn-ber of uncovered source sentence positions to the left of the rightmost position m in the coverage set  . 
This munber must be less than or equal to n-1.
Otherwise for the predecessor search hyt ) othesis , we wonld have chosen a position that would not have been among the first nuncovered t  ) ositions . 
Ignoring the identity of the target language words e and c'  , the possible partial hypothesis extensions due to the IBM restrictions are shown in Table  2  . 
In general , m , l , l'~k/1 , 12 , /3 and inline umber 3 and 4 , l'must be chosen not to violate the above reordering restriction  . Note that in line 4 the last ; visited position fortile successor hypothesis must be m  . Otherwise , there will be four uncovered positions t br the t ) redecessor hypothesis violating the restriction . A dynamic programming recursions in > ilar to the one in Eq  . 2 is evaluated . In this case , we have no finite-state restrictions for the search space  . 
Tile search stm'ts in hyi ) othesis (0 , 0) and ends in the hyt ) otheses (1 ,   .   .   . , J,j ), with jC1, .   . -, d . 
This approach leads to a search procedure with complexity O  ( E a . j4) . The proof is given in ( Tilhnann , 2000) . 
4 Experimental Results 4 . 1 The Task and the Corpus We have tested tim translation system Oil the Verb mobil task  ( Wahlster 1993 )  . The Verb mobil task is an appointment scheduling task  . Two subjects are each given a calendar and they are asked to schedule a meeting  . The translation direction is from German to English  . A summary of the corpus used in the experiments i given in Table  3  . The perplexity for the trigrmn language model used is  26  . 5 . Although the ultimate goal of tile Verb mobil project is the translation of spoken language  , the input used for the translation experinmnts reported on in this paper is the  ( more or less ) correct orthographic transcription of the spoken sentences  . Thus , the effects of spontaneous speech are t ) resent in the corpus , e . g . 
the syntactic structure of tile sentence is rather less restricted  , however the effect of sl ) eech recognition errors is not covered . 
For the experiments , we use a simt ) lepret ) rocessing step . German city names are replaced by category markers  . The translation search is carried out with tlm category markers and tlm city names are resub -stituted into the target sentence as a postt  ) rocessing step . 
Table 3: Training and test ; conditions for the Verb mobil task ( * number of words without punctuation marks )  . 
\[German English
Training : Sell tences


Vocabulary Size

Test-147: Sentences

Perplexity 4189 7945 363279 394648 3454 1699-26 . 5 Table 4: Multi-reference word error rate ( roWER ) and subjective sentence rror rate ( SSER ) for three different search t ) rocedures . 
Search CPU time
Method\[sec\]
MonS 0.9
QmS 10.6
IbnlS 28 . 6 roWERSSER\[yo\]\[y0\] 42 . 0 30 . 5 34 . 4 23 . 8 38 . 2 26 . 2 4 . 2 Per formance Measures The following two error criteria are used illour ex-t  ) erinmnts : ? roWER : multi-reference WER : We use the Levenshtein distance between tile automatic translation and several reference translations as a measure of tile translation errors  . On average ,   6 reference translations per automatic translation are availal  ) le . Tile Levenshtein distance between the automatic translation and each of tile reference translations is comt  ) uted , and the minimum Levenshtein distance is taken . This measure has the advantage of being completely automatic  . 
? SSER : subjective sentence rror rate :
For a more detailed analysis , tile translations are judged i ) yatminantest 1 ) erson . For the er--ror counts , a range from 0 . 0 to 1 . 0 is used . An error count of 0 . 0 is assigned to a perfect rans-lation , and an error count of 1 . 0 is assigned to a semantically and syntactically wrong transb > tion  . 
4.3 Translation Experiments
For tile translation experiments , Eq . 2 is recursively evahlated . We apply a beam search concet ) tasinst ) eech recognition . However there is no global pruning . Search hypotheses are i ) rocessed separately according to their coverage set d  . The best scored
Om , , , , , ,( c ) = c,c ', 6", j
The hyl ) othesis ( d , e ,  $ , C , j ) ist ) 1'1151(;(lif:
Q~,(e,S,C,j ) < to . O , ~ cam(C ) , where to is a threshold to control them mlber of surviving hypotheses  . Additionally , for a given coverage set , at most 250 different hypotheses are kept during the search process  , and the number of difl'erent words to ) ehyl ) othesized by a source word is limited . For each source word f , the list of its possible translations c is sort e ( 1 according top (  . f l c ) ? p . ,, . , , i(c ) , where Puui ( e ) is the unigrmn probability of the English word c . It is sufficient o consi ( ter only the best 50 words . 
We show translation results for three at ) l ) roaches : tile monotone search ( Mon S ) : where no word reordering is allowed ( Tillmann ,  1997) , the quasi-monotone search ( QmS ) as 1 ) resented in this palser amt the IBM style ( IbmS ) search as described in
Section 3.2.
TMsle 4: shows translation results t br the three ap-I ) roaches . The eomls uting time is given in terms of CPU time per sentence  ( on a 450-MIlzl?entimn-III-PC )  . Itere , the printing threshold to = 10 . 0 is used . 
q _5:anslation errors are reported in terms of multi-reference word error rate  ( roWER ) and subjectives ( mtene error rate ( SSER )  . The monotone search tserforms worst in terms of bothel Trorrates  5IsWI~  ; I~ . 
midSSEIL The (; OSlll ) lstislg time is low , sitlce 51 o5e-ordering is (: arriedo551 ,  . '\]' he quasi-in onotone sarchi ) e1foI'551st ) est , inter 551s of l ) other rorrates roWER and SSh ; R . Additionally , it ; works about 3 times as fast as the II3M style sem:e h . For our demonstration system , we typically use the pruning threshold to = 5 . 0 to speed Ul ) the search by a factor 5 while allowing for a sm?fll degradation i translation accuracy  . 
The effect of the pruning threshold to is shown in Table  5  . The coml ) uting time , the number of search errors , and the mull ; i-reference WEll , ( roWER ) are shown as a flmction of to . The negative logarithm of to is reporte(t . The translation scores for the hy-i ) otheses generated with different threshohl values to are compared to the translation scores obtained with a conservatively large threshold to  =   10  . 0 . For each test series , we count tile mlml ) er of sentences whose score is worse than the corresponding score of the tent  ; series with the conserw ~ tively large threshold to  =   10  . 0 , and this mm:ber is reported as the number of search errors  , l ) epending on the threshold to , the search algorithm may miss the globally of ) timal path which typically results in additional translation errors  . Decreasing the threshold results in higher mWEll due to additional search errors  . 
Table 5: Effect of sere'e\errors (147 sentences ) . 
Search to ICP U time  #search
Method\[\[sec\]error
QmS0 . 0 0 . 07 108 1 . 0 0 . 13 85 2 . 5 0 . 35 44 5 . 0 1 . 92 4 10 . 0 10 . 60 lbmS 0 . 0 0 . 14 108 1 . 0 0 . 3 84 2 . 5 0 . 8 45 5 . 0 4 . 99 7 10 . 0 28 . 5 2   0 of the beam threshold on then mn berroWER \[%1   42  . 6 37 . 8 36 . 6 34 . 6 34 . 5 43 . 4 39 . 5 39 . 1 38 . 3 38 . 2 Table 6 shows example translations obtained by the three , difli ; rent appro ~ mhes . Again , the monotone search performs worst . In the second and third translation examples , the 1bins word reordering performs worse than the QmS word reordering  , since it ; cannot takel ) roperly into at : coun the word reordering ( 115 (  ; to the , German verb groul ) . Tile German finite verbs ' l ) in ' ( second exmnple ) and ' kSnnten ' ( third exmnt ) le ) are too far away from the t ) ersonal pronouns ' ich ' and ' Sic ' ( 6 respectively 5 source sentence positions )  . In the last example , the less restrictive IbmS word reordering leads to a better translation  , although the QmS translation is still a ceep tabh ' . 
5 Conclusion in this pal)er , we have presented a new , efficient DP-based search procedure for statistical machine translation  . The approach assumes that , the word reordering is restricted to a few positions in the source sentence  . The approach as been success fiflly tested on the 8000-word Verbmobil task . l'hture extensions of the system might include : 1  ) An e?tended translation model , where we use . more context opre-(lict a source word . 2) Antrot ) roved language model , which takes into at : count syntactic structure , e . g . to ensure that al ) roper English verb grout ) in generated . 
3 ) A tight coupling with the speech recognizer out -lint  . 

This work has been supported as part of tile Verbmobil project  ( contract number 01 IV 60 1A ) by the Certain 5 Federal Ministry of Education , Science , Research and Technology and as part of the Eutrans project  ( ESPRIT project number 302 68 ) by the Eu-rot ) can Comimmity . 

Table 6: Example Translations for the Verb mobil task . 
Input : Ja , wunder bar . K Snnenwirma cllen.
MonS : Yes , wonderflfl . Can we do.
QmS : Yes , wonderflfl . We can do that.
IbInS : Yes , wonderflfl . We can do that.
Input : Dasistzuknapt ) , we ilichab demdritten in Kaisers lauter nb in . Genauge nommenim ratn dritten . 
Wiew Srees dennmngh ln Samstag , demze hnten Februar ? MonS : That is too tight , becmlse If roln the third in Kaisers lauter n . hi fact only on the third . 
How about 5hm Saturday , the tenth of February " ? QmS : That is toot ight  , because Imn frolntim third in Kaisers lauter n . In fact only on the third . 
Ahmhow about Saturday , February the tenth ? IbmS : That is too tight , froln the third because I will be in Kaisers lauter n  . In fact only on the third . 
Atllnhow about Saturday , February the tenth ? Input : Wenn Siedann noch densiel  ) zehntenkSnnten , wSred as toll , ja . 
MonS : If you then also the seventeenth could , would be the great , yes . 
QmS : If you could then also the seventeenth , tlm t would be great , yes . 
1binS : Then if you could even takes eventeenth , that would be great , yes . 
Illtmt : . Ja , daskommt mirse hr gelegen . Machenwires dannambestenso . 
MonS : Yes , that suits me perfectly . Do we should best like that . 
QmS : Yes , that suits mefine . We do it like that the nbest ; . 
IbmS : Yes , that suits mefine . We should best do it like tlmt . 

A . L . Berger , P . F . Brown , S . A . Della Pietra , V . J . Della Pietra , J . R . Gillett , A . S . Kehler , R . L . Mercer .  1996 . Language Translation apparatus and method of using context-based translation models  . United States Patent , Patent Number 5510 981 , April . 
P . F . Brown , V . J . Della Pietra , S . A . Della Pietra , and R . L . Mercer .  1993 . The Mathematics of Statistical Machine Translation : Parameter Estimation  . Computational Linguistics , vol . 19, no . 2, pp .  263-311 . 
M . Held , R . M . Karp .  1962 . A Dynmnic Progrmn-ruing Approach to Sequencing Problems  . & SIAM , vol . 10, no . 1, pp .  196-210 . 
H . Ney , S . Niessen , F . J . Och , H . Sawaf , C . Tilhnmm , S . Vogel .  2000 . Algorittuns for Statistical %' ansla-tion of Spoken Language  . IEEE Transactions on Speech and Audio Processing , vol . 8, no . 1, pp .  24-36 . 
F . J . Och , C . Tilhnann , H . Ney .  1999 . hn prov cd Alignment Models for Statistical Machine ~I Yans-lation  . In Proc . of the , loint SIGDAT Conference on Empirical Methods in Natural Language Pro-ccssing and Very Large Corpora  ( EMNLP99 )  , pp . 
2028, University of Maryland , College Park , MD,
USA , June.
F . J . Och and Ney , H .  2000 . A comparison of alignment models for statistical machine translation  , hi Proceedings of COLING 2000: The 18th International Conference on Computational Linguistics  , 
Saarbr/ieken , Germany , July-August.
C . Tilltnann .  2000 . Complexity of the Different Word Reordering Approaches  . The document can be found under the URL http:// www-i6  . Informatik . RWTg-Aachen . de/Colleagues / tilli / . Aachen University of ' Technology , Aachen , Germany , June . 
C . Tilhnann , S . Vogel , H . Ney and A . Zubiaga .  1997 . 
ADP based Search Using Monotone Alignments in Statistical Translation  . In Proc . of the 35th Annual Conf . of the Association for " Computational Linguistics  , pp . 289296, Madrid , Spain , July . 
W . Wahlster .  1993 . Verbmol ) ih Translation of Face-to-Face Dialogs . MT Summit IV , pp .  127-135,
Kobe , Japan.

