and satisfactory definition exists , and some linguists
deny any validity of the word , relegating it to folk

Following Greenberg we take words as being composed of morphemes 
so that a word may be identified with a sequence of morphemes and no morpheme overlaps two words  . From the distribution of the morphemes of a corpus we find clusters which approximate the words of the corpus  . 
The approximating units are determined relative to the corpus from which the distribution is defined  . The corpus may be either considered as a closed sublanguage in itself or as a sample from some larger corpus  . 
We study the behavior of approximate units relative to longer and longer portions of the corpus  , and also relative to the corpus considered as a statistical sample  . 
Assuming that a word may be r~presented as a sequence of morphemes  , how should this sequence be distinguished ? In the wellknown paper of Togeby  ,   ( 19&9 ) there is a convenient summry of structural views of the word  . In his discussion , the word is set for thas a morpheme sequence possessing properties classified under the headings of  1 ? Formelibrej . i30 Permutabilite ~ . In considering how a ~ , 2 ? Seoarabllite , and morpheme sequence should be distinguished as a word we will begin by examining Toge by fs classifications  . 
In Togeby , under the discussion of a word as a formelibre minimum  , reference is made to Bloomfield's ( 1933 ) statement about the word as a minimum freeform and the ~ mallest items which are snoken by themselves  , in isolation . 
The idea of minimum freeform is actually found somewhat earlier in Bloomfield's  ( 1926 ) Postulates . 
1 differ and not we find
A minimum free form is a word . A word is thtm ' a " form which may be uttered alone  ( with . meaning ) but cannot be analyzed into parts that may ( all of them ) be uttered alone ( with meaning )  . 
Thus the ~ word ~ can be analyzed into ~_~ and z ~ but the latter part cannot be uttered alone  ; the word ~ can be analyzed into wr_wr_it_~and- er  , but the latter cannot be uttered alone ( the word err he'by virtue of different meaning a different form  )   . . . 
Similar views are found in the older " universal grammars  . " They principally in taking the Aristotelian position that the word some smaller unit has meaning  . For example , in Harris (1771) a concern with min , tmum units of meaning . 
But what shall we say ? Hav @ these parts ( of a Qu@ntity of sound ) again other parts , Which ~ are in like manner significant and may be pursued to Infinite ?  9an we suppose that a liMea ~ ing ~ iike . Body , to be divisible ; and to include within itself other Meanings without end ? If this beab surd  , "' then mhstw@~ec~ssarliy ! ~ admit , that there is ~ such a thing as a Sound significant  , of which no part is of itself significant . 
And thiS : ~ is ~ at we oall ' . t . he proper : ~ haracte ~ of a Wo ~ For thus though the Words  ( Suu ) and ( shineth ! have each a Meaning , yet ie there ce ~ ainly no-Mem ~ inginian T ~ f their Paths  , neither in the syllables of one , nor the ~ etters of the other . 
James Harris refers to Priscian's definition in which the word is defined as a minimum meaningful utterance in connected speech  . 
'" Dictio@S~part time or at lonis construct a e  , idest , in ordine compositae . Parsautem , quantumad't btU~inteiiigendum , ~ id'est , a  ~ . ~otius ~ ensus "- intellectum . Hocaute mideo dictumes t , nequisconeturix ~ induaspartes dividere , hocest , iU , ~- z . 
Xietr_~ ; nonenimad to tumintelligen dum haecfit Fb ~ purpo~e~6fconstruc~ng our model we ~ eHail ~ interpret . : minimuTM freeform as follows : ? A word'S'i Sa sequence of mubword units  . If this sequence may be uttered alone , then it is to be expected that the sequence cooccurs freely with other sequences  . 
Under the classification of separabilite , Togeby places the requirement of Jakobs on ( 1938 ) that words are these parable components of phrases :  m4nlmal actually separable comuonants of the phrase . 
Conversely , the constituents of a word should not be separable  . 
The general requirement of separablllte seems to be that a word is a morpheme sequence which may cooccur with other morpheme sequences to give granmmtical utterances  . If the sequence is a distinct word , then its morphemes must be contiguous , and the morphemes of a noncontiguous gra , ~natical sequence cannot be identified with the same word  . 
Under permutabilite I , Togeby quotes H Jelmelev ( 19%3 ) '_' les mots pour ront touts !- ~ lement ~ tred ~finisc ~ lessignes minimad ontl'?soression  , 
J .
et dem ~ emel contenu , sont recluro auement Dermutables " According to Togeby  , HJelms lev means that " unchangement del ' or dre desroots  p0~rra entrainer unchangement desens . t and is qu ' unchan~ement del ' or dredes ~ rties duroots n ' enserap as capable  . " The requirement here is that if a sequence of morphemes is identified with a word  , then the order of the sequence must be invariant . 
In Greenberg (1957) , the proposed definition of the word based on substitution and the recognition of grau ~ atical sequences  , we interpret as follows : Let She a sequence of linguistic units and G the class of graummtical sequences  , in Greenberg's words the class of sequences which " exist as expressions in the language  . " Suppose that S~XABCDE~G is a morpheme sequence  . We want to decide whether or not the boundary between B and C is a word boundary  . 

To each morpheme of S there corresponds a " nucleus  . " For the nucleus of B to be a word terminal it is necessary that " in finite insertion " of nuclei $ possible between B and C  , otherwise if there " is a maximum to the number of n ~ e i that can be inserted  , " the boundary is " intra word boundary . " Nuclei are classes of morpheme sequences having strongly equivalent substitution proper ties  . Some of the conditions for class membership are so strict that we would expect the def ined classes to be empty for the language tak ~ en as a whole  . Perhaps as Chomsky conjectures in a review of Greenberg's essay : " It might be that the not ion of word may beds fined r ~ lativ ~ to a par ticularly simple set of sentences  . (1958) In practice , Greenberg's conditions might be interpreted as follows : S = XABCDE occurs in the language  . The subsequence BC may belong to a single word if it is replaceable by a single morpheme and gram ~aticality is preserved  . If for a small number of morpheme sequences Si , the sequer ~ es XAB SiCDE are grammatical , then the subsequence BC belongs to the same word . If the sequences XABS iCDE are granm~tical for a large number of Si  , then the subsequence BC probably does not belong to the same word  . 
In an unpublished ~ , Juill and develops a constructive definition of the word which requires the recognition of gra ~naticality  . If S = XABCDE ~ G is a morpheme sequence , the boundary between B and C is classified according to the potential sentence occurrences of B and B  . 
Boundaries are classified as " conJunctive % r " disjunctive  . " Disjunctive boundaries isolate potential words called " functional units  . " Conjunctive boundaries occur potentially within words but must be tested by an " ~ nsertion criterion  . " Thus if BC spans a conjunctive boundary , then B is a word boundary if there exists a morpheme sequence Si such that XAB SiCDE g G  . 
The Use of Numerical Linguistic Data
Our object now is to define a quantitative procedure for approximating words  . Th ~ procedure attempts to meet the various requirements summarized  21 the last section . Since our interest is in distributional methods , we do not want the procedure to include an independent test for gra ~ maticality  . 
The requirements that we attempt to fulfill are summarized by Julli and as d ~ and ~ eoarabilit ~  . These are realized as a con~noncharacteristic in the procedures of Greenberg and Juill and : A potential word is isolated as a sequence of morphemes which are associated in some special way  , then the potential word is tested for its function as a word  , according to some test of insertion . 
Let us imagine a linguist confronted by the following data  . 
Frequency refers to text frequency . Let XABCDE be a sequence of morphemes to be segmented  , Consider the boundary between B and C . Is this boundary a word boundary ? Assume first that B occurs only with A  , E , C and G , as indicated in Casei . 
Molpheme Pair Frequency Mcrpheme Pair Frequency
AB4 BC'3
EB '6 B ~7
Casei
With no further information , we might observe that B occurs more frequently with A than with C  , and segment as ABCD . Under this condition the requirement of adhesion may be met  , but a simple consideration of frequencies is not sufficient to meet the requirement of separability  . This is illustrated by the hypothetical set of data of 
Case 2.
Morpheme Pair Frequency

EBi
GBi
HBi
IBi
J Bi
KBi
Morpheme Pair Frequency
BC3 ~ F7
Case 2
In this case the frequency of AB also exceeds the frequency of BC  , but the segmentation ABCD would not agree with linguistic intuition at all  . In Case 2 , B has much greater freedom of combination on the left than on the right  , and to satisfy the condition of separability , at least approximately , we would segment as ABCD ? In formalizing these intuitions  , we refer to the procedure of Harris ( 1955 ) for grouping phonemes into morphs . Harr is assumes that an utterance U may be represented as a sequence of phonemes a Ia  2   . . . an . 
Let R ( al ) be the number of different phonemes which may follow the phone mea I in the total language  . Similarly , let R(al , a2 ) be the number L ( an ) be the number of different phonemes which may precede an  , L ( an_1 an ) the number which may precede an1 an , and so on . Then the sequence SR = R ( al ) R ( ala2 ) R ( ala2 a3 )   . . o R(al a 2 . . . an ) describes the freedom of cooccurrence on the right at each phoneme of 
U , and the sequence
SL = L(a Ia2o . .an ) L(a 2 . . . an ) . . . L ( an ) describes th ~ freedom of cooccurrence on the left at each phoneme of U  . 
Harris observes that morpheme boundaries tend to occur at positions in U where t ~ corresponding values of R and L are large or attain their relative maxima  . Thus if R(aI . . . ak ) is a relative maximum in the sequence SR , the nak is a morpheme terminal . Likewise ak is a morpheme terminal if R(aI . . . ak ) exceeds a value comparable to the total number of different phonemes in the language  . Under similar conditions for L(aj . . . an ), aj is a morpheme initial . 
Applied to sequences of morphemes with uncontrolled diversity  , Harris's procedure becomes particularly unwieldy . We suggest that we might achieve the same results as Harris by using fixed-length subsequences rather than some higher-level syntactic unit  . Thus for some fixed k , the cooccurrence measures Rk(al . . . ak)Rk(a2 . ? . ak+l ) . . . Rk(an_k+l . . . an ) might yield the same segments as th ~ sequence
R(al ) R(ala2) . . . R(aI . . . an ) ?
A Segmentation Procedure
The placing of segment boundaries at positions of maximum freedom of combination realizes separability  , but the requirement that a word should be a morpheme sequence showing strong internal association is accounted for only in a negative way--we do not place boundaries at positions of low freedom of combination  . We propose another procedure for grouping morphemes by combining both left and right freedom of cooccurrence  . As a result we derive a scale of degrees of distributional separation  . 
In Harris's procedure there is sufficient information to form a ranking of boundaries  . If al . . . an is the sequence to be segmented then we place a boundary between ak and ~ ak +  1 if one or more of the following conditions is met . 
1. R(alo .. ak ) is a relative maximum in SR.
2. L(ak+l . . . an ) is a relative maximum in SL.
3 . Ror L are large in comparison with the number of different phonemes  . 
If any two of these conditions are satisfied , we have stronger distributional evidence for segmentation than in the case of just one alone  . Likewise , if all three conditions are fulfilled , then ~ we wo ' ~ ld expect that a k would be a morpheme terminal more often than if just two of the conditions are fulfilled  . We shall adopt a similar line of reasoning to segmentations based on the distributions of fixed -length sequences  . 

For convenience we introduce some notation . Let AB ) CD indicate a right hand boundary after B , following from the distribution of B , and AB ( CD indicate a lefthand boundary before C , following from the distribution of C . 
In a " first-order segmentation " ~ f the sequence XABCDE ~ we will use only the distributional properties of single morphemes  . Thus , in our hypothetical Case 2 , we refer only to the distributional properties of B  . 
Morpheme Pair Frequency

EB1
GB 1
HB1
IB 1
JB 1
KB 1
Morpheme Pair Frequency
BC3
BF 7
In this case the text frequencies indicate that B has much greater freedom of combination on the left than on the right ? Given no further information  , we segment as A(BCD . We formalize this decision in the following " Cutting Rule  . "
If R(B ) ~ L(B ) cut as XAB ) COE.
If R(B~L(B ) cut as XA(BCDE.
If R(B ) = L(B ) cut either as XAB ), CDE or as

Let us insert right-or lefthand boundaries at C by use of the cutting rule  , as we did with B . The strangest evidence for segmentation ( separability ) is in the case where R ( C ) >L ( C )  , so that we place a lefthand boundary before C ; and at the same time R(B ) > L(B ) , so that we place a right hand boundary after B . The result is indicated as AB ) ( CD . The weakest evidence for segmentation ( adhesion ) is where R ( B ) ~L ( B )  , and ~ the same time R(C ) > L(B ) . The result is indicated as A(BC)D . 
There are nine possible combinations according to the distributional properties of B and C  . These are shown in Figure 1 , which we refer to as a " Segmentation Rule . " The number of slashes--the " degree " of the boundary -- indicates the relative evidence for segmentation  . 
~ R~B)-L(B):,0=0<0
R(c)-L(C ) > 0 - - - - 0 < 0
BIIoBIIIoBIIIIC
BICBIIc BIIIC
BIcBIIc
Figure 1. Segmentation Rule
The first sample which we will consider for purposes of illustration is from the primer Ted and SaSAIy  . This text contains 121 different printers ' words in all . As in other deliberately morphemically closed lO texts  , Zipf's law doesne ~ operates o we have a large variety of contextual combinations with many repetitions  . The sample consists of the first & , 670 morphemes and forms the main narrative . We obtain the segments : come // Boots//said // Ted // // come and // ride / / // come and // ride / // in / // my wagon////jump/in///Boots//said // Ted////ride /// in///my//wagon // Boots // ~ jump /inland // ride ~ I ~ ~ herell well goll saidl/Ted The foregoing segmentation is first order in that inference is made using only the distribution properties of single morphemes  . The procedure may be extended to consider n -tuples of units for " nth order " rules  . 
However rules using extended context have two difficulties  . One is the simple difficulty of finding enough context in a short text  . A second , more interesting restriction is that certain boundaries may not follow each other  , depending on the order of the segmentation . For example , two zero-degree boundaries may not follow each other under a rule of any order  . 
The simple type counts , as measures of freedom of cooccurrence may be replaced by other more general measures  , for example the entropy E of the type-frequency distribution  . See , for example , Khinchin (1957) . 

Entropy has the desirable property that it may be used to estimate the average number of morphemes that may cooccur with a given unit  . For example , if the unit U has entropy ~ ( U ) of successors 3 then the ' r diversity " ll of successors is 2 E'U' . (~ The entropy would be the same if all the 2 E ( U ) successors were equally likely . 
Evaluation Procedures
Applied to real data , the constructive procedures of Greenberg and Juill and are developed with the aid of many illustrative examples  , but are still programmatic end have not been applied to large linguistic samples  . Likewise , Harr is gives the morphemic segmentation of many sentences but does not give a numerical evaluation of his results for a large text  . -In evaluating our approximation procedures , we will be concerned with degrees of adequacy . The results presented so far suggest that there is a strong correspondence between the degree of a segment boundary and the corresponding syntactic boundary  . It appears that segment boundaries of zero end first degrees correspond to intra word boundaries  , second-degree segment boundaries to word boundaries  , and third-end fourth-degree boundaries to phrase and sentence boundaries  . 
To determine the correspc~enee , we give a more precise formulation . 
In the morpheme sequence XABCDE let BI and CI be the lowest level constituents containing B and C respectively  . It may happen that BI = B and CI = C . If BI and CI belong to the same printers ' word , then the ~ ntactic boundary between B and C is a moroheme boundary  . If BI and CI do not belong to the same printers ' word  , then the syntactic boundary between B and C is labeled according to the highest syntactic level of 
BICI . or boundary , since ungent lemanly is a printers ' word . However in the ~ L~g_~g ~ , where B = ~ and C ~_ ~ , B1=the ~ of England and C1='s . Consequently we take the boundary between ~ and ' s as a phrase boundary  . ' In the two word sequences , ~ heman and he went , the spaces mark word and phrase boundaries respectively  . 
Between any two morphemes we have 20 possible combinations of syntactic and segment boundaries  . The correspondence my bee~mluated by the ~ statistic  , or derived statistics such as the contingency coefficient C-~//~?~?See  , for axmmple , Kendall (1952) . 

Some Distributional Groupings
We examine the correspondence between syntactic and segment boundaries using several samples of morphemic data  . 
In mmny cases a ~ ero-degree pair occurs in a manner which is only barely statistically significant  . Let us compare . 
look Sally
R/L~3/1~39/33
Sign(RL)-+ and come and
R/L 19/32 21/19
Sign(RL)-+
For the sequence lo0 kSall ~ , the differences ( RL ) appear to be statistically significant , but in _ q g ~ , we may wonder whether the slight positive value of R  ( and ) -L ( and ) is due to sampling variations . 
lua statistical version of our procedure , we test the hypothesis that R ( and ) ~ L ( and ) . Since there is no exact sampling theory for this test  , we construct an approximate test . The A6~6 morpheme text is divided into approximately equal blocks  , and RLce ~ puted for each block separately . The values of RL my be viewed as independent samples  , provided the individual block size is large enough  . We infer from the signs of RL in each block that R  ( come ) <L ( come )  . But we my not infer that R ( and ) L ( and ) , since the positive difference occurs in only one trial in five  . On the other hand , for the pair look ~ , R ( look ) < L ( look ) and R ( Sally ) >L ( Sally ) in all five blocks . 
Considering the ~6~6 morpheme text as a statistical sample , the inferred zero-degree segments are said , look Ted , l~kSally , and run Ted . If they occurred , run Sally , look Ted . say Ted and say would also have zero degree , while come run and comelo__~would be of second degree  . 
The next sample is from a lower school r~ader . The corpus is the first 21OO morphemes from a simplified version of_RobinsQn Crusoe  . 
Even though this text is simplified , it is fairly representative of ordinary language and the frequency distribution follows Zipf's law  . 
The words are morphemically simple , but many morphemes occur only once . 
Eor the first sentence , the morphemic representation and the groupings relative to samples of the first  300  ,  600 ,   . . . , 2100 morphemes follow . 
The ship being fited out I goed on board the onest of 
September 1659.
The shlp being fitted outlwent on board thefirstofSpetamberl659 The ship being fitted out I went on board the first of  Septemberl659 The ship being fitted out I went on board the first of  Septemberl659 The ship belng fitted out I went on board the first of  Septemberl659 ? ? ? The ship being fitted out I went on board the first of  Septemberl659 As soon as the sample reaches 12OO morphemes , the segmentation becomes stable . In this first sentence ing fltted and Qf September  1659 remain unsegmented since fit , September , and 16 ~ occur only once each e ~ , and first are coextensive with printers ' words . On board shows strong association and is operationally a word  . The morpheme the shows strong disassociation in the context the //// f~st  , but neutral association in the context the//shio . 
Several high-frequency morphemes tend to occur early in the text so that we have fairly extensive distributional information for the first sentence  , but less information for morphemes occurring later in the text  . 
In this sample there are 124 different morphemes . Of these 215 occur only once and 82 only twice , so we have little information for segmentation . 
On the other hand , the high-frequency morphemes the , ship , be , in ~ , out ,   . . . all occur in the first sentence . A consequence is the poor performance of the procedure when applied to more than the first two sentences  . See table A final example is Quine's Word and Ob . iect . We show the segmentation of this sentence relative to a sample of  900 morphemes . Even though the words tend to be polymorphic , the morphemic diversity is smaller than that found for the first  900 morphemes of Kobinson Crusoe . The values are & . O and 5 . 1, respectively . It follows that morphemic combination in WQ ~ and  0b~ect is more restrained and the occurrence of longer words does not imply more freedom of morphemic combination  . 
The segmentation follows.
For // the/case/of////sent / / ences / /// generally / / // however // or // // even // the/ case/of//eternal//sent / / ences / /// generally surely // // / there // is /// of  111/ how Ifar III in II direct IIII quotation H/my III deviate / // from // the // diroot  . 
The morpheme groupings are :
For the case of sentences generally however or even the case of eternal sentences generally surely there is nothing approaching a fixed standard of how far indirect quotation may deviate from the direct  . 
Some n ~ nerical results are summarized in Table 1 . The measures of correspondence are between word boundaries and segment boundaries of degrees two  , three , or four . In Table I , Length refers to the text length in morphemes , and N is the number of boundaries for which the correspondence measures were computed  . 

Ted and ~% lly
Robinson Crus Qe
Word and Ob~ec ~
Length ~6 ~6







NX2C Diversity 19710 ~ . A . 59 2 . 8 95 5 . 0  . O 77 . 0 95 35 . 8  . 85 ~ . i  Tablei . Stmmmry of word and segment correspondences . 
The general conclusion is that words do co ~ respond to segments of at least second degree in a statistically significant manner  . The correspondence , however , , is dependent on text length and style . 

Left Right Linguistic Asymmetry
In applying Harris's procedure to our test data , we observe that the segments obtained from the R 's alone were different from the segments obtained from the L's alone  . 
Using entropy as a measure of freedom of cooccurrence  , and segmenting after each macimum in ~ , we obtain the first-order segments : come Boots / said Ted/come and ride/come/andride/in mywagon/jump in Boots/said Ted/Placing a boundary before every maximum in EL  , we obtain the segments : come/Boots said Ted/ come/andride/come and ride in/mywagon jumpin/Boots said/Ted Combining ER and ~  , we obtain the segments : come // Boots // said / /Ted////come and // ride / / // come and // ride //// in r~ywagon////jumpin // Boots said Ted // // Notice that the segments following from the ~ 's alone are in better agreement with conventional syntactic units than those following from the EL'S alone  . Using just the EL'S we obtain : Boots said Ted , co ~ and ride ______ ~ , Boots said as segments which are not easily identifiable as phrases  . 
Notice also that fourth-degree boundaries coincide more often with those following f ~ om the ER's than those following from the EL'S ? This suggests that there is more information for segmentation in ~ foliowing units as compared to preceding units  . 
If we examine the phonemic examples in Harris's paper  , e . g . 
~ say 1 ow wo h1 zw ~ r ~ p
R 5   29   15   15   28   7   5   29   7 l 8   29   29   7   2   29   9   29 L 24   3   23 lO 2   27   5   3   23   16   1   8   18   23   2/~   5   23   3_I or
Th ~ silow alls were up it kantey nz ~ i u wm in ~ mR  i0   28 iiii 27   7   6   6   3   28   21   9   2   9   28  &  i0   2   28 L 22   19   21   1   1   7   7   3   7   16   22   1   1   1   2   1   5   13   9 
It contains a luminum.
we find that the range of following phonemes is larger than that of the preceding  . In It contains a luminum , for example , the range of successors is 28-2  =  26 and that of predecessors is 221  =  21  . Moreover , the R's and L's give different segments . From the R's ~ e obtain it/kan/teynz/@lu~n/in /Bm 
From the L's alone we obtain it ~@ n/teynz /@ luwmin/@m and preceding units is found in ~ on  ( 1963 )  . In this study the linguistic units were Fries ' classes  , and the sample a text of 5000 words . 
The second-order segments from the following classes are If one believes/that all questions raised/by science /  . . . 
The reverse segmentation gives :
If/one believes that all/questions raised by /science In this text  , the variance of ER is larger than that of EL . 
A related result is Johnson's ( 1965 ) experiment which relates constituent structure to memory blocks  . Carried out in reverse order , where Ss are expected to remember preceding words  , constituents are not so well isolated . 
In our primer data , following morphemes are more variable than preceding morphemes  . Using entropy as a measure of diversity,
E(E ~) = E(EL ) = 3 . 18, where E indicates expected value . It may be shown that the expected value of right and left entropies must be equal  . But for the variances we find
Var(ER ) = 2.33 and Var(EL ) = 1.98.
The difference Var ( ER ) - Var ( EL ) is significant for this sample . 
For the application of our segmentation rules it is of interest that ER-EL is more closely correlated with ER than it is with EL  . And , in Moreover , in these samples Cor(IER-ELI , ER ) ~ Cor(JER-ELI , EL ) . The variances and correlations are shown in Table  2  . 
red and Sal_~y
Robinson Crusoe
Word and Ob'ect
Length ~6 46
Var(ER ) 2.33 3.63 2.19
Var(EL ) 1.98 3.46 1.99
Cor(4~-F~l , ~) .61 .32 .37
Cor(~R-ELJ , EL ) .51 .24 .19
Table 2. Variances and Correlations.
These measures of directional diversity apparently reflect that the language is a unidirectional process  . This is to be expected in a suffixing language such as English  . We wonder if some direction alasy ~ mmtry is a property of all natural languages  . 

Text Specific Compounds
One purpose of this paper was to clarify the distributional nature of the word  . The assumption has been that a word is a cluster of morphemes  . A quantification of what one might mean by " cluster of morphemes " leads to the segmentation rules  , and we have presented the results of their application in numerical detail  . 
The hypothesis that words are clusters of morphemes according to our interpretation is partially verified by the data that have been presented  , but the results remain suggestive rather than definitive  . 
Printers ' words and distributional groupings are coextensive with a much greater-than-chance frequency  . Moreover , in one case at least , there is a close correspondence between the degree of distributional separation of morphemes and the corresponding syntactic boundaries  . 
An ofttimes unstated assumption in statistical studies of language is that the results would become better if the sample size were larger  . 
This assumption is confirmed , but only in a restricted sense . In the specialized language of the primer Ted and Sally  , we used a large sample procedure to eliminate zero-degree segments and obtain a closer correspondence with printers ' words  . This procedure is applicable to the closed vocabulary of this primer  , in which every morpheme is used many times . It would not be applicable to texts where Zipf's law holds  . , , " and most morphemes are used only once . 
A study of the relationship between segmentation and sample size shows that segments are quite stable and do not change with respect to longer and longer portions of a text  . In some cases , of course , larger tional information . The general conclusion is that the distributional freedom with respect to limited contexts may be established from relatively small samples  . 
With regard to establishing the distributional reality of printers ' words j morpheme segments of fixed order do not necessarily approach words as the sample size increases  . The distributional clusters which do not correspond to printers ' words furnish style indicators  . Thus , we have the segments : look Ted , ~ in Tedan ~ Sally ; on board and on__ shore in Robinson Crusoe ; and ~_~ and the case of in Word and Object . 
These stylistic groupings show the same strong association that is found between the morphemes occurring within words  . The Begroupings are not necessarily them cst frequent in a ? sample  . 
The groups on board , the case of , etc . function as compounds in their respective texts . We may speculate about the role of morpheme frequency in the formation of compounds  . To use our theory in a predictive sense , we would assert morphemes showing strong association  , in the sense we have defined it , operate as compounds . 
Our rules enablaus to make statements about the relative ease of combination of linguistic units  . We have already pointed out that in the . ~ obins on Cruso esample th_~e , in the context the // h ~ , shows neutral association , while in the context th__ee // // first , the disassociation is strong . A parallel example , also in Robinson Crusoe , is on n where we findom board , on shore . On the other hand , in the context of the prepositional phrases on us and cathem  . we find the nentral associations on II we and on IIt__h ~  . 

These examples suggest that there are degrees of distributional freedom and that instead of hoping to give an absolute distributional characterization of the word  , we should speak of degrees of distributional wordhood  . The degree of boundedness of the morphemes of a word is not an absolute property but depends on the corpus containing them  , and in addition the context of surrounding morphemes  . 
Graphemic Grouping
The segmentation rules are numerical procedures for grouping linguistic units  . Here we apply these rules to graphemic data . For a graphemic application we compare Ted and Sall ~ and Word ~ nd  0b~ect  . 
Using letters , we can process much larger samples than we could using morphemes  . Relative to the first 16,6AO letters of T ~ . and Sally , we obtain the segments
Come Boots said Ted
In this simple text almost all words can be isolated from letter samples  . 
In contrast , consider the sentence fra~nent from ~ ord and 0b . ~ect : What counts as a word as against a string . . . 
Relative to a sample of 15 , 889 letters , the second-order se~nents from maxlmain R : What counts as a word as against a string  . . . 
Frc~maxima in L :
What counts as a word as against a string ...
Combining the information from the Rs and Ls we obtain the segments  . 
What counts as a word as against a string ...
2~  . . . . . : " The : complexitY ': of the ~ extma ~ es a marked ~ ifference ' ~ theoper-  . . . . . ' ~': at'?O'n of O~"segmenta ~' ion ; ruie , We obt ~ in many wo ~ bo~d ~ ries but also ' ~' ~ , : insa ' , : ~`' ~ Ate~of:one'~s ~ labi ~: wo~sSuch ~: as " Ta and Sally  , such combinations : do not ocdur .   .   .   .   .  ' ~ : : ' : " '  . . . . . . . : A : text " ~ e ~ ed ~ teto helas ' ~' ~ W0 i Sthel~er school ~ ea der All Around Me . The segmentation reiative tO .   .   .   .   .   .   .   .   .   .   .   .   15760 letters ~ ows ' ~ aniselation of meaningful letter sequences  , which are not necessarily words . The text begins : .   .   .   . Now . Whi ~ eywase leven years old , or there abouts , He had . 
- ~" s~n~i ~ nr ~ ~ vesi "' ~ . . . . '~ '  . . ~: NOW W~' . .te~a ~ ~ leven . y , ears . old or there about she had .   .   . 
This text illustrates that the segmentation ~' i~8 di Strib Ution , giving X ,  2 , she . . . .  , ": ass~ents\[::Nop ~ ctuation was involved in r ~ h ~~- t ~ ~  ; ~ u % ~ n : ot ; ~h ' ~ e-t~e'6~Se ~' groupings ~' sUb ~ ant ~ y for , ? i  ~ . !'- :~ ~ ~: ~ , ~: : ~  , 25 ~~' ~ EFERENCES Bloomfield , Leonard , " A Set of Postulates for the Science of Language , "
Lan ~.,_2,1926, pp . 153-16~.
Bloomfield , Leonard , ~, New York , 1933, p . 178 Chomsky , Noam , Word , 12, 1958, p .  217 . 
Gannnon , E . , Prgc . , IX Inter , Cong . of Ling . , 1963, pp .  507-13 . 
Greenberg , Joseph, . Essays in Linguistics , Chicago , 1957, p .  27 . 
Harris , James , Hermesora Philosoohical Inquiry Concerning Universal 
Gra ~, London , 1771, pp . 2021.
Harris , Zellig , " From Phoneme to Morpheme , " _~ ,  $1 ,  1955 , pp .  190~23~ . 
Hjelmslev , L . , Omkrin ~ Soro ~ teories Grundl ~ ggels ?, 1943, p .  66 . 
Jakobson , R . , Actes d ~ IV me C~ngre8 de Linaulstes ,  193~ , pp .  133-3~ . 
Johnson , N . F . , " The Psychological Reality of Phase Structure Rules "  , J . of Verbal Learnin ~ and Verbal Beh ~ viQr ~ ,  1965 , pp .  ~69-~75 . 
Juilland , A . The Word , unpublished MS
Kendall , M . G . , The Advanced Theory of Statistics . Vol . l , New York , 1952, p . 290 et seq . 
Khinchin , A . I . , _Mathem~ical Foundation of Information Theory , New York ,  1957 , pp .  2-~ . 
Togeby , Knud , " Qu'est-cequ'unmot ? " Travau ~ du C~rcle Ling ~ istioue de 
Copenha~e , V , 19~9, pp . 97-111.
TEXTSAMPLES
Defoe , Daniel , " Robinson Crusoe , "_ Beacon Third Reader . Ginn and Co . ,
Boston , 1914.

Francis , N . , The Structure of American English , New York ,  1959 . 
Gates , A . I . , and Bartlett , M . M . , All Around Me , New York , 1957 . 
Gates , A . I . , Haber , M . B . , and Salisbury , F . S . , Ted and Sall E , New
York , 1957.
Quine , W . ,  . Word and Object , M . I . T . , 1960, pp . 13-1A . 

