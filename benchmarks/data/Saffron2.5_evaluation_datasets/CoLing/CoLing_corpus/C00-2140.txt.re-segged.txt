DIASUMM : Flexible Summarization of
Spontaneous Dialogues in Unrestricted Domains
Klaus Zechner and Alex Waibel
La Jlguage'l ~ chnologies Institute
Carnegie Mellon University
5000 Forbes Avenue
Pittsbm:gh , PA 115213, USA
zechner ., waibel@cs , cmu.edu

In this paper , we present a summa . rization system for spontaneous dialogues which consists of a novel multistage architectm'e  . It is specifically aimed at addressing issues related totlle nature of the l  ; exts being spoken vs . written and being di Mogical vs . 
monologica . l . The system is embedded in a . graphical user interface ~ md was developed and tested on transcripts of recorded telephone conversations in 
English and Spanish ( CAI , LHOMI , ;).
1 Introduction
Summa . rization of written docmnents has recently O ' been a  . focus for much research in NI , t ~( ~ . o . , ( Mani and 1Vlasq~ury , 1997; AAAI , 1998; Maniel . al . , 1998; ACL ,  2000) , to nanle some of tile In a jol : events in this field ill the past few years  )  . I lowever , very little a . ttention has been given so far to the summa-riza . tion of spol , r (' ~ n language , even less of conversa-lions vs . monologic ' altexts . We believe tha . tsum-mariza . tion of speech will bccoJne increasingly more important  , a . s the ~ ml(mnt of online audio da La . grows and demand for r~tl ) id browsing , skimming , a . nda . e-cess of speech data increases . Another application which particulm : lypertains to our interest in spo--ken dialogue summarization would be the generation of meeting minutes for archival purposes a  . nd/or to update l ) a . rticil)a . nts . joining a . tla . terstages on qm'progress of the convers a . tion so far . 
Sunmmrization of dialogues within limilcd domains ha  . s been attempted within the context of the VERB MOBII  , pl:oj cct("protocolgeneration " , ( Alexandersson and Poller ,  1998 ) ) or by SRI's MIMI summarizer ( Kameyama et ~ d . , 1996) . lecent work on spoken language summarization i unrestricted domains has focused ahnost exclusively on Broadcast News  , mostly due to the spoken hmguage track of recent TREC evaluations  ( Oarofolo et al , 1997; Garotblo et al ,  1999) . ( Waibel et a . 1 . , 1( . )98 ) describe a Meeting Browser where summaries earl be generated using technology established for written texts  . 
(Va . lenza . el . M . , 1999) go one step further and in c of p or a . te knowledge from the speech recognizer ( confidence scores ) into their summarization system , as well . 
Wea . rgue that the nature of spoken dialogues , together with their textual representations a speech recognizer hypotheses  , requires a . set of specifical > proa . chestomake summarization feasible for this text genre  . 
As a demonstrable proof of concept , we present the multistage a . rchitecture of the summa . rization system I ) IASUMM which can flexibly deal with spoken di , dogues in English and Spa . nish , without any restrictions of domahl . Since it cannot rely on a . ny domain specific knowledge base , it uses shallow sta-tistica J approaches and presents  ( possibly modified ) ca:lracts from the original text . assumma . ry . 
We . present results of several evaluations of our system using human transcripts of spontaneous telephone conversations in English and Spanish from the  ( ~ , AI , LIIOME corl)/ls((LI)C) ,  1996) , in particular the accura . cy of the topic segmentation and in \[ brmat . ion condensing components ( sections (5 and 7) . Also , Ibr I . he purpose of a global evaluation , a user study was l~ei : % i : med which a . d dresscd in \[ or \] nation access t . in Jea . nda . ccura . ey of retain e . d information e ompa . ring different versions of summaries ( section 10) . 
This paper is organized as follows : In the next section  , we provide , a . now ; rviewa . bouttiein , till issues Ibr summa . rization of Sl ) oken dialogues and indicate I ; hc " ~ l ) l ) roaches we , are taking in our system . We then present he system a . rchitecture ( section 3), followed by a . detailed description of the readier building blocks  ( sections <1 to 8 )  . After a . briefelmra . cteriza-tion of the ( 2 UI ( section 9 ) we describe a user study for global system evaluation in section  10  . We conclude the pa . per with a smmnary and a brief outlook in section 11  . 
2 Issues and Approaches : Overview
In this section , we give a , no verview about the main issues that a . nysunmmrizat;ion system for spoken di-a . logues has to address midindica . te the approach we are taking for each of these in I  ) IASUMM . 
In a gener M sense , when dealing with written texts , usually there is plenty of information available which can be used l br the purpose of summa-t  , itles , passage head ( rs , i ) aragral ) h boundaries , or other , nark-ul ) S . ( hf for l . mud . ely , however , , , on c ( . ) f this holds for : q ) ccch data whh : harrives as a stream of word l , ok (' w ; from ; I recognizer , (: utiuto " utt ( . q'-antes " by using a silence heurist i (' . 
2.1. Lack of clause . 1) Oulldaries
One of the mosl . serious issues is the lackel senten ( : e or clause boundaries in spoken dialogues whi ( : hix particularly problemati ( :  . ; in (: escnten(:es , clauses , or l ) aragral ) hsa . r e ( . : onsider cd the " minimal re , its " in virtually all exist il , g summarization syst cu , s . \' V heu humans speak , they so , lletillles pause durin qa(:\]a . use , and not always at . l . heeml of a claus (' , whi (: h means that the outl ) u to far ( ; coguizer ( whi (: hus , t-ally uses some silelme-heuristics to cut the segments  ) frequently does nol real , eliIogi(:alsep , l , en (: e or clause boundaries , l , ooking at five I '; nglish(~A , ,I , HOM , ,: ( li-alogues with an average ii/11111)(" . 1' of : 20 iltl\[ . ('3'a,l(' . c~ . qeat . h , we find on average 30 such " ( : ontinuations " of logical clauses over automa . ti(:ally detcrmiueda (: ous-tit"segmentI ) ounda . ries . luasmmnary , this can cause a . r (; du (: tion in coh( , ,ren(:c and r<~dability of the outlmt . 
We address this issue I ) y linking adjac ( ; nttm'nsofth( ; smuesl ) eaker together if the silence between the mixless than a given col  , sl . \[/ llt(se(;tiolld) . 
2 . 2 Distrilml ; c . dint'(n'matioll Siuce we have multi-pari , y conversations as o\] ) l ) oscd to In onologi ( ' altexts , so nmtim cs the cru ( : ialin\['or-matiou is found in a question-auswer -l  ) air , i . e . , it involv('s more than oue Sl)eaker ; extracting ouly the question or only the auswer wo  , ld be meaningless in ma . nycases . We found that on average about 10% el ' the speaker turns belong to such question -answerl  ) airs in five examined English ( ~AIA , IIOME dialogues . Often , either the question or the answer ix very sho I:t and does not contain any words with high relevan  ( : c . In order not to " lose " these short tutus at a later stage  , when only then ~ ost , relevant turns are extracted , we link them to the matching question/answer a head of /  . ime , using two different methods to detect questions aud their answers  ( section 4 )  . 
2.3 Distluent speech
Speech disfluencies in spontaneous convers , ttions -- such as fillers , repetitions , repairs , or unfinished clauses -- can make transcril ) ts ( and summary extracts ) quite ha . rd to read and also introduce all tin-wanted bias to relevance computations  ( e . g . , word repetitions would cause a higher word count t br the repeated content words  ; words in untinished clauses would be included in the word count  . )' l'o alleviate this problem , we employ a cleanup tilter pipeline , which eliminates liller words and , : el ) - el . it . ions , and segments the tm'ns into short clauses ( sectiou 5 )  . \ Ve also remove incomplete clauses , typically sentem : c-iuitial repairs , at this stage of our ' . syst ? lu . This " clea . niug-up " serves two main pur-1) oscs : ( i ) it . im : rea ~ cstim readabilit 3 ~ ( for the fiually ( ; xtracl . cd segments ); and ( ii ) it . ~nakcs the text more tractable by subsequent modules  . 
The following exaln l ) lecom\] ) arcs a turn before and after t . he cleanup component : before : IMEAN WELOSEWE LOSEICAN'TI 
CAN'TDOANY THING ABOUTITSO after : we lose/i can't do anything about it  2  . 4 Lack oftel ) i (" l ) oundaries (; AI , I , IIOMEs \]) c'e( ; h data is lll/llti-to\] ) ica \] I ) tlt does uot include mark < q ) \[' or pa . ragral ) hs , noral , ytolfie-inforlJ , ative headers . Tyl)ically , welind about 5I0( . lilt'eren topics within a 10-mim d ; e segment of a di--ah ) gue , i . e . , the . topic changes about every 1   2 minutes in these conversations . To facilitate browsing and smHtlm rization , we thus have to discover topi-(:ally coherent , segl , lents automatically . This is done using a TextTiling approach , adapted t'ron~(l\]earst , \]997) ( section ( i ) . 
2.5 Speech . reeogl fizer errors
Imst but not least , we face t . hel ) roblcmofiml ) er-t'e ( : tworda ( :cura ( : y of sl ) eech recognizers , l ) articu-larly when ( h' . a ~ ling with Sl ) OUl . a \] moust ) eech over a large vo ( :al ) uhu ' yaud over a low I )  ; mdwi(Ith(:hamJe\] , SIIC\]I\[~Sl , h(~(' , AI , I , IIOME ( at ; tl ) as c's which we Juainly used for develol ) lnent , testing , and evaluatiou of our syste/n .   ( hu ' r ( mt recognizer styl ) ically exhibit word error rates \[' or l , hese (: or l ) or aill the order of 50% . In I ) IASUMM's hfl'ormation condensation component , the relevauc c weights of speaker ttlr , ls(:all be adjusted to take into acc . omd , their word confidence scores from 1 . 111; sl ) eech recognizer . That way we can reduce the likelihood of extra . eting passages with a larger amount of word ln is reeognitions  ( Zeclmer and \ Vaibel ,  201111) . luth is 1) aper , however , the focus will be exclusively on results of our evaluations on human generated transcripts  . No information from the speech recognizer nor from the acoustic signal  ( other than inter-utterance pause durations ) are used . We are aware that in particular prosodic information may be of help for tasks such as the detection of sentence boundaries  , speech acts , or topic boundaries ( l\]ir schberg ~ md Nakatani , 1998; Shriberg et al . , 1998; Stolcke et al ,  2000) , but the investigation of the integration of this additional source of infermarion is beyond the scope of this pal  ) er and lel't t br future work . 
3 System Architecture
The global system architecture of I ) IASUMM is a 1 ) ipeline of the tbllowing l burma jor components :
CLEAN ~ Turn Linking and TELE ! i \] Cleanup Filter ! 
Ii \]
Jinput for . Topic Segmentation
TRAN Sil
Information Condensation ~ TRANSi
L 171----\]77 - ~ CLEAN
Telegraphic Reduction TELE
Fignre 1: System architecture turn linking ; cleanup filter ; topic segmentation ; and information condensation . A . fifth component is added a . t the end for the purpose of telegraphic reduction  , so that we can maximize the information content in a given amount of space  . The system architecture is shown in Figure 1 . It also indicates the three major types of smnmaries which can be generated by l  ) IaSUMM : ' P\]~ANS ( " transcript " ) : not using the linking and cleanup components ; CLEAN : rising the main four components ; ' I'EI , E (" telegraphic " summary ): additionally , using the telegraphic reduction component . 
The following sections describe the components of
DIASUM Mill more detail.
4 Turn Linking
The two main objectives of this component are : ( i ) to form turns which contain a set of full ( and not partial ) clauses ; and ( ii ) to forlnturn-pairs in cases where we have a question-answer pair in the dialogue  . 
To achieve the first objective , we scan the input for adjacent turns of one speaker and link them together if their timestamp distance is below a prespecified threshold  0  . If the threshold is too small , we don't get most of the ( logical ) turn continuations across utterance boundaries , if it is too large , we run the risk of " skipping " over short but potentiMly relevant Daglnents of the speaker on the other channel  . We experimented with thresholds between 0 . 0 and 2 . 0 seconds and determined a local performance maximum around  0  =  1  . .0 . 
For the second objective , to form turn-pairs which comprise a question -answer information exchange between two dialogue participants  , we need to detect wh-and yes-uo-questions i the dialogue  . We tested \] English \] Spanish
Annotated l ) at a turns 16031185
Wh-questions /12   78 yes-no-questions / t3   98 questions total 85   ( 5 . 3%) 176 (14 . 9%)
Automatic Detection Results ( F1)
SA classifier
POS rules raudom baseline 0 . 24 0 . 22 0 . 22 0 . 37 0 . 02 0 . 1 3 Tahle 1: Q-A-pair distribution in the data and ex-pel ' imental results for automatic Q-A-detection two approa  . ches:(a ) a It MM based speech a . ct(SA ) classifier(\]/Jes ,  \] 999 ) and ( b ) a set of part-of-speech ( POS ) based rules . The SA classifier was trained oll dialogues which were manually annotated for speech acts  , using parts of the SWITCIIBOARI ) corpus ( Godfrey et al , 1992) for Fmglish and CALLIIOMF , for Spanish . The corresponding answers for the detected questions were hypothesized in the first turn with a  . differents l ) eaker , following the question-turn . 
Table 1 shows the results of these experiments for 5 English and 5 Spanish CAI , L\]IOME dialogues , corn-payed to a baseline of randomly assigning n question speech acts  , n being the number of question-turns marked by human a  . nnotal ~ or s . We report Fl-seores , where F1-~withP=preeision and/g--recall . 
We note that while the results \[ br the SA -classifier and the rule-based approach are very similar for English  , the rule-based apl ~ roach yields better results tbr Spanish  . The much higher random baseline for Spanish can be explained by the higher incidence of questions in the Spanish data  ( 14 . 9?/(, vs .  5 . 3% for

5 Clean-up Filter
The cleanup component is a sequence of modules which serve the purposes of  ( a ) rendering the transcripts more readable ,   ( b ) simplifying the input for subsequent components , and ( c ) avoiding unwanted bias for relevance computations  ( eesection 2 )  . All this has to happen without losing essential information that could be relevant in a summary  . While other work (\]\] eeman et al , 1996; Stolcke et al ,  1998 ) was concerned with building classifiers that can detect and possibly correct wn : ious speech disfluencies  , our implementntion is of a much simpler design . It does not require as much lnanual annota . ted training data and uses individual components for every major category of disfluency  . 1 t While we have not yet numerical ly evaluated the perfofmance of this component  , its output is deemed very natural to read by system users  . Since the focus and goals of this contpo-nent are somewhat different hanl  ) reviotts work in that area , meaningful comparisons are hard to make . 

Single or multiple word repetitions , fillers ( e . g . , " uhm ") , and discourse markers without semantic content ( e . g . , " you know ") a . rere moved fl : om the input , some short forms axe expanded ( e . g . , " we'll "-+" we will "), a . ndfl'cquent word sequences are combined into a single token  ( e . g . , % lot of "-+ " a_lot_of") . 
Longer tm'ns are segmented into shorl clauses , which are defined a . s consisting of at least a . subject and a . n in I lect cd verbal form . While ( Stolcke and Shriberg , 1996) use ngram models for this task , and ( C ~ awald ~ tetal , 1997) use neura . l networks , we decided to use a . rule-based approach ( using word a , nd POS information ) , whose perform a . nce proved to be compat'able with the results in the cited\]  ) ~- pets ( 1 , '~ > 0 . 85, error < 0 . 05) . ~leo , . several of tile clea . n-up filter's components , we in a . keuse of Brill's POSta . gger(Ih:ill,I,(), qd) . For Fmglish , we use ~ t modified version of Brilt's original t ~ gset  , and the tagger was adapted and retra . ined for Sl ) oken langua . georl ) or a , ( CAIAA IO ME a . lKlSWIT Cll-tlOalU )) ( Zechner , 1997) . For S1)anish , we crea . tedourown tagset . , derived from the l , l ) C lexicon and front the CIATEI/ . project ( LeOn ,  1994) , and trained the tagger on ma . nua . lly annotated ( ~; AI , I , IIOME dialogues , l ! ' urthernlore , a . POS based sha . lk ) w chunk parser ( Zechner a . nd Wa . ibel , 1998) is used to fill . (' . , '(, tit . likely ca . ndidates for incomplete , clauses dneto speech repair or interrul ) tion by the other Sl leaker . 
6 Topic Segmentation , ~ illceCAI , I , IIOME dialogues area . lways multi-topica . I , segmenting them in totOl ) ical units is an important : ; tel ) in our summa . riza . tion system .  ' . l ' h is allows us to l ) rovi ( le " signature ?' information ( frc qllenl ; coil-tent words ) about every topic to the user as a . hell ) for faster 1) rowsing and accessing the dat . a . , l , ' ur-thel:more , the subsequent in form a . tio , condensation COI \] l \]) Ollent ca . ll ~, VolYkon smaller parts of the dia Joguea . nd thus opera . remore ellieiently . 
Following ( loguraev and Iicnnedy , 1997; Ba . rzi-la . y and Elhadad , 1997) who use'l'extTiling(llcarst , 1997) for their summa . riza . tion systems of written text , we adapted this algorithm ( it . s block comparison version ) R ) rsl ) eech data : we choose turns to be minimal units a . nd compute block simila . rity between l ) locl(s of k turns every d turns . We use 9English and 15 Spanish @ ALI , tIOMI , ; dialogues , manually annota . ted for topic bound a . ries , to determine the opt in mmw dues for a set of TextTiling pm:am-eters and ~ t  . the same time to eva . lua . te the accuracy of this algorithm .  ' . redo this , werana . nn-R ) ld cross-wdidation (" . jack-l~nifing ") where ~ dldia . logues but one are used to determine the 1 ) est parameters " train set " ) m , d the remaining dia . logue is used as 2'\]' lie COIIIIIDA'is oIIW~:tS ( \[ Oll COI1t . he S~-tllle < lat at set as used m(Gav ; ddhctal .  , 1997) . 
EnglishSpanish block size k 25   15 sample distance d 2   2 rounds of smoothing r 2 l smoothing widths 2 \]' l . ' able 2: Optim M ' l > xt ' . l . ' iling pa . rameters for English and Spanish CAI , IAIOME dialogues nmnber of db dogues r~mdom baseline test set avg  . (%n seen data ") train set a ~ vg . (" seendat ?')
English Spanish 91 50 . 34 0 . 35 0 . 58 0 . 53 0 . 69 0 . 58 ' l'~d ) le 3: Topic segment a . tion results for English and Spa . nish CAI , IAIOMI , : dialogues(Fl-Scores ) a heldout d~ta . set for eva . luation (" test set ") . This process is rcpea . tedn times and average results are reported . Ta . ble 2 shows the set of p~u : a meters which worked best for most diak  ) gues ~ md ' Fable 3 shows tile eva . hm . tion results of the crossvalidation experiment .  / , ' ~- scores improve I ) y 18-2d % abso htte over the random baseline for unseen a . nd by 2335% for seen data . , the performance for E\]@ish being better than for Spanish  . ' l ' hese results , albeit achieved on a . quite different ext genre , are well in line with the results in ( llea . rst , 1997) who reports a . nabsolute improvement of a , bout:20% over a , random baseline for seen data . 
7 Information Condensation
The inform a , tion condensa , tionCOml ) onent is the core o\[' our sysl , en : ~ , liltspUrl ) OSe is to determine weights for terms and turns ( or linked turn-i ) airs ) and then to rank the turns a . ccording to their relewmce within each topical segment of the dialogue  . 
For term-weighting , lf*insl ) ired formula . e(Sa . lton and Buckley , 1990) are used to empha . size words which are in the " middle range " offl : equency in the dialogue a  . nd do not a . pl ) eat : in a . stoplist . : ~ For turn -- ranking , we use a version of the " maximal n , argina . l relevance " ( MMI ) algorithm ( Ca . rbonell and Goldstein ,  1998) , where emphasis is given to liurns which conta . in ma . ny highly weighted terms to t " the current segment  ( " sa . lience ") a . nd are sutficiently dissimila . r to previously ranked turns ( to minimize redunda . ncy) . 
For 9 English and ld Spanish dialogues , the " most relevant " turns were nmrl ~ edlay hm nancoders  . We ran a . series of crossvalidation experiments o(a , ) optimize the parameters of this component related to tJ'*idf a  . nd MMR computa , tion and to(b ) deterl nine 31 , ' or l , ; nglish , our stoplist comprises 557 words , for Spanish , 831 words . 
9 71 how well this information condensing component can match tile human relewmce annotations  . 
Summarization results are comlmted using 1 l-pt-avg precision scores t ` or ranked turn lists where the maximum precision of the list of retrieved turns is averaged in the  11 evenly spaced intervals between recall=\[0  , 0 . 1),\[0 . 1,0 . 2),  .   .  \[1 . 0,1 . : 1) ( Salton and McGill , 1 . 983) .   4 Table 4 shows the results from these experiments . Similar to other experiments in the summarization literature  ( Ma . nieta . l . , 1998) , we find a wide performance variation across different texts  . 
8 Telegraphic Reduction
The purpose of this component is to maximize information in a tixed amount of space  . We shorten the OUClmt of the summarizer to a " telegraphic style "  ; that way , more in rorm a . tion can be included in a summary of k words ( 02: n byt es )  . Since we only use shallow methods for textual analysis that do not generate a  . dependency structure , we cannot use complex methods for text reduction as described  , e . g . , in ( Jing , 2000) . Our method simply excludes words occurring in the stoplist fl : om the summary  , except for some highly inforlnative words such as ' T ' or  ~11ot  ~  . 
9 User Interface and System
Perforlnance
Since we want to enable interactive summarization which a  . llows ~ user to browse through a dialogue qnickly Cosearch for information he is interested in  , we have integrated our summarization system into a  3AVA-based graphical user interface ( " Meeting Browser " )   ( Bert et al ,  2000) . This interface also integrates the output of a speech recognizer  ( Yu et al . , 1 . 999) , and can display a wide variety of infer 1nation about a conversation , including speech acts , dialogue games , and emotions . 
For suml narization , the user can determine the size of the summary and which topical segment she wants to have displayed  . Ite can also rocus the summary on particular content words  ( " querybased summary " ) or exclude words from consideration ( " dynamic stoplist expansion " )  . 
Smmnarizing a 10 minute segment of a CALL-hOME dialogue with our system takes on average less than  30 seconds on a 167 MHz 320 MB Sun Ultral workstation . S 4 We are aware that this annotation and evaluat ion scheme is far fl'om optlmahit does neither reflect the fact that turns are not necessarily the best units for extraction or that the  11-pt-avg precision score is not optimally suited for the sum-marization task  . We thus have recently developed a new word-based method for annotation and evaluation of spontaneou speech  ( Zechner ,  2000) . 
5The average was computed over five English dialogues  . 
10 Human Study 1 (1 . 1 Experiment Set ; up Ill order to ewduate the system as a . whole , we conducted a study with humans in the loop to 1 ) eable Cocoln pare three types of summaries ( TITANS , CLEAN , TELE , see section 3) with the flllloriginal transcript . 
We address these two main questions in this study :   ( i ) how fast can information be identified using different types of summaries ?  ( ii ) how accurately is the information preserved , comparing different types of summaries ? We did not only ask the user " narrow " questions for a specific piece of information -- along the lines of the Q-A-evaluation part  . of the SUMMAC conference ( Manie Ca . l . , 1998) -- but also very " global " , nonspecific questions , tied Coa . par Cicular ( topical ) segment of the dialogue . 
The experiment was conducted as follows : Sub -jeers were given  24 texts each , a ceompa . nied by either a generic question ( "What is the topic of the discussion in this text segment ?"  ) or three specitic questions ( e . g . , " Which clothes did speaker Abuy . '?") . 
The texts were drawn from five topical segments each rrom five English CAIAA IOME dialogues  .  ( ; They have four difl > rent formats : ( a ) fldl transcripts ( i . e . , the transcript of the whole segment ) ( FULL ) ; ( b ) summa . ry of the raw transcripts ( without linking and clea . n--up ) (' rll . aNS ) ;   ( c ) cleaned-up summary ( using all four major components of our systenl )   ( C , I , I , ; AN ); and ( d ) telegram suln 21\]a , ry(derived rron\](c ) , using also CiteCelegraphic reduct . ion component ) ( TI '; LE ) . 
' l ' he texts or for , , , a . t , , ( b ), ( c ), a . nd(d ) were generated 1 ; o have the sa aue length : 40% of ( a ) , i . e . , we use a 60% reduction rate . All these formats can be accotnpanied by either a  . generic or three specitic questions : hence there are eight types of tasks for each of the  24: texts . 
We divided the subjects in eight groups such that no subject had to l  ) erform more than one task on the same text and we distributed the different Cask sevenly \[' or each group  . Thus we caumake unbiased comparisons across texts and tasks  . 
The answer accuracy vs . a predefined answer key was manually assessed on a  6 point discrete scale between 0  . 0 and 1 . 0 . 
10.2 ll , esults and Discussion
Of the 27 subjects taking part in this experiment , we included 24 subjects iu the evaluation ;   3 subjects were excluded who were extreme outliers with respect o average answer time or score  ( not within /*+-2s Cd dev )  . 
From the results in Table 5 we observe the following trends with respect to answer accuracy and response time : SOne of the  25 segments was set aside for demonstration purposes  . 

EnglishSpanish nun+her of dialogues 914 turnst ) er dialoguema . rked ; ts relevant I ) y human coders 12% 25% Il-pt-a . vg precision ( average over t . ol)i(:a . l segnlent . s ) 0 . 45 0 . 5 . 0 score variation between ( liak ) gues 0 . 2 0 . 49 0 . 15 0 . 8TM ) Ie 4: Smmnarization result ; s for English and S1) an isll ( I~AI , I , IIOME
I , ' or nmttrans (: lea . n \] tele'\]'ime vs . A(:c . T in . :\] Ae ( . ' l'ime\[A(C . I Time\[Ac ( generic ( q = 72 ) specific ( q = 216 ) 
L full Time ~ Ace.
I 0._(,.1D .): s,-~ec.
-% ~\[07739' l'M ) le 5: Average a . nsw('rtimes(i ,, sect a . nda . ccuracy scores (\[0 . 0-1 . 0\] ) overeight dilferent tasks ( number of subjects = 2d ; q := mmd ) er of questions l ) er task type) . 
summary l , ypegeneric/indicative speci\[ic/informative\ [ !  ) / )  . sIwci . , l \]
LrLs1 ? t . 0' l ' able 6: Ilela . tive answer accuracies in % for dill ' ~, rent
Sl ) l\]llll~/ri ( ~ S*ge~w'ric questions ( " indicative summarie , s " , the task being to identi\[y the topic o\['a text  ) : The tWO cleaned uDStll nF la , ries tool(M ) out , the same Limeto in ; ocess I ) ui . had lower a eeura (' y scores than timv ( ; rsion directly u : dug the trans (: ril ) l . .
* spcc ~/ ir quest . ions (" ilfl ' or lnal . ives unllllaries ", the ( . ask being Iolil MS l ) ecilieint L rllmlion in t\]l ( ~ re?t ) :  ( I ) The accuracy advant , age of the raw I , ranscripl , sunlmaries (' I'R , ANS ) over the clealled u \] ) versions ( CL lCAN ) is only small (  , oZ :; Latis-tica . lly signitieant : L :-0 . 748) 7 . (2) ' l'her("isasui ) eriority of the ' l'l , ;lA , ,-StllnlHary to t)o(;h otJmr kinds (' rFLI . : is significa . nlJymore ;, iCC tllX/l(2(h ~-/ . ll
CLEAN\[(()r1) " ~0.0 ~ r)).
l , ' rom this w (; conjecture thai . our methods for (: us-tomiza J . ion of the summaries to spoken dialogues is mostly relew mt for in J ' ormativ c  , but llots ot Ull(;h for in di , : , tiv csmmmu ' ization . We drink that el . her methods , such as lists of signature l ) hrases would l ) entor 0 effective to usel brt he\]al ; tcr\[mrl ) ose . 
'l ) dt le 6 shows the answer accuracy for the three different smmnarytyl  ) es relative 1 ; o the accuracy of tile f ldl transcripl , texts of l , hesa . mesegmenl , s (': relative ~ ms wer a . ccm:acy ") . We , observe that ; tit(:r('l~d ; ive accuracy reduction for all smnn \] aries i markedly lower than the reduction of tc'xt size : all sunmmries were reduced from the full transcripts l  ) y 60% , whereastile answer a ( : ( : uracy only drops between 9% ( TITANS ) a , tld 24% ( CI , EAN ) l()l " the generic quest , ions , 7111\['DA;\[ , , ill 2 , of 5 dialogues . I,\]mCI , I . 1 ANSII llllllD , l ' y score sm : e highertll all th < > se of the ' I ' IIANS summaries  . 
and between 20% (' rF , l , l  ~ , ) and 29% ( CI , F , AN ) fOl : the speci\[ic questions . This proves that our systeln is able to retain most of the relevant information in tim summaries  . 
As for average ' answer times , we see a . ma . rked reduction (3()0,) of all sunmm . ries coulp arc d to the full texts in l , hc . q cneric case ; for the Slm Cificease , the time reduction is sonle what sma . ller(l5% 25%) . 
One shortcoming of the current , system is thai ; it oper ~ d ; es on turns ( or \[ ; tlrll-pa . irs ) as minimal units \[' or extraction , tn\[St ture work , we will investigate possil ) ilities to reduce the minimal units ot 7 extrac--l . ionl . otim level of chmses or sent . < m < : es , wilhoul , givlike ; Ul ) the idea of linking cross-slxmker information . 
1  1 Summary and lglture Work \ Vehave presented as unmmrization sysl  , e ~ for six ) ken dialogues which is constructed to address key difl  ) renees of spolcen vs . written langua . ge , dia . logues vs . monologues , and inul . i-topical vs . mono-topical texts . The system cleans up the input for speech disfluencies  , links t . urns together into coherent information units , determines t Olfica . l segments , and extracts the most relevant pieces of informal  , ion in a user-customiza . bleway . I ~; v a h m l , ions of major system (: Oral ) Orients and of t . he syste Jn as a . whole were 1) er for nmd . ' l'hc results of a users l , udy show that with a . sutmnary size of d0% , between 71% and 911% of the inlbrma . tion of the fill \] text is ret . a . ined in the summary , depending on tile type of summary and timLyl ) ('s of quest , ions being asked . 
\?c ' are currently extending the system to be able to ha  . ndle different levels of granularity for extract ; ion(clauses , sentences , turns ) , leurthermore , we plan to investigate the , integration of l ) rosodic information into several ( -on q ) onents of our system . 
12 Acknowledgements
Wewa . nt , l , otha . nk the almotators for their ell'errsaim Klaus Hies for providing l  . he automatic speech a (: tt?omAlon Lavie , Marsal Gawtld ~/ , Jade Goldstein , Thomas MacCracken , and the & llonymotlsl : eviewers on earlier drafts of this paper  . 
This work was funded in part by the VEfBMOBI1 , project of the Federal Republic of Oerma , ny , ATR-Interpreting Telecommunications Research L ~l  ) ora-tories of Japan , and the US l ) epartment of l ) e fense . 
References
AAAI , editor .  1998 .   Proceedin9s of the AAAI98 Spring Symposium on Intelligent Te . vt Summarization , Stan\]ord,

ACL .  2000 . Proceedings of thc ANLP/NAACL-2000 Workshop on Automatic Summarization , Seattle , WA , May . 
Jan Alexaudersson and Peter Poller .  1998 . Towards multilingual protocol generation for spontaneous speech dialogues  . In Proceedings of the INLG-98 , Niagara-on-the-lahc , Canada , ilugust . 
fcg in a Barzilay and Michael Elhadad .  1997 . Using lexical chains for text summarization . In ilCL/EACL-97 Workshop on Intelligent and Scalable Te . vt Summarization . 
Michael Bert , lalph Gross , llua Yu , Xiaojin Zhu , Yue Pan , Jie Yang , and Alex Waibel .  2000 . Multimodal meeting tracker . In Proceedingso \] the Conference on Content Based Multimedia Information Access  , IHAO-2000 , Paris , l < 7' ance , April . 
Braniinir Boguraev and Chrlstol ) hcr I(cnnedy .  1997 . 
Salience-based characterisation of text documents . In ACID/EACL- 97 Workshop on Intelligent and Scalable Text

Eric Brill .  1994 . Some advances in transforlnation-I ) ~ed part of speech tagging . In Proceeedings o . fAAAI-9/~ . 
Jaime Carbonellmid Jade Goldstein .  1998 . The use of MMR , diversity-based reranking for reordering docunlents and producing summaries  . In Proceedings o . f the 21st ACM-SIGIJg International Co , florence on Research and Development in lnJormationll  . ctrieval , Melbour ~; c , Australia . 
Johl \] S . Garofolo , Ellen M . Voorhees , Vincent M . Stanford , and l ( aren Sparck . \] ones .  \]997 .   TII\]C-6   1997 spoken doc-Illllell L retriew fl track overview and results  . In Proceed-in 9 so . \[ the 1997"17 H?C-6 Conference , Gaithe ' rsburg , MI ) , 
November , pages 83-91.
John S . Garofolo , Ellen M . Voorhees , Cedric G . P . Auzanne , and Vincent M . Stratford .  1999 . Spoken doculnent retrieval : 1998 evaluation aud investigation of newinetrics . 
In Proceedings of the ESCA workshop : Accessing information in spoken audio  , pages 17 . Camloridge , UK , April . 
Morsel Gawddh , Klaus Zechner , and Gregory Aist .  1997 . 
I ligh perforlnauce sgn lentation fspontaneous speech using part of speech and trigger word infornmtion  . In Pro-eeed in 9s of the 5th ANLP Conference , Washington DO , pages 1215 . 
J . J . Godfrey , E . C . ltolliman , and J . Mcl ) mfiel .  1992 . 
SWITCttBOARD : telephone speech corpus for research mid development  . In Proceedings of the IUASSP-92 , vohnne1 , pages 517-520 . 
Martl A . II earst .  1997 . TextTiling : Segmenting text into multiparagraph subtopic passages  . Computational Lin . -guistics , 2311):33-64, March . 
Peter A . I Ieeman , Ieyunghe Loken-Khn , and James 1: . Allen . 
1996 . Oombining the detection and correction of speech repairs  . In Proceed in 9s of ICSLP96 . 
Julia Ilirsehbergmid Christine Nakatmfi .  1998 . Acoustic indicators of topic segmentation . In Proceedings o . f the
ICSLP98, Sydney , Australia.
II ongyan Jing .  2000 . Sentence reduction for automatic text sum , narlzation . In Proceedings of ANIH~-NAACL-2000,
Seattle , WA , May , pages 310-; 315.
Megumi Kameyama , Goh Kawai , and isao Arima .  1996 . A real-tinie systcni for summarizing human-human spontaneous spoken dialogues  . Ill Proceedings of the ICSLP96, pages 681-684 . 
Linguistic Data Consortium ( LDC) .  1996 . Call Home all d
Call Friend LVCSR databases.
Fernando S~nchez\[,edn .  1994 . Spanish l . agset for tile CI ~ . ATIBR project , http://xxx . lanl . gov/cinp-lg/9406023 . 
lndet jeet Mani and Mark Maybury , editors .  1997 . Proceed-ings of the ACL/ICACL '97 Workshop on Intelligent Scalable Text Summarization  , Madrid , Spain . 
\]ndet:ie et Mani , I ) avidl to use , Gary Klein , l , ynette Hirschman , Leo Obrst , Therese Firmin , Michael Chrzanows ld , and l Jeth Sundheim .  1998 . The ' I'\]P-STERSUMMAC text summarization evaluation  . Mitre Technical Report MTIi98W0000138 , October 1998 . 
Klausliles .  1999 . It MM and neural network based speech act detectiou  . \]n Proceedingso \] the ICASSP-99, Phoenix,
Arizona , March.
Gerard Salton and Chris Buckley .  1990 . \]? lexlble text matching for information retrieval  . ' Pcchnical report , Cornell University , Department of Computer Science , TR .  90-1158,

Germ'd Salton and Michael J . McGill .  1983 . Introduction to Modern Information ltetrieval . McO , ' awIIill , q\~kyo etc . 
Elizabeth Shriberg , Rebecca Bates , Andreas Stolcke , Paulq ) * ylor , Danielaurafsky , Klausfies , Noah Coccaro , lachel Martin , Marie Meteer , and Carol Van EssDykema .  1998 . 
(Jan prosody aid the automatic classification of dialog acts in conversational speech ?  Lan9aa9 e and Speech ,   , 1113-4):439 487 . 
Andrew , sStolcke and l~liza beth Shriberg .  1996 . Automatic linguistic segmentation f conversational speech  . In Proceedingso \] the I6'SL\]~-96 , pages 1005-1008 . 
Andreas Stolcke , Elizabeth Shriberg , Rebecca Bates , Marl Ostendorf , Dilek I Iakkani , Madelei , mP lauche , ( JSkhan Tfir , and Yutin .  1998 . Automatic detection of sentence 1ooundm:ies and disfluencies based on recognized words . In Proceedings of the ICSLP98 , Sydney , Australia , Decen > bet , volunm 5 , pages 2247--2250 . 
Andreas8 to lcke , I Slizabeth Shriberg , l ) ilek II akkani-T fir , and GSk hanq'fir .  2000 . Prosody-based automatic segmentation of speech into sentences and topics  . Speech Comn ~ u -" nh catio ' a . , 32(1-2) . 
l/ob in Valenza , 3kmyl ~ obins on , Mariannel \] ick cy , and loger Tucker .  199,(/ . Sunnnarisation of Sl ) oken audio through in-forniatiou extraction , tn Proceeding so , f the /' TSCA workshop : A ceess in . 9i ~ fformatio'ni~spoken audio , pages 11116 . C . 2 ambridge , UK , April . 
Alex Waibel , Michael Belt , and Michael Finke .  1998 . Meeting browser : Tracking and summarizillg meetings  , in Proceedings of the DARPA Broadcast Newsl/Vo 'rkshop  . 
Hue Yu , Michael Finke , and Alex Waibel .  1999 . Progressill atltonlatic meeting transcril)tion . \]n Proceedings qf EUI ~ OSI'E ECI 1-99 , Budapest , lhm9 ary , September . 
Klaus Zeehner and Alex \? aibel .  1998 . Using chunkbased partial parsing of spontaneous speech in unrestricted domains for reducing word error rate in speech recognition  . 
In Proceedings of COLING-ACL98 , \] WI on treal , Canada . 
Klaus Zechner and Alex Waibel .  2000 . Minimizing word error rate in textual suinnlaries of spoken l miguage  . \] u Procced-ing so \] the First Meetingo . f the North American Chaptero . f the Association for Computational Linguistics , NAACL 2000 , Seattle , WA , April/May , pages 186-193 . 
Klaus Zechner .  1997 . Building chunk level representations for spontmmouspeech in unrestricted domains : The CHUNI'  ; Y system and its al ) plication to reranking Nbest lists of a speech recognizer  . Mas-ter's thesis ( project report ) , Oh/I_U , available fl ' om : http://wuu . es . emu . edu/-zechner/publicatons . html . 
Klaus Zechner .  2000 . A word-based annotation and evaluation scheme for summarization of Sl  ) ontanco IJs speech . Awfilabl cfi ' oni http://www . cs . ?,,,, . eduFzechner/pubiications . i,1:ml . 

