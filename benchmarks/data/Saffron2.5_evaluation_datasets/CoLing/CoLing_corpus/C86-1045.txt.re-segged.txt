Categorial Unification Grammars *
Hans Uszkoreit
Artificial Intelligence Center
SRI International and
Center for the Study of Language
and Information at Stanford University

Categorial unification grammars ( CUGs ) embody the essential properties of both unification and categorial grammar formalisms  . Their efficient and uniform way of encoding linguistic knowledge in well-understood and widely used representations makes them attractive for computational applications and for linguistic research  . 
In this paper , the basic concepts of CUGs and simple examples of their application will be presented  . It will be argued that the strategies and potentials of CUGs justify their further exploration i the wider context of research on unification grammars  . Approaches to selected linguistic phenomena such as long-distance dependencies  , adjuncts , word order , and extraposition are discussed . 
0. Introduction
The work on merging strategies from unification grammars and categorial grammars has its origins in several research effors t that have been pursued in parallel  . One of them is the grammar development on the PATR system  ( Shieber et al , 1983; Shieber , 1984) at SRI . For quite a while now I have been using the excellent facilities of PATR for the design and testing of experimental \[ CUGs  . Such grammars currently run on two PATR implementations : Stuart Shieber's Z et al is p version on the Symbolics  3600 and Lauri Karttunen's Interlisp-Dw : rsion on the XEROX  1109  . The work on CUGs has influenced our efforts to develop a larger PATR grammar  , and will do so even more in the future . 
On the theoretical side , this work is part of ongoing research on such topics as word order variation  , modification , and German syntax within projects at SRI and CSLI  ( Stanford University )  . 
The structure of the pape reflects the diverse nature of the enterprise  . In the first section , I will introduce the basic notions of CUGs and demonstrate them through examples in PATR notation  . The second section discusses the motivation for this work and some of its theoretical implications  . The third section sketches a linguistically motivated CUG framework with a strong lexical syntax that accomodates word order variation  . 
The paper concludes with a brief discussion of possible CUG approaches to long-distanced pendencies  . 
1. Basic Notions of Categorial Unification
Grammars 1.2. Unification Grammars and Categorial

Both terms , unification grammar ( UG ) and categorial grammar ( CG )  , stand for whole families of related grammar formalisms whose basic notions are widely known  . lYet , for the characterization f the class of formalisms I want to discuss  , it will be useful to review the most central concepts of both UG and CG  . 
Unification grammar formalisms employ complex feature structures as their syntactic representations  . 
These structures encode partial information about constituents  . Either term or graph unification is utilized as the main operation for checking  , propagating , and merging of the information in these complex representations  . Most unification grammars also use the complex feature structures for the linking of syntactic and semantic information  . 
In traditional categorial grammars , all information about possible syntactic ombinations of constituents is encoded in their categories  . Those grammars allow only binary combinations . One of the two combined constituents , the functor , encodes the combination funtion , the other constituent serves as the argument to this function  . Instead ot 7 phrase structure rules , the grammar contains one or , in some formalisms , two combination rules that combine a functor and an argument by applying the function encoded in the functor to the argument constituent  . Most categorial grammars only combine constituents whose terminal strings concatenate in the input string  , but this need not be so . In most categorial grammar formalisms , it is assumed that the syntactic functor-argument structure in the corresponding compositional semantics  . 

There are usually two types of grammatical categories in a categorial grammar  , basic and derived ones . Basic categories are just category symbols , derived categories are functions from one ( derived or basic ) category to another . A derived category that encodes a function from category A to category B might be written B/A if the functor combines with an argument to its right or B ~  , if it expects the argument to its left . Thus , if we assume just two basic categories , N and S , then N/S , S/N , N\S , S\N , ( S\N)/N , ( N/S\(S\(N/N )) , etc . are also categories . 
Not all of these categories willever occur in the derivation of sentences  . The set of actually occurring categories depends on the lexical categories of the language  . 
Assume the following simple sample grammar : ( 2 ) Basic categories : N , S lexical categories : N ( Paul , Peter )   ( S\N ) fN ( likes ) The grammar is used for the sample derivation in ( 3 ) :  ( 3 ) Peterlikes Paul
N(S\N ) finN


It should be clear from my brief description that the defining characteristics of unification grammar have nothing to do with the ones of categorial grammar  . We will see that the properties of both grammar types actually complement each other quite wetl  . 
1.2. A Sample CUG in PATR Notation
Since the first categorial unification grammars were written in the PATR formalism and tested on the PATR systems implemented at SRI  , and since PATR is especially well suited for the emulation of other grammar formalisms  , I will use its notation . 
The representations in PATR are directed acyclic graphs  ( DAGs )  2  . Rules have two parts , a head and a body . The head is a contextfree rite rule and the body is a DAG  . Here is an example , a simple rule that forms a sentence by combining a noun phrase with a verb phrase  . 
188 (4) head XO-~X 1 ,   X2 body in unification otation < X0 cat >= S < X1 cat >= NP < X2cat > = VP < X1 agr >= < X2agr > body in graph notation x or
SNP
The rule states that two constituents X1 and X2 can combine to form a constituent X0 if the terminal string covered by X1 immediately precedes the terminal string of X2 and if the DAGs of X0  , X 1 , and X2 unify with the X0 , X 1 , and X2 subgraphs of the rule body , respectively . 
I will now show the most straightforward encoding of a categorial grammar in this notation  . There are two types of constituent graphs . Constituent graphs for basic categories are of the following form:  ( 5 ) 
NS
Of course , there might be more features associated with the constituent :  ( 6 ) / oe 7
NSF in ite 3Sg
Derived constituents have graphs of the following form :  ( 7 ) arg ( t0b ) Backward Functional Application ( BFA ) value-~functor argument < value >= < functor val > < argument >= < functor arg > < flmctor dir > :--: Left  . 
This is the graph associated with the VP likes Paul : in graph notation:  ( 8 )   ,  . / ~ Left/~agrca ~ // pers/form cat/pers~num
SF in iteN 3Sg
It corresponds to the derived-category smboh (9)
S\N form : Finite pers : 3 num : Sg ( 10 a ) and ( 10b ) are the rules that combine constituents . 
As in traditional categorial grammars , two such rules sufice . 
(10 a ) Forward Functional Application ( FFA ) value -~ functor argument < value >= < functor val > < argument >= < functor arg > < functor dir >= Right  . 
in graph notation : value ~ J-~~'~.
/funct?rl.~rgu
Rightment value ~-- JJ -~- ~ rgument /

If Backward Functional Application is used to combine the constituents Peter and likes Paul  , the result is a finite sentence . 
However , if the same rule is applied to the identical constituents likes Paul and likes Paul  , again a finite sentence is obtained . '\]\[' his is so because the graph for likes Paul actually unifies with the value of arg in the same graph  . This can be easily remedied by modifying the graph for the VP slightly  . By stipulating that the argument must not have an unfilled argument position  , one can rule outderivcd categories as subject arguments t br the VP :  ( II ) /0 o-i/?e ? Tum
SF in iteN 3 Sg 1 . 3 . Extensions to the Basic Formalism In this subsection \[ want to discuss very briefly a few extensions of ' the basic model that make it more suitable for the encoding of natural-language rammars  . The first one is the sorting of fimctors according to their own syntactic category  . This move might be described alternatively as defining the type of a constituent as being defined by both a set of syntactic  ( and semantic ) This function is also expressed as the value of an attribute  . For a basic category the value of the function attribute is NIL  . The following graph is a simplified example of a functor category  ( prenominald jective in a language with case and number agreement within the 

~~/~~' ~ unction ca ; ~/ ~ s::m--~gr
The combination rules need accordingly . This is the modified functional application . 
to be changed rule of forward value -~ functor argument < value >= < functor function val > < argument >= < functor function arg > < functor function dir >= Right  . 
In a traditional categorial grammar , a derived category is exhaustively described by the argument and value categories  . But often , syntacticians want to make more finegrained distinctions  . An example is VP modification . In a traditional categorial grammar , two different VP modifiers , lets say an adverb and an adverbial clause , would receive the same translation . 
(12) Peter called himan grily
N ( S\N ) fNN ( S\N ) / ( S~q )   ( 13 ) Peter called himat work
N ( S\N ) /NN ( S\N ) / ( S~aN ) the category ( ( S\N ) \ ( S\N ) )/ ( (S\N ) \ ( S ~ N ) ) to allow the derivation of ( 14 )  , the ungrammatical sentence (15) is also permitted . 
(14) Peter called him very angrily
N ( S\N ) /NN ( ( S\N ) \ ( SLN ) )/  ( S\N ) / ( S ~ X\[ )   ( ( S\N ) \ ( S ~ N' ) )  ( 15 ) * Peter called him very
N ( S\N ) /NN ( ( S\N ) \ ( S  ~ ) )/  ( ( S\N ) \ ( S\N ) ) at work ( S\N ) / ( S  ~ ) If functor categories are permitted to carry features of their own that are not necessarily bound to to any features of their argument and value categories  , this problem disappears . Adverbs and adverbial clauses could receive different features even if their categories encode the same combination function  . 
Another solution to the problem involves the encoding of the difference in the value part of the functor  . 
Yet this solution is not only unintuitive but also contradicts a linguistic generalization  . It is unintuitive because there is no difference in the distribution of the resulting VPs  . The only difference holds between the modifiers themselves  . The gene ~: alization that is violated by the encoding of the difference in the value subgraphs is the endocentricity of the VP  . The modified VP shares all syntactic features with its head  , the lower VP . Yet the feature that indicates the difference between adverbs and adverbial phrases could not be in both the argument and the value parts of the functor  , otherwise iterations of the two types of modifiers as they occur in the following pair of sentences would be ruled out  . 
(16a ) Peter called him very angrily at work.
(16b ) Peter called himat work very angrily.
Another augmentation is based on the PATR strategy for linking syntax and semantics  . Most grammars written in PATR use the constituent graphs also for encoding semantic information  . Every constituent has an attribute called trans or semantics  . 
The value of this attribute contains minimally the internal semantic fnnction-argument structure of the constituent  , but may also encode additional semantic information  . The separate encoding of the semantics allows for a compositional semantics even in construction in which syntactic and semantic structure divertas in certain raising constructions  . The following graph for a ficticious prenominal adjective that was introduced earlier contains translation attributes for the functor  , the argument and the value . The meaning of the adjective is indicated by the atom Red  . 
cat ~/ functi % ~ rans

Accing ~._ ~ g

At first glance , the lexical graphs--even the ones that are used in the highly simplified examples -- seem to exhibit an excessive degree of complexity and redundancy  . However , the lexical approach to syntax is built on the assumption that the lexicon is structured  . To create a lexicon that is structured according to linguistic generalizations  , we introduced lexical templates early on in the development of PATR  . 
Templates are graphs that contain structure shared by a class of lexical entries  . Lexical graphs can be partially or fully defined in terms of templates  , which themselves can be defined in terms of templates  . If a template name appeam in the definition of some graph  , the graph is simply unified with the graph denoted by the template  . 
The next augmentation is already built into the formalism  . Categorial grammarians have recognized the limitations of fimctional application as the sole mode of combining constituents for a long time  . One of the obvious extensions to classical categorial grammar was the utilization of functional composition as a further combination mode  . A good example of a categorial grammar that employs both functional application and functional composition is Steedman  ( 1985 )  . Forward functional composition permits the following combination of categories :  ( 21 ) A/B + B/C = A/C The resulting category inherits the argument place for C from the argument B/C  . 
Neither Steedman's nor any other CGI amaware of permits functional composition i its full generality  . In order to prevent overgeneration , functional composition as well as other combination modes that are discussed by Steedman are restricted to apply to certain categories only  . This somehow violates the spirit of a categorial grammar  . Steedman's combination rules , for instance , are netuniversal . 
In CUG , functional composition is subsumed under functional application  . It is the functor category that determines whether simple functional application  , or functional composition , or either one may take place . 
Conjunction is a good case for demonstrating the versatility  . 
Consider the following sentences : 3 ( 22 a ) Peter and Paullike bananas . 
(22b ) Peter likes bananas and Paul likes oranges.
(22c ) Peter likes and buys bananas.
The conjunction and may combine two simple argument categories  ( 22 a )  , two functors with one unfilled argument position ( 22b )  , or two functors with more than one unfilled argument position  ( 22c )  . If the conjuncts have unfilled argument positions  , the conjoined phrase needs to inherit them through functional composition  . 
The simplified lexical graph for and is given under  ( 23 )  . 
In order to avoid a thicket of crossing edges , I have expressed some of the relevant bindings by indices  . 
191(23) c ~ .. r (
The most appealing feature of this way of utilizing functional composition is that no additional combinators are required  . No restriction on such a rule need to be formulated  . It is only the lexical entries for functors that either demand  , permit , or forbid functional composition . 
Extensions to the formalism that I have experimented with that cannot be discussed in the frame of this paper are the use of multiple stacks for leftward and rightward arguments and the DCG-like encoding of the ordering positions in the graphs  . In Sections 3 . and 4 . , I will discuss further extensions ofthe formalism and specific linguistic analyses  . The following section contains a summary of the motivations for working on and with CUG and the main objectives of this work  . 
2 . Motivation and Theoretical implications Both terms  , unification grammar and categorial grammar are used for classes of grammar formalisms  , for individual grammar formalisms , and finally for grammars that are written in these formalisms  . In addition , they might also be used by linguists to denote linguistic theories that are built around or on top of such a formalism  . This is the type of terminological overloading that linguists have learned to live with--or at least gotten accustomed to  . 
As I indicated in the previous section , I consider CUG to stand for a family of grammar formalisms that might be described as the intersection of categorial and proposed so far is therefore not a new grammar formalism and even less a linguistic framework  . 
The proposal is simply to further explore the usefulness and formal properties of subclasses of CUG  . 
This proposal can be supported by a number of reasons  . 
Both types of formalisms have clear advantages.
Categorial grammars have been hailed for their conceptual carity and their potentials for l inking syntax and semantics  . The fact that they have been around for along time and that they are currently enjoying a renaissance in the works of Steedman  , Bach , Dowty , and many others demonstrates their virtues . Unification grammars are spreading last and lend themselves to powerfifl but efficient computer implementations  . 
Traditionally , categorial grammars have been lacking syntactic sophistication  . In a functor category such as A/B , only domain and range of the function are specified but nothing is said about bow they are related  ; how , for instance , the features of the argument influence the features of the value  . The graph notation expresses the relation between argument and value categories quite well  ; it is expressed in a set of bindings between subgraphs of the two categories  . 
In the context of this discussion , some remarks are in order on the specific role PATR has played for the experiments with CUGs  . The philosophy behind the development of PATR has been to provide a tool for writing  , testing , and comparing grammars of very different types in a powerful formalism with well-understood formal properties and a well-defined semantics  ( Shieber 1984 )  . 
Thus PATR could be useful for writing grammars , design in grammar formalisms , and for exploring classes of such formalisms . The work on exploring categorial unification formalisms has not only benefitted from the features of PATR but it has in a way also influenced the development of the PATR formalism  . It was , for instance , essential for the writing of categorial grammars to allow category variables in the contextfree phrase structure part of the rules  . How else could one formulate the rules of functional application  . The implementation f this facility through Stuart Shieber  , however , raised interesting problems in connection with the prediction aspect of the Earley-parser  . Original Earley prediction works on category symbols  . An answer to these problems was presented by Shieber  ( 1985 ) who proposed to do Earley prediction on the basis of some finite quotient of all constituent DAGs which can be specified by the grammar writer  . 
Another example for the influence of the CUG efforts on the development of PATR is a new template notation introduced by Lauri Karttunen in his Interlisp-D version of PATR  . Since categorial grammars exhibit an extensive embedding of categories within other categories  , it is useful to unify templates not only with the whole lexical DAG but also with its categorial subgraphs  . The @- notation permits this use of templates ( Karttunen ,  1986)3 3 . ACUG Grammar Model that Aecomodates Word
Order Variation
Worder order variation has always been one of the hardest problems for categorial grammars  . Functional composition together with typeraising can be used to obtain all permutations of the sentences that are generated by a traditional categorial grammar  . Totally free word order does therefore not pose an unsurmountable problem to the categorial approach  . As with other types of grammar formalisms , it is semi-free word order that is difficul to accommedate  . 
GPSG , LFG , and FUG all have mechanisms for encoding ordering regularities  . Such a device does not exist in the categorial grammars that i am aware of  . 
However , Uszkoreit (1985 a , b ) argues ( on the basis of data fl'om German ) for an application of l/near precedence rules to the valency list of syntactic functors  . 
This approach presupposes that the valency list contains adjuncts as well as complements as the flmetor's syntactic arguments  ) The model can be summarized as follows . The lexicon lists uninstantiated ntries . For functors , these entries contain a set of thematic roles . The uninstantiated lexical entry may also state whether thematic roles have to be filled  , whether they may be filled more than once , and whether idiosyncratic properties of the fnnetor predetermine the syntactic features of certain syntactic arguments  . 
There are three types of rules that instantiatel xical entries : feature instantiation rules  , valency instantiation rules , and order instantiation rules . 
An instantiated functor has an ordered valency list containing syntactic specifications of complements and adjuncts together with the appropriate semantic bindings  . The model can account for the interspersing of complements and adjuncts as they occur in many languages including English  . The model can also account for right -extraposition phenomena  . 

Therefore , the valency list may constain adjuncts that do not fill a thematic role of the functor but combine semantically with some constituent inside a linearily preceding member of the same valency list fi In the proposed model  , the dependency between the extraposed phrase and its antecendent is neither established by functional application/composition nr by feature passing  . It is assumed that there is a different matching process that combines the noncontiguous phrases  . A process of this kind is independently needed for the matching of adjuncts with thematic roles that are embedded in the meaning of the functor :   ( 26 a ) Tellme about French history . 
(26b ) Start in 1700.
The year 1700 is obviously not the start time for the telling . 
(27a ) Hiscall was very urgent.
(27b ) lie tried desperately from every phone booth on campus  . 
It is not try that supplies here the source role but the implici theme of try  . If the theme role is filled , everybody would analyze the from PP as semantically belonging to the theme of try :  ( 28 ) He tried to call her desperately from every phone booth on campus  . 
I want to conclude this discussion with a remark on the parsing problem connected with the proposed model  . 
In older PATR Phrase Structure grammars as well as in the categorial PATR grammars  , all graphs that may be connected with a word in the input string are either retrieved from the lexicon or from a cache of a h'eady built lexical graphs  , or they are constructed on the spot fi ' om the\[ exical entries through the morphology and through lexical rules  . 
For obvious reasons , this approach cannot be used in conjunction with the categorial model just proposed  . If all adjuncts are included in the valency list , and if moreover all acceptable linearizations are performed in the extended lexicon  , there is no upper bound on the number of acceptable lexieal graphs for functors  . This means that lexical entries cannot be fully instantiated when the word is recognized  . \]' heyneed to be instantiated incrementally as potential arguments are encountered  . 
In Uszkoreit ( 1985b ) it is argued that the ordered valency lists of a functor admitted by the lexical \[ nstantiation rules form a regular language  . \[f further research confirms this hypothesis , the incremental nstantiation fvalency lists could be performed through sets of finite state machines  . 
193 4 . A Note on Long-distance Dependencies in CUGs In Steedman's  ( 1985 ) categorial grammars , long-distance dependencies are end coded in the function-argument structure of categories  , The categories that form the path between filler and gap in a derivation tree all carry a valency slot for the filler  . This uniform encoding of both subeategorization and long-distance dependencies in the argument structure of categories seems at first glance superior to the HPSG or PATR approaches to long -distance dependencies  , in which the two types of information are marked in different feature sets  . However , it turns out that the Steedman grammars have to mark the long-distance valency slots in order to distinguish them from other valency slots  . 
There could still be a justification for encoding the two types of dependencies in the same argument stack  . 
One might loose important nesting information by separating the two types of slots  . However , I have not yet seen a convincing example of nesting constraints among subcategorization and long-distance dependencies  . 
Therefore , I consider the question of the appropriate place for encoding long-distance dependencies still open  . 
A last remark on long-distance dependencies . In a unification based system like PATR it is not trivial to ensure that gap information is passed up from one daughter constituent only when a rule is applied  . There are two ways to enforce this constraint . The first one involves a multiplication of rules  . For a binary rule A-->BC , for instance , one could introduce three new rules , one of which does not do any gaP passing , another one the passing of a gap from B to A , and the third the passing of a gap from C to A . 
PATR uses a little more elegant method which has been first suggested by Fernando Pereira  . Two features are threaded through every tree , one of which carries a gap up a tree , passing through all the constituent so the left of the gap  , and a second one that is set to NIL if a gap has been found and that is then sent through all the constituents to the right of the gap  , unifying it on the way with potential gaps . It requires that information about the two special features be added to every rule  . In PATR a preprocessor f rules adds this information for all rules in which the grammar writer did not include any gap threading information herself  , e . g . , for encoding island constraints . 
In a CUG that only contains two ( or at least very ? few ) rules , the first method of duplicating rules appears preferrable over the gap threading approach  . Rules that propagate gap information might also include rules that permit parasitic gaps along the lines of Steedman's rules of functional substitution  . 


Bar Hillel , Y . (1964) Language and information . Wesley , Reading,

Johnson , M .   ( 1986 ) " Fronting and the Internal structure of the VP in 
German . " ms . Stanford University.
Karttunen , L .   ( 1986 ) "D-PATR : A development environment for unification-based grammars  . " in this volmne Shieber , S . M . , If . Uszkoreit , F . C . N . Pereira , JJ . Robinson , and M . 
Tyson ( 1983 ) " The Formalism and implementation fPA ' PR-\[I" in : Research on Interactive hcqui ~' ition and Use nf Knowledge  . 
Artificial intelligence Center , SRI International . ~, lenlo Park,

Shieber , S . (1984) " The Design of a Computert , anguag c , t br Linguistic Intbrmation . " in Shieber , S . , L . Karttunen , and F Pereh'a ( eds . ) , Notes fi ' om the Unification Under ground A Compilation ~ f Papers on Unification  . based Grammar Formalisms , Technical Note 327 , SRI-lnternational , Menlo
Park , Cal
Shieber , S .  1985 ) " Using Restriction to Extend Parsing Algorithms For Complex Feature Based Formalisms  , " in : Proceedings of the
ACLI985.
Steedman , M .   ( 1985 ) " l ) ependency and Coordination in the Grammar of Dutch and English  . " Language 61:523-568 . 
Uszkoreit , H . (1982) " German Word Order in GPSG . " In I ) . 
Flickinger , M . Macken , and N . Wieg and ( Eds . ) , Proceedings of the First West Coast Conference on Formal Linguistics  , Stanford
University , Stanford , California.
Uszkoreit , H .   ( 1985a ) " Problematische Konstruktionenffikontextfreie Phrasenstrukturgrammatikendes Deutschen  . " in Klenk , U . ( Ed . ) Strukturen und Verfuhren in der maschinellen Sprachverarbeitung  , AQ-Vet lag , Dudweiler Uszkoreit , H .   ( 1985b ) " Linear Precedence in Discontinuous Constituents  . " paper presented at the Conference on Discontinuous Constituency  , July 1985 , Chicago ' , Illinois ,   ( to appear in Syntax and Semantics 201 Uszkoreit , H . 1986) " Constraints on Order " CSLI Report 46 , Stanford University ( also to appear in Linguistics . )
Notes * The research for this paper was made possible through a gift by the 
System l ) evelopment Foundation.
tFo ran introduction to the family of unification grammar models refer to Shieber  ( for thcmning )  . A good introduction to the basic notions of categorial grammar is Bar\[tiliel  ( 1964 )  . 
2The PATti implementations that arc currently used at SR \[ actually permit cyc lic graphs  . 
: I Right-Node-Raising ( RNR ) which leads to sentences a : Peterlikes and Paul buys bananas will be neglected here  ( although RNR is an attractive lopic for catcgorial grammarians and one of my grammars ~ ctnally handles many cases of RNR  . ) IAn even lilt ) regeneral notation can ) e used that does not distinguish between root templates and subgraph templates  . As long as template names are marked by some typographic onvention  . 
could be freely used wherever a graph is described.
~ The version of t!le linear precedence rule component proposed b ~ Uszkoreit  1982  . 1986) is \ tlI > compatible with this approach . The . , proposal permit > the formalization of partially free word order as\[t results fl ' om the interaction of potentially conflicting ordering principles and as it probably occurs to some degree in all natural languages  6Sag   ( 1985 ) proposes a mechanism for IIPSG that allows the syntactic binding of an extra poscd phrase to a complement or adjunct slot of a complement or adjunct  . However , this approach is too restricted . Although there is a strong tendency to only extrapose complements and a diunets of toplevel complements and adjuncts  , there is certainly no such constraint in languages like English or German  . The following sentence could not be handled since the extraposed relative clause modifies an adjunct of the subject  . 
Petitions from those people were considered who had not filed a complaint before  . 
7 Mark Johnson ( 1986 ) has worked out a quasi-categorial solution of this phenomenon in the framework of HPSG  . 
