
MET APRINT 3
( META MET APRINTI)
Responses to " COMPUTERIZEDLING UISTICS : KALFA COMMENTARY " 
- Martin Minow-
Rather than attempt a summary of the replies to " metaprint "  1 included here , I feel it would be more useful forme to d is cuss one of my programs  . 

The program generates sentences from a gener at ive  ( context-sensitive , transformational ) grammar . It is almost identical in function to that p re-sented by Joyce Friedman in preprint  14  . 
LANGIJAGE
While I had previously written a context-f ree generator in assembly language  , these programs were written in SNOBOL3 , which is intended specifically for st ring processing  . There were both advantages and dis-advantages inherent in this choice  . The language provides simple , power-ful operations for parsing strings and allows easy defination of pushdowns tacks and lists  . In addition , a primitive was available which re-cogn izes strings balances with respect to parentheses  , Because of this , I chose to represent trees as fully parenthes ized strings  . What is more important than this is the fac t that SNOBOL manages all storage auto-mat ically  , Thus the program has almost no pre-defined l imits  , The major disadvantage of my choice was that I was completely in-experienced in the language and unfamiliar with the recursive techn iques permitted  . Thus the program was extraordinarily ineffic i ent  , 
THE PROGRAM
Bot the context-sensitive generator and the transformations program were written in two separate step ts  , one converting the rules from a form as similar to that used by the linguist as possible to a fo rm convenient for storing on the machine  . In general , all rules containing abbreviatory devices ( braces and parentheses ) were expanded to a number of subrules . These were then punched out and used as input to the gene-rator itself  . The size of the programs is
CF generator ( assembly )
CS rule reader
CS generator
Transformations " rule reader
Transformations executor 2500 cards 300 statements ~ 360  ~  280  -  600 In addition , each program contained . approximately one comment for each 4 statements since this was the only way I could understand what I really intended to write  . These were written as the program was writ ten and proved invaluable  . I should note that I generally over-document my programs as r tend to borrow algorithms f rom them years later  . 
lz
DEVELOPMENTTIMES
The CS program took about six weeks to get run n ing while the trans-for : ' ~ a tions program ! ook the better part of four months before it worked well enough that I could a ttempt to transform a " real " sentence  . Due to personal reasons , I was unable to debug the grammar/program wel lenough to consider distribution  . The cost of processing a real tree was also prohibitive  ( 20 minutes at 7094 time )   . I again note that this was caused more by my in experience with SNOBOL than by any faults inherent in the language  . The work could hardly be done so quickly in assembly language or FORTRAN as I first wou ld have to write a large set of subroutines for string handling  , input-output , etC . 
INFLUENCE OF THE LANG UAGE
The strongest external influences on the program was the fact that data must be punched on cards  . Thus a two dimensional notation , as used by From kin and Rice ( preprint 53 ) for example , seemed too diffi-cult to program to war rant the effort  . Trees and rules thus must be written in al in earmanner  , using parentheses for structure identifi cation  . 
(Though the programmer may indent i tems when punching  .   ) Any other limitations were primarily caused by my in experience  . Note especially that there is no limit at ion on the number of characters in a string  . 

Until I found out about Friedmanls program ( preprint 14 ) I had considered rewriting the transform at ions program in  SNOBOL4 -- a string processing language similar to  , but incompatable with , its predecessor . It seems , however , that only the algorithm ( preserved in the commentary ) could be transferred as SNOBOL4 s increased capabilities allowed a much more efficient approach to tree parsing  . 
OPERATING SYSTEMS
While it would be very nice to be able to generate sentences in a time-sharing envi ronment  , If eel that the Ianguages currently availab le and especially the amount of work that must go into interfacing programs with operat ing systems preclude any such effort at the present time  . One solution is to have full control over a small computer  , however , this may excessively limit the size of the program  . While there doesn't seem to be any clear- cut answer  , I seem to be reluctantly choosing the power and nit-picking of the large operating system so as not to limit the programs  . I hope somebody convinces me that I am wrong . 
i3\] open hagen ~28th August 1969.

It may bc too late for you to include this in your summary  , but now it's writte ~ Is end it any how . 
The first step in the investigation reported in my paper  , CA3 . 3, is a urogram for sorting e . text into words and word delimiters , and ~ hus qualifies as a data processing program  . In my vie : v , this pro-gram presents the features you are interested into ~ higher degree th~n-the fo llowing programs which are < ~ atamatically much simpler  , involving only m cnipulations of the numer ical codes for words and ?~ etermlned by the f irst progr ~  , m~-L in ~ ulstically of other symbols a ? course the later programs contain all the essent i als  . 
Th , ~ . , ~ ai : ' ~ m-r ~ ~ va . ~ izble tome , ,at Cooenhagen Un ivers i ty is a GiZR (~ ; ~_ : ish make ) with a central store of -409640-bitc , L!s ~ n ? po~iphe--r < ~ lstere of ab . 30000 Oc~l!s . Programming is done in Llgol with , -::-~ ensio:z ~ which make the single bits of each word easily nccessibie  , T . hc datam ~_ t has no opera . to t , but is aveilab ! o to the personnel of se- , e::'ol"~"-'"~~-Jn~i ~ u~c ~ which undoubtedly contributes to more ~ reoue-_t " ethnical break downs then comparable operator-managed data mats have  . 
The text v . - ~ oh J-mined on 6-pocitic np . r . per % ape , , ' id ~ outpari ' ~:; chc3k , ~ . ndit " ook some ingenuity to convert it to the usu  . < i8 . ? pos--i-~io: . \]~: p e .   . ~ ll the same it is much che , ~ per to get the text outhese T , z'intf . ngnrckinooroduce , ? tapes than to cod ~ . thema :* ev ;, The convc,~'ionw,~sm . ~,\] enott of ! exov : rit crcode , but, .   . , ithlet % arscoded in ~""~' ~ . \] p:: . .  . . . . . I ~ order , ' a = 1, b = 2 etc ) o . nd other symbols with v nl-resf co ~ ~ . .~ un:7:- . r<i3 . . ' . word ~ .   .   .   .   .   . ' efined nsa ~ qu~o ~ . . . . . . . of letters at : nest inte : :' rup ~ ed ~', . , n .   .   .   .   .   .   . lower c~esy~2 bc ! after the first ; and each " cO to , m--~: fou:~?::n . the t_~:: t is first store , 4 in . ' . u ~ r ~ . v(zzle ~:; Lb be on the saic . . . . . . ) . Who : la non-letter symbol is found the word is then conver-'e  , ~ to storage for ~: ~ . :5 letters arc plnc , ,q in the f i rst 25 bitu of " c ~- i i t : . : n ,:: . : tt ',; ob"~si:'/5 . oatr ~ whether ~ . h . . word hzs no more th,<~z 5 - c ca~ . ' rs , ' . znd if not . . . . . th . ,_ ~ , ~ lS is the first part of the word or , '-~ , i , q'tqr~I / ! bits are left empty if it is the fi rstpc ~ r % of the word ~  el2o t': . o:~:~-~'i . ": t+ei::'-r-~c % c:red~:~ndone bitind icates whe~her it is "~' ~  ,  . ~, . en ! ~ . ~-14~o , , , .  ', . - oi '( i ~ . ._ not , . 
I . ,'o: . vco : , , es\[:\]te , :' J . otior . .~,t . / l , ,'~ok--uD - : , : ! i tho , word stored like describ-ed the alp ! nbetio order in  , q coincides with ~ z numerical ordering whe'ncells-ire interpreted as integers  ( % he\[ , it which in inte~ei~mode ind-icates sign is ~ l  , ' . ,e . ysie ? tempty ~ i , e . as + ) ~ The dictionary is stor-ed in an array of lorsth  3?90 to c\] . \] on , room : for other variables in - o ! uding the word mrm ' ayo ~ loncth  60 men-~i- . r . adabo'?o ~ it is numbered 201A000~-r~zser . s " . Each ~ e , : r word found is -_ . o . exp\] . a-\[neainl-~:ep , 1 . 1 ur - .   . 
s-bored under t '_ , efiz-sbvacen , t " ltt:qbe ? ?;" . 11 d : ?<; er , ' ? occurrence of it is indicated by this number in the output  . 
%' healph ~ . bct Joor/crime : :_sta\]:encare of by list pl ' oo essing " the vacant  12 bibs in the first part of a word : is usc ? to store the number  , of the next war ( ! in zlphn batic order . To avoid having l ; o , Zoth rouc-h-~he , Thole dictionary an index is kept of init if ~! s indicmting the nuzTbcr of the first word with each initial  .   ( Some reduction of search time ceul c~undoubted lybe obtained if ~ he initiols were sub-d ivided by the value of the next letter ~  ) Theou % ~ a % of -6he program consists of the dictionary , number and letter sequence for ca . oh % ~ ord ~ ordered either by numbers or alpha -beticel ! y  , and the processed texts Zring , words given by their number above 200 , other symbols by their number below I00 , depending , on the ~ aiue of ~' ~ l ; ' q t case symbo ? , , space w-ich only separates two words is suppressed ~ other possibilities of reduct ion do not vresen % nearly the same reduction of space requirement  . ) -2-14? In this way , the central store will hold a dictionary of ab . 
2500-3000 words ( words up to 5 letters take one cell , with 612 letters they take 2 oells , 13193 cells etc . ) which in a unitary text will hold all but the very infrequent words  . 
The program builds heavily on the type of data mat used  , only the most general principles will be transferable  . Some slight alter at-ions have bennnecesse ~ ry to enable the program to be run on another data mat of the same make which is operator-run  ( but still totally without time ? sharing or similar devices  )  . I cannot to any degree of accurm cy assess the initial time used for programming  , ~ ich was not excessive , or that for debugging , which was considerable . Both parts of the work ~ reredone over along period in b~tween other work  . 
Gust ~ v Leunbach
Answers to questionnaire ~5
Type of Project : Modelling of Linguistic System Language : Assembly language  , IBM 360/65I , 5DOK(h . s . ) The computer used works in a time snaring set up  , in which we are one of ~ number of users;
No comversational methods are used.
Ch~ice of Language : Owing to the fact that 50~ of t ~ e central core storage is permanently occupied by the time sharing system  , the space available to our program is only 20~ to 251 K ; this is barely sufficient ; hence , in order to compress the job as much as possible , the entire application was programmed in assembly language  . The formulation of the problem and the program , therefore are in many ways influenced or , rather , determined by the charact-eristics of the part icular machine  . 
Development time : The flow charting , defining of algorit J~ms , and linguistic research had all been done previously  , in three years work , for another machine GE 425 ; the time required to remodel the entire applica -tion for use on the IBM  360 was approximately 3 months . -The linguistic approach and the algorithmic formulations it requires and makes possible are highly unorthodox and  , therefore , not at all suitable for formulation in an exist ing high-level language  . 
The system works without vocabulary lobk-up ; the sentences to be analysed are input on punched cards  ; such storage of words as occurs during the analysis procedure  , is achieved by numeric code . 
There are no character manipulation subroutines ; input and output definition is in IOCS . No extern-alst orage is used . 
The program is thoroughly defined by the sequence of operations determined by the linguistic procedure  . 
5inca the appl icat ion is exclusively experimental  , there is continual exchange end modification of both program and algorithms  ; end the program was written , from the outset , with this in mind , i . e . 
allowing for easy alteration in many areas.
Notes comprehensible only to the programmer who devised the program  . 
165 izo of Program : 3200 instructions , no commentary . 
The modQl 360 we are using disposes of approximately iBO machine instructions  ; the Multistore progra ~ employs no more than 30 of these ( of which about 6 or 8 could be reduced to others , so tha ~ the total of used instructions could be brought down to approximately  22  , or 12~ of the instructions available in the machine )  . 
This is a typical symptom of the situation of l inguistic  , artificial intelligence , artificial perception , etc . , programming in general : the machines actual ly available are far too compli-cated  , i . e . they can do in numerable things which are not needed in that kind of program  ; on the other hand , machines specially designed for these tasks would have to have larger central cores  . 
No doubt processing times could be greatly shortened on special purpose machines  . 
Time sharing : Yes . If we had a console in our office , it certainly would save time . 
Job Control: 5ince the computer has to be used by other people and for other tasks as well  , one has to accept job control ; if we had a computer exclusively for this part icular use of ours  , we should do away with job control . 
Change of Machine : Since the program was to some extent determined by the particular machine  ( capacity , byte configuration , etc . ) we are using , it is not transferable to another type . Being purely experimental , this was no . ._~t an objective . 
Language : Yes . The requirements beings overy specific ( see above ) programming in a machine oriented language is essential  . 
Teaching : No.
Linguist Programmers : No . The analytical work to be done to understand the workings of natural language is still so enormous that they should not scatter their attention and efforts  ; they should , however , have fairly clear ideas about what can and what cannot be implemented on a computer and  , above all , how minutely all formulations of linguistic rules have to be defined  , if they are to work satisfactorily on a computer  . 
L4, 192912th Street-Apt.A
Santa Monica , California 90404
August 26, 1969 ( preprint number 53)
In reply to some of your ideas expressed in " Metaprlnt "  , I - , -semdlng a brief history of the phonological testing program  ( seep reprlnt #53 )  . The program has been through several translations and parts of it have actually run on two machines  wh?1e other parts have not yet been coded . 
? he project began about a year ago , when a fairly simple program ~ ms written in Super Basic on the Tymshare  , Inc . time sharing system . That program accepted a single test form , placing it in a binary matrix of feature values . Rules were written directly in SuperBasic coding  , performing the desired operations on the bit matrix  . Later in the school year we decided to try to set up a similar system on the IBM  360/91 on campus and the SuperBasle program ~ s rewritten in PL/I  . This program was still simply a rule executor and the rules had to be coded in PL/I  . 
IM\[ffi ~' ultles with the IBM system led to the abandonment of this project  . There were two main causes here which lead into the current system called PHONOR  . First , I was completely turned off by the IBM system performance  ( 91 means 91% downtime )  . The more important reason , however , is that I wanted more flexibility in the scope display than the primitive batch job system allowed  , Durlmg thet ~ ume the proErem was being rewritten in PL/I  , I was think lnEmore and more about a better system of rule specification aQd input than coding in a standard computer language  , not very suitable for a linguistic researcher to use the system  . Some earlyth ~ aklng about the string matching process and a gradually Improv?ng knowledge of Chomsky and Halle's SPE led to a rule cumpiler a ~ or ltb ~ which accepted a string of text stating the rule us ~ a notation quite similar to the SPE format and produced as output all st of matching proCess operations  . I soon realized that these mate hlng operations could be coded and stored fairly compactly as they were produced by the compiler and then read by a separate rule interpreter syst ~ which contained the test matrix 
Martin Minow 2   26 August 1969   f8 and performed the matching operations in the order in which the compiler had stored them  . This led to the present system written for the LINC-8 in our lab . 
Input to the compiler will be either from the telety pecr from a specified file on disk or mag tape  . The input rules may be displayed on the scope in a two-dimensional format very close to the SP__EE formalism  . This input may he edited , compiled or saved in a file . When the interpreter is loaded ( by a single c~mm and to the compiler system ) the most recently compiled set of rules is loaded  . Operation of the interpreter is under complete interactive control of the linguistic researcher at the console  , who may enter test forms , specify which rules to apply and set crreset flags for various print out options as the interpreter runs  . 
The compiler may also be recalled at any time.
I have not added substantially to the basic compiler algorithm since writing the conference paper  . I have worked out a subroutine generation system to take care of the case mentioned in the last paragraph  . Actually most of the coding in the compiler is ( will be ) concerned with more mundane house keeping tasks such as input text manipulation and sett lnEup storage for the coded output  . 
As the program nears completion , I will definitely have clearer documentation of its structure and capabilities  . It end to avoid this as most progra~ners do unless I can get it done while I'm in the mood of blowing my horn  ( as now )  . Then it flows out pretty well . 
I hope to remain responsive to suggestions as the program is used and desire to make it available as widely as possible  . 
Since rely yaurs,
D ~ : k s c
FHONC <19
The Ln % eract tvePhor , ole ~ ic/ulste ~
The heart of t~s system is a rule expr ~ ~ Jonlar , ~guage consisting of operations to be perforaed on the strir  4 of phonologl ca?n its stored in the test matrix . 
These operations are described in the paper using the PL/I language and comprise pushdown stack operations  , unit match instructions , matrix modification in str-uctions and various for = ~ of branch instructions  . The system actually consists of two parts ; I ) Auompilor , which reads the rules as they are entered and translates them to the rule expression language  , and II ) An interpreter , which contains the test matrix , accepts at % st string from the consolear ~ interprets the rule expression language  , modifying the test matrix as indicated by the rule coding  . 
PHONOR is now being written for the Digital Equipment Corp  .   LINC-8 with two llnctape units and 8K of core memory . The interpreter is written in PDP-8 machine language and is now completed . The compiler is bein ~ written in LINC IAP-6 assemb ~ language and will be running some time in October  ,  1969 . One memory field ( @K ) is dedicated to storage of the rule expression coding when the interpreter is running  . 
I expect to get 30 to 40 average sized rules in the memory field . Additional fields of r~les may be stored on Linctape and read in under program control  . The present system has an upper limit of 128 rules . 
One item described in the paper which the present system will not  . support is the notation " " X " , meaning any string of units not contain lng the boundary symbol "#"  . This would require a more complex matching algorithm than I have yet worked out  . If it appears that such a notational device is useful it will be considered as a future extension  . I hope to be able to include in the near future the capability of handling indexed disjunctions  ( angle brackets in Chomsky and Halle , SPE ) . 
This brings up a number of questinns relating to disjunctively ordered rules  ( as in SP~E ) and the exact sequence of matchir ~ gun its within a rule  . PHONCR treats disjunctions somewhat differently than the system of SP__~ in that computational efficiency is g~ven priority over descriptive efficiency  . I think it is a shortcoming of the current ideas on descriptive simplicity in a gray  , nat that dynamic computational simplicity is not taken into account  . It is my hope that future use of the PHONO ~ system will help in setting up new models for overall operation ~ lsimplicity in the phonological component  . 
For more information on this system , write to
D . Lloyd Rice
Phoneti ~ Lab , Humanities Bldg . 1110

Los Angeles . Ca . 90024\[nONHALL
D ~ pART ~ RNTOFCO~d PUTERSCIENCE
CORNELLUNIVERSITY
ITHACA , N.Y . 14850
Telephone (607) 25~4117
August 18, 1969
I refer to your metaprint entitled " Computerized Linguistics "  . 
For your information I should like to answer the questions which your aise inso far as they apply to the SMART document retrieval system : i  . The SMART system is infox ~ nation retrieval oriented  . 
2 . The system is programmed fop a batch processing computer  ( IBM 360 model 65 ) largely in Fortran IV , with some of inner routines and executive programs in assembly language  . 
3 . The choice of language was determined by the programming systems available with our computer and the preferences of the programmers  . 
4 . The planning , flow chart lng , and programming took approximately thmee years from  1961 to 196~  , and a total of approximately i0 man years . 
5 . The total number of programming steps ? assembly language instructions  ) is approximately 150 , 000 . 
6 . The proET am is not easily transfer Table onto another machine  . 
7 . For many years I have been teaching a graduate course entitled " Automatic Information Organization and Retrieval " in which linguistic analysis  pr6cedumes are used . 
I should heglad to participate in the panel session if it is held within the first couple of days of the Conference  ( since I must leave early )  . I shall be glad to amplify on the comments given above  . 
Sincerely , t ~ t ? ~ k Gerard Salton

Computer Science

G . Veillon Zi
I-PROJECT Mechanical translation
The program is used both for actual processing and for testing linguistic models  . 
A complete program is running on an IBM 7044 computer ( 3 ZK memory ) and a new version is being written for the
IBM 360-67.
II-LANGUAGE
Programming for the 7044 were written in IV ~ AP ( macro assembly language )  . The program consists of eight steps , along with a supervisor embedded in the IBSYS ( IBJ OB ) system which interfaces the different programs with each other and with input-output devices  . 
This is , of course , a batch-processing system.
In the new program , the most important algorithms , which have to be very efficient , will be written in assembler language . Auxiliary programs will be written in PL t . This program must run both under conversational mode  ( using Cp-Cms system ) and batch-processing mode . Conversational mode will be used for debugging and for testing linguistic models  , while batch-processing will only be used for production  . 
The language choice never influences the problem defination  . 
III-STRUCTURE of the program
The program is composed of eight different steps , each roughly corresponding to a particular linguistic model  . 
These are : -!- pre-editing
Z-dictionary look-up 3 -morphological analysis 4 -syntactical analysis 5 -tree transformations ( intermediate language )   6 -syntactical generation 7 -morphological generation 8 -post-editing !- the program itself 2 -the input text ( _ which is the output of the previous step )   3 -linguistic parameters : grammar and lex icography  4 -the output text . 
The last three are encoded to preserve program efficiency  . 
Grammars , for example , may be pre-compiled by a special subrout in e  . 
It is also necessary to provide auxiliary programs  ; giving input , output , and if necessary , intermediary results a human-readable fo rm  . 
Thus , we need to write two different types of p rograms  , tl~e processor--which must be very effic ient and is i usually quite short--IS wri tten in assembler language  . The auxiliary programs--which need not be particutarily efficient  , but must be easily modifiable--are wri tten in a problem-oriented language  , PLI . The tatter represent 60% of the programming work ( including compilers , text file updating , dictionaries , etc .  )
IV-TIMEREQUIRED
This depends on the nature of the step . In the case of syntactical analysis , probably the most important , the following roughly holds : statement of proglem : about two or three years defining data structures and system programming : six months programming and debugging the algorithm : one year programming and debugging auxilia ryprograms : one year computer time for p rogram debugging : ten hours  ( 7044 ) The complete 7044 program , including all eight steps , contains about 65000 machine instructions , 20000 for the program , 45000 for auxitiary routines . 

V-PROGRAM CONVERSION
After the 7044 progra~s " ~ edebugged , we began changing to the 360-67 . % % e are trying to convert all algorithms directly  . Thernoe , ~ important changes are relative to data managment  . We had many problems with tape devices for the files and feel that the direct- access capabilities of the newer machine w ill prove very useful  . 
In writing the first program , we were very cautious about programeffic iency  . While this is , of course , important , it did become very time consuming for the l inguistic debugging  ( of grammars ) and dictionary updating . This was partly due to batch-processing . With the new computer , we shall always use conversational node for debugging  . The program thus must be executable in both conversational and batch modes  . 
The most important problem is to make the fil es comparable under both systems  . 
PL ! seems to give us all the power we need , but we intend to limit iss use to auxili ary programs  . 
I think it is important to speak a little about artificial languages for linguis tics  . We were obliged to define special languages for this purpose  . 
In some cases , we wrote a compiler ; while in others , such as tree transformation , we used a sophisticated macro processor . Macro assembly is very attractive -- the operations being easy to define  , describe , and modify . 
In our case , language defining and macro . writing took only three months . Unfortunately , macro assembly is very slow and , in the case of the 360 , not sufficiently powerful . We were thus obliged to write our own compi ler  , instead of using the IBM software direct ly  . 
