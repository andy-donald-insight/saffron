Tagging for Learning:
Collecting Thematic Relations from Corpus
Uri Zernik and Paul Jacobs
Artificial Intelligence Program
GE Research and Development Center
Schenectady , NY 12301


Recent work in text analysis has suggested that data on words that frequently occur together reveal important information about text content  . Cooccurrence relations can serve two main purposes in language processing  . First , the statistics of cooccurrence have been shown to produce accurate results in syntactic analysis  . Second , the way that words appear together can help in assigning thematic roles in semantic interpretation  . This paper discusses a method for collecting cooccurrence data  , ~quiring lexical relations from the data , and applying these relations to semantic analysis . 
1 Introduction
Two text processing problems rely heavily on cooccurrence patterns - the way that words appear together  , possibly idiosyncraticly . First , statistically weighted cooccurrence information can assist in the " bracketing " of noun groups  , which can otherwise lead to a eombinatoric explosion of parse trees  \[1\]  . 
Second , cooccurrence rlations can provide evidence of semantic information for thematic role assignment  , an important ask that is otherwise fraught with in accuracy  . 
Only cooccurrence patterns collected over a corpus can help to determine which is  . object and which is recipient in PAIDDIVIDEND ( ISSECURE ) vs . PAIDSHARE HOLDERS ( ARESATISFIED) . A sufficiently rich lexicon would include the semantic preferences for distinguishing these thematic roles  , but such a lexicon does not yet exist . 
Cooccurrence patterns are a means of probing a global corpus for clues that help resolve ambiguity at the local sentence level  . Patterns such as PAIDTOSHAREHOLDERS and PAID THEMTHEDIVIDEND are detected in the corpus at large  . Through these latter examples , in which the distinction between recipient and object relative to the dative verb PAY is made explicit  , the former cases in which tile relation is implicit can be resolved  . 
In contrasto previous work which addressed the identification of surface relations  , i . e . , SVO triples \[2\] , in our work we address the acquisition of semantic relations  , focussing at the assigment of thematic roles . 
This task ( i . e . tagging for acquisition ) requires high reliability and so it relies less on statistical properties and more on deterministic local marking  . 
In this paper we discuss a technique for parsing and semanticly analyzing complex sentences with the aid of cooccurrence relations  , and show how these relations are acquired from tagged corpus  . 
1.1 The Phenomenon
Consider , for example , the sentence below , taken from the Dow-Jones newswire :
THELARGEST CO ~ iPANY ONTHELIST,
WHICHLAST PAIDSHARE HOLDERSINJANUARY,
SAIDTHE 5 PCSTOCKDIVIDEND WOULDBE
PAYABLE FOLLOWING THE PAYMEN TO FTHE
CASHDIVIDEND . ( DJ , October 27, 1988)
For this sentence , which is not exoticor unusual in its complexity , there are 24 nontrivial different parse trees . Human readers , in contrast to most programs , can quickly identify groups of words that " hang together " such as COMPANYPAIDADIVI-DEND  , STOCKDIVIDEND , and CASHDIVIDEND , and use these clusters to understand the sentence unambiguously  . Moreover , a human reader can easily recognize SHAREHOLDERS as recipient and DIV-IDEND as the object of PAY  . Along these lines , our program develops the capability to identify such patterns by training on a large corpus of examples  . 
1.2 The Training Corpus
The training corpus , from which our lexical information is extracted , consists of more than ten rail-34 ilion words from the Dow Jones newswire ( 10 months worth of stories )  . For the root PAY , for instance , we collected more than 6000 examples , 20 of which are given below . 
To exploit this data , a system must transform common patterns into operational templates  , encoding a core relation between the words . The sections that follow describe the evolution and implementation of this acquisition technique  . 
2 Cooccurrence : Previous Work
Garside \[4\] and Church et al \[1\] provided a major impetus for this line of work . In Church's work , a collection of English collocations bootstrapped from a tagged corpus facilitated the construction of an adaptive " tagger "  , a program that annotates a text with part-of -speech information  . 
Frank Smadja \[7\] continued Church's effort by collecting operational pairs such as verb-noun and adjective -noun pairs  . Smadjaused these pairs to constrain \]\ [ exical choice in a language generator  ; for example , the system prefers " depositacheck " to " place a check " based on the frequency of cooccurrence of deposit and check  . 
Ido Dagan \[3\] pursued this topic further by projecting cooccurrences beyond the local context  , using collocations for anaphora resolution . For example in,
THECARWASDRIVING ONTHEROAD.
SUDDENLYITBRAKED.
CAR is selected over ROAD as the anaphor of IT , since CARBRAKE is a stronger collocation than ROAD BRAKE  . Interestingly , this idea complements Wilks'p reference semantics  \[8\]  , in which preference is based on a semantic hierarchy  . In Dagan's method , preferences are based on word patterns acquired from corpus  . 
Our work further emphasizes globM-sentence connections  . An example that highlights the use of cooccurrence is given on the next page  . 
THECHAIRMAN ANDCHIE FEXE CUTIVE OF FRANKL-IN FIRST FEDERAL SAVINGS ~ LOANAS SOCIAT-ION OF WILKES-BARRE  , \[SAID\]FRANKLINFIRST
FEDERAL'S PLANOF CONVERSION HADBEEN
APPROVED BYTHE FEDER ALHO MEL OAN BANK
BOARD\[ANDTHAT\]THEOFFERING OF COMMONS H RES INFRANKLINFIRST FINANCIAL CORP  . 
HADBEEN APPROVED BY THE BANKBO ARDAND BY
THESEC . ( DJ , 07-25-88).
What is the attachment of THAT?THAT could potentially attach to almost any preceding word  , e . g . , FEDERAL THAT , BOARD THAT , CONVERSIONTHAT , SAIDTHAT , etc . The affinity of the wordpair SAYTHAT ( although it does not appear in this sentence as a collocation  ) supports the appropriate attachment . 
Furthermore , cooccurrence relations support thematic role assignment  . This is important for our ultimate objective of producing more accurate conceptual information from news stories  \[5\]  . The text below illustrates one type of problem in role assignment : 
THELARGEST COMPANYONT HELIST,
WHICHLAST PAIDSHARE HOLDERSINJANUARY,
SAIDTHE 5 PCSTOCKDIVIDEND WOULDBE
PAYABLE FOLLOWING THE PAYMEN TO FTHE
CASHDIVIDEND . ( DJ , October 27, 1988)
Who paid what to whom and when ? Co-occurrence -based analysis generates lexical relations such assubj-verb  , verb-obj , and verb-obj2 , relations which are further mapped into appropriate thematic and semantic roles  . The program thus determines that COMPANY is the payer of PAID  , SHAREHOLD-ERS the paye e , and DIVIDEND the payment . 
3 Lexical Representation
An acquired lexical structure called a Thematic Relations  ( Figure 2 ) facilitates this analysis . For a pair of content words , a relation provides ( 1 ) a strength of association ( or " mutual affinity " )  , and (2) a structure type . 
This table is acquired from corpus by a tagger based on morphology and local syntax  . 
4 Extracting Cooccurrence
Relations from Corpus
The algorithm operates in three steps : ( 1 ) tag the corpus for morphology and part of speech ,   ( 2 ) collect collocations using relative frequency , and ( 3 ) use tagging to determine lexical relations within collocations  . 
4.1 Part-of-speech Tagging
Since the corpus size is about 10 million words , a fullfledged global sentence parsing is prohibitively expensive  , and tagging must be carried out by localist methods  , i . e . , by means of morphology and local syntactic markers  . There are three degrees of difficulty of cases to be tagged  . 
Morphology-based Tagging : Only a few words can be tagged using morphology alone  . While PAYMENT and SHAREHOLDERS are unambiguously nouns  , morphology-based tagging is ambiguous for most words  . For example , PAID and SAID could be either verb or adjective ( i . e . participle modifier ) ; STOCK and CASH could be either noun or verb . 

REEMENT , ITHASAGREEDNOTTO
DTHATITINTENDSTOCONTINUE
TIONSAND MODIFIYING DIVIDEND
A PATTERN FOR THE FUTURE . IT
JUNE30. THE COMPANYLAST
A10 PCSTOCKDIVIDENDTOBE
NINCOMEDIVIDEN DO F1 CASHR
AUG.1S . THE COMPANYLAST
UTTHESPECIAL DIVIDEND TO BE
CT .  21 . THE COMPANYLAST 10 PERSHARESPECIAL DIVIDEND
PERSHARE . THEDIVIDENDIS
TEDFORA5 PCSTOCKDIVIDEND
ERLYDIVIDENDOF 68.75 CENTS
TERLY DIVIDENDO F12CENTSIS
HESPLITAND THEDIVIDENDARE1 . 5 MILLION . THEDIVIDENDIS
FTHECOMPANYON ANY DIVIDEND
NTHEUPCOMING FINAL DIVIDEND
LDINGONE ADDITION ALDIVIDEND
PAYANY FUTURECASHDIVIDENDS , INCLUDING THE PAYING THEDIVIDEND .  -0- ;   11   08 AMEDT 07-22-PAYING ASTOCKOF 60 CENTSFORATOTALOF $1  . 
PAIDASPECIALDIVIDENDOF8CLASTYEAR . - O-PAIDA 7 . 5 CDI VIDENDON MAY 9 . GROWGROUPPAIDAUG .  18 . -0-;209 PME DT07-28-88:"? PAIDINFEBRUARY .  -0- ;   3   10 PMEDT 07-28-88: PAID AlOCSPECIAL DIVIDENDINS EPTEMBER 1987 PAIDFROM PROCEEDS OF THE SALE TO $6 ASHAREPAIDADIVIDENDOF 11 CENTSASHAREONJ ~ Y 2 PAIDTOSTOCKH OLDERSONJAN .  5, 1988 . TOPP









TOSHARE HOLDERS OFRECORDJULY 5.
AUG . 12 TO HOLDERS OFRECORDJULY 15.
OCT . IWILLBE PAYEDINTHEUSUALMAN
AUG .29 TO HOLDERS OFRECORDAUG .12.
SEPT . 14 TO HOLDERS OFRECORDAUG .22
AUG . 18 TO HOLDERS OFRECORDAUG .8.
DATEONORA FrERAUG . 1, 1990, FORTH
OF1 0.85 PENCE ASH ARE . HEIGHTENING
OVERA12-MONTH PERIOD . DUETHURSDAY.
Figure h PAY Sentences in Corpus 0 . 1 5   0   56   0   73   0   11   0   19   0   22   0   46 predicate : PAY predicate : PAY predicate : PAY predicate : PAY predicate : PAY predicate : PAY predicate : PAY subject : COMPANY object : DIVIDEND  object2:SHAREHOLDER object : MILLION object : CASH object : * number * PC object : TOPRATES Figure  2: Word Pairs Indicating Mutual Affinity and Themat icRoles  36   3 Syntax-based Tagging : Local syntactic markers help to remove most cases of ambiguity  . For example , was SAID ( read : the word SAID preceded by was ) can be unambiguously tagged a verb ; the PAID shareholders , is an adjective ; and the
STOCK is definitely a noun.
Statistics-Based Tagging : Taggers reported by  \[4  ;   1\] have capitalized on a large collection of bigrams plus statistically weighted gramma rules  . 
In this method , statistical properties are acquired from a large training corpus which was tagged manually  . Statistical methods have proved very effective , and attained a high level of accuracy \[6\] . 
4.2 Problematic Cases
Some cases prove even more difficult and cannot be resolved by localist methods  . Consider the following two examples . 
? " The company preferred stock PAID .   .   .  "  . In this clause , PAID , could be either an adjective or a verb ( see " the horse raced past the barn " )  . 
Indeed , this clause could probably be determined by a global parse  , however , this would be too expensive computationally . 
?" CONVINCING MANAGEMENT proved tough " is even harder since it presents a Necker cube situation  ( i . e . changing the interpretation of either word seems immediately to change the interpretation of the pair  )  . Is it an adjective-noun or is it a verb-noun pair ? In general  , the analysis of such pairs requires deeper understanding of word relationships  . Consider another example:
LATERINTHED AYBUYING INTEREST
DIMINISHED ...
Again , it is difficult to tell whether INTEI~EST in BUYING diminished or the BUYING of IN-TERESTs diminished  . Thus , local clues do not contribute towards the proper resolution of such  cc'~3es  . 
The incorrect resolution of such cases , which unfortunately are pervasive in the corpus , impinges on two objectives : performance and learning  . 
In order to perform text analysis , in the first case one must determine whether management was convinced  , or the management convinced some second party ; in the second case , one must determine the subject of the main verb of the sentence  , i . e . , which is the , subject of DIMINISHED ? Many applications require an unambiguous result  . Thus a call must be made one way or another . Statistical means might make that call slightly more judiciuos on the average  . 
However , when tagging is used for learning of thematic roles  , inappropriater solution of such cases can drastically contaminate the final results by biasing it in a certain direction  . Results are far more accurate when ambiguous cases are left out altogether  . 
4.3 Tagging for Learning
Our tagger is based on a 7 , 0 00-root lexicon that facilitates accurate morphological nalysis  , and about I00 local-syntax rules . It produces tagging for about 60% of the content words in the corpus . Tagged output for a sample sentence is given below  . 
THE///DTLARGEST/IARGE/EST/ADCONPANYI//NNoNIIIPP THE///DTLIST///ml*co~ma*///SPWHICH///CCLAST/ // ADPAID/PAY/ED/?SHAREHO-LDEmS/SHARZHOLDER/S/NN IN///PPJANUARY///DD*comma*///CCSAID/SAY/ED/? ? THE///DT  8//lAD PC///NNSTOCK///??DIVIDEND////NNWOULD/WII ~// AXBE///AXPAYABLE/PAY/ABLE/AD FOLLO WING/FOLLOW /ING/??THE///DTPAYMENT/PAY/HENT/NNOF///PPTHE / // DTCASH /// NNDIVIDEND /// NN * period */// SP 
A 4-tuple in the sentence above is a word/root/affix/part -of-speech  . As expected , many content words in this sentence cannot be unambiguously tagged  , and are marked ? , i . e . , undetermined . 
In particular , notice that PAID remains unresolved . 
Fortunately , most PAY cases in the corpus are simpler and are appropriately tagged  . 
OF///PPTHE///DTCASH///NNDIVIDEND///NNTHE///DT COMPANY///NNLAST///JJPAID/PAY/ED/VAA///DT  5///NN DIVIDEND///N 0N///PP   , ,\]' A-
NUARYIIIDD ...
For purposes of thematic role acquisition the identification of passive and active voice is crucial  . In the sample sentence above , PAID is appropriately tagged as a verb in the active voice  ( marked as VA )  . 
4.4 Collecting Collocations
Based on the tagging above ( the root field ) , all collocations in the corpus are counted , and the following table is generated . 
This table is similar to Smadja's\[7\] , and it provides the position of collocative words relative to PAY  , and the total count within 4 words in either direction . 
4.5 Determining Lexical Relations
Lexical relations are determined using the known functionality of the verb  ( see\[9\] ) and supporting examples . PAY is marked in the lexicon as a dative verb . 
Consider 5 cases containing the pair PAYSHARE-HOLDER , from which the thematic relation is induced ( VA stands for verb , active voice ; VP for verb , passive voice ; AD for adjective ) . 
437 word-4-3-2-10+1+2+3+4 total
PRICE 5144 38380 171232 12558
COMPANY 475 3712 6026 1161 367
DIVIDEND 3742 3612 10111 1425 287
RATE 6516 1090 14112 163281
MILLION 928 1220 41025 353263
STOCK 350 134 2071 222 203
MAJOR 0 2060 209280182
DUE 1435 1604 3966 7172
INTEREST 135 7408 1429 34168
SPECIAL 13558 403179 24160
CASH 31197 1038 2317 145
CENT 1926 101 103 3326 10138
SHARE 9250 29047 2333 130
AMOUNT 244 315 1003 118 1613 0
PC 12 30 14 230 422 111 117
SPLIT 21025 5700 40098
DATE290130 2229 10195
Figure 3: A Distance Matrix between Word Pairs ( I ) STINGHOUSES AIDITINTENDS TOPAY/vaTHETWO SHAREH OLDERS/nn  $2  . 08 ASH AREPLUSA ( 2 ) ONTROLOFTHECOMPANY WITHOUT PAYING/vaALL SHAREHOLDERS/rmAFAIRPRICE  . THE ( 3 ) THE CASH PORTION OF THE PRICE PAID/??TOPOLYSAR COMMONSHARE HOLDERS/nnWILL  , INCR ( 4 ) CIPATINGSHAREHOLDERS/nnWILLBEPAID/vp $3 ASHARECASH . NOBROKERAGEFEESORT (5) PERSHARE . THEDIVIDENDISPAYABLE/adTOSHARE OLDERS/nnOF RECORDJULY ~  . 
(6) ENTSASHAREFROM 37 . 5 CENTS , PAYABLE/adSEPT . ITOSHARE HOLDERS/nn OFRECORDAUG Figure 4: Word Pairs Tagged as to their Part of Speech 38   5 Exanlples ( 1 )  ,  (4) , and ( 5 ) support he hypothesis that StIAREHOLDER is an object2   ( the recipient ) of PAY . 
5 Cur rent S ta tus and Conc lus ions Based on a number of tagged sentences  , the system determines that SHAREHOLDERS are recipients of PAY  , while DIVIDENDS axe objects . This generalized lexical relation enables the semantic resolution of more difficult case such as DIVIDENDPAYMENT and COMPANYPAIDS TOCK DIVIDEND  . 
The implemented system using these techniques includes several elements :  ( 1 ) morphology analysis-currently produces accurate results for all the required cases  ;   ( 2 ) tagging-produces results for only 60% of the required examples ; more detailed rules could improve this figure to about  70%  ;   ( 3 ) rule forming-currently works only with dative verbs such as 
PAY and SELL.
A number of important pieces of recent research have highlighted the power of cooccurrence information in text  . In the techniques described here , we have extended this research to use cooccurrence information for discriminating thematic roles  . These techniques combine data acquisition from a tagged corpus with relation-driven language analysis to derive thematic knowledge from the text  . 
References\[1\]K . Church , W . Gale , P . Hanks , and D . Hin-die . Parsing , word associations , and predicate-argument relations . In Proceedings of the International Workshop on Parsing Technologies  , 
Carnegie Mellon University , 1989.
\[2\]K . Church , W . Gale , P . Hanks , and D . Hindle . Using statistics in lexical analysis . In U . Zernik , editor , Lezical Acquisition : Exploiting OnLine Resources  . Lawrence Erlbanm Associates , Hillsdale,
NJ , 1990.
\[3\]I . Dagan . Using collocation in anaphora resolution . Technical report , Technion , Computer Science Dept artment , Haifa , Israel ,  1989 . 
\[4\]G . Leech R . Garside and G . Sampson . The Computational Analysis of English . Longman , London , Britain , 1987 . 
\[5\]L is a F . Ran , Paul S . Jacobs , and Uri Zernik . 
Information extraction and text summarization using linguistic knowledge acquisition  . Information Processing and Management ,  25(4):419-428 ,  1989 . 
\[6\]B . Santorini . Annotation manual for the pentreebank project . Technical report , University of Pennsylvania , Computer and Information Science , Philadelphia , PA ,  1990 . 
\[7\]F . Smadja . Macrocoding the lexicon with cooccurrence knowledge  . In U . Zernik , editor , First International Le ~: ical Acquisition Workshop  .  1989 . 
\[8\]Y . Wilks . A preferential , pattern-matching semantics for natural anguage understanding  . Artificial Intelligence , 6, 1975 . 
\[9\] U . Zernik . Lexical acquisition : Learning from corpus by capitalizing on lexieal categories  . In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence  , Detroit , Michigan ,  1989 . 

