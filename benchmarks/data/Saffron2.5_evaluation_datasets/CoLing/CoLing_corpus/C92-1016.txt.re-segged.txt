Using Active Constraints to I ) arse "") ~'('', . :,\[,~k ,, <;
Philipl ) eI/la (: he
lnstitut d ' hf for , natiqu(~
Universit 6 de Neuchate I(Suisse)
email : Blache((~i , ffo , unine , ch
Abstract
Active constraints of tile CO , lsl ratnl higic program-in , rig paradigm allow ( l ) the reduction of the search space of progr~tms and  ( 2 ) a very concise representation of the problcnls . These two l ) roperties are particuhtrly interesting for I ) arsing prob-\[elns : they can hel I ) us to reduce non-determin is ln and to use large coverage gramlnars  . In this paper , we describe how to use Slleh constraints to t parsing ID/LP grammars and propose an in lplen lelmtl  , iou in PrologIll . 
Keywords : constraints , syntax , ID/I , P formalism , bottom-up filtering , Prolog IlI 1 Introduction Logic programming is one of the nlost useful tools in computational linguistics  . These two domains are progressing very rapidly . The former with the emergence of the constraint paradign l and the latter with the systematic use of well-formalized linguistic theories  . In the l~st few years , naturallal > guage processing ( hereafter NLP ) and more precisely syntax have created tools allowing expression of general knowledge  . 
Constraint simplify parsing problems to a con siderable extent  , both in a formal and computation alway . From a formal point of view , we will see that they allow a very good adequacy between linguistic aim computational theories  . We know that this prol ) erty is essential to solve generality , reusability and coverage prolf lems . On the otim rhal , d , from a computatiol ml point of view , constraints setup a control of the I ) rocesses which reduces non-determ misnlm parsing . 
The question is to know whether it , is possible to illl ph ! tlle IltaI ) arsiagIllethod I ) ased oil actllale oil-straints . The answer depends on the choice of the grmmnatical formalism  . We think thai the II ) /LP formalism used lit ( IPS ( -I theory can bring a so hltion to this I ) roblem . 
In this paper , we will describe a parsing method based on \[ D /LP formalism using boolean constraints  . We will show that this n lethod agrees with th ( goals of generality and corm'el . 
2 Parsing and deduction
I Ioth for historical it llll \ [ orlilal reasolls , parsing turn ck ) serelalions with logic The birth of Prolog , for example , w~s conditioim d by I hataud NLP was one of the early applications of this language  . One of there ~ molls , a . s shown in \[ PereiraS , g \], istii at we (' . all compare ) ars dlg and dednet , ion , More precisely , it phrase-structure rule ( hereafter PS-rule ) can be interpreted its a Rmnula ( an ilnplication )  , like a classical in Drenee rule . 
'\[' hus , aPS-rule of the form:
NX ~(' ~ , .   .   .   , C ,   , can be interpreted as the fl~llow mg implication :   (  , '1A .   .   . A ( . ' , , D , S'X the clausal form of which is : ~ CiV ,   . ? V ~ (5' ,   , V , b ' X Because of the ui , iquei ~ ess of the positive literal , we can interpret a PS- . rule as a Ilorn clause , with a direct translation into I'ro log . Thus , a contextfreegr ~ unlnar , represenled by a set . of PS rule , corresponds to a set of clauses . To verify the grammaticality of a sentence is tlulse quivMent to proving the COllSiSteacy of a set of clauses  . 
There is , howew , r , a restriction in the analogy hetwee\[lP~-rtlleS & lid clalts es:a  \[1111'  , detines all order on ils right-haI . l--side chunellt S , whereas a clause does not . This restriction has important colise qllenct , s011 tho generality of the lile Challi SlllS . 
hldeed , lhenoti ( m of order i i ivo I v i ) sit multilllication of the rifles describing a giw ~ n phrase : we get as zn  ; nly rules as there are (: on figural . ious . This is one of the limits of phrase structure gramlnars  . 
ll )/ l , l'formMism and boolean constraints will alk ) wustos Mve this problem . "Ore will obtain a nearly perfect adequacy bet . wee IlI . h ~ theoretical iiiode \] ai id its implementation . Within the classifieation proposed miF , van . s87\] , it will be a strong direct interl ) retation of the model . 
A(ms 131 ! COLING 92 , NAN'II~S , 2328 ao ( rr 199281 Pit < It . OFCOLING 92, NAN rES , AU < ; .  2328 ,   1992   3 Constraints and linguistic theory The basic mechanism of constraint logic programming is the restriction of the search space  , or the reduction of the domain-variables . Tiffs goal can be reached differently depending on the active or passive constraint type  ( ef\[Vanllentenryck89\] )  . In the classical logic programming framework , the basic technique is that of generate-and-test . Iuthisease , the program generates values for the variables before verifying some of their properties : the search space is reduced a posteriori  . On the other hand , in the CLP paradigm , the use of constraints allows the reduction of this space a priori  . Moreover , the set of constraints forms a system which incorporates new constraints  ( luring the process , while the use of simple predicatcs verifying a property only has a local scope  . 
This active/passive distinction can be useful for parsing  , especially according to the type of knowledge that is constrained  . Active constraints can easily be defined for syntactic structures and their formation  . On the other hand , expressing relations between these structures with this kind of constraint is not always possible  . 
We will describe the principles governing the for -marion of the structures  . A syntactic structure can be of two types : * simple structures : lexical categories  ( e . g . Del ,
N , V .   .   .   ) ? complex structures : phrases or propositions ( e . g . NP , VP .   .   .   ) The formation of complex structure sigoverned by two types of knowledge : ? internal : specific information within a structure ? external : relations between structures Internal knowledge concerns the structure composition  , independently of its context . For a phrase , it is the set of its constituents . External knowledge describes interactions between structures  . They concern on the one hand the order and on the other handtile government  ( in the sense of phrase-structure grammars : selection  , agreement .   .   . )  . 
ID/LP formalism uses such a distinction : it separates information about immediate dominance  ( i . e . the set of possible constituents of a phrase ) from that on linear precedence ( i . e . the partial order relation between these constituents  )  . 
It is possible to consider these two types of knowledge as constraints  ( cf\[Saint-Dizier 91\] )  . But it is important to distinguish their respective fune-tionings  . We will illustrate this point by presenting principles for each type  . 
o Internal knowledge
Each complex structure must contain at least one particular element called the head  . This category gives the phrase its type and its presence is compulsory  . The other constituents are usually optional . We must specify that local constraints could require the presence of a particular category  , but it is a subcategorization aspect : it concerns relations between the substructures of the complex structure and is not specific to the structure itself  . We will see that this distinction between optional and compulsory constituents can be represente directly as an active constraint  . 
o External knowledge
In the case of ID/LP formalism , the order constraints ( i . e . linear precedence ) cannot be easily used with an a priori reduction of the search space  . 
Indeed , LP-rules define a partial order upon the set of categories  . The LP-aeceptability relation uses this order and can be regarded as a constraint upon the domain -variables  . It is a symbolic user-defined constraint . The use of this kind of constraint is possible in Chip  ( ef\[Dincbas88\] )  , but not in Prolog III ( cf\[ColmerauergO\]) . 
t lowever , using this order relation as an actual constraint allowing the reduction of domain-variables is difficult  . Insofar as it is a partial order , the LP notion cannot be used to predict he categories that can follow a constituent  . It is used during the parse to verify the possibility for each new category to appear at a given place in the syntactic structure  . 
Generally speaking , internal properties allow an easier use of active constraints than external ones  . 
4 Const ra in ts and ID / LP fo rmal i sm As we have seen  , ID-rules of ID/LP formalism only contain tile set of possible constituents  ( without any notion of order )  . Therefore , an ID-rule is strictly equivalent to a clause . 
Example:
NP "-'* id Del , N , AP ~ NP V ~ De ~ V ~ NV ~ AP This equivalence is the basis of the conciseness and generality properties of GPSG  . But it is difficult to represent . As we have seen , logic programming cannot directly represent the non-ordered aspect of a clause  . I lowever , it is possible to represent this kind of information as active constraints  . 
These must allow the expression of tile simple fact that a phrase is wellformed if it is at least composed of the constituents Ct  ,   .   .   . , C , . Other relations between the structures ( like order or selection ) will only be verified if this constraint is satisfied  . 
ACT~ . SDECOLING-92 , NANTES , 2328 AOt ~ rr 199282 PROC . OFCOLING-92, NANTES , AUG .  2328 , 1992 Practically , each rule descrihing a phrase cor : responds to a clause whose literals represent categories  . An ID-rule is thus translated into a boolean formula where each category corresponds to a boolean  . The semantics of this representatiou is the following : A literal is true if it corresponds to a wellformed structure  . A structure is well-formed if it corresponds to ale ~ cical category  ( simple structure ) or to a well-formed phrase ( compler structure )  . 
Thus , the boolean value of a complex structure is the interpretation of this formula  , and so depends on the value of its constituents . 
Ezample:
Given the following set of ID-rules describing a NP : 
NP--q~DeCN
NP ~ i,*N
NP-old DeCAP , PP , N
NP ~ i a Det , AP , N
NP--qaDet , PP , N
This set of rules corresponds to the following for nmla :  ( 1 ) el AN ) V ( N ) V ( Det AAP APPAN ) V ( Dot AAPAN ) V ( Det APPAN ) DNP It is interesting to note that the ID/LP formalism strongly reduces the problem of PS -rules multiplication inherent in phrase-structure grammars  , t lowever , as we have seen in tile previous example , there is still a redundancy in the information . Indeed , a set of rules describing a phrase allows us to distinguish between two types of constituents according to their ot  ) tionaloreomt mlsory aspect . 
Hence , for each phrase we can define a minimal set of compulsory constituents  ( generally limited to the head of the phrase )  , which we call the minimal set of a phrase . 
Ezample:
In the previous example , the minimal set of the NP is N . 
We introduce an additional restriction preventing the repetition of an identical category within a phr  , ~ se . This restriction is very strong and has to be relaxed for some categories  ( uc has PP )  . But it remains a general principle : most of the categories should not be repeated  . 
We then construct a principle defining tile wellformedness of complex structures  . ' t ' his principle only concerns internal knowledge : A phrase is wellformed iff it respects the following properties : mit contains at least one head ? no constituent is repeated ~  , all its embedded phrases are wellformed In the logical paradigm  ( equivalence between a role and a clause )  , we say that a literal is true ~ it corresponds to a lexieal category of the parsed sentence or if it correslmnds to a wellformed phrase  . 
This formation rule allows its to simplify the ver -itication of the grammatieality of a sentence  . We simply need to verify the presence of the minimal set of compulsory constituents o indicate the wellformedness of a phrase  . The boolean value of the complete structure is then evaluated recursively  . If all the intermediate structures are true , the complete structure is also true and corresponds to a gralomatical sentence  . 
We will call realization the actual presence of a category in tile syntactic structure corresponding to a sentence  . The verification process of the well-for nmdness of a phrase follows these steps  1  . verifie at mn of the realizatiou of the minimal set  2  . verification of the members hil ) of the realized constituents within the minimal set  3  . verification of the uniqueness of the constituents in a pllr  , ' ~ se 4~ verification of the well4ormedness of embedded phrases In an active constraint , we replace the set of clauses describing all the possible constructions with a system <  ) f constraints S defining the set of l ) ossihle constituents and the condition of realization for the minite lalset  . We can represent i as follow : Let G ' he the set of possible constituents of a phrase XP  , let Xt > e the head of XI' , let M be the minimal set such xsM = XUC' ( where C'C C )  , and let zX be the disjtmction of the literals of M  . 
The wellformedness constraint is : s = A7) xl ,
Example:
The wellformedness constraint for aNt ' is: NDNI ' The well : formedness constraint for a PP is : f'rel>ANPDI'PACIESDE  COLING-92  , NAI qrES , 2328^o ~ r199283 PROC . OFCOL1NG-92, NANTES , AUG .  2328 ,   1992 It is interesting to note that the implication corresponding to the set of rules describing the NP in the previous example forms a system of constraints that can be simplified to NDNP  . This property is verified for all phrases : Given a grammar G  , VXP such that Xf'EG , lelA be the disjunction of the liter'Ms of the minimal set of XP  , then the formula corresponding ~ othe rules describing XP is simplified to ADXP  . 
We thns have both a linguistic and a h ) rmaljns-titcation of tile active constraint used to verify tile wellformedness of a phrase  . 
5 Implementation in Prolog III
We will now describe the parsing strategy and its implementation  . 
5.1 Bottom-up filtering
Our parsing strategy relies on tile concept of left boundary of a phrase  . It is an improvement of the left-corner strategy ( cf\[Rosenkrantz 70\] ) called bottom-up filtering ( ef\[maehe90\] )  . It consists in using tile information extracted from  1  , P constraints to determine all the left-bounds of the phrases from the list of lexieal categories corresponding to a sentence  . This process , unlike the left-corner one , relies on a distributional analysis of the categories and the verification of some properties  . 
We define the following flmctions which allow the initialization of the left boundaries  . 
oFirst-legal daughters ( noted I " LD ( P ) ) : this function defines for each phrase P the set of categories that can appear as left boudaries  . It is detined , as follows ( LP relation between sets is noted with ~: ) : Let P be a phrase , ga such that f '-~ c ~ then FLD , the set of first legal daughters , is defined , ' ~ s
R ) llows:m , D(P ) = eE ~ such that e - < , , -  e   < , Immediate precedence ( noted ll ' ,   , ( c ) ) : this fimetlon defines for each FLI ) c of a phrase P the set of categories that can precede e in P  . It is defined as follows : Let P be a phrase , V (* such that P--?o , let x be a nonterminal , etcEFLD(P ) , then IPv(e ) , the set of immediate precedence of c for P , is defined as follows : IP p(c ) = .   .   .   .   . h that ( x-4c ) or (, cE .   .   .   .   .   .   . lneither x-<cnore-<zea:ist ) o I u ' tialize : this flmction verifies whether a category c is the actual left boundary of a phrase 
P . It is defined ms follow:
Let I be a string , let C be tile list of lexical categories of I , VeEC , c'GN ( set of non 4erminal symbols ) such that c'precedes c in C ; c initializes S life EFLI )   ( S ) antie ' ? IPs ( e ) The syntactic structure of the sentence is built from a list of partially evaluated st ructures  . The process consists in determining all the h . 'ft bounds and , from this structure , in completing tire partial structures by an analysis of the other constituents of the phrase  . This is done by verifying whether the current category can or cannot belong to the cnrrent phrase  . We have at our disposal the set of possible constituents for each phrase  , the LP constraints and the other instantaton principles of the GPS  ( \] theory . After these verifications , if tile current category cannot belong to the current phrase  , then we have reached the right boundary of the current ptm~se  . 
Example:
Input sentence : 7' he old mansings.
Categorization :
Det . Adl.N . V
Partial structure:
S . ( NP , Det ). ( AP , Adj ). N . ( VP , V)
Complete structure : ( S , ( NP , Det , ( AP , Adj ) , N) , ( VP ,  !7 ) ) This strategy allows a reduction of the search space  . Parsing becomes a simple membership test of a category within a set  . 
5.2 Implementation
The following implementation considers only the ID /LP formalism  ( instead of the entire GPSG theory )  . We will not speak here about the other GPSG principles  , bnt their insertion in the ID/LP module is very shnple  . 
The parsing mechanism consists in assigning the value truel  . othe boo\]eans corresponding to the categories a ~s and when they appear  . If the structure is simple ( i . e . a lexical category ) , the LP-a eeep lability of this category in the phrase is checked and tire corresponding boolean is a  . ssigned AC . I'ES DECOLING-92 , NANTES , 2328 AO (; F199284 PROC . OVCOLING-92, NANTES , At ; c; . 2328, 1992 tilevMue true . In the case where the l ) ott on > uptiltering detects a left-bound , tile corresponding boolean of tile current category is ms signed tile value true and tile embedded phrase is parsed before coming back to tile construction of tim current phrase  . When we reach the right boundary , the well-form e ( lness of tim embedded structures is checked ( i . e . all the corresponding booleans must be true ) . If this is tile case , the corresponding boolean value is that of tile disjunction A of tile literals corresponding to the minimal set  . 
The representation of tile categories and their associated Iiooleans will be done through two parallel lists which will be examined simultaneously during an affectation  ( or any other operation )  . 
Al ) hrase is described l ) y the set . of its possil ) le constituents , the set of its optional categories ~ uld ~ for l nuls  , using its tniniLnal set . '\[' lie two sets are represented by lists and the R  ) rmula is an imldiCa-don of the form ADXP . This inlbrm~ttion is collected into a systen l of constraints e har  ; teteriz-ing each phra . se . 
Here is a simplilied version of our parsing prc ~ cess  . The following predicates allow the parsing of a I thrase and its simple or complex constituents  . 
Itc ; m be noted that tile gramn m . tieal knowledge islmshed at it low level . It is repn:sented by the set of constraints ~ ssoeiated to each phrase  . 
Moreover , at this level we do not use the notion of sub -eategorizatioil  , but only rules concerning the general structure . We grill id SO notice the concise-hess of this representation with reg  ; ~rd toeh ~ ssical phra . se--strueture formalisms . 
Deseril ) tion of the . implementation Let G be the following l l ) / l , P grammar:
NP-qa1)el , N
NP-'iaN
NP ~ ia Del , AP , I'P , N
NP-q , tDet , Al ', N
NP-+ia Det , PP , N
NP . ' i a Det , Al ', PP , N , l'R cl
Nt'-+ia Det , A1', N , PRel
NP ~ idDet , PP , N , PRel
NP-qd Det , N , P Rel
NP-~LaN , t'Rel
VI'~id V
VP--, i , tV , NP , PP
Vl > -+ id V , N)
VP ~ iaV , 1'1'
AP--'L , LAdj
I'P-'i , tl'ret ', NP
PRel-'idl'ro , NP , VP qlml bllowing predicates correspond to the heart of the parser for the grammar G : A Phrase  ( < S ( c )  > . i,12, Cat , Bool , ' r),
Coilstfluent(S , Cat , Bool)
Lphcceptable(S , Cat , Bool ) hngmbedded Phraee(<S , c > . 1, ll . 

A Phrase ( ii , 12, Cat , gool , A2)
Tree (< S\[<c > . All >. A2, T);
A Phrase (< c > . i , 11, Cat , Bool , < c > . A ) -+
LpAcceptable(c , Cat , Boo\] . ) lltstall ciate(e , Cat , Bool)
A Phrase(l , it , Cat , Boo\].,A);
Th ( A Phraserll h ! takes as ill plltihe list Of partial structures returned by bottum-up filtering  . It distinguishes between ( we (: ~ ua . sace or < ling to the type of the current structure : complex  ( rule ~1 ) or simple ( rule #2 )  . In the first c~use , the following processes arce Mlcd : ? veritication of themend  ) ership of the current structure within the set of the pnssibb con-sl  . it ) lel/tsel the currelt tphrms e ( Constituent rule over if i <' a tion of the l , l ) acceptability ( LpAcceptabler , lle ) ~ , parse of the elnbedded CO lllplex structure ( An Embedded Phrase rule ) tmrse of the rest cd " the phr ; Lse ( A Phraeerule ) construction and w'rilicatiou of the syntactic tree  ( Treerub ) In the case of simple structures , afl ; erchecking timl , P-aeceptal fility , the correslmndiug boolean is assigned tile value true  ( Instanciate rule ) and tile parse of the current phrase is pursued . 
If the APhraser , defails , the right-bound of the phrase is reached and die parse is pursued at a superior level  . 
An Embeddad Phrase (< S , c > . l , 11, gag , Bool , A)-,
Constraints(S,C,B,R,S')
Instanciate(c,C,B )
A Phrase(l , ii , C,B , A)
Correct Constituents ( R , r)
Valid(r , S , S ' , Cat , Boo\]) ; r Fhe Ail Fanbedded Phrase rule allows the parse of & ll  ( !WCOIUp texBtriictt li'e . It begins with tile system of insailing constraints describing this struc-tur ~  ( Coilstraints rule )  . TI , ewllidity of the constituents is clmcked ( Correct Constituents and Validrt des ) Before rettlrlling the boolean w thic of the parse for this phrg~se  ( variable S ' )  . 
Constraints ( NP , C , B , R , NP ) , C - < Dot , Nm , AP , PP , PlteI> , 
Be < I )_ot , N , A.P , PP , PRel >,
R : < A ~ , PP , P_R e I > ,
N => N1 ~ ;
Acri ! sI ) ECOLING-92 , NANIES , 2328 AO\[a 199285I ) ROC . OFCOIANG92, NANTES , AtX; .  2328, 1992
Conatraints(VP , C,B,R,VA~)-~C=<Vb,IP,PP>,
B =< V , IIA ~, P-P > ,
R = < I_P , P_P >
V :: ~. VP;
Constraints ( AP , C , B , R , A ~) - ~ C = < Adj > . 
B = < aAj > ,
R = <> .
AAj ~ A_P ;
Constraints ( PP , C , B , R , PP ) - ~ C = < Prep , NP> , 
B = < P-top , IrA ? > ,
R =< I_P >, ( P_repaIIJ ~) =; ~ PA : ;
Constrainta ( PRel , C , B , R , P ~ Rel)---*C=<Pro , NP , VP> , 
B =< P_ro , Ii_P , V_P > ,
R = < NA ~. V-P > ?( P2 co & V ~) : ~ P_Kel;
We can notice that in this representation , subcategorization consists in verifying the boolean values corresponding to the categories concerned  . 
6 Conclusion
The ID/LP formalism distinguishes between internal and external knowledge about syntactic structures  . This characteristic allows the expression of parsing mechanisms at a very high level of generality  . We can represent the description of a phrase in an extremely concise way with a rule clustering operation  . These properties allow the use of active constraints  . The result is an implementation in agreement with the theoretical nmdel respecting in particular l the generality and conciseness properties of GPSG  . Moreover , active constraints efficiently control the progress of the processes and limit nondeterminism of parsing  . This last characteristic is very important for the ID/LP formalism which uses non-ordered rules implying an increase of the search space  . 
We have shown in this paper how to use active constraints for ID/LP formalism  . We can apply the same approach to the entire GPSG theory interpreting feature structures and instaneiation principles as formulas  ( cf\[Blache92\] )  . 
The implementation presented here has been done in Prolog III on a Macintosh  . From a coverage point of view , we can indicate that the rules in the grammatical formalism presented in our example roughly amounts to twenty standard ID-rules  . 
References\[Blache 9O\]Blache P . & J . -Y . Morin ( 1990 ) Bottom-Up Filtering : a Parsing Strategy for
GPSG , COLING'90.
\[ Blaehe 92\] Blachee . (1992) Interpretation of
GPSG with Constraint Logic Grammars,
ICEBOL '92.
\[Colmerauer90\]ColmerauerA . (1990) An Introduction to Prolog III , CACM , 33:7\[Damas91\]DamasL . , Moreira N . & Varile G . 
(1991) The Formal and Processing Models of CLG , proceedings of the 5th European Chapter of the ACL . 
\[Dinch as 88\]Dine basM . , Vanilentenryck P . , Si-monis H . , Aggoun A . Graf T . & Berthier F .   ( 1988 ) The Constraint Logic Programming Language CHIP , International conference on 5th Generation Computer Systems , ICOT . 
\[Evans87\]EvansR .   ( 1987 ) Theoretical and Computational InteIT relations of GPSG  , Thesis , 
University of Sussex.
\[Guenthner88\]Guenthner F . (1988) Features and Values 1988, CIS . Bericht-90-2, Mfinchen . 
\[ Johnson 90\] Johnson M . (1990) Features , Frames and Quantifier-free Formulae , in Logic and Logic Grammars for Language Processing  , P . 
Saint-Dizier & S . Szpakowiczeds , Ellis Hor-wood . 
\[ Kasper 90\]K asper 1% . & W . Rounds ( 1990 ) The Logic of Unification in Grammar , in Linguistics and Philosophy ,  13:1 . 
\ [ Pereira 831 Pereira F . & O . Warren (1983) Parsing as Deduction , ACL83 , 21st Annual meeting . 
\[ Rosenkrantz 70\]1% osen krantzD . & P . Lewis (1970) Deterministic Left-corner Parser , IEEE Conference Record of the llth Annual Symposium on Switching and Automata Theory  . 
\[ Saint-Dizier 91\] Saint-Dizier P .   ( I991 ) Processing Language with Logical Types and Active Constraints  , proceedings of the 5th European
Chapter of the ACL.
\[Stabler90\] Stabler E .   ( 1990 ) Parsing as Logical Constraint Satisfaction , in Logic and Logic Grammars for Language Processing  , P . Saint-Dizier & S . Szpakowiezeds , Ellis Horwood . 
\[ Van Hentenryek89\] VanllentenryckP.
(1989 ) Constraint Satisfaction in Logic Programming , MIT Press . 
ACTESDECOLING-92 , NANTES , 2328 nOt ~ r199286 PROC . OFCOLING-92, NANTES , AUG .  2328, 1992
