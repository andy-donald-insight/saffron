Finding Structural Correspondences from Bilingual Parsed Corpus 
for Corpus-bsed Translation
Hideo Watanabe * , Sadao Kurohashi ** and Eiji Aramaki **
*IBM Researdt , Tokyo Research Laboratory
1623-14 Shimotsuruma , Yamato,
Kanagawa 2428502, Japan

** Graduate School of Inforlnatics , Kyoto University
Yoshida-homnachi , Sakyo,
Kyoto 606-8501, . JaI)an



In this paper , we describe a system and methods for finding structural correspondences from the paired dependency structures of a source sentence and its translation in a target language  . The system we have developed finds word correspondences first  , then finds phrasal correspon ( tences based on word correspondences . We have also developed a GUI system with which a user can check and correct tile correspondences retrieved by the system  . 
These structural correspondences will be used as raw translation I  ) atterns in a corpus-based translation system . 
1 Introduction
So far , a number of methodologies and systelns for machine trauslation using large corpora exist  . 
They include example-based at ) proaches\[7 ,  8 ,  9 ,  12\] , pattern-based approaches \[10 ,  11 ,  14\] , and statistical approaches . For instance , example-based approaches use a large set of translation patterns each of which is a pair of parsed structures of a source-language fragment and its target-language translation fragment  . Figure 1 shows an exanl-ple of translation by an example -based method  , ill which translation patterns ( pl ) and ( p2 ) are selected as similar to a ( lefthand ) Japanese dependency structure , and an ( right hand ) English dependency structure is constructed by merging the target parts of these translation patterns  1  . 
In this kind of system , it is very important ocollect a large set of translatiou patterns easily and efficiently  . Previous systems , however , collect such translation patterns mostly manually  . Therefore , they have problems in terms of the development cost  . 
1Words in parenthesis at the nodes of the Japanese dependency structure are representative English translations  , and are for explanation . 
This paper tries to provide solutions for this issue by proposing methods for finding structural correspondences of parsed trees of a translation pair  . These structural correspondences are used as bases of translation patterns in corpus-based approaches  . 
Figure 2 shows an example of extracting structural correspondences  . In this figure , tile left tree is a Japanese dependency tree , the right tree is a dependency tree of its English translation  , dotted arrows represent word correspondence , and a pair of boxes connected by a solid line represent phrasal correspondence  . We would like to extract these , ook\"4"- .   . ~  . . . ," ~ . . a movie ~ Figure 2: An Example of Finding Structural Cor-respoudences word and phrasal correspondeuces automatically  . 
In what follows , we will describe details of procedures for finding these structural correspondences  . 
2 Finding Structural Correspondences
This sectiou describes methods for finding structural correspondences for a paired parsed trees  . 
2.1 Data Structure
Before going into the details of finding structural correspondences  , we describe the data format of a 9a noun--noun , n0 mu--drinkll0 un--n0 unverb ! i , , t . 
"', dllkhe.__medicinel1~#\[.--
I(p2)
Figure 1: Translation Example by Examt ) le-based ~ li'anslation dependency structure . A det ) endeneystru ( ' ture as used in this pat ) er is a tree consisting of nodes and links ( orm : cs )  , wh(' . reanode represents a content word , while a link rel ) resents a fllnctional word or a relation between content words  . For instance , as shown in Figure 2 , at ) reposition " at ; " is represented as a link in l ~ , nglish . 
2.2 Finding Word Correspondences
The tirst task for findings tru ( ' tm : alcorresI ) On-den ( : c's is to lind word ( : or ro , sl ) on denccs t ) et ; ween ( ; he nodes of as our ( : e parsed tree and the nodes of at ; w get parsed tree . 
Word correspondences are tkmn (1 byeonsull ; ing a source-to-target translation dictionary . Most words can find a unique 1 ; ranslation candidate in a target tree , but there are cases such that there are many translation candidates in a target parsed tree for a source word  . The retbre , the main task of tind-ing word correspondences is to determine the most plausible l  ; ranslation word m nong can(tidates . We call a pair of a source word and its translation candidate word in a target tree a word correspondence candidate denoted by WC  ( s , / , ) , where s is a source word and t is a target word . If 17\[TC(s,/,)ix a word correspondence and ida . te such that there is r to other WC originating h ' oms  , then it is called
WA word correspondence.
The basic idea to select the most plausil ) le word correspondence candidate ix to select a candidate which is near to another word correspondence whose source is also near to a sour  ( : e word in question . 
Suppose a source words has multiple candidate translation target words t ~  ( i = 1 ,  . . . ,7~ , ) , that is , there are multiple 17 FCs originating h'om . s ' . We , denote these multiple word corresl ) ondence candidates by WC ( s , tl ) . For each I'V C of s , this procedure finds the neighbor WA correspondence whose distance to WC ix below a threshold  . The distance between WC(sl ,/, ~) and WA(s . 2,/,2) is defined as the distance between sl and . s2 plus the distmme between s2 and 1 , 2 where a distance between two nodes is defined as the number of nodes in the t  ) ath who so , ends are the two nodes . Among I~VCs of . s for which neighbor H/Aix to und , the one with the smallest ( list an ( : ( ~ is chosen as the word corre-Sl ) on denee of s , and I/VCs wh Ml are not chosen are invalidated ( or deleted )  . We call a word correspondence found t ) y this procedure WX . We use 3ast ; he distance threshold of the above procedure currently  . This procedure ix applied to all source nodes which have mult ii  ) leWCs . Figure 3 shows an example of WX word correspondence . In this examt ) le , since the Japanese word " ki " has two English l ; ranslation word candidates " time " and " period , " there are two WCs(~7C1 and WC2) . The direct parent node " ymlr yo " of " ki " has a WA correspondence  ( I/V A1 ) to " concern , " and the direct child node " ikou " has also a WA correspond c ' nee  ( WA2 ) to " transition . " In this ease , since the distance between I'VC2 and WA2 is smaller than the distan ( : e between I . VC1 and WA1 , I ' VC ~ incl mnged to a 1/l/X , and I~ITC1 is a dandoned . 
In addition to WX correspondences , we consider a special case such that given a word correspondence l'l Z  ( s , / , ) , if s has only one child node which ix . . -~% omp t .   .   . WAI at // concern . " timeyuuryo , . ." ( concern ) -" ni . ., Wc1 same . . . . accompany ki . .,*\[__ ( time ) . . . . . . . . . . . . . . W_ . .G2 . . . . . . . . . . . .
'" -- periodikou . . . . . . . . . VVA2 of transition ( transition ) Figure 3: An Exmnt ) le of WX Word Correst ) on- ( lence a leaf and t has also only one child node which ixaleaf  , th ( ; nwe COll Strlle talle W word correspondence called  1US from these two leaf nodes . This WE procedure is al ) plied to all word correspondences . 
Note tlmt this word correst ) on dence is not tose . le , ct one of candidates , rather it is a new finding of word corre , spondence by utilizing a special structm : e . For instance , in Figure 3 , if there is a word e or respol > dence 1 ) etween " ki " and " period " and there is no word correst  ) ondence between " ikou " and " transition , " then I <  V , g ( iko'u ~ transition ) will be found 1 ) 3' this 1 ) roeedure . 
These WX and WSt ) rocedures are continuously al ) plied until no new word correspondences arct ' ( mnd . 
Aft ; eral ) l ) lying the above WX and I'V Spro(:e-dures , there are some target words t such that t is a destination of al  , l/C( . s " , t ) and there ix no other 1 , 176  , whose destination ixt : . In this case , the lUG(s , t ) correspondence and idate is chosen as a valid word correspondence bt ween s and /  , , and it ; is called a
HzZ worde or rest ) on dence.
We call a source node or a target node of a word correspondence an anchor node in whatt bllows  . 
The above t ) rocedures for finding word corre-sI ) ondences are summarized as follows : Find WCs by consulting translation dictionary  ; 
Find WAs ; while ( true ) find WXs ; find WSs ; if no new word corresp , is found , then break ; find WZs ; 2 . 3 Finding Phrasal Col'resl ) ondences The next step is to tind phrasal correspondences based on worde or l'eSl  ) on dences t ' ( mndt )  3 , 1) roce . -dures described in tim previous section . What we would like to retrieve here , is a set of phrasal correspondences which ( : overs all elements of a paired dependency trees . 
In what follows , we ( : all a portion of a tree which consists of nodes in a  1  ) att ~ from a node ? tI (  ; o all-oth ( ; r node nu which is a descen ( lanl ; of n : lalin- . 
eartree denoted by LT(v , 1 , n ~) , and we denote a minimal sul ) tree including st ) coiffed nodes hi ,   . . . , n . ~, l)yT(nl , .   .   . , n , ) . For instan(:( , ~ in the English tree structure ( the right tree ) in Figure 4 , LT ( tcch , nology , science ) is a rectangular area covering % eclmol-?tg " e e~ogy  , " and SO l , no , , anti . T ( J'acl ; or , cou ' ntr jl ) is a 1 ) olygonal area covering " factor , "" at Dcl , ,  .   .   .   . t)ol-icy , " and " country . " The tirst step is to find a 1 ) air of word correst ) on-dences W ,  ( . ~'~, t ) and ~4 q( . , . ~, t ~) such that . , , a . ,t s2 constructs a linear tree LT(si , s2) and there is no anchor node in th ('1) al ; h from s ~ to s 2 other than . s ' ~ and . s2 , where 1UI and H~denote anytyi ) e of word ( ' or rest ) on ( lences 2 and we assmnet here is a word corres I ) on dence t ) etwee , n roots of source and (; arget trees by defmflt . We construct at ) hrasal correspondence fi'om source nodes in LT ( s ,   , s2) and target l/o ( lesit lr\]'(t:l ,  / '2 )  , ( l ( ) l lote(t by \]; '( l ~ , ~F'( . q'l , . ";2), 5\] . n(tl , t2)) . 
For ill stall ( ' e ~ illFigll re41~\]"11~\]~12~1 ) '2~ 1 ) 3 and \] ) 4 tu . ' esource portions of phrasal et ) r respondences found in this step . 
The next stel ) checks , forea(:h1' , if all anchor llo ( les of wor ( 1eorres1 ) Oll ( leile ( ?s wllose SOU lT (  ; e o1 ~ ; al-get node is included in Pareal , eo included in P . 
If at ) hrasal correst ) on denees atisiies this condition , then it is called closed , otherwise it ix called open . 
Further , nodes which are not included in the I ) in question are called open nodes . If al ) ixot ) en , then it ix merged with other 1 ) hrasal correspondences having ol ) en nodes of P so that the merged 1 ) hrasal correspondence b comes ( -losed . 
Next , each P ~ , , is checked if there is another l ) q which shares any nodes ottmr than anchor nodes with P  . ,, . If this is the case , these P: . , and 1~ are lnerged into one phrasal correspondence . In Figure 4 , t ) hrasal correspondences i 11 and P12 are merged into P1  , since their source I ) or tions LT ( haikei , koku ) and LT ( haik ci , seisaku ) share " doukou " which is not an anchor node . 
Finally , any path whose nodes other than the root are not included in any  1  ) s but the root node ix included in a 1 ) is searched for . This procedure 2Since WC is not a word correspondence ( it is a candidate , of word corresi ) on dence ) , it isllOi ; conside , red here . 
908 is a pl ) lied I ; o1) oth source a . nd ( ; arget trees . Aim . th found 1 ) y this 1 ) ro ( : ( xlur ( ~ is called an open pal , h , , m~(t its root no(le is called a pivot . If such an Ol ) enpath is found , it is t ) rocessed as follows : l , breach 1) ivot node , ( a ) if the t ) iv ot is not an mm hor no d ( ; , then openlmths originating fl : om the pivot is merged into a  1   ) having I ; he pivot , ( b ) if the pivot is an ~ LIl ChOfllo ( lo ~ ; hOll3_llOWt)hl'~lS~L1c()rFos1) oII((~IlC(~ , iS created from Ol ) ( m1) ai ; hsoriginating from them > thor nodes of the word  ( : or rcsl ) on ( l ( :ncc . 
In Figure 4 , w (: gettinally four phrasal (: or r (:-
Sl ) on ( lences l ~, f ~, l ~, an ( ll~t.
! haikei . !,, : I- . . . . . . . . . . . . . . . . . . . - ~ factor ' , , , l ' , i / ~0:: aect " ,   ,  ' , ,( tre , nd ) if \~~-" li;k . '/; ~ oy , _:~, koku ( seis ak ~' ~ t---- . ~---~~' ( C0 UrlttV)_l , ( p0%, ~: t' . . technology . lrltly ~< : : :> i - - - - : :- : ~= 7: : TLIio . ; I(major ) ~ , _/_-X-~/'giutu"\]\](technolo~ly)l' . ? science kagaku " ( scie , nce) .  -
P4/tt/ffi
Figm:ed : Anl ~; xaml)le of Finding Phrasal Corr (>

The above 1 ) ro ( : eduresfl ) r finding l ) hrasal ( : or r ( > Ht ) o II do IICOS~-LF ( ~ Slll Ill Il ? ~ riz ( KlgtS follows:
Find initial Ps;
Mea'gea . nOl ) Cn1 > ~ with otheri's having open nodes of 1 ; 
Create newPs 1 ) ymerging \] ) s which have more tlmn 2 ( : ommon nodes ; 
Findot ) en path , all difthet ) ivot is mlmm hor , ; hen merge the path to P having the anchor , otherwise create new l ) by merging all opent ) ai , hshaving l ; lmpivot ; 3 Experiments 3 . 1C , or lms and Dictionary We used ( l()( ; lllil(~'ll ; st ' rolil White Papers on S ( :i-en ( - e  and Technology ( 1 . 994 to \]996 ) pul ) lished by the S ( : ience mid Technology Agency ( STA ) of tim . \]al)mmsegov crlim(~nl; . STAlm blished th ( ; se White PaI ) ers in both Jat)mmse and English . The Com-mmfications lese a . rch Laboratory of " the Ministry of Posts and Telecommuni  ( :a . tion of the . \] al ) mmseg overlmmnts upl ) liedus with the l ) ilingual corpus wtfich is already roughly aligned . We made a bilingual cortms consisting of pa . rs(;d dependency structures by using the KNP\[2\] . \]al)mmso ,  1 ) arser ( ( l ( wel-Ol ) ed by Kyoto ( h five ) sity ) for . Jal ) anes ( ~sentences and the ESG\[5\] English 1 ) arser ( developed by IBM Watsonie , sear(:hCenter ) for Englishs(~nl ; (! nces . 
We mad(al ) oul ; 500 senl ; ( m (: el ) airs , each of whi (: h11 ~1 , '4; I , OIlC-I;O-OII (' ,  80 , 11;(' , 11 (; 0 (- orresl ) onden (:( ~ , , fl'OI\[l ( , \] lOraw(t ~ t taofl ; he , Whitel ) al ) crs , mids (' , l( ; ( ; i ; ( xlrm > domly aboul ; 130 s('a H ; en (: c pairs for (' , Xl ) ( Mm(;nts . 
i low(wer , since a 1) nrser does not always \]) ro(hwe( ; or l'c ( ; \[ ;  1) ; ~l " s(tt ; re(s~wo(~x (: lude (1 some , ~( ~ ii ; ( Hic(~p ; Lil's wl fich have severe 1) arse errors , and tinally got i\[15S(~ , II\[;OIlC (; pairs as a , to , s ts (% . 
As a trm~slation wor (1 dictionary/)et w(',(m . lat)ml (' , s ( ; and English , we , tirsl ; used , l-to-l ~; trml slati ( ) n(li(:-l , ionary which has mot ( , ' tlmn 100 , 000 ( , if l ; l'i ( ; ~ , but we , fi ) un(ll ; l ~/ ; lller (? are som(~word('orr(~sl ) Oll(l(~ , llt ;(~ snot(:()v(ued in this di (: nary . Tlmref () rG we merged ( retries fi:om\]';-t;o- . I translatiol l dictionary in order to get ; much broad (: ov ( wag ( , ' . Thel;o Ddnulnl ) ( r ( ) f entries a . renow more I ; ha . n\[50,000 . 
3.2 Experinmntal Results
Td)lei shows l ; he result of ( ~ Xl)c , rimeni ; fl ) rtind-ing word correspond(nm(~s . A row with ALL in th (' , l : yl ) e cohmm shows Llle total ~ CClll ' ~ lcy of WOI' ( 1 cor-r ( Lqpolld ( '31c ( ~ sandol ; \] l ~ rrowssh()\v Llle . ~ iCClll'ktcy of each t , yt)e . It is clear that WA (: or r(~sl ) Olld(~ll(;(' , shave a very high a (' cura(:y . Other word (: or resl ) On--do , nc ( , , salso ha . vearo Jatively highac (: ura(:y . 
Table 2 shows timrem fl to fexl ) erimenl , s for find ~ ing 1) hrasal correspondences . The row with ALL in I ; hel ; yt ) c cohlmn shows l ; hel ; ol ; alaccuracy of phrasal (: ol'r(~sl ) on do , n(:(~s found by the 1) rol ) osed 1) rocedure . 
Thisac ( : macy level is not I ) romising and it is not ; useful for later 1) ro(:e , sses since it needs human ( : he ( : k-ingml ( l ( : or rec?ion . Therefore , we sul ) categoriz ( ~ each phrasal corl'eSpond ( m ( ' es , and checkl ; hea('-(:uracy for each subca . tegory . 
We consider the following sut ) catcgories for 1 ) hrasal ( ' x ) rl' ( Sl ) olidell ( - ( ~s : ? MIN . . . The minimal t ) hrasal correst ) on dence , that is , I ' (1Zl '( . s'l , . s2), LT(tl , t2)) such that ( ; herc




WZ 11 11 11 . nunl . of SUCCESS of correct ratio found corresp . (%) corresp . 
771 745 96 . 63 612 600 98 . 03 131 118 90 . 07 13 12 92 . 3  15   15   100 Table h Experimental Result of Word Correspondences are word correspondences W  ( s1 , tl ) and W(s2 , t2) ,   s2 is a direct child of St and t2 is a direct child of tl . 
? LTX . . . P ( LT ( . s'I , S2) , LT(tl , t2 ) ) such that all nodes other titan s2 and t2 have only one child node . 
? LTY . . . P ( LT(sl , . S2) , LT ( tl , t2)) such that all nodes other than Sl , s2 , 1':1 and t . 2 have only one child node . 
LTX is a special case of LTY , since Sl and tl of LTX must have only one child node  , on the other hand , ones of LTY may have more than two child nodes . A subcategory test tbraphrasal correspondence is done in the above order  . Exmnples of these subcategories are shown in Fig 5  . 
Tlm result of these subcategories are also shown in Table  2  . Subcategories MIN and LTX have very high accuracy and this result is very promising  , since we can avoid nmnual checking for ttms e phrasal correst  ) ondences , or we would check only these types of t ) hrasal correspondence smmmally and discard other types  . 
As stated earlier , since we removed only sentences with severe parsing errors from the test set  , please note that the abovemtmbers of experimental results are calculated for a bilingual parsed corpus including parsing errors  . 
4 Discussion
There have been some studies on structural align -Inent of bilingual texts such as  \[1  ,  4 ,  13 ,  3 ,  6\] . Our work is similar to these previou studies at the conceptual level  , but different in some aspects .   \[1\] reported a method for extracting translation templates by CKY parsing of bilingual sentences  . This work is to get phrase-structure level phrasal correspondences  , but our work is to get dependency-structure level phrasal correspondences  .   \[4\] proposed a method for extracting structural matcl fing  ( pairs of dependency trees ) by calculating matching similarities of two dependency structures  . Their work focuses on tile parsing ambiguity resolution by calculating structural matching  . Further ,  \[3 ,   6\] proposed structural alignnmnt of dependency structures  . Their work assuined tha . tleast common ancestors of each fragment of a structural correspondence are preserved  , but our work does not have such structural restriction  .   \[13\] is different o others in that it tries to find phrasal correspondences by comt  ) aring a MT result and its manual correction . 
In addition to these differences , the main difference is to find classes ( or categories ) of phrasal correspondences which have high accuracy  . In general , since bilingual structural alignment is very complicated and difficult task  , it ; is very hard to get more than 90% accuracy in total . If we get only such an accuracy rate , the result is not useful , since we need manual clmcks t br the all correspondences retrieved  . But , if we can get some classes of phrasal correspondence with  , for instance , more than 90% accuracy rate , then we can reduce manual clmck-ing for phrasal correspondences in such classes  , and this reduces the development cost of translation patterns used in later corpus-based translation pro-tess  . As shown in the previous section , we could find ttmt all ( : lasses of word correspondences and two subclasses of phrasal correspondences are more than  90% accurate . 
When actually using this automatically retrieved structural correspondence data  , we must consider how to manually correct the incomplete parts and how to reuse mamlal correction data if the parser results are ctmnged  . 
As for the tbrlner issue , we need an easy-to-use tool to modify correspondences to reduce the cost of mmmal operation  . We have developed a GUI tool as shown in Figure 6 . In this figure , the bottom half presents a pair of source and target dependency structures with word correspondences  ( solid lines ) and phrasal correspondences ( equences of slmded circles )  . You can easily correct correspondences by looking at this graplfical presentation  . 
As fortlm latter issue , we must develop methods for reusing the manual correction data as much as possible even if tim parser outputs are changed  . 
We have developed a tool for attaching phrasal correspondences by using existing phrasal corm -spondence data  . This is implemented as follows : Each phrasal correspondence is assigned a signature which is a pair of source and target  , sentences , each of which t in s bracketed segments which are included in the phrasal correspondence  . For instance , tmihatu((~uebiomeR ) , ~10 gijutu- , ,-( tedr , do ? . t?)
I --, < Jevelop rned0f--,'.-tect'lrlOlogy
ILlZl.l~l.l,~\[<dime goseit you(i , otldl
I yat ~ . ad 0 uteki .   .   .   .   .   .  , . corltinue * o--shob'o- . ~obj""k9Klt ; dh/'/\economicfkagat , lJ " ~ . 
% unparallelled . ? tij du-\[--~ec ; hn010 ? tl~<~o~lI"-)/ . ', , , ooloy- . x , , 0, , , kantena ~ laedlkorera . ,-science . 
 #gzee ( a ) MIN ( b ) LTX ( c ) LTYpUrposes PecI- , qhis Figure 5: Examples of Categories of Phrasal Correst ) ondences
A : 5115511. of type found
COl ; l'esi).
ALL 678
MIN 223
LTX17
LTY 27

I515151. of (: or rect co5-5"(~Sl).

SllC(;(~SS ratio ~/ A (%) 63.56 96 A1
D : nunL of nodes covered t)yA
E : nunl . of nodes covered by B

SllCCeSS ratio
E/D (%) 59 . 02 96 . 76 17 100 153 153 100 20I 74 . 0725319175 A 9

Tal)le2:lgxperinmntalFh' , sultot ' Phrasal Correst ) on ( len : es the following signature is made h ) r ai ) hrasal corre-
Sl ) on ( lence(c ) in Figure 5: ( . ~ i : j) . . . \[ korer~nokantenkarmlo\]kagaku\[gi-ju tu\]  . . . 
. . . science and \[ technology fl:om this lmrl ) ose \] . . . 

In the above e , xample , segments betwee , n '\[' and '\]' represent a phrasal correspondence  . 
If new parsed dqmn dency structures for a sentence pair is given  , for each phrasal correspondence signature of the sentence pair  , nodes in the structures wtfich are inside 1 ) rackets of the signature are marked , mid if there is a minimal sul ) tree consisting of only marked nodes , then a phrasal corre-Sl ) ondence is reconstructed from the phrasal correspondence signature  . By using this tool , we can efficiently reuse the manual efforts as much as possible even if parsers are updated  . 
5 Conclusion
Ill this I ) al)er , we have t ) rol ) osed methods for finding structural correspondences  ( word correst ) on-dences and i ) hrasal corr (  ; spondences ) of bilingual parsed corpus . Further , we showed that the t ) reci-sion of word correst ) ond ( mces and some cat c'gories of t ) hrasal corresl ) ondences found 1 ) your methods are highly accurate , and these correst ) ondences can reduce the cost of trm~slation pattern accumulation  . 
In addition to these results , we showed a GUI tool formmmal correction and a tool for reusing previous correspondence data  . 
As fld ; ure directions , we will find more subclasses with high accuracy to reduce the cost for translation pattern preparation  . 
We believe that these methods and tools can accelerate the collection of a large set of translation patterns and the develop lnent of a corlms-based translation system  . 
911 ~ relid="28" type="P4"src="3 . 4,9,10,11,12 . 13"tgt="1,2 . 3 , 4 , 8 , 9 , 1 2" eval="T~RUE"score="O"geoeratlon=''subtype= " or ff'org="con'lment='"'=~rel  id="29"   type="P5"   src="1  , 2 , 3" tg ~" l 0 , 11 , 1 2" BvaI="TRUE " score="0" generation=""subtype="org"org="comment :="' > ~ rel  ld="3O  "  type="P5"   src="5  . 6 . 7"\[g1="5 . 6 , 7" eva~"TRUE " score="0" generation="sublype="org"org=""cornmen ~'' ~ < tel  id="31"   type="P5"   src="7  . 8, 9"tg ~"7 . F'evaI="TRUE " ecore="O " generation="subtype= " org " erg = " cerumen  . t = "" ~ . 
' ~ relid="32" type="P5"src="3,4 . 9 . 10,11 . 12 . 13 " tgt="1,2,3,4 . e , g , 1 2" evaI="TRUE " score="0" generation="'subtype="org"org=''comment=-"' -'  . 

L4\h6aclen;~aadtactiil C : ; Id6i'g , 0 tiCid ; ~; fr n ~\[ , ~r . c ~ un~les . .  .   .   .   .   .  ,  .   .   .   .  ? ~-  . 
, . ? L : i :: ?: i %
Figure 6: An GUI tool for presenting/manipulating structural correspondences 
References\[1\]Kaji , H . , Kids , Y . , and Morimoto , Y . , " Learning Translation Templates from Bilingual Texts  , " Proc . of Coling 92, pp . 672-678, I992 . 
\[2\] Kurohashi , S . , and Nagao , M . , " A Syntactic Analy ~ sis Method of Long Japanese Sentences based on the Detection of Conjunctive Structures  , " Computational
Linguisties ~ Voh 20, No . 4, 1994.
\[3\] Grishman , R . , " Iterative Alignment of Syntactic Structures for a Bilingual Corpus  , " Proe . of 2nd Workshop for Very Large Corpora , pp .  5768, 1994 . 
\[4\] Matsumoto , Y . , Ishimoto , H . , and Utsuro , T . , " Structural Matching of Parallel Texts , " Proc . of the 31st of
ACL , pp . 2330, 1993.
\[5\] MeCord , C . M . , " Slot Grammars , " Computational Linguistics , Voh 6 , pp .  3143, 1980 . 
\[6\] Meyers , A . , Yanharber , R . , and Grishman , R . , " Alignment of Shared Forests for Bilingual Corpora  , " Proc . of the 16th of COLING , pp . 460-465, June 1996 . 
\[7\] Nagao , M . , " A Framework of a Mechanical Translation between Japanese and English by Analogy Principle  , " Elithorn , A . and Banerji , R . ( eds . ): Artificial and Human Intelligence , NATO 1984 . 
\[8\] Sato , S . , and Nagao , M . " Toward Memory-based Translation , " Proc . of 13th COLING , August 1990 . 
\[19\] Sumita , E . , Iida , II . , and Kohyama , H . "' Translating with Examples : A New Approach to Machine  3Yanslao tion , " Proc . of " InfoJapan 90, 1990 . 
\[10\] Takeda , K . , " Pattern-Based ContextFree Grammars for Machine ~l ~ anslation  , " Proc . of 34th ACL , pp . 144--15I , June 1996 . 
\[11\]Takeda , K . , " Pattern-Based Machine ~ l Yans lation , " Proc . of 16th COLING , Vol . 2, pp . 1155-1158, August 1996 . 
\[12\]Watanabe , H . "A Similarity-Driven Transfer System , " Proc . of the 14th COLING , Vol . 2, pp .  770 . -776, 1992 . 
\[13\] ~ Vatanabe , H . " A Method for Extracting ~ I Yanslation Patterns from ~ lS ' anstation Examples  , " Proc . of the 5th Int . Conf . on Theoretical and Methodological Issues in Machine Translation  , pp .  292-301, 1993 . 
\[14\]Watanabe , H . , and Takeda , K . , " A Pattern-based Ma . -chine Translation System Extended by Example -based Processing  , " Proc . of the 36th ACL&17th COLING,
Vol . 2, pp . 1369o 1373, 1998.

