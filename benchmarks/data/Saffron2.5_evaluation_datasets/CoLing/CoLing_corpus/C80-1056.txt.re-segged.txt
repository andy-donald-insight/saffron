HOW TO DEAL WITH AMBIGUITIES WHILE PARSING : EXAM --- 
A SEMANTIC PROCESSING SYSTEM FORJA PANE SELANGUAGE
Hidetosi Sirai
Dept . of Mathematical Engineering and Instrumentation Physics 
Faculty of Engineering , University of Tokyo
7-3-1, Hongo , Bunkyoku
Tokyo 113, Japan
It is difficult for a natural language understanding system  ( NLUS ) to deal with ambiguities . There is a dilemma : an NLUS must be able to produce plausible interpretations for given sentences  , avoiding the combinatorial explosion of possible interpretations  . Furthermore , it is desirable for an NLUS to produce several interpretations if they are equally plausible  . EXAM , the system described in this paper , is an experimental text understanding system designed to deal with ambiguities effectively and efficiently  . 

What is ambiguity ? The term ' ambiguity ' usually refers to the property that certain sentences may be interpreted in more than one way and that insufficient clues are available for the intended or optimal interpretation  . 5 The decision as to whether or not there are ambiguities in a given sentence is difficult  ; some systems with little knowledge may overlook the possibility of alternative interpretations in some sentences  , and other systems may be puzzled as to which interpretation to choose even when there is only one plausible interpretation for human beings  . 
In general , the more knowledge a system has , the greater are its possibilities of interpretation  . One solution is to generate all possible interpretations and ask the user to choose one of them  . But this is obviously absurd . Another solution is as follows : in the parsing process  , the system chooses one interpretation and if that one fails  , looks for another , and in the semantic process it produces all plausible interpretations on the basis of certain criteria  I0  . 
A different approach is adopted in EXAM.
The reasons for this are as follows : i ) In the processing of the Japanese language , it is undesirable to separate the parsing and the semantic process  , since noun phrases , especially the subject are often omitted . Thus , we cannot parse Japanese sentences efficiently without using semantic information  . 
2 ) It is undesirable to ask the user to choose from among several interpretations whenever ambiguities occur in text understanding systems  . 
3 ) We may overlook the possibility of other interpretations if we adopt the strategy of making semantic interpretations after parsing  , since such a strategy might exclude what turns out to be the proper interpretation when making a choice among several grammatically ambiguous alternatives  . It would be awkward if there is another interpretation and we realize that it is the appropriate one only after having processed several sentences  . 
EXAM is an experimental text understanding system designed to deal with ambiguities effectively and efficiently  . EXAM consists of three components : hierarchical knowledge sources  , a semantic interpreter and a fundamentally breadth-first augmented contextfree parser  . The second version of EXAM is under development on the HLISP system using the HITAC  8700/8800 at the
University of Tokyo.
2. CLASSIFICATION OF AMBIGUITIES
In this chapter , the ambiguities with which we are concerned are classified into three types : levels of word meaning  , levels of grammar and levels of discourse . Examples are given for each of these types . We point out that these are among the ambiguities that an NLUS must deal with  . 
2.1 Levels of word mean in $
There are many words in the Japanese language which are phonologically similar but correspond to different lexical entries in a dictionary  . For example , sisei corresponds to 17 entries in a standard Japanese dictionary 8  . 
This is known as homonymy and should be distinguished from polysemy  . 

The referents of pronouns are often ambiguous . We call this ambiguity referential ambiguity . In Japanese , nouns are often used coref-erentially , and so the remay arise the problem of whether some noun is being used in the generic or in the specific sense  . We also call this referential ambiguity . 
2.2 Levels of srammar
Consider the following sentence.
( i ) Taroowa Z ~ roon iwazaton agura ~ se-ta.
' Tarooma de Ziroobeathim purposely.'
This sentence is ambiguous , because there are two possible interpretations , namely , Taroogawazatonagura-se-ta ' Taroo purposely made  . . . ' and Z~roogawazatonagut-ta ' Ziroo purposely beat  . ' This is called grammatical ambiguity , that is ,   ( i ) has two different parsing trees ( or superficial syntactic structures )  , as follows: ( l-a ) \[ Tarooga Zirooni \ [ ( Zirooga ) (Taroo o ) wazatonagura \] sse-ta\]s ( l-b ) \[ Tarooga Zirooniwazato \ [ ( Zirooga )   ( Tarooo ) nagura \] sse-ta\]s The ambiguity of coordinated noun phrases such as wak aio toko to on na'young men and women ' is also included in the grammatical ambiguity category  . 
The interpretation of the scope of negatives such as  ( 2 ) also constitutes a problem . 
(2) Taroowa Ziroono youni rikou denai.
This sentence is ambiguous , having the following three readings : ( 2a ) Taroo , like Ziroo , is not clever . 
(2b ) Taroo is no tascle veras Ziroo.
(2c ) Zirooisclever , but Taroo is not.
In Japanese , these three readings have the same superficial syntactic structure  , but allow three different semantic analyses , according to the rule of interpretation used . We call this interpretative ambiguity . 
2.3 Levels of discourse
The role of a sentence in discourse is often ambiguous  . Consider the following sentence . 
(3) Onakagasui-ta.
' I ~ m hungry . '
This is merely an assertion , with no special implied meaning when used without any particular context  . But if we have a certain context , for example , if Taroo and Ziroo were walking along the street at no on  , and Ziroouttered sentence ( 3 ) in front of a restaurant , then (3) might have a different meaning , that is , " let's have lunch . " ( In this case , one says that (3) has illocutionary force . ) Consider another example : ( 4 ) Taroow amitide koron-da . Banananokawagasokon ~ atta . 
' Tarooslipped and fell on the street . There was a bananask in there . ' St is difficult to interpret the second sentence with assurance  . We can interpret it as stating the cause of the event described by the first sentence  , and also as stating a result of this event , that is , Taroo found the bananask in as a result of falling down in the street  . We call this cohesion ambiguity . 
2.4 Sense and meaning
In this paper , we distinguish ' sense ' from ' meaning . ' " Meaning " refers to the interpretation of linguistic expression  , taking the context into account . " Sense " means , on the contrary , the interpretation of the expression in the absence of context  . In other words , " sense " is literal meaning . In this account a variety of ambiguities , such as homonymy and grammatical ambiguity , are regarded as ambiguities in sense . 
Other ambiguities , such as referential ambiguity and cohesion ambiguity are those in meaning  . 
In EXAM , we adopt the strategy of first determining the sense of linguistic expression  , and then the meaning . Therefore , the transformation of sense representation into meaning representation i ~ carried out after disambiguating the " sense " ambiguity  . 
3 . HOW TO DEAL WITH AMBIGUITIES IN PARSING EXAM incorporates three sources of knowledge : frame memory  , text memory and working memory . The frame memory holds prototype frames , script frames and other useful information such as metaknowledge  . The text memory holds three components : the context  , which is the socalled frame system connecting the frames produced by the semantic interpreter  ; the frame representing the sense of the last sentence  ( which constitutes the data for ellipsis )  , and the speaker's current viewpoint . The working memory stores various interpretations of the sentence being processed during parsing  . 
In parsing process , EXAM translates linguistic expression into frames Which represent their structure  , such as word order . The transformation of sense representation into meaning representation is not necessarily carried out during the parsing process but may be done if required  . 
Constructing the sense representation from the expression depends upon the knowledge contained in the frame memory  . EXAM also takes the knowledge contained in the text memory into consideration when transforming sense representations into meaning representations and selecting the plausible interpretations  . 
The parsing process in EXAM is carried out by a parser called MELING and the knowledge representation language  . In this chapter , we shall describe these and explain how EXAM deals with ambiguities  . 
3.1 MELING---a parser
MELING stands for Modified Extended LIN Gol , which is slightly different from Extended LINGOL ~It is basically an augmented contextfree parser using a bottom-up and topdown parsing algorithm nary and the grammatical rules provided by the user  . 
The descriptive format of the dictionary is , \[< morpheme > < syntactic-category > ( < message-list > < interpretation > ) < gen>\] . 
The < message-list > is regarded as attached to the syntactic category of the morpheme  , and is used to control the parsing . < Interpretation > , when evaluated , returns the frames or other data relating to the appropriate function of the morpheme in the semantic processing  . 
The format of the grammatical rules is \[< left > < right >  ( < advice > < cog > ) < gen>\] . 
The < left >-< right > pair represents a contextfree rule of the form 
A-?B or A-?BC , where A , B and C are nonterminal symbols . For example , \[ S ( NP VP )   ( (% S:NP+VP ( FML ) (FMR ) )  (  #MM'@NP + VP = S ( @ LC ) (@RC ) ) nil \] indicates that the phrase name is S and that its syntactic constituents are NP and VP  . 
In general , it is possible that several parsing trees may be produced for one sentence  , therefore , the parsing process must be controlled by using syntactic and semantic information  . The < advice > and the < cog > are provided for this purpose  . 
The < advice > is an arbitrary LISP function which serves to control the parsing process by using syntactic information  . It is evaluated if the parser creates a new requirement for a parsing tree in a  top-d0wn manner by using the grammatical rule under consideration  , or if the rule is applied to produce a new parsing tree in a bottom-up manner  ; the parsing process depends upon the result . The < advice > program should be one which returns the result deterministical Sy in the local syntactic context  . For example , a program dealing with the inflection of verbs is provided to serve as < advice > for the rewriting rule which decomposes a verb into its root and its suffix  . 
The < cog > is a LISPS-expression ( or program ) for producing interpretations and controlling the parsing process in terms of these interpretations  . Usually , semantic processing costs more than syntactic processing  , hence the parser does not evaluate the < cog > very frequently  . The < cog > would be evaluated in the following cases : i  ) if several partial parsed trees with the same root node and the same terminal symbols  ( Fig . i ; we call these ambiguous PPTs ) were found to make sense given the syntactic context  , or 2 ) if some phrases are produced which are considered as components for semantic interpretation  ( e . g . sentence , thematic phrase , adverbial clause , etc . ) noun adj .   .   .   .   .   . nounl !! det---noun!noun .   .   .   . p !!!! fkuroikcmT in osyouzy o noun
Idet .   .   .   . noun noun .   .   .   .   . p\]adj---noun!i !!!! kuroikcmzino syo ~ zyo ' agirl with dark hair ' 
Fig . iAn example of ambiguous PPTs.
The result of such an evaluation is a list of pairs each consisting of an interpretation and a number which indicates to the parser the degree of our satisfaction with the interpretation  ( or " likelihood " )  . 
As we have seen , syntactic and semantic processing are distinctly separated  , and the semantic processing is dependent upon the parsing tree  . Furthermore , if there are grammatical ambiguities , that is , ambiguous PPTs , the semantic processer is used to retain only plausible interpretations  , and then MELING continues the parsing process accordingly  . We pointed out that although there may be several semantic interpretations  , the number of parsing trees is just one . 
That is , the interpretations produced all belong to the same syntactic category  . Thus , MELING eliminates the ambiguous PPTs . 
3 . 2 GIRL --- a knowledge representation languase GIRL has framelike knowledge packets as a basic data type  , and these packets are mutually connected by certain links  . Following KRL1 terminology , the packets are called units , and the links are called slots . The format of a unit is :\[ unit-name category self-slot slot l  slot2   . . . slot n\] . 
In EXAM , interpretation may be regarded as transforming proty type frames into frames representing the meaning of the phrases or sentences by instantiating them  . The prototype frame ( called PROTO-unit ) is indicated by the category " PROTO " in the frame memory  . GIRL provides a hierarchy with several modes of property inheritance for PROTO-units  , and uses this hierarchy to instantiate them in the semantic interpretation  . The units have several slots , and most of them have the following format : ( role facet filler comment ) or ( role check-to-fill when-filled comment )  . 
The former is called a semantic slot and the latter is called a prototype slot  . The role/filler pair in the semantic slot corresponds to the traditional attribute/value pair  . The facet specifies the characteristic of filler ; it is usually "=" ( value) . The comment is used for various purposes : default value  , expectation , attached procedures to be evaluated later , etc . 
are specified.
EXAM instantiates PROTO-units by transform -- 370 ing their prototype slots into semantic slots . 
In addition to this , several slots are added and removed . In instantiating units , the check-to-fill is evaluated when a candidate for the filler of the slot is provided  , and returns either NIL or a number as the result . If the result is NIL , then the candidate is abandoned . Otherwise , the result , that is , a number , indicates the candi-date's fitness and then the transformation from prototype slot into semantic slot is carried out  . 
After this is comleted , the when-filled is evaluated . The when-filled may consist of any kind of programs  . 
GIRL has another type of slot which specifies the definitions of the units and the global requirements applicable to the unit as a whole  . 
However , we shall not describe it here.
3.3 Ambiguities and interpretation
As we have seen , the semantic processing is dependent upon the parsing tree  . In more concrete terms , the interpretations , that is , frames , of a certain phrase consist of the interpretations of its syntactic constituents  . In case the form of a grammatical rule is A+B C  , the frames of the constituents B and C form the arguments for the < cog > of the grammatical rule  , and then the semantic interpreter produces the interpretations of the phrase A  . In this manner , the semantic processing is carried out in a bottom-up and left-to-right fashion  . 
Here we have a problem : since MELING is a basically breadth-first parser  , the number of interpretations which are sense less to human beings becomes very large as the length of the sentences increases  , and the parser operates inefficiently . ( In fact , the time required for the older version of MELING to process a sentence of length n is generally proportional to n  2 and sometimes n ~ . ) However , EXAM does not produce all combinations of possible interpretations  . The semantic interpreter is evoked in two cases ( see 3 . 1): in the first case , it determines the sense representation and eliminates some interpretations  ; in the second case , EXAM attempts to produce the meaning representation and also produces certain " anticipations "  . 
In the first semantic interpretation , the traditional and most powerful tool is socalled semantic marker  . EXAM implements this tool using the generalization hierarchy  . For some " cases " , such as locative and time , the semantic marker functions as the selection restrictions  . However , for other " cases " it does not , and in such cases , it is regarded as an indicator of the " likelihood " of various interpretations  . Furthermore , the Japanese language has many homonyms which have the same categories  , especially nouns . We group such homonyms into several special frames whose category is " GROUP " in accordance with their semantic category  . If there is sufficient information to determine the sense of the semantic interpretation  , the " GROUP " frames are replaced by the frames corresponding to the appropriate sense  . 
The " case ordering " is also an indicator of " likelihood "  . Inoue 4 points out that in Japanese , there is a certain ordering of cases in themati -zation and relativization  , such as : subject > object > dative > locative egoal >source  . . . 
We have adopted this notion and have applied it to the disambiguation of certain grammatical ambiguities  . For example , consider the following phrase :
Taroonokenkyuu
In the absence of any particular context , the system is more likely to interpret this phrase as Tarooga suru/sitakenkyuu ' the research carried out by Taroo ' than Tarooni tuite noken kyuu ' research concerning Taroo '  . 
These ' devices are very effective in dealing with homonymy  , polysemy and grammatical ambiguity . EXAM chooses the most plausible interpe-tations depending upon their " likelihoods "  . If there are several interpretations whose " likelihoods " are equally great  , then EXAM retains all of them . That is , " likelihood " is used to indicate the order of preference of interpretations  . 
In the semantic interpretation , if the " PROTO " frames are instantiated with some slot filler  , then the category " PROTO " is replaced by the category " INSTANT "  . The distinction between these categories , that is , " PROTO " and " INSTANT " , is important . For example , akaii ronokuruma ' a red car ' and sonnairono kuruma ' a car with such a color ' are wellformed expressions  , butironoku ~ ma'a car with color ' is rather ill-formed  . We explain this phenomenon as follows : the frame with the " INSTANT " category is  , as it were , a specified frame , and is therefore preferred to " PROTO " frames in the modification of other frames  . This distinction is also used as an indicator of " likelihood "  . 
\[ We must note that the frames with categories such as " PROTO "  , "INSTANT " and " GROUP " are merely temporary in the working memory  , and these categories are replaced by appropriate ones such as " CLASS "  ( which means generic )  , " INDIVIDUAL " ( which means specific object ) or " SOME " ( which means in definite object ) in the meaning interpretation process . \] In the second semantic interpretation , dealing with referential ambiguity constitutes the most important phase of the process  . Usuall ~ candidates for the referent are not uniquely determined in the local context where the ambiguity occurs  . Therefore , EXAM delays the disambiguation until after the entire sentence has been processed  . EXAM collects the requirements of the referent from the interpretation of the comlete sentence  . In particular , some Predicates such as hosii ' want'produce opaque contexts  , and in such cases the category determination II should be carried out after processing the entire sentence  . 

Another pretation is parsed treesing sentence ( 5 ) Taroono task involved in the second inter-the elimination of unnecessary  . For example , consider the follow-in u wak or i id a . 
' Taroo's do g is a collie . '
When MELING has processed the sentence ( 5 ) up through the word wa , it produces the following partial parsed trees :
SnOUFI theme\\dettheme
Taroonoinuwa Taroonoinuwa
In this case , only the first is plausible , and the second is unnecessary . ( In fact , the second partial parsed tree is plausible only when the sentence is of a form such as : Taroo no  , inuwa . . . ) Therefore , EXAM eliminates unnecessary parsing trees in accordance with the result of the semantic interpretation  , that is , " likelihood " . This method makes the parsing process more efficient  , but involves some risk of misinterpretation . Hence , the elimination of parsing trees is carried out on the basis of certain linguistic evidence  7  , and the number of the parsed trees which are retained may sometimes be greater than one  . 
The other task is to produce " anticipations " in the second semantic interpretation  . Consider the following sentence : ( 6 ) Taroowaterebiomi-nagarabenkyousi-ta . 
' Taroo studied while watching television . ' When EXAM observes nagara , it anticipates that the agent of mi ( ru ) ' watch'will be coreferential with the agent of the verb of the matrix sentence  , that is , in this example , benkyousi ' study ' . In this manner , " anticipations " also serve to produce plausible interpretations and eliminate some ambiguities  . 
As for ambiguities in meaning , EX ~ does not deal with these in an entirely conclusive manner  . However , we should note that " cohesion relations ''3 play an important role in disambiguation . Dealing with ambiguities in meaning requires comprehension of the structure of the text and the determination of the topic  . The structure of the text is determined by the cohesion relations  . First , EXAM attempts to recognize how sentences are related  . In particular , conjunctions and sentences which are provided to support the reader's comprehension are employed in the recognition of these relations  . If EXAM succeeds in recognizing these relations , then the inference mechanism attempts to explain why these sentences are related  . In this manner , EXAM deals with ellipsis and properly disambi -guates some sentences  . For example ,   ( 7 ) Kaeru wahiatarino yoi mizunonakanit ~ nagoo umi-masu  . At a takai to koronohouga yoku so datu kara desu . 
' Frogslay their eggs in water which is well exposed to sunshine  . Because they grow well in warm places . ' The second sentence is related to the first by the " explanation relation " and this is indicated by kara ' because '  . Then EXAM attempts to clarify the question of why the second sentence constitutes an explanation of the first  . In this case , mizunonaka ' in water ' and tokoro ' place ' correspond to one another  , and EXAM discovers the omitted element ( kaeru gaun-da ) tamago ' eggs ( which are layed by frogs ) ' 4 . DEALING WITH AMBIGUITIES AF TER PARSING So far , we have discussed the question of dealing with ambiguities while parsing  . However , ambiguities may still remain ! Furthermore , in some sentences , such as the headings of news articles , we often find ambiguities which we cannot eliminate for lack of a preceding context  . 
How can we deal with such situations ? In this section  , we describe some strategies which are still under development now  . 
In such cases , we must delay the disambiguation and provide some mechanism for selecting the appropriate interpretation when sufficient information has been supplied  . One solution is to introduce a kind of Truth Maintenance  System2  . 
For example , consider the following sentence : ( 8 ) Every man loves a woman . 
As is well known , sentence (8) has two interpretations . These interpretations are stated in the first order predicate calculus as follows:  ( 8- a ) Vx\[man ( x ) + my\[woman ( y ) Alove ( x , y ) \]\]  ( 8-b ) 3y\[woman ( y ) ^Yx\[man ( x ) ? love ( x , y ) \]\] This sentence should not be regarded as meaningless  , even if we have no context and hence cannot disambiguate it  . Since we can deduce (8-a ) from (8-b ) , we surely have at least the information described in  ( 8- a )  . Hence , we enter ( 8- a ) into the text memory as a " premise " and ( 8-b ) as a " hypothesis " . If some information contradicting (8-b ) exists , the Truth Maintenance System will delete ( 8-b ) from the text memory . 
Here , we adopt the following standpoint : if the disambiguation is essential for the understanding of the text  , the text ( or the writer ) will certainly provide clues adequate to disambiguate the sentence  , and if this is not the case , the system may adopt any interpretation consistent with the context  . 
In fact , sentences which follow ambiguous ones are often paraphrases of or explanations for them  . For example , (9) John says that everyone loves a woman . Whom does John think everyone loves ? The first sentence of  ( 9 ) is ambiguous , but we can disambiguate it by means of the second . 
Thus , we had better delay the interpretation of ambiguous sentences after having processed  5  . CONCLUSION We have discussed the procedures by which EXAM deals with ambiguities  . This constitutes a difficult task for an NLUS and the trivial method of asking the user to choose one of several possible interpretations has been adopted  . 
In dealing with ambiguities , EXAM avoids the combinatorial explosion of possible interpretations by means of several devices  . We classify ambiguities into two categories , that is , ambiguity in sense and ambiguity in meaning . EXAM adopts the strategy of first processing sense representations  , and secondly meaning representations ; the parsing process is carried out in an essentially breadth-first manner  . 
However , EXAM does not completely clarify ambiguities in meaning  , especially ambiguities which are not resolved by the preceding context  . 
This constitutes a problem which still awaits solution  . 

The author wishes to express his since regratitude to Professor Masao Iri  , Dr . Hozumi Tanaka , Dr . Elmer J . Brody and Hidetosi Yokoo for encouragement , cooperation , and various useful comments and suggestions . 
REFERENCES\[i \] Bobrow , D . G . and Winograd , T . , " An Overview of KRL , a Knowledge Representation Language " , Cognitive Science , Vol . i , No . i , 1977, pp . 3-45 . 
\[2\] Doyle , J . , " A Glimpse of Truth Maintenace ", Proc . of the 6th International Joint Conference of Artificial Intelligence  ,  1979 , pp . 232-237\[3\] Hobbs , J . R . , " Coherence and Coreference ",
SRI Tech . Note 168, 1978.
\[4\]Inoue , K . , Nihongo no Bunpou Kisoku ' The Rules of Japanese Syntax '  , Taishukan ,  1978 . 
\[5\] Kooij , J . G . , Ambiguity in Natural Language,
North-Holland , 1971.
\[6\] Lyons , J . , Semantics , Cambridge Univ . Press , 1977 . 
\[7\] Minami , F . , Gendai Nihon~o no Kouzou ' Structures of Modern Japanese Language '  , Taishukan ,  1974 . 
\[8\] Nishio , M . , Iwabuchi , E . and Mizutani , S . , Iwanami Kokugo Jiten dai 2 han'lwanami's Japanese Dictionary 2nd ed . ', lwanami , 1971 . 
\[9\] Tanaka , H . , Sato , T . and Motoyoshi , F . , " Predictive Control Parser : Extended Lingol " , Proc . of 6th International Joint Conference on Artificial Intelligence  ,  1979 , pp ~ 868-870 . 
\[ i0\]Winograd , T . , Understanding Natural Language,
Academic Press , 1972.
\[ ii \] Yokoo , H . and Sirai , H . , " Bunmyaku Syouou Rikai o Hukumu Nihongo Syori Sisutemu ' A System for Understanding Anaphora in Discourse '"  , Proc . of 21th Conference of Information Processing Society of Japan  ,  1980 , pp . 1006-1007 . 

