USINGLINGUISTIC , WORLD , AND CONTEXTUAL KNOWLED GE
INAPL ANRECOGNITION MODEL OF DIAL OGUE ~
LYNNLAMBERT and SANDRACARBERRY
Department of Computer and Information Sc iences 
University of Delaware
Newark , Delaware 19716, USA
email : lamber t@cia , udel , edu , earberry@c is , udel , edu
Abstract
This paper presents a plan-based model of dialogue that combines world  , linguistic , and contextual knowledge in order to recognize complex communicative actions such as expressing doubt  . Linguistic knowledge suggests certain discourse acts  , a speaker's beliefs , aud the strength of those beliefs ; contextual knowledge suggests the most coherent continuation of the dialogue  ; and world knowledge provides evidence that the applicability conditions hold for those discourse acts that capture the relationship of the current utterance to the discourse as a whole  . 
1 Introduction
Recognizing the roles that utterances play in a dialogue and how the utterances should be interpreted in the context of preceding dialogue is a crucial part of a robust model of understanding  . In order to perform this recognition , our tripartite plan-based model of dialogue identifies not only domain and problem-solving actions but also discourse or communicative actions that determine how utterances relate to each other  . 
For this communicative action recognition , we combine information gleaned from a variety of knowledge sources : contextual  , linguistic , and world knowledge . 
The combination of these different knowledge sources enables the recognition of complex communicative actions such as expressing do nbt  . Although our tripar-tite model recognizes three different kinds of actions  ( domain , problem-solving , and discourse ) , the focus of this paper will be the recognition of discourse actions and how a combination of knowledge sonrces enables us to perform this recognition  . 
2 Our Tripartite Model
A number of researchers have contended that a coherent discourse consists of segments that are related to one another through some type of structuring relation \[  Gri75  ,   MT83\] or have modeled is course based on the semantic relationship of individual clauses \[  Pol86\] or groups of clauses \[ Rei78\]  . But all of these fail to capture the goal -oriented natnre of discours c  . Grosz and Sidner\[ GS86\] argue that recognizing the structural relationships among the intentions underlying a  1 This work is being supported by the National Science Foundation trader Graait No  . IR1-9122026 . The ~ overrlnlellth & scer-tMn rights in tiffs material  . 
discourse is necessary to identify discourse structure  ; although they do not provide the details of a computational mechanism for recognizing these relationships  , they do argue convincingly that it requires multiple knowledge sources  . We have developed a plan-based model of dialogue and have incorporated into our model Grosz and Sidner's claim that linguistic  , contextual , and world knowledge should be combined in recognizing the role of an utterance in a discourse  .   . 
We contend that at least three kinds of actions , domain , problem-solving , and discourse , should be captured by a model of task-oriented i alogue  . 
Many researchers \[ A1179 , Car 87 , LAB7 , Sid 85 ,   GS86\] have demonstrated that recognition of domain action sendows a system with the ability to success-fnlly address many important and difficult problems in understanding  . Several researchers have also investigated the recognition of problem-solving actions \ [  LA87  , Ram 9I , Wil 81\] . For example , if a user wants to earna degree , the user might perform problem-solving actions of  1  ) evaluating alternative degrees ( i . e . , the user might decide whether a BS or a BA is more desirable  )  , 2) instantiating the type of degree to be earned , and 3 ) building a plan for performing the domain action of earning the selected egree  . 
Carberry\[ Car89\] points out the importance of recognizing discourse actions  , the communicative actions that speakers perform iumaking an utterance  ( e . g . , asking a question , providing baek grouml information , or expressing surprise ) . Discourse actions provide expectations for subsequent utterances  ( e . g . , when a question is asked , one expects the question to be accepted and eventually answered  )  . Recognition of some discourse actions such ms Give-Background also explains the purpose of an utterance and bowit should be interpreted  ; rather than just a statement of fact , the utterance providing background information should be used by the system to fill in necessary background knowledge in order to fully understand related utter-antes  . 
We capture these three types of actions in separate levels of our disconrse model  , which we refer to as a DM\[LC91\] . Within each of these levels , actions may contribute to other actions on the same level  ; for example , on the discourse level , providing background data , asking a question , and answering a question all can be part of obtaining information  . Thus , actions at each level form a tree structure in which each node represents an action that a participant is performing and the children of a node represcntactions pursued in order to perform the parent action  , t to wever , discourse , problem-solving , and domain actions are not ACTESDECOLING-92 , NAMES , 2328 AOI~'P 199 2310 PROC . OVCOLING-92, NAI , ZrES . AUG .  2328, 1992
Domain Levelr .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  ,
I*rI'~+'Co~SI'CS+60) I : .   .   .   .   .   .   .   .   .   .  -~-  .   .   .   .   .   .   .   .   .   .   .   .   . , Pt?-b-(em--':s--~YI9tJ--~Y-q .   .   .   .   .   .   .   . ~ t .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   , I """ d'P ~" ~ s_!::S2 , Ta~-Co ' " o ~ S 1 , CS3~?!)\]IlmNlliale-V , ars ( Slr $ 21 Lea ~ lI-Mateflal(S\[tC 3601 . . fac)l \[

Discourse Levell .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  -  .   .   .   .   .   .   .   .   .   .   .   .   .   . i .   .   .   .   .   .   .   .   .  ,  .   .   .   .   .  2",' .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
IOb , min+tnfo-Ref CSI ,  $2 , _fat , Teaches ( fac , CS300))\]

A\[.~:uot(sl,ss,:.~,'r + ~ h?~t.?,css6o))
Reque ~ l(Sl . 2, ln form + Ref(S2.
\[st,f ~, Teachex(_fac,CS360))\[
Surface-Wn-Question(S1 , S2 , I\[fac , Teach ~(_ fac , C8360))\[\[Answer-Ref(S2 , Sl , jac , -'+ I Teaches L . fa ~, CS 36 . O ) , Teaches ~ D6Smith ~ CS 360)\[ hl form ( S2 , Sl , Teaches ( Dr . Snlim . CS360)) I?\[*T'?II(S ;,' SI,Teaches(Dr . Smlth , lLq360)) " lISurface-Inform(S2 , Sl , Teaches ( Ill . Smith , CS 36 0 ) ) I Figure 1: Dialogue Model for two utterances --~" = Emfi ) le Arc = Subactlon Arc completely independent of one another  ; discourse actions may be executed in order to obtain the information necessary for performing a problem-solving action and problem-solving actions may bcexecuted in order to construct a domain plan  . Our model captures this interaction by allowing links between the actions at adjacent levels  . Figure I contains a sample DM derived from two utterances  , and section 3 describes how the
DM in Figure 1 is constructed.
3 Different Kinds of Knowledge
The following dialogue will be used to demonstrate why our system needs world  , contextual , and linguistic knowledge , and to show low the combination of these different knowledge sources enables the system to recognize implicit acceptance of previously commuuicated propositions and to identify the role of utterances that cannot be determined from one or two knowledge sources alone  . The system is playing the role of $2 , (1) SI : Who is teaching CS 3607(2)$2: Dr , Smithisteaching CS 36 0 . 
(3 ) SI : Bulisn't CS 360 an undergrad course ? ( d ) $2: Yes . 
(5) Dr . Smith leaches gradnate and undergrad courses . 
(6) Sl : Who handles the CS'360 lab ? 3 . 1 Wor ld Knowledge In order to recognize how actions are intended to contribute to otlm r actions  , our system needs knowledge abont how to perform actions  . This world knowledge is I ) rovided in the form of a library of discourse , problem-solving , and domain recipes \[ Pol 90\] . Our representation of a recipe includes a header giving then a toe oftile recipe and the action that it accomplishes  , preconditions , applicability conditions , constraints , abody , effects , and a goal . Applicability conditions represent conditions that nmst be satisfied illorder for the recipe to be reasonable to apply illtile given situation whereas constraints limit the allowable instantia-lion of variables in each of the components of a recipe\[  LA87  , Car 87\] . Figure 2 contains a sample discourse recipe . 
Given the senlalltic representation fanew utterance  , the system mnst assimilate tim utterance and produce an updated dialogue model  ( DM )  . Plan inference rules\[ A1179\] and constraint satisfaction \[ LA87  ,   Car87\] suggest chains of higher level actions that an utterance may in ! part of  , and foetlsing heuristics\[Car 87 , SidSl\]order these inference paths according to coherence  . For exanlple , the semantic rel ) resentation of ( 1 ) is : Surface WH-Question ( fil ,  $2 , _fac , Teaches (_ fac , csa@))From this surface question , t ) lan inference rules suggest that ( 1 ) is executing a Rcquest action and that this Request action is part of an Ask-Re\]action which in turn is part of an Obtain-lnfl~-Re\] action since each of these actions is part of the body of a recipe that performs the higher level action As the system infers these actions  , tile system also tentatively ascribes certain beliet ~ that must hold in order fl ~ r the agent to be pursuing these discourse actions l " or example  , morder for (1) tolw part of ; mObtaln-ln\]o-Rcfaction ,   , ql must not know the answer to thv quest h)n ; if SIknew who was teaching CS 360 , this utterance might be part of a 7'est-L+slcncr action instead . These requisite beliefs are capture dill tile applicability conditions of discourse recipes  . A stile system in Drs actions , it must be plausibh ~ that the applicability conditions are ACRESDE  COLING-92  , NANTES . 2328 AO~r 1992311 P Rec . OFCOLING-92, NANTES , AUG .  2328 .   1992 Discourse Recipe-Cl: _agent1 expresses doub to _agent2 about_propl because _agent1 believes _prop2 to be true Action : Express-Doubt ( _agent l , _agent 2 , _ propl , _prop 2 , _rule )
AppCond : believe(_agent l , _prop2) believe(_agent l , befieve(_agent2 , _ propl )) believe(_agent1 , _rule ) believe (_ agent l , ((_ prop2A_rule ) = ? , ~_ propl ) ) in-focus ( _ propl ) Body : Convey-Uncertain-Belief ( _agent l , _agent 2 ,   . prop2) Address-Q-Acceptance (_ agent2 , _agent 1 , -prop2) Effects : believe(_agent2 , ~ be heve (_ agent l , _ propl )) be heve (_ agent2 , want (_ agent l , Resolve-Conflict (_agent2 , _agent l , _prop1 , _prop2))) Goal:want(_agent2 , Resolve-Conflict (_agent2 , _agent l , _ propl , _prop2))
Figure 2: Sample Discourse Recipe satisfied ; otherwise , the inference is rejected . 
So , another part of our system's world knowledge is a model of the speaker's beliefs  . Since our investigation of naturally occurring dialogues indicates that people express hades of belief in propositions and expect others to recognize these beliefs  , we maintain a multi-strength model of beliefs to represent an agent's varying degrees of belief in a proposition  , ranging from having no idea whether a proposition is true  ( or false )  , to being certain that a proposition is true ( or false )  . We also maintain a model of a stereotypical user whose beliefs may be attributed to the speaker as appropriate during tim course of the conversation  . 
After the system has inferred actions on the discourse level  , it must identify how these relate to problem -solving and domain actions  . This is accomplished by chaining between actions on adjacent levels of the DM  . For example , once the system infers that ( 1 ) contributes to an Obtain-lnfo-Refaction on the discourse level  , plan inference rules suggest that S1 wants the goal of the Obtain-lnfo-Refaction , namely know ref(S1 , _fac , teaches (_ fac , CS360)) . Since knowing possible fillers for a parameter is a precondition to instantiating that parameter  , the system infers that S1 wants to know who is teaching CS360 in order to instantiate the instructor parameter in an action to learn the material for that course  ; that is , the system infers that S1 want slnstantiate-Single-Var ( S1 ,  $2 , _fac , Learn-Material ( S1 , CS 36 0 , _fac )) . Since in stautiating one paranteterman action is part of a plan to instantiate all of the parameters in that action  , the system infers that St want slnslanlial c-Vars ( S1 ,  $2 , Learn-Matenal ( Sl , CS 36 0 , _fac )) , and since this latter action is part of a recipe for building a plan  , the system then infers the problem-solving action  , Build-Plan ( S1 ,  $2 , Take-Course(S1 , CS360)) . These instantiate-Single-Var , lnstantiate-Vars , and Build-Plan actions are entered into the problem-solving level of the DM  . Building a plan to perform some domain action is a precondition to doing that action  ( assuming agents are acting intentionally )  , so the system infers that Sl wants Take-Course ( Sl , CS360) , and this domain action is entered into the domain level of the DM  . 
Once the system has assimilated an utterance into the DM  , it nmst update its belief nm del for the speaker to reflect the beliefs that were tentatively ascribed to the speaker during the plan inference process  . 
These beliefs can then be used in understanding subsequent utterances  . 
3.2 Contextual Knowledge
Each new utterance must be interpreted with respect o the existing dialogue context \ [  GS86  , Car 87\] . 
This process requires contextual knowledge , which our system captures with the use of the DM , a focus of attention which designates the most salient  . action on each level of the DM , and focusing heuristics which suggest the most coherent continuation of the dialogue  . 
For example , on the discourse level , utterances that contribute to the currently focused action are more expected  , and thus more coherent , than utterances that contribute to an ancestor that is further removed from the focus of attention  . This contextual knowledge creates expectations that help determine how to interpret new utterances  . For example , after aqnestion is asked , the context suggests that acceptance of the question will be pursued  ( i . e . , the listener will ensure that the question is understood  , justified , and answerable ) ; then it is expected that the question will be answered  . 
Because our system does not yet include a planner , we incorporate S2's utterances into the DM in the same way as Sl's have been  . So , continuing with our example dialogue , we express the semantic representation of ( 2 ) as : Surface-lnform ( S2 , $1 ~ Teacites(Dr . Smith , CS 36 0 ) ) Plan inference rules suggest hat the surface inform might be part of a Tell action which might be part of an Informaction  2 which migh the part of an Answer-Refaction which might in turn be part of an Obtain-lnfo-Rcf action since each of these actions is part of the body of a recipe that performs the higher  le4el action . 
Contextual knowledge is then used to determine how to relate  ( 2 ) to the previous dialogue . Focusing heuristics suggest hat the best interpretation of  ( 2 ) is that it is part of a plan for performing the Obtain-lnfo-Refaction that was an ancestor of the Request action of utterance  ( 1 )  . No new problem-solving or domain actious are inferred  . 
Figure 1 gives the DM that our system builds from utterances  ( l ) and ( 2 ) with the current focus of 2We differentiate between telling a listener some string of words said in forming a listener of a proposition  , hiorder to informal is tener of some proposition  , the listener must first un-derstaald the content of the proposition  ; tiffs is the goal of the Tellaction . The goal of the ln\]ormaction is that the listener believe the COlmnunicated proposition  . 
AcrEsDECOL 1NG-92 , NANTES , 2328 AOI~T1992312 PROC . OFCOLING-92, NANTES , AUG .  2328 ,   1992 attention on each level marked with an asterisk . Thus , we have seen that both world knowledge ( consisting of a plan library and beliefs about the speaker's beliefs  ) and contextual knowledge ( consisting of the existing DM , the current focus of attention , and focusing heuristics ) are required in order to determine what actions a speaker is performing and how these actions relate to the l  ) revious dialogue . 
3.3 Linguistic Knowledge
Linguistic knowledge must also be taken into account in recognizing the actions that a speaker is performing  . This knowledge in ehldes the surface form of an utterance and clue words  . The surface form of an utterance is one way that a speaker communicates varying degrees of belief in a proposition  . Consider , for example , the following two utterances : (7) Is Dr . Smitht each ing CS 3107(8) Isn't Dr . Smitht eaching CS3107 The form of the utterance in ( 8 ) indicates an uncertain belief in t improposition that Dr  . Smithisteaching CS 310; utterance (7) , however , conveys only a lack of knowledge about the proposition  . Similarly (3) is not merely a Yes/No question ; instead , this surface form conveys that S1 thinks that CS360 is an undergrad course , but is not certain of it . Our system uses the form of the utterance to recognize the strength of a speaker's beliefs  ; these beliefs are then used to determine whether the applicability conditions for the suggested discourse actions are satisfied  . 
Tile second type of linguistic information that we use is clue words  . These lingtfistic clues often sng-gest whattype of discourse action the speaker might be  pursuing\[LAB7  , H in 89\] . a We use these linguistic clues as evidence for discourse actions  . For example , utterance (3) contains the clue word " but , " which suggests a non-acceptance discourse action  . Thus , the linguistic information that our system captures includes knowledge about the surface form of an utterance and about clue words  . 44 Combining Knowledge for
Discourse Act Recognition
Because there arenlany ways that an utterance can continue a dialogue and because the correct interpretation is not always the one most strongly suggested by plan chaining and focusing heuristics  , evidence from other knowledge sources is needed to identify the intended relationship between an utterance and the existing dialogue context  . For example , the interpretation of ( 3 ) most strongly suggested by focusing heuristics is that of requesting clarification of  ( 2 ) in order to nnderstand it . Intuitively , however , (3) seems to be e?-pressing doubt at S2's answer , not trying to understand 3The surface form of some utterances may also serve this purpose  . 
4The utter~ame itself in fact contains more ilf formation than just clue words  , surface for nl , and propositional content , but our system uses only these three . Part of our future work includes incorporating other linguistic information such as tense  . 
it . Plan inference rules and focasing heuristics then are not sufficient odetermine what role  ( 3 ) is serving in the discourse . More knowledge is needed from other sources . 
Intuitively , for each new utterance that relates to the previous dialogue on the discourse level  ,   5 there is some discourse action that captures this relationship and serves to describe the role of the new utterance with respect to the preceding dialogue  . Since many such relationships are plausible ( e . g . ,  ( 3 ) could be interpreted as expressing doubtor as indicating a lack of understanding  )  , we contend that evidence is required for recognizing the discourse action that identifies the correct relationship  . 
In our model , this discourse action will he an element of an inference path from the utterance to some action in the current tree structure on the discourse level  . Furthermore , it will introduce new parameters which must be instantiated based on values from the DM in order for the path t ? terminate with an action already in the DM  . By replacing these new parameters with values from the DM that are not present in the semantic representation of the utterance  , wc are hypothesizing a relationship between the new utterance and the existing discourse level of tile DM  . Thus , this action serves the aforementioned role of capturing how the new utterance relates to the current dialogue context  . We will refer to such actions ase-actions since we contend that there must be evidence to support he inference of these actions  . 
For example , suppose that the semantic representation of an utterance such as  ( 8 ) is
Surface-Neg-YN-Question(Sl , $2 PropA ) and that chaining suggests that the utterance is part of a Convey-Uncertain  . Belief action which is part of a recipe for the Express-Doubt action shown in Figure  2  . The parameters_agent ; I , _agent 2 , and _p~rop2 in the Express-Doubt action will be instant iated with the values  $1  ,  $2 , and PropA that appear in the semantic representation of the utterance and propagate during chaining to the Convey Uncertain-Belief action and in turn to the Express-Doubtaction  , t lowever , the parameters_propl and Aru\] . e are introduced for the first time in the Express -Doubt action and have many plausible instantiations  . Continued chaining from the Express-Doubt discourse action could eventually lead to an Informaction  , and we might equate this Inform with an Inform that already exists in the DM  , thereby interpreting tile new utterance as related to this previously identified action  . Unifying the Informaction on tim inference path with an Informaction in the DM  , and propagating the resultant substitutions back down the inference chain  , will result in_proptanti_vu : l . ebeing instantiated based on information from the DM  . In particular , _propl will be instantiated with the proposition from the Informaction and_vu : l_e will be constrained to a rule that SI might tt fink suggests that  _prop2 and_prt ~ pl are inconsistent . 
l lowever , it is not enough that these instantiations plausibly satisfy the applicability conditions for the Express-Doubtaction  . For example , consider tile following dialogue : 5 Solne utterances , llcha~(1) and (6) , do I lot relate to previous dialogue on the discourse lvel  . 
ACRESDE COLING-92 , NAN q~S , 2328 AO'/Zr 1992313 PROC . OFCOLING-92, NANTES , AUG .  2328 , 199 2t 9t SI : Who is teaching CS 3607($2: Dr . Smith . 
(11) SI:Isn't Dr . Smithlhe professor who won the teaching award last year ? While it is at least plausible that  , in the mind of the speaker , there is a rule which makes winning at each ing award in consistent with teaching  CS360  , interpreting ( 11 ) as expressing doubt at ( 10 ) seems incorrect . Thus , to prevent such erroneous interpretations , we contend that evidence is needed to recognize discourse actions that capture the relationship between a new utterance and the existing dialogue context  . 
In our recognition algorithm , evidence may take two forms : 1 ) world knowledge indicating that tile applicability conditions for an e-action are satisfied  , and 2 ) linguistic evidence from clue words suggesting a par-titular discourse action  . If the system has evidence that the applicability conditions of an e-action are satisfied  , tilen the system will use the knowledge as evidence that this may be the discourse action that the speaker is pursuing  . On the other hand , if there is sufficient linguistic knowledge suggesting a particular discourse action  , then these applicability condition should be attributed to the speaker  , as long as they are plausible ( i . e . , if there is nothing in the system's model of the speaker's beliefs to suggest hat the applicability conditions are not satisfied  )  . So , if the clue word but is used , then a non-acceptance discourse action such as expressing doubt should be easier to recognize  ( i . e . , silould require less evidence that the applicability conditions hold  ) than if the clue word is not present . 
For example , consider the following , in which there are no clue words in ( 14 a ) and ( 14 b )  , but (14~) contains the clue word but . 
(12) Sl : Who is teaching CS 3607 (13) $2: Dr . Smith . 
(14,) SI:Isn't Dr . Smithons abbatical next year ? ( 14 b ) SI:Isn't Dr . Smith the professor who won the teaching award last year ?  ( 14 c ) SI : But isn't Dr . Smith the professor who won the teaching award last year ? Chaining from  ( 14~ ) could produce an inference path containing an Express-Doubt discourse action  . The surface form of (14 , ) establishes that S1 has an uncertain belief that Dr . Smithisons abbatical , the first applicability condition for an Express -Doubtaction  ( see Figure 2 )  . s The effect of the question/answer pair in ( 12 ) and ( 13 ) is that SI believes that $2 thinks that Dr . Smith teaches CS 360 , tile second applicability condition in all Express-Doubtaction  . Tilestereotypemmhl\[e contains the belief that professors on sab-batical do not teach  , so the system can ascribe to SI the following belief : Vx  , y ( course ( y ) A professor ( x ) Aon-sabbatical ( x ) ) ~ ~ teachcs ( x , y ) . This belief satisfiest be third applicability condition  ( the belief about a rule )  , and this belief , along with the belief that Dr . 
Smithisons abbatical , implies that Dr . Smith is not teacbmg CS 360 , the fourth applicability condition . Finally , a check of the DM indicates that the proposition e The first applicability condition is actually an uncertain belief  .  \[  LC92\] describes our fortnal belief model and how belief strengths are represented in recipes and in our belief model  . 
that Dr . Smith teaches CS 360 is in focus , the last applicability condition . Therefore , since there is evidence for the applicability conditions of the Express-Doubtaction  , and since focusing heuristic suggest hat this is a coherent discourse action  ( although not the most preferred )  ,   ( 14 a ) is recognized as expressing doubt at S2's answer , that Dr . Smithisteaching CS 36 0 . 
If the dialogue included ( 14 b ) or ( 14 c ) instead of ( 14 a )  , some of the same evidence would exist . Ill both (14b ) and (14c) , the system believes l ) that S1 believes that Dr . Smitllwon the teaching award last year ( though S1 is not sure of this )  , 2) that S1 believes tlmt $2 thinks that Dr . Smithisteaching CS 36 0 , and 3) that the proposition that Dr . Smith teaches CS 360 is in focus . Thus , some of the applicability conditions for expressing doubt at Dr  . Smitht each ing CS 360 hold . 
However , tim system has no knowledge for titile crucial implication that determines how this utterance relates to tile preceding dialogue  ; the system has no evidence that S1 believes that winning at eaching award implies that Dr  . Smith is not teaching CS 360 . Therefore ,   ( 14 b ) is not interpreted as an expression of doubt at the response in  ( 13 )  , and other discourse acts are considered . The presence of the clue word in (14 e ) , however , strongly suggests an Express-Doubt discourse act and thus less evidence is needed to recognize it  ; that is , the system does not need explicit evidence that S1 holds the requisite beliefs but only needs to be able to plan-sibly ascribe them to SI  . Therefore , since mlr model call plausibly ascribe to S1 belief in the implication that Dr . Smithwinning at eaching award implies that Dr . Smith is not teaching CS 360 , the system will recognize ( 14~ ) and ( 14 c ) as expressions of doubt , using evidence from linguistic knowledge for ( 14~ ) aml from world knowledge for ( 14o )  . 
Thus , we want our system to use linguistic knowledge when present  , world knowledge when present , and both when possible . On r algorithm for processing is tim following : from the semantic representation of the utterance  , infer sequences of actions ( inference paths ) using plan inference roles . If the applicability conditions for any of these actions are implausible  , reject the inference . For actions which are note-actions , tentatively ascribe the beliefs in the applicability comlitions  . For actions that are e-actions , determine how much evidence is available for titile action  . If there is more than one e-action for which there is evidence from both linguistic and world knowledge  , then choose the inference path closest to the focus of attention for which there is multiple evidence  . If linguistic or world evidence is available for nmret hanonee-action  , then choose the inference path closest to the focus of attention with this single supporting piece of evidence  . If there is no evidence for any e-action , then choose tim inference path which contains no e-actions and is closes to the focus of attention  . 
5 Completing the Example
We return briefly to the dialogue given in Section  3 to il hlstrate how our process model uses the above algorithm to recognize complex communicative action such as expressing doubt as well a simplicit acceptance of previous utterances  . 
Utterances (1) and (2) were discussed earlier , ACTESDECOLING-92 , NANTES , 2328 Ao(rr 1992314 PROC . OFCOLING-92, NANTES , AUO .  2328, 1992
Dluoourse Level
Dom~dn Leveli .   . ~ .   . iprol ? l . em- . .,~ ly  n ~ . 1:  . re(el .   .   .   .  \]  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
Ilnstantiate-V ~? . 1l : llnstantiate-Sin~le-Var\]I ~, . , ~ si . N0v~I , .   .   .   .   .  - :~-  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . -~- ":- ~ ~  . ~ , . .
---~--= Enable Arc =, ~ tlbact loll Arc
Obtain-hffo-Ref(2)(3) (4) (6) (5)
Figure 3: Dialogue Model for Example and the IM for these utterances is given in Figure  1  . 
Tile semantic representation of ( 3 ) is : Surface-Neg-YN-Question ( Sl ,  $2 , undergrad-e on rse ( CS360)) . 
The surface form of the utterance suggests that Sl thinks that  CS360 is all undergrad course , hut is not certain of it . This belief is tentatively entered into the system's model of Sl's beliefs  . Plan inference rules suggest that the surface request is an action in a Convey-Uncertain-Belief action  . The linguistic clue but suggests that S1 is objecting to sorn c previous utterance of S2's   . One of the possible infereuees from the Convey -Uncertain-Belief action is an Ezpress-Doubt action  . 
t lowever , since this is an e-action , evidence is necessary to infer this action . The linguistic clue provides one piece of evidence to support this inference  , but the system also looks for evidence from world knowledge  . 
It therefore cheeks to see if it is plausible that  S1 's belief about CS360 being an undergrad course might mq ) tyt , hat Dr . Smith is not teaching CS 360 . Althought be system has no such belief explicitly represented in its model of S  1  , there is also no evidence to suggest hat S 1 does not helieve that this implication might hold  . Since there is no othere-action for which there is evidence and since tim applicability conditions for an Express-Doubt action are plausible  , the system infers that the Convey-Uncertain -Belief action may be an action in an Express -Doubt action which may be an action in an Address -Unacceptance discourse action which may be an action in an Address-Believability discourse action which may be an action in an lnJorm action  . Focusing heuristics suggest hat this hf form is the same Inform that  ( 2 ) is pursuing . Tiros ,   ( 3 ) is interpreted ms not accet ) ting ( 2 ) by expressing doubt at it . vlnferencing for the rcmainder of the dialogue is similar to the first three utterances  . The int~rence paths which result from utterances ( 4 ) and ( 5 ) are shown in Fig~lre 3 above the appropriate numbers . 
Finally , although the system initially a~tentpts to closely relate utterance  ( 6 ) to other utterances at the discourse level , there is no evidence for any e-action that might link this utterancc to the existing context on tile discourse level  . There arc no clue words to suggest a relationship  , and there arc noe-actions for which there is evidence that the applicability conditions hoht  . Therefore , a completely new discourse action of obtaining information is inferred  , sT tf is initiation of a new discourse action indicates implicit acceptance of tile previous discourse actions since if  S1 did not accept $2'  . ~ answer ,   $1 would be required to indicate non-acceptance\[ LC92\]  . The DM for the entire dialogue is shown in 1 , ' igure 3 ( for space rea . sons , only tile action names are shown ) . Thus our model recognizes both acceptance and non -acceptance of communicated  7Although not discussed , there must also be m~c-actlon that relates ( 2 ) totile DM . This action is tile Answer-J ~ e\] ; vidence for the An . ~ wer-Re\]action is fi'om world knowledge , whic : h indicates that the applicat ) ility conditions for this Answer-Re\]action hold  . 
htferencing of (2) is then similar to that of (3).
8Further discussion may determine that SI is trying to continue the negotiation dialogue  ; however , that has not been communicated by this utter a ~ lce  . We a ~' eit tvestigatlng how our sys-tern might modify the I  ) M that it has built if it discovers later that the structure built previously is incorrect  . 
ACTESDECOLING-92 , NANTES , 2328 AOt ~ Tr 1992315 PROC . OFCOLING-92, NANTES , AUG .  2328 , 1992 propositions , including acceptance after negotiation of \[ GS86\] conflicting beliefs . 
This example has illustrated : 1 ) how the structure of a discourse is identified in our three level model  , how our model recognizes the relationship of the cur-\[  Rin89\] rent utterance to the existing context and to other utterances  , and how the tripartite structure produces a richer model of discourse structure than previous models  ; 2) how beliefs are communicated , recognized , and used in the identification of discourse actions and discourse structure  ; and 3 ) how our process model uses \[ LA87\] linguistic , world , and contextual knowledge together in order to recognize acceptance and non-acceptance of communicated propositions  . 
6 Conc lus ions and Future Work \[ LC91\] Our plan-based model of dialogue incorporates world  , linguistic , and contextual knowledge sources into the recognition of communicative actions  . Lin-\[ LC92\] guistic knowledge suggests certain discourse acts  , a speaker's beliefs , and the strength of those beliefs ; contextual knowledge suggests the most coherent continuations of the dialogue  ; and world knowledge provides evidence that the applicability conditions hold for those \[  MT83\] discourse acts that identify the relationship of the current utterance to the discourse as a whole  . By combining these different knowledge sources , we are able to recognize complex discourse acts such as express-\[  Po186\] ing doubt , to identify the relationship of utterances to one another  , and to capture the rich structure of task -oriente dialogue  . 
Grosz and Sidner\[ GS86\] claim that a robust model of understanding must use constraint satisfaction to interpret utterances  ; that is , when evidence is \[ Pol90\] available from one source , less evidence is needed from other sources . We have partially included their suggestion by using world and linguistic knowledge when contextual knowledge is not sufficient o infer actions for which the remus the some evidence  . However , we would like to expand our notion of partial evidence\[  Ram91\] to allow evidence from the three knowledge sources to be represented in terms of degree : thus  , when world knowledge is overwhelmingly strong , no other knowledge is needed , but when it is very weak , knowledge from other sources will be needed to suppor the inferences not allowed by the weak world knowledge alone  . 
References\[ A1179\]  \[  Car87\]  \[  Car89\]  \[~  ri75\] James F . Allen . A Plan-Based Approach to Speech Act Recognition . PhD thesis , University of q bronto , Toronto , Ontario , Canada ,  1979 . 
Sandra Carberry . Pragmatic Modeling : Toward a Robust Natural Language Interface  . 
Computational Intelligence , 3:117-136, 1987.
Sandra Carberry . A Pragmatics-Based Approach to Ellipsis Resolution  . Computational
Linguistics , 15(2):75-96, 1989.
Joseph E . Grimes . The Thread of Discourse.
Mouton , The Hague , Paris , 1975.
\[Rei78\]\[Sid81\]\[Sid851\[Wil81\]
Barbara Grosz and Candaee Sidner . Attention , Intention , and the Structure of Discourse . Computational Linguistics , 12(3):175-204, 1986 . 
Elizabeth Hinkelman . Two Constraints on
Speech Act Ambiguity . In Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics  , pages 212-219 , Vancouver , Canada ,  1989 . 
Diane Litmus and James Alien . A Plan
Recognition Model for Subdialogues in Conversation  . Cognitive Science , 11:163-200, 1987 . 
Lynn Lambert and Sandra Carberry . A Tri-partite Planobased Model of Dialogue . In Proceedings of the 29th Annual Meeting of the ACL , pages 4754 , Berkeley , CA , June 1991 . 
Lynn Lambert and Sandra Carberry . Modeling Negotiation Dialogues . In Proceedings of the 30th Annual Meeting of the ACL , Newark , 
DE , June 1992. To appear.
William C . Mann and Sandra A . Thompson.
Relational Propositions in Discourse . Technical Report ISI/RR-83-115 , ISI/USC , November 1983 . 
Livia Polanyi . The Linguistics Discourse Model : Towards a Formal Theory of Discourse Structure  . Technical Report 6409 , Bolt Beranek and Newman Laboratories Inc . ,
Cambridge , Massachusetts , 1986.
Martha Pollack . Plans as Complex Mental
Attitudes . In Philip R . Cohen , Jerry Morgan , and Martha E . Pollack , editors , Intentions in Communication , pages 77-104 . MIT
Press , 1990.
Lance A . Ramshaw . A Three-Level Model for Plan Exploration . In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics  , pages 3646 , Berkeley , 
California , 1991.
Rachel Reichman . Conversational Coherency.
Cognitive Science , 2:283-327, 1978.
Candace L . Sidner . Focusing for Interpretation of Pronouns . American Journal of Computational Linuistics ,  7(4):217-231 ,  981 . 
Candace L . Sidner . Plan Parsing for Intended Response Recognition in Discourse  . Computational Intelligence , 1:1-10, 1985 . 
Robert Wilensky . Meta-Ptanning : Representing and Using Knowledge About Planning in Problem Solving and Natural Language Understanding  . Cognitive Science , 5:197-233, 1981 . 
AcrEsDECOLING-92 , NANTES , 2328 ^ ot ~ r1992316 PROC . OFCOLING-92, NANTES , AUG .  2328, 1992
