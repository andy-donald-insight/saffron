A MORPHOLOGICAL RECOGNIZER WITH SYNTACTICAND
PHONOLOGICAL RULES
John Bear
Artificial Intelligence Center
SRI International
333 Ravenswood Ave
Menlo Park , CA 94025


This paper describes a morphological naly zer which  , when parsing a word , uses two sets of rules : rnles describing the syntax of words  , and rules describing facts about orthography . 
1 Introduction t
In many natural language processing systems currently in use  , the morphological phenomenare handled by programs which do not interpret any sort of rules  , but rather contain references to specific morphemes  , graphemes , and grammatical categories . 
Recently Kaplan , Kay , Koskennicmi , and Kart tunen have shown how to construct morphological analyzers in which the descriptions of the orthographic and syntactic phenomena are separable from the code  . This paper describes a system that builds on their work in the area of phonology/orthography and also has a well defined syntactic omponent which applies to the area of computational morphology for the first time some of the tools that have bccn used in syntactic analysis for quite a while  . 
This paper has two main parts . The first deals with the orthographic aspects of morphological analysis  , the second with its syntactic aspects . The orthographic phenomena constitute a blend of phonology and orthography  . The orthographic rules given in this paper closely resemble pho Im logical rules  , both inform and fimctlon , but because their purpose is the description of orthographic facts  , the words orthography and orthographic will be used in preference to phonology and phonological  . 
The overall goal of the work described herein is the development of a flexible  , usable morphological analyzer in which the rules for both syntax and spelling arc  ( 1 ) separate from the code , and ( 2 ) descriptively powerful enough to handle the phenomena encountered when working with texts of written language  . 
2 Orthography
The researchers mentioned above use finite-state transducers for stipulating correspondences between surface segments  , and underlying segments . In contrast , the system described in this pa-llamin debted to Lauri Karttunen and Fernando Pereir ~ for all their help  . Laurl supplied the initial English automat ~ on which the orthographic grammar was based  , while Fernand of urnished some of the Prolog code . Both provided many helpful suggestion ~ and explanations as well  . I would also like to thank Kimmo Koskennlemi for his comments on an earlier draft of this paper  . 
This research was supported by the following grants : Naval Electronics Systems Command  N00039-84-K-0078  ; Navelex N00039-84-C-0524 P00003 ; Office of Naval Research N00014-85-C-0013 . 
per does not use finite state machines . Instead , orthographic rules are interprete directly , as constraints on pairings of surface strings with lexieal strings  . 
Tile rule notation employed , including conventions for expressing abbreviations  , is based on that described in Koskenniemi \[1983 , 1984\] . Tile rules actually used in this system are based on tile account of English in Karttunen and Wittenburg  \[1983\]  . 
2.1 Rules
What follows is an inductive introduction to the types of rules needed  . Some pertinent data will be presented , then some potential rules for handling these data  . We shall also discuss the reasons for needing a weaker form of rule and indicate what it might look like  . 
Let us first consider some data regarding English /s / morphemes: 
ALWAYS-ES box+s~--~boxes class+s ~ classes fizz+s~fizzesspy+----*spiesash+s~ashes ehureh+s~---ochurches 
ALWAYS-Sslam+s~slamshit+s~hitstip+s*--- * tips 
SOMETIMES-ES,
SOMETIMES-Spiano+s ~ pianos solo+s~solos do+s ~ does potato+s ~ potatoes banjo+s ~ banjoes or banjos cargo+s ~ cargoes or cargos Below are presented two possible orthographic rules for describing the foregoing data : tu  )  + - - -  , cxIzIy/iIs ( h ) Ich_sp ~2 ) + ---* exIzIy/iIs ( h ) Ieh Io_s The first of these rules will be shown to be too weak  ; the second , in contrast , will be shown to be too strong . This fact will serve as an argument for introducing a second kind of rule  . 

Before describing how the rules should be read , it is necessary to define two technical terms . In phonology , onespeaks of underlying segments and surface segments  ; in orthography , characters making up the words in the lexicon contrast with characters in wordforms that occur in texts  . The term lezical character will be used here to refer to a character in a word or morpheme in tile lexicon  , i . e . , the analog of a phonological underlying segment . 
Tile terms at\[ace character will be used to mean a character in a word that could appear in text  . For example ,   \[1 ove+ed\]is a string of lexieal characters , while \[ I oved \] is a string of surface characters  . 
We may now describe how the rules should be read . The first rule should be read roughly as , " a morpheme boundary \[+\] at the lexical level corresponds to an \[ el at the surface level whenever it is between a n\[x\]andan\[s\]  , or between a\[z\]andan\[s\] , or between alcxical \[ y \] corresponding to a surface\[i \] and an\[s\]  , or between an \[ sh\]andan\[s\]or between a\[eh\]andan\[s\]  . " This means , for instance , that the string of lexical characters \[ chur eh+s\]corresponds to the string of surface characters\[churches\]  ( forgetting for the moment about the possibility that other rules might also obtain  )  . The second rule is identical to the first except for an added\[o \] in tile left context  . 
When we say \[+\] corresponds to \[ el between an lxl and an N  , we mean between a Icxical Ix\]corresponding to a surface lxl and a lexical Is\]corrcsponding to a surface \[ s\]  . If we want cd to say that it does not matter what the lexieal\[x\]corresponds to on the surface  , we would use\[x/=\]instead of justix\] . 
The rules given above gettile facts right for the words that do not end in \[ o\]  . For those that do , however , Rule1 misses on\[do+s\]~-~\[docs\] , \ [ potato+s\[?=~\[potatoes\] ; Rule 2 misses on\[piano+s\]~\[pianos\] , \[ solo+s\]~:~\[solos\[ . Furthermore , neitherule allows for the possibility of more than one acceptable form  , as in \[ banjo+s\]~ ( \[ banjoes\]or\[banjos\] )  , \[ cargo+s\](\[ cargoes\]or\[cargos\]) . 
The word sending in \[ o \] can be divided into two classes : those that take an \[ es\]in their plural and third-person singular forms  , and those that just take an \[ s\] . Most of the facts could be described correctly by adopting one of the two rules  , e . g . , the one stating that words ending in \[ o \] take an \[ es \] ending  . In addition to adopting this rule , one wouhl need to list all the words taking an \[ s\]crating as being irregular  . This approach has two problems . First , no matter which rule is chosen , a very large number of words wouhthave to bc listed in the lexicon  ; second , this approach does not account for the cocxlstcnce of two alternative forms for some words  , e . g . ,\[ banjoes\]or\[banjos\] . 
The data and arguments just given suggest he need for a second type of rule  . It would stipulate that such and such a correspondence is allowed but not required  . An example of such a rule is given below :
R3) +/ callowed in contexto_s.
Rule 3 says that a morpheme boundary may correspond to an\[elbetweenan\[o\]andan\[s\]  . It also has the effect of saying that if a morphcme boundary ever corresponds to an \[ c\]  , it must be in a context hat is explicitly allowed by some rule  . 
If we now have the two rules R1 and R3,
R1 ) 4 - ~ e/xlz\[y/\[Is ( h ) \[ eh-s
R3)+\]e allowed in contexto_s , we can generate all the correct forms for the data given  . Furthermore , for the words that have two acceptable forms for plural or third person sing-ular  , we get both , just as we would like . The problem is that we generate both forms whether we want them or not  . Clearly some sort of restriction on the rules , or " finetuning , " is in order ; for the time being , however , the problem of deriving both forms is not so serious that it cannot be tolerated  . 
So far we have two kinds of rules , those stating that a correspondence always obtains in a certain environment  , and those stating that a correspondence is allowed to obtain in some environment  . The data below argue for one more type of rule , namely , a rule stipulating that a certain correspondence nver obtains in a certain environment  . 
DATA FOR CONSON ANT DOUBLING
DOUBLING : bar+ed~barred big+est ~ biggest refer + ed+---~referred 
NODOUBLING : question+ing , - --4 questioning hear+ing ~ hearing hack+ing ~ hacking
BOTH POSSIBILITIES : travel+ed ~ ( travelled or traveled ) both are allowed In English , final consonants are doubled if they , " follow a single\[orthographic\]vowel and the vowel is stressed  . "\[ from lart tunen and Wittenbnrg 1983\] . So for instance , in\[hear+ing\] , thcfinal \[ rI is preceded by two vowels , so there is no doubling . In\[haek+ing\] , the final \[ k\] is not preceded by a vowel , so there is no doubling . 
In \[ question + lug\] , the last syllable is not stressed so again there is no doubling  . 
In Karttunen and Wittenlmrg \[1983\] there is a single rule listed to describe the data  . l lowever , the rule makes use of a diacritic ( ' ) for showing stress , and words in the lexicon must contain this diacritic in order for the rule to work  . The same thing could be done in the system being described here  , but it was deemed undesirable to allow words in the lexicon to contain diacritics encoding information such as stress  . Instead , the following rules are used . Ultimately , the goal is to have some sort of general mechanism  , perhaps negative rule features , for dealing with this sort of thing , but for now no such mechanism has been implemented  . 
RULESFORCONSON ANTDOUBLING " Allow ed-type " rules '+'/ ballowed in contextv Vb_vVz '+ '/ callowed in contextv Vc_vV '+'/ d allowed in contexlv VdvV '+'/ fallowed in contextvVf_vV'+'/gallowed in contextvV g_vV'+'/I allowed in contextvVIvV '+'/ mallowed in contextv Vm_vV'+'/nallowed in contextv Vn_vV '+'/ pallowed in context vVp_vV'+'/rallowed in contextvVr_vV' +'/ sallowed in contextvVs_vV '+' It allowed in contextv Vt V'+'/z allowed in contextvVz_vV " D is allowed-type " rules '+' /bd is allowed in contextvVvV h_vV '+'/ c disallowed in contextvVvV c_vV '+'/ d disallowed in contextv Vv Vd _v V  2In these rules , the symbol vV stands for any element of the following set of orthographic vowels : a  , e , i , o , u . 
2 73 '+'/ fd is allowed in context vVv Vf V '+' /gd is allowed in contextv Vv Vg_vV  '+'/1 disallowed in contextvVvVlvV '+'/ m disallowed in contextvVvVm_vV'+'In disallowed in contextvVvVn_vV '+'/ p disallowed in contextvVvV pvV '+'/ r disallowed in contextvVvVr_vV '+'/ s disallowed in contextvVvVs_vV '+'/ t disallowed in contextvVvV tV'+'/z disallowed in contextv Vv Vz_v V The allowed -type rules in tile top set are those that license consonant doubling  . The disallowed-type rules in the second set constrain the doubling so it does not occur in words like\[eat+ing\]?:==>\[eating\]and\ [ hear+ing\]?====~\[ hearing I  . The disallowed-type rulcs say that a morpheme boundary \[+\] may note ver correspond to a consonant when tile \[+\] is followed by a vowel and preceded by that same consonant and then two more vowels  . 
The rules given above suffer from the same problem as the previous rules  , namely , overgeneration . Although they produce all the right answers and allown ml tiple forms for words like \[ travel+er \] ~   ( \[traveller\]or\[traveler\] )  , which is certainly a positive result , they also allow multiple forms for words which do not allow them  . For instance they generate both \[ referred\] and\[refered\]  . As mentioned earlier , this problem will be tolerated for the time being . 
2 . 2 Compar i son w i th Koskenn iemi ' s Rules Koskenniemi  \[1983  , 1984\] describes three types of rules , as exemplified below :
R4) a > b := :*- c/dc/f-g/hi/j
RS)a>b ~= olde/f-g/hi/j
R6) a > b~e/dell-g/hi/j .
Rule R4 says that if a lexical \ [ a \] e or responds to a surface \[ b \]  , then it must be within tile context given , i . e . , it must be preceded by \[ c/d eft \] and followed by \[ g/h i/j  . This corresponds exactly to tile rule given below : RV  ) a/b allowed in context olde/f_g/hi/j . 
The rule introduced as R5 and repeated below says that if a lexieal\[a\] occurs following\[c/de/f and preceding\[g/h i/j  , then it must correspond to a surface \[ b \]:
RS)a>be-=e/de/f_g/hi/j .
' rhe corresponding rule in the formalism being proposed here would look approximatel yike this :   R10  ) a/sSd is allowed in contexte/dc/f-g/hi/j , where sS is some set of characters to which \[ a \] can correspond that does not include \[ b\]  . 
A comparison of each system's third type of rule involves com-post on of rules and is the subject of the next section  . 
2 . 3 Ru le Compos i t ion and Decompos i t ion In Koskennlemi's systems  , rule composition is fairly straightforward . Samples of the three types of rules are repeated here: 
R4) a > b=:~e/de/fg/hi/j
R5) a > b ?=== e/de/f_g/hi/j
R6) a > b~e/de/f_g/hi/j
If a grammar contains the two rules , R4 and RS , they can be replaced by tile single rule R6 . 
In contrast , the composition of rules in the system proposed here is slightly more complicated  . We need the notion of a default correspondence . The default correspondence for any alphabetic character is itself  . In other words , in the absence of any rules , an alphabe ti character will correspond to itself . There may also be characters that are not alphabetic  , e . g . , the \[+\] representing a morpheme boundary , currently the only non-alphabetic character in this system  . Other conceivable non-alphabetic characters would be an accent mark for representing stress  , or say , a hashmark for word boundarics . The default for these characters is that they correspond to  0   ( zero )  . Zeroisttle name for the null character used ill this system  . 
Now it is easy to say how rules are composed in this system  . 
If a grammar contains both Rll and RI2b clow , qlen RI3 may be substituted for them with the same effect : Rll  ) a/b allow edit , contexte/de/fg/hi/jR 12 ) a/"a's default " disallowed in contexte/de / fg/h~/j 
R13) a ~ b/c/de/fg/hi/j
In fact , when a file of rules is read into the system , oCCUl'rence : ~ of rules like RI3 are internalized as if the grammareally contained a rule like Rll and another like  R12  . 
2.4 Using the Rule ~
Again consider for an example tile rule R1 repeated below . 
R1 ) + -- ~ e/xIzlY/i\[s ( h ) \ [ oh_s When this rule is read in , it is expanded into a set of rules whose contexts do not contain disjunction or optionality  . Rules R14 through R19 are the result of the expansion :
R14)'+'--~e/xs
R15)'+'~ e/z_s
R 16)'+'--~ e/y/i_s
R 17)'+'--* e\]s si2.18)'+'~ e/shs
R19)'+'~ e/eh_s.
R 14 through R19 arc in turn expanded automatically into R20 through R31 below : R20  ) '+'/0 disallowed in context x_sR21 ) %'/0 disallowed in context z_sR22 ) '+'/0 disallowed in context y/i . . s R23 ) '+'/0 disallowed ill contexts-sR 24 ) '+'/0 disallowed in context sh:sR25 ) '+'/0 disallowed in context ch_sR 26 ) '+' / eallowed ill context x_sR 27 ) '+'/ e allowed in context z_sR 28 ) '+'/ e allowed in context y/i-sR 29 ) '+'/ e allowed in contexts_sR 30 ) '+'/ e allowed in context sh-sR 31 ) '+'/ e allowed in contexteh_s . 

The disallowed-type rules given here stipulate that a morpheme boundary  , lexieal\[+\] , may never be paired with a mill surface character  ,  \[0\] , in the environments indicated . Another way to de . scribe what disallowed-type rules do , in general , is to say that they expressly rule out certain sequences of pairs of letters  . For example , R20
R20 )   +/0 disallowed in can text x_s states that the sequence  . ,, X'-"8 .  ,  . 
III . . . X0S ...
is never permitted to be a part of a mapping of a surface string to a lexical string  . 
The allowed-type rules behaves fightly differently than their disallowed-type counterparts  . A rule such as
R26)'+'/e allowed in context x_s , says that lexieal\[+\] is not normally allowed to correspond to surface Ie \]  . It also affirms that lexical \[ q-\] may appear between as Ix and a~tIs  . Other rules starting with t be same pair say , in effect , " here is another cn virmun cnt where this pair is acceptable  . " The way these rules are to be interpreted is that a rule's main correspondence  , i . e . , the character pair that corresponds to the underscore in tile context  , is forbidden except in contexts where it is expressly permitted by some rnle  . 
Once the rules are broken into the more primitive allowed-type and disallowed-type rules  , there are several ways in which one could try to match them against a string of surface characters in tile recognition process  . One way wonld be to wait until a pair of characters was encountered that was the main pair for a rule  , and tficn look backwards to see if the left context of the rule matches the current analysis path  . If it does , put the right context on hold to see whether it will ultimately be matched  . 
Another posslblility would be to continually keel ) track of the left contexts of rnles that are matching the characters at hand  , so that when t be main character of a rule is encountered  , the program already knows that the left context has been matched  . 
The right context still needs to be pnt on hold and dealt with the same way as in the other scheme  . 
The second of the two strategies i the one actually employed in this system  , though it may very well turn out that the first one is more efficient for the current grammar of English  . 
2.5 Possible Correspondences
The rules act as filters to weed out seqnenees of character pairs  , but before a particular mapping can bcweeded out  , somcthlng needs to propose it~s being possible . There is a list called a list of l ) ossible correspondences , or sometimes , a list offeasible pairs - that tells which characters may correspond to which others  . Using this list , the ri : cognizer generates l ) ossible Icxica \] forms to correspond to tile input surface form  . These can then bcchecked agains the rules and agains the lexicon  . If tim rules (1o not weed it out , and it is also in the lexicon , we have successfully recognized a morpheme . 
3 Syntax
The goal of the work being deserl bcd was an analyzer that would be easy to use  . In the area of syntax , this entails two subgoal . s . 
First , it should be easy to specify which morphemes may combine with which  , and second , when tile recognition tlas been completed , the result shnuld be something that can easily be used by a parser or some other program  . 
Karttunen \[1983\] and Karttlmen and Wittenburg \[1983\] have some suggestions for what a proper syntactic component for a morphological analyzer might contain  . They mention using contextfree rules and some sort of feature-handling system as possible extensions of both their and Koskenniemi's systems  . In short , it has been acknowledged that any such system really ought to have some of the tools that have been used in syntax proper  . 
The first course of action that was followed in building this analyzer was to implement a unification system for  ( lags ( directed acyclie graphs )  , and then to have the analyze runify the dags of all tile morphemes encountered in a single analysis  . That scheme turned out to be too weak to be practical  . The next step was to implement a PATR rule interpreter\[Shieber  , et al 1983\] so that selected paths of dags could b cunified . Finally , when that turned out to be still less flexible than one would like  , tile capability of handling disjunction in the dags was added to the unification package  , and the PATR rule interpreter\[Karttnncni984\] . 
The rules look like PA'I'R rules with tile context free skeleton  . 
The first two lines of a rule are just a comment , however , and are not used in doing the analysis . The recognizer starts with the ( lag\[cat:empty\] . The rnlebelow states that the " empty " dag may be combined with the  ( lag from a verb stem to produce a dag for a verb . 
% verb ~ emllty+verb stem % 1   2   3   <2 cat >= empty <3 cat >= verb_stem <3 type >= regular <1 type >= <3 type > < l cat >= verb <1 word >= <3 lex > < lform >= inf tense : prespers : 1  ~  1  . 
The resulting dag will hea . mbigatous between an infinitive verh , and al ) rcsent tense verb that is in clther the first or second person  .   ( The braces in timrule arc the indicators of disjunction  . ) The verb stem's value for the feature Icx will be whatever spelling tile stem has  . This value will then I ) e the value for the fl ~ at ~ u ' e word in the new ( lag . 
The analyzer applies these rules in a w~ry simple wrff  . It always carries along a ( lag representing the results found t , hnsfar . 
Initially this dagis\[cat:empty\] . When a morpheme is fonnd , tile analyzer tries to combine it , via a rule , with the ( lagit has been carrying along . If tile rule succeeds , a new ( lag is produced and becomes the ( lag carried along by the analyzer . In this way tile information about which morp bentes have been fonn dispropagated  . 
If anling is encountered after a verb has been found  , the following rule builds the new ( lag . It first makes sure that the verb is infinitive ( form : inf ) so that tile suffix cannot be added onto the end of a past participle  , for instance , and then makes the tense of the new dag be pres part for present participle  . The category of the new dag is verb , and the value for word is the same as it was in the original verb's dag  . The form of the input verb is a disjunction of inf  ( infinitive ) with \[ tcnsc : prcs , pets : 12\] , so the unification succeeds . 
275% verb ~ verb+ing % 1 ~ .   3   <2 cat >= verb <3 lex >= ing <2 form >= inf <1 eat >= verb <1 word >= <2 word > <1 form >=\[ tense:prespart\] . 
The system also has a rule for combining an infinitive verb with the nominalizing\[er\] morpheme  ,   . g . , swim:swimmer . This rule , given below , also checks the form of the input verb to verify that it is infinitive  , it makes the resnlting dag have category : noun , number : singular , and so on . 
% noun - - ~ verb+er % 1   2   3   <2 cat >= verb <3 lex > -- er <2 form >= inf <1 cat > --- noun <1 word >= <2 word > <1 nbr >= sg <1 p e r s > = :3   . 
The noun thus formed behaves just the same as other nouns  . 
In particular , a pluralizing Is\]may be added , or a possessive \[' s\] , or any other affix that can be appended to a noun . 
There are other rules in the grammar for handling adjective endings  , more verb endings , etc . Irregular forms are handled in a fairly reasonable way  . Their regular nouns are listed in the lexicon with form : irregular  . Other rules than the ones shown here refer to that feature  ; they prevent tile addition of plural morphemes to words that are already plural  . Irregular verbs are listed in the lexicon with an appropriate value for tense  ( not unifiable within f ) so that the test for infinitiv cness will fail when it should  . Irregular adjectives , e . g . good , better , best are dealt within an analogous manner . 
4 Further Work
There are still somethings that are not as straightforward as one would like  . In particular , consider the following example . Let us suppose as a first approximation that one wanted to analyze the \[ un\]prefix in English as combining with adjectives to yield new ones  , e . g . , unfair , unclear , unsafe . Suppose also that one wanted to be able to build past participles of transitive verbs  ( passives ) into adjectives , so that they could combine with\[t in \] , a . ~ in uncovered , unbuilt , unseen . 
What we would need , would be a rule to combine an " empty " with an \ [ un\]to make an\[un \] and then a rule to combine an \[ un\]with a verb stem to form a thing l  , and finally a rule to combine a thing l with a past participle marker to form a negative adjective  . 
More rules would be needed for the case where \[ un\]combines with an adjective stem like \[ fair \]  . In addition , rules would be needed for irregular passives , etc . 
In short , without a more sophisticated control strategy , the grammar would contain a fair amount of redundancy if one really attempted to handle English morphology in its entirety  . However , on a more positive note , the rules do allow one to deal effectively and elegantly with a sufficient range of phenomena to make it quite acceptable as  , for instance , an interface between a parser and its lexicon . 
5 Conclusion
A morphological analyzer has been presented that is capable of interpreting both orthographic and syntactic rules  . This represents a substantial improvement over the method of incorporating morphological facts directly into the code of an analyzer  . 
The use of these rules leads to a powerful , flexible morphological analyzer . 
References\[1\] Karttunen , L .   ( 1983 ) " Kimmo : A General Morphological Processor , " in Tezas Linguistic Forum #22 , Dalrymple et al , eds . , Linguistics Department , University of Texas,
Austin , Texas.
\[2\] Karttunen , L . (1984) " Features and Values , " in COLING 84 . 
\[3\] Karttunen , L . and K . Wittenburg ( 1983 ) " A Two-level Morphological Analysis Of English , " in Texas Linguistic Forum #22 , Dalrymple et al , eds . , Linguistics Department , University of Texas , Austin , Texas . 
\[4\] Kay , M . (1983) " When Meta-rules are not Meta-rules , " in K . Sparcke-Jones , and Y . Wilkes , eds . Automatic Natural Language Processing , Jotm Wiley and Sons , New York . 
\[5\] Koskenniemi , K . (1983) " Two-level Model for Morphological
Analysis , " IJCAI83, pp . '683-685.
\[6\] Koskennlemi , K .   ( 1984 ) " h General Computatlona \] Model for Word form Recognition and Production  , ~ COLING 84 , pp .  178-181 . 
\[7\] Selkirk , E . (1982) The Syntaz of Words , MIT Press . 
\[8\] Shieber , S . , It . Uszkoreit , F . Percira , J . Robinson , and M Tyson ( 1983 ) " The Formalism and hnplementation of PATR-II , " in B . Grosz , and M . Stiekcl ( 1983 ) Research on Interactive Acquisition and use of Knowledge  , SRI Final Report 1894 , SRI International , Menlo Park , California . 

