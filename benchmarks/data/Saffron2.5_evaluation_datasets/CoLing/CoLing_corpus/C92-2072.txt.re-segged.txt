Towards Robust PATR
Shona Douglas * and Robert Dalet
Centre for Cognitive Science
University of Edinburgh
Edinburgh EH8 9LW , Scotland
Abstract
We report on the initial stages of development of a robust parsing system  , to be used as part of The Editor's Assistant , a program that detects and corrects textual errors and in felicities in the area of syntax and style  . Our mechanism extends the standard PATR-n formalism by indexing the constraints on rules and abstracting away control of the application of these constraints  . This allows independent specification of grouping and ordering of the constraints  , which can improve the efficiency of processing , and in conjunction with information specifying whether constraints are necessary or optional  , allows detection of syntactic errors . 
Introduction
The Editor's Assistant \ [ Dale 1989 ,   1990\] is a rule-based system which assists a copy editor in massag-ing a text to conform to a house style  . The central idea is that publishers ' tyle rules can be maintained as rules in a knowledge base  , and a special inference engine that encodes trategies for examining text can be used to apply these rules  . The program then operates by interactively detecting and  , where possible , offering corrections for those aspects of a text which do not conform to the rules in the knowledge base  . 
The expert-system-like architecture makes it easy to modify the system % behaviour by adding new rules or switching rule bases for specific purposes  . 
Our previous work in this area has been oriented towards the checking of low-level details in text : for example  , the format and punctuation of dates , numbers and numerical values ; the punctuation and use of abbreviations ; and the type faces and abbreviations to be used for words from foreign languages  . 
In this paper , we describe some recent work we have carried out in extending this mechanism to deal with syntactic errors  ; this has led us to a general mechanism for robust parsing which is applicable outside the context of our own work  . 
? Email addeasi S . Douslaa@ed.ac.uk.
tAI so of the Department of Artificial Intelligence at the University of Edinburgh  ; email address is
R , Dale?ed.ac.uk.
Syntactic Errors
Categories of Errors
Ultimately , the aim of The Edilor JsAssistant is to deal with real language ~ unrestricted natural language text in all its richness  , with all its idio~yn-cracies . The system is therefore an experiment in what we call intelligent text processing : an intersection of techniques from natural anguage pro-cossing and from more mundane text processing applications  , with the intelligence being derived from the addition of language sensitivity to the basic text processing mechanisms  . 
Many of the corrections mader outinely in the course of human proofreading require subleties of semantic and pragmatic expertise that are simply beyond current resources to emulate  . However , examination of common syntactic errors and in felicities  , both as described in the literature ( see , for example , \[ Miller 1986\] ) and es appearing in data we have analysed , has led us to distinguish a number of tractable r -ror types  , and we have based the development of our system on the various requirements imposed by these classes  . The error types are defined very much with processing requirements in mind  ; orthogonal cate-gorisations are of course possible  . We give summary descriptions of these cla . ~shere ; examples are provided in Figure 1 . 
Constraint Violation Errors:
These involve what , in most contemporary syntactic theories , are best viewed as the violation of constraints on feature values  . All errors in agreement fall into this category . 
Lexlcal Confusion : These involve the confusion of one lexical item with another  . We specifically include in this category cases where a word containing an apostrophe is confused with a similar word that does not  , or vice versa . 
Syntactic Awkwardness : We include here cases where the problem is either stylistic or likely to cause processing problems for the reader  . Note that these ' errors ' are not syntactically incorrect  , but a reconstructions which , if overused , may result in poor writing , and as such are often included in style-checker ' hit-lists '  ; thus , we would include multiple embedding constructions  , poten-ACT , SDECOLING-92 , NANTES , 2328 AOIJT 1992468 PROC . OFCOLING-92, NANTES , AUO .  2328, 1992
Constraint Violation Errors: ( l ) Subject-verb number disagreement : a . * John and Mary runs . 
b . * The dogs runs.
(2) Premodifier-noun number disagreement : a . * This dogs runs . 
b . * All the dog run.
(3) Subject-complement number disagreement : a . * There is live dogs here . 
h .* There area dog.
(4) Wrong pronoun case . : a . * ll candmer anto the dog . 
b , * This stays between you and I , (5) Wrong in delb lit carticle : a . * A apple and an rottenold pear . 
b . ANeXT workstation and * a NE Claptop.1
Le . xical Confosion : ( 6 ) Confusion of its and it's : a . * Its late . 
b . * Tim dogate it's bone.
(7) Confusion of that ,, their , and they're : a . * Their is a dog here . 
b , * They ' re is a dog here.
e .* Ttmrc dog was cohi.
d . * They're dog was cold.
e .* The relere now.
f . * Tt mir here now.
(8) Confusion of p~ivc's and plurals : a . * The dog's are cold . 
b .*3' lieboyate the dogs biscuit.
Syntactic Awkwardness : ( 9 ) ~\[ bomany prepositional phraees : a . Tileboy gave the dog in the window at the end with tilered collar with the address on the back of it a biscuit  . 
(10) i ) a ~' ~ ive constructions : a . The boy wa . sseen by the dog . 
Missing or extra elements : ( 11 ) Unpaired delimiters : a . * The dog , wllich was intile garden was quiet . 
(12) Missing delimiters : a . * The dog , I think was in the garden . 
b . * In the garden dog , sarcame nace.
(13) Missing list ~ parators : a . * There were two dog ~ three cats and a canary . 
( ld ) Double syntactic function : a . * its ~, cms to be is a dog . 
b . * l think know F ve been there before.
Figure 1 : Example's of Syntactic Errors : tally anlbiguou syntactic structures  , and garden path sentence ~ s in this category . These problems are detectable by simple counting or recognition of syntactic forms  . 
Missing or Extra Elements :
The searcc ~ mes where elements ( either words or ptmctuation symbols ) arc omitted or mistakelfly included in a text . An interesting subcategory here , which is surprisingly frequent , is the pres~ence of two constituents which serve the same or a similar purpose  ; by analogy with double-word errors ( where a word appears twice it , succession when only one occurrence was intended )  , we refer to these as cas ~ of doul ) le syntactic function . 
The crrors dealt within this paper all fall into the first class  , i . e , thorn that can be seen as breaking constraint . son feature values . At the end of the paper we slakes onte observations on how the mechanism can bc  . extended lx ) the other classes . 
: Previous Work
Of course , there exists a signiiicant body of work dealing with  ( xml putational approaches to syntactic errors like those just discu ~  . scd . Broadly , work dealing with ungrammatical input falls into two cate-goric : approaches where the principal objective is to determine what meaning the speaker intended  , and approach ~ where the principal objective is too on struct mlap propriate correction  . The first kind of approach is most appropriate in the development of natural language in Lcrfaces  , where syntactic dys-flueneies can often be ignored if tile ~ mer~s intentions can be determined by means of other evidence  , tIow-ever , these , approach ~( in the simplest cases , based on detecting content words ) arc inappropriate where thesy sL mamustal . ,~o propose a correction for the hypothcsised error  . 
Of the differented miqucs that have been propo . ~md under the second category , the most useful is that usually referred to as re laxation  . T iffs is a rather elegant method for extending a grammar's coverage to include ill-formed input  , while retaining a principled connection between thc constructions accepted by the more restrict ive grammar and those accepted by the extended one  . If a grammar exprt . ~ses in-form a Lionill terms of constraints or conditions on features  , a slightly leasre , ~trietiv cgrammar can be constructed by relax ing some subset of these con-strain Ls  . Work commonly referred to in this corntextine lud ~ K wasny and Sond heimer  \[1981\] and Weischedel and Black \[1980\]  , but very many systems u . ~ e . some kind of relaxation process , whether of syn-tactic or semantic on straints . The most wellknown is lnM'~q work on the Epistle and Critique systems\[tleidornctel  . 1982; Jensenet at . 1983; Richardson and Braden-t Iarder 1988\] . 
ll n British English , NEC is spelled out , rather than being pronolmeed like the word neei4 thus , the correct form here is an NEC , Ae*rl~s DECOIANG-92 , NAtCn . : S , 2328 AOI\]T1992469 PROC . O1: COLING-92, N^I~rgs , AUG .  2328 , 1992E pistle parses text in a left-to-right , bottom-up fashion , using grammar rules written using an augmented phrase structure grammar  ( APSG )  . In APSG , each gramma rule looks like a conventional contextfree phrase structure rule  , but may have arbitrary tests and actions specified on both sides of the rule  . So , for example , we might have a rule like the following : ( 15 ) NO VP ( NUMB . AGREE . NUMB(NP )) - ~
VP(SUBJECT = NP)
This rule states that a noun phrase followed by a verb phrase together form a VP  ,   2 provided the number of the N\[ and the original VP agree  . The resulting VP structure then has the original NP as the value of its 
SUBJECT attribute.
Using rules like the ~ e , the system attempts to parse a sentence as if it were completely grammatical  . Then , if no parse is found , the system relaxe some conditions on the rules and tries again  ; if a parse is now obtained , the system can hypothesise the nature of the problem on the basis of the particular condition that was relaxed  . Thus , if the above rule was used in analysing the sentence Either of the models are acceptable  , no parse would be obtained , since the number of the NP Either of the models is singular whereas the number of the VP are acceptable is plural  . However , if the number agreement constraint is relaxed , a parse will be obtained ; the system can then suggest hat the source of the ungran \] matical-ity is the lack of number agreement between subject and verb  . 
One thing that must be borne in mind when considering the merits and demerits of relaxation methods is that they depend crucially on how much of the particular  grammar2s information is expressed as constraints on feature values  . Where the basic form of a grammar is , say , complex phrase structure rules , the use of features may be confined to checking of number and person agreement  . If , on the other hand , more of the informative content of the grammar is represented as constraints  , as in recently popular unification-based grammars \ [ Sheibcr  1986\]  , relaxation can be used to transform grammars to less closely related ones  . 
In the remainder of this paper , we show how a unification-based formalism , PATR-II , may be extended by a declarative specification of relaxations so that it can be used flexibly for detecting syntactic errors  . Under one view , what we are doing here is rationally reconstructing the E pistle system within a unification-based framework  . A useful consequence of this exercise is that the adoption of a declarative approach to the specification of relaxations makes it much easier to explore different processing regimes for handling syntactic errors  . 
~ This second , higher-level VP plays the role of what we would normally think of as an S node  . 
Y , OXlX2 ( XO cat ) = VP ( Xlcat ) = NP ( X2 cat ) = VP ( X0 subject ) = Xl ( Xlhum )  =  ( X2 hum ) Figure 2: PAT tiversion of the Epistle rule
Making PATR Robust
The Basic Mechanism
In this section , we describe an experimental system , written in Prolog , that is designed to support the mechanisms necessary to apply PATR-type rules to solve constraints selectively  . The major components of the system are ( a ) the parsing mechanism ; ( b ) the underlying P^TR system ; and ( c ) the rule application mechanism that mediates between these two  . 
The parser encodes the chosen strategy for applying particular gramma rules in a particular order  . At this stage , the parser is not a crucial component of the system  ; all we require is that it apply rules in a bottom -up fashion  . Accordingly , we use a simple shift-reduce mechanism . The parser will be the focus for many of the proposed extensions discussed later  ; in particular , we are in the process of implementing a chart -based mechanism to allow handling of errors resulting from missing or extra elements  . 
The basic PATR system provides a unification based mechanism for solving sets of constraints on feature structures  . A PATR rule corresponding to the grammar rule discussed in the context of Epistle above is shown in Figure  2  . 
It is fairly obvious that , given some mechanism that allows us to remove the final constraint in this rule  , we can emulate the behaviour of the Epistle system  . 
In our model , the rule application mechanism provides the interface between the parsing mechanism  , which accesses the lexicon and decides the order in which to try rules  , and the PATR . system . To see how this works , we will consider a slightly morn complex rule , shown in Figure 3 ; the use of the numbers on the constraints will be explained below  . 
Given this rule , a constituent of category NP will be found given two lexical items which axe respectively a determiner and a noun  , provided all the constraints numbered 1 through 6 are found to hold . Note the constraint numbered 4: we suppose that the features addressed by ( X1 agr precedes ) and ( X2 agr begins ) may have the values vowel and consonant . This allows us to specify the appropriater strictions on the use of the two forms a and an  . 3 a Of course , the imp\]ication here that a is used before words beginning with a vowel and an is used before words beginning with a consonant is an over simplification  . 
There area iso , of course , other means by which this con-ACIT . SDECOL 1NG-92 , NANTES , 2328 AOIYI'1992470 PROC . OFCOLING-92, NANTES , AUG .  2328, 1992
X0 XlX21 ( X0 cat )  2  ( Xlcat )  3  ( X2 cat )  4  ( Xlagr precedes )  5  ( Xlagrnum )  6  ( X0 agrnum ) : ~ NP--Det--N ( X2 agr begins )  - -  ( X2 agrhum )  =  ( X2 agrhum ) Figure 3: Simple NP tale in the PATR formalism
Relaxing Constraints
Given the rule in Figure 3 , and a standard parsing mechanism , there will be no problem in parsing correct NPS like these dogs  . t lowever , consider our target errors in (16a-e ): (16) a . * this dogs b . * andogc . * andogs Exmnple ( 16 a ) exhibits premodifier noun number disgrecment ;   ( 16 b ) exhibits use of the wrong indefinite article ; and (16c ) cxm tains both of these errors . 
If the parser is to make any sense of thcse strings  , we must introduce a more elaborate control structure  . 
Premodifier-noun number agreement is enforced by constraint  5  ; constraint 4 enforces the use of the proper indefinite article  . We need to be able to relax constraint 5 to parse ( 16 a )  , and to relax constraint 4 to parse (16t)) ; to parse (16c ) , we want to relax both ( xm stralnts 5 arid 4 at once . 
"\[ b deal with this , we make use of the notion of a relaxation leve l Instead of applying all constrafers associated with a rule  , we specify for evcry rule , at any given relaxation level , those constraints that are necessary and those that are optional  . 
At relaxation level 0 , which is equivalent to th cbo-haviour of the standard PATR system  , all constraints are deemed nece . ~ ary . At relaxation level 1 , however , constraints 4 and 5 are optional . Optional constraints , if violated , need not result in a failed parse , but do correspond to particular errors . 
The algorithm in Figure 4 applies all constraints appropriately , given a specification as just dcscribed . 
Here , N is the set of nccessary constraints and O is the set of optional constraints  , both for a given relaxation level L ; R is the set of constraints which have to be relaxed in order for the rule to he used  . 
R will always be a subset of O , of course ; wer ( . ~ turn the actual vahm of 1~ as a result of parsing with the rule . The outer conditional ensures that all the necessary constraints are satisfied  . The inner conditional takes appropriate action for each relax-able constraint whether or not it is satisfied : if the straint could be d~eckcd  ; however , we include it here as a constraint on the application of the rule for expository purp ~ c ~  . 
When applying rule r at relaxation level L :
N ~- necessary constraints on rat L
O*--optional constraints on rat L ; ~ ~ if all n ( : N can be solved then incorporate any instantiations required for ead loi  r50 do if o , can be solved then incorporate instantiations else R?--O~Oo ~ end if next else return failure end if return C Figure  4: The relaxation algorithm , version 1l ~ . claxation level 0: necessary constraints = 1 , 2 , 3 , 4 , 5 , 6 optional constraints =
Relaxation levelt : nec~sary coustraints --1 , 2 , 3 , 6 optional constraints = 5 , 4 Figure 5: The relaxation specification for the NP rule , version l : optional constraints
Relaxation level 1: necessary constraints : 1 , 2 , 3 relaxation packages : ( a ) 5 , 6: Premodifier-noun munber disagreement ( b )   4: ~/ ~ error Figure 6: The relaxation specification for the NP rule , version 2: grouped constraints constraint is satisfied , it has exactly thcsame effect as an ecc ~ ary constraint  ; if not , the constraint is recorded as having been relaxed . 
Once paining is complete , the information in R can then be used to generate an appropriate error message  . 
The operation of this algorithm is supported by explicitly indexing each constraint within a tale  , as in Figure 3 , and absl . racting out the specification of whieh vonstraint . smay be relaxed at a given relayation lew fl . The constraint application specification for the NP rule is given ill Figure  5  . 
Grouping Constraints
This is not the whole story , however . Consider the NP this dogs , which would be correctly parse datre-Acids DE COLING-92  , NAN ' Ir ~ . s , 2328 AO~"1992471 PROC . OFCOLlNG-92, N_tCrEs , AUG .  2328 .   1992 laxation level 1 as exhibiting premodifier-noun number disagreement under the system described so far  . 
The instantiation of X0 resulting from this rule application would be as follows : ??\]\]  x0: I : ; :: 0 , uNote in particular that ( X0 agrnum ) has the value plu . This results from the solution of constraint 6 , which is one of the necessary constraints at relaxation level  1 as specified in Figure 5  . This ' feature transport ' constraint propagates the number of the tread noun totile superordinate noun phrase  . It is not appropriate to perform such a propagation under the current  , cirolmstances , however , because once a case of prc modifier-noun number disagreement has been identified  , we cannot ell whether it is the number of the noun or the number of the determiner that is in error  . One might argue that one of the two is more likely than the other  , but such a heuristic belongs in the mechanism that offers replacements rather than in the relaxation mechanism itself  . If the number of the noun is always propagated to the noun phrase  , spurious error reports may emerge in subsequent parsing : for example  , in the text Th/s doys runs , a subject verb number disagreement will be flagged in addition to the premodifier-noun number disagreement error  . This will be at best misleading . 
We would like to be able to express the intuition that it is not really meaningful to apply constraint  5 if constraint 5 has failed ; these constraints should be grouped together , to be applied together or not at all . So we introduce an addition to the specification for relaxation level  1  , shown in Figure 6 . 
We refer to a group of constraints to be relaxed together or not at all  , plus the error message that corresponds to the failure of the group of constraints  , as a relaxation package . The algorithm of Figure 4 has been adapted to apply such relaxation packages  , resulting in the algorithm in Figure 7 . Here , R is the set of relaxation packages required in order to complete the parse  . 
Note that if all the constraints in a relaxation package can be applied successfully  , they have exactly the same effect as necessary ones  , in terms of contributing to the building of structure  . Thus , if the number agremnent condition constraint 5 is satisfied , as in the case of the text andogs , then the associated feature percolation constraint  ,  6 , will add the feature ( agrnmn ) to XO , with value ( X2 agrhum ) . 
Ordering Constraints
In the previous section , we altered the mechanism to allow for the fact that it is not meaningful to apply some coustraints if others have failed  ; in the worst case , this avoided confusing error diagnoses . 
Even if no such confusion would result , however , con-When applying rule rat relaxation level L :
N*-necessary constraints on rat L
O4-relaxation packages for rat L
R ~- if all n ? N can be solved then incorporate any instantiations for each relaxation package P ~ EO do if all constraints  c4 ? Pi can be solved then incorporate any instantiations else R*--R+P ~: end if next else return failure end if return R Figure  7: The relaxation algorithm , version 2 siderablefficiency gains can be made by ordering constraints in such a way as to minimise unnecessary structure building  . A similar point is made by Uszkoriet\[1991\] , who talks of the need for a flex * ible control strategy for efficient unification based parsers  , to ensure that the conditions that are most likely to fall are tried first  . 
Ideally , the ordering of constraints would be derived automatically from other information  ; but it is unclear how this would be done . Currently , we make use of one central ordering principle : ( 18 ) Category constraints on RnS items come first . 
In the bottom-up parsing system we use , all RrlS items will be instantiated with feature structures corresponding to lexical entries  , or to syntacticate-gories built up by rule from lexical entries  ; it is a discipline on our lexicon and our structure building rules that all such feature structures will have a cat feature  . This means that a query about the cat value will involve no structure building  . However , if , before checking the category , we were to enquire about the ( agrnum ) feature , we might involve ourselves in some unnecessary structure building  , because if applied to a feature structure that does not have an  ( agrnum ) feature , what was thought of as a conditional constraint will in fact result in structure building  . For example , the constraint in ( 19 ) applied agains the structure in ( 20 ) will result in the structure shown in ( 21 )  ; this is clearly not desirable . 
(19 )   ( Xlagrnum ) = pluconjunction \] ( 20 )   X1 =\[ l':xt::andJ cat:conjunction\]lex : and/AcrEsDE  COLING-92  , NA ~ fI~S , 2328 AOt ~ r1992472 PROC , OFCOLING-92 , NAN rES , AUG .  2328, 1992
Relaxation level 0: necessary c~mstraints : 2 , 3 , 5 , 4 , 1 , 6 relaxation packages :
Relaxation level 1: necessary constraints : 2 , 3 , 1 relaxation packages : ( a ) 5 , 6: Premodifier-noun number disagreement ( b ) 4: a/a , , er ror Figure 8: The relaxation specification for the Nr rule , version 3: constraint ordering These considerations give ri ~ to the ordering of constraints given in Figure  8  ; we assume that when the algorithm in Figure 7 tests whether all members of a constraint set can be solved  , the constraints are solved in the order given in the specification  , and the test halts as soono . s any member of the constraint set cannot be solve & 
Discussion
Wc have argued that combining the relaxation technique for syntactic error correction with a grammar  ( such a . s is found in recent unification formalisms ) that expresses most of its information in the form of constraints provides a good starting point for all exi-ble mechanism for detecting and correcting syntactic errors  . Our work in this areas of arraises a number of interesting  ( lUt . ~ tions which need to be pursued lurther . 
Dependencies betw cen Constraints : As we have seen  , the ordering of constraints in the relaxation specifications ivery important  . However , the particular ole a specific constraint per-h ) rms will of course depend on the particular parsing strategy being used  . Ideally , we would like to generate the ordering information ant x  ) matically , although it is not entirely clear how this might be  ( lone . One source of some ordering constraints might come from using typed feature structures in tile lexicon  , so that the rule application mechanism can deterniine a bead of time what the primary source of information is  . Another approach might lie to require the grammar writer to specify the c  , on straints on rules as belonging to specific categories  , and then to allow the rule application mechanisni to impose a predefined ordering between categories  ; in particular , the most trouble -~ ) mc constraints are those which transport feature values around a structure  , since ttmy may transport the wrong values , ms we saw in the example discussed earlier . 
Generation of Replacement Wext : A topic we have not addressed in the pr~ent paper is the generation of corrections for hypothesis cd errors  . The result of parsing using relax at km provides ufli-cleat information to generate such replacements  , but once again we need to maintain in furmatiou about the dependencies between elements of a structure so that  , when a new structure is created , any conflicts that ari ~ can be re = solved : for example  , if generating a correction involves changing tile num feature of a noun from plural to singwlar  , we need to encode the information that the lex feature is dependent upon the hum feature and some specification of the root form  , so that the re-t fiaeement mechanism knows which features take priority and which may be overrid den  . 
Deciding between Errorlt : ypotheses : When a constraint unifying two incompatible values v l midv ~ has to be relaxed  , then in tile absence of further in fi ) rmation there are two equally likely error hy -pothers : one  , that v l is the correct value and t ~ a is wrong , mid the other that v ~ is correct and Vl is wrong  . However , there are two typ ~ of situation in which further information available  dm5ng parsing may ratable one hypothesis to be preferred  . 
The first is where the absolute likelihood of one error seems greater thau that of the other  , l , brexample , in the case of the noun phro . ? ? c these dog it might prove to be much more likely for a writer to mistakenly omit the single letters than to choose the wrong determiner  , which involve each angeof two letters there may be quantifiable difference between the assumptious behind the two hypotheses  . The second is where a number of possible r-rors are linked  , for example if the whole sentence w~m"llJese do gare fie ~ vze  , llere , two possibl errors involving different rules are interdependent  , midonce again it is possible to argue that one error hypothesis requir ~ a quantiliably dilferent set of ~ umptions  ; here , both these and ant would have to be wrong if dog were to be a  . ~sumed COrrect, . 
" lb a certain extent , it may be possible to rely on unilication to deal with the seconfliet  . ~ . The relaxation package dealing with the noun phr ~ number disagreement might ' hold its fire '- not signal an error immediately -- leaving the number feature of the noun phrase uninstantiat cd  . Then there will be no clash with the number of the verb phrms e  , which will be propagated down to the noun phrase . 
It may be pix ~ sible to hook this value up to the subsequent t  ) rocc ~ ingel the error suggestion from the nol in phrase rule  . 
Alternatively , the idea that there are a number of a ~ sumptious behind a given error hypothc's is could be formalised  , perhaps by 1L ~ inganA ' rMS\[deKleer1986a , 1986 b \] to keep track of inconsistencies . Ily-potimses could be weighted both by their absolute likelihood and the contextual evidence  ( i . e . , the number mid weight of related errors eonsis ? entmid in co~mistent with the hypotheses  )  . 
Much depends on where during the parsing pro ~ eess errors arise and are notified  , and so detailed consideration of this issueh ~ . ubeen deferred until oure ht~rt parser extension to this system has been explored  . 
Acrl ! s DECOLING-92 . NANTES . 2328h O(rr 1992473P ~ oc . o ~ COLING-92 . NArcri ! s . Aeo . 23k 28 .   1992 Levels of Relaxation : The examples we have provided have only explicitly mentioned one level of relaxation  , One can imagine situations where other , further levels of relaxation are available . 
In particular , note that , since categorial information can be specified by means of constraints  , we can also consider handling instances of words misspelled as words of other syntactic ategories by means of the same mechanism  ; relaxing category feature constraints might be an appropriate candidate for a further level of relaxation  . There is of course the question of how one decides what relaxation should be available at what levels  ; determining this requires more detailed statistical analysis of the frequencies of different kinds of errors  . 
It is also likely to bc required that individual error rules  , spread across a number of grammar rules , be capable of being treated as a unit , that is , switched on or off together , orthogonal to the idea of relaxation levels . 
Different Kinds of Relaxation : In the foregoing  , we a~qumed that relaxing a constraint simply meant removing it  . There are other notions of constraint relaxation that could be used  , of course ; for example , if a constraint assigns a value to some feature , we could relax this constraint by assigning a less specific value to that feature  . There may be other cases where we would want to generalise the notion of relaxation to include the possibility that a constraint could be replaced by a quite different constraint  . 
Conclusions and Future Work
We have described a simple extension to the PATR-n for nndism which allows us to provide declarative specifications of possible relaxations on rules  . This provides a good starting point for a flexible mechanism for detecting and c~rrecting syntactic errors  . 
Onerea . ~ on for this is that relaxation provides a precise and systematic way of specifying the relationship t  ) etwer u error flfl and ' CorrecU forms , making it easier to generate suggestions for corrections  . A second reason is that the very uniform representation of linguistic information will allow flexible strategies for relaxation to be applied  ; this is particularly important when dealing with text that may contain unpredictable errors  . 
As we have shown , the mechanism described here can be applied straightforwarly to Constraint Violation Errors as described at the beginning of the paper  . 
At the moment w c have a rather adhoe mechanism that deals with cases of Lexical Confusion by providing alternativelxical entries in the case of parse failure  , but this needs to be integrated better with the relaxation mechanism  . Cases of Stylistic Awk-wardness imply require the addition of a critic that walks over the structures produced by the parser  . 
Them Qorfocus of our current work is the replacement of the shift-reduce parser by a chart parser  , to enable us to handle cases of Missing or Extra Elements  . 

This work was carried out as part of lED Project 1679  , The EditorJ8 Assistan ~ Douglas is supported by SERC grant GRF  35654  . Much of our thinking on this topic was inspired by conversations with PabloRomero-Mares  , who constructed an early version of the parser as an MSe project  . 
ReferencesttDale \[1989\] Computer-based Eitorial Aids . Pages 12-20 in Recent Developments and Applications of Natural Language Understanding  , edited by Jeremy
Peckham . Kogan Page , London.
It Dale \[1990\] A Rulebased approach to Computer-Assisted Copy Editing  . Computer Assisted Language
Learning , 2, 59-67.
GE Heidorn , KJensen , LA Miller , RJ Byrd , and MSChodorow \[1982\]\] The E pistle text-critiquing system . IBM Systems Journal , 21, 305-326 . 
J de Kleer 1986a \] An Assumption-based Truth Maintenance System . Artificial Intelligence , 28, 127-162 . 
J de Kleer\[1986b\]Extending the TMS . Artificial
Intelligence , 28, 163-196.
SCK wasny and NKS on dheimer \[1981\] Relaxation Theories for Parsing Ill-Formed Input . American Journal of Computational Linguistics ,  7 ,  99-108 . 
KJensen , GE Heidorn , LA Miller , and Y Ravin \[1983\] Parsefitting and prosefixing : getting a hold on ill-formedness  . American Journal of Computational Linguistics ,  9 ,  147-160 . 
LA Miller \[1986\] Computers for Composition : A Stage Model Approach to Helping  . Visible Language , XX(2), 188218 . 
SDRichardson and LCBraden-Harder \[1988\] The ILx perience of Developing a Large-Scale Natural Language Text Processing System : CRITIQUE  , In Proceedings of the 2nd Applied Natural Lanouage proHcessing Conference  , pp 195-202 . 
SMS hiebcr I1986\] An Introduction to Unification-based Approaches to Grammar  . The University of
Chicago Press , Chicago , Illinois.
HUszkoreit \[1990\] Strategies for Adding Control Information to Declarative Grammars  . In Proceedings of the 29th Annual Meeting of the Association for
Computational Linguistics , pp 237-245,
RM Weischedcl and JE Black \[1980\] Responding In-telligently to Unparsable Inputs . American Journal of Computational Linguistics ,  6 ,  87-109 . 
AcrE . s DECOLING-92 , NANTES , 2328 AOUT 1992474 PROC . OFCOLING-92, NANTES , AUG .  2328, 1992
