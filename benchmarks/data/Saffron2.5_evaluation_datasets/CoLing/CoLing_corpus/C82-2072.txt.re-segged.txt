I~RANANDPHRED : ANALYSISANDI~ODUCTIONUSINGA CO~0N 

Robert Wilensky
Computer Science Dlwision , Department of EECS , University
of Californ?a , Berkeley , Caltforn ? a 94720 , USA
1 o0 Introduction
We propose a model of language use that is der ived from wlew l ~ language processing systems as knowledge-based sys-tems  . The knowledge that needs to be represented and organized here is the large amount of knowledge about what the utteran-ces of a language mean  . In this paper , I describe some of the theoretle el under pin ni ~ e of the model  , and then desorl be two programs , PHRAN and I~RED , that are based on these ideas ? We have conducted a number of experiments with these systems that have some bearing on the utility of the model " s presumpt-ions  , including testing these systems on other languages  ( Spa-hish and Chinese )   , and implementing one of them in a relation - al database system  . 
2  . 0  . The assumptions of the model 2?1? The Importance of Non-generative Lan~age Language user knows a great number of fact about what utterances of their language mean  . That is , in addition to knowing the meanings of a la rge number of words  , they know the steaL % license of a set of mean ing fulingu/st to units that are not necessarily understood in  term8 of the i ~ components . Our conjecture is that such units consti tute a very considerable fraction of the language knowledge needed by an intelligent language processor  . 
-296-2.2.3 harable Knowledge Base
In our model , it is assumed that the knowledge used for analysis and for production is by and laxge the same  . 
That is , there is only one database of knowledge about the meanings of a language's forms  . By having the knowledge of the two components be a shared database  , only one form of representation is needed . Moreover , the addition of new knowledge to thAs data base extends the capabilities of both sys- tems simultaneously  . 
As thAs requirement forces knowledge to be represented deolaratively  , the other benefits of such representations emeen joyed as well  . For exsunple , in this format , knowledge about the language is kept separate from the processing strategies that apply th is knowledge to the understanding and product ion tasks  . Thuue adding new knowledge requires only adding new asssztion B to the database  , not writing and debug ~ new code . In addition , other knowledge besides themes u~ng of a phrase can be easily associated with such declar a tive repres-entations  . 
3.0. PHRAN and P~h~ED
We have been developing this model of language use in two related programs  , PHRAN ( PHR as alANs~yzer ) and PHRED ( PHR as al~ngllsh Diction )  . PHRAN is a language understanding program writ ten by ? igal Arens  . It reads English sentences and produces representations from them that encode their meaning  . PHRED is a natural language production meohanAs  ~  , developed by Steven Upstill . PHRED takes meaning represent at-ions as input and expresses the mi~~nglish sentences  . 
Both PHRAN and PHREDs hs~ea common database of language knowledge  . This database contains declarative represent-ations about what the phrase of the English language mean  . 
This knowledge is stored in the form of pattex ~- conoe Dt pears  . 
A pattern is a phrasal construct of varying de ~ rees of speci-ficity  . The concept part of a pattern-concept pair is a og n--  297 -ceptual template that represents the meaning of the associat-ed phrase  . Together , these pairs associate different forms of utterances with their meanings  , PHRAN under stands by reading the input text and trying to find the phrasal patterns that app ly to it  . Eventually , the conceptual template associated with the desired pattern is used to generate the st ructure denoting the meaning of the ut terance  . PHRED produces sentences that encode an idea by examining the same knowledge base  . 
4.0 Spanish and Chinese PHRAN
We have build both a Spanish and a Chinese version of PHRAN simply by chansing the pattern- concept database  . These programs lend support to some of the cla ims we make for our model  . We found that it was possible to rewrite most of the patterns into phrases of another language without havinsg the knowledge encoder learn anything about the inner workings of the program  . This suggests that a system like PHR ~ could be designed to allow fairly easy construct ion of a language pro-cessor for a new language  , or to allow for the addition of special purpose phrases or Jargon by some user who was not an expert AI programmer  . 
5.0 AI and Relation Data Bases
We implemented a version of PHRAR in a conventional database system  . PItR . kN was rewritten in EQEEL , a query langua-gefor the INGRES relational data base system developed at Berkeley  . Tests were run to compare the relative per foremnce of the systems on various size data bases  . 
The results can be summarized as follows : The LISP version is considerably faster when the database of pattern--concept pairs is small  . However , when the database is large ( 2000 words and 500 patterns )  , the EQUEL version is about 3 times faster than the LISP version . Thus performance problems in naturallan ~ Aag@ may be solved by importing developments in data base technology as the size of our knowledge bases grow  . 

