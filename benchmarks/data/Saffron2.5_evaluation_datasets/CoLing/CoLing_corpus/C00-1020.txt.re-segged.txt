A Client/Server Architecture for Word Sense Disambiguation 
Caroline Brun
Xerox Research Centre Europe
6, chemin de Maupertuis
38240 Meylan France
Caroline . Brun@xrce.xerox.com

This paper presents a robust client/server implementation of a word sense disambiguator for English  . 
This system associates a word with its meaning in a given context using dictionaries as tagged corpora in order to extract semantic disambiguation rules  . 
Semantic rules are used as input of a semantic application program which encodes a linguistic strategy in order to selec the best disambiguation rule for the word to be disambiguated  . The semantic disambiguation rule application program is part of the client/server achitecture enabling the processing of large corpora  . 
1 Introduction
This paper describes the implementation fan online lexical semantic disambiguation system for English within a client/server linguistic application  . 
This system allows to selec the meaning of a word given its context of appearance in a text segment  , and addresses the general problem of Word Sense Disambiguation  ( WSD )  , ( Ideeta190) , ( Gale et al 92) , ( Gale et al 93) , ( Leacock et al 93) , ( Yarowsky 95) , ( Ng et al 96) , ( Resnik et al 97) , ( Vdronis et al98) and ( Wilks et al98) . 
The basic idea of the semantic disambiguation system described here is to use a dictionary  , in our case , the Oxford-Hachette bilingual dictionary ( OHFD ) , ( Oxford 94) , a bilingual English/French French/English dictionary designed initially for humans but stored in SGML format  , in order to extract a semantic disambiguation rule database  . The dictionary is in effect used as a semantically tagged corpus  . 
Once the semantic disambiguation database is available  , it becomes , as well as a dictionary and an ontology , are soume used by the server to perform WSD on new input  . A linguistic strategy was implemented in order to selec the best matching disambiguation rule in a given context  . 
This implementation is a followup of the Semantic Dictionary Lookup  ( SDL ) a heady implemented in this client/server system ( Aimelet 98 ) and o1' the methods proposed in ( Dini et al 98 ) and ( Dini et al 99 )  . The originality of our implementation lies in the rule selection strategy for application as well as in the use of the client/server characteristics to perform WSD  . After a brief presentation of the client/server characteristics  , we examine the implementation of the WSD system . Then we describe the results obtained after evaluation of the system  , and finally we conclude with the description of its applications and perspectives  . 
2 Architecture of the system 2 . 1 XeLDa " a linguistic client/server application XeLDa addresses the problem of a generic de -veloplnent l'ramework for linguistic-based and linguistics-enriched applications  , based on available , as well as future research results . Potential applications include : translation aids over a network  , on a desktop or a portable PC , syntax checking , terminology extraction , and authoring tools in general . This system provides developers and researchers with a common development architecture for the open and seamless integration of linguistic services  . XeLDa offers different service such as dictionary lookup  , tokenization , tagging , shallow parsing , etc . 
Dictionary lookup and shallow parsing are extensively used in the semantic rule extrac-tion /application processes described in this paper  . 
2.2 Dictionary Lookup
The OHFD dictionary is accessible via the XeLDa server  , which allows a fast and easy lookup of words . Each entry in the OHFD dictionary ( cf . 
Figl , entry of seize in SGML format ) is organized in different levels ( Akroyd 92 )  , corresponding to syntactic ategories (< S1> . . . </ S1> , S1=part of speechnmntic categories (<$2> . . .  </$2> , the senses we are interested in ) , themselves divided into several translations ( < TR > . . . </ TR >) . 
<SE><HW>seize</HW><HG><PR><PH>si:z</PH></PR > </HG><SI><OI><PS>vtr</PS></OI><  S2><02><LA>Iit</LA > < IC > takehold of</IC></02> < TR > saisir < CO > person , object </ CO > </ TR > < TR > < LE > to seizes baround the waist</LE>saisi rqn parlataille</TR><TR><LI > to seize hold of </ Ll > sesaisir de < CO > person </ CO ></ TR><TR>s'emparer de<CO>object</CO></TR > < TR>s autersur<CO > idea </ CO > </ TR >  </$2>   <$2><02> < LA > fig </ LA > < lC > grasp </ IC></02> < TR > saisir < CO > opportunity , moment </ CO > </ TR > < TR > prendre < CO > initiative </CO></TR><TR><LI>to be seized by </ LI>@ treprisde < CO > emotion  , pain , fit</CO > </ TR > </$2>  <  S2><02><LA>Mil</LA><LA>Pol</LA > < IC > capture </ iC></O2> < TR > s'emparer de < CO > power , territory , hostage , prisoner , installation</CO></TR><TR>prendre<CO>control < /CO > </ TR >  </$2>  <  S2><O2<LA>Jur</LA></02> < TR > saisir < CO > arms , drugs , property </ CO > </ TR > < TR > apprd hender < CO > person < /CO > </ TR >  </$2> </SI><SI><OI><PS>vi</PS></OI><TR><CO > engine  , mechanism</CO>segripper</TR></SI></SE>
Figl:SGML entry of seiee\]Sl are a bitl'll Ol * ~ informative tlmn simple part of speech since they distinguish also t  , ansiliv c , imransiliv crellexive verbs , past participles , as well as some plural/singular nouns . 
Fine-grained SGML tags markup different kinds of infornmtion related to semantic categories  ( <$2> ) and translations , in particular : ?< C () > . . . </ CO > mark collocates ( typical sub-jeers , objects , modiliers ,  . . . ); ?< LC > . . . </ LC>mark compound exaln ples associated with the head word  ; ? < LI ~ , >  . . . </ LE > mark general examples used for illustration of a word or a phrase  ; ? < I , I > . . . </I , I > mark idiomatic examples ; ?< I~O > . . . </LO>mark examples illustrating an obligatory syntactic structure of an entry  ; ? < I . U > . . . </ LU > mark examples of usage ; ?< I,V > . . . </ IN > mark examples of phrasal verb l ) attem . 
The recta-semantic information encoded into these ( \] iff ClCtltSGMI . tags is used to acquire semantic dis- , mfl ~\] guation rules from the dictionary and guides the semantic rule application process  , kSex plained later . 
2.3 Shallow Parser
The " shanow parsing " technology is based on a cascade of finite state transducers which allows us to extracl from a sentence its shallow syntactic structure  ( chunks ) and its ftmctional relationships ( AYtctal .  97) . 
The following example illustrates the kind of analysis provided by the shallow parser : Ai ~voh  , erattd two shot guns we fwsei ~ edat thepart3~ \[SC\[NPA revolver NP\]/SUBJ and\[NP two shot guns NP\]/SUBJ:v were seized SC\] \[PP at the part yPP\]  . 
SUBJPASS(revolver , seize)
SUBJPASS ( shotgun , seize)
VMODOBJ(seize , at , party)
Shallow parser transducer sal'C accessible via the XcLI  ) a server enabling fast and robust execution ( Roux 98 )  . 
The syntactic relations used in the disambiguation system arc subject verb  , verb-object and modifier . 
Subject-verb relations include cases such as passives  , rellexive and relative constructions . Modilierval , and adverbial phrases as well as relative clauses . 
2.4 Rule extractor
To perform semantic tag assignment using the OHFD dictionary  , a sense number ( Si ) is assigned to each semantic category ( <$2> ) of each entry . 
These sense numbers act as semantic tags in the process of disambiguation rule application  , because they directly point to a particular meaning of an entry  . 
In the context of our OHFD-based implementation , sense numbering consists in concatenating the homograph number  ( which is 0 if there are no homographs of the entry , or 1 ,  2 ,  3  . . . . . for each homograph otherwise ) , the S1 number , and the $2 number . For example , the entry seize is composed of five distinct senses  , respectively numbered 0 . I . 1, 0 . I . 2, 0 . I . 3, 0 . I . 4 ( for the transitive verb ), 0 . II . l ( for the intransitive verb ) . Such sense numbers allow a deterministic retrieval of the semantic ategories of a word  . 
As in GINGERI ( Dini et al 98 ) and GINGERII ( Dini et al 99 ) the acquired rules are of two types : word level and/or ambiguity class level  . 
The database is built according to the following strategy : for each sense number Si of the entry  , examples are parsed with the shallow parse hand functional dependencies are extracted from these examples : if a dependency involves the entry lemma  ( head word )  , a semantic disambiguation rule is built . It can be paraphrased as : If the lemma X , which is ambiguous between $1 ,  $2 ,   . . . , S  ~ , appears in the dependency DEP ( X , Y ) or DE p(Y , X ) then it can be disambiguated by assigning the sense Si  . 
Such role sate word level roles , because they match the lexical context . 
For each sense number again , collocates amused to build semantic rules . The type of dependency illustrated by a collocate of an entry is SGML-tagged in the OHFD  2  , and is directly exploited to build rules in the same way  . 
Then , for each rnle already built , semantic lasses from an ontology ( in our case , WordNet 3 , ( Fell-2For example , a collocate in a verb entry describes either a SUBJ or an OBJ dependency depending on its SGML tag  3Since WordNet classes are relatively poor for adjectives and adverbs  , additional infommtion about adjectival and adverbial classes is extracted fi'om a general thesaurus  , the Roget . 
baum 98 ) ) are used to generalize the scope of the rules : the non-head word argument of functional dependencies is replaced in the rule by its selnan-tic classes  . The resulting rule can be paraphrased as : If the lemma X  , which is ambiguous between St ,  $2 ,   . . . , Sn , appears in the dependency DEP ( X , ambiguity class(Y )) or DEl'(mnbiguity_class(Y ) , X ) then it can be disambiguated by assigning the sense Si  . 
Such rules are class level rules , because they match the semantic context rather than lexical items  . In both cases , the type of the role (< LC > , < LE > , < LI > , < LO > , < LU > , < LV > , < CO >) is kept and encoded into the rules . 
Fox " example , from the last semantic category of seize ,  0 . I . l , the system built the following word level rules :
SUBJ(engine , seize)~0.l.1<CO>;
SUBJ(mechanism , seize ) = ~0. I . 1<CO >;
Since engine belongs to the classes number 6 ( noun . artifact ) and 19 ( noun . phenomenon ) , whereas mechanism belongs to the classes number 6 , 4 ( noun . act ), 17 ( noun . object ), and 22 ( noun . process ), corresponding class level rules are :
SUBJ(6/19, seize ) = ~0.I.1<CO>;
SUB.I(4/6/17/22, seize)~0.l.l<CO>;
All dictionary entries are processed , which allow to automatically build a semantic disambiguation rule database available to be used by the semantic application program to disambiguate unseen texts  . 
2.5 Rule application program
The rule application program matches rules of the semantic database against new unseen input text using a preference strategy in order to disambiguate words on the fly  . In cases where the system is not able to find any matching rules  , it gives as fallback resul the first meaning corresponding to the syntactic part of speech of the word in the sentence  . Since the OHFD has been built using corpora frequencies  , the most frequent senses of a word appear first in the entry  . Therefore , even if there are no matching rules , the system gives as result the most probable meaning of the word to disambiguate  . 
The linguistic strategy used in the application program is shown on several examples  . 
134 2.5.1 Simple rule matching
Sttppose one wants to disambiguateile wo M seize in the sentence : Only cg'tero ranges had been served did  , led seize the initiative , ascrmmnage pick-zq ) e/fort by Ronme Kirkl ) a triek cancelling out Moore's score . 
The rule application l ) rograullirst extracts the functional dependencies by means of the shallow parser  . The word to be disambiguated has to be member of one or more dependencies  , ill this case :

The next step tries to match these dependencies with one or more rules in the semantic disambiguation database  . 
If one aud only one role matches the lexical context of the dependencies directly  , the system uses it to disambiguate he word , i . e . to assign the sense number Si4to it ; otherwise , if several rules match directly at word level , the selection process uses the meta-semantic information encoded in SGMI  , tags within the dictionary ( and kept in the rules oil purpose ) with the following preference strategy : rule built fl ' om collocate  ( < C ( )> )  , from compounds examples (< LC>) , from idiomatic examples (< IA >) , t ' rom structur examples (< L()>) , from phrasal verb pattern examples (< IN >) , t ' romusage examples (< LU >) , and finally from general examples (< I , E>) . 
As far its implementation is concerned , rules are weighted flom 1 to 7 according to their types . 
This strategy relies on the linguistic choices lexicographers made to build the dictionary and takes into account the accuracy of the linguistic type el ' the examples : it ranges from collocates  , which encode very typical arguments of prcdicatcs  , to w'~ry general examples , as such the resulting rules are linguistically -based  . 
In these particular exmnple , only one lexical rule matches the dependency extracted : seize : l  ) OBJ ( scize , iuitiative ) = > 0 . I . 2 < C ( )> meaning that the sense nmnber alTected to seize is  0  . 1 . 2 . This rule has been built using the typical collocate of seize in its  0  . I . 2 sense , namely initiative . The translation associated to this sensenmn ber of seize in the dictionary is prendre  , which 4 possibly translation , depending on the application is the desired one in this context  . 
2.5.2 Rule competition
In some casts , many rules may apply to a given wo M in the same context  , therefore we need a rule selection strategy . 
Suppose one wants now to disambiguate lheword seize  , in the sentence : 77w police seized aman employed by the Krttgetw-dorp branch of the United Building Society on approximately  18 May 1985  . 
The dependencies extracted by the shallow parser which might lead to a disambiguation  , i . e . 
which involve seize , are:


VMODOBJ(seize , about , 1985)
VMODOBJ(seize , of , Society)

In the case of our example , none of Iherules of the database lnatch directly the lexical context of the dependencies  . Therefore , the system tries to match the selnantic on text of the dependency  . 
To perform this task , the distance between the list of semantic lasses o1' a potential rule ( El ) and the list o1' semantic lasses associaled with tile non -head word  o1' the dependency ( L2 ) is calculated : d = ( UAI ? I )   ( UNION ( L1 , L2))-(;AIU ) ( INT'I , gI , :( I , I , L2)))
UAI ~ I ) ( UNION(IA , L2 )   ) " l benable fast execution in terms of distance calculation  , a transducer which associate : ~ a word with its WoMNet top classes has been built and is loaded on the server  . The distance calculated here ranges from 0 to 1 , 0 meaning afttll match of classes , 1 no match at all , the " best " rules being the ones with the smallest distance  . Ill this particular example , the list of classes at lached to man in WordNet is used to calculate the distance with the potential matching rules  . Several rules now match the semantic on text of the dependency 

After removing rules matching with a distance above some threshold  , it appears that two potential matching rules still compete : ? one is built using the collocate\[prise  , let\]:
DOBJ(seizc , prisoner ) = > 0 . I . 3 < CO > ; ? the other is built using the example to seize somebody around the waist : 
DOBJ(seize , somebody ) := > 0 . I . l < LE >; at class level DOBJ(seize , l8) = > 0 . I . 1 < LE >; Indeed , prisoner and somebody sham the same semantic WordNet class  ( 18 , noun . animate ) which is a member of the list of classes attached to man as well  . The following preference strategy is applied S : first  , preferules from collocate (< CO >) , then from compounds examples (< LC>) , then from structure examples (< LO >) , then from phrasal verb pattern examples (< LV >) , then from usage examples (< LU >) , and then fiom general examples (< LE >) . This strategy allows the selection of the role to apply  , here the one built with the collocate \[ prisoner  \]  . The sense number attached by the system to seize is  0  . i . 3 , the general meaning being capture , and the French translations ' emparer de . 
In cases where two competing rules are exactly of the same type  , the system chooses the first one ( first sense appearing in the entry )  , relying on the fact that the OHFD was built using corpora : by default  , semantic ategories of the entries are ordered according to frequency in corpora  . 
2.5.3 Rule cooperation
The previous example showed how rules can compete between each other  . But in some cases they can cooperate as well . Let's disambiguate seize in the following example sentence : United Slates federal agents seized a sm face-to-air rocket launche ~  ; arocket motto ; range-finders and a variety of milim O , manuals . 
Since the sentence contains a coordinate direct object of seize  , one gets the following dependencies fiom the shallow parse  , :




Many roles are matching at class level , with a given distance d , namely : DOBJ(seize , 4/6/1l ) = ; ,  0 . I . 3 < CO > ; d = 0 . 75 DOBJ(seize , 7/24/4/9/26/6/18/10) = 50 . I . 3 < CO > ; d = 0 . 9DOBJ(seize , 8/6/14) = > 0 . I . 4 < CO > ; d = 0 . 75 DOBJ(seize , 21/7/15/9/6):::> 0 . I . 4 < CO > ; d = 0 . 83 Two rules point out the sense number 0 . I . 3, the two others , the sense number 0 . 1 . 4 . The strategy of role selection takes tiffs fact into account  , giving in ore importance to sense numbers matching many times  . As far as implementation is concerned , the distances associated with roles pointing on the same sense number are multiplied together  . 
Since distances range from 0 to 1 , multiplying them decreases the resulting value of the distance  . 
Since the lowest one is chosen , the system put the emphasis on semantic redundancy  . In the example , the distance finally associated with sense nmnber  0  . I . 4 is 0 . 6625 , which is smaller than the one associated with sense number  0  . I . 3 (0 . 675) . The sense number selected by the system is therefore  0  . 1 . 4 , the translation being saisir , which is the desired one . The stone strategy is implemented for word level rules cooperation  , in this case , rule weights are added . 
2.6 hnplementation
The different modules of the system presented here are ilnplemented in C ++ in the XeLD a client /server architecture : - As a heady mentioned  , the rule learner is a silnple XeLD a client that performs rule extraction once  ; - The rule application program is implemented as a specific dictionary lookup service : when a word is semantically disaln biguated with a rule  , the application program reorders the dictionary entry accord-lug to the semantic ategory assigned to the word  . 
The best matching part of the entry is then presented first  . This application is built on top of Locolex ( Bauer et al 95 )  , an intelligent dictionary lookup which achieves ome word sense disambiguation using word context  ( part of speech and nmltiword expressions ( MWEs ) 6 recognition )  . However , Lo-colex choices remain purely syntactic . Using the OHFD information about examples , collocates and subcategorization as well as semantic lasses from an ontology  , the system presented here goes fnrther to wm'ds emantic disambiguation  . 
5 At class level , idiomatic examples are not used , because the idiomatic expressions given in the dictionary are fully lexicalize de ' Multiword expressions range flom compounds  ( salle debain ) and fixed phrases ( a priori ) to idiomatic expressions ( to sweep something t , nder the rug ) . 
136 3 Evaluation
We ewfluated the system for English on the 34 words used in the SENSEVAL competition ( Kilgar-tiff 98 ; Kilgarriff 99) , as well as on the SENSEVAL corpus ( HECTOR ) . This provkled a test set of around 8500 sentences . The SENSEVAL words arc all polysemous which means that the results given below reflect real polysemy  . 
We use the SENSEVAL test set for this in vitro ewfl-uation in order to give us a mean of comparison  , especially with the results obtained in tiffs competition with GINGER  i1   ( Dinielal .  99) . Still , it is impeltant to keep in mind that this comparison is difficult since the dictionaries used are different  . We used the OHF1 ) bilingual dictionary while in SENSEVAL the Oxford monolingual dictionary fl ' om HEC- 
TOR was used.
The evaluation given below is l ) efformed it ' and only if the semantic disambiguator has found a matching rule  , which means that tim results focus only on our methodology : recall and precision would have been better if we hadewduated all outputs  ( even when the resul ! is just the first meaning corresponding to the syntactic partel'speech of the word in the sentence  ) because the OHFI ) gives by defaul the most frequent meaning of a word  . 
The results obtained with the system arc given on the following table: 
POS Precision Rccall
N 83.7% 27.4%
A 81.3% 55.8% v 75% 37.6%
Global 79.5% 37.4%
Polysemy 5.4 5.7 6.2 5.8
Numbers show that the recall is equivalent to the one we obtained with GINGER  1I   ( 37 . 6%) in SEN-SF , VAL ( tiffs just means that dictionaries content is about the same  ) but precision is dramatically improved ( 46% for GINGER1I for 79 . 5% with this system ) . Increase in precision is due to the fact that we used more finegraine dictionary information  . 
Moreover , the evaluation shows that the distribution of the precision results follows the preference strategy employed to select rtfles : collocate rules am more precise than examples rules  , compounds or idiom rules am themselves more precise than us-agle exaln ples  , etc . 
Another ewfluation of smaller coverage has been performed on " all polysemous words " of about  400 sentences extracted flom the T/me , s ' newspaper ; and shows similar results according to part of speech distribution  . 
POS Precision Recall Polyscm)
N 81% 28.3% 5.5
A 79% 64% 5.8
V 74% 34.5% 9.8
Global 78% 36.1% 6.2
These results confirm that dictionary information is very reliable for senmntic disambiguation tasks  . 
4 Conclusion and Future expectations
This paper describes a client/server implementation el ' a word sense disambiguator  . The method uses a dictionary as a tagged corpus in order to extract a semantic disalnbiguation rule database  . Sirice there is no need for a tagged training corpus  , tim method we describe , which performs " all words " semantic disambiguation  , is unsupervised and avoid e ; the data acquisition bottleneck observed in WS1) . Rules are available to be used by a semantic application program which uses a specilic linguistic strategy to select the best matching rule to apply : the rules elec-lion is based on an SGML typed-based preference strategy and takes into account rules competition and rule cooperation  . 
l~mp has is put on the advantage of the client /server implementation it in ' ms  o1' robustness as wellk S on the good results provided by the strategy in terms of recall and precision  . The client/server implementa-lion provides robustness  , modularity and l'a~t execution . 
The disambiguation strategy provides hig , h precision results , because senses and examples have been delined by lexicographers and the rel ' ore provide a reliable linguistic source for constructing a database of semantic disambiguation rules  . Recall re . suits are good as well , meaning that the coverage of the dictionary is iml  ) ortant . 
These results could be improved by learning more disambiguation rules  , for example using the colrespondences between functional dependencies : when a dependency DOBJ  ( X , Y ) is extracted , a rule for SUBJPASS(Y , X ) can be built ( and vice-wzrsa ) . 
They could be improved as well by integrating more line-grained semantic in l'ormation l ' or adverbs and ac!iective  , WordNet being relatively poor \[' or these parts of speech  . 
Since the architecture is modular , thesy ~; tem initially provided for F , nglish can be quickly adapted for any other language as soon as the requi:red components are available  . We already started to build a integrate a French semantic ontology into the system  . At the moment , it is planned to extract such an ontology from the dictionary itself  , using the semantic labels which amassociated with semantic categories  . The expectation is to obtain more consistency between semantic tags  ( dictionary ) and semantic lasses ( ontology )  . 
Because we used a bilingual dictionary we integrated the disambiguation module into a general system architectured dicated to the comprehension of electronic texts written in a foreign language  . 
This technique coupled with other natural language processing tecl miques such as shallow parsing can also be used to extract general semantic networks from dictionaries or encyclopedia  . 
Acknowledgments : Many thanks to Frdd drique Segond for help  , support and advices . Thanks to E . Aimelet , S . Aft-Mokhtal ; J . R Chanod , M . H . Cor-rdard , G . Grefenstette , C . Roux , and N . Tarbouriech for helpful discussions . 

Elisabeth Aimel et .  1998 . XeL Da Dictiona ~ T Lookuphn provement X RCE ATS XeLDa Technical Report  . 
S . Ait-Mokhtar , JR Chanod .  1997 . Subject and Object Dependency Extraction Using FiniteState Transducers  . In Proceedings of the Workshop on atttomatic Information E : mztctiotzarid the Building of Lexical Semantic Resourees  , , ACL , p71-77 , 
Madrid , Spain.
R . Akroyd . September 1992 . Markup for the Oxford-Hachette French Dictionary , English to French . Technical report Oxford University Press . 
D . Bauel ; E Segond , A . Zaenen .  1995 . LOCOLEX : the translation rolls off your tongue . In Proceedings of ACH-ALLC , Santa-Barbara , USA . 
L . Dini , V . DiTomaso , E Segond .  1998 . Error Driven Word Sense I ) is ambiguation IP roceedings of COLING/ACL , p320-324 , Montreal , Canada . 
L . Dini , V . DiTomaso , E Segond .  1999 . GINGERII : an example-driven word sense disambiguator  . In Computer and the Humanities , to appear . 
C . Fellbaum .  1998 . WordNet : An Electronic Lexical Database , MIT Press , Cambridge ( MA ) . 
W.A . Gale , K.W . Church , D . Yarowsky . 1992.
Work on statistical methods for word sense disambiguation in Probabilistic Approaches to Natural Language : Papers from the  1992 AAAI Fall Symposium , p54-60 , Cambridge , MA , October . 
W . A . Gale , K . W . Church , I3 . Yarowsky .  1993 . A method for dismbiguating word senses in a large corpus  , in C()ml ) uter and the Humanities ,  26:415-439 . 
N . Ide . Vdronis .  1990 . Very lalge neural networks for word sense disambiguation  , in Proceed il ~ gs of the 9th european conference o Iz artificial intelligence , ECAI '90 , p . 366-368, Stockhohn . 
A . Kilganiff .  1998 . SENSEVAL : An Exercise in Evaluating Word Sense Disambiguation Programs  . 
In Proceeding of the First International Col ~\[ ' erence onlx mguage Ressources and Evaluation  , Granada , 

A . Kilgarriff .  1999 . Gold standar datasets for evaluating word sense disambiguation programs  . In Computer and the Humanities , to appear . 
C . Leaeock , G . To well .  1993 . Corpusbased statistical sense resolution , in Proceedings of the ARPA Human Langttage technology workshop  , San Francisco , Morgan Kaufman . 
H . T . Ng , H . B . Lee .  1996 . Integrating Multiple Knowledge Sources to Disambiguate Word Sense : an Examplar-based Approach  . In Proceedings of the ACL , p . 40-47 . 
Oxford-Hachette .  1994 . The Oxford Hachette French Dictionao ~ . Edited by M . -H . Corrdard and V . Grundy , Oxford University Press-Hachette . 
R Resnik and D . Yarowsky .  1997 . A perspective on word sense disambiguation methods and their evaluation  . In Proceedings () . \[' ACL SIGLEX Work-sho1 ) on Tagging Text with Lexical Semantics : Why , 
What , and How ?, Washington D.C ., USA.
Claude Roux . 1998. XeL Da Shallow Parser XRCE
ATS XeLDa Technical Report.
J . Vdronis , N . Ide .  1998 . Introduction to the Special Issue on Word Sense Disambiguation : The State of the Art  . in Computational Liltguistics 24/1 . 
J . Vdronis , N . lde .  1990 . Word sense disambiguation with very large neural networks extracted fiom very large corpora In Proceedings of the  13th international cotzference on computatimzal linguistics  , COLING'90 , volmne2 , p . 389-394, Helsinki , Finland . 
D . Yarowsky .  1995 . Unsupervised word sense disambiguation method rivalizing supervised methods  . 
In Proceedings o\['the ACL , p189-196.
Y . Wilks , M . Stevenson .  1998 . Word Sense Disambiguation using Optimised Combinations of Knowledge Sources  . In Proceedings o\[COLING/ACL,
Montreal , Canada.

