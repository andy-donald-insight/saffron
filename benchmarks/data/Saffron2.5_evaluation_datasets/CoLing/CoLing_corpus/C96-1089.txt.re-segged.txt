Learning Bilingual Collocations by Word-Level Sorting 
Masahiko Haruno Satoru Ikehara Takefumi Yamazaki
NTT (', ommunicatiol tSci('ncel , al)s.
1-2:156 Take Yokosuka-Shi
Ka . nagawa . 2:18-03, , l :) a , n
haru no@n'c'ckb , nt-I ; , jpike hara@nttkb , rt'c-I ; , jpyamazaki ~ nttkb , ntt . jp
Abstract
This paper I ) roposes ; tnew t nethod
for learning bilingual colloca , tions from
sentence-aligned paral M corpora . Our
method COml ) ris (' s two steps : (1) ex-
tracting llseft ll word chunks ( n-grmns ) by word-level sorting and ( 2 ) constructing bilingua , l('ollocations t ) y combining the word -( ; hunl(sa(-quirediustag('(1) . 
We apply the method to a very ( ' hal-lenging text l ) ~ tir : a stock market1 ) ul-let ; in in Japanese and il ; sabstract in En--glish . I ) om ; tinsl ) ecific collocations are well capture dewm if they were not con-ta  . ined in the dictionaric's of economic tel ? IllS . 
1 Introduction
In the field of machitm translation , there is a , growing interest in corl ) llS-I ) as edal ) l ) roa . (' hes(Sato and Nagao , 1990; l ) a . ganmid (', hutch , 199d ; Mat . 
sulnotoet M . , 19 . 93; Kumanom , dllimka . wa . , 199d ; Smadja et al , 1996) . The main motiw ~ . tion behind this is to well ha . nd le , domain specific expressions . I ~ a chapl ~ licatiotl dom ~ dn hasva . rious kinds of collocations ranging from word -level to sentence-level  . '\]' he correct use of these collocations grea . l . lyinlluell cC's the qua . lity of outptt texts . 
Ilexa . uso such detaih'd collocations ; ~ r~'~<tillicult1:o hand-conlpile , the automatic extra ( : tion of bilingual collocations is needed . 
A number of studies haw > aJ . tetnpte ( I to extract bilingua J collocations from paral M corpora  . These studies c~m be classified into two directions  . One is hased on the full parsing techniques . ( Mat , - sumoto et al . , 1993) I ) roposed a . method to find out phrase-lew'l correspondences , while resolving syntactic ambiguities a . t the same time . Their ninth- ( ) ( Is determine t ) hrase e or resl ) ondences I ) y using the phrase structures of I , hetwohm gua , gesandox-isting bilingual dict . iona . ries . Unfi ) r l . unately t l , ' seal ) proaches are protnising only for ( , he compara--I , ively short sentences l , hatca , I > e a , a \] yze(II>y ; t(' , I + , : Y type l > arser . 
The other direction for extracting bilingual cob local  . ions involw+:statistics . ( Fung ,  1995 ) acquired bilingual word correspondences without sentet l ce alignment  . Although these methods ; rerob/Is ~ HI ( IaSSlllllerioillfOl'lll~ttiOllSOltrce~their outputs are just word word corresl  ) otMences . 
( Kupiec , 1993; Kumano and lirakawa ,  1!194 ) extracted noun phr~me ( NP ) correspondences from aligned parallel corpora . n(Kupiec ,  1993) , Nl's in English and Frencht ; exts are + first extracted by a . NP recoguizer . Their correspotldence prol > abilities arc then gradually relined by using an EM-like iteration algorithm  . ( t , ~ uma . no and Ili-rakawa , 1994) lirst extracted . Japanese NPs in the S&III(?way , and comhined statistics with a bilin-gtta . l dictionary t brMT 1 of ind out NP ( -or respon-dences . Although their apl ) ro+t chesa . t . ta . ined high accuracy for the + task considered , the most crucial knowledge for MT is tn or cCOml ~lexcorre-spOll delices Sllch ~- LSNI'-VP corres \[  , Oll ( teltces at HIsenl . et , ' e-hwe\[or respotldences . It seems di\[\[icuttI . o extend these statisticall lethods to ~ tI ) roa . (ler rmtge of collocations because they are specialized to Nl's  o1: sillglc " words . 
( Smmlj ~ tetal ,  1996 ) proposed a gener M method to extract a I ) roader ange of colloca . tions . 
They first extract English collocations using the Xtract systet n  ( Smadja ,  1993) , and the ulook for French coutlter parts . Their search strategy is an item tive combina . tion of two elements . This is ha , sed on the intuitive ide~tim " if a set of words  ( ' onstitutes a collocation , its subset will M so be correla . ted " . Although this idea is corre ~(: t , heit-eraire combination strategy generates a . mlmberol + useless expressions . Infa . ct , Xtract . employs a . 
rol ) ustl ", nglish pa . rser to lilter out the wrong collo-ca . tions which form more thaalha . If lhe candidates . 
In other hmgua , ges such as Japanese , pa , rser-lmscdprmfi . g cannot be used . Another drawback of their approa , ch is that only the longesl , ngram is a dopl . ed . That is , when ' Ja . lmn-US autotrade talks ' is ardol)ted as ; /collocation ,  ' , lapall-IlS'cannot bcrecognized as a . collocal , i on though it is i . -dependently used very often . 
In thi , ~ pN)er , we propose an alt , ernative method based oil word-lewds orting . Our method com- ( n-grams ) by word-level sorting and ( 2 ) constrnct-ing bilingual collocations by combining the word-chunks acquired at stage  ( 1 )  . Given sentence-aligned texts in two languages ( Haruno and Yamazaki ,  1996) , the first step detects useful word chunks by sorting and counting all uninterrupted word sequences in sentences  . In this phase , we developed a new technique for extracting only useful chunks  . The second step of the method evaluates the statistical similarity of the word chunks appearing in the corresponding sentences  . Most of the fixed ( uninterrupted ) collocations are directly extracted from the word chunks  . More flexible ( interrupted ) collocations are acquired level by level by iteratively combining the chunks  . The proposed method , which uses effective word-level sorting , not only extracts fixed collocations with high precision  , but also avoids the combinatorial explosion involved in searching flexible collocations  . In addition , our method is robust and suitable for realworld applications because it only assumes part-of -speech taggers for both languages  . 
Even if the part-of-speech taggers make errors in word segmentation  , the errors can be recovered in the word chunk extraction stage  . 
2 Two Types of Japanese-English
Collocations
In this section , we briefly classify the types of JapaneseEnglish collocations by using the material in Table  1 as an example . These texts were derived from a stock market bullet in written in Japanese and its abstract written in English  , which were distributed electrically via a computer network  . 
In Table 1 , ( ~ g - ~ , ~' l -~/ Tokyo Forex ) ,   ( H~I ~ ! IYJ ~\ [ ~ n ~\] ~/ auto talks between Japan and the U  . S . ) and (~ k , . ' ~/ ahead of ) are JapaneseEnglish collocations whose elements constitute uninterrupted word sequences  . We call hereafter this type of collocation fixed eolloeatlon  . Although fixed collocation seems trivial , more than half of all useful collocations belong to this class  . Thus , it is important o extract fixed collocations with high precision  . In contrast , ( b')t-t~'~~~~1~?ki ~? , _~/ The U . S . currency was quoted at -~) and ( b ") t . ~' ~ ~ ~ ~ ~ l ~ ~ k_2 ~/ / The dollar stood . .~ ) 1 are constructed from interrupted word sequences . 
We will call this type of collocation flexible col-location  . From the viewpoint of machine learning , flexible collocations are much more difficult to learn because they involve the combination of elements  . The points when extracting flexible collocations is how the number of combination  ( candidates ) can be reduced . 
Our learning method is twofold according to the collocation types  . First , useful uninterrupted 1 ~ . represents any sequence of words . 
word chunks are extracted by the word-level sorting method  . To find out fixed collocations , we evaluate stochastic similarity of the chunks . Next , we iteratively comb in the chunks to extract flexible collocations  . 
3 Extracting Useful Chunks by
Word-Level Sorting 3 . 1 Prev ious Research With the availability of large corpora and memory devices  , there is once again growing interest in extracting ngrams with large values of n  . ( Nagao and Mori ,  1994 ) introduced an efficient method for calculating an arbitrary number of ngrams from large corpora  . When the length of a text is I bytes , it occupies l consecutive bytes in memory as depicted in Figure  1  . First , another table of size l is prepared , each field of which represents a pointer to a substring  . A substring pointed to by the ( i-1 ) then try of the table constitutes a string existing from the ith character to the end of the text string  . Next , to extract common substrings , the pointer table is sorted in alphabetic order . Two adjacent words in the pointer table are compared and the lengths of coincident prefix parts are counted  ( Gonn et al . , 1992) . 
For example , when ' auto talks between Japan and the U . S . ' and ' autotalks between Japan and China ' are two adjacent words  , then mn ber of co-incidences i 29 as in ' auto talks between Japan and ' . The ngram frequency table is constructed by counting the number of pointers which represent the same prefix parts  . Although the method is efficient for large corpora  , it involves large volume of fractional and unnecessary expressions  . The reason for this is that the method does not consider the interrelationships between the extracted strings  . That is , the method generates redundant substrings which are subsumed by longer strings  . 
text ntrhg(Ioharaoter ~: I bytes ) la , ol . tertable
Figure 1: Nagao's Approach
To settle this problem , ( Ikehara et al ,  1996 ) proposed a method to extract only useful strings . 
Basically , his methods is based on the longest-match principle  . When the method extracts a longest ngram as a chunk  , strings subsumed by the chunk are derived only if the shorter string of_tell appears independently to the longest chunk  . 
If ' autotalks between Japan and the U . 5' . ' is extracted as a chunk , ' Japan and the U . S . ' is also The dollar stood 0 . 26 yenlower at 84 . 21-84 . 24 at 5p . m . 
For exmarke trading was extremely quieta head of fnr therauto talks between Japan and the U  . S . , slated for early dawn Tuesday . 
The U . S . currency was quoted at 1 . 361-1 . 3863 German marks at 5:15 p . m . 
Table 1: Sample of Target Texts extracted because ' Japan and the U  . S . ' is used so often independently as in ' Japan and the U  . S . 
agreed . . . ' . However , ' Japan and the ' is not extracted because it always appears in the context of ' Japan and the U  . S . ' . The method strongly suppresses fractional and unnecessary expressions  . 
More than 75 % of the strings extracted by Na-gao's method are removed with the new method  . 
3 . 2 Word-Leve l Sort ing Method al Ipl l I @ i I \[ dl@~tlh\]\[poln ~ rimbl ~ ? O : ~ nl ~ llm~r 
Figure 2: Word-Level Sorting Approach
The research described in the previous section deals with character-based ngrams  , which generate excessive numbers of expressions and requires large memory for the pointer table  . Thus , from a practical point of view , word-based ngrams are preferable in order to further suppress fractional expressions and pointer table use  . In this paper , we extend Ikehara's method to handle word-based ngrams  . First , both Japanese and English texts are part-of -speech  ( POS ) tagged 2 and stored in memory as in Figure 2 . POS tagging is required for two main reasons : ( 1 ) There are no explicit word delimiters in Japanese and  ( 2 ) By using POS information , useless expressions can be removed . 
In Figure 2 , '@' and ' \0' represent the explicit word delimiter and the explicit sentence delimiter  , respectively . Compared to previous research , this data structure has the following advantages . 
2We use in this phase the JUMAN morphological analyzing system  ( Kurohashi et al ,  11994 ) for tagging Japanese texts and Brill's transformation based tag-get  ( Brill , 1994) for tagging English texts . We would like to thank all people concerned for providing us with the tools  . 
1 . Only heads of each word are recorded in the pointer table  . As depicted in Figure 2 , this remarkably reduces memory use because the pointer table also contains other string characteristics as Figure  3  . 
2 . As depicted in Figure 2 , only expressions within a sentence are considered by introducing the explicit sentence delimiter '   \0'  . 
3 . Only word-level coincidences are extracted by introducing the explicit word delimiter '@'  . This removes strings arising from a partial match of different words  . For example , the coincident string between ' Japan and China ' and ' Japan and Costa Rica ' is ' Japan and ' in our method  , while it is ' Japan and C ' in previous methods . 
colnol ~? ontadopt dance ~4(151-/02
IlC ) * I

I ?)
J , .   .  ,  .  , ,<  . o .   .   . tc . ~, c'o .  ,  . ~1o . 
aap . n ~- q and ?, ~ t ~, *~1 J s
Jupatt(~an,tC,~tI~US
J it pitt ~ t tn ? U ~ , tI~<~~IS
Japai ~? U~n ( IC a ) II ~ C ~ O_?/
Figure 3: Sorted Pointer Table
Next , the pointer table is sorted in alphabetic order as shown in Figure  3  . In this table , sent no , and coincidence represent which sen-fence the string appeared in and how many characters are shared by the two adjacent strings  , respectively . That is , e o in ei denee delineates candidates for use fifl expressions  . Note here that the coincidence between Japan @ and @ China  . . . and Japan @ and @ Costa Rica . . . isl0 as mentioned above . 
Next , in order to remove useless subsumed strings , the pointer table is sorted according to sent no .   . In this stage , adopt is filled with '1' or '0' , each of which represents i for not if a string is subsumed by longer word chnnks  , respectively . Sorting by sent no , makes it much easier to check the subsumption of word chunks  . When arise from a sentence , the latter is removed because the former subsumes the latter  . 
Finally , to determine which word-chunks to extract , the pointer table is sorted once again in alphabetic order  . In this stage , we count how many times a string whose adopt is 1 appears in the corpus . By thresholding the frequency , only use-tiff word chunks are extracted . 
4 Extracting Bilingual

In this section , we will explain how JapaneseEnglish collocations are constructed from word chnnks extracted in the previous stage  . First , fixed collocations are induced in the following way  . 
We use the contingency matrix to evaluate the similarity of word-chunk occurrences in both languages  . Consider the contingency matrix , shown Table 2 , for Japanese word chunk cj p , ~ and English word chunk c ~ , g . The contingency matrix shows : ( a ) the number of JapaneseEnglish corresponding sentence pairs in which both Cjpn and ce  , ~g were found ,   ( b ) the number of JapaneseEnglish corresponding sentence pairs in which just c ~  , v was found ,   ( c ) the number of JapaneseEnglish corresponding sentence pairs in which just ejp  , ~ was fonnd ,   ( d ) them nnber of JapaneseEnglish colresponding sentence pairs in which neither chunk was found  . 
Cengab cd
Table 2: Contingency Matrix
If ejpn and Cen . q are good translations of one another , a should be large , and b and c should b c small . In contrast , if the two are not good translations of each other  , a should be small , midbaud c should be large . To make this argument more precise , we introduce mutual information ~ s follows . Thresholding the mutual information extracts fixed collocations  . Note that mutual information is reliable in this case because the frequency of each word chunk is thresholded at the word chunk extraction stage  . 
p , ' ob(q , , , , , c ~ , , . , ) = log"("+~+~+ d ) log v, . ob(,:j,,,)v, . ob(~ , ~ , ,~) (  , + b )( , + c ) Next , we sumnmrize how flexible collocations are extracted  . The following is a series of procedures to extract flexible collocations  . 
1 . For any pair of chunks in a Japanese sentence , compute mutual information . Con > bine the two chunks of highest mutual information  . Iteratively repeat this procedure and construct a tree level by level  . 
2 . For any pair of chunks in an English sentence , repeat the operations done in the the
Japanese sentence.
3 . Perform node matching between trees of both langnages by using mutual information of Japanese and English word chunks  . 
t in , ~ l ~ or eR
Figure 4: Constructing Flexible Collocations The first two steps construct monolingual similarity trees of word chnnks in sentences  . The third step iteratively evalnates the bilingual similarity of word chunk combinations by using the above trees  . Consider the example below , in which the underlined word chunks construct a flexible collocation  ( ~Y if / ~? ~ . ~t~ , f~t~_~ , : xg  ~ ,   I-iti~'~3: ~?_k~-L/~:/~rose ~ on the oil products spot market in Singapore  )  . First , two similarity trees are constructed as shown in Figure  4  . Graph matching is then iteratively attempted by compnt-ing mutual inforlnation fbr groups of word chunks  . 
In the present implementation , the system combines three word chunks at most . The technique we use is similar to the parsing-b ~sed methods for extracting bilingual collocation  ( Matsumoto et al . , 1993) . Our method replaces the parse trees with the similarity trees and thus avoids the combinatorial explosion inherento the parsing-ba ~sed methods  . 
lia : ample : , , ,
Naphtha and gasoil rose on the oil products pot market in Singapore  5 Preliminary Evaluation and
Discussion
We performed a preliminary ewduation of tile proposed method by using  10-days Japanese stock market bulletins and their Fnglish abstracts  , each containing 2000 sentences . The text was first au--tomatically aligned and then hand-checked by a hum~m supervisor  . A sample passage is displayed in TM~Ie1 . 
In this experiment , we considered only the word chunks thai ; appeared more than 4 times for fixed collocations and more than 6 times for flexible collocations . Table 4 illustrates the fixed collocations acquired by our method  . Almost all collocat . ions in Table 4 in volw ~ domain specilic jargon , which DI ( j \] ( ~I-~~I1\]~TokyoForex~I ) olhu " ~ t t , ~ yenb ' , i !--' l-1~"~\[+\]\]~9 I~~_~k?c The 1 , J . S . clirrency W it S ( llloted at were sold ~ dropped as well II ~ I ~~" ? fJ~'i ~  ( lb /' eIla , nk of , lapi in injected P~-d ~' nY--~-\]!~~" Oll lrOll ~ ~ lllllil  , GlllOForcsl , fy--Tal)h ; 3: Saniples of li'lexible(~ollocations
No___Jttl ) Olles (:= ~ . k'c , tJAFCO ~-~-7--~ sq-:~ . kb/%'~ , 6 t0 , j , ~ , ~~2"":; Ta)5~~~t ~-_26 a a_~
CBQs\]z~j~kA,~0 f ~ ffktf/19 ~ lIg't11 ~

Tokyo Forexahead of
German mark
Japan Associated l Cin~nce in contrast remained aidelined watching fear 
Tokyo Goldfuture ~ ( \] in : slow wait-and-acemood
Loco-London gold ~ in at mark
Convertible bond ~ dealers trad in ~ ; volume h ~ i ~ h-yielder a
Nikkei 300 future nAft-opg:~-cln:conr~ctended economic ~ timulun pack a e ~ a ? -- cloted t~t future acls : bondInt ~ rket convertible bondn nikkeifuture ~ aft-opg:~\[  . disheartened by -' . .0')~1 . ~7)~ ~  .   .   .   . petaton of % Lo ~ , 9 ~'1~4 ~ q : e@ ; eduphish-tech sharen wMt-and-~e?mood
Surnitomo Forestry
U.S.-dapt tn~utot ~ lks npecul ~ tive buying of_
Tokyo~me . 8: ~ intereatrate ~ the dapan-U , S . & u to dispute
N-oT . T . Jiii ) l-i11 thG(~asf ~9 fll ~*~' l' , t31~) l4a ~ Cl4Al~-- ,   , m - , 4 ~4o/\]'II a ) 9' dI )   ~--7-- ~Ltc--~-~--~o ~ 0-~:   3   5t bond ~ and bond futures public funds in ttitut ional inventors benchmark semicon ductor-related ~ to cks  forei6n inve ~ tor ~ hlgh-tech ~ tocks turn over small-lot ~ ellinfz-r ~ cord high benchmark low 
Tokyo Stockn 2nd Sec were weak individual inveator a pretax profit
The firnt ~ ection of TSI ~ , the Nikkei ~ tock average
Tokyo CB ~ Oqp ~ i long term government bondll were ~ rnded at importerll advanced cover in ~ 
Showa Denkovolume w ~ hit a new year ' ~ hi ~ rh ruling co~litlon q:i ~ JJ ~ T if ~__ : ~ l~R'~r  , i , :~ , ~ . .,~ ? Nikkei World Commodi t ie , : ~ ir,J I r/
Suml to mo Special Metals
Nikkei 300 future nMn ~
OSl ~ year ' ~ low ln ~ close in chednp
Ta , ble 4: Siunples of Fi?cd Collocation , < ~ cannot , be const . rueted composit , ionally . For exam-phi , No 9 nieans ' Tokyo ( ~ ohlFu Lure , m~rkel ; ended trading R ) r the ( lay ' , but was never written as such . As well as No .  9  , a nuuflml : ofseut ; ence-level collocations were also extracl , ed . No . 9, No . 18, No . 23, No . 2 < No . 35, No . 56 and No . 67 a . ret , ypica , lheads of Lllestock markel ; report . The seexi ) rcssioi is a . plleare wery da . yinst . ock markel , re-ports . 
Il Lisinl , eresl , iilEI4) not , ic(~lhevariel , yo\[fixed colh ) ca . tions . They dill ' ~' r in their consl . rucl . ions ; noun phrases , verll phrases , I ) rel ) os it . iol ml phrase <; and sentrnce -- level . All , hough coltvention a Jnle Lll-ot is focus on hourillh rases or  , ryt ; oen (: onll/assall kinds of (- olloca . tions at the sanie time , we be-liew " l , ha , t , fixed colloca , tion is a uil np or l , anl , classo\['colh ) cation . It is useful to iltl , ensively sl , udyfixed collocations because 1 , he ( : ollocatioll of lilore com--plex structures is ( lillic . lt to h'i ,  '  , regardle ' ~ , ~ of them f~l , hod used . 
' I'M Ae3 exemplifies the flexible colloca . tions we acquired fronl the saint cO rll US . No . 1 to No . 4 are typical exprossions in stock nlark c'l , reports . These collocation are eXl ; l'en lc . ly useful for l , elll ) lal , e--based nlachine / . ra . nsla . tiol ~ sysl . enls . No . 5 is a . nexamph ~ o1'a useless (' ol\[ocalriOIt . BOt\]l Olnrona , nd ~ unii , omoForcst ; ryarc cotupap , y names 1 , lid , l ; co-o cem-I ' requenl , l y i . sl , ockuia , l'kel , i ' el ) or t ; s , bul , t . he . qc two conlpanics ha , veuo direct relal ; iou . In fact , nlore I . hanhalf of a . IIlh ! xibh ~ collocations acquired were like No .  5 . To remove use h>s scoJJ()('; t-lions,co,stra . inl . s <) nl ; ll <"<' haracl . ertyl > eS would I ) e useful . Most useful , lapa/ICSe/lcxiblt'(:ollocai . iOllScoul ;; linal , least one ilira . gamt3ch~u-acter . Thus ,  3  , Iai)~nese has ( , n'c(~t , yp e , ~of chara ~ ctcrs(IIira . ga . na , I(a tak;~na . , and t < anjO , each of which has dilt't ! rcnta . n . ) uttts of i . lbrntalio .   . In ( Oll Ll , t , qt , Enl-lish ha . souly posing this constraint on extracted strings . 
It is also interesting to compare our results with a JapaneseEnglish dictionary for economics  ( I watsu ,  1990) . About half of Table 4 and all of Table 3 are not listed in the dictionary . In particular , no verb phrase or sentence-level collocations are not covered  . These collocations are more useful for translators than noun phrase collocations  , but greatly differ from domain to domain . Thus , it is difficult in general to hand-compile a dictionary that contains these kinds of collocations  . Because our method automatically extracts these collocations  , it will be of significant use in compiling domain specific dictionaries  . 
Finally , we briefly describe the coverage of the proposed method  . For the corpus examined ,   70 % of the fixed collocations and 35 % of the flexible collocations output by the method were correct  . 
This level of performance was achieved in the face of two problems  . 
? The English text was not a literal translation . Parts of Japanese sentence were often omitted and sometimes appeared in a different English sentence  . 
? The dataset was too small.
We are now constructing a larger volume of corpus to address the second problem  . 
6 Conclusion
We have described a new method for learning bilingual collocations from parallel corpora  . Our method consists of two steps : ( 1 ) extracting useful word chunks by the word-level sorting technique and  ( 2 ) constructing bilingual collocations by combining these chunks  . This architecturer-flects the fact that fixed collocations play a more crucial role than accepted in previous research  . 
Our method not only extracts fixed collocations with high precision but also reduces the combinatorial explosion that would be otherwise considered in escapable in extracting flexible collocations  . Although our research is in the preliminary stage and tested with a small number of Japanese stock market bulletins and their English  , the experimental results have shown a number of interesting collocations that are not contained in a dictionary of economic terms  . 

Eric Brill .  1994 . Some advances in transformation based part of speech tagging  . In
Proc . 12th AAAI , pages 722-727.
Ido Dagan and Ken Church .  1994 . Termight : identifying and translating technical terminol-one type of character  . 
ogy . In Proc . Fourth Conference on Applied Natural Language Processing  , pages 34-40 . 
Pascale Fung .  1995 . A pattern matching method for finding noun and proper noun translations from noisy parallel corpora  . In Proc . 33rd ACL , pages 236-243 . 
Gaston H . Gonnet , Ricardo A . Baeza-Yates , and Tim Snider , 1992 . Information Retrieval , chapter 5, pages 6682 . Prentice-Hall . 
Masahikol Iaruno and Takefinni Yamazaki . 1996.
High-Performance Bilingual Text Alignment Using Statistical and Dictionary Information  . 
In Proc . 34th ACL.
Satoru Ikehara , Satoshi Shirai , and Hajime Uehino .  1996 . A statistical method for extracting unit nerrupted and interrupted collocations from very large corpora  . In Proc . COLING96 . 
Keisuke Iwatsu .  1990 . TREND : JapaneseEnglish Dictionary of Current Te rm s  . Shougakkan . 
Akira Kumano and Hideki Hirakawa . 1994.
Building an MT dictionary from parallel texts based on linguisitic and statistical information  . 
In Proc . 15th COLING , pages 76-81.
Julian Kupiec .  1993 . An algorithm for finding noun phrase correspondences in bilingual corpora  . In the 3lst Annual Meeting of ACL , pages 1722 . 
Sadao Kurohashi , Toshihisa Nakamura , Yuji Matsumoto , and Makoto Nagao .  1994 . Improvements of Japanese morphological naly zer JUMAN  . In Proc . International Workshop on Sharable Natural Language Resources  , pages 2228 . 
Yuji Matsumoto , tIiroyuki Ishimoto , and Takehito Utsuro .  1993 . Structural matching of parallel texts . In the 31st Annual Meeting of ACL , pages 2330 . 
Makoto Nagao and Shinsuke Mort .  1994 . A new method of ngram statistics for large number of n and automatic extraction of words and pha -rases from large text data of japanese  ,  . In Proc . 
15th COLING , pages 611615.
Satoshi Sato and Makoto Nagao .  1990 . Toward memory-based translation . In Proc . 13th COL-
ING , pages 247-252.
Frank Smadja , Kathleen McKeown , and Vasileiost latzivassiloglou .  1996 . Translating collocations for bilingual lexicons : A statistical approach  . Computational Linguistics , 22(1):1-38,

\[' rankSmadja .  1993 . Retrieving collocations from text : Xtract . Computational Linguistics , 19(1):143177, March . 

