Degrees of Stativity : The Lexical Representation of 
VerbAspect
Judith L . Klavans and Martin Chodorow
IBM T.J . Watson Research
Yorktown Heights , NY

~Hunter College of the City University of New York

L'acqnisition automatique de connaissance lexicale hpartir de larges corpuss'estessentiellement oce up & desph finom ~ nes de cooccurrence  , aux dfipens destraits lexicaux in h~rents . Nousprfisent on siciunem & hodologie quipermet d ' obtenir l ' informations fimantiques url ' aspect du verbeen analysa ~ t automatiquement uncorpuse t en appliquant destests linguistiques hl'aided ' unestifled ' outils d ' anr dysestructura \] e  . Lorsqueces deuxt ~: hessontaccomplies , nous proposons unerfip resentation del'aspect du verbeqnias socieune valeur demesure pour les diff firents types d'fiv~nements  . Les mesures zefl ~ tentl ' usage typique du verbe , et par consfiquent une mesu reder fisistance ou denon-r~sistance hla coercion dans lee on text e delaphrase  . Lesr fisult at squenous rapportonsicion tfitfi obten us de deuxmani ~ res:en extrayant l ' information n&essrSrehpartir du corpus & i quetfide Francis and Ku~era  ( 1982 )  , et en fais ~ nt tourner unanalyseur syntaxlque ( MeCord 1980 ,  1990 ) surle corpus du Reader's Digest a find'extraire une information plus pr&ises url ' usage du verbe dansle text e  . 
Not retravaili Uust redeux aspects : 1 . Les ptopri6t6s lexicales inh6rentes peuvent fitred fitermin & sen appli-qurm taux textes unes & ie detest sllngnistiques bien & ablis  . Celadonnel ' analyse de corpus une dimension suppl ~ mentair equiva au-delh desph ~ nom~nes de coocurrence  ( eomme par example information mutuelle , substitutabilitfi ) . 
2 . Une propri~t ~ lexiealen ' a pas be-soind'etre discrete mats peut & rere pr ~ sent ~ eentant que valeur ~ in-terprdter comme une tendance ou probabilit Y  ; decettemani ~ re , \]eoh- . jet lexieal exprime la propri~t ~ donn ~ edartsun contexte non-marqu & Les valeurs der/v ~ esdu corpus sont variables  , e'est-h-dire des valeursh de gr~s . 
Destests linguistiques on t&~automatiquement appliques aux corpus analys~s demani ~ rekd & erminer lavaleur initiale del ' aspect pour la stativit ~  , etce , pour unensenble deverbes frequents , repr ~ sentant plus de 90% desoccurrences deverbesdans un corpus d'un million deroots  . 
ACTESDECOLING-92, NA rTr ~ . 2328 A Ol~r 1992 1126 PROC . OFCOLING-92 . NANTES , AUG .  2328 ,   1992 Degrees of Stativity : The Lexical Representation fVerbAspect Judith L  . Klavans and Martin Chodorowt
IBM T.J . Watson Research
Yorktown Heights , NY amd ~ Hunter College of the City University of New York 
Abstract
The automatic acquisition of lexiced knowledge from large corpora has dealt primarily with coocurrence phenomena  , t the expense of inherent lexic~l features . We present here umethodology for obtaining semantic information on verb aspect by parsing a corpus and automatically up-plying linguistic tests with a set of structural analysis tools  . Once applied , we propose a representation for verb aspect hat associates a value with weights for event types  . Weights reflect typical verb use , and thus represent a measure of the resistance or ease of coercion in sentential context  . The results we report here have been obtained in two ways : by extracting relevant information from the tagged Brown corpus  ( Francis and Ka~era 1982 )  , and by running ~ parser ( McCord 1980 ,  1990 ) on the Reader's Digest corpus to extract more accurate information on verb usage in text  . 
1 Overview
Our work illustrates two points : 1 . Inherent lexical properties can be deterufined by applying a battery of established hnguistic tests to corpora ~ This adds to the utility of corpus analysis a dimension beyond coocn r-fence phenomena  ( e . g . mutual information , substitutability ) . 
2 . A \] exical property need not be discrete bat can be represented as a value to be interpreted as a tendency or probability for the lexical item to exhibit the given property in an unmarked context  . Corpus-derived values are variable , i . e . DEGREEValU~Linguistic tests have been automatically applied to parsed corpora to determine an initial aspectual value for stativity for use to f frequent verbs  , cov-eting over 90% of verb occurrences in a one million word corpus . 
2 Event types
Aspect can be informally defined as a property which reflects the temporal organization of an event  , such as duration ( whether an event involves change over time )  , telicity ( whether it has a definite endpoint or is ongoing )  , iter at l v l t y ( whether or not it is repetitive ) and so on ( see Comrie 1976 . ) We assume three event types , following Vendler 1967 , refined by many others , and recently recast from the perspective of computational lexicon building by Pastejovsky  1991  , and Pustejovsky and Boguraev ( to appear ) 1:State ( S ) : knon , resemble , b ~ , love
Process(P ): run , walk , eviM
Transition ( T ): give , open , build , destroy A verb can enter into u construction which may change the overall phrasal or sentential event structure  , asttte result of event-coercion . Coer-cion can be defined as the process by which verbs in context appear to demonstrate some regular ambiguities  , i . e . they appear to change categories . 
Pustejovsky argues that uverb is inherently ( lex-fealty ) specified as being of a certain event type ( e type )  . 
Schema : e-type ( Verb ) -SIPI Te-type ( reeenble ) ~ Se-type ( run ) ~ Pe-type ( give ) -T
Figure One
I Nolice that accomplishment verbs ( e . g . ~ palnt ? pie-ture ") , and Itch leveme , tveltbw ( " reachago M " ) are both considered tr ~ neition verbi , AcrEsDECOLING-92 . NANIJ ? S . 2328 AO~I 19921127 PnOC . OFCOLING-92, NAhrrgs , AUG .  2328 , 1992 We call this the NON-DEGREE APPROACH , since there is node greespecified . Our claim is that , rather than the representation in Figure One , the event structure is a vector of values , etype(Verb ) = ( S , P , T ) . We deal here only with the statics/non-statics distinction  , since there are regular differences between states versus activities and accomplishments  ( Lakoff 1965 )  . We propose a simplified representation e-type ( Verb ) =Vo ( x ) with a single value for stativity , Vs , the non-statics value being merely the complement  , i . e . 1I , + V~s = 1 . Our position can be summarized as:
Schema : e-type ( Verb ) ~ Vs ( Z ) where 0 < Vs ( X ) <1 and nhore VH+V~s = 1 . 
Figure T~o
We call our position the DEGREE APPROACH since a numeric value or DEGREEiSspecifted  . We agree with the notion of assuming basic verb types  , with coercions , rost ratheposition proposed by Dowry 1979 that there be different entries for different usages  . 
To allow the process interpretation i sentences like:  ( i ) The childiv being a fool today . 
(2 ) Shei ~ resembling her mothez more and more each day  . 
the phrase " more ( and more ) " in (2) , a temporal expression , acts to " coerce " or force a nonstative event ( in this case a process )  . ~In fact , the verb " be " , often touted as fundamentally the most sta-tics verb in the language is frequently coerced into process and transition  . 
3 Computational Lexicons
The work reported here is part of an ongoing project in the bexical Systems Group at IBM Research to extract and represent lexical knowledge in CompLex  , a computational lexicon which will be able to provide information to natural language processing systems  . The seeds of this project are presented in Klavans  1988  , where it is argued that the building of a computational lexicon requires ~ Our position might be viewed in terms of ~ signing probabilities to the arc tranmltions in ~ system luck as that proposed by Moths and Steedman  1988  , in which coercions ~ rerecursive but carefully constrained along several keypa-r ~ neters defining possible transitions within a finite -state trtmsitionetwork  . 
mapping of resources into a common central lexi -cat datubase  , rather than being dictionary bound . 
The view is further expanded in Byrd 1989 . Pustejovsky and Boguraev ( to appear ) argue that a the ~ ory of lexl cal semantics making use of a knowledge representation framework offers an expressive vocabulary for the representation f such lexical information  . They outline a concrete framework consisting of four levels of lexlcal meaning :  ( 1 ) Argument Structure ; (2) Event Structure ; (3) Quails Structure ; and ( d ) Lexical Inheritance Structure . 
Pustejovsky 1991 provides formal details of the event structure specification for verbs  , with a for-real explanation of semantic type coercion  . 
Specification of verb and phrasal aspect matter to NLP systems in several ways  . For example , when a stative verb is used in the presentense , it involves only one occasion of the event . In con-trust , a nonstative usage involves a frequentative , iterative , or repetitive interpretation . Thus:
John knous the answers . ( single )
John runs . ( repetitive )
Sue builds houses . ( repetitive )
It is necessary to understand the interpretation f statl vity for several reasons  . In language generation , adverbial adjuncts which have a durational interpretation are  , undermost circumstances , disallowed : * John knew the answers for three days  . 
John ran for three hours.
Sue built houses for three decades.
For text analysis , if a verb which is usually stative is used with a non-statl vead verb  , such as " deliberately " , it can be inferred that the event is nonstative , and not the reverse . If the event is non-statics , then it can be inferred that it could be a repetitive or iterativ event  . This can effect not only the semantic interpretation of the text itself  , but also translation and the choice of adverb . 
3  3Many of these issues are discussed in the CLS pecial Issue on Tense and Aspect  ( June , 1988) in articles by Hin-niche , Moens and Steedman , Nakhimovsky , Passoneau , and Webber . For example , Pass one au demonstrate show , without an ~ ccurate specification f the ~ pectual tendencies of the verb coupled with the effect of temporalnd aspectual adjuncts  , messages , which tend to be in the present tense , t trenot correctly understood nor generated in the PUNDIT system  . For instance , " the pressure is low " must be interpreted at statlve  , whereas " the pump operates " must be interpreted as a process  . In machine translation , for example , the verb parecers emeaning ' to resemble one another ' is even leHs statics in Spanish than in English  . 
Thus , sentence ( 2 ) above should be translated into Spanish ACRESDE COLING-92  , NAntES , 2328 AO'dr 19921128 PRec . OFCOLING-92, NANTES . AUG . 2328, 1992 Aspect is complex . Stativity is not u simple feature such as an imate  ( +/ -  )   . Toob .   .   .   .   . this , it suffices to look in any comprehensive grammar , for example , Quirk et al 1972 , in wt fich lexieal verbs are divided into the classes " dynamic " and " stative "  , with the cavea that " it would be more accurate to speak of ' dynamic ' and " stative ' uses of verbs "  ( p .  9495) . Dowty 1979 observes that the issue of interpretation and aspect involves " the thorny problems of polysemy and honrophony "  ( p . 
62) . Since some verbs are " more statl ve " than others  , meaning that the most common unmarked use is as a marker of sentential or event stativity  , the lexicon must embody this lexieal fact . Our proposal provides the capability in the lexicon of representing that variability  , combined with automatic means of inducing variability values  . 
4 Procedure
Some standard tests for the stative/nou-statlve distinction are given in Dowty  1979  , such as the progressive , imperative , cmn plement of force/persuade , intention M adverbs , and pseudo-cleft , as in : 4
Progressive : non-statives * John is kneeing the anuuer  . 
John in running.
John in building shouse.
Complement of force/persuadu : * flail forced John to know the ansner  . 
flail pursua dud Amy to run .
John forced Bill to build a house,
Adverbs , eg-deliberately , carufully : * Gull doliburatuly knouthe an Beer  . 
Evelyn ran carefully.
Sue carefully built a house.
Even though tests for stativity involve interactions between semantic and syntactic facets of a sentence  , we have chosen three tests for stativlty , the most robust being the tendency for a verb to occur in the progressive  . Unlike other tests , the progressive itself is a statement of duration and process  . 
We hypothesized that degree of stativity , i . e . a value for stativity Vo , conld be inferred by determining the ratio of total frequency of occurrence of a verb in a progressive usage  , past or present , in the simple present , not the progre , mive , a ~ i * tEngllJh . 
ead ad~a . llase parse eI~sa ? ~~ ~ dre.
For activity verbs , the progressive in EngliJh translates to the progressive in Spalfi Jh  . 
4 Activltes and accompllshmentl aresubject to other dim-tinguilhing tests which are not the wubject of this paper  . 
over its frequency as a verb in the same corpus :
F ( V erb(X ) whore 0 < V , <1
A value closer to 0 indicates that a verb prefer sta-tivlty . \]' his basic value can be modified by other tests  , such the force/persuade test , and the delib-erately/carefully test . 
We are aware that this is an overMmplificatlon of the property of stativity  . I lowever , our goal is to search for the most robust and pragmatically possible tests to start with  . Our technique has given results which concur with our intuitions  , although there are limitations discussed below , sIn order to do this , we needed utext tagged for part of speech . Otherwise , instance such as " hearing aid " , '% knowing look " would be taken as instances of progressive verbs  . 
5 Results
Tagged Ku~era and Francis Data
The Brown corpus provided a convenients arting point  , since words are tagged for part of speech . 
l to wever , a closer look at the tagset itself reveals a weakness which could bias our results  . The tag VBG is used to tag " verb , present participle , and gerund . " Thus , there is no distinction in the label for the different usages of the "- ing " form  , although some "- ing " forms are labelled NN for noun or JJ for adjective  . Despite this problem , we chose to use the Brown data , knowing that the numbers a right be distorted . We started with a list of the 100 most frequent words labelled as verbs ( i . e . the 100 most frequent verbs , which account for over 90verbs which have been discussed in the literature on stativity  ( such as " resemble " , " matter " , " intend ") . Figure Three lists some results , ordered by degree of stativity . 
e-type(try ) = Vs ( . 3326) u-type(work ) = V0( . 3064) e-typu(nit ) = V , ( . 2929) u-type(run ) = V , ( . 2853) e-typu(play)-Vs ( . 2552) a Pustejovsky , person M communication , hempointed out some problem cases where the progressive fMsely indicates that root is non -Jtative  , such as lie/sit verbs ( The book is lying on the shelf , The c~p is sitting on the cownte O , and mental attitude verbs ( John il thinking that he should 90 home now , S do hn is knowing that he should go home note , Marllis suspecting that John will propose tonight  .   ) Such problem tvan be rewolved by finetuning test J . 
? We thank Slav ~ Kate for point in \[ us to this resource  . 
ACTESDECOLING-92 , NANTES , 2328 AOt ~ V 19921129 PROC . OFCOLING-92, NANTES , AUO . 2328,199 2e-type(move ) = Vs ( . 2326) e-type(go ) = 11, ( . 2304) e-type(follow ) = V , ( . 1234) e-type(give ) = V , ( . 0783) e-type(become ) = V , ( . 0718) e-type(hoar ) = V , ( , 0669) e-type(~eel ) = V , ( . 0637) e-type(uppettr ) = V , ( . 0481) e-type(know ) = 1/',( . 0332) e-type(vent ) = V , ( . 0253) e-type(need ) = Vw ( . 0197) e-type(be ) = V , ( . 0173) e-type(eeem ) = V , ( . Ol20)
Figure Three
As can be seen , the ranking roughly reflects intuitions about stativity  , so , for example , seem is more stative than hear , which is in turn more st ~ tire than run . 
Parsing with English Slot Grammar The second more refined method utilizes a parser to analyze text  , and to record verb usages . For this purpose , we used the English Slot Grammar ( Me-Cord 1980 , 19901 a broadcoverage parser written in PKOLOG .   7 To obtain counts of verb usages from the representations produced by ESG  , we used a tool for querying trees ( QT ) , built by the second author , also in PROLOG . The corpus is the Reader's Digest ( RD ) corpus , consisting of just over one million words . We took the same llst of the 115 most frequent and most frequently discussed verbs that was used for obtaining values from the Brown corpus  . We extracted all sentences under 30 words containing the inflectional variants of these verbs from the RD corpus  . We then ran the parser on this subcorpus , ran QT , and obtained values for the different verb usages  . Unlike the Brown data , distinctions are made between the gerundive and participial usages  . Figure Four gives results for some verbs , listed in the same order as in Figure Three , with n indicating the number of tokens : e- type  ( try ) = V , ( . 2167) ( n = 286) e-type(york ) = V , ( . 1311) ( nffi244)e-type(sit ) = Vs ( . 1506) ( n = 146) e-type(run ) = V , ( . 1565) ( n = 230) e-type(play ) = V , ( . 2315) ( n = 95) e-type(move ) = V , ( . 0798 )   ( n = 2131 TAn exception to the quality it imperatives , ** here there were some errors in the parsing ; they were removed from our cM culation t . 
e-type(go ) = 1I , ( . 2901) ( n = 107t)e-type ( foiler ) = 1I , ( . 0375) ( n = t33) e-type(give ) = V , ( . 0209) ( n = 430) e-type(become ) = V , ( . 0507) ( n = 493) e-type(hear ) = V , ( . OO00) ( n=242) o-type(feel ) = V,( . 0317) ( n = 315) e-type(uppenm ) = V , ( . 0272) ( n = 147) e-type(knov ) = V , ( . OOO0)(n = 630) e-type(want ) = V,( . 0000) ( n = 466) o-type(need ) = V , ( . O000) ( n = 258) e-type(be ) = V , ( . 0124) ( n=12482) e-type(seem ) = V , ( . 0000) ( n = 260)
Figure Four
Additional Syntactic Tests
The progressive test is only one of several tests , and in and of itself is certainly inadequate . Several tests mast be run , and then event values must be computed for each linguistic test  . Two parameters are involved : the strength of each test as an indicator of etype  , and the sparsity of data . 
We have preliminary results on two tutditional tests : the force/persuade tst and the deliber -ately/carefully test  . Synonyms and taxonyms were collected for each ( a d ) verb , data were extracted frmn the corpus and parsed . For example , the following shows how a sentence with " force " was analyzed  . However , more data is needed , from a larger corpus , for the results to be significant . 
The same applies for the adverb test.
Difficul tiue forced him to aband on ...
verb ( force ) in f_camp_verb ( abandon )
Figure Five-Verb " Force "
Results of running and computing the weights of different tests on larger corpora will be reported in future publications  . 
6 Discussion
As expected , the results from each corpus differ considerably ; we believe this is due primarily to surface tagging vs  . full parsing . The results from the second method using ESG do not carry the noise from the ambiguous VBG tag from the Brown corpus  . However , there are two important points to be made : ( 1 ) One million words is simply not enough . More data need to be ( and will be ) run to get a more complete and accurate count . 
These are to be viewed as preliminary data , us ~ able but not complete . (2) The value V , ( . 0000) AcrEsDF . COLING-92, NANTES , 2328 A our 1992l130 PREC . OVCOL1NG-92, NANTES , AUG . 2328,1992 cannot be considered categorical . Verbs are generally adaptable in context , s It is a known fact that value * either for words with low frequencies or words in low frequency constructions must be computed on very large corpora  ( Liberman 1989 . ) The current limitations of this approach must be clearly stated  . First of all , this method con-rates the polysemons usages of certain verbs and  , in English , of the verb-particle construction . It could be argued that with enough corpus data , this would become unimportant , but we believe this position not correct . What is required is a fuller analysis of adjuncts in order to know if n verb has been coerced  . For example , it could be the case that a verb which is S in the an-marked case  ( i . e . in a neutral context ) tends to appear as a T verb frequently , since that verb might not occur frequently in a null context at all  . As another example , consider the case of a typical stative verb " know "  . With the object " answer " , " know " becomes typically in choative , e . g . 
" know the answer by tomorrow " meaning " become knowledgeable of the answer "  , or it could be used in the transition sense , e . g . " he will know the answer by tomorrow " meaning " he does not know now and will know then  . " Thus , it could be underlying semantic structure , and not surface syntactic behavior , that determines coercion possibilities . 9 In conclusion , The DEGREE APPROACH captures the fact that verbs have degrees of e type  , i . e . that some verbs are more pliable than others . Thus , rather than the non-degree values in Figure One , we argue for entries like : e-eype ( reee a blo ) = V , ( . 0740) e-typo(go ) = V#( . 2304) e-type(seem ) = V , ( . 012 O ) A corpus-breed method can be used to antomatl -cally derive values for etype  , i . e . undern certain cutoff , the verb is stative , but altern bh in context . More importantly , it gives a degree of likelihood that given any context  , the verb will be used statively or non-statively . 
* This is at act which any semanticist who is trying to argue a firm point can at * el * to  . 
tAho , there appear to be some clashes on the resulting values and intuitions  , thus leading to the suggeJtion that either our intuitions are not correct or that the method it unreliable  . We have not , in fact , addressed the issue of underly in ~ semantic representation  ( e . g . in terms of prim . 
itive a ) in this paper . It has been suggested that syntactic tests \[ or aspect might be flawed  , and that the only way to distinguish aspectual c asses it via the semantic on se-quence sota restive vs  . non0tative proposition . If correct , the approach of extracting values based on syntactic tests will fail by definition  , regardless of whether the value , are assigned manually or automatically . 
7 References 1 . Byrd , Roy .  1989 . " Discovering Relationships unsung Word Sense *" , Dictionaries in the Electronic Age : Proceedings of the Fifth Annual Con-Jereneco \] the University of Waterloo Centre \] or the New Oxford English Dictionary  2  . Comrie , Bernard 1976 . Aspect . Cambridge
University Press : Cambridge , English.
3. Dowry , David . 1979. Word Meaning and Mon.
* ague Grammar . Dordrecht : tloll and.
4. Francis , W . Nelson and Henry Ku6era . 1982.
Frequency Analysis of Enlglish Usage : Lexicon and Grammar  . tlonght on Mifflin : Boston . 
5 . Klavaas , Judith L .   ( 1988 ) " Building a Corn-puts * loaM Lexicon using Machine Readable Dictionaries "  , Proceedings of the Third International Congress of the European Association for Lexicography  . Budapest , Hungary . 
6 . Lakoff , George .  1965 . " On the Nature of Syntactic Irregularity " , PhD Dissertation , Depart-meat of Linguistics . Indiana University : Bloom-ingtoa , Indiana . 
7 . Liberman , Mark .  1989 . " How Many Words Do People Know?"Invited Talk delivered at the  27th Annus . l Meeting of the Association for Compata ~* tonal Linguistics  . Vancouver , B . C . , Canada . 
8 . McCord , M . C .  1980 . " Slot Grammars " Computational Linguistlcs , Vol 6: 31-43 . 
9. MeCord , M.C.199 0." SLOT GR AMMAR :
A System for Simpler Construction of Practical Natural Language Grammar *  , " in R . Sender ( Ed . ) , International Symposium on Natural Language and Logic  , Lecture Notes in Computer Science , Springer Verlag . 
10 . Moensp Marc and Marc Steedman .   1988 " Temporal Ontology and Temporal Reference " Computational Linguistics  . Vol .  14:2:15-28 . 
11 . Pustejovsky , James .  1991 . " The Syntax of Event Structure " Cognition Vol .  41:103:47-82 . 
12 . Pustejovsky , James and Bran Bognrnev . to appear . " Lexical Knowledgel ~ . epreaentation ad Natural Language Processing " IBM Journal of 
Research and Development.
13 . Quirk , Randolph , Sidney Greenbaum , Geoffrey Leech , Jan Svartvik .  1972 . A Comprehen-sive Grammar of the English Language , Longman:

14 . Teany , Carol Lee .  1987 . "GrnmmatlcalizingAspect and Affectedness " , PhD Dissertation , De~par*men * of Linguistics . M . I . T . , Cambridge : Massachusetts . 
15. Vendler , Zeno . 1967. Linguisticsiu Philoso.
phy , Coruell University Press : Ithaca , New York . 
ACTESDECOLING-92 , NAgrES , 2328 ho~rr 1992 1131 PROC . oF COLING . 92, NANTES . AUG .  2328, 1992
