Schema Method : A Framework
for Correcting Grammatically Ill-fo rmedInput 
Ikuo KUD01) , Hidey a KOSHINO2) , Moonkyung CHUNG2) and Tsuyosi MORIMOTO1)
1) ATR Interpreting Telephony Research Laboratories
Twin21 Building MID Tower
2-1-61 Shiromi , Higashi-ku
Osaka 540, Japan
2) CSK Research Institute
3-22-17 Higashi-Ikebukuro , Toshima-ku
Tokyo 170, Japan

The schema method is a framework for correcting grammatically ill-formed input  . In a natural language processing system ill -formed input cannot be overlooked  . A computer assisted instruction ( CAD system , in particular , needs to show the user's errors . This framework diagnoses ill-formed input , corrects it and explains the error , if an input is ill-~' or med . The framework recognizes a sentence at two steps : first parses weak grammar  , and then strongly filters the parsed sentence . When it is known what sentences are passed by the filter  , it can be used even if it is imperfect . As the strong filter , a new method is used : an interpretation schema and an interpretation rule  . An interpretation schema collects input information schemata and then an interpretation rule judges whether the collected schematare correct or incorrect  . This approach overcomes the problem of relaxation control  , the major drawback of the previou syntactically -oriented methods  , and is also more efficient . 
1 ? Introduction
Ill-formed input cannot be ignored when a natural language processing system such as a computer assisted instruction  ( CAD system or a machine translation system is built  . Particularly in a CAI System , students often make mistakes , such as mispunctuation , lack of agreement , misplaced/improperly-used words , etc . In these cases , a CAI system needs to point out input errors , and show why the input it ~ wrong . In order to do so , the system needs to diagnose and correctill -formed input to explain the errors  . 
The schema method as a framework for correcting grammatically ill-formed input is suggested and the diagnosis and correction of errors is discussed  . 
There have been many studies for processing ill -formed input for English  . The point of those studi . es is the diagnosis : how does the system find an error ? The approaches are classified into two groups : the syntactically-oriented group and the frame-based group  . 
The syntactically-oriented group includes robust parsers based on Augmented Transition Networks  ( ATN ) which Use the relaxation technique/Kwansny 1981 . /or the meta-rule/Weisehedel 1980 ,  82 ,  87/ , and the EPISTLE system which addresses the problems of the checking grammar and style of texts  , such as letters , reports and manuals , written in ordinary English/Heidorn 1982/ , /Jensen 1983/ . 
The frame-based group attempts to deal with ungramnmtical input through extensions to pattern matching parsing/Hayes  1981/  , through conceptual case frame instantiation /S chank  1980/and through approaches involving multiple cooperating parsing strategies/Carbonell  1983/  . The target of that study is dialogue phenomena in communication with limited-domain systems  , such as database systems , electronic mail systems , etc . 
The aim of this study is error-correction of nonnative speakers written English text  . This approach is syntactically oriented . 
The syntactically-oriented approaches/Kwansny 1981/ /Weischedel 1980  , 82 , 87/ , /Heidorn 1982/ , /Jensen 1983/are very similar . Their basic idea is relaxation . They first attempt to parse the input , using fully grammatical rules . 
If the sentence is not parsed , some of the conditions are relaxed . However these approaches have two major drawback . 
(1 ) Relaxation control strategies : when inputs are ill-formed  , some means of ranking alternative si appropriate . 
The number of relaxed configurations may be large.
One of the most critical problems is control . The need to relax the very rules that constrain the search for an interpretation is like opening Pandora's box  . /Weischedel 1987 ( PP . 117 ) /  ( 2 ) Computational inefficiency : the relaxation approach cannot recognize ill-formed input before the analysis with wellformed grammar is finished  . Furthermore , fully wellformed grammar is needed . To makefully wellformed grammar , subcategorization fparts of speech is needed and other conditions are added  . As a result , there are too many rules . 
In comparison to previous approaches , this approach does not use the relaxation technique  . The difference between previous approaches and this one is the method of recognizing an ill -formed sentence  . Previous approaches first use a strong filter , then relax the conditions . This approach , however , first uses weak grammars , and then strongly filters the passed sentence . This approach recognizes a sentence at two steps . 
An attempt is made to expand lexical-functional grammar  ( LFG ) /Kaplan 1982/to deal with ill-formed input . LFG has two drawbacks : ( 1 ) LFG can't deal with errors of omission and ( 2 ) LFG has no framework for error correction . If an input sentence is wellformed , this framework obtains an LFG f-structure . If not , the sentence is corrected . 
Examples of error correction are given in the next section  . In the section following the basic idea is described  3~i and the problem of a unification mechanism for processing ill-formed input is discussed  . This framework is shown in section 4 . 
2 . Non-native speaker's ill-formed phenomena In this section  , treated examples of nonnative speaker's ill -formed phenomen are given  . The application is a CAI system for Japanese junior high school students in a primary English course  . Their errors are different from a native speaker ' s  . Typical errors are shown in Table 1 . 
English is very different from Japanese in parts of speech  , word-order , tense , etc . For a Japanese , there is no concept of ( l ) countable and uncountable nouns ~:>~~> in Table  1  ,   ( 2 ) singular and plural forms < ~ ( 3 ) articles ~> ~> ( 4 ) agree-merit between subject and verb@ ( 5 ) adverb word-order ~ . 
Japanese interfered with the students'acquision of English  . The following errors are often made by Japanese adults as well  . (4) verb style < ~(5) category mistakes , word misuse ~> . Furthermore , junior high school students are reading and hearing a foreign language  ( English ) for the first time , and thus have no concept of foreign language whatsoever  .   ( 6 ) Logical error @: the student who made the mistake explained that " are + not -* aren't "  , " is+not-*isn't"so"am+not--*amn't " .   ( 7 ) Primary students are not familiar with Engli sh grammar and can't distinguish between " Who " or " Where "@@  .   ( 8 ) Surface rror : letter or punctuation problems Table  1  . Examples of errors by junior high school students < ~* He plays piano  . < ~* Heplsy the baseball . 
He plays the piano . He plays baseball.
@* some good advices '< ~* I am student.
some good advice I am a student.
@* A moon is smaller than an erath.
The moon is smaller than the earth.
~* He is one of those men who is difficult to please  . 
He is one of those men who are difficult to please . 
< ~* I have finished my home work already.
I have already finished my home work.
~>* He is listening musi conther a dionow.
He is listening to music on the radion ow.
< ~* We cannot play baseball in here.
We cannot play baseball here.
@* Yes , I am n't .
Yes , I am not . Yes , I'm not.
~* Who does cook breakfast ? ~* Where they live ? Who cooks breakfast ? Where do they live ?@* Doesmr  . brown have a book
Does Mr . Brown have a book ?@* We must stop to complain . 
We must stop complaining.
Grammatical errors ~@ are treated , but not semantic errors ~> and absolutely ill -formed sentences which are not comprehensible  . The aim is to diagnose grammatical errors and show a reason for the error  . For example:
Input sentence ; Mr Brown has a pen , correction ; Mr . Brown has a pen . 
the reason ; Aperiod is needed after " Mr " .
The comma after " pen " should be a period.
3423. Basic idea
In this section , the basic idea of the frsme work and ~ be problem of the LFG unification mechanism in dealing with ill-formed input is described  . 
3.1 Two-level filter
The framework uses two-level filters for input sentence classification : a wellformed sentence  , a relatively ill-formed sentence or an absolutely ill-formed sentence as shown in Figure  1  . 
(1) First an attempt to parse the input , using normal contextfree grammar ( Filter I ) is made ~ Both a well of ormed sentence and the relatively illoformed sentence which includes feature errors are passed through the filter  ( Filter I )  . 
(2) Secondly , these inputs are checked with a strong filter ( Filter II )  . A wellformed sentence passes , but a relatively ill-formed sentence does no L ( 3 ) An input which is not passed through the first fi lter  ( Filter I )  , includes word-order or omitted-word errors ~ or unnecessary words @@  . The input is classified by a filter (~) , called Improper Grammar , as relatively ill-formed or absolutely ill- formed  . 
jal~essed ~ In iut .   .   .   .   .  "~ . -  .   . ~'--~ rejected
Filter(I)\]
F-S : iltor (   ) 1\[Improper Grammar / ( relatively ill-formed ( absolutely ill-formed ) < ~<~<~@: sentence ~> ~ number in Table 1
Figure 1Two-level filter 3 . 2 Filter test Filter ( I ) is a context ~ free grammar . This filter is a weak filter . Therefore some relatively ill-formed inputs are passed  . Consider how many sentences are derived from the grammar rules in Figure  2  .  25  ( 5 ? 1?5 ) sentences are generated by the gramma rules and dictionary entries  . Of course , not only wellformed sentences as in (1) below , but also ill-formed sentences as in (2) ,  (3) , (4) below ~ are included . 
Grammar rules Dictionary
S--*NP VP : Verbal Phrase ( VP ) pronoun -* this
VP--~verb NP verb-~is
NP -* pronoun : Noun Phrase ( NP ) det ~ an
NP-~det noun noun - ~ apple
NP-*noun noun --, apples
The generated sentences (1) This is an apple . (2) This is apple . 
(3) This is an apples . (4) This is apples.
Figure 2The generated sentences 3 . 3 The prob lem of the LFG uni f icat ion mechan ism f~o ill-formed input Relat ively i l l - formed sentences  , as well as feature errors , pas ; ~ t ~ rough Filter(I ) . Filter ( II ) must work as a strong grammatical filter . LFG contains such a strong filter , call c , d the unit'ication mechanism , '" frontF- . 
Descriptions to F-Structures fKaplan1 . 982 ( pp . 203)/" . For exmnpl % " This is a apple " In LFG a -disagreement  , " a apple " , is rejected because the following equations are not unified  . 
. ;   ( t ~\] PEC ) : a from a ( 1' SPEC ) = an from apple I ~ o we ver ~ for diagnosis and error-correct lont here are : ~ ome drawbacks in LFG framework :  ( 1 ) LFG can q : check an error of omission as in the noun phrase ' ~ apple ' in the sentence " This is apple "  . 
A stile sentence lacks the article " an " , there is no determiner equation and the unification mechanism does not work  . Thus the sentence is recognized as a wellformed sentence  . 
fO from ( h : lack of article ( 1' iIPEC ) = an from apple ( 2 ) LFG has no error-correction framework . It only rejects the ill-formed input . Addition of an error-correction mechanismi ' ~ thus necessary  . 
304 Improper Grammar \[ Filter ( liD\]In this application , users are non-native speakers unfamiliar with English grammar  . Thus , a user often makes word-order errors , includes unnecessary words , or leaves out words@@ . A teacher could show why " does " is not necessary in the sentence @"* Who does cook breakfast ' S "  , or wily " do " is needed in @"* Where they live ?"  . If a : ~ ystem diagnose such sentences , it needs to provide the grammar ulest br analysis  . The type of error shown in Figure 3 is called improper grammar . 
* S*Sq-pron*AUX VERB3 NP q-adv NP VERBI ( ~SUBJ ) = 4  ( tOBJ ) = ~ I ( tSUBJ ) =
III 1 * wire doe ~ cook breakfast ?* where they live ?
Figure 3 Examples of improper grammar 4 , ' ~ ? hefl ? am ( ~ wo ~' kIn I bissection an overview of the f rame work is explained  . Unificagon approach has some drawbacks for diagnosis as we described in  3  . 3 . A new method is used as a filter ( lI ) . The idea is to compare input style with proper m , rfi ~ cesty\]~ . s which are synthesized from lexical and grarmmatic ai conditions  . An interpretation schema collects l : he conditions  ( surface schema and LFG schema ) and an L~\[erpretation rule synthesizes proper styles and judges whether the sentence is ill- or well  , formed as shown in Figure 4 . In this section , at first , new schemata are notated : surface schema (4 . 1), surface constraint (4 . 2) , in ~ e ~? pre~ation schema , interpretation schema with condition , conditional schema and kill schema (4 . 3) . And then the ins~mnfiation mechanism and interpretation of 
Input sentence . . . . . . . . . . . . . . . . . . . . Jnpu~\[q)ParsingPl'oce s sing .   .   .   .   .   .   .   .   .   . ~IFG schema'U " rfaescjlema .   .   .   . 
wm,~I~l@Instantiation*J Surface constraint
Filter(II ) J ~" ~ T ~ ~
II mln put style i - - - - - ~ ( ~ Synthesize styles ( = Proper styles ) 
Success Error lfD Correct sentence f-structure ~ Explanation of the errors 
Figure 4 A schema method overview new schemata are described  ( 4 . 4) (4 . 5) . Finally error-correction is illustrated (4 . 6) . 
4 . 1 Inl~ut p rocess ing \ [ Surface schema \[ A capitaletter and a punctuation indicate surface of an input sentence  . In this framework such inibrmation is represented as a schema  , called a surface schema . In the input processing , the input sentence is converted into surface schemata  . The schema is notated as follows . 
(gn f-name ) = value " gn " is the designator which shows the word-order " n "  . " f-name " is a function name of schema , like word , letter or mark , etc . " value " is its schema's value . 
For example , tile ill-formed input , " MR . Brown have eat a apple , " is represented as surface schemata in Figure 5 . 
" MR . " is represented a slout-surface schemata : " ( gl word ) --mr " ; the word is " mr " . 
"(glmark ) = period " ; the mark after the word is a period . 
"( glletter ) = 1" ; the first letter of the word is a capital (" M ") . 
"( glletter ) = 2" ; the second of the word letter is a capital (" R') . 
Input sentence : * MR . Brown have eat a-apl ~ ie V--I/IIIII *, MR . , Brown , have , a , apple , designators L .   .   .   .   .  ~  .   .   .   .   .   .   .   .   . J .   .   .   .   .   .  ~_  .   .   .   .   . _L . . . . . . ~  .   .   .   .   .   .   .   .   .   . r .   .   .   .   . -v .   .   .   .   .   .   .  ~  .   .   .   .   . " I- .   .   .   .   . -r .   .   .   .   . c .   .   .   .   .   .   .   .   . 
ga ', gl ', g2', g3Ig4*, g5Ig 6
Surface schemata
Word =\[( gl word ) = mr , ( g2 word ) = brown , ( g3 word ) = have , ( g4 word ) = eat , ( g5 word)--a ,   ( g6 word ) = apple\]Mark =\[ ( glmark ) = period ,   ( g6 mark ) = comma \] Letter--i ( gl letter )  = 1 , ( gl letter ) = 2 , ( g2 letter ) = 1\]
Figure 5 Examples of surface schema 4 . 2 Lex icon \[ Lexical sur face constra int \ [ In the lexicon  , lexical features and constraints are involved as schemata  . A constraint for a surface schema is called a surface constraint  . A surface constraint is notated as follows : ( ITf-name ) = ? value . 
" IT " means meta-vm:iable . " It " is substituted for " gn " , when the surface constraint is instantiated . 
There are two kinds of surface constraints : lexical and granmaatical  . The capital letter " M " in " Mr . " is a lexieal position . A lexical surface constraint is assigned to the dictionary  ( Figure 6 )  . 
(IT word ) = cmr ; the word must be " mr " .
(ITmark ) = cperiod ; the mark after the word must be a period . 
(IT letter ) = el ; the first letter of the word " mr " must be a capital  . 
Lexicon Lexical surface constraints and LFG schemata  neun3 Mr .   ( IT word ) = cmr ( tPRED-1 ) = mr ( IT mark ) = cperiod ( tGENDER ) = male ( IT letter ) = cl ( 1' CATEGORY ) = noun3 noun l Brown ( IT word ) = c brown ( ~ PRED ) = Brown ( IT letter ) = cl ( 1' PERSON )  = 3  ( 1' NUM ) = SG ( 1' CATEGORY ) = nounl
Figure 6 Lexicon 4 . 3 Grammar \ ] Grammat ica l sur face constra int \ ] The first letter in a sentence is always a capital letter and the last punctuation in a sentence is noted as a mark  ( a period , a question mark or an exclamation point , etc . ) . 
These are regarded as grammatical constraints . In our h'amework these grammatical constraints are represented as grammatical surface constraints  . They are assigned to grammar ul ~ as shown in Figure  7  . 
( ITF letter ) = ?1 ; This means the first letter in the sentence must be a capitaletter  . ITF shows first order in the sentence . 
(ITL mark ) = cperiod ; This means the last mark in the sentence must be a period  . ITL shows last order in the sentence . 
Grammar rule
S--*NP VP ( 1'SUBJ ) = $ 1' =  ( ITF letter ) = cl ( ITL mark ) = cperiod Figure 7 Grammar rule with surface constraints \[ In terp retation schema \] In order to diagnose and correct errors  , our framework has three steps ; (1) collecting information on the input sentence ,   ( 2 ) synthesis of interpretation and ( 3 ) comparison of ( l ) and ( 2 )  . 
The interpretation schema collects LFG schemat and surface schemata  . It is assigned to lexicon or grammar rules . In the parsing process , it is instantiated and collects schemata . The schemata corrected by interpretation schema are conveyed to the interpretation rule  . This schema is notated as follows . 
( Tf-name ) = i values
T is a meta:variable as well as LFG notation and " f-name " is a functional name of the interpretation schema  . Its
Values are sets of schemata ?
For example an interpretation schema for agreement between determiner and noun is notated as follows  . 
( ~) ( tDET-NOUN ) = i\[DET\] , \[NOUN\]\[DET\]means set of schemata from determiner  , and \[ NOUN\] means from noun . 
(Example 1 ) For the correctly-formed noun phrase " an apple " , the interpretation schema , DET-NOUN , is attached to gramma rule ( 1 ) as shown in Figure 8 . In instantiation , the interpretation schema collects LFG schemata in lexicon and surface schemat as its values below  . 

Grammar Rule and Interpretation schema ( 1 ) NP-*DETNOUN ( 1' DET-NOUN ) = i\[DET\] , \[ NOUN\] .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
NP:fn(1'DET-NOUN ) = i\[DET\],\[NOUN\]
DET z/NOUN ~1 ! Ix ~ exico . I ( tSPEC ) = ' an ' II ( 1'PRED ) = ' apple '' ~ LFG schemata I ?* NUM ) = SGII?t NUM ) = SG\[ .   .   .   .   .   .   . J , , lJ(tSPEC l ) = ' an/the '
An instantiated interpretation schema ( ~ fnSPEC ) = ' an'\[f in PRED ) = ' apple '- ( fnDET_NOUN ) = i ~\ [ ( fnNUM ) = SG ( fnNUM ) = SGU ( giw OrD ) = an I/ ( t . SPEC1) = ' an/the'A ,  \[ ( gi+1WORD ) = apple_Figure 8 An example of interpretation schema of " an apple "   ( Example 2 ) In another case , the ill-formed noun phrase " 0 apple " , lacks an article . As above , an interpretation schema collect schemata in Figure  9  . 
Other examples of interpretation schemata and their attached grammar are shown in Figure  10  . 
Grammar Rule and Interpretation schema (2) NP- , NOUN(~'DEW-NOUN ) = i\[~\] , \[ NOUN\]
An instantiats d interpretation schema ( fnDET-NOUN ) = iO1\[finNUM ) = SG/I ( t-SPEC1 ) =' ar ~ the '/ ? J2 Lgj WORD ) : apple AJ Figure 9 An example of interpretation schema of "0 apple "\[ Interpretation schema with a condit ion and conditional schema \] An interpretation schema with a condition  , and its conditional schema area pair and act as an interpretation schema  . An interpretation schema with condition can act when there is a conditional schema  . These schematar enotated as ( a ) an interpretation schema with a condition : ( ~' f-name ) = i-CONV alues and ( b ) a conditional schema: ( 1' f-name ) = CONValues . 
For example , this schema ( ~ ) means that if a noun phrase \[ NP:f2\] is a pronoun \[ PRONOUN\] , it checks whether the case of pronoun is subjective \ [ subj\[  . If the noun phrase is not a pronoun , such as " an apple " , there is no need to check . 
(~( f2CASE ) = i-CON\[\[NP : f2l,\[subj\].
The following schema ( ~ ) is its conditional schema . It is attached to gramma rule ( 5 ) and means the noun phrase is a pronoun . 
(~  ( f2CASE ) = CON\[PRONOUN \]\ [ Kill schema \] A kill schema is the instantiation inhibition mechanism  . It works tokill the interpretation schemata and is notated as follows:  ( ~ f-name ) = k ( ~ f-name-l )  , ( tf-name-2) . . . . . . . .  . 
(3) N~P ~-> D~T . . . . AOJ . ~' NOUN ~(~' ~ I ) ET2 ADJ-NOUN ) = i\[I)ET\] , \[ADJ\] , \[ NOUN\] ( 4 ) NP-~ADJ NOUN ( ~' DET-ADJ-NOUN ) = i\[O\] , \[ ADJ\] , \[ NOUN\] ( 5 ) NP ~ PRONOUN ( ~ CASE ) : ~ CON\[PRONOUN\] ( 6 ) S : f1--~NF : f2VERB3: QNP : ~ ( fiSUBJ ) : ~ i'2 ( hoBJ )  = 5  ( ITF letter )  :: ?1  ( ITL mark ) = cPeriod ( QSUBJ & V- . FORM ) = i\[NP:f2\] , \[VERB3\](f2CAGE ) = i--CON\[NP:f2\] , \[ subj\](f3CAGE ) : : i - - . OON\[NP:fa\],\[obj/poss\](7) S : fl . - ~ NP : t2 AUX:QVERB 3: fINP : f3 ( il SUBJ ) ~: i2 ( it on J ) = i ' a ( ITF letter ) = cl ( ITL mark ) = cperiod ( f ~ SUBJ&A-FORM ) = i\[NP : f21 , \[AUX\](flAUX&V-FORM ) = i\[AUX\] , \[ VERB3\](f2CASE ) = i . _CON(\[NP:f2\] , \[ subj\](f3CASE ) = ~ i~-C0~\[NP:f~l , \[ obj/poss\](8) S : it- , ~ NP:f2 VERB-be:fl NP:f3 ( fl SUBJ ) = f2 ( fl COMP ) = f3 ( ITI , , letter ) = cI ( ITL mark ) = cperiod ( t'1SUBJ&V-FORM&COMP ) = i\[NP:f2I , \[VERB~be\] , \[NP:f3\](h SUBJ&V . -FORM&COMP ) = k(f2DET-NOUN ), ( f2DET-ADJ-NOUN )
Interpretation Schemata Grammar rule ~ )   ( TDET~NOUN ) =I\[DET\] , \[NOUN\]Rule ( I ) (2 )   ( ~  ( I'DET-AI ) J-NOUN ) =i\[DET\] , \[A1)J\] , \[NOUN\]Rule ( 3 ) (4 )   ( ~  ( t'ISUBJ&V-FORM ) =i\[NP:f2\] , \[ VERB3\]Rule(6) (8)( . 4) ( flSUBJ&A-FORM ) = i\[NP:f2\] , \[AUX\]Rule('/)(f ~ AUX&V-FORM ) = d\[AUXI , \[ VERB3\]Rule ( 7 )   ( fl SUBJ&V-FOR M&COMP ) = i\[NP:f~\] , \[VERB-be\] , \[NP:fs\]
Rule ( 8 ) knter pretation Schemata with condition Graml nar ule ~  )   ( f2CASE ) = i . ~CON\[NP : f ? . \],\[ subj\]Rule(6)(7) (8)
Conditional ~ chema Grarmnar rule ( 0_ )   ( 1"CASE ) = cON\[PRONOUN\]Rule ( 5 ) 
Killschema Grammar rule ( 9 )   ( f2 SUBJ&V-FORM&COMP ) = k ( f2DE'r-NOUN )  , Rule (8) ( f2I)V . T-A~ ) J-NOON )  @ ) This schema checks agreement between determiner , adjective and noun such as ' the same name ' , '* some good advices ' , '* a good jobs ' , and '* a interesting book ' . 
? This schema checks whether verbibrm ( V-FORM is a proper tbrm for subject style ( SUBJ )  . \[NP:f2\] is subject . 
For example " To m gives . . . ","* Helaugh . . . ", " You made_ . ." and "* Mr,and Mrs . Brown laughs . . . " . 
(~ ) This schema checks whether auxiliary verb form ( A-FORM ) i ? , ; a proper form for subject ~ tyle ( SUBJ) . \[NP:f2\] is subject . For example "* Tom have given . . . " and " He can laugh . .  .  '  . 
@This schema checks whether verb form ( V-FORM ) is a proper titan for auxiliary verb . For example ' ~ l ~ om has given . . . ", ' ~* Tom has give . .,", "* You can laughed . . . " and " He is speaking . . . "@ This ~ chema checks agreement between subjective " be " noun phrase  , verb . and compliment .  \[  NP:f2\] is subjective ~ a oun phrase and \[ NP : fS\] is compliment  . For exaraple "* These is apples . ", "* He is students . " and "* They are a student . " Figure 10 Examples of grammar and interpretation schema 1' is a metaovariable and " f-name " is a kill -schema's name  . 
Its value in . . . . . . . is the killed schmnata's name . 
There are hierarchy and priority between interpretation schemata  . A kill schema is used to keep interpretation schemata independent  . The schema attached to noun phrase can collect schemata only wifl f in the noun phrase  , while the schema attached to sentence level can collect schemata in the sentence  . Thus , the former is local and the latter is global . For example , "* This is a apples . " Tile noun phrase , " a apples " , is wrong and should be " an apple " . But the local interpretation schema ~ ( Figure 10 ) can't determine which is correct , " an apple " or " apples " , while the global interpretation schema@can judge that " an apple " is correct  . The global interpretation schema ? checksibr agreements within \[ NP:fS\] instead of the local interpretation schemata  ( ~ ) or ? . Therefore , the local interpretation schemata ( J ) and ( . 2), are not necessary . 
Thus , the kill schema@ , which corresponds to the global interpretation schema @  , kills local interpretation schemata Q ) and ? . 
@( f2 SUBJ&V-FORM&COMP ) = k(f2DET-NOUN ) ,   ( f2DET-ADJ-NOUN )   ( ~ )   ( f2DEW-NOUN ) = i\[DET\] , \[NOUN\](~(f2DET-ADJ-NOUN ) = i\[DET\] , \[ADJ\] , \[ NOUN\]4 . 4 lns tant ia t ion How to instantiate schema is explained  . Both t and ~- metavariables are assigned to actual variables  ( fl , f2 . . . .) as well as LFG . 
A surface schema , a surface constraint and an interpretation schema include " IT " metavariables  . " IT " recta-variables are assigned as follows . 
( Dininput processing , the designator " gn " which shows the word-order in the input sentence is assigned to surface schema  . 
(2) When'the dictionary is looked up , surface constraints in the lexicon are instantiated  . " IT " meta-variable in a surface constraint is bound to the designator " gn " in surface schema  . 
(3) When a gramma rule is fitted , surface constraints in the
S : flGrammar
NP:f2AUX:ItVERB 3: fl NP : fa ( fl SUBJ ) = f2 ( fl SUBJ&A-FORM ) = i ( it OBJ ) = fa ~ ( gl letter ) ~- ? l\[NP:f2\] , \[ AUX\] ( g6 mark ) = cperiod CASE ) = i-CON ( fl AUX & V-FORM ) = if ( f3 CASE ) - - - i -- CON\[NP : f2\] , \[ subj\]\[AUX\] , \[ VERB3\]/\[NP:fa\] , \[ obj\]noun3 nounll det noun ! ~ ( f3DET-NOUN ) = i\]\[\[~\[DET\] , \[NOUN\]\:Lexicon\:(~ .   ( gl word ) - - cm r ~ : ~ : ~ ~ ~ ~ " ~ ' ~ ~ ' ~ < ~6 w Ord ) - ~ capple ( ~ )   ( gl word ) = mrg2 g3 g4 g5 ( g6 word ) = apple
Mr . Brown have eat an apple
Figure 11 An example of a parsing tree and instantiation mechanism 
An example is shown in Figure 11.
4.5 Interpretation ( Filter It)
After the parsing proces . % interpretation schemata , interpretation schemata with a condition , conditional schemat and kill schematare instantiated  . Interpreta-tion schemat are interpreted by interpretation rule  . Input is judged for consistency or inconsistency . 
The interp , ' etation schemat are independent , thus the interpreted order is free . The interpretation flow is as follows . 
(1 ) check conditional schema : if it is an in terp retation schema with condition  , find the paired condition . If conditional schema are not paired , inhibit the instantiated interpretation schema with a condition  . 
(2 ) check kill schemata : if the kill schema includes interpretation schemata which should be killed  , inhibit the instantiated interpretation schema  . 
(3) Interpretation rule : if it is not included , interpret it . 
\[ Interpretation rule I
An interpretation rule diagnoses the input sentence  . 
The schemata collected by an interpretation schema are checked by an interpretation rule  . An interpretation rule synthesizes the word by using collected schemata  . The diagnosis process is as follows . 
(1 ) Find input style from an interpretation schemata . 
(2 ) Synthesize correct style by ? using an interpret at ion rule  . 
(3  ) Compare input style with synthesized sty le  , if consistent , he input style is right . If not , correct he input style to the synthesized correct style  . 
An interpretation rule synthesizes the resul t with conditions from interpretation schema  . For example , the I ) ET-NOUN rule is Shown : in Table 2 . This rule determines if the noun is corrected and synthesizes the specification  ( SPEC ) tbrm as adapted for the noun . 
(Example 1 ) In the case 0f correctly-formed noun phrase " an apple " , the interpretation rule is shown in Figure 8 . 
(1) input style : ( gi word ) = an ,   ( gi + lword ) = apple from surface schemata in Figure 8 . 
(2  ) synthesized style:conditions are ( ~' NUM ) = SG ,   ( ' ~ SPEC 1 ) = ' an/the ' from noun and ( i " SPEC ) = ' an ' from determinant in Figure 8 , the result is ( ~ SPEC ) = an from Table 2 Interpretation Rule for DET-NO_UN
Rule No.I

Conditions
NUM SPEC1
From noun From noun
PL the
PLa
PL an
PL~D
SGa/the
SGa/the
SGa/the
SGan \] the
SGan \] the
SGan \] the
SGX

SPECISPEC
Frem do t~--I the "- IO*-IO aia the I the- " Iaan  , an the Ithe--Ian
IX
Rule B in Table E.
(3 ) Compare ' ( gn word ) == an ' with ' ( tSeEC ) = an ' . Th ~ value is the same . Thus this noun phrase is correctly . -ibrmedo ( Example 2 ) In the case of ' the ill~tbrmed noun phrase " ( Dapple " which lacks an article , the interpretation rules are shown in Figure 9 . 
(1) input style : ~ , ( gj word ):--= apple f Yom surface schemata . 
(2  ) synthesized style:conditions are ( \]' NUM ) := : :\[ ~ G , (1" SPEC1) = : ~ an/the ' from noun , there ~' ; ult is ( ~ SPI~C ) ---- an from rule 10 in Table 2 . 
(3) Comparison O with ($ SI'EC ) = an , as a result it lacl ~: s the article " an " . Add the surface constraint " ( gn -0 . 5 wo , rd )::: can " beibre "( gn word ) = capple " . 
4.6 Erroreor recLion
The error correction phase explains the erroz to the user  . For example , "* MR . F , row n have e a tapple / ~ the f : low of ' error correction is shown in Figure  12  . input sentence i ~ converted into surface schemata and parsed  . Surface constraints and interpretation schemata rethen obtained  . 
These interpretation rules are diagnosed and three errors found  ; (1) SUBJ&A-FORM , (2) AUX & V . FORM and (3) DleT- . i'~OUN Input sentence : * MR . Brown have eat apple, .   .   .   .   .   .   . -~---( Input processing ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Surface schemata
Word =\[( gl word ) := mr , ( g2 word ) = brown , ( g3 word ) =: have , ( g4 word ) : : eat ,   ( g5 word ) = : apple\]Mark-:\[ ( glmark ) : period ,   ( g5 mark ) : comma \] Letter=\[ ( gletter )  := 1 , ( gIletter ) == 2 ,   ( g2 letter )  : 1\] :~  ( Parsing and instantiation ) Surface constraints from lexicon and grammar rules Word : ?\[  ( gl word ) := cmr , ( g2 word ): thrown , ( g3 word ): e have , ( g4 word ) :: coat ,   ( g5 word ) : eapple\]Mark:c\[ ( glmark ) = cperiod ,   ( g5 mark ) = : cperiod\]Letter:c\[ ( gl letter )  --- ?1 , ( g2 letter ) : ?1\] .   .   .   .   .   .  -~-  . . . . ( Interpretation ) "-~ . . . .  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
Convert ( 1 ) SUBJ&A-FORM : ( g3 word ) = chave - ~ ( g3 word )  := ( : has ( 2 ) AUX&V-FORM : ( g4 word ) = coat ~ ( g4 word ) = e cat en ( 3 ) DET-NOUN : ( g5 word ) ~: apple ~- ~ ( g4 . 5 word ) = can ,   ( g5 word ) = apple ( 4 ) MARK : ( g5 mark ) : comma -+ ( g5 mark ) =: cperiod ( 5 ) LETTER : ( gl letter )  --~ 2 -~  .   .   .   .   .   .   .  -~-  . . . . ( Error corection ) .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
Surface constraints replaced by synthesized schemata Word = e\[  ( gl word ) = cmr , ( g2 word ) := e brown , ( g3 word ) = e has , ( g4 word ) = eeaten , ( g4 . 5 word ) = can ,   ( g5 word ) ::: eapple\]Mark--e\[ ( glmark ) = epcriod ,   ( g5 mark ) = cperiod\]Letter=~?\[ ( gl letter ) - - - el ,   ( g2 letter ) = : el \] the correct sentence: ) \]/ r . Brown has eaten an apple . 
the reason : 1) " have " must be " has " .
2) " eat " must be " eaten ".
3) " an " is needed befb x'e " apple ".
4) " W'in"MR"must be a smalletter.
5) " comma " af ~ er " apple " mu ~ tbc " period '*.
Figure 12 An example of error correction 346 ,  (; , Vigure 10) , Fmih ~(' w_ore , surface errors , (4) MARK and (5) I , ETTER , a ~' el ~ rlmd by the difference between surface : ~ chen-mtaat ~ d surface constraints  . The surface constraints are replac ? ~ d by ~ ; yn the sized schemata . The corrected seaten , : e , " Mr . Brown has eaten an apple . ", is then synthe ~: . ; zed ~ Yom surface constraints . The explanations 1)~?5) are g , mcrated by tim result of interpretation rule . 
Thisi'm ~ , e work to a CAI ~; y stem , called ":\] , ~ : , i ( English )   ( JA\["~ was applied and designed to teach English to junior hiKh  ; -mimol students . This: . ~y ~ tem has two main modules ;   ( l ) machine translation/Ku do 19 g ( i / and ( 2 ) this Crm , lework . 
If stm ! e~t ~: p ~' oda (: ? ~ ill . .fiwmed English int)nL , the sy~tem corrects the errors arid shows why they are wren F  . If there are no erro ~' s ~ gi ~ e sentence i . ~translated into Japanese . 
Thissy , ~ i . em was implemented i ~ Prolog ( about 120KB ) . 
Performam ~ eisreul- . tir ~, e(answers within 5 seconds ) . 
Actually t , his system was ilscd by junior high schools t , dents ? We collected mistakes and then ted back to th  , ; system ? This ~ Lystem is one of applications of this \] Yame work in a limited d  ( m ) aii )  . The framework is easy to apply to another domain . To construct a m ' , ,v system , only need be changed the grammar , dictionary and interpretation rulcs . 
6, i ~ imitati ,, m and futm , eworl ~
The ti'a : me work/b . cgrammatically ill . . . Ibrmed input was described ~ ( 1' he following problems remain unsolved : ( 1 ) The_Imui ( m of semantically illdbrmed input : in this framework a semantically ill-  . .formed sentence is passed . Ascma ~, ~ . ic ii ~ ermast be added alter filter(lI ) . 
(2 ) The problem of interpretation : interpretation is often changed by context and situation  . Human beings correctill-formed sentences by recognizing context and situation  . 
Fo ~" example , I1, is a boy ?
Whichic Lerpre ~ ation is right , dialogue situation , word . .
order error Clsheaboy ? ) or misimnctuation ( He is a bay . )? A system wil ) need a context recognizer and a situation recognizer ~ 

This paper has suggested the schema method , a new i ~ a mework t br correcting ill-formed input . This fl'amework recognizes input at two steps with weak and strong filters  . 
When it is known what sentences are passed by the filter  , it ca~beu : ~ edeven if ' imperfect . This method has the tbllowing advantages : Cl ) the proL ( \[ cul of control strategies for relaxation can be avoided beet ase the relaxation teel miqae is not used  , and ( 2 ) comfmtational efficiency ? The LF ( i ~ floamework t br correcting grannaatically ill -fi  ) ~- med input was extended ; a . mlrface schema and ani ~ terp retation schema have bee~proposed  . This fl " arne work ca ~ , correct enters without breaking LFG fi' a mework  , because these schm~mta , as well as LFG schema , cabbe treated . The refbre to make an applied system is very easy . This t Yame work was implemented in Prolog to devise  . a ~ J~ef'ulCAI system ?

We would like to thank Akira Kurematu , president of ATR Interpreting Telephony Research Laboratories  ( ATR ) and Mr . Yada , president of CSK Research Institute ( CRI ) for their constant encouragement . And we would also like to acknowledge the helpful comments of Hitoshi Iida  ( ATR )  . Many thanks also to Hideo Kobayashi ( Nishi-Sugamo Junior High School )  , Kenji Okamoto , Yoshio Ooyama , Kei Okabe and Syuuichi Tanaka ( CRI) . 

Carboneli , J . G . & I Iayes , P . J .   ( 1983 ) ' Recovery Strategies for Parsing Extragramnmtical Lnguage ' American Journal of Computatienal 
Linguistics , Volume 9, pp . 123-146.
/iayes , P . J&Mouradian , G . V .   ( 1981 ) ' Flexible Parsing ' American Journal of Computational Linguistics  ,  7(4) , pp . 232-242 . 
lteid or n , G . E .   ( 1982 ) ' Experience with an Easily Computed Metric for Ranking Alternative Parses ' Proceeding of  20tll Annual Meeting of the ACL . Totont , Canada , pp . 82-84 . 
lleid or n , G . E , , Jensen , K . , Miller , L . A . Byrd , R . J . and Codoro , M . S . 
( 1982 ' The EPISTLE Text-Critiquing System'IBM Systems 
Journal 21(3), pp . 305-326.
Jensen , K . , IIeidorn , G . E . , Miller , I , A . and Ravin , Y .   ( 1983 ) ' Parse Fitting and Prose Fixing : Getting a Hold on ill-formedness ' American Journal of Computational Linguistics  , Volume 9 , Number 34 , July-December , pp . 147-160 . 
Kaplan , R . M . & Bresnau , J .   ( 1982 ) ' Lexical-Functional Gramnmr : A Formal System for Grammatical Representation ' In : Bresnan  , d . 
( ed ) ' The Mcmtal Representation of Grammatical Relations '  , The MIT Press , Cambrige , Massachusetts , pp .  173-281 . 
Katie , 1 . & Nomura , H .   ( 1986 ) ' Lexica L functional Transfer : A Transfer Framework in a Machine Translation System Based on LFG '  , Proceeding of 11th International Conference on Computational Linguistics  , Bonn , August , pp . 112-114 . 
Kwasny , S . C . & Sondheimer , N . K .   ( 1981 ) ' Relaxation Techniques for Parsing Grammatically Ill-formed Input in Natural Language Understanding Systems ' Ammq can Journal of Computational Linguistics  , Vol . 7, Number 2, April-June , pp . 99-108 . 
Matmnoto , I . & Matumoto , Y .   ( 1976 ) ' A Practical II and book of Common Mistakes in English among Japanese Students and 
Business men ', l to k use i do
Schank , R . C . & Leboeitz , M . & Birnbaum , L .   ( 1980 ) ' An Integrated Understander ' American Journal of Cmn putational Linguistics  , Volume 6 , Number 1 , January-March , pp . 13-30 . 
Schuster , E . (1985 ) ' Grammar as user models ' Proceedings of the Nineth International Joint Conference on Artificial Intelligence  , August , 
Los Angeles , California , pp . 20-22
Weischedel , R . M . & Black , I . E .   ( 1980 ) ' Responding Intelligently to Unparsable Inputs ' American Journal of Computational Linguistics  , Volume 6 , Number 2 , pp . 97-109 . 
Weischedel , R . M . & Sondheimer , N . K .   ( 1982 ) ' Anhn proved Ileuristic for Ellipsis Processing ' Proceeding of  20th Annual Meeting of the
ACL . To ( on (, Canada , pp . 85-88.
Weischedel , R . M . &' Sondheimer , N . K .   ( 1987 ) ' Meta-rules as a Basic for Processing Ill-formed Input ' ln  ; R . G . Reilly ( ed . ) Cmn munieation Failure in Dialogue and Discourse , Elsevier Science Publishers
B.V . ( North-Holland ), pp . 99-120.

