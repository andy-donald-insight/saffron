Research on Architectures for Integrated Speech /Language 
Systems in Verbmobil
Gfinther GSrz ~ Marcus Kesseler , J SrgSpilker , Hans Weber
University of Erbmgen-Nfirnberg
IMMD ( Computer Science ) VIII - - - Artificial Inl 0 elligence
AmWeich selgarten9
D-91058 ERLAN(\]EN
Emaihgoerz , kesseler , spilker , weber O informatik . uni-erlangen , de

The German joint research project Verb mobil ( VM ) aims at the deveh ) pment of a speech to speech translation system . This paper reports on research done in our group which belongs to Verb-mobil's subprojeet on system architectures  ( TP 15 )  . Our specific research areas are the construction of parsers for spontaneouspeech  , investigations in the parallelization of parsing and to contribute to the development of a flexible communication architecture with distributed control  . 
1 Introduction
The German joint research project Verb mobil ( VM )   1 aims at the development of a speech to speech translation system  . This paper reports on research done in our group which belongs to V crbmobil's subproject on system architectures  ( TP 15 )  . The task of this subproject is to provide basic research results on incremental and interactive system architectures for the VM research prototype and to demonstrate their feasibility in the prototypical INTARC system  . Our specific research areas are the construction of parsers for spontaneous speech  , investigations in the parallelization of parsing and to contribute to the development of a flexible communication architecture with distributed control  . The paper is organized as follows : Section 2 reports on the design and implementation of an incremental interactive speech parser which integrate statistics i  1This work was flm ded by the German Federal Mirfistry for Researdl and Tedmology  ( BMFT ) in the framework of the Verbmobil Project under Grant BMFT  01 IV 101 H / 9  . The responsibility for the contents of this study lies with the authors  . 
with a chart parser e in ploying a unification grammar  ( UG ) formalism . Furthermore , results of experiments on the interaction between the parser and a speech recognizer using expectations  , are reported . In section 3 we present experiences with a parallel version of the parser  . Section 4 deals with distributed control in modular Natural Lan-guage/Speech  ( NLSP ) systems . 
2 Design and Implementation of
Incremental Interactive Speech

In a Left Right Incremental architecture ( LRI) , higher level modules can work in parallel with lower level modules  . The obvious benefits of such a narrangement are twofold : The system does not have to wait for a speaker to stop talking and topdown constraints from higher level to lower level modules can be used easily  . ' lb achieve LR ! behavior the singular modules must fulfil \] the following requirements : Processing proceeds incrementally along the time axis  ( " left to right " )  . 
Pieces of output have to be transferred to the next module as soon as possible  . 
So far in INTARC-1 . 3 we have achieved an LRI style coupling of ibur different modules : Word recognition module  , syntactic parser , semantic module and prosodic boundary module . Our word recognition module is a modified Viterbi decoder  , where two changes in the algorithm design were made : We use only the forward search pass  , and whenever a final ttMM state is reached for an active word model  , a corresponding word hypothesis is sent to the parser  . Itence backward search becomes a part of the parsing algorithm  . The LRI parsing algorithm is a modified active chart parser with an agendad riven control mechanism  . The chart vertices correspond to the . frames of the signal representation . Edges correspond to Word or phrase hypotheses , being partial in the case of ac-time point related to the utterance  , in every cycle a new vertex is created and new word hypotheses ending at that time point are read and inserted into the chart  . In one cycle , aba ( : kwar ( search is performed to the beginning of the utterance or to some designated time point in the past con~stitnting a starting point for grammatical analysis  . Search is guided by a weighted linear combination of acoustic score  , bigram score , prosody score , grammar derivation seore and grammatical parsability  . The search prodecure is a beam search implemented as an agend access mechanism  . The grammar is a probabilistic typed UG with separate rules for pauses and other spontanous speech phelnonmua  . 
2.1 Basic Objects
In the h ) llowing we use record notation to refer to subcoml ) on cnts of an object . A chart vertex Vt corresponds to frame number t . Vertices have four lists with pointers to edges ending in and starting in thai  ; vertex : in active-out , in active ~ in , active-out and active-out . A word hypothesis W is a quadruple ( from , to , key , score ) with Jvm and to being the start and end frames of W  . 
W . Key is the name of the lexical entry of W and W . score is the acoustic score of W for the frames spanned  , given by a corresponding HMM acoustic word model . An edge i ' , ' consists of flor a , the start vertex and to , a list of end vertices . Note that after a Viterbi forward pass identical word hypotheses do always come in sequence  , differing only in ending time . E . actual is the last vertex added to t ? to in an operation  . Those " families " of hypotheses are represented as one edge with a set of end vertices  . E . words keeps the covered string of word hypotheses while SCORE is a record keeping score components  . Besides that an edge consists of a gramma rule E . rule and F, . next , a pointer to some element of the right hand side of l ? rule or NIL  . As in standard active chart parsing an edge is passive  , if E . n c x t = n i l , otherwise it is active . E . eatpoints to the lefthand side of the grammar rule  . SCORE is a record with entries for inside and outside probabilities given to an edge by acoustic  , bigram , prosody and grammar model : Inside-X Model scores for the spanned portion of an edge  . 
Outside-X Optimistic estimates for the portion fi'om vertex  0 to the beginning of an edge . 
For every vertex we keep a bestfirst store of scored edge pairs  . We (: all that store Agenda/incyclei . 
2 . 2 Bas ic Operat ions ' I'here are tive basic operations to detine the operations of the parsing algorithm  . The two operations Combine and Seek Down are similar to the wellknown Earley algorithm operations Com-pleterarm Predictor  . Furthermore , there are two operations to insert new word hypotheses  , Insert and Inherit . All these operations can create new edges , so operations to calculate new scores from old ones are attached to them  . hiorder to implement our t ) eam search method appropriately buts in q ) ly , we define an operation Agenda-Pu~q ~ , which selects pairs of active and passive edges to be prmn  ; dor to be processed in the future . The Ct ( , notation for l ) asic operations are given in -' , '' simplicity . 
2.2.1 Combine
For at ) air of active and passive edges ( A , l ) , if A . next = I . cat and L fivm ~ A . to , insert edge ti with l ', ' . rule-A . rule , E . cat : -- A . eat , E . nexl--:shifl(A . uext ), l ? f l ~) m . -= A . fl'o,n , l ? to = A . to . 
For X = Bigram , Grammar and Prosody : t ? Outside-X = A . Outside-X+I . lnside-X+7'tans(X,A,1) l?lnsid c-X = A . lnside-X4-1 . 1nside-X4-7' rans(X,A,1)
I " or X = Acoustic:
E . Outside-X = A . Oulside-X\[l . from \]@ Llnsi & '- X " Frans(X , A , I ) l?1 nsid c-X = A . lnsid c-X\[1 . flvm\](t)LInside-X
Trans(X , A , l ) ' l ) he operator ct ) performs an addition o\[a nun > her to every element of a set  . Trans(X , A , l ) is the specilic transition penalty a model will give to two edges  . In the ctLse of acoustic scores , the penMty is always zero and can be neglected . In the . bigram c ~ use it will be the transition from the last word covered by A to the tirst word covered by B  . 
2.2.2 Seek Down
Whenever an active edge A is inserted , insert an edge E for every rule 1 ~ such that A . next-E . cat , I ', ' . rule = If , F, . f lvm-A . actual , t3 . to = A . actual ? For X---Acoustic , Prosody and l ) igraln :
E . lnside-X = 0
I ? Outside-X = A . Outside-X
For X == Grammar: 1? lnside-X = grammar score of IIl ? Outside-X = A . Outside-X+7~rans(X,A,l';)+I ~ . inside-X . This reeursive operation of introducing new active edges is precompiled in our parser and extremely etlicient  . 
485 2.2.3 Insert
For a new word hypothesis W = ( a , i , key , score ) such that noW ' = ( a , i-i , key , score ') exists , insert an edge E with E . rule = lex(key ), E . cat = lex(key ), E . from = Va , E . to = ~ and for X =

E . Inside-X = E . Outside-X = ( i , score ) , for X = Prosody and Bigram :
E . Inside-X = E . Outside-X = O , for X = Grammar E . Inside-X = E . Outside-X = grammar score of lex(keg) . 
2.2.4 Inherit
For a new word hypothesis W = ( a , i , key , score ) such that a W ' = ( a , i-l , key , score ') exists : For all E in Vi_l . in active-in or Vi_l . active-in:If last(E . words ) = key then add ~ toE . to , add ( i , E . Inside-Acoustic\[i-l\]-score '+ score ) toE . Inside-Acoustic and add ( i , E . Outside-Acoustic\[i-I\]-score '+ score ) toE . Outside-

If E is active , perform a Seek-Down on E in ~.
2.2.5 Agenda Push
Whenever an edge E is inserted into the chart , if E is active then for all passive A , such that A . from 6E . to and combined-seore(E , A ) > Beam-Value , insert(E , A , combined-score(E , A )) into the actual agenda . If E is passive then for all active A , such that E . f~vm 6A . to and combined-score(A , E ) > Beam-Value , insert(A , E , combined-score(A , E )) into the actual agenda . Combined-Score is a linear combination of the outside components of an edge C which would be created by A and E in a Combine operation  . Beam-Value is calculated as a fixed offset from the maximum Combined-Score on an agenda  . Since we process bestfirst inside the beam , the maximum is known when the first triple is inserted into an agenda  . Agenda-Pop will remove the best triple from an actual agenda and return it  . 
2 . 3 A s imple LR I la t t i ce parser The follwing controloop implements a simple LRI lattice parser  . 
1 . T = 0 . Create VT 2 . Insert initial active edge E into VT , with
E . next =  S3 . Increment T . Create VT 4 . For every W with W . end=7': Insert(W ) or
Inherit ( W ) 5 . Until Agenda\[T \] is empty: ( a ) Combine ( Agenda-Pop )   ( b ) When combination with initial edge is successful , send result to SEMANTICS 6 . Communicate with PROSODY and go to 32 . 4 The Grammar Model The UG used in our experiments consists of  700 lexical entries and 60 rules . We used a variant of insideoutside training to estimate a model of UG derivations  . It is a rule bigram model similar to PCFG with special extensions for UG type operations  . The probability of future unifications is made dependent from the result type of earlier unifications  . The model is described in more detail in ( Weber 1994a ; Weber 1995) ; it is very similar to ( Brew 1995) . 
2.5 LRI Coupling with Prosody
In INTARC we use three classes of boundaries , B0 ( no boundary ) , B2 ( phrase boundary ) , B3 ( sentence boundary ) and B9 ( real break ) . The prosody module , developed at the University of Bonn , classifies time intervals according to these classes  . A prosody hypothesis consists of a beginning and ending time and model probabilities for the boundary types which sum up to one  . A prosodic transition penalty used in the Combine operation was taken to be the score of the best combination of bottom-up boundary hypothesis Bx and a trigram score  ( lword , B x , rword ) . Herel word is the last word of the edge to the left and r word is the first word spanned by the edge to the right  . Prosody hypotheses are consumed by the parser in every cycle and represented as attributes of vertices which fall inside a prosodic time interval  . In a couple of tests we already achieved a reduction of edges of about  10% without change in recognition rate using a very simple trigram with only five word categories  . 
2.6 Experimental Results
In a system like INTARC-1 . 3 , the analysis tree is of much higher importance than the recovered string  ; for the goal of speech translation an adequate semantic representation for a string with word errors is more important hanagood string with a wrong reading  . The grammar scores have only indirect influence on the string  ; their main function is picking the right tree . We cannot measure something like a " tree recognition rate " or " rule accuracy "  , because there is no treebank for our grammar . The word accuracy results cannot be compared to word accuracy as usually applied to an acoustic decoder in isolation  . We counted only those words as recognized which could be utterance  . Words to the right which could not be integrated into a parse  , were counted as deletions - - - although they might have been correct in standard word accuracy terms  . This evaluation method is much harder than standard word accuracy  , but it appears to be a good approximation to " rule accuracy "  . Using this strict method we achieved a word accuracy of  47%  , which is quite promising . 
Results using topdown prediction of possible word hypotheses by the parser work inspired by  ( Kita et . al .  1989 ) have already been published in ( Hauenstein and Weber 1994a ; ltmlenstein and Weber 1994b ) , ( Weber 1994a ) , and ( Weber 1995) . 
Recognition rates had been improved there for read speech  . In spontaneous speech we could not achieve the same effects  . 
2.7 Current Work
Our current work , which led to INTARC-2 . 0 , uses a new approach for the interaction of syntax and semantics and a revision of the interaction of the parser with a new decoder  . For the last case we implemented a precompiler for word-based prediction which to our current experience is clearly superior to the previous word classbased prediction  . For the implementation of the interaction of syntax and semantics we proceed as follows : A new turn-based UG has been written  , for which a context-sensitive stochastic traiuing is being performed  . The resulting grammar is then stripped down to a pure type skeleton which is actually being used for syntactic parsing  . Using full structure sharing in the syntactic chart  , which contains only packed edges , we achieve a complexity of O(n3) . In contrast to that , for semantic analysis a second , unpacked chart is used , whose edges are provided by an unpacker module which is the interface between the two analysis levels  . 
The unpacker , which has exponential complexity , selects only the nbest scored packed edges , where n is a parameter . Only if semantic analysis fails it requests further edges from the unpacker  . In this way , the computational effort on the whole is kept as low as possible  . 
3 Parallel Parsing
One of our main research interests has been the exploration of performance gains in NLP through parallelization  . To this end , we developed a parallel version of the INTARC parser  . Although the results so far are yet not as encouraging as we expected  , our efforts make for interesting lessons in software engineering  . The parallel parser had to obey the tbllowing restrictions : Running on our local shared memory lnnltiprocessor  ( Sparc Serverl 0 0 0 ) with 6 processors , parallelization should be controlled by inserting  Solaris-2  . 4 thread and process control primitives directly into the code  . The only realistic choice we had was to translate our parser with Chest nut Inc  . ' sLisp-to-C-Translator automatically into C . Since the Lisp functions library is available in C source  , we could insert the necessary Solaris parallelisation and synchronization primitives into key positions of the involved fnnctions  . 
3.1 Parallelization Strategy and
Preliminary Results
For effective parallelization it is crucial to keep communication between processors to a minimum  . 
Early experiments with a fully distributed chart showed that the effort required to keep the partial charts consistent was much larger that the potential gains of increased parallelism  . The chart must be kept as a single data structure in a shared memory processor  , where concurrent reads are possible and only concurrent writes have to be serialized with synchronisation primitives  . An analysis of profiling data shows that even the heavily optimized UG formalism causes between  50% - and 70% of the compntational load in the serial c~e . 
Therefore we provide an arbitrary number of unification workers running in parallel which are fedunification tasks from the top of an agenda sorted by scores  . Due to the high optimization level of the sequential parser  , load-balancing is faMy poor . Namely , the very fast type check used to circumvent most unifications  , causes large disparities in the granularity of agenda tasks  . Furthermore , pathological examples have been found in which a single unification takes much longer than all other tasks combined  . 
I ~::~::"~-~'~14~- IM ? ,   ,  ?  ,   ,   ,   ,   ,   3 ttxl ~ 2  ~  tz3  ~  t4  ~  5   Sta6   $*1z7 Sstz $ ~ lz9 r , ~tlO Figure 1: PercentuMgains and losses over attained over 10 ditferent sentences ( Spilker 1995 ) 
Verbmobil
The question of control in VM is tightly knit with the architecture of the VM system  . As yet , the concept of architecture in VM has been used mostly to describe the overall modularization and the interfaces implied by the data flow between modules  . This socalled dornair ~ architecture is incomplete in the sense that it does not specify any interactio ~ strategics  . Within our research on interactive system architectures we developed a modular communication framework  , ICE ~ , in cooperation with the University of Hamburg . Now , ICE is the architectural framework of the VM research prototype  . 
4.1 The INTARC Architecture
The INTARC architecture as first presented by ( Pyka 1992 ) is a distributed software system that allows for tile in tcr conncction of NLSP modules under the principles of incrementality and interactivity  . Figure 2 shows the modularization of INTARC-1 . 3: There is a main broad channel connecting all modules in bottom-up direction  , i . e . , from signal to interpretation . Furthermore , there are smaller channels connecting several modules  , which are used for the topdown interactive disambiguation data flow  . In erementality is required for all modules . ICE assumes that each module has a local memory that is not directly accessible to other modules  . Modules communicate explicitly with one another via message sent over bidirectional channels  . This kind of communication architecture is hardly new and e onl ? on tsus directly with a large number of unresolved issues in distributed problem solving  , ef . ( Durfee et al 1989) . In the last 20 years there have been numerous architecture proposals for distributed problem solving among computing entities that exchange information explicitly via message passing  . 
None of these models include explicit strategies or paradigms to tackle the problem of distributed control  . 
4 . 2 Structural Constra ints of Verblnobi l Modularity  , being a fundamental assumption in VM ( Wahlster 1992 )  , does still leave us with two problems : First , modules have to communicate with one another , and second , their local behaviors have to be somehow coordinated into a coherent global  , possibly optimal , behavior . Unfortunately , the task of system integration has to obey some structural constraints which are mostly pragmatic in natnre :  2based on PVM ( parallel virtual madfine ) semRnb ~ represenl ~ ( mt
I .   .   .   .   .   .   .   .   .   .   .   .   .   .  / - . . ~-? a,fi~f ~ . ~, ,) ~ ho .   . 
~' ~ z,-Ol ~ mb ~ g ~ og on Det * lFIow(TopDo~n)
MoJtl Da ~ Flo * ( l-lot tom Ui))
Figure 2:' l ) he interactive , incremental INTARC-1 . 3 architecture Some of the modules are very complex software systems in thelnselves  . Highly parameterizable and with control subtly spread over many interacting submodules  , understanding and then integrating such systems into a common control strategy can be a very daunting task  . 
Control issues are often very tightly knit with the domain the module is aimed at  , i . e . , it is very difficult to understand the control strategies used without sound knowledge of the underlying domain  . The problem even gets worse if what is to be fine -tuned is the interaction between several complex modules  . 
These two arguments are similar in nature , but difl hr in the architecturM levels that they apply to  . 
' Fileformer is implementation related , the latter algorithm arid theory related . 
4.3 Layers of Control
Modules have to colnmunicate with one another and their local behaviors have to be coordinated into a coherent global  , possibly optimal , behavior . 
In highly distributed systems we generally tind the following levels of control : System Contro l : The minimal set of operating system related actions that each participating module must be able to per\[brm which will to t  , trace and terminate individual modules or the system as a whole  . 
Is ( ) lated Loca l Cont roh The control strategies used within the module  , disregarding any interactions beyond initial input of data and final output of solutions  . ' Fhere is only one thread of control active at any time  . 
lnteraetiv (; Local Controhll . oughly , this can be seen as isolated local control extended with interaction cal  ) al/ilities , lncr ~" mental it p is given by the l ) ossibility of control flowing back to a certain internals take aftex an outl  ) ut operation , llighermt craclivily is made possible by entering a state more often fl : omw ~ rious points within the rood-tile and by adding a new waiting lool/to cheek for any to t  ) -down requests . The requirement for any . 
time behavior is a special case of that ( G6rz and
Kesseler \]994).
in ore : experience ~ he change to interactive CO l > trol will tremendously increase the complexity of the resulting  ( : ode . But we ares will making the simplifying assumptions that tile algorithm can be used increnlentally-but there are algorithms m ~suitable for incremental processing  ( e . g . A *) . 
h ~ c rementality can lead to the ( \[ elrlalld for a eoln-i ) \] etere design of alnodule . Furthexmore we assume that simply by exchanging data and doing simple extensions in the control \ [ to we very thing will balan  ( : e outnicely on the system scale which is enorlnously naiv  ( : . Even for the sequential architecture implied by the case of isolated local control  , we have to solve a whole plethora of uew problems that corne along with interaetivity : * Mutual deadlock-Mutual live-lock-Race conditions  ( missing synchronization )   , , Over-synchronization D ia logue Cont roh In systems like VM there is a module that comes close to possessing the " inte--grated view " ot ' a centralized blackboard control : the dialogue module  . So it seems the right place to handle some of the global strategic control issues  , like :- l ) omain error trundling . Observe time on t constraints . ll , esolve , external ambiguitie . s/unl ( nowns The fact that tile dialogue module exercises a kind of global control does not invalidate what has bee  , n said about the unfeasability of central control  , be . .
cause the control exercised by it is very coar . ', egrained . To handle liner grained control issues in any roodule would take us back to memory and/or eomm  , mication system contention . 
References
Chris Brew . Stochastic t\]I'SG , l ) roccx , dings of l . he\]'hn'ol ) eanACI , Conference 1995 , b ; din/)urgh , 1995 l '; dn mnd 11 . I ) urfec , Victor I . I , cssev , and I ) an MI) . 
Corkill . Coop ~ rative l ) is tribut dProbh:mSoh . , ing , pages 83147 . Volume 4ot : Aw ' on Iarr et al(b ; d . ) . 
Thell . nd book of Arlifi ' ciullnt clli . qence leading,
Mass .: Addison-Wesley , 1989.
(', iit dher G6rz and Marcus I < esschw . Anytime ALgorithms for Speech Parsing ? Proceedings of  ( \] OIAN ( L94 , Kyoto , 19) 4 Andr casl lauensl , eiu and \[ laus Weber . An invesligaotion of tightly coupled time synchronous speech language in lcEfaccs us in  9 a unification grammar . In : l' . McKevitt ( Ed . ): Proceedings of tile Workshop on Integration of Natural Language and Speech Pro-  ( : esslng , AAAI-94 , Seat de ,  \[994 , 4249 Andrcasl Iauenstein and Hans Weber . An lnveatiga-lion of Tightly Coupled Time Synchronous Speech Language hder faces  . Proceedings of K()NVI'\]NS 94 , Vietma : Springer , September 19!)4 , 141150 Marcus Kcsseh ! r . l ) is tribvted Control in Vcrbmo-bil + Uniwwsil . y of Erlangen-Niit'nberg , IMMDV\[l1,
Verbmot ) ilel ) Ort 24, 1994.
Kit . a , K . , I < awabata , T . and Saito , \[I . HMM conliu-ous speech recognition usin9 predictive L 1~ parsiw I . 
IEEE IC , 4, S'SI~Proceedings , 1989, 703706.
(\] laudius\[)yka . Management of hypotheses in an iutc ~ . qralcd spccch-la ~* guage architecture . Proceedings of
EU Al-92, 1992, 55856036 vgSpilker . Parall clisic run 9 eines in krcmc . nlellcn , aklivcn(\]hart pars crs . Diplomathesis , Uniw ~ rsil ; y of F , r langen-N6 rnberg , l " r langen , December 1995 . 
Wolfgmlg Wahlstcr and Judithl '; ngelkamp , editors . 
Wissensch afllichc Ziele und Nctzpldncfilr das VERBM  0 BlL-Projekt . I ) FK1 , Sarbri M~en , \]992 . 
Ilans Weber . Time Synchronous Uhart Parsing of , 5'pccch lntcgratin 9 UniJication Grammars wilh Statistics . Speech aridl , anguage l ~\] ngineering , Proceedings of ; hel ' ; ighth Twente Workshop on Language Technology ,  (1 ,  . Bores , A . Nijholt , Ed . ),
Twentc , 1\[)94, 107-119 tlans Weber . I , R-inkrcmcnt clles probabili-stisches Chart parsing y on Worthypothcsenmeng cnmit Unifikations  . qrammatiken : Eineeng cK opplungy on Sucheun d Analyse  . Ph . l ) . Thesis , University of Hamburg ,  1995 , Verbmobil Report 52 . 

