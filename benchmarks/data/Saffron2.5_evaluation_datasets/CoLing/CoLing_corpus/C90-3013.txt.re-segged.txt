Efficient Disjunctive Unification
for Bottom-Up Parsing
David Carter
SRI International Cambridge Research Centre
23 Millers Yard , Mill Lane , Cambridge , CB2 1RQ , U . K . 
dmc@ai.sri.com , dmc@sri.co.uk

This paper describes two novel techniques which , when applied together , in practice significantly reduce the time required for unifying disjunctive feature structures  . The first is a safe but fast method for discarding irrelevant disjunctions from newly -created structures  . The second reduces the time required to check the consistency of a structure from exponential to polynomial in the number of disjunctions  , except in cases that , it will be argued , should be very unusual in practical systems . The techniques are implemented in an experimental Japanese analyser that uses a large  , existing disjunctive Japanese grammar and lexicon  . Observations of the time behaviour of this analyser sugges that a significant speed gain is achieved  . 
1 Introduction
This paper describes the approach taken to the unification of disjunctive feature structures in an experimental bottom-up shift-reduce Japanese aaalyser called Propane  , for Prolog Parser using the Nadine Grammar . Nadine ( Kogure , 1989; Kogure and Nagata ,  1990) , which is inlplemented in L is p , is the analysis and translation component of SLoTRANS  , the spoken language translation system under development at ATIt Interpreting Telephony Research Laboratories  , and its large (12 , 000 line ) grammar and lexicon make extensive use of disjunction  . 
The general problem of unifying two disjunctive feature structures is non-polynomial in the number of disjunctions  ( Kasper ,  1987) . That is , barring rev-olutionary developments in the theory of algorithms  , the problem is NP-complete , and the time taken to pertbrm such a unification can  , in general , at best be an exponentially increasing function of the number of disjunctions  , t lowever , in writing large grammars of natural anguages , it is often convenient to be able to specify constraints in terms of disjunctions  . This seems especially to be the case for Japanese  , because of its relatively free word order and widespread ellipsis  . It is therefore important o develop unification algorithms that can in practice unify disjunctive feature structures in a reasonable time  , despite the inherent NP-completeness of the task . 

Propane's unification method embodies two novel techniques  . Firstly , when a new mother constituent is created by the application of a grammar rule to daughter constituents during bottom-up arsing  , disjunctions not relevan to the mother can safely be removed  , tIowever , deciding on relevance in less tit an exponential time is a nontrivial problem  . 
Propane's techniqneis rapid , and resuh . s in the removal of enough irrelevant disjunctions that constituents higher in a parse tree are not burdened with inordinately many of them  . Secondly , Propane adopts a modification to Kasper's ( I987 ) disjunctive unification algorithm that " ah nost all the time "  ( in a sense of that phrase to be discussed )  , runs in binomial time . 
Practical results , which will be presented throughout this paper , suggest hat these techniques have the desired effect of allowing Propane to parse even quite long sentences in a reasonable time  . These results need , however , to be evaluated in the context of ATR's Japanese language processing research programme in general and of Propane's approach to parsing in particular  , which will therefore be presented in the next section as a preliminary to the main body of the paper  . 
2 Bot tom-up Pars ing o f Japanese ' Pile Nadine system is geared towards the processing of Japanese sentences of the type encountered in telephone conversations  . At ATR , a substantial corpus of dialogues has been collected by simulating  , both by speech and by keyboard , telephone calls to the organizing otfice of an international conference  . Attile time the research described here was carried out  , Nadine's grammar and lexicon were being developed and tested mainly on a subcorpus of  100 sentences comprising five of these dialogues . The results presented in this paper therefore all derive fl ' om applying Propane to this same sentence set  . Although the size of the set is comparatively small  , the sentences in it were not in any sense " made up " to suit either the Nadine or Propane parsers  . Rather , to the degree that a simulation can approach reality  , they can be taken as representatives of the kinds of sentences to be handled in a realistic language processing application  . 
Japanese has sever M characteristics which suggest that bottom-u parsing ~ approaehes might be partic -ular ~ lyfl ' uit flfl  . . The language is a head-finM , strongly left-branchirlg ~ one . . This means that modifiers ale ways attach to a head on  . theiright , and that there is a ~ prefet ~ ence for : attachment . to the nearest such head . that obe . ys : the constraints that syntax , seman ~ ticsaud : ~ pragmatics , place . . on possible combinations . 
"l?his , prefe~rence ~ is : so , trong , as to suggest a parsing alger : ithmLtrat ~ . ,firgt - e6nstructs analyses that : obey iG bacl ~ urac , king : and , pro&a:oing analyses with ~ different braeketfn~gs only  , if . the : initial ! analysis or analyses are iudgeld ~ un  , a ceep table , by , some . outside process . 
At gempt ; s . traX , eb ~ enmade , for example in Na-dine and \[ iy Shi~tzu . i ~ nd Naito (1989) ; to use the left-branching pref~rence to slect among alternative  aeti0ns  ; : in ~: c ~ art " parser . However , the approach adopte'd ' in Propane-is to implement the preference dire ' et ly ' into ' the tnedianish ~ Of a shift-reduce parser : In gener ~ l:  , a stiift x reduce parser uses a ~ able of pars d states and po~sibl ~  adti0iis tti at determine , at each St ' age , whether a shift or a reduction is appropriate , ? h'd'intile liit'tercase , what grammar rule ~ . , ' hoU\]d '% ~ eusd . IIo we Ver , When Japanese is formal-ized"6si'ng a ' grammar i ' n which every rule has ex-act l j , two right xhi in diside elements - ms is the case in Nadine grammar-the left-br~mching preference  corresp'6nds  ~  t0 as tl ' at ~ gy of reducing the top two categorfes i ot~tlie:st:ack~vhd heverth:ere is a grammar rule ~ thaf allows t  , liemt0b'e ~' reduced . and shifting only wti ; enthis cannot , b'ed one . Notable is the re-Ibre requiked ~ . Nadihe ' ~ gramma rules include syntactic , s 6 ~ anii C-afid ; piiiaglfiati ? information , so that Prop~i\]g'g:decisi'6n ~oredt/ce or not depends on the aecei~t'liSitf ' ty  '0fth:e ~' restflt ~ at : all three of these lin-guisttd'16Vo  . lg1"$/ ~ cti . ' a ' test ; fakes advantage of them a X tmfim-dmotmg Of ~ vM lable information  . and ap-plies'it ~ in ~ fai . rl2' straightforward ' and ' efficicnt way . 
A if ~ rni~t~v Clekic dlen ~ rf es ' for Words , and alternative gramma rules that'can apply to the same pair of  daiight6r categories , mean that each position on the p ~ , rse'r~s :' stack is in fact occupied no ~ by a single  eateg9i ' ~ bii ~ by a list of categories ( each of which , of eb firse , cbn ~ a if is a disjunctive structure that may have many realiZatiOns  ) : The lengths of these lists do not grow significantly as parsing progresses  , because just as the lexicon and the grammar can introduce al\[ernatives  , so the application of grammar rules c~t i i remove the rn/The attemp to reduce each of m ~ q ssible head ' daughters with each of n possible  n0ii-hea  , d ' augliterg typically results in far fewer than ' m  , :) f . md ~ het , structures , because not every rule appli ~ at \] bnsue coeds .   .   .   .   .   .   .   . 
O ~'c0mplicati0ti hatarises in parsing written Japanese ~ s that word born danes a  . renotmdmated explic ~\[ ly . " I ~ lnsfiaea ~ . ns that the lexicon imposes ala . ttice structure , not a simple sequence of tokens , on the input , so that , when as hffope ~: at mn~s needed the t ) o ~ ato ~ l ~ fft , f for ~ , ~ s , not necessarily well-defined Propane deals with this situation in the follow-iug ~ way  . When shifting , edges of all lengths are placed onto the stack , and are allowed to participate in any following sequence of reductions  . Before the next shift , however , Propane " prunes " the edges that constitute the top of the stack  , removing all but the longest . This corresponds to the assump ~ lion that there is a preference for longer strings of characters to correspond to lexical items where possible  , but that this preference should be overturned when a shorter string  , but not a longer one , allows a reduction with what precedes it . 
Alaa'ge proportion of the lO0-sentence subcorpus targeted by Nadine can be parsed correctly by this simple approach of always preferring reductions to shifts and longer edges to shorter ones  . Nevertheless , on . many occasions the correct parse will involve at least one violation of these pre\['erenees  . In general , some kind of intelligent backtracking and/or lookahead is required  . In Propane , only a limited form of \] ook ahead exists . Sometimes , an examination of the parts of speech ( i . e . category names only and not feature values ) in the grammar and those of the constituents in the stack and of t  . he item that would be consumed in a shift shows the following situation : a reduction is possible  , but if it is performed , the next shift cannot itself be followed by a reduction  , whereas if a shift is performed next , two reductions may be possible . That is , , there are two alternatives : reduce now and then be forced to shift twice  , or shift now and , unless unification failure prevents it , reduce twice . In such situations , Propane chooses the second option . This often allows sentences to be parsed which would not otherwise be  , and does not preven the parsing of any sentences in the subcorpus  . Because only category names , and not features , are examined , the lookahead procedure is very quick . 
With this small amount of lookahead included , Propane was able to parse 75 of the 100 sentences in the subcorpus . No attempt was made to check thoroughly the validity of these because of the present author's limited farniliarity with Japanese and the Nadine grarn mar  ; however , they were inspected informally , and none seemed to be obviously wrong . 
Of the 25 sentences for which no parse was found , ten involved an incorrect reduction . Eight of these might : have been prevented had information corresponding to Gunji's  ( 1988 ) treatment of " sentence levels " for modification been present in the grammar  . Twelve sentences failed through incorrectly favouring longer edges over shorter  ; all of these failures involved a lexical entry for the same particle sequence  , and could have been prevented either by altering the treatment of that sequence or by im-: plementing the same kind of lirnited lookahead for : the long-over-short preferel ~ eeas was clone for the = reduce-over-shift preference  . Of the other three failures , two were sentences on which the Nadine parser also failed  , suggesting that they were outside grammatical and /or lexical coverage  , and one remained unexplained . '\]' hus in summary , up to 98% of theyses : by Propane given the improvements just  , listed ,   3 ' Pruning Irrelevant Disjuncts If " bottom -uparsing is to beeffident  , it is impeltan ( ~li at disjunctions that are irrelevant to . a newly-:er ~ eat:'ed mother Coiisti~uent-~' that is ~ d~sj~nC tions wli~se values never affect the ' reaiizat ~ onsOf the ' con  ; s t : i : the fit , i . eltllese'toftin'mSi ~ i its disjunctive ' norm ~i ' form  2_ are : disC ~ ded Whene Verpossib . lel Otherwise , the number of disjunCt'i0ns in a constihlent will be roug , hly . proportional t'6 the mumber '~ f'\[e~ical:'enries and lgraln mar : rules used  , to construct , it ~ l and : t tie . time ta . l~en , to unify two constituents ~ wil , 1 , ncrease at " l~astas;:fasVas ' that number J and , probably ra~her daster . 
However , : i't is , nov possibtesi ~ mply ' to-dlscard , disjunctive ' constraints t , t  ~ at refer , 0 nty ' ~ ot ; he daugtrter nod ' ~ s , ,' because feature , struct ~ ures are , grap'hs , not'tree's ~ ~ he . sa ~ mesubstructure ' frequen-tty appears ~ ; in more ~ ~ , h , a . noue place i When a grammar ole ' haside : n ~ if l ~ d : par:t of  , the , motl ~ erst , ~ c'ture ~ with::p ' arg of a-d~ugh'tie ~ one ; ~ he'n , any disjune ~ ions ~ i ~ iV ~ lving ~ the la . t,~m,~m~tst *, be preserved . Some : means mus ~ ~ therefore be ~ ou . nd , of . k ~ eping track of wll at pieces ' of struc-tu , re'ateMm~ed ? or in ~ other ' wovd~s ; w . hat pai . fs of ! fea-tm~e , pat ~ hs , lead to the ~ same V ~ kues . I~f q h d s . qs ; done ; ~ a:di~jn,~6tion that: . enpt:icitly qn:vOlve ~ ; Only daug : h ~ er constituents , ~ cau , , safely be di~carde'd :: if . . no feature ' path , tJ hmugh , 'the ~ mother ? l~ads , : to ~ i , t ~ oe't'o ~ , any : o ' fits , ~ coinponents . 
:' O ~ course ; t ' he set of featu . repaths , t'hat's'la:are'avalise will'di~fferfo . vt ~ he different reM~z ~ tions ~ Com-ple ~ ice ~ ' of disjut ~ e~s  ) of a ' disjtlneti Ve'sti ~ ueture . 
It ~ is ) not even simpty ' the Casettra ~ eacI\]disjun : Ctco~atvibut'es ~: its own:s'et'  . of ', cm ~ iirtion p ' t ~ ths ; na embe ~ s of : ~ . wc ~, differ ~ nt ,, ~ i ; sj : une ~ ionsva ~ ii , ehu . ~et ~ V6; p'a : ~ hs'~'6h~y~t~t ~,% ~ a ~ . ~ eya:\[naiir ~ axe~li ~ , at i 0 niw , hichitt)eyar ~ b , qt , t ~ lec . t~d . if ' Mmypl , a ~ e the ( same vgF ~ i , ~ bl , ein , t . go different , positions Thus . to de ~ ideinNltibty w!!~ti ~ qr'a , gi , vead ; is j , ~ metshg , ~tldi , qr , shg~tgng ~ . b , , elgliifi , ca $ . de~l , one would need to ~ y . < l~it . hr . ot~t ~ ? yery : ~ pg~tsi , blg ~ . ~'e~Jiz~ . t . i ~ nQf the whole str , u , c ~; , ur ~, l ~' o ~ . gss , tS ~, t/is , eN ? . o ~ mi ~ ti ~ ig ! hen I ~ mher of . disj ~ wta , ~ nd , tb , er , . ~ rfoi'e~pl:a?c~pt ~, bl ? This rute %~ ut, . ~9 ~ I ~ p ~ r p . ~gesia ~ eptt ? e , ~gn , t~ , tionSi ! ~ l ~' , : to t , ha , t  ~ , 0f , E is ~ le!~a ~) GD brre:p ~ , @: io ~: ; tp -! g ~ , ~ i , cl  ~ . ~t , ! : a ~ . ?: ire . f<r . .c m ~:,#\] ~ o , , t ~, g ,~ ff . ~? gq4rb . ,y . 
elglhe , t,~l~t , emg , t,iy ~ . ,aflo , Btefl , ,i , n ~ Pl ' ~ t ? & g ~ , aft ; qn ? , ~ h~t , , somethnes , keep ;; ~ di~j , u~ct , 4 ~ l ~ ~ b , a ald , ,ba ~ hl~w ~! to , gj , v , ~ io , qo . r~ect,~!e,s~ . ! ~ , bu ~ me , . . ' el . ~ ~ toer ~ u : mber . th ? ~ , I , Each , disjunctive , stmct , ure , ~ie ~ mn~-A < hy~a ; lexieon ~723 or grammar predicate , therefore , is assigned a set of " path groups !! , which each correspond either to a variable that :   . appears more than once in the original Nadine definition  , or to an explicit identity equation between two : or more positions in the feature structure : To some  , extent , , a path group is analogous to a set . of Eisele , and : ' rD . 5 r repointers that all , p , oint to : the , , same position . . However , the cru-cial,,poil ~, is , . tha ~, i ; n . Bropane, . ,no:record is kept of w , hieh , position : i ~ n , ,the and/or , tree each path comes from . This a neans ,, two things . .  , Firstly when deciding whether ; ~ to 4hro , ~caway , disju . n ~ tior ~ referring ~ oa particular ~ gosition Sn-a : daugil ~ er  , stucture , Propane can check the , ( m4ique , , disjunctiondndependent ) se of patti , group , s ,   . and ffn , 0, p , ossib ! e equivalence with pant of . themo ~ , ~mr , z  ~ r , u?tu ~? is found , the:disjunction c~nsafei ~ be pruned . The . p ~' ice we pay for this disju , nctifm , i ~ gtep9 ~ n dence is th ~ , t . the path groups can sp ~ ecify~sp , uriQu ~ . ~, ~ va\[?nees . It is possible for two p~hs . t9 be~so~ia ~ tedwher * . ; th~y , arise from two ~ dif , ferent , ,  inc0mpatible di ~ jull cJ~s or to remain as so ? i-a~ed after the d\ [sjuncts  )  . from which they arose have been eliminated through later unific at mn  . I to weve Lsn ) ce path groups ~ are used only for demdmg wtmt digjunctons " to d ~  ; eard , and not as part of the fea~-??% ,  ; ( ~ :  ,   . 
ture structure representation itself a spurious path group c ~ a  . nonly result in some inefficiency and not in an irt co't '  , ct . result . 
This tec~n'i que is . thus a compromise between on the pge : ! ~ nd , i ? ~ r , -y , jagoBt . ,possibly exhaustive com-pg;~i~;u t~p , ,ach~ey a perfect , result , , and on the oth , e . rh and , not ~!5 . e ~ r ~ ingar ~ y : thiag . ~ tall . It avoids any expone ~)!) i ~): Sx . p , ~ , nsi~n:0 f , disjunctions at the cost , of so , mesli . gb , ! . t t ! ~ , ~) eee , ss , a ~? proge ~ sir ~ gata later sta ~ . 
I ~ prg . ct , ic %' t'~;'cot invoive , q t s e e n ~ , quite accept a ~ , in , t  ~ aatth ~1 . 1, ~ m3'~r,qfdi~juac~s in . , ~ constituent dQ~s no , ~ iqcre~s . c~,~ . ~! yithi ~ heigt ~ t in the . parse . tre ~, : ~ M ~ q ~ her , < ~ ? p ~ fl ~ le , nc . , of . keeping . irrelevant dis,-jt!~,CSSS~,t,l~i ~: if ~ . t ; t , bgend , of the parse , the set . of all full re ~\] iz ~ tions of a disjunctive . feature structure . is exhaust wely epume ~ ated then , tl ~ e same realization t t , ~ G(:; ,  '  ,  '  , '; ( ) l':'~?':~' , may ' be . encotlntered ' . repeatedly However , experbenne suggests that for t ! ~ e current Nadine gra~mnarlit  ) l ~' ,   , ~ ' !~ ! . lI ) . F , !) ' ~ , . "';, ahz at mns (~ enihcal or . d~fferertt ) per parse of ' the 75 senten , c , essu?cess\[ully . parsed was exactly two , and , on ! yone sentence received more than six real-i . z  ~ i di is .   .   .   . " hel?runinzot ~ e , ~ tionifact resulted in , on av-e~e ~ , ~0 , ~ decre~e ~) a the , numbe ~ of & sjunctions t . ')' g ~")")) II~):l'~03 , I(!fl , : i  ~ ,  ~  , ": in . a new \] yi created tnother const it , uent , overall " re- . I " ~ O\[ . l ~ IC*I\[')Gli"t' . , . '' f " ~ . '" dace " . , operations t)erfgrmed in processing ~ he cor-"U ;  ' ?  , e ?) l " LAIUI ~; dI?fU , '; ~" VU '"':'"'? . "" pusProbal ~ lvfort,j . gS reaso $ ~ the number of disjunc-f ) \[\[ l't ~'\[" ) " f  ~ )   . (Yt\[f)t~itf ;)" , V""~"~""':' . " tmnsfn a new mother constituent . only barely show . sa positive cQr relation to the size , in constituents , of t!msu ) it r~-~l~a ~' ~ t domg ~ ates ~ nd from which t t has ~\]   )  "  ) ~\] G ~ ) \] I . ~ttJOfl ~ .  ' ;~ '1 '  . I ; ~'*' b "' Dee D-off \] it . ton the other nano , \] i pruning were not ~' he correlation between subtree ~ ize and number of dis-jUnctmns  , for d~e406 tree nodes crea , ted , w , % sonly just , slg- , ? ~ q t ? ,   ,  :  ,   ,   ,   ,   .  ?  .  "  . " n\]ti ~ e ~ fl ~ , ) ? t , t ~ ff 6"'5% ' lex , el : ' g f gell ' the , mlll hypothems that the pertbrmed , each constituent e ott ld be expected to add its quota of irrelevant disjm~cts to ~ very ottmr constituent that dominated it  . l ) espite the relatively modest figure of a 20% decrease over one reduction , the cumulativ effect of such decreases over a whole parse is the retbre quite significant  . 
In particular , it is worth noting that if ' , through pruning , the number of disjunctions in a node does not increase with the number of nodes it dominates  ,   ; hend is junctive unification will have no ef\['ect on the time complexity of parsing as a flmction of sentence length  . There is reason to hope that this will often be the case  ; while disjunction may be widespread in grammar ules and texical entries  , Kasper ( 1987 ) observes that in his implementation , " in the analysis of a particular sentence most fieatures have a unique value  , and some features are not present at , all . \ Vhen disjunction remains in the description of a sentence after parsing  , it usually represents ambiguity or an underspecified part of the grammar  . " it is tempting to interpolate between the extremes of single words and whole sentences and to speculate that  , with thorough pruning , the number of disjunctions in a node should decrease with its height in the tree  . 
4 Pairwise Consistency Checking
When a new mother constituent has been creal , ed by rule application , it is essential to verify that it . 
does in fact have at least on ~ cousistent realization  . 
Although redundancy is not a major problenl for ouri  ) urposes , a representation that did not di:-stinguish bet . ween realizable and ~ , n realizable struc * ures ( that 5:< between success and failure i ~ lunification ) would eseriously flawed . I lowever . consistency checking is , in the general case : an N\['-complete problem . 
Kasper (1987) describes a teel mique which , l brevery set of ' , ~ conjoined disjt , p . ctions , checks the: , con-: ; ~stcncy first of single disjuncls against the delinite part of the description  . : h < , ixhat of pairs , and so on u I0 to ~> tuples for full cca ~ sistency . At each stage l , : , m~y disjunct that does not take part in any consis-t  . ent/c'-tuple is eliminated .   2 If all the disjuncts in a disjunction are elhninated  , the conjunction of which I : l ~ at disjm~ction is a conjunclise liminated too  ; and if theooterlYlOStc . onjm~ct . ion of the whole foatur c . ~;tructure is , qiminat . c-d,unifica . tiorl fails . This tech-l~ique has the adwm tage that the pruning of nodes a ~ stage/e will make stage/c ' +   1 more eflicie Jqt . Nevertheless , since n can sometimes be quite large , this exhaustive process be time ~ consunfiug , and indeed in the limit will take exponential time  . 
Propane's attempted solution to this problem is based on the hypothesis that the vast majority of large unrealiza  . t ~ ledi@mctive feature struct . ures that i : ~ mnber of disjunctions is independ cnlo\["subCreesize  . 
2Smnew ha . t confusingly , l ( aspee uses the term " n-wise con-sb~tency " for I . heched ? ing of ' nq--l-luples of ( t is . it mcts . \ Veavoid , his usage . 
will be created in the use of a practical natllt : a lan-guage grann nar will be no to ~ tly unr ca  . lizable , \]) ut also " pairwise ~ m realizable " , in the sense that they will Nilator betb , ' e the second stage of l ( as per's consistency check , for k = 2 . 
There a sotlwe can expect most unrealizable structures also to be pairwise unrealizable is that most comnrely  , unrealizability will result from the contents of two nodes in the tree being incompatible  , through assigning non-unifiable vah~es to the same positiol ~ in a feature structure  . Although the recanclearly be exceptions , the hypothesis is that it is fairly unlikely , in a large disjunctive structure ( which is the case where exponen . iality would be harmful ) that there would be a non-pairwise inconsistency but no pairwise inconsistency  . 
Following this hypothesis , when the Propaneuni-tier has created a structure  , it checks a ~ d prunes it first for pairwise consistency  , and if this succeeds , risks trying for a single full realization ( one choice at each disjunct ) straight away . Thus it differs from Kasper's algorithm in two ways : no exhaustive leowise checks are made for k >  2  . and when a fl fll check is made , only one success is required , avoiding an exhaustive search through all combinations of disjuncts  , a Of course , if the structure is pairwise realizable but not flflly realizable  , the search for a single success will take exponential time  ; but . , accord-lug to the hypothesis , such occurrences , for struc-ture . s with enough disjuncts for exponential time cobe unacceptably long  , should be extremely rare . 
The effectiveness of this strategy can only be judged by ' observing its behaviour in practice  . In fact ,   7~o instances were observed of the search for a flfll realiza bition taking an inordinately long time ar -Iel'pairwise consistency checking and pruning have succeeded  . Thus it can be tentatively concluded that , wilh the current version of the Nadine grammar and with bottom-up parsing  , the risk is worth taking : that is , a full realization is virtually always possible , in reasonable ~ irne , tbrapairwise consistent structure . Maxwell and Kaplan's (1989) belief that % . . \[ simple inconsistencies \] become less predominant as grarn mars are extended to cover more and more linguistic phenomena " does not therefore al ? ear to  ) be true of the Nadine grammar , in spite of its coverage of a wide range of phenomenat many linguisr  , ie levels ; or if it is true , it . does not affect the success of Propar ~ e's strategy '  . That is . even if simple in eGns is tencies artless predominant  , they are still common enough that a large structure that is unre-alizable because of complex in consistencies will also  3According to M\[axwell and Kaplan ( 1989 )  , " in practice , K as pernoted that .   .   . once bad singleton disjuncts have been el iminated  , il is more efficient to switch to DNF\[ disjunctive normal form \]  ( hart to compnieat\[oftim higher degrees of consistency  . " This variation of the algorithm given in Kasper  ( 1987 ) is closer t . o Propane's strategy , b~H . the expansion i of ull \[) N\[," is it . self in general an exponeatia \] pt ' ocess and will . 
when many disjunctions remain , l . ,e far more expensive Ihan looking for a single realizatiol a  . 

Of course , this does not alter the fact that in general , i . e . for an arbitrary input and for an arbitrary grammar written in the Nadine formalism  , Propane's unification algorithm , like Kasper's , is exponential in behaviour . In the limit , an exponential term in the formula for the time behaviour of an algorithm will dominate  , however small its associated constant factor . 
Unlike Nadine's unifier , Propane's strategy has the property that when a structure survives consistency checking  , not every member of every disjunct in it can necessarily participate in a full realization  ; that is , ideally , it should have been pruned . However , this property is only undesirable to the extent that  , at the end of the parse , ii . makes any exhaustive search for flfll realizations in efficient hrough excessive backtracking  . Again , in practice , this seems not to be a problem ; exhaustive full realizat ~ ion is extremely quick compared to parsing  . 
An analysis of Propane's processing of its corpus reveals quite wide variation in the relationship between the total number of disjunctions in a rule application  ( in both daughters and the rule ) and the time taken to perform the unification . However , although , unsurprisingly , unification time increases with the number of ( is junctions , it . appears from inspection to be perhaps linear with a small binomiM component  , and not exponential . This is , in fact , what an analysis of the algorithm predicts . 
The linear component derives from the check of each disjunct sep a  . rately against the definite part . , while the parabolic component derives from the pairwise check  . The relatively small size of the latter may imply t  . hat a majority of disjuncts are eliminated during the first phase  , so the second has less work to do . 
5 Unification and Parsing Times The al . ~sence of any known exponential process ( other than the final phase of unification , which appears never to take very long ) in Propane's parsing and unification algorithms gives grounds for expecting that in practice  , the time taken to parse a . sen-teuce of 7~ lexical items should be polynomial in n . 
Because of the pruning of irrelevant disjuhctions , the value of n should be fairly small , leading to a significant speed advantage over systems like the Nadine parser that do not  , pruned is junctions and that use the full ( exponential ) version of Kasper's algorithm . 
The results of a comparison between Nadine's and Propane's parsing times sugges that such an advantage does exist  . However , the results are not sufl'i-ciently detailed to allow the verification of Propane's exact time behaviour  . 
Assen Cence lengt . hgrows , Propane . tends to perform progressively faster in a stntistically significant way  . 4In particular , Nadiue's attempts to parse two't I " or each of ( : lie 31 sell . i , ences containing more than one fairly long sentences  ( 12 and 18 lexical items respectively ) in the corpus had to be aborted because of the time they took  , but both these sentences received a parse from Propane intento  (  ; hirteeuminutes . Had Nadine not been aborted in these cases , two more data points would be available that would increase the significance further  . 
The progressive speed advantage of Propane may be dug partly to the fact that  , a . s discussed above , it ; follows only the single sequence of shifts and reductions specified by the algorithm described in section  2  , and does not explore alternative bracketings . 
I Iowever , Nadine is also , through numericals coting , sensitive to the left branching preference , which guides it to explore , and presumably to find , preferred parses first ; and the Nadine times used in 1he comparison were those taken to find the first parse  , not all parses . 
Another difference between the two parsers is thai Nadine  , being chart-based , stores the edges it creates so that later backtracking need not cause work to be rel  ) eated . Propane does not backtrack in this way . However , because o\["amundane practical im-itation in the Prolog implementation used  , Propane is also forced to store ( assert in the database ) every constituent it . creates , advancing the . parse by successive storing , lhiling and backtracking rather than by the simple recursion that would otherwise be performed  . The time taken to store constituents in fact increases faster than that used by or  . her aspects of processing , and :\[' or the longest sentences parsed represents  70 to 80 percent of the total time . It might be , there for < tha . t if storage time were ignored for both pars v , > , Propane'speed advantage would be eveI1 more apparent . 
Such vague remarks are admittedly unsatis ~ qng and should  , given time , befirmed up by the acquisition and analysis of more data  . , and by separate evaluations of the parsing and unification time behaviours  . The latter would im~olve comparing the two pa . rsers framing with the same unifier and then the two unifier srmming under the same parsing algorithm  . Nevertheless , there are , as already mentioned , a priori grounds for ex-pect . ing Propane's uni-tier to have an increasingly marked advantage  , and the data presented here are fully consistent with that expectation  , showing as they do a statistically significant trend  . 
A formal complexity analysis of a botton > up parser using the techniques described in this paper would only be of limited interest  . Complexity analyses deal with worst cases , and in those terms , the essential hypothesis that pairwise consistency checking will ': ahnost all the time " besu Ncient is meaningless  . Likewise , to claim that disjmlction pruning lexicM item and succes ~ f  , dly parsed t35' both systems , the correlation was mea . suredbt ~ tween then mnber of lexie M items in the seatence and tile \] ogarithm of the ratio of parsing times  . It was easily statistically sigl fificant at the  5% level , and its sign indicated that the correlation is in the direction of Propane performing bett  . er for longer sentences . 
5 tree nodes in the case of Propane and the Nadine grammar  , is to say nothing about its effectiveness in the worst ease  . One could easily write a grammar in which every disjunction fi'om daughter nodes was needed by mothers  , so that nothing would be pruned at all . And thirdly , it is not claimed that the left-branching preference in a Npanese is anything more than a preference  , albeit quite a strong one . 
However , because the grammar , lexicon and sentence set dealt with here are in no sense to yones written to test unification techniques but are the tools of a major effort to process natural language us it ~ actually used  , it is of interest to analyse Propane's overall time behaviour under the assumption that the relationships inferred a  . bove through observation and statistical rnethods are valid  ) There seems to be no a priori reason to doubt that the same behaviour could be achieved by ' other system  , ~ or . for other languages ( except , of course , that the left-branching characteristic is language-dependent  )  . 
Thus in Propane , the number of unifications attempted ( luring the successful parsing of a sentence of length N is O  ( N )   ( this happy situation is , of course , bought at the price of failure when the preference heuristics fail  )  . Let us a . ssnme a strongly left-branching structure , which , being maximally unbalanced , is the worst case . Then the number k of nodes dominated by each new mother node the parser  ( attempts to ) create will be uniformly distributed between 0 and N . From observation , it seems that the number of disjunctions d involved in a unification that  . dominates knodes will be proportional to k ( This is the pessimistic option ; as argued earlier , there are grounds for hoping that , with suNeient pruning , d will not increase with k at all , so that disjunctive unification time will made no contribution to parsing time as a flmction of N  )  . Unification time for d disjunctions , under the pairwise consistency hypothesis , appears to be proportional to d2 . 
Compositional semantic interpretation will probably mean in the limit that the size of the non-disjunctive part of a constituent will also be proportional to the number of constituents dominated  . Unification time here is order nlo , qn in the sizes n of the input structures ( Kasper ,  1987) . Thus a node dominating k others will take order kalogk time to create  . Summing over kfi'om0 to N gives an order N41 o . qN result . More generally , a parsing algorithm that on atomic categories h~s order f  ( N ) should , with disjunction , have order f ( N ) N 21ogN if the distribution of k over nodes created is also uniform  . 
In conclusion , the assessnrents of the various aspects of Propane's time behaviour are all consistent with  , and in some eases provide good evidence for , 5 Statistic M correlation tests , of course , cannot tell us what relationship , e . g . linear or exponential , holds between two variables ; they can only tell us that soree relationship appears to exist  . ~ J ' he time an Mysis can therefore only be tentative  . 
the claim that the two novel techniques described here can signifieantly enhance the speed with which sentences can be parsed using a large grammar containing disjunctions  . As long us the essential hypothesis about pairwise consistency holds \[ br the particular grammar and the sentences it will in practice encounter  , polynomial time behaviour can bcexpected , as compared to an exponential time for other approaches involving disjunctive unification  . 

This research was carried out while I was a visiting researcher at A'FR Interpreting Telephony Hesearchl  , aboratories , Kyoto , Japan . I am grateful t . oDr Akira Knrematsu , Mr Kiyoshi Kogure and others at ATR for thought -provoking discussions and tbr providing a very pleasant research environment  . 

Eisele , A . , and D Srre , J . (1988) " Unification of l ) i:- , -junctive Feature Descriptions " , Proceed ~ w/soft/~e26th Annual Meeling of the As . ~ociatio ~ for Com-pulalional Lin . guistics . 
Gunji , T . (1989) " Synta . cticSketch 88: Japanese " . 
In : Syntax : an International I and book of ( ' or ~ tt : 7~- porary Research , de Gruyter . 
Kasper , R .   ( \]987 ) '% Unification Method for Disjunctive Feature Desc : riptions '  , Pr ' oce eding so / the 2515 Annual Meeting of the Associalio T ~ for Computational Linguistics  . 
Kogure , K .   ( 1989 ) " Parsing Japanese Spoken Sentences based on HPSG  "  , Proceedings of lhc : International Workshop on Parsing9 Technologies , Carnegie
Mellon University , 132-\]41.
Kogure , K . , and Nagata , M .  (1 . 990) " Parsing Spol . > n Japanese Sentences Bused on I-IPSG " , Procccdin ( . s . o /
C'oling-90.
Maxwell , J . T . , and Kaplan , R .   ( 1989 ) " An Overview of Disjunctive Constraint Satisfaction "  , Proccedi~gsoflhc International Workshop on Par ~ sing Tc  . ch ~ zolo-ales , Carnegie Mellon University , 18-27 . 
Shimazu , A . , and Naito , S .   ( 1989 ) " t'refi ~ rence Rad-ing Models of Japanese Sentences "  , Gengo Shortlo Communication Kenky?ikai , 89:114 ( in Japanese) . 

