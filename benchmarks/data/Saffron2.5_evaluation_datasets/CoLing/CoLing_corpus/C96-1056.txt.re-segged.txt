GRICE IN CORPORATED
Cooperativity in Spoken Dialogue
Laila Dybkj~er , Niels Ole Bernsen and Hans Dybkj~er
Centre for Cognitive Science , Roskilde University
PO Box 260, DK-4000 Roskilde , Denmark
emails : laila@cog . ruc . dk , nob@cog . ruc . dk , dybkjaer@cog . ruc . dk
phone : +45467577 l1fax:+4546754502

The paper presents a consolidated set of princip -lesof cooperative spoken human machine dialogue which have the potential tor being turned into practically applicable design guidelines  . The principles have been validated in three ways . 
They were established fi'oma Wizard of Oz simulation corpus used to develop the dialogue model for a spoken language dialogue system  . 
Developed independently of Gricean theory , some of the principles were refined through comparison with Grice's maxims of cooperativity in conversation  . Finally , the principles were tested in the user test of the implemented dialogue system  . The paper shows that Grice's maxims constitute a subset of the principles  . The non-Gricean principles and dialogue aspects they introduce ampresented and discussed  . 
1 Introduction
In the last four years , we have designed and implemented the dialogue component of a spoken language dialogue system  ( SLDS ) prototype in the domain of flight ticket reservation  . The aim has been to develop a realistic , application-oriented prototype whose dialogue management allows users to perform their reservation task in spontaneous and natural spoken language  . Being well-structured , the ticket reservation task generally lends itself to system-directed dialogue in which the user answers questions posed by the system  . The only user initiative our system permits is that users may initiate clarification and repair metacommunication through uttering the keywords ' repeat ' and ' change '  . In designing such a system , it is crucial to reduce the number of situations in which users are inclined to take other forms of dialogue initiative  , such as asking questions when they do not understand the system's dialogue behaviour or providing information which the system did not ask for  ( Schegloff et al 1977 )  . This is why the issue of dialogue cooperativity came to play a central role in our design of the dialogue structure  . We needed to opti-mist system dialogue cooperativity in order to prevent situation such as those described above  . To this end , we developed a set of general principles to be observed in the design of cooperative  , spoken human machine dialogue . The principles have been validated in three ways . Firstly , they were developed on the basis of a simulated human-nmchine dialogue corpus collecte during dialogue model design  . Secondly , we compared the principles with Grice's maxims of cooperative human-human dialogue  . Thirdly , the principles were tested against he dialogue corpus fi ' om the user test of the implemented system  . 
This paper analyses the relationship between our principles and Grice's maxims  . We first describe how the principles were developed  ( Section 2 )  . We then justify the comparison between principles and max-ires  ( Section 3 )  . Section 4 compares principles and maxims . Section 5 briefly describes how the principles were tested the on user test dialogue corpus  , and
Section 6 concludes the paper.
2 Developing and Testing Principles of
Cooperative Human-Machine Dialogue
The dialogue model for otu " flight reservation system was developed by the Wizard of Oz  ( WOZ ) experimental prototyping method in which a person simulates the system to be designed  ( Fraser and Gilbert 1991 )  . Development was iterated until the dialogue model satisfied the design constraints on  , i . a :, average user utterance length . The dialogues were recorded , transcribed , analysed and used as a basis for ina-provements oil the dialogue model  . We perlormed seven WOZ iterations yielding a transcribed corpus of  125 task-oriented human machine dialogues corresponding to approximately seven hours of spoken dialogue  . The 94 dialogues that were recordeduring the last two WOZ iterations were performed by external subjects whereas only system designers and colleagues had participated in the earlier iterations  . A total of 24 different subjects were involved in the seven iterations  . Dialogues were based on written descriptions of reservation tasks  ( scenarios )  . 
A major concern during WOZ was to detect problems of user-system interaction  . We eventually used the following two approaches to systematically discover such problems :  (   ) prior to each WOZ iteration we matched the scenarios to be used agains the current dialogue model  . The model was represented as a graph structure with system phrases in the nodes and expected contents of user answers along the edges  . If a deviation from the graph occurred during the matching process  , this would indicate a potential dia-possible .   ( ii ) The recorded dialogues were plotted onto the graph representing the dialogue model  . As in ( i ) , graph deviations indicated potential dialogue design problems  . Deviations were marked and their causes analysed where upon the dialogue model was revised  , if necessary . 
At the end of the WOZ design phase , we began all lOl'e theoretical , forward-looking exercise . All the problen is of inleractioii uncovered dr ! ring WOZ wore analysed and represented as violations of principles of cooperative dialogue  . Each problem was considered a case in which the system  , in addressing the user , ii adviolated a principle of cooperative dialogue  . The principles of cooperative dialogue were made explicit  , based on the problems analysis . The WOZ corpus analysis led to the identification of  14 principle sel : cooperative hun3an-machine dialogue ( Section 4 ) based on analysis o1'   120 examples o1: user-systeill interaction problems .   \[1: the principles were observed in the design of the system's dialogue behaviour  , we assunled , this would serve to reduce the occurrence of user diah  ) gue behaviour that lhesy siem had not been designed to handle  . 
3 Maxims and Principles of Cooperative

We had developed our principles of cooperative hu -nlan-nmchine dialogue in del  ) endently o1"Griceanco- , operativity theory ( Bernsen et al , 1996a ) . \]) rior to the user test ( Section 5) , we coln i ) ared the principles with ( h'ice's Cooperative Principle and maxims . In lhisprocess Iheprinciples achieved their current lorn las shown in Table  1  . Their original expression is presented in Section  4  . Grice's Cooperative Principle ( CP ) is a general principle which says thai , to act cooperatively in conversation , oilc should make one's " conversational contribution such as is required  , at the stage at which it occtlrs , by tile accepted purpose or direction of the talk exchange in which one is engaged "  ( Grice 1975 )  . Grice proposes lhat the CP can be explicated in terms of four groups of simple max-ires which are not claimed to be jointly exhaustive  . 
The maxims are marked with an asterisk in Table 1.
Grice focuses on dialogues in which the interloc -utors want to achieve a shared goal  ( Grandy 1989 , Sarangi and Slembrouck 1992) . In such dialogues , lie claims , adherence to the maxims is rational because it enstu'es I haltheinter locutors pursue the shared goal most efl'iciently  . Task-oriente dialogue , such as that of our SLDS , is a paradigm case of shared-goal dialogue . Grico , however , did not develop the in axinls with the purpose of preveuthlg coinmunication failure in shared-goal dialogue  . Rather , his interest lies irithein l ~ rences which an interlocutor is able to make when the speaker deliberately violate soue of the maxims  . 
I\[tecalls such deliberate speaker's messages ' conversational implicatures '  . Grice's maxims , although having been conceived for a dilTerent purpose  , nevertheles serve the same objective as do ( ) tit " p , inciples , namely that of achieving the dialogue goal as directly and smoothly as possible  , e . g . by preventing questions of claril \] cation . It is exactly when a hunian or , for that in atler , an SLDS , non-deliberately viohttes a maxim , that dialogue clarification problems are likely to occur  . Thus , the main dil : ference between Grice's work and ours is that them axims were developed to account for cooperalivity in hUll lall-hUlnal/dialogue  , whereas our principles were developed to a ceoulll \[' or cooperativity in hunlan-nmchhle dialogue  . Giv cat he conll nonalily of purpose , it beconies of interest to conlpare principles and Illaxinls  . We waut to show that the principles include the illa Xilll Sasa subset end thus provides a corpus -based confirmation of their validity for spoken human machine dialogue  . More (> vet ' , the principles manifest aspects of cooperative task-oriented dialogue which were not addressed by 

4 Comparison between Maxims and

In this section we analyse the relationship between Grice ' snmxiins and our principles el : dialogue coop-erativity  . A\[irstaim is to demonstrate hat a subset of the principles are roughly equivalent totile ntax-hns  . We Ihen argue that there nlaining principles express additional aspects of cooperativity  . The dislinc-lion between I , ri , lcQ ) h " and axl WC t ( Tablel ) is theoretically int portant because an aspect represent stile l  ) roperty o1' dialogue addressed by a particular maximor prhlciple  . One result of analysing Iherehltionship between principles and nlaxhns is the distinction  , shown in the tables , 1) elween ? , eneric and specific principles . Grice'sulaxims are all generic . A generic principlelnay subsunle one or ltlore specific principles which specialise the generic principle to certain classes of phenomena  . Although important to SIA ) S design , specific principles may be less signil \] cant to a general account of dialogue cooperativity  . 
4 . 1 Pr inc ip les wh ich are Reduc ib le to Max ims Grice ' snmxims of truth and evidence  ( GP3 , (7I ) 4) have no coui/terparts aniong () ttrt ~ , ' inciples but inay simply be inchided among the principles  . The reason is that one does not design an SLDS in the domain  o1' airticket reservation which provides l : alse or unfounded information to cuslomers  . In other words , the maxims of truth and evidence are so important to the design  o1: SLI ) Ss that they are unlikely to emerge duriug dialogue design problenl-solving  . During sys-toniinll ) lenlalion , one constantly worries about truth and evidence . It canuoi be allowed , for instance , that the system confirrns inforn latioll which has il Ol been checked with the database and which might be false or impossible  . Grice ( 1975 ) observed the i : un-dan lental nature of the maxims of truth and evidence in general and  GP3 in particuhir ( of . Searle 1992) . 

Table 1 . The generic and specific principles of cooperativity in dialogue  . The generic principles are expressed at the same level of generality as are the Gricean maxims  ( marked with an * )  . Each specific principle is subsumed by a generic principle  . 
The lefthand column characterises the aspect of dialogue addressed by each principle  . 
Dialogue Aspect
Group 1: lnflrmativeness
Group 2:
Truth and evidence
Group 3:

Group 4:

Group 5:
Partner asymmetry
Group 6: ' Background knowledge
Group 7: ~ P , epair and clarification
GP no . SP no.

GPISP1
GPISP2






GP7 SP3


GPI 0
GPI0 SP4
GPI0 SP5

GP 11 SP 6
GPIISP7

GPI2 SP8

GP 13 ~ P9
GP 13 SPI 0
GPI3 SP ll
Generic or Specific Principlei * Makey our contribution as informative as is required  ( for the current purposes of the exchange )  . 
Befully explicit in communicating to users the commitments they have made  . 

Provide feedback on each piece of information provided b ~? the user  . 
* Do not make ~ our contribution more infornmtive than is required  . 
* Do not say what you believe to be false.
* Do not say that for which you lack adequate evidence  . 
* Be relevant , i . e . Be appropriate o the immediate needs tite ach stage of the transaction  . 
* Avoid obscurity of expressio I . .
* Avoid ambiguity : ..
! Provide same formulation of the same question ( or add re ~ ) ' to users every -- where in thes , steln's dialo ~ uc , turns . 
* Bebrief ( avoid unnecessary/t ~ rolix it ~/).. ~.
* Be orderly.
Inform the dialogue partners of important nonnormal ch?racteristics which they should take into account in order to behave cooperatively in diak  ) gue . 
Provide clear and comprehensible communication f what the system can and cannot do  . 
IP rovide clear and sttfficient instructions to users on how to interact with the system  . 
' Fake partners ' relevant b . ack ~ round knowledge into account . 
Take into account possible ( and possibly emmeous ) user inferences by analogy from related task domains  . 
Separate whenever possihle between tire needs of novice and expert users  ( user-adaptive dialogue )  . 
Take into account legitimate partner expectalions a to your own background know lcdse  .   .   .   .   . . . 
Provide sufficient task domain knowledge and inference  . 
Initiate repair or clarification lct a -connnunication in case of comlntlnication l 'ailure  . 
Provide ability to initiate repair it's ~/ stem understand in ~ has failed  . 
Initiate clarification recta-communication in case of inconsistent user input  . 
hfitiate clarification recta-communication in case of ambifzuous user input  . 
The following principles have counterparts among the maxims :  1  . Avoid'semantical noise ' in addressing users . 
(1 ) is a generalised version of GP6 ( non-obscurity ) and GP7 ( non-ambiguity )  . Its in felicitous expression was due to the fact that we wanted to cover observed ambiguity and related phenomena in one principle but failed to find an appropriate technical term for the purpose  . (I ) may , without any consequence other than improved clarity  , be replaced by GP6 and GP7 . 
2 . Avoid superfluous or redundant interactions with users  ( relative to their contextual needs )  . 
(2 ) is virtually equivalent oGP2 ( do not overdoin-lormativeness ) and GP5 ( relevance )  . Grice observed the overlap between GP2 and GP5 ( Grice 1975 )  . (2) may , without any consequence other than improved clarity  , be replaced by GP2 and GP5 . 
3 . It should be possible for users to fully exploil the system's task domain knowledge when they need it  . 
(3 ) can be considered an application o1'GPI ( infermativeness ) and GP9 ( order liness )  , as follows . If the system adheres to GPI and GP9 , there is a maximum likelihood that users obtain the task domain knowledge they need from the syslem when they need it  . 
T be system should say enough and address the task -relevant dialogue topics in an order which is as close as possible to the order expected hy users  . If the user expect some topic to cometipearly in the dialogue  , that topic's nonoccurrence at its expected " place " may cause a clarification sub < lialogue which the instance  , the system did not ask users about their interest in discount fare  . Having expected the topic to cometip for seine time  , users therefore began to in-quire about discount when approaching lheend of the reservalion dialogue  . (3) may be replaced by GP1 and
GP9 without significant loss.
4 . P , educe system lalk as nnich as possible during individual dialogue turns  . 
(4) is near-equivalent to GP8 ( brevity).
Sunlmarising , the generic principles ( 1 ) - ( 4 ) may here placed by maxims GPI , GP2 and GP5-GP9 . 
These maxilns are capable of perforii/illg the same task in guiding dialogue design  . In fact , as argtled , the maxim sai'oable to do the better job because they  , i . e . 
GP6 and ( IP7 , aildGPI and GP9 , respectively , spellOtll the illleilded coiltei its ill " two of I heprin cilfles  . 
This provides COl'ptis-l ) ased Coilfiiilllit \ [ Oil I ) \[" lilUXililSGPI , (1152 and CII:'5-(;P9 , i . e . of ttleir staling basic principles of cooperative  , task-oriented hulliall-illa-chine dialogue . However , \[ or dialogue design ptirpo-SOS , lheilla Xill/SilltlSt beaugn lenled hy task -slJecl:/T cordomain-sl  ) ecific princOHes , such as the \[ bllowing . 
5 ( SP3) . Provide same for nluhition of the same qucslion ( or address ) to users everywhere in the system's dialogue ttlrlls  . 
(5 ) represents an addition all WCCaU tion against the occurrence of ambigttity in niachine speech  . It can be soeii as a Sl ) ccial-purpose application o1'GP'/ ( i lon-aul biguity )  . 
6 ( SPI) . t  ~ ; efully expliciline t ) lllnlunicating to tlS-el'S the CO illitlllents they have Illade  , 7 ( SP2) . Provide feedback Oile~lch piece of infor-
Ination provided by lheriser.
Those principles are closely related . The novel coot > orativity as poel they introduce is lhal they require the cooperative speaker to produce a specific dialogue contl'il~ution which explicitly expresses an intorprola-lion of the intor locuior's previous diah  ) guoconlribu-lion ( s )  , provided I halthe interlocutor has in a do ; . l dialogue contribution of a certainly po , such as a coninlit nlonl Io book a flight . We propose ihal these principles besuhs unlod by ( i l'1 ( infornialiveness )  . 
4.2 Prindpleshic ldng Equivale nlslilil Olil 4 the

The principles discussed in this section appear irreducible to maxims and thus serve to augment the scope of a theory of cooperativity  . 
4.2.1 Dialogue Partner Asymmetry
Dialogue partner asynimctry occurs , roughly , when Oll Oorliloi ' e of I hodialogue partners is llot in a nor-lllal conditioll or situation  , leer in stall CO , a dialogue partner may have a hoalitlg deficiency or be located in a particularly noisy environn lcnt  , in such cases , dialogue cooperativity depends Oll the taking into accotln to \[' that participant'special characteristics  . 
For obvious reasons , dialogue partner asynmietry is important in SI , DS dialogue design . The machine is not an ornml dialogue partner and users have to be aware of this if communicalion faihire is to be avoided  . The following two principles address dialogue parln or a synllnelry :  8   ( SP4 )  . Provide clear and comprehensible com-In unication  ?  ) 1: what the system can and cannot do . 
9 ( SP5) . I'rovide clear and sufficient instructions Io users oil hOW\[  ( ) interact with tile system . 
Being limit cd in its task capabilities and intended for walk-up-and-use application  , our SLDS needs to protect itself from unmanage a hlc dialogue contributions by providing users with an upq'rontmental model of what it can and cannot do  . If this inclmtl model is too complex , us crs will not acquire it ; and il ' then lodclistoosituplistic > its remaining details must be provided elsewhere during dialogue  .   ( 8 ) adds an iln portant clement to Ih canalysis of dialogue coopcrativily by aiming at inl proving user coopcrativily  . It shows that , at least in hunlan-nlach inc dialogue , coopcraiivity is a fornmlly nlor cconiplcx pheuon lc nont hananticipated by Gricc  . In addition to principles stating how a speaker should he havc  , principles are needed tic-cording to which the speaker should consider transferring part of the responsibility for cooperation to the interlocutor  . (9) has a roles it nihu " to lhat of (8) . 
The lnincil ) lcscx anlincd in this section in lroducca new aspect  o1 dialogue cooperativity , naniely part-her asymmetry and speaker's consequent obligation to inform the partner  ( s ) of non-norn ml speaker characteristics , l ) ue to lhelatter , the principles cannot be subsumed by any olhcrl ) rincipl cormaxim . We propose I hat (8) and (9) are both . vl~eci/k'princil Jcs subsumed by a new generic pri  , l cilfle:GPI 0 . hl for tn the dialogue parttlors of inll ) Ot'tantil Oll-il ( ll'lllal charact crislics which they should take into accotilll in order tt  ) behave cooperatively in dialogue . 
4 . 2 . 2 llack grot md Knowledge 10 ( GPII) . Take users ' relevant background knowledge into account  . 
( ; 1511 is expressed at the level of generality of ( h'icc's theory . The principle explicitly introduces two notions : the notion  o1' interlocutors ' background knowledge and that of possible dilTcrcnccs in background knowledge between dilTer cnt user populations and individual users  . (; P1I appears to be presupposed by max in mGPI , GP2 and G155-( ; 1'9 in the sense that it is not possible to a dhc , ' e to any of I hese maxims without adhering to GPI I  . Moreover , in order to adhere to GPII , it is necessary lkn " the speaker to recognise relevant differences among inler locutors and interlocutor groups in Icrms  o1' background knowledge . 
Based on this recognition , a speaker either a h'cady has built prior to the dialogue  , or adaptively buikts during dialogue , a model o1' the interlocutor which serves to guidespeaker coopcrativily  . Increased user design ( Bernsen et al 1994) . 
GPIl cannot be reduced to GPI ( informativeness ) because , first ,   GP1 does not refer to the notions of background knowledge and differences in background knowledge among interlocutors  . Second , a speaker may adhere perfectly to ' exchange purpose '  ( cf . GPI ) while ignoring the interlocutor's background knowledge  . For instance , in the user test a user wanted to order a one-way ticket at discount price  . The system , however , knew that discount is only possible on return tickets  . It therefore did not offer the discount option to this user nor did it correct the user's misunderstanding  . At the end of the dialogue , the frustrated user asked whether or not discount had been granted  . Third , as argued above , GP ll is presupposed by maxims GPI , GP2 and GP5-GP9 . Grice , however , does not argue that GP1 is presupposed by those maxims whereashe does argue that  GP3   ( truth ) and GP4 ( evidence ) are presupposed by them ( Grice 1975 )  . For similar reasons , GP5 ( relevance ) ( Sperber and Wilson 1987) , cannot replace GPI1 . Informativeness and relewmce , therefore , are not only functions of the purpose ( s ) of the exchange of infornmtion but also of the knowledge of the interlocutor  . 
11 ( SP8) . Provide sufficient ask domain knowledge and inference  . 
(11 ) may appear trivial as supportive of the design of usable information service systems  . However , desig-ners of such systems are continuously confronted with questions about what the system should know and what is just within  , or barely outside , the sys-tem's intended or expected on min of expertise  . The system should behave as a perfect expert vis- ~> visits users within its declared domain of expertise  , otherwise it is at fault . In WOZ Iteration 7 , for instance , a subject expressed surprise at not having been offered the option of being put on a waiting list in a case in which a flight was already fully booked  . We became aware of the problem during the post -experimental interview  . However , the subject might just as well have asked a question during the dialogue  . Since (11) deals with speaker's knowledge , it cannot be sub-smncd by GP ll . We therefore propose to introduce a new generic principle which mirrors  GP11:   GPI2  . Take into account legitimate partner expectations as to your own background knowledge  . 
(11) , then , is a specific principle subsumed by GPI2 . 
12 ( SP6) . Take into account possible ( and possibly erroneous ) user inferences by analogy fi'om related task domains  . 
(12 ) is a specific principle subsumed by GP1 l ( background knowledge )  . It was developed from examples of user mistmderstandings of the system due to reasoning by analogy  . For instance , the fact that it is possible to make reservations of stand-by tickets on internationalilights may lead users to conclude  ( erroneously ) that this is also possible on domestic l qights . 
13 ( SP7) . Separate whenever possible between the needs of novice and expert users  ( user-adaptive dialogue )  . 
(13 ) is another specifi'c principle subsumed by GPII . 
Interlocutors may belong to different populations with correspondingly different needs of information in cooperative dialogue  . For instance , a user who has successft dly used the dialogue system on several occasions no longer needs to be introduced to the system but is capable of launching on the ticket reservation task right away  . A novice user , however , will need to listen to the system's introdnction to itself  . 
This distinction between the needs of expert and novice users was introduced in WOZ Iteration  7 when several users had complained that the system talked too much  . 
4.2.3 Meta-eommunication
Even if an SLDS is able to conduct a perfectly cooperative dialogue  , it will need to initiate repair and clarification metacommunication whenever it has failed to understand the user  , for instance because of speech recognition or language understanding failure :  14   ( SP9 )  . Provide ability to initiate repair il ' system understanding has failed  . 
(14 ) states what the cooperative speaker should do in case of failure to understand utterances made by the interlocutor  . Our system adheresto ( 14 ) in that it communicates it failure to understand what the user just said  .   ( 14 ) cannot be subsumed by GPI ( informativeness ) which ignores communication faihn e . 
Together with the new specific principles from the user test  SPI0 and SP11   ( Section 2 )  ,   ( 14 ) is a specific principle of htmm n-machine dialogue which may be subsumed by : OPl  3  . Initiate repair or clarification meta-commu -nicatkmin case of communication failure  . 
5. The user test
The set of principles presented in Table 1 , apart fi'om SP10 and SPII ( see below ) , were tested against henser test dialogue corpus ( Dybkjmr et al ,  1996) . In the user test the speech recogniser was simulated whereas the other system components were the implemented ones  , The system was tested with 12 external users . The 57 recorded and transcribe dialognes were scenario -based and covered the full functionality of the system  . We systematically analysed the transcribed ialogues to detect those deviations between expected and actual user utterances that would signal problems of user-system interaction caused by non-cooperative dialogue design  . An example is presented below of a piece of dialogue fi'om the user test in which two system cooperativity problems occur  ( Smean system and Umeans user ) :
S1: Do you want retnrn tickets ' ?
UI : Yes please.
$2:Are you particularly interested in discotmt ?
U2: Yes.
332 $3: On which date will the journey start ?
U3: Monday.
$4: Monday January 16. At which tin\]e ?
U4:7:20.
$5: There is node parture at 7:20 . The closes lother red departure is at 10:50 . Do you want this deparlure ?
US : No thanks.
Each identified problem in the dialogue corpus was categorised according to which principle had been violated and described in terms of the sympton \ ]   ( S )  , a diagnosis ( D ) and a cure(C ) . Below is shown the description for the two problems in  $5  . 
GPI : Make your contrihution as in l'ormalive as is required  ( for the current purl \] oses o1 the exchan-ge )  . 
S : U : interested in discount ( red ) + outdeparture time at 7:20 . S : node parture at 7: 20 . 
D : The system provides insufficient informalion.
It does not tell that lhere is a blue departure at  7:20  . 
C : The system should provide sufficient in for nta -lion  , e . g . by telling that there is no red departure bul lhall here is abh  , edel ) arture at the chosen hour . 
SPIll : Initiate clarification recta -communication in case of inconsistent user input  . 
S : U : interested in discount ( red ) + outdeparture time at 7:20 ; S : node parture at 7: 20 . However , 7:20 does exist but wilh out discount . 
1 ) : S gives priority to discount over time without proper reason  . 
C : S should ask U about priority: 7:20 is not a discount departure . Red discount can be oblained on the departures at x  , y and z . Which departure do you want . \[flU provides a new departure time : S : do you still want discount  . If U:no;S:non-discount departures\[ . 
It turned out that a hnost all of I he 86 system dialogue problems identified could be ascribed to violations of the cooperative principles  ( Bernsen et al , 1996b ) . We only had to add two specific f ~ rinciples o1' meta-contmunication ( SPI0 and SPII in Tahle 1 )  . Sincena et a-comnmnication had not been simulated uring the WOZ experiments  , this came as no SLUT ) rise . The lollowing GPs and SPs were found violated at least once : GPs I  ,  3 ,  5 ,  6 ,  7 ,  10 , II ,  12 , 13 and SPs 2 ,  4 ,  5 ,  6 , 8 ,  10 , II . 
The user lest confirmed the broad coverage of the principles with respect o cooperative  , spoken user-system dialogue . Less flattering , of course , the test thereby revealed several deficiencies in our cooper a--live dialogue design  . 
6 Conclusion
Comparison between our principles and ( ; rice's maxims has shown that there are more generic principles of cooperativity it \] human machine dialogue than those identified by Grice  . Three groups of principles reveal aspecls of cooperative dialogue left unaddres-sed hy the maxims  . This produces a lot alo1's evcn dialogue aspects , each of which is addressed by one or more generic principles  ( Table 1 )  . Some generic principles subsume specific principles  . It may be asked whyGfice was not aware of the Ihreegeneric aspects of dialogue partner asymmetry  , background knowledge and recta-communication . It seems obvious that it canno the because Ihese aspects arc absent from human-huntan spoken dialogue  . More plausibly , dialogue partner asymmelry is a hsent from prototypical cases of human-hun mndialogue  ; background knowledge is so perw mive as lohe easily ignored  ; and Grice explicitly was not concerned with dialogue failure pure and simple  . 
The results from the comparison will \] Grice's tllaXilllS and from the user test suggest lhat the principles of cooperative spoken human machine dialoguelllay represent a step towards a Ill Ole or less complete \] lid practically applicable set of designgt fidelines for cooperative SIJ  ) S dialogue . 

I~ernsen , N . O . , l ) ybkj:er , 11 . and l ) ybkj ; er , I, . (1996a ) . 
" Coopcralivily in\[hmmn-Machinc and lluman -lltmmn Spoken Dialogue  , " Discour ~' ePr <) cesses ,  21 , 2 ,  213-236 . 
Bcrnsen , N . O . , I ) ybkfier , H . and Dybkj~er , I ~ . (1996b ) . 
" l ~ rill ciples for the Design of Cooperative Spoken llure\]n-Machine Dialogue  . " To appear in Proceedings of 1CSLP'96 , l ~ hilad cll ~ hia , October . 
t~crnscn , N . O . , l ) ybkj ~ er , L . and l)y hkj ~ er , II .  (1994) . '% dedicated task-oriente dialogue theory in support of spoken language dialogue systems design  . " Proceeding soj ICSLP'94 , Yokohama , Sepl cmbcr ,  875-878 . 
Dybkjmr , L . , Bcrnsen , N . O . and Dybkj~er , 11 .  (1996) . 
"lw llualion of Spokenl ) ialogucs . User Test wilh a Simulated Speech Rccogniscr . " Report 9bj ' om the Danishl'r@eelin & ) okel ~ l , a / ~ guage Dialogue Syxlems . Roskild cUniversity , l ; ebmary . 
f : rasef , N . M . and Gilbert , G . N .  ( 1991 ) . " Simulating speech systems . " ~' ompuler Speechaml Language 5, 81-99 . 
Grandy , P, . E .  (1989) . " On Grice on language . " The Journalojl Vlilosol)t O , 86, 10, 514-25 . 
(; rice , P .  (1975) . " lx~gic and conversation . " In P . Cole & J . L . Morgan ( Eds . ), Synta . raml semal ~ lics Vol .  3 . " Si ) eechacts (4158) . New York : Academic Press . Reprinted in Gricc , P . : Studies in the way of words . Cambridge , MA:
Ilmward University Press 1989.
Sarangi , A . K . and Slcnlbrot . lck , S .  (1992) . " Non-cooperationi communication : A reassessmenl of Gfic can pragmatics  . ", I our mdq/Pragmatics 17, I17-154 . 
Sclmgloff , E . A . , Jefferson , G . and Sacks , 11 .  (1977) . " The preference for self-correction i the organization of repair in conversation  . " lzm guage 53, 361-82 . 
Searlc , J . R .  (1992) . " Conversation . "In Searle , , I . R . et al(l :, ds . ), ( On ) Searle ( mcom , ers'ation . Amsterdam : Johnllen jamin's I~ul~lishing Company . 
Sperber , D . and Wilson , 1) .  (1987) . " Prdc is offelevance , communication adcognition with open peer commentary  . " Behavioral aml Brain Sciences 10, 4, 697-754 . 

