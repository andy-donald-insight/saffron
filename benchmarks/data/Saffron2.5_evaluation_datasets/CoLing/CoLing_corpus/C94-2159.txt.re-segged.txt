PA USE ASAPHRASE DEMAR CATORFORSPEECH AND LANGUAGE PROCESSING 
JUNKO HOSAK AMARK SELIG MAN HAR ALD SINGER
ATR Interpreting Telephony Research Laboratories
Hika , ridai22 , Seikacho , Sor ~ ku-gun , Kyoto 619-02 , Jap ; m
Abstract
In spontaneous speech understanding a sophisticated integration of speech recognition and language processing is espceially crucial  . However , the two modnles are traditionally designed independently  , with independent lin-guistie rules . In Japanese spc . ech recognition the bun-sct suphrase is the basic processing unit and in language processing the sentence is the basic unit  . This difference has made it impractic M to use a unique set of linguistic rules for both types of processing  . Further , spontaneous speech contains unexpected utterances other than wellformed sentences  , while lingnistic rules for both speech and language processing expect wellformed sentences  . 
They therefore fail to process everyday spoken language  . 
To bridge the gap between speech and language processing  , we propose that pauses be treated as phrase demar -cators and that the interpausal phrase be the basic common processing unit  . And to treat the linguistic l ) he no I~l-ena of spoken language properly , we survey relevant features in spontaneous speech data  . We then examine the effect of integrating pausal and spontaneous speech phenomena into synt~tctic rules for speech recognition  , using 118 sentences . Our experiments show that incorporating pansal phenomena as purely syntactic on straints degrades recognition accuracy considerably  , while the additional degradation is minor if some filrther spontaneous speech features are also incorporated  . 
1 INTRODUCTION
A spontaneous speech understanding system accepts naturally spoken input and understands its meaning  . 
hi such a system , speech processing and language pro-cessiug must be integrated in a sophisticated manner  . 
I to wew : r , the integration is not straightforward , as the two are stndied independently art ( /have different processing units . Moreover , spontaneous speech contains unexpected phenomena , such as hesitations , corrections and fragmentary expressions , which thus far have not been treated in linguistic rules  . 
The most significant concern in speech processing is raising the recognition accuracy  . For that purpose , applying linguistic information , e . g . using stochastic models \[ ll , syntactic rules\[2\] , sen , anticint brmation\[3\] and discourse plan@l\] , is most promising . In a recent Japanese speech translation system\[5\] b * lnselsu-based syntactic constraints are successfully applied in the speech processing  module\[6\]   1  , However , rules repre-lA bunsetsu rouglfly corresponds to a phrase and is the next largest unit after the word  . Then unfl ) er of words in a phrase ranges from I to 14 , art (\] the mean numl ) erisal ) on t317\] . 
senting the same constraints cannot be used directly in sentence-based language processing  , where the primary concern is to understand sentence meaning  . In speech recognition , a sequence of words forms a bun-selsu and a set of bunse is us then forms a sentence  . 
In language processing , on the other hand , where the sentence is the basic processing unit , treating the main verhaud its complements i usually the core of processing  . For the sentence kaiginimoshikomitai nodes u ga  , meauing ' I would like to apply for the conference  , ' the processing discrepancy is sketched in
Figure 1:
Speech Processing kaigin , ~moshikomi\]~no desuga
LTII .. I
Language Processing \] moshikomi ~ taino do suga
II-7. ~ L..
Figure 1: Structural Difference
Although linguistic rules for speech recognition always cope with uncertain l  ) hone me hypotheses , they still expect well-for nmd speech input , and this is even more true of linguistic rules in language processing  . 
In spontaneouspeech , however , there are hesitations , corrections and incomplete utterances which are uot treated in the conventional framework  . 
In addressing spontaneouspeech understanding , two main prohlems must be solved : the absence of common processing components a ~ s sketched in Figure  1  , and our insufficient knowledge of spontaneous speech features  . In this paper , we propose the pause as a phrase demarcator and the interpausal phrase as the basic processing unit  . A phrase is naturally demarcated with pauses in spoken language and an interpausal phrase often functions as a meaning  unit\[8\]\[9\]  , in spontaneous speech understanding we must both accept naturally spoken input and understand its lneaning  . Use of the pause as a phrase de-marcator is advantageous for both of these purposes  . 
Further , we investigate several frequent spontaneous We then apply tile study to speech recognition  . We examine the effect of integrating into syntactic rules pausal phenomena and certain features of spoken language  , using 118 test sentences . 
2 ANALY SISO FSPONTA-
NEOUSDIAL OGUES 2 . 1 Spontaneous D ia logue Data As sources of spontaneous data  , wensefour Japanese dialogues concerning directions from Kyoto station to either a conference center or a hotel  , collected in the Environment for MultiModal lnteraction\[10\]  . 
Speaker A is pretrained to give the directions , mentioning possible transportation , location and so forth . 
Two subjects seeking directions , Speaker B and Speaker C , are given some keywords , such as the name and timdate of the conference . They may use telephone connections only , or may use a multimodal set np with on screen graphics and video as well  . Table 1 shows how many words are used in tile dialogues studied : 
Table 1: Words in the Corpora
Speakers A , B
Speakers A , C

Telephone Multimedia 5367 141167 1124~7o31838
Total 3541
The corpora consists of 3541 words in total , and contains 440 different words , it has 403 turn-takings , and thus roughly 403 sentences . 
In the multimedia setup , speakers used eictic expression such as koko and koremeaning " here " and " this  , " respectively . The dialogues also la~sted longer than those in the telephone-only setup  . I to we ver , we did not find any further distinct differences between the two setups  . We therefore analyse all of the dialogues in tile same way  . 
For our stndy , transcripts of the spontaneous dialogues have been prepared  , and these contain too > photogical tags and turntaking information  . Pause information within turns , i . e . , breaths or silences longer than 400 miliseconds , is provided a ~ swell . 
2.2 Pause as a Phrase Demarcator
In Table 2 we illustrate the adequacy of the inter-pausal phrase as a processing unit with a series of directions to Kyoto station's Karasumachou exit  .   3'he entire explanation consists of three turns separated by short response syllables  , snchash at , that do not overlap I , l ~ explanation . That is , the speaker paused during these responses . We marked each turn with '/' URN at the end . As a primary demarcator we used pauses and turns . Thus either PAUSE or TURN appears in the second colunm  . Further demarcator candidate such as the filled pauses anoor Pete  , the emphasis marker desune and the response syllable hat when overlapping the explanation appear in the third eo hmmas FILLED PAUSE  , DESUNE and RESPONSE , respectively . 
A rough translation follows each interpausal phrase : 
Table 2: Phrase Demarcator ~2 K ~@" QL2~:   6 PAUSE FILLED PAUSE if it is from here ~ 6 PAUSE this side ? - ) ~t ~>*&'-\[:2Z ) ~ O"C'N~~b ~ PAUSER , ESPONSE yougoup the stair sccfoa/~o-cN~- TU a N you cross here all the way ~* PAUSE and ~  , ~ , -?' I~E SPONSE - - ~ : J ~ Y ~ JJ mP AUSE when you see the nezt stairs  , this one , turn left , first ~_ ~ 7-~" PAUSEDESUNE at this place like across road which appears ~' ~ cEfo ~ CT  ; ~ ~ 5-TURN turn rigM "(" , ~ffIC'~"o"%I~Iz ' ~ X2 " PAUSE and yellt ' ~ lrTz right-PC ca ) N~-C-
I ~ g ~- C \]* . ~"~~-~ PAUSE t ~ ESPONSE and lhen if you go down the stairs here you come out of the karasumachou emil The length of the processing unit plays an impelrant role in speech recognition  . Table 2 shows that alternative demarcator candidates such as FILLED PAUSE and RESPONSE usually cooccur with pauses  . 
In Table 2 , for example , we find only one case where RESPONSE does not eooe cur with a pause  . Consequently , tile segments within turns bounded by these alternative markers would not be much different from those bounded by pauses  ; in particular , they would not be nan & shorter or longer . Thus , at least where length is concerned , the combination of PAUSE and TURN seems appropriate and sufficient to mark out phrases  . With respect to language processing , Table 2 shows that interpausal phrases are often adequate as translation units  , which suggests that such phrases often function as meaning units  . 
Interpausal phrases typically end with a conjunctive postposition  , such msya or kere domo ; a postpositional phrase ; an interjection , such as hator moshi-moshi ; the genitive postposition no for adnominals ; gation form ; ~m ? iliaries with senl ; enceliua\[conjuga-tiol:form ; or aseut , eneef in all ) arl . icle , such as lea or " ll ? . 
2 . 3 Features of Spontaneous D ia - logues We studied t  , en features of Sl ) Ont ~ mc . ous dialogues which are not , consid ( , rediugrammars for weal\['ormed senl ; ences\[6\]\[I1\] . Table 3 shows the fi'ah : res and t ; hcirfrequem : ies : In Ex . 2 Speaker\]3 did not ; finish whag hewm , i , edt . o say , but SpeMcerAm:derstoodhisiutention and inl ; err : ll ) ted his utterance , which is therefore fragumn-tary . Speaker 11 continued but , before he could liaish Speaker A finished for him  . So Speaker B'sl:tge . ra:lce is again \]' r:tgn:el:l,a'y . 
Ex . 3
Speaker A : ful:aeki ( lead'ter I , wo stops
Speaker H : keage keage 5' peaker A : soude , su that's right
Tabh '.3: Feature and Occurrence
Us (: of dc,s ~. ze:ffI
Use of a ~: oo 35I
Fragmentaryul ; term ~ ce 2:5\]
IJseofec/o 1, 5I
Endo\["tm'n with a PP7:
POS tl ) osition drop 7',
Question without ka5\]
I ) is fluency : soude . ~' ~ n ~, 51
Apposition 1I
Inversion 31
We expected a very high frequency of the \[ led pauses  a'0oo and celoflm ctio aiagas discourse managers\[I2\]  , l loweve . r , Table 3 shows only a roodest frequency . Iq ~ ol : ological varim , ions such as utb * oo al:da Tio for a 11 oo ; Hidetlova : ldcello\['or 0el0 were uot coltllted . This may be why the \[' requeucy of fbed:cxpr ( . .ssions ix unexpectedly low . 
Some flai , ures shown in Table : 1 are disc: , ssed in the (' . X ;- U I/I ) I esets below . Fe . al , ures it : focus ; ~ reiu bold type:
F , x . 1 soch . h'a ~ I o(lesm tenoviba kava basu gades une dele . masu there is a busfl ' om that buss ~ , op "\]' heperson giving dire . cdonsoff , e::usesdmex pression desu ~: e . The use o\["d csu'neemphasiz(:st , he preceding utterance . , typically the inlmediat . ely preceding miMmal phrase . In Ex . I the first use emphasizes so chirano and the seconds l  , resse . sba . s . uyR . 
We deuol , et , heperson giving the directions as Sp ( , a kcrAaud the person seeking the infornmtion as Speal : erB in Examples  2  , and 3 . 
Ex . 2
Speakerlkkeagcnokitanorl , h<ffkeage . 5' l ; cakcvA : soudes ' ~ l that's rigit
Speaker I ~ : ( legnehiexit
Speaker A : f ~ hzdcg'uchidc , ~' a ~ tcil/stl ~ enord ~ exit , okay ? Speaker A is giving directions but before he has completed hisul  , terancv Spealce . rB interrupts witl ~ the station name . SpeM:erA did not continue his\[h'sl , utterance and agreed wit\[:Speaker B . St ) e . ake . rA's first utterance is a non:hal phrase , which is never eoml Je . ted . 
...-41-"3 APPI,ICA\]ION OFTHE
ANALYSIS
To e?amine the l'easibility of integrating h:to syntactic rules both p:ms alphen outen and the fi  ; ah : res0\["SI ) OIILI /: IOOIlS speech studied in Section 2 , we prepared three , dill'trent sets of rules . In all threes (% s , rules have bee . nexl ) licitly u : oditied l ; ore present lmUS gdphel:ot:wp . a . The . first set : Pause ; contains only such modifications , while I , he other l ; wo sets add olle addition aispont : meous 5mtut'e each : rule set Emphasisl > crmit sllseo\[" , heell : l ) has is marker deswncel ' Let a noun phrase , while rule set Turn allows t ) ost posid on alu (; i . erauccs at ; t : heendo\['a turn . \ a?e conducted pre . 
liminary speech recoguitiou cxperiment , s with a pgL rser which uses linguist , ic constraints written ~ us a CFC . 
(  . ~ Ollstralrlt , s3 . \] Linguistic ~" To represem ; ore ' underlying linguistice on stnfints we adapted existiug synt  ; wt . ie rules developed for sl ) eech recognition \[6\] . Earlier expcriluents using b'lutselsu-based sl ) eech input showed 70% sent , encereeognid on accuracy fortl : etop caudidat , e and 8 , 1% for d : c . top 5 e:m didates . 
The format for all of our synt , actic : ': a lexix as fob-lows ;   ( < CATI > <--> ( < CAT2 > < CAT 3 > ) ) Nonterminals are surrounded by <> . \]' heabove rule indicates thal . CATI consists of CAT2al:d CAT3 . 
We denote the categories in interpa::sa/phrase rules in lower-cruse and t  , he categories in interpausal phrasebased se : /gelleerllie Sil : uppercase  . 
In the rule set Pause we prepared about d5 l > hrases dmt can end will : a pause : postposi -tiona I phrases  , COllj : lllCt , ivephrases , adnom in Mver-bal phrases marked with a special conjugation form  , nominal phrases with the genitive postposition no  , and coordinate verbal phrases . The first three rules are as follows: ( < pp-pau > <--> ( < pp > < pause > ) )  ( < conj-pau > <--> ( < conj > < pause > ) )  ( <vaux-mod-pau > <--> ( < vaux-mod > < pause > ) ) In the rule set Emphasis we prepared seven additional rules for treating the emphasis marker desune  , represented as follows: ( < pp-pau > <--> ( < pp > < emphasis > < pause > ) )  ( < pp-no-pau > <--> ( < pp-no > < emphasis > < pause > ) ) Methods for combining interpausal phrases to obtain an overall utterance meaning require further study  . At this stage we defined a sentence very loosely . It can be an interjection ; an interjection followed by a combination of interpausal phrases  ; or simply a combination of interpausal phrases . To allow fragmentary ntterances , in the ruleset Turn , we also introduced a sentence consisting of a nominal phrase  , which may contain adnominal phrases . Complete sentences in Turn are defined as follows  :   ( < SSS > <--> ( < INTERJI > ) )  ( < SSS > <--> ( < INTERJI > < SS > ) )  ( < SSS > <--> ( < SS > ) )  ( < SSS > <--> ( < M-NN > ) ) Table 4 shows the size and phoneme perplexity of the three sets of rules : 
Table 4: Size and Perplexity
Pause Emphasis Turn
Rules 2326 2333 2327
Words 751 752 751
Perplexity 3.96 3.96 3.96
A given phoneme string can belong to several categories  . For instance , de can be a postposition or a copula conjugation form  . The number of different phoneme strings is 503 for Pause and Turn , and 504 for Emphasis . 
3  . 2 Speech Recogn i t ion Exper iment We conducted a speech recognition experiment with  118 test sentences concerning secretarial services for an international conference  . A professional broad-caster uttered the sentences without any special constraint such as pause placement  . 
For our speech recognition parser , we used tIMM-LR\[14\] , which is a combination of generalized LR parsing and Hidden Markov Models  ( HMM )  . The system predicts phonemes by using an LR parsing table and drives HMM phoneme verifiers to detector verify them without any intervening structure such as a phoneme lattice  . Linguistic rules for parsing can be written mCFG format  . 
As mentioned in section 3 . 1 , we explicitly defined rules that can end with pauses in linguistic constraints  . According to the pause model , a pause can last from 1 to 150 frames , where a frame lasts 9 reset . 
Examples (1) and (2) show the results of It MM-Lit . Japanese speech recognition 2 .   ( 1 ) shows sample results of ruleset Pause and ( 2 ) shows sample results of Turn . The phoneme strings which were actually pronounced are enclosed in II :  ( i ) Ikaigino a Nnaishowao mochidesuka I ( Do you have a conference invitation ? )   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
I : kaigi-no-P-a Nnaisyo-o-o mochi-desu-ka 2 : kaigi-ni-P-a Nnaisyo-o-o mochi-desu-ka 3 : kaigi-ga-P-a Nnaisyo-o-omo chi-desu-ka > 4: kaigi-no-P-a Nnaisyo-wa-P-omo ehi-desu-ka 5 : kaigi-ni-P-a Nnaisyo-wa-P-omo chi-desu-ka ( 2 ) \[ iie\[ ( no )   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
1: imi-e2:igo-e > 3: iie 4: ima-e
S : kigeg-e
In the examples , the symbols > ,  - , N and P have special meaning : A correctly recognized phrase is marked with >  . A word boundary is marked with- . 
A syllabic nasal is transcribed N . A pause is marked with p . 
Example ( 1 ) shows typical recognition errors involving postpositions like no  , m , ga , and o , which often receive reduced pronunciation i natural speech  . 
The surounding context may aggravate the problem.
IIer e , for instance , topic marker waiser roneously recognized as object marker o in the environment  ; of preceding and subsequent phoneme o . The possible introduction of pauses at such junctures further complicates the recognition problem  . Analysis deeper than CFG parsing will often be needed to filter unlikely candidates  . Example ( 2 ) demonstrates the dangers of allowing postpositional phrases to end utterances  . 
Here , all recognition candidates other than the third are inappropriate postpositional phrases  . To recognize the unlikelihood of such candidates , we will need further controls , such as discourse management . 
Our resulting sentence speech recognition accuracies are shown in Table  5  . For instance , using rule set Pause , the correct candidate was the highest ranking candidate  50  . 0 percent of the time , Rank 1 , while the correct candidate was among the top , 5 candidates 55 . 9 percent of the time , Rank 5 . 
2 The maximal amount of the whole beam width , called the global beam width , is set at 100 , emd the maxim M be au width of each branch , the local beam width , is 12 . 

Table 5: Recognition tate (%) y-T . oT5 o /,\[ o . H
II < 4.2 ii
II
I i
With the underlying linguistic rules fl ) r the three rule sets , earlier experiments had achieved 70% sen-I , encespeech l : e cognition accuracy for speech input with explicit p~mses at bunsets'u bonndaries  . Our best , present results tbr spontaneous speech are much more modest :  50%  . 
' l ' ~ d ~ le 5 shows that the introduction of the emphasis marker des'uric did not affect processing : as seen in Table  4  , rule set Emphasis has a slightly higher perplexity than Pause  , but we hade x~(:tly the same re-sues for the two . On I ; he other hand , the perplexities of Pause and Turn~re identical  , but the treattnent of fragmentary utterances did decrease recognition ac- 

4 CONCLUSION 2'o treat spontaneous speech understauding we have two main problems : the absence of a common pro -ceasing unit gJ  . lld in su flie ie ilt knowle . dgeofs pouta-rictus speechf cat area . 
We have proposed pauses as i ) hrase det Ylar catol's and interpausM phrases as common processing units to allow integration of speech recognition and language processing in the processing of spontaneous speech understand\[us  . We demonstrated the adwm-gages of processing based on iutcrpausa I phrases using examples taken from spontameous speech dialogues containing  3  , 541 words . Using the same data , we studied certain features of spoken language , such as tilled pauses and fragmentary utterances . Based on the study , we prepared three difDrent CFG rules e . ts for preliminary speech recognition experiments . In all three sets , rules have been e ? plicitly modified to represent pausal phenomena  . Tiw . first set eolltaii is only such modifications , while the other two sets acid tile add it , ion alspontaneous feature each : rise of the emphasis marker desune after a noun phrase or postpositional utterances at the end of a turn  . For 118 sel/tences , sel/tence reco~llitiollacct lracy\['or pause -based rules was considerably less than the accuracy obtidned in earlier buTise is u-based tests using mandatory pauses at b~tn  . selslt boundaries ; but flirt , her loss of accuracy caused by incorporating the spontaneous features was minor  . 
We believe that the loss of speech recognition accuracy for sentence seen in our pause-based experiments is largely due to the difficulties of eombin-luginter pausa I phrase hypotheses  . Our r/lies cur-reiltly eombine interpausal phrases in a relatively unconstrained lllS  . unerltls illg only weaks yutactic COll-straiuts . Based vn filrther study of the structures which precede and follow pauses or filled pauses  , we hope t . o provide stronger syntactic on straints in the ftit'dre  . 
5 ACKNOWLED GEMENTS
Wc wish to thank \]) r . Y . Yamazaki , President of ATR-ITL , 2' . Morimoto , I lead of Department 4 , and many of our \[ TL colleagues for their generou supports lidell collrage lilellt  . 
References\[1\]Lee , K . -F . and Iton , \[\[ . -W . (1988 ) : " Large-VocMmMry Speaker-independent Continuous Speech Recognition Using \[\] MM  , " Prec . of ICASSP-88, pp .  123-126 . 
\[2\] Ney , II , (\]987 ) : " l ) ymmfict'rogrammlngSpeech Recognition Using a ( \] on texl . - Free Grammar , " Proc . 
of IC , ASSP-87, pp . 69-72.
\[3\] Matsunaga , S . , Sagayama , S . , Honmia , S . and Furui , S . (1990 ) : " A Continuous Speech Recognition System Based on a Two-Level Grammm : Approach  , " Pro <: . of
ICASSP-90, pp . 589-592.
\[4\]Y amaok ~ hT . and lida , H . (19 . 90 ) : " A Method to Predict the Next Utterance \ [ ) ' singit Four-layered Plan Recognition Model , " Prec . e\[ECAL90, pp . 726-731 . 
\[5\] Morimoto , T . , Takezawa , T . , Yato , F . , ctM . (1993 ) :" AG'IUsSpec'chG'ransb~tionSystem:ASUHA , " Prec . 
of Eurospcech-93, Vol . 2, pp . 129\]-t294.
\[6\]\[\[ osaka , J . , TM cezawa , T . (1992 ) : " Construction of corpus-based syntactic rules for accurate speech recognition  , " Prec . of CO tiNG-92, pi , . 806-812 . 
\[7\] Ehara . , '1' . , Ogura , IC , Mot\[mote , T . (1990):" ATRl)ia . logue \]) at a hase , " Prec . of ICSLI > -90, pp .  1093-1096 . 
\[8\] Fodor , J . , Bever ,  % ( 1965 ) : "' Fhepsychological real-icy of linguistic segments  , " Journal of Verbal Learning aud Behavior , pp .  4:414-420 . 
\[9\] Sugito , M . ( t988): " Pause and intonation in discourse , " Nihongotonih ongokyouiku , Vol . 2, pp . 343- . 
363 ( in Japanese).
I , oken-Kim , K . , Yato , F . , et a 1 . (1993 ) : EMMI-ATR environment for multi-roods inter ~ Lction  , q'T-
IT-0081, A'\['R.
llesak ~ h3 . (1993): A ( Iramlmtr for Japanese Generation in l , he TUGFr ; tmework , Technica J Report TIL1-0346 , A'I'IL Sadanobu , T . , Takubo , Y . ( ; 1993 ) : " The Discourse M~nagement Function of Fillers- a ca  . se of " eet o " and " ant(o ) ' > -, Prec . of ISSD-93, pp . 271-274 . 
Hosaka , J . , '\[' akezawa , ' l' . , Uratani , N . (1992 ) : " Analyzing Postposition \ [ ) tops in Spoken Japanese , " Prec . of l(3SLP-92, Vol . 2, pp . 1251q254 . 
Kita , K . , Kawabala , T . , Saito , li .   ( 1989 ) : " HMM Continuous Speechle cognit on Usii Ig Predictive LIParsing  , " Prec . of ICASSP-89, pp . 703-7\[)6 . 

