Towards Developing Reusable NLP Dictionaries
Pimvander Eijk and Laura Bloksma and Mark van der Kraan 
Research lllstitut c for l , ang t , age and Speech
Foundation for I , anguage Technology
State University of Utrecht
The Netherlands
van dereijk ~ let . ruu . nl
Abstract
Development of reusahle dictionaries for NI , P applications requires a carefully designed lexi -cological framework  , a lexical acquisition strategy , an integrate development toolbox , and facilities to generate dictionaries for client applications  . This paper presents results of tile LEX lC projecO  , which was set up to prep are the development of large multilingual lexieal resources  . 
K t ; y words : lexicons , tools , largescale resources , typed feature structures . 
1 Introduction 1 . 1 Common L inguis t ic Resources A large amount of the investments in the development of any NLP application is spent on the construction of what one might call " large databases of lexieal and grammatical resources "  . These resources could in principle he useful for many applications although they hardly ever are : due to the lack of agreement on the definition of basic notions and of consensus on the analysis of linguistic phenomena they are often linked too closely to specific applications  . Moreover , given the generally limited size and duration of NLP projects both quantity and quality of such project-specific databases are disappointing  . 
In this paper we will discuss results from the LEx lc project  , a feasibility study preparing largescale develop-1The Lexic project wanfinanced and supported by the three project partners : Philips Research  , developing tile Rosetta machine translation system  , the Foundation for Language Technology , participating in tile Eurotra project , and Van Dale , one of the lnaln dictionary publishers in the Netherlands  , as well as by tile the European Commission , and thel ) utchministries of Education and l"coaomic Affairs  . Details of the project are discussed in \[ van tierEijkctal  . , 1991) . 
The ~ tuthors want to that tkAnnevan Bolhu is , Joyl Icrk-lotz , Jeroen Fokker and Tim Dumas for contribution to the activities discussed in this paper  . 
irleut of s . reusabh ! lexical database , started hyacons or tiume f industrial and university partners  . The lexica\[database is designed to consist of an integrated package of two monolingual dictionaries for I  ) ut ch and Spaaish and the bilingual dictionaries relating the ~ languages  . 
The consortium comprised a dictionary publisher as well as NLP application developers  , giving it the unique opportunity of confronting the large body of exl  ) erience , infrastructure and existing data of publishers with the requirements of a new class of profe ~ qional users  . 
Another interesting aspect of the proj cct was that it addressed the whole spectrum of issues in lexieal database development  , from lexical acquisition to serving heterogeneous client applications  . In the current absence of arty standard fortile ( grammatical ) content of the dictionary ( e . g . standardized sets of grammatic M features ) the reusability of a dictionary can only be evaluated in terms of usability for some target applications  . 
1.2 Structure of the paper
Section 2 discusses the issue of acquisition of lexical data  . 
Section 3 introduces the implementation formalism and tools  . The lexicon architecture is discussed in section 4  . 
Conversion of data to client applications of the database is discussed in section  5  . 
2 Acquisition 2.1 Strategies
There are three potentially useful strategies to develop large lexical resources  , which are not ill principle mutually exclusive . 
MRDs The extraction of data from machine-readable dictionaries has received nmch attention ill the past decade  . In our view tile usefulness of existing material for NLP application has been somewhat overestimated  . Traditional dictionaries are oriented towards a market of hlll/lau  constlu3ers ~ who coustllt the dictionary for entirely different reasons than NLP applications  . 
For instance , most of the information in NhP dictio . 
uaries is concerned with the grammatical description of Ac : rf!sDI !  COLING-92  , NAh'H ~ S , 2328 AOt'rr 199253 l'l~oc , o1: COLING-92 , NANTI ! S , AU ( ; .  2328 , 1992 words , which in many dictionaries i only rudimentarily available ~  . 
Furthermore , given that humans can use their intelligence and knowledge of the language  ( s )  , much information is only present in unformalized efinitions and examples  . As discussed in e . g . \[ MeNaught ,  1988\] , it is often feasible to extract ( relatively ) formalized information , but the cost-effectiveness of autmnatic extraction of information from less formalized at a is highly questionable  . 
From this discussion it follows that MRDs at one cannot be the source for NLP dictionaries  . In section 2 . 2 we will discuss in more detail the evaluation of the potential sources of data for our specific purposes  . 
Corpora Automatic extraction of lexical features by applying various pattern recognition techniques to large bodies of text has received some attention recently  ( cf . 
e . g . \[Zernik and Jaeobs , 1990\]) . t lowever , the information needed for our applications cannot be extracted from corpora yet  , although important improvements can bcexpected in the following years  . 
Lexicography Given the present inadequacy of MRDs and corpus-related tools  , manual abour is indispensable for lexicon development  . The tools described in section 3 have been developed as a ' work bench'to support these lexieographical ctivities  . We will show that this tool allows for easy integration of information extracted from MRDs with lexicographic editing  . 
2.2 Sources
Evaluation Measure It is difficult to assess the " reusability " of existing data without an evaluation mea~snre  , i . e . without knowing . for what purpose the data shonld be usable . This is especially difficult in the case of grammatical features  . We developed a lexicon fragment ( implemented as TFS type hierarchy , cf . section 3 ) defining the classification scheme for the monolingual dictionaries  . This fragment is inspired by If PSG and GB , and incorporates many of the ( innovative ) distinctions developed by ttm client applications Eun  . OTItA and ROSETTA . It is , however , much more lezicalist than these systems . 
Eventually , all lexical entries in the two languages should be described using this scheme  , so that they can be readily converted to client applications  . The data that can be extracted from a potential source has been interpreted with respect othis classification scheme to assess the amount of information contained in it  . 
Data Analysis The machine-readable sources we con-sidcred are the existing VanDale Dutch monolingual and bilingual Dutch-Spanish machine -readable dictionary and the CELEX lexical database  . From our evaluation it followed that existing MRDs for Dutch  ( as for almost all other languages ) contain only a small part of the information eeded by NLP applications  . 
~ Well-structured dictionaries like \[ Longman , 1987\] are an important exception to this , cf . \ [ Boguraev and Briscoe , t989\] , Fortunately , the CELEX lexical database has enriched a selection of  30000 entries of the " Van Dale Dictionary of Contemporary Dutch " with grammatical information  , taking into account the requirements of a number of  ( prototype ) NLP applications under development in the Netherlands  . A large amount of information eeded for our target applications can be converted automatically from this database  . The entries , stored in a relational database , can be imported into the Dutch lexicon using the TFS constraint solver similarly to the conversion to client applications  ( ee section 5 )  . The CKr . gx dictionary has historic links to tile Van Dale dictionaries  ( especially with respect o reading distinction )  , which greatly simplifies integration of these sources  . 
With respecto translation information we found that the " raw " translational data could be extracted easily from the Vail Dale bilingual dictionaries  . The original Vail Dale concept is especially interesting for multilin-gum applications  , as the Dutch part is the same ( at least in principle ) in all bilingual dictionaries with Dutch as source language  ( cf . \[ van Sterkenburg el al . , 1982\]) . 
Extraction of information about phrasal translation  , such as the choice of the support verb of a noun in the target language  , is unfortunately hidden in unrestricted text ( example sentences etc . ), from which it is difficult to extract . Phrasal information also snffers greatly from incompleteness  . 
3 The TFS Formalism
Before discussing the proposed lexicon architecture we will introduce the computational framework in which it has been formalized and ilnplemented  , the formalism of typed feature structures . 
Currently the family of unification-based formaf is : rLq is an emerging standard as the implementation formalism of natural anguage processing systems  . A variant called typed feature structures , discussed a . o . in\[Carpenter ,  1990\] , \[ Emele and Zajac , 1990\] and \[ Zajac ,  1990\] , ha . s been adopted in a number of European lexicon projects  , including ACQUILEX , Euito'ra A7 and MULTILEX . In the course of our project , a TFS database , user interface and a constraint solver have been implemented  . 
TFS is an excellent formalism for computational lexicons  , as it enables a definition of types , or classes , of linguistic objects , arranged in a multiple inheritance hierarchy , where types are associated with an appropriate -hess specification defining their features and the types of those features and with  ( possibly disjunctive and complex ) constraints . The object-oriented character of the system allows for minimization of redundancy  , whereas the type system maximizes integrity of data  . 
Three TFS-based tools have been developed : ? a tool for interactive definition ~  , entry and modification of data ( cf . section 3 . 1) . 
* a TFS database which can be accessed from the user interface and the constraint solver  . 
3The TFS-editor can bc used to interactively define a type hierarchy  , as such a hierarchy can be viewed itself a . uaty ped feature structure , ef . \[ Fnkker , 1992\] . 
Acra~s DECOLING-92 , N^N'r I!S , 2328 Ao'\]r 199254 Pgoc . OFCOLING-92 . NAN'fES , AUC; .  2328 , 1992 ? a TFS-compiler for data manipulation , e . g . selections and conversion . 
The TFS-compiler is similar to the systems described by \[ Carpenter  ,  1990\] , \[ Emele and Zajac ,  1990\] , and \[ I , ' ranz ,  1990\] , and like the seit constitutes a general-purpose constraint-based formalism which can be used for a wide variety of tasks  , including parsing , translation and generation . Our prototype is implemented on top of Sicstus Prolog  , and is used primarily for selection and conversion of data  . It offers a number of tracing and debugging facilities to assist in the design of type -hierarchies and during query-evaluation  . 
These three tools can import and export data in a special-pn rpo ~ text format  , whict l is useful for interchange and further processing  . The acquisition tools for the Van Dale dictionaries and Celex can also generate their output in this format  . 
3.1 User Interface
The hierarchical definition of the grammatical types in TFS corresponds closely to a " decision tree " which the lexicographer traverses while editing a lemma  . A graph~teal user interface has been developed by the computer science department of the State University of Utrecht  ( \[ Fokker ,  1992\] ) which allows the user to narrow down the main type of the lenrma  ( s ) he is editing to a specific subtype and to subsequently edit the associated feature structure  . For example , a lemma is refined li'om ENTRY to VERB to DATIVE_VERB  , then constraints for this type are retrieved and the features and their substructures can be edited recursively  . 
Of course , only appropriate features are presented and can be edited  , e . g . it is impossible to edit a feature arg3 of an intransitive verb . While editing tile value of a few-ture the editor creates a subwindow already positioned at the minimal type of this feature  . E . g . while editing a verb , the feature semantics will already be positioned at the type EVENT  , as this is the minimal type of this feature for verbs  . 
The editor includes a useful help facility which can be viewed as an online instruction manual : a hell  ) function exists for each choice point which describes a number of criteria and examples to help making the decision  . 
It will now be clear how lexicographic work using the decision tree model relates to importation of lcxical data from existing sources  , such ms MRDs . These can he converted to partially edited lexical entries  , so that the lexicographer doesn't have to start at the ' root ' level  ( e . g . 
the choice point El/TRY in tile example ) , but at an intermediate level ( e . g . VERB ) . Further choices lea ( \[ to more refined descriptions of the word . Like all errors , errors iu the source dictionary can be corrected by moving back to a higher-level choice point in the hierarct ~ y  . 
Completed entries , and also arbitrary substructures , can be named and storediua database for future use as shared  ( sub ) structures in other entries . Useful applications of this cross-reference mecban is mare iu morphology and for the implementation fsynonymy  ( see 4 . 2) . 
Compounds can be assigned a feature tree with features left_daughter and right_daughter  , whose values are pointers in the database to their constitnting parts  . 
Tile editor has been implemented in C using tile Microsoft Windows  3  . 0 graphical interface . Tile progran r is designed to hee~mily portable , e . g . to X windows . The underlying database can be shared via a LAN . As the other tools , the database allows for import and export of feature structures in tile interchange format  . 
The editor is designed specitically for the TFS for-raalism  . However it cantie used for any specific type hierarci ~ y  , a stile definition of the type hierarchy is simply defined in a separate text file which is read by the program during start np  . IIence , it is potentially interestillg fortile devch ) pment of many other ( NLP ) dictionaries . 
An interesting elaboration of the editor would he to add extra functionality for the lexicographer besides editing at td viewing feature structures  , such & ~ facilities to consult w trious online dictionaries or text corpora  . 
4 D ic t ionary organ izat ion llaving introduced the computational framework wc will proceed with tile diseussion of the organization of the dictionary  4  . The emph ~ as is has been on two types of modularity : I  . Modularity of dictionaries and thesaurus . 
The general approach is to define clearly amun -her of a hstractiou levels  ( cf . section 4 , 1 ) in order to achieve ccLsy conncctability of the monolingua\[dictionaries via bilingual dictionaries  . By geueraliz ~ lug bilingual translation to bilingual synonymy  ( or equivalence , cf . section 4 . 2 ) wc can even separates e~mantic descriptions ( " concepts " ) from the elements in which they arc realized in languages  . Wc will show how such concel ) tual dictionaries can bc generated from bilingual ( fictionarics ( 4 . 3) . 
2 . Modularity of grammatical description ( cf . section ~) . 
With respect othe linguistic content of tile mono lingual dic Liouaries  ( i . e . the grammatical description ) we will diseuss the use of typed feature structure constraints expressing relations bct w cengram ? matical descriptions in various linguistic theories  . 
This allows fi ) raveryllexihle relation between varions grammatical descriptions  . 
4.1 Timm(~nollngual dictionary
Wordforms in a language , ~ Ls found in text corpora , arc associated with canonical forms according to \[ exi-cological conventions  . In particular contexts they are associated with c ? act \] y one of a tixed finite number of designations ~  . In \[ Zgusta ,  1971\] , two other " componeuts " of meaning are distinguished besides designation  , viz . connotation and range of application . Our ( somewhat poor ) working definition of synonymy is a relation hct ween reading sharing designation only  , both within a language and across languages ( where it is traditionally called equivalence )  . 
~Thi . s is a condensed summary of \[ v and crEijk , 1992a \] . 
5Note that wead ( q~t the approach of discrete readings , el . 
\[tcaItltckcn , 199(\].
AcrEsI ) ECOLING-92, NANqES , 23~28Ao ( rr 1997 . 55'R ~) C . OFCOI . ING92, NAN-rEs , AU(I .  2328 ,   1992 The relation between wordform saml canonical forms is many-to-many : or timgrapllic variants are mapped onto a single canonical form  , and a single wordform call be related to ~ veral lexical entries via inflectional rule * s  . The monolingual dictionary is a net of lexical entries  , which are pairings of canonical wordforms of a language and their designations  , and in addition describe their grarn rnatical properties  . 
As a result , a lexical entry d muld minimally have the two features canonical ~ form and semantics  . The former feature has the simple type STRIM6 , the latter , the description of the designation , has a complex value , po&'fi-bly including ~ n rantic features , but minimally containing an identifying feature v  , as we want to make sure it will always be possihle to interconnect tile monoling nal dictionaries via bilingual dictionaries  . Apart from these two features , there will he other features for the d~crip-lion of the grammatical properties of the word  . 
The combination of canonical J ' or m and grammatical description should allow for the complete and correct generation of all word forms and their a  . , mociated features trnctures . As our intended client applications have front ends for this purpose the database was not designed to be a fullform dictionary  ; tiffs could change , depending on the needs of future client applications  . 
The ~ t of designations can be viewed as a thesaurus or " knowledge base "  ; the lexical entries are " pointers " from words into this knowledge base  , and can be implemented as sudlin TFS . 
The relation between canonical wordforms and desig-nations is also many-to-many  , due to synonymy ( several wordforms related to the same designation  ) and lexical ambigality ( one wordform related to several designa-tions )  . In addition to this there will be alternations in the description because of alternative grammatical patterns  . These alternations are implemented as TFS disjunctions  . 
4.2 The bilingual dictionary
Bilingual dictionaries can be viewed as a relation between words in two languages  . The levels " word form " , " lexical entry " and " reading " correspond to various degrees of granularity in bilingual dictionaries  . Ideally , the bilingnal dictionary relates lexical items between languages at the level of readings  , though in practice most existing dictionaries refer to canonical forms or even to word forum in the target language  . Furthermore , the source language side in bilingual dictionaries usually refers to readings different from the monolingually motivated ones  , because they are tuned to tile target language : two readings are not distinguished if they translate to the same word  , or an additional reading is created for an additional translation  . An exception is the original concept of the bilingual Van Dale dictionaries  , where the source language reading structure of the bilingual  6g  . g . the Dutch word form be kcnd is associated with the adjective be kcnd  ( meaning well-known ) and ( by participle formation ) to the verb bekennen ( to conJess )  . 
r'I'he name of t , to red semantic substructures in the TI : S database serves this purpose  . 
dictionaries i hased directly on the moaolingual reading structure  ( of , \[ van Sterken hurgef at . , 1982\]) . 
An interesting approach to the hilingual dictionary would be to view it ~  . s describing pairings of bilingual synonyms . Tile advantage of this would be that 1 . the dictionary supl ) or ts preservation of meaning in translation . 
2 . formal properties of equivalence rlations ( e . g . transitive closure ) can be exploited to automatically ex-paml the dictionary  . 
3 . coding efforts call be reduced : tile detinition of the designation can be shared between monolingual nd bilingual synonyms  . 
Tile main difference hetween traditional dictionaries and our approach is therefore that tile indirectransla-tional description of hilm gual synonymy is replaced by a direct relation between lexical entries in the nmnolingual dictionaries to all independent " knowledge hase " of synonym clusters  . This approach is conamonille . g . multilingual terminology ( cf . \[ Picht and 1) rask au ,  1985\]) , but less common in lexicology . 
We will show that the two representations can be translated into each other  . Section 4 . 3 describes how a knowledge base is generated from monolingualnd bilingual dictionaries  . A bilingual dictionary can be generated automatically from a set of monolingual dictionaries and a klmwledge base by enumerating the pairs of lexical entries in two monolingual dictionaries pointing to the same synonym cluster  . 
4.3 Gcneratlng Synonym Clusters
Existing machine-readable trilingual dictionaries s can be converted to a representation based on bilingual synonymy  , by " extracting " the underlying concepts . The process consists of tile following steps : First  , the dictionaries are parsed and transformed to a table synoaym of the relation between a reading Rz in a language LZ and a reading  R2 in L = . Two versions of this program have been developed and tested : one for the Van Dale Dutch-Spanish dictionary and one for bilingual entries in the EUROTRA transferule format  . A version for dictionaries in a standard interchange format would be a possible future extension  . 
Second , reflexive , symmetric , and transitive closure is applied to the synonyM/4 relations . For each reading the generated synonym cluster can be viewed  . E . g . according totile Van Dale Dutch-Spanish dictionary  , reading 0 . 1 of Dutcheer beto on ( English On ark of ) honour ) has one synonymous reading in Dutch and three synonyms in Spanish  . 
eer beto on O . 1:
SActually , there is no restriction to it b = lingual dk ' tionary : severe  . lbi - or multilingu M dictionaries , and even monolingual diction ; tries of synonyms , can be processed similarly , resulting in a mull dingual dictionary . This has been checked using several Eurotra transfer dictionaries  . 
9 'I'hl8 program was first hnplented in Prolog for the Ndict system  ( \ [ Bloksma et el . , 1990\] ) itnd modified for a Fro-tetra research group on " ll  . cversibie Transfer " . 
A(:rlisi)1 ~ COLINC ~92 , NAN-IES , 2328 ^ o(rI 299256 Psoc . O1: COLING-92 , NAN q'ES , AUG ,  2328 , 2992 $ s:ho~t . najo honorast ributo . 
nl : ( eQr be to on_0,1 . arbo ~ ija 0 . 1  , The current implementation is not yet fully satisfying  . 
lecauea : there is no reading distinction on the , ql ) rmish side in the VanDaleNS ( only the Dutch words in the example are marked with a reading n m n b e r  , e . g .  0 . 1), some clt inters will get mixed upIsE . g . Spanish fresco as adjective means fresh and a ~ noun fresco  , though the program will currently not slake this distinction  . 
: frssco_0.1: os:fraucol impioref resco.
nl : fresco0, 1grin 0.1.
The program couhl of course be modified to ~ Lse the grummatical information about the target word in tbc dictionary as reading distinguisher  ; the noun fresco would then never be confimed with the adjective  . This is ull de ~ iral ) leilll ) rincil ) lc , bowcver , at ; we do not WK llt syntactic criteria to guide readiug distinction  , l " or instance , many adjectives in I~x ) mance languages have hemol ) honousuominal counterparts , with identical morphology and ~ manties . We don't want to be forced a priori to distinguish separate readings for the ~ e two cases  . 
Furthermore , wellknown examples of category shiftiu translation re  . g . adverbs translating to verbs etc . ) show it is impossible to attach a unique syntactic ategory to an equivalence class  . 
These presentations of synonym clusters can be very helpful to interaetively improve transfer dictionaries : errors of this type can easily he detected by native speakers of the languages  ( who need not know the other language ) and corrected by creating appropriate reading distinction in Spanish  . 
We cbecked the quality of t be synonym clusters gener  . 
ated from from both Van Dale and a EUItO'rRA Spanish Dutch dictionary  . The Eurotra dictionary , where both source and target language items are referred to at the reading level  , was converted to over 2187 chtsters ,   315 of whicb contained more than one Spanish reading . Native speakers agreed with more than 95% of these synonym sets g cuerated via the bilingual elomlre step  . The interpretation of bilingual translation as synonymy is therefore correct in the vast majority of eases  . 
l lowever , exceptions exist , such as t be translation of the Spanish reloj , which , even though a true ( aud inf request ) l ) ut ch synonym exists ( viz . uurwerk ( el . English lime piece)) , more commol fiytrauslate ~ to one of its hy-pouyn ~besiege  ( Engwatch ) or k lok ( Eng clock )  . 
An interesting e\[a horation four approach would be to extend the k * mw ledge base by ordering the synouym clusters themselves via hypono  , nyIt(cf . \[ Cruse ,  1986\] , l?'l'he problem of c'annecting wordforms to their reading sha * lu'en called the mapp in  9t~roblem   . Gf . \[ llyrd clal . ,  1987\] for discussion of a method to map word forms to readings by comparing a  . o . t ~ enlastic featn reslike human of the source re ~ling and potentiM target reaAings  . 
l *' I ' his idea is simil ~ tro Wordnet , a collection of synonynl sets linked via a variety of Icxical relations  ( \[Bcckwirth et al ,  1989\]) . Our & p proad lextends this idea by adding a multiling t la J dimension  . Word set'syllol tymt ~ tt ~ are ~ . lsO related by relations with leaso h : as translational contu : qu  ( mt:cn . 
\[Lyous , 1977\]) . Client applications could then extract Irauslati ( mal databased not only on synonymy but also on hyp  ( er ) onymy . However . this is a dillicult area , where no obvious solutions exist . It is not clear at all which translatiou solution automatic translators should select in c~mes like this anyway  . 
After thls correction process the synonyln clnsters can be couverted to TFS format and stored in the database  , The a . ~sociated monoling unldict k ) nnries are then modifled automatically badding cross-reference informatiott  ( via the features emastics ) from the lcxicn lentries to the synonym dust crs they use a ~ uociated with  . 
4.4 Creating a knowledge I ) ase.
Synonym clusters reMly become descriptions of desig-nations once semautl c information is added to the synonym dusters  , which is then , in a truly interlingual way , shared between synonyms . Muchmmlaxltic information froul the ( ~ ELEX 1 ) utch dictionary can I > e moved to the synonym clusters  , as well as Van Dale defiuitious of concepts in natural anguage  . Tb clatter arc useful for semi-automntic interactive applications Is  . 
The current approach can be said to inlpiement the a poproach of possible bilingual exlcal translalioa  , Tiffsal > preach should he developed in a uumber of ways  . Apart from the problem of translation to non -synouyms we mentioned  , it is desirable to inchL de information in the dictionary to guide the choice among possible translations  , iu cases where there are several syuonyms in the target language  . Stylistic , e olloeation alnd frequency in f l ) rmation can be of use for this purpose . This infer motion is partly available from existing sources  ( sucbas CF , I , EX attd Van Dale) , and large text corpora are also obviously relevant sources of this information  . 
5 A model for conversion
Conversion or exchange of lexical data presupposes a detailed comparison of the various dictiouaries  , which in turn requires a careful description of the various dictionaries  . Given the purpose of Comparison , the descriptions shouM be cast in a uniform , preferably high-level data descriptiou lauguage . Several such languages exist , such as the Entity-Relationship model , a tool in database design . We will use the TFS formalism introduced in ~ ction  3 for this purpose . 
A lirst step in tiffs comparison is to convcrt various dictionaries to the uniforln TFS format  . In\[n~xq tNI , P formalisms lexical entries are records or feature structures  , so this syntactic transformation is generally unproblematic  . In passing , implicit semantic structure in the wtr . 
ious dictionaries ( e . g . feature cooeeurrencer ~ trictions ) can be re , Meted explicit hy constructing a type hierarchy for the ~ uystcms  , ( ) n the has is of these descril)tions , constraints on the rehttion hetwc~m lexical entries in the dilt~rent dictionaries caube detined  , These constraints can be called Also see\[ Calzolari  , 1990\] for ai ) ropos Maimil ~ , r to ours to integrate the dictionary and the thesaurus  . 
lal " or exautple , lo . uettaill corl ) tltate ~ . .3 . 11 interactive rea(Ihtg selection\[acillty . 
Acrli ~; l ) t !('( JING 92 . NAN~ES . 2 ~28 ao ( Tr1 !) 9257 P Rec . o1:COl,IN(;92 . NANTES . AUG , 2328 . 1992 semantic , as they relate the content of the various dictionaries  , and neutral as they merely pinpoint correspondences between dictionaries  ; they define the way dictionaries ( which may be unrelated in other respects ) are similar . 
Constraints can be viewed as implication alnd bicon-ditional constraints  ( as in \[ van der Eijk , 1992b \]) , and it is possible to implement them as a complex TFS type  . 
This type serves both as documentation f the dictionary and as conversion specification  . 
A conversion specification is a TFS type CONVERT having features for each of the dictionaries  ( e . g . lezic , eu-rotra and rosetta ) , and establishes the basic conversion relation between entries in the LEXIC dictionary  ( as derived from the sources and augmented by lexicographers  ) and entries in the EtrROTRA and ROSETTA dictionaries  . 
This conversion type is structured hierarchically as well : the high-level type CONVERT has many subtype specify-ing how specific subtypes  ( and hence subsets of the respective lexicons ) of the various dictionaries are related . 
Disjuncts in the constraints of these types enumerate corresponding patterns described as feature structures  . 
An advantage is that these conversion constraints can be defined at the appropriate lvel of abstraction  . It is in principle possible to establish relations holding for all entries as well as for an individual entry  . As the conversion types are also ordered in an inheritance hierarchy  , subtypes will inherit the constraints of their supertype  ( s )  . 
Note the inherent declarative character of the conversion constraints : there is no notion of ' input ' and ' output '  . One advantage of this is that a single formalism can bensed for importation  , generation as well as integration of lexicons . A second advantage is that the conversion constraints can also be used to test wheth cr two existing dictionaries are related as postulated in the conversion constraints  . 
Full derivability of a particular dictionary can be viewed as a special case of the general  ( in principle relational ) scheme , where the substructure of a feature like rose tta is fully  ( and functionally ) derivable from the substructure of another ( lezic )  . Informally , all primitive distinctions in the target dictionary can be computed given the information in the source dictionary  , i . e . the constraints define a homomorphism from the serving dictionary to the client application  . 
It is an empirical issue whether this derivability relation can actually he defined between two dictionaries  . 
For newly to be created " generic " lexicons , this derivability is a design requirement . For the client dictionaries we have had to look at  , creation of a generic source appeared to be a complex  , but feasible , task . 
Operationally , conversion proceeds as query-evaluation . Givcn an appropriated cfinition of the CONVERT type  , the solutions to the following query will find alllexieal entries whose canonical for mistiers in the LEx Ic database and return all corresponding further instantiations of the ROSE TrAtype  . 
These instantiations correspond to the I ~ . OSETTA descriptions for this lexical entry . 
Ic ?'"' iENTRY lexic:canonical_fiets rosetta : ROSETTA  6 Illustration We will illustrate conversion using the example in \[ van der Eijk  ,   1992a \] relating two familiar linguistic theories , GPSG and a unification variant of Catego-ria \] Grammar  , rather than the LEXIC fragment and ROSETTA , which we actually implemented . 
The categorial lexical entries have a feature subcat whose value is either a CATEGORY or a FUNCTION  . The type FUNCTION has appropriate features argument  , ( with two features direction and category ) , and result , where the result can be either a function again or a CATEGORY  . 
Individual Icxical entries are simply instances of this highly general recursive scheme  . E . g . the subcat feature of a transitive verb ( i . e . ( NP\S)/NP ) has type FUNCTION , with an NP argument to the right and , recursively , a FUNCTION from a subject NP to an S as result . 
In GPSG individual lexical entries also have a feature subcat  , but its value , an in tcg cr , is used to select the corresponding contextfree grammar rule for this com-plc mentation pattern  . 
One of the disjuncts of the constraints for the CONVERT type will then be the following  . Unifying specific categorial entries into the cg substructure will cause the cur-responding psg feature to become instantiated  . 
? CONVERT cg:subcat:
FUNCTION\[dir:RIGNT\]arg:eat:NP dir : LEF Tres:arg:cat:NPres:Sn:--  1 v : + gpsg:bar : 0 subcal : 2 Due to the declarative character of TFS constraint evaluation  , the above constraint will yield the same result whether the cg  , t begps gor both features are instantiated . 
Evidently , the example is very simplistic . The prototype conversion module we developed in our project to translate LEXIC feature structures to I~OSETTA feature structures contained over  500 disjuncts Is , and this module only covered conversion of a subset of the verbs  . 
This number is caused by the fact that conversion rules la This numbe results from expansion to disjunctive nor-real form  . Tile actual notation for conversion rules allows for embedded is junctions and is  , hence , much more concise . 
AcrEsDECOLING-92 , NAr , ' fES , 2328 AOI~T199258 Pltoc . OFCOLING-92, NANTES , AUG .  2328 ,   1992 tend to become very idiosyncratic once the underlying theories of two dictionaries diverge  . 
7 Conclusion
We discussed how a multilingual lexical database can be coustructed using an mnber of existing lexical resources and lexicography  . The TFS formalism is very appropriate for the design and implementation fNLP lexicons  . 
We showed that its hierarchical structure can ben ~d profitably in a data entry tool which allows the lexicographer to manipulate fature structures graphically  . 
Lexical acquisition from existing lexical resources can be combined seamlessly with lexicographie work  . 
The lexicon architecture we designed is an important improvement over earlier approaches : various abstraction levels and the mappings between them are defined more precisely  , and the modularity is increased significantly by the ~ paration of the knowledge base from language-specific dtionaries  . 
With respect othe issue of reusability , we outlined a framework for the specification of comparative description of linguistic encoding schemes  . This specification can be used operationally as translation rules to convert lexical data  . 
References\[Beckwirth et al , 1989\] Richard Beekwirth , Christiane Fefibaum , Derek Gross , and George Miller . Wordnet : Alexieal database organized on psycholinguistic principles  . Paper presented at the First Lexical Acquisition Workshop  , IJCAI 89 ,  1989 . 
\ [ Bloksma et al , 1990\] Laura Bloksma , Aune van Bo \] oh uts , Pimvander Eijk , Piusten Hacken , Joytlerklots , Dirk Heylen , Hans Pijnenburg , Frank Sesiuk , Anne-Marie Teeuw , Louisdes Tombe , and Ton van der Wouden . Ndict : Final report . Technical report , Eurotra-NL , University of Utrecht ,  1990 . 
\ [ Boguraev and Briseoe , 1989\] Bran Boguraev and Ted Briscoe , editors . Computational Lexicography for Natural Language Processing  , London and New York ,  1989 . Longman . 
\[ Byrdelal . , 1987\] Roy Byrd , Nieoletta Calzolari , Martin Chodorow , Judith Klavaals , Mary Nell ' , and Om-meya Rizk . Tools and methods for computational lexicology . Computational Linguistics , 13(3-4), 1987 . 
\[Calzolari , 1990\] Nieoletta Calzolari . The dictionary and the thesaurus can be combined . In Relational Models of the Lexicon . Martha Evens , 1990 . 
\[Carpenter , 1990\] Bob Carpenter . The logic of typed feature structures . Draft , 1990 . 
\[Cruse , 1986\]D . A . Cruse . Lexical Semantics . Cambridge University Press , 1986 . 
\[ Emele and Zajac , 1990\] Martin Entele and R ~ miZajac . 
Typed unificatiou grammars . In Proceedings of the 13th International Conference on Computational Linguistics  ( COLING )  ,  1990 . 
\[ Fokker , 1992\] Jeroen Fokker . Lemming user manual . 
Technical Report INF/DOCL92-04 , Department of Computer Science , State University of Utrecht ,  1992 . 
\[Franz , 1990\]Alex Franz . A parser for HPSG . Technical report , Laboratory for Computational Linguistics , Carnegie Mellon University ,  1990 . No . CMU-LCL-90-3 . 
\[Longman , 1987\] Longmau . Longman Dictionary of Contemporary English . Longman House , Burnt Mill , Harlow , Essex , England ,  1987 . Second Edition . 
\[Lyons , 1977\] John Lyons . Semantics . Cambridge University Press , 1977 . 
\[ McNaught , 1988\] John McNaught . Computational lexicography and computational linguistics  . Lericogvaph . 
lea , (4), 1988.
\[ Pieht and Draskau , 1985\] Heribert Pieht and Jennifer Draskau . Terminology : An Introduction . University of Surrey , 1985 . 
\[tenl facken , 1990\]Plustent lacken . B . eading dictinc-tiou in MT . In Proceedings of the 13th International Conference on Computational Linguistics  ( COLING )  ,  1990 . 
\[ van der Eijk et al , 1991\]Pim van der Eijk , Laura Bloksma , Annevan Bolhuis , Joy Ilerklots , Lily van Munster , Jeroen Fokker , Mark van der Kraan , and Angelique Geilen . Final report of the Lexic Project Phase 1 . Technical report , Foundation for Language
Technology , 1991.
\[vander Eijk , 1992a \] Pimvander Eijk . Multilingual lexicon architecture . Working Papers in Natural Language Processing , Katholieke Universiteit Leuven , Stichtiug Taaltechnologie Utrecht ,  1992 . forthcoming . 
\[vander Eijk , 1992b \] Pimvander Eijk . Neutral dictionaries . \[ n Cheng-Ming Guo , editor , Machine Tractable Dictionaries : Design and Construction  , chapter 6 . 
Ablex , 1992. for th coraing.
\[ van Sterkenburg el al . , 19821 Piet van Sterkenburg , Willy Martin , and Bernard AI . A new VanDale project : Bilingual dictionaries on one and the same monolingua\[basis  . In J . Goetschalckx and L . l ~ olling , editors , Lexicography in the electronicage , pages 221-237 . North-tloll and , Amsterdam , 1982 . 
\[Zajac , 1990\]R ~ miZajac . A relational approach to translation . In P1vc . 3rd Int . Con\]' . on Theoretical and Methodological Issues in Machine Translation of 
Natural Language , 1990.
\[Zernik and Jacobs , 1990\] Uri Zernik and Paul Jacohs . 
Tagging for learning : Collecting thematic relations from corpus  . In Proceedings of the 13th International Conference on Computat ` ional Linguistics  ( COLING )  , 
Helsinki , 1990.
\[Zgusta , 1971\] Ladislav Zgusta . Manual of Lexicography . 
Mouton , 1971.
Acqa~s I ) ECOLING-92, NANTES . 2328 Aoffr 1992$9 PROC . Oi ; COLING-92, NANTES . AUG .  2328, 1992
