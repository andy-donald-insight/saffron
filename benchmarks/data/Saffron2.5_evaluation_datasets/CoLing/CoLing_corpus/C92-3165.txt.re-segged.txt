Interactive Speech Understanding
Iliroaki Saito
Dept . of Mathematties
Keio University
Yokohama , 223, JAPAN
Email : hxs@nak.math.keio.ae.jp
Abstract
This paper introduces at robust interactive method for speech understatnding  . The gener-atlized LR patrs ing is enhanced ill this approach  . 
Patrsing proceeds fl'om left to right correcting minor errors  . When at very noisy portion is detected , the patrser skips that portion using a . fake nonterminal symbol . The unidentified portion is resolved by re -utterance of that t portion which is parsed very efliciently by using the parse record of the first utterance  . The user does not have to speak the whole sentence again  . This method is also cat patble of hatndling unknown words  , which is imlmrtatn t in pra . ctical systems .  1 ) erected unknown words earn I ) e increment at lly incorporatted into the dictionary after the interatction with tile user  . A pilot system has shown great elfectiveness of this atp proach  . 
1 Introduction
It has been continuously mentioned that tsome kind of latnguage knowledge is essential in good -quality speech understanding  . Until recently , however , most research has focused mainly oil word recognition at n done of the excellent recognition systems built to date is Sphinx developed by Lee  \[7\]  . Although SI ) hinxatt tained at n excellent word accuracy of 96 % on at 997-word task , its sentence recognition accuracy drops slgnific at ntly clue to its use of only at stattistica Jtrigra ~ lgratm-iilal '  . 
There hat vebeen at few atttempts to integratte at speech recognition device with an attural language understanding syste  , n , ltatyeselal .   \[3\] adopted technique of case fi'ame instantiation to patrs eat continuously spoken English sentence in the form of at word lattice  ( a set of word cat ndldattes hypothesized by at st ) eech recognition module ) and produce at frame representation f the utterance  . 
The case frame patrs in ghats been pursued by Poesio et al  \[8\] and Giatchin et al \[2\] for instance . 
Meanwhile , at compiler-oriented shift-reduce LR parsing technique hats been used for speech recognition recently due to its no-batck tracking tatl  ) le-drlvenei\[iciency\[12 , iII ,  6\] . Becatuse the parsing proceeds from left to right pruning low-l  ) robatl ) ility t ) a trtiatl-parses , the correct parse cat n not be obtained if the parsing fails to find the correct path in the beginning  . Moreover , it is sometimes difficult to handletim very noisy input  , esl)ecially the input with missing words . Thus an Lll . parser sometimes yields totally incorrect but syntactically-sound hypotheses or no hypotheses attall  . This weakness is occasionally cited to demonstrate superiority of the pa  . rsing methodnsing much simI ) ler bigram or trigrat m grammars in which there . covery in the middle of the inputearn be done at eats e  . In this paper , we describe at method of enllatncing the generalized  1  , R ( GLR ) parsing to watrds interactive speech understanding . 
Section 2 describes the enhatnced GLR parrs-lug . Section 3 describes the rol ) ustness of the parser and presents an interatctive method to resolve the unclcatr I  ) or tion of the input and unknown words . Section 4 experiments the effectiveness of the technique in parsing spoken sentences  . Finally the concluding rematrks at regiven in Section  5  . 
2 Enhanced GLR Parsing for
Speech Understanding
Ill this section , tile GI , R patrs ing method is described first . Then some techniques which en-hatnce the robustness are described  . 
AcrEsDECOLING-92 . NANTES , 23 . 28^ot ~' r199210 S3Paoc . OFCOLING-92, NAt crras . Aoo .  2328, 1992 2 . 1 Background : GLR Pars ing The LR parsing technique was originally developed for the compilers of programming languages  \[1\] and has been extended for natural anguage processing  \[11\]  . The GLI\[parsing analyzes the input sequence from left to right with no backtracking by looking at the parsing table constructed from the context-flee gramma rules in advance  . 
An example grammar and its parsing table are shown in Figurel and Figure  2 respectively . 
Entries " sn " in the action table ( the left part of the table ) indicate the action " shift one word from the input  1  ) uff cronto the stack and go to state n " . Entries " rn " indicate tile action " reduce constituents on the stack usiug rule n "  . The entry " ace " stands for the action " accept  "  , and t ) lank spaces represent " error " . "$" in the action table is the end-of-inl ) ut symbol . The go to table ( the right part of the table ) decides to which state the parsers houhlgo after a reduce action  . The LR parsing table in Figure 2 is different fi'om regular LR tables utilized by the compilers in that there are multiplentries  , called conflicts , on the rows of state 11 and 12 . While the encountered entry has only one aztion , parsing proceeds exactly the same way as the regular LR parsing  . 
In case there are multiple actions in an entry , all the actions are executed with the graph -structured stack  \[11\]  . 
(1  ) S - -> NP VP ( 2 ) S-->SPP ( 3  ) NP-->n ( 4 ) NP-->detn ( 5 ) NP-->NP PP ( 6 ) PP --> prep NP ( 7 ) VP --> vNP
Figure 1: Example CFG Rules 2 . 2 GLR Pars ing for E r roneous Sentences The original GLR parsing method was not designed to handle ungrammatical sentences  . This feature is acceptable if the domain is strictly defined and input sentences are correct at all times  . 
Unfortunately , accuracy of speech recognition is not 100% . Common errors in speech recognition are insertions  , deletions ( missing words ) , and sub-<Action Table > I < Go to Table > det nv prep $ IN PPP VPS  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 
s 3   s4   s6   s7   s6 slO s3   s4   r3   r3   r2   r2 rlrl r5   r5   r5   r4   r4   r4   r6   r6  , s 6 r 6 r T , s6r721 ace 598 r3
Figure 2: GI , R Parsing Tablestitn tions . Some techniques have been developed to handle erroneou sentences for the GLR parsing  \[12  ,  10\] . 
? The action table can be looked up in a predictive way to handle a missing word  . 
Namely , a set of possible terminal symbols Ti at State i can be missing word candidates  . 
? This way of using the action table is also useful to handle substitution and insertion errors  . I . e . , the table can tell which part of the input should be replaced by a specific symbol or ignored  . 
'\[' he parser explores every possibility in paralle P  . 
2.3 Gap-filling Technique
The techniques described in tile previou section cannot handle such a big noise as two consecutive missing words  . To cope with this , the gap-filling technique \[9\] is presented here . 
Intile gap-filling GLR parsing , the go totable is consulted just the same way as the action table  , in addition to its regular usage . Namely , at states i which is expecting shift action(s ) , the parser also consults the goretable . If an entry m exists along the row of states l under the column lie practice  , pruning is incorporated to reduce search by using the likelihood attached to each word in the speech hypotheses  , ACIT ~ DECOLING-92 . NANTES . 2328^OI~T19921054 PROC . OFCOL 1NG-92 . NAN'r~s,AU6 . 23-28 , 1992 labeled with nontel'nl in M1) , the parser shifts D onto the stack an ( l goes to state m . Note that no . : zINP\]-~input is scanned when this action is performed  .   . .~):\]~-+~ When the input is in<:omplete , the parser pro0%\" ,   . wo cut B adduce shyl ) otheses with a fake nonterminal attile +"+ ~ n . + ~ v " . adj noisy position .  ::,  . . . ." +" . . . .
We show an example of l ) arsing an incorrectly NO 2 Wp\]-BINP\] ~2 recognized sentence " we cuts ad with a kuife " using the grammar in I : igure  12 and the LI ? table in Figure 2  . : ~ At the initial state 0 , the got ( ) ta-Ill (+ , tells that the nonterminals NP and Scan I>e shifte  ( 1 using the gap-filling technique . Although the first wor<t " we " ( noun ) is expected at state 0 , these fake+nonterminals are ere+a real ( \] " igure 3 ) in ca+se " we " is an incorrectly recognized word . 
Tile new states for the fake tlon terminals NP and S are  2 and 1  , resi > ectively , q'hego to table tells that fake nonterminals PP and VP can be place  ( \[ at state 2 . In this case , however , we do not create these nonterlltinals ~ l ) ee a use two fakel/o Iltel'llti-nalsr + u'ely need to I > eI  ) \[a ( : e <\] adjacently in pracice . No further fake nonterminal is at t , a . ched to iiitile fake nonterminal S for the same reason  . ~! v +, /\[ NP ) 2
O % '" , , we OOl had with a knilo n v ad i prop el l n l : igure  3: I ' arse Trace Iu parsing the third word " sad " , a fake nonterminal\[NP\]to word " cut " keeps the correct path  ( Figure , 1) . 
l ' arsing continues in this way and the linal situation is shown in Figure  5  . As a result , the parser tinds two snccessfifl parses : ( n ( v ( \[ NP\] ( prep ( det n )   )   )   )   )   (   ( n ( v\[NP\] )   )   ( prep ( den )   )   ) Namely , the \] ) arser Jinds < rot that the third word is incorrect and must be the word  ( s ) in NP category . 
2'J'he terminal symbols of this grammar are grammatical category names called prcterminals  . A lexicon should be prepared to map all actual word to its pretcrm in a \]  . 
: ~' l'hc techniques in the previou section arc enough for parsing this erroneouse/dencc  . We use this eXaml > leonly for describing I hegal ~iliing tech J  , illue . 
with a knMepe ~ ~1 n
Figure 4: Parse Trace(cont'd)+,"\[NP l ~";', . ~ eel~?+wi~h / . 
'\ n,"v ~-, adI . , ' I ) t ~+*; ~", do l ~ i ! " . . \ - - k ~ !!! \' VP k . mnioi1
S . r " , , , "
Figure 5: Parse Trace ( conq ) let e )   3 Interactive Speech Understanding In this section , the rot ) tLstness <) ftlw( ; LR parser with various error-recovery techniques ( esl ) ecia . lly the gap-filling te (: htdque ) aga . instanoisy input is described . Then an interactive way to resolve the unident if ied portion is I  ( reseld . ed . 
3 . 1 Reso lv ing Un ident i f ied Por t ion The gap -fi l l ing teehniqtm enhances the robustness of the  ( HAl parsing in handling a noisy in t ) ut as folk > ws : ? A fake nonterminals fills big missing con-stituents of the input which would yiehlno hylm theses without the gap-  . tilling func + tion . 
* The gap+filling fiHtction enables an LR parser to perform reduce actions only when the action creates a definite high-score nontermi-hal  . The fake nonterminal is likely to I ) eci-tllel+111 illSel'ti<' ) ii of all tlll kl lo ~ , vii word , ACI'ES DECOLING-92 , NANTES , 2328 AO(ff 19921055 PROC . Ol : COLING-92, NANTES . AUG .  2 , 3+28 ,   1992 A gap filled with a fake nonterminal can be resolved by reanalysis of the input under the constraint that that portion of the input should yield the specific nonterminal  . This topdown reanalysis would be effective agains the genuinely bottom-up GLR parsing  . In practice , however , a more reliable way is to ask the user to speak only the missed portion  . In the previous example , only the portion of \[ NP\]shouhliest ) oken again . 
The parser can analyze the re-utterance efficiently  , as follows : 1 . The parser keeps the parse record of the first input  . 
2 . The parser starts parsing the new input just where the fake nonterminal was created  . 
3 . The parsing ends when tim same-nameral nonterminal symbol is created out of there -utterance  . 
3.2 Handling Unknown Words
If the reutterance caunot be parsed correctly even by there utter aime  , the unidentified portion is likely to contain an unknown word  . Finding an unknown word by a specific nonterminal symbol enables the interactive grammar augmentation as the following  , for instance . 
The parser cannot identily the ~ ollowing portion of your input  . 
We cut \[ NP\]wit hak nife
If this is a new word in the category of \[ NP\] a rule NP-->  ( recog . result of the 2nd utterance ) will be added to the grammar . Is this ok ? Handling unknown words is important in natural language processing  . For example , Kainioka et al .   \[5\] proposed a mechanisnl which parses a sen-tencc with unknown words nsing Delinite C  , lause Gralumars . The efficient gap-filling technique of handling unknown words is quite useful in practical systems and enhances the robustness of the 
GLR parsing greatly.
When an unknown word W , ,~ , is detected , the word should be incorporated into the system . If the grammar is separated from the lexicon , the word can be easily added to the dictionary . If the grammar contains the lexicon , the LR table should be augmented incrementally in the following way  . 
1 . For each state si which has an entry under the column of the nonterminal D  ( $ ~ k , ) in the go to table , add shift action " sm " ( m is the new state number ) for W .   .   .   .   ( If W new consists of such multiple words as " get rid of '  , a new state should be created for each element of the words  .  ) 2 . Add reduce action " rp " ( p is the new rule number ) for all the terminals on the row of state nl . 
Before we close this section , wc should consider side etfects of the gap -tilling technique  . It is true that putting fake nonterminals expands earch  . 
Thus , some side effect might appear if the accuracy of input is not good  . Namely , input should be good enough to produce distinct fake nonterminals and real nonterminals  . Although it is difficult to analyze this phenomenon theoretically  , the following natural heuristics can minimize the search growth  . 
oTwo consecutive fakeu on termiuals are not allowed as shown in the previou section  . 
? When a word ( Wi ) can be shifted to both a fake nontern final D . fake and a same-name real nonterminal D~e , z , only D  ~ , t should be valid . 
? When D : , ~ and D , . ~ l ( : an be bundled using the local ambiguity packing \[111 tec bnique , discardl)f ( , k , , . 
4 Exper iments : Pars ing Spoken Sentences We evaluated effectiveness of tlle enhanced GLR parsing by spoken input  . We used a device which recognizes a . lapanese utterance and produces its phoneme sequence  \[4\]  . The parser we used is 1 ) ased on the ( -HA/parser exploring the possibilities of substituted/inserted/deleted phonemes  \[10\] by looking up thee on filsion mntrix , which was constructed from the large vocabulary data  . 
The confusion matrix is also used to ms sign the score to each explored phoneme  , because the recogld tion device gives neither the alternative phoneme candidates nor the likelihood of hypothesized phonemes  . The gap-filling fimction is incorporated iuto the parser in the following experiments  . Parsing al > hone me seq nence might soundless pot > ular than I  ) arsing a word lattice in speech AcrEs DECOUNG-92 , NANTES , 2328 Ao(:r199210 S6PROC . OFCOLING-92, NANTES , AU6 . 23-28, 1992 recognition . Because the parser builds a lattice dynamically in parsing the sequence from left to right using a CFG which contains the dictionary  , no static lattice is necessary . 
125 sentences ( five speakers pronounced 25 sentences ) were tested in tim domain called " conversation between doctors and patients  . "111 sentences were parsed correctly \[88 . 8 %\]  ( the correct sentence was obtained as the top -scored hypothesis  )  .   14 failed sentences can be classified into three groups :  ( i )   4 sentences were parsed as the top-scored hypotlms es with fake nonterminals  . Thus the parser asked the user to speak the unidentitied portion again  . 
( ii )   6 sentences were parsed incorrectly in that the correct sentence did not get the highest score mainly because the incorrect nonterminal had a slightly higher score than the correct one  . In this case , both the closely-scored correct and in cofrect nontermin~s are packed into one nouterll i-nal using the local ambiguity packing technique in an efficient implementation  . In this situation the parser should ask the user to speak only that unclear portion in the same way as in  ( i ) instead of producing a barely top-scored hypothesis  . In the current implementation the parser asks the user which word is the correct one  . 
( iii ) 4 sentences were pronounced very I ) adly.
The user has to speak the whole sentence again.
5 sentences with unknown words were also tested , in all eases , the unknown word was detected . 
This result shows that interactive partial re -utterance is very effective both for error -recovery and for detection of unknown words  . 
5 Concluding Remarks
We presented a robust interactive apl ) roach for speech understanding . The GLR parsing method WaSenll aliced to recover errors and to skip a very noisy portion  . These techniques remedy " , dl-or-nothing-imss of the CF(Lbased LRt ) arsing . The skipped portion is represented by a faken on -termimd which is resolved l  ) yre-utterance . An unknown word is also detected by a fake nonterminal and is incorporated into the dictionary incrementally through interaction with the user  . 
Exl ) eriments in t ) arsing a Jal ) an esel ) honeme sequence have shown a great effectiveness of this interactive approach  . 
References\[1\]SethiR . Aho , A . V . and J . D . Ullman . Compilers . 
Addison Wesley , 1986.
\[2\]E . Giachin and C . l , ullent . Robust Parsing of Severely Corrupted Spoken Utterances  . 
In Proceedings ,   12th lnte ~ mational Conference on Computational Linguistics  ( COLING )  , Budapest , ltungary , August 1988 . 
\[3\]llauptmmmA . G . Carbonell J . G . Hayes , P . J . 
and M . Tomita . Parsing spoken language : A semantic case framc approach  . In Proceedings , llt hlnle T ~ aalional Conference on Computational Linguistics  ( COLING )  , West Germany , August 1986 . Bonn . 
\[4\] Morii S . lloshimiM . Hiraoka , S . and K . Niyada . 
Compact isolated word recognition system for large vocabulary  . In Proceedings , IEEF-IEC'EJ-ASJ International Conference ou Acoustics  , Speech , and Signal Process in 9 ( ICASSP ) , Tokyo , 
April 1986.
\[5\]T . Kamioka and Y . Anzai . Analysis of sentences including unknown words by hypothesis generation mechanism  . Journal of Japanese Society for Artificial Intelligence  , Vol . 3 No . 5, pages 627-638,
September 1!)88.\[In Japanese\].
\[0\] Kawabat , a T . Kits , K . and I1 . Saito . tl MM Continuous Speech Recognition Using Predictive LR 
Parsing . In ICASSP , May 1989.
\[7\]K . F . Lee . Large-Vocabulary Speaker-ht dependenl Continuous Speech Recognition : The SPHINX System  . Phi ) thesis , Computer Science Department , Carnegie Mellon Uniw ; rsity , April 1988 . 
\[8\] M . Poesio and C . lhlllent . Modified Cm ' ~ e frame Parsing for Speech Understanding Systems  . In Proceedings , l Oth International Joint Conference on Artificial Intelligence  ( IJCAI )  , Milan , August 1987 . 
\[9\] II . Saito . Gap-tilling LR Parsing for Noisy Spoken Input : " Ibwards Interactive Speech Hx ~ eognition  . 
In Proceedings , httcTmattonal Conference on Spoken Language Processing  ( ICSLP )  , Kobe , Japan , 
November 1990.
\[10\]II . Saito and M . Tomita . Parsing Noisy Sentences . In Proceedings ,   12th International Conference on G ' omputalional Linguistics  ( COL-IN (  ; ) , Budapest , lhm gary , August 1988 . 
\[11\]M . Tomita . l '; Jlieient Parsing for Natural Lan . 
guage , l(luwer Academic Publishers , Boston,
MA , 1985.
M . q bmit a . An efficient word lattice parsing algorithm for continuous speech recognition  . In Pro-ceed in . q s ,   IEEE-1ECEJ-ASJ htternational Conference on Acoustics , Speech , and Signal Processing ( ICASSP ) , 2bkyo , April 1986 . 

ACRESDE COLING-92 , NANTES , 2328 AO ( rr 19921057 PRoc . OFCOL1NG-92, NANTES , AUO .  2328, 1992
