Polarization and abstraction of grammatical formalisms as 
methods for lexical disambiguation
Guillaume Bonfante and Bruno Guillaume and Guy Perrier 
LORIA-UMR 7503,
Campus Scientifique , B.P . 239,
F-54506 V and ? uvrele`s Nancy CEDEX
Guillaume . Bonfante , Bruno . Guillaume , Guy . Perrier@loria . fr

In the context of lexicalized grammars , we propose general methods for lexical disambiguation based on polarization and abstraction of grammatical formalisms  . Polar-ization makes their resource sensitivity explicit and abstraction aims at keeping essentially the mechanism of neutralization between polarities  . Parsing with the simplified grammar in the abstract formalism can be used efficiently for filtering lexical selections  . 

There is a complexity issue if one consider exact parsing with largescale lexicalized grammars  . Indeed , the number of way of associating to each word of a sentence a corresponding elementary structure ? a tagging of the sentence ? is the product of the number of lexical entries for each word  . The procedure may have an exponential complexity in the length of the sentence  . 
In order to filter taggings , we can use probabilistic methods ( Joshi and Srinivas , 1994) and keep only the most probable ones ; but if we want to keep all successful taggings , we must use exact methods . Among these , one consists in abstracting information that is relevant for the filtering process  , from the formalism F used for representing the concerned grammar G  . In this way , we obtain a new formalism Fabs which is a simplification of F and the grammar G is translated into a grammar abs  ( G ) in the abstract framework Fabs . From this , disambiguating with G consists in parsing with abs  ( G )  . The abstraction is relevant if parsing eliminates a maximum of bad taggings at a minimal cost  . 
( Boullier ,  2003 ) uses such a method for Lexicalized Tree Adjoining Grammars  ( LTAG ) by abstracting a tree adjoining grammar into a contextfree grammar and further abstracting that one into a regular grammar  . We also propose to apply abstraction but after a preprocessing polarization step  . 
The notion of polarity comes from Categorial Grammars  ( Moortgat ,  1996 ) which ground syntactic composition on the resource sensitivity of natural languages and it is highlighted in Interaction Grammars  ( Perrier ,  2003) , which result from refining and making Categorial Grammars more flexible  . 
Polarization of a grammatical formalism F consists in adding polarities to its syntactic structures to obtain a polarized formalism F polin which neutralization of polarities is used for controlling syntactic composition  . In this way , the resource sensitivity of syntactic composition is made explicit  . ( Kahane ,  2004 ) shows that many grammatical formalisms can be polarized by generalizing the system of polarities used in 
Interaction Grammars.
To abstract a grammatical formalism , it is interesting to polarize it before because polarities allow original methods of abstraction  . 
The validity of our method is based on a concept of morphism  ( two instances of which being polarization and abstraction  ) which characterizes how one should transport a formalism into another  . 
In sections 1 and 2 , we present the conceptual tools of grammatical formalism and morphism which are used in the following  . 
In section 3 , we define the operation of polar-izing grammatical formalisms and in section  4  , we describe how polarization is used then for abstracting these formalisms  . 
In section 5 , we show how abstraction of grammatical formalisms grounds methods of lexical disambiguation  , which reduce to parsing in simplified formalisms . We illustrate our purpose with an incremental and a bottom-up method  . 
In section 6 , we present some experimental results which illustrate the flexibility of the approach  . 
1 Characterization of a grammatical formalism Taking a slightly modified characterization of polarized unification grammars introduced by  ( Kahane ,  2004 ) we define a grammatical formalism F ( not necessarily polarized ) as a quadruple ? Struct F , Sat F , Phon F , Rules F?:1 . Struct F is a set of syntactic structures which are  graphs1 in which each edge and vertex may be associated with a label representing morphosyntactic information  ; we assume that the set of labels associated with F is equipped with subsumption  , a partial order denoted v , and with unification , an operation denoted unions q , such that , for any labels l and l ? , either lunions ql ? is not defined , which is denoted lunions q l ? = ? , or lunions ql ? is the least upper bound of l and  l?2  ;  2 . SatF is a subset of Struct F , which represents the saturated syntactic structures of grammatical sentences  ;  3 . PhonF is a function that projects every element of SatF in the sentence that has this element as its syntactic structure  . 
4 . Rules F is a set of composition rules between syntactic structures  . Every element of Rules F is a specific method for super-posing parts of syntactic structures  ; this method defines the characteristics of the parts to be superposed and the unification operation between their labels  . Notice that we do no task rules to be deterministic  . 
The composition rules of syntactic structures , viewed as superposition rules , have the fundamental property of monotonicity : they add information without removing it  . Hence , the definition above applies only to formalisms that can be expressed as constraint systems in opposition to transformational systems  . 
Let us give some examples of grammatical formalisms that comply with the definition above by examining how they do it  . 
? In LTAG , Struct LTAG represents the set of derived trees , SatLTAG the set of derived trees with a root in the category sentence and without nonterminal leaves  . 
1Usually trees or directed acyclic graphs.
2The least upper bound of l and l ? can exist and , at the same time , lunionsql ? be not defined ; if the operation of unification is defined everywhere  , the set of labels is a semilattice . 
The projection PhonLTAG is the canonical projection of a locally ordered tree on its leaves  . Finally , Rules LTAG is made up of two rules : substitution and adjunction  . To view adjunction as a superposition rule , we resort to the monotone presentation of LTAG with quasi-trees introduced by  ( Vijay-Shanker ,  1992) . 
? In Lambek Grammars ( LG ) , Struct LG is the set of partial proofs and these proofs can be represented in the form of incomplete Lambek proofnets labelled with phonological terms  ( de Groote ,  1999) . 
SatLG represents the set of complete proofnets with the category sentence as their conclusion and with syntactic categories labelled with words as their hypotheses  . 
The projection PhonLG returns the label of the conclusion of complete proofnets  . 
Rules LG is made up of two rules : a binary rule that consists in identifying two dual atomic formulas of two partial proofnets by means of an axiom link and a unary rule that consists in the same operation but inside the same partial proof net  . 
Now , inside a formalism defined as above , we can consider particular grammars :
A grammar G of a formalism F is a subset G ? Struct F of its elementary syntactic structures  . 
A grammar is lexicalized if every element of G is anchored by a word in a lexicon  . In LTAG , G is constituted of its initial and auxiliary trees  . 
In LG , G is constituted of the syntactic trees of the formulas representing syntactic categories of words as hypotheses plus a partial proofnet anchored by the period and including a conclusion in the category sentence  . 
From a grammar G defined in a formalism
F , we build the set D ( G ) of its derived syntactic structures by applying the rules of Rules F recursively from the elements of G  . The language generated by the grammar is the projection L  ( G ) = Phon F ( Sat F?D ( G ) ) . 
2 Morphisms between grammatical formalisms Polarization and abstraction can be defined from a more general notion of morphism between grammatical formalisms  . A morphism from a grammatical formalism C to a grammatical formalism A is a function f from Struct C to Struct A with the following  properties3:   ( i ) f ( SatC ) ? Sat A ; ( ii ) ? S ? SatC , PhonA(f(S )) = PhonC(S ); ( iii ) if S1 ,   .   .   .   , Sn are composed into a structure S in C by means of rules of Rules C  , then f(S1) ,   .   .   .   , f ( Sn ) can be composed into the structure f ( S ) by means of rules of Rules A . 
Given such a morphism f and a grammar G in C , the image of G byf denoted f ( G ) is the grammar ? in A ? induced by the morphism . 
The three properties of morphism guarantee that the language generated by any grammar G of C is a subset of the language generated by f  ( G )  . In other words , L(G ) ? L(f(G )) . 
We propose to use the notion of morphism in two ways : ? for polarizing grammatical formalisms and in this case  , morphisms are isomorphisms ; grammars are transposed from a formalism to another formalism with the same generative power  ; in other words , with the previous notations : L(G ) = L(f(G )) ; ? for abstracting grammatical formalisms and this case  , the transposition of grammars by morphisms entails simplification of grammars and extension of the generated languages  ; we have only : L(G ) ? L(f(G )) . 
An example of the use of abstraction for lexical disambiguation may be found in  ( Boullier ,  2003)4 . We propose to link polarization with abstraction because polarities allow original methods of abstraction  . Polarization is used as a preprocessing step before the application of these methods  . 
3 Polarization of grammatical formalisms The goal of polarizing a grammatical formalism is to make explicit the resource sensitivity that is hidden in syntactic composition  , by adding polarities to the labels of its structures  . 
When morphosyntactic labels becolarized in syntactic structures  , they get the status 3An elegant definition of morphism could be given in a category-theoretical framework but we have chosen here a more elementary definition  . 
4Our definition of morphism must be slightly extended for embedding the proposal of  ( Boullier ,  2003) . 
of consumable resources : a label that is associated with the polarity + becomes an available resource whereas a label that is associated with the polarity ? becomes an expected resource  ; both combine for producing a saturated resource associated with the polarity $  ; labels associated with the polarity = are neutral in this process  . In a polarized formalism , the saturated structures are those that have all labels associated with the polarity = or $  . We call them neutral structures . The composition of structures is guided by a principle of neutraliza-tion : every positive  ( negative ) label must unify with a negative ( positive ) label . 
The polarization of a formalism must preserve its generative power : the language that is generated by a polarized grammar must be the same as that generated by the initial non-polarized grammar  . This property of ( weak and even strong ) equivalence is guaranteed if the polarized formalism is isomorphic to the non-polarized formalism from which it stems  . Formally , given a grammatical formalism F , any formalism Fpol with a morphism pol : F?F pol is a polarization of F if :  ( i ) For any structure S ? Struct F , pol ( S ) results from associating each label of S with one of the polarities : +  ,  ? ,  = , $; in others words , labels of Fpol a repairs ( p , l ) with papolarity and la label of F . The set of polarities + ,  ? ,  = , $ is equipped with the operation of unification and the subsumption order defined by Figure  1  . The operations of subsumption and unification on pairs are the pointwise operations  . That is , for any pairs ( p , l ) and ( p ? , l ?) , ( p , l)v(p ? , l ?) iff pvp ? and lvl ? ( p , l ) unionsq(p ? , l ?) = ( punionsqp ? , lunionsql ? )   ( ii ) SatF polis constituted of the neutral structures of Struct Fpol  . 
( iii ) pol is an isomorphism whose inverse mor-phism is the function that ignores polarities and keeps invariant the rest of the structure  . 
Let us illustrate our purpose by taking again our two examples of formalisms  . 
? For LTAG ( see figure 2) , polconsists in labelling the root of elementary syntactic trees with the polarity + and their non terminal leaves  ( substitution and foot nodes )  ? + = $ ? $ ? + $ + = ? + = $ $ $ = ? ? + ? ? ? $ Figure  1: unification and subsumption between polarities poldestr 

N*Adjred



Adj N?red N+,N+,N ?, N?red,Adj
Figure 2: Syntactic structures associated with the adjective red in LTAG  , LTAGpol , ( LTAGpol ) destr with the polarity ? . In every pair of quasi-nodes , the top quasi-node is labelled with the polarity ? and the bottom quasi-node is labelled with the polarity +  . With respect to the classical presentation of LTAG  , initial trees must be completed by an axiom with two nodes of the type sentence : a root with the polarity = and its unique daughter with the polarity ?  . In this way , polestablishes a perfect bijection between the saturated structures of LTAG and the neutral structures of LTAGpol  . The rules of adjunction and substitution of Rules LTAG polmimic the corresponding rules in LTAG  , taking into account polarities . We add a third composition rule , a unary rule which identifies the two quasi-nodes of a same pair  . It is routine to check that pol is a polarisation . 
? In LG ( see figure 3) , polarization is already present explicitly in the formalism : negative formulas and subformulas are input formulas  , hypotheses whereas positive formulas and subformulas are output formulas  , conclusions . 
4 Abstraction of polarized grammatical formalisms The originality of abstracting polarized formalisms is to keep a mechanism of neutraliza -tion between opposite polarities at the heart of the abstract formalism  . Furthermore , we can choose different levels of abstraction by keeping more or less information from the initial formal- 
S+NP ? eats
NP ?( NP\S)/NP eats polS + , NP ? , NP ? eats destr Figure 3: Syntactic structures associated with the transitive verb eats in LG  , LGpol , ( LGpol ) destrism . 
As an example , we propose a high degree abstraction , destructuring . Destructuring a polarized formalism consists in ignoring the structure from the initial syntactic objects to keep merely the multisets of polarized labels  . Formally , given a polarized formalism P , we define the formalism P destras follows : ? Any element M of StructP destr is a multiset of labels  . All elements of M are labels of P , except one exactly , the anchor , which is a neutral string . 
? SatP destrismade up of multisets containing only neutral and saturated labels  ; ? The projection PhonP destr returns the label of the anchor  . 
? Rules Pdestr has two neutralization rules . A binary rule takes two multisets M1 and M2 from Struct P destras inputs ; two unifiable labels + l1 ? M1 ( M2 ) and ? l2 ? M2 ( M1 ) are selected . The rule returns the union of M1 and M2 in which + l1 and ? l2 are unified and the two anchors are concatenated . 
The only change with the unary rule is that this operates inside the same multiset  . 
A morphism destr is associated to P destr ( see figure 2 and 3 ) : it takes any structure S from Struct P as input and returns the multiset of its labels with an additionnal anchor  . This anchor is the neutral string PhonP ( S ) if this one is defined . 
An important property of P destr is that it is not sensitive to word order : if a sentence is generated by a particular grammar of P destr  , by permuting the words of the sentence , we obtain another sentence generated by the grammar  . Destructuring is an abstraction that applies to any polarized formalism but we can design abstractions with lower degree which are specific to particular formalisms  ( see Section 6 )  . 
5 Application to lexical disambiguation
Abstraction is the basis for a general method of lexical disambiguation  . Given a lexicalized grammar G in a concrete formalism C  , we consider a sentence w1 .   .   . wn . For each 1 ? i ? n , let the word wi have the following entries in the lexicon of G : Si  , 1 , Si , 2  .   .   . Si , mi . A tagging of the sentence is a sequence S1 , k1 , S2 , k2 .   .   . Sn , kn . 
We suppose now that we have given an abstraction morphismabs : C ? Cabs  . AsL(G ) ? L(abs(G )) , any tagging in abs ( G ) which has no solutions comes from a bad tagging in G  . As a consequence , the methods we develop try to eliminate such bad taggings by parsing the sentence  w1w2   .   .   . wn within the grammar abs(G ) . 
We propose two procedures for parsing in the abstract formalism : ? an incremental procedure which is specific to the destructuring abstraction  , ? a bottom-up procedure which can apply to various formalisms and abstractions  . 
5.1 Incremental procedure
We choose polarization followed by destructur-ing as abstraction  . In other words : abs = destr?pol . Let us start with the particular case where unification of labels in C reduces to identity  . In this case , parsing inside the formalism Cabs is greatly simplified because composition rules reduce to the neutralization of two labels + l and ? l  . As a consequence , parsing reduces to a counting of positive and negative polarities present in the selected tagging for every label l : every positive label counts for  +1 and every negative label for ?1  , the summust be 0 ; since this counting must be done for every possible tagging and for every possible label  , it is crucial to factorize counting . For this , we use automata , which drastically decrease the space ( and also the time ) complexity . 
For every labell of C that appears with a polarity + or ? in the possible taggings of the sentence  w1w2   .   .   . wn , we build the automaton Alas follows . The set of states of Alis [0 . .n]?Z . 
For any state ( i , c ) , i represents the position at the beginning of the word  wi+1 in the sentence and c represents a positive or negative count of labels l  . The initial state is (0 ,  0) , and the final state is ( n ,  0) . Transitions are labeled by lexicon entries Si,j . Given any Si , j , there is a transition ( i ? 1 , x )
Si , j ? ?( i , y ) if y is the sum of x and the count of labels l in the multiset destr  ( Si , j) . 
Reaching state ( i , c ) from the initial state (0 ,  0 ) means that ( a ) the path taken is of the form S1 , j1 , S2 , j2 ,   .   .   .   , Si , ji , that is a tagging of the first i words ,   ( b ) c is the count of labels l present in the union of the multisets abs  ( S1 , j1) , abs(S2 , j2) ,   .   .   . , abs(Si , ji) . 
As a consequence , any path that leads to the final state corresponds to a neutral choice of tagging for this label l  . 
The algorithm is now simply to construct for each labell the automaton Aland to make the intersection A = ? l?LabelsAlof all these automata  . The result of the disambiguation is the set of paths from the initial state to the final state described by this intersection automaton  . Notice that at each step of the construction of the intersection  , one should prune automata from their blind states to ensure the efficiency of the procedure  . 
Now , in the general case , unification of labels in F does not reduce to identification  , which introduces nondeterminism in the application of the neutralization rule  . Parsing continues to reduce to counting polarities but now the counting of different labels is nondeterministic and interdependent  . For instance , consider the multiset + a , + b , ? a unionsq + b of three different elements . 
If we count the number of a , we find 0 if we consider that + a is neutralized by ? a unionsq b and  +1 otherwise ; in the first case , we find +1 for the count of b and in the second case , we find 0 . 
Interdependency between the counts of different labels is very costly to be taken into account and in the following we ignore this property  ; therefore , in the previous exemple , we consider that the count of a is 0 or +1 and the count of b is also 0 or +1 independently from the first one . 
For expressing this , given a label l of F and a positive or negative label l ? of Fpol  , we define Pl(l ?) as a segment of integers , which represents the possible counts of l found in l ?  , as follows : ? if l ? is positive , then Pl(l ?) = ? ? ?
J 1 , 1 K if l v l ?
J 0,0 K if lunion sql ? = ?
J0 , 1K otherwise ? if l ? is negative , then Pl(l ?) = ? ? ?
J ? 1, ?1K if lvl ?
J 0,0 K if lunion sql ? = ?
J ? 1, 0 K otherwise
We generalize the function Pl to count the number ollabels l present in a multiset abs  ( S ) :
Pl(S ) = Jinf , supK with:inf = ? l ? ? abs ( S ) min ( Pl ( l ? ) ) sup = ? l??abs ( S ) max ( Pl ( l ? ) )
The method of disambiguation using automata presented above is still valid in the general case with the following change in the definition of a transition in the automaton Al : given any Si  , j , there is a transition ( i ? 1 , x )
Si , j ? ?( i , y ) if y is the sum of x and some element of P l ( Si , j) . 
With this change , the automaton Albecomes nondeterministic . 
The interest of the incremental procedure is that it is global to the sentence and that it ignores word order  . This feature is interesting for generation where the question of disambiguation is crucial  . This advantage is at the same time its drawback when we need to take word order and locality into account  . Under this angle , the bottom-up procedure , which will be presented below , is a good complement to the incremental procedure . 
5.2 Bottom-up procedure
We propose here another procedure adapted to a formalism C with the property of projectivity  . Because of this property , it is possible to use a CKY-like algorithm in the abstract formalism Cabs  . To parse a sentence w1w2 ? ? ? wn , we construct items of the form ( i , j , S ) with San element of Struct Cabs and i and j such that  wi+1   .   .   . wj represents the phonological form of S . We assume that Rules ( Cabs ) has only unary and binary rules . Then , three rules are used for filling the chart : initialization : the chart is initialized with items in the form  ( i , i+1 , abs(Si+1 , k )) ; reduction : if the chart contains an item ( i , j , S ) , we add the item ( i , j , S ? ) such that S ? is obtained by application of a unary composition rule to S  ; concatenation : if the chart contains two item ( i , j , S ) and ( j , k , S ?) , we add the item ( i , k , S ? ? ) such that S ?? is obtained by application of a binary composition rule to S and S ?  . 
Parsing succeeds if the chart contains an item in the form  ( 0 , n , S0) such that S0 is an element of SatCabs . From such an item , we can recover all taggings that are at its source if  , for every application of a rule , we keep a pointer from the conclusion to the corresponding premisses  . The other taggings are eliminated . 
6 Experiments
In order to validate our methodology , we have written two toy English grammars for the LG and the LTAG formalisms  . The point of the tests we have done is to observe the performance of the lexical disambiguation on highly ambiguous sentences  . Hence , we have chosen the three following sentences which have exactly one correct reading :  ( a ) the saw cut the butter . 
( b ) the butter that the present sawcut cooked well . 
( c ) the present saw that the man thinks that the butter was cut with cut well  . 
For each test below , we give the execution time in ms ( obtained with a PCPentium III , 600 Mhz ) and the performance ( number of selected taggings/number of possible taggings  )  . 
6.1 Incremental procedure
The incremental procedure ( IP ) results are given in Figure 4:
LGLTAG ms perf.ms perf.
( a )  1 3/36 3 3/96  ( b )  42 126/12 960 40 126/48 384  ( c )  318 761/248 832 133 104/1 548 288
Figure 4: IP with destr ? pol
One may notice that the number of selected taggings/total taggings decrease with the length of the sentence  . This is a general phenomenon explained in ( Bonfante et al ,  2003) . 
6.2 Bottom-up procedure
The execution time for the bottom-up procedure ( BUP ) grows quickly with the ambiguity of the sentence . So this procedure is not very relevant if it is used alone  . But , if it is used as a second step after the incremental procedure  , it gives interesting results . In Figure 5 , we give the results obtained with the destr abstraction  . 
Some other experiments show that we can im-
LGLTAG ms perf.ms perf.
( a )  2 3/36 9 3/96  ( b )  154 104/12 960 339 82/48 384  ( c )  2 260 266/248 832 1 821 58/1 548 288
Figure 5: IP+BUP with destr?pol prove performance or execution time with specific methods for each formalism which are less abstract than destr  . 
6.2.1 Tailor-made abstraction for LG
For the formalism LG , instead of complete de-structuring , we keep some partial structural information to the polarized label  . As the formalism is projective , we record some constraints about the continuous segment associated with a polarity  . In this way , some neutralizations possible in the destr abstraction are not possible any more if the two polarities have incompatible constraints  ( i . e . lie in different segments ) . This new morphism is called proj . The execution time is problematic but it might be controlled with a bound on the number of polarities in every  multiset5   ( see Figure 6 ) 
LG sentence Time(ms ) Perf.
( a )  2 1/36  ( b )  168 5/12 960  ( c ) with bound 623643/248832
Figure 6: IP+BUP with proj ? pol
Without bound for sentence ( c ) , the running time is over 1m in . 
6.2.2 Tailor-made abstraction for LTAG
For LTAG : a possible weaker abstraction ( called l tag ) consists in keeping , with each polarity , some information of the LTAG tree it comes from . Rather than bags where all polarized labels are brought together  , we have four kind of polarized pieces : ( 1 ) a positive label coming from the root of an initial tree  ,   ( 2 ) a negative label coming from a substitution node ,   ( 3 ) a couple of dual label coming from the root and the foot of an auxiliary tree or  ( 4 ) a couple of dual label coming from the two parts of a quasi-node  . Rules in this formalism reflect the two operations of LTAG  ; they do not mix polarities relative to adjunction with polarities relative to substitution  . Figure 7 shows that the execution time is improved ( wrt . Figure 5) . 

The examples we have presented above should not be used for a definitive evaluation of particular methods  , but more as a presentation of the flexibility of our program : polarizing grammatical formalisms for abstracting them and parsing  5This bound expresses the maximum number of syntactic dependencies between a constituent and the others in a sentence  . 
LTAGms perf.
( a )  6 3/96  ( b )  89 58/48 384  ( c )  272 54/1 548 288
Figure 7: IP+BUP with l tag ? pol in the resulting abstract frameworks for disambiguating lexical selections  . We have presented one general tool ( the destructuring abstraction ) that may apply to various grammatical framework . But we think that abstractions should be considered for specific frameworks to be really efficient  . One of our purpose is now to try the various tools we have developped to some large covering lexicons  . 
So far , we have not taken into account the traditional techniques based on probabilities  . Our point is that these should be seen as an other way of abstracting grammars  . Our hope is that our program is a good way to mix different methods  , probabilistic or exact . 

G . Bonfante , B . Guillaume , and G Perrier.
2003. Analyse syntaxique e?lectro statique.
Traitement Automatique des Langues . To appear.
P . Boullier . 2003. Supertagging : a Non-
Statistical Parsing-Based Approach . In 8th International Workshop on Parsing Technologies ( IWPT ?03 )  , Nancy , France ,  2003 , pages 55?66 . 
P . de Groote .  1999 . An algebraic correctness criterion for intuitionistic multiplicative proofnets  . Theoretical Computer Science , 224:115?134 . 
A . Joshi and B . Srinivas .  1994 . Disambiguation of superparts of speech ( or supertags ) : Almost parsing . In COLING ?94, Kyoto . 
S . Kahane .  2004 . Grammaires d?unification po-larise?es . In TALN?2004, Fe`s , Maroc . 
M . Moortgat .  1996 . Categorial Type Logics . In J . van Benthem and A . ter Meulen , editors , Handbook of Logic and Language , chapter 2 . 

G . Perrier . 2003. Les grammaires d?interaction.
Habilitation a ` diriger des recherches , Universite ? Nancy 2 . 
K . Vijay-Shanker .  1992 . Using description of trees in a tree adjoining grammar  . Computational Linguistics , 18(4):481?517 . 
