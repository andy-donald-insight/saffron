SYNTACTICNORMALIZATION OFSPONT ANEOUSSPEECH*
Hagen Langer , University of Bielefeld , W-Germany

This paper presents some techniques that provide a
standard parsing system for the analysis of ill -formed utterances  . These techniques are feature generalization and heuristically driven deletions  . 

Generally the development of grammars , formalisms and natural language processors is based on written language data or  , sometimes , not real data at all , but invented ' example sentences ' . This holds for both computational and general linguistics  . Thus many parsing systems that work quite well for sentences like la  . and lb . fail , if they get applied to the authentic data in 2a . and 2b . : la . 



die Grund for mist nichteckig the basic form is not angular das blaue habeichals Waage auf dem  gr0nen llegen I have got the blue onelying upon the OAT green OAT 
One DAT like a balance die Grund die Grund form sind is nich Isnle heckig the the basic the basic form are is not is not angular das blaue habichale Waageaul das  gr0ne liegen I have got the blue onelying upon the ACC green Accone ACC like a balance To native recipients the utterances in  2  . appear to be more or less defective , but interpretable x pressions . 
Moreover , the interpretation of 2a . or 2b . might require even less effort than , for instance , understanding an absolutely grammatical'garden path sentence '  . 
Since utterances like 2a . and 2b . occur quite frequently in spontaneous speech , an approach to parsing everyday language has to provide techniques that cover repairs  , ungrammatical repetitions (2a . ), case-assignment violation (2b . ) , agreement errors and other phenomena that have been summarized under the label'iU-formed'in earlier research  ( Kwasny/Sondheimer "1 am indebted to Dafydd Gibbon , Hans Karlgren and Hannes Rieser for their comments on earlier drafts of this paper  . This research was supported by the Deutsche Forschungsgemeinschaft  . Some aspects are discussed in more detail in Langer  1990  . 
1981 , Jensen et al 1983 , Weischedel/Sondheimer 1983 , Lesmo/Torasso 1984 , Kudo et al 1988) . 
Though the present paper will adhere to this terminology  , it should be emphasized that it is not presupposed that there are any general criteria precise enough to tell us exactly whether some utterance is ' ill-formed'relative to a natural language  . Let us assume , instead , that some utterance U is ' ill-formed ( defective , irregular .   .   .   .   ) with respect to a grammar G'iff U is not a sentence of the language specified by G  . Since , for instance , repairs exhibit a high degree of structural regularity  ( el . Schegloff et al 1977 , Lever 1983 , Kindt/Laubenstein in preparation ) one might prefer to describe them within the grarxma ar and not within some other domain  ( e . g . within a pro-duction/perception model ) . Therefore the concept ' ill--formed'is used as a relational term that always has to be redefined with respect o the given context  . 
There have been two main directions in the prior research on ill-formedness  . The one direction has focussed on the problem of parsing ill-formed input in restricted domain applications  , such as natural language interfaces to databases or robot assembly systems  ( Lesmo/Torasso 1984 , Selfridge 1986 , Carbonell/Hayes1 . 987) . Though the techniques developed in that field seem to be quite adequate for the intended purposes  , the results are not directly transferable to the interpretation of spontaneouspeech  , since the restrictions affect not only the topical domains but also the linguistic phenomena under consideration : e  . g . the CASPAR parser ( cf . Carbonell/Hayes 1987 ) is restricted to a subset of inlperatives , Lesmo/Torasso ( 1984 ) achieve interpretations for ill-formed word order only at the price of neglecting long distance dependencies tc  . 
The other main direction has been the ' relaxation '- approach  ( Kwasny/Sondheimer 1981 , Weischedel/Sondheimer 1983) . The basic idea is to relax those grammatical constraints an input string does not meet  , if a parse would fail otherwise . The main problem of this approach is that relaxing constraints  ( i . e . ignoring them ) makes a grammar less precise . Thus , for instance , a noun phrase that lacks agreement in number is analysed as a noun phrase without number and it remains unexplicated how this analysis might support a further interpretation  . Surprisingly , none of these papers concentrates on real life 180   1 ~ q ~ ontaneous speech ( most of them are explicitly eon~cerned with written man-machine communication  )  . 
The present paper focusses the problem of norm - Mization  , i . e . how to define the relation between ill- , brined utterances ( e . g . 2a . and 2b . ) and their wellformed'counterpa~s'(la . and lb . ) . A sentence is an adequate normalization of an ill -formed utterance  , if it corresponds mour intuitions about what the speaker might have intended to say  . This is , of course , not observable , but a request for repetition ( which typically does not give rise to a literally repetition in case of ~ nutterance like  2a   . ) might serve as a suitable test . 
In the present approach normalization is based on ~ olely syntactic heuristics  , not because syntactic in-t brmation is regarded to be sufficient  , but as a starting point for further work . Thus , the normalizations achieved on the basis of these heuristic serve as de-hlult interpretations that have to be evaluated using additional intbrmation about the linguistic and situational context  . The empirical background is a corpus of authentic German dialogues about block worlds that has been recorded t br the study of coherence phenomena  ( cf . For schergruppe Koh@enz\[ed . \] 1987) . 
I will discuss three heuristics that are used in an experimental normalization system  , called NOBUGS ( NOrmalisierungskomponenteim Bielefelder Unifika -tions basier ten Analyse systemf/Jr Ges prochene Sprache normalization component of a Bie ! ef eM tmifica-tion-based  , ; peech analysis system ) . The core of NOBUGS is a left-corner parser that interprets a GPSG-Iike formalism encoded in DCG notation  . The grammars used with NOBUGS are very restrictive and exclude everything that is beyond the bounds of written standard German  . But in combination with the heuristics I will discuss now the system is capable of handling a wider range of phenomena including morphosyntactic deviations  , explicit repair and ungrammatical repetitions . 
MORPHO-SYNTACTICDEVIATIONS
Morphosyntactic deviations make up a considerable proportion of errors both in spoken and written German  ( German has a much more complex inflect-ional morphology than English  )  . 
The basic principle of this approach to normalization is as follows : ' Fry to find out which properties of a given input string make a parse fail and use the given grammatical knowledge to alter the input string minimally so that it is assimilar asl~ssible to its initial state but without he properties that caused the thilure  . 
What is meant by that can easily be seen if we consider an example where the property that makes a parse fail is evident  , e . g . the string ' John sleep ' , which lack stile NP-VP-agreement concerning person and mtmber that is required by the following rule:cat=Seat=NP cat=VP person = X ~ ~ ease = nompers on = X ~ num = X  2 person = X ~ num = X ~ num = X2 This rule is not applicable to ' John sleep ' , since there are no lexieal entries for ' John ' and ' sleep '  , respectively , that have unifiable specifications for person and number  , and this makes the whole parse fail . 
The strategy to account for strings like ' John sleep ' consists of three steps : Step  1: Collect all lexical entries that match with the words of the input string and generalize them by substituting variables for their morpho-syntaetic specifications  ( ease , number , gender etc . ) . 
S tep2: Parse the string using the generalized lexical entries instead of tim completely specified entries  . 
S tep3: If the parse with generalized specifications i successful  , the problem with the input string is mor-pho -syntactie  ( agreement error or ease-assignment violation )  . Collect all preterminal categories ( most of them still contain variable morphosyntactic specifications  ) and try to unify them with full-specified lexical entries  . At least one matching entry will belong to some item different from the corresponding word in the input string  . In that case replace the original word by the matching item  . If there are many different sets of matching entries choose the one that requires the least number of substitutions and output it as the default normalization  ( if there are many sets of matching entries that require the same least number of substitutions the normalization is ambigous  . In that case output all of them ) . 
Returning to our example string ' John sleep ' , let us assmne that the grammar consists just of the rule stated above and the following lexical entries : 
Jol ) n : slee F .
sleeps : person = 3 , num=so , cat = rip , case=norn person = 3 , num , , pl . cat = vp person = 3 , num=sg , cat = vp Generalizing the lexical entries for the input string ' John sleep ' will produce two new entries : 
John : sleep : person = MAR1 , hum=VAR2 , cat = np , case=VAR3 person=VAR 4 , num=VAR 5 , cat = vpAparse using these entries will be successfld  . The application of the rule unifies the variable specifica-2   181 dons for nmnber and person and instantiates case nominative in the NP  . The preterminal categories resulting from the parse are : person = VARI person = VARInum =  VAR2 num = VAR2 cat = np cat = vp case : nomThough the crucial specifications  ( person and num ) are still variable the difference is now that there are the same variables in both categories  . The ( only ) set of lexical entries that match with these preterminal categories requires the replacement of's leep'by'sleeps ' and thus ' John sleeps ' is the normalization of ' John sleep '  . 
Note that this strategy is not , in principle , limited to morphosyntactic features . It might be useful for phonological and semantic normalization  , as well . 
EXPLICZTREPAIR
When people detect an error during an utterance they often try to correct it immediately  . This , in general , makes the utterance as a whole ungrammatical . The structure of an utterance containing a self repair is often : Left context-reparandum- repair indicator-reparans right context  . 
The reparandum is the part of the utterance that is to be corrected by the reparans  . Typical repair indic-ators are interjections like ' uhno '  , ' nonsense ' , sorry ' etc . The following example from our corpus shows that structure  ( note that the left context is empty in the original German version  ) : Denlinke no h~uatsch_den rotons tells tdu links hinrel ~ a randum indicator reparans right contox ~ You  , put the ! ef~oneeh nonsense the redone to the left left c  . reparandum indicator reparans right context A plausible normalization of this utterance would be ' Den rotens tells tdu linkshin '  ( ' You put the redone to the left 3 . This normalization differs from the original utterance in that the reparandum and the repair indicators have been deleted  . The strategy to cover this type of repair is to s can the input string w ~ w v  . .w . 
until a repair indicator sequence w~w~?r . .wj is found (1 < i < j < n ) . If there is such an explicit signal , then there probably is something wrong immediately before the repair sequence  . But it is not clear what the reparandum is . Possibly the reparandum is just the word immediately before the repair indicator sequence or a longer substring or even the whole substring w~wv  . .w~_ ~ . Which deletion of a substring WkWk + ~ . . . Wj gives a grammatical sentence can only be decided by the grammar  . Thus it is necessary to parse the results of the alternative deletions beginning with wl  . . . w  ~ . 2 wj+t . . . w . and incrementing the length of the deleted suh string until the parse succeeds  . If the deletion of a substring wkw ~+, . .wj makes a parse successful and if there is no other deletion of a substring w ~ w ~+ l  . . . wj such that k < 1 then wtw 2 . . . wk_~wj+~wi42 . . . wn is the normalization of the input string . 
If applied to the utterance ' You put the left one eh nonsense there done to the left ' the first deletion gives ' You put the left there done to the left'which is not accepted by the parer  . The second alternative tried ( ' You put the there done to the left ' ) fails , too . 
But the third attempt ( ' You put there done to the left ' ) is accepted by the parser and thus considered as the normalization of the original utterance  . 
UNGRAMMATICAL REPETITIONS
Ungrammatical repetitions of single words or longer stretches occur quite frequently in spontaneous speech  . 
As long as a sequence is repeated completely and without any alteration it is easy to detect the redundant duplication and remove it from the input string to get a normalized version  . The problem is with incomplete repetitions and repetitions that introduce new lexical items : Some blocks some red blocks are small  , \/\/ part 1 part 2 Some red some blue blocks are small . 
\__/\__/partIpart2
The deletion of the substrings indicated as ' part  1' in the utterances above , respectively , would yield a suitable normalization . Utterances of this kind are in many respects like the explicit repairs discussed above  , but they lack indicators . Typically , part 2 is similar to part 1 in that at least some words occur in both substrings  . Moreover , part 1 and part 2 often belong to the same category ( e . g . NP in the utterances above ) . This similarity motivates the following heuristic : The input string  wlw2  . . . w ~ is scanned for two different occurrences , ayw ~ and wj(1_<wI<wi<w , ) , of the same lexical item . w ~ and wj are permitted to differ in their inflectional properties  , since an unsuitable inflection of w ~ might have been the reason to repeat it in proper inflexion as wj  ( e . g . 
' He takes took a block ') . If such a repetition is 182   3 fbund the substring beginning with the first occurrence up to the word immediately before the second occurrence  ( i . e . w~w~+, . . . wj . ~) is parsed . If the parse is ~ succesful and yields some category C for the substring  , the next step is to find a prefix of w j w j + a . . . w , that belongs to the same category C . 
If such a prefix exists and wtw 2 . . . w ~_ t w j w j + ~ . . . w , is accepted as a grammatical sentence it is considered to be the suitable normalization  . 
Let us apply this strategy to the utterance ' Some blocks somered blocks are small '  . Scanning this input string from the left to the right will immediately find the repeated lexical item ' some '  . The parse of the substring ' Some blocks ' results in an NP and thus a prefix of ' some red blocks are small'is searched for which is also an NP  . Such a prefix is found ( i . e . 
' somered blocks ' ) and therefore'somered blocks are small'is tested if it is a grammatical sentence and  , indeed , it is . 
RESULTS , CONCLUSIONS , FURTHERTASKS
The normalization strategies outlined in this paper make a/given standard parsing system applicable to certain language phenomena that occur frequently in spontaneous speech  , but deviate from the standards of written language  . Additional rules , special grammar formalisms or fixed parsing algorithms are not requir-ed  . 
If the parse succeeds , the analysis assigned to a deviating input is not only some partial structure description  , but a wellformed sentence including its complete syntactic structure  . 
Preliminary tests have shown that the normalizations achieved by the strategies discussed in this paper are plausible default interpretations in most cases  . Bad normalizations result from the lack of phonological  , semantic and world knowledge . A typical example is ' Take a red block oh no blue block ' which gets incorrectly normalized into ' Take a red blue block '  , if the grarn mar accepts ' block ' being specified by two different color adjectives  . If it does not , trying the next alternative according to the explicit-repair strategy described above will yield the most plausible result'Take a blue block '  . Another way to avoid the wrong normalization is to consult additional phonological infomlation about the input string  . It is very probable that there is a contrastive stress upon ' blue ' in the input utterance  . Let us assume the rule : if there is a word with contrastive stress in a reparans sequence then there must be a suitable word in the repar and mn sequence to which it is in contrast  . This implies that ' red'must be part of the reparandum  ( and thus has to be deleted ) and rules out the wrong norm-alization ' Take the red blue block '  . A further task will be to find out how additional semantic and phonological intormation both in the grammar and in the normalization strategies can be used to make the normalization results more reliable  . 

Carbonell , J . G . /Hayes , P . J . : Robust parsing using multiple construction -specific strategies  . In : Bolc , Leonard\[ed . \]: Natural language parsing systems . 
Berlin 1987 . pp .  132 .   ( Springer series symbolic computation-artificial intelligence  )  . 
For schergruppe Koh ~ iren z\[ed . \]: " nG ebit deoder was "- Datenzum Diskurs fiber Modellwelten  . KoLiBri-
Arbeitsbericht 2. Bielefeld 1987.
Jensen , K . /Heidorn , G . E . / Miller , L . A . /Ravin , Y . : Parse fitting and prose fixing : getting a hold on ill-formedness  . In : AJCL9 (1983), 147-160 . 
Kindt , W . /Laubenstein , U . : Reparaturen und Koordi-nations konstruktionen . KoLiBri-Arbeitsbericht 20 . 
( In preparation).
Kudo , I . / Koshino , H . /Chung , M . / Morimoto , T . : Schema method : A framework for correcting grammatically ill-formed input  . In : COLING 1988, 341-347 . 
Kwasny , S . C . /Sondheimer , N . K . : Relaxation techniques for parsing ill-formed input in natural language understanding systems  . In : AJCL 7(1982), 99-108 . 
Langer , H . : Syntaktische Normalisierungges prochener Spraehe  . KoLiBri-Arbeitsbericht 23 . Bielefeld 1990 . 
Lesmo , L . /Torasso , P . : Interpreting syntactically ill-formed sentences . In : COLING 1984, 534-539 . 
Levelt , W . J . M . : Monitoring and self-repair in speech . 
In : Cognition 14 (1983), 41-104.
Schegloff , E . A . /Jefferson , C . /Sacks , H . : The preference for self-correction in the organization of repair in conversation  . In : Language 53 (1977), 361-382 . 
Selfridge , M . : Integrated processing produces robust understanding  . In : CL 12(1983), 161-177 . 
Weischedel , R . M . /Sondheimer , N . K . : Meta-Rules as a basis for processing ill-formed input  . In : AJCL 9(1983), 161-177 . 

