Toward the " At-a-glance " Summary:
Phrase-representation Summarization Method
Yoshihiro UEDA , Mamiko OKA , Takahiro KOY AMA and Tadanobu MIY AUC Hl
Industry Solutions Company , Fuji Xerox ~ Co . , Ltd . 
430 Sakai , Nakai-machi , Kanagawa 259-0157, JAPAN
Ueda . goshihiro , oka . mamiko , Koyama . Takahiro , Miyauchi . Tadanobu@fujixerox . co . jp

We have developed a summarization method that creates a snmmary suitable for timp  , ' ocess of sifting information retrieval results . Unlike conventional methods that extract iln portant sentences  , this method constructs short phrases to reduce the burden of reading long sentences  . We have developed a prototype summarization system tbrJapanese  . Through a rather largescale task ~ based experiment  , he sumnmry this system creates proved to be effective to sift IR results  . This summarization method is also applicable to other languages such as English  . 

Sulnmaries are used to select relevant information from information retrieval results  . The goal of sunmmrization for such " indicative " use is to provide fast and accurate judgement  . 
Most automatic summarization systems adopt the " sentence selection " metho & which gives a score to eve ~ sentence on the basis of its charac-  . 
teristics , such as word frequency , the position in which it appears , etc . and selects sentences with high scores . 
Tim sentences collected in such a way tend to be so long and complex that the reader must reconstruct imstructure while reading them  . 
Reading such sentences involves some annoy-ante.
Our aim is to reduce this burden by provkling an " at-a-glance " summary  . 
Phrase-representation summarization is a method to create the " at-a-glance " summary for the Japanese language  , ttere we present the concept , the algorithm , and ewihiation of the efficacy of the summary produced by a prototype based on this method  . Extension to English is also discussed . 
1 The Concept
Examples of an "' at-a-glance '" summary are the headlines of news articles  . The headline provides intbrmation tbr judging whether the article is to be read or not an & in this sense  , it is really ?? indicative . " The characteristics are : ? Brevity ( short in length ) ? Simplicity ( less embedded sentences ) We use "' pll rases " to represent hesimplicity characteristic I and set our goal to create phrase-represented summaries  , which provide the reader with an outline of the document  , avoiding reading stress by enumerating short phrases containing the important words and concepts composed from these words  . 
The l nethod we adopted to achieve this goal is to construct such phrases from the relations between words rather than extracting important sentences fl ' om the original document  . 
2 Summarization Method 2 . 1 Outline of the Algorithm Here we give a short description of the ot  , tline of tiffs method using the example shown in Fig  .  1 .   2 i  The word "' phrase " used here is not of tile linguistic sense but an expression tbr "' short " and " sinaple  . "In Japanese , there is no rigid distinction between " phrase " and "' clause  . " - ~ Intiffspaper , Japanese words are represented in English as much as possible  . The words left in Japanese arc shown in italics , such as -~ a " ( a particle for AGENT ) , " jidai '" (" era ") , etc . Each relation name is constructed from a Japanese pailicle and its function  ( shown as a case name or an equivalent l- ; nglish U . S . top compa : ! v . PICORP's CEOK en Ono said that . .  . 
(b ) analysis graph & (1) analysis of relations . . . . . . . ~ ~--~( ;,', , enF ~, ir(2) selection of .  / , ?  .   .   .   .   .   .   . " nioite " - AT ~ core relation m-FQ\[- "1 "' ha'-IHEM\[=~'~\]venture ~'\ [ PICORPj ' -- I  .   .   .   .   .   . erom--71 ent4 , I ,   , " no-ur ! protection I /'- .  '  . . . "- "- I , , , , ~ t "- ~\] license\[, . -larmouncedl\[t_ecnnomgyI " . ,o"-OBJ ' ~ ' ' - I , II ~ (3) Addition of relations .   .   .   .   .   .   . ni'-DAT(c ) obtained phrase . ~  ( 4 ) generation PICORP licenses environment pro tection technology to AMICOI Fig  .   1 : Outline of phrase-representation summarization The method consists of the Efllowing tbur major steps :  ( 1 ) Syntactic analysis to extract he relations between words  ( 2 ) Selection of the core relation ( 3 ) Adding relations necessaD ' for the unity of the phrase's meaning  ( 4 ) Generating the surface phrase from the constructed graphFirst  , the sentences in the given document are analyzed to produce directed acyclic graphs  ( DAGs ) constructed fi'om relation units , each of which consists of two nodes ( words ) and an arc ( relation between tim words )  . Each node is not only a single word but also can be a word sequence  ( noun group )  . 
Then an important relation is selected as a " core " relation  . In F'ig . l , the arc connecting the two shaded nodes is selected as the " core  . " The core relation alone carries insufficient information to convey the content of the original docunaent  . Additional arcs ( represented by preposition ) . 
double lines ) are attached to narrow the infornm- . 
tion the phrase supplies.
The tbllowing short phrase can be generated fi'om the selected nodes and arcs in the graph : P ICORP licenses  ( its ) environment protection technology to AMICO .   3 Phrase-representation summarization enutner-ates such short phrases to give the readers enough infornmtion to grasp the outline of a document  . 
This algorithm is explained in the next section.
2 . 2 Fur ther descr ip t ion o f each s tep The steps shown in the previous section consists of a cycle that produces a single phrase  . The cycles are repeated until the generated phrases satisfy a predefined condition  ( e . g . the length of the summary ) . The scores of the words used in the cycle are reduced by a predefined cut-down  ; This short sentence can be expressed as a phrase intt ~ elinguistic sense in \[  . ; nglish : I~IC ( )RI ) ' slicensing ( its ) environment protection technology to AMIC ( ) . 
8 79 ratio to avoid fi'equent use of the same words in the summai T  . 
The basic algorithm is shown in El , , " ~
Relation AnM , . ~' is
Syntactic analysis is applied to each sentence ill the document to produce a DAG of the relations of words  . We use a simple parser based on pattern matching ( Miyauchi , et al 1995) , one of whose rules always judges each case dependent on its nea  , ' est verb . Some of them is analysis will be hidden by " ambiguity packing " ill the " additional relation attachment " step  . 
Relation Scoring
All importance score is provided for each relation unit  ( two nodes and an arc connecting them )  . 
First , every word is scored by its importance.
This score is calculated based on tiletf*IDF wdue  ( Salton ,  1989) 4 . 
Then , the relation score is calculated as follows :
Score = Srel*N1+W2"S2)
Here , SI and $2 are tile scores of the two words connected by relations  . The score of a word sequence is calculated by decreasing the sum of the scores of its constituent words according to tile length of the word sequence  . 
Wl and W2 are the weights given to each word.
Currently , all words are equally treated ( WI---
W2=1).
Srel is the importance factor of tile relation.
The relations that play central roles ill the meaning  , such as verb cases , are given high scores , and the surrounding relations , such as "' AND " relations , are scored low . Tile relation scores for modifier-modified relations such as adverbs are set to  0 to avoid selecting them as the core relations . 
Core relation selection
The relation unit with tile highest score among all relations is selected as the " core relation  . "
Additional relation attachment
The inlbrmation that the core relation carries is usually insufficient  . Additional relations arc attached to make the information tile phrase ? ~ ll  ) F is calculated from I million WW ~ , V documcnts gathered by a Web search engine . 
Doct lnlent__.~Input
Relation Analysis 1
Relation Scoring \]
I\[Core relation 1 \[ selection\[Relation\[\[Generation of I\ [_  . surface ~ hrases I
Output\[Snlnnlary \]
Fig . 2 Basic flow of the algorithm supplies rnore specific and to give the reader sufficient information to infer the content of the original doculnent  . " File following relations are a part of the relations to be attached  . 
@ Mandatory cases
Relations that correspond to mandatory cases are attached to verbs  . Mandatory case lists are defined for verbs except for those that share tile common mandatory case list  , which includes ?' ga'-AGENT , % vo "- OBJ and " ni "- DATIVE . " Ha " -' ftfEME,"mo'- . ALSO , and null-marke relations are also treated as man -datory  , because they can appear in place of the mandatory relations  . 
Ex . ) AMICe"ga "- AGENT release -+ AMIC e " ga'-AGENT
PDA " wo'-OBJ release ( AMIC ereleases PDA . )@Noun modified by a verb In Japanese , the " verb-noun " structure repre- . 
sents an embedded sentence , and the noun usually fills some gap in the embedded sentence  , l ( ' the verb in the core relation ( noun--verb ) consists ot'sucl laverb-noun relation , the modified noun is also assumed to carry important information  , even if it does not t511 the mandatory case ( fl lough the case is not verb-llOtlll relation is attached to tile core  . 
Ex .) PDA " wo ".- OBJ release
PDA " wo "- OBJ release 0-THAT5AMICe ( AMICe that releases I :> DA ) 
PI)A"wo"-OBJ release-~PDA " wo "- OBJ release 0 . -Tt4ATpDs ! ( a plan to release PDA ) @ Anlbiguity packing The analysi . strees often contain error . < ; be--cause the pattern-base parser doesn't resolve ambiguities  . For exarn ple , the strtl Ctt lreV0- . TI-IATN 1" no'-OVN2(VingNl's N2)i , q ambiguous in Japanese ( V canr nodil ~ , /either N1 or N2 but the parser always aim - . 
lyzesN2 as modified ) ? lf'theV- . NI rehltioniv ; selected as the cole , the N1-N2 rehition is always attached to the core to include the pos-  . 
sible V-N2 relation.
il Modifiers of genericll OUllS
Tile concepts brought by generic rloun , ; such as < ~ mom f " ( thing) , + ~ koto "(< ~ that "' of that-clause) , ~ baai " ( case ) , ~ Tidai " ( era ) are not so specific that they usually acconlpany lnodifi-  . 
erstobe infbrmative , tlere such modifiers are attached to make them int brmatiwe  . 
l '; x . ) era " ni " . TIME emerge ' ~ U ~ " no " - . OFera"ni " . -TIME emerge ( emerge dirl the era of confi , isiorl ) 77 , rmimg tiancomlitio ~ , Judges whether tim surn nlarics created so far arc sufi-icient  . Curreritly the termination coriditior is defined by either the number of produced phrases or the total summary length  . 
Rescoring oj relation u
If the condition is not flll filled , thes ; esteps from selection of the core relation Must I . ) e repeated to create another phrase , tefi ) reselecting a new core , the scores of the words used in this cycle are reduced to increase the possibility for other words to be used in the next phrase  . Score reduction is achieved by multiplying tile predefined Ctll-dowll ratio R  ( 0 < It < 1 ) by the scores of the words used . l , >, ehition scores are recalculated us in . ~, the nov , word scores . 
Generation o.fsur ~ we phrases
Tiffs process produces I ) AGs each of ~ laich consists of one core relation and several attached iclations  . In , latmnesc , the surface phrases can be ea . , ; i l ) obtained by connect hlg the still ' ace string of the nodes in their original order  . See Chapter 5 for the generatioil method for \]\[: , nglish . 
3 The Prototype
Wc developed a prototype of the summarization system based on this algorithm  . The development language is Java and the system is working on 
Windows95/c ) 8/NT and Solaris 2.6 a.
The time consumed by summarization process is in proportion to the text length and it takes about  700 rnsec to generate a surnmal T for an Adsized document  ( 2000 Japanese characters ) using a PC with a Celeron processor ( 500Mtlz )  . Over 95% of the time is consumed in the relation analysis tep  . 
4 Evaluation
We have conducted an experiment to evahiate the system  . This section is a short sum rnaW of the expei + iment reportediri  ( ( ) ka and Uedar ,  2000) . 
The aim of a phrase--represented summary is to give fast and accurate sifting of lit results  . To evahiate whether the aim was achieved ? we adopted a task-based evahlation  ( Jing , et al 1998 , Mani , et al 1998) . One of the problems of those experiments using human subjects as assessors is in accuracy caused by the diversity of assessment  . 
To reduce the diversity , first we assign 10 sub . iects ( experiment participants ) fbreach suln nlary sample . Then unlber of subjects was just I or 2 in the previous task-based experiments . 
Second , we gave the subjects a detailed instruc--tion including the situation that led them to search the WWW  . 
4, 1 Experiment Method
The outline of the evahiation is as follows : 5   '0'" shows that the re~ll'e i1  ( ) particle ~ ; urany other \ ~ , ol'ds Colln ccting two ; ~ , old :-; .   , lapt trics ; edticSll't require anything like relative pi + o noun + < ~'  . lava and Solaris are the tra ( temarks of Sun Microsv stems . Windows and C cler on tll ' O the mldcmark ! ; of Microsoft and lntel , respedively . 
8 81 ? Assume an inlbrmation need and make a que Iw for the information eed ? Prep are simulated WWW search results with differentypes of summaries :   ( A ) first 80 characters , ( B ) important sentence selection ( Zechner ,  1996) , ( C ) phrase-represented summary , ( I )) keyword enumeration . The documents in the simulated search result set are selected so that the set includes an appropriate number of relevant documents and irrelevant documents  . 
? Have subjects judge from the summaries the relevance between the search results and the given int ' ormation need  . The judgement is expressed in t ' our levels ( from higher to lower : L3 , L2 , LI , and L0 , which is judged to be irrelevant ) . 
? Compare the relevance with the one that we assumed  . 
The documents the user judges to be relevant compose a subset of the IR results and it should be more relevant othe information eed than the IR results themselves  . Because we have introduced three relevance levels  , we can assume three kinds of the subsets ; L3 only , L3+L2 , and L3+L2+LI . The subset composed only from the documents with L3 judgement should have a high precision score and the subset including  L1 documents should get a high recall score . 
4.2 Result
Because recall and precision are in a trade ~ off relation  , here we show the result using fmeasure , the balanced score of the two indexes . 
2 * precision * recall f - - meaX l l l ' e = precision + recall The fmeasure averages of the experiment result of three different asks are shown in Fig  .  3 . 
It shows that the phrase-represented summaries ( C ) are more suitable t brsifting search results than any other summaries in all cases  . 
4.3 Discussion
The result can be explained using the number of summaries that contain clues to the information need  . Summaries consist in , , of short units ( phrases ( C ) and keywo Ms ( D ) ) are gathered from the wide range of the original text and accord-in  ,  . zlv have many chances to include the clues . 
The actual average numbers of summaries that phrase-represented Stltll nlal - ~ 
E1AFIBEIC liD,?:::Jif)t'ui:11
Eut.

Only L3L2L3L1L2+L3
Fig . 3 Experiment result contain the clues are 2 . 0, 4 . 3 and 4 . 7 for ( B ) sentence , ( C ) phrases and ( D ) keywords , respecotively , in spite that ( D ) keywords include more clues than any other samples  , they don't get a good tscore . The reason is considered to be due to the lack of information about the relations among keywords  . 
5 Applicability to Other Languages
Although this algoritlun was first developed for the Japanese language  , the concept of phrase ~ representation stmunarization is also applicable to other languages  . Here we show the direction toward its extension to t'nglish  . 
English has a clear concept of ~' phrase , " and simply connected words do not produce wellformed phrases  . I'h is require semantic analysis and generation from the semantic structure  . 
We will consider the following example again.
Ex . ) A venture company PICORP announced to license their environment protection technology to AMICO  , aU . S . top company . 
lf " PICORP " and " license " must be included in the summary and " announce " is not so important  , " PlCORP license ( s ) " is the core of the desired phrase . Generating it require sub . iect resolution o\["" license " and thus semantic level analysis is required  . Moreover , predicate-argument structures arc preferable to syntactic trees because the sub  . iect and the object are represented in the same level  , th lification gramt narflame work such as I , FG ( Kaplan and P , restmn . 1082) and tlPSG ( Pollard and Sag , t994) fulfill these requirements . 
Fig . 4 is a part of the analysis rcsuh represented in




VCOMP ' announce ( 1"SUBJ )   ( ? VCOMP ) '\[1\]\[PRED"PICORP"\]PRED'license ( i " SUBJ )   ( \[ OBJ )   ( tTOOBJ ) '
SUBJ\[11
OBJ\[PRED'environment protection technology'\]
TOEPPTO1OBJ\[PRED'AMICO'\]2$
SUBJ\[PRED " PICORP"\]
OBJ\[PRED'environment protection technology'\]
TO~PP 107\]
OBJ\[PRED ' AMICO'\]
PICORP licenses erlvironment protection technology to AMICe  . 
PICORP's licensing of environment protection technology to AMICe  . 
PICORP to license environment protection technology to AMICe  ( headline style ) Fig .   4: Analysis and generation of summary A score is calculated for each feature structure and the core feature structure will be selected by its score instead of selecting a core relation and attaching mall datory relations  . In the corel~mture structure , index\[1\] is replaced by % I , JBJ of the top l \] eatu restructure . 
( eneratin <, . > phrases t'r Olllthet\:ature structure requires templates ?  . Several pattern , <; c , an be selected io generate phrases :
V-ing ( gerund ) tbrm
ARGI's PRED--Ang ARG2 ' co ARG3 not in ' or mARGI's noun ( P R F , D ) o ? ARG2 to ARG3 to--infinitive l~l-nl
For ARGI to PRED ARG2 to ARG3
In this case , tile her in fOF lll ~" lqC () RP's license c , f the protection technology to AMIC ( )" is avoided because tile noun " qicense " lacks the meaning of " action " or "' event  .  '"  ( ) tiler rules specific to headlines such as ~' to -infinitive represents ' uture " Callal SO be hltroduced  . 
6 Related Work bllOSt sumnmrization studies ( including Zcchnero 1996 ) arc based on inq3oitant sentence selection and seek belier selection methods  . We have +' Generationel " articles is h . 'ft to be considered . 
pointed out that sumnmries made by this method tend to be btn densome to read  , and have proposed phrase-representation summarization as an alternative  . The following studies bear some relation to our study  . 
The summarization method by Boguraev and Kctmedy ( 1997 ) adopts ~ phrasal expression " rather than sentences or paragraphs  . However , it begins to create a phrase not from a core relation but a core word  ( in their words , "' topic stamp ") and produces multipk ; phrases containing the same core word ; it is therefore not suitable for summaries for sifting IR results  . In addition , because it does not consider the roles and importance of th cattaching arcs when enriching the core  , less important words are often attached to the core  . They aimed at supporting fast reading rather than sifting IR rest llts  . 
Some studies are similar to ours in that they make sentences short  . Wakao , et al (1998) and Mikami , ctal .   ( 1998 ) aim to create closed captioning fl-oman announcer's manuscript by paraf~hrasing and renlov hlgn lodifiers  . This method does nhr onlove \[ he "' l't ll k ~" o1" the an alxs is tree and the sun lll ~ aries canilot be made as short as in phrase-representation  . 
Na`ao , elal .   ( 1998 ) also proposed aineti ~ od to create summarization based on the i ' ehlthms Document Annotation  )  , a tagset that the document author inserts into the document and that contains linguistic information such as sentence structures and reference infimnation  . Althot@athis method is similar to ours in some points  , the stlmmaw consists of sentences and thus does not have " at-a-glalme " capability  . Most of all , the expectation that every doctmlent is tagged linguistically will not be fulfilled until special editors with automatic linguistic tagging be contepopular  . 

We introduced the concept of " at-a-glance " summary and showed an algorithm of phrase -representation SU lnmarization as a realization of the concept  . An experiment shows that the summaries are effective for sifting IR results  . 
We continue to fine-trine the prototype for timber efficacy  . 

We would like to thank our laboratory members who give us valuable suggestions and participated in the experiment  . 

Bougraev , t3 . and Kennedy , C .   ( 1997 ) : " Salience-based Content Characterisation f Text Documents  , " Proc . 
Intelligent Scalable Text Summarization , pp . 29.
Jing , H . , Barzilay , R . , McKeown , K . and Elhadad , M . 
(1998 ) : " Summarization Evaluation Methods : Experiments and Analysis  . " In Intelligent Text
Summarization . pp . 51-59. AAAI Press.
Kaplan , R . M . and Bresnan , J .   ( 1982 ) : "' Lexical-Functional Grammar : A Forlnal System for Grammatical Representation  , " in Bresnan , J . ( ed . ) The Mental Representation oJ " Gramnzatical Relalions  , 
MIT Press.
Mani , 1 . , House , D . , Klein , G . , ttirschman , L . , Obrst , L . , Firmin , T . , Chizanowski , M . , and Sundheim , B . 
(1998 ) :"' The 77PSTER SL/MM:tCT~:vt Summarization Evaluation . " Technical P , eport MTR98 W0000138 , MITRE Technical Report . 
Mikami , M . , Yamazaki , K . , Masuyama , S . and Nakagawa , S .   ( 1998 ) : " Summarization of News Sentences for Closed Caption Generation  , " t'roc . 
llq > rks h~q ) l ) rogram The 4th Anmzal Meeting ( 71 Tim . - l . s ' xociation . /br Natural Language l ) roce . ssiny , pp . 
1421 ( in Japanese).
Miyauchi , T . , Ol<a , M . and Ueda . Y .   ( 1995 ) : - Key-relation technology for text rett+ieval . ""/' roe . the
SDAIR'95, pp . 469-483.
Nagao , K . and tlasida , K . (1998): " Autotnatic Text Sununarization P , a sed on the Global Doctnnent Annotation , " Proc . COLING-g&pp . 917-92 I . 
Oka , M . and Ueda , Y .   ( 2000 ) : "' Evaluation of Phrase-representation Summarization based on Information Retrieval Task  , " Proc . ANLP , NAACL 2000 Workshop o , ' z , 4 zz lomatic Sumnzarization , pp .  59 -- 68 . 
Pollard , C . and Sag , 1 . A . (1994):ttead-Drivent'hrase Strltctm'e Grammar , The University of Chicago

Salton , G . (1989)::tulomalic 7Z , x/l ' rocessing : The 7) ' an . ~/ brmation , Aalysis , and Retrieval of In Jbrma-tion by Compttter , Addison-Wesley . 
Wakao , " F . , Ehara , T . and Shirai , K .   ( 1998 ) : " Auto?matic Summarization for Closed Caption for TV News  , " Proc . Workshop Program The4t\]l Annual Meeting ( ?/ The Association for Natural La ~ Nuage
Processing , 713 ( in Japanese).
Zechner , K .   ( 1996 ) : "' Fast Generation of Abstracts from General Domain Text Corpora by Extracting Relevant Sentences  . " l ' roc . COLING96, pp .  986 . ,, 989 . 

