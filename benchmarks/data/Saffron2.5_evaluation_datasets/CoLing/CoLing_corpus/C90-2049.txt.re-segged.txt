Dependency Analyzer:
A Knowledge-Based Approach to Structural Disambiguation 
Katashi Nagao
IBM Research , Tokyo Research Laboratory
5--19 Sanbancho , Chiyoda-ku , Tokyo102, Japan
Email : nagao@jpntscvm.bitnet

To resolve structural ambiguities in syntactic analysis of natural anguage  , which are caused by prepositional phrase attachment  , relative clause attachment , and so on , we developed an experimental system called tile Dependency An-al ! lz cr  . The system uses instances of dependency structures extracted frot haterminology dictionary as a knowledge ba  . ~ e . Structural ( attachment ) ambiguity is represented by showing that a word has several words as c  ; tndidate modiliees . Tim system resolve such ambiguity as follows . 
First , it searches the knowledge base for modification relationships  ( dependencies ) between the word and each of its possible modifiees  , then assigns an order of preference to these relationships  , and finally seieets the most preferable deper . dency . The knowledge base can be constructed semiautomatically  , since the source of knowledg exists in the form of texts  , and these sentences can be analyzed by the parser and transformed into dependency structures by the system  . We are realizing knowledge bootstrapping by adding the outputs of the system to its knowledge base  . 
1 Introduction
The bottleneck of sentence analysis , structural ambiguity , occurs when a sentence has several alternatives for modifier-modifiee relationships  ( dependencies ) between words or phrases . This kind of ambiguity cannot be resolved merely by applying grammatical knowledge : there is a need for semantic processing  . Resolution of structural ambiguitie seems to be a problem of selecting the most preferable dependency from several candidates by using largescale knowledge on dependencies among words  . 
There are two problems in realizing practical semantic processing : one is that knowledge must be large scale  , and must be constructed automatically or semiautomatically  ; the other is that the mechanism for utilizing knowledge  , inference , must be efficient or tractable . We developed a system called the Dependency Analyzer that resolves these problems  . 
The Dependency Analyzer is a systen lfl ) rstructural dis-ambignation . One of its characteristics is that it selects the most preferable dependency by using a knowledge base containing terminological knowledge in the form of dependency trees  . The knowledge base can be constructed semiautomatically  , as described in Section 2 . The inputs of this system are parse trees , which are outputs of the PEG parser , a broadcoverage English parser\[5\] . The system translates the phrase structures into dependency strut-ships between words  . The main processes of the system are executed if attachment ambiguities are included in the phrase structures  . In the dependency structures , attachment ambiguities are represented by showing that some words have several candidate modiliees  . From these de-pe . ndency structures , several candidate dependencies are extracted . The system decides which of these should be adopted by using background knowledge an  , l context . The decision is made viatim mechanisms of path search and distance calculation  . A precise description of path search is given in Section  3  . An explanation of distance calculation is given in Section  4  . Another problem for disambiguation , namely interaction ( or constraints ) between attachment ambiguities , is discussed in Section 5 . 
2 Knowledge Base
The knowledge must be large=scale , since natural anguage semantic should have a broad coverage of lexical items  . 
Since dependency structures are built by analyzing sentences and by tra:nsforming phr~estructures in a straightforward way  , if knowledge is assumed to consist of dependency structures  , a knowledge base is easily constructed by using already-existing online dictionaries  . This idea of using online dictionary definitions as a knowledge base was originally proposed by Karen Jensen and Jean-Louis Binot  \[6\]  . Junichi Nakamur and Makoto Nagao \[101 evaluated tile automatic extraction of semantic relationships between words from the online dictionary  . We emphasize that a data structure for representing knowledge should be as simple as possible  , because it must be easy to construct and efficient  . 
We selected the tree structure as a means of representing knowledge  , because it is a very simple and manageable data structure  , and because tree structures are suitable for describing dependency structures  . 
Tile tree structure is defined as follows . A Tree consists of a Node and reeursions ( or null ) of Tree , and a Node consists of repetitions of a paired attribute name and u  . ttribute value . 
For example , Figure 1 shows a tree ( dependency ) strnc-ture for the clause " the operating system stores the files in the disk  . " In this tree , " WORD , "" POS ( part of speech) , " and " CASE " are att , q bute names , and " store , "" VERB , " and " AGENT " are attribute values . 
In our system , the knowledge can be extracted fi:om dictionaries of terminology  , and is of two types : ( 1 ) dependency structures and ( 2 ) synonym and taxonym relation - (   ( ( WORD . " store ") ( POS . VERB ))((( WORD . " operating system ") ( CASE . AGENT ) ( POS . NOUN ))) ((( WORD . "file ") ( CASE , PATIENT ) ( POS . NOUN ))) ((( WORD . " disk ") ( CASE . LOCATION ) ( POS . NOUN ))))
Table h Tree Index Tabled synonym and taxonyr a trees to  ( O ) -qo ( o ) t~2 ( 0 ) tsO ) t  ~ ( o ) tea ( o ) t  ~ ( 0 ) t  ~ ( 0 ) tn ( 1 ) ts0 ) t25 ( 1 ) t82 ( o ) dependency trees tlol ( O1 ) tl so ( 1O ) tu ( 1 ) trio ( t ) tlOl ( 1 1 ) t350 ( 0 2 3 ) tas ( 1O ) tllo ( 11O ) lqgure hTree structure for the clause " the operating system stores the files in the disk " ships  . 
The process of knowledg extraction is as follows . First , dictionary statements are rewritten manually as simple : ~ entences  . Next , sentences are parsed into phrases true-tm'es by tile PEG parser  . Then . phrase structures are transformed into dependency structm'es by the Depen-de'nc:qStr~zctu're Builder  , which is a component of tile Dependency Analyzer . Finally , sernantie case markers are manually added to the modification links in dependency  . structures . Synonym and taxollym relationships are extracted from sentences of the form " X is a synonynt for Y " and " X is a Y " respectively  . These sentences are automatically transformed into tree structures each of which has two nodes R  ) rtile words " X " and " Y " and a link from " X " to " Y " with the label " is a  . " In the case of " X is a synonym for Y , " since " Y " is also a synonym for " X , "" Y '" is connected with " X " at the same time by a link with the label " is a  . ' "\ Ve developed an interactive tree management tool  , the Tree Editor . which makes it easy for users to deal with trees . 
Another problem of natural language processiug is the knowledge acquisition bottleneck  . Some ideason how to a . cquire knowledge fi'oma ! ready-existing dictionaries automatically or semiautomatically haw ~ be  . en proposed\[10,41 . 
But it is still difficult to develop a knowledge base hilly automatically because of ambiguities in the natural language analysis of dictionary definitions  . A more practical way , to overcome the t ) otthmeck is so called kno'wl edge bootstrap-tn'a ~ . \] . By knowledge bootstrapping , the Dependency Analyzer extends its knowledge automatically by using a e or'e knowledge base that includes mammll vedited dependency  . ~; truetures . Since the De . pendency Analyzer uses dependency structures as knowledge and outputs a dependency structure with no ambiguity  ( case ambiguity is also resolved by the system )  , tile output can be added to the knowledge base . Of course we still need to evaluate the automatically constructed knowledge base  . But the reliability ( performance ) of the knowledge base is rising grad-ua\[ly , so it is expected that human interw , ntion wil I be greatly reduced in the near future . 
"t Path Search An Et Iicient Algo-rithm Path search is a process for finding relationships between the words in a candidate dependency by using a knowledge base  . Since relationships between words in these candidates do not always exist in the knowledge base  , relation -/\ (3(o )( ? O(2) t . 5 (2 1 0)
Figm'e 2: Tree and Node Locationships between synonyms and taxouyms of these word seau also /  ) e targets . Path search is done ill the following steps : 1 . Synonyms and t~u , : onyms of words in the candidate dependencies are found by using the knowledge base  . 
In the knowledge base , synonym and taxonym relationships are also defined in the form of trees  . All the synonyms and taxonyms can be collected by transiting relationships  . 
2 . Dependencies between elements of each synonym and taxonym set  ( including the original words ) are also found by using the knowledge base . 
We developed an efficient algorithm for path search  , using the table of indices shown in Table 1 . In this table , t  ~ , represents the pointer of the tree in which the word on the same line appears  , and the numbers in parentheses represent the node location of the word in the tree  . Relationships between the numbers amt the node are shown in Figure  2  . The left side of tile table shows trees in which a synonym or at axonym of the word on the same line appears as its parent node  . For example , in the tree to , the word a is on the node of location (0) , and by traversing to up by one node fl'om location  ( 0 ) we can find that the word b is on the node of location  ( ) , so b is a synonym or a taxonym of a , as shown in Figure 3 . Thus , in order to find a synonym or a taxonym of a word  , we just traverse uptile tree on the left side of the table by one node  . We assume that synonym and taxonym relationships are transitive  , that is . that a synonym/taxonym of one of the synonyms /taxonyms of a word is also a synonym/taxonym of the word itself  . We can to ~ bl synonym/tm xonym ( isa ) a
Figure 3: Synonym/Taxonym Tree/bd " keep " . ~, . .
" VM/SP .   .   .   . information " / " virtual disk " Figure 6: Ambiguous Dependency Structure
Figure 4: Dependency Tree ~110 ~ O~to ~ b q . ,, - . d


Figure 5: Path collect all its synonyms/taxonyms by iteration of that process  . The next stage of path search is to find whether there are dependencies between words within each set of syn-onyms/taxonyms  . This process searches trees that involve both words and checks whether there is a path from one word to the other  . In the dependency trees , the words ' locations show whether there is a dependency between them  . 
For example , we can see that tile word b is a dominator of the word dfrmn the locations of these words in the emnmoutree  tH0   ( shown in Figure 4 )  , which is included in both the set of dependency trees that include b  . ttl , ttl 0 , and that of dependency trees that included , tas , t110 . In the tree structures , if the node a is an ancestor of the node b , then there is a unique path front b to a . Thus , finding dependency between words is equivalent o checking their node locations in the dependency trees  . A path between words wl and w2 is found by the following processes : 1  . The synonym/taxonym sets of these words , S  ~ , ~ and
S ~, are collected.

Ion " virtual disk "
Figure 7: Candidate Dependency 4 Distance Calculation - A Heuristic P rocess for Selection of the Most 
Preferable Dependency
Several conditions are added to path . s , and the ch ) seness of dependevcy in a path is computed according to these conditions  . The degree of closeness of dependenc . y is called the dependency distance . This is calculated by using the number of dependencies in clnded in a path and the values of the conditions  . Three conditions are used to calculate the dependency distart ce: 
I . Case consistency
For example , in the sentence " VM/SP kceps the information on the virtual disk  , " there is a prepositional phrase attachment ambiguity  , as shown in Figure 6 . If the path shown in Figure 8 is found together with the candidate dependency shown in Figure  7  , then tile semantic case of the path's dependency between " store " and " disk " must be consistent with the grammatical case of the sentence's dependency between " keep " and " virtual disk  . " lIere , the case consistency between the sentence and the path holds  , since the grammatical case " on " call have the role of the semantic case " location  . " If this consistency holds , then the value of case consistency is 1 ; otherwise , it is 0 . 
2. Cooccurrence consistency
This is the consistency between the other modifiers of the modifiee of tile candidate dependency  , called the cooccurrent modifiers , and those of a path . 
2 . The common trees t z .   .   . that involve both elenmnts , ei 6Swl and ej ~ Sw2 , of each set are found . 
3 . Tile node locations of ei and ejint ~ .   .   . are checked . 
For example , a path between the words a and c is shown in Figure  5  . 
" store " " keep .   .   .   . disk " lisa " virtual disk "
Figure 8: Path " keep " " VM/SP "' ~ virtual disk "
Figure 9: Co-Occurrence " operating system " " file .   .   .   . disk "
Figure 10: Dependency Tree
Intile example sentence , for instance , there is a cooccurrent modifier " VM/SP " of the candidate dependency between " keep " and " virtual disk  , " as shown in Figure 9 . In this case , " VM/SP " has the grammatical case subject . On the other hand , if the path is given by the dependency tree shown in Figure  10  , then there is also a eo-o ceurrent modilic r " operating systenf ' that has the semantice ase of agent  . In addition , there is at mxonym relationship between " VM/SP " and " operating system " in the knowledge base  , as shown in Figure \] . I . In this case , the cooccurrence consistency between " VM/SP " and " operating systenf ' holds  , since there is a relationship between the words and both case  , ; are consistent ( the grammatical case subject call have a semantic case agent  )  , as shown in Figure 12 . 
The vahm of cooccurrence consistency is tile number of co-oceurrent modifiers that are consistent between the path and the sentence  . Here , the value is 1 , since only one co-oe current modifier " VM/SP " is consistent  . 
Context consistency
Context consistency holds if dependencies in a path already exist in previous sentences  . For example , if the sentence " the data is stored in the storage device " comes before tile above sentence  , then the dependency structure shown in Figure 13 is in the context base in which the dependency structures of previou sentences are stored  . Then the other path ( shown in Figure 14) , which corresponds to the dependency between " store " and " disk " in the " path  , " is found by using the context base . Thus the dependency between " store " and " disk " is defined by the context  . The vahn ' , of context consist mmy is the number of dependencies in the path that are  . defined by tile context . In this case , the wflue " operating system " lisa " VM/SP "
Figurelh Taxonym Relationship agent location " operating system " ~" store "  . i . . . . " disk " subject on " VM/SP " " * " keep " ~ " virtual disk " Figure  12: Diagram of Co-Occurrence Consistency " store "
St --> " data . . . . storage device "
Figure 13: Dependency Tree in tile Context Base is 1  , since there is one dependency in the pa & and it is de  . fined in the context . 
The dependency distance is computed from the following formula : Distance =\ [ Depl+~c'o  , , , x(n-1)(t ~ ,   . . . . .  + 1 ) x ( l@o o~+1 ) ' where \] Dep\]represents the number of dependencies included in the palh  , i " c . . . . . is the value of case consistency , 1~' oo ~ . is that of cooccurrence cm~sistency , and l'C , o , ,t is that of context consistency . 
This formula assumes that case and cooccurrence consistency affect the distance of the whole path  , but that context consistency affects the distance of each dependency in the path  . 
n is a real number in tile range 0 < n < 1 ; it is a heuristic parameter that represents the degree of unimportance of context consistency  . 
The dependency distance between " keep " and " virtual disk " that is calculated by using the path in the example is  0  . 125 , because the number of depent tencies is 1 , the value of case consistency is 1 , that of cooccurrence consistency is 1 , and that of context consistency is 1 ( n is defined 0 . 5) . 
The ambiguity of an attachment is resolved by selecting the candidate dependency that is separated by the shortest distance  . 
" store " -.. < storage device " disk "
Figure 14: Path of Context
Constraint Table T 5 . 6 Constraint Table 7~5,7 Cons ~ r~dnt Table T 6 . rtl ' ~ 0 IlI 0   1  ~  6/7   3   6   1   0   1   3k~__~l_L2 o V3 f li 212o0   \[5  ~  1   0   Ic~0 Im I1   2 ~ m , o ) :%_'7_'7 , 0 /  , Q/~"-- ,  / 7 ~\0~ , ~) I~O/3 , s Figure 15: Ambigu , ms Dependency Slructure 5Planning , Constraint Propagation , and Process of Disambiguation When there are several attachment ambiguities in one sentence  , the relationships of each pair of ambiguities are represented by a constraint network  \[91  . The idea that a m-Mguous syntactic structures can be represented by a data structure of constraint network was originally developed by Hiroshi Maruyama  \[7 t . A constraint network consists of constraintables . 
For example , the constraintables shown in Table 2 are constructed from tile ambiguous dependency structure shown in Figure  15  . In this dependency structure , words 5 ,  6 , and 7 have attachment ambiguities , otheir possible modifiees are 1 , 3 ,  1 , 5 , and 3 , 6 respectively . The constraint table is a two-dimensional matrix that represents the  . possibility of simultaneous modification of two ambiguous attachments  . The rows and columns of the matrix show the candidate modifiees of each modifier  , and an element in the matrix means the possibility  ( 1 or 0 ) that both dependencies can exist simultaneously . For example , constraint table T5 . 7 indicates that if word 5 modifies word 1 , then word 7 cannot modify word 3 because of the rule of no-crossing . 
By using the constraint tables , the system decides which ambiguity should be resolved first  . This process is called planning . In the above example , words 5 ,  6 , and 7 have two candidate modifiees each . But from the constraint tables , we can see that if word 7 modifies word 3 , then words 5 and 6 cannot modify word 1 . Thus , in this case , the ambiguity concerning the modification of word  7 should be resolved first . The algorithm for plauning consists of the following steps :  1  . On each row of the constraint table Ti . j , sum up the element values ( Ai in Table 2) , and subtrac the sum from the size of the row ( Bi )  . Then sum up the results on all rows ( Ci ) . The result is the value of merit of 2 . Do the same in each cohm m . The result is the value of merit of the ambiguity of word j  . 
3 . In all the constraint tables , sum up all the values of merit of each ambiguity , and divide each of these values by the number of their candidate modifiees  . 
4 . The expected values of meTit of all ambiguities are given by the above process  . Select the ambiguity that has the highest expected value  . 
When an ambiguity is resolved , the system updates the constraintables by tile filtering algorithm called constraint propagation  . We apply Mohr and Henderson's AC-4 algorithm \[8\] for constraint propagation . We reduce the computational cost of disambiguation by using planning and constraint propagation  . 
Structural disambiguation fa sentence is done as follows  . The PEG parser tmrses a sentence and constructs its phrase structure  . The Dependency Stractur cBuilder trans-httes the phrase structure in t  . o the dependency strm:ture , and constructs the constraint tables when the phrase structure contain sew ~ ral structural ambiguities  . The Planner , which is the component for planning , gives the Dis-ambiguator the information on an ambiguous dependency and its candidate modifiees  . The Disambiguator decides which modifiee is the most preferable by doing path search and distance calculation  . After resolving one ambiguous attachment , it calls the constraint propagation routine to filter the other ambiguities ' candidates  . After filtering , the Transformertans forms the dependency structure into one that has correct dependencies for all resolved attachments  . 
These processes are iterated until no ambiguity remains  . 
6 Related Work
There are several approaches to structural disambiguation  , including resolution of prepositional phrase attachment  . Wilks et al \[12\] discussed some strategies for disambiguation based on preference semantics  . Our framework is closely related to their ideas . While their strategies need handcoded semantic formulas called preplates to decide preferences  , our system can construct dependency knowledge semiautomatically  . Dahlgren and Mc-Dowell \[2\] proposed another preference strategy for prepositional phrase disambiguation  . It is based on ontological knowledge , which is manually constructed . Whereas this framework ( and also that of Wilks et al ) was aimed at disambiguating single prepositional phrases in sentences  , our approach can handle the attachments of multiple prepositional phrases in sentences  , ttirst \[3\] developed a mechanism for structural disambiguation  , called the Semantic Enquiry Desk , which is based on Chraniak's marker passing paradigm  \[1\]  . Our path Search is partially equivalent to marker passing  . While marker passing involves a high computational cost and finds ninny meaningless relations  , our path search is restricted and finds only paths that in-elude synonym/taxonym relationships and dependencies  . 
Our system can reduce the computational cost by using a limited knowledge search  . Jensen and Binot \[6\] developed a heuristic method of prepositional phrase disambiguation us in p  , online dictionary definitions . Our approach is sire--liart , otheirs in the sense that both use dictiouaries as knowledge sources  . The differences are in tile ways in which dictionary definitions are used  . While their method sear : hes for knowledge by phrasal pattern matching and calculates certainty factors by complex procedures  , ours uses knowledge it : asimt ) le and efficient way , searching tree :: and traversing nodes , and calculates t ) referenees by a fe , w simplified processes . We rnlter\[11\]t ) ropsedae:n-neeliol:ist approach to8l rllctll ra . \[ disan : biguation f noun phrases . He integrated syntaclic and semantic on slraints on lhere laxation et work  . ~ el : la I : tic 2OllS'l'ailltS ol : prepo-sitional reh:tions hil ) s be tweet l words are learned by a back-lro\ ] agation algorithm  . Learned semantics is often very t : seful for natural language processing  , when sexnantic re-htti , mshit ) s cannot be represented explicitly .   \\2: represm : t semantic relationships between words by explicit relationship chains  , al : d therefore do not need learning by backpropagation  . We integrate sem . mti : preferences and syntactice on strailll Sty using e  ( mstraint tropagathm . n : t it is a sequential : o : : ue ' tion ad does not allow their i ilterac-  . 
tim . \\k ! are thii:king of desig If in pafrau : e work that deals wilh both syntactic and semanli : constraints simultam'-ousty  . 
7 Concluding Remarks
We deveh ) ped the DepeT~dcrtcy Anal:/zertore:olve structural ambiguity by sen : antic processing  . It aims t < ~ overcome two serious problems in realizing pr : ' a'tical semantic pr  , ~ , cessing::en::@u'::nm:ie conslrution of knowledge and efficient usenf that knowledge  . The key ideas , path . 
.sea~'ch and distance calcuiatiora , ~~ e . reshown to be feasible . 
\ Venow have a knowledge base constructed by using defi :  ,  . itions giver ~ in the " IBM Dictionary of Computing /' which inch : des about  20  . 009 instance . s of dependency : true-turc ' . s , h : addilion , we evaluated the system by disan:-biguat . ing the prepositional phrase attachment of about 2 , 0()0 sentence . ': . The results were as follows: ( 1 ) : he number of arz flJiguou : - ; prepositio::alphrases wa > 4 . 290, (2) the numbe , of correctly ( lisanfiiguat . eda ' ~ ta:hm'n:s was 3 , 569 , and ( 3 ) the success ratio of disambiguatio::was 83 . 2% . 
Further enhancement plans arc listed be . low : ,, ~, ?~' . are exploring the formalization of dependency dis -tar  , ce with reference to graph theory . I ) ep e . ndeney dis-tMlee is a Ssllnled to be a score lbr the  ( : OIl Sistel ~ cy of a dependency with tim background knowledge and context  . The background knowledge and context are represented as trees  ( special ca . ~ es of graphs ) , and c ( ms is-tency might be defined by a degree of matching between trees  . 
, L . We are planning to enhance tile system for other problems such as adverb attachment and scope of eonj ' unc-tion  . s . To resolve generals truetmal ambiguity problems , we must design a general ambiguity-packed syntactic strncture  , since the system can deal wilh locally packed ambiguities  . 
Acknowledgements i would like to thank members of the IBM Tokyo Research Laboratory  , Karen Jensen of the IBM Thomas J . 
Watson Research Ceqter , and tile reviewers for their vain-able comments on a draft of this paper  , Hiroshi Nomiyama for his help in implementing tile system  , Mizuho Tanaka , ~%hko Kobayashi , Mitsuyo Sadohara , and Xbmoko Uehida for their kind support it : constructing the knowledge base and evaluating the system  , and Michael McDonakl for his helpful adviee on the wordi\[:g of this paper  . 
References\[1\]Charniak , E . , " A Neat Theory of Marker Pressing , " Procec . dirzgs of AAAI-86, 584-588, 1986 . 
\[2\] Dahlgren . K . and McDowe!l , J . , " Using Commonsense Km~wledge to Disambiguate Prepositional Phr~u~eXiod-ifiers  , " Proceed in . q . s of A . 4 A\[-a < 589-593, !986 . 
\[3\] tlirst,G . , Scmanlic hlterpre . t , Ltion and ZheRc . s,)hLtio . nofA'mbiguity , Cambridge University Press ,  1!357 . 
\[ . 1\] Jacob :, P . and Zernik . U . , " Acquiring Lexical K'aowl-edge from Text : A Case Study  , " Proceedings (; fAAAL 88 ,  739-7-1 . 1, 988 . 
\[5\] Jensen , K . , He Morn , G . E . , Richardson , S . D . , and Haas , N . , " PLNLP , PEG , and CRYI'IQUE : Th , ' ee Contribn-tions to Computing in the Humanities . "IBM Research
Report , EC11841.1986.
\[6\] Jensen , K . and Binot JL . , " Disambiguating Prep ( >sitional Phrase Attachments by Using OnLine Dictionary Definitions  , " Coraputational Ling'u?stics ~13: 251-260 ,  1987 . 
\[7\] Maruyama , H . , " Structural Disambiguation with Con-strain ~ , Propagation , " Proceedings o/~l~e28th Annual
Meeting of the ACL , 1990.
\[8\] Mohr , E . and Henderson , T . . " Are and Path Con-siste . ney II evisited . " Artificial Intelligence , 28:225-233 . 

\[9\] Montanari , U . , " Networks of Constraints : Fundamental Properties and Applications to Picture Processing  , "
Inf~imation Sciences , 7:95-132, 1974.
\[10\] Nakamura , J . and Nagao , M . , " Extraction of Semantic information from an Ordinary English Dictionary and its Evaluation  . " Proceedings of COLING-88 .  459-46,1, 1!)88 . 
\[ ll \] Wermter , S . , " Integration of Semantic and Syntactic Constraints for Structural Noun Phraset  ) is ambigua-tion , " P ' roceedir LgsofIJCA\[-89 ,  1-186-1491 ,  989 . 
\[ i\[2\]Wilks,Y . , Huang , X . , and Fass , D . , " Syntax , Preflu-ence and Right Attachment , " Proceedings of I . ICAL 85,77978 . 1, \]!)85 . 

