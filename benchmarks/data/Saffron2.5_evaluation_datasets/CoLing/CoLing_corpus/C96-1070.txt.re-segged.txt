Incremental Translation
Utilizing Constituent Boundary Patterns
Osamu FURUSE , Hitoshi IIDA
ATR Interpreting Telecommunications Research Laboratories 
22 tlikaridai , Seikacho , Sorakugun , Kyoto ,  619-02 , Japan
furuse , iida@itl.atr.co.jp

We have proposed an incremental translation method in Transfer-Driven Machine Translation  ( TDMT )  . In this method , constituent boundary patterns are applied to an input in a bottom-up fashion  . Also , by dealing with best-only substructures , the explosion of structural ambiguity is constrained and an efficient translation of a lengthy input can be achieved  . Through preliminary experimentation our new TDMT has been shown to be more efficient while main -tMning translation quality  . 
1 Introduction
A system dealing with spoken language requires a quick response in order to provide smooth communication between humans or between a human and a computer  . There ibre , assuring efficiency in spoken-language translation is one of the most crucial tasks in devising such a system  . 
In spoken language , the translation of lengthy utterances can yield a huge amount of structural ambiguity  , which needs to be efficiently processed by the system  . As a solution for achieving an efficient spoken -language system  , several techniques , such as incremental generation ( Fin-kler , 1992; Kempen ,  1987 ) and marker-passing memory-based translation ( Kitano ,  1994) , have been proposed . Many of these techniques adopt a left-to-right strategy to handle an input incrementally and a bestfirst strategy to avoid the explosion of structural ambiguity  . These strategies ( : an be achieved with bottom-up rocessing . 
We have already proposed Transfer-Driven Machine Translation  ( TDMT ) for efficient and robust spoken-language translation  ( Furuse , 1994a ; Furuse , 1994b ) . However , the topdown and breadth-firs translation strategy in the earlier versions of TDMT  , which yields a quick response for inputs with restricted lengths  , may show poor efficiency when processing a very lengthy input or inputs having many competing structures  . 
In a topdown and breadth-first application , all the possible structures are retained until the whole input string is parsed  . This requires many computations and results in inefficien translation  . For instance , the sentence below has many competing structures , mainly because of possible combinations within noun sequences  . If this expression is combined with another expression  , the structur M ambiguity will be further compounded  . 
With bacon chickeneggs lettuce and tomato on it.
In contrast , if structural ambiguities of substrings are always settled and are never inherited to the upper structures  , the explosion of struc-turM ambiguity could be constrained  . Thus , an incremental strategy that fixes partial results is necessary for efficient processing and is achieved by bottom-u processing in left-to -right order  . 
This paper proposes TDMT using an incremental strategy for achieving efficien translation of a lengthy input or one having a lot of structural ambiguity  . In this method , several constituent boundary patterns are applied to an input string in a bottom-up fashion  . This bottom-up application , based on the concept of chart parsing , can constrain the explosion of structural ambiguity by dealing with best-only substructures uing semantic distance calculations  . 
In this paper , we will first ; outline our new translation strategy . We will then explain how constituent boundary patterns can be used to describe the structure of an input string in TDMT  . 
Then we will describe the bottom-u pattern application  , based on chart parsing . Next , we will show how the explosion of structural ambiguity is constrained by dealing with the best -only substructures  , based on semantic distance calculations . By comparing the preliminary experimental results from the former topdown method and those from our new method  , we will demonstrate the usefulness of our new method  . A summary of our approach will conclude the paper . 
2 Translation strategy
In TDMT , translation is performed by applying stored empirical transfer knowledge  , which de-guage expressions and target language x pressions at various linguistic levels  . The source and target expressions of tile transfer knowledge in TDMT arcext  ) ressed by constituent boundary patterns , which represent meaningful units for linguistic structure and transfer  . An efficient application of transfer knowledge source parts to an input string plays a key role in achieving quick translation  . 
The procedure R ) rapplying constituent boundary patterns is perfomed after the assignment of morphological information to each word of an input string  , and is as follows: ( a ) Insertion of constituent boundary marker ; ( b ) 1) eriw ~ tion of possible structures ;   ( e ) Structural disambiguation 1 ) y semantic dis-lance calculation . 
In the topdown and breadth-tirst pattern application  , the above procedure is executed in the described order  . Because the selection of the best structure might have to be postponed until all possible struct m ' es are derived  , the costs of translation could be high . 
In contrast , the incremental method determines the best structure locally and  ( -an constrain the number of competing structures fbr the whole input by performing  ( b ) in l ) arallel with ( c )  ; consequently , translation costs are reduced . 
The structure selected in ( c )   ( : ontains its trans-t~rred result and head word infbrination  , which is used for semantic distance calculation when combining with other structures  . The output sentence is generated as a translation result Dora the structure for the whole in l  ) ut , which is composed of bestfirst substructures . 
In the three subsequent sections , we will explain ( a ) , ( b ) , and ( c ) , focusing on the bottoir > up and bestfirst ranslation strategy  . 
3 Constituent boundary pattern
In this section we will briefly explain how constituent boundary patterns are used to describe the structure of an in t  ) utstring in TI ) MT and what procedures arc applied before constituent boundary pattern applications  ( Furuse , 1994b ) . 
We will show bottom-u pattern application by translating the following sample English sentence into Japanese: 
Th cbus goes to China to wn atten a.m.
First , all the words in this sequence are assigned the following parts-of-speech  . 
article , noun , verb , preposition , proper noun , preposition , numeral , postnominal A constituent boundary pattern is defined as a sequence that  ; consists of variables and symbols representing constituent boundaries  . A variable corresponds to some linguistic constituent and is expressed as a capital letter  ( e . g . X ) . 
A constituent boundary is expressed by either a functional word or a part-of-speech bigram marker  ( e . g . noun-verb ) . Variables in tile source language expression must be separated by constituent boundaries  . 
For instance , the expression " goes to China-to wn " is divided into two constituents  , i . e . " goes " and " Chinalown " . The preposition "1o " can be identified as a constituent boundary . Therefor ( ; , in parsing " goes to Chinatown " , we use the pattern " X to Y ' , which has two variables X and Y and a constituent boundary " to "  . 
' l'he expression " theb~zs goes " can be divided into two constituents " the bud ' and " goes "  . How-eve . r , there is no flmctional surface word that divides the expression into two constituents  . In such (' ases , weem t ) loy part-of-speech bigrams as boundary markers . " bus " and " goes " are a noun and a verb , respectively . Thus the marker noun-verb can be inserted as a boundary marker into the input " the busgoes "  , giving " The bus noun-verb goes " . This sequence will now match tile general transfer knowledge pattern " X noun-verb Y "  . 
Of the possible bigrams in the above part of ~ speech sequence  , only " noun-verb " is an eligible constituent boundary marker  ( Fro:use , 1994b ) . 
This marker is inserted into the above sentence : The bus noun-verb goes to China town attena  . m . 
Indices to possible patterns are obtained from several words and bigrams in the abovem ~ rker -inserted string  ( Table 1 )  . 
Table 1 : Retrieved patterns word thc 7~o?tn-vcrb to at retrieved pattern ( linguistic level ) the X ( (: ompound noun ) 
X noun-verb Y ( simple sentence)
X to Y ( verb phrase , noun phrase)
X at Y ( verb phrase , noun phrase)
Xa . ra . ( compound noun )
The procedure xt ) lained so far is the part that ; the topdown and bot ; to m-u pattern application methods have in common . 
4 Incremental pattern application
In this section , we will show the application of constituent boundary patterns based on the concept of bottom -up chart parsing  . 
4.1 Linguistic level
In order to limit the combinations of patterns during pattern application  , we distinguish pattern levels and for each linguistic level  , we specify the linguistic sublevels which are permitted to be used in the assigned variables  . 
Table 2 shows examples of the relationships between linguistic levels  . A variable on a given level in the second column of Table  2  . For instance , in the noun phrase " X of F ' , the variables X and Y cannot be instantiated by a simple sentence  , but can be instatiated by a noun phrase , a compound noun , and so on . 
Table 2: Possible linguistic sublevels invariables linguistic level sublevels of variables simple sentence VP  , NP ,   . . . 
verb phrase ( VP ) VP , NP , verb , ...
noun phrase ( NP ) NP , CN , proper noun ...
compound noun ( CN ) CN , noun , ...
According to the regulation of the linguistic levels ' relation shown in Table  2  , a marker-inserted string is parsed using the constituent boundary patterns  . 
4.2 Active and passive arcs
A chart parsing method ( Kay ,  1980 ) can avoid repeatedly recomputing partial results and achieve incremental processing by using a bottom-up and left-to-right strategy  . In chart parsing , an input string is parsed by combining active and passive arcs  . These can be assigned to a substring of an input string when a pattern is applied to it  . If all the variables of the applied pattern are instantiated or a substring can be matched to a pattern whose variables are all instantiated  , a passive arc is created for the substring . When a substring can be matched to the left part of a pattern and the right variables of the pattern are not in statiated  , an active arc is created for the substring . 
In conventional chart parsing , many arcs can be created because every word can create active and passive arcs based on its part -of-speech  . 
Also , many arcs can be chained via nonterminal symbols such as a part-of-speech and NP  ( noun phrase )  . For instance , the pronoun , " f'can create many active arcs relevant othe rules " Pronoun  1"  , " NP ~ Pronoun " and " S - - + NP VP " , which can be chained . Therefore , a lot of computation is required in conventional chart parsing  . 
In contrast , chart parsing with constituent boundary patterns can constrain the number of arc creations because only an constituent boundary creates active arcs while a variable  ( e . g . X ) never creates an arc . We obtain indices to patterns from each word of the sentence  . With these indices , patterns are retrieved and checked to determine whether each of them can create an arc  . 
4 . 3 Pat tern app l i ca t ion a lgor i thm Our algorithm for bottom-up application of patterns is as follows  . If the whole input string can be covered with a passive arc  , the parsing will succeed and the derivation of the passive arc will be the parsed result  . 
1 . If the processed string is a content word ( e . g . 
noun , verb ) create a passive arc.
2 . If the processed string is a constituent boundary " a "  , create each kind of arc as follows , according to the pattern I retrieved from the constituent boundary  . 
2a . If the retrieved pattern is of the type " XaY " and a left-neighboring passive arc can satisfy the condition for X's instantiation  , create an active arc for " X aF ' , in which Y has not yet been instantiated . 
2b . If the retrieved pattern is of the type " Xa " and a left-neighboring passive arc can satisfy the condition for X's instantiation  , create a passive are for " Xa " . 
2c . If the retrieved pattern is of the type " a ~' , create an active arc for " a ~' . 
3 . If the created passive arc satisfies the leftmost part of an uninstantiated variable in the pattern of neighboring active arcs  , the variable is instantiated with the passive arc  , and a new passive or active arc is created . If a passive arc is generated in this operation , repeat the procedure until a new arc can no longer be created  . 
Figure 1 shows how an input string is parsed using our bottom-up chart method  . A solid line denotes a passive arc that covers a substring of the input below  , while a dotted line denotes an active arc . 
The content words " bus " , " goes " , " Chinatown " and " ten " create passive arcs . The functional word " the " , which is relevant o the pattern " a X " , creates an active arc . The assignment of the functional word " a . m . " to the pattern " Xa " creates a passive arc by combining another passive arc  . The boundary markers " noun-verb " , " to " and " at " , which are relevant o the pattern " X a Y " , create active arcs by combining left-neighboring passive arcs  . 
First " the " creates the active arc ( 1 ) relevant o the pattern " the X " . " bug ' creates the passive arc (2) . The passive arc ( 3 ) is created by combining ( 1 ) and ( 2 )  . " noun-verb " creates the active arc (4) , whereby the variable X of " X noun-verb F ' is matched against  ( 3 )  . " bus " creates the passive are (5) , and the passive arc ( 6 ) is created by combining ( 4 ) and ( 5 )  . " to " creates the active are (7) , whereby the variable X of " X to ~' at verb phrase is matched against  ( 5 )  . 
1 There are other types of patterns , such as " X a Yfl ~' , where ce and/3 are constituent boundaries . 
They can be easily processed by slightly extending the algorithm  . 
414 (20) (16)  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  (12)  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . (11) ( lO ) .   .   .   .   .   .   .   .   .   .   .  (7) (6)  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   ( 4 ) the bus noun-verb goes ( 9 )  18 ) to China town atten ( 15 )   ( 14 ) 
Figure 1: Chart diagram (19) (1~) a.n 2.
We continue the procedure incrementally.
When the rightmost word has been processed , the derivation of the passive arc of the whole input gives the parsed result  , in our example the derived process of the passive arc  ( 20 )  , which is the combination of (4) and (19) . 
5 Preference of substructure
The passive arc (19) , which is relevant o " goes to China town attena . m . ", h ~ two competing rc-suits . One is the combination of (7) and (18) , where " X at F ' is a noun phrase . The other is the combination of ' (12) and (17) , where " X at 1 ("' is a verb phrase . Thus ,   ( 19 ) has two possible structures by the application of " XatF '  . " X to F ' at the verb phrase level and " X a . m . " at the compound noun level are also applied . 
The technique for obtaining substructure preference is the determination of the best substructure when a relative passive arc is created  . Only the best substructure can be retained and combined with other arcs  . 
5.1 Semantic distance
The most appropriates t ~ ructure is selected by computing tile total sum of all possible combinations of partial semantic distance values  . The structure with the least total distmme is judged most consistent with empirical knowledge and is chosen as the most plausible structure  . 
The semantic distance between words is calculated according to the relationship of t impositions of words ' semantic attributes in the thesaurus  . 
The distance between expressions i the sum of the distance between the words comprising the expressions  , multiplied by some weights ( Sumita ,  1992) . 
5.2 Head word information
The head words with invariable bindings serve as input for distance calculations  . An input for distance calculation consists of head words invariable parts  . The head part is designated in each pattern . Table 3 shows the head parts of the possible substructures for " goes to China town attena  . m . ", which corresponds to the passive arc (19) . 
Table 3: I lead words for ( 19 ) 's substructures passive matched designated head arc pattern head word  ( 9 )  , (19) X to Y X goes (17) X a . m . a . m . a . m . 
(18 ) XatY X Chinatown ( 19 ) X at Y X goes In " X at F ' for the substring " goes to China-townattena  . m " combined with (12) and (17) , the variables X and Y are substituted for the compound expressions " goes to Chinatown " and " tena  . m . ", respectively . Thus , in " X at Y " for the structure in (19) , the input for distance calculation is " goes " for  "3  ; "' and " a . m . " for " Y " . Since the head of " X at Y " is designated as " X  '  , " goes " becomes the\[lead word for (19) . This information is used when ( 19 ) is combined with another substring . 
5.3 Structure selection
The difference in total distance value between the two possible structure sidue only to the distance value of " X at F '  . Table 4 shows the results of the distance calculation in " XatY " for the combination of  ( 7 ) and ( 18 )  , and for that of (12) and (17) . 
( goes , a . m . ) expresses the bindings for variables X is the target expression corresponding to "~'  . 
Table 4: Distance calculation in " X at F ' level input closest example target distance  ( 7 ) + ( 18 )  02 ) +07 ) noun phrase verb phrase ( Chinatown , a . m . )( goes , a . m . )(morning , a . m . )( depart , a . m . )
VnoX'VniX ' 0.50 0.21
According to the distance calculation in the combination of  ( 7 ) and ( 18 )  , " I /' no 3; '" , with the distance value 0 . 50, is selected as a target expression . In the combination of (12) and (17) , "Y'niX '" with the distance value 0 . 21 is selected as a target expression . Thus , the combination of ( 12 ) and ( 17 ) is selected as the structure of the passive arc ( 19 )  . Based on the results of distance cabculations , other partial source patterns for (19) , " X to Y " and " X a . m " , are transferred to " Y'ni3 ( '" with the distance value 0 . 12 , and " gozen X ~ jt ' with the distance value 0 . 00 . Thus , the passive arc ( 19 ) has its source and target structure through the combination of  ( 12 ) and ( 17 )  , the total distance value 0 . 33, and the head word " goes " . 
Then , the structure of the whole input string , which corresponds to (20) , is constructed by combining (19) with (4) . In this combination , " X noun-verb Y ' matches the input string and is transferred to " X'wa Y '" based on the result of distance calulation  . From the combined structure for (20) , the sentence below is generated after adjustment necessary for Japanese grammar  . The words " bus " , " goes " , and " Chinalown " are transferred to " basu " , " iku " , and " Chainalaun ''2 , respectively . 
Basuwagozen i0 jini Chain at a unni ikimasu " ik ~" is the conjugated form of " iku " followed by masu  , a polite sentential-final form . 
6 Preliminary Experiment
In this section , we perform Fmglish-to-Japanese translation to compare the efficiency of the topdown pattern application with that of our new method  , based on the bottom-up application and substructure preference in the TDMT prototype system  . 
6.1 TDMT prototype system
The TDMT prototype system , whose domain is travel conversations , is designed to achieve 2The prototype system assigns a defaul target expression to a surface source expression  . Another target expression is selected when a specific example in the transfer knowledge is closes to the input  . 
multilingual spoken-language translation ( Furuse ,  1995) . While language-oriented modules , such as morphological analysis and generation , are provided to treat multilingual translation , the transfer module , which is a central component , is a common part of the translation system for every language pair  . The system is written in LISP and runs on a UNIX machine  . Presently , the prototype system can translate bilingually between Japanese and English and between Japanese and Korean  . In English-to-Japanese translation , the present vocabulary size is about 3 , 0 00 words 3 and the number of training sentences i about 2  , 000 . 
6.2 Experimental results
We have compared translation times in the TDMT prototype system for two cases  . One case utilizes topdown application ; the other case utilizes the new application method presented in this paper  , which adopts bottom-u pattern application and retains only one substructure using semantic distance calculation  . The translation times are measured using a Spare10 workstation . 
We have experimented with the translation times of some English sentences into Japanese  . 
The following sentences cause only minor structural ambiguity  . Note that a comma is not used in the input sentence  , because it is assumed to be a spoken-language input such as the output of speech recognition  . 
(1)1 have a reservation for tomorrow.
(2 ) Will my laundry be ready by tomorrow ? ( 3 ) You can walk therein about three minutes . 
(4 ) Then may I have your credit cardnumber please ? Table  5 shows the translation time of the above sentences  . For these translations , not much difference could be seen between the new bottom-up method and the topdown method  . For such inputs TDMT can quickly produce the same translation results with either method  . 
' Fable 5: ' Danslation time for short sentences input sentence  ( 1 )   ( 2 )   ( 3 )   ( 4 )  #of translation time ( see ) structures top ~ new ~ --20 . 18 0 . 17 4 0 . 17 0 . 20 4 0 . 38 0 . 35 11 0 . 85 0 . 7 0 The following sentences cause much structural ambiguity because of PP-attaehment  , relative clauses , conjunctions , etc . 
3In the Japanese-to-English translation system , the present vocabulary size is about 5 , 000 words . 
416  ( 5 )   7'his salescler k doesn't understand anything 1 say and i'm wondering if you wouhlhelp me explain what \[ want  . 
(6 ) Could I please have your name the date of arrival and the number of persons in your party ?  ( 7 ) 7 bll somcone at the , fl ' on tdesk what game you want to scc and what type of seat you want and they ' llget the tickets for you  . 
(8) I h , fl som claun dry to be cleaned bul I can't remember where the clcaners is and I was wondering if you could help me  . 
Table 6 shows the translation time of the above sentences  , hit heabove translations the same translation results could again be obtained for both methods  , l lowever the new method can achieve a far more efficient translation than the tol>down metho  ( t . 
Table 6: ' l ' ranslation time for long sentences it , pUL
S ( ! ll ~ oell C ( \]  ( 0 )   ( r )   ( 8 ) \[~ translation ti , ne\]!4 . oa //2 . at/1le, . to ~ . ~7_3  #ofs Lrl I ( : Lures Average tramslation times in the topdown method were  1  . 15 seconds for a 10-word input and 10 . 87 seconds for a 20-word input . Average translation times in the bottom-up method were  0  . 55 se (: onds for a 10-word input and 2 . 04 seconds for a 20-word in l ) ut . The translation time in the topdown method is consider e  , d to t ) e ( : h ) sely relate ( l to then nmber of possibh ~ stru (  ; tures , while l , he translation time in our new method is not direcdyretle  ( -ted by this number . The inc . rease in the . number of substructures retained will , the . new method is much smaller than that of the number of possible structures in the topdown method  . Therefore , our new method can efficiently translate a longer input string having many  ( -ompeting structures . 
Also , we have performed a small translation-quality experiment on the two pattern application methods with the  95 untrained sentences within the system's vocabulary  . Boththet Ol ) -down method and the proposed bottom-up method gave the correct translation \[ br the same  60 sentences with a success rate of 63  . 2% . ~' o , . only two sentences , difl > rent structures we . reproduced by the two methods ; however , all of them were incorrect translations . This experimental result shows that our new translation strategy maintains translation quMity  . 
Similar results , which show the llSe~llhles S of the new TI ) MT tbr spoken Janguage translation , were obtained in otherty l ) es of translation such as Jal ) an ese-to-English ( or , -Korean ) translation . 
7 Conclusion
We have proposed an increlnental translation method in Transfer-Driven Machine'l Yanslation  ( TI ) MT )  . in this method , constituent boundary patterns are applied to an input it  , a bottom-up and left-to-right fhshion . Additionally , by dealing with best-only substructures , the explosion of structural ambiguity is constrained and eflq  ( -icnt translation of ~ lengthy input can be achieved  . 
Through preliminar yexl ) erimentation , our new TI ) MT hasb (' ~ e . n shown to be efficient and particularly promising for spoken dangnage translation  . 
One important future research goal is tile in- ( ' or poration of incremental n . or phologieal analysis and generation into the prot ) osed translation strategy , which would provide as in mltaneous interpretation mechanismt brN  ) plication to at ) ra ( '-ti ( ' alspoken-lm , guage translation system . Also important is the introduction of a repair mechanism to correct the I  ) est-first results . 
References
W . Finkler and A . S('hauder 1992. FA fects of In.
(- remental () utl ) ut onlncrement MN atural \] , anguage (~ eneration . In IOlh I , \] uropean Confer?enee on Artificial Intelligence  , \[) ages 505-507 , 
Vienna , Austria.
O . l " ur use , l " , . Sull'lita , and H . \[ ida . 1994a . 
' l'ransfi:r--Driven Machine'l Yans ladon Utilizing l  , ~mpirical Knowledge ( in Japanese) . 7' rans ~ actions of lnformah on Processing Sot , c@of
Japan , Vol . 35, No.3, pages 414425.
O . Furuse , and il . \] ida . 1994b . Constituent Ik ) undary Parsing for l Cxample-llased Ma ( ' hine Translation . Inl ) roe . 4 Uoling '9~, pages 105
III.
O . li'uruse , J . Kawai , H . Iida , S . Akamine , and I) . B . Kim .  1995 . Multilingual Spokeml , anguage Translation Utilizing Translation Examples  . In Prec . of NLPRS'95, pages 544549 . 
M . Kay .  1980 . Algorithm Schemat and Data Structures in Syntactic Processing  . 7> chnical Report USL-80-1~2 , XI ~; ROX Pale Alto Research

C . Kempen and l'\] . lh)enkamt ) .  1987 . An \] n ( ' re-mentall ~ rocedural Gra Hunar for Sentence Formulation  . Co . qnitiv c Science , 2(11): pages 20:l258 . 
il . Kitano .: 1994. The g < DMDIALOG System.
In Speech-2b-Spcech75"anslation , 11 . Kitano , Kluwer Academic Publishers , pages 47113 . 
lie Sumita and 1 t . 1 ida .  1992 . Example-Based Transfer of Japanese Adnominal P articles into English  . IEICIs ' 7'ransaclions on Information and Syslems , F75-1) , No . 4, pages 585594 . 

