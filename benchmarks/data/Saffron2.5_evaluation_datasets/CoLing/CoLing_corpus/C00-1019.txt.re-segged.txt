Automated Generalization of Translation Examples
Ralf D . Brown
()a . lnc'g'c Mellon Univ clsity , l~a . nguage Technologies 111 stil;ul : (' . 
l ) it tsl)urgh,I)A\]52 13-3890
ralf+~,/cs.(;1nu.cdu
Abstract
l~t : ovious work has shown thai adding gen-er a . liza . tion of the exa . ml ) les in the corpus of a . nexa . ml ) le-1) ased machine tra . nsla . tion(I'31 LMT ) system ea , n reduce 1; here ( ltfire . damounto\['pre-tra . nsla . tedex a . ml ) le textl ) yas\[iltl(;\]l is a . ii order o\['magnitude for Spa . nish-l';nlish and l,'rench-l~;nglish I+',I~Mrl ' . Using word clusto . t : itlg to a . tt-toma . tica Jly generalize the example e or l > uS ca . n provide the majority o\['thisinl provement for l  , ' rench-l'hlglish wil ; hnonlanua Iilltervelltioll ; the prior work required a . la . rgeI ) iliugual dic-lionary ta . gged wil ; l1) a . rls of speech aud the manual crea . tion of gl ' . %llllll . : ll " rules . /~ y seeding the clustering with a . small a . mount of manually-crea . tedi M ' or ma . tion , event ) el ; tert ) erl ' or nla . nceea . nbea . chieved . This pa . l ) ev descril ) es a . method whereby bilingual word clustering ca . n1) eper-\[brined using sta . nda . rd'nto,zoli'n . q ttal document clustering techniques , a , nditse\[l'ectiveness at re-ducing the . size of the examl ) le corpus , ' equire(I . 
1 hltroduction
I' ; xanq)le-Iased Machine'l'ransla Lion(I' ; IM'I') relies on a . collection of textual units ( usually sentences ) and their tra , nsla , l , ions . New text , o1) etra , nsla , tedisnla , tcheda , ga , inst the source-langua . geha . If of the colh'x;tion , and the corresponding tra . nsla . tions from the ta . rget-langua . gehalfaxe used to generate a . l ; ra . nsh ~ tion of the new text . 
l ~ x perience with several language pairs has shown that producing a  . nEBMT system which provides reasom t . blet , ra . nsla . tion coverage of unrestricted texts using simple textual matching requires on the order of two million words of pre-translated texts  ( one million words in each l ; mguage ) ; if either la . nguage is highly in \[ letting , polysynthetic , or ( worse yet ) a . gglut in a . tive , even lllorotext will be required . Itma . yI ) edifficult , time-consuming , and expensive to obtain tha . tmuch pa . rallel text , pa . rtieula . rly for lesser-used la . nguage pairs . Thus , it ' one ' wishes to develop a . newtr,~nslatorra . pidly a . nda . tlow cost , techniques are needed which permit the 131~MT sys~tom to 1  ) erform just as well using substantia . llyless example text . 
lk ~ th the C , a . ij in Ii ; I~MT system 1) y Veale and ~" r\V a . y(\]997) and 1, hea . uthor'sl~\]~h/lIsySteln(I999) COllVel't ; he examples in the corpus in to teml ) la . tesagainst which the new text sea . nI)ema . tched . ( la . ij in va . ria . I ) lizes the wellformed segment mappings between source a  . ndta . rget sentences 1; ta . ti is able to find , using a . closed set o\[' markers to segment 1 . he input into l ) hrasos . 
q ' hea . utllor ' . ~syslemi ) er\['orms its generaliza . tiollusing equix , a . lence classes ( both syntactic a . ndse-ma . ntic ) a . nda . production-rule grammar . First , any occurrences of terms conta , in edina , nequivalence class are replaced l ) y a . token giving 1 . he name of the equiw dence (: lass , a . nd then the gramma . rules a ~ reused to replace l ) a . tterns of words a . n d tokens I ) y more genera . l tokens ( such as < NI '> for noun phrases ) . (\] town , 1999) showed t\]la . tone ca . n reduce the corpus size by as much as a . \] lordero\['ma . gnitude in this way . 
( liven l ; ha . t , explicit , ma . llua . lly-gom~ra . tedequi-va . lence classes reduce the need for examl ) le text , an obvious extelmion would l ) eI ; o ; ~tte\]nl ) tlogelleral . et ll(~seclasses a . ul;olna . tica . l\[y froll l the corpus of pre-tra . nslated exanlples . This pa . -1) or describes () lie ~ q ) l ) roa , ch to a . utoma . tedex-1; racl ; ioll of equiva . lence classes , using clustering tecl miques . 
Therema . inder of this l ) a per describes how to 1 ) erform bilingua . 1 word clustering using standard monoh ; ngual document clustering techniques 1 ) y converting the problem space ; the va . rious clustering algorithms which were inves-tiga . ted ; mid the effectiveness of generaliza . tion using the derived clusters a . t reducing the required amount of example text . 
2 Converting the Problem
The task of clustering words a . ccording to their occurrence pa , tterns ca , n 1) e t e s t a , tedasa , sta , n-dard document-clustering task by converting the l  ) rol ) lemsl ) a . ce . For each unique word to be clllstered , crea . tea . l ) seudo-doculnent conta . ining the words of the contexts in which the ft word N  ) -identifier . After the pseudo-documents are clustered , retrieving the identitier for each document in a particular cluster l  ) roduce stile list of words occurring in su\[\ [ iciently similar contexts to be considered equivalent \[' or the l  ) urposes of generalizing an EBM ( 1 ~ system . 
By itself , this approach only produces a monolingual clustering  , but we require a , bilin-gum clustering fox " proper generalization since different senses of a word will appear in differing contexts  . The method of Barrachina and Vilar ( 1999 ) provides the means for injecting bilingual information into the clustering process  . 
Using a bilingual dictionary--which may be created fl ' om the corl  ) us using statistical meth- ( )<Is , such as those of Peter \] ~ rown el al ( 71990 ) or the author's own l ) r ( ~ viotls ? work ( Brown , 11997) and the parallel text , create a roughma . pping1 ) etween the words in the source-language half of each translation example in tile corpus and tile target-language halfel ' that example  . Whenever there is exactly one l ) ossible translation candidate listed for a word by the mapping  , generate a bilingual word pair consisting of the word and its translation  . This word pair will be treated as an indivisible token in further processing  , adding bilingual information to the clustering process  . \] eorming 1 ) airs in this manner causes each distinct translation of a  . word to be treated as a separate sense ; although translation pairs do not exactly correspond to word senses  , pairs can be formed without any additional knowledge sonrces and are whattile EBM:I' systern requires for its equivalence classes  . 
1 , ' or every unique word pair found in the 1 ) re-vious step , we a . c curnulate counts for each word in the surrounding context of its occurrences  . 
The context of ~ n occurrence is defined to be tileNwords immediately prior to and the N words immediately following the occurrence  ; Ncurrently is set to 3 . Because word order is important , counts are accumulated separately for each position within the context  , i . e . for N = 3 , a particular context word may contribute to any of six different counts  , depending on its location relative to the occurrence  . Further , as the distance ffoln the occurrence increases , the surrounding words become less likely to be a true part of the word-pair's context  , so tile counts are weighted to give the greatest importance to the words immediately adjacent o the wordpair being examined  . Currently , as ilnple linear decay fl ' om 1 . 0 to-~is used , but other decay functions such as the reciprocal of the distance are also possible  . Tile resulting weighted set of word counts tbrms the above mentioned I  ) seudo-document which is converted into a term vector Ibr cosine similarity computations  ( a standa M measure in information retrieval , defined as the dot product of two term vectors normalized to unit length  )  , If the clustering is seeded with a . set of initial equivalence classes ( which will be discussed below )  , then the equivalences will be used to generalize the contexts as they are added to tile overall counts \[' or tile word pair  . Any words in the context for which a unique correspondence can be found  ( and f ' or which the word and its corresponding translation are one of the pah:s in an equivalence class  ) will be counted as if the name of the equivMence class had been l  ) resent in the text rather than the original word . For example , if days of the week are an equivalence class , then ': ( lidhecome on Fridas : ' and " did hele ave on Mends3:' will yield identical context vectors for " come " and " leave "  , maldngite asier\['or those two terms to chlster together  . 
To illustrate the conversion process , consider tile li ' rench word " ( ' in q " in two examl ) les where it translates into English as :: five " ( thus forming tile word pair " cinq_five " ) : < NUt > < NI/L > Leci , zqjoursd cpuisla < NUL > < NUL > 73e five dags si~zcelhe ellcs com'me ~ , cc~w~ , tc~zc in qj ours . < NUL > they will begin i ~), five days . < NUL > where < NU t > is used as a placeholder when the wordpair is too near the beginning or end of the sentence for the flfll context obe present  . 
Note that the word order on the target-language side\]s not considered when building the term vector  , so it needll Ot be the same as on the source -language side  ; the examples were chosen with the same word order merely for clarity  . 
The resulting ternl vector for " cinqJive " is a . s follows , where the numbers in parentheses indicate the context word's position relative to the word pair under consideration : 
Word Occur Weight < NW l . >(-3) 1 0 . 333 elles (-3) 10 . 333 1 0 . 667 commencer on t(-2) 10 . 667
Le(q ) 11 . oooen (-1) 11 . 000 jours ( J ) 22 . 000 depuis (2) 10 . 667  . (2) 1 0 . 667 la(3) 10 . 333 < NUL > (3) 10 . 3 33 Term vectors such as tile above are then clustered to determine equivalent usages among words  . 
1263 Clustering Approaches
Atota . l of six clustering a . lgo Hthmsha . v(~I ) oen1 . ested ; throe variants of grout ) - a . vora . go . ('\] tl sl . (' . , '- insa . ndi , hree of agglomer a . tive clustering . In-cl'omentalgroup-a . vera . ge clustering was ilnple-mented tirst , to provide a . proof of concopt , borore the COml ) ut a . tiona . lly more expensive a . g-glomerative ( bottom-up ) clusteril ~ g wasiln ple-mented . 
The incremental groul ) - a . vera . gea . lg or il ; hm sallexa . mine each word pair in turn , computing a similsu : ity measure to evory existing clust or  . If th(;1)(; stsiinila . rity measur ( ; is al ) ov ( ~ a . l)r (; del ; er-nf in (' d threshold , the new word pair is i ) laced in tile corresponding cluster ; other w is % a now ( ; \] usi ; eriscrea . ted . The throe varianl ; sdiltT , r only in tile simila . rity moasure eml ) loyed : : 1 . cosin (; similarity 1)(;1; w(~(; n1 , h(~i)s(;u(lo<loc-umonl , a . nd the centroido 1"the oxisting cluster ( standard grOOUl ) -a . vera . geclus to . rillg ;) 2 . a . verage of ' i ; \] locosine similar il ; iesl ) otwe ( ; n thel ) seudo-docuni ( ; nl ; a . ndallnl(;nll ) erso\['the0xisting(:lust(; , '( a . voragc-link clustor-ing ) 3 . square root of '1; h(;a . vcrag(; of 1; lie S(luared cosine simila . r\]l;io . sI ) ct we onl ; hel ) seudo-(locuinentan(\]allmolnl )( ~ , ' sorlhe existing (' hlster ( rool . -nloa . n-sqllar ( , nlo(lifical . ion of average-liNl ? clustering ) Thoso i ; hro(~vn ria . tiol , S give h l c , ' eas\]nglyIIl()l'(':weight to 1 , hone a . rermcml ) ersof'thooxist . ing clust ; cr . 
Timt)o(;1; oin-u1) a . gglomera . tive algoril ; hms all funcl ; ionI)y(;tea . tills a . clustor For each I ) Seudo-(\[o (: unlenl , , t;hon r(;i)(;a . 1 ; ( ; (llyln(u:gingl:li ( ; two clusl ; or s witlithe\]iighesl ; siinila . ril , yscore unl , i l110( , WOC\]tlS , or H\]lSt , vo , %  , q\]ii lila , ril ; y . ~(: Ol '( ~( ~ x (' . (~(;d-ingal)re(Iol ; or nlino(\]1; hl:es hold . The three vari--;/ , IIi ; S/ , ga , ill differ () lily ill1; lioS\]liiilaril , ylllOlStll'O
Ollll ) loy c(l:\] . cosine simila . rity between clust or centroids ( st ~ ul(la . rdagglomei : a . tivo clustering ) 2 . a . vera . ge of cosines it nilari Ly 1 ) etweenmen > l ) ers of the two clusters ( a . vera . ge-tink ) 3 . nia . xilnal cosino similarity betwe on a . nypairOfni (' . nll ) oi : sofl , \] iei ; wo clusl ; (' , rs(single-lin \]) l"oi : (; a cli of the va . i:ia . tions a . bovc , the l ) r(~(l(;1 , er-ni in cd(;hreshol(I is a . funci;ion of word\['r(xluoncy . 
Two words wliich each a . l)l)ea . r only on c(Y in the entire tra . ining text a . ndha . rea . high simila . rib , score a . romore likely to ha . rea . l)l)ea . red in siniila . r contexl ; sI ) y cohicid e . ncel : ha . n1; wo wor(ls which each a , 1) pea . rill1;hetraJliil/g1;(;xi;liftytin-its . 
l,'ro(tUOI/cy10-\]2-\]5>16
Threshold-1\] . 00 2 0 . 85 3 0 . 80 4 0 . 75 0 . 70 0 . 65 0 . 60 9 0 . 55 1 \] 0 . 50 0 . 45 0 . 40I , ' igure \]: Chtsleling'l'hro . shold tunction I ~ brex a . ml ) le ~ when using threowords one i-thorside as context  , a . nda . linca . rdcca . yint ; ermweights , two singleton words achievo a . sinlitar-it ; 5, scor(', of () . 321 (1 . 000 is them a . ximumt)os-siblc ) if just one o\["theimmodia , telya(lja , c cnt words is the sa . mc for 1) oth , evon if none of '1 ; hoother five context words axe thesa , mc ' . /ks the number o\['occul'renc (' s increases , l ; ho contri \]) u-l , iont , o the simila . rit , yscore o\['hi dividua . l words decreases , ma . kingitless likely 1 ; o encounter a high score by chance . Ilencc , we wish to set a . si ; ricl ; er1;hres\] , ol(l\['or clustering low-frequollcy words i ; hatihigho , '- l ' roquel my words . 
The thr(~sholdFunction is exI ) ressc(lin 1 , ( ~ rmsoftimfr ('( lU(mcyo1"occurrence inth(~1 , ra . il , ing1 . exl . s . I " or si , ,gle , ull (' lus (; ere(\[vord pairs , I , hot're quollcy is sinll ) ly1 , 11 on umb ( ~ rol'1;hnosI , he wor(I1) a . ir was ( m (: ounl , ( u ' ( , d . When I)e , '\[' or n > ing groul ) - a . \, erag ( ; ; lu . qlx ; ring , thel'requoncyas-signodl ; () a . ('\] / ml ; (' . ristim sumo\['(; h(;frequen cios of a . ll the members ; for agglomer a . l . ive (: lust (' . ri ) lg , the \[' re(ltten ( ; y is the sum when using cent ; roids and 1 , helnaxim unlfre(lucn('y < tn long them ( ; m-I ) oJ ' Swllen using l ; heaverage or lmarest- , ,(;ighl)or , ~ imila . rity . The va . lu(~of'the(;hr(>shold\['ora . given pair of (' lusi , (' ms is the va . lue of timthr(~,~holdI'unctiona . t the lower word frequency . \] : igure 1 sl , ow sl , h(' , threshold tunction used in the ( , Xl ) Cr-iments whose results a , rcrel ) or tcd here ; cluster-ins is only allowed if the simila , rity measure is a . 1) ove the indicated threshold vahm . 
On its own , clustering is quite suc ( : essfill for generalizing EBMT ( ' Xaml ) les , I ) ut the fully-a . utomated t ) roducl ; ion of clusters is not com-t)a . tible with adding a , l ) roduction-rule gra . mma . ras(lcscril)od in(l~rown,\]999) . Therel ' or e , the clustering process may 1) e seeded with a . set of manua . lly-gc'nera . ted clusters . 
V V hell seed clusters m'e a . va . i lablo . , the cluster-ins process is moditied in two ways . First , l ; hegr OUl ) - avera . gea . pl)roa . clmsa . ddaninitia Jclusl ; erforo . a , (' h soed clusl cr and the a . gglolnera . tive ap-pair ; these initial clusters are tagged with the name of the seed cluster  . Second , whenever a tagged chister is merged with an untagged one or another cluster with the same tag  , the combination inherits the tag ; further , merging two clusters with differentags is disallowed  . As a result , the initial seed chlsters are expanded by adding additional word pairs while preventing any of the seed clusters from themselve sinerg-ing with each other  . 
One special case is handled sep a . rately , namely numeric strings . If both the source-language and target-l~mguage words of a word pair are numeric strings  , the word pair is treated as if it had been specified ill the seed class < number >  . Word pairs not containing a digit in either word can optionally be prevented fi'om being added to the < number > chlster unless explicitly seeded in that cluster  . The former feature eusures that n unibers will a pl ) ear in a . 
single cluster , rather than in multiple chlsters.
The latter avoids the inclusion of the many non -numeric word pairs  ( primarily adjectives ) which would otherwise tend to cluster with numbers  , because both they and numbers are used as modifiers  . 
Once clustering is completed , any clusters which have inherited the same tag ( which is possible when using agglomerative clustering  ) are merged . Those clusters which contain more than one pseudo -document are output  , together with any inherited label , a . nd can be used as a set of equivalence classes for EBMT  . 
Agglomerative chlstering using the maximal cosine s in fila  . rity ( single-link ) produced the subjectively best clusters , and was used for the experiments described here . 
4 Experiment
The I nethod described in the previous two sections was tested on French-English EBMT  . 
The training corpus was a subset of the 1BM Ilansard corpns of Canadian parliamentary proceedings  ( Linguistic Data Consortium ,  1997) , containing a total of slightly more than one million words  , approximately half in each language . Word-level alignment between French and English was pertbrmed using a dictionary containing entries derived statistically from the full Hansard corpus  , auglnented by the ARTH , French-English did ; ion a . ry(ARTFL Project , 1998) . This dictionary was used for all
EBMT and chlstering runs.
The efl'ects of varying the amount of training texts were determined by further sl  ) litting the training corl ) us into smaller seglnents a M using differing numbers of segments  . For each
Clust I ; 1563; 1.652
Melnbersl J . IS'l'O Il EHISTOIW
ECONOMIE ECONOMY
CERTAINI!~MENTCEITAINLY
CERTAINEMENT SURELY
CERTESSURELY
JAMAISNEVER
PASNOT
I~EUT-F , TREMAY
H ~ OI~ABLEMENT PROBAI~LY
QUEONLY l.lfl';NNOTItING
S\[JREMENT CERTAIN LY
SUREMENT SURELY
VRAIMENT REALLY
CONSER VATEUR CONSEIWATI\q~J
CQNSER VATEUIITORY
I ) EMOCIi,NI.'IQUEDEMOCtl,ATIC
I ) I~IV lOCRATIQUIENDP
LIBI~RALLII3ERALl ) lANII , A%LSLAS\]\])ERNIIjEIESPAST
I ) ERNIIERIDS Ih ; CENT
PIOCI\]AINF,SNEXT
QUEL QUESFEW
QUF , LQU h ; SSOME
AVONSHA\q';
SOMMESARI'~pptr,p1, LLC10 RALLCAMPAIGN
EM~2CTOIi , AILF ~ EIAECTION
FI~I)I~RAM:,S-I ) IOX qNCIAL 1,;S
FEI ) ERAL-PllOVIN CIAI,
INDUS'FRIEM3~SINI)US'I'IIIAI,
OUVRIERESLABOUR
FA(,J()N h;VENT
P ? 17'I ~ VIDLNCLCLEARLY
EVIDh;NC\]'; OBVIOUSIN
HOMMF , SPOIATICIANS
PRISONNIFJ SPR/SONEIS
RETOUR , BA . CII(,
REVENIRBACK
CONVENUAGREED
SIGNESIGNEI)
VUSEEN
AGRJ COLE AGR1 CUL'I'URE
ENT'IERAROUN\])
ENTIERTIll ROUGI\]OUT
OCCIDENTAL WESTERN
AVIDUGLI~SBI , IND
CIIA . USSURI'2 SSI-IOES
CONSTRUC ; I'EURS BUILD h ; RS
PENSIONN , F , SPENSIONERS
RISTRAITESPENSIONERS
VETEMENTS CLOTHING
POISSONFISI\]
PORCIK ) RK
Figure 2: Sanli)le Chlsters the corl ) uS a . recones . Lena . ted into a . single file , which is used as in l ) ut\['or both the clustering l ) t : ogra , ma . nd the EIM:I . ' system . The clust ; er-ltlg1) rogranlisrtltt( ; o detern fine a . set o1" equivalence classes , a . nd these classes a . rethen pro-vk led to tile I ' ; IM : I'systetna Jest with the tra . in-ingexa , mples to be indexed , lleld-outlla . nsa . rd text ( a , 1) I ) roxima . lselyd 5, 0()O words ) is then tra . ns-laLed , + tndtile l ) ercent a . ge of tile words in the test text for which the I ~ ; I~M~ . I'system could lindma , tchesa . nd generate a . tl ' a . lasla . tion is determined . 
To test the efl'ects of adding seed ( ' lttsters + a set of ' initia . 1 clusters was generated with the \] te . lp of the AI : I'I"I , dict ; i on a . ry . First , the 500 most frequ ( : nt words in the milliou-word\]\]~msa . rdsul ) se . t ( excluding pun (' . \[; uation ) were extracted . These terms were then nmtched a . gMnst the AI ~ . TFI , dictionary , removing those words which had multiword transla . tions as well a . ssevera J which listed multil ) leparts el " sl ) eech For the same tra , nslation ( multil > lel > a , rts of speech can only 1 ) e used i \[' the corresi > on ( I-ingtra . tlsla . tiolls are distinct f'rom each <) ther ) . 
The remaining d20 tra . nslal . ion pairs , tagged for l ) a . r to \[' speech , were then convert : e(linl , ose(~(I clusters a . ndl ) rovided to the clustering t ) rogra . nl . 
Tofa . cilita . t experiments using the t ) re-existing l ) roduction-rule grammar , tire a . d(litiona , Itra . ns-la?ion I ) a , h's from the lna , nually-gelmra , ix ~ (1 equiv-aJe . n(:e('la . sses were a . ddedt ; ol ) rovide seeds for five equiva . \] encelasses which a . renot , l ) resent in the diction a . ry . 
5 Results
Then lethod ( les('ril>edi , Ithisl ) a , per does ( Sttl ) jectively ) a , very good jol > of clustering like words to get \ ] wx  , alid using the clusters to get l-era . lize EIMT gives a . (; onsider a . I ) leboost , to the . 
l)etTVol'ltl~-Lt , ce+of'thel<\]\]\]\]\/l~\['SySl ; (': lll . 
l " igure 2 shows a , sa . ml ) ling of tilesma . ller clusters generated from 1 . \] million words o\['Hansard text . While then mmbers of a , cluster are often semantica , lly linked ( a , s in cluster 848 , which cotltains types of politica . 1 paxl ; ies , or clusters tag ), they need not be . Those clusters whose members a . renot semantically linked gen-eraJly contain words which a  . 17 e all th es a . mel ) a . rt of sl ) eech , numl)er , a . nd gender(a . s in (: luster 2472, which cost a . insexclusively plural nouns ) 1) ut a . s will be discussed in t ; he next section , even those chlsters whose , neml ) ersa . retota . llyunrela . tedmay 1) e useful a . nd correct . . One J'a . h : ly cotlltl \] Otloccurrelt ce a , lll Ollg the smaller clusters is that various synonymous  1  ; ra . nslnt ; ionso\[a word ( from either source or target language ) will chlster together , as in cluster \]652 . This is pa . rticula . rly useful whentile ta . rget-language word is thesa . me , a . sth is a . llows va . rious wa . ys of expressing t . he same thing to be tra . nsla . ted when ~ l . llyOf " those\['OFtlIS~/l'e present in the tra  . ining (' or pl . ts . 
Figure 3 shows how adding a . utoma . tically-generated equiva . lence classessul ) sta . ntially increases the covers , we of the EI 3MT system . A1-terna . tively , l nuch less text is required to rea . cha . specific level of coverage . The lowest curve in the . graphistile percentage of the d5 , 0 00-word test text for which the EIM:J'system was able to genera  . tetra . nsla . tions when using strict lexi-c+d matching against the trahling corpus  . The lop-most curve shows the best perform a . nce , previously achieved using 1) otha , la . rgese to feqt tiva-lent o classes ( in t ; he fornt of tagged entries from the \]\ ItYI'II+ ' I  , dicl ; iona . r v ) a . nda . production-rule gra . nlntar(\]rows,J999) . Of the two center curves , the lower is the performs . nee when gen-era . lizing the tra . ining corl ) us using the equivalence classes which were autolna  . tica . lly goner-ated from that same text , a . nd tim up per shows the t ) er form a . tl ce using (' lustering with the d25 seed pairs . 
/k scanb ~ , seen in Figure 3 ,   80% coverage of the test text is achieved with less than  300  , 000 words using nta . ntta . lly-crea . te(lgener-alizat , ion information a . nd with approxima . te-ly 300,000 words wllen using a . utonmtically-creaJ ; edgenera . liza . tioni form a . tion , but requires 1 . 2 million words when not using genera . liza . -ties . 90% covers . we is reached with less than 500 , 000 words using lna . nua . lly-ereat . ed in form a . 
liona . nd should I > ereached with less t . ha . n1 . 2 tnillion words using a . utonm . tically-crealed gen-era . lization in form a . tk)n , versusT million words without genera . liza . tion . T iffs reduction I ) y a . tim- ( or of four to live in tile amount of text is accom-1  ) lishe ( I with lit ; tieo ) ' no degradation in the quality of the tra . nsla . tions . Adding a . small amount of kt , owle ( lge in the f ' or n to 1"425 seed pairs re- ( lutes the required trahling text ; even further ; this ca . nla . rgely beat tril ) uted to the merging of clusters which would otherwise have rema  . ined distinct , thus increasing the level of generaliza . -ties . 
Adding the production-rule gratnma . r to the seeded clustering had little effect . When usirt g more than 50,000 words of tra . ining text , the increase in coverage from adding the gramma , r was negligible , and even with the sma . llestraining corl ) or a , (, he + increase wa . svery modest . 
Using thesa . methresl tolds tha . twere used in tilefully-~mtonla . ticcase , clustering on 1 . \] million words expands the initial 425 word pairs in 37 clusters to a200 word pairs , a . nd adds a . n additions . 1555 word pairs in \] d ( ) further non-(;t:ivia , 1 clusters . This (: Oral ) ares very fa . vorably
Oo(D



O'si--x- .   .   .   .  :  .   .   .   .   .   . x .   .   .   .   .   .   .   .   .   .   . x .   .   .   . i .   .   .   .   . -x .   .   .   .   .   .   .   .   .   .  *  .   .   .   .   .   .   .   .   . 
~-.~+", zz
V 3....i ~,( a "/, /// / i
I 0.2 0.4 0.6
Corpus Size ( millions of words ) lexical matching only -~-- with automatic clustering  -4--clustering   w/425 seeds-D-- , full manualg ~ neralization -- x---0 . 8 l i'igure 3:   BI3MT \] ~ el'formance with and without Generalization to the  3506 word 1  ) airs in 221 clusters tbund without seeding . 
' l'he1) rogram also runs reasonably quickly.
The step of creating context term vectors converts approximately  500  , 0 00 words of raw text per minute on a 300 MHz processor .  1 , ' or agglomerative clustering , the processing time is roughly quadratic in the number of word\]  ) airs , with a theoretical cubic worst case ; the 17 , 5 27 distinct word pairs found from the million-word training corpus require about  25 minutes to cluster . 
6 Discussion
One statement made earlier deserves cla . rifica-tion:l ; hemembers of ~ cluster need not be related to each other in any way  , either syntactically or semantically , for a cluster to be useful and correct . This is because ( absent a grammar ) we do not care about the features of tile words in the cluster  , only wh , cthc ~" their tr(msla-lion , sJ bllow the same patt crT ~ . 
An illustration based on actual experience is useful here  . In early testing of the group-average clustering algorithm with seeding  , the < conjunction > seed class of " and " and " or " was used  . Clustering augmented this seed class with " , "( comma . ), " in ", and % y " . One can easily see tha . t the comma is a valid member of the class , since it takes the place of " and " in lists of items  . 13 ut wllat about ': in " and "135; " , wl fich are prepositions rather than conjunctions2   11' one considers the tra . nsbttiont ) attern__ 7~ C\[?__F r'eNl ~ I'>cNP2 --+ EW/A 1   1 F-~:/NI ) : 2 it becomes clear that all of the terms in the expanded class give a correct translation when placed in the blank in this pattern  , lndeed , one could imagine a production-rule grammar geared toward taking advmltage of such common translation patterns regardless of conventional linguistic features  . 
7 Conclusion and Future Work
Using word clustering to automatically generalize the example corpus of an I  ; BM'I ? system can provide the majority of tile improvement which can be achieved using both ~ manually-generated set of equivalence  ( ' lasses and a pro-duct ; i on rule grammar . The use of a set of small initial equivalence classes produces a substantial further reduction in training text at a very low cost  ( a few hours ) in lal ) or . 

An obvious ' ~ x tension to using st, . e\]clusl;orsiS(;(1+180( , 110I'Oslll ;()\[' a , ClU , 'ql ; ': l ' illg1"I+111 ; IS l ; tl?i \] lil ; i a \] seed\['ora second it ; ra , l;io\]to1'chlsl , er-ing , sin ('' , th ; addition alg , neralization of lo-;a . iCOlll ; ! xl ; scnabl(;d1) ythela . rgcrs , e(1clusl , (, J's will l ) or mita . ( l(litionalex\])allSiOllO\['LIloclusl,(Brs . 
l : or such iter a . tivo : lustoring , a . II but the last roun ( 1 shou I ( 1 l ) l' ( 2Slllllal ) lyUSesl ; ri( ; Ler 1 , hresh-ol(Is , to avoi (1 adding goom any irr ; l , A , antinonl-t)ers Lotim clusLers . I ) rdiminary OXl ) erinmnt shay B been inconclusive -- although ihc result o\['a second it wation ' onta  . insmore , ' . rmsill the ; lusl ; ers , IBBMT ler form a . nce to es not seem to lint ) rove . 
More sophistica . ted ; hlsl ; o . l ' illg ; a . lg ( rithms such as k-lneans and ( l ( ' + terln in Lqtica . nnealingl\]lay'1) rovi(lo\])etter-qua . lity clust ws for bcl , tert)ei't " of lllall ; e:-1+ , ; the (~ xi)ens ( ; of illCl ' O as ( ; (\] t ) ro'e Hsill ~ tim ' . .
This a . i ) lZ : oach to gel WX a . l , inge(luival('Jw(~cla . sse should worl ( jusl ; as well\['orl ) hrases as I ' or single words , simply hymo ( lil ~ qng ; he conver-Si ( ) ll SLOp1 ; Oel'oat ; ( ; C(lltOXtVeCl ; or sl " or phrases . 
This enhancenmnt would elimi , lal ; ' ~ i ; he current limitation t , hattrat , slal ; ion \]): q , il : Sl , O1) O . clust ( ; red\]\]lUSt ) O single words in 1) oth languages . \ Vot : k or , this n\]o ( lifi;al ; ion is : urP(~ll ; lyttn(lerway . 
An inleresting \[' ui , ur ~( ; xI ) eriment would 1 ) (~ tbr'going gratnnlar rules based ) nst and a . rdgl:all lll:-/,l ; ical\['' . :-1+,l ; tll'(~sSll:has\]) . ~ l , rl , o\['st ) "(': :\] l , and inst , adcrea , tinp ; agran ~ ma , rguid ( , II3 , ; 1~; (' lusters I ' oun ( lfully aul , o ~ tati'ally(wil , houl , sceliug ) fronlth ~ exa . nlllcre\l , . ' Filer , : ( ; n two HI ) y +\ ( lcTait and ' l ? . .iil lo ( I 999) , OXtl':dcl . , - ing tra1~slal , iontal ; l;'+rn,q woul(la . t)poa . rt , o1o . al ); rfe:l ;; oml ) lc'nmnt , as 1; h'5 are it , e\[t'ect lind-i , g : ont ; ext strings wit\] , ( le . slots , while the work descril)ed h(' . relit , ( ls , he fillers I ' (1' tJ ~) s('slots . ( liv ; n the al ) ility to learn such+1 + . gra . mmar without l\]\]a . nual intervmtion , it would \]) e(:onl ' . 
I ) ossil ) l ~ toere ' at ; an I!'I:~MT 8ystm\]usillgg:ql-era , liz , ( le , : aml ) les from nol , hi \] ~ g~n)r ; than l ) ar-allell ; ext ~ which for n ~ any hulguag ( , pairs could also 1) c acquired ah nost fully a , utom ~ tically 1 ) y crawling the World Wide V Vel )   ( Resnil ,  :1 . 998) . 

A\]~ . TFL Project .  :1998 . I"re'nch-?'nglish . Dic-lionarg . Iroject for American and French lesearchi \] the Treasury of  , hel : renchl , anguage , University o\["Chicago . http://-human?ties . uch?cago , edu/kgTFL , html . 
Sergio Barrachinaa .nd Juan Miguel \: ilar . 1999.
Bilingual Clustering Using Monolingual Algorithms . Ill 15 vcecdings of lhel@hlh\]'n . lcrna-~ional ( 7onJ?rence on Theoretical and Methodological Issues in Machinc  7  ) ' anslatio'n ( ~1341-99 )  , pages 7787 , Chester , England , August . 
I ) ctorl ~, roxvH , . l . (; ocke , S . l ) ella \]) iotra , V . I ) ollalh : l , r a , I : . do line l <, 3 . l , afl'erl . y , R . Mercer , and I . I ~ . oossh, .  1990 . A Statistical Approach to Machine Translation . COmlmta Honal Lin- . qui . slic % 16:7985 . 
lalF\]) . \] h:own .  1997 . Autonlated\])ictionaryl ' ; xL racLion lot " l(nowlcdge-l , ' ree:'Example-1 , as cd Translation . Inl ) ~ vccedin : lsofihc , 5' cvcnlhh , l(rnaiional ( . ' o , @ Tvnccon"IJm-orclical and A4 clhodolo:licall ~ ue . sinMa-chi'~c7'an . ~lalion ( TM1-97) , F , ages \]111\]8 , Sant ~ t\]:c , New Mexico , July . ht ; 1; p://-www . cs . cmu . edu/Oral:f/papers , html . 
Rail " I) . lh ' own .  1999 . Adding l , ingttistic l(nowl-edge Coal , exica \]\]'; xamp\]e-\]~asedTra , nsla-tionSystem . In I ) rocccding . softh c12 iEM , hh zl cr national ( , ' onj ) renccon 7' h cor el , icalm zdM clhodoh::licalfss . uc . ~ in Machine 7) ' anslation . 
(7341-99) , pages 2232 , Chesl:er , I ~; ngl and , August . http://www . cs . cmu . edu/~ratf /- papers . html . 
I , illguistic I ) al , a . Con . ~ or Lium .  1997 . lla ~> ' ard(,'ou ~ u . ~ of I ) aralld?'Rqlish(rodt'Yc,~ch . 
IAnguisticl ) at a Consorl ; ium , \]) e cember.
http://wwu.ldc.upenn , edu/.
l(ev in McT l ' a . it and Arturo Trujil \] o .  1999 . Al , atlguag > NeutralSl ) arse-\] ) at a Algorithn lfbr I : xtracting'I'ranslation I atterns  . \]II\] ) ro ( : ccd-in : lsoflhcl'/i : lhlhhztcrlzationalCo ~ @ rcnccon  77~colv:ical and Mcthodoh : gical Is . sues in MachMc7~rmtslatio~t(7'A41-99) , l ) ages 981 ()8 , Ch~ster , l'3 ngla , (1 , August . 
Ihilill ( , snik .  \]998 . I ) ara . llelStrait(Is:A1) re-liminary lnves Ciga . tion into Mining the\V (; br1 for l~\]lingua . 1 e\ . In I ) a . vidl'a . rweI1, l , a . urle (: left ) or , and Edua . rdllovy , editors , Mac . hine 7' a ~ . ~la Zionad the hdbrm . alionSoup : 7' hird(;'on , fcrcncc of IhcA . ~ . .s'ociation for A'lachi~c ' l . anslation in Ihe Americas ( AA4' F4-9S ) , vol-un\]e1529 o\['L ccl'mvNo*cainArZi . /ici all nlcl-ligc:~zcc , i ) ages 7282 , l , anghorne , Iennsylva-ida , () ctler . Springer . 
Tony Vcalc and An(ly Wa . y .  1997 . Gaijin : A ' lhml ) la . te-I ) riven Bootstrapl ) ingAI ) l ) roacll to Exa , ml ) Ie-Ba . sed Ma , chin ( ; Tra . nsla . tion . 
: It\]1 roeced in : p of the NeMNL l ~' 97 . New Mel . hods in Natural Langauge 1) rocessess in 9, Sofia . , lhdgaria . , Sel ) teml)er . http://-wwu . compapp , dcu . ie /" tonyv/papers /- gaijin . html . 
Ellen M . \: oorhees .  1986 . lmplel\]mntingAg-glomera . tivellier archical Clustering Algo-rithms for Use in \]  ) ocument l/etrieval . 
I'n Jbrmationl ~ rocessi'ng and Mana . qeme'nt , 22(6):d 65,176 . 

