ANAU TO MATIC PROCESS ING OF THEN A TURALL ANGUAGE
INTHEWORDCOUNTSYSTEM
HIROSHINAKANO , SHIN'ICHIT SUCHIYA , AKIOT SURUOKA
THENATION ALLANG UAGERESE ARCHINS TITUTE
3-9-14, NISHIGAOKA , KITAKU , TOKYO , JAPAN

We succeeded in making a program having
the following four functions :
i . segmenting the Japanese sentence 2 . transliterating from Chinese characters ( called Kan~i in Japanese ) to the Japanese syllabary ( kana ) or to Roman letters 3 . classifying the parts-of-speech in the Japanese vocabulary  4  . making a concordance We are using this program for the pre-editing of surveys of Japanese vocabulary  . 
In Japanese writing we use many kinds of wri ting systems  , i . e . Kan Oi , kana , the alphabet , numerals , and so on . We have thought of this as a demerit in language data processing  . But we can change this from a demerit to a mer it  . That is , we can make good use of these many writing sys tems in our program  . 
Our program has only a small table con-tain ing  300 units . And it is very fast . 
In our experiments we have obtained approximate ly  90% correct answers . 
Introduction
Obtaining clean date is very important in language data processing  . There are two problems here . One is how to input the Japanese text and the other is how to find errors in the data and cor rect them  . The human being is suited to com-plicated work but not to simple work  . 
The machine , on the contrary , is suited to simple work but not to complica ted work  . In the word count system using computers , the machine has simple work ( sorting , computation , making a list ) , and the humans have complicated work ( segmentation , transliteration from Kan~itokana , classification of parts of speech , finding errors in the data , discrimination of homonyms and homographs , ets .  )  . 
However , in this system there is one major problem -- humans often make mistakes  . And , regrettably , we cannot predict where they will make them . Thus we decided to make an automatic process ing system  . This system has to be compact , fast , and over 90% accurate . 
In Japanese writing we generally use many k inds of writing systems  . 
For example,
In this example sentence we find used the a lphabet  ( C , O , L , I , N , G ) , numer-als (8 ,  0) , kana ( hir as an a--the Japanese cursive syllabary -- ~  , O , ~ ,  ~ , ~ ,  ~ , and katakana--the Japanese straight-lined syllabary -- ~  ,  ~  ,  ~  ,  -  ,   , ~  ,  -  , j ~) , Kanji ( ~ . ~, ~, ~ i , ~, ~ i ~), and signs ( . ) . And as you can see , there are no spaces left between words . This makes Japanese data processing difficu lt  . 
Our program makes good use of these dif-ferent elements in the writing system  . 
At present the automatic processing program makes more mistakes than humans do  . 
But we can predict where it will make them and easily correct errors in the data  . 
Objective
Our objective is a system having the follow ing functions : i  . segmentation 2 . tranliteration from Kanji tokana 3 . classification of parts of speech 4 . adding lexical information by use of a dic tionary  5  . making a concordance 6 . making a word list Numbers i ,  2 , and 3 are especially im-portant for our program . Our report will mainly deal with these three functions  . 
The input data is generally a text writ-ten in Japanese  . The output is a concordance sorted in the Japanese alpha-betical order  , giving information of the parts of speech , and marked with a thesaurus number . 


Figure i is a flow chart of our program.
Input is by magnetic tape , paper tape , or card . The input code is the NLRI ( National Language Research Institute ) code or some other code . Of course we have a code conversion program from other codes to the NLRI code  . 
The second block of Figure 1 shows what we call the automatic processing of nat-ural language  . In the supervisor square we check and select the results of the three automatic process ing programs  . 
Some of these programs have many kinds of p rocessing of natural language For example  , the automatic segmentation program involves the classification of parts of speech  , automatic syntactic analysis , automatic transliteration from Kan~ito kana  , and so on .   ( An example will be found in the next section .   ) In the adding lexical information block of Figurei  , we make use of the diction-ary obtained by research into some  5 million words at the NLRI . This diction-ary includes word frequenc i es  , parts of speech , classes by word origin , and a thesaurus number . 
By using the concordance we can find and correc terrors in the data  . As our program is unfortunately not always com-plete  , this concordance is very useful . 
In the output block of Figurei we can choose a variety of output devices -- an alphabet l ine printer  , ak an aline printer , a high-speed Kan ~ i printe ~ , or a Kan~idis play . 
Methodi . Automatic transliteration from Kanji to Roman letters The Chinese characters have many differ-ent readings in Japanese  . For example , /sei//syo//um-//iki/nama / / ai // tachi//tatsu//tate // dachi // ritsu // rittoru/--/ichi // itsu//kazu / hajime // hito / We have to arrange the Japanese words in the Japanese alphabetical order  . 
The program puts the reading way to each word for the word list  . 
The method of selecting the reading is to choose it in accordance with the surroundings of the Kanji in the text  . 
The possible readings for each Kanji are li sted in a small table  . The records in this table are of 3 types-Groupsl , 2  , and 3 represented by numbers i ; 2 , 3 ~ and 4 , 5 , 6 respectively in Figure 2 . 
The Kanji in Groupi have one reading each . The program replaces the KanOi with this read ing  . In Figure 2, No . If alls into this category . We have about 700K anji in Groupi ( ~ , ~  , ~ , ~  , ~ , ets .  )  . 
The Kanji in Group 2 have to wormore readings each . In Figure 2, Nos . 2 and 3 fall into this category . 
The format for these entries is group number , the Kanji , the operation code ( a numeral or Capital letter )   , and the reading ( up to 8 small letters ) . 
The appropriate reading is chosen for the si tuation of the Kanij in accordance with Table i  . 
situat on operation letter front behind AIg 2 C 3 D 4 E 5 F 6 G 7 H 8 untiunti 0 i 0 I 0   1   0 i 0   1   0   1   0 i 0 i u n t i K a n j l i 0   0   1   1   0   0   1   1   0   0   1   1   0   0   1 Kanjiuntii 0   1   0   0   1   0   1   1   0   1   0   0 i 0   1 Kanji Kanjii 0   1   0   1   0 i 0   0   1   0 i 0   1   0   1 O : replace Kan Ji to reading in the table
Tablei . Operation of situation
IINP DT

INFOR MATION CONCORDANCE
Figurei . Aflow chart--339-- ( l ) 1 ? #I < OI~U ? ( 2 ) 2~21K8A ~ UTA ? ( 3 ) 2 ~ 1KFIAKAMA @ )   ( 4 ) 3 Jll 18 SENN 2HKR ~ IAB " tl ~ I1Pqt ~ j ~\] .  ?  , (5) 3~i ~ iI~E ~ I2A ~ OY O ; KM~2I"\]Lr2@(6)3:~<1lgUI~I ~ U~<Pl~2H % , 2@ Figure 2 . Table of Kanji reading ( Input )   ( Output )   ( l ) ' t ~ ~ f ~ ~ ~ . KOff UKR MONLITR NLI . 
(2) ill~f '~<'. KR\[,IRDE~OYOGU.
Figure 3 . result of experimentation Figure 3 gives a sample of the results of our exper iments  . The Kanji/~/inno . 
1 here is a group 2K an Ji . Its situation in the context/~<~/ is that in front of it is the Kan~i /~/ and behind it is the non-Kanji /~/  . When the context is Kanji+non-Kanji , the program selects reading i/ka / . The situation o ~/ in context/~~%O/is non -Kanji+non-Kanji so the reading A/#uta/ is selected  . AS are sult/~%P/is transliterated to /ko#ukawo#uta#u /  . 
Group 2 contains 1500 Chinese characters.
The Kanji in Group 3 have a special reading in a special context in addition to their regular meanings  . In Figure 2, Nos . 4, 5, and 6 are in this group . In Figure 3, /) bl/in No .   2 can be processed without a special reading , but in no . 3 the special reading is needed . To obtain this reading , the special context after the the sign * is applied  . The format , as in Figure 2, no .  4 , is group number (3) , Kanji ()) I) , reading number ( i ,  2) , operation code (8 , H ) , reading , sign (* ~ code for front or behind ( M , N ) , Kanji ~ , ~ F ) , and applied reading number ( l , i ) . 
Groupe number
Kanji
Reading number
Operation's letter
Reading way
Sighn
Sighn of front or behind 1
Caracter 1
Applied reading number 1 ( e . g . ) 1 letter 311 218 H8s n ~ all letter
SENNKAWA1 letter *
MN 11
In this case reading number 1 is applied because ~/ is found in front of / )  , I/ . 
The merits of this method are that the table is small and the process fast  . If we had a table listing vocabulary rather than Kanji  , it would be much larger , requiring at least 70 , 000 entries . 
One demeritis that the process does not completely cover all cases  . The phenomenon of rendaku or renjo , in particular , requires special contexts . There are no rules for this . Examples of rendaku and renjo are follows: ( in English ) ~/ hon/+/hako/-->/honbako/book case ~ / ko /+/ !omo /--> / kodomo / child ~/ ten/+/ou/-->/tennou/ emperor I ~  ~4g /in/+/en/--~/in~en/karma fir ~/ sake /+ / ya/--+/sakaya/wineshop  2  . Automatic segmentation We do not use spaces between words in Japanese  , but we do use many different elements in our writing system  . There are Kanji , kana ( hiragana and katakana ) , the alphabet , numerals , and signs . 
Figure 4 shows the ratio of these elements in Japanese newspapers  . If we look at a Japanese text as a string of dif-ferent kinds of characters  , we can replace the characters of a Japanese sentence with the abbreviations of Table  2  . 
AM .   i0 t :/?'~ I ~ ~ 446   55   2   3   3   2   1   2 In Japanese composition we are taught the proper use of the different characters in this way : Kanji-to express concepts  ; more concretely , for nouns , the stems of verbs , etc . 
hiragana-for particles , auxiliary verbs ~ I the endings of verbs and adjectives  , writing phonetically , etc . 
katakana-for borrowed words , foreign personal and place names , onomatopoeia , etc . 
alphabet for abbreviations numerals-for f igures Therefore  , if the different characters are used proper ly they suggest the type of word  . Katakana \ Romanchar \ ~ umeral\\I Sighn
Kanji Hiragana ~ ~43 . 4 28  . 0 Running charactes : i , 489, 175 ~ . 6
Figure 4 . Ratio of characters on newspaper- 340 We checked the character combinations . 
The ratio of segmental point to the character combinations is as follows  . 
behind 12345 fronti .  5 . 7 61 . 7 2 .  92 . 1 40 . 8 3 .  25 . 4 89 . 5 1 . 0 ---4 .  2 . 8 i0 0 . 0 i0 0 . 0 13 . 2 5 .  2 . 7 i0 0 . 0 - - - i 0 0 . 0 6 .  98 . 2 84 . 7 62 . 1 33 . 3i : Kanji ,   2: Hiragana 3: Katakana 4: Alphabet 5: Numeral 6: Sighn
Object : 15,677 characters
Table 2 . A ratio of segmental point 45 . 2 75 . 0 i0 0 . 0 73 . 8 95 . 7 i0 0 . 0 i0 0 . 0 95 . 1 33 . 3 0 . 0 90 . 0 0 . 0 75 . 0 23 . 7 ---  ( % ) We can segment at character combinations with a high ratio in Table  2 but not at those with a low ratio . 
For our program we converted Table 2 to the form found in Table 3  . We can segment a sentence at the places where nu -meral  1 is found in the table . 
behind 1   2   3   4   5   6 front 1 Kanji 0   1   0   1   1   1   2 Hiragana 1   0   1   1   1 I 3 Katakana 0   1   0   0   0   0   4 Alphabet 0   1   1   0   0   1   5 Numeral 0   1   0   1   0   1   6 Sighn 1   1   1   0   0   0 Table 3  . Table for segmentation by character combin at ion  1t  ~ ~  1R   4~  . 9 b~o ~ . C1EglP1~1P+iTi@9
I ? iR1 ~.1 P : 1:t :
Figure 5. Table for segmentation and
Classification of parts of speech Hi ragana-Hiragana type is use of the second most frequent combinations in Japanese  . According to Table 2 , We are unable to segment for this combination . 
' Therefore we make the following rule.
The hiragana / ~/ is used only as a parti- cle and we always segment at it  . The other hir as an a characters are segmented according to the character string table found in Figure  5  . The format , as in the second line in Figure 5 , is the number of characters in the string (4) , the character string ( up to i0 characters )   ( C ~ L  ~ )   , the length of the words (2 , I , i ) , the parts of speech ( C , E , P ) , and the conjugation (9) . 
This table contains only 300 records.
These are the particles , auxiliary verb ~ adverbs , and character strings which cannot be segmented by Tabie  3   ( ex . CJb ~ in Figure 5) . 
This table is applied as follows . The program first searches the characters tr ings of the table in the input sentences  . If a character string ( ~ gb  ~ ) fits part of an input sentence ( E ~ b~l:I ~ )  , then the program segments it into parts by the lengths of words in the table and adds the info rmation about the parts of speech and conjugat ion  . As a result we obtain the words (~/ b /~/) . 
Figure 6 shows the results of automatic segmentation and automatic translitera-tion from Kan jitoRoman letters  . The operation of Table 3 has resulted in no segmentation for the str ings  ( /COLING80/ )   ,  ( /~ / )  , (/ ~ rff-~y ~--$-- J ~/) , and ( /~!~ / ) as well as the segmentation at the sign ( / . /)  . The operation of the table in Figure 5 has resulted in the segmen-tation for the hi rasana  ( / ~ /  )   ,  (/ ~ / )  , (/ V /) ,  ( /~ /) , and (/~/) . 
3 . Automatic classification of parts of speech In order to analyze the vocabulary we have to classify it by parts of speech  . 
The program dose this by three methods.
The first method is by using the table found in Figure  5  . 
The second method is by the form of the word , applying the rules below . The ratio of correct answers obtained is given in parentheses after each rule  . 
i . If the last character of the word is in Kanji , katakana , or the alphabet , then the word is a noun . 
(94 . 4%) 2 . If the last character is /~/ , then it is a verb in therenyo form ( conjugation ) or an adjective in the syushior rental form  .  (86 . 2%) 3 . If the last character is /~/ , then it is a verb in the syushior rental form or an adjective in thereny_o_form  .  (83 . 4%)-341 C0LII',\]G80~"~ . m , o ), ~ rit1,, . ~-, T . -Jl , ?'~ flf ~ ~ . : K\[tC 0 LING 8   0 GATO  #UKIJEII : ILINOTDSISENNTNO HO0 RUDEKAI : IISA HISANASOBINl#AKITAKO TO MORAGA KANEOOTE~IKU  . 
~ . : : a > . F .  ~ . -, . .~'~" I ~ I ~ ,% 2,~ . ~- ~ tf -~ ~ . 
ZIJONN . F . KENEDE*IHAI~IDA~IN ADANITOI~LIRIJO ~ UDAOl\] TA  . 
~ C : , , ~ . ~- ~ i00 g:b",I00F\]~"<E~L, . 
J(>~~lOOg ~", iOOH~<EZL',.
PANNKD ~0100 GKA , I00~IEIIN BUNN KUD A SAHI . 
RETA.
Figure 6 . Result of Segmentation and Transliter at ion from Kanji to Roman character  4  . If the last character is / Y/ , then it is verb , syushiform .  (95 . 8%) 5 . If the last character is / K/ , then it is verb , kate if or m , or demon-strative pronoun , or auxiliary verb ~ I(92 . 9%) 6 . If the last character is / b / , then it is verb , meire if or m , or noun . 
(63 . 3%) 7 . If the last to w characters ar ~/ , then it is adjective , mizenform , or verb , renyoform .  (74 . 2%) 8 . If the last character is /~/ , then it is verb , renyoform .  (79 . 6%) 9 . If the last to w characters are Kanji-hi rasana  , then it is a verb . 

If the vowel of the last hirasana is / a / , then its conjugation is mizen or renyoform , and if it is / i / , then it is mizen or reny o if it is / u / , then it is syushior rental if it is / e / , then it is kateiormeire i if it is / o / , then it is meire ii 0 . If the last character is a numeral , then it is a figure and if it is a sign , then it is a sign . 
The third method is by word combinations.
That is , in Japanese grammer word combi-nation--espec ially of nouns or verbs and particles or auxiliary verb ~~- is not free  . The formula given in Figure 7 is made from this rule . 
Its format is as follows : i . the word 2 . its part of speech 3 . auxiliary verbs ~ r particles which can be used in front of this word  4  . parts of speech and conjugations which can be used in front of this word  5  . if 3 and 4 do not agree then 5 ap-plies obligatorily . 
Figure 8 is the result of automatic classific at ion of parts of speech  . The explanation of the codes used in it is as follows : i  ( noun )  . E ( verb) , M(adjective ) P ( auxiliary ver ~ I , R ( particle ) C(adverb) , A(conjanction ) , B ( inter-jection ) , Y ( sighn ) , X ( figure )   ( i )   ( 2 ) f ( 3 )  # 1 / 1 ? @  ( I ) Figure 7 . table for Classification of parts of speech-  -342  - ( 1 )  ~'-~ , t . ) ~ d ~" . )"( I'I5 (2) #g~~bT . L ', ~5 . 
(3) ~ ACLIRIH ~ TE411RU.
II (5) ~3 + (6) 1REREY (7) 9i-
Figure 8 . Result of Classification of parts of speech
Q ( auxiliary verb ~ i or particle )  8  ( ' mizen ' form )  ,  9  ( ' renyo ' form )  #  ( ' mizen ' or ' renyo ' form )  +  ( ' syushi'or'rental'form ) char . 
~Dbchar .' sfreq.
38404 aux . v . & part . other 32588 (84 . 9%) 2( 0%) 2(0 . 0%) 1305(5  . 5%) 64(0 . 3%) 13138(59 . 4%) 17037(89 . 8%) 3 (0  . 0%) 10173(62 . 1%) 0( 0%) 13324(83 . 0%) 0( 0%) 10569(66 . 2%) l(0 . 0%) 17(0  . i %) o(0%) 1470 2(99 . 9%) o(0%) 8351 (61 . 8%) 00( 0%)
Figure 9 . Result of supervisor 6 . automatic classification by method 3 , resulting in / ~' ) /being changed from a verb to a noun ( using the formula for/i/found in Figure 7 )  . 
The steps in Figure 8 are i . input data 2 . the result of segmentation 3 . the result of transliteration from
Kanjito Roman letters 4 . the automatic classification of the parts of speech by methods i and  2   ( by table and by wordform )  5 . the conjugations ( l ) ! ~@@ ~ ~ ~1~' ~ ~ ~ ~ ~ ~ ~' b ~ . 
4. Supervisor
The supervisor program checks the results of the three automatic processing programs and selects the correct results or processes back  . It also utilizes information obtained through each program  . That is,
I . The results of the character check ~ t ttA , t'bm . 
TAKUSANN 110 KIbl OT ABAl IERA REMASEN il DESITA . 
1 RiRPROPPPPPY+O +3+
TAKUSANII 110KINOTABANERARE 1R1REPPPPY
O   + 3 + (2) i ~8 < ~ L ~( . J ~\], ~" ' ~ ? i ~8 < ~ ~ G . ~' ~? ~ BMOSIRBKUTE ~ ASOBISUGITA . 
fb  ~ .
MASENN DESITA ?
EMREEPY +3  # #+ ~  8 <\[\] d~~II~OMOSIROKUTEI~ASOBISUGITA . 
EMREPY +.33 +
Figure I0 . Result of supervisor --343--and conversion from kana to Roman letters are used for each program  . 
2 . The information obtained in automatic trans literation is used in segmentation  . 
Namely , if the special context is applied , then the program does not segment at that point because the character string is a word  . 
3 . The information obtained at the conversion f romk anato Roman letters is used in segment at ion  . 
Namely , if the consonant of the
Romanized Japanese is (*) , ( J ) , or ( Q ) -- these are used as special small characters in kana -- then the program dose not segment at that point  . 
4 . The information obtained in seg-mentation is used in classifica-tion  . 
Namely , the program obtains infor-mation concerning parts of speech and conjugation through using the table in Figure  5 in segmentation . 
Checking the results of the processing invo lves the following : i  . Checking particle and auxiliary verbs trings obtained by the pro-gram at class if ication  . If these strings are impossible in Japanese , then the segmentation was mistaken . 
The program corrects these.
2 . There are not many words composed of one character in Japanese except for particles and auxiliary verbs  . Figure 9 gives the frequen-cy of some characters and the frequency of words consisting of that character alone  . 
Words of high frequency that are not partic les or auxiliary verbs are produced by er rors in segmen-tation  . The program then corrects these errors , combining them into longer words . 
3 . If a verb in therenyo form is followed by another verb  , then it is a compound word and the program cor rects the error to produce a longer word  . 
Figure i0 shows the results of the supervisor program . In test sentence i , the program at first segmented / ~/ L ~/ ~/ ~ / as auxil-iary verbs through the use of the table in Figure  5  . But the super-visor program checks and cor rects this string and the classific at ion program adds th ~ information of verb to / ~t ~ ' ~/  , as can be seen in
Figure i0.
In test sentence 2 , the program at first segmented it/#ASOBI/ SUGI/TA/  , but the supervisor program checked this and cor rected this string to the compound word  , /#ASOBISUGI/ , plus/TA / . 
We can process Japanese sentences using these methods and obtain words and vari-ous info rmation about these words  . With this program we can obtain a rate of cor rect answers of approximately  90 percent .   Y3 We should be able to improve this program at the level of the supervisor and the tables  . However , we don't think that it will be possible to obtain  i00 percent correct answers because this system uses Japanese writing and the Japanese writ ing system is not  i00 percent standardized . In addition , if we wish to produce a complete program , it is neces-sary to process on the basis of syntax and meaning  . At per sent , this is not the object of our efforts . 
5. Adding lexical information
The National Language Research Institute has been investigating the vocabulary of modern Japanese since  1952  , and has been using the computer in this research since  1966  . As a result , some five mil-lion words are available as machine readable data  . This data contains vari " ous information such as word frequency  , part of speech , class by word origin , and thesaurus number . The thesaurus , Bunruigoih ~ oin Japanese , was produced by Doctor Oki Hayashi . It contains about 38 , 000 words in the natural language of
Japanese.
6. Making the concordance
We will not explain this program here since we have written a separate report about it  ( number 6 in the list of refer-ences below )   . Please refer to this report for further deta ils  . 
Figure ii is the result of this process.

Professor Akio Tanaka developed this plan , made a prototype for automatic translite ration from Kan~itokana  , and permitted us to use this program . 
Mr . Kiyoshi Egawa made a prototype for an automat ic segmentation program and permitted us to use it  . They also contributed to this study through our shifurn is hedus with the opportunity to study this and provided his support for our efforts  . 
References
Hiroshi Nakano . 1978. An Automatic
Processing Sysem of Natural Language.
STUDIESIN COMPUTATION ALLING UIS-
TICS , Vol.i 0, pp . 17-40
Akio Tanaka . 1969. A Program
System of Transliteration , from Kanjito Kana , and from Kanjito
Romaji . STUDIESIN COMPUTATINAL
LINGUISTICS , Vol , 2, pp . 107-138
Kiyoshi Egawa .  1968 . An Inquiry into the " Automatic Segmentation " of Japanese Text  . MATHE MATICAL LINGUISTICS , Vol . 43/44 pp .  46-52
Kiyoshi Egawa . 1969. A System of
Automatic Segmentation for Japanese
Text . MATHE MATICAL LINGUISTICS,
Vol . 51 pp . 1722
Hiroshi Nakano . 1971 Automatical
Classification of Parts of Speech.
STUDIESIN COMPUTATION ALLING UIS-
TICS , Vol , 3pp . 98-i15
WORDWORDROMANIZED PARTSTHES AURUS
NUMBER JAP ANESE SPEECHNUMBER 0 1421:I : E11 . 202~, fc01224=I = Eg 4 . 921 ~_ 500 224 = I = ERUE + ~ , ? 501769 = I = ERUE + ~ , ~t~01949 = IKANAKEE8t-tiE .   01719 = IKIE = ~@ 01761 = IKIE = ~ 02080 = IKIE = ? k ~ 02495 = IKI E9  ~  01146 : IKI 1  ~  00469 : IKI : O = I = I 1  ~  02070 : IKIRUE + 2  . 581 ~$02827: IKIRUE+2 . 581 ~ ka , 502524: IKIRUE+2 . 581~501970 = IKIRUE+2 . 581 ~- ~, 502 128: IKIRUE + 2 . 581~<01278 = IKUE + ~ , 400438 = IKUM 9~ , <00520: IKUMS~&'501621: IKO = U12 . 382 ~, ~901667 = IKO = U 12 .  ~2
J  ~ , ~00025: IGO1 ~ , , G 00840 = ISI 1  :~:~  00258  :  I8 IKII ~ i l I ! 00551 = ISIKI 1   ~8   00950 = ISIKISA E8 ? t ~ fF ' ~\] ~ 00285 = ISIKINA = I 1 Hiroshi Nakano .  1976 . A Program Li-brary for Making the Verbal Con -cordance by Computer  . STUDIESIN
COMPUTATION ALLINGUISTICS , Vol . 8 pp .   18-62 The National Language Research Institute 1970  . STUDIES ONTHEVOCABULARY OF MODERNNEW SPAPERS . The N . L . R . Inst . 
REPORT 37,
Notes : * i Auxiliary verb : This term means the bound form which conjugate  . 
It is put Jodoshi in Japanese.
* 2 / ~ ~ g ~6~/ is rightly segmented for /@ la ~/ and /6  ~/  . This case is an error of program . 
*3 A ratio of correct answers is follows.
Sample : 2500 words from a high school textbook
Segmentation : 91.3%
Transliteration from Kanji to Kana : 95 . 7% Clasification of parts of speech : 97 . 0%
KEYWORDINCONTEXT-- . ~', ~ b,~9~:~~CI~,@~?~P167 > l~J~~1 . 14 o 89 tgi ~ i ~8 k . b&8"~b ~,<,~- ~ b,~te~J~?~ . l~o ) ~ l<llO ) XAd ~ tll~Ijl ) ii Ll@11 ii ; i i i i I ~ z i l I ( E b , -fl J . / ~& o ~< Figure ii . Concordance of a high school textbook
