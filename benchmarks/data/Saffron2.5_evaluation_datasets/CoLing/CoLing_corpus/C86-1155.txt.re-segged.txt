Future Directions of Machin; . ~ Translation
Junichi TSUJII
Deportment of Electrical Engineering
Ryoto University
Sakyoku , Kyoto 606

"1 introduction
Good historical surveys and comprehensive current state of the art surveys have already been given for MT by several authors \[ Bruderer  1977\] \[ Vauquois \] . 979\]\[Nagao1983\]\[Tucker 1984 , 1985\]\[Slocum\]985 a\] . 
The objectives , the basic design principles and the current stages of development of some of the major groups which aim to develop practical and reasonably large MT systems are found in the special i ssues on MT of ACL\[Slocum  1985b  \] , where a comprehensive bib-liography of MT from 1973 to 1984 is also given . In addition , \[Nishida 1985\] gives a very clear idea of what is going on in Japanese MT research  . 
All of these surveys show that MT has its own history and techniques developed quite separate ly from the other research areas of natural language processing  , especially the areas of natural language understanding  ( NLU Jnshort )  . The researchers in NLU have repeatedly compla ined that current MT systems translate texts w it hout understanding them  . On the other hand , the MT researchers have claimed that NLU researches have always developed ' prototype ' systems which only deal with texts in strong ly restricted subject fietds and cannot be extended to cover various linguistic phenomena found in the other fields  . 
However , it is obvious that the problems concerned with ' understanding texts ' cannot be avoided for the future development of high quality translation systems  , and , in fact , several experimental systems\[Carbonel\]11 . 978 ,   81\] \[ Lytinen 1982\] \[Ishizaki 1986\] \[Nomura 1986\] aims to translate texts through understanding them  . 
In this paper , we will discuss several problems concerned with ' understanding and translation '  , espe-cially how we can integrate the two lines of research  , with their different histories and different techniques  , into unified frameworks , and the diffi-culties we might encounterinat tempting such an integration  . The discussion wil \] reveal some of the reasons why MT researches are so separated from the research in the other application fields of NLP  . We will also list some of the key problems , both linguistic and computational , which we encountered during the development of our MT systems  , the Musystems\[Nagao\]984 ,  85 , 86\]\[Tsujii 1984 , 85\]\[Nakamura 1984 , 86\]\[Sakamoto 1984\] , and whose resolutions we consider to be of essential importance for future MT research and development  . 
2 T rans la t ion between J apa~\]ese and Indo -European 

The MT research and development activities in Japan including the Mu project are distinguished from others in that they all aim to treat language pairs of quite different \] anguage families  , i . e . Japanese and one of the Indo-European languages , typica \] ly English ; most of the activities in other parts of the world  , with few exceptions \[ Tong 1986 \]\ [ Loh 1975\]\[Feng   \]982\]  , have focused on translation among Indo-European \ ] anguages  . Because Japanese is quite di Eferent from Indo -European languages in various aspects such as its \] exica \] items  , syntactic and semantic structures , etc . , the t rans \ ] a t \ ] on process bas to be much more sophisticated  . 
The experience of PAIIO-SPANAM\[V as concellos 1985\] shows , for example , in the translation from Spanish to English , that translation results sufficient for native speakers of English to correct translation errors can be obtained even without having a separate phase  ( the analysis phase ) of obtaining explicit representations of the syntactic structures of source sentences  . In contrast to this , because Japanese and English have quite di fferent phrase orderings  , results of th . i . s standard cannot be obtained in JapaneseEnglish translation unless the entire syntactics t ructure of the source sentences is captured  . Furthermore , in Japanese-Ehglish translation , different syntactic interpretations of source sentences almost always lead to different t ranslations so that we cannot expect syntactic ambiguities to be preserved in both languages  . That is , although the METAl , group\[Beneht 1985\] reports that ' We employ only the highest-scoring reading  ( i . e . 
syntactic interpret at . ion ) for translation .   .   .   . 
Surprisingly often , a number of the higher-scoring interpretations will be translated identical '  , we can rarely expect this to happen in transla tion between Japanese and English  . Moreover , certain syntactic concepts which are supposed to be common to all Indo-European languages are quite problematic in 
Japanese . For example , \] . . We do not \]\] ave in Japanese expl ic i t mark ing of defJnite and indefinite distinct ions among noun phrases by determiners  2  . Whether the concept of syntactic subject exists in Japanese or not is undetermined among Japanese linguists  3  . Although relative clause constructions in English and embedded clause constructions in Japanese roughly correspond to each other  , the two constructions have quite different characteristics  . Japanese embedded syntactic constructions such as  ( preposition +-- ing\]forms of phrases which modify nouns  , appositional phrases introduced by ' that ' , etc . , depend ing on the semantic relationships between the modifying clauses  ( embedded clauses ) and the modified noun\[Nagao 1984 ,  1986\] . 
These facts indicate that capturing the syntact ic structures of entire source sentences is necessary  , although not sufficient , for the translation between English and Japanese . Moreover , we need a certain amount of change in the syntactic structures of source sentences in order to generate natural translations  . It is obvious that translation between all language pairs requires more or less structural change  , but to what extent such structure change is necessary and to what extent such structure change requires semantic or extra-linguis tick now \]  . edge ( and so , cannot be systematically formulated upon syntactic structures alone  ) is highly dependent on individual language pairs . Pairs such as Japanese and one of the Indo -European languages offer one of the extremes : we often have to refer to deeper structures than syntactic ones  , such as the socalled semantic or conceptual st ructures of sentences  , in order to obtain natural translations . 
That'deeper ' understanding is relevant to high quality translations is intuitively obvious  . 
However , the discrepancy between Japanese and Indo -European languages is so large that even at certain deeper levels the discrepacy still remains  ; l . The correspondence of words in the two languages  , English and Japanese , is not so straightforward . This implies that a set of semantic or conceptual units  , from which deeper level representations of source sentences might be constructed  , is difficult to define ( see Section 4) . 
2 . A single event in the realworld is often captured differently in the two languages  . For example , an event which is expressed in English by a sentence with a transitive verb is often expressed in Japanese by a sentence with an intransitive verb accompanied by a deep cause case element  . Even deep semantic case relationships seem then to be dependent on individual languages  . Although more or less the same phenomenon has been observed even in translation among Indo -European languages  ( for example , ( King ,  1986\]) , the difference between Japanese and the Indo -European languages in terms of their deep case structures remains particularly large  . 
These considerations have led the MT researchers in Japantobasic problems as to what kinds of ' understanding ' are relevant to translation  , whether results of ' understanding ' sentences ( texts ) can be represented independently from individual languages  , and finally , what ' understanding ' sentences can really mean  . These issues should be made clear not only for translations of language pairs belonging to quite different language families but also for developing future high quality MT systems for any language pair  . The Japanese Ministry of Post and Telecommunication  , for example , recently announced snew ,   15 year project for the simultaneous translation of telephone communication  , in which ordinary dialogues will be translated  . We cannot expect in such a system the heavy interventions of professional translators that most current MT systems presume  . 
Raw translation results should be natural enough for languages  . 
3 Basic Approaches
One of the recurring controversies among MT researchers has been between the adoption of the transfer approach and the adoption of the interlingual approach  , and this seems extremely relevant to various issues of the possible relation--ships between ' understanding ' and ' translation ' in future MT systems  . The transfer approach , originally proposed by GETA\[ Vauquois1979\] and adopted by many research and development groups including the MU project  , EUROTRA\[King1981\]\[Johnson1985\] , TAUM\[Kittredge 1976\]\[Isabelle 1985\] , METAL\[S\]ocum1982\]\[Bennet1985\] , PAHO-ENGSPA\[Vasconcellos1985\] , ASCOF\[Biewer1985\] etc . , is an approach in wh ich t rans la t ion is carr ied out essentially in three phases : analysis  , transfer and generation . The second phase , transfer , is a contrastive phase where lexical items , stereotyped expressions , and the syntactic and semantic structures of two languages are compared so that both lexical i tems and certain levels of the linguistics t ructures of the source languages may be trans ferred to their ' equivalents ' in the target languages  . 
The interlingual or pivot approach , which has been repeatedly advocated by researchers originally interested in natura l language understanding  ( NLU ) who take machine translation as one possible application\[Muraki  1982  , 1986\]\[Lytinen 1982\] , instead performs translation through two phases , understanding and paraphrasing . The results of the first phase in this approach are supposed to be represented in the form of expressions of interlingua  , from which the second phase may generate the target sentences  . The expressions of interlingua are language universal in the sense that the second phase can generate target sentences from them without considering what the source language is  . It is claimed that this approach is superior to the transfer approach because of the following advantages  . 
l . Multi-Lingual Translation : Because this approach does not have any phases dependent on language pairs  , only two kinds of modules for transforming sentences of individual languages to expressions of interlingua and vice versa are necessary for multi-lingual translations  . 
2 . High quality Translation : Because this approach first understands source sentences and then paraphrases the ' understanding ' in the target languages  , the translation results are natural and easy to understand  . 
Fig . \] . is a schematic figure often used for explain ing the relationship between the transfer approach and the interlingual approach \[ Vauquois  1979\] \[ Tucker \]985\]  . This figure shows that there is an abstract ion hierarchy of descriptions such as surface word sequences  , surface syntactic structures , deep syntactic structures , semantic structures , conceptual structures , etc . where , at the deeper levels , the descriptions of sentences of different individual \] anguages become closer and f in all y  , at the deepest level ( the level of understanding )  , converge . 
SL Text TL Text
Sc~:icStr.......~SyntactJeStr.
Seman ~ tic8tr . -----/'~' m--~-* S~tic Sir . 
Contextual Str . Contextual Str.
Unders randing
Fig . \] . . A Naive Schemat ic Figure of Translat ion Which is often used but quite misleading This f igure  , however , is often misleading in that it suggests an interpretation where each level of the hierarchy may replace the shallower levels of descript ion  . This is to interpret the figure as showing that each \] eve \] Jn the hierarchy can express in its own descriptive framework all aspects of the information conveyed by source sentences : once a description at the deeper \]  . evel is achieved , it can replace the sha\]lower , more surface-oriented levels of descript ion  . This imp\]ies that the transfer approach is more atentative approach only adopted until we develop technologies for ' understanding ' texts and the frameworks for expressing the result of understanding  , that is , interlingua . 
The early experiences of CETA , however , show that this naive view does not work well . The surface syntactic structures of sentences  , fo ~ example , cannot be replaced fully by their deep case struc-tures  , because surface strnctures convey extra- information concerned with  , for example , the focus of the discourse , the distinction of old/new informat ion in the context  , emphasized e\] . ements or phrases , etc . , and such ext ra - in fo rmat ion is a l so relevant to the determination of the target sentence structures  . Generally speaking , for translation , we have to extract from texts , not only what is described ( the extra-linguistic aspects of texts ) but also how Jt is described and how the texts are organized  ( the linguistic aspects of texts )   . 
The early , naive interlingual approach tended to put emphasis on just what is described  . The same tendency may also be observed in some parts of linguistics and recent knowledge -based approaches to MT  . Fillmore's initial notion of cases \[ Fillmore  1968\]  , for example , was proposed for retaining identities of events in the realworld which are expressed di fferently in surface sentences  , so that the sentences
John opened the door with the key.
The key opened the door.
The door opened.
are all reduced to the same case structures . However , even if they describe the same realworld events  , they describe those events from different v iewpoints  . At least , the sentences may play different roles in d is course  , and so , when they are put in a certain context , some of them may violate discourse coherency and beless natural than others  . 
One could claim , as researchers of knowledge based approaches often do  , that , because discourse roles of sentences should be determined during the generation  ( paraphrasing ) phase by ' inte\] . ligent'text generators , the analysis ( understanding ) phase need not extract factors re\] . evant to discourse from source texts . It is probably true that some dJs course fac tors and so some parts of surface linguistic structure should be determined during the gener at ion phase of target texts  . E Iowever , because the same sequences of events in the real world can usually be described by a number of d ifferent texts  , each having its own coherent discourse structure , MT systems should be able to select one of them dynam Jeally based on the text struc tures of the source languages  . Certain factors concerned with the text organizat ion of the source languages should be extracted during the analysis phase to facilitate such selection  . Otherwise , however in tell Jgent the text general ors might be  , they may always generate the same texts as t ranslations of different \] y organized source texts whenever ' essentially ' the same sequences of events are described  , albeit from different viewpoints and attitudes . 
Although there are certain types of texts , such as ' factual ' news report i . ng articles of newspapers on terrorism \ [ Ishizaki  \[986\] \[ Lytinen 11982\] in which only what events occured in the real wor \] d and in what order are Jmportaut  , there are , of course , far more varied types of texts to be translated . \[ Tucker \] . 984\] also notes this point as follows . 
' In spite of its initial appeal , the knowldgebased approach--raises some we ighty questions  , for example ,   . . . . To what degree are the sc r ip ts of know\]edge based machine translation well suited to ' non-story ' texts such as conference proceed ings  , scientific artic\]es , and budget documents ?' There is , however , another possible interpreta-tion for Fig . l . Here the hierarchy is taken as a hierarchy of the depth of processing during the analysis phase  , according to what kinds of informa-tion are be ing explicitly extracted from source sentences at each level \[ Boitet  1984\]  . In this view , an analysis program which performs processing to a certain level gives as its output certa in struc-tural descriptions  ( or sets of structural descrip-tions ) which contain explicit representations of information up to that level  . An analysis program which processes sentences to the level of deep case struc tures  , for example , outputs certain descrip-tions from which the other program  , the transfer program , can retrieve information of , not only deep case relationships , but also surface syntactic structures and sur face ordering of the words of input sentences  , without any further linguistic processing . 
The current transfer-based MT systems usually s t and on this view  , where , based on the deep case structures and surface syntactic structures of source sentences revea led during the analysis phase  , the transfer programs compute the most appropr iate corresponding descriptions of target sentences  . In the cuurent transfer-based systems , however , discourse factors are not usually expressed expl icitly in the descriptions but are impli citly preserved in the surface syntactic structures which preserve the surface orderings of phrases  . The surface syntactic structures are then preserved during the transfer phase as much as possibJ  . e so that discourse ro\] . es of elements in the sentences are presumably t rans ferred to the target descriptions  . This principle of ' using source sentences as mou\]ds of target sentences ' works rather wel lintranslation among languages with many simi larities because the syntactic notions of one language such as syntactic subject often play almost the same discourse roles in the other languages  . 

However , though the same principle works to a certain extent in the translation between Japanese and Indo-European languages  , it does not work so well . In the translation of such a language pair , because surface syntactic structures of source sentences often have to be drastically changed in order to realize the deep case relations in the target  , the principle itself becomes hard to follow . In addition , though the principle is based on the assumption that syntactic notions such as syntactic subject etc  . play the same roles in the two languages , the assumption is not valid . The principle , therefore , tends to produce either understandable but unnatural translations  , or to make the transfer component ad hoc , complex , and difficult to maintain when we attempt to get natural translations  . Furthermore , as can easily be seen , the principle is not even satisfactory for the translation of similar languages when we want to get high quality translations  . It is obvious that we have to extract explicitly more kinds of information from source texts than deep case structures and utilize these to compute descriptions of the target sentences  . 
Note that ' to extract more kinds of information explicitly during the analysis ' does not  , in fact , necessarily mean ' to express such kinds of information in a language independent framework ' nor does it imply that such extracted information can fully replace the shallower levels of description  . Indeed , because the linguistic aspects concerned with ' hew things are described '  , ' how texts are organized ' etc . 
are more language-internal aspects than those of ' what are described '  , it is likely that they are more difficult to express in a language universal framework  . 
Our tentative view of future MT systems , which is based on the transfer approach and will be zevised in a later section  , is shown in Fig . 2 . In this framework , the analysis phase is expected to extract exp licitly many more different kinds of information other than deep case relationships  . They are the
Factors of I\la Certain Aspect I . . . . . . I F cOmputatiOn ~ ICorre?fondin~

I ? is couse I ! I of ~~ Target Text
Semantic 1
IFactOrs118yntacticl/\[Analysis\]

SLText
Factors of \] a Certain Aspect I of Understanding \] 
Factors of \] a Certain Aspect l ~ of Understanding\[Discouse\[Factors\] 
I Semantic\[Factors
Syntactic I/F actors
I\[Generation \]
TL Text
Fig . 2 A Schematic View of Future MT systems \[ A Tentative View \] syntactic structures of source sentences  . We neither expect , as described above , that such extracted information should be represented in a language universal manner  , nor expect that they uniquely determine surface syntactic structures of source sentences  . In this sense , they need not be a complete set of factors determining surface structures of source sentences and so the surface structures cannot be replaced by the set of these factors  . They merely give us a framework which facilitates the systematic comparison of the two languages  . Based on the set of these factors , the transfer phase computes corresponding factors of target sentences including discourse factors  , semantic structures , syntactic structures , etc . from which the generation phase will generate target surface syntactic structures  . As the extracted factors give the transfer component a constraint set which is to be satisfied if possible  , the factors computed in the transfer give a similar set of conditions to be satisfied in the generation phase  . 
Though our current view of future MT systems is based on the transfer approach  , our objective in this section is not to claim that this approach is superior to the interl in gual approach  , but only to claim that the word ' understanding texts ' in the context of MT is quite vague and  , therefore , that we have to examine and define what is real ly meant by the mythical word ' understanding ' before discussing the advantages and di sadvantages of the two approaches  . In fact , while several large and practical MT systems  , including some commercially available , have been developed in Japan based on diffe rent approaches such as the ' Pivot approach '\[ Muraki  1985\]  , ' Conceptual Transfer Approach'\[Uchida 1980 , 1985\]\[Amano 1985\] , ' Integrated Approach '\[ Tanaka 1983\] , each of which puts emphasis on dif-ferent aspects of translation processes  , especially on aspects of ' understanding ' , when one closely examines the internal translation processes and what kinds of information are utilized in these systems  , one in fact finds many similarities and fewer dif-ferences than one might have expected  . 
Before ending this section , we would like to add some comments : First of all  , we neither deny the existence of certain levels of understanding which are language universal nor their importance and relevance to translation  . On the contrary , we are willing to accept such claims . Our objective is only to claim that such levels of ' understanding results ' should be integrated with other aspects of information conveyed by input texts  . Second , though it is implicitly assumed by the researchers of the inter-lingual approaches that the transfer approach is incompatible with ' understanding texts '  , that ass Ump-tion , as Fig . 2 . shows , is simply wrong . 
Translation and Understand in q
In order to discuss the problem on a more concrete basis  , we will first see how ' understanding of a sentence ' has been understood in conventional NLU frameworks  . 
Fig .  3 . shows a simplified framework of an NLU system  . In this framework , ' understanding of a sentence ' is regarded as a process of transformation from an input sentence S  , a linear sequence of words , into a meaning representation M(S ) . The M(S ) , in turn , is used as an input to a certain scheme of ' internal processing ' such as a deductive inference  , problem solving program , etc . , which Js actua l ly imp lemented as a computer p rogram to carry out a certain specific task  . In this framework , the meanings of input sentences are defined Jn terms of the ' internal processing'specific to individual ' understanding'systems  , and so the results of I understanding ' are represented by symbolic expression ~ which can be interpreted by internal programs for specific tasks  . 

Procedure \]

Input Sentence

Syntactic Meaning
Descripk Jon--\[Interpretation \] ~ Representation 
M(s)_t
Internal \]
Program for a Specific Task I which works on

Fig . 3 A Simplified Framework of an NLU
An ordiz ~ ary NL frontend for a database system , for example , transforms sentences into expressions of a certain query Ianguage such as SQI  , , an artificial language designed Ifor data base accesses  . The internal program in this case is tile SQL interpreter which can execute the expressions to retrieve appropriate data  . As all extreme example , the STUDENT system\[D . Bobrow \] . 968\] , which solves exercises of arithmetic expressed in English  , transforms texts into a simultaneous equation . In this system , the ' meaning ' of an input text is an equation . 
Such transformation from an input to the M ( S ) \]sessentia Ilyan information extraction process where only information relevant to specific tasks is extracted  ; it is not an information preserving process in t be sense that exact surface sentences usually cannot be regenerated from information extracted  . In other words , M ( S ) used so far represent the ' meanings ' of input sentences only from a certain point of view  , that is , from the viewpoint of ' internal processing ' for a specific task  , and therefore , only preserve information relevant to that task  . Though other frameworks which have been adopted by NLU rese  ; ~ r chersin certain fields such as ' text understandi  . ng ' seem to have different flavors , the essential framework is almost the same . In these systems , ' understanding texts ' is taken to be a process of relating texts to internal'knowledge' called's cripts '  , ' frames ' , ' schemas'etc . prepared in the systems beforehand . Knowledge in these systems is claimed to imitate human conceptual memory formed through exper iences in the realworld and to be general in the sense that it is independent of specific tasks  . Such systems , however , also have their own tasks such as ' paraphrasing  '  , ' summary generation ' etc . to show their understanding capabilities by external behaviour  ; these tasks implicitly define the content and descriptive frameworks of their knowledges o that the information to be extracted from texts is restricted  . In addition , because the internal forms of knowledge to which input texts are related usually reflect situations  ( or sequences of events ) in the real world , they have nothing to do directly with linguistic texts  . That is , ' understand-~ng results ' in these systems often miss the linguistic aspects of texts  . 
In contrast to a restricted approach to meaning extraction  , however , the aim of translation Js I tore express by using sentences of target \] an-guages the informat ion of all aspects contained in sentences of source languages  , with as \] east distortion as possible ' . 
It is commonly recognized by l~nguists that a \]\] different surface sentences convey different information  . If we share th\]s understanding , the M ( S ) in MT should v\]rtua \]\] y retain in formation for regenerating exact source sentences  . That is , we do not have any ' internal processings ' JnMT by which we can define certain aspects of info rmation conveyed by texts  . The M ( . ~ ; ) of source sentences in MT should preserve information of a \]\] kinds conveyed by source sentences  , not only what Js described by the texts but also how it is described  , from what viewpoints and by what attitudes . Such considerations have led us to the f rame work a \] ready shown as Fig  .  2 . in this framework , we abandon single layers of descriptions for representing ' understanding results '  , and instead , have several layers of descriptions which col lectively determine the surface syntactic structures of the source sentences and which are a \]\] to be utilized dur Lng the transfer  . 
Based on this assumption of the muiti-\] ayered description o\[source texts  , we can thin \] < of certain \] . a yers of description which are language universal  . 
and which correspond to ' understanding resu\]ts ' in conventional NLU systems  . We will discuss in the following sections some of the problems in utilizing these extra-l inguistic Layers of ' understanding ' in trans lation processes and what roles these layers shou\]  . dplay in the preeess as a whole . 
5 Words and Concepts
We will first examine the basic units from which complex expressions in these language independent layers might be constructed  . The researchers advocating r la~ve interIingua\] approaches have Jnmin dsnchavie was shown Jn Fig  .  4 . In this view , each word of individual languages denotes a language independent or extra-linguistic concept  , though some words are ambiguous and denote several different  ( mutually distinguishable ) concepts . Such concepts denoted by words in individual languages are the basic units of language un iversal description  . In this view , words of individual languages are related to each other through the concepts  , and translation of words from one language to another is to be performed straightforward ly through these concepts  . 
This view is we\]\] . -fitted for the terminological concepts and words in a scientific field  . The word word of Language-i__Word of Language-5 - ~_J\[F . . . . hi \[ Japanese \] Word of l . , anguage-2~ Linguistic ~ word of Language-6 \[Chinese\]----~~\[German\]Word of Language-3" /~" word of Language-7 \[Korean\]/<\[EnglJsh\]
Word of Language-4 word of Language-8 \[Russian \]\ [ Malayl
Fig . 4 A Naive View of Relationships between Words and Concepts concept called ' mass ' in English or ' shitsuryou ' in Japanese  . The concept has its own definition in the theor ies of physics  , which are , of course , language independent . The relationship between words and concepts here is similar to that found in Fig  .  3 , where the meanings of linguistic expressions ( and so those of individual words ) are related to symbolic expressions used in ' internal processing '  . Theories of physics are here playing the same role as do ' internal processings ' in NLU  ( Fig .  5) . 
word of Language-l~/Word of Language-4 \[ Japanese\]~\[Prench\]Word of Language-2_~ Linguistic ~ Word of Language-5 \[Chinese\]v ~\ [ German \] Word of Language-3" ~" Word of Language-6 \[Koreane\]~\[English\]I '' Langauge independent theories \] which give semantics to the I extralinguistic concepts  ( e . g . Theories Of Physics ) J Fig . 5 Terminological Words and Concepts In o rd inary texts  , even in abstracts of scien-tific and technological papers which our MU systems aim to translate  , however , we find a large number of ordinary words which lack such formal definitions and for which the above naive view of lexical translation does not work well  . The concepts denoted by ordinary words such as ' to introduce '  , ' to produce ' , ' advantages ' , ' fields'etc . do not have formal explicit definitions , even if we accept the existence of such denoted ' concepts '  . Especially , as\[Hobbs1984\]noted , verbs are usually used to describe quite different situations or events in the real world  . He gives the following examples of usages of ' to produce ' in medical text books on hepati t is as follows  . 
A disease can produce a condition
A virus can produce a disease
Something can produce a virus.
Intesia flora can produce compounds etc.
Note that , in Japanese , we have a verb'tsukuri-dasu'which roughly corresponds to ' to produce ' in English  , but some of the above usages of ' to produce ' would need to be translated into a diffe rent Japanese verb  , ' hikiokosu ' . In order to retain the simplicity of translat i on through extra-linguistic concepts  , we have to prepare at least two different concepts denoted by ' to produce ' which are denoted in Japanese by'tsukuridasu ' and ' hikiokosu '  , respectively . Moreover , because we can easily recognize the diffe rences among situations described by ' to produce ' in the above sentences  , it is natural to imagine that there may be other languages which require further division of the concepts  . The naive scheme in Fig .  4 . may result in a proliferation of concepts and cannot explain the correspondence of words in different languages  . 
Hobb's answer ( and , of many other researchers both in NLU and linguistics  ) to this question , which is intuitively reasonable , is : ' to produce ' in the above examples is not a polysemy  , because all of the such as ' x causes y to come into existence '  . This kind of approach , the lexical decomposition approach , not only can prevent the proliferation of concepts  , but it also has another advantage in that it reduces the diversity of surface expressions by representing sentences with different surface verbs such as ' to produce '  , ' to create ' , ' to generate ' etc . 
by the same combinations of primitives . Such a reduction is preferable for ' know\]edge ' based processing which utilizes extra- linguistic knowledge  , i . e . set of rules intrinsic to external worlds , because the processing is concerned with events or situations described by texts but not di rectly concerned with texts themselves  . 
Though such reduction is inevitable for certain kinds of knowledge based processing  , we have to notice that the lexical decomposit i on approach  , by itself , does not explain anything about lexical correspondence among different languages  . On the contrary , it may increase the difficulties of lexical choice in translation  . In order to discriminate ' to assassinate ' from ' tokill '  , ' to murder ' etc . , though we have a rather direct correspondence between ' to assassinate ' in English and ' an nsatsusuru ' in Japanese  , we have to encode many kinds of information other thal \] ' X cause Y to become not to be a live ' such as Y's social status  , the reason of ' killing ' ( political or not ) and , in general , the speaker's conception of the ' killing'event in question  . In other words , the description cannot replace surface lexical : items unless a complete set of  ( cognitive or other ) i_~et ors relevant to surface lexical choices are fully specified  . The fact that most decompositionists have been only concerned with verbs shows that to specify such a set of primitives for expressing even only the core meanings of nouns is far more dif ficult  . 
(Note that ' field ' shou ld be t rans lated into six or more different nouns in Japanese\[Nagao \]  . 986\]) Furthermore , because the factors to be considered relevant , or the features of situations to be described that are considered to be relevant  , to surface lexical choices are highly dependent on each lexical item  ( and so , of course , dependent on each language ) , we cannot expect to have a complete set of factors which can be applied to choices of every lexical item of every individual language  . Trying to get such a language independent set may result in a proliferation of factors instead of the proliferation of extra-linguistic concepts found in the naive scheme  . 
Again , note that we do not claim that the aspect of understanding captured by decomposition is irre levant to translation  . Instead , it constitutes one of several indispensable layers of description which facilitate systematic comparison of the two languages  . In order to translate ' to assassinate ' correctly into Japanese  , we have to discriminate the literal meaning and metaphorical meanings of the word  ( such as ' to hurt someone'shon or by an astytr ick or verbal abuse '  )  , because the Japanese verb ' an nsatsusuru ' may express the latter  , the metaphorical meaning . Such discrimination obviously requires unders tanding of what really happened in the real world  , and the understanding at this level ( contextual understanding level ) should be expressed by a descriptive framework using a certain set conceptual primitives  ( because understanding results of this level should be represented independently from surface diversified texts  )  . We only claim that the description only expresses certain aspects of ' meanings ' of surface words and it cannot replace them  . We also claim that any attempts to get a complete  , language universal set of primitives for explaining lexical choices in any language will be invain  , and that what we really need at present is much more comprehensive comparative studies on lexical choices between languages in question in order to clarify what kinds of factors are relevant to the selection of appropriate target equivalents for each individual word of the source language  . 
6 Impliciti\[nformation
The discussion in the last section can be summarized thus  ; Because a continuously in finite physical-/mental world is described by a natural language wh ich has only finite words  , words in individual languages are used to descr i be certain ranges o\[events/objects  . That is , ' meanings ' of words a ~: t quite vague . This vagueness causes difficulties of lexical choice in translation by the fact that certain families of events/objects which can be des-cribed by the same words in one language should be described by several different words in other languages  ( Fig .  6) . 
Range of Event
Described by ' to Produce ~/---
Range of Events . . . . -- escribed by
English~ . J"I/""~~"Japanese Verb verb ~----~~_ _~/>' tsukuridasu'rt ~% to Produce ~/"'  ~  , ~-----'---Range of Events ~ , Described by "- Japanese Verb'hikiokosu'
Fig . 6 Vagueness of Word Meanings
The same line of discussion can be applied to linguistic expressions in general  . That is , the set of ( cognitive or other ) factors which determine surface expressions changes from one language to another  . Or , even if similar factors work in the determin at ion of surface expressions  , they may be reflected by using quite different syntactic devices  . 
It often happens that to determine target surface expressions requires a set of factors which are not expressed at all in the source language or which are quite implicit  , even if they are expressed . 
On the one hand , to translate Japanese to English , for example , we have to have information about plural-singular and definiteness-in definiteness dis-tinct ions of noun phrases which are implicit in 

The Japanese sentence ' watashi-ha kinokang of u-ni atta  . '\[ I\]\[yesterday\]\[nurse\]\[tomeet\ ]\[ past\]may correspond to the following four sentences in 
English , depending on the context.
'I metanurse the nursenurses the nurses yesterday ' Because Japanese native speakers do not feel explicitly the above sentence lacks information  , we can claim that the sentence is just vague as ' meanings ' of words are  . That is , the sentence can describe a set of situations in the realworld which share certain properties in common  , but in English , the same set of situations should be expressed differently  , depending on properties of situations wh ich are not relevant to the selection of Japanese expressions and which therefore remain implicit in 

On the other hand , Japanese is rich Jnhonorific expressions and highly dependent on speaker-h ~ arer's social re lationships  . Therefore , in the translation from English to Japanese , we have to recover such information which is implicit in English  . For example , a simple sentence such as ' I'll come tomorrow ' may correspond to Japanese sentences such as ' asuoukagai/tashimasu'\[the hearer is blg her in the social position \]' as uou kaigaishim as u '\[ the hearer is higher in the social position \ ]\[ the speaker is intimate with the hearer \]' a suikuyo'\[the speaker is intimate with the hearer \]\[ the speaker is male \]' asuiku wa ' \[ the speaker is intimate with the hearer \]\[ the speaker is female \]' asuikimasu'\[ neutral \] English native speakers certainly do not think that the sentence is ambiguous in the above sense  . In this case , Japanese requires information about social status of speakers and hearers  , which is not so relevant to the selection of English expressions  . 
Speaker's intentions , which recent researches of NLU\[Brady 1983\] \[Appelt 1985\] \[Grosz 1986\]   , especially in dialogue systems , place a strong emphasis upon , are a typical example of implicit informat ion  , and we can easily imagine situations where it also plays an important role in translation  , especially in translation of dialogues such as the simultaneous translation of telephone communication  . 
It is , however , not desi'rable for translation systems to translate sentences according to speaker's intention alone  . Translating ' It's hot in this room ' to ' mado-oaketeku dasai '  ( Please open the window ) probably commits too much as a translation system  . The system should select natural expressions in target languages as long as they do not disto rt the ' meanings ' of source sentences too much  . This implies that ' understanding of sentences ' and ' the meanings of sentences ' should be distinguished  . What is meant by ' understanding of sentences ' is  , as recent researches in NLU typically show , to understand the situations where certain utterances are given or the situations which texts describe  , including such factors as speaker's intent ions  , speaker-heater's social relationships , definiteness/indefiniteness of referenced objects  , etc . Though these factors are relevant to the select ion of target expressions  , it is doubtful that all such derived info rmation is a part of the description of source sentences which expresses various factors determining the surface NLU often confuse understanding results with the description of input sentences  . 
As noted before , the researches in NLU so far have revealed that ' understanding sentences ' cannot be defined  , at least computationally , without considering certain specific internal tasks  , and the task of MT , ' to re-express in target languages the information conveyed by sentences of source languages with as least distortion as possible '  , by itself , does not define anything about what kinds of under-standing are required in MT  . Because the factors relevant to the determination of surface structures are dependent on each language  , the exact require-ments on what aspects of the situations described by source texts should be ' understood ' cannot be fixed unless the language to which the texts are to he translated is specified  . 
English native speakers , for example , can ' understand '' I ' llcome to mmorrow ' without any attention to the social relationships of the speaker and the hearer  . Only when they are asked to translate the sentence into Japanese  , must they consciously consider such factors to select the most appropriate Japanese expression  . The same line of discussion can be applied to the problem of target word selection  . We cannnotenumerate , by monolingual thinking , different ' concepts ' denoted by the verb ' to produce '  . Only when we are asked to translate sentences containing the verb into another language  , can we try to find appropriate target words . During this process , ' understanding of the sentences ' and so ' understanding of the situations described by the verb ' are promoted in such a direction that we can identify the most appropriate target verbs  . 
The above discussion implies that certain ' understanding processes ' are target language dependent  , and cannot be fully specified in a mono-l in gual manner  . We have to separate , at least conceptually , bilingual processings from monolingual processings which extract explicitly a set of factors determining the surface structures of source texts  . In the tentative framework in Section 2 , the role of the transfer phase was restricted to computing factors for determining targets t ructures from factors ex-tracted from source texts including their surface structures  . We assumed there that a set of factors for determining target surface structures could be computed from those extracted during the ana lysis phase  , though the computation itself was dependent on language pairs  . The discussion in this section shows that this assumption is not true  . The transfer phase should do more than that . The revised framework is shown in Fig .  7 . Though we adop there the conventional division of phases in current transfer based systems  , we do not claim that the three phase confi-gurat ion is the best and that these three phases should be executed in order  . Instead , we can think of a system in which the ' understanding'phase extracts not only factors determing surface source texts but also factors for determining target structures  . But even so , we claim that the understanding results in such a system have to be specific to language pairs and not language universal  . Which configuration is superior to the other , the two phase configuration or the three phase configuration  , should be disscused ability of grammars and dictionaries  , efficiency of processing , etc . but not from the viewpoint of ' understanding texts '  . 
Understanding Processes which are required for the
Invocation set of t\[A set of monolingual factors It ~ monolingual factors which collectively I ~ which collectively determine ~- ~ \[ Transfer \] determine surface structures surface structures of source texts of target texts tl\[Analysis \]\ [ Generation \] 
Source Texts Target l Texts
Fig . 7 . A Schematic View of Future MT Systems 7 Layers of Understanding-Knowledge and Translation The fact that ' understanding texts ' has been understood differently by diffe rent researchers in NLU implies that the ' knowledge ' to which text contents are to be related is different from one system to another  . So far , quite different sorts of information prepared beforehand in systems have been called ' knowledge '  . In Section 5 , we discussed two different approaches to meanings of words which may lead us to quite different views of what'knowledge'is : One is to relate meanings of words to extra-linguistic  , language independent concepts whose semantics are  , in turn , given by certain theories ( or formal systems ) , internal processing for specific tasks such as database accesses  , problem solving , etc . The other is to describe core meanings of words by relating the words to a certain set of pr imitives  . The latter may be augmented by adding further description using cognitive  , situational or other features ( as noted in Section 6 , some of these may be language dependent ) in order to specify what families of objects /events the words can describe  . The knowledge described by this approach is essentially knowledge about possible usages of words and can be utilized to translate words of certain types or to make general inferences on the situations described  . On the other hand , ' knowledge ' which is often mentioned in fields such as knowledge engineering  , expert systems and so forth refers to knowledge of specific fields  , and is more easily expressed in the first approach  . These two approaches are quite opposite . While the decomposition approach tries to discover a single description which covers possible usages of a word including its metaphor icalusages  ( the decomposition a lists may claim all usages are metaphorical  )   , the extra-lin-guistic concept approach ( the concept approach , in short ) tries to enumerate a set of concepts denoted by the word  . While the decomposition approach attempts to find internal structures of single words  , the concept approach tends to identify even complex expressions such as ' diagrams on the plane of the celestial equator '  ( note that this expression has a simple trans lation equivalent in Japanese like'jizuhyou  '  ) as single concepts . A Snoted in Section 5 , the concept approach , which we there called the ' naive approach ' , cannot be used to express the whole meaning of texts  , but this does not imply that know-\] . edge expressed by this approach is irrelevant in MT  . 
On the contrary , it often happens that we realize ' lack of knowledge ' in systems  , when we find re\]s-translations of terminological words or when we find misunderstandings of source texts  . 
Because the decomposition approach essential lycaptures possible usages of words  , it cannot decide appropriate translations of terminological expres-sions by itself  . This is obvious because even human transla tors who have enough knowledge of language usages often mistranslate terminological words  . The systems or human translators should have knowledge about relationships between words and extra-linguis-tic concepts in the subject f ields  . Because such relatiorlships are a kind of conventions specific to each subject field  , we simply have to know these conventions . Several current MT systems prep are certain f rameworks for treating such conventions of term translations specific to individual subject field ~: such as the field code in the MU systems\[Sakamoto  \]984\]  , the micro-glossaries in PAHO's systems \ [ Vasconcellos  1985\]   , hierarchical organizations of dictionar ies in GETA's systems\[Boit et  1982\]   , etc . 
However , though relating terminological expressions ( or words ) in different languages through extra- linguistic  , language universal concepts has become a standard way of thinking in the field of terminology and already adopted by several multi-lingual terminology databanks  ( for example , \[Goetschalckx 1974\]) , they do not explicitly introduce the extra- linguistic concepts in their frameworks but instead  , relate rather directly the terminological words or expressions of the different languages  . 
(Uchida 1985\] claims that we have to introduce extra-l inguistic concepts even in MT systems  , because ;   ( 1 ) futurn MT systems should include not : only knowledge of the correspondence of terminolog ical expressions but also factual knowledge and knowledge about inference rules specific to the fields  , etc . 
(2 ) Such extra-linguistic knowledge is language universal  , and , therefore , sbou\]d be managed by dif-ferent f rame works from genera \]  , linguistic knowledge which is l~mguage dependent  . 
\ [ Boitet 1984\] shows how factual knowledge in a specific sub ject field can be utilized to resolve certain syntactic ambiguities such as those of the scope of coordinations  , determination of antecedents of relat Jw~c lauses and pronouns  , etc . For example , he discusses that determining the correct scopes of the coordinations  ( i ) dangerous\[cyanide and chlorine \] fumes ( 2 ) \[ carbon and nitrogent etraoxy de \] requires fatual knowledge of a specific level such as  ( 3 ) cyanide fumes are dangerous ( 4 ) there is no carbontetraoxy de in normal chemistry  . 
The sequences of ' cyanide and chlorine fumes ' and ' carbonan  ( \[ nitrogent etraoxy de ' could not be dif -ferentiated  , if we used only a rough semantic classi-ficat ion of nouns such as being the name of a chemica let c  . ( These examples , as Boitetnotes , cannot be correctly interpreted by a simple method of preference semantics  .   ) The necessity of detailed factual knowledge such as  ( 3 ) and ( 4 ) is obvious , and , because such knowledge in chemistry is language independent  , it should be represented in a language universa lmanner  . Extra-linguistic concepts should play more important roles than mere links among the terminological terms of individual languages  . 
However , although we completely agree that extra-l inguistic knowledge should play more important roles in future high quality translation systems  , we have to be very carefulill the introduct ion of such knowledge into MT systems  . First of all , as we have repeatedly claimed , the ' meaning s'extracted from sentences that can be related to knowledge of this kind does not at all exhaust the information conveyed by sentences that need to be ' transferred ' into target sentences  . Moreover , because sentences even in specific subject f ields consist of both ter-minological terms and ordinary words  , we cannot expect to express a \] I the results of understanding such sentences at the \] eve\]  . of description using only the extra-linguist ic concepts  . We can only expect to express the understanding results of certain parts of sentences at this level and check whether the understanding results of those parts are compatible with common sense knowledge of the specific field  . In ozher words , the processing at this level cannot play the main role ~ n translation but can only p lay some roles to prevent certain kinds of ' misunderstanding '  . 
\ [ Boitet 1984\] notes this point as ' grafting on expert systems '   . 
In addition to this , the boundary between ter-minological terms and ordinary words is not so clear  . 
When we restrict terminological terms to names of chemical compounds  , of mechanical parts , etc . , Ld\]e problem of the boundary might not appear so serious : but such restr ict ion <:' an lead to serious l imita-t ion on the ava i lab i l i ty of knowledge of th i s k ind for forming select in a \] restrictions necessary for the d is ambiguation of source sentences  . If we attemp to extend the range of ' termino logical terms '  , the problem of the boundary between terminologica l terms and ordinary words arises  . For example , \[ Hobbs1984\] points out that , in a text book on hepatitis , ordinary words such as ' human ' , ' animal ' , ' water ' , ' alcohol'etc . have specialized meanings different from those in general fields  ; the concept denoted by ' human ' , in this field , is not a lower concept of the concept denoted by ' animal '  . We might then claim that these two terms are terminological terms of the field and that the denoted concepts have certain restricted relationships with the other concepts in the fields  . 
A \] though such seleetional restrictions specialized in certain subject fields might be very useful for resolving syntactic ambiguit ies of sourse sentences  , problems here are how to find such restricted usages of ordinary words that are specific to certain fields  , how to clarify the possible rela-tionships anlong ' concepts ' in those fields  ( to create semantic models of the fields )   , etc . As the above example shows , even clarifying the hierarchy among concepts  , which is one of the prevailing techniques for organizing ' knowledge ' in ordinary knowledge representation research  , is not so easy when we have to deal with reasonably large subject fields  . In order to utilize knowledge of this sort in the dlsambiguation pFocess  , we have to encode not only such hierarchical relationships among concepts but also many other kinds of factual knowledge about factual knowledge can resolve certain specific ambiguities of given sentences '  , we have to develop methodologies by which we can systematically clarify a set of concepts in the given fields and the relationships among those concepts  , and can gather factual knowledge relevant to those concepts  . 
The above discussion shows that there is not a clear boundary between terminological words and ordinary words  ; but instead , there is a continuous distribution of words f rompure terminological words  , such as names of chemical compounds , at the one extreme to pure ordinary words at the other  . Though the pure terminological words have their own language universal definitions and can be related directly to extra-linguist ic concepts  , the ordinary words have only their usages in individual languages and we have to infer the denoted ' concepts ' from their usages  . 
That is , as noted before , the denoted ' concepts ' of ordinary words are language internal and cannot be related di rectly to extra-linguistic concepts  . The-selectional restrictions which ord in ary words have  , therefore , can only be captured by specifying what events/objects can be described by those words  , and that specification might be language dependent  . 
Some of the difficulties in MT are caused by the fact that most of the words in certain sub ject fields  , even words which are usually taken as part of the terminology of those fields  , are in between the two extremes , and sentences usually contain words at various positions in the distribution  . For example , a sentence such as ( 5 ) The mixture gives off dangerous cyanide and chlorine fumes contains two pure terminolog ical words  ( i . e . , cyan ide , chlorine ) , two ordinary words ( i . e . , ' to give ' , ' to be dangerous ' ) and two intermediate types of words ( i . e . ' fume ', ' mixture ') . This fact requires us to prepare various sorts of description for the selectional restrictions among words  ( for the analysis phase ) and also for the selection of target equivalent words  ( for the transfer phase )  . As selectinal restrictions for di sambiguation  , we have to have factual knowledge of the fie lds  ( for restric-tions among terminological words  )   , restrictions specified by using cogni tive  , situational or other features ( for restrictions among ordinary words -- deep case frames with semantic restrictions on case fillers  , which are specified in the verb dictionary , are one of the typical techniques found in current MT systems  ) and varied sorts of mixtures of these two ext remes  . On the other hand , for the selection of appropriate target word selection  , we have to have several kinds of ' transfer ' mechanism using different sorts of informat ion such as extra-linguistic concepts wh ich link the words of individual languages  , distinguishing features for described events -/ objects  , and so on . 
The situation becomes even more complicated due to the fact that a single word has often both specia-lized usages and general usages  , even if we restrict our domain of translation to certain limited areas  . 
The frameworks which current MT systems prov ide  , such as semantic features , subject fie\]d codes , micro-glossaries specific to the fie lds  , hierarchically organized dictionaries , etc . , cannot ordinary words and terminologica l words , and between usages specialized in fields and general usages  . 
We have to emphasize that there is no single layer of ' understanding ' exclusively re levant to translation  ; only mutually related layers of under-stand ing ranging from detailed understanding  ( related to factual knowledge in the field ) to the vague and general understanding of si tuations  . All these layers will need to contribute to high quality translation in the future  . 
8 Problems in the Future 8o far , we have discussed what makes MT researches di fferent from other frameworks in NLU  , and we have stressed that one of the peculia rities of MT as an NLP application is that we cannot readily setup a particular task -oriented level of ' understanding ' in MT as we can in other applica-tions  . This peculiarity causes some difficul t problems not encountered elsewhere  , and we wi\] 1 list some of them since their resolutions seem particulary important in future  , high quality translation systems . 
\[ Problemi \] ( Multi-Layer Representation ) The process of machine translation can be taken as a sequence of processes of the extraction of vario ~ is factors which collectively determine the surface syntactic struc-tures of source sentences  , the computation of factors which are relevant to target sentence structures  , and the realization of those factors as sur face struc-tures in the target language  . Therefore , we need a certain descriptive framework in which we can express these various sorts of factors and from which we can retrieve such factors  . Annotated tree structures such as those used in the MU systems  , GETA , METAL etc . are one of such currently available frameworks . 
Annotated trees as they are , however , have only single structures ( trees ) of nodes with various sorts of information described in the annotation parts  . It is obvious that each different sort of information requires different geomet or ical structures so that the current annotated trees may not be sufficient for sophisti cated processing required in the future MT systems  . Though Kay's notation in unification grammar\[Kay  1984\] is obviuosly one of the candidate frameworks , it is appropriate only for describing interpretations which have already determined by the analysis phase  . Effective computational frameworks shoud be developed for producing such descriptions f rom source sentences which might be quite ambiguous  . Texhniques for sharing a partial descript ionata certain level by several different descriptions at different levels and for maintaining the consistency of description when some parts of it are changed should be developed  . 
\[ Problem2\] ( Integration of Understanding Levels ) As discussed in Section 7 , we should be able to integrate several dif ferent levels of ' understanding ' with lingu istic levels of description  . The descriptive frameworks developed so far have confined themselves to either linguist ic levels or to one of the specific understanding levels  . Kay's unification grammar , LFG , GPSG etc . are all concerned with the description of l inguistic levels  . All of them , for example , treat surface words as primitive units . On the other hand , most researches in NLU aim to relate texts to certain extra-linguistic knowledge so that the final understanding results are expressed independently from their linguistic source structures  . In order to integrate understanding result s with the translation proccess  , we need further researches to clarify not only what levels of understanding are really re\]  . evant to translation but also how we are to coord inate such diversified levels of process ing computation a Ily  . 
\ [ Problem3\] ( Incompleteness of Texts and ' Knowledge '- Robustness of Processing  ) I Iuman translators can translate'I'll come tomorrow ' into Japanese without : any knowledge about the social relationships of the speaker and the hearer  . They will translate the sentence based on the default assumption that the relations h ip is neutral  . It usually happens that , even for human translators , certain factors relevant to the detc~rmination of target structures cannot be obtained because of the incompleteness of texts and lack of necessary knowledge  . The system should be able to determine the most feasible translations based on the incomplete factors extracted from soui-ce texts  . Though establishing sets of factors w~ich collectiw ~ ly determine the surface structures of the source and target languages may facili tate systematic contrastive studies of the two languages and make present a d-hoctrans fer phase cleaner  , we have to note that actual systems cannot a \] . ways extract such factors from the source texts . Even in future systems , we will have to prepare heuristic guided transfer procedures based on lower level factors  , such as syntactic structures , alone . That is , the idea of ' safetynets ' is indispens ab\] e  , however intelligent the future MT system might be  . \[Nishida \] . 982\] diss cusses , in their MT system from English to Japanese , some techniques for calculating surface syntactic structures of Japanese which can preserve the discourse factors of English texts  , without referring to such factors explicitly . These rules are a kind of heuristic but are not linguistically well-founded  . For this kind of processing , we may have to introduce other kinds of knowledge  , for example , the expert knowledge of professional translators \[ Tucker  1985  \]  . 
\ [ Problem 41 ( Easy Accomodation of Future Development of Theories  ) As noted in Section 3 , we cannot expect to have a complete set of factors which carl uniquely determine the sur face syntactic structures of a language  . Becauese there is always possibility that future linguistic research will reveal factors which have not yet been noticed  , the computational framework should be flexib leen ough for accomodating these factors  . In this sense , to commit strongly to one linguistic theory at present seems dangerous for computat ional frameworks  . Furthermore , though most linguistic theories aim to descr i be linguistic structures from a mono-l in gual point of view  , the factors to be extracted from source texts depends on the target language  . Some of the factors relevant to translation can only be clarified through bi-\]  . ingual , contrastive studies of the two languages and by referring to the aspects of ' understanding ' which are obviously beyond the scope of cur rent linguistic theories  . We \] lave to note that the computation alf rameworks for machine translation should be f lexible enough for treating various sorts of phenomena which current linguistic theories do not cover  . 
\[ Problem 5\] ( Other Factors to be Accomodated-Discourse Factors  , Cognitive Factors ) The computa-tional researches in discourse analysis so far have put emphasis on a certain set of topics  , such as resolutions of anaphoric express ions  , recovering speakers ' intention from ut terances  , etc . Although these are more or less relevant to high quality translation in the future  , we have to attack much wider ranges of prb\ ] emsconcerned with discouse phenomena  , that is , what kinds of discourse factors are relevant to the determination of surface sentence styles and in what manner  . Though relevant topics have been treated in text linguistics and many useful ideas have been proposed already  , many of them seem to be too vague to formal J , zecomputationally . It is time to fin ( \] computat Jorlal formalization for them and to integrate them with translation processes  . MT is one of the most promising application fields where the research results in text l inguistics could be utilized  . 
\[Ishi wata 1985\] discusses how cognitive features are relevant to translation  , especially word translation . By taking the French verb ' tomber ' and the Japanese translation equivalents ' taorer u ' and ' ochJru ' as a typical example  , he shows that certain movements or objects wh ich carl be expressed by the verb ' tomber ' in F rench should be described dif-ferently by using either'taoreru ' or ' ochiru '  . His claim \] s that such selection of target word depends on how the speaker recognize the movements of objects  , that is , whether the motion Js rather per pendicular ( i . e . the stone fa\]is ) or not ( i . e . the man fell over ) . That is , the selection of appropriate Japaneses verbs depend on a certain kind of ' image'\]eve\ ] understanding of the event whJch the French verb describes  . Whether such levels of understanding carl be represented in a symbolic manner  , and what kinds of such symbolic cognitive features are necessary  , whether there is a set of cognitive features which is effective for any language pair  , and so on are , of course , research topics in the distant future . However , we lave to note that such cognitive levels of features are more useful than extra-lin- guistic know \]  . edge in specific subject fields , for the choice of appropriate target equiva lents for words with wide usages  . 
\[ Problem 6\] ( Setting Layers of ' Understanding ' ) As discussed in Section 6 and 7 , we can distinguish at least the two extreme layers of understanding and knowledge relevant to MT  . Whether these two kinds of understanding and knowledge can be represented Jnsingle f rameworks  , \] low they should be coordinated with lingu istic processing  ( analysis , transfer , generation ) computation a \]\] . y , to what extent these kinds of knowledge can real lybeen coded in systems  , etc . have to be clarified . If tho two kinds of knowledge should be represented separately  , we have to clarify hew many different layers exists and \] low they should be mutually related  . 
We have listed above some of the problems caused by the peculiarity of MT that we cannot determine in advance a certain concrete level of ' understanding '  . 
The other peculiarities of MT come from the fact that MT systems have to treat documents of much wider subject fields and of much more varied text types than other applicat ions  . Our Musy stems , for example , restrict the document type to abstracts of sc ientific and technological papers butt reat scientific fields in genera \]  . . The PAHO's sys tems t rans la te documents in more restricted fields but include very wide ranges of document types  , including conference reports , budget proposals , letters etc . 

This fact , in combination with the difficulty of se tting the understanding level  , causes many practical difficulties . 
\[ Problem 7\] ( Complexities of Semantic Models ) Wider subject field simply more complexities in semantic models  . In database access , one only has to deal with a simple set of semantic classes such as ' name of companies '   , ' person's name ' , ' salary ' , etc . and their possible semantic relationships . However , as\[Bennet 1985\] notes ' the thought of writing complex models of even one complete technical domain is staggering : one set of manuals we have worked with --- is part of a document collection that is expected to comprise some  i00  , 000 pages . A typical NLP research group would not even be able to read that volume of manual  , much less write the necessary semantic models , in any reasonable amount of time ' , we have to treat much more complex semantic fields in MT  . We have to develop methodologies to clarify the structures of such complex semantic models systematically for any given subject field  . 
\ [ Problem8\] ( In stability of Lexical Coding ) wider subject field simply a large amount of vocabulary  , and high quality translation requires rich information to be coded for each lexical item  . This means that we need many lexicographers for lexical coding  , and the problem of consistency arises . High semantic complexities imply that criteria for lexical coding are not so evident  . In the MU project , we prepared rather detailed manuals for lexical coding but they are still not sufficient for obtaining good quality codings  . The semantic codes , for example , are often dependent on individual lex icographers and such inconsistency caused many troubles in grammar development and also depressing translation errors  . 
The problem of instability is not found not only in semantic coding but also in every other description items in the dictinary  , when codings are perforlaed by many people . We have to develop not only flexibles of tw are tools for facilitating lexical coding and consistency cheking\[Kogure  1984\] \ [ Boitet 1982 \] but also effective linguistic checking procedures  . 
\[ Problem9\] ( Weak Semantic Constraints ) The lack of concrete internal processing for specific tasks implies that the system cannot reject nonsense interpretations of input sentences  . In other applications , certain syntactic interpretations are judged as nonsense when the internal processing cannot give any meaningful semantics to them  . Furthermore , as Hobbs noted by the examples of ' to produce ' , wide subject fields imply that various usages of words which share a core meaning in common will appear in texts  . That is , many usages which have metaphorical flavors ( ' The card rinks gas ' is a wellknown example given by \[ Wilks  1972\]  ) will commonly appear in texts and make the rejection of syntactic interpretations on semant ic grounds harder  . In the MU systems , we prepared about 50 semantic categories for nouns , but most of them are not as effective as we had expected for preventing ' nonsense ' interpretations  , though they are effective for certain kinds of semantic interpretation  ( for example , for deep case inter-\]gretations of preposit ional phrases which are not :: strictly governed by their predicates  ) and target word selection to some extent . A Snoted in Section 7 , though Wilks ' idea of ' preferential semant ics ' is this idea with the other kinds of processing and wi % n preferences of other levels  . 
\[ Problem I0\] ( Maintainability of Systems ) In the discussion of \[ Problem 3\] , we claimed that the transfer component should be robust and be able to compute the most feasible factors relevant to target structure determination  , even if necessary factors cannot be given by the analysis phase  . The same line of discussion can be applied to the entire process of MT  . The analysis phase , for example , cannot expect that a full set of necessary info rmation for inter-pretation of input sentences will always be accessible  . This implies that , at each phase of transla-tion , a certain number of rules , which area kind of heuristics and not theoretically well-founded  , should be prepared . Furthermore , to deal with wide subject fields implies that we have to treat varied types of linguistic phenomena  , which again requires a large number of rules in those systems  . Widerfields also increase ambiguities at each level of intepretation  . 
A single word may have several different part -of-speech interpretations  , to each of which several different syntact ic features may be assgined  ( for example , a verb often have several different surface case patterns  )  . This difficulty can be avoided to some extent in other applications because we can fix certain levels of interpretation in advance  ( for example , ' ship'may only be used as a noun in a certain database access system  , though it has a verb interpretation ) . In order to prevent the prolifera-tion of possible syntactic interpretation in MT  , we need a certain number of disambiguation rules which are also heuristic based\[Tsujii  1984\]  . In short , we have to manage a large number of rules whose mutual relationships are tighter than those found in most other rule based expert systems  . We have to develop not only flexible software systems for managing such large rule based sys tems\[Johnson  1984\] \[Nakamura 1986\] but also methodologies by which we can systematically organize and integrate knowledge of quite different sorts  . 
9 Conclusions
In this paper , we have concentrated on problems concerned with ' understanding and translation ' and have tr ied to clarify that the aspects of ' understanding ' relevant to MT are different from those in conventional NLU researches and their application fields  . The relation ~ ships between linguistic expressions and their understanding results are not asst raightforward as most researchers in NLU have assumed  . Though most researches in NLU have focused on single aspects of understanding which are defined by ' internal processing '  , we have to treat almost all aspects of ' understanding texts ' in MT  , which are mutually intertwined in a compli cated manner and have to be integrated into single computationally unified frameworks  . Though this is an extremely hard task , the difficulties seem to be deeply related both to ' understanding texts ' in a true sense and to the essential properties of natural language  . We would also like to claim that it is time to integrate these two fields with their dif ferent histories and different techniques  , MT and NLU , and so to start to clarify what ' understanding texts ' really means  . 

Although the views expressed in this paper are my own  , I would like to thank my colleagues of the Mu -project who are engaged in developing the ac tual systems  . In particular , I would like to thank Prof . 
M . Nagao , the director of the whole project , Assistant Prof . J . Nakamura who is responsible for software development  , and Mr . Y . Sakamoto ( ETL ) and Mr . M . Sato ( JICST ) who is actually engaged in constructing d ictionaries of a large vocabulary  . I also wish to thank Dr . J . Bateman and Prof . M . Yamanashi ( Kyoto Univ .   ) who are not official members of the projec t but whose critical comments improved the paper very much  . 
References\[Amano1985\]: Amano , S . : Toshiba Machine Translation System , in Proc . of International Symposium on
Machine Translation , 1985\[Appelt 1985 . \]: Appelt , D . : Planning English Re-ferring Express ions  , Artificial Intelligence ,  26 , Machine Translation System , Computational Linguis-tics , Vol . ii , NO . 23,\]985\[Biewer1985\]: Biewer , A . , Feneyrol , C . , et , al . : ASCOF-A Modular Multilevel System for French -German Translation  , Computational Linguistics , Vo \] .  11,
No . 23, 1985\[Bobrow 1968\]: Bobrow , D . : Natural Language Input for a Computer Problem -Solving System  , in M . Minsky ( Ed . ) , Semantic Information Processing , MIT Press , Ambrunaz : Implementation and Conversational Environment of  ARIANE-78  . 4, in Proc . of COLING 82 , 1982\[Boitet1984\]: Boitet , C . , Gerber , R . : Expert Sys-tems and other Techniques in MT Systems  , in Proc . of
COLING84, Stanford , 1984\[Brady\] . 9831: Brady , M . , Berwick , R . C . : Computa-tional Models of Discourse , MIT Press , 1983\[Bruderer 1977\]: Bruderer , H . E . : Handbook of Machine Translation and Machine-A ided Translation  ; Automatic Translation of Natural Language and Multilingual Terminology Data Banks  , North-Holland , 1977\[Carbonell , 1978\]: Carbonell , J . , Cu \] lingford , R . , Gershman , A . : Toward Knowledge-Based Machine Translation , in Proc . of COLING 78, \] . 978\[Carbonell , 1981\]: Carbonell , J . , Cullingford , R . , Gershman , A . : Steps Toward Knowledge-Based Machine Transla tion  , IEEE Transactions on Pattern Analysis and Machine Intelligence  , PAMI-3-4 , 1981\[Feng1982\]: Feng , Z . : Memoire pour une tentative detraduction mu itiling ue du Chinoisen Franea is  , Anglais , Japonais , Russeet Al\]m and , in Proc . of
COLING 82 , 1982\[Fillmore19(~8\]: Fillmore , C . : The Case for case , in ' Universals in Linguistic Theory ' ( eds : Bach and Harms )  , Holt , Rinehart and Winston , 1968\[Goetschalckx 1974\]: Goetschalckx , J . : Translation , Terminology and Documentation in Internation a l 
Organization , Babel ,  20-4 ,   1974 \] Grosz 1986\] : The Structures of Discourse Structure , in Proc . of the Symposium on ' Language and Artific i al 
Intelligence ' , Kyoto , 1986\[Hobbs1984\]:Hobbs , J . :' Sub\]anguage and Knowledge ', in Proc . of Workshop on sublanguage Description and Processing  , New York Univ . , 1984\[Isabe\]le1985\]:Isabel\] . eP . , Bourbeau , L . : TAUM-AVIAT\]~ON : Its Technical Features and Some Experimanta \] Results  , Computational Linguistics , Vol . 
ii , No . i , 1985\[Isiwata 19136\]: Ishiwata , T . : ' Linguistic Research and Machine Translat ion '  , Report on Advanced Study for Natural Language Processing  ( ed : Nagao )  , Kyoto
University , \] . 986  ( in Japanese ) \[Ishizaki 19196\]: Ishizaki , S . , Isahara , H . : Natural Language Processing System with Deductive\[  , earning Mechanism , in Proe . of the Symposium on ' Language and Artificial \ [ Intelligence '  , Kyoto , Japan , 1986\[Johnson1984\]: Johnson , L . , Krauwer , S . , Rosner , M . , Varile , G . : The Design of the Kernel Architecture for the EUROTRAS of tw are  , in Proc . of COLING 84 , 1984) Johnson 1985\]: Johnson , R . , King , M . , de Tombe , L . : EUROTRA : A Multilingua \] System under Development  , Computational Linguistics , Vo \] . ii , No . 2-3, \] . 985\[Kay 1984\]: Kay , M . : Functional . Unification Grammar : A Formalism for Machine Translation  , COLING 84 , Machine Translation System , in Proc . of 7th IJCAI,
Vancouver , \]919\]\[King\]986\]: King , M . : On the Proper Place of Semantics in Machine Translation  , in Proc . of the Symposium on ' Language and Artificia l Intelligence '  , 
Kyoto , \] . 986\[Kittredge 1976\]: Kitterdge , R . , Boutbeau , L . , Isabelle , P . : Design and Implementation of an English -French Transfer Grammar  , COLING 76 , 1976\[Kogure 1984\]: Kogure , K . , Yokoi , A . et . al . : The Frame Editor for Diction ar Edit ing  , WGP reprint , Working Group on Natural Language Processing , Information Processing Society of Japan ,  1984 , in
Japanese\[Loh1975\]: Loh , S . -C . : Computer Translation of
Chinese Journals , AJCL , 43, 1 . 975\[Lytinen 1 . 982 I : Lytinen , S . , Schank , R . : Representation and Translation , Yale AI Project Research Report 234 , 1982\[Muraki 19821: Muraki , K . : On a Semantic Model for Multi-Lingual ParaPhrasing  , in Proc . of COLING 82 , System VENUS : Two Phase Machine Translation System  , Proc . of International Synposium on Machine Translation  ,  \] . 985\[Nagao1983\]: Nagao , M . : La Traduction Automatique,
La Recherche ,  150 , 1983\[Nagao1984\]: Nagao , M . , Nishida , T . , Tsujii , J . : Dealing with Incompleteness of Linguistic Knowledge in Language Translation  , in Proc . of COLING 84, 1984\[Nagao1985\]: Nagao , M . , Tsujii , J . , Nakamura , J . 
1 985 : The Japanese Government Project for Machine Translation  , Computational Linguistics , Vol-ll , No . 
23,1985\[Nagao1986\]: Nagao , M . , Tsujii , J . : Transfer Phase of a Machine Translation System  , in Proc . of COLING 86 , ( to appear )\ [ Nakamura 19841: Nakamura , J . , Tsujii , J . , Nagao , M . : Grammar Writing System ( GRADE ) of Mu-Machine Translation Project and its Characteristics  , in Proc . 
of COLING 84 , 1984\[Nakamura 1986\]: Nakamura , J . , Tsujii , J . , Nagao , M . : Solutions for Problems of MTParser , in Proc . of
Coling 86 , 1986 ( to appear )\[ Nishida1980\]: Nishida , F . , Takamatsu , S . : English--Japanese Translation Through Case Structure Conversion  , COLING80 , 1980 Translation : Japanese Perspectives , in Proc . of the 7th Translating and the Computer Conference , London , Shimazu , A . : Translation by Understanding , in Proc . 
of COLING 86 ,  1986  ( to appear ) \[Sakamoto 1984\]: Sakamoto , Y . , Sato , M . , Ishikawa , T . : Lexicon Features for Japanese Syntactic Analysis in Mu-Project-JE  , in Proc . of COLING 84 , 1984\[Schank1975\]: Schank , R . : Conceptual Information
Processing , North-Holland , 1975\[Slocum1985 a \]: Slocum , J . : A Survey of Macine Translation : Its History , Current Status , and Future Prospects , Computational Linguistics , Vo \] . ii , No . I , Machine Translation , Computational Linguistics , Vol . 
ii , Noi ,  23 , 1985\[Tanaka 1983\]: Tanaka , H . , Isahara , H . , Yasukawa , H . : An English-Japanese Machine Translation System using the Active Dictionary  , Technical Report , ETL , 
Ibaraki , 1983\[Tong1986\]: Tong , L . C . : English-Malay Translation System : A Laboratory Prototype  , in Proc . of COLING 86 ,  1986  ( to appear ) \[Tsujii 1984\]: Tsujii , J . , Nakamura , J . , Nagao , M . : Analysis Grammar of Japanese in the Mu-pro ject  , in
Proe . of COLING 84 ,   1984 \[ Tsujii 1985\]: The Japanese Government MT Project , in Proc . of International Symposium on Machine
Translation ,   1985 \[ Tsujii 1986\]: Future Trends of Machine Translation , in Proc . of the Symposium on ' Language and Artificia l 
Intelligence ' , Kyoto , 1986\[Uchida1980\]: Uchida , H . , Sugiyama , A . : A Machine Translation System from Japanese into English based on Conceptual Structure  , Proc . of Coling 80\[Uehida1985\]: Uchida , H . : Fujitsu Machine Translation System ATLAS , in Proc . of International Symposi \ [ on MT , 1985\[Tucker 1984\]: Tucker , A . B . : A Perspective on Machine Translation : Theory and Practice  , C . ACM , Vol . 
27, No . 4, 1984\[Tucker 1985\]: Tucker , A . B . , Nirenburg , S . : Macine Translation : A Contemporary View , Annual Review of Information Science and Technology  , Vol . 19, Knowledge Industry Publications , Inc . , 1985 \ [ Vasconce l los 1985\] : Vasconce l los , M . , Leon , M . : SPANAM and ENGSPA : Machine Translation at the Pan American Health Organization  , Computational
Linguistics , Vol . Ii , No . 2-3,1985\[Vauquois1979\]: Vauquois , B . : Aspects of Mechanical Translation in 1979 , Conference for IBM Japan
Scientific Program , GETA , 1979\[Vauquois1985\]: Vauquois B . , Boitet , C . : Automated Translation at Grenoble , Computational Linguistics , 
Vol . ii , NO . i , 1985\[Wilks1972\]: Wilks , Y . : An Artificial Intelligence Approach to Machine Translation Grammar  , in Computer Models of Thought and Language ( eds ; Schank and
Colby ), W . H . Freeman , 1972\[Wilks1975\]: Wilks , Y . : A Preferential Pattern Matching Semant ics for Natural Language  , Jour . of AI,
Vol . 6, 1975
