EBL2: ANAPPROACHTO
AUTOMATICLEXICAL ACQUISITION
LARSASKER*BJ ( )R N GAM BACK ~ CllRISTER SAM UELSSON 1
asker@day , nu . negam?sics , sochrister ~ sics , se
Keywords : linguistic tools : / exical acquisiti ( ul ; explanation-based larning
Abstract
A method for automatic lexical acquisition is out lined  . An existing lexicon that , in addition Io ordinary \] exical entries , contains prototypical cntrips for various nonexclusive paradigms of open-cl ~  ,  . ss words , is extended by inferring new lexical entries from texts containing unknown words  . This is done by comparing the constraints placed on the unknown words hy the naturalanguage system's grammar with the prototypes and a number of handcoded phras  (  , templates specific for each paradigm . Once a sufficient number of observations of the word in different contexts have been made  , a lexical entry is constructed for the word by assigning it to one or sew ~ ralpara-digm  ( s )  , Parsing sentences with ull known words is normally very time-consuming due to the largen mn-ber of grammatically possible analyses  . To cir ~ cumven this problem , other ilhrase templates are extracted automatically from timgram lnal and domain -specific texts using an explanation based learning method  . These templates represent grammatically correct , sentence patterns . When a sell-tence matches a template , the original I ) arsing component can be by passed , reducing parsing times dramatically . 
1 Introduction
A persisting trend in unification-based approaches to natural language processing is to incorporate large quantir Aes of information in the lexicon  , informatio , i that has traditionally resided in the gran , mar rules . 
Acquiring a lexicon has thus be colneadiflicull and time consuming txsk  , even for moderately sized lexira . In addition to this , an . ' , ' natural language processing system intended for serious applications must include a large lexicon --several thousands of words or more is commonly considered a minimun ~ size which adds even more to the complexity of the lu ' ob-lem  . In view Of this , tools for lexical acqusition are not only desirable they become a necessity  . 
Most . approaches to this problem hay , ' been * Department of ( . \] onlpuler,~lldS)'steRISS cieIIC('S,S\[ock . 
hohn University , Electrnm 23(/, S-16 . t , In \] < . ISTA , Sweden . 
INLP-group , Swedish hmtitute tff Computer Science , Box 1263 , S 16 . 128 KIST & Stockhohn , Sweden . 
to construct a range of tools that require vari-nus degrees of inleraclive support when new lexical entries are created  , either from raw text material ( as ille . g . , \[' frost & Bnchberger 86 , Groszctal 87 , Wilensky 90\] and tile early work by Zernik\[Zernik ~ (  , " Dyer 85 , Zernik 87\]) , or from machine readable dictionaries ( see e . g . ,\[ Bognraevelal 87, (' . alzolari & " Bindi90\]) . Although interactive tools or h'xical acquisition greatly simplifies tile task of constructing a lexicon  , it . is desirable to gooue step further and fully remow " the need for user interaction  . 
One of the first systems that aimed at constructing lexica \] entries automatically from raw text was Granger's FOUL-U'P system\[ Granger  77\]  . FOUL-UP extended a lexicon by referring restrictions placed on unknown words by instantiating scripts that matched the sentences containing then n known words  . This I ) uilt on aimmber of assumptions which in general do nolbold  , in particular : that all the information eeded to create all entry is contained illone text : that nonmrphological information is needed  ; tha ~ specific ( handcoded ) scripts covering the domain can be made available in advance  , hi one of the later approaches to automatic lexical acquisition from raw text  , \[dacobs , to Zernik 88\] have shown the need to consult a variety of knowledge sources such~s morphological  , syntactic , semantic , and contextual knowledge when determining a new lexical entry  . 
This paper describes an automatic nlethod to acquire new lexical entries by using analytical learning in coml  , in a lion wit . h strategies used in an existing interactive tool for lexical acquisition  ( VEX\[Carter 89 )  . In the process of constructing a lexical entry . the system combine several different sources of information : the underlying NL system  ( CLE , \[ Alshawired . ) 92\] ) will contribute information on syntactically and semantically permissible phrases and ontile rules for in Ilectional nmrl  ) hology . The corpus wilt contrihute information on which of these constructions actually occur  . This information is combined with tile the linguistic knowledgencoded in the interactive l xical acquisition tool to infer lexical entries for unknown words m the text  . 
The rest of I hepaller is laid out as follows : Section  :2 contains informational ) out the various elements on which the method is based  . Section 3 de-AcrEs DECOLING-92 , NANTES , 2328 Aot ) ' r19921l72 PRec . el : COLING-92, NANTES , AUG .  2328 ,   1992 scribes the method itself and Section 4 reports on For these " paradigm words " only , the complete set the current state of the implementation  , of feature vahles is explicitly specified . 
2 The elements of the scheme 2 . 1 The Core Language Engine , CLE The Core Language Engine is a general purpose natural language processing system for English developed by SRI Cambridge  . It is intended to be used as a building block in a broad range of applications  , e . g . data-b ~ . se query systems , machine translation systems , text-to-speecb/speech-to-text systems , etc . 
The object of the CLE is to map certain natural language x pressions into appropriate predicates in logical form  ( or Quasi-Logical Form\[Alshawi , ( . : vanEij ck89\]) . The system is based completely on tmilication and facilitates a reversible phrase-structure type grammar  . 
The Swedish Institute of Computer , ' qci ( m ( e has with support from 8RI generalized the fi'anw work and developed all equivahmt system for Swedish  ( the S-CLE , \[Gamback & Rayner 92\]) . The two copies of the CLE have been used together to form a machine translation system\[Alshawi et  a191\]  . The S- ( ' LE has a fairly large gramnmr covering most of the common constructions in Swedish  . There is a good treatment of inflectional morphology  , covering all main inflectional closes of nouns , verbs and adjectives . 
The wide range of l ) ossihle applications have put severe restrictions on the type of lexicon that can be used  . The S-CLE h ~ a function-word lexico ~ J containing about  400 words , including most Swedish pronouns , conjllnct lous , prepositions , determiners , particles and " special " verbs . In addition , there is a " core " content-word lexicon ( with common ouns , verbs and adjectives ) and domain specitic h'xica . 
This part of t be system is still under development and all these content-word lexica together haw  , about 750 entries . 
The lexical entries contain information about il ~ -flectional morphology  , syntactic and semantic subcategorization , antisortal ( selectional ) restrictions . 
Information abont the linguistic properties of an entry is represented by complex categories that include a principal category symbol and specifications of con-straints on the values of syntactic/semantic features  . 
Such categories also appear in the C . LF , 's grammar and matching and merging of the information encoded in them is carried out by unification during parsing  . Two categories can be unified if the constraints on their feature values are compatible In the actual " core " and domain Icxica  , this information is kept implicit and represented as pointers to entries in a " paradigm " lexicon with a number of words representing basic word usages and inflections  . 
2.2 The Vocabulary EXpander , VEX
In the English CLE , new lexicon entries can be added by tile users with a tool developed for the purpose  . 
q'h is lexicon acquisition tool , the Vocabulary EX-pander , is fully described in \[ Carter89\] . In parallel with the development of the S-CLE , a Swedish version of the VEX system was designed \[Gamback  92\]  . 
VEX allows for the creation of lexical entries by users with knowledge both of a natural anguage and of a Sl  ) ecilic application domain , but not of linguistic theory or oftile way lexical entries are represented in the CLE  . It presents examl ) le sentences to the user and asks lor information on tile grammaticality of the sentences  , and for selcctional restrictions on arguments of predicates VEX adopts a copy and edit strategy in colmtrnctiug Icxical entries  . It builds on the " paradigm " lexicon and sentence patterns  , that is , declarative knowledge of the range of sential contexts ill which the word usages in that lexicon 
Call OCCUI'.
In the present work we want to investigate to what extents nch creation of lexicon entries can be performed with a minimum of user interaction  , ln-stead of presenting exaruple sentences to the user we are allowing the program to use a very large text where hopefully unknown words will occur in several ditlbrenl sentence patterns  . This strategy will he filrther described i ~ , the following sections . 
First , however , we will define what we mean by the notion of ( subcategorization ) " paradigm " . Tile definition we adopt here is based on the one used in \[ Carter  89\]  , namely that
Definition 1 a paradigm zs any minimal non . empty intersection of Icxical entries . Every category in a pa , ' adlgm will occur in czaclly the same set of entries in the lexicon as every other category Of auy  ) in that paradigm . 
Everyent , y consists of a dis3o2ulunion of paradigms . 
lh're , we assume that a lexicon can be described in terms of  ( a small set of ) sucb paradigms , relying on ttle fact . that the open-class words exhibit at least approximatergularities  )  2 . 3 The Lexicon Learning system , L 2 Previous experiments in automatic lexical acquisti-lionat  . S1CS ( L~-Lexicon Learning ) used a set of 1 The system does not attempt to cope with coaed -categc  ) rywords . '\[' hey have to be entered into a apecific function-word lexicon by a skilled linguist  . 
ACTESDECOLING-92 , NANTES , 2328 AO~r19921173I'gOC . OFCOLING-92, NAN'rES , AUG .  2328 ,   1992 sentences and a formal grammar to infer the lexical categorit  . '-s of the words in the sentences . The original ideawa . q to start with an empty lexicon , assuming that the grammar would place restrictions on the words in the sentences sufficient to determine an assignment of lexical categories to them\[Rayner elal  88\]  . This can I ) eviewed as solving a set of equations where the words are variables that are Io be assigned lexical categories and the constraints that all sentence sparse with respect o the grammar are the equations  . 
Unfortunately , it proved almost imposs it , le to parse sentenees containing several nn known words  . 
For this reason the scheme was revised in several ways\[tlgrmander  88\]  ; instead of starting with a neu/pty lexicon , the starting point bccan w , a lexicon coutaining clnsed-cl ; ksswords snell ; L~l ) FOll OIl nS ~ prepositions and determiners . The system would then at each stage only process entences that coilrained exactly one unknown word  , the hop , , I ) eing that tlie words learned from these sentences would reduce the number of unknown words in the other ones  . In addition to this , arn or phologicat component w~s included to guide the assignments  . Although the project proved the femsibility of the scheme  , it also revealed some of its inherent problems , especially the need for f a . ster parsing methods . 
2 . 4 Explanation-based learning , EBLA problem with all natural language grammars i that they allow avemt number of possible constructions that very rarely  , if ever , occur in real sentences . The application of explanation-based learning ~ ( EBL ) to natural language processing allows us to reduce timset of possible analyses and provides a solution to the parsing inefficiency problem mentioned above  ( Subsection 2 . 3) . 
The original idea\[Rayner88\]wast . obypassll Ol'-lna \] processing and instead use a set of learlled rules that per h  ) rmed the t . ~ qks of the normal parsing component , l : ly indexing the learned rules eflicieutly , analysing an input sentence using the learned rules is w~ry much faster than normal processing \[ Samuelsson & Rayner  9t  \] . The learned rules can be viewed as templates for grammatically correct phrases which are extracted from the  . granmmr and a set of training sentences using explanatiou-bmqed larning  , llere , we assume the following definition :
Definition 2 a ten't platets a generalization constrvcted from lheparse tree for a success fidly processed phrase  ,   . , 1 template is a tree spanning the parse with a mother category as root and a collection of its ancestor nodes  2t~xplanation-lmsed learning is n machine learning tech-Ill qlle closely related totlla Cro-operator learllilg  , chtlllkillg , and parliM evaluation and is described in e . g . . \[ I)e . long &
Mooney 8~';, Mitchell et at 86\].
( at arbitrary , but predefined , deep levels of nesting ) as I~a~les . 
The fact that the templates are derived from the original gramlnar guarantees that they represent correct phrl Lses and the fact that they are extracted from reals enteuce sensnres I hat they represent constructions that actually occur  . 
3 Explanation-based lexical learning , EBL2
The basic algorithm goes , xs follows : 1 . Using a large corpus from the domain , extract teUll ) lates from the sentences contaiuinguo1 . 111-known words . 
2 . Analyse the remaining sentences ( the ones con-taiuing unknown words ) using the templates , while maintaining an interim lexicon for the unknown words  . 
3 . Compare the restrictions placed on the unknown words by the analyses obtained with other handcoded phrase template specific for the paradigms m the lexicond  .   ( 2reate " rear ' lexical entries from the mforma-ti <m m the intcrhn lcxicon when a full set of such templates \[ covering a paradigm  ) has been found . 
In the following subsections , we will address these issues in turn . 
3  . 1 Ext rac t ing templates f rom a domain - spec i f i c corpus A typical situation where we think that this method is well suited is when a general purpose NL system with a core lexicon  ( such as the S-CLE ) is to be customized to a specific application domain  . Tile vocabulary used in the domain will include e . g . technical terms that are not present in the core lexicon  . Also , the use of the words in the core lexicon may differ between domains  . In addition to this , some types of graln matieal coust rilcts may be more e onll nonillone domain than ill all other  . We will try to " get the flavour of the language " in a particular application euviromnenl from domain-specific texts  . 
The corpus is divided into two parts : one with seatellces containing iln known words  , all (\] another where all the words are known , The latter group is used to extract plmme templates that capture tile grammatical constructions occurring in tile domain  . r Fhe process of extracting phrase templates from training sentence si outlined in Subsection  2  . 4 . 
AcrEsnl ~ COTING-92 , NAt , rl~s , 2328 Ao(rr 19921!74 PRec . OFCOLING-92, NAmV:s,AUG .  2328, 1992 3 . 2 Analysing the remaining sentences Assuming that a partieular set of phrase tenlplales is applicable to a sentence containing an unknown word will associate a set of constraints with the word  . 
Naturally , the constraints Oil I\[lek Bowlt words of the sentence should be satisfied if this tcmplatvis to be e  ( msidered .   3 This will correspond to a partic+-ular parse or analysis of these utenee  . Thus a solof constraints ia . ssociated with each different pm'seA number of entries in the prot  . otypeixic ou will mat cll the set of constraints associated with a sen-teuce  . \['\] aeh prototy I ) e is all ill Cal'llatio I lofil paradigtn , Thus we can a . ssociate a word with a set of paradigms . ( Note thai the paradigms may be nonexclusive . ) All such + msociatious ( corresponding to different parses of the same sentence  ) are collected , and used to update the + interimh'xie on . 
'\[' h ( ! IllOSt obvious conslraiuts colnt ! froll syll tictie considerations  . If , in I he sentence John loves a ca ( the word loves were unknown , while the other words did indeed have the obvious lexicai entries  , the grammar will require loves to be a transitive verb of third person singular agreement  . Since the protot Yl ) eS of verbs are iutl , e imperative form , we nmst associate a finite verb form with the imperatiw ~  , This is done by applying a omr phologieal rule that strips the '- s ' from the word loves  , reinforcing the hypothesis and gaining the tense information in the process  . 
Now , this n torphological information lnay seem uniml ) ortant in Fnglish , but it definitely is + lolit , Swedish : a word with more that + onesy\]lal , h + ending with '- or ' has to be an in ( h . finite common gel , dernoun . If it is not of lat in originitln usl , be a phiral form an ( It husil sentire morl ) hology is kJvm , n The odds that it is a count abh " noun ( liked . ck ) , as ( \[ ) posed tO1t lllaSSIIOIln ( such IS walev )  , ; ll'C ( ) vet " whehning . 
3.3 Constructing lexical entries
During tile analysis of the set of sentences conlain-ing unknown words  , an interim lexicon for these unknown words is kept  . The interimlexie on isimlexed on words terns and updated each titlie a IWWSell fence is i  ) roees sed . \[" or each words I , eul+t'e/o pieces of information are retained in this lexicon : a hypothesis about which paradigm or set  . of paradigms lheword is assumed to belong to , and a justifieat . i on I haten codes all evidence relevant to the word  . The jnsti-fieation is used to make the hypothesis amlisma intained so that the entry may be Ul  ) (lat , ed whett new inlbrmation about tim word arrives . When all the l ) hrase templates ( sentence patterns ) for lhl filhnent 3 Ulde Sstile ) ' I h ) ill fact CO ll't!sp ( l l t d t o o t h t T l l r ) ll lexicaliz , : dSl?llSeS of tile word , in ' to hOllO~l . & l ) hS , of a Sl ) ecilic para ( ligm have been found , an entry for the word is made in the domaim specifie lexicon that is bcm g constructed  . This is done while still keeping the justilication reformation  , since this might con-taht evidence indicating other word senses or holno-graphs  4 hnI ) lementation status A prelimiuary versi ( ~ u of the lexieal acquisition systern has been implemented in Prolog  . " File meal-tile extracting telnplates fro lnSell tences with knowll words is\[uily operational  . The parser for sentences witilunkuown words has also been tested  , while tile iater im lexicon still is subject to experimentatiol LPresenl  . ly , aw'rysiml ) lestrategy for the interiln lexicon has been tesled  . This version uses the set of all hypotheses ns the justification and use their dis-  . it metion as theer a'rent hypothesis . We are currently working Oll extending this sd lenle to one incorporating the full algorithm deseril  ) ed above . 
Unknowuwor ( l ~ are matched with tim subcalego-rizatiou paradigms of the S-CLE  . In total 62 differ-en lsynl . aet . ic/semantic paradigms are known by the present systmn :  5 for Swedish nmms , l0 for adjectives , aud all timothers for verbs . Timmor phological inflections are subdivided into  14 different inflectional cbLsses of nouns , 3 classes of adjectives , and 24 classes of verbs . 
5 Conclusions
We have ( mt . lin <' da method for autonlatic lexie alae- ( luisilion . An existing lexicon built on the usage of i ) rolotypica \] entries for l ) aradigms of opemela . sswords , isext . end ~' db 5 infi ~ rring new lexical entries fl ' OIII texts containing Dnkl/own words  . The COll-straints placed on these words by the gramnlar arc compared with the prototypes and a hypothesis is made al  ) ou I what paradigm the word is most likely to l ) olong to . 
The hy\]lo these sai ) otlt , the iln known words are kept+man interim lexicon until a suflicient level of confidence is reached  . Phrase templat < ~ s are both hand-cod <+ daud extracted front the grammar and donlaiu-spt ! citic texts using an explanation-based h  , arning method . 
6 Acknowledgements
The work reported here was fimded by the Foundation tot the Swedish Institute of Computer Science aud the Swedish National Board for Industrial and 
T < , chnicall ) evelol ) mel\]t ( NUTEK).
Aeries nECOLING O2 . N,~t ~ " nis , 2328^ot ~ rl 19921l 75I ) roc . OFCOLlNG-92, NANTES , AU() .  2328 ,   1992 We would like to thank Manny Rayner and David Carter  ( SRI Cambridge ) and Seifllaridi ( SICS ) for helpful discussions and suggestions , and Pierre Gan-der ( Stockholm University ) for valuables upl ) ort . 

Alshawi , 11 . and J . van Eijek (1989) . " Logicalt " orms in the Core Language I '; ngine " , the 271h Annual Meeling of the Association for Coalpala -tional Linguistics  , Vancouver , llritish Columbia , pp .  25- 32 . 
Alshawi , tl . , D .  (' . after , B . Gaml ) iiek and M . Ray-net 11991) . " Translation by Quasi Logical Form Transfer " , the ~9lh Annual Meeting of th ~ Association for Computational Li  ) tgaisltes , University of California , Berkeley . California , pp .  161 . .

Alshawi , I1 . ( ed . ) (1992) . 7' h ~ Core Langttage Engine , C ' ambridge . Massachusetts : The MIT

Boguraev , B . , T . tlriscoe , J . Carroll , D . Carter and C . Grovcr (1987) . " The Derivation of a Grammatically Indexed Lexicon from the Long-lnan Dictionary of Contemporary English "  , the 251h Annual Meeting of the Associat to a for Computational Linguistics  , Stanford , California , pp .  193-200 . 
C . arter , D .  11989) . " Lexical Acquisition in the ( _lore Language Engine " , the 4th Conference of the European Chapter of the Association Jbr Computational Liaguist tcs  , Manchester , Eugland , pp .  137- 144 . Also available as SRI lnternatio a a\[
Report CCSRC-012, Cambridge , England
Calzolari , N . and R . . Bindi (1990) . "Aequisilion of Lexical Information from a Large Textual Italian Corpus "  , Ihe 131h International Conference on Computational Linguistics  , lh ' lsinki , 
Finland , Vol . 3, pp . 5459.
DeJong , G and R . Mooney 11986) . " Explanation Based Learning : An Alternative View "  . Machine Learning , 1:145--176 . 
Ganfl ) ~ ckI:L and M . ll . ayner (1992) . " The Swedish Core Language Engine " , the 2rd Nordic Conference of Tex ! Comprehension iMan aad Machine  , Link Sping , Sweden . 
Gamb/iek B .  (1992) . " I , exieal Acquisition : The Swedish VEX System " , the 2rd Nordic Conference of Tert Comprehension iMan and Machine  . Linki Spiag , Sweden . 
Granger , R . It .  (1977) . " FOlrl , -UP : A program that figures Otlt meallings of words from colltex  ( ' , the 5tblnter ~* atio ) ml Joint Conference on Artificial Intelligence , Cambridge , Massachusetts , pp .  172- 178 . 
Grosz , B . J . , D . E . Appelt , P . Martin , and F . C . N . Pereira 11!)87) . " TEAM : An Experiment in the Design of Transportable Natural Language Interfaces "  , Artificial Intelligence ,  32:173 243 . 
tl6rmander , S .  11988) . " The Problems of Learning a 1 , exicou with a Formal Grammar " , SICSR , e-search l/eport R88019 , Stockholm , Sweden . 
Jacob . ~ . P . a ~ l ? lU . Zernik 11988) . " Acquiring Lexieal Knowledge from Text : A Case Study "  , the 7th National Conference on Artificial Intelligence , 
Saint Paul , Minnesota , pp . 739744.
Mitchell , T . M . , It M . Keller and S . T . Kedar-Cabelli (1986) . " Explanation-ltased Generalization : A Unifying View "  . Machine Learning , 1:4780 . 
Rayner , M .  11988) . " Applying Explanation-Based Generalization to Natural Language Processing "  , the lntcrnalional Conference on Fifth Geaeration C'ompuler Systems  , ' lk ) kyo , Japan , pp . 1267-1274 Rayner , M . , /~ . Hugosson and G . Ilagert (1988) . 
-lIsmgaLogic Grammar to Learna Lexicon " , the 12th International Conference on Computational Linguistics Budapest  , llungary , pp . 524-529 Also available , as SICS Research Report-
R88001, Stockhohu , Sweden.
Samuelsson , C . and M . Rayner (1991) . " Quantitative Evaluation of Explanation-Based Learning a ~ an Optimization Tool for a Large -Scale Naturali  , anguage System " , the 12th International Jotnl Conference on Artificial Intelligence  , Sydney , Australia . 
Trost . tl . and E . Buchberger 11986) . " Towards the Automatic Acquisition of Lexieal Data "  , the llth International Conference on Computational Linguistics  , ltonn , Germany , pp .  387 389 . 
Wilensky , R .  (1990) . " Extending the Lexicon by Exploiling Subregnlarities "  , the DARPA Speech and Natural Language Workshop , llidden Valley , Pennsylvania , pp .  365-370 . 
Zernik , U . and M . Dyer 11985) . ' " lbwards a Self-Extending Lexicon " , the 22rd Annual Meeting of the Associatio ~ t for Computational Linguistics  , University of Chicago , Chicago , Illinois , pp 284292 . 
Zernik , U .  (1987) . " l : mguage Acquisition : Learning al Iierarehy of Phrases "  , the lOth International Joint Conference o ) 1 Artzficial lntelliqence , Milan , italy , pp . 125131 ACTXS DECOLING-92, NAN'W . S , 2328 AO(Yr 19921I76 PROC . OFCOLING-92, NANTES , AUG .  2328, 1992
