The Typology of Unknown Words:
An Experimental Study of Two Corpora
Xiaobo Ren and Francois Perrault
xren@ccrit.doc.ca , perrault@ccrit.doc.ca
CCRIT , Communications Canada , 1575 Chomedey Bid , Laval , Qu 6 be c , Canada , H7 V2 X2
Table of contents

Related work



Extracting unknown words

G1: Correct words
G2: Erroneous words
Frequency of unknown words
Recognizing unknown words
G2: Erroneous words
GI : Correct words


1.0 Introduction
Most current state-of-the-art natural language processing  ( NLP ) systems , when presented with real-life texts , have problems recognizing each and every word present in the input  . Depending on the application , the consequences can be severe . For example , in a machine translation system the quality of the processing may suffer and sometimes further processing may even be impossible  . There are two main reasons why a word might not be recog-razed and thus be considered unknown by the system : ? The linguistic knowledge of the system is not complete  , i . e . the word is correct but is not present in the system's d=ctionary  ; ? The word is erroneous . 
A lot of effort has been directed towards dealing with the latter  , i . e . finding ways of detecting and correcting erroneous words  . Most of the developments in this area of research are based on a paper by Damerau \ [ Damerau  64\] where the author offers a classification of erroneous words  . 
The aim of this paper is to present furthe results about the frequency and types of unknown words found in real-life corpora  . We hope that the results of our study will be of some use in the development of NLP systems capable of dealing with realistic input  . 
Our findings confirm Damerau's results in that the great majority of erroneous words contain a single typographical error and belong to one of the four following catego-fie  , s : insertion , deletion , substitution , transposition . 
But we have also found that a large proportion of the unknown words is made up of correct words which are not present in the dictionary  . For example , derived words alone represent 30% of all unknown words in our sam-pies . 
These results indicate the need for further work before an acceptable velof robustness can be attained  . Although traditional typographical error detection and correction techniques can be used to handle the majority of erroneous words  , much remains to be done before such problematic are as as derived words can be dealt with effectively  . 
2.0 Related work
In his pioneering article\[Damerau 64\] , the author gives valuable information about the frequency of typogruphi-cal errors  . In his paper Damerau indicates that typically ,   80% of all ill-formed words in a document are file result of one of four typographical errors : ? Transposition of two letters  , e + g . & bali instead of 61 abli ; ? Insertion of one extra letter , e . g . 6 conomio que instead of 6 conomique ; ? Deletion of one letter , e . g . additionelle instead of addi-tionnelle ; ? Substitution of a valid letter by one that is wrong  , e . g . 
oglig 6 instead of oblig 6.
More recent results \[ Pollock and Zamora 83\] also indicate that in most cases , there is only one error per word . 
The classification of possible errors has been extended over the years to include other types of errors\[Srihari  85  , Szanzer 69 , Veron is 88\] . Based on this body of work , we ACTESDECOLlNG-92 , NANTES , 2328^o ~ r1992408 Pgoc . OFCOLING-92, NANTES , AUG .  2328 ,   1992 can propose the following incomplete list of the possible nature of errors : ? Typographical errors  , which are errors of execution in carrying out the task of typing text on a keyboard  ; ? Orthographic errors , which are errors of intention attrib-utable to distraction or lack of knowledge on the part of file author  ; ? Syntactic and semantic errors ; ? Errors committed during rite input procedure , ither by an optical character recognition device or by a speech recognition system  ; ? Storage and transmission errors due to noisy electronics or communication channels  . 
3.0 Corpus
Our typology of unknown words is based on the study of two corpora  . 
3.1 Hansard
The first one , a French corpus called the Hansard , is a transcript of all file proceedings that took place in tile Canadian House of Commons in  1986  . 
Since Canada is offmially a bilingual country , whenever Members of Parliament gather together to debate laws  , the transcripts of the session have to be made available in both English and French  . On the day a session is held , transcripts are translated and printed rapidly in order for the Members of Parliament to have a bilingual copy of the previous days ' session on their desk the next morning  . 
The main characteristics of this corpus are : ? Spoken language style  ; ? Manually typed on a conrputer ; ? Madeup of both translations from English to French and source French statements  ; ? Translated by qualified professional translators  ; ? Translated rapidly ; ? Even the source text is sometimes touched up by professional writers  . 
3.2 Jobs
The second corpus , called Jobs , was obtained from Employment and Immigration Canada and consists of English job offers  . Employment centres across Canada receive calls from employers offering job opportunities  . 
Clerks are responsible for answering the telephone and writing up the job postings  . 
Then min characteristics of this corpus arc : ? Telegraphic style  ; ? Manually typed into a computer program flint has a rig-idly formatted interface  ; ? Made up solely of text originally written in English  ; ? Written rapidly by a clerk . 
3.3 Extracting unknown words
The two cmp or a differ in nature and in the way respective lists of unknown words were extracted  . 
For the Hansard corpus we tokenized the text and we automatically tagged each token with a part of speech\[Foster  91\]  . From this list we then removed all punctuation , numbers and words beginning with a capitaletter ( proper nouns and abbreviations merit separate study  )  . We then singled out all the words that could not be found in an electronic dictionary  . For this operation we used tile DMF\[Bourbeau , Pinard 86\] which contains the equivalent of 59   000 entries . 
As for the English corpus most of the work was done by hand  . We tokenized the text as previously described but the sifting of punctuation  , numbers , words beginning with a capitaletter and known words  , was done manually , leaving a list of unknown words . 
4.0 Typology
We trove divided the list of unknown words into two main groups  . GI contains words that could not be recognized but were correct  , while G2 contains erroneous words . We have further subdivided these two groups into different types of unknown word  . 
Our goal has been to identiy tendencies in this group wc call " an known words "  . In doing so , we iucr cased the number of types and inevitably some of these types intersect  . We have relied on our intuition and experience to as-sign the most plausible type to the unknown words  . 
In this section descriptions will be given of each of these types along with numerous examples  . In addition , in the case of G2 types , we speculate on tile possible causes of error . 
4 . 1G 1: Correct words 4 . 1 . 1 Proper nouns In principle , proper nouus shouklnnt be part of the list of unknown words since we removed all words beginning with a capital letter  . But a few occurrences of proper nouns appeared with tile wrong eapitalizmion and in other cases a lowercase component of a proper noun  ( isolat-ed by the tokenization process ) was found . 
E . g . ottawa ( Ottawa ) 1 , nat(B'naiBrith)ACRES DECOLlNG-92 , NANIES , 2328 Ao~r 1992409 Prec . OFCOLING-92, NANTES , AUG .  2328, 1992 4,1 . 2 Abbreviations Uppercase abbreviations ( acronyms , initials , etc . ) are not considered to be unknown words , but a few ( common ) abbreviations are written in lowercase and thus end up in the unknown word list  . 
E . g . km0dlom/~tre ), pub(publieil ~) 4 . 1 . 3 Ordinals Although numbers and punctuation have not been considered valid unknown word candidates  , ince letters are sometimes used as roman numbers , a few ordinal numbers were found . 
E.g.i(1), iv(4) 4.1.4 Regional words
Those are words or expressions that cannot be found in traditional dictionaries  . Some of them can found in specialized dictionaries\[Shiaty  88\] and some of them can be identified by native speakers  . 
E . g . abrier ( couvrir ) , b6 eosses ( toilettes) , cenne(sou ) 4 . 1 . 5 Scholarly words Scholarly words include technical or rare words  . They can be found in large reference tools like Termium  2  . 
E . g . 6 cosph~re , a moxicillin , an adrome , ayatollah 4 . 1 . 6 Parts of expressions Certain expressions ( French and Latin mostly ) are made up of several elements separated by spaces  . Isolated from the rest of the expression , some of these elements cannot be recognized . 
E . g . facto(de facto ) , wa ( oskeewawa ) , feminem ( adfeminem ) 4 . 1 . 7 Foreign words in the Hansard this category corresponds to anglicisms or 
English words appearing in a quote.
E.g . abortionniste , affluente , run n~s
However , we also found foreign words in the English corpus . 
E . g . chadchow , noel , solicite 4 . 1 . 8 Derived words Derived words are very productive . The number of oc-carrences of this type of unknown word in the Hansard represents almost  30% of all unknown words . In French we found 96 affixes that were used to form new words , I . In the context of an example , parentheses indicate the correct or intended word . 
2 . The terminological databank of the Translation Bureau of the Department of the Secretary of State of Canada  . 
Certain words have both a prefix and a suffix at the same time  . 
E . g . r66 chelonnement , prO commercialisation Certain affixes are more productive than others : anti-  , d & , d~s- , extra- , sur- , in- , inter-rO- , super--age , -ation , - ien , -cur , -iser , -ment 4 . 1 . 9 Compounds We excluded from the unknown word list compounds beginning with a capitaletter and compounds that cannot be recognized when considered as a whole nor when the elements are considered individually  . The unknown words classified as compounds are : ones that should start with a capitaletter but do not  ; those in which the necessary spaces or hyphens have been deleted  , i . e . the elements have been concatenated ; and compounds made up of an element that cannot be recognized  ( often because of the ' o ' infix )  . 
E . g . c~t blo distributeurs , chimio-d 6 pendance , radioas tronomique 4 . 1 , 1 0 Garbled words We include in this category words that are divided by a blank space  , words that are joined together but are not compounds and words which are  , in general , affected by electronic noise . Although in some ways this could be considered an error  , we did not want to put this category in G2 because contrary to other types in G2  , in this case the writer cannot be held responsible for the error  . 
E . g . employ Es , sAvez-vous , a finque , erreur . C e 4 . 2 G2: Erroneous words 4 . 2 . 1 Accents These errors are unique to the French corpus and can be subdivided into four types : ? Accent insertion  . 
E . g . 61 ~ vant (6 levant ) , ~ssai ( essai ) , 6 tages ( otages ) ? Accent deletion . 
E . g . a chetera ( ch ~ tera ) , aerospatiale(a6rospatiale ) , ag6es ( ag6es ) ? Substitution of one accent for another . 
E . g . hg6es (~ g6es ) , 6 v/mement(6v6nemen 0 , all , gem(all6gera ) ? Repositioning of the accent . 
E . g . chomfige ( ch6mage ) , compose 6 ( compos6e ) , d6 g6 utant(d6g of itant ) 4 . 2 . 2 Punctuation This type of error is unique to the English corpus and corresponds to problems with hyphens and apostrophes  . 
There are three cases : ? Deletion of a necessary hyphen  . 
Acrv . sD13 COLING-92, NANTES , 2328 not . ~- r1992410PRoc . OFCOLING-92, NAN'rES , AUG . 2328, 1992 E . g . cardior espiratory ( cardio-respiratory ) , cle , an up(cleanup ) ? Insertion of a hyphen . This usually occurs when hyphens are used to parenthesize txt  . 
E . g . class-secondary , cleaners-including ? Deletion of an apostrophe denoting possession  . 
E . g . compauys ( company's ) 4 . 2 . 3 Insertions Knowing the configuration of a standard keyboard and the way people type suggest several plausible reasons for the inserfiou of superfluous characters  . 
? A key is held down too long , generating sequences of identical letters . 
E . g . 6 to nnne , access , be a au conp , a artnership ? The finger strikes two contiguous keys at the same time  . 
E . g . 6 conomio que , 6 galememnt , profcessional , tlt gen ?' Influence ' of other letters in the same word  . 
E . g . 6 videme n l , , a6oroport , accueuillir , taboubli , electrolologist Other instances of insertion seem to be simply attribut-able to a lack of knowledge of the language  . 
E . g . 6 per due meot , absoluement , or tho paedic , paediatric . 
For another group of insertion-type errors , no obvious explanation could be found . 
E . g . constinu 6, lotusi , manchine , xperience p 4 . 2 . 4 Deletions The omission of a character is the most common typographical error  . This is probably related to a situation where rapid typing is required and where them ind might work faster than the hand  . t fere is a list of the ten most frequently omitted letters  ( the percentages are based on the total number of words in this chLs s  ) :
Letter rs in tep c1a - !% 9 . 4 9 . 2 6 . 3 5 . 85 . 8 5 . 4 3 . 2 3 . 1 2 . 5 2 . 2 qhble1:Most common deletions in the Han~rd
Lettereiran sucth % 9 . 2 6 . 4 5 . 6 4 . 514 . 1 3 . 8 3 . 0 2 . 6 2 . 6 1 . 9 Table 2: Most common deletions in Jobs 4 . 2 . 5 Subst i tut ions This is a fairly complex category  . Substitution of one letter for another can be typographical or orthographic n nature  . Some tentative explanations include : ? The letter is replaced by an adjacent letter  . 
E . g . ' indident ( incident ) , esperience ( experience ) , satisfai samte ( satisfaisante ) ? The wrong hand is used . 
E . g . quesque ( quelque ) , gouvervement ( gouveroement ) ? The letter is ' influenced ' by another letter in the same word  . 
E . g . bubget ( budget ) , songages ( on dages ) , stell ( steel ) ? The error is orthographic in nature . 
E . g . maintenence ( maintenance ) , engouragement ( encouragement ) , auvrage ( naufrage ) - Other substitution secape simple explanations . 
E . g . da(de ), ja(je ), saire(fake ) 4 . 2 . 6 Transpositions There are three types of transpositions : ? Inversion of adjacent letters  . 
E . g . appear nace , appmpraite , commerical ? Inversion of nonadjacent letters . 
E . g . 6 no comique , an amulie , condiser , ditues ? Although not strictly speaking a transposition  , we also include here the displacement of a single letter  . 
E . g . avatanges , comagpnies , avalaible , expierence 4 . 2 . 7 Grammar There are not many errors under this heading  , since no syntactic analysis has been done in order to extract helist of unknown words  . What we have here are errors of morphology and conjugation  . 
E . g . 6 tEe(6t 6), pines(pin ), cloths ( clothes)4 . 2 . 8 Other There are a Iew remaining words which we could not lit in the other categories  ; ome of them are incorrect while others can be considered spelling variations flint are not fully standard  . 
E . g . tee shirt ( T-shirt ), thru ( through ) 5 . 0 Frequency of unknown words The Hansacd corpus contains  4   173   506 tokens . Among these tokens we found 2   982 distinct unknown words occurring 9   301 times . This represents 0 . 2% of all tokens . 
The Jobs corpus contains 140482 tokens . Of those ,   1   016 were distinct unknown words occurring 2   109 times . This represents 1 . 5% of all tokens . 
We now present in tabular form the frequency distribution of unknown words in built corpora  . For each type of unknown word we indicate the number of distinct words  ( cases ) and the total number of occurrences ( occ . ) found . 
ACRESDE COLING-92 , NA ~ Cn~S , 2328 Ao~r199241l Puoc . oF COLING-92, NA rer~s , Auo .  2328 , 1992 For each of these numbers , we also give the associated percentages over the total number of unknown words in both  G1 and G2  . Therefore the total percentages of G1 and G2 add up to 100 percent . 

Derived words
Foreign words
Scholarly words ! Parts of expressions
Garbled words



Regional words
Proper nouns
Total  #of cases %  #of occ .  % 526 17 . 22 ' 2814 29 . 93 392 12,83 2014 21 . 42 73 2 . 39 658 7 . 00 73 2 . 39 579 6 . 16 94 3 . 08 296 3 . 15 48 1 . 57 160 1 . 70 8 0 . 26 153 1 . 63 10 0 . 334 30A 61 80 . 59 26 0 . 28 8 0 . 26 21 0 . 22 1250 40 . 92 6764 71 . 93 in the Hansard Table 3: G1 frequencies
Type  #of cases %  #of occ .%
Deletions 6452 1.11976 10,38
Insertions 4061 3.2950 35.35
Accents 248 8.1241 44.40
Substitutions 230 7.5331 93.39
Grammar 141 4.62 258 2.74
Transpositions 135 4.42 169 1.80
Total 18055 9.0826 3928.07
Table 4: G2 frequencies in the Hansard
Type  #of cases %  #of occ .%
Garbled words 143 13.64 322 15.27
Foreign words 100.95 361.71
Total 153 14.78 358 16.97
Table 5: G1 frequencies in Jobs








Total  #of cases %  #of occ .  % 224 21 . 35 514 24 . 37 287 27 . 36 467 22 . 14 158 15 . 06 363 17 . 21 140 13 . 35 227 10 . 76 58 5 . 53 87 4 . 13 13 1 . 24 49 2 . 32 16 1 . 53 44 2 . 09 894 85 . 22 1751 83 . 03
Table 6: G2 frequencies in Jobs
The following points should be noted : ? A word containing two errors is accounted for in two categories  . This explains why the total is a slightly higher than the total number of unknown words given previously ?? In the Hansard there are  16 words ( 0 . 17% ) that contain more than one error per word and 94 words ( 1 . 01%) that belong to both GI and G2 ( e . g . a word can be incorrect and be derived at the same dine  )  . On the other hand . 
with Jobs there are 42 words (1 . 99%) that contain more than one error per word . These results are comparable to Damerau's findings about the preponderance of single error words  . 
? Of course , different extraction procedures give different results  . The Hansard contains a great many correct words not in the DMF  ; on the other hand the Jobs list of unknown words contains very few of those correct words  . When faced with a word they do not recognize immediately  , humans have the option of consulting a dictionary  ( general or specialized ) and even if the word is not in any of those , the person can still rely on his or her intuition about word composition and derivation in order to accept a word  . 
? In the case of the Hansard the total number of occurrences in  G1   ( 71 . 93% ) is much higher than the total number of occurrences in  G2   ( 28 . 07%) . This significant rest flt shows that instead of putting all of our efforts into trying to develop a better error correcter  , we would gain a lot from looking into ways of dealing with the deficiencies of our lexical databases  . 
? Since English does not have accents , this category is not represented in G2 of Jobs . 
? On the other hand , errors involving hyphens and apostrophes are very common in the Jobs corpus  . We classified these as punctuation errors . 
? We believe that the punctuation category of G2 Jobs is not representative of English in general . The high frequency of this type of error is due to a peculiarity of the AcrEs DE  COLING-92  , NANTES . 2328 AO~r1992412 PROC , Ol : COLING-92 , NANTES , AUG .  2328 ,   1992 program responsible for the input of job descriptions which encourages the use of hyphens to parenthesize text  . 
6.0 Recognizing unknown words
In this section we examine possible avenues of investigation designed to deal with the different unknown word types  . 
6.1 G2: Erroneous words
Wheu confronted with an unknown word , the ideal NLP system would be able to understand the text and to deal with what was intended by the writer  , and not just what he wrote . But of course this is not within the scope of current technology  . 
A more realistic goal is to try to deal with typographical errors and a lot of attention over the years has been given to the detection and correction of such errors  . Different methods have been proposed , some completely automatic , others mean to assist humans in proofreading , some practical and usable , others of theoretical interest only . 
For a good overview of this field of research we suggest \ [ Peterson  80\]  , while \ [ Pollock 82\] contains an extensive bibliography . 
Despite years of research , the detection and correction of typographical errors remains a problem not entirely resolved  . Commercial software as well as state-of-the-art techniques described in the literature can only propose approximate solutions  . No program is capable of detecting every error and capable of alway suggesting the right correction  . 
Despite their limitations , ome existing methods can still be useful and sometimes even better than most human correctors  . This fact is well illustrated by the success of commercial detector/corroctors available on the market  , despite an overall performance that can at best be described as acceptable \[ Dinnematinad Sanz  90\]  . 
in order to detect errors most techniques rely on a list of correct words known to the system  ( a dictionary )  , possibly augmented by a set of morphological roles  . 
Amongs the possible approaches to typographical error correction  , two method seem to be more successful than the others  . We can either compare the unknown word against each of the dictionary words and if one of those comes close enough to the original word according to some measure of similarity  , it can be used in its place ( for an example see\]Wagner and Fischer 74\] )  . Or we can take an erroneous word , undo all possible errors we want to detect and then search the dictionary to see if any of those potential corrections produces a valid word  . We call this method the hypothesis generation method  . For example a transposition error can be detected by transposing each pair of characters in the unknown word and then consult-lug the dictionary with the resulting words  . This essentially is the technique used in such programs as the  DEC-10 Spell software . 
The method based on a measure of similarity is too inefficient to be practical and is mostly of theoretical interest  . 
The latter is more efficient but also more approximate in that it is not guaranteed tim\[ we will find a correction if we did not expect he offending error  . 
\[ n  both cases the contents of the dictionary must be carefully selected  . It must be large enough to offer reasonable coverage  , but on the other hand there is a real danger of using a list of words that is too big  , in that a very extensive list will usually contain rare and archaic words that could correspond to errors on more frequent words  . 
An error correct or integrated in an NLP system should allow us to reduce the dictionary search space by comparing the erroneous word only with dictionary words complying with die syntactic and semantic requirements valid at that time in the processing  . This should make the search significantly more efficient  . For example , if at some point we are expecting a verb and we encounter an unknown word  , in order to suggest corrections we could limit ourselves and cousitler only the verbs in the dictionary  . 
due interesting aspect of typographical error correction method such as the hypothesis generation method is that they can also be used to correct some of the other types of errors  . So with these methods , not only do we have a ( somewhat approximate ) solution to insertion , deletion , transposition and substitution errors , but in some cases they will also solve punctuation  , accent and grammar errors . For example in the case of accents , we can extend the French alphabet with the possible accented letters and simply use this alphabet to generate more candidate corrections  . 
Again if the hypothesis generation method is chosen  , then further use can be made of the knowledge gained about he type of errors usually comufitted  . For example in order to minimize the number of hypotheses generated and to maximize the probability of tinding the right correction  , when testing the deletion of a character , one could attent pt to " reintroduce " the character only in the case of the  10 most frequent deletions . More anecdotal knowledge gained through the sifting of the list of uu-know u words could also be of  . some use . For example , duplication of consonants was a frequent type of insertion error and thus  . if only a few hypotheses are to be tried , unknown words with duplicate consonants could be considered prime candidates for insertion errors  . 
6.2 G1: Correct words
The results collected in the course of our study should at the very least  , influence the amount of effort put into dealing with each of the diflerentypes of errors  . The re-ACIT . SDECOLING-92 . NANTES , 2328 AO~T 19924 I3l'Roc . OFCOLING-92, NANTES , AUO .  2328 ,   1992 alization that a large percentage of unknown words are part of the  G1 group warrants renewed effort in treating this type of problem  . 
There will always bew~ds that a system cannot recognize  , if only because some of them belong to socalled open classes  . But we can still reduce the number of such . words . 
One obviousolution is to enrich the dictionary , for example with common abbreviations and expressions  . Another similar , but more modular solution consists in supplementing the basic dictionary with auxiliary dictionaries  . One could envision separate dictionaries for regional and scholarly words for example  . 
The ordinals found in our corpora could easily be recognized by a grammar describing the formation of roman numerals  . 
Foreign words represent a difficult problem . They are exceptions to the usual assumption that the whole text to be processed is expressed in the same language throughout  . 
Although it does not completely solve the problem , the detection of such signs as double quotes , setting the words apart from the text , could be used to suggest that the following unknown words might be foreign  . 
It might be possible to recognize garbled words and compounds by using methods similar to the ones used to treat  G2 words . For example the deletion of a necessary hyphen could be detected and possibly corrected as is done for the deletion of an ordinary character  . 
As we have seen , derived words represent an impressive percentage of the total number of unknown words  . Even if we were to enlarge the dictionary we would never be able to include very derived word  , for they are much too productive . Therefore the solution seems to lie in a rule -based description of derivation similar to the description of inflectional morphology  . This will require integrating detailed studies of affixation and of the structure and semantic ompositionality of derived words  . 
Finally , GI words are perhaps more difficult to process than  G2 words . As\[Hayes and Mouradian 81\] put it : " Since novel words are by definition ot in the known vocabulary  , how can we distinguish them from misspelling ?" Most of the time  ( but not always ) they will not be close enocagh to words in the dictionary for the system to make suggestions  . The best one can hope for in this situation is to deduce from the context he maximum amount of information about he word  , such as its role in the sentence . 
As for the ability to learn new vocabulary , this is beyond the capabilities of current artificial intelligence  . 
7.0 Acknowledgments
This work was conducted by the Computer-Assisted Translation group at the CCRIT  . For their participation i the data collection we are greatly indebted to Pierre Isa ~ belle  , Elliott Mackloviteh and Marie-Louise Hannan . We also wish to thank Marc Dymetman , Marie-Louise Hannah and Elliott Macklovitch for their helpful comments  . 
8 . 0 References \[ Bourbeau , Pinard 86\] Bourbeau , L . and Pinard , F . , Dictionnaire micro-informatis~6 du Fmn~ais ( DMF )  ,  1987 , Progiciels Bourbeau-Pinard Inc . , Montr6al . 
\[ Damerau 64\] Damerau , F . J . , A technique for computer detection and correction of spelling errors  , Comm . 
ACM , 1964, 7, 3, pp . 171-176.
\[ Dinnematinad Sanz 90\]D innematin , S . , and Sanz , D . , Sept correcteurs pour l'orthogmphe etla grammaire  , Sciencet Vie Micro ,  1990 , pp .  118-130 . 
\[ Foster 91\] Foster , G . E , Statistical lexieal disambigua-fion ,  1991 , Master's thesis , McGill University , 

\[ Hayes and Mouradian81\] Hayes , P . J . and Mouradian , G . V . , Flexible parsing , American Journal of Computational Linguistics ,  81 ,  7 ,  4 , pp .  232-242 . 
\ [ Peterson80\] Peterson , J . L . , Computer programs for detecting and correcting spelling errors  , Comm . 
ACM , 1980, 23, pp . 676-687.
\[ Pollock82\] Pollock , J . J . , Spelling error detection and correction by computer : some notes and a bibliography  , Journal of Documentation ,  1982 ,  38 ,  4 , pp . 

\[ Pollock and Zamora83\] Pollock J . J . and Zamora , A . , Collection and characterization of spelling errors in scientific and scholarly texts  , J . Am . Soc . Inf . Sc . , 1983, 34, 1, pp .  51-58 . 
\[Shiaty88\]Shiaty , A . E . ed . , Dictionnaire du franc , a is plus ,  1988 , CEC , Montr6al . 
\[Srihari85\]Srihari , S . N . , Computer text recognition and error correction ,  1985 , IEEE Computer Society
Press , Silver Spring.
\[Szanzer 69\] Szanzer . A . J . , Error-correcting methods in natural language processing  , Information Processing ,  1969 ,  68 ,  2 . 
\ [ Veronis88\] Veronis , J . , Correction of phonographic errors in natural language interfaces  , Comm . ACM , 1988, pp .  101-115 . 
\[Wagner and Fischer 74\] Wagner , R . A . and Fischer , M . 
J . , The string-to-string correction problem , JACM ,  1974 ,  21 , I , pp .  168-178 . 
AcrEsDECOL . ING-92, NANTES . 2328 ^ ot ~ r1992414PRoc . OFCOL 1NG-92 . NANTES , AUG .  2328, 1992
